{
    "pablohoffman": "Thanks for the improvement @akshar-raaj !\n. thanks @willingc!\n. Sounds good.\n\nShould we also add the Scrapy 0.24 requirement to setup.py and a requirements.txt file?. May also be worth mentioning the required version in the README. \n. Thanks for the improvement @akshar-raaj !\n. thanks @willingc!\n. Sounds good.\n\nShould we also add the Scrapy 0.24 requirement to setup.py and a requirements.txt file?. May also be worth mentioning the required version in the README. \n. ",
    "kmike": "I don't think it is an indent error, check https://docs.python.org/2/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops. But this `else` seems unnecessary; just `return item` should do the same.\n. Agree. \n\nI also think that the example project (and the tutorial) should show how to yield scrapy.Request and use callbacks other than the default 'parse', and how to use custom 'start_requests' - it is not clear how Scrapy works from this demo project. But that's another issue :)\n. I don't think it is an indent error, check https://docs.python.org/2/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops. But this `else` seems unnecessary; just `return item` should do the same.\n. Agree. \n\nI also think that the example project (and the tutorial) should show how to yield scrapy.Request and use callbacks other than the default 'parse', and how to use custom 'start_requests' - it is not clear how Scrapy works from this demo project. But that's another issue :)\n. ",
    "dangra": "thanks!\n. thanks!\n. ",
    "redapple": "@kmike , I've marked this project as deprecated.\r\nI'm cleaning things up.. @Granitas , indeed, CSS selectors are converted to XPath. And XPath is more powerful as you can go in any direction, even upwards, and have complex predicates and use string functions.\nThough, the killer feature of CSS Selectors to me is `.classname`, which is quite handy here for dmoz. The extra trailing space here:\n\n```\n<div class=\"site-item \">\n```\n\nis easy to get wrong.\nThe equivalent XPath is so ugly IMO (`descendant::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' site-item ')]`)\n`:nth-*(odd/even)` is also nice and shorter than with XPath, yet less useful.\n\nProbably dmoz is not the best website to use for an XPath tutorial in the end.\n. There's an open issue about this on parsel: https://github.com/scrapy/parsel/issues/13\n. Thanks for the heads up @mjrao !\r\nI've updated the README with a deprecation notice.. @mjrao , you can of course advertize a fork of yours into a dmoztools.net spider project.\r\nIt's just that Scrapy team will not be maintaining this outdated educational dmoz.org spider.. Hey @jonjack , it's great that you learned Scrapy that way!\r\nAs you understood, this `dirbot` repository is now deprecated and the Scrapy team has no intention of changing the codebase. Indeed, we're promoting https://github.com/scrapy/quotesbot\r\nFeel free to advertize your fork for other users coming to Scrapy from dirbot (there's a new [/r/scrapy/](https://www.reddit.com/r/scrapy/) if you want to post there). Hello @baitercel ,\r\nI'm afraid this repository is now deprecated. Please see the [deprecation notice in the README](https://github.com/scrapy/dirbot/blob/master/README.rst).\r\nThe Scrapy team will not accept patches to it anymore.\r\nAn equivalent education scrapy project is now at https://github.com/scrapy/quotesbot. @kmike , I've marked this project as deprecated.\r\nI'm cleaning things up.. @Granitas , indeed, CSS selectors are converted to XPath. And XPath is more powerful as you can go in any direction, even upwards, and have complex predicates and use string functions.\nThough, the killer feature of CSS Selectors to me is `.classname`, which is quite handy here for dmoz. The extra trailing space here:\n\n```\n<div class=\"site-item \">\n```\n\nis easy to get wrong.\nThe equivalent XPath is so ugly IMO (`descendant::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' site-item ')]`)\n`:nth-*(odd/even)` is also nice and shorter than with XPath, yet less useful.\n\nProbably dmoz is not the best website to use for an XPath tutorial in the end.\n. There's an open issue about this on parsel: https://github.com/scrapy/parsel/issues/13\n. Thanks for the heads up @mjrao !\r\nI've updated the README with a deprecation notice.. @mjrao , you can of course advertize a fork of yours into a dmoztools.net spider project.\r\nIt's just that Scrapy team will not be maintaining this outdated educational dmoz.org spider.. Hey @jonjack , it's great that you learned Scrapy that way!\r\nAs you understood, this `dirbot` repository is now deprecated and the Scrapy team has no intention of changing the codebase. Indeed, we're promoting https://github.com/scrapy/quotesbot\r\nFeel free to advertize your fork for other users coming to Scrapy from dirbot (there's a new [/r/scrapy/](https://www.reddit.com/r/scrapy/) if you want to post there). Hello @baitercel ,\r\nI'm afraid this repository is now deprecated. Please see the [deprecation notice in the README](https://github.com/scrapy/dirbot/blob/master/README.rst).\r\nThe Scrapy team will not accept patches to it anymore.\r\nAn equivalent education scrapy project is now at https://github.com/scrapy/quotesbot. ",
    "Granitosaurus": "I'm not sure if changing the `xpath()` approach to `css()` is a good idea. Throughout the whole tutorial we use xpath and xpath seems to be the default in general. Also I'm pretty sure css is being converted to xpath anyways so css selectors aren't even a real thing #xpathmasterrace :)\n. @redapple Yeah, it's really bothersome that xpath doesn't have a default alias for such class detection. However you can extend the xpath functions for lxml really easily as per http://lxml.de/extensions.html. \nCool gist for has-class behaviour: https://gist.github.com/shirk3y/458224083ce5464627bc\n\nThough I'm pretty sure that's beyond the scope of this tutorial but maybe this is worth mentioning somewhere in the docs that xpath can be extended with python functions in such way? Maybe even populate default ~~scrapy~~ parsel namespace with some shortcuts as the has-class from above?\n. I'm not sure if changing the `xpath()` approach to `css()` is a good idea. Throughout the whole tutorial we use xpath and xpath seems to be the default in general. Also I'm pretty sure css is being converted to xpath anyways so css selectors aren't even a real thing #xpathmasterrace :)\n. @redapple Yeah, it's really bothersome that xpath doesn't have a default alias for such class detection. However you can extend the xpath functions for lxml really easily as per http://lxml.de/extensions.html. \nCool gist for has-class behaviour: https://gist.github.com/shirk3y/458224083ce5464627bc\n\nThough I'm pretty sure that's beyond the scope of this tutorial but maybe this is worth mentioning somewhere in the docs that xpath can be extended with python functions in such way? Maybe even populate default ~~scrapy~~ parsel namespace with some shortcuts as the has-class from above?\n. ",
    "eliasdorneles": "Hey @paulojblack, thanks so much for the PR!\nSorry for taking long to handle this -- your changes were incorporated in #21 which also added PY3 compatibility.\nThanks a bunch! :+1: :+1: \n. Hey @WiseDoge !\nSorry for taking so long to finally handle this!\n\nWe've merged #21 which fixes the spider for the website changes among other code improvements.\nWe're also starting a new project [quotesbot](https://github.com/scrapy/quotesbot) that will use the same website used in the newly updated Scrapy tutorial.\n\nThanks again!! :+1: :+1: \n. Hello @andrewpost, thanks for the PR!\nSorry for taking long to handle this, we've merged #21 which fixes for the website changes among other code improvements.\nWe're starting a new project [quotesbot](https://github.com/scrapy/quotesbot) that will use the same website used in the newly updated Scrapy tutorial.\nThanks again!!\n. Hi, @zhugezuo, thanks for the fix !\nWe've ended up merging #21 which adds PY3 compatibility too.\nAlso, we're creating a [new project for the examples](https://github.com/scrapy/quotesbot) that will use quotes.toscrape.com just like the newly updated tutorial, which will help avoiding this problem in the future.\nThanks again!\n. Hi @halldor, thanks for the PR, sorry for taking long to handle this!\nWe've merged #21 which fixes for the website changes and also adds Python 3 compatibility, and we're starting a new [quotesbot project](https://github.com/scrapy/quotesbot) that will use quotes.toscrape.com just like the newly updated tutorial and will be better maintained.\nThanks again!! :+1: \n. Hey @paulojblack, thanks so much for the PR!\nSorry for taking long to handle this -- your changes were incorporated in #21 which also added PY3 compatibility.\nThanks a bunch! :+1: :+1: \n. Hey @WiseDoge !\nSorry for taking so long to finally handle this!\n\nWe've merged #21 which fixes the spider for the website changes among other code improvements.\nWe're also starting a new project [quotesbot](https://github.com/scrapy/quotesbot) that will use the same website used in the newly updated Scrapy tutorial.\n\nThanks again!! :+1: :+1: \n. Hello @andrewpost, thanks for the PR!\nSorry for taking long to handle this, we've merged #21 which fixes for the website changes among other code improvements.\nWe're starting a new project [quotesbot](https://github.com/scrapy/quotesbot) that will use the same website used in the newly updated Scrapy tutorial.\nThanks again!!\n. Hi, @zhugezuo, thanks for the fix !\nWe've ended up merging #21 which adds PY3 compatibility too.\nAlso, we're creating a [new project for the examples](https://github.com/scrapy/quotesbot) that will use quotes.toscrape.com just like the newly updated tutorial, which will help avoiding this problem in the future.\nThanks again!\n. Hi @halldor, thanks for the PR, sorry for taking long to handle this!\nWe've merged #21 which fixes for the website changes and also adds Python 3 compatibility, and we're starting a new [quotesbot project](https://github.com/scrapy/quotesbot) that will use quotes.toscrape.com just like the newly updated tutorial and will be better maintained.\nThanks again!! :+1: \n. ",
    "stummjr": "This looks good.\n\nWould be good to remove `from scrapy.selector import Selector` from `dmoz.py`, though.\n. This looks good.\n\nWould be good to remove `from scrapy.selector import Selector` from `dmoz.py`, though.\n. ",
    "aixocm": "www\n. www\n. ",
    "halldor": "No problem. I have to admit I didn't even check if there was already a PR with a fix for this. I just thought nobody cared enough.\n\nGood news. Scrapy is a great project and deserves good demos and documentation.\n. No problem. I have to admit I didn't even check if there was already a PR with a fix for this. I just thought nobody cared enough.\n\nGood news. Scrapy is a great project and deserves good demos and documentation.\n. ",
    "mjrao": "thanks for your reply.. thanks for your reply.. ",
    "jonjack": "@redapple no worries. @redapple no worries. ",
    "baitercel": "* add \"main.py\"  to  quick start\r\n* change \"www.dmoz.org\" to \"dmoztools.net\" . l see , think u . * add \"main.py\"  to  quick start\r\n* change \"www.dmoz.org\" to \"dmoztools.net\" . l see , think u . "
}