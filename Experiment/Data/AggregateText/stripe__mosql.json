{
    "nelhage": "That's not a goal of MoSQL. Bidirectional sync is much more complicated -- you have to worry about things like conflict resolution, and what to do if the collection map only exports some of the MongoDB fields.\n. Whoops. Looks like I trusted the docs, but didn't actually test that suggestion!\n\nIt looks like mongo-ruby-driver doesn't support `?readPreference` in URIs. I've opened a bug with 10gen: https://jira.mongodb.org/browse/RUBY-547\n\nIn the meanwhile, you can use `?slaveOk=true` in your connection strings. If you connect directly to a secondary, that will make the client not give that error, and if you connect to the replica set as a whole, that sets a \"secondary-preferred\" read preference, meaning it will try to read from a secondary if one is available.\n\nI'll update the docs.\n. Sorry, I was unclear -- a direct connection to a secondary **with `?slaveOk=true`** should work. The option means slightly different things when connecting to a replSet versus directly -- when talking to a single node, it just means \"It's OK if this node is a secondary\".\n. Thanks, merged!\n. We don't support pulling out individual fields in embedded documents, yet, unfortunately, although it is on the TODO list.\n. @andrewjshults My preference would be to support the existing format, and just upgrade it internally on load -- I think it should be unambiguous which format we're looking at. Happy to review further once you have something a little further along.\n. (sorry for the delay, been busy)\n\nHm. I think the one labelled as \"current new\" makes more sense to me. As your example shows, either one can be viewed as an extension of the current format, since the current format overloads the key to mean both source and destination. I think I like using the destination as the key, since it feels like you're more-clearly describing how to build up a SQL table from the Mongo collection, rather than vice-versa.\n\nIt also allows for more extensibility going forward -- you could support mapping the same mongo key to multiple places in SQL, or you could support `:source: [some expression syntax]`, to support doing more-complex transformations at import time. Both feel more natural in the \"current new\" syntax.\n. Hi,\n\nI just pushed MoSQL 0.2.0, which supports accessing elements inside sub-documents using dot notation. Please give it a try and let me know if works for you.\n. Interesting. Can you share your `collections.yml`? If you run the tailer with `-vvv`, it should print a \"processing op: ...\" line shortly before that WARN line -- can you send me that op? Feel free to redact any values, I am mostly interested in the structure of what the op is.\n. Thanks, that was helpful. I've found the bug -- we're not correctly interpreting certain update operations, which our ODM never performs, so we didn't see the bug. I'll push a patch shortly.\n. This should be fixed in git. Are you able to give that version a try?\n. Yeah, I would reimport. Sorry for that hastle.\n\nOn Fri, Feb 8, 2013 at 2:32 PM, Matthew Gordon notifications@github.comwrote:\n\n> Thanks for the quick assistance. I have switched to the github master and\n> I don't see any warnings in a few minutes of testing so I expect that the\n> issue is indeed fixed. I'll let you know if they return.\n> \n> Sounds like it's time for a reimport.\n> \n> \u2014\n> Reply to this email directly or view it on GitHubhttps://github.com/stripe/mosql/issues/5#issuecomment-13316465..\n. I have not tested mosql on Windows at all, but yes, it looks like the problem is that SIGUSR2 is not supported there. If you remove `USR2` from the list on `cli.rb:27`, does that solve the problem? There is no requirement for USR2 -- we just trap it as part of how our production environment works.\n. That looks like a syntax error in your collections.yaml. Opened #7 to have a better error message here.\n. Thanks for the report! There was a bug deleting rows that use object IDs, which I've just fixed (and pushed a test for). It should be safe to upgrade and resume tailing without a re-import.\n. Thanks for the report, and the compliments! I see the bug, working on a fix now.\n. Does that fix it for you?\n. Great, that's been a multiply-requested feature, and I'd love to merge it, I just haven't had the time yet.\n. Hm, this should definitely have a better error message.\n\nIs your mongo server running as part of a replica set? You need to run mosql against a replica set, as documented here: http://docs.mongodb.org/manual/replication/\n. Yeah, the intent when I made that a warning was to support doing imports against a non-replSet, but I never actually implemented it. I'll update this ticket to track the fact that that should be possible.\n. (CC @andrewjshults, who has also been thinking about this)\n\nI'm definitely open to the idea of supporting unrolling into relational tables. There are a bunch of tricky questions I don't have good answers, too, though, such as what to use for unique IDs on the unrolled tables, and how you manage updates -- we don't actually see, e.g. `$pop` operations as such in the oplog, we just see a `$set` of the entire array. Do you have to in general do a diff of some sort against the existing array to figure out what updates to perform?\n\nI haven't had time to give this a ton of thought, and I think there may not be perfectly clean answers to all of these questions, but I'd be open to something workable if someone has the time to think about it harder.\n. I'm not particularly familiar with the capabilities of PostgreSQL's updatable views, off hand. If someone more up to speed on them wants to propose something, I'd be happy to think about it.\n. Hi,\n\nCurrently, the only support is that if you specify `extra_props: true`, the document will end up in the `_extra_props` column in postgres, as part of a JSON document. See #4 for some more ongoing work on better support for embedded documents.\n. Thanks!\n. I opted to instead remove the `require 'bundler/setup'` lines, since there's no reason we actually require bundler, they're just there for convenience during development.\n. Hey -- thanks for this PR. This looks pretty good, and I'd be happy to take something like this.\n\nUnfortunately, the code currently has some implicit assumptions that the SQL primary key is named `_id`, so your example of renaming `_id` doesn't work. I've pushed a commit to the pr-15 branch that contains a test case demonstrating the problem.\n\nIf you wanted to, I'd love to remove the implicit `_id` assumption and make this work, but as a stop-gap, I'd also just merge a version that adds an assertion that `_id` is not renamed, with the plan of improving the situation later.\n. Thanks! Merged, with some slight cleanup and an extra test.\n. Thanks for the PR! I may or may not be able to take a good look at this until early next week, but this definitely looks like a potentially very useful extension.\n. Hey, taking a closer look at this now.\n\nI'm not sure I totally understand the example in the README. What is `@db[:repositories]`? That's not in the config file, is this some SQL table maintained outside the MoSQL system?\n\nAlso, where does the `customer_id` field on the `orders` table come from? Are you creating the order table outside of MoSQL?\n\nI don't totally understand the point of the example. You're effectively translating the the mongodb OIDs into some kind of SQL ID? Why aren't the SQL IDs just the same as the (stringified) SQL IDs?\n. (Sorry for my delayed response)\n\nThat makes sense. Yeah, I think I'd like to see a self-contained example in the docs, ideally one that could be run completely using the included code.\n\nI think this is probably worth merging in some form; I'll go through and do some closer review of the actual code this week.\n. Hrm. Sorry, I've been busy and kinda procrastinating. Thinking about this some more, I think the right way to get this kind of extensibility might be, instead of adding a weird hook to load code, to do some slight refactoring to make it possible to pull in `MoSQL` as a library, and then call methods to inject yourself into the stream process. That would be even more flexible than the proposed approach, and would let you manage the hook code and versioning and all that just as another rubygem, which would be better, operationally. If that sounds acceptable, I'd be happy to do that work and throw up an example of using it to get the functionality demonstrated in the examples so far.\n. Thanks for the report. I just pushed a fix to that crash.\n\nIf it stop running for a few days, whether or not resuming tailing is safe does depend on how much oplog is available.  You can tell this via `db.getReplicationInfo()` in the mongo shell, or by looking at the `local.oplog.rs` collection directly.\n\nOf course, even if you can catch up, if you're far enough behind and you have enough write volume, it might be faster to just reimport regardless.\n. Hi Matthew,\n\nDo you have logs from the MoSQL import? Are there any lines at WARN priority? (you can just grep for `WARN`). At the moment, if MoSQL encounters records that don't match the declared schema, it will ignore them and issue a WARN-level log statement.\n\nThe duplicate inserts are harmless -- MoSQL implements \"upsert\" by doing an `INSERT` and catching the duplicate-key exception and doing an `UPDATE` instead. I actually just pushed a change today that reworks this logic to avoid the exceptions in the Postgres logs, since they're noisy and worrying if you don't know to expect them.\n. Hi,\n\nI haven't heard any reply in about a month, so I'm going to close this issue. Please feel free to re-open if you're still seeing problems. \n. A cowoker should be merging a branch that will format arrays as JSON, in which case you can parse them using PostgreSQL 9.3's native JSON operators, or by helper functions written in some extension language (e.g. I have some helpers written in plv8 that we use). Unfortunately, those are the best options at present.\n. Hi,\n\nI agree that we could do better here in general. Do you have an example that produces that specific error, so I can make sure we handle it more gracefully?\n. You can run an initial import against a non-replset, but you won't be able to mirror changes in realtime, since that feature depends on the replication oplog.\n\nYou don't need to have multiple nodes, however -- you just need to be running the mongod with `--replSet`, which will cause it to maintain the oplog, even if it is a single-node cluster.\n. I'd love to see someone play with this! I am not aware of any work in this direction, although we've thrown around the idea (but never implemented anything) at Stripe. Dealing with nested hashes in some way is indeed the first obvious issue I see, but should be resolvable in some way.\n. Thanks for the report! I couldn't initially find a way to get error codes out of Sequel exceptions, but I apparently wasn't digging hard enough!\n. That's a reasonable optimization. It's also vaguely on my list to try to optimize `$set` ops to not need to read the original record in from Mongo, and just translate the the op directly to SQL..\n\nWe tend to use postgres schemas that map most of the columns from mongo, so the optimization of skipping some ops wouldn't be a huge win in our environment, but I'd happily look at a patch if someone else was interested.\n. We currently rely on postgres-specific features (notably Postgres' `COPY` for initial bulk import). It probably wouldn't be too hard to refactor to support other backends, but it's not currently on my agenda.\n. The ones I know offhand:\n- `copy_data` in `lib/mosql/schema.rb`, used for initial bulk import. It should be easy to add a generic importer that uses `INSERT` and is portable (but slow), and then support backend-specific optimized versions.\n- `duplicate_key_error?` in `lib/mosql/sql.rb` depends on the `pg`-specific API to extract error codes from a database error. On MySQL, it might make sense to make `upsert` just do a `REPLACE` or something to implement `upsert`.\n\nThere may be more.\n. I haven't done so, and I don't know of anyone who has, offhand, but I'd be somewhat surprised if it doesn't work. If you run into any issues, I'd be happy to hear about them.\n. Hrm. What is your use case here? Won't this result in not getting any logging output, since we don't currently have a way to configure a logfile, and `Process.daemon` redirects output to `/dev/null`.\n\nMy recommended way of deploying MoSQL would be to use a process supervisor that monitors your processes as children, and manages redirecting stdout/stderr to a logfile for you. This allows all the logic of logging and daemonization and management to live in one standard tool, without requiring every utility to know how to manage it separately.\n\nSome common process supervisors that support this mode of operation are [supervisord](http://supervisord.org/), [daemontools](http://cr.yp.to/daemontools.html), [upstart](http://upstart.ubuntu.com/), and [systemd](http://www.freedesktop.org/wiki/Software/systemd/).\n. I haven't heard of anyone doing so, although I'd be happy to take a PR. The logic should probably go in or around `transform` in `lib/mosql/schema.rb`.\n\nWe use `COPY FROM` with CSV input for the initial bulk load; Do you know if it's possible to represent PostGIS data in that form?\n. Yeah, I definitely like the idea of having pluggable transformers for columns. It's something I've thought about, but haven't gotten time to implement, so I'd be happy to review a PR.\n. Hrm. I haven't encountered this before, but I'm happy to dig. Are you able to share the (redacted if necessary) record that is causing that error, as well as the collection map you are using? You should be able to find the record from a mongo shell via:\n\n`mongo> db.COLLECTIONNAME.findOne({_id: ObjectId(\"5233b00caddfe6c60c000003\")})`\n. ah-ha, I should have realized earlier -- I'm pretty sure this is just issue #23. I've just pushed MoSQL 0.3.0 to rubygems (we'd fixed the issue, but not done a release, previously). Can you give that a try, or else try running from git, and let me know if that fixes the problem?\n. The folks at Citus Data have actually already written that FDW, which I experiment with before writing MoSQL: https://github.com/citusdata/mongo_fdw\n\nMoSQL has several advantages, including:\n- By pulling all the data into local storage, `JOIN`s can be much more performant, since postgres has more ability to reason about and optimize them.\n- By copying data into a secondary store for analytics, we can isolate background analytics and reporting from having any impact on production systems.\n. If you want to improve the FDW and find that works better for your application, great! We've found that MoSQL works great for our use case, and believe that the model has several fundamental advantages, including performance of queries and aggregates, isolation from production, and the ability to write code in something other than C.\n. lgtm!\n. Thanks for the patchset! I'm super busy right now, but I'll try to look at this in more detail by early next week at the latest.\n. I'm fine taking this PR if you fix the things I've mentioned. I'd ideally like to see the code factored out so we have backend-specific adapters that implement a common interface, but I'm happy to merge this for now without that.\n. You probably need to install `libpq-dev` -- that's a native C dependency that the `pg` gem needs in order to compile.\n. What happens if you try it with the `/dbname` URL and add `--skip-tail`? If you don't have admin access to the database you will be able to use the live-streaming feature (which requires access to the replication log), but you should at least be able to do a one-time import.\n. Yeah, that could be fixed. The reason for that logic was that we use a single `collections.yaml` schema file for all of our replsets (each replset has a disjoin set of logical databases), and so we needed to discover which databases actually exist in the `mongod` to sync, instead of blindly connecting to all the databases. I'd happily take a PR that does something more clever.\n. Looks plausible. Have you tested this end-to-end -- i.e. actually running some data through a schema file that declares a JSON `_extra_props`?\n. cool! Thanks for the PR.\n. The high-level picture is simple: You will need to discover each of the backing shards, and tail them individually, tracking state separately.\n\nThe thorny issue comes around chunk migrations by mongos. You'll want to double-check how those end up represented in the oplog, but I'm pretty sure you'll see an insert on the destination shard, followed later by a deletion on the source shard. A naive implementation that tails every oplog would thus follow the delete, even though the document still exists in the sharded cluster as a whole.\n\nI have a few thoughts for how to fix this, but no solution I really like.\n. One option is, for each record in postgres, to keep track (in an additional column, managed entirely by MoSQL) of which shards it exists in. An insert appends to that set (if the record already exists), and a delete removes; If the set ever becomes empty, you can delete the record.\n\nOne option is to, on delete, consul the `mongoc` _possibly by way of the `mongos`' APIs) to determine whether the shard that's being deleted from is the canonical location of the record, and ignore the delete if not. This has some problems where the `mongoc` represents the *current_ mapping, but you're tailing the oplog potentially some distance in the past, and it's possible there have been additional `mongoc` updates since then.\n\nOne option is to hope that the oplog contains enough information to detect this situation directly. I haven't looked into whether that's true. Even if it is you need to handle the case where `mosql` exits mid-migration, so that on resumption it won't see the past -- i.e. you'll need to reflect all state into the database table `mosql` uses to store its state.\n\nI think that's basically all the ideas I've had. I'll update this issue if I recall / think of more.\n. @goutamdan Can you your database against b1a9eda? That fixes the most obvious issue, but I haven't done an end-to-end test yet.\n. Will this properly create the schema as an array type? I'd love to take a patch to do this, but I think we'll need some way to denote in the collection map that the column should be an array type, so that we can create the right schema. That'd also let us preserve compatibility with existing installations, by defaulting to JSON unless the schema calls out an array type.\n\nI'd also like to see some tests.\n. Thanks! Added a few small fixes on top, and merged.\n. cool, seems useful.\n. Can we name it `--only-db`? I think that gives a better sense of what the option does -- limits us to one database, directly, no matter how many are named.\n\nCan you also add a note to the README about this option and using MoSQL on hosted services?\n\nWith those changes, looks great!\n. Great, thanks for putting this together and the turnaround on those fixes!\n. @christinang89 Are you able to test the commit I just pushed in your environment? If that works, I'll merge and mark this as closed.\n. Hm, your backtrace suggests you're still running the installed `0.3.1` version. Did you clone the branch and try running directly out of there? I'm pretty sure this should fix it, so I'm happy to merge and cut a gem if that's easier for you.\n. awesome! Sorry, I was going to cut a release but got pulled away. I'll merge and do that now.\n. Oh wow, it hadn't even occurred to me that Mongo would support that. But yeah, this looks like a workable approach. Thanks for updating and writing the tests!\n. Hm. We should probably be doing this transformation for other types, too -- e.g. I bet we don't handle an array of `BSON::ObjectId`, either. Probably `transform` needs to walk the structure recursively.\n\nBut this patch should be an incremental improvement, so I'm happy to take this for now. Thanks for submitting it!\n. By default, `MoSQL` drops and re-creates all tables on an initial import, in order to ensure a clean import. You can pass `--no-drop-tables` to inhibit the dropping behavior, if necessary.\n\nIt will still print \"Creating table\", but with `--no-drop-tables` what that actually indicates is just that it's checking for existence and has found the table.\n\nMoSQL's `-v` option does not take a verbosity level; Try `-v -v -v` to get more debug output, and hopefully that will reveal more detail. I suspect that the problem may be on your postgres server in some form -- can you check whether the query is hanging on that end?\n. You can set `?slaveOk=true` or `?readPreference=secondary` in the connection URL.\n. The [README](https://github.com/stripe/mosql/#usage) documents this at the bottom of the \"Usage\" section, but I'd be happy to hear ideas for how to make that more discoverable\n. The README documents `?readPreference=secondary` and mentions doing initial imports against secondaries (mongo calls \"slave\" nodes secondaries, as of the \"new\" replication architecture)\n. Thanks! Should be resolved\n. Hm, I think this is from the new version failing earlier because your mapping doesn't have `_id` mapped (as I mentioned in #57). We should make this error out better, but MoSQL really isn't going to work for you unless you map in `_id`, unfortunately\n. MoSQL needs a node configured as `--replSet` in order to tail. You don't actually need a multiple-node cluster, but MoSQL relies on reading the MongoDB oplog in order to replicate data, which isn't written out unless the Mongo server is configured as a replset node.\n\nMoSQL requires that your collection map include a mapping for the `_id` field in order to properly replicate changes and to de-duplicate identical records. Since `_id` is the primary key on the MongoDB side, we can't tell whether a record is a duplicate or a new record unless we also preserve the `_id` field onto the Postgres side\n. Great, glad it's working out! I'll close this for now; I'd probably consider a PR adding documentation, but I won't likely get around to writing any just yet.\n. Hm, `clobber` doesn't seem like the right test. How would you feel about either:\n- Changing the text to \"ensuring table exists\"\n- Guarding with a `if !db.table_exists?`\n\n?\n. Yes, this is a potential issue, and MoSQL really should at least detect it and abort where possible.\n\nI'd have to think pretty hard about what happens with updates and deletes if you tail in a different thread -- for instance, if you see an update to an object before you've imported it, what do you do?\n\nGiven that Mongo's own replication has this same property, I suspect we'd be better off just detecting and aborting, instead of trying to be too clever about it.\n. One thing you can look at is the output of `db.getReplicationInfo()` in the mongo shell; That will give you statistics on the length of time preserved in the oplog. MoSQL needs to be able to do the initial import in that amount of time or less in order to not lose data.\n. Do you run a replica set in production, so that you can do an import from a secondary? That's our usual recommendation to avoid performance degradation.\n\nBut we could probably add a rate limit or throttle. If you want to experiment, adding something in `handle_op` would probably be the right place: https://github.com/stripe/mosql/blob/master/lib/mosql/streamer.rb#L195\n. Fascinating! Thanks for this, and looks good.\n. This seems pretty sensible to me. I feel like we should probably write some automated tests for actual oplog tailing, even if we won't be able to run them on Travis because their mongo's are not configured with an oplog -- we can just `skip` them, and run them locally when necessary\n. Those log lines are just informative, and not problems -- every `mongod` will have a `local` and `admin` database, and you probably don't want to import them, since they contain internal data.\n\nIf you run `mosql` with `-vvv` it will emit more debug information. Most likely, your `collections.yaml` file doesn't specify the correct `mongo` database, or has some other mistake.\n. Modulo the concerns around making sure we don't update timestamps too early, I think this lgtm.\n. Should be there now! Sorry about the delay.\n. Your input document has\n\n> \"tags\"=>\"[]\"\n\ni.e. it looks like the value is the stringified form of a JSON array. MoSQL expects `ARRAY` columns to be actual BSON arrays in the document, not JSON arrays. So the conversion is getting confused (and unfortunately we're giving a terrible error message).\n. `4fa0c49bc43e9e0700000085` is the record in your pasted logs I was looking at --  what do you get if you try the same check on that `_id`?\n. If you run an import with `-v`, it should show some basic stats about where the time is spent -- in SQL vs. reading/transforming the data. What does that show? Approximately what rate of import (documents/s) are you getting?\n. There's no option to do so, currently. You could force it to skip by populating the `mosql_tailers` table, which is where MoSQL stores its current progress. We do have a `--tail-from` option, to start tailing at a specific point, but it doesn't suppress the initial import. It's quite possible that it should, though.\n. :+1: \n. :+1: \n\nThere are sadly no tests because Travis doesn't run a replset, so I'd have to do some work to set up real tests :/\n. Yeah, I'm pretty sure there was no  good reason for that pickiness.\n. Awesome, thanks.\n. Can you paste a full stack trace?\n. @ryanatwork Just pushed a fix. If you're able to test it and confirm you're working again, that'd be awesome. I can cut a new release if that would be helpful.\n. Can you include more information about what concretely you're seeing, as well as some log output from running with `-vv`?\n. Yeah, I'd be happy to take this.\n. I believe this bug is fixed in 0.4.2, which I just pushed to rubygems. Can you test that and reopen if you still have this issue?\n. Hm. Did your cluster experience a failover or any other such event? Is there anything suspicious in the mongod logs?\n\nI'll dig a bit, but I'll note that if this only happens intermittently, it should be mostly safe to ignore, if you automatically restart mosql -- it's designed to handle crashes and recover automatically and safely.\n. @http301 looks like this broke the tests \u2013 can you resolve that somehow, and also add a test demonstrating the bug that this fixes?\n\nThanks!\n. The provided test case doesn't fail if I revert the rest of your changes, so if there is a real bug that's being fixed here, your test case isn't demonstrating it :/\n\nFrom the note you provided in email, I suspect (but am not positive) that you have a record in the database that contains non-UTF-8 in a string, which I'm concerned may be tricky to get Ruby to deal with in the way we want :/\n. I would like to see a test that demonstrates a correct behavior, that fails before the patch, and not after.\n\nThe test that's currently there fails before and passes after, but it's not clear to me why it's demonstrating a correct behavior \u2013 `force_encoding` a non-utf8 string into utf-8 would be surprising behavior at best. Is there a test that calls `handle_op` that demonstrates the behavior?\n. Thanks!\n. Hi,\n\nI strongly recommend running MoSQL with some sort of process management. MoSQL responds to a large variety of transient errors by just exiting, with the assumption that a process manager will restart it. We use daemontools at Stripe, which is unfortunately a slightly unusual choice.\n\nMoSQL doesn't support pid files. In general I recommend a process manager that obviates the need for pidfiles, such as by not daemonizing the child and remaining monitoring it directly.\n. Yeah, that seems plausible. I'd probably make it a CLI flag, `--limit` or something. I'd also consider `--query` or `--filter` that only applies to the initial import and takes a JSON-encoded query.\n. There's some discussion of using MoSQL with redshift in #38. I think the short version is that it's unlikely to work well, unfortunately.\n. Hey \u2013 I haven't looked at implement gridfs support, since I don't use it anywhere.\n\nI agree that adding support might be useful, and I'd consider a PR. It'd probably be easier to review a strawman PR than try to speculate about the code via a description.\n\nhex-encoding the binary data is _probably_ the way forward to fix the encoding issue, but I'd try to replicate it in a test and then add a bunch of debug prints or thereabouts to understand what's going on.\n. I just pushed a 0.4.3 \u2013 does that resolve your issue? Our dependencies in the gem are unfortunately sloppy at present :(\n. Thanks for this! I'd love to have at least some basic tests, though \u2013 is there anyone else on your team who might be able to help you out? I might be able to find some time to point you in the right direction, if not.\n. thanks!\n. thanks!\n. Can I ask you to add a test case for this new behavior? Otherwise, it seems reasonable.\n. We've definitely used that with success on 1.8.3. Have you verified that with `1.12.3` you're still hitting the primary (via `tcpdump` or `db.currentOp()` or whatever\u2026)\n. have you patched it in your environment and verify that it works on 1.8 for you?\n. Ugh, that's exciting. Thanks for digging into this. I probably don't have time to get things working on 2.x, so it sounds like rolling back is probably the best bet.\n. MoSQL relies on the idempotence of the oplog, and only updates the database once every minute or so. If your application can tolerate a small amount of replay in a failure situation, this is an easy trick.\n\n10 updates per second seems quite slow, even for durable writes to postgres, if you have a remotely beefy database machine. Consider investing in tuning or profiling your database.\n. That's not a goal of MoSQL. Bidirectional sync is much more complicated -- you have to worry about things like conflict resolution, and what to do if the collection map only exports some of the MongoDB fields.\n. Whoops. Looks like I trusted the docs, but didn't actually test that suggestion!\n\nIt looks like mongo-ruby-driver doesn't support `?readPreference` in URIs. I've opened a bug with 10gen: https://jira.mongodb.org/browse/RUBY-547\n\nIn the meanwhile, you can use `?slaveOk=true` in your connection strings. If you connect directly to a secondary, that will make the client not give that error, and if you connect to the replica set as a whole, that sets a \"secondary-preferred\" read preference, meaning it will try to read from a secondary if one is available.\n\nI'll update the docs.\n. Sorry, I was unclear -- a direct connection to a secondary **with `?slaveOk=true`** should work. The option means slightly different things when connecting to a replSet versus directly -- when talking to a single node, it just means \"It's OK if this node is a secondary\".\n. Thanks, merged!\n. We don't support pulling out individual fields in embedded documents, yet, unfortunately, although it is on the TODO list.\n. @andrewjshults My preference would be to support the existing format, and just upgrade it internally on load -- I think it should be unambiguous which format we're looking at. Happy to review further once you have something a little further along.\n. (sorry for the delay, been busy)\n\nHm. I think the one labelled as \"current new\" makes more sense to me. As your example shows, either one can be viewed as an extension of the current format, since the current format overloads the key to mean both source and destination. I think I like using the destination as the key, since it feels like you're more-clearly describing how to build up a SQL table from the Mongo collection, rather than vice-versa.\n\nIt also allows for more extensibility going forward -- you could support mapping the same mongo key to multiple places in SQL, or you could support `:source: [some expression syntax]`, to support doing more-complex transformations at import time. Both feel more natural in the \"current new\" syntax.\n. Hi,\n\nI just pushed MoSQL 0.2.0, which supports accessing elements inside sub-documents using dot notation. Please give it a try and let me know if works for you.\n. Interesting. Can you share your `collections.yml`? If you run the tailer with `-vvv`, it should print a \"processing op: ...\" line shortly before that WARN line -- can you send me that op? Feel free to redact any values, I am mostly interested in the structure of what the op is.\n. Thanks, that was helpful. I've found the bug -- we're not correctly interpreting certain update operations, which our ODM never performs, so we didn't see the bug. I'll push a patch shortly.\n. This should be fixed in git. Are you able to give that version a try?\n. Yeah, I would reimport. Sorry for that hastle.\n\nOn Fri, Feb 8, 2013 at 2:32 PM, Matthew Gordon notifications@github.comwrote:\n\n> Thanks for the quick assistance. I have switched to the github master and\n> I don't see any warnings in a few minutes of testing so I expect that the\n> issue is indeed fixed. I'll let you know if they return.\n> \n> Sounds like it's time for a reimport.\n> \n> \u2014\n> Reply to this email directly or view it on GitHubhttps://github.com/stripe/mosql/issues/5#issuecomment-13316465..\n. I have not tested mosql on Windows at all, but yes, it looks like the problem is that SIGUSR2 is not supported there. If you remove `USR2` from the list on `cli.rb:27`, does that solve the problem? There is no requirement for USR2 -- we just trap it as part of how our production environment works.\n. That looks like a syntax error in your collections.yaml. Opened #7 to have a better error message here.\n. Thanks for the report! There was a bug deleting rows that use object IDs, which I've just fixed (and pushed a test for). It should be safe to upgrade and resume tailing without a re-import.\n. Thanks for the report, and the compliments! I see the bug, working on a fix now.\n. Does that fix it for you?\n. Great, that's been a multiply-requested feature, and I'd love to merge it, I just haven't had the time yet.\n. Hm, this should definitely have a better error message.\n\nIs your mongo server running as part of a replica set? You need to run mosql against a replica set, as documented here: http://docs.mongodb.org/manual/replication/\n. Yeah, the intent when I made that a warning was to support doing imports against a non-replSet, but I never actually implemented it. I'll update this ticket to track the fact that that should be possible.\n. (CC @andrewjshults, who has also been thinking about this)\n\nI'm definitely open to the idea of supporting unrolling into relational tables. There are a bunch of tricky questions I don't have good answers, too, though, such as what to use for unique IDs on the unrolled tables, and how you manage updates -- we don't actually see, e.g. `$pop` operations as such in the oplog, we just see a `$set` of the entire array. Do you have to in general do a diff of some sort against the existing array to figure out what updates to perform?\n\nI haven't had time to give this a ton of thought, and I think there may not be perfectly clean answers to all of these questions, but I'd be open to something workable if someone has the time to think about it harder.\n. I'm not particularly familiar with the capabilities of PostgreSQL's updatable views, off hand. If someone more up to speed on them wants to propose something, I'd be happy to think about it.\n. Hi,\n\nCurrently, the only support is that if you specify `extra_props: true`, the document will end up in the `_extra_props` column in postgres, as part of a JSON document. See #4 for some more ongoing work on better support for embedded documents.\n. Thanks!\n. I opted to instead remove the `require 'bundler/setup'` lines, since there's no reason we actually require bundler, they're just there for convenience during development.\n. Hey -- thanks for this PR. This looks pretty good, and I'd be happy to take something like this.\n\nUnfortunately, the code currently has some implicit assumptions that the SQL primary key is named `_id`, so your example of renaming `_id` doesn't work. I've pushed a commit to the pr-15 branch that contains a test case demonstrating the problem.\n\nIf you wanted to, I'd love to remove the implicit `_id` assumption and make this work, but as a stop-gap, I'd also just merge a version that adds an assertion that `_id` is not renamed, with the plan of improving the situation later.\n. Thanks! Merged, with some slight cleanup and an extra test.\n. Thanks for the PR! I may or may not be able to take a good look at this until early next week, but this definitely looks like a potentially very useful extension.\n. Hey, taking a closer look at this now.\n\nI'm not sure I totally understand the example in the README. What is `@db[:repositories]`? That's not in the config file, is this some SQL table maintained outside the MoSQL system?\n\nAlso, where does the `customer_id` field on the `orders` table come from? Are you creating the order table outside of MoSQL?\n\nI don't totally understand the point of the example. You're effectively translating the the mongodb OIDs into some kind of SQL ID? Why aren't the SQL IDs just the same as the (stringified) SQL IDs?\n. (Sorry for my delayed response)\n\nThat makes sense. Yeah, I think I'd like to see a self-contained example in the docs, ideally one that could be run completely using the included code.\n\nI think this is probably worth merging in some form; I'll go through and do some closer review of the actual code this week.\n. Hrm. Sorry, I've been busy and kinda procrastinating. Thinking about this some more, I think the right way to get this kind of extensibility might be, instead of adding a weird hook to load code, to do some slight refactoring to make it possible to pull in `MoSQL` as a library, and then call methods to inject yourself into the stream process. That would be even more flexible than the proposed approach, and would let you manage the hook code and versioning and all that just as another rubygem, which would be better, operationally. If that sounds acceptable, I'd be happy to do that work and throw up an example of using it to get the functionality demonstrated in the examples so far.\n. Thanks for the report. I just pushed a fix to that crash.\n\nIf it stop running for a few days, whether or not resuming tailing is safe does depend on how much oplog is available.  You can tell this via `db.getReplicationInfo()` in the mongo shell, or by looking at the `local.oplog.rs` collection directly.\n\nOf course, even if you can catch up, if you're far enough behind and you have enough write volume, it might be faster to just reimport regardless.\n. Hi Matthew,\n\nDo you have logs from the MoSQL import? Are there any lines at WARN priority? (you can just grep for `WARN`). At the moment, if MoSQL encounters records that don't match the declared schema, it will ignore them and issue a WARN-level log statement.\n\nThe duplicate inserts are harmless -- MoSQL implements \"upsert\" by doing an `INSERT` and catching the duplicate-key exception and doing an `UPDATE` instead. I actually just pushed a change today that reworks this logic to avoid the exceptions in the Postgres logs, since they're noisy and worrying if you don't know to expect them.\n. Hi,\n\nI haven't heard any reply in about a month, so I'm going to close this issue. Please feel free to re-open if you're still seeing problems. \n. A cowoker should be merging a branch that will format arrays as JSON, in which case you can parse them using PostgreSQL 9.3's native JSON operators, or by helper functions written in some extension language (e.g. I have some helpers written in plv8 that we use). Unfortunately, those are the best options at present.\n. Hi,\n\nI agree that we could do better here in general. Do you have an example that produces that specific error, so I can make sure we handle it more gracefully?\n. You can run an initial import against a non-replset, but you won't be able to mirror changes in realtime, since that feature depends on the replication oplog.\n\nYou don't need to have multiple nodes, however -- you just need to be running the mongod with `--replSet`, which will cause it to maintain the oplog, even if it is a single-node cluster.\n. I'd love to see someone play with this! I am not aware of any work in this direction, although we've thrown around the idea (but never implemented anything) at Stripe. Dealing with nested hashes in some way is indeed the first obvious issue I see, but should be resolvable in some way.\n. Thanks for the report! I couldn't initially find a way to get error codes out of Sequel exceptions, but I apparently wasn't digging hard enough!\n. That's a reasonable optimization. It's also vaguely on my list to try to optimize `$set` ops to not need to read the original record in from Mongo, and just translate the the op directly to SQL..\n\nWe tend to use postgres schemas that map most of the columns from mongo, so the optimization of skipping some ops wouldn't be a huge win in our environment, but I'd happily look at a patch if someone else was interested.\n. We currently rely on postgres-specific features (notably Postgres' `COPY` for initial bulk import). It probably wouldn't be too hard to refactor to support other backends, but it's not currently on my agenda.\n. The ones I know offhand:\n- `copy_data` in `lib/mosql/schema.rb`, used for initial bulk import. It should be easy to add a generic importer that uses `INSERT` and is portable (but slow), and then support backend-specific optimized versions.\n- `duplicate_key_error?` in `lib/mosql/sql.rb` depends on the `pg`-specific API to extract error codes from a database error. On MySQL, it might make sense to make `upsert` just do a `REPLACE` or something to implement `upsert`.\n\nThere may be more.\n. I haven't done so, and I don't know of anyone who has, offhand, but I'd be somewhat surprised if it doesn't work. If you run into any issues, I'd be happy to hear about them.\n. Hrm. What is your use case here? Won't this result in not getting any logging output, since we don't currently have a way to configure a logfile, and `Process.daemon` redirects output to `/dev/null`.\n\nMy recommended way of deploying MoSQL would be to use a process supervisor that monitors your processes as children, and manages redirecting stdout/stderr to a logfile for you. This allows all the logic of logging and daemonization and management to live in one standard tool, without requiring every utility to know how to manage it separately.\n\nSome common process supervisors that support this mode of operation are [supervisord](http://supervisord.org/), [daemontools](http://cr.yp.to/daemontools.html), [upstart](http://upstart.ubuntu.com/), and [systemd](http://www.freedesktop.org/wiki/Software/systemd/).\n. I haven't heard of anyone doing so, although I'd be happy to take a PR. The logic should probably go in or around `transform` in `lib/mosql/schema.rb`.\n\nWe use `COPY FROM` with CSV input for the initial bulk load; Do you know if it's possible to represent PostGIS data in that form?\n. Yeah, I definitely like the idea of having pluggable transformers for columns. It's something I've thought about, but haven't gotten time to implement, so I'd be happy to review a PR.\n. Hrm. I haven't encountered this before, but I'm happy to dig. Are you able to share the (redacted if necessary) record that is causing that error, as well as the collection map you are using? You should be able to find the record from a mongo shell via:\n\n`mongo> db.COLLECTIONNAME.findOne({_id: ObjectId(\"5233b00caddfe6c60c000003\")})`\n. ah-ha, I should have realized earlier -- I'm pretty sure this is just issue #23. I've just pushed MoSQL 0.3.0 to rubygems (we'd fixed the issue, but not done a release, previously). Can you give that a try, or else try running from git, and let me know if that fixes the problem?\n. The folks at Citus Data have actually already written that FDW, which I experiment with before writing MoSQL: https://github.com/citusdata/mongo_fdw\n\nMoSQL has several advantages, including:\n- By pulling all the data into local storage, `JOIN`s can be much more performant, since postgres has more ability to reason about and optimize them.\n- By copying data into a secondary store for analytics, we can isolate background analytics and reporting from having any impact on production systems.\n. If you want to improve the FDW and find that works better for your application, great! We've found that MoSQL works great for our use case, and believe that the model has several fundamental advantages, including performance of queries and aggregates, isolation from production, and the ability to write code in something other than C.\n. lgtm!\n. Thanks for the patchset! I'm super busy right now, but I'll try to look at this in more detail by early next week at the latest.\n. I'm fine taking this PR if you fix the things I've mentioned. I'd ideally like to see the code factored out so we have backend-specific adapters that implement a common interface, but I'm happy to merge this for now without that.\n. You probably need to install `libpq-dev` -- that's a native C dependency that the `pg` gem needs in order to compile.\n. What happens if you try it with the `/dbname` URL and add `--skip-tail`? If you don't have admin access to the database you will be able to use the live-streaming feature (which requires access to the replication log), but you should at least be able to do a one-time import.\n. Yeah, that could be fixed. The reason for that logic was that we use a single `collections.yaml` schema file for all of our replsets (each replset has a disjoin set of logical databases), and so we needed to discover which databases actually exist in the `mongod` to sync, instead of blindly connecting to all the databases. I'd happily take a PR that does something more clever.\n. Looks plausible. Have you tested this end-to-end -- i.e. actually running some data through a schema file that declares a JSON `_extra_props`?\n. cool! Thanks for the PR.\n. The high-level picture is simple: You will need to discover each of the backing shards, and tail them individually, tracking state separately.\n\nThe thorny issue comes around chunk migrations by mongos. You'll want to double-check how those end up represented in the oplog, but I'm pretty sure you'll see an insert on the destination shard, followed later by a deletion on the source shard. A naive implementation that tails every oplog would thus follow the delete, even though the document still exists in the sharded cluster as a whole.\n\nI have a few thoughts for how to fix this, but no solution I really like.\n. One option is, for each record in postgres, to keep track (in an additional column, managed entirely by MoSQL) of which shards it exists in. An insert appends to that set (if the record already exists), and a delete removes; If the set ever becomes empty, you can delete the record.\n\nOne option is to, on delete, consul the `mongoc` _possibly by way of the `mongos`' APIs) to determine whether the shard that's being deleted from is the canonical location of the record, and ignore the delete if not. This has some problems where the `mongoc` represents the *current_ mapping, but you're tailing the oplog potentially some distance in the past, and it's possible there have been additional `mongoc` updates since then.\n\nOne option is to hope that the oplog contains enough information to detect this situation directly. I haven't looked into whether that's true. Even if it is you need to handle the case where `mosql` exits mid-migration, so that on resumption it won't see the past -- i.e. you'll need to reflect all state into the database table `mosql` uses to store its state.\n\nI think that's basically all the ideas I've had. I'll update this issue if I recall / think of more.\n. @goutamdan Can you your database against b1a9eda? That fixes the most obvious issue, but I haven't done an end-to-end test yet.\n. Will this properly create the schema as an array type? I'd love to take a patch to do this, but I think we'll need some way to denote in the collection map that the column should be an array type, so that we can create the right schema. That'd also let us preserve compatibility with existing installations, by defaulting to JSON unless the schema calls out an array type.\n\nI'd also like to see some tests.\n. Thanks! Added a few small fixes on top, and merged.\n. cool, seems useful.\n. Can we name it `--only-db`? I think that gives a better sense of what the option does -- limits us to one database, directly, no matter how many are named.\n\nCan you also add a note to the README about this option and using MoSQL on hosted services?\n\nWith those changes, looks great!\n. Great, thanks for putting this together and the turnaround on those fixes!\n. @christinang89 Are you able to test the commit I just pushed in your environment? If that works, I'll merge and mark this as closed.\n. Hm, your backtrace suggests you're still running the installed `0.3.1` version. Did you clone the branch and try running directly out of there? I'm pretty sure this should fix it, so I'm happy to merge and cut a gem if that's easier for you.\n. awesome! Sorry, I was going to cut a release but got pulled away. I'll merge and do that now.\n. Oh wow, it hadn't even occurred to me that Mongo would support that. But yeah, this looks like a workable approach. Thanks for updating and writing the tests!\n. Hm. We should probably be doing this transformation for other types, too -- e.g. I bet we don't handle an array of `BSON::ObjectId`, either. Probably `transform` needs to walk the structure recursively.\n\nBut this patch should be an incremental improvement, so I'm happy to take this for now. Thanks for submitting it!\n. By default, `MoSQL` drops and re-creates all tables on an initial import, in order to ensure a clean import. You can pass `--no-drop-tables` to inhibit the dropping behavior, if necessary.\n\nIt will still print \"Creating table\", but with `--no-drop-tables` what that actually indicates is just that it's checking for existence and has found the table.\n\nMoSQL's `-v` option does not take a verbosity level; Try `-v -v -v` to get more debug output, and hopefully that will reveal more detail. I suspect that the problem may be on your postgres server in some form -- can you check whether the query is hanging on that end?\n. You can set `?slaveOk=true` or `?readPreference=secondary` in the connection URL.\n. The [README](https://github.com/stripe/mosql/#usage) documents this at the bottom of the \"Usage\" section, but I'd be happy to hear ideas for how to make that more discoverable\n. The README documents `?readPreference=secondary` and mentions doing initial imports against secondaries (mongo calls \"slave\" nodes secondaries, as of the \"new\" replication architecture)\n. Thanks! Should be resolved\n. Hm, I think this is from the new version failing earlier because your mapping doesn't have `_id` mapped (as I mentioned in #57). We should make this error out better, but MoSQL really isn't going to work for you unless you map in `_id`, unfortunately\n. MoSQL needs a node configured as `--replSet` in order to tail. You don't actually need a multiple-node cluster, but MoSQL relies on reading the MongoDB oplog in order to replicate data, which isn't written out unless the Mongo server is configured as a replset node.\n\nMoSQL requires that your collection map include a mapping for the `_id` field in order to properly replicate changes and to de-duplicate identical records. Since `_id` is the primary key on the MongoDB side, we can't tell whether a record is a duplicate or a new record unless we also preserve the `_id` field onto the Postgres side\n. Great, glad it's working out! I'll close this for now; I'd probably consider a PR adding documentation, but I won't likely get around to writing any just yet.\n. Hm, `clobber` doesn't seem like the right test. How would you feel about either:\n- Changing the text to \"ensuring table exists\"\n- Guarding with a `if !db.table_exists?`\n\n?\n. Yes, this is a potential issue, and MoSQL really should at least detect it and abort where possible.\n\nI'd have to think pretty hard about what happens with updates and deletes if you tail in a different thread -- for instance, if you see an update to an object before you've imported it, what do you do?\n\nGiven that Mongo's own replication has this same property, I suspect we'd be better off just detecting and aborting, instead of trying to be too clever about it.\n. One thing you can look at is the output of `db.getReplicationInfo()` in the mongo shell; That will give you statistics on the length of time preserved in the oplog. MoSQL needs to be able to do the initial import in that amount of time or less in order to not lose data.\n. Do you run a replica set in production, so that you can do an import from a secondary? That's our usual recommendation to avoid performance degradation.\n\nBut we could probably add a rate limit or throttle. If you want to experiment, adding something in `handle_op` would probably be the right place: https://github.com/stripe/mosql/blob/master/lib/mosql/streamer.rb#L195\n. Fascinating! Thanks for this, and looks good.\n. This seems pretty sensible to me. I feel like we should probably write some automated tests for actual oplog tailing, even if we won't be able to run them on Travis because their mongo's are not configured with an oplog -- we can just `skip` them, and run them locally when necessary\n. Those log lines are just informative, and not problems -- every `mongod` will have a `local` and `admin` database, and you probably don't want to import them, since they contain internal data.\n\nIf you run `mosql` with `-vvv` it will emit more debug information. Most likely, your `collections.yaml` file doesn't specify the correct `mongo` database, or has some other mistake.\n. Modulo the concerns around making sure we don't update timestamps too early, I think this lgtm.\n. Should be there now! Sorry about the delay.\n. Your input document has\n\n> \"tags\"=>\"[]\"\n\ni.e. it looks like the value is the stringified form of a JSON array. MoSQL expects `ARRAY` columns to be actual BSON arrays in the document, not JSON arrays. So the conversion is getting confused (and unfortunately we're giving a terrible error message).\n. `4fa0c49bc43e9e0700000085` is the record in your pasted logs I was looking at --  what do you get if you try the same check on that `_id`?\n. If you run an import with `-v`, it should show some basic stats about where the time is spent -- in SQL vs. reading/transforming the data. What does that show? Approximately what rate of import (documents/s) are you getting?\n. There's no option to do so, currently. You could force it to skip by populating the `mosql_tailers` table, which is where MoSQL stores its current progress. We do have a `--tail-from` option, to start tailing at a specific point, but it doesn't suppress the initial import. It's quite possible that it should, though.\n. :+1: \n. :+1: \n\nThere are sadly no tests because Travis doesn't run a replset, so I'd have to do some work to set up real tests :/\n. Yeah, I'm pretty sure there was no  good reason for that pickiness.\n. Awesome, thanks.\n. Can you paste a full stack trace?\n. @ryanatwork Just pushed a fix. If you're able to test it and confirm you're working again, that'd be awesome. I can cut a new release if that would be helpful.\n. Can you include more information about what concretely you're seeing, as well as some log output from running with `-vv`?\n. Yeah, I'd be happy to take this.\n. I believe this bug is fixed in 0.4.2, which I just pushed to rubygems. Can you test that and reopen if you still have this issue?\n. Hm. Did your cluster experience a failover or any other such event? Is there anything suspicious in the mongod logs?\n\nI'll dig a bit, but I'll note that if this only happens intermittently, it should be mostly safe to ignore, if you automatically restart mosql -- it's designed to handle crashes and recover automatically and safely.\n. @http301 looks like this broke the tests \u2013 can you resolve that somehow, and also add a test demonstrating the bug that this fixes?\n\nThanks!\n. The provided test case doesn't fail if I revert the rest of your changes, so if there is a real bug that's being fixed here, your test case isn't demonstrating it :/\n\nFrom the note you provided in email, I suspect (but am not positive) that you have a record in the database that contains non-UTF-8 in a string, which I'm concerned may be tricky to get Ruby to deal with in the way we want :/\n. I would like to see a test that demonstrates a correct behavior, that fails before the patch, and not after.\n\nThe test that's currently there fails before and passes after, but it's not clear to me why it's demonstrating a correct behavior \u2013 `force_encoding` a non-utf8 string into utf-8 would be surprising behavior at best. Is there a test that calls `handle_op` that demonstrates the behavior?\n. Thanks!\n. Hi,\n\nI strongly recommend running MoSQL with some sort of process management. MoSQL responds to a large variety of transient errors by just exiting, with the assumption that a process manager will restart it. We use daemontools at Stripe, which is unfortunately a slightly unusual choice.\n\nMoSQL doesn't support pid files. In general I recommend a process manager that obviates the need for pidfiles, such as by not daemonizing the child and remaining monitoring it directly.\n. Yeah, that seems plausible. I'd probably make it a CLI flag, `--limit` or something. I'd also consider `--query` or `--filter` that only applies to the initial import and takes a JSON-encoded query.\n. There's some discussion of using MoSQL with redshift in #38. I think the short version is that it's unlikely to work well, unfortunately.\n. Hey \u2013 I haven't looked at implement gridfs support, since I don't use it anywhere.\n\nI agree that adding support might be useful, and I'd consider a PR. It'd probably be easier to review a strawman PR than try to speculate about the code via a description.\n\nhex-encoding the binary data is _probably_ the way forward to fix the encoding issue, but I'd try to replicate it in a test and then add a bunch of debug prints or thereabouts to understand what's going on.\n. I just pushed a 0.4.3 \u2013 does that resolve your issue? Our dependencies in the gem are unfortunately sloppy at present :(\n. Thanks for this! I'd love to have at least some basic tests, though \u2013 is there anyone else on your team who might be able to help you out? I might be able to find some time to point you in the right direction, if not.\n. thanks!\n. thanks!\n. Can I ask you to add a test case for this new behavior? Otherwise, it seems reasonable.\n. We've definitely used that with success on 1.8.3. Have you verified that with `1.12.3` you're still hitting the primary (via `tcpdump` or `db.currentOp()` or whatever\u2026)\n. have you patched it in your environment and verify that it works on 1.8 for you?\n. Ugh, that's exciting. Thanks for digging into this. I probably don't have time to get things working on 2.x, so it sounds like rolling back is probably the best bet.\n. MoSQL relies on the idempotence of the oplog, and only updates the database once every minute or so. If your application can tolerate a small amount of replay in a failure situation, this is an easy trick.\n\n10 updates per second seems quite slow, even for durable writes to postgres, if you have a remotely beefy database machine. Consider investing in tuning or profiling your database.\n. ",
    "mrgordon": "Thanks! Yeah a direct connection to a secondary gives the \"not master and slaveok=false\" response but slaveOk=true sounds like the way to go. Thanks!!\n. Thanks. Worked correctly. I had to switch from zsh to bash for the query string to work. Really loving this. It's part of our migration path off of Mongo\n. ``` yaml\nsome_dbname:\n  conversions:\n    :columns:\n    - _id: TEXT\n    - accurate: BOOLEAN\n    - adjusted_amount: DOUBLE PRECISION\n    - amount: DOUBLE PRECISION\n    - country: TEXT\n    - currency: TEXT\n    - external_id: TEXT\n    - external_type: TEXT\n    - finished_at: TIMESTAMP\n    - job_id: INTEGER\n    - judgments: INTEGER\n    - response: TEXT\n    - started_at: TIMESTAMP\n    - tainted: BOOLEAN\n    - uid: TEXT\n    - worker_id: INTEGER\n    - bonus_amount: DOUBLE PRECISION\n    :meta:\n      :table: conversions\n```\n\nDEBUG MoSQL: processing op: {\"ts\"=>seconds: 1360355811, increment: 76, \"h\"=>-5783231566697040009, \"op\"=>\"u\", \"ns\"=>\"some_dbname.conversions\", \"o2\"=>{\"_id\"=>BSON::ObjectId('51156129153d40539f0020ad')}, \"o\"=>{\"job_id\"=>166980, \"judgments\"=>8, \"finished_at\"=>2013-02-08 20:36:49 UTC, \"currency\"=>\"cents\", \"adjusted_amount\"=>1.23, \"country\"=>\"USA\", \"worker_id\"=>16055423, \"amount\"=>1.23, \"uid\"=>\"ABC\", \"accurate\"=>true, \"external_id\"=>\"123\", \"external_type\"=>\"something\", \"tainted\"=>true, \"started_at\"=>2013-02-08 20:33:46 UTC}}\n\nDEBUG MoSQL: upsert some_dbname.conversions: _id=\n\nDEBUG MoSQL: Transformed: [nil, true, 1.23, 1.23, \"USA\", \"cents\", \"123\", \"something\", 2013-02-08 20:36:49 UTC, 166980, 8, nil, 2013-02-08 20:33:46 UTC, true, \"ABC\", 16055423, nil]\nE, [2013-02-08T20:36:51.449228 #18490] ERROR -- : PG::Error: ERROR:  null value in column \"_id\" violates not-null constraint: INSERT INTO \"conversions\" (\"_id\", \"accurate\", \"adjusted_amount\", \"amount\", \"country\", \"currency\", \"external_id\", \"external_type\", \"finished_at\", \"job_id\", \"judgments\", \"response\", \"started_at\", \"tainted\", \"uid\", \"worker_id\", \"bonus_amount\") VALUES (NULL, true, 1.23, 1.23\n002, 'USA', 'cents', '123', 'something', '2013-02-08 20:36:49.548000+0000', 166980, 8, NULL, '2013-02-08 20:33:46.000000+0000', true, 'ABC', 16055423, NULL) RETURNING \"_id\"\n. Thanks for the quick assistance. I have switched to the github master and I don't see any warnings in a few minutes of testing so I expect that the issue is indeed fixed. I'll let you know if they return.\n\nSounds like it's time for a reimport.\n. You made it so easy it isn't much of a hassle ;)\n. Thanks for the fix and the info!\n\nOn Mar 25, 2013, at 7:20 PM, Nelson Elhage notifications@github.com wrote:\n\nThanks for the report. I just pushed a fix to that crash.\n\nIf it stop running for a few days, whether or not resuming tailing is safe\ndoes depend on how much oplog is available. You can tell this via\ndb.getReplicationInfo() in the mongo shell, or by looking at the\nlocal.oplog.rs collection directly.\n\nOf course, even if you can catch up, if you're far enough behind and you\nhave enough write volume, it might be faster to just reimport regardless.\n\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/stripe/mosql/issues/17#issuecomment-15437384\n.\n. Thanks! Yeah a direct connection to a secondary gives the \"not master and slaveok=false\" response but slaveOk=true sounds like the way to go. Thanks!!\n. Thanks. Worked correctly. I had to switch from zsh to bash for the query string to work. Really loving this. It's part of our migration path off of Mongo\n. ``` yaml\nsome_dbname:\n  conversions:\n    :columns:\n    - _id: TEXT\n    - accurate: BOOLEAN\n    - adjusted_amount: DOUBLE PRECISION\n    - amount: DOUBLE PRECISION\n    - country: TEXT\n    - currency: TEXT\n    - external_id: TEXT\n    - external_type: TEXT\n    - finished_at: TIMESTAMP\n    - job_id: INTEGER\n    - judgments: INTEGER\n    - response: TEXT\n    - started_at: TIMESTAMP\n    - tainted: BOOLEAN\n    - uid: TEXT\n    - worker_id: INTEGER\n    - bonus_amount: DOUBLE PRECISION\n    :meta:\n      :table: conversions\n```\n\nDEBUG MoSQL: processing op: {\"ts\"=>seconds: 1360355811, increment: 76, \"h\"=>-5783231566697040009, \"op\"=>\"u\", \"ns\"=>\"some_dbname.conversions\", \"o2\"=>{\"_id\"=>BSON::ObjectId('51156129153d40539f0020ad')}, \"o\"=>{\"job_id\"=>166980, \"judgments\"=>8, \"finished_at\"=>2013-02-08 20:36:49 UTC, \"currency\"=>\"cents\", \"adjusted_amount\"=>1.23, \"country\"=>\"USA\", \"worker_id\"=>16055423, \"amount\"=>1.23, \"uid\"=>\"ABC\", \"accurate\"=>true, \"external_id\"=>\"123\", \"external_type\"=>\"something\", \"tainted\"=>true, \"started_at\"=>2013-02-08 20:33:46 UTC}}\n\nDEBUG MoSQL: upsert some_dbname.conversions: _id=\n\nDEBUG MoSQL: Transformed: [nil, true, 1.23, 1.23, \"USA\", \"cents\", \"123\", \"something\", 2013-02-08 20:36:49 UTC, 166980, 8, nil, 2013-02-08 20:33:46 UTC, true, \"ABC\", 16055423, nil]\nE, [2013-02-08T20:36:51.449228 #18490] ERROR -- : PG::Error: ERROR:  null value in column \"_id\" violates not-null constraint: INSERT INTO \"conversions\" (\"_id\", \"accurate\", \"adjusted_amount\", \"amount\", \"country\", \"currency\", \"external_id\", \"external_type\", \"finished_at\", \"job_id\", \"judgments\", \"response\", \"started_at\", \"tainted\", \"uid\", \"worker_id\", \"bonus_amount\") VALUES (NULL, true, 1.23, 1.23\n002, 'USA', 'cents', '123', 'something', '2013-02-08 20:36:49.548000+0000', 166980, 8, NULL, '2013-02-08 20:33:46.000000+0000', true, 'ABC', 16055423, NULL) RETURNING \"_id\"\n. Thanks for the quick assistance. I have switched to the github master and I don't see any warnings in a few minutes of testing so I expect that the issue is indeed fixed. I'll let you know if they return.\n\nSounds like it's time for a reimport.\n. You made it so easy it isn't much of a hassle ;)\n. Thanks for the fix and the info!\n\nOn Mar 25, 2013, at 7:20 PM, Nelson Elhage notifications@github.com wrote:\n\nThanks for the report. I just pushed a fix to that crash.\n\nIf it stop running for a few days, whether or not resuming tailing is safe\ndoes depend on how much oplog is available. You can tell this via\ndb.getReplicationInfo() in the mongo shell, or by looking at the\nlocal.oplog.rs collection directly.\n\nOf course, even if you can catch up, if you're far enough behind and you\nhave enough write volume, it might be faster to just reimport regardless.\n\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/stripe/mosql/issues/17#issuecomment-15437384\n.\n. ",
    "andrewjshults": "Based on some offline discussions with @nelhage I'm working on dot syntax support over here: https://github.com/andrewjshults/mosql/tree/dot-syntax\n\nNote that I did change the collections YAML format to allow for a cleaner mapping once the dot syntax component is in place (e.g., name columns baz instead of foo.baz), so your current collections.yml isn't going to be compatible. The changes are fairly straightforward to make though (the README has an updated example).\n. @nelhage makes sense - I was actually thinking last night that the two formats are sufficiently distinct that it would be nice to support the existing format as a compressed version of the syntax. I think I'm going to switch around the source/destination in the YAML format of the new format a little bit so that it's more in line with the current format.\n\nExisting\n\n``` yaml\n- (source & destination): (type)\n```\n\nCurrent \"new\"\n\n``` yaml\n- (destination):\n  :source: (source)\n  :type: (type)\n```\n\nNew new\n\n``` yaml\n- (source):\n  :destination: (destination)\n  :type: (type)\n```\n\nTo me, this seems like it'd be a bit more unified (the new format is basically just adding additional parameters), but let me know your thoughts. I got a really basic version working last night, but it definitely needs some additional handling support for the different mongo types + unit tests.\n. I've added a quick patch to handle this for development work (just running a single mongo instance locally) here https://github.com/andrewjshults/mosql/tree/non-replicate-set\n\nThere's probably a cleaner way of doing this (it should probably exit after the initial import if not connected to a replica set), but this has worked so far.\n. Unfortunately, I'm not longer at the place that I was at when I originally started working on this, so my work is quite out of date at this point. There's some work on my fork for unrolling embedded dicts, but as @nelhage mentioned in his earlier comment unrolling arrays and properly supporting keeping them in sync between the two databases will be quite a bit of work (and may be hard to be entirely generalizable).\n. Based on some offline discussions with @nelhage I'm working on dot syntax support over here: https://github.com/andrewjshults/mosql/tree/dot-syntax\n\nNote that I did change the collections YAML format to allow for a cleaner mapping once the dot syntax component is in place (e.g., name columns baz instead of foo.baz), so your current collections.yml isn't going to be compatible. The changes are fairly straightforward to make though (the README has an updated example).\n. @nelhage makes sense - I was actually thinking last night that the two formats are sufficiently distinct that it would be nice to support the existing format as a compressed version of the syntax. I think I'm going to switch around the source/destination in the YAML format of the new format a little bit so that it's more in line with the current format.\n\nExisting\n\n``` yaml\n- (source & destination): (type)\n```\n\nCurrent \"new\"\n\n``` yaml\n- (destination):\n  :source: (source)\n  :type: (type)\n```\n\nNew new\n\n``` yaml\n- (source):\n  :destination: (destination)\n  :type: (type)\n```\n\nTo me, this seems like it'd be a bit more unified (the new format is basically just adding additional parameters), but let me know your thoughts. I got a really basic version working last night, but it definitely needs some additional handling support for the different mongo types + unit tests.\n. I've added a quick patch to handle this for development work (just running a single mongo instance locally) here https://github.com/andrewjshults/mosql/tree/non-replicate-set\n\nThere's probably a cleaner way of doing this (it should probably exit after the initial import if not connected to a replica set), but this has worked so far.\n. Unfortunately, I'm not longer at the place that I was at when I originally started working on this, so my work is quite out of date at this point. There's some work on my fork for unrolling embedded dicts, but as @nelhage mentioned in his earlier comment unrolling arrays and properly supporting keeping them in sync between the two databases will be quite a bit of work (and may be hard to be entirely generalizable).\n. ",
    "akluthe": "Not sure if I am getting a related error now or not.\n\nC:/Ruby193/lib/ruby/1.9.1/psych.rb:203:in `parse': (<unknown>): found character\nthat cannot start any token while scanning for the next token at line 2 column 1\n (Psych::SyntaxError)\n        from C:/Ruby193/lib/ruby/1.9.1/psych.rb:203:in`parse_stream'\n        from C:/Ruby193/lib/ruby/1.9.1/psych.rb:151:in `parse'\n        from C:/Ruby193/lib/ruby/1.9.1/psych.rb:127:in`load'\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:12\n0:in `load_collections'\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:12\n6:in`run'\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:16\n:in `run'\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/mosql-0.1.0/bin/mosql:7:in`<to\np (required)>'\n        from C:/Ruby193/bin/mosql:23:in `load'\n        from C:/Ruby193/bin/mosql:23:in`<main>'\n. Not sure if I am getting a related error now or not.\n\nC:/Ruby193/lib/ruby/1.9.1/psych.rb:203:in `parse': (<unknown>): found character\nthat cannot start any token while scanning for the next token at line 2 column 1\n (Psych::SyntaxError)\n        from C:/Ruby193/lib/ruby/1.9.1/psych.rb:203:in`parse_stream'\n        from C:/Ruby193/lib/ruby/1.9.1/psych.rb:151:in `parse'\n        from C:/Ruby193/lib/ruby/1.9.1/psych.rb:127:in`load'\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:12\n0:in `load_collections'\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:12\n6:in`run'\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:16\n:in `run'\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/mosql-0.1.0/bin/mosql:7:in`<to\np (required)>'\n        from C:/Ruby193/bin/mosql:23:in `load'\n        from C:/Ruby193/bin/mosql:23:in`<main>'\n. ",
    "addisonj": "are you pushing up the new version to ruby gems? I didn't see a version bump.\n. I just built from master and installed.\n\nFound another one:\n\nEBUG MoSQL: processing op: {\"ts\"=>seconds: 1360870248, increment: 2, \"h\"=>-5242060077508462325, \"v\"=>2, \"op\"=>\"u\", \"ns\"=>\"user.favorites\", \"o2\"=>{\"_id\"=>BSON::ObjectId('511d3b6677f7ebd6d1c9c2e6')}, \"o\"=>{\"$set\"=>{\"userId\"=>BSON::ObjectId('511d3a8677f7ebd6d1c9c257')}}}\nDEBUG MoSQL: resync user.favorites: 511d3b6677f7ebd6d1c9c2e6 (update was: {\"$set\"=>{\"userId\"=>BSON::ObjectId('511d3a8677f7ebd6d1c9c257')}})\n/var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:1127:in `literal_other_append': can't express BSON::ObjectId('511d3b6677f7ebd6d1c9c2e6') as a SQL literal (Sequel::Error)\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:117:in`literal_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:465:in `complex_expression_sql_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/adapters/shared/postgres.rb:1057:in`complex_expression_sql_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/sql.rb:92:in `to_s_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:1087:in`literal_expression_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:95:in `literal_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:1319:in`select_where_sql'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:835:in `block in clause_sql'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:835:in`each'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:835:in `clause_sql'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:15:in`delete_sql'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/actions.rb:131:in `delete'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:260:in`sync_object'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:293:in `handle_op'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:250:in`block in optail'\n        from /var/lib/gems/1.9.1/gems/mongoriver-0.1.0/lib/mongoriver/abstract_persistent_tailer.rb:27:in `block in stream'\n        from /var/lib/gems/1.9.1/gems/mongoriver-0.1.0/lib/mongoriver/tailer.rb:94:in`stream'\n        from /var/lib/gems/1.9.1/gems/mongoriver-0.1.0/lib/mongoriver/abstract_persistent_tailer.rb:26:in `stream'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:249:in`optail'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:143:in `run'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:16:in`run'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/bin/mosql:7:in `<top (required)>'\n        from /usr/local/bin/mosql:19:in`load'\n        from /usr/local/bin/mosql:19:in `<main>'\n\nI can open as new issue, but it looks to be somewhat related case with an update\n. Seems to be running very smoothly now!\n\nThanks!\n\nAlso, I need to be able to grab properties from nested objects. I am going to try and see if I can put something together and send off a PR in the next few days.\n. very nifty functionality.\n\nI could imagine this also being a good framework for having default/bundled callbacks that might solve other problems, such as mapping nested objects to other fields or parsing out timestamps from objectIds.\n\n+1\n. any movement on this?\n. are you pushing up the new version to ruby gems? I didn't see a version bump.\n. I just built from master and installed.\n\nFound another one:\n\nEBUG MoSQL: processing op: {\"ts\"=>seconds: 1360870248, increment: 2, \"h\"=>-5242060077508462325, \"v\"=>2, \"op\"=>\"u\", \"ns\"=>\"user.favorites\", \"o2\"=>{\"_id\"=>BSON::ObjectId('511d3b6677f7ebd6d1c9c2e6')}, \"o\"=>{\"$set\"=>{\"userId\"=>BSON::ObjectId('511d3a8677f7ebd6d1c9c257')}}}\nDEBUG MoSQL: resync user.favorites: 511d3b6677f7ebd6d1c9c2e6 (update was: {\"$set\"=>{\"userId\"=>BSON::ObjectId('511d3a8677f7ebd6d1c9c257')}})\n/var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:1127:in `literal_other_append': can't express BSON::ObjectId('511d3b6677f7ebd6d1c9c2e6') as a SQL literal (Sequel::Error)\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:117:in`literal_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:465:in `complex_expression_sql_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/adapters/shared/postgres.rb:1057:in`complex_expression_sql_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/sql.rb:92:in `to_s_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:1087:in`literal_expression_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:95:in `literal_append'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:1319:in`select_where_sql'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:835:in `block in clause_sql'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:835:in`each'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:835:in `clause_sql'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/sql.rb:15:in`delete_sql'\n        from /var/lib/gems/1.9.1/gems/sequel-3.44.0/lib/sequel/dataset/actions.rb:131:in `delete'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:260:in`sync_object'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:293:in `handle_op'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:250:in`block in optail'\n        from /var/lib/gems/1.9.1/gems/mongoriver-0.1.0/lib/mongoriver/abstract_persistent_tailer.rb:27:in `block in stream'\n        from /var/lib/gems/1.9.1/gems/mongoriver-0.1.0/lib/mongoriver/tailer.rb:94:in`stream'\n        from /var/lib/gems/1.9.1/gems/mongoriver-0.1.0/lib/mongoriver/abstract_persistent_tailer.rb:26:in `stream'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:249:in`optail'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:143:in `run'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/lib/mosql/cli.rb:16:in`run'\n        from /var/lib/gems/1.9.1/gems/mosql-0.1.0/bin/mosql:7:in `<top (required)>'\n        from /usr/local/bin/mosql:19:in`load'\n        from /usr/local/bin/mosql:19:in `<main>'\n\nI can open as new issue, but it looks to be somewhat related case with an update\n. Seems to be running very smoothly now!\n\nThanks!\n\nAlso, I need to be able to grab properties from nested objects. I am going to try and see if I can put something together and send off a PR in the next few days.\n. very nifty functionality.\n\nI could imagine this also being a good framework for having default/bundled callbacks that might solve other problems, such as mapping nested objects to other fields or parsing out timestamps from objectIds.\n\n+1\n. any movement on this?\n. ",
    "christinang89": "Hey @nelhage , I'm facing the same issues as @addisonj above and this is the error I'm seeing:\n\n```\nINFO Mongoriver: Starting oplog stream from seconds: 1407538029, increment: 0\n/usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1228:in `literal_other_append': can't express #<BSON::DBRef:0x007fe5cbc85060 @namespace=\"accounts\", @object_id=BSON::ObjectId('53aa28bee4b008bb2ef7d7cd')> as a SQL literal (Sequel::Error)\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:107:in `literal_append'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1536:in `block in update_set_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1528:in `each'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1528:in `update_set_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:228:in `_update_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:174:in `update_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/actions.rb:769:in `update'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/sql.rb:50:in `upsert!'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/sql.rb:38:in `upsert_ns'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:195:in `block in handle_op'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:39:in `unsafe_handle_exceptions'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:194:in `handle_op'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:154:in `block in optail'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/abstract_persistent_tailer.rb:28:in `block in stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/tailer.rb:107:in `stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/abstract_persistent_tailer.rb:27:in `stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:153:in `optail'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/cli.rb:161:in `run'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/cli.rb:16:in `run'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/bin/mosql:5:in `<top (required)>'\n    from /usr/local/bin/mosql:23:in `load'\n    from /usr/local/bin/mosql:23:in `<main>'\n```\n. @nelhage  thanks!\n\nYes, that would work for my use case. However, what would you suggest as a simple way to extract out the referenced _id?\n\nAlso, it seems that this is causing the op-tail not to work and I have to manually reimport all my data on a daily basis. (For now, I'm using crontab to do this twice a day as a stop gap solution). \n\nDo you have a better/ easier/ more elegant solution? Thanks for your help!\n. Hmm, unless I'm doing something wrong, it's still throwing this error:\n\n```\n INFO Mongoriver: Saved timestamp: seconds: 1407784998, increment: 1 (2014-08-11 12:23:18 -0700)\n/usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1228:in `literal_other_append': can't express #<BSON::DBRef:0x007f9b4b51c3e8 @namespace=\"accounts\", @object_id=BSON::ObjectId('53aa28bee4b008bb2ef7d7cd')> as a SQL literal (Sequel::Error)\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:107:in `literal_append'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1536:in `block in update_set_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1528:in `each'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1528:in `update_set_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:228:in `_update_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:174:in `update_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/actions.rb:769:in `update'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/sql.rb:51:in `upsert!'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/sql.rb:39:in `upsert_ns'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:213:in `block in handle_op'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:39:in `unsafe_handle_exceptions'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:212:in `handle_op'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:172:in `block in optail'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/abstract_persistent_tailer.rb:28:in `block in stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/tailer.rb:107:in `stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/abstract_persistent_tailer.rb:27:in `stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:171:in `optail'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/cli.rb:165:in `run'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/cli.rb:16:in `run'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/bin/mosql:5:in `<top (required)>'\n    from /usr/local/bin/mosql:23:in `load'\n    from /usr/local/bin/mosql:23:in `<main>'\n```\n. Yea I tried to run directly out of there, but it is likely I did it wrong. (Sorry I'm a beginner!)\n\nYea maybe if you just go ahead and merge it, I can try and report issues, if any! :)\n\nThank you!! :D\n. Hey @nelhage  so i managed to clone it correctly, just tested it and verified that it works smoothly! :) \n. Hey @nelhage , I'm facing the same issues as @addisonj above and this is the error I'm seeing:\n\n```\nINFO Mongoriver: Starting oplog stream from seconds: 1407538029, increment: 0\n/usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1228:in `literal_other_append': can't express #<BSON::DBRef:0x007fe5cbc85060 @namespace=\"accounts\", @object_id=BSON::ObjectId('53aa28bee4b008bb2ef7d7cd')> as a SQL literal (Sequel::Error)\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:107:in `literal_append'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1536:in `block in update_set_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1528:in `each'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1528:in `update_set_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:228:in `_update_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:174:in `update_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/actions.rb:769:in `update'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/sql.rb:50:in `upsert!'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/sql.rb:38:in `upsert_ns'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:195:in `block in handle_op'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:39:in `unsafe_handle_exceptions'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:194:in `handle_op'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:154:in `block in optail'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/abstract_persistent_tailer.rb:28:in `block in stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/tailer.rb:107:in `stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/abstract_persistent_tailer.rb:27:in `stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:153:in `optail'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/cli.rb:161:in `run'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/cli.rb:16:in `run'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/bin/mosql:5:in `<top (required)>'\n    from /usr/local/bin/mosql:23:in `load'\n    from /usr/local/bin/mosql:23:in `<main>'\n```\n. @nelhage  thanks!\n\nYes, that would work for my use case. However, what would you suggest as a simple way to extract out the referenced _id?\n\nAlso, it seems that this is causing the op-tail not to work and I have to manually reimport all my data on a daily basis. (For now, I'm using crontab to do this twice a day as a stop gap solution). \n\nDo you have a better/ easier/ more elegant solution? Thanks for your help!\n. Hmm, unless I'm doing something wrong, it's still throwing this error:\n\n```\n INFO Mongoriver: Saved timestamp: seconds: 1407784998, increment: 1 (2014-08-11 12:23:18 -0700)\n/usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1228:in `literal_other_append': can't express #<BSON::DBRef:0x007f9b4b51c3e8 @namespace=\"accounts\", @object_id=BSON::ObjectId('53aa28bee4b008bb2ef7d7cd')> as a SQL literal (Sequel::Error)\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:107:in `literal_append'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1536:in `block in update_set_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1528:in `each'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:1528:in `update_set_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:228:in `_update_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/sql.rb:174:in `update_sql'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/sequel-4.12.0/lib/sequel/dataset/actions.rb:769:in `update'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/sql.rb:51:in `upsert!'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/sql.rb:39:in `upsert_ns'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:213:in `block in handle_op'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:39:in `unsafe_handle_exceptions'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:212:in `handle_op'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:172:in `block in optail'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/abstract_persistent_tailer.rb:28:in `block in stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/tailer.rb:107:in `stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mongoriver-0.3.1/lib/mongoriver/abstract_persistent_tailer.rb:27:in `stream'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/streamer.rb:171:in `optail'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/cli.rb:165:in `run'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/lib/mosql/cli.rb:16:in `run'\n    from /usr/local/lib/ruby/gems/2.1.0/gems/mosql-0.3.1/bin/mosql:5:in `<top (required)>'\n    from /usr/local/bin/mosql:23:in `load'\n    from /usr/local/bin/mosql:23:in `<main>'\n```\n. Yea I tried to run directly out of there, but it is likely I did it wrong. (Sorry I'm a beginner!)\n\nYea maybe if you just go ahead and merge it, I can try and report issues, if any! :)\n\nThank you!! :D\n. Hey @nelhage  so i managed to clone it correctly, just tested it and verified that it works smoothly! :) \n. ",
    "dpatti": "This was a bit confusing for me at first, too, since it says `is not a replset. Proceeding anyways...`. I just didn't realize it was a requirement until I looked at the source and saw the `['local']['oplog.rs']` reference. That said, a single import should be possible whether or not you are using a replset, so it might be something to consider.\n. I've also forked the project and added a few things of my own, including relational tables. We don't support oplog tailing, since even without any of the additions, the oplog tailer can't keep up with our traffic. Though a bit out of date with upstream, we use it in production just fine. The branch is here:\n\nhttps://github.com/dpatti/mosql/commits/fogcreek\n\nIt's implemented exactly as I wrote originally, though we use the newer long-form representation of columns, like so:\n\n```\nmy_blog:\n  posts:\n    :columns:\n      - _id: VARCHAR(24)\n      - title: VARCHAR(150)\n    :meta:\n      :table: posts\n      :extra_props: true\n    :related:\n      user_post_likes:\n        - post_id:\n          :source: _id\n          :type: VARCHAR(24)\n        - user_id:\n          :source: users_liked[]\n          :type: VARCHAR(24)\n      user_post_ratings:\n        - post_id:\n          :source: _id\n          :type: VARCHAR(24)\n        - user_id:\n          :source: ratings[].user_id\n          :type: VARCHAR(24)\n        - score:\n          :source: ratings[].score\n          :type: INT\n```\n. Correct, so specifying `users_liked[]` as the source does a simple unwind. If you are using subdocs, you can unwind a specific attribute of each of the subdocs in the array, such as `ratings[].user_id` and `ratings[].score`. I would not recommend unwinding two _different_ arrays within the same relational table. I don't know if my code can handle that, though I remember thinking about it hard when I wrote it.\n. Are you getting an error at all? I tried it with some dummy data and it seemed to work for me. You put `subscriptions[]._id` as type `INT` -- you didn't by chance mean `VARCHAR(24)`, did you? If it's still not working, could you paste an example document?\n\nEdit: Here's how I run it:\n\n```\nMOSQL=path/to/mosql/checkout\nexport BUNDLE_GEMFILE=$MOSQL/Gemfile\nexport RUBYLIB=$MOSQL/lib\n\nMONGO=mongodb://localhost/\nPOSTGRES=postgres://localhost/testdb\nbundle exec \\\n  $MOSQL/bin/mosql --collections --collections.yml \\\n                   --mongo $MONGO \\\n                   --sql $POSTGRES \\\n                   --reimport \\\n                   --skip-tail\n```\n. I removed the ellipses from your doc, inserted it into mongo, and it exported fine. I got all 3 tables and 1 row in each.\n. Oh right. That has something to do with sequel. I know my Gemfile.lock uses `sequel (3.44.0)`, and I know that when I tried updating it one time, it ended up not having the `String#lit` definition anymore. As far as I can tell, it's still there in master, so I don't know if you want to try forcing the same version I am using in the lock.\n. Unfortunately I don't think it can be merged in, or at least not trivially.\nI made all of my changes under the assumption that you are not using the\noplog tailer. What kind of error are you seeing? It could certainly be\nsomething in my code.\nOn Apr 1, 2014 11:32 AM, \"Nick Plante\" notifications@github.com wrote:\n\n> Is work still ongoing on this? Would love to see it merged in at some\n> point... unfortunately I'm getting some import errors when using the fork\n> that I don't get from current mosql master.\n> \n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/stripe/mosql/issues/11#issuecomment-39219554\n> .\n. @monfresh Thanks for the details, but would you mind posting them as an issue on my fork? I don't want to keep generating notifications for Mosql contributors for code that isn't going to be merged upstream. That said, I will try and find some time in the next few days to reproduce and fix it.\n. @AboulEinein The fork was eventually moved here: https://github.com/trello/mosql/tree/streamless-fork\n\nThough I think it is still being used at Trello, it is very out of date and probably comes with a lot of caveats. I'm not involved with it anymore, so that's about as much as I can offer. \n. @laurentrivard I moved the fork into @trello a few years ago while I worked there, but seeing as how it's not there anymore, they either deleted it or made it private.. This was a bit confusing for me at first, too, since it says `is not a replset. Proceeding anyways...`. I just didn't realize it was a requirement until I looked at the source and saw the `['local']['oplog.rs']` reference. That said, a single import should be possible whether or not you are using a replset, so it might be something to consider.\n. I've also forked the project and added a few things of my own, including relational tables. We don't support oplog tailing, since even without any of the additions, the oplog tailer can't keep up with our traffic. Though a bit out of date with upstream, we use it in production just fine. The branch is here:\n\nhttps://github.com/dpatti/mosql/commits/fogcreek\n\nIt's implemented exactly as I wrote originally, though we use the newer long-form representation of columns, like so:\n\n```\nmy_blog:\n  posts:\n    :columns:\n      - _id: VARCHAR(24)\n      - title: VARCHAR(150)\n    :meta:\n      :table: posts\n      :extra_props: true\n    :related:\n      user_post_likes:\n        - post_id:\n          :source: _id\n          :type: VARCHAR(24)\n        - user_id:\n          :source: users_liked[]\n          :type: VARCHAR(24)\n      user_post_ratings:\n        - post_id:\n          :source: _id\n          :type: VARCHAR(24)\n        - user_id:\n          :source: ratings[].user_id\n          :type: VARCHAR(24)\n        - score:\n          :source: ratings[].score\n          :type: INT\n```\n. Correct, so specifying `users_liked[]` as the source does a simple unwind. If you are using subdocs, you can unwind a specific attribute of each of the subdocs in the array, such as `ratings[].user_id` and `ratings[].score`. I would not recommend unwinding two _different_ arrays within the same relational table. I don't know if my code can handle that, though I remember thinking about it hard when I wrote it.\n. Are you getting an error at all? I tried it with some dummy data and it seemed to work for me. You put `subscriptions[]._id` as type `INT` -- you didn't by chance mean `VARCHAR(24)`, did you? If it's still not working, could you paste an example document?\n\nEdit: Here's how I run it:\n\n```\nMOSQL=path/to/mosql/checkout\nexport BUNDLE_GEMFILE=$MOSQL/Gemfile\nexport RUBYLIB=$MOSQL/lib\n\nMONGO=mongodb://localhost/\nPOSTGRES=postgres://localhost/testdb\nbundle exec \\\n  $MOSQL/bin/mosql --collections --collections.yml \\\n                   --mongo $MONGO \\\n                   --sql $POSTGRES \\\n                   --reimport \\\n                   --skip-tail\n```\n. I removed the ellipses from your doc, inserted it into mongo, and it exported fine. I got all 3 tables and 1 row in each.\n. Oh right. That has something to do with sequel. I know my Gemfile.lock uses `sequel (3.44.0)`, and I know that when I tried updating it one time, it ended up not having the `String#lit` definition anymore. As far as I can tell, it's still there in master, so I don't know if you want to try forcing the same version I am using in the lock.\n. Unfortunately I don't think it can be merged in, or at least not trivially.\nI made all of my changes under the assumption that you are not using the\noplog tailer. What kind of error are you seeing? It could certainly be\nsomething in my code.\nOn Apr 1, 2014 11:32 AM, \"Nick Plante\" notifications@github.com wrote:\n\n> Is work still ongoing on this? Would love to see it merged in at some\n> point... unfortunately I'm getting some import errors when using the fork\n> that I don't get from current mosql master.\n> \n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/stripe/mosql/issues/11#issuecomment-39219554\n> .\n. @monfresh Thanks for the details, but would you mind posting them as an issue on my fork? I don't want to keep generating notifications for Mosql contributors for code that isn't going to be merged upstream. That said, I will try and find some time in the next few days to reproduce and fix it.\n. @AboulEinein The fork was eventually moved here: https://github.com/trello/mosql/tree/streamless-fork\n\nThough I think it is still being used at Trello, it is very out of date and probably comes with a lot of caveats. I'm not involved with it anymore, so that's about as much as I can offer. \n. @laurentrivard I moved the fork into @trello a few years ago while I worked there, but seeing as how it's not there anymore, they either deleted it or made it private.. ",
    "cbandy": "Do updatable views solve this somehow?\n. Do updatable views solve this somehow?\n. ",
    "taylorbrooks": "Any further thoughts or update on this?\n\nI'm facing the exact scenario... need to unroll an embedded array into a different table.\n. Yeah I don't need to keep the databases in sync. The mongodb is small enough that I can drop and reimport periodically.\n\nWhat branch of your fork have you worked on this?\n. Thanks @dpatti.\n\nWant to make sure I understand this clearly... In your example, users_liked is an array of user ids embedded with the posts collection and this yaml file will create a user_post_likes relational table in pg? (Same goes with post ratings?)\n. Cool. Yeah off the top of my head I don't think I have a case where I'd need to do that.\n\nThanks a ton!\n. Hrm, anything I'm missing here? I can't get the embedded array to unwind into a new table.\n\n``` yml\nmongodb:\n  accounts:\n    :columns:\n    - id:\n      :source: _id\n      :type: VARCHAR(24)\n    - name:\n      :source: name\n      :type: VARCHAR(100)\n    - state:\n      :source: state\n      :type: VARCHAR(24)\n    :meta:\n      :table: accounts\n    :related:\n      subscriptions:\n        - subscription_id:\n          :source: subscriptions[]._id\n          :type: INT\n        - state:\n          :source: subscriptions[].state\n          :type: VARCHAR(24)\n        - product_id:\n          :source: subscriptions[].product_id\n          :type: VARCHAR(24)\n        - account_id:\n          :source: _id\n          :type: VARCHAR(24)\n      cards:\n        - last_4: \n          :source: cards[].last_4\n          :type: INT\n        - expiration_month:\n          :source: cards[].expiration_month\n          :type: INT\n        - expiration_year:\n          :source: cards[].expiration_year\n          :type: INT\n        - account_id:\n          :source: _id\n          :type: VARCHAR(24)\n```\n. Changed type to <code>VARCHAR(24)</code>, didn't change the import.\n\nHere's a sample doc: https://gist.github.com/taylorbrooks/15204ce0fd219b6e9c3d\n\nTrying your way of running it now.\n. I think I got it working. I deleted all versions of mosql, install from your fork and used your CLI stuff.\n\nI still get this error (from what I can tell it's still correctly imported accounts and subscriptions) :\n\n``` shell\nINFO MoSQL: Creating table 'accounts'...\nINFO MoSQL: Creating table 'subscriptions'...\nINFO MoSQL: Importing for Mongo DB sso_development...\nINFO MoSQL: Importing for sso_development.accounts...\nINFO MoSQL: Imported 339 rows into 'accounts' (0.1s, 0.0s SQL)...\nINFO MoSQL: Imported 209 rows into 'subscriptions' (0.1s, 0.0s SQL)...\n/Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:277:in `add_identity': undefined method `lit' for \"extract(epoch from now())\":String (NoMethodError)\n    from /Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:267:in `check_index_creation'\n    from /Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:219:in `initial_import'\n    from /Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:148:in `run'\n    from /Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:16:in `run'\n    from ../../Rails/mosql/bin/mosql:5:in `<main>'\n```\n. Any further thoughts or update on this?\n\nI'm facing the exact scenario... need to unroll an embedded array into a different table.\n. Yeah I don't need to keep the databases in sync. The mongodb is small enough that I can drop and reimport periodically.\n\nWhat branch of your fork have you worked on this?\n. Thanks @dpatti.\n\nWant to make sure I understand this clearly... In your example, users_liked is an array of user ids embedded with the posts collection and this yaml file will create a user_post_likes relational table in pg? (Same goes with post ratings?)\n. Cool. Yeah off the top of my head I don't think I have a case where I'd need to do that.\n\nThanks a ton!\n. Hrm, anything I'm missing here? I can't get the embedded array to unwind into a new table.\n\n``` yml\nmongodb:\n  accounts:\n    :columns:\n    - id:\n      :source: _id\n      :type: VARCHAR(24)\n    - name:\n      :source: name\n      :type: VARCHAR(100)\n    - state:\n      :source: state\n      :type: VARCHAR(24)\n    :meta:\n      :table: accounts\n    :related:\n      subscriptions:\n        - subscription_id:\n          :source: subscriptions[]._id\n          :type: INT\n        - state:\n          :source: subscriptions[].state\n          :type: VARCHAR(24)\n        - product_id:\n          :source: subscriptions[].product_id\n          :type: VARCHAR(24)\n        - account_id:\n          :source: _id\n          :type: VARCHAR(24)\n      cards:\n        - last_4: \n          :source: cards[].last_4\n          :type: INT\n        - expiration_month:\n          :source: cards[].expiration_month\n          :type: INT\n        - expiration_year:\n          :source: cards[].expiration_year\n          :type: INT\n        - account_id:\n          :source: _id\n          :type: VARCHAR(24)\n```\n. Changed type to <code>VARCHAR(24)</code>, didn't change the import.\n\nHere's a sample doc: https://gist.github.com/taylorbrooks/15204ce0fd219b6e9c3d\n\nTrying your way of running it now.\n. I think I got it working. I deleted all versions of mosql, install from your fork and used your CLI stuff.\n\nI still get this error (from what I can tell it's still correctly imported accounts and subscriptions) :\n\n``` shell\nINFO MoSQL: Creating table 'accounts'...\nINFO MoSQL: Creating table 'subscriptions'...\nINFO MoSQL: Importing for Mongo DB sso_development...\nINFO MoSQL: Importing for sso_development.accounts...\nINFO MoSQL: Imported 339 rows into 'accounts' (0.1s, 0.0s SQL)...\nINFO MoSQL: Imported 209 rows into 'subscriptions' (0.1s, 0.0s SQL)...\n/Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:277:in `add_identity': undefined method `lit' for \"extract(epoch from now())\":String (NoMethodError)\n    from /Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:267:in `check_index_creation'\n    from /Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:219:in `initial_import'\n    from /Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:148:in `run'\n    from /Users/taylorbrooks/Documents/Rails/mosql/lib/mosql/cli.rb:16:in `run'\n    from ../../Rails/mosql/bin/mosql:5:in `<main>'\n```\n. ",
    "zapnap": "Is work still ongoing on this? Would love to see it merged in at some point... unfortunately I'm getting some import errors when using the fork that I don't get from current mosql master.\n. Is work still ongoing on this? Would love to see it merged in at some point... unfortunately I'm getting some import errors when using the fork that I don't get from current mosql master.\n. ",
    "monfresh": "@dpatti Thanks for your work, but unfortunately, there's definitely something wrong with your code. I tried a basic YAML without any `related` stuff in it, and it chokes, whereas the stripe mosql gem works perfectly. I'm using sequel 3.44.0 as you recommended, and I'm passing in the `--skip-tail` option.\n\nHere's my YAML:\n\n``` yaml\nohana-api-smc_development:\n  locations:\n    :columns:\n    - id:\n      :source: _id\n      :type: TEXT\n    - organization_id: TEXT\n    - accessibility: TEXT\n    - admin_emails:\n      :source: admins\n      :type: TEXT\n    - description: TEXT\n    - emails: TEXT\n    - hours: TEXT\n    - languages: TEXT\n    - name: TEXT\n    - short_desc: TEXT\n    - transportation: TEXT\n    - urls: TEXT\n    - updated_at: TIMESTAMP\n    - created_at: TIMESTAMP\n    :meta:\n      :table: locations\n      :extra_props: true\n```\n\nYour code results in 3 distinct errors that appear a bunch of times:\n1.\n\n```\nWARN MoSQL: Ignoring row (id=): PG::NotNullViolation: ERROR:  null value in column \"id\" violates not-null constraint\nDETAIL:  Failing row contains (null, null, null, null, null, null, null, null, null, null, null, null, null, null, null).\n```\n\n2.\n\n```\nPG::ProgramLimitExceeded: ERROR:  index row size 3568 exceeds maximum 2712 for index \"locations_pkey\"\nHINT:  Values larger than 1/3 of a buffer page cannot be indexed.\nConsider a function index of an MD5 hash of the value, or use full text indexing.\n```\n\n3.\n\n```\nPG::DatatypeMismatch: ERROR:  column \"updated_at\" is of type timestamp without time zone but expression is of type record\nLINE 1: ...\",\"hours\":\"(24 hours daily)\"}]}'), \"updated_at\" = ('521d32e4...\n                                                             ^\nHINT:  You will need to rewrite or cast the expression.\n```\n\nHere's a sample entry from the DB:\n\n``` json\n{\n  \"_id\": {\n    \"$oid\": \"521d32b91974fcdb2b000002\"\n  },\n  \"_slugs\": [\n    \"san-mateo-county-slash-silicon-valley-convention-and-visitors-bureau\"\n  ],\n  \"accessibility\": [\n    \"wheelchair\"\n  ],\n  \"address\": {\n    \"_id\": {\n      \"$oid\": \"521d32b91974fcdb2b000004\"\n    },\n    \"street\": \"111 Anza Blvd., Suite 410\",\n    \"city\": \"Burlingame\",\n    \"state\": \"CA\",\n    \"zip\": \"94010\"\n  },\n  \"ask_for\": [\n    \"Receptionist\"\n  ],\n  \"contacts\": [\n    {\n      \"_id\": {\n        \"$oid\": \"521d32b91974fcdb2b000003\"\n      },\n      \"name\": \"Anne LeClair, CAE, CDME\",\n      \"title\": \"President, CEO\"\n    }\n  ],\n  \"coordinates\": [\n    -122.3486066,\n    37.5909749\n  ],\n  \"created_at\": {\n    \"$date\": 1377645241035\n  },\n  \"description\": \"Offers information about the county's attractions and brochures and maps of cities in the county. Assists groups and individuals in booking sleeping rooms and meetings.\",\n  \"emails\": [\n    \"info@smccvb.com\"\n  ],\n  \"faxes\": [],\n  \"hours\": \"Monday-Thursday, 8:30-5; Friday, 8:30-4\",\n  \"kind\": \"other\",\n  \"languages\": null,\n  \"mail_address\": {\n    \"_id\": {\n      \"$oid\": \"521d32b91974fcdb2b000005\"\n    },\n    \"attention\": \"Convention and Visitors Bureau\",\n    \"street\": \"111 Anza Blvd., Suite 410\",\n    \"city\": \"Burlingame\",\n    \"state\": \"CA\",\n    \"zip\": \"94010\"\n  },\n  \"name\": \"San Mateo County/Silicon Valley Convention and Visitors Bureau\",\n  \"organization_id\": {\n    \"$oid\": \"521d32b81974fcdb2b000001\"\n  },\n  \"phones\": [\n    {\n      \"number\": \"800 288-4748\",\n      \"hours\": \"(Monday-Thursday, 8:30-5; Friday, 8:30-4)\"\n    }\n  ],\n  \"short_desc\": \"Offers information about the county's attractions and brochures and maps of cities in the county.\",\n  \"transportation\": \"SAMTRANS stops within 6 blocks.\",\n  \"updated_at\": {\n    \"$date\": 1383857247210\n  },\n  \"urls\": [\n    \"http://www.smccvb.com\"\n  ]\n}\n```\n\nI hope this helps you troubleshoot. Thanks!\n. @laurentrivard I do not. I haven't used this since 2014.. @dpatti Thanks for your work, but unfortunately, there's definitely something wrong with your code. I tried a basic YAML without any `related` stuff in it, and it chokes, whereas the stripe mosql gem works perfectly. I'm using sequel 3.44.0 as you recommended, and I'm passing in the `--skip-tail` option.\n\nHere's my YAML:\n\n``` yaml\nohana-api-smc_development:\n  locations:\n    :columns:\n    - id:\n      :source: _id\n      :type: TEXT\n    - organization_id: TEXT\n    - accessibility: TEXT\n    - admin_emails:\n      :source: admins\n      :type: TEXT\n    - description: TEXT\n    - emails: TEXT\n    - hours: TEXT\n    - languages: TEXT\n    - name: TEXT\n    - short_desc: TEXT\n    - transportation: TEXT\n    - urls: TEXT\n    - updated_at: TIMESTAMP\n    - created_at: TIMESTAMP\n    :meta:\n      :table: locations\n      :extra_props: true\n```\n\nYour code results in 3 distinct errors that appear a bunch of times:\n1.\n\n```\nWARN MoSQL: Ignoring row (id=): PG::NotNullViolation: ERROR:  null value in column \"id\" violates not-null constraint\nDETAIL:  Failing row contains (null, null, null, null, null, null, null, null, null, null, null, null, null, null, null).\n```\n\n2.\n\n```\nPG::ProgramLimitExceeded: ERROR:  index row size 3568 exceeds maximum 2712 for index \"locations_pkey\"\nHINT:  Values larger than 1/3 of a buffer page cannot be indexed.\nConsider a function index of an MD5 hash of the value, or use full text indexing.\n```\n\n3.\n\n```\nPG::DatatypeMismatch: ERROR:  column \"updated_at\" is of type timestamp without time zone but expression is of type record\nLINE 1: ...\",\"hours\":\"(24 hours daily)\"}]}'), \"updated_at\" = ('521d32e4...\n                                                             ^\nHINT:  You will need to rewrite or cast the expression.\n```\n\nHere's a sample entry from the DB:\n\n``` json\n{\n  \"_id\": {\n    \"$oid\": \"521d32b91974fcdb2b000002\"\n  },\n  \"_slugs\": [\n    \"san-mateo-county-slash-silicon-valley-convention-and-visitors-bureau\"\n  ],\n  \"accessibility\": [\n    \"wheelchair\"\n  ],\n  \"address\": {\n    \"_id\": {\n      \"$oid\": \"521d32b91974fcdb2b000004\"\n    },\n    \"street\": \"111 Anza Blvd., Suite 410\",\n    \"city\": \"Burlingame\",\n    \"state\": \"CA\",\n    \"zip\": \"94010\"\n  },\n  \"ask_for\": [\n    \"Receptionist\"\n  ],\n  \"contacts\": [\n    {\n      \"_id\": {\n        \"$oid\": \"521d32b91974fcdb2b000003\"\n      },\n      \"name\": \"Anne LeClair, CAE, CDME\",\n      \"title\": \"President, CEO\"\n    }\n  ],\n  \"coordinates\": [\n    -122.3486066,\n    37.5909749\n  ],\n  \"created_at\": {\n    \"$date\": 1377645241035\n  },\n  \"description\": \"Offers information about the county's attractions and brochures and maps of cities in the county. Assists groups and individuals in booking sleeping rooms and meetings.\",\n  \"emails\": [\n    \"info@smccvb.com\"\n  ],\n  \"faxes\": [],\n  \"hours\": \"Monday-Thursday, 8:30-5; Friday, 8:30-4\",\n  \"kind\": \"other\",\n  \"languages\": null,\n  \"mail_address\": {\n    \"_id\": {\n      \"$oid\": \"521d32b91974fcdb2b000005\"\n    },\n    \"attention\": \"Convention and Visitors Bureau\",\n    \"street\": \"111 Anza Blvd., Suite 410\",\n    \"city\": \"Burlingame\",\n    \"state\": \"CA\",\n    \"zip\": \"94010\"\n  },\n  \"name\": \"San Mateo County/Silicon Valley Convention and Visitors Bureau\",\n  \"organization_id\": {\n    \"$oid\": \"521d32b81974fcdb2b000001\"\n  },\n  \"phones\": [\n    {\n      \"number\": \"800 288-4748\",\n      \"hours\": \"(Monday-Thursday, 8:30-5; Friday, 8:30-4)\"\n    }\n  ],\n  \"short_desc\": \"Offers information about the county's attractions and brochures and maps of cities in the county.\",\n  \"transportation\": \"SAMTRANS stops within 6 blocks.\",\n  \"updated_at\": {\n    \"$date\": 1383857247210\n  },\n  \"urls\": [\n    \"http://www.smccvb.com\"\n  ]\n}\n```\n\nI hope this helps you troubleshoot. Thanks!\n. @laurentrivard I do not. I haven't used this since 2014.. ",
    "AboulEinein": "I'm trying to create relational tables, are there any updates regarding this issue?\n@dpatti I can't find your fork.\n\nAny help would be really appreciated.\n. @dpatti thank you so much for the reply! I'll check it out.\n. @laurentrivard I do not, unfortunately.\r\n\r\nCheck AWS Database Migration Service (https://aws.amazon.com/dms/) . @jtmarmon I ran into the same problem and the cause of the problem was that in my Mongo schema I had an `Array` of `Objects`, and each object had `_id` and in my YAML `Collection Map` file I was mapping this field to `JSONB ARRAY` and I guess it was failing to cast that `_id`.\n\nI'm not sure if there's a fix for this, what I did for now was removing the definition of that field so it ends up in the `_extra_props` column.\n. I'm trying to create relational tables, are there any updates regarding this issue?\n@dpatti I can't find your fork.\n\nAny help would be really appreciated.\n. @dpatti thank you so much for the reply! I'll check it out.\n. @laurentrivard I do not, unfortunately.\r\n\r\nCheck AWS Database Migration Service (https://aws.amazon.com/dms/) . @jtmarmon I ran into the same problem and the cause of the problem was that in my Mongo schema I had an `Array` of `Objects`, and each object had `_id` and in my YAML `Collection Map` file I was mapping this field to `JSONB ARRAY` and I guess it was failing to cast that `_id`.\n\nI'm not sure if there's a fix for this, what I did for now was removing the definition of that field so it ends up in the `_extra_props` column.\n. ",
    "laurentrivard": "@AboulEinein @monfresh any of you still have @dpatti 's fork? . @houshuang Looking into converting our MongoDB data with postgres but we have arrays inside our documents. Would you PR help us import arrays into their own tables? . @AboulEinein @monfresh any of you still have @dpatti 's fork? . @houshuang Looking into converting our MongoDB data with postgres but we have arrays inside our documents. Would you PR help us import arrays into their own tables? . ",
    "flavio": "Good points, I'm going to work on the issue you reported.\n. Everything should be working fine right now. Mosql handles properly also the tables with a primary key named in a different way.\n. First of all sorry for the late response. I've been pretty busy during the last weeks.\n\nI have to admit my example wasn't really clear, plus it contained some code taken from my actual callbacks which I forgot to remove/rename. Let me explain what I'm using mosql for, this should hopefully make everything clear.\n\nWe have a big database running inside of MongoDB and we want to move its contents to PostgreSQL. While doing that we want to:\n- get rid of MongoDB's `ObjectId`s and use standard sql ids.\n- unwind the associations between our collections. Our previous code used [Mongoid](http://mongoid.org/), now we are migrating to Active Record. Some of these relations are simple _\"has one/belongs to\"_, but we have also a _\"has and belongs to many\"_.\n\nSo we defined our PostgreSQL schema inside of Rails using a set of migrations and then we created mosql's `collections.yml` file. Some columns and tables are hidden to mosql (like the join table for the _habtm_ association and the foreign keys used by the _\"belongs to\"_ relations).\n\nThe columns/tables not visible from mosql are populated on the fly by custom callbacks. That's why the callback methods receive the whole object as read from MongoDB.\n\nI recognize this is a really specific (and strange) usage of mosql. I hope this comment makes everything clear.\n\nDo you think my example (cleaned up and improved a little bit) could be useful?\n. Good points, I'm going to work on the issue you reported.\n. Everything should be working fine right now. Mosql handles properly also the tables with a primary key named in a different way.\n. First of all sorry for the late response. I've been pretty busy during the last weeks.\n\nI have to admit my example wasn't really clear, plus it contained some code taken from my actual callbacks which I forgot to remove/rename. Let me explain what I'm using mosql for, this should hopefully make everything clear.\n\nWe have a big database running inside of MongoDB and we want to move its contents to PostgreSQL. While doing that we want to:\n- get rid of MongoDB's `ObjectId`s and use standard sql ids.\n- unwind the associations between our collections. Our previous code used [Mongoid](http://mongoid.org/), now we are migrating to Active Record. Some of these relations are simple _\"has one/belongs to\"_, but we have also a _\"has and belongs to many\"_.\n\nSo we defined our PostgreSQL schema inside of Rails using a set of migrations and then we created mosql's `collections.yml` file. Some columns and tables are hidden to mosql (like the join table for the _habtm_ association and the foreign keys used by the _\"belongs to\"_ relations).\n\nThe columns/tables not visible from mosql are populated on the fly by custom callbacks. That's why the callback methods receive the whole object as read from MongoDB.\n\nI recognize this is a really specific (and strange) usage of mosql. I hope this comment makes everything clear.\n\nDo you think my example (cleaned up and improved a little bit) could be useful?\n. ",
    "adamgotterer": "+1 for some form of this functionality\n. +1 for some form of this functionality\n. ",
    "lucasmartins": "You have to either create another table to map that embedded attribute or - which I think is easier - create a text column  to store as JSON (that won't be useful if you need to use the data for SQL data analysis).\n\nSorry I can't be of more help...\n. You have to either create another table to map that embedded attribute or - which I think is easier - create a text column  to store as JSON (that won't be useful if you need to use the data for SQL data analysis).\n\nSorry I can't be of more help...\n. ",
    "HAPPYY": "Thanks for help, we have already tried  these methods  what you said. \n(1).i created another table \nbut how can i relate two tables  when there aren't reference id?\n(2).create a text column \nit's really hard to group by some embedded attribute ,i have to join similar  sq l  sentences  ,I can analysis simple situations  but can't dig deep information...   \n\nhope more guys come here to discuss this question~\n. Thanks for help, we have already tried  these methods  what you said. \n(1).i created another table \nbut how can i relate two tables  when there aren't reference id?\n(2).create a text column \nit's really hard to group by some embedded attribute ,i have to join similar  sq l  sentences  ,I can analysis simple situations  but can't dig deep information...   \n\nhope more guys come here to discuss this question~\n. ",
    "frankliu747": "mongodb:\ncus:\n:columns:\n- id:\n  :source: _id\n  :type: INTEGER\n- status:\n  :source: status\n  :type: INTEGER\n- insure_for:\n  :source: insure_for\n  :type: VARCHAR(20)\n- email:\n  :source: email\n  :type: VARCHAR(20)\n- nick:\n  :source: nick\n  :type: VARCHAR(100)\n- payment_scope: VARCHAR(10)\n- sex: INTEGER\n- has_social_insure: BOOLEAN\n- updated_at: DATE\n- created_at: DATE\n- utm_id:\n    :source: utm._id\n    :type: INTEGER\n  - utm_source:\n    :source: utm.utm_source\n    :type: VARCHAR(100)\n  - utm_medium:\n    :source: utm.utm_medium\n    :type: VARCHAR(100)\n  - utm_campaign: \n    :source: utm.utm_campaign\n    :meta:\n    :table: cus\n    :extra_props: false\n. mongodb:\ncus:\n:columns:\n- id:\n  :source: _id\n  :type: INTEGER\n- status:\n  :source: status\n  :type: INTEGER\n- insure_for:\n  :source: insure_for\n  :type: VARCHAR(20)\n- email:\n  :source: email\n  :type: VARCHAR(20)\n- nick:\n  :source: nick\n  :type: VARCHAR(100)\n- payment_scope: VARCHAR(10)\n- sex: INTEGER\n- has_social_insure: BOOLEAN\n- updated_at: DATE\n- created_at: DATE\n- utm_id:\n    :source: utm._id\n    :type: INTEGER\n  - utm_source:\n    :source: utm.utm_source\n    :type: VARCHAR(100)\n  - utm_medium:\n    :source: utm.utm_medium\n    :type: VARCHAR(100)\n  - utm_campaign: \n    :source: utm.utm_campaign\n    :meta:\n    :table: cus\n    :extra_props: false\n. ",
    "shaneog": "This doesn't work for me. Is there any way of dealing with multiple embeds yet?\n. :+1: \n. This doesn't work for me. Is there any way of dealing with multiple embeds yet?\n. :+1: \n. ",
    "tirdadc": "More documentation / examples of this being done would be welcome, at this point it seems like I'd be better off with manual migrations given the number of embedded models I have.\n. More documentation / examples of this being done would be welcome, at this point it seems like I'd be better off with manual migrations given the number of embedded models I have.\n. ",
    "ryanatwork": "Thanks for fixing @nelhage !!\n. We (Upworthy) run mosql on Heroku.  \n\nBasically just add a Procfile with this line:\nworker: bundle exec mosql --sql $DATABASE_URL --mongo $MONGOHQ_URL?slaveOk=true\n. What we do is just alter the postgres table by adding the column we need.  Then we just a touch on our mongo table that we need which causes an update and the data comes over. \n. Sure..\n\n```\n2014-11-07T20:51:13.098247+00:00 app[worker.1]: /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:1230:in `literal_other_append': can't express BSON::ObjectId('52f3c511e045f9b21d002dc9') as a SQL literal (Sequel::Error)\n2014-11-07T20:51:13.098254+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/adapters/shared/postgres.rb:1247:in `complex_expression_sql_append'\n2014-11-07T20:51:13.098256+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/sql.rb:107:in `to_s_append'\n2014-11-07T20:51:13.098261+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:85:in `literal_append'\n2014-11-07T20:51:13.098262+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:1429:in `select_where_sql'\n2014-11-07T20:51:13.098253+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:484:in `complex_expression_sql_append'\n2014-11-07T20:51:13.098257+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:1192:in `literal_expression_append'\n2014-11-07T20:51:13.098263+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:230:in `delete_sql'\n2014-11-07T20:51:13.098267+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/streamer.rb:239:in `handle_op'\n2014-11-07T20:51:13.098268+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/streamer.rb:176:in `block in optail'\n2014-11-07T20:51:13.098269+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mongoriver-0.4.0/lib/mongoriver/abstract_persistent_tailer.rb:33:in `block in stream'\n2014-11-07T20:51:13.098270+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mongoriver-0.4.0/lib/mongoriver/tailer.rb:162:in `call'\n2014-11-07T20:51:13.098265+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/streamer.rb:195:in `sync_object'\n2014-11-07T20:51:13.098278+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/cli.rb:16:in `run'\n2014-11-07T20:51:13.098273+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mongoriver-0.4.0/lib/mongoriver/tailer.rb:162:in `stream'\n2014-11-07T20:51:13.098275+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mongoriver-0.4.0/lib/mongoriver/abstract_persistent_tailer.rb:32:in `stream'\n2014-11-07T20:51:13.098276+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/streamer.rb:175:in `optail'\n2014-11-07T20:51:13.098277+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/cli.rb:170:in `run'\n2014-11-07T20:51:13.098251+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:107:in `literal_append'\n2014-11-07T20:51:13.098264+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/actions.rb:118:in `delete'\n2014-11-07T20:51:13.098279+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/bin/mosql:5:in `<top (required)>'\n2014-11-07T20:51:13.098297+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/bin/mosql:23:in `load'\n2014-11-07T20:51:13.098298+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/bin/mosql:23:in `<main>'\n2014-11-07T20:51:13.916233+00:00 heroku[worker.1]: Process exited with status 1\n2014-11-07T20:51:13.927391+00:00 heroku[worker.1]: State changed from up to crashed\n```\n. @nelhage Thanks!  Just deployed it, looking good so far. \n. @nelhage well.. spoke to soon maybe.  We deployed this but now data isnt passing from our mongo to postgres instance.  I tried reverting but now its stuck (not sending data from mongo to postgres).  Any ideas?\n. I'm not sure what happened.  It looks like it may have been a timestamp thing?  Anyway, I deleted the contents of mosql_tailers and it caused a reimport.  So our data is back to flowing. \n\nNot sure if anyone else has had an issue going from 0.3 to 0.4.\n. Thanks for fixing @nelhage !!\n. We (Upworthy) run mosql on Heroku.  \n\nBasically just add a Procfile with this line:\nworker: bundle exec mosql --sql $DATABASE_URL --mongo $MONGOHQ_URL?slaveOk=true\n. What we do is just alter the postgres table by adding the column we need.  Then we just a touch on our mongo table that we need which causes an update and the data comes over. \n. Sure..\n\n```\n2014-11-07T20:51:13.098247+00:00 app[worker.1]: /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:1230:in `literal_other_append': can't express BSON::ObjectId('52f3c511e045f9b21d002dc9') as a SQL literal (Sequel::Error)\n2014-11-07T20:51:13.098254+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/adapters/shared/postgres.rb:1247:in `complex_expression_sql_append'\n2014-11-07T20:51:13.098256+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/sql.rb:107:in `to_s_append'\n2014-11-07T20:51:13.098261+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:85:in `literal_append'\n2014-11-07T20:51:13.098262+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:1429:in `select_where_sql'\n2014-11-07T20:51:13.098253+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:484:in `complex_expression_sql_append'\n2014-11-07T20:51:13.098257+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:1192:in `literal_expression_append'\n2014-11-07T20:51:13.098263+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:230:in `delete_sql'\n2014-11-07T20:51:13.098267+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/streamer.rb:239:in `handle_op'\n2014-11-07T20:51:13.098268+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/streamer.rb:176:in `block in optail'\n2014-11-07T20:51:13.098269+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mongoriver-0.4.0/lib/mongoriver/abstract_persistent_tailer.rb:33:in `block in stream'\n2014-11-07T20:51:13.098270+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mongoriver-0.4.0/lib/mongoriver/tailer.rb:162:in `call'\n2014-11-07T20:51:13.098265+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/streamer.rb:195:in `sync_object'\n2014-11-07T20:51:13.098278+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/cli.rb:16:in `run'\n2014-11-07T20:51:13.098273+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mongoriver-0.4.0/lib/mongoriver/tailer.rb:162:in `stream'\n2014-11-07T20:51:13.098275+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mongoriver-0.4.0/lib/mongoriver/abstract_persistent_tailer.rb:32:in `stream'\n2014-11-07T20:51:13.098276+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/streamer.rb:175:in `optail'\n2014-11-07T20:51:13.098277+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/lib/mosql/cli.rb:170:in `run'\n2014-11-07T20:51:13.098251+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/sql.rb:107:in `literal_append'\n2014-11-07T20:51:13.098264+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/sequel-4.16.0/lib/sequel/dataset/actions.rb:118:in `delete'\n2014-11-07T20:51:13.098279+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/gems/mosql-0.4.1/bin/mosql:5:in `<top (required)>'\n2014-11-07T20:51:13.098297+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/bin/mosql:23:in `load'\n2014-11-07T20:51:13.098298+00:00 app[worker.1]:     from /app/vendor/bundle/ruby/1.9.1/bin/mosql:23:in `<main>'\n2014-11-07T20:51:13.916233+00:00 heroku[worker.1]: Process exited with status 1\n2014-11-07T20:51:13.927391+00:00 heroku[worker.1]: State changed from up to crashed\n```\n. @nelhage Thanks!  Just deployed it, looking good so far. \n. @nelhage well.. spoke to soon maybe.  We deployed this but now data isnt passing from our mongo to postgres instance.  I tried reverting but now its stuck (not sending data from mongo to postgres).  Any ideas?\n. I'm not sure what happened.  It looks like it may have been a timestamp thing?  Anyway, I deleted the contents of mosql_tailers and it caused a reimport.  So our data is back to flowing. \n\nNot sure if anyone else has had an issue going from 0.3 to 0.4.\n. ",
    "hunterowens": "Specifically, migrating a collection of\nthishttps://github.com/dssg/census-communities-usa/blob/master/data_notes/example_data.json\ntype\nof data using this yml\nfilehttps://github.com/dssg/census-communities-usa/blob/master/data_notes/collections.yml\nproduces\na cryptic error.\n\nOn Thu, Jul 25, 2013 at 4:36 PM, Nelson Elhage notifications@github.comwrote:\n\n> Hi,\n> \n> I agree that we could do better here in general. Do you have an example\n> that produces that specific error, so I can make sure we handle it more\n> gracefully?\n> \n> \u2014\n> Reply to this email directly or view it on GitHubhttps://github.com/stripe/mosql/issues/24#issuecomment-21586563\n> .\n. Specifically, migrating a collection of\nthishttps://github.com/dssg/census-communities-usa/blob/master/data_notes/example_data.json\ntype\nof data using this yml\nfilehttps://github.com/dssg/census-communities-usa/blob/master/data_notes/collections.yml\nproduces\na cryptic error.\n\nOn Thu, Jul 25, 2013 at 4:36 PM, Nelson Elhage notifications@github.comwrote:\n\n> Hi,\n> \n> I agree that we could do better here in general. Do you have an example\n> that produces that specific error, so I can make sure we handle it more\n> gracefully?\n> \n> \u2014\n> Reply to this email directly or view it on GitHubhttps://github.com/stripe/mosql/issues/24#issuecomment-21586563\n> .\n. ",
    "tomsoft1": "Thanks a lot for the help!\n. Thanks a lot for the help!\n. ",
    "motevets": "Just an update.  While we were looking work on this here, we ultimately decided to hold off because [Postgres expanded their JSON datatype support in 9.3](http://wiki.postgresql.org/wiki/What%27s_new_in_PostgreSQL_9.3#JSON:_Additional_functionality).\n. Ah, yes.  This is a much better approach.  Thanks for your feedback!\n. It took me a bit, but thanks to [a post on SO](http://stackoverflow.com/a/11137004/852639), I found out that It is possible to represent PostGIS data in CSV using [WKT](http://postgis.refractions.net/documentation/manual-1.3SVN/ch04.html#id2726203).  For example a CSV could looking something like this\n\n``` csv\nname,geocode\nDisney World,POINT(28.4116733 -81.5825738)\n```\n\nI'll start cracking on this! \n. So I was thinking of refactoring out Transformations.  I think it could actually, in the long run be refactored out into:\n- a **Schema** _is composed of many_ **Collection**s\n- a **Collection** _is composed of many_ **Column**s\n- a **Column** _has a_ **Transformation**\n- **Transformation** _is a_ **SimpleTransformation**, **MagicTransformation**, **PointTransformation**, etc.\n\nA simple class diagram I made is [here](https://docs.google.com/drawings/d/1_oCfAXFo6SsvHCItTzT9dQzOigotkbLhLDtebVjesK8/edit?usp=sharing).\n\nWhat do you think @nelhage?\n. Just an update.  While we were looking work on this here, we ultimately decided to hold off because [Postgres expanded their JSON datatype support in 9.3](http://wiki.postgresql.org/wiki/What%27s_new_in_PostgreSQL_9.3#JSON:_Additional_functionality).\n. Ah, yes.  This is a much better approach.  Thanks for your feedback!\n. It took me a bit, but thanks to [a post on SO](http://stackoverflow.com/a/11137004/852639), I found out that It is possible to represent PostGIS data in CSV using [WKT](http://postgis.refractions.net/documentation/manual-1.3SVN/ch04.html#id2726203).  For example a CSV could looking something like this\n\n``` csv\nname,geocode\nDisney World,POINT(28.4116733 -81.5825738)\n```\n\nI'll start cracking on this! \n. So I was thinking of refactoring out Transformations.  I think it could actually, in the long run be refactored out into:\n- a **Schema** _is composed of many_ **Collection**s\n- a **Collection** _is composed of many_ **Column**s\n- a **Column** _has a_ **Transformation**\n- **Transformation** _is a_ **SimpleTransformation**, **MagicTransformation**, **PointTransformation**, etc.\n\nA simple class diagram I made is [here](https://docs.google.com/drawings/d/1_oCfAXFo6SsvHCItTzT9dQzOigotkbLhLDtebVjesK8/edit?usp=sharing).\n\nWhat do you think @nelhage?\n. ",
    "toothrot": "I'd be happy to help add MySQL support. Do you have any list of postgres specific things that I could work through?\n. Thanks. I'll give this a shot with our staging setup in the next few weeks and will update this if there is any positive progress.\n. @smchugh Haven't ended up doing anything on it. Oddly enough, ended up using Postgres.\n. @jkleint Any luck here?\n. Ended up getting this working by using a different Sequel, but it's really not worth it. You want to do a COPY as Redshift recommends. Inserts are unusably slow.\n. @yiwang You actually really don't want to use Redshift like this! It has around 500ms per insert performance, so moped is a bad fit. I'll post our script we use for an ETL from our mosql postgres instance sometime in the next month.\n. Yup. Using this in production right now. Works great.\n. I'd be happy to help add MySQL support. Do you have any list of postgres specific things that I could work through?\n. Thanks. I'll give this a shot with our staging setup in the next few weeks and will update this if there is any positive progress.\n. @smchugh Haven't ended up doing anything on it. Oddly enough, ended up using Postgres.\n. @jkleint Any luck here?\n. Ended up getting this working by using a different Sequel, but it's really not worth it. You want to do a COPY as Redshift recommends. Inserts are unusably slow.\n. @yiwang You actually really don't want to use Redshift like this! It has around 500ms per insert performance, so moped is a bad fit. I'll post our script we use for an ETL from our mosql postgres instance sometime in the next month.\n. Yup. Using this in production right now. Works great.\n. ",
    "smchugh": "Was there any progress on this @toothrot? I'm about to try implementing this myself unless you found a viable solution. Thanks\n. Thanks, @toothrot. Postgres wasn't an option for us, so I wrote up the following patch https://github.com/stripe/mosql/pull/37.\n. Thanks for taking a look at this. The Travis CI error seems to be from the fact that it's looking for 0.3.1 rather than 0.3.2. I'll change the version file to use 0.3.1 when I go in and remove the slaveOk commit\n. @goutamdan We ended up not using this tool, so the projected ended up dropped. I'd ideally like to pick it back up on my own time, but haven't had the chance. If you wanted to pick this up, I'd be more than glad to accept a PR into this branch.\n. Was there any progress on this @toothrot? I'm about to try implementing this myself unless you found a viable solution. Thanks\n. Thanks, @toothrot. Postgres wasn't an option for us, so I wrote up the following patch https://github.com/stripe/mosql/pull/37.\n. Thanks for taking a look at this. The Travis CI error seems to be from the fact that it's looking for 0.3.1 rather than 0.3.2. I'll change the version file to use 0.3.1 when I go in and remove the slaveOk commit\n. @goutamdan We ended up not using this tool, so the projected ended up dropped. I'd ideally like to pick it back up on my own time, but haven't had the chance. If you wanted to pick this up, I'd be more than glad to accept a PR into this branch.\n. ",
    "tensiondriven": "Sounds good - this issue is in our current sprint, so look forward to an update one way or the other in the next week or so.  Thanks for the prompt reply!\n. :+1: \n. Sounds good - this issue is in our current sprint, so look forward to an update one way or the other in the next week or so.  Thanks for the prompt reply!\n. :+1: \n. ",
    "charlietran": "I've used MoSQL with Heroku Postgres, the actual MoSQL process was running on an EC2 instance. Worked great!\n. I've used MoSQL with Heroku Postgres, the actual MoSQL process was running on an EC2 instance. Worked great!\n. ",
    "levity": "We've just deployed the actual MoSQL process on a Heroku dyno. Too early to tell how robust it is, but so far it's been painless.\n. Just a plain old dyno. I wrote a rake task that starts mosql in a subprocess, and then added a line to the Procfile, then started it up with `heroku ps:scale`. \n\nThe rake task [looks like this](https://gist.github.com/levity/9773299). Procfile and ps:scale usage are well-documented on Heroku.\n. Here's the object, with some fields replaced by \"...\":\n\n```\n{\n    \"_id\" : ObjectId(\"5233b00caddfe6c60c000003\"),\n    \"charge_id\" : ObjectId(\"5233b00caddfe6c60c000002\"),\n    \"created_at\" : ISODate(\"2013-09-14T00:38:36.769Z\"),\n    \"force_charge\" : false,\n    \"order_item_id\" : ObjectId(\"5226716a2774e24751000002\"),\n    \"ordered_date\" : ISODate(\"2013-09-14T00:48:54.365Z\"),\n    \"shipped_date\" : ISODate(\"2013-09-17T00:00:00Z\"),\n    \"shipped_email_date\" : ISODate(\"2013-09-18T00:03:28.008Z\"),\n    \"shipping_address_1\" : \"...\",\n    \"shipping_address_2\" : \"\",\n    \"shipping_city\" : \"San Francisco\",\n    \"shipping_country\" : \"United States\",\n    \"shipping_first_name\" : \"...\",\n    \"shipping_last_name\" : \"...\",\n    \"shipping_state\" : \"CA\",\n    \"shipping_zip\" : \"...\",\n    \"short_id\" : \"ed8fd\",\n    \"state\" : \"out_for_delivery\",\n    \"subscription_id\" : ObjectId(\"5233b009addfe6c60c000001\"),\n    \"tracking_id\" : \"...\",\n    \"tracking_link\" : \"http://wwwapps.ups.com/tracking/tracking.cgi?tracknum=...\",\n    \"tracking_method\" : \" GROUND SERVICE RESIDENTIAL\",\n    \"updated_at\" : ISODate(\"2013-10-18T23:38:14.744Z\"),\n    \"user_id\" : ObjectId(\"5233a444e3f92f9f72000002\"),\n    \"version\" : 859\n}\n```\n\nThe `state` field was the one that had the value \"shipped\" and is now \"out_for_delivery\". The error occurred when the document was updated to change the state. \n\nOne unusual thing about this `state` field is that it stores symbol values, which isn't apparent from the MongoDB dump. (Actually I have no idea how Mongoid knows the value is a symbol; I just had to ask [on StackOverflow](http://stackoverflow.com/questions/19460828/how-does-mongoid-know-the-difference-between-string-values-and-symbol-values) about this.)\n\nAnd the config for this collection:\n\n```\n  orders:\n    :columns:\n    - id:\n      :source: _id\n      :type: TEXT\n    - charge_id: TEXT\n    - created_at: TIMESTAMP\n    - updated_at: TIMESTAMP\n    - error_message: TEXT\n    - ordered_date: TIMESTAMP\n    - order_item_id: TEXT\n    - shipped_date: DATE\n    - shipping_first_name: TEXT\n    - shipping_last_name: TEXT\n    - shipping_address_1: TEXT\n    - shipping_address_2: TEXT\n    - shipping_city: TEXT\n    - shipping_zip: TEXT\n    - shipping_state: TEXT\n    - shipping_country: TEXT\n    - short_id: TEXT\n    - state: TEXT\n    - subscription_id: TEXT\n    - tracking_id: TEXT\n    - user_id: TEXT\n    :meta:\n      :table: orders\n      :extra_props: true\n```\n. Sweet, will do!\n. That did the trick, thanks for the quick help!\n. We've just deployed the actual MoSQL process on a Heroku dyno. Too early to tell how robust it is, but so far it's been painless.\n. Just a plain old dyno. I wrote a rake task that starts mosql in a subprocess, and then added a line to the Procfile, then started it up with `heroku ps:scale`. \n\nThe rake task [looks like this](https://gist.github.com/levity/9773299). Procfile and ps:scale usage are well-documented on Heroku.\n. Here's the object, with some fields replaced by \"...\":\n\n```\n{\n    \"_id\" : ObjectId(\"5233b00caddfe6c60c000003\"),\n    \"charge_id\" : ObjectId(\"5233b00caddfe6c60c000002\"),\n    \"created_at\" : ISODate(\"2013-09-14T00:38:36.769Z\"),\n    \"force_charge\" : false,\n    \"order_item_id\" : ObjectId(\"5226716a2774e24751000002\"),\n    \"ordered_date\" : ISODate(\"2013-09-14T00:48:54.365Z\"),\n    \"shipped_date\" : ISODate(\"2013-09-17T00:00:00Z\"),\n    \"shipped_email_date\" : ISODate(\"2013-09-18T00:03:28.008Z\"),\n    \"shipping_address_1\" : \"...\",\n    \"shipping_address_2\" : \"\",\n    \"shipping_city\" : \"San Francisco\",\n    \"shipping_country\" : \"United States\",\n    \"shipping_first_name\" : \"...\",\n    \"shipping_last_name\" : \"...\",\n    \"shipping_state\" : \"CA\",\n    \"shipping_zip\" : \"...\",\n    \"short_id\" : \"ed8fd\",\n    \"state\" : \"out_for_delivery\",\n    \"subscription_id\" : ObjectId(\"5233b009addfe6c60c000001\"),\n    \"tracking_id\" : \"...\",\n    \"tracking_link\" : \"http://wwwapps.ups.com/tracking/tracking.cgi?tracknum=...\",\n    \"tracking_method\" : \" GROUND SERVICE RESIDENTIAL\",\n    \"updated_at\" : ISODate(\"2013-10-18T23:38:14.744Z\"),\n    \"user_id\" : ObjectId(\"5233a444e3f92f9f72000002\"),\n    \"version\" : 859\n}\n```\n\nThe `state` field was the one that had the value \"shipped\" and is now \"out_for_delivery\". The error occurred when the document was updated to change the state. \n\nOne unusual thing about this `state` field is that it stores symbol values, which isn't apparent from the MongoDB dump. (Actually I have no idea how Mongoid knows the value is a symbol; I just had to ask [on StackOverflow](http://stackoverflow.com/questions/19460828/how-does-mongoid-know-the-difference-between-string-values-and-symbol-values) about this.)\n\nAnd the config for this collection:\n\n```\n  orders:\n    :columns:\n    - id:\n      :source: _id\n      :type: TEXT\n    - charge_id: TEXT\n    - created_at: TIMESTAMP\n    - updated_at: TIMESTAMP\n    - error_message: TEXT\n    - ordered_date: TIMESTAMP\n    - order_item_id: TEXT\n    - shipped_date: DATE\n    - shipping_first_name: TEXT\n    - shipping_last_name: TEXT\n    - shipping_address_1: TEXT\n    - shipping_address_2: TEXT\n    - shipping_city: TEXT\n    - shipping_zip: TEXT\n    - shipping_state: TEXT\n    - shipping_country: TEXT\n    - short_id: TEXT\n    - state: TEXT\n    - subscription_id: TEXT\n    - tracking_id: TEXT\n    - user_id: TEXT\n    :meta:\n      :table: orders\n      :extra_props: true\n```\n. Sweet, will do!\n. That did the trick, thanks for the quick help!\n. ",
    "nikilster": "@charlietran What were the deciding factors in running the MoSQL process on ec2 vs heroku? \n\n@charlietran @levity What's the latency like?  Real time is pretty important for my visualizations.\n. @levity What type of dyno did you use in heroku / how exactly did you set that up?  Thanks - I'm new to Heroku :) \n. Fantastic thanks!\n. wow okay that was amazing.  I spent several hours trying to fix this.  Thanks!\n. I'm guess that I can't run the admin commands since its a hosted db - is there any way around this?\n. @charlietran What were the deciding factors in running the MoSQL process on ec2 vs heroku? \n\n@charlietran @levity What's the latency like?  Real time is pretty important for my visualizations.\n. @levity What type of dyno did you use in heroku / how exactly did you set that up?  Thanks - I'm new to Heroku :) \n. Fantastic thanks!\n. wow okay that was amazing.  I spent several hours trying to fix this.  Thanks!\n. I'm guess that I can't run the admin commands since its a hosted db - is there any way around this?\n. ",
    "brettallred": "@levity - have you tried (do you know how to) run multiple mosql processes in a single worker dyno? \n. @levity - have you tried (do you know how to) run multiple mosql processes in a single worker dyno? \n. ",
    "jtmarmon": "hey @aauthor - I also have geocoded location data. having support for PostGIS would be awesome. any luck on this?\n. hey @nelhage @sbailliez - I'm on mosql v 0.4.2 and still getting this error. any ideas?\n. awesome. i'll see if i can get a chance to work on this over the next couple of weeks. \n. +1 - anyone know what would cause this? I checked the timestamp that it appears to be failing on and I don't see any issues\n. looks like there was a PR open to resolve this here: #83 which broke tests. \n. hey @aauthor - I also have geocoded location data. having support for PostGIS would be awesome. any luck on this?\n. hey @nelhage @sbailliez - I'm on mosql v 0.4.2 and still getting this error. any ideas?\n. awesome. i'll see if i can get a chance to work on this over the next couple of weeks. \n. +1 - anyone know what would cause this? I checked the timestamp that it appears to be failing on and I don't see any issues\n. looks like there was a PR open to resolve this here: #83 which broke tests. \n. ",
    "jkernech": "+1\n. +1\n. ",
    "ollym": "Would it not be better to improve the FDW driver? Since Postgres 9.3 you can now send updates via the FDW as-well. I wouldn't know about the efficiency of JOINs etc. but it looks like this is postgres' way forward\n. Would it not be better to improve the FDW driver? Since Postgres 9.3 you can now send updates via the FDW as-well. I wouldn't know about the efficiency of JOINs etc. but it looks like this is postgres' way forward\n. ",
    "goutamdan": "During the initial import, the query for bulk copying always fails because of syntax errors caused by wrong quoting. The field names have double quotes and the values have no quotes at all. So this always falls back to the update and insert queries. This makes initial import extremely slow. Any plans to fix this? \n. During the initial import, the query for bulk copying always fails because of syntax errors caused by wrong quoting. The field names have double quotes and the values have no quotes at all. So this always falls back to the update and insert queries. This makes initial import extremely slow. Any plans to fix this? \n. ",
    "jkleint": "Haven't pursued it, sorry.\n. Haven't pursued it, sorry.\n. ",
    "yiwang": "@toothrot which version of Sequel you use to get it work? can you share how you did it? thanks!\n. @toothrot which version of Sequel you use to get it work? can you share how you did it? thanks!\n. ",
    "ColmHally": "Hi @toothrot, @yiwang, any updates here? Struggling with this same issue at the moment..\n. Hey @BraedenP I'd be very interested in seeing your changes to insert multiple records in a single INSERT, even if it's rough!\n. Hi @toothrot, @yiwang, any updates here? Struggling with this same issue at the moment..\n. Hey @BraedenP I'd be very interested in seeing your changes to insert multiple records in a single INSERT, even if it's rough!\n. ",
    "anacrolix": ":+1:\n. :+1:\n. ",
    "vkarpov15": "Just ran into this. Curious, why is this not listed as a dependency in the mosql package or somewhere upstream? Surprise dependencies are a pain.\n. Just ran into this. Curious, why is this not listed as a dependency in the mosql package or somewhere upstream? Surprise dependencies are a pain.\n. ",
    "sadowski": "Unfortunately, if you look at the code in lib/mosql/streamer.rb line 96 it calls @mongo.get_databases(). This call translates to a listDatabases call on the server, which requires admin access (even if you use --skip-tail).\n\nI'm not really sure why we need to iterate through the databases to find the already specified database. If I've already specified the one I want to connect to, it should just assume that I am connected to the correct database. This might be an area for improvement.\n\nOh, also, the reason I am experiencing this error is because I'm using a hosted MongoDB solution (MongoHQ) and don't have admin access.\n. Thanks for the feedback! I've implemented the changes you've requested.\n. Unfortunately, if you look at the code in lib/mosql/streamer.rb line 96 it calls @mongo.get_databases(). This call translates to a listDatabases call on the server, which requires admin access (even if you use --skip-tail).\n\nI'm not really sure why we need to iterate through the databases to find the already specified database. If I've already specified the one I want to connect to, it should just assume that I am connected to the correct database. This might be an area for improvement.\n\nOh, also, the reason I am experiencing this error is because I'm using a hosted MongoDB solution (MongoHQ) and don't have admin access.\n. Thanks for the feedback! I've implemented the changes you've requested.\n. ",
    "pshc": "For the record, the need for admin access can be avoided with `--only-db`.\n. For the record, the need for admin access can be avoided with `--only-db`.\n. ",
    "AndrewBarba": "Was anyone able to get this working with Compose (MongoHQ)? If so can you share more details and what options you ended up using? I've tried many times with the `--only-db` option and that still does not work. \n. Hm I did do that, any chance you can post the exact command (without credentials obviously)\n. For reference this is what I tried but it fails at the listDatabases command:\n\n```\nmongodb://$USER:$PASSWORD@$HOST:$PORT?replicaSet=set-$REPLICA&readPreference=secondary --only-db $DB\n```\n. Was anyone able to get this working with Compose (MongoHQ)? If so can you share more details and what options you ended up using? I've tried many times with the `--only-db` option and that still does not work. \n. Hm I did do that, any chance you can post the exact command (without credentials obviously)\n. For reference this is what I tried but it fails at the listDatabases command:\n\n```\nmongodb://$USER:$PASSWORD@$HOST:$PORT?replicaSet=set-$REPLICA&readPreference=secondary --only-db $DB\n```\n. ",
    "edchan77": "I'm using Compose as well, didn't find a solution yet.\n. It works with compose. Looks like I forgot to specify the dbname! --only-db [dbname]\n. @AndrewBarba Perhaps you forgot to specify the the DB after the port?\n\nmosql --mongo mongodb://$USER:$PASSWORD@$HOST:$PORT/$DB?replicaSet=set-$REPLICA&readPreference=secondary --only-db $DB\n\nBtw, you should include both addresses in the replicaset uri, since you don't which will be primary or secondary e.g.\nmosql --mongo mongodb://user:password@candidate.1.mongolayer.com:1234,candidate.2.mongolayer.com:5678/dbname?replicaSet=set-xxxyyyzzz&readPreference=secondary --only-db dbname\n. I'm using Compose as well, didn't find a solution yet.\n. It works with compose. Looks like I forgot to specify the dbname! --only-db [dbname]\n. @AndrewBarba Perhaps you forgot to specify the the DB after the port?\n\nmosql --mongo mongodb://$USER:$PASSWORD@$HOST:$PORT/$DB?replicaSet=set-$REPLICA&readPreference=secondary --only-db $DB\n\nBtw, you should include both addresses in the replicaset uri, since you don't which will be primary or secondary e.g.\nmosql --mongo mongodb://user:password@candidate.1.mongolayer.com:1234,candidate.2.mongolayer.com:5678/dbname?replicaSet=set-xxxyyyzzz&readPreference=secondary --only-db dbname\n. ",
    "hendrikswan": "I'm keen to pick this issue up and do the work to support shardsets, but would need some guidance. \n. Thanks for the great explanation! I'm still keen to hear your thoughts on how to fix it, even though you aren't happy with any of them. Maybe it kicks something lose in my mind.. \n. Oooh, it would be cool if it's that simple!\n\nOn Thu, Jun 26, 2014 at 9:34 PM, Evan Broder notifications@github.com\nwrote:\n\n> I think this may actually be comparatively straightforward.\n> \n> There are oplog entries for chunk migrations (a bunch of insertions on the\n> destination shard, and a bunch of deletions on the source shard). I haven't\n> tested this directly, but I'm told that there's a \"fromMigration\" flag on\n> all of those oplog entries. For cases where you're consolidating a sharded\n> cluster into a single postgres server, it should be sufficient to just skip\n> oplog entries with fromMigration.\n> \n> I haven't actually tested this, though, so your mileage may vary, etc.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/stripe/mosql/issues/43#issuecomment-47269533.\n\n## \n\nHendrik Swanepoel\nemail: hendrik.swanepoel@gmail.com\nmobile: 0829279906\n. Sorry @davidssonarnor, but unfortunately in the end we ran an ETL on a timer. All our mongo collections were time stamped, so we moved new and updated records over based on queries. . I'm keen to pick this issue up and do the work to support shardsets, but would need some guidance. \n. Thanks for the great explanation! I'm still keen to hear your thoughts on how to fix it, even though you aren't happy with any of them. Maybe it kicks something lose in my mind.. \n. Oooh, it would be cool if it's that simple!\n\nOn Thu, Jun 26, 2014 at 9:34 PM, Evan Broder notifications@github.com\nwrote:\n\n> I think this may actually be comparatively straightforward.\n> \n> There are oplog entries for chunk migrations (a bunch of insertions on the\n> destination shard, and a bunch of deletions on the source shard). I haven't\n> tested this directly, but I'm told that there's a \"fromMigration\" flag on\n> all of those oplog entries. For cases where you're consolidating a sharded\n> cluster into a single postgres server, it should be sufficient to just skip\n> oplog entries with fromMigration.\n> \n> I haven't actually tested this, though, so your mileage may vary, etc.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/stripe/mosql/issues/43#issuecomment-47269533.\n\n## \n\nHendrik Swanepoel\nemail: hendrik.swanepoel@gmail.com\nmobile: 0829279906\n. Sorry @davidssonarnor, but unfortunately in the end we ran an ETL on a timer. All our mongo collections were time stamped, so we moved new and updated records over based on queries. . ",
    "ebroder": "I think this may actually be comparatively straightforward.\n\nThere are oplog entries for chunk migrations (a bunch of insertions on the destination shard, and a bunch of deletions on the source shard). I haven't tested this directly, but I'm told that there's a \"fromMigration\" flag on all of those oplog entries. For cases where you're consolidating a sharded cluster into a single postgres server, it should be sufficient to just skip oplog entries with fromMigration.\n\nI haven't actually tested this, though, so your mileage may vary, etc.\n. Yeah, I think this makes sense overall\n. Hmm, the issue here is likely that `BSON.serialize` uses the original default maximum BSON size (4MB). The maximum has since been raised, but increasing it relies on negotiating the new limit with the connection.\n\nReplacing `BSON.serialize` with something like `BSON::BSON_CODER.serialize(obj, false, false, 16*1024*1024)` will likely also fix your issue (without requiring a new dependency)\n. I think this may actually be comparatively straightforward.\n\nThere are oplog entries for chunk migrations (a bunch of insertions on the destination shard, and a bunch of deletions on the source shard). I haven't tested this directly, but I'm told that there's a \"fromMigration\" flag on all of those oplog entries. For cases where you're consolidating a sharded cluster into a single postgres server, it should be sufficient to just skip oplog entries with fromMigration.\n\nI haven't actually tested this, though, so your mileage may vary, etc.\n. Yeah, I think this makes sense overall\n. Hmm, the issue here is likely that `BSON.serialize` uses the original default maximum BSON size (4MB). The maximum has since been raised, but increasing it relies on negotiating the new limit with the connection.\n\nReplacing `BSON.serialize` with something like `BSON::BSON_CODER.serialize(obj, false, false, 16*1024*1024)` will likely also fix your issue (without requiring a new dependency)\n. ",
    "apocolipse": "+1 for this feature\n. +1 for this feature\n. ",
    "michael-erasmus": "I recently found these two posts which might be helpful:\n\nhttps://www.mongodb.com/blog/post/tailing-mongodb-oplog-sharded-clusters\n\nhttps://www.mongodb.com/blog/post/pitfalls-and-workarounds-for-tailing-the-oplog-on-a-mongodb-sharded-cluster\n\nIt has more details around the using the 'fromMigration' flag and details a general approach to follow.\nI'm also interested in this feature, but not for sending data directly to Postgres. \n\nAs I understand it, mosql uses mongoriver for tailling the oplog, so support for sharded collections could be built into mongoriver, no?  \n. I recently found these two posts which might be helpful:\n\nhttps://www.mongodb.com/blog/post/tailing-mongodb-oplog-sharded-clusters\n\nhttps://www.mongodb.com/blog/post/pitfalls-and-workarounds-for-tailing-the-oplog-on-a-mongodb-sharded-cluster\n\nIt has more details around the using the 'fromMigration' flag and details a general approach to follow.\nI'm also interested in this feature, but not for sending data directly to Postgres. \n\nAs I understand it, mosql uses mongoriver for tailling the oplog, so support for sharded collections could be built into mongoriver, no?  \n. ",
    "davidssonarnor": "Any news on this? @hendrikswan . @hendrikswan ok I understand did you use mosql or just roll out your own?. Any news on this? @hendrikswan . @hendrikswan ok I understand did you use mosql or just roll out your own?. ",
    "IevgeniiB": "Hi, guys! Any updates on this issue?\n. If someone will experience such issue - don't forget to import `_id` field as well\n. Hi, guys! Any updates on this issue?\n. If someone will experience such issue - don't forget to import `_id` field as well\n. ",
    "edkurowski": "This does create the proper array type in postgres and will insert the data correctly.  I'll update the logic so that it will only treat the value as an array type if the schema has been set up to match.  And of course, I will have some tests for you.  Thanks.\n. This does create the proper array type in postgres and will insert the data correctly.  I'll update the logic so that it will only treat the value as an array type if the schema has been set up to match.  And of course, I will have some tests for you.  Thanks.\n. ",
    "braedenp-msft": "I finally had some time to look through the source, and the bottleneck is quite obvious:\n\nWhen doing the initial import, [COPY](http://www.postgresql.org/docs/9.3/static/sql-copy.html) is used to pull the records in through STDIN, which is significantly faster than running multiple INSERTs, or even inserting multiple records in a single INSERT, especially when doing large imports.\n\nWhen tailing, however, an upsert is executed for _each_ record, incurring 1-2 separate queries for each one.\n\nI put together a patch for my project that consolidates sequential inserts into a COPY operation, if possible (with fall-back to upserts in the case of constraint violations or other errors). For environments with mostly updates, this change doesn't affect performance. For environments where large inserts are common, however, this change makes a huge difference.\n\nIf anybody is interested, I can clean it up and put together some tests for merging.\n. I finally had some time to look through the source, and the bottleneck is quite obvious:\n\nWhen doing the initial import, [COPY](http://www.postgresql.org/docs/9.3/static/sql-copy.html) is used to pull the records in through STDIN, which is significantly faster than running multiple INSERTs, or even inserting multiple records in a single INSERT, especially when doing large imports.\n\nWhen tailing, however, an upsert is executed for _each_ record, incurring 1-2 separate queries for each one.\n\nI put together a patch for my project that consolidates sequential inserts into a COPY operation, if possible (with fall-back to upserts in the case of constraint violations or other errors). For environments with mostly updates, this change doesn't affect performance. For environments where large inserts are common, however, this change makes a huge difference.\n\nIf anybody is interested, I can clean it up and put together some tests for merging.\n. ",
    "kungfoox": "Definitely interested. Any thoughts on merging this into mosql?\n. Hey there. So this has been happening quite often for me. We have never been able to resume properly without during reimport. (either we get the same error over and over again or the data from the time it went down until the time it resumes is missing). LMK if there is anything we can help to properly resume?\n. Thanks for the reply. I think that's exactly what's been happening. We only had 20 min of opslog during our peek hours (<-- not much time to recover). We ended up increasing the opslog size for the secondaries so we'll see how much benefit that gives us. The other problem was connecting to the secondaries though readPreference. For some reason that seems to fail a lot. Instead, we point directly to the secondaries and use slaveOk. Cross fingers, will see if that holds up. \n. Definitely interested. Any thoughts on merging this into mosql?\n. Hey there. So this has been happening quite often for me. We have never been able to resume properly without during reimport. (either we get the same error over and over again or the data from the time it went down until the time it resumes is missing). LMK if there is anything we can help to properly resume?\n. Thanks for the reply. I think that's exactly what's been happening. We only had 20 min of opslog during our peek hours (<-- not much time to recover). We ended up increasing the opslog size for the secondaries so we'll see how much benefit that gives us. The other problem was connecting to the secondaries though readPreference. For some reason that seems to fail a lot. Instead, we point directly to the secondaries and use slaveOk. Cross fingers, will see if that holds up. \n. ",
    "barretod": "What happened with this? We really need this optimization, mosql can no longer keep up in our environtment.\n. Did you figure out how to address the concerns around timestamps? We really need this optimization in our environment. \n. What happened with this? We really need this optimization, mosql can no longer keep up in our environtment.\n. Did you figure out how to address the concerns around timestamps? We really need this optimization in our environment. \n. ",
    "AndreaCrotti": "I found the no-drop-tables option and now it does not hang, however:\n1. it still doesn't write anything to Postgres\n2. it still says \"Creating table\", but now it should not create it anymore right?\n   \n   vagrant@ubuntu-13:~$ mosql  -c collections.yaml --mongo mongodb://user:password@localhost:27017/ --sql postgres://user:password@localhost/garage --skip-tail -v 3 --no-drop-tables\n    INFO MoSQL: Creating table 'engine_comment'...\n    INFO MoSQL: Mongd DB 'local' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'garage-test' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'activity2' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'activity' not found in config file. Skipping.\n    INFO MoSQL: Importing for Mongo DB alexandria...\n    INFO MoSQL: Mongd DB 'garage' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'admin' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'activity_hfi' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'chat' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'test' not found in config file. Skipping\n\nThanks a lot\n. Yes but the thing is that I really don't want it to create the schema, I do that in other ways.\nAlso because now I'm testing a small subset to see if it works, and it would generate a wrong schema..\n\nAnyway I got it working I was just using the wrong collection name since I renamed!\nAlright then thanks for the answer.\n. Ok thanks sorry it turns out I can also query the primary anyway.\nWhat do you mean with the last sentence? I don't see anything about slave in the README..\nIt could be in a FAQ section but it's more really a Mongo question in a way than a mosql question.\n. Ah sorry I was looking for \"slave\" in the page and was not finding it.\nWell as a FAQ there could be the error I reported and what is the option to\npass to be more  complete..\n\n2014-08-21 18:10 GMT+01:00 Nelson Elhage notifications@github.com:\n\n> The README documents ?readPreference=secondary and mentions doing initial\n> imports against secondaries (mongo calls \"slave\" nodes secondaries, as of\n> the \"new\" replication architecture)\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/stripe/mosql/issues/54#issuecomment-52951158.\n. Ah ok, the older version worked anyway, so that became a requirement in master then?\n\nI think maybe adding some validation of the YAML before running the SQL and get a syntax error would be already good, thanks!\n. Because the problem is that the id in Mongo is a UUID not just a long auto incrementing, I would rather not use that as Primary Key in Postgres.\n\nThe alternative I suppose could be that if something fails I do a --reimport, or if use tail-from with the timestamp when it stopped, does it make sense?\n. I noticed now this\n\n```\n WARN MoSQL: `mongodb://django:django@localhost:27017/' is not a replset.\n WARN MoSQL: Will run the initial import, then stop.\n WARN MoSQL: Pass `--skip-tail' to suppress this warning\n```\n\nSo maybe thinking that the two things are correlated..\nSo if it's not a replset then it will not tail?\nTo test it locally I need to create a replica set then?\n. Ok thanks now I understood how it works, for production we have a replica set I just have to configure one also locally to test it..\n\nAbout the _id yes fair enough makes sense, but the question is, can I map the MongoDB id to a field that is not the primary key in PostgreSQL?\nWould it still be able to de-duplicate identical records?\n\nBecause I would really like to avoid having a primary key an UUID, Django doesn't like so much if you mess around with the primary keys..\n. I did some experiment myself and unfortunately I think the mapping does not work if it's not the primary key.\n\nI just added this mapping\n\n```\n- couch_id:\n  :source: _id\n  :type: UUID\n```\n\nAnd couch_id to the Postgres model, but if I import twice it still duplicates the rows.\nIn theory now however it could work, because it has all the information needed to understand that the row has already been inserted right?\n. By the way I found out the trick, the field I map to does not have to be a primary key as long it's unique and not null.\n\nMaybe this would be nice to be documented somewhere since it's not so evident otherwise, thanks!\n. Any news about this very simple change?\nI don't think the travis build is affected by this right?\n. Yeah it's not an easy problem, it would be nice at least to have an idea about how big the oplog could become for that to be an issue, and for how many documents more or less it might become to be an issue..\n. Yes well the Mongo database is pretty fast and it does not have problems, it's just that it's writing too fast in Postgres and thus causing a very high load there.\n\nI think I'll end up just adding some sleeps here and there, not a great solution but it might work at least..\n. I guess we can close this by now\n. I found the no-drop-tables option and now it does not hang, however:\n1. it still doesn't write anything to Postgres\n2. it still says \"Creating table\", but now it should not create it anymore right?\n   \n   vagrant@ubuntu-13:~$ mosql  -c collections.yaml --mongo mongodb://user:password@localhost:27017/ --sql postgres://user:password@localhost/garage --skip-tail -v 3 --no-drop-tables\n    INFO MoSQL: Creating table 'engine_comment'...\n    INFO MoSQL: Mongd DB 'local' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'garage-test' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'activity2' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'activity' not found in config file. Skipping.\n    INFO MoSQL: Importing for Mongo DB alexandria...\n    INFO MoSQL: Mongd DB 'garage' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'admin' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'activity_hfi' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'chat' not found in config file. Skipping.\n    INFO MoSQL: Mongd DB 'test' not found in config file. Skipping\n\nThanks a lot\n. Yes but the thing is that I really don't want it to create the schema, I do that in other ways.\nAlso because now I'm testing a small subset to see if it works, and it would generate a wrong schema..\n\nAnyway I got it working I was just using the wrong collection name since I renamed!\nAlright then thanks for the answer.\n. Ok thanks sorry it turns out I can also query the primary anyway.\nWhat do you mean with the last sentence? I don't see anything about slave in the README..\nIt could be in a FAQ section but it's more really a Mongo question in a way than a mosql question.\n. Ah sorry I was looking for \"slave\" in the page and was not finding it.\nWell as a FAQ there could be the error I reported and what is the option to\npass to be more  complete..\n\n2014-08-21 18:10 GMT+01:00 Nelson Elhage notifications@github.com:\n\n> The README documents ?readPreference=secondary and mentions doing initial\n> imports against secondaries (mongo calls \"slave\" nodes secondaries, as of\n> the \"new\" replication architecture)\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/stripe/mosql/issues/54#issuecomment-52951158.\n. Ah ok, the older version worked anyway, so that became a requirement in master then?\n\nI think maybe adding some validation of the YAML before running the SQL and get a syntax error would be already good, thanks!\n. Because the problem is that the id in Mongo is a UUID not just a long auto incrementing, I would rather not use that as Primary Key in Postgres.\n\nThe alternative I suppose could be that if something fails I do a --reimport, or if use tail-from with the timestamp when it stopped, does it make sense?\n. I noticed now this\n\n```\n WARN MoSQL: `mongodb://django:django@localhost:27017/' is not a replset.\n WARN MoSQL: Will run the initial import, then stop.\n WARN MoSQL: Pass `--skip-tail' to suppress this warning\n```\n\nSo maybe thinking that the two things are correlated..\nSo if it's not a replset then it will not tail?\nTo test it locally I need to create a replica set then?\n. Ok thanks now I understood how it works, for production we have a replica set I just have to configure one also locally to test it..\n\nAbout the _id yes fair enough makes sense, but the question is, can I map the MongoDB id to a field that is not the primary key in PostgreSQL?\nWould it still be able to de-duplicate identical records?\n\nBecause I would really like to avoid having a primary key an UUID, Django doesn't like so much if you mess around with the primary keys..\n. I did some experiment myself and unfortunately I think the mapping does not work if it's not the primary key.\n\nI just added this mapping\n\n```\n- couch_id:\n  :source: _id\n  :type: UUID\n```\n\nAnd couch_id to the Postgres model, but if I import twice it still duplicates the rows.\nIn theory now however it could work, because it has all the information needed to understand that the row has already been inserted right?\n. By the way I found out the trick, the field I map to does not have to be a primary key as long it's unique and not null.\n\nMaybe this would be nice to be documented somewhere since it's not so evident otherwise, thanks!\n. Any news about this very simple change?\nI don't think the travis build is affected by this right?\n. Yeah it's not an easy problem, it would be nice at least to have an idea about how big the oplog could become for that to be an issue, and for how many documents more or less it might become to be an issue..\n. Yes well the Mongo database is pretty fast and it does not have problems, it's just that it's writing too fast in Postgres and thus causing a very high load there.\n\nI think I'll end up just adding some sleeps here and there, not a great solution but it might work at least..\n. I guess we can close this by now\n. ",
    "sambauers": "Hey! Thanks for this fix, seems to have worked for my case.\n. Thanks! No more monkey patching my Engine Yard servers.\n. Hey! Thanks for this fix, seems to have worked for my case.\n. Thanks! No more monkey patching my Engine Yard servers.\n. ",
    "adborden": "Thanks, @nelhage. Is there a way that I can confirm this? As far as I can tell, this field /is/ an Array, though not sure how to tell BSON from JSON.\n\n```\n> db.products.find({_id: ObjectId('4f3aee0fd2f645040000000c')}, {tags: true}).map(function (p) { return  p.tags instanceof Array; });\n[ true ]\n```\n. ```\n> db.products.find({_id: ObjectId('4fa0c49bc43e9e0700000085')}, {tags: true}).map(function (p) { return  p.tags instanceof Array; });\n[ true ]\n\n> db.products.find({_id: ObjectId('4fa0c49bc43e9e0700000085')}, {tags: true}).map(function (p) { return  p._id instanceof Array; });\n[ false ]\n```\n\nFWIW, the above log is from mosql 0.3.1 and would crash mosql. I've upgraded to 0.4.1, it no longer crashes, imports most rows, but still prints a similar error -- only with verbose -v logging.\n. Thanks, @nelhage. Is there a way that I can confirm this? As far as I can tell, this field /is/ an Array, though not sure how to tell BSON from JSON.\n\n```\n> db.products.find({_id: ObjectId('4f3aee0fd2f645040000000c')}, {tags: true}).map(function (p) { return  p.tags instanceof Array; });\n[ true ]\n```\n. ```\n> db.products.find({_id: ObjectId('4fa0c49bc43e9e0700000085')}, {tags: true}).map(function (p) { return  p.tags instanceof Array; });\n[ true ]\n\n> db.products.find({_id: ObjectId('4fa0c49bc43e9e0700000085')}, {tags: true}).map(function (p) { return  p._id instanceof Array; });\n[ false ]\n```\n\nFWIW, the above log is from mosql 0.3.1 and would crash mosql. I've upgraded to 0.4.1, it no longer crashes, imports most rows, but still prints a similar error -- only with verbose -v logging.\n. ",
    "ezesculli": "I saw performance problems when I had big latency between MongoDB & PostGre databases. I tried different configurations on the cloud, using different MongoDb providers (MongoDB, EC2 instance, etc.) & PostGre providers (Amazon RDS, Heroku PostGre, etc.) to had the better performance. Hosting everything on EC2 was the best solution!\n\nHope it helps!\n. Any updates on this? Is this working on Mongo 3?\n. I saw performance problems when I had big latency between MongoDB & PostGre databases. I tried different configurations on the cloud, using different MongoDb providers (MongoDB, EC2 instance, etc.) & PostGre providers (Amazon RDS, Heroku PostGre, etc.) to had the better performance. Hosting everything on EC2 was the best solution!\n\nHope it helps!\n. Any updates on this? Is this working on Mongo 3?\n. ",
    "macobo": "Would it be possible to give the whole log output of running mosql (including the command). There might be some info there about what is going wrong since I haven't seen this before.\n. Oh, it seems like you're using an old version of mosql that relied on mongoriver to also be an older version.\n\nUpdate your mosql gem to be 0.4.0 and everything should start working.\n\nLet me know if that doesn't help.\n. Yeah, not sure why rdoc is yelling at you, but everything seems OK.\n\nGlad you got it working!\n. Would it be possible to give the whole log output of running mosql (including the command). There might be some info there about what is going wrong since I haven't seen this before.\n. Oh, it seems like you're using an old version of mosql that relied on mongoriver to also be an older version.\n\nUpdate your mosql gem to be 0.4.0 and everything should start working.\n\nLet me know if that doesn't help.\n. Yeah, not sure why rdoc is yelling at you, but everything seems OK.\n\nGlad you got it working!\n. ",
    "LenChang": "## the command\n\nmosql -c collections.yaml --mongo mongodb://xx.xxx.xxx.xx --sql postgres://xx.xxx.xxx.xx/name?password=1111 -vvv\n\n## the whole log\n\nD, [2014-10-07T06:14:06.640896 #7478] DEBUG -- : (0.000319s) SET standard_conforming_strings = ON\nD, [2014-10-07T06:14:06.643818 #7478] DEBUG -- : (0.000237s) SET client_min_messages = 'WARNING'\nD, [2014-10-07T06:14:06.644043 #7478] DEBUG -- : (0.000129s) SET DateStyle = 'ISO'\nD, [2014-10-07T06:14:06.645777 #7478] DEBUG -- : (0.001230s) SELECT NULL AS \"nil\" FROM \"mosql_tailers\" LIMIT 1\nD, [2014-10-07T06:14:06.656736 #7478] DEBUG -- : (0.000554s) SELECT (\"timestamp\") FROM \"mosql_tailers\" WHERE (\"service\" = 'xxxxxReplSet') LIMIT 1\n/usr/lib64/ruby/gems/1.8/gems/mongoriver-0.4.3/lib/mongoriver/abstract_persistent_tailer.rb:82:in `read_state': read_state unimplemented! (RuntimeError)\n    from /usr/lib64/ruby/gems/1.8/gems/mongoriver-0.4.3/lib/mongoriver/abstract_persistent_tailer.rb:95:in`read_position'\n    from /usr/lib64/ruby/gems/1.8/gems/mongoriver-0.4.3/lib/mongoriver/abstract_persistent_tailer.rb:25:in `tail'\n    from /usr/lib64/ruby/gems/1.8/gems/mongoriver-0.4.3/lib/mongoriver/tailer.rb:156:in`tail_from'\n    from /usr/lib64/ruby/gems/1.8/gems/mosql-0.3.2/lib/mosql/streamer.rb:167:in `optail'\n    from /usr/lib64/ruby/gems/1.8/gems/mosql-0.3.2/lib/mosql/cli.rb:165:in`run'\n    from /usr/lib64/ruby/gems/1.8/gems/mosql-0.3.2/lib/mosql/cli.rb:16:in `run'\n    from /usr/lib64/ruby/gems/1.8/gems/mosql-0.3.2/bin/mosql:5\n    from /usr/bin/mosql:23:in`load'\n    from /usr/bin/mosql:23\n. thanks for you help!!\n. when i updated mosql. The log print some ERROR messages\n\nInstalling RDoc documentation for mongoriver-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nInstalling ri documentation for mongoriver-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nERROR:  While generating documentation for mongoriver-0.4.0\n... MESSAGE:   Unhandled special: Special: type=33, text=\"implement\"\n... RDOC args: --ri --op /usr/lib64/ruby/gems/1.8/doc/mongoriver-0.4.0/ri --quiet lib --title mongoriver-0.4.0 Documentation\n(continuing with the rest of the installation)\nInstalling RDoc documentation for mosql-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nInstalling ri documentation for mosql-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nDone installing documentation for mongoriver, mosql after 8 seconds\nInstalling RDoc documentation for mongoriver-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nInstalling ri documentation for mongoriver-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nERROR:  While generating documentation for mongoriver-0.4.0\n... MESSAGE:   Unhandled special: Special: type=33, text=\"implement\"\n... RDOC args: --ri --op /usr/lib64/ruby/gems/1.8/doc/mongoriver-0.4.0/ri --quiet lib --title mongoriver-0.4.0 Documentation\n(continuing with the rest of the installation)\nInstalling RDoc documentation for mosql-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nInstalling ri documentation for mosql-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\n\nso it's correct ??\n. By the way. the latest version of MoSQL is working!!! it's a great product for our team, thanks a lot!! \n. ## the command\n\nmosql -c collections.yaml --mongo mongodb://xx.xxx.xxx.xx --sql postgres://xx.xxx.xxx.xx/name?password=1111 -vvv\n\n## the whole log\n\nD, [2014-10-07T06:14:06.640896 #7478] DEBUG -- : (0.000319s) SET standard_conforming_strings = ON\nD, [2014-10-07T06:14:06.643818 #7478] DEBUG -- : (0.000237s) SET client_min_messages = 'WARNING'\nD, [2014-10-07T06:14:06.644043 #7478] DEBUG -- : (0.000129s) SET DateStyle = 'ISO'\nD, [2014-10-07T06:14:06.645777 #7478] DEBUG -- : (0.001230s) SELECT NULL AS \"nil\" FROM \"mosql_tailers\" LIMIT 1\nD, [2014-10-07T06:14:06.656736 #7478] DEBUG -- : (0.000554s) SELECT (\"timestamp\") FROM \"mosql_tailers\" WHERE (\"service\" = 'xxxxxReplSet') LIMIT 1\n/usr/lib64/ruby/gems/1.8/gems/mongoriver-0.4.3/lib/mongoriver/abstract_persistent_tailer.rb:82:in `read_state': read_state unimplemented! (RuntimeError)\n    from /usr/lib64/ruby/gems/1.8/gems/mongoriver-0.4.3/lib/mongoriver/abstract_persistent_tailer.rb:95:in`read_position'\n    from /usr/lib64/ruby/gems/1.8/gems/mongoriver-0.4.3/lib/mongoriver/abstract_persistent_tailer.rb:25:in `tail'\n    from /usr/lib64/ruby/gems/1.8/gems/mongoriver-0.4.3/lib/mongoriver/tailer.rb:156:in`tail_from'\n    from /usr/lib64/ruby/gems/1.8/gems/mosql-0.3.2/lib/mosql/streamer.rb:167:in `optail'\n    from /usr/lib64/ruby/gems/1.8/gems/mosql-0.3.2/lib/mosql/cli.rb:165:in`run'\n    from /usr/lib64/ruby/gems/1.8/gems/mosql-0.3.2/lib/mosql/cli.rb:16:in `run'\n    from /usr/lib64/ruby/gems/1.8/gems/mosql-0.3.2/bin/mosql:5\n    from /usr/bin/mosql:23:in`load'\n    from /usr/bin/mosql:23\n. thanks for you help!!\n. when i updated mosql. The log print some ERROR messages\n\nInstalling RDoc documentation for mongoriver-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nInstalling ri documentation for mongoriver-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nERROR:  While generating documentation for mongoriver-0.4.0\n... MESSAGE:   Unhandled special: Special: type=33, text=\"implement\"\n... RDOC args: --ri --op /usr/lib64/ruby/gems/1.8/doc/mongoriver-0.4.0/ri --quiet lib --title mongoriver-0.4.0 Documentation\n(continuing with the rest of the installation)\nInstalling RDoc documentation for mosql-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nInstalling ri documentation for mosql-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nDone installing documentation for mongoriver, mosql after 8 seconds\nInstalling RDoc documentation for mongoriver-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nInstalling ri documentation for mongoriver-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nERROR:  While generating documentation for mongoriver-0.4.0\n... MESSAGE:   Unhandled special: Special: type=33, text=\"implement\"\n... RDOC args: --ri --op /usr/lib64/ruby/gems/1.8/doc/mongoriver-0.4.0/ri --quiet lib --title mongoriver-0.4.0 Documentation\n(continuing with the rest of the installation)\nInstalling RDoc documentation for mosql-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\nInstalling ri documentation for mosql-0.4.0\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:280: warning: conflicting chdir during another chdir block\n/usr/lib/ruby/1.8/rdoc/rdoc.rb:287: warning: conflicting chdir during another chdir block\n\nso it's correct ??\n. By the way. the latest version of MoSQL is working!!! it's a great product for our team, thanks a lot!! \n. ",
    "glasser": "I mean, I added it myself and I have no claim to understand how gems works these days :)\n. I mean, I added it myself and I have no claim to understand how gems works these days :)\n. ",
    "tomeara": "Great! I just made the change to the README.\n. Great! I just made the change to the README.\n. ",
    "sbailliez": "Thanks, will give it a shot this week end and let you know !\n. Thanks, will give it a shot this week end and let you know !\n. ",
    "mark-roggenkamp-snapav": "No failover or similar that I've found thus far but I'll keep looking. I'll drop a monit config in to keep it going.\n\nI'm pulling from two different RS's and only one has experienced the issue.\n\nThe docs say \"By default, the server will automatically close the cursor after 10 minutes of inactivity or if client has exhausted the cursor.\" It's a pretty busy RS so I can't imagine inactivity coming into play under normal circumstances.\n\nI'll keep digging, Thanks.\n. I think this is maybe the result of it getting behind and eventually hitting the bounds of the oplog oldest entry.\n\nI'm going to close this. I'll re-open if I find anything indicating something code related.\n. In our case it was because mosql was unable to process and store the data fast enough so it slowly falls behind. Once it's trying to process data older than the oplog has available you get this error I believe. One option might be to increase the oplog size if it's some temporary high traffic condition that could be recovered from after the storm is over. Other than that I imagine it's mostly about scaling up the mosql server and/or postgres. The only way to scale mosql out I think would be to split up each collection's processing into a seperate mosql process. There are no options for parallelizing the processing otherwise I don't believe thought I'd love for someone maintaining the project to verify.\n. My pleasure, thank you for creating and maintaining the project.\n\nMark\n\nFrom: Nelson Elhage <notifications@github.com<mailto:notifications@github.com>>\nReply-To: stripe/mosql <reply@reply.github.com<mailto:reply@reply.github.com>>\nDate: Thursday, January 1, 2015 6:47 AM\nTo: stripe/mosql <mosql@noreply.github.com<mailto:mosql@noreply.github.com>>\nCc: Mark Roggenkamp <mark.roggenkamp@snapav.com<mailto:mark.roggenkamp@snapav.com>>\nSubject: Re: [mosql] Fixed bug when using a renamed _id field and an update with replace (#85)\n\nThanks!\n\n## \n\nReply to this email directly or view it on GitHubhttps://github.com/stripe/mosql/pull/85#issuecomment-68485009.\n. No failover or similar that I've found thus far but I'll keep looking. I'll drop a monit config in to keep it going.\n\nI'm pulling from two different RS's and only one has experienced the issue.\n\nThe docs say \"By default, the server will automatically close the cursor after 10 minutes of inactivity or if client has exhausted the cursor.\" It's a pretty busy RS so I can't imagine inactivity coming into play under normal circumstances.\n\nI'll keep digging, Thanks.\n. I think this is maybe the result of it getting behind and eventually hitting the bounds of the oplog oldest entry.\n\nI'm going to close this. I'll re-open if I find anything indicating something code related.\n. In our case it was because mosql was unable to process and store the data fast enough so it slowly falls behind. Once it's trying to process data older than the oplog has available you get this error I believe. One option might be to increase the oplog size if it's some temporary high traffic condition that could be recovered from after the storm is over. Other than that I imagine it's mostly about scaling up the mosql server and/or postgres. The only way to scale mosql out I think would be to split up each collection's processing into a seperate mosql process. There are no options for parallelizing the processing otherwise I don't believe thought I'd love for someone maintaining the project to verify.\n. My pleasure, thank you for creating and maintaining the project.\n\nMark\n\nFrom: Nelson Elhage <notifications@github.com<mailto:notifications@github.com>>\nReply-To: stripe/mosql <reply@reply.github.com<mailto:reply@reply.github.com>>\nDate: Thursday, January 1, 2015 6:47 AM\nTo: stripe/mosql <mosql@noreply.github.com<mailto:mosql@noreply.github.com>>\nCc: Mark Roggenkamp <mark.roggenkamp@snapav.com<mailto:mark.roggenkamp@snapav.com>>\nSubject: Re: [mosql] Fixed bug when using a renamed _id field and an update with replace (#85)\n\nThanks!\n\n## \n\nReply to this email directly or view it on GitHubhttps://github.com/stripe/mosql/pull/85#issuecomment-68485009.\n. ",
    "ghost": "@nelhage I did that. Stupid of me to assume everything else would be a string. Sorry about that. Also added a test for the same\n. I changed the test. I realized I was testing the wrong stuff originally.\n\nWhat am I expected to test? The method transform_primitive. In case of malformed ASCII (or anyother format for that matter), we need to force encode to UTF-8 (This was indeed the case in my case and there apparently isn't a better way to handle this)\n. @nelhage I did that. Stupid of me to assume everything else would be a string. Sorry about that. Also added a test for the same\n. I changed the test. I realized I was testing the wrong stuff originally.\n\nWhat am I expected to test? The method transform_primitive. In case of malformed ASCII (or anyother format for that matter), we need to force encode to UTF-8 (This was indeed the case in my case and there apparently isn't a better way to handle this)\n. ",
    "loganfuller": "Querying the data would be the same as querying any SQL database and doesn't need the MoSQL daemon. I recommend PGAdmin as a GUI, otherwise you can just use the psql command line tool.\n. Querying the data would be the same as querying any SQL database and doesn't need the MoSQL daemon. I recommend PGAdmin as a GUI, otherwise you can just use the psql command line tool.\n. ",
    "luizkowalski": "No, I mean, I want to send all writes to mongodb and some reads to pgsql\nI think this is not a mosql problem, so I'm closing this\n. No, I mean, I want to send all writes to mongodb and some reads to pgsql\nI think this is not a mosql problem, so I'm closing this\n. ",
    "arnists": "https://github.com/JamesCropcho/variety has some such capabilities.\n. Did you test this?\n. https://github.com/JamesCropcho/variety has some such capabilities.\n. Did you test this?\n. ",
    "benjaminaschultz": "Yep! That works for me now. \n. Yep! That works for me now. \n. ",
    "dcu": "any update on this one?\n. I just found the --unsafe option. I'll try again.\n. any update on this one?\n. I just found the --unsafe option. I'll try again.\n. ",
    "Winslett": "I had the same issue.  I just monkey patched it to remove the invalid k,v from the obj.  I replaced the `mosql` binary with the following, which I call `monkey-patched-mosql`.  Then, I run the ETL process from the following code, which modifies the `MoSQL::Schema.transform` method.  It could be cleaned up by using a `super`.\n\nThe ETL errors from my data were caused by binary values and larger than expected BSON documents.\n\n```\n#!/usr/bin/env ruby\n\nrequire 'mosql/cli'\n\nmodule MoSQL\n  class Schema\n    def transform(ns, obj, schema=nil, depth = 0)\n      schema ||= find_ns!(ns)\n\n      original = obj\n\n      # Do a deep clone, because we're potentially going to be\n      # mutating embedded objects.\n      obj = BSON.deserialize(BSON.serialize(obj))\n\n      row = []\n      schema[:columns].each do |col|\n\n        source = col[:source]\n        type = col[:type]\n\n        if source.start_with?(\"$\")\n          v = fetch_special_source(obj, source, original)\n        else\n          v = fetch_and_delete_dotted(obj, source)\n          case v\n          when Hash\n            v = JSON.dump(Hash[v.map { |k,v| [k, transform_primitive(v)] }])\n          when Array\n            v = v.map { |it| transform_primitive(it) }\n            if col[:array_type]\n              v = Sequel.pg_array(v, col[:array_type])\n            else\n              v = JSON.dump(v)\n            end\n          else\n            v = transform_primitive(v, type)\n          end\n        end\n        row << v\n      end\n\n      if schema[:meta][:extra_props]\n        extra = sanitize(obj)\n        row << JSON.dump(extra)\n      end\n\n      log.debug { \"Transformed: #{row.inspect}\" }\n\n      row\n    rescue BSON::InvalidStringEncoding, BSON::InvalidDocument\n      obj = obj.select do |k,v|\n        begin\n          BSON.deserialize(BSON.serialize({\"#{k}\" => v}))\n          true\n        rescue BSON::InvalidStringEncoding, BSON::InvalidDocument\n          puts \"Pruning #{k} from the hash.\"\n          false\n        end\n      end\n\n      raise \"tried and failed to prune with #{[ns, obj, schema]}\" if depth > 2\n      transform(ns, obj, schema, depth + 1)\n    end\n  end\nend\n\n\nMoSQL::CLI.run(ARGV)\n```\n. I had the same issue.  I just monkey patched it to remove the invalid k,v from the obj.  I replaced the `mosql` binary with the following, which I call `monkey-patched-mosql`.  Then, I run the ETL process from the following code, which modifies the `MoSQL::Schema.transform` method.  It could be cleaned up by using a `super`.\n\nThe ETL errors from my data were caused by binary values and larger than expected BSON documents.\n\n```\n#!/usr/bin/env ruby\n\nrequire 'mosql/cli'\n\nmodule MoSQL\n  class Schema\n    def transform(ns, obj, schema=nil, depth = 0)\n      schema ||= find_ns!(ns)\n\n      original = obj\n\n      # Do a deep clone, because we're potentially going to be\n      # mutating embedded objects.\n      obj = BSON.deserialize(BSON.serialize(obj))\n\n      row = []\n      schema[:columns].each do |col|\n\n        source = col[:source]\n        type = col[:type]\n\n        if source.start_with?(\"$\")\n          v = fetch_special_source(obj, source, original)\n        else\n          v = fetch_and_delete_dotted(obj, source)\n          case v\n          when Hash\n            v = JSON.dump(Hash[v.map { |k,v| [k, transform_primitive(v)] }])\n          when Array\n            v = v.map { |it| transform_primitive(it) }\n            if col[:array_type]\n              v = Sequel.pg_array(v, col[:array_type])\n            else\n              v = JSON.dump(v)\n            end\n          else\n            v = transform_primitive(v, type)\n          end\n        end\n        row << v\n      end\n\n      if schema[:meta][:extra_props]\n        extra = sanitize(obj)\n        row << JSON.dump(extra)\n      end\n\n      log.debug { \"Transformed: #{row.inspect}\" }\n\n      row\n    rescue BSON::InvalidStringEncoding, BSON::InvalidDocument\n      obj = obj.select do |k,v|\n        begin\n          BSON.deserialize(BSON.serialize({\"#{k}\" => v}))\n          true\n        rescue BSON::InvalidStringEncoding, BSON::InvalidDocument\n          puts \"Pruning #{k} from the hash.\"\n          false\n        end\n      end\n\n      raise \"tried and failed to prune with #{[ns, obj, schema]}\" if depth > 2\n      transform(ns, obj, schema, depth + 1)\n    end\n  end\nend\n\n\nMoSQL::CLI.run(ARGV)\n```\n. ",
    "mattknapp": "Agreed, doesn't work in 3.0.  Error attached.\n![mosqlerror](https://cloud.githubusercontent.com/assets/463360/7484460/fad4beac-f345-11e4-9949-0ccd9bf6676e.JPG)\n. Agreed, doesn't work in 3.0.  Error attached.\n![mosqlerror](https://cloud.githubusercontent.com/assets/463360/7484460/fad4beac-f345-11e4-9949-0ccd9bf6676e.JPG)\n. ",
    "elementr1": "Thanks @mattknapp for screenshot\n. Thanks @mattknapp for screenshot\n. ",
    "manish2409": "Similar error in ubuntu:\n![screenshot from 2015-10-26 14 50 16](https://cloud.githubusercontent.com/assets/10112561/10725303/0fc67682-7bf1-11e5-8353-e2de5e523cf1.png)\n. Similar error in ubuntu:\n![screenshot from 2015-10-26 14 50 16](https://cloud.githubusercontent.com/assets/10112561/10725303/0fc67682-7bf1-11e5-8353-e2de5e523cf1.png)\n. ",
    "dmitrypol": "+1\n. +1\n. +1\n. +1\n. ",
    "imornar": "any update on this? looks like mongo 3.2 does not work as wel\r\n<img width=\"598\" alt=\"2016-11-26 at 14 25 32\" src=\"https://cloud.githubusercontent.com/assets/9463015/20640662/561e8fd0-b3e4-11e6-8d58-c22d31c2730c.png\">\r\n. any update on this? looks like mongo 3.2 does not work as wel\r\n<img width=\"598\" alt=\"2016-11-26 at 14 25 32\" src=\"https://cloud.githubusercontent.com/assets/9463015/20640662/561e8fd0-b3e4-11e6-8d58-c22d31c2730c.png\">\r\n. ",
    "fedot": "Probably should solve #73\n. Probably should solve #73\n. ",
    "agani": "Any chance that this version could be released to RubyGems.org?\n. Any chance that this version could be released to RubyGems.org?\n. ",
    "mayatskiy": "+1\n. +1\n. ",
    "tbatchelli": "I had this issue and it was caused by missing meta-table, e.g.:\n\n``` yaml\nstaging-bookings:\n  bookings:\n    :meta:\n      :table: bookings\n    :columns:\n      ...\n```\n\nthe documentation is not clear in that this is needed, or there is a bug somewhere, but adding this metadata made it all work.\n. I had this issue and it was caused by missing meta-table, e.g.:\n\n``` yaml\nstaging-bookings:\n  bookings:\n    :meta:\n      :table: bookings\n    :columns:\n      ...\n```\n\nthe documentation is not clear in that this is needed, or there is a bug somewhere, but adding this metadata made it all work.\n. ",
    "joanrodriguez": "This did the trick for me, documentation unclear indeed\n. This did the trick for me, documentation unclear indeed\n. ",
    "GMolini": "That did the trick for me too. Thanks!\n. That did the trick for me too. Thanks!\n. ",
    "allpratik": "Same Issue. Will the above stuff work? \n. @JosephZeng1121 AFA in my case, we ditched Tableau and used Pentaho through KTR files. Pentaho is not that visually appealing as of Tableau, but it is versatile enough and helped us to get our work done.\n. Same Issue. Will the above stuff work? \n. @JosephZeng1121 AFA in my case, we ditched Tableau and used Pentaho through KTR files. Pentaho is not that visually appealing as of Tableau, but it is versatile enough and helped us to get our work done.\n. ",
    "jney": "@arnists excuse me for the delay.\ni tested it and i have got a `[null]` instead of the content\n. @arnists excuse me for the delay.\ni tested it and i have got a `[null]` instead of the content\n. ",
    "JosephZeng1121": "hi, any thoughts on this issue. Our mongo structure is full of array. It's really hard to parse jason array in tableau\n. hi, any thoughts on this issue. Our mongo structure is full of array. It's really hard to parse jason array in tableau\n. ",
    "bitliner": "@JosephZeng1121 a way could be to update the code and add the support for arrays.\n\nI had a look at it, and I think what should be changed is after [this line](https://github.com/stripe/mosql/blob/master/lib/mosql/streamer.rb#L144)\nand at `schema.transform(...)` method.\n\nCan this help?\n. @JosephZeng1121 a way could be to update the code and add the support for arrays.\n\nI had a look at it, and I think what should be changed is after [this line](https://github.com/stripe/mosql/blob/master/lib/mosql/streamer.rb#L144)\nand at `schema.transform(...)` method.\n\nCan this help?\n. ",
    "dmitrypisanko": "I have the same problem. Any solution?\n. I have the same problem. Any solution?\n. ",
    "bbdurall": "I've figured out a solution, but my Ruby knowledge is very minimal, so I'll need some assistance in getting this patch into the proper form to add to the repo.\n\nFirst, install the deep clone gem, from the Unix shell:\n`gem install ruby_deep_clone`\n\nThen, comment out line 212 of schema.rb:\n`obj = BSON.deserialize(BSON.serialize(obj))`\n\nand underneath insert the following lines:\n`require \"deep_clone\"`\n`obj = DeepClone.clone(original)`\n\nI don't think this is the proper way to introduce an external dependency to the project, but as a quick hack it worked for me. It's quite slow on large objects (it took over 5 mins to process: ~2000 rows containing large PDFs), but it eventually inserts them into the postgres db.\n. I've verified, changing line 212 of schema.rb to:\n`obj = BSON.deserialize(BSON::BSON_CODER.serialize(obj, false, false, 16*1024*1024))`\nfixes the issue. I tried to push up a new branch for the fix, but I don't seem to have permission to do so. What's the best way to get this fix into the master branch?\n. I've figured out a solution, but my Ruby knowledge is very minimal, so I'll need some assistance in getting this patch into the proper form to add to the repo.\n\nFirst, install the deep clone gem, from the Unix shell:\n`gem install ruby_deep_clone`\n\nThen, comment out line 212 of schema.rb:\n`obj = BSON.deserialize(BSON.serialize(obj))`\n\nand underneath insert the following lines:\n`require \"deep_clone\"`\n`obj = DeepClone.clone(original)`\n\nI don't think this is the proper way to introduce an external dependency to the project, but as a quick hack it worked for me. It's quite slow on large objects (it took over 5 mins to process: ~2000 rows containing large PDFs), but it eventually inserts them into the postgres db.\n. I've verified, changing line 212 of schema.rb to:\n`obj = BSON.deserialize(BSON::BSON_CODER.serialize(obj, false, false, 16*1024*1024))`\nfixes the issue. I tried to push up a new branch for the fix, but I don't seem to have permission to do so. What's the best way to get this fix into the master branch?\n. ",
    "bikashmishra": "Thanks Nelson. We verified that we are reading off of primary with the current setup. \nSince 1.8.3 is successfully tested, would mosql have any issues if we changed the dependency and reverted to the older version? \n. Been off for a while, but have had a chance to dig deeper since. The versions being used are : `mongo-driver (1.12.3)`, `mosql (0.4.3)`, `MongoDB 3.0`\nI started off by testing the mongo-driver from a stand alone script. That worked fine i.e. read from secondary. \nNext I went deeper into the MoSQL code. Things are as expected until the function `initial_import` is called in `streamer.rb`. Before the line \n`collections = db.collections.select { |c| spec.key?(c.name) }`\nclient instance is secondary (checked config via `@mongo['admin'].command(:ismaster => 1)` ). However after this line is executed, the instance switches to primary. \n. Update on the issue. This is what we found out:\n\nThe `db.collections` command results in a `listCollections` call. This command is only allowed to be run on the primary. So the mongo driver routes this command to the primary. This happens in both old and the new drivers. However on `1.12.3` the driver continues to be struck to the primary and reads from there.\nFor the `1.12.x` drivers: if no `listCollections` or similar commands are executed on the connection before making a read query, the driver correctly reads from the secondary.\n\nSo it would seem to be a mongo driver issue. This issue has been fixed in the latest versions. So I see 2 ways to resolve this:\na) update mosql to use latest drivers\nb) use an older driver with mosql (unfortunately not an option if using Mongo3.0 as 1.12 is the earliest driver supporting 3.0)\n. @ptrikutam No workaround yet. We are living on the edge by forcing read from secondary (i.e. if secondary switches or goes down, we have to manually change things). \nRolling back is not an option if you are using Mongo 3.0 as the older drivers are not compatible\n. Thanks Nelson. We verified that we are reading off of primary with the current setup. \nSince 1.8.3 is successfully tested, would mosql have any issues if we changed the dependency and reverted to the older version? \n. Been off for a while, but have had a chance to dig deeper since. The versions being used are : `mongo-driver (1.12.3)`, `mosql (0.4.3)`, `MongoDB 3.0`\nI started off by testing the mongo-driver from a stand alone script. That worked fine i.e. read from secondary. \nNext I went deeper into the MoSQL code. Things are as expected until the function `initial_import` is called in `streamer.rb`. Before the line \n`collections = db.collections.select { |c| spec.key?(c.name) }`\nclient instance is secondary (checked config via `@mongo['admin'].command(:ismaster => 1)` ). However after this line is executed, the instance switches to primary. \n. Update on the issue. This is what we found out:\n\nThe `db.collections` command results in a `listCollections` call. This command is only allowed to be run on the primary. So the mongo driver routes this command to the primary. This happens in both old and the new drivers. However on `1.12.3` the driver continues to be struck to the primary and reads from there.\nFor the `1.12.x` drivers: if no `listCollections` or similar commands are executed on the connection before making a read query, the driver correctly reads from the secondary.\n\nSo it would seem to be a mongo driver issue. This issue has been fixed in the latest versions. So I see 2 ways to resolve this:\na) update mosql to use latest drivers\nb) use an older driver with mosql (unfortunately not an option if using Mongo3.0 as 1.12 is the earliest driver supporting 3.0)\n. @ptrikutam No workaround yet. We are living on the edge by forcing read from secondary (i.e. if secondary switches or goes down, we have to manually change things). \nRolling back is not an option if you are using Mongo 3.0 as the older drivers are not compatible\n. ",
    "ptrikutam": "@bikashmishra did you figure out a workaround? Or did you just end up rolling back? I've got a related issue with my project that employs the use of mosql.\n. Got it, thanks.\n. Oh, and let me just re-iterate -- thank you for all your great work with mosql! This is a fantastic project and very very useful. Thanks!\n. @bikashmishra did you figure out a workaround? Or did you just end up rolling back? I've got a related issue with my project that employs the use of mosql.\n. Got it, thanks.\n. Oh, and let me just re-iterate -- thank you for all your great work with mosql! This is a fantastic project and very very useful. Thanks!\n. ",
    "BradRuderman": "@sachmans  I know this probably isn't ideal but you can pull it out with a query, perhaps even creating a function:\n\nSELECT to_timestamp(('x' || lpad(substring(object_id,0,9), 8, '0'))::bit(32)::int)::timestamp ts\nFROM objects\n. @sachmans  I know this probably isn't ideal but you can pull it out with a query, perhaps even creating a function:\n\nSELECT to_timestamp(('x' || lpad(substring(object_id,0,9), 8, '0'))::bit(32)::int)::timestamp ts\nFROM objects\n. ",
    "andrewbaker00": "@mrfelton Use:\n`created_at: TIMESTAMP WITH TIMEZONE`\n\nworks for me.\n. @mrfelton Use:\n`created_at: TIMESTAMP WITH TIMEZONE`\n\nworks for me.\n. ",
    "aligajani": "@ShipraShalini  I have the same query, did you find a solution?\n. @ShipraShalini  I have the same query, did you find a solution?\n. ",
    "stewart-hector-whoknows": "There appears to be no support for Foreign Keys.  \n. There appears to be no support for Foreign Keys.  \n. ",
    "wujiang": "Any updates on this? Thanks.\n. Any updates on this? Thanks.\n. ",
    "houshuang": "Note that currently this only works if the array selector is the final element. Ideally something like supervisor[0].id should also work.\n. No, this only selects a specific value from an array, it does not import the whole array.. Note that currently this only works if the array selector is the final element. Ideally something like supervisor[0].id should also work.\n. No, this only selects a specific value from an array, it does not import the whole array.. ",
    "nelhage-stripe": "Hey @awreece,\r\n\r\nUnfortunately, Stripe hasn't used this project in some time and so it's been mostly unmaintained. If you happen to be interested in taking on ownership+maintenance, we'd potentially be willing to chat about that, but otherwise we probably won't be able to review this PR.. Hey @awreece,\r\n\r\nUnfortunately, Stripe hasn't used this project in some time and so it's been mostly unmaintained. If you happen to be interested in taking on ownership+maintenance, we'd potentially be willing to chat about that, but otherwise we probably won't be able to review this PR.. ",
    "awreece": "Thanks for the quick reply!\r\n\r\nGood to know. We're not the right long term maintainers of this tool -- we view it as a way to migrate off of mongodb and so we'd abandon maintenance shortly as well. \r\n\r\nFeel free to close the PR, but I'm also happy to just leave it open and visible in the main project -- maybe some future company will see it and want to pick up where we leave off.. Thanks for the quick reply!\r\n\r\nGood to know. We're not the right long term maintainers of this tool -- we view it as a way to migrate off of mongodb and so we'd abandon maintenance shortly as well. \r\n\r\nFeel free to close the PR, but I'm also happy to just leave it open and visible in the main project -- maybe some future company will see it and want to pick up where we leave off.. "
}