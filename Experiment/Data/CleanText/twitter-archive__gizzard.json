{
    "freels": "I forgot to add, this involves both a name server schema change, as well as new stuff in the shard manager service thrift interface.\n. The logic in sql shard makes this less clear, but materialize and purge are stubbed out in AbstractShardFactory to do nothing. I can fix it so we do not rely on purge to be a no-op in those cases and instead never call it for an AbstractShardFactory. The same logic should be applied to materialize in that case.\nFixed shardsForHostname to filter in the db.\n. purge and delete logic cleared up. one of these days, we should clean up the nameserver sql shard for real, but not this time, I guess.\n. True, what I really mean is: \"These things are ephemeral and do not have a backing data store.\" As opposed to the desirability of any specific behavior. Any good ideas for naming that?\n. hey, I like virtual. that makes sense.\n. whoa! the issue magically closed when I merged the branch into master. #skynet\n. looks decent!\n. Responses to Robey, complete with emoticons:\nconfig/test.scala#3 Yeah, no package objects in 2.7... this is a one-off in test configs to memoize things across tests. This may not be the best place for it :/\nCopyJob.scala#32 shady, yes :) If only we had a library to assist in extracting structured types from unstructured collections such as Map[String,Any]... ;)\nReset.scala#11 I think it will come back from the dead when we get to Groups :(\n. also if this review is annoying, we can move it to reviewboard\n. Yeah, we can expand it to separate traits. The entire time writing this I wanted to move to 2.8 so I could have package objects and be able to alias these types, and context bounds, etc. etc. \n. The reason I left them separate is that we don't want to have to serialize pages in the normal copy job, which is required by cross-cluster copies. We can look at cleanup, however, but the process is different between the two. Refactoring would involve extracting out paging logic and having cross-cluster and normal copies share that.\n. abandoning for now. will try again later.\n. +1 Looks good. NameServerState might be better as a simple case class like we discussed, but it's not really a big deal. Performance may be an issue with a large number of shards without filtering in SQL, but we can cross that bridge if/when we come to it.\n. shipit\n. yeah\n. merged. confirmed that gizzmo/busy stuff will work with extra field values\n. I lined the NOT NULLs up there.\n. merged\n. shipit!\n. It would be nice to unify this implementation and the ones above it. Perhaps have the Proxy singleton delegate to ProxyFactory?\n. also, it's a bit strange that you create the proxy factory, then pass the wrapped object, and then the proxy function. would it make sense to add the proxy function to the proxy factory constructor?\n. shipit, i'd say.\n. done.\n. I think this looks ok, but maybe we should get robey to glance at it.\n. I could have sworn that ed fixed this. Looks reasonable.\n. Let's just rename this back to copy (also, re-merge master)\n. reviewd in person w/ Ed\n. reviewed in person w/ ed\n. shipit\n. shipit\n. I forgot to add, this involves both a name server schema change, as well as new stuff in the shard manager service thrift interface.\n. The logic in sql shard makes this less clear, but materialize and purge are stubbed out in AbstractShardFactory to do nothing. I can fix it so we do not rely on purge to be a no-op in those cases and instead never call it for an AbstractShardFactory. The same logic should be applied to materialize in that case.\nFixed shardsForHostname to filter in the db.\n. purge and delete logic cleared up. one of these days, we should clean up the nameserver sql shard for real, but not this time, I guess.\n. True, what I really mean is: \"These things are ephemeral and do not have a backing data store.\" As opposed to the desirability of any specific behavior. Any good ideas for naming that?\n. hey, I like virtual. that makes sense.\n. whoa! the issue magically closed when I merged the branch into master. #skynet\n. looks decent!\n. Responses to Robey, complete with emoticons:\nconfig/test.scala#3 Yeah, no package objects in 2.7... this is a one-off in test configs to memoize things across tests. This may not be the best place for it :/\nCopyJob.scala#32 shady, yes :) If only we had a library to assist in extracting structured types from unstructured collections such as Map[String,Any]... ;)\nReset.scala#11 I think it will come back from the dead when we get to Groups :(\n. also if this review is annoying, we can move it to reviewboard\n. Yeah, we can expand it to separate traits. The entire time writing this I wanted to move to 2.8 so I could have package objects and be able to alias these types, and context bounds, etc. etc. \n. The reason I left them separate is that we don't want to have to serialize pages in the normal copy job, which is required by cross-cluster copies. We can look at cleanup, however, but the process is different between the two. Refactoring would involve extracting out paging logic and having cross-cluster and normal copies share that.\n. abandoning for now. will try again later.\n. +1 Looks good. NameServerState might be better as a simple case class like we discussed, but it's not really a big deal. Performance may be an issue with a large number of shards without filtering in SQL, but we can cross that bridge if/when we come to it.\n. shipit\n. yeah\n. merged. confirmed that gizzmo/busy stuff will work with extra field values\n. I lined the NOT NULLs up there.\n. merged\n. shipit!\n. It would be nice to unify this implementation and the ones above it. Perhaps have the Proxy singleton delegate to ProxyFactory?\n. also, it's a bit strange that you create the proxy factory, then pass the wrapped object, and then the proxy function. would it make sense to add the proxy function to the proxy factory constructor?\n. shipit, i'd say.\n. done.\n. I think this looks ok, but maybe we should get robey to glance at it.\n. I could have sworn that ed fixed this. Looks reasonable.\n. Let's just rename this back to copy (also, re-merge master)\n. reviewd in person w/ Ed\n. reviewed in person w/ ed\n. shipit\n. shipit\n. ",
    "robey": "in SqlShard#deleteShard: if a factory is an AbstractShardFactory, you call purge immediately. is that because any descendant of AbstractShardFactory should be auto-purged? if so, can you give it a name like AutoPurgeShardFactory or something?\nslightly worried that shardsForHostname might be slower if you fetch tens of thousands of shards and THEN filter by hostname on the client.\ncool to get rid of the Busy converter. :)\n. i think i'm just being confused by the word \"abstract\", which normally means a base class with some default implementation, but in this case i think what you really mean is \"class that doesn't want the two-phase delete feature\". if you renamed that class, it would be clearer.\n. hmm....\nSymbolicShardFactory? VirtualShardFactory? \n. okay, a lot more work done, but i think the patch is still pretty small:\n- refactored the exception unwrapping -- i think it's possibly even \"more correct\" now\n- enforced that any shard exception has the shard id in it, so we can trace problems whether there's a stack trace or not\n- support black-hole shards via exception, which were previously only implemented jank-style in flockdb\ni'll try this out on t-flock first but i think this is ready.\n. can you add the description above as a doc comment on the class?\nlooks good to me.\n. yay! +1\n. merged.\n. merged!\n. merged!\n. MAN i really wish i could comment inline.\nmeta-comment: sucks that the scariest part of this patch is the config stuff. it's a big chunk of the already-huge patch. in the future, it'd be nice to split this kind of thing into two smaller patches, since they're not really related.\n+1 aside from minor code style quibbles, below.\nconfig/test.scala#3 -- the way i handled this in configgy3 is to add a type alias to the package object so that importing config._ is enough. that may not be possible in scala 2.7 tho. :(\nGizzardServer.scala#17 -- might as well make this be an ostrich Service since it has start/shutdown/quiesce.\nJobScheduler.scala#24 -- agreed. mark as FIXME please.\nCopyJob.scala#32 -- hella shady. that is all. :)\nReplicatingJob.scala#44 -- nice!\nReset.scala#11 -- just erase the commented-out block.\nManagerService.scala#21 -- code style.\n. it bothers me a bit that copyAdapter is just an opaque (S, S, Option[Map], Int) => Option[Map]. being able to label the params as \"source\", \"cursor\", etc, would make it a lot less mysterious. but to do that you'd have to make it a full-fledged trait with a single method.\ndoes the GizzardServer now assume all jobs will be in json just because copy jobs are? if so, we'll have to clean that up for haplo if haplo comes out of cold storage.\n. on GizzardServer#31 i think you meant override def.\nShardCopyAdapter: shouldn't the pages be Seq[...]?\nlooks good otherwise. i didn't check the remote-copy code as much since i know that will get harsh testing.\n. +1\ncode style: NameserverState#41 is missing whitespace after the \"foreach\"\n. just import mutable, not both mutable and mutable.ListBuffer.\nspace on line 45, \"while (\"\nwon't this have the side effect of making old copy jobs fail? (they won't have a destination_shard that the copy job can parse.) i guess this changes the api too. i guess that's okay since we're bumping to 1.6 and all the servers will have to change anyway.\nline 49 is eeeeeevil! you know that will cause a reflection call, right? :) i guess it doesn't matter in this rarely-called code, but eeeeeeevil!\nlooks good aside from the 2 code style fixes.\n. the one with the cast-to-existential-type. :)\n. i think the synchronized on line 74 isn't necessary.\n. tab on SqlShard line 28.\n. +1 after tiny code style changes.\n. +1\n. cool! i didn't know about toMap.\n+1 except i'd appreciate fixing the extra-long line. i feel like we should be more solid about our code style.\n. it looks basically okay to me.\n. in SqlShard#deleteShard: if a factory is an AbstractShardFactory, you call purge immediately. is that because any descendant of AbstractShardFactory should be auto-purged? if so, can you give it a name like AutoPurgeShardFactory or something?\nslightly worried that shardsForHostname might be slower if you fetch tens of thousands of shards and THEN filter by hostname on the client.\ncool to get rid of the Busy converter. :)\n. i think i'm just being confused by the word \"abstract\", which normally means a base class with some default implementation, but in this case i think what you really mean is \"class that doesn't want the two-phase delete feature\". if you renamed that class, it would be clearer.\n. hmm....\nSymbolicShardFactory? VirtualShardFactory? \n. okay, a lot more work done, but i think the patch is still pretty small:\n- refactored the exception unwrapping -- i think it's possibly even \"more correct\" now\n- enforced that any shard exception has the shard id in it, so we can trace problems whether there's a stack trace or not\n- support black-hole shards via exception, which were previously only implemented jank-style in flockdb\ni'll try this out on t-flock first but i think this is ready.\n. can you add the description above as a doc comment on the class?\nlooks good to me.\n. yay! +1\n. merged.\n. merged!\n. merged!\n. MAN i really wish i could comment inline.\nmeta-comment: sucks that the scariest part of this patch is the config stuff. it's a big chunk of the already-huge patch. in the future, it'd be nice to split this kind of thing into two smaller patches, since they're not really related.\n+1 aside from minor code style quibbles, below.\nconfig/test.scala#3 -- the way i handled this in configgy3 is to add a type alias to the package object so that importing config._ is enough. that may not be possible in scala 2.7 tho. :(\nGizzardServer.scala#17 -- might as well make this be an ostrich Service since it has start/shutdown/quiesce.\nJobScheduler.scala#24 -- agreed. mark as FIXME please.\nCopyJob.scala#32 -- hella shady. that is all. :)\nReplicatingJob.scala#44 -- nice!\nReset.scala#11 -- just erase the commented-out block.\nManagerService.scala#21 -- code style.\n. it bothers me a bit that copyAdapter is just an opaque (S, S, Option[Map], Int) => Option[Map]. being able to label the params as \"source\", \"cursor\", etc, would make it a lot less mysterious. but to do that you'd have to make it a full-fledged trait with a single method.\ndoes the GizzardServer now assume all jobs will be in json just because copy jobs are? if so, we'll have to clean that up for haplo if haplo comes out of cold storage.\n. on GizzardServer#31 i think you meant override def.\nShardCopyAdapter: shouldn't the pages be Seq[...]?\nlooks good otherwise. i didn't check the remote-copy code as much since i know that will get harsh testing.\n. +1\ncode style: NameserverState#41 is missing whitespace after the \"foreach\"\n. just import mutable, not both mutable and mutable.ListBuffer.\nspace on line 45, \"while (\"\nwon't this have the side effect of making old copy jobs fail? (they won't have a destination_shard that the copy job can parse.) i guess this changes the api too. i guess that's okay since we're bumping to 1.6 and all the servers will have to change anyway.\nline 49 is eeeeeevil! you know that will cause a reflection call, right? :) i guess it doesn't matter in this rarely-called code, but eeeeeeevil!\nlooks good aside from the 2 code style fixes.\n. the one with the cast-to-existential-type. :)\n. i think the synchronized on line 74 isn't necessary.\n. tab on SqlShard line 28.\n. +1 after tiny code style changes.\n. +1\n. cool! i didn't know about toMap.\n+1 except i'd appreciate fixing the extra-long line. i feel like we should be more solid about our code style.\n. it looks basically okay to me.\n. ",
    "xeno-by": "Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. Thank you for your contribution! Twitter has decided to stop supporting Gizzard as an open source project. Sorry that your pull requests was not reviewed earlier.\nWe're now formally archiving this project but please feel free to fork and resurrect.. ",
    "eaceaser": "We should revisit ReplicatingShard.scala's exception handling while we're at it, because its kind of harebrained, which is partially my fault. i.e. I'm not sure if we should continue to unwrap ExecutionException there, as essentially we will have floating exceptions without a stack trace to tell where they came from....\nAlso, by getting rid of the stack traces for most ShardExceptions, that essentially loses the stacktrace which would indicate which method in a concrete shard that an exception was raised from, which is potentially useful information. \nThis seems like a good idea but may be too coarse? Should we instead tune our logs to not output stack traces when not necessary? I.e. have no stack traces in a human readable log, but have them in some kind of machine readable log format for more detailed analytics? I don't know if theres a right answer to this.\n. word\n. SHIP IT\n. ship\n. looks ok\n. looks ok\n. this looks good.\n. this looks really reasonable. i cant wait for the nameserver refactor too.\n. this generally looks good. \n. ship it\n. s h i p i t\n. We should revisit ReplicatingShard.scala's exception handling while we're at it, because its kind of harebrained, which is partially my fault. i.e. I'm not sure if we should continue to unwrap ExecutionException there, as essentially we will have floating exceptions without a stack trace to tell where they came from....\nAlso, by getting rid of the stack traces for most ShardExceptions, that essentially loses the stacktrace which would indicate which method in a concrete shard that an exception was raised from, which is potentially useful information. \nThis seems like a good idea but may be too coarse? Should we instead tune our logs to not output stack traces when not necessary? I.e. have no stack traces in a human readable log, but have them in some kind of machine readable log format for more detailed analytics? I don't know if theres a right answer to this.\n. word\n. SHIP IT\n. ship\n. looks ok\n. looks ok\n. this looks good.\n. this looks really reasonable. i cant wait for the nameserver refactor too.\n. this generally looks good. \n. ship it\n. s h i p i t\n. ",
    "fizx": "Do we need to make production and development configuration .scala files first?\n. Can we make CopyJob a special case of the CrossClusterCopyJob, with the JobRelay set to something simple?  I'd rather not have two copy jobs with separate code paths.\n. Reproduction of email for posterity:\nOn Wed, Dec 15, 2010 at 7:59 PM, Matt Freels freels@twitter.com wrote:\n\nCan we just add a couple of extra methods to dump links and shards? We already have list_forwardings, so this just adds redundancy. In working with the API, the slowness is a result of having to crawl the shard trees for links. \n\nTotally agree.  Great idea.\n\nEverything else can be pulled down with a few fast calls. Additionally, this doesn't have any way to pull a subset of the data, which is necessary for tflock at least since it has so many shards.\n\nI really want to avoid expanding scope here.  My new implementation of your suggestion above just exposes nameserver methods over thrift.  Would it be ok to have:\nlist_all_links()\nlist_all_links()\nlist_all_forwardings() # an alias of get_forwardings for symmetry\nwith plans for implementing something perhaps like:\nlist_links(1: offset LinkInfo, 2: limit int), etc at a time TBD later?\nYour suggestions are implemented in the new revision of the pull request (same url).\nKyle\n. Deprecated in favor of https://github.com/twitter/gizzard/pull/36\n. If you get the chance to laugh at or correct my style on NameserverState.scala, please do. \n. I added integration tests and merged with the current master\n. Closing and re-opening a new pull request.\n. Closing and re-opening a new pull request.\n. This is also wired into flockdb (branch: copy_split_thrift).\n. Robey: which line 49?\n. Ship it!\n. Code looks good, but there are some services with replication level > 2.  I think we should support N-ary repair jobs.\n. LGTM\n. Do we need to make production and development configuration .scala files first?\n. Can we make CopyJob a special case of the CrossClusterCopyJob, with the JobRelay set to something simple?  I'd rather not have two copy jobs with separate code paths.\n. Reproduction of email for posterity:\nOn Wed, Dec 15, 2010 at 7:59 PM, Matt Freels freels@twitter.com wrote:\n\nCan we just add a couple of extra methods to dump links and shards? We already have list_forwardings, so this just adds redundancy. In working with the API, the slowness is a result of having to crawl the shard trees for links. \n\nTotally agree.  Great idea.\n\nEverything else can be pulled down with a few fast calls. Additionally, this doesn't have any way to pull a subset of the data, which is necessary for tflock at least since it has so many shards.\n\nI really want to avoid expanding scope here.  My new implementation of your suggestion above just exposes nameserver methods over thrift.  Would it be ok to have:\nlist_all_links()\nlist_all_links()\nlist_all_forwardings() # an alias of get_forwardings for symmetry\nwith plans for implementing something perhaps like:\nlist_links(1: offset LinkInfo, 2: limit int), etc at a time TBD later?\nYour suggestions are implemented in the new revision of the pull request (same url).\nKyle\n. Deprecated in favor of https://github.com/twitter/gizzard/pull/36\n. If you get the chance to laugh at or correct my style on NameserverState.scala, please do. \n. I added integration tests and merged with the current master\n. Closing and re-opening a new pull request.\n. Closing and re-opening a new pull request.\n. This is also wired into flockdb (branch: copy_split_thrift).\n. Robey: which line 49?\n. Ship it!\n. Code looks good, but there are some services with replication level > 2.  I think we should support N-ary repair jobs.\n. LGTM\n. ",
    "joshbuddy": "yes please!\n. lgtm, shipit!\n. yes please!\n. lgtm, shipit!\n. ",
    "yswu": "looks good\n. looks good\n. ",
    "stuhood": "Adding at least 1 test that uses 3 shards would be awesome, but I'm ok with shipping this.\n. #shipit\n. Shipit.\n. Pending adding comments to that test, #shipit from me.\n. #shipit\n. Refreshed to execute transform operations directly. e0aa443 and 0e28edc are cherry picks from the ds-61 branch, which will consume these same TransformOperation objects.\n. #shipit\n. #shizipit\n. Thanks!\n. Adding at least 1 test that uses 3 shards would be awesome, but I'm ok with shipping this.\n. #shipit\n. Shipit.\n. Pending adding comments to that test, #shipit from me.\n. #shipit\n. Refreshed to execute transform operations directly. e0aa443 and 0e28edc are cherry picks from the ds-61 branch, which will consume these same TransformOperation objects.\n. #shipit\n. #shizipit\n. Thanks!\n. ",
    "jcorwin": "Superseded by https://github.com/twitter/gizzard/pull/82\n. #shipit\nLooks good overall. As we discussed, I think we should have automatic server-side logging of all operations into a designated log.\n. Superseded by https://github.com/twitter/gizzard/pull/82\n. #shipit\nLooks good overall. As we discussed, I think we should have automatic server-side logging of all operations into a designated log.\n. ",
    "hyungoo": "Thanks for the reviews. I changed the nulls to options and added some comments. Let me know how it looks.\n. thanks!\n. Thanks for reviewing Stu! :)\n. Thanks for the reviews. I changed the nulls to options and added some comments. Let me know how it looks.\n. thanks!\n. Thanks for reviewing Stu! :)\n. ",
    "rvpgithub": "Just one comment, otherwise LGTM.\n. #ShipIt\n. Just one comment, otherwise LGTM.\n. #ShipIt\n. ",
    "wangmeng99": "good call. changed.\n. good call. changed.\n. ",
    "alanliang": "SHIP IT\n. SHIP IT\n. ",
    "elimisteve": "typo fix. Wow, the irony.\n. typo fix. Wow, the irony.\n. "
}