{
    "magiconair": "Transparent TCP proxy support was on my radar at some point but so far I didn't have the use case for it. I want to enhance a couple of other things first so this is not high on my prio list ATM.\nLeaving this open as enhancement\n. @rvm2015 What is your use case?\n. @rvm2015 Fabio is an FE-BE router which routes incoming traffic to different BE services based on information in the protocol (i.e. host and/or path from the HTTP request). I get the SNI use case for SSL traffic since I can get the host information and use that for routing information but how would I route an arbitrary incoming TCP stream to a BE service that can handle it? Based on ports? Which protocols are you using where you need raw TCP traffic?\n. I think I have a couple of use cases for TCP routing now and the proxy itself is pretty simple. I just need to update the config language and dynamic listener support. First version may not support SNI though but I'm still looking into this.\n. @JonathanBennett The TCP proxy itself is not difficult and I think I have that ready somewhere. Main issue is how to configure the listeners and that they need to start and shutdown automatically which is different from the statically configured HTTP listeners. That also isn't hard but $dayjob and $kids take most of my energy right now. \nI'm going to focus on the API for the multiple registries since this is a small change but has lots of potential. Then I'll work on the config change which will enable the strip prefix and weight parameter and also offer the tcp syntax. Then it isn't far from the dynamic listeners. I have some code lying around for that as well but it probably won't merge anymore.\nIf you want to help you could pick up one of these things. Let me know if you are interested and we can try to figure something out.\n. @mterron It is on my list but I am working on other things right now. What is your use case?\n. @InAnimaTe yes :)\n. @InAnimaTe, @mterron, @jefferai et. al. here you go.\nThis patch implements TCP passthrough support for TLS connections and uses the SNI header for routing providing end-to-end encryption with dynamic routing!\nThis is working but needs testing. Please hit on it and find out where it breaks. I need to think a bit more about timeouts and edge cases. \nHere is how you can test this:\n./fabio -proxy.addr ':9999;proto=tcp+sni'\nThis will configure a listener on port 9999 which will capture the first package, parse the TLS ClientHello and extract the server name from it. Any error or no TLS will close the connection immediately. Traffic is then routed to the service which is registered with prefix <serverName>/. Note the trailing slash which is something I need to fix later. \nThe demo/server now has an option to provide a TLS certificate as follows:\n./server -proto http -prefix <serverName>/ -cert cert.pem -key key.pem\nYou'll get some TLS handshake error lines from consul performing health checks. That's fine for now. I'll suppress them later.\nThen run openssl as follows:\n/usr/local/opt/openssl/bin/openssl s_client -tls1_2 -connect 127.0.0.1:9999 -servername <serverName>\nand test with\nGET /health HTTP/1.0\nYou should get\n```\nHTTP/1.0 200 OK\nDate: Sun, 21 Aug 2016 09:18:49 GMT\nContent-Length: 3\nContent-Type: text/plain; charset=utf-8\nOK\nclosed\n```\nOr with curl (make sure you use the homebrew version on OSX):\n```\n/usr/local/opt/curl/bin/curl -k -i https://:5555/health\nHTTP/2 200\ncontent-type: text/plain; charset=utf-8\ncontent-length: 3\ndate: Sun, 21 Aug 2016 09:22:34 GMT\nOK\n```\n. @InAnimaTe any update?\n. Right now you have to compile it yourself. \n. Rebased on master\n. I'm considering merging this patch onto master and marking it as experimental since I still think some timeouts are missing. But that would give people a better opportunity to test this. Then I could tag a 1.3 release as well. Opinions?\n. Done. Merged to master and released v1.3. Documentation is here:\nhttps://github.com/eBay/fabio/wiki/Features#tcpsni-proxy-support\nPlease test and let me know where it breaks. \n. @nugend yes, the tcp+sni proxy is essentially a vanilla TCP proxy with some goodies. So building the proxy isn't the problem. I need to add code to create listeners dynamically. It'll come but I'm working on something else right now.\n. @nugend What's your use case?\n. @holtwilkins I'll have a look\n. @holtwilkins the PROXY protocol is only on the HTTP listener right now which will break the TCP+SNI listener as it will not be able to parse the ClientHello. I'll add that and put a patch on a branch. Could you test that?\n. @holtwilkins I think that should do it. I'm working on making the TCP+SNI proxy more testable anyway and I'll add that to the test cases. However, that change isn't ready yet. \n. @holtwilkins In case you didn't see the issue-1-add-proxyproto-to-tcp-sni branch: https://github.com/eBay/fabio/tree/issue-1-add-proxyproto-to-tcp-sni\n. @holtwilkins Excellent. Then I'll merge it and make sure that I have a test for it in the next update.\n. Merged this to master and referred to it as #177 \n. @nugend I'm tracking the generic tcp proxy support separately in #179 but I'll keep this one open since it has the comprehensive discussion of use cases in a single place.\n. Generic TCP proxying support is now in the release-branch-1.4 Please check #179 for more info on how to use it. I'd really appreciate any feedback.. Right now I don't have plans to support URL rewriting since I would also have to support rewriting URLs in responses and I'm not convinced that URL rewriting is necessary in general. Services should announce the routes they serve and have handlers to service them. Fabio is fast even with lots of routes per host to the number of routes don't matter. \nYou probably don't have two services responding to /api directly but to some sub path like /api/foo and /api/bar.\nHaving two different services announce the same route (or parts thereof) allows you to migrate from one implementatin to another. Traffic shaping allows you to do this gradually. This is how we migrate Java services to Go or split up services which have become too large into smaller ones.\n. Can you explain how many paths you would have to register and for how many services? I'm also interested in why you have an /OrderService prefix that is not used by the services. What is the use case for that? \nTo give you an idea: we generally register one or two routes per service.\n. I have decided not to support this since fabio favors convention over configuration. If a service handles traffic on /foo/bar then it should announce that route and have a handler for it. By expecting the router to strip part of the URL the service behaves differently when run with or without the router which makes the router an essential part of the configuration. That is against the idea of fabio which is supposed to be stateless and zero-conf.\n. Yep. Good catch. \n. I'll try that myself first before I merge.\n. I've produced an official image from a scratch container also with the integrated ca-certificates.crt file to provide proper SSL support but I still need to test that with a valid cert. Could you try whether this image works for you since I'm not using Docker? If it is OK then I'll push my change.\ndocker run -d -p 9999:9999 -p 9998:9998 -v $PWD/fabio.properties:/fabio.properties magiconair/fabio\n. I've moved the config file from /fabio.properties to /etc/fabio/fabio.properties so that you can store the configuration and one or more SSL certs in a single directory and just mount that instead of the individual files. I've updated the magiconair/fabio:latest and magiconair/fabio:1.0.3 docker images accordingly. \nDocker support is now official and I'm closing this pull request (not merging)\n. Duh\n. Thank you :) Already done. https://github.com/hashicorp/consul/pull/1319\n. Nope. It is merged but not live yet.\n. If your service does not provide a green health check, or is in maintenance mode or the node it is running on is in maintenance mode then fabio ignores it.\n. You are right that fabio only looks for changes in the health check. However, this isn't a health check for your service since the ServiceID field is empty. The serfHealth is for the consul agent process AFAIK. \nThere are a couple of ways on how to provide the health check. You can either have consul call an HTTP endpoint in your service (e.g. /health) which needs to return 200 OK if it is ok. Or you can call consul yourself and tell it that your service is still alive. Check the consul documetation on health checks.\nfabio-example lines 76-80 register the service health check as an HTTP check (consul will call fabio-example) and lines 46-49 configure the health check handler which just returns OK with status code 200.\nI will update the README to make this more clear.\n. Done. Thank you :)\nhttps://github.com/eBay/fabio/blob/master/README.md#quickstart\n. @jrusiecki thank you. If you don't register a health check then I don't know whether your registered instance is actually alive. All I know is that the consul agent where the app was registered on is alive. This isn't enough to build a routing table. \n. @jrusiecki If you do not register your own health check then /v1/health/service/mywebbackend?passing will return 200 OK even if there is no service at all. \nYou can try this by registering a service in consul without a health check:\n```\ncurl -XPOST -d '{\"ID\":\"foo1\",\"Name\":\"foo\",\"Port\":1234,\"Tags\":[\"urlprefix-/foo\"]}' http://localhost:8500/v1/agent/service/register\ncurl -i 'http://127.0.0.1:8500/v1/health/service/foo?passing'\nHTTP/1.1 200 OK\nContent-Type: application/json\nX-Consul-Index: 5\nX-Consul-Knownleader: true\nX-Consul-Lastcontact: 0\nDate: Sat, 22 Oct 2016 07:29:04 GMT\nContent-Length: 498\n[{\"Node\":{\"Node\":\"xxx\",\"Address\":\"127.0.0.1\",\"TaggedAddresses\":{\"wan\":\"127.0.0.1\"},\"CreateIndex\":3,\"ModifyIndex\":5},\"Service\":{\"ID\":\"foo1\",\"Service\":\"foo\",\"Tags\":[\"urlprefix-/foo\"],\"Address\":\"\",\"Port\":1234,\"EnableTagOverride\":false,\"CreateIndex\":5,\"ModifyIndex\":5},\"Checks\":[{\"Node\":\"xxx\",\"CheckID\":\"serfHealth\",\"Name\":\"Serf Health Status\",\"Status\":\"passing\",\"Notes\":\"\",\"Output\":\"Agent alive and reachable\",\"ServiceID\":\"\",\"ServiceName\":\"\",\"CreateIndex\":3,\"ModifyIndex\":3}]}]\n```\nIf fabio would not require an actual service health check for foo it would try to route traffic to this endpoint.\n. The branch contains the first attempt. Probably need to dig a bit more.\n. Added support for transparent websocket proxying. Works for my simple client but could use some real-world testing.\n. I've added experimental websocket support. See documentation https://github.com/eBay/fabio#websockets.\nI call it experimental since I don't have an in-house use case to test this beyond a simple test client which is included in the code base. Please test and file issues if something is broken.\n. The only caveat I can think of is that this is no longer an application level gateway. With this code you don't know whether you're actually forwarding websocket data since you're forwarding whatever goes over the wire. The current implementation will forward the messages only having properly terminated the WS messages. That has benefits and downsides. Need to think about it. \n. Tested the code above and it works. I'll do the error checking slightly different to make sure you don't end up with a dangling TCP connection. The benefits are one dependency less and independence of the websocket protocol version. The downside is that after the the initial handshake a malicious client can throw whatever traffic at the server. Opinions?\n. In the process I've learned about Request.Write \ud83d\ude03\n. I've added the raw websocket handler for testing but left it disabled. See proxy/proxy.go on how to enable it. \nI'm still leaning towards the filtered WS handler unless there is a performance and/or compatibility issue. \n. Looks like there are some compatibility issues with the WS proxy that uses the library. I'll make the raw WS proxy the default in 1.0.6.\n. Merged raw websocket proxy to master as the default.\n. Duh. Thanks :)\n. Additional backends is something I'm considering but I want to do some other things first. \n. I'm going to take a first step in this direction by refactoring the code to hide the consul specific logic behind an interface. This will make supporting additional backends simpler. \nHowever, my main concern is whether these systems (e.g. Marathon) allow services to publish their routes in the registry (e.g. zookeeper or etcd) in an atomic way. The purpose of fabio is to be stateless and build the routing table automatically and not just to use a different storage mechanism.\n. Support for Google Compute Platform is in the works by @emicklei\n. @composer22 How does fabio get notified of changes in the swarm setup? Polling? Other than that it looks interesting.\n. Fabio performing health checks does not sound like a direction I want to go. Fabio is only a client of a service registry. Something else needs to maintain the state.\n. fabio does not perform a status check with consul. It literally waits until consul has determined that the state of the ensemble it manages has changed. Either through a change in health checks or by adding or removing services or instances. fabio only reacts to these changes in the registry and that is by intention.\nHow would fabio determine how to perform the health check? Remember that fabio is supposed to be zero-conf, i.e. it rebuilds its routing table from data that the services provide. A health check does not need to be on /. It doesn't need to be HTTP. HTTP 200 OK may not be sufficient. What about TCP services, e.g. MySQL? Do you want to add health checks for all these things into fabio?\nConsul is more than a glorified nagios or zookeeper. It eliminates the backend load balancer by providing service discovery between the services and to deliver that you need health checks since otherwise you don't know which services are up.\nThis means that fabio can work with the state of the services without being involved in how the state is determined. \nI'm not saying this isn't useful but I don't think it is as simple as you describe it.\n. The backend registry is abstracted away behind an interface so adding health checks to fabio is not the problem. The problem is how does fabio know what to check for? The main idea behind fabio is to reverse the configuration management. Instead of maintaining an LB configuration in addition to your service configuration the services \"tell\" fabio which routes they accept and which instances are available to serve them. I don't know enough (read squat) about the Docker API at this moment to determine what can work for this setup but I'll have a look.\n. I've spent some time on adding to additional backends for fabio: static and file which replace the special case for the proxy.routes parameter. They also serve as an example on how to add another registry backend. For example, making the file backend watch the config file and push a change would be a simple change. Adding a redis, mongodb, mysql backend would also be simple. Consider this a starting ground for more complex registry backends like the one for the Docker API. The work on this issue also triggered the fix for issue #43 to override all runtime vars from the config file via environment variables which should make the Docker use case simpler. Whoever is interested in additional backends please have a look at this change. \n. Issue #46 describes an idea on how to externalize the API that fabio uses to talk to a registry. I'm not yet sold on the idea since I'm not a firm believer in the plugin extension model but it may be worth considering. \nI will close this ticket since the latest change provides now three backends and an internal API on how to implement them. Also, the configuration is more explicit on how to select a backend. \nPlease create separate tickets for each backend you would like to see support for so that we can trace progress there. I'll open one for the Google compute platform from @emicklei.\n. Thx\n. HTTP/2 support comes with Go 1.6 and should (TM) work more or less out of the box but I haven't tried that yet. I'm assuming that you want to reduce the number of websocket connections with this or am I missing something?\n. Thanks. You like anything in particular?\nRegarding roadmap: No, not really. I've got some things on my mind which I'll work on but I'm happy to listen to what others would like to see. It won't be everything to everybody but I'm curious what could fit. If you've got an idea please open a ticket. \nIf you want to try HTTP/2 you could compile fabio with Go tip and if I understand the HTTP/2 support for 1.6 correctly then that is all you have to do. \nHTTP/2 gives you a more efficient channel between the server and the client so that you don't suffer from TCP slow start and connection management but it doesn't change the routing problem. That's one thing I've really tried to address with fabio: getting rid of the load balancer configuration and provide enough flexibility in the services to allow for fast iterations and simple refactoring. \nSo forgive me if I ask again: Where is for you the connection between web sockets, microservices, client upgrades and http/2?\n. I'm going to close this ticket for now for lack of feedback. Please re-open if you need more information or create specific issues for a feature you want/need to support a concrete use case.\n. Did you override consul.addr to point to a consul agent? By default fabio assumes that there is a consul agent running on the same machine which most likely isn't the case for the docker container.\n. Yes, smart idea. Thx\n. All dependencies are in the repository and live under the _third_party directory. You don't have to install any libraries. Did you just clone the repo into some directory or did you use go get?\nPlease try this:\n```\nmake sure GOPATH is set\ngo get github.com/eBay/fabio\ncd $GOPATH/src/gihtubn.com/eBay/fabio/demo/server\ngo build\n./server ...\ncd $GOPATH/src/gihtubn.com/eBay/fabio/demo/wsclient\ngo build\n./wsclient ...\n```\nI'll think of the shebang trick but I'm no so thrilled about the executable bit on the .go files.\n. Can you please post the fabio log? It should note the change in the health and service status and print the generated routing table.\n. Also, since you're using docker could you describe how you are running the individual applications right now? What is running where and can they all talk to each other on the addresses and ports you've configured ...\n. @strarsis The logs are more helpful at this point\n. I think the confusion comes from the registrator. You don't need the registrator for registering either fabio or the demo service. They are both capable of registering themself. Try removing the registrator from your setup and just run the binaries. That should work.\n. I think this a duplicate of issue #23. fabio does not flush the last route. I'll release a 1.0.7 to fix this properly.\n. a :bug: I'll fix it\n. That is not necessary since go get will run go install which will build a binary for fabio and store it in $GOPATH/bin Only, if you want a fully static binary on OSX then you need the Makefile since it sets the -tags netgo for the linker. On Linux this is the default. You can check that with ldd fabio and should get no dependencies. \nAlso, go build has the same effect. The only thing the Makefile does really is to ensure the git hash is stored in the main.version variable.\nI've written the Makefile mainly for myself for the release process but gaging from this ticket it may confuse more than it helps. Maybe I should put it in the build directory\n. The binary will only be in an unexpected folder if you set your GOPATH per project. Also, then go get will put the binary into $GOPATH/bin whereas the source lives in $GOPATH/src/github.com/eBay/fabio. I'm going to close this as wontfix since this is the documented behavior of Go apps.\n. I'll add at least basic auth and client certificate authentication to the next release. This requires to switch the UI to HTTPS for which I'll provide a builtin certificate which can be overwritten. \n. This is unfortunately not going to happen for 1.0.9 but as a temp workaround I suggest to have the UI bind to localhost\n. #258 is a first step in that direction. Managing the certificates via the config file is a stop gap until the entire configuration moves to the backend to have a full cluster configuration. Also, hashicorp has Vault which is built for managing secrets. Both things are on my list of things to work on.\n. Interesting use case. Didn't take that into account. Yes, with the current setup you'd just update the configuration and restart which would interrupt existing connections. How often do the certificates change in your setup?\n. No, there is no 'reload' command since by design this shouldn't be necessary... We'll find a solution.\n. Fabio will support different backends soon. The one for Google Compute Platform is in the works so there is definitely a tradeoff in using either Vault or some other configuration mechanism. Storing the certificates in the backend is simple at least for consul. \nHow would you store the certificates in consul? As PEM files without password or as P12 files with password? If you want password protection how does fabio get the password?\n. Yes, that is correct if I use Vault for storing secrets. If you don't want that additional dependency then you get that unlock problem.\n. Storing the passphrase next to the cert isn't any benefit at all. You might as well just use the unlocked files. So the question then becomes how secure is your backend registry or the servers you're deploying to. I'm leaning towards this:\n- fetch PEM files from URL (registry or otherwise). Retrieval via HTTPS would be nice but that's not how consul is usually deployed. least secure option. For dev or in trusted networks.\n- fetch PKCS#12 files from URL (registry or otherwise) and provide passphrase during fabio startup either via properties file or on the command line. All certs would then require the same passphrase. Since someone who has access to the machine could also dump the memory to get to the passphrase properties should be good enough.\n- use Vault which most likely also requires a key for fabio to unlock the vault\n. ok, so I can add multiple certificates to a single listener which are either statically or dynamically configured. This isn't really a code issue but a config issue. I need to think about this a bit more how I express this in the configuration. Once I've figured that out the implementation should be straightforward.\n. @strarsis I've started working on this.\n. Current plan is to support a configurable certificate store per listener. A certificate store is either a fixed set of certificates, a directory with a list of certificates which is reloaded whenever something changes,  consul which is again updated when something changes and vault. Since consul already offers a secured HTTP API lets first get this working and then see whether another API is necessary.\n. @strarsis fabio will support multiple different certificate sources like file, path, http, consul and vault. You can test this in the cert-source branch. SNI is supported. \nSince they all have different provisioning mechanisms I find it difficult to come up with an API that will work in all cases. Also, some of the tools already provide HTTP APIs which can be used for provisioning. So I chose not to provide an API in fabio but to make the integration with different types of certificate sources easy.\nfile   - path to a cert/key file like in the current configuration\npath   - path to a directory with cert/key files, refreshed periodically (provision with puppet, salt, ansible)\nhttp   - url to a directory with cert/key files, refreshed periodically (provision with puppet, git, ...)\nconsul - url to KV store, refreshed automatically \nvault  - url to secret list, refreshed periodically\n. Yes\nFrank Schr\u00f6der\n\nOn 2. Apr 2017, at 01:39, Roman Naumenko notifications@github.com wrote:\n@magiconair Are you considering letsencrypt integration?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @tino Nobody has been picking this up yet and if you are working on a PR then this would be very welcome. You can integrate that directly with fabio. @pschultz has done preliminary work for these types of cert stores in #135/#315. He has provided a proof-of-concept implementation for ACME which you can see here: https://gist.github.com/pschultz/80a13aa3488f4e9afa1e440bea3c3d6e\n\nThis still needs config, wiring and testing but it is a start. I suggest you open an issue for that and submit a PR. This would also prevent morphing this ticket into something else.. @tino There should be no need to add a separate tag name for that. The only thing that is required is to fetch or generate a certificate on the fly. Keep in mind that fabio can be run in clusters so you need a place to store the certs, e.g. consul.. Won't happen for 1.0.9 unfortunately.\n. I've started working on that to support #27 and #70 and #79 - which will support multiple dynamic certificates per listener - and will probably settle for \nproxy.addr = [host]:port;opt=arg;opt=arg,[host]:port;opt=arg;...\nThis allows me to specify an arbitrary number of options without going crazy on parameter parsing. It is a similar approach as with the GODEBUG env variable. \n. Patch fixed the issue.\n. I still think your GOPATH is wrong. First set your GOPATH then use go get to download the code. If you want to use git clone then you need to create the entire path yourself.\nmkdir ~/gopath\nexport GOPATH=~/gopath\ngo get -u github.com/eBay/fabio # will fetch source, compile it and put binary into $GOPATH/bin\nwith git clone\nmkdir -p ~/gopath/src/github.com/eBay\ngit clone github.com/eBay/fabio ~/gopath/src/github.com/eBay\nexport GOPATH=~/gopath\ngo install github.com/eBay/fabio # will compile binary into $GOPATH/bin\nThat's why you should use go get unless you know what you're doing.\nBut the main problem is actually go1.3.3. From https://github.com/eBay/fabio#installation:\nTo install fabio run (you need Go 1.4 or higher)\natomic.Value was introduced with Go 1.4. https://golang.org/doc/go1.4\n. However, use Go 1.5 since it has a more predictable garbage collector. Get the binaries for Linux from here: https://golang.org/dl/\n. To complete this:\nmkdir ~/gopath\nexport GOPATH=~/gopath\ngo get -u github.com/eBay/fabio\ncd $GOPATH/src/github.com/eBay/fabio\ngit checkout v1.0.7\ngo install # will build v1.0.7 in $GOPATH/bin\nI've also started putting pre-compiled binaries in the releases section: https://github.com/eBay/fabio/releases\n. HTTP/2 will not be included with Go 1.5 since Go 1.5 has no HTTP/2 support. I'll have a look\n. Just tested this with go1.6rc2. I need to make one small modification to enable HTTP/2 support but then it seems to work out of the box. \n. Sticky sessions are a pain in general and I'm not a fan. In general, they show that your application needs refactoring since it wasn't designed to run in an HA setup and you are trying to push this problem into the load balancer instead of solving it in the application. Is this an actual problem you have or a hypothetical? Can you explain your use case a bit better?\nSession draining is automatic behavior in fabio. Once a route is removed fabio won't send new requests to that target. Existing connections remain active but do not time out. Again, this is an application problem. You need to have proper timeouts there. Generally, when a service is removed from consul you are shutting it down and handling graceful shutdown there. Fabio cannot know what an acceptable timeout is for each service. If the service is not coming down by itself then something will kill it. In either case the TCP connection is reset and fabio terminates that connection. \n. If a single instance can handle the load then you can make sure that one and only one instance is running at any given time. Maybe try to acquire a consul or mysql lock during startup and if you can't then shutdown again.\n. Is this with 1.0.7?\n. which consul version are you using?\n. Ah, haven't tested with consul 0.6.0 yet. Can you post the output of curl localhost:8500/v1/health/state/any?pretty and let me know which services should be omitted?\n. or if you don't want to do that send me a private gist\n. If I look at this code https://github.com/eBay/fabio/blob/master/registry/consul/passing.go I can't see how it would be included with a status of \"critical\". Once the service went critical can you check the fabio logs whether the route for this service is actually there. (reminder to dump raw routing table via api...) Could you post the routing table as well, please?\n. fabio goes through the health checks for all instances and not per service. If a health check is for a service (ServiceID != \"\") and has a Status != passing then it is omitted. That's why I don't understand how this can happen. However, I've just spotted something in your health checks. Your ServiceID fields are not unique, i.e. you use local-overview-swap for both instances. Try making them unique, e.g. local-overview-swap-node001-8080. I don't think the way you're doing it is correct but I need to check to be sure.  The ServiceName can stay at local-overview-swap\n. I'll keep that in mind but for now I'd consider this a config issue and close it. Let me know if there are other issues.\n. If I look at http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html section 3.2.3 I find this:\n\n3.2.3 URI Comparison\nWhen comparing two URIs to decide if they match or not, a client SHOULD use a case-sensitive octet-by-octet comparison of the entire URIs, with these exceptions:\n- A port that is empty or not given is equivalent to the default\n    port for that URI-reference;\n    - Comparisons of host names MUST be case-insensitive;\n    - Comparisons of scheme names MUST be case-insensitive;\n    - An empty abs_path is equivalent to an abs_path of \"/\".\nCharacters other than those in the \"reserved\" and \"unsafe\" sets (see RFC 2396 [42]) are equivalent to their \"\"%\" HEX HEX\" encoding.\n. You can just register both routes but my suggestion is to fix your app.\n. let me know how this works out.\n. @herbrandson I think adding another matcher in https://github.com/fabiolb/fabio/blob/master/route/matcher.go and adding a config option in https://github.com/fabiolb/fabio/blob/master/config/load.go#L250-L252 should do the trick. \n\nFeel free to send a PR.. Merged #553 . I was kind of waiting for someone to open that request. I need to add it. \n. Could you check this version out and see if it works? Best is you build it with make build to get a binary with a proper version number. If that works for you then I'll roll it into the next release.\n. Here you go. pls test.\n. I can think of two ways:\n1. You can start up with a property file and set the proxy.routes value with a static route. That will disable the dynamic routing update from consul and use only those routes\n2. You can set the routes in consul as manual override and remove them afterwards.\nI was actually planning to remove the proxy.routes feature since I don't see a use-case for it since the whole point of fabio is to not have such an option. \nThe more important question for me is why you would want to do this in the first place? If you have microservices and they register in consul during startup or test then fabio will pick their routes up. Maybe you just need to mask your tests with a consul registration/deregistration wrapper to achieve this since this is how your services would act when run in production.\n. I'm going to close this question for lack of feedback for now. Please re-open if you need more information or create a ticket with a specific feature request for a concrete use case.\nThx\n. Can you give some examples for cases 2 and 4?\nFor the circuit breaker one could argue that if the service is throwing lots of errors it isn't healthy anymore and should indicate that via the health check to consul which would then automatically remove it from fabios' routing table. Then the health check would actually say \"service healthy\" instead of just \"service up\".\n. Could you please explain briefly in your own words what behavior you think fabio should have and which problems this would solve instead of sending me links and make me figure it out? I took a glance a the articles and I am not sure they apply to fabio at all but I may be missing something here.\n. OK, I get the circuit breaker argument in that fabio can actively drop connections to reduce the load on the backend servers. The question is how fabio determines that a service has an error. 400, 503, 1s timeout, 5s timeout, all of the above? So you would have to configure that for every route since fabio itself isn't configured. \nFallback would be a pretty service unavailable page instead of a dropped connection, correct? (for example)\nRetries are dangerous since fabio cannot know which calls are idempotent and hence safe to retry. You can make the assumption that GET requests are OK to retry but that may not necessarily true for all of your routes. So this would also be something to either be disabled by default or to be enabled on a per-rotue basis.\nThe isolation that you are referring to and the link you've sent stems partly from the fact that Netflix is using java and tomcat as their underlying services. Fabio is written in Go and does not suffer from the thread-per-request model. It can handle a lot more concurrent requests if the underlying operating system can. In our setup the backend services will bail way before fabio does. Also, you don't run just a single fabio server if only for the sake of high-availability. The way our teams run fabio is to deploy it to each of their servers which handle incoming http requests which scales the number of concurrent requests you can handle horizontally.\nAs for the \"bulk call\" feature I'm assuming that you want fabio to trigger multiple service calls from a single inbound request. This is a matter of API design and should not be put into the API gateway IMO. If I understand the linked Netflix article correctly then that is exactly what they are doing. \nHowever, most of these issues are only really relevant if you are starting to run services at scale. May I ask what the scale of the services (in req/sec) is you want to use fabio for?\n. OK, I'm going to close this issue since it is about whether fabio could support certain features and I think we've explored this sufficiently. If not then feel free to re-open. \nOtherwise, please create specific tickets for features (one per feature) that you want/need to support a concrete use case. \n. No, and I don't have plans for it right now since this wouldn't be a simple addition to the existing proxies. I've used that approach in previous setup but that required iptables configuration. What's your use case?\n. So far our experience has been that fabio does not add much to the latency. It isn't zero copy but if you deploy it to each of your frontend nodes it might just work. \n. yeah, but if you deploy fabio onto the content servers directly you also don't have that problem. Then it only depends how you distribute your incoming requests. That may be possible with DNS RR but I haven't done that kind of stuff for a while.\n. And thanks for the compliments :)\n. I'm going to close this since I'm not sure at the moment how fabio would implement DSR other than manipulating the kernel routing table with iptables. Deploying fabio on the content servers comes close enough with the current architecture. Supporting zero copy proxying support may help but is platform dependent and the following thread makes it at least questionable whether there is sufficient benefit.\nhttps://groups.google.com/d/topic/golang-nuts/Fa6AM71CsEg/discussion\nPlease feel free to re-open when you have more concrete throughput requirements where fabio is the bottleneck.\n. I like the idea but would prefer a different syntax. Especially with the idea of the tcp proxy I'm thinking about using a URL for this:\np-[scheme]://[host][:port][/path][?opt=val[&opt=val]...]\nExamples:\np-tcp://host:port\np-http://host:port/hello\np-https://host/hello\np-ws:///hello\np-/hello (equivalent to p-http:///hello)\np-/hello?weight=0.8\n...\nurlprefix-host/path then translates to p-http://host/path and p-https://host/path\n. @nanoz and @tiago-msilva I thought that this would be more work but the route add command already supports a weight option which does the right thing. The only thing missing was to expose this via the urlprefix- tag. You can now add a weight=.x option to specify a weight on a target, e.g. urlprefix-:3306 weight=0.2 proto=tcp\nSorry, @nanoz I did not want to take the opportunity for contributing away from you but was done pretty much when I looked at the the place which I wanted to point out to you. \nTo illustrate this I've added a new detail option for the log.routes.format which you can use to dump the routing table in a different format.\n./fabio -log.routes.format detail\n2017/06/19 11:51:14 [INFO] Updated config to\n+-- host=:3306\n|   +-- path=\n|       |-- addr=127.0.0.1:5001 weight 0.20 slots 2000/10000\n|       +-- addr=127.0.0.1:5000 weight 0.80 slots 8000/10000\n+-- host=:3307\n    +-- path=\n        +-- addr=127.0.0.1:5002 weight 1.00 slots 1/1\nWould you mind testing this? This is on the issue-42-weigh-targets branch.. try this:\nshell\nmkdir ~/go\ngo get -u github.com/fabiolb/fabio\ncd ~/go/src/github.com/fabiolb/fabio\ngit checkout issue-42-weigh-targets\ngo install\nls ~/go/bin/fabio. >= go1.8.3. @tiago-msilva Thanks for testing this. I try to do a release a month. It has been three weeks since the last release. I'll have a look what else is on the list and could shoot for a 1.5.1 next week.. merged to master. @jarrettj you need to register service instances with different weights. If they all have the same then this won't have an effect. . The command line flags you've found belong to the demo server which I use for demonstration and testing. The only command line flags in fabio are in https://github.com/eBay/fabio/blob/master/main.go#L30-L32\nWhich values would you like to configure via environment variables?\n. runtime.gomaxprocs can already be configured via GOMAXPROCS. I'll have a look on how to come up with a generic method for configuring these values via environment variables.\n. Thanks. I'll have a look. AFAIK, viper is using my properties library to load them :) \nUsually, I try not to add additional libraries for simple tasks and would prefer to have a better idea about what is being submitted before the pull request arrives. Could you explain how the property values are overridden with the ENV vars and what changes are required?\nMight be a good idea to add a Contributions section to the README and finally figure out the Contributors Agreement feature in github...\nSince I'm also the author of the properties library I was thinking about adding a generic ENV var overrides to the lib later. General idea is to normalize the name of the keys by replacing dots with underscores and have a configurable prefix, e.g. routes.proxy could be overwritten with FABIO_routes_proxy\n. Your change looks simple enough so I'm curious what the delta is. One comment about the vendoring approach. Please use party for now to copy the dependency into the _third_party directory using import path rewriting. This also works with Go 1.4 and 1.5 out of the box. I'll move to the new vendoring scheme once 1.6 is out. Also, keep the commit message for the vendored in library in the same format as the others, e.g. Vendoring in version xxx of github.com/spf13/viper since this is how I keep track of the versions.\n. I've decided to implement it myself since I was working on a refactoring for issue #12 which required somewhat more control over the configuration. Adding the env var support was a trivial change there and I've pulled it into a separate commit. If this works then I'll merge it. Please have a look.\nAll config parameters can be configured via env vars by replacing the dots with underscores. So metrics.target=stdout becomes metrics_target=stdout ./fabio. Env vars take precedence over the config file but both can be specified. Since it then becomes difficult to determine the actual runtime configuration I've decided to log the final runtime configuration during startup.\n. merged. closing.\n. You're probably right. I'll have a look and add it next week if it's missing. \nFrank Schr\u00f6der\n\nOn 1. Apr 2017, at 21:33, Armando Magalh\u00e3es notifications@github.com wrote:\nIs this defined anywhere in the docs? I couldn't find it there\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. This is a duplicate of issue #2 for which I've decided not to support this. See the reasoning in the closing comment. \n. I would counter that argument that it is better to add another handler to the service than splitting up your configuration across services and load balancer. I know you can do and lots of other load balancers allow you to do it but in our own setup we have had enough additional complexity with this that this actually led to the development of fabio in the first place.\n. I agree on the host but not the path but that doesn't really matter. Please start this discussion with a suggestion on how this should work from the configuration perspective so that we can decide what the best approach is. No promises since I'd like to see how you want to solve that first and also want to think a bit about edge cases.\n. Why should this work only for a single, global prefix? Do you want to strip some of the path or all of it, for some of the services or for all of them, the same prefix for all services? \n\nhttp://foo.com/service/user/index.html -> http://usersvc/index.html\nor\nhttp://foo.com/service/user/index.html -> http://usersvc/user/index.html\nCan you explain a bit more what makes it so difficult to change the apps? Are these services you don't control or can't change or are they just too many?\n. Does http://serviceserver/user/index.html need to know that /serviceprefix was stripped from the original request? (i.e. do we need to inject a header?)\nI could extend the route add command with a strip <prefix> option which would allow to control this per route/target. The only question is how to encode that in the service registration. \nIn issue #42 I've outlined a more flexible notation for the tags, i.e. p-host/path?key=val&key=val... which would provide the mechanism to add a strip=/serviceprefix option. \n. @SathishN Actually, that is the kind of use case that made me decide not to support stripping in the first place. If you have two different API endpoints then you shouldn't name them both /client since they are different. The full names for these endpoints are /v1/client and /v2/client. Your integration tests should be different since they need to talk to the compatible endpoint and by moving the version routing in the load balancer - any load balancer - you make your application routing dependent on that configuration. \nOne motivation for fabio was to gently nudge people in the direction of not doing that since your code most likely doesn't care whether it has a handler for /client or /v1/client. However, the difference is that if you do that then you can just publish that route, i.e. your service says \"I accept /v1/client\" and fabio can pick that up and send you that traffic without any extra magic. It is also more explicit if you want to test the service by itself.\n. @msabramo have you tried? The main message is that the app should work the same with or without a load balancer in front of it. \n. I get it. I'll add it but need the refactor of #111 to be able to express this. \n. The change in the branch allows to specify a strip=/foo option to be added to strip /foo from outgoing requests. The incoming request is still matched on /foo/bar. The syntax is\n```\nconsul tags\nurlprefix-/foo/bar strip=/foo\nconfig lang\nroute add svc /foo/bar http://1.2.3.4:5555 opts \"strip=/foo\"\n``. @jovandeginste yes, e.g.urlprefix-/foo/bar strip=/fooThe example I gave is wrong since theopts \"key=val key=val ...\"syntax is used for theroute add ... ` statement. I'll fix it.. What kind of side effects do you mean? The original request URI is not added as a request header. If you want that you could just not strip the prefix?\nI'm also wondering whether the strip=/path is the best way to express this. If you have an opinion on this then please let me know. . @jovandeginste consul kv is not an option since there are not transactions between registering a service and modifying the kv store. What if the one works and the other doesn't? When a service dies entries would have to be cleaned up from the kv store by a separate process. That's a design decision I've made early on. I agree the tag prefixes are a workaround since there is no room to have meta-data in the service registration.. Our services don't use the registrator and are self-contained. That means they register and de-register themself and therefore something else would need to cleanup afterwards. KV and service registrations will get out of sync especially in large scale installations. It is only a matter of time.. Merged to master. Matching happens on the longest path. So what you're looking for is for your service to either announce / or /foo/v1.0. You can have more specific routes later. If you have another service that handles /foo/v1.0/user then that will take precendence.\nYou can also match on foo.example.com/ or foo.example.com/foo/v1.0/\n. If you provide SERVICE_TAGS=urlprefix-foo.com/ for every instance then you get the desired behavior. \nThat assumes that every such instance can handle every request for foo.com. As long as that is true you're good. \n. Also, the best is just to try it and provide a specific example of what doesn't work as expected.\n. I think I get it. Try this: curl -v -H 'Host: lb-hello-world.example.com' 'http://lb-hello-world.example.com:9999/v1.0/hello. fabio uses the Host header to match the request with the routing table. Since your request has a Host header of lb-hello-world.example.com:9999 and not lb-hello-world.example.com there is no match. Hence the 404. \n. Also, see this: https://github.com/eBay/fabio#debugging\n. And https://github.com/eBay/fabio#request-tracing might come in handy, too.\n. No problem. I'm glad we found it. What did you not see in the docs? The links I've posted are referenced from https://github.com/eBay/fabio#documentation albeit at the bottom of the page.\nThe way you probably deploy fabio is either behind a load balancer which terminates SSL and distributes traffic to multiple fabio instances or you run fabio on port 80/443 on the internet directly. In both cases the Host header will be set correctly since reverse proxies shouldn't mess with the headers from the incoming request.\nMaybe this helps: https://github.com/eBay/fabio#deployment\nLet me know what else is unclear.\n. To be honest your setup sounds rather complex and I think you're missing the point of the design goal of fabio a bit. The way we are running fabio is as follows:\nInternet -> LB (term SSL) -> N x fabio -> services\nThe LB has only a single rule: route all traffic to fabio. \nThe main motivation for developing fabio is simplification: to eliminate the complex routing and rewriting logic that we had to replicate across the LBs and that we had to keep in sync with the services we've deployed. So the LB config became essentially a vital part of the service configuration without the service would not function but it was managed differently (puppet vs. git)\nSince fabio builds the routing configuration on-the-fly from an up-to-date service registry the inbound LB becomes a simple SSL terminator or you run fabio directly on the internet as your front-facing service and get rid of the LB altogether.\nAlso, depending on your traffic you may not need several fabio clusters. We're running comfortably 5-10k req/sec over a group of fabio servers and that can be scaled up easily by just adding more instances. So instead of having two groups of 3 fabios you might be fine with just one group of 3 and add more instances as you see fit.  \nLast but not least we use fabio only for the inbound routing, i.e. directing internet traffic to the services but not for communication among the services themselves since you use consul with service registration and service discovery for this. \n. We were also not in a greenfield environment and slowly moved towards service discovery and registration. fabio was born out of that environment.\nRegarding performance tuning please be my guest but if you look at the proxy/proxy.go code you'll find that the core of the actual reverse proxying is simply using the net/http/httputil.ReverseProxy class without any changes. We don't see noticeable latency. \nMy initial tests which motivated me to go further showed that a single Dell M620 blade was able to handle 18.000 req/sec with a 2.3k byte response over the network w/o problems. Go 1.6 might push this further. So before you spend time optimizing I'd first see how far you can push it and I am curious how far you do. Please share. May I ask what the load is that you have to handle?\nI'm going to close this issue then since I think your main questions have been answered.\n. @composer22 Also, if you would like to be listed in the README as one of the sites which is using fabio (maybe with a req/sec load number) then just send a pull request.\n. I can do that but it misses the point of having a service registry. :)\nfabio is conceptually not dependent on consul. The current implementation is and that is a difference. Your services should depend on a service registry for service registration, discovery and centralized health checks. fabio is a mere consumer of that data to simplify your inbound http traffic routing. \nIf I wanted to do what you propose then I could stop using consul altogether and provide some generic mysql backend. Also, it would make your services dependent on the fabio API and I would have to replicate the behavior of the APIs that already exist. You couldn't use existing libraries for service registries.\nMy suggestion is to embrace consul instead of fighting it. If you want to use a different service registry backend then that is fine but then we/you/I would have to spend some time implementing it. A friend of mine has implemented one for the Google Compute Platform. It wasn't that difficult. \n. Please feel free to comment to keep the discussion going since I am curious why you are suggesting this in the first place but unless I am missing something really fundamental this is not going to happen. \n. The current registry is implemented via an interface which could be externalized. https://github.com/eBay/fabio/blob/master/registry/backend.go contains the interface definition. \nOK, I get it - finally :) I'll think about it. Would make integration simpler but deployment more complex since you now have to build at least two components. Fabio and the registry adapter. But I could provide the current consul implementation as a sample implementation. \n. Just as a note for myself:\nThe idea is to decouple the registry backend from fabio itself via an API to make development of registry backends simpler since they don't need to be integrated into fabio itself. \nAlthough, it makes the development of the registry backend simpler fabio no longer is the one binary that you run and it just works. This will increase operational complexity and create another source for potential errors. The benefit of this approach largely depends on how difficult it is to add support for additional registries. I think the idea has merit but there is a hidden cost in additional integration testing. Then users will have to debug both fabio and the registry plugin to determine where the cause of a misbehavior is. \nSo I'm not sold yet since lowering the operational complexity is one of the key goals of fabio.\n. I am not worried about the implementation since this is rather simple but what this introduces is a dependency problem. It means that this now becomes a binding contract which I must support forever since I have no control over the registries. If I want to support an additional functionality or refactor the API I have to support both APIs and you will have registry plugins which work with either the one or the other API. I also have no leverage of forcing registry providers to upgrade nor do I have any way for users to upgrade. \nI would essentially give up the ability to quickly fix bugs or provide workarounds in implementations and so would the users. \n. I'm also wondering how many of these service registries are out there. I didn't focus on adding support for them since this wasn't my initial use case but with the internal api and the GCP proof of concept this has shown not to be too difficult. \n. I'd also like to make one comment on your language: I didn't force anything down anybodies throat. We use consul internally and that's what I've developed fabio for. I'm open for suggestions but I want the discussion to be solution oriented. \n. This could indeed be a better approach than an API since otherwise people will write plugins in all kinds of languages which then pulls in those dependencies. \n. The go-plugin approach has the appeal of keeping the deployment simple since you would have to deploy at most two binaries: fabio and the registry plugin. However, testing the plugin would require a fabio instance or a mock that correctly implements that RPC interface. Ideally, the plugins would live as sub-directories in the fabio repo so that you don't have to assemble a working distribution. I'm just wondering how that is any different from the approach that I am taking right now with the only exception that not all dependencies are compiled in. \nWhile the API approach provides great flexibility it will make integration testing, bugfixing and triaging, especially deployment more complex since people will write plugins in other languages which then pull in those dependencies. Stability of fabio then becomes directly related to the stability of that plugin with little option for me to fix it.\nSo right now I'm leaning towards getting a couple more registry backends into fabio first to see that a) the interface is sufficient and b) integration cost into fabio is high enough to justify a split. If the Docker API is an important part for you why don't you take the plunge of providing an implementation for it?\nAdding a generic registry plugin which just externalizes the API is something that can be achieved at any time. Turning that clock back seems a bit harder to do.\n. There is one additional aspect which is the KV store. Right now this is used for manual overrides and I've got issue #27 which asks for storing certificates there. Storing this information so that it is available for all fabio instances requires consensus so that they all have the same view of the routing table. In the current setup consul solves that. Once consul becomes optional I would have to provide another alternative for these features. etcd and zookeeper provide alternatives but what about the Docker API or the various DNS services you mentioned? This probably requires decoupling the service discovery from the KV management in the API but still leaves me with the question on how to actually implement it. \n. I am not responsible for the quality of third party plugins but those plugins will make the deployment and more complex and with that fabio itself. The fact that it is a single binary which you just copy and run and don't have to configure is not a coincidence.\nI am running a fairly complex setup right now and also maintain a public API which I have to keep backwards compatible. I prefer solutions that have \"batteries included\". Engineering is about tradeoffs and I'm looking for holes in your argument. In your mind the problem is solved but I just don't see it. The fact that you don't see any downsides but only benefits I something that in my experience doesn't work out. \nfabio is not dependent on consul. It is dependent on a registry that provides the addresses of active services and the routes they serve. Because of the automatic nature there should be a way to modify the generated routing table in a consistent and persistent way (overrides).\nYou and others already mentioned that consul an unnecessary dependency. It is one more piece of infrastructure that has to be installed, maintained, backed up, configured, monitored, scaled, secured, upgraded and understood. So how would the Microsoft DNS registry plugin work if there is no consul and you want to store and maintain overrides for a cluster of fabio instances distributed over a couple of datacenters?\nAs for the Docker API: From what I can tell this is for a single host setup with multiple containers which can be queried fairly simple via the GET /containers/json call which provides addresses and ports of the containers and ENV vars could contain the paths to be registered. That and some authentication, maybe listen to the event API instead of polling should do the trick and can be implemented with the standard http lib. The problem is only where to store manual overrides but maybe that isn't an issue in a single host deployment. \n. After thinking about it for a while I think the simplest thing that could possibly work is along the lines of what you suggest. Fabio could just watch multiple KV entries in consul for changes instead of one for the overrides. By watching /fabio/registry/* and merging them all together you could support any external system through any means since all you have to do is to manage that entry with an HTTP POST request on an already existing API.\ne.g. \n/fabio/registry/consul\n/fabio/registry/static\n/fabio/registry/SkyDNS\n/fabio/registry/Docker\nThe benefit of this is that I wouldn't have to think about a consistent persistence layer, authentication, API and so forth since consul already provides this. The current implementation of the consul registry could also use the same mechanism to be consistent with the rest and it could either become a plugin or remain internal. Order would not matter since the registry plugins are expected to issue only route add commands and the route del commands would remain in the manual overrides which would still be appended last. What do you think?\n. This would require that every plugin developer has to solve the problem of the KV store. Then the KV store connection should be a separate API as well. One for consul, file, redis, ... \nWhile this makes it indeed very flexible it would also mean that you now have to install, run, monitor and upgrade three things instead of just one. Maybe written in different languages, requiring different incompatible runtimes. Different combinations of plugins will work while others wont. Failure of any of these components leads to failure of fabio. People less equipped with knowledge of these things will plug things together and this will create support questions which someone has to pick up and respond to. Since fabio sits in the critical path of any application this worries me. \nThat is one of the reasons I like Go and the Hashicorp approach. Building a single \"batteries included\" binary which just works. You move the complexity from the deployment into the development. The plugin approach makes it easier for the developers to integrate but harder for the users to use.\nYes, code has to be compiled into fabio and a library might have to be added but the registry code is usually very simple, based on either HTTP, file or DNS and can fit into a couple of lines of code since the systems you are interfacing with already have an API. \nHowever, I do acknowledge that another method for integrating with other registries is beneficial. I think watching multiple endpoints in consul might be a balanced first step since you can then write a plugin for another registry which just pushes the routing table into consul. With that step fabio becomes actually dependent on consul. \n. Another thought is that fabio actually only needs a versioned KV store and fabio could provide an API to that to avoid that registry plugins would have to implement different KV store mechanisms. Then the fabio instances only need to be notified when the KV store has changed.\n. Also, the KV store is important for custom error pages and certificates for the whole cluster. \n. consul as the KV store also provides one additional function which is essential to fabio clusters: change notification. Without that you have to revert to polling. \nIf I assume that the KV store and the coordination are the critical functions for fabio and that there are any number of providers which push routing information into that store then I could do the following:\nfabio provides an API endpoint which allows uploading a routing table. Each routing table has a name, any number of routing tables is possible, all routing tables are merged in no particular order with the manual overrides merged last. \nIn the first iteration fabio would continue to use consul for the KV store and the coordination but other options are possible. To support any KV store (e.g. redis, MySQL, memcache, ...) I would have to factor out the cluster management (i.e. change notification). \nSo adding these endpoints together with merging all routing tables should provide the desired functionality.\n```\nPUT /routes/\nContent-Type: text/plain\nroute add service ...\nDELETE /routes/\n```\nThis would allow you to write a plugin for the Docker API which just pushes its routing table into fabio whenever it detects that there is an update. \nInitially I would support the current config language but support JSON in a subsequent iteration. Then I'll refactor the built-in consul registry to also just push to KV store. But there has to be a leader election so that not all fabio instances of a consul cluster push the same changes to the KV store at the same time. \nThis different routes should also be visible in the UI.\nI could provide a number of \"provided\" registry plugins which get built together with fabio and which I run from fabio as a child process providing the API endpoint as a startup parameter. This way I still have a single code base, one set of deployables and you still have to start only fabio to get things rolling. \n. In the current implementation consul has two completely independent functions:\n- consistent KV store\n- service registry\nWith that in mind: \n- Docker API is a service registry\n- etcd is a KV store\n- zookeeper is a KV store\n- redis is a KV store\n- GCP is a service registry\n- SkyDNS is a (probably) a service registry\n  ...\nTo really follow your argument fabio would require two plugins:\n- a KV driver (to store manual overrides, 404/503 pages, certificates, cluster configuration)\n- a service registry driver (to generate the routing table)\nFactoring these out as external plugins simplifies the development of external integrations but complicates deployment since now three independent executables are necessary for fabio to function independent of how they actually communicate.\nAlso, when you run a cluster of multiple fabio instances (as we do in our 16 node clusters) how do they all get notified that the manual overrides were changed by a user or that a 404 page changed? Again, in the current setup consul provides this function by providing a consistent storage and change notification in between the fabio instances.\nEase of deployment is most likely one design goal that the Hashicorp developers had when developing consul and nomad for example. Nomad has integration points but provides most functions out of the box (from the single binary) without the use of external plugins - unlike mesos/marathon which is way more flexible and more difficult to setup and control.\nMy issue is that I most likely don't have enough bandwidth to build integrations for all possible combinations into a single product even though I find that preferable since the library bloat in Go is minimal. I also don't think that a large plugin eco system is always the preferable solution. (again see Hashicorp)\nWhat I do think though is that it would be sufficient if fabio supports a selection of common KV store backends natively (as in built-in) and provides an external API for service registries. I think supporting consul, etcd, redis and zookeeper as KV stores should provide enough coverage to get started. \n. @if6was9 i haven't given up on that plan but I think i need to provide a KV store solution and Fabio should retain its zero conf approach. This isn't related to eBay using consul. We just happen to pick it. Kubernetes is an obvious target. \n. Good point. I am refactoring the backend registry configuration for issue #12 anyway right now and I'll add that. I'll see that this gets merged quickly.\n. Accidentally amended the commit for issue #12 instead of creating a separate one. You'd have to build a docker image yourself for now with this change until I've released 1.0.9. I was planning to do this next week on 17 Feb 2016 when Go 1.6 comes out. Let me know if that works for you.\n. I've pushed magiconair/fabio:1.0.9-pre to docker hub so that you can test it. It is master+issues #12 and this one. Please note that I did not test this except for go test ./... Let me know whether that works for you.\n. I've pushed a 1.0.9-pre2 docker image from master which contains all changes including your PR #49. Would be awesome if you could test it.\n. Cool and thank you very much for testing. Then I'm going to wait for the Go 1.6 release and push 1.0.9 with these changes out.\n. No, they haven't since I needed a point release for the configuration of the read and write timeout based on stock 1.0.8. master was too far ahead. The changes are in 1.1rc1 (incl. the Docker image) since I've decided to push the version number and started thinking a bit more about RC and pre releases. \nSince Go 1.6 got released yesterday I'm going to provide a 1.1-1.5.3 and 1.1-1.6 build based on master. Should be live soon.\n. Yes, that makes more sense.\n. So that fabio could detect the running services from docker without the need for having consul.\n. I'm stumbling over this myself every once in a while. 0% would be one option but could then be confusing if the route has actually 0% because of the wrong distribution. I'll check whether I can just add a flag and mark the route as deleted and show that in the UI, e.g. as grayed out.\n. I've implemented this as marking deleted routes in the UI with weight 0%, grayed out and stricken through. Since this requires some deeper changes I need to review this a bit more and check if I have sufficient test coverage for this - probably not. But feel free to test the change. \n. \n. I'm going to add proxy.readtimeout and proxy.writetimeout to the configuration until the listener config is refactored. This will be a branch release based on 1.0.8.\n. I've just pushed release 1.1rc1 so you can find binaries and a docker image to test. This was compiled with Go 1.6rc2. I'll release 1.1 once Go 1.6 is out.\n. The use-case as I understand it after some discussion is this:\nWhen services are accessed via fabio through their generic consul DNS name then each service has two names:\nmysvc.service.consul\nmysvc.service.${DC}.consul\nServices could discover the data center during startup and register the appropriate prefixes. However, this is not possible when registering Docker containers through registrator. By allowing to expand ${DC} to the data center of the consul agent a service can register two generic prefixes which work in any data center.\nurlprefix-mysvc.service.consul/\nurlprefix-mysvc.service.${DC}.consul/\n. Generating multiple routes for any number of data centers is not necessary.\n. It is merged.\n. Thanks for @ilya-pi for finding it.\n. Hmm, the fix for this bug fundamentally conflicts with issue #52 since there the deleted routes are only marked but not removed. I may have to rethink that\n. I'll roll this fix first and then refactor for issue #52.\n. Indeed. Thx\n. I think that's fixed with PR #58 which fixes a regression of issue #49. I'll work on a fix for #57 and then release a 1.1.1 which has this change. I think for now either use an older version or specify the ip address.\n. Should be fixed with the 1.1.1 release.\n. @jmheidly Because it did not provide support for manual overrides and I wanted to refactor the code to make that possible. Also, other than @emicklei nobody else pushed for this. This isn't off the table that's why it is still open. Are you interested in using this?. You can ignore that unless you want to use the urlprefix-/foo tag in DNS queries.\n. Can you explain what problem this solves? I got the motivation for the ENV var overrides in #43 but I don't see the benefit of supporting N different config file formats. \n. I don't think that any of the examples you list apply since they all stem from the information being distributed over several places. Regressions happen and so do refactorings for fixing issues (i.e. consul.serviceaddr). Unless I'm missing something, using viper would have not prevented any of these issues since I simply forgot to update the default config file. \nAlso, the FABIO_ prefix for the env vars probably breaks existing setups since the current implementation does not require this. \nThe reason I chose the properties format - besides the fact that I wrote the lib - is to have a commented default configuration file. That you won't have with JSON so HCL or TOML should be the choice and here the (IMO fruitless) config file format discussions begin. Also, fabio should have as little configuration as possible in the config file and it should be static so this should be something you touch rarely.\nWhat you call boilerplate is what I call \"one dependency less\" since it is much simpler for me to fix a bug in my own code than in someone else's. To quote Pike: \"A little copying is better than a little dependency.\" (https://go-proverbs.github.io) \nI understand that you prefer the viper approach over homegrown code and I appreciate the effort you put into this. I also really appreciate you pointing out the current bugs and regressions. Right now I am just not convinced that using viper would have prevented and will prevent these things in the future.\nI am not opposed to merging this but I'd like to do it for the right reasons. I'll think about it and your suggestion about using command line flags in addition to env vars and config files. Ideally, fabio should not require people to dig that deep unless there is a bug. You should download it and be able to use it right away. \n. So the real problem is not that the configuration is difficult but that the listeners are not dynamic enough. I am aware and want to change this. This actually has to change as soon as the dynamic TCP proxy is possible. Currently, the url prefix configuration and the static listener configuration are blocking this. However, given my current workload I don't know when this will happen so I'll probably merge this anyway.\nSome questions:\n1. is there a way to not introduce a breaking change for --cfg? Can't you parse the cmd line args manually? Isn't there a hook in viper?\n2. what about PR#9 in magiconair/properties you have filed? Is that required for this?\n3. Also, could you drop the FABIO_ prefix also for the reason of backwards compatibility. Is there a way to support both with and without prefix and deprecate the env vars without?\n4. Could you have a look at the failing travis build for your change, please?\n. I've left some comments on magiconair/properties#9. Lets address them so that we can move forward with this PR.\n. This will be superseded by #79 unless I'm missing something substantial.\n. What exactly are you trying to achieve?\n. Why would that be the responsibility of the router? Fabio should know nothing about your application. It just routes requests to your services based on the information they provide.\n. How would you do that in HAproxy or nginx? We have the same problem with services in Java and Go. What we have done is to factor out the actual check into a separate service so that the request handler only needs to make a simple call. Then the integration effort is low.\n. @voanhduy1512 In cases where we need this we have an apache in front of fabio. Again, this might be something your app need/can/should handle. The general guideline is that your app should work the same with or without the load balancer. \n. That's a good idea.\n. After looking at the code this isn't easy to implement natively but I could just rewrite the routing table before parsing it. \n. I mean that I could just generate the statements for the services which match the tags. It won't blow up the routing table.\n. Hi @smancke, \nThanks for working on this. A couple of comments on the style:\nIn general, it might be better if you separate refactorings (like the change in the test structure) from additions. Also, I think that splitting the addHeader() function up into smaller pieces does not make a lot of sense here since you're not adding a lot of code. I'd prefer if you leave the style for both the addHeader() method and the tests the way it was and just add your code and test cases. This makes it easier for me to review the change.\nAlso:\n- Please use IP and URL in uppercase consistently in the variable names and remove extra blank lines\n- Please check all errors also in tests (see commit 61f6883)\n- Since you have already added a comment to the test case in the table driven test I would prefer if you wouldn't split up the table into smaller segments. Also, please stick to the if got, want := x, y; got != want {...} idiom where possible. Consistency is key. Don't call it expected once and want somewhere else. Since I prefer that you revert to the previous style consider this a general guideline.\n- Please check the guidelines on documenting Go code for godoc, i.e. that the comment should start with the function name\n- Please sort the imports as the rest of the files: stdlib, blank line, fabio libs, blank line, rest\nCan you please explain which behavior regarding X-Forwarded-For changes exactly (provide an example) since breaking existing applications is a big no-no. This may need to become configurable with the current behavior as a default. \n. Hmm, I've implemented this in #10 after reading this: https://en.wikipedia.org/wiki/X-Forwarded-For. According to that article the format is X-Forwarded-For: client, proxy1, proxy2 which is the reason I've put the proxy.localIP there. The Forwarded header should have a by parameter with the proxy ip if I understand this correctly. So what am I missing?\n. Right, the proxy list is the list of the previous proxies. OK, makes sense. Thx for clarifying.\n. Hi @jonmorehouse, this has been requested multiple times in #2 and #44 which is still open. Personally, I think stripping the URL prefix is the wrong approach since it moves essential configuration from your application into the load balancer and it makes your application behave differently with and without load balancer. IMO, in a lot of cases adding an additional handler isn't that much work but it makes the routing explicit. \nHowever, I get that some people would like to this support for this and there are some edge cases where adding handlers is not easy. I've outlined a different syntax for the urlprefix tag in #42 which would allow this option more organically. Feel free to work on that and build the strip prefix option on top of that. \n. @jonmorehouse I'm going to close this PR as the strip prefix feature has been implemented for #44 and shipped in v1.3.7. In any case I want to thank you for your submission to show interest in the project and this feature.. Yeah, that has been on my wish list for a while (see #27)...\n. @jefferai I've got a question regarding the Vault integration. Right now I'm polling Vault every couple of seconds (default every 3s, no less than every sec) to get the list of certificates stored under a certain path. I am also renewing the token on every refresh.\nI assume the path structure in Vault looks like this:\nsecret/fabio/certs\nsecret/fabio/certs/a.com cert=---BEGIN CERTIFICATE --- key=--- BEGIN RSA PRIVATE KEY ---\nsecret/fabio/certs/b.com cert=---BEGIN CERTIFICATE --- key=--- BEGIN RSA PRIVATE KEY ---\n...\nI don't care about the leases since I'm always replacing the certificates with whatever I get from Vault and I couldn't see how Vault would tell me when things have changed like Consul does. \nIs this in line with how Vault should be used?\n. @jefferai The problem isn't about cert expiration but about detecting when another cert has been added or removed and how quickly fabio can pick this up without being restarted. \nThink about how this would work in consul. You add a cert to the KV store and all watchers would be notified that something has changed. Then fabio can load the new list of certificates and replace the old one. Since Vault does not have such a mechanism for watching for changes I have to revert to polling. Am I missing something or does that make sense to you?\n. Hi @jefferai\nthe design is as follows: a background process fetches the available certificates from a source (file, path, http, consul, vault), checks if there is a difference to the previous value and only then updates them. \nThis decouples the fetching of the certs from the serving, i.e. fetching certs cannot block the main proxy.\nIf I would fetch the certs on the first request I would have to deal with a stampeding herd on startup where thousands of requests would all try to fetch the cert at the same time. I could still funnel this through a lock but this has the potential of blocking the proxy. \n. @jefferai your comment got me thinking. I should be able to keep this decoupled while at the same time fetch certificates only on demand. \n. @jefferai no that didn't get lost and that is the function I'm using for serving the certs and the certs are cached in memory until they change. \nThe problem is with fetching and when and how to trigger the reload. You rely on a SIGHUP which has to be triggered by someone or something. Also, if you run more than one fabio instance they'd all have to receive the signal more or less at the same time on different machines unless you build a coordination mechanism into vault. If that isn't there then this is a process that someone has to build and maintain which I want to avoid. \nConsul offers the option to wait (long poll, waitIndex) for a change. That allows me to update the proxy routing table of all connected fabio instances at the same time without the need for external coordination. I'd like to achieve the same thing with the cert sources but since only consul offers the wait-for-change feature I've reverted to polling where necessary. \n. Everything else in fabio is automatic. There are no signals to be sent and nothing to be configured. That's the design goal of it. Therefore, certificates should be available to fabio as soon as they are added to the store and they should be available to all fabio instances that make up a cluster more or less at the same time - ideally immediately. \nSo I either try to fetch the cert for an unknown domain on the first request, or I tell fabio to reload the certs manually or fabio checks whether something has changed periodically. \nThe first option requires some refactoring and has the potential for blocking fabio while the certificates are being fetched. What if I get lots of requests for domains I don't have a cert for? That might kill the cert store\nThe second option requires either some manual intervention or some glue code the user has to provide. Both are not in line with fabios design goals.\nThe third option is how fabio works now but it requires a database which notifies fabio when something has changed (i.e. consul) or I have to poll for changes.\n. Hi @jefferai \nUnfortunately, I'll still be on vacation until Tuesday but we can meet on Wed, 15 Jun since I'm presenting in the afternoon. I'll be at the venue in the morning. \nAdmin interaction is something I specifically don't want. I'll explain that during the presentation why :)\nI'll think about this a bit more.\n. You need to register services with unique service ids in consul or otherwise, this won't work. I'll update the readme to make this clear since you're not the first one to run into this issue. However, this is how you should use consul. It's not fabio related.\n. Looks OK. Some minor nitpicks in formatting and naming. Is there a way to squash the commits into one before submitting? I don't need/want the full history on how we got there. (used to gerrit)\n. If I understand the host header change correctly then this behaves as follows:\nGiven the route route add srv xxx.com/foo http://yyy.com/ the current implementation would forward with the Host header set to xxx.com and your change would change that to yyy.com, correct?\nIf that is the case than I cannot merge this since it would break our app big time. We rely on the original host header to be present. This discussion is along the same line I have with people asking for path prefix stripping. By doing this you move a central piece of configuration into the LB and you rely on this function to be there. Without that your application does not work. \nfabio is trying hard not to do that by not offering these options as the app should work the exactly same with and without fabio. This means that an app should handle all routes and it should also understand all host names. I understand that other LBs offer this but I think this should be solved in the app itself. Please let me know whether I understood this correctly.\n. Also, I don't think that this behavior is \"correct\" since it depends on what the LB is supposed to be doing. Sure, you can rewrite the host header but if the application needs to generate links that contain the full external host name then you would have to configure that separately since it can't extract that information from the request anymore. IMO, the whole path mangling is the wrong approach. Just like NAT on the IP level. It works but it causes all kinds of problems downstream.\n. Lets leave it out for now. I need to think about this a bit more and TBH so far nobody has complained about it but I'd like to stick to RFCs where possible. Can you add another issue about this? Then we can have that discussion there. \nIf I understand correctly I should be able to do the squashing in github now. Lets try that. \nThank you\n. As long as this is supported by the gometrics library I'm using it should only be a matter of configuration.\n. Unfortunately, the github.com/rcrowley/go-metrics does not have a statsd reporter but their architecture is pluggable. You can write one...\n. Jordan Shaw from PubNub sent PR #139 to fix this. Thank you and closing.\n. BTW, you can just force push commits into your own branch and github will update the PR automatically. Found that out on a different project :)\n. Thx\n. Hi @manos , sorry for the delay. I was on vacation for a couple of weeks and I'm catching up now. I think what you're suggesting makes sense.. @manos the host=www.domain.com option has been added with #294 . This has been fixed in #375 which is currently on master. I'll cut a 1.5.3 today to roll this out since the metrics refactor is going to take longer. . So the host=dst option implements the original desired behavior. host=dst was added with #294. In addition to host=dst you can use host=www.mydomain.com to set the exact host header.\n1.5.3 is released. Thx Wojciech\n. Not yet but certainly doable. Just log to local disk?\n. so access log to stdout, normal log to stderr?\n. Any preference on the format?\n. There was quite a bit of work to do AFAIR. I'm on vacation for another week and should have time to pick some of the slack early December. . Lets first get this working. Writing to a file is trivial but I agree with @leprechau that this shouldn't be necessary in this day and age.. OK, here is access logging support for fabio. The code supports the common and combined log file format out of the box with common being the default. To enable access logging you have to set proxy.log.target=stdout.\nYou can also configure a custom log format. Check fabio.properties for details. You'll also find examples on how the common and combined log file formats are defined. \nI've spent some time writing the code in a way so that it doesn't alloc since fabio sits in the hot-path.  \nFor everybody interested in this feature: Testing is highly appreciated. I'm especially interested in whether the values are correct and whether all the fields you're looking for are covered. This branch is based on master but I'll rebase it once 1.4 is out.. Rebased the patch on the new 1.4 release which is on master now.. Just in case someone wonders why I didn't just use text/template for the log line format (I just did for example). I wrote a short benchmark to get an idea. \nHere are the results\n$ go test -v -benchmem -bench Log -run lxjdlf\nBenchmarkLog/my_parser-8             1000000          2337 ns/op           0 B/op          0 allocs/op\nBenchmarkLog/go_text/template-8       100000         19035 ns/op         848 B/op         76 allocs/op\nPASS\nok      github.com/eBay/fabio/logger    4.480s\nAnd here the code\n```go\nfunc BenchmarkLog(b *testing.B) {\n    t1 := time.Date(2016, 1, 1, 0, 0, 0, 0, time.UTC)\n    t2 := t1.Add(100 * time.Millisecond)\n    req := &http.Request{\n        RequestURI: \"/?q=x\",\n        Header: http.Header{\n            \"User-Agent\":      {\"Mozilla Firefox\"},\n            \"Referer\":         {\"http://foo.com/\"},\n            \"X-Forwarded-For\": {\"3.3.3.3\"},\n        },\n        RemoteAddr: \"2.2.2.2:666\",\n        Host:       \"foo.com\",\n        URL: &url.URL{\n            Path:     \"/\",\n            RawQuery: \"?q=x\",\n            Host:     \"proxy host\",\n        },\n        Method: \"GET\",\n        Proto:  \"HTTP/1.1\",\n    }\nresp := &http.Response{\n    StatusCode:    200,\n    ContentLength: 1234,\n    Header:        http.Header{\"foo\": []string{\"bar\"}},\n    Request: &http.Request{\n        RemoteAddr: \"5.6.7.8:1234\",\n    },\n}\n\nb.Run(\"my parser\", func(b *testing.B) {\n    var keys []string\n    for k := range fields {\n        keys = append(keys, k)\n    }\n    sort.Strings(keys)\n    format := strings.Join(keys, \" \")\n\n    l, err := New(ioutil.Discard, format)\n    if err != nil {\n        b.Fatal(err)\n    }\n\n    b.ResetTimer()\n    for i := 0; i < b.N; i++ {\n        l.Log(t1, t2, resp, req)\n    }\n})\nb.Run(\"go text/template\", func(b *testing.B) {\n    tmpl := \"\"\n    for i := 0; i < len(fields); i++ {\n        tmpl += \"{{.Req.RemoteAddr}}\"\n    }\n    t := template.Must(template.New(\"log\").Parse(tmpl))\n    d := &struct {\n        Req  *http.Request\n        Resp *http.Response\n    }{req, resp}\n\n    b.ResetTimer()\n    for i := 0; i < b.N; i++ {\n        t.Execute(ioutil.Discard, d)\n    }\n})\n\n}\n``. @holtwilkins Indeed. Thanks for finding this. This should be fixed now. Could you have another look, please?. Fixed nil pointer panic inproxy/http_proxy.go:93. Rebased to master after travis test failure fix.. Cool and thanks @holtwilkins for taking another look. @sielaq has also found the nil pointer issue so I think the code is in good shape. I'll sit on this for a couple more days since I don't like the config options yet because they clash a bit with theproxy.log.routesoption I've added lately and then there is PR #246 for a remote logging backend which should be integrated later. . @ak66982 No, of course not. Should have written a full integration test :( I'll fix it.. @ak66982 Fixed.. This produces now:addr:\"127.0.0.1:5000\" host:\"127.0.0.1\" port:\"5000\"`\nI've added a couple of additional fields:\n//   request_scheme          - request scheme\n//   request_url             - request URL\n//   upstream_request_scheme - upstream request scheme\n//   upstream_request_uri    - upstream request URI\n//   upstream_request_url    - upstream request URL\nThe full list is:\n//   header.<name>           - request http header (name: [a-zA-Z0-9-]+)\n//   remote_addr             - host:port of remote client\n//   remote_host             - host of remote client\n//   remote_port             - port of remote client\n//   request                 - request <method> <uri> <proto>\n//   request_args            - request query parameters\n//   request_host            - request host header (aka server name)\n//   request_method          - request method\n//   request_scheme          - request scheme\n//   request_uri             - request URI\n//   request_url             - request URL\n//   request_proto           - request protocol\n//   response_body_size      - response body size in bytes\n//   response_status         - response status code\n//   response_time_ms        - response time in S.sss format\n//   response_time_us        - response time in S.ssssss format\n//   response_time_ns        - response time in S.sssssssss format\n//   time_rfc3339            - log timestamp in YYYY-MM-DDTHH:MM:SSZ format\n//   time_rfc3339_ms         - log timestamp in YYYY-MM-DDTHH:MM:SS.sssZ format\n//   time_rfc3339_us         - log timestamp in YYYY-MM-DDTHH:MM:SS.ssssssZ format\n//   time_rfc3339_ns         - log timestamp in YYYY-MM-DDTHH:MM:SS.sssssssssZ format\n//   time_unix_ms            - log timestamp in unix epoch ms\n//   time_unix_us            - log timestamp in unix epoch us\n//   time_unix_ns            - log timestamp in unix epoch ns\n//   time_common             - log timestamp in DD/MMM/YYYY:HH:MM:SS -ZZZZ\n//   upstream_addr           - host:port of upstream server\n//   upstream_host           - host of upstream server\n//   upstream_port           - port of upstream server\n//   upstream_request_scheme - upstream request scheme\n//   upstream_request_uri    - upstream request URI\n//   upstream_request_url    - upstream request URL\n. @ak66982 Thank you. I'm glad you like it.\nRight now, I'm getting the content length from the http response generated by the Go reverse proxy. i didn't dig into how it retrieves it but I'll have a look.. Added a full integration tests which generates the log output through the proxy with a real request. This uncovered two bugs in the $upstream_request_uri and $upstream_request_url fields which did not contain the upstream uri paths and args since this magic was happening somewhere in the httputil.NewSingleHostReverseProxy() code. \nThe other thing I've discovered was that the request object got modified through the reverse proxy code which made the $request_url, $request_scheme and $request_args fields invalid or incomplete. This has been fixed.\n@ak66982 I still don't have a test for the -1 value in the $response_body_size so it would be helpful if you could try to narrow this down further.. I've renamed the log parameters as follows:\nlog.access.format\nlog.access.target\nlog.routes.format (replaces proxy.log.routes)\nThis should also make integration with PR #246 more consistent. If there are no objections then I'm going to merge this and release version 1.4.1.. Published release v1.4.1 with access logging support. Thanks for your help.. This will break with defaultEnv.default. The whole magic term default is broken. It might make more sense to make the default a set of variables which are pre-defined. Then the default just becomes a format string, e.g. metrics.prefix = ${hostname}.${exe} I have to think about that.\n. The simplest workaround is to set an ENV variable METRICS_PREFIX and set it to the value you want. That should work out of the box.\n. Hmm, using text/template is an interesting approach. The code needs some cleanup but the biggest concern is that hostname -f won't work on Solaris the way you think it does - and there are people running fabio on Solaris. With this we could also make the clean function available through the template.\n. @md2k Can you explain why using command line flags or environment variables is not an option for you?\n. @md2k If you can run GOGC=400 /usr/local/bin/fabio then I think you can also run GOGC=400 METRIC_PREFIX=${ENV}.$(hostname -f) /usr/local/bin/fabio the main problem with this approach is that you probably want to clean the hostname separately from the env so this won't do what you expect. I like the template approach in general but the current implementation will not work since it isn't portable. I have to think about this a bit more.\n. Maybe we want this to default to the value of proxy.localip\n. proxy.localip is set automatically to the first address it finds.\n. Please have a look here: https://github.com/eBay/fabio#websockets\nCurrently, the implementation detects the protocol based on the presence of the Upgrade: websocket header in the request. So if your backend accepts websockets on /foo register urlprefix-/foo and it should just work. \nPlease let me know if it doesn't\n. Yeah. Saw the issue on PanteraS. Not yet. I've got some time scheduled to work on Fabio so maybe I find time to squeeze it in. Pls subscribe to #1\n. Have a look at the Quickstart: https://github.com/eBay/fabio#quickstart\nYou need to add a urlprefix-/ tag to all service definitions if they handle /. The idea behind fabio is that services announce which endpoints they handle during service registration and they do that by adding a urlprefix-host/path tag for every endpoint they accept.\n. Also, the checks are vital since fabio will only add services with a passing health check to the routing table. So it is good that you have them. :) Another common mistake are non-unique service IDs for different instances of the same service.\n. urlprefix-/\n. I don't see a route add coomand in the log. Therefore, your service is not included. Can you replace your health check with an http check instead of the script? Did you reload consul after the change? Does consul show the service green ?\n. What does curl localhost:8500/v1/health/state/any?pretty say?\n. No problem. Glad you got it working. Let me know if there are other issues.\n. Yes, that is true - unfortunately. The parser will not allow it but the rest of the code assumes to get only valid data and I do not pass the errors along. Should not be too difficult but I am busy with something else right now.\n. First: thank you :)\nSecond: I think you are confusing two things. A wildcard certificate allows TLS connections for all domains under *.domain.com. fabio supports wildcard certificates.\nHowever, fabio currently does not support assigning multiple certificates (wildcard or otherwise) to the same listener. So you could not have *.domain-1.com and *.domain-2.com assigned to the same host:port. The good news is that I am working on supporting this right now. \n. @mterron yeah, I don't think it is difficult. The problem right now is that for TCP proxying support fabio needs to bring listeners up dynamically and I also need a way to express this in the configuration. Both are not difficult issues but they're also not one-line fixes either since they require some re-architecting.\n. I'll close this ticket and merge it with #1 \n. Just try it and let me know how it goes. I don't have an environment to test this in. \ngo get -u github.com/eBay/fabio\ncd $GOPATH/src/github.com/eBay/fabio\ngit checkout v1.1.1\ngo build\n. I'm going to close this one for now. Pls re-open if necessary.\n. @floekke No. I'm going to publish Windows binaries from the next release onwards. Please open tickets for issues since I'm not testing this on Windows.\n. @RXG0 Looks like the switch to goreleaser threw the Windows binary under the bus. https://github.com/fabiolb/fabio/releases/tag/v1.5.4 still has windows binaries. I'll manually add the other ones and fix the release process.. @RXG0 I've added the missing Windows builds for 386 and amd64 to the releases page. 1.5.7 does not build on Windows since I forgot to add a stub function. I'll push a 1.5.7.1 shortly.\nhttps://github.com/fabiolb/fabio/releases. The way you should do this is to do the redirect in the application and not on the LB. If your application needs a resource to be on HTTPS then it should detect that and send the redirect itself. This way your application does not depend on the LB to do the work. \n. The question is what you consider basic and universal but I agree that fabio could provide this providing that the application configures it. That means there needs to be a way for the application to express this. It's already on the list for #87. \n. @iadknet Services are the only place where you know whether something has to be on HTTP or HTTPS. After all it is your service that defines the requirement and not the environment. What you are doing by moving that configuration into the LB is to split up the service configuration into two places which from that moment on have to be kept in sync. That means you have to configure fabio that this specific route needs to be on HTTPS and that again means that you have to manage that configuration and deploy it everywhere in sync with your service deployments (think puppet). How is that different from any typical nginx/haproxy setup? The whole point of fabio was to not do that but to have the LB auto-configure itself from the requirements the services have. The only way to achieve this IMHO is to have the services tell the LB what to do.\n@leprechau One could argue that TLS ciphers are a system wide configuration like the ip address or the port. I would view them as a security configuration and the only situation where I could see them to be configurable is if you have to support some legacy configuration. This feels like and edge case to me but I don't know for sure. In any case that could be made configurable in the static configuration by providing different TLS listeners. With the Go std lib tls stack it isn't possible AFAIR to specify this per connection but only on the listener itself.\n. @iadknet Only your service knows which endpoints need to be on SSL. AWS doesn't and that is the environment IMO. This makes it a service config but lets not split hairs here. I think we've made both our points clear enough :)\nAlso, I get your other point that it is much simpler to put one rule in front of the app to fix this instead of fixing this everywhere. Don't get me wrong: I'm happy to provide that feature if I can implement it in a way that doesn't require you to provide static config everywhere. \nWhat occurred to me is this: Couldn't you have an https-redirector service which announces http://foo.bar/ and whose only service is to redirect to https://foo.bar/ (with /path) if you want. Then your other services can announce https://foo.bar/. Then you would have to make fabio terminate SSL. Not sure how that works on AWS.\nI guess when you say that SSL is an environment config you mean that in some environments you want so use SSL for your app and in others you don't. In that case that's an optimization to make your dev env look different from your prod env. \n. @iadknet The typical argument was/is that HTTP is inspectable and cacheable and has less overhead than HTTPS. So ideally you guard your auth endpoints and leave the rest open for others to sniff your cookies I guess. :)\nAlso, no need to worry. I'm happy we're having this discussion since it gives me a better idea whether this is an actual problem or just an idea. The main issue right now is that I don't have a good vehicle to ship the extra options from the urlprefix- tag into the routing table since I've got my intermediary language and a crappy parser. Also, I now have four different representations of the same thing I'm considering replacing the route add ... commands with a compatible JSON structure which I can then use for overrides and on the API. Not as human friendly but probably not the end of the world either and I don't have to write parsers and generators for different representations.\n. @avarabyeu It is the right place and right now this isn't possible, unfortunately.. I'm wondering how we could express this in the syntax. The route command could look like this:\nroute redirect /foo proto=https code=303\nbut the urlprefix- tag becomes increasingly useless here. . Finally, this got added. Thanks a lot @ctlajoie . Something like this?\nroute add https-redirect / https://$host$path opts \"redirect=301\"\nNote that this doesn't work yet but it's easy to add. I'll have a PR ready soon. @holtwilkins @leprechau https://github.com/fabiolb/fabio/pull/451 \nThis probably needs some more love. I'll have a closer look tonight.. @tino That would be a consequence of this approach. I'm open for suggestions. There is some impedance mismatch between the config language and the urlprefix- tags. Maybe this is a good time to re-open that can again. \nBasically, route add commands are generated from the urlprefix- tags. We could add something like fabio <arbitrary command> to the tags which fabio would copy verbatim to the routing table. This way we could keep the short urlprefix- tags but also offer the full power of the config language to the tag based registration. \nThen you could add a tag fabio route add :80/ https://$host$path opts \"redirect=301\" to add this.\nDoesn't look like too much work. Any takers? . Actually, this is trivial ~and would solve probably a lot of problems~. I've written a POC with just a few lines. I'll move this to a separate issue. \nUpdate: I'm not sure if it would actually solve a lot of problems but I would no longer have to maintain two different syntaxes for the same thing. urlprefix- would be a shorthand notation which could also be expressed via route add commands assuming that the values provided by Consul like $service and $addr are available as pseudo-vars. Then urlprefix-/ would be a shorthand for route add $service / http://$addr/ and you could use the latter as Consul tag.. This vaguely rings a bell but I need to dig through the consul documentation again why that is. For now, I suggest to provide the service address.\n. The consul documentation for services https://www.consul.io/docs/agent/services.html says that the service address is optional. \n\nThe address field can be used to specify a service-specific IP address. By default, the IP address of the agent is used, and this does not need to be provided. \n\nI've added a change to use the address field if the ServiceAddress is empty. Could you test whether that works for you?\n. @mazhack ServiceAddress takes precedence over Address. \n. We have a netscaler in front of it. On AWS you probably have different options. You can also multiple DNS entries with different ip addresses but the simplest thing is to use a stateless layer 4 switch (ip packet rewriting) with DNAT. Assuming that your L4 switch is also the default gateway all you have to do is to replace the destination address in the incoming packet with one of the fabio instances and dump the packet on the wire again. We used to do that with Linux IPVS but that looks a bit dated now. Not sure if that works with the latest kernel. iptables might do the trick.\nSince you only need to shuffle packets around, rewrite them without keeping track you don't need any keepalived magic. The overhead is close to zero.\n. @joeblew99 Can you explain what that means: \"The web clients boot off S3 for www.example.com\" Do they have an internal ip, an external ip, both? \n. Hmm, that looks like a bug. I'll have a look.\n. My guess is the same thing happens when you add a route for urlprefix-foo.com/ and call fabio with http://foo.com:80/. When I look at the table below then the fix would be to drop the default port from the incoming request. That means http://foo.com:80/ would be translated to http://foo.com/ and https://foo.com:443/ to https://foo.com/ before lookup. \nIn both cases the urlprefix-foo.com/ route would match but neither urlprefix-foo.com:80/ nor urlprefix-foo.com:443/ would although they would be an exact match with the incoming request. They would only match if :80 (or :443) is not the default port, .e.g http://foo.com:443/ or https://foo.com:80/.\nThis would only become a problem if you want to match on certain protocols I guess which I'm going to address when introducing the new prefix syntax as described in #42.\nI guess dropping the default port from the incoming request is what you would expect to happen. But there is a small chance that this will break someones setup if they have a prefix urlprefix-foo.com:80/ with requests for http://foo.com:80/ which will then no longer match. I'll probably have to hide this behind a switch so that you can revert to the old behavior. \n```\nurl                     urlprefix       match\nhttp://foo.com/         foo.com/        yes\nhttp://foo.com:80/      foo.com/        yes\nhttp://foo.com:443/     foo.com/        no\nhttp://foo.com/         foo.com:80/     yes\nhttp://foo.com:80/      foo.com:80/     yes\nhttp://foo.com:443/     foo.com:80/     no\nhttp://foo.com:443/     foo.com:443/    no\nhttps://foo.com/        foo.com/        yes\nhttps://foo.com:443/    foo.com/        yes\nhttps://foo.com:80/     foo.com/        no\nhttps://foo.com/        foo.com:443/    yes\nhttps://foo.com:443/    foo.com:443/    yes\nhttps://foo.com:80/     foo.com:443/    no\nhttps://foo.com:80/     foo.com:80/     yes\n``\n. @mazhack I've pushed a fix for this into a branch. I still need to add a switch to the configuration but could you check whether that works for you?\n. @ksoftirqd Can you give a concrete example?. @ksoftirqd Why are you running fabio on a random port? Its main use case is to route incoming traffic from the internet to frontend services (FE-BE or N-S) and not between services (BE-BE or E-W). For that you use service discovery. I'm assuming that you are trying to use fabio for BE-BE routing because you try to put it into theurlprefix-` tag. \nFor FE-BE routing to work you usually run fabio on a well known port since you need to configure your inbound LB (which listens to 80/443) to forward traffic to the fabio instances. If fabio is your internet facing LB then you need to run it on 80/443 anyway. Please have a look at https://github.com/ebay/fabio/wiki/Deployment.\nBut maybe I'm missing something here and if so please explain.. @ksoftirqd I need to think about that. You may be right that this isn't really necessary. \nFor now you can work around that by registering the route as urlprefix-fabio:*/foo. This should work out of the box.. That was added with #163 . In this case it doesn't matter IMO since if either in or out dies the function returns and closes both in and out which will terminate the remaining go routine sooner or later. Also, only the first error is interesting since it is the cause and the other one is a consequence of the Reader/Writer being closed. Since the errc channel goes out of scope when the function returns and does not escape it should be cleaned up as well including the unconsumed error.\nAre you asking out of curiosity or is there an issue you're looking into?\n. Interesting idea. This might solve a couple of other issues for people as well. Code looks clean on first glance and I like the integration. I'll spend a bit more time reviewing this but this looks like it is going in.\nThanks for this.\n. Looks good. I'll update the docs.\n. Not right now. You can configure multiple listeners but the routing table is shared among them and routing is currently done only via host/path. To fully support this fabio would need to be able to dynamically create and shutdown listeners. I need this for the TCP server support but right now that is not possible.\n. @chy168 with the fix for #90 you can announce a urlprefix-foo.com:443/api which will only be accessible via https assuming your HTTPS listener is configured for port 443. To route based on protocol I need to fix something else first but that should help you for now.\n. @SkyRocknRoll what you could do is to run one fabio per port and use different tag prefixes but that is pushing fabio a bit beyond of what it is currently designed to do. You certainly lose the ability to just route to a new service without configuration since you have to spin up a fabio instances for that new port. I'd go with @mazhack that using static ports for incoming requests is not a good idea. Use different URLs instead but that might not be possible for you.\n. @stevenscg How is the link between xyz.example.com and port 8085 or port 30000 established in this scenario? If all your requests come in on port 80 you need a way to determine the target. That isn't clear to me from this description. \n. Also, I'm starting to think that a different matcher implementation (with some small refactoring) might be a solution to this instead of waiting for the full tag prefix refactor. The lookup function gets the full request and has the full routing table available so any two pieces which allow a matcher to link request and target should work. Right now I'm linking incoming request uri to service uri (or prefix). But one could also build a matcher that matches destination port to some advertised host:port. However, the part that I don't get in the described scenario is how the decision is made that xyz.example.com should end up on that instance running on port 30000. There is nothing that links the domain to that port (or 8085) unless the client is requesting the resource on that port instead of 80.\n. @stevenscg So the ELB has the domain -> port mapping and fabio acts as a second level dynamic router, right? If that's the case then this should be doable at least in step one without dynamic listeners. This assumes that you have either automated the listener configuration and handle fabio restarts or that you don't add new ports that often.\n. @sriyer No, this hasn't been implemented yet and I don't have the bandwidth to do the refactoring. My guess is that the activity comes from fabio checking consul in the background. If you configure fabio manually anyway you might want to disable that to see whether that helps.. Like this? Could you test it and let me know whether that works for you?\n. Forgot logging. \n. ok, then I'll merge that one as well.\n. merged.\n. Hi @mitchellh, Thanks and that is nice to hear. I might see you in Amsterdam during Hashiconf 2016.\nMatching on the full host header is indeed the intended behavior but maybe I'm missing something here. If it wouldn't do that then you couldn't run different services on foo.com:81 and foo.com:82 for example since they would both be routed to foo.com. What I've recently added though is dropping of the default port. See #90 \nWhat is your use case?\n. I've just merged #93 from @dkong which adds glob matching but only to the path. That should be simple to extend to the host as well.\n. Why can't you just run 80/443 in TCP mode and terminate SSL on fabio? Sure, you'd lose the original src ip but you would lose that anyway if you're not going through some kind of protocol gateway. \nAlso, how would fabio supporting PROXY help here? Assuming the originating request is coming from a regular HTTP client and ELB running in TCP mode you also wouldn't have an X-Forwarded-For header with the src ip or am I missing something? I'm not an expert on ELB though ...\n. I guess I could replace the http listener with the one from Armons repo: https://github.com/armon/go-proxyproto or at least use it as a basis. AFAIU, it just detects the PROXY line and then stores the addresses in the Conn struct. Doesn't look difficult. \n. @mitchellh I'm still fighting with setting things up on AWS but from the look of it that should be all that's necessary. I'll test it once I have things running on AWS but if you want to give it a spin please feel free.\n. Got it to work. I've added a simple log line to show the remote addr. (access logging is #80)\nWith HTTP LB:\nGot request from 10.0.1.58:62422 for /echo\nWith TCP LB and patch for #97:\n```\nPROXY TCP4 82.161.239.242 192.168.9.213 63477 80.\nGot request from 82.161.239.242:63477 for /echo\n``\n. I was. Even found https://github.com/hashicorp/terraform/pull/1749. Only had to figure out what to set as policy (ProxyProtocol`) :)\nThat's what I'm currently getting:\nGET /echo HTTP/1.1.\nHost: fabio-example-elb-1332123959.eu-west-1.elb.amazonaws.com.\nUser-Agent: Go-http-client/1.1.\nConnection: Upgrade.\nForwarded: for=82.161.239.242; proto=http; by=10.0.1.248.\nOrigin: http://localhost/.\nSec-Websocket-Key: t9mUKAGGLUFiEwpz7aCN5w==.\nSec-Websocket-Version: 13.\nUpgrade: websocket.\nX-Forwarded-Proto: http.\nX-Real-Ip: 82.161.239.242.\nThe X-Forwarded-For header is added automatically by the HTTP reverse proxy but not for the ws proxy. Also, the X-Forwarded-Proto header should probably contain ws or wss. I'll fix it. \n. I've fixed the header handling in #98 and merged the change for #97 to master. I've also added support for the X-Forward-Port header while I was at it. The result is:\nGET /echo HTTP/1.1.\nHost: fabio-example-elb-1332123959.eu-west-1.elb.amazonaws.com.\nUser-Agent: Go-http-client/1.1.\nConnection: Upgrade.\nForwarded: for=82.161.239.242; proto=ws; by=10.0.1.248.\nOrigin: http://localhost/.\nSec-Websocket-Key: FJXs4MaHM29ID8+Yp3EnCg==.\nSec-Websocket-Version: 13.\nUpgrade: websocket.\nX-Forwarded-For: 82.161.239.242.\nX-Forwarded-Port: 58686.\nX-Forwarded-Proto: ws.\nX-Real-Ip: 82.161.239.242.\nLet me know whether that does the trick.\n. No, but it might be a good time for a 1.1.3rc1. I'll spin one\n. Done - both release and Docker container. Let me know how it goes. \n. There is an issue with Armons proxy listener. For some reason the request object no longer has the tls.ConnectionState set in TLS which means I can't set the protocol headers accordingly. I need to investigate this but for now consider v1.1.3rc1 broken.\n. I think I just used it in the wrong place. Testing now\n. Should be fixed in 1.1.3rc2\n. I've release 1.1.3 today and I am closing this ticket for now. Pls re-open if you have issues.\n. Not right now but I can add it. You only want the health check disabled or fabio not registered at all?\n. ok. I'll add it. Not difficult.\n. That should do the trick. Can you test it, please?\n. yep, it should :)\n. I'll have a look later today whether I can fix this properly. \n. Any idea why your consul servers are going down? We don't really have that issue.\n. That should fix it.\n. Merged it to master. Pls reopen if it causes issues.\n. Hi @EvertMDC, I don't have plans to support this at the moment. Mostly because sticky sessions cause more problems than they solve. I suggest to fix the application. \nThe main problem with fabio is that is intended to be used in a highly dynamic environment where instances come and go regularly. A cluster of fabio instances does not share state so the sticky routing would have to be stateless and deterministic in such an environment. I could hash the source ip or a cookie, modulo it by number of instances and send it to the resulting instances. But during restarts of services users would be sent to the wrong server, basically invalidating their session. \nSo my suggestion is still to fix your app.\n. iptables isn't portable and using a source address pool doesn't seem to hard to do.\n. @md2k one of the next things on the list\n. @md2k I think I have a first patch ready. The approach is to allow configuration of proxy.localaddrs which contains a list of source ip addresses for outgoing connections. Right now, I have support for a comma separated list (e.g. 1.0.0.1,1.0.0.2,1.0.0.3, ...) but I could also add range (1.0.0.1-1.0.0.5) and/or CIDR (1.0.0.0/27) support. \nThe patch has fast paths for zero and one local addresses. For more than one it will pick a random address and then try to establish a connection. If that fails for whatever reason it will try the next one and so forth until all have been tried at which point the connection has failed. I'm not sure whether that approach makes enough sense and I need to sleep on it a bit.\nI also need to check whether I can detect if a connection attempt failed because of local ports exhausted or backend not responding. \nThe dial timeout is for establishing the connection independent of the number of source ip addresses.\nIf you can it would be great if you can test this patch. I'll dig a bit more on errors and write an integration test.\n. Couldn't your service announce both a generic and a specific route, i.e. p-/foo and p-/foo.v1? I'm assuming that you have another proxy in front of this which does the header parsing.\n. I think now I get it. You want to route based on /path and Header: value instead of just /path. Currently, fabio routes only on /path so this won't work out of the box. Since you mention that you've identified the client before I am assuming that there is another proxy that performs the identification. \nWhat you could do is the following:\nYou register all services with Header: x with x-/path, all services with Header: y with y-/path and so forth, e.g. v15-/path, v16-/path. \nThen you would have to run a fabio instance per prefix by setting the register.consul.tagprefix value to either x, y, v15, v16, .... They would have to run on different ports though. \nIn essence you're namespacing your service URLs and your fabio instances still share the same service registry. \nTBH, this sounds like a workable but not very elegant solution. Let me know whether that solves your problem for now and I'll think of something better.\n. I suggest to use something shorter like p_x_v1_q1-/path. It is messy but I need to wrap my head around this a bit more to come up with a better solution.\nThanks and keep me posted how it works.\n. @simonsparks you only need the public key to enable client certificate authentication. In the example from fabio.properties this is path/to/clientauth.pem. \nproxy.addr = :443;path/to/cert.pem;path/to/key.pem;path/to/clientauth.pem\nHowever, I haven't tried this myself yet but it is the only option I have for configuring client certificate authentication. Please note that you still have to provide TLS certificates for the fabio listener itself since client cert authentication only works via SSL AFAIK.\nLet me know how this works out for you. If you continue to have problems then I can try this myself.\n. @simonsparks Glad to hear and happy that it works. Let me know if there are other issues.\n. Good point. I've added a patch which adds this feature. Let me know if this works.\n. I'm also thinking whether this is something that fabio could do natively. It could determine the fabio instances in another data center and route requests for failed routes there. This would save another roundtrip since fabio knows which routes it has. \nCan you explain your use case a bit more and which other functions your nginx is serving?\n. I'm going to merge this one. The change is simple enough. Please re-open if this doesn't work as intended.\n. @simonsparks without trying this myself I'd say this looks like this problem. When I generate a test certificate I always have to set IsCA and add x509.KeyUsageCertSign to the KeyUsage for the verification to work. The question is whether fabio should \"fix\" the cert on the fly which may be valid for some and invalid for other certs. Or whether it should provide a tool to \"fix\" the cert. I can't just assume that all client auth certificates are self-signed certs for the AWS API Gateway.\n. Lets first see whether this works. I'll push a patch in a minute for testing. Are you comfortable building a fabio binary yourself or do you rely on a pre-built or docker image?\n. I can upload a binary to github and you could replace go get temporarily with wget. Would that work? I assume linux_amd64 ...\n. or can you ssh into your AMI instance and replace the binary? Sorry, I'm a total AWS noob.\n. BTW, I've just created https://fabiolb.slack.com/ . Might be a good use case to test this.\n. I am a bit torn about the slack channel since it splits the discussions across multiple mediums. Now others don't see the discussion we had there. OTOH, chat provides a mechanism for others to participate. I've added a Gitter (https://gitter.im/eBay/fabio) link to the README. Someone has used that before but I forgot about it Lets see whether that picks up. So far I'm OK with responding to issues but I'm curious what others think.\n. @simonsparks I've pushed an updated patch which introduces a new config option aws.apigw.cert.cn which you now have to set to ApiGateway to enable the workaround. Could you test this and let me know whether it works like the hard-coded version? Then I can merge this to master\n. @simonsparks I've merged the change to master. I agree that the new config name aws.apigw.cert.cn does not fully express what this change does but so far I've failed to come up with a better name. I'll revisit this when moving to 1.2 or when someone else comes up with another use case. At least this way people can use it who have the same problem you have. I need to update the docs anyway.\n. @raben2 this is on master but I did not create a new release yet. Please run go get -u github.com/eBay/fabio to build the master version. I plan to release a 1.1.6 with this change in the next couple of days and then close of the 1.1 branch so that I can switch to 1.2\n. @raben2 @simonsparks BTW, I'm going to drop the parameter aws.apigw.cert.cn in the 1.2 release since it doesn't make sense there. Instead, I'm adding a caupgcn option to the certificate source which you can then set to ApiGateway. I've also come up with a better name for this option which is CA Upgrade CN. That should make it clearer what this is. Because of the changes I'm going to push a 1.2rc3 today and it would be cool if you could give this a quick spin to check whether that part works. 1.2rc3 is live as of today and if there are no issues then I'll merge this to master later this week. Would be cool if you can test.\n. Try a kill -QUIT <fabio pid> and look for the goroutine which hangs in the fabio code. Can you post that here?\n. doesn't look unusual but I'm a bit confused by the hostname you're using in the request: 127.1 doesn't look right. Can you try curl -v http://127.0.0.1:9999/ ?\n. This isn't in my code. Did you add this?\n2016-06-11_22:01:28.56105 goroutine 10 [syscall]:\n2016-06-11_22:01:28.56105 runtime.CPUProfile(0x0, 0x0, 0x0)\n2016-06-11_22:01:28.56105   /usr/lib/go/src/runtime/cpuprof.go:418 +0x34\n2016-06-11_22:01:28.56105 runtime/pprof.profileWriter(0x7fa04a0ea358, 0xc820020118)\n2016-06-11_22:01:28.56106   /usr/lib/go/src/runtime/pprof/pprof.go:599 +0x1c\n2016-06-11_22:01:28.56106 created by runtime/pprof.StartCPUProfile\n2016-06-11_22:01:28.56106   /usr/lib/go/src/runtime/pprof/pprof.go:593 +0x145\n2016-06-11_22:01:28.56107 \n2016-06-11_22:01:28.56107 goroutine 11 [chan receive]:\n2016-06-11_22:01:28.56107 github.com/davecheney/profile.Start.func4(0xc82011a870)\n2016-06-11_22:01:28.56107   /home/ptqa/go/src/github.com/davecheney/profile/profile.go:159 +0xef\n2016-06-11_22:01:28.56108 created by github.com/davecheney/profile.Start\n2016-06-11_22:01:28.56108   /home/ptqa/go/src/github.com/davecheney/profile/profile.go:165 +0xf44\n2016-06-11_22:01:28.56108\nJust tried a GOVENDOREXPERIMENT=1 ~/go1.5.3/bin/go build and ran fabio with the default config on OSX and got this:\n$ curl -i http://127.0.0.1:9999/\nHTTP/1.1 404 Not Found\nDate: Sun, 12 Jun 2016 16:22:20 GMT\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\nOK, thanks for letting me know anyway. I'll keep an eye on this if others have the same issue. \n. I've noticed that you are working on https://github.com/ptqa/chef-fabio. Would it be OK if I mention this in the README?\n. @aerickson Thanks for finding and flagging this in the other project. https://github.com/lobsterdore/ansible-fabio/issues/6. Also, commented on https://github.com/lobsterdore/ansible-fabio/issues/4 which suggests not to build fabio from source in the first place which I think is the better option.. That sounds like a good idea although you then make your service behavior dependent on fabio instead of nginx. This is the same as the strip prefix discussion but I get the impression that enough people want this so lets at least provide a mechanism to provide this properly. \nCan you provide an example request including the headers fabio should add? Using tags will probably not work in all cases since a service can register multiple prefixes in different domains, e.g. a.com/foo and b.org/bar for which you may need to provide different headers. \nBefore you start coding lets hash out first what this could look like. Pls have a look at my last comment on #42 which suggests a format for providing options.\n. I did some digging and started a proposal for a more generic syntax which would allow configuration of a whole bunch of issues. See #111 for details.\n. @boyvinall Could you provide an example of the headers which would need to be added?\n. Another approach is to leave the urlprefix-host/path unchanged and allow for urlprefix-host/path key=val key=val ... This would provide the same flexibility will full backwards compatibility.\n. OK, here is what I am going to do:\nStep 1\nAdd support for key=val options to the existing urlprefix- tags. This keeps them backwards compatible and won't break any existing setups. The first option after the tag prefix is the route target. This should also work for a TCP or UDP proxy although it reads a bit awkward.\nurlprefix-host/path\nurlprefix-host/path proto=https strip=/path\nurlprefix-1.2.3.4:5555 proto=tcp\nStep 2\nAdd support for multiple tag prefixes to allow migration from urlprefix- to something more generic like fabio and add support for a route= option as an alias for the route target so that the previous example reads as:\nfabio route=host/path\nfabio route=host/path proto=https strip=/path\nfabio route=1.2.3.4:5555 proto=tcp\nwhich is equivalent to\nfabio host/path\nfabio host/path proto=https strip=/path\nfabio 1.2.3.4:5555 proto=tcp\nwhich is equivalent to\nurlprefix-host/path\nurlprefix-host/path proto=https strip=/path\nurlprefix-1.2.3.4:5555 proto=tcp\nMaybe step 2 won't be needed but I'd like to add step 1 ASAP to support additional use cases without breaking existing setups.. Merged new route parser to master. The new route parser is in use. Closing.. Try 127.0.0.1:9998/health or whatever you have configured for ui.addr\n. That's the health check fabio registers in consul.\n. Cool. Let me know if there's anything else. \n. Can you explain a bit more what you're after?\n. If you are not using the service discovery feature in consul you can start your fabio instances with different values for registry.consul.kvpath. Their manual overrides (i.e. ${registry.consul.kvpath}/config) would be different. That should do the trick if I understand your question correctly.\n. No problem. I am going to close the ticket now. Please re-open if you have more questions.\n. The intended solution for this is to have your existing service announce both a.example.com/ and b.example.com/\n. And no worries about asking questions. It points to things that could be improved in the docs.\n. @raben2 Thanks a lot. It is appreciated. \n@calvinmorrow ok, I get it. AFAICT, you cannot modify an existing service registration in consul. The API does not have a mechanism for that. But you can re-register a service by first deregistering it and then registering it again. \nI still have the feeling that the overrides are the wrong tool for this problem.\nHow are you currently registering the services in consul? \n. What do your names look like? Do they just differ in the host part?\nFrom what I understand, you deploy a new version into your production environment but don't want to make it accessible under the official name. So you give it one or more other names until your tests have passed, e.g. stage1.api.example.com, stage2.api.example.com, ... until at the end you promote to api.example.com. Interesting... \nSo even if your services would announce all possible names then this wouldn't work since you can't delete a route for a specific instance yet. \nIf you would generate the routing table yourself you lose all benefits from consul service registration and health checks. \nBut these are containers, they should stop and start quickly and after the first deployment the image should be cached. How big is the overhead if you just redeploy them with a different tag? \nCould you modify the apps so that they register themself and re-register on a certain signal?\nNot trying to sidestep the problem but no simple approach comes to mind just yet. \n. I have to think about this for a bit. Some ideas like filtering routes or multiple routing tables came to mind but I need to think about the edge cases and so far none of them worked.\nThe main goal of fabio is that the load balancer does not have to be configured since the services already know what they serve and they should publish this into the registry. Your deployment approach is in conflict with this since the name of the app depends on some external factor (your passing test) and not on the presence of the application itself.\nAs for the downtime during container redeployment: \nWhen you are doing the switch to the new version by redeploying them with the correct name you still have the old version running. So you won't have a downtime of the service just a brief moment where both the old and the new version are running at the same time. Once the new deployment is done you would have to shut down the old version anyway. But I get why you would consider this strange since you're only changing the traffic stream. \n. Hmm, interesting problem. I still have this nagging feeling that something is off with your deployment/testing procedure. Making fabio do what you want should be possible but I'm not sure if this is the right solution to this problem. \nHow fast do your containers restart and what load do you have on them (req/sec)? Our Go services usually restart within a second but we also have 1k req/sec per instance. \nI still think that restarting them with the right name is the right approach and that you should have a look how to make your application work with this. The swap won't be atomic one way or another so better prepare for it. If you have versioned static files like /static/js/jquery-2.4.js you could also put them under /static/<version>/js/jquery-2.4.js and announce a.com/static/<version> instead of a.com/static. This would at least solve that new pages would find their resources. However, it would also mean that clients would have to download static resources that didn't change.\nWhat if fabio had an option to delete routes by source and tag?\nroute del svc api.example.com/ tag 'v1'\n. In your setup the service cannot know the name it is going to be accessed by since this is determined by an external event. The only thing it can know are the /path values since you need to have handlers for it. So you would need a mechanism to route traffic for a specific host/path to a set of services which have a certain set of criteria which cannot contain the host name.\nI think you would need the following new command:\nroute add svc host/path tag \"v4\"\nwhich would then route host/path to all services with tag v4 and which you set in the manual overrides. The service would still register urlprefix-/path but since host/path is more specific it would always be chosen.\n. and 1-2 min startup time: wow ...\n. This sounds like a cool feature and I think someone requested something similar before. One approach I can think of is to build a combined routing table from multiple consul instances but make fabio prefer local services. Then you could decide whether to load balance across AZs or use this for fault tolerance. Might even be useful to have a weight parameter in there like send N% of traffic to other AZs.\n. @dsolsona I think that goes in the right direction. \n. One of the things I have in the works is splitting the registry into a kv and multiple discovery modules. This would allow you to configure multiple consul discovery instances (and kubernetes, docker, ...) all at the same time and the combination of them generates the routing table. I think this should solve this problem. @madeddie feel free to improve the POC but be aware that it might not get merged. In any case it could serve as a good basis for the discussion.\n. Indeed. \n. @erikvanoosten Just use Status\n. Could you please rename the field in the config struct to ServiceStatus? Then it is in line with the config parameter and the rest of theServiceXXX fields in the Config struct. Leave the function parameters at status. Then we're good. Sorry for bothering again. Should have seen this yesterday.\nBTW, is there a way for me to amend this change like in gerrit so that I don't have to bother you with this?\n. Also, no need to squash the commits beforehand. I can do that in github now\n. It is on the list of things to do. I'll poke the colleagues who are working on this.\n. No not yet. The discussion is around how to implement that without having shared state between multiple fabio instances. I think this would also require #111 to be able to express what the limits are per route and how to react to them.\n. This is picking up some more steam so I'd like to state where the issues are IMO. For this, I'd like to have the discussion on how to implement this first before we jump into pull requests. \nIMO, there are two main issues:\n- There is currently no way to express a rate limit in fabio. For this the config language needs to change and the route tags (see #111) need to change as well. This would pave the way for a whole lot of other things as well so this might end up in a separate ticket or as a subtask of #111.\n- The implementation should be pluggable to test different approaches just like with the route matcher. Ideally, we start out with a stateless approach where each fabio instance decides by itself whether or not to block a given client. It can then inform the others (e.g. via consul) that a certain client has been blocked and until when. This eliminates the need for a shared state which would have to be hit on every request. \nLets use this as a starting point for the discussion and see where this leads us.\n. Shouldn't this work by just setting the Accept-Encoding: gzip, deflate header? Can you explain a bit more what you're after?\n. @tanuck so you want fabio to inject the Accept-Encoding header into the outgoing request?\n. @tanuck Sorry, I don't get it. Isn't that exactly the behavior of the net/http library? The browser sets the Accept-Encoding header and fabio compresses the response sent back to the client? I'm sure I'm missing something here. Could you provide an example request/response from/to fabio and from/to upstream service?\n. @tanuck I think I get it. You want some responses to be compressed independent of whether the browser has requested compression, i.e. text/css should always be compressed even if the browser did not send the Accept-Encoding header.\n. @tanuck ah, I think the penny finally dropped. I was under the impression that the Go std lib already does this but it looks like it doesn't. The DisableCompression applies only to the client AFAICT. In that case I'll add it. Shouldn't be a big issue.\n. I'll let you know when I have a patch ready. For now this needs to be a global option since I don't have a way to express this on the routes yet. \n. @smancke any objections if I incorporate your code with proper attribution? License is MIT.\n. @smancke just read your first comment again where you're ok with this. \n. I've finally found the time to implement this. I've mostly taken your code @smancke and replaced only the testify/assert framework with my own 10-liner since I didn't want to pull in testify/assert + dependencies just for this. The other change is that the list of compressible content types need to be configurable and since we need to do prefix and postfix checks (e.g. everything ending on +json) I've opted for a regular expression in proxy.gzip.contenttype which describes the content types. I still need to implement an integration test that checks that it actually integrates properly. Feel free to test.\n. @numard If this can wait until the end of next week then I have the perfect thing to work on while I'm at your office. Should be in on Friday, 28 Oct and the week after.\n. Merged.\n. Sounds like an interesting approach. ipvs works only on Linux but there should be other FW solutions for FreeBSD, Solaris and Windows as well.\n. @robholland The patch should fix it. Can you test it?\n. Merged to master\n. I need to dig through the Go source a bit to understand what the different ClientAuthType values do. They don't look like flags to me which can be combined at will. \nAlso, I don't see how I could request a cert for authentication after I've seen the SNI header. I have to set the client auth policy on the connection. \nI think I would need to request a client cert for every connecting client and then determine later whether that matches the server name. However, I'm not sure what clients will do who are asked to provide a client cert but then don't. \n. @kivoli I am wondering whether the recent patch for #1 would solve your issue in a different way? With this patch fabio allows full end-to-end encryption with dynamic routing by inspecting the SNI header and routing accordingly. \n. @kivoli are you still interested in this?\n. OK, then I'll have another look at this.\n. You have two options:\n1. All services register their specific routes, e.g. jack urlprefix-/api/a, urlprefix-/api/b and for john urlprefix-/api/c\n2. You register one service with /api and the other ones with their specific routes. This makes sense if hack has urlprefix-/api/a-x and john has only urlprefix-/api/z\n. Also, path stripping is not implemented right now. See #44 So if the external URL is http://host.com/john/api then your service needs to register AND respond to /john/api\n. Duplicate of #44 . Sounds good. I'll see what I can do.\n. @robholland The patch I've uploaded should do the trick. \n* Add 'noroute' counter for requests to non-existing routes\n    * Add 'http.status.xxx' timer for responses with a specific status code\n    * Add 'ws.conn' counter for counting number of open websockets\nI'm a bit torn by keeping track of all status codes since this code is in the hot path. The generic implementation has to create the metric name and lookup the timer for every request which means 1-2 allocs and accessing a (global?) lock. \nA possible optimization would be to limit the number of status codes fabio keeps track of and make that configurable. Then I can pre-alloc the timers and don't have to look them up. \nIf it is easy for you to run a load test to see whether that makes a difference then that would help a lot. I'll see what I can do on our end. For now, I've opted for the more useful implementation but I'll merge this after I've seen some numbers. \n. @robholland No problem. I think this one has enough value. I'll run this in our environment first to see how it behaves. Let me know if/when I can help again.\n. Rebased this on top of #147 \n. Merged to master.\n. Yes. There shouldn't be any implications other than the config management. I'd only ask you to base your changes on the 1.2 branch since I'm merging that shortly. \n. @robholland I've added support for Riemann metrics but the driver I've found (github.com/pingles/go-metrics-riemann) pulls quite a lot of baggage. Did you have a different driver in mind? In any case it would be cool if you could test that.\n. Then I'll leave this here until someone else wants this. It isn't a big deal to merge but the deps are a bit dated ...\n. If someone else wants this then please +1 \n. Rebased this on #147 \n. Rebased on master.. Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. You should be able to register your service under https://mydomain.com as long as fabio can resolve that name to 1.2.3.4. From your setup I'm assuming that you are forwarding to an HTTPS backend. I've never tested that. \n. Yes, #1 will fix that.\n. @discobean #1 has bee merged to master and is in 1.3. Can we close this one?\n. Fixed in 1.2rc4\n. :) no worries. Contributions are very welcome. \nSSE vaguely rings a bell but very, very far in the back of my head. This looks simple enough but I just need to figure out how to expose this. Let me read up on SSE and determine whether I can make this automatic by detecting it through the Accept header (like Websockets) or whether there is some other mechanism. I'll add this to the list of things that need to be configured through #111 \n. @madeddie: Since github doesn't allow me to make changes to your PR I've created a new one which makes the option configurable and just extends the existing HTTP handler. Could you please test this by checking out this branch and running go install? It should behave the same way as your patch as long as you configure the proxy.flushinterval to a value > 0s.\nOTOH, I'm not sure if for SSE requests there should always be a non-zero flush interval since it otherwise doesn't seem to work. Need to think about that.\n. Added attribution to your PR.\n. I think I'm going to change the behavior which makes SSE work out-of-the box, e.g. set a default flush interval for auto-detected SSE connections. fabio's goal is to be zero-conf. Will do a bit more digging if a 1s flush interval for SSE connections is a sane default. Opinions are welcome.\n. I've set the default to 1s and merged it to master. \n. @hamann Since the only difference in behavior is the FlushInterval to be non-zero I fail to see how this would work? \nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_proxy.go#L133-L139\nWhen the response comes back I can inspect the headers but then the request is handled and the response is returned. Furthermore, if the FlushInterval is not set then you may have to wait for the full response to arrive before you can even see the response headers. \nThere is no way to keep state between requests. Also, your next request may end up on a different fabio instance.\nWhat is preventing you from setting the Accept header?. Thanks. I'll have a look.\n. @beyondblog I had a look and here are my comments:\nI like the approach of creating a list of functions which create the log line depending on the format. The implementation is abusing the types a bit and makes too many allocations by using string concatenation instead of a bytes.Buffer from a sync.Pool\nI'd replace the types with something like this:\n```\ntype value func(w io.Writer, t time.Time, r *http.Request)\nvar values = map[string]value{\n    \"$remote_addr\": func(w io.Writer, t time.Time, r http.Request) {\n        w.WriteString(r.RemoteAddr[:strings.Index(r.RemoteAddr, \":\")])\n    },\n    \"$time\": func(w io.Writer, t time.Time, r http.Request) {\n        w.WriteString(t.Format(time.RFC3339))\n    },\n    \"$request\": func(w io.Writer, t time.Time, r *http.Request) {\n        w.WriteRune('\\\"')\n        w.WriteString(r.Method)\n        w.WriteRune(' ')\n        w.WriteString(r.URL.Path)\n        w.WriteRune(' ')\n        w.Write(r.Proto)\n        w.WriteRune('\\\"')\n    },\n}\nvar pattern []value\n```\nIn addition, I'd use a sync.Pool to re-use the buffers since this code sits in the hot-path. \n```\nvar BufSize = 1024\nvar pool = sync.Pool {\n    New:func() interface{} {\n        return bytes.NewBuffer(make([]byte, 0, BufSize))\n    },\n}\nfunc logger(w io.Writer, format string, t time.Time, r http.Request) {\n    b := pool.Get().(bytes.Buffer)\n    b.Reset()\n    for , p := range pattern {\n        p(b, t, r)\n        b.WriteRune(' ')\n    }\n    b.Truncate(b.Len()-1) // drop last space\n    , err := w.Write(b.Bytes())\n}\n```\nI'd also drop the lazy pattern parsing and prefer an Init() function which parses the pattern and returns an error. This way you save a nil check on every request.\nThen, I would not use a log.Logger for the output since you are already creating the full log line including time stamp. Just pass in an io.Writer.\nI am also not sure if fabio should write the access log to a file. The normal log is written to stderr which means you need to capture and redirect it anyway. fabio should also be run under a supervisor which restarts it (daemontools, systemd, supervisor, ...) so that you could redirect the output to a file and let someone else handle log rotation. What if you want to ship the access logs via rsyslog over the network? What if fabio runs in a docker container. For now I would just send them to stdout which would save another allocation since you can then write the content of the buffer directly to stdout instead of converting it to a string first.\nproxy.log.enable is redundant. proxy.log.file.path should be named proxy.log.target and should default to empty which disables access logging. The other option should be stdout. \nI might also drop the $ from the format variables since it doesn't serve any purpose but it might increase readability. \nI might want to have a look at the speed of time.Format(time.RFC3339) and check if a special implementation would be better. Again, keep in mind that we're driving fabio with a couple of thousand requests per second and adding lots of allocations to every request will just put more pressure on the GC. \n. Looks better. I've added some comments. Please drop the enabled flag since it is redundant. If you don't want to log you should not have a logger in the first place. I'd also move the logger creation into the main function since it can FATAL and then inject it into the Proxy.\n. @beyondblog I think a logger package is a good idea. Maybe like this?\n```\npackage logger\nvar BufSize = 1024\ntype value func(b bytes.Buffer, t time.Time, r http.Request)\nvar values = map[string]value { ... }\ntype Logger struct {\n    // p stores the log pattern as a list of value functions\n    p []value\n// mu guards w\nmu sync.Mutex\n\n// w is the log destination\nw io.Writer\n\n}\nfunc (l Logger) New(w io.Writer, format string) (Logger, error) {\n    if w == nil { return nil, nil }\n    p, err := parse(format)\n    if err != nil { return nil, err }\n    return &Logger{p, w}\n}\nfunc parse(format string) ([]value, error) {\n    var vv []value\n    for _, f := range strings.Fields(format) {\n        v := values[f]\n        if v == nil { return nil, fmt.Errorf(\"invalid log field %s\", f) }\n        vv = append(vv, v)\n    }\n    return vv, nil\n}\nfunc (l Logger) Log(t time.Time, r http.Request) {\n    b := pool.Get()\n    b.Reset()\n    for _, v := range l.p {\n        v(b, t, r)\n        b.WriteRune(' ')\n    }\n    b.Truncate(b.Len()-1) // drop last space\n    b.WriteRune('\\n')\n    l.mu.Lock()\n    l.w.Write(b.Bytes())\n    l.mu.Unlock()\n    pool.Put(b)\n}\n```\nCould you also add some table driven tests for the value functions and the parsing? I usually write them like this:\n```\nfunc TestLog(t testing.T) {\n    ts := time.Date(2016, 1, 1, 0, 0, 0, 0, time.UTC)\n    tests := []struct {\n        req    http.Request\n        format string\n        out    string\n    }{\n        {},\n        {&http.Request{Host: \"abc.com\"}, \"req_host\", \"abc.com\"},\n                ...\n    }\nfor i, tt := range tests {\n            b := new(bytes.Buffer)\n    l, err := logger.New(b, tt.format)\n            if err != nil { t.Fatalf(\"%d: got %v want nil\", i, err) }\n            l.Log(ts, tt.req)\n    if got, want := string(b.Bytes()), tt.out; got != want {\n        t.Errorf(\"%d: got %q want %q\", i, got, want)\n    }\n}\n\n}\n```\n. Apologies to the watchers for spamming you with code-review comments. I'm used to the gerrit workflow where all comments get published in one go.\n. @beyondblog I've taken your PR and refactored it a bit since the logger is sitting in the hot path and I'd prefer it not to allocate memory since that would put pressure on the GC. \nUnfortunately, I still haven't figured out how to collaborate on PRs the same way as it is possible to do this on gerrit. Therefore, I've created a new branch, squashed your commits and rebased them on master and added my cleanups on top of them. If you know how to do this better on GH then pls let me know.\nHere is what I did:\n- Add a benchmark and added some comparisons\n- Use bytes.Buffer instead of io.Writer so that I can use the WriteXXX methods directly\n- Inlined all calls to fmt.Sprintf() and time.Format() to avoid allocations. For this I've written a custom atoi function which does not alloc. \n- I've added more tests to cover all log fields and I am not sure if the way this is currently implemented yields to the correct results. However, I was focussing mainly on having the tests and the benchmarks and not on the correctness of the tests.\n```\nbefore\nBenchmarkLog-8   1000000          1807 ns/op          80 B/op          6 allocs/op\nafter\nBenchmarkLog-8   2000000           919 ns/op           0 B/op          0 allocs/op\n$ benchcmp 0-baseline.txt 3.5-inline-time-format.txt\nbenchmark          old ns/op     new ns/op     delta\nBenchmarkLog-8     1807          919           -49.14%\nbenchmark          old allocs     new allocs     delta\nBenchmarkLog-8     6              0              -100.00%\nbenchmark          old bytes     new bytes     delta\nBenchmarkLog-8     80            0             -100.00%\n```\n. Yeah, it's still on my plate but I got sidetracked. Without Fabio doing the logging you've got only two options. Either your apps do the logging or you put another proxy in front of Fabio. However, this won't provide you with the instance it got routed to. \n. @roman-gliffy FYI, #80 is tracking this and I've got a patch ready for testing. Should be merged soon.\n@rokka-n The patch also supports logging the upstream server.. @aldarund I am sorry to hear that. \nconsul.addr has been deprecated and replaced by registry.consul.addr in commit 5250bac in adding support for issue #12 - multiple backends and went live with release 1.1 on 18 Feb 2016. Since then your log should have contained the following output:\n$ ./fabio -cfg fabio.properties\n2016/07/24 20:16:38 [INFO] Version 1.1 starting\n2016/07/24 20:16:38 [WARN] config: consul.addr has been replaced by registry.consul.addr\n2016/07/24 20:16:38 [INFO] Runtime config\n...\nOver the last five months I've released 6 more releases (1.1.1 - 1.1.6) and four RCs for 1.2 which all contained the same warning. \nAlso, https://hub.docker.com/r/magiconair/fabio/tags/ lists all fabio versions up to 1.0.2 including the latest RCs for 1.2 in addition to latest. You can refer to a specific version as follows:\n```\ndocker pull magiconair/fabio:\ne.g.\ndocker pull magiconair/fabio:1.1.6-go1.6.2\n```\nUsing latest has some risks since you assume that nothing will break or change between versions. \nI do my best not to break things for one to prevent situations like yours since that clearly does not make people happy. But also because we are using fabio in our production environment. Bringing down a site like marktplaats.nl because of an upgrade that contains an edge case I've overlooked would be too dangerous. That's why we pin our versions per environment and roll out newer versions in our test environments and on our laptops first. \nSince most of the development work is currently shouldered by me, I'm human and make mistakes I don't feel that I'm in the position to give a lifetime backwards compatibility guarantee like the Go team for Go 1 for example since that would prevent me from removing anything that has become obsolete over time. Some design decisions I made turned out to be too narrowly focussed. They made sense at the time but don't fit when requirements changed. I want to be able to change things. \nAlso, I don't control packaging or how and when people roll-out fabio in their environment. I don't control how they stay informed, whether they check the CHANGELOG or Twitter.\nCombine this with wanting to change things means that I can only depend on fabio users following best practices and a defensive approach when using fabio in their own environment. \nI think your approach of running latest on your production site without testing it first is a bit reckless. With this you're destined to get burned at some point.\nHowever, I should have probably mentioned the removal in the CHANGELOG and announced it beforehand instead of just dropping it after a couple of months; although, I'm not sure if that would have helped in your case. \nI'm open for suggestions on how to handle deprecations of features, config options and behavior in the future.\n. At the time I've decided to rely on log messages only for deprecation warnings. Maybe fabio is too stable or doesn't get restarted often enough for people to notice. \n. I am going to close this one but feel free to comment for further suggestions.\n. @jamessammut Is there anything in the logs of either fabio or rancher? I've just tested fabio with websocket support with the included demo/server -prefix /echo -proto ws and demo/wsclient and that works just fine. \n. @jamessammut there is no such thing. Might be worth adding. The question is if it works with an older version but not with the most recent version then what has changed? Can you capture the requests with tcpdump and/or WireShark before and after fabio? Maybe fabio 1.2 is sending something different that makes rancher behave that way. \n. @jamessammut I am going to close this ticket for now until there is more evidence pointing towards fabio. In that case please comment or re-open (not sure if you can but I will).\n. @jamessammut Best thing would be to collect some tcpdump logs from both sides of the fabio connection. That might tell something.\n. Closing again since there is no feedback for 4 weeks. Feel free to re-open when new data arrives.\n. This is really strange since fabio just opens up a raw TCP proxy between the two endpoints for websocket connections. First step would be to look at the connection before and behind fabio with ngrep on an unencrypted connection. . https://github.com/fabiolb/fabio/blob/master/proxy/http_proxy.go#L107-L114\nand\nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_raw_handler.go#L18-L67. I didn't expect the problem to go away but now we can compare what is sent to fabio and what fabio sends to rancher.\nBTW, -W byline formats the output by line.. Could you also capture with -s 1520 to make sure the entire body is captured since this looks truncated. I need to see the full request. Also, I'm assuming right now that the incoming request to fabio works on rancher unmodified.. These can't be the same requests. Look at the cookie and the websocket key.\nThese are the formatted requests (headers sorted alphabetically for comparison):\n```\nbefore fabio\nGET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1\nAccept-Encoding: gzip, deflate, sdch\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4\nCache-Control: no-cache\nConnection: Upgrade\nCookie: PL=rancher; token=Y6APWTUxqxMwVf1TDPq38fQ2HzRKmP9UFbzBaY7D; CSRF=E84259568E\nHost: rancher.x.x.x\nOrigin: http://rancher.x.x.x\nPragma: no-cache\nSec-WebSocket-Extensions: permessage-deflate; client_max_window_bits\nSec-WebSocket-Key: O1tgYw0qtqmj12P0AiFyCA==\nSec-WebSocket-Version: 13\nUpgrade: websocket\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36\nafter fabio\nAccept-Encoding: gzip, deflate, sdch, br\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4\nCache-Control: no-cache\nConnection: Upgrade\nCookie: _ym_uid=1480687797947545909; _ga=GA1.3.1084697215.1480687797; PL=rancher; token=LoxoWkymzCuwZ3NrH5SccmGKFrE6U4PHxVkKdHNc; CSRF=55CD8433FA\nForwarded: for=10.2.24.253; proto=wss; by=x.x.211.37\nHost: rancher.x.x.x\nOrigin: https://rancher.x.x.x\nPragma: no-cache\nSec-Websocket-Extensions: permessage-deflate; client_max_window_bits\nSec-Websocket-Key: MtZ0QxeTQSdQXF87guU6HQ==\nSec-Websocket-Version: 13\nUpgrade: websocket\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36\nX-Forwarded-For: 10.2.24.253\nX-Forwarded-Port: 443\nX-Forwarded-Proto: wss\nX-Real-Ip: 10\n``. Try withngrep -q -d  -W byline /v2-beta port `. The delta is that fabio adds some headers (expected) and that the header names are normalized (go stdlib behavior) which could trip rancher up. Other than that there is no difference. \nTry sending the request with telnet to rancher (just copy the lines into a text file, select all and then paste. Make sure there is a newline at the end). Then try the same with the changed header names.\n```\nSec-WebSocket-Version: 13.\nSec-WebSocket-Key: lGEnYPVpBoP7o5autfutNQ==.\nSec-WebSocket-Extensions: permessage-deflate; client_max_window_bits.\nvs\nSec-Websocket-Extensions: permessage-deflate; client_max_window_bits.\nSec-Websocket-Key: lGEnYPVpBoP7o5autfutNQ==.\nSec-Websocket-Version: 13.\n```\nIf that's not the problem then it is indeed what is in the added headers. A simple way to test this is to make the request with the X-Forwarded-Proto header set to http for example since fabio won't overwrite it if it is set:\nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_headers.go#L47-L49\nForwarded: for=10.2.24.253; proto=ws; by=x.x.211.37.\nX-Forwarded-For: 10.2.24.253.\nX-Forwarded-Port: 80.\nX-Forwarded-Proto: ws.\nX-Real-Ip: 10.2.24.253.\n. This seems relevant: http://stackoverflow.com/questions/2406518/why-does-javas-url-class-not-recognize-certain-protocols. Use java.net.URI instead of java.net.URL.\n```java\nimport java.net.URL;\nimport java.net.URI;\nclass Playground {\n    public static void main(String[ ] args) throws Exception {\n        // URL url = new URL(\"ws://foo.com/bar\"); // throws MalformedURLException\n        URI url = new URI(\"ws://foo.com/bar\");\n        System.out.println(url.toString());\n    }\n}\n```\n. @ket4yii can you put a link to the rancher issue you've opened here?\nSince X-Forwarded-Proto isn't really specified I'd say lets do what works. The Forwarded header though is specified and there is no such restriction: https://tools.ietf.org/html/rfc7239#section-5.4 . I've pushed a change. Could you test whether that works for you?. ok, I'll merge it soon then. Thanks for testing!. It is on master. You can build it yourself for now. . I'll have a look.\n. I don't think this is a hard requirement. I've created the fabio token as an orphaned token which apparently requires these privileges. I'll check what the best approach is and make this configurable if necessary. If you have suggestions on how to set this up feel free to comment.\n. The rationale is that you provide a short-lived (e.g. 30s) token to fabio during startup so that fabio could generate its own token which it continues to use and extend as long as it is running. Otherwise, anybody who can inspect the environment via the /proc filesystem or the command line arguments would be able to re-use the token. \nHowever, it is perfectly possible that I misunderstood something and that this is achievable without creating an orphan token. I remember having a discussion on the Vault approach fabio takes with @jeffrai - the Vault maintainer. I'll dig into the docs again.\n. I think I prefer the approach where fabio gets the ability to create and manage its own token since you then don't have to worry about renewals and visibility. In your approach you'd still need a short-lived token to bootstrap fabio only for fabio to re-use the same token and move token renewal outside of fabio. \nOne question is whether that requires the creation of an orphaned token. Another is what happens when the parent token expires? This should invalidate the child tokens as well. And I also need to check whether I deal with the expired token the right way, i.e. invalidate the cert store instead of treating it as \"connection error\" which means that the certs remain valid. \nIn our environment we don't restart fabio for days, weeks or even months. It just runs and we forget about it. \nAs far as I recall the conversation with @jeffrai during HashiConf EU he suggested the approach of the short-lived startup token. But at that time Vault 0.6.0 was just out and the guy was quite popular. Not sure if we had enough time to talk about it in-depth.\n. Hmm, this won't work. If you pass a short-lived token to fabio and create a renewable child token with it then the child will expire when the parent expires unless I'm missing something. \nI've created a script which simulates the behavior: \nhttps://gist.github.com/magiconair/d0a5f8bf8605f1c21064132edd7344e1\nHow should this work?\n. Possibly. OK, then fabio would get a token, unwrap it and renew it on a regular basis. I think that makes sense. \n. I think I have something working but this needs a bit more refactoring since the current code tries to unwrap the token twice which won't work. \n. @far-blue I've pushed a patch that changes the way fabio integrates with vault. It will use the provided token instead of creating a new one and will transparently unwrap a wrapped token. fabio still tries to refresh the token on every refresh cycle but it will no longer fail if it can't. However, it logs a warning on every failure which has the potential of filling up the logs quickly if provided with a non-renewable token. I've also updated the integration test to use a policy to limit the required capabilities. \nI think this is starting to look better than the original approach but I need to test the edge cases a bit more. It would be great if you could test this setup.\nThe required policies are (assuming that you configured your cert store with secret/fabio/cert):\n```\n  path \"secret/fabio/cert\" {\n    capabilities = [\"list\"]\n  }\npath \"secret/fabio/cert/*\" {\n    capabilities = [\"read\"]\n  }\n``\n. I would have assumed that as well but the test registers this policy and refreshes the token on every cert refresh cycle. Since that didn't cause an error maybe that is included in thedefaultpolicy. Enjoy your holiday :)\n. @far-blue any chance looking at this?\n. That's good news. I'll add some more logging to the code. The only concern is to flood the logs but I'll check what can be done about that. TheRefreshvalues are atime.Durationwhich means they are inns. Default is3s`. Might be a good idea to or render them as string.\n. The refresh interval and token extension interval solve different problems:\nThe refresh interval is the time it takes fabio to detect a certificate for a domain it did not have before. It also determines how quickly fabio will act upon a deleted certificate or a revoked token.\nThe token extension interval protects (or is supposed to protect) fabio from intermittent failures of vault. fabio could fetch new certs lazily but at this moment I'm concerned about thundering herd issues during startup. Also, I don't want fabio to shut down because it cannot reach vault.\nI think the latter part could use some more thought since both the cert and the token have a TTL which fabio could honor. But even then you'd want fabio to honor a revoke operation quickly. \nRegarding refresh: as long as vault does not offer a way to notify a watcher for changes (like consul) then I don't see an alternative to constant polling. Configuring certificates in an external store becomes interesting if you have too many or if they change too often to configure them manually. But then you want fabio to react as soon as the cert is there/gone just like with the services.\n. yes, I agree. That would be a saner implementation. The question is whether the added complexity will have any benefits. The current implementation is straightforward, simple and robust. Since it always fetches everything there is no doubt on what the current state is. Since it always refreshes the token I don't have to have another timer for this. \nAlso, I don't consider polling every 3s rapid. Even with 10 concurrent fabio instances you're only generating 30 req/sec which should be cheap and come from memory (but may not now that I think about it since you may be using an external storage like S3). We're easily handling 1000 req/sec on a single service for a cached response with < 1ms latency and not a lot of CPU load. \nPreferably, I'd like to have the lazy fetching implemented at a higher level so that this doesn't become something vault specific. I'll think about this and check on how to refactor this maybe for a 1.3 release. Lets first make sure that the behavior is correct, is generally usable and doesn't kill your infrastructure. Then I can make it more efficient in the next iteration.\n. No, this is a service that is delivering its own cached data. At any rate 30 req/sec don't seem a lot but that doesn't change the validity of your argument. I'll see what I can do to reduce the impact. For now, just increase the refresh time or set it to 0 to disable it. \n. Well, that's emberrassing :) yes it does. I'll update the docs.\n. yes. It's next on the list. Time is scarce right now. I'll merge it soon.\n. Merged to master. Lets deal with the fallout in subsequent tickets. @far-blue really appreciate your help and dedication on this one!\n. Updated the wiki with the new behavior\n. Not yet. I'll check what it takes to add that.\n. I'm curious how this would work independent of vault since you could mimic this with a script or LetsEncrypt or something else. The current CertSource model is that certificates exist and that fabio just picks them up. If a cert does not exist fabio will refuse the connection. \nIn the model of a generated cert that would no longer happen unless the cert provider refuses to generate the cert.\nWho controls which certs are permissible? Can fabio just generate any cert? What if I announce urlprefix-www.google.com/ ?. Yes, a PR would be welcome. Generated certs need to be cached for as long as they're valid (or TTL/2) since this method is called per connection. I assume the base path defines the root domain for which you can generate certs. I think that's fine but you should take into account use-cases for multiple domains.. The question is whether you want to allow one or all domains in the pki or whether you want to be able to restrict it to some (e.g. foo.com and bar.com but not google.com for example). I don't know how to achieve that and whether that's something you can do within the vault config that fabio just has to send or whether there needs to be something to be done in fabio and/or whether we need to extend the config DSL. Just keep that in mind when creating the PR, please.\n. SIGQUIT or SIGTERM should do this. Let me check whether this is a regression. How are you shutting it down?\n. Looks like a shutdown race. I'll try to make it more robust and provide a patch. Can you work with that and build a fabio binary yourself or do you need a full Docker container to test this? \n. Actually, I don't think there is a race. startListeners blocks until it gets a shutdown signal which is triggered by signal.Notify(sigchan, os.Interrupt, os.Kill, syscall.SIGTERM). That closes the quit channel which returns startListeners and then triggers registry.Default.Deregister() as the last call. And that one waits for completion, AFAICT. \nYou should have the following log output:\n2016/07/26 16:50:53 [INFO] Updated config to\n2016/07/26 16:50:53 [INFO] consul: Registered fabio with id \"fabio-LM-AMS-00963965-9998\"\n2016/07/26 16:50:53 [INFO] consul: Registered fabio with address \"10.249.126.25\"\n2016/07/26 16:50:53 [INFO] consul: Registered fabio with tags \"\"\n2016/07/26 16:50:53 [INFO] consul: Registered fabio with health check to \"http://[10.249.126.25]:9998/health\"\n2016/07/26 16:50:53 [INFO] consul: Health changed to #3360\n2016/07/26 16:50:54 [INFO] consul: Health changed to #3361\n2016/07/26 16:51:00 [INFO] Graceful shutdown over 0\n2016/07/26 16:51:00 [INFO] Down\n2016/07/26 16:51:00 [INFO] consul: Deregistering fabio\n2016/07/26 16:51:00 [INFO] consul: Health changed to #3363\n. I think by moving the deregistration into a defer block should take care of a stale registration if fabio fatals during startup but after registration. I'll have a look.\n. Yeah, that's the edge case. If fabio FATALs after initBackend it does not clean up after itself. defer won't help since FATAL calls os.Exit(1) I'll see how to improve that.\n. I've pushed a patch which seems to address the issue. log.Fatal has been replaced with exit.Fatal which waits until all registered exit handlers have been called and then exits. The line numbers of the last log lines should be off and I need to think about the approach in general a bit more but it would be great if you could test it.\n. Try this:\nmkdir ~/gopath\nexport GOPATH=~/gopath\ngo get -u github.com/eBay/fabio\ncd ~/gopath/src/github.com/eBay/fabio\ngit checkout issue-136-always-deregister-from-consul\ngo build (or make)\n./fabio\nIf you are on OSX and need to build a linux/amd64 binary run make linux\n. OK, then I'll let that rest for a couple of days. Helps me to reason about the approach a bit longer. If nothing comes up then I'll merge it. Looking at #134 now.\n. I've had a look at it again and think the approach is sound. I've added a test for the exit behavior and made sure that exit.FatalF can be called concurrently. Just merged this to master.\n. Good way to test this is ./fabio -proxy.addr 1.2.3.4 assuming that you don't have 1.2.3.4 on that machine. \n. Health check disappears with the service since you can't register a health check without a service.\n. No, in that case fabio will not de-register itself but consul will mark fabio as down as the health check fails. Just restart fabio or clear the registration manually. If you use consul for things other than fabio (e.g. service discovery between your services) then this is not a problem. I also don't recall consul crashing on us either. \nHowever, after having fabio in production for a year on several fairly heavily loaded public websites with tens of fabio instances and hundreds of micro-services we literally never had that happen with any of the releases (knock on wood). This doesn't mean it can't happen but this is not the kind of thing you have to deal with on a regular basis and it is fairly easy to fix if it does happen.\nI've come to call fabio the piece of infrastructure we forget it exists.\n. The usual problem for this is the missing health check. \n. :) no worries\n. The current behavior is to serve the first certificate if none matched since this matches the TLS behavior of the Go stdlib. I can add that. Shouldn't be difficult.\n. @far-blue I am wondering whether the fallback option is a property of the cert source (proxy.cs) or the listener (proxy.addr)? And also, whether it should be fallback with default true or nofallback with default false. Do you have an opinion?\n. @far-blue I tend to agree on both. The only issue with fallback is that now you have to set it everywhere in the code to get the default behavior which goes against the idea that empty structs should be useful and should encode the default behavior. \nI can't think of a better name which expresses this in a different way. exactmatch does not capture it and would also need a reference to the certificate matching if configured in the context of the listener. What would this mean?\nproxy.addr=:443;cs=demo;exactmatch=false\n. I like strictmatch. No negative logic but still a default value of false.\n. Still need to add a test for getCertificate() which does the actual work but that patch should do the trick.\n. @far-blue thx for your help\n. I'll sleep over the strictmatch name and if nothing comes up I'll merge that tomorrow or the day after.\n. Merged to master.\n. Looks good. I'll fix the copy/paste typos in the properties and cmd line args.\n. So far questions are being asked in the github issues. There is a gitter.im link but there isn't much traffic. I'd like to think that this is because fabio just works but I don't know. Might be time for a mailing list/Google group. In any case feel free to ask your question right here and I'll do my best to respond quickly.\n. Try setting a service id.\n. and make sure it is unique per instance. Typical is helloworld-host:port\n. No worries. You are not the first one with this problem. It is either the missing health check or the missing/non-unique service id. That's why these things are also the first items in the README and Quickstart ;)\n. Closing for now. Feel free to re-open or to ask more questions.\n. @lennart That's a good point. If I would use the service id instead of the name then it would be more difficult to implement weighted routing. I could also update the parser to allow services with names and then quote the name. . @lennart Updated both the Quickstart and the README.. Added #373 to track this.. :)\n. @pdoreau I've added a section about registrator and docker compose to https://github.com/eBay/fabio/wiki/Features#docker-support. Could you and @devsprint have a quick look whether that looks OK?\nRe AWS demo file: I've used this only to spin up fabio on AWS to debug a client cert auth problem and for nothing else. Feel free to send a PR if you think this would be useful. \n. @devsprint Could you provide an example for this? I can't seem to find this in their (quite sparse) documentation or I'm just dense.\n. Thx. I've updated the https://github.com/eBay/fabio/wiki/Features#registrator example accordingly.\n. Fixed\n. ok, closing this one now. Feel free to comment or to re-open.\n. @far-blue good to know. I'll see that I can wrap up the vault change soon. It's a time issue and we finally have some summer sun. Not sure for how long though ...\nfabio is stateless therefore it doesn't matter which instance you use. Adding an option to register the admin ui prefix in consul itself sounds interesting.\nMy concern is that some users will just blindly add /admin to their regular domain essentially exposing the admin ui on the net - which would create a nice open reverse proxy for everybody to use. This is too easy to get wrong. Maybe by setting this fabio would require configuring authentication. However, that requires that the admin ui is on HTTPS which requires that there is a listener and a cert ... (rabbit hole)\nTBH, in our experience we rarely look at the admin ui if ever. The manual overrides are the \"fixer\" tool to amend a broken deployment. They shouldn't be part of the normal workflow but maybe I'm missing something here.\n. The whole point of developing fabio was to forget about configuring the load balancer - and we do. We never touch it anymore. Our stuff just works. \nDevs are in complete control what gets routed where once their services are configured properly in consul. Therefore, you only need to look at the admin console for blue/green deployments or weighted routing which happens during larger refactorings which shouldn't happen that often I guess.\n. Released v1.2.1 just now.\n. @postwait and @maier I've moved the metrics library implementation behind an interface in the metrics/metricslib package where I've extracted the methods from the go-metrics library I'm currently using. This should make it possible to plug in any metrics library you want as long as it supports this interface. If the interface is not sufficient for what you are trying to do feel free to enhance it but keep it simple and generic if possible. Looking forward to the PRs :)\n. I think I missed a spot. The current implementation distinguishes between two different namespaces for metrics: the service metrics and the general fabio metrics (like requests). Service metrics get purged when the service or an instance disappears. This was implemented by using two different registries but that abstraction got lost with this change. I need to add that back in or make the purge code aware of what is a service metric and what isn't. Just keep that in mind when implementing your change.\n. @maier My previous approach was too complex. The whole notion of the metrics package providing two registries was somewhat broken which made the testing more complex than needed to be. I've dropped the metricslib and the gometrics package and rolled this all into the metrics package. There you can now create multiple registries each with a single name space. The main.go then sets up the two name spaces for global and service metrics. That makes it cleaner and simpler IMO but you need to change something in your code. Sorry about that. \nSupporting multiple different providers could then be implemented by adding a MultiRegistry analogous to the io.MultiWriter \n. Merged to master.\n. @maier and @postwait please file follow-up tickets for issues with the circonus implementation. This is now on master. It would be great if you could test it and let me know whether it works.\n. @maier Thanks for your help with this.\n. I've tried this myself with a free Circonus account and can see it working as well. However, I notice a lag of a couple of seconds during startup which I suspect is the authentication with Circonus. I'll check whether I can hide this somewhere. \n. Fabio acts as an HTTP/2 server but will not make HTTP/2 requests to the backend servers. Since the backend servers are usually physically close to fabio this isn't too much of a problem. \nInternet - HTTP/1.1 or HTTP/2 -> fabio - HTTP/1.1 -> server\nDoes that answer your question?\n. I'll close this for now. Feel free to comment or re-open.\n. What happens when a service or an instance of a service appears and then disappears again? Will the circonus library stop reporting metrics for this instance? That's the reason behind the Names() and Unregister() functions since they allow fabio to trim the reported metrics to the current set of services and instances.\n. OK. As for the vendored libraries: Updating vendor.json is not enough. You need to run govendor add for all libraries and check the source of the libraries in. I usually do this in a separate commit labeled 'Vendoring github.com/... plus dependencies' and then one additional commit with all the squashed changes for the issue. I can squash commits in github now but then I'd squash your changes and the vendored libs together. Could you please create two commits with first the vendored libs and then your changes? git push -f is fine.\n. Check the last three commits on master for an example.\n. Could you also update the comment for the 2nd commit to Issue #147: Add support to send metrics to Circonus. I think if you force push the branch to your repo git push -f then this won't create additional commits in the PR. GH should just replace the current PR.\n. I thinks this looks ok enough. I'll merge this manually since the config/load_test.go needs updating and there are one or two typos. Thanks for your patience with the code review. \n. @maier you seem to have forgotten to add metrics.circonus.apikey to the fabio.properties. Could you provide me with the snippet and then I'll add it. Thx\n. @maier or is this ok?\n```\nmetrics.circonus.apikey configures the API key to use when\nsubmitting metrics to Circonus. See: https://login.circonus.com/user/tokens\nThis is optional when ${metrics.target} is set to \"circonus\".\n\nThe default is\n\nmetrics.circonus.apikey =\n``\n. Got it. I'm still curious whatTestAll` is testing and how you determine that the test has passed. Could you explain, please?\n. ok, that's what I thought. This is an integration test which requires manual inspection. I'll leave it in for now but need to think about whether I would want to mock the API or check this another way. I don't  want to test the driver. \nAs a side note: I would also like to merge the change from #125 which adds a counter to the metrics registry. \n// Counter defines a metric for counting events.\n type Counter interface {\n     // Inc increases the counter value by 'n'.\n     Inc(n int64)\n }\nHow would I add this to the circonus registry?\n. OK, I just noticed that the registry methods return pointers (&cgmTimer) but the methods on the structs have value receivers. How does this even work? I guess in the current implementation it doesn't make a difference whether it is either/or but I think it should be consistent. I'll change the timer/counter methods to have pointer receivers as well (e.g. func (t *cgmTimer) UpdateSince(...)) unless you know a good reason why I shouldn't.\n. Did a manual merge of this PR to master.\n. Merged to master based on PR #150 \n. This is the default behavior of the flag package.\nhttps://golang.org/pkg/flag/#pkg-overview\n\nCommand line flag syntax:\n\n-flag\n-flag=x\n-flag x  // non-boolean flags only\n\nOne or two minus signs may be used; they are equivalent. The last form is not permitted for boolean flags because the meaning of the command\n\ncmd -x *\n\nwill change if there is a file called 0, false, etc. You must use the -flag=false form to turn off a boolean flag.\nYou must use the -flag=false form to turn off a boolean flag.\n. No worries and please keep asking if something is not clear. You're probably not the only one who has this problem.\n. Indeed ...\n. I could use some help here. I had a look a the K8s API and I can't find a way for the services to publish their prefixes like they do in tags in consul. I think deploying a consul cluster just for fabio seems a bit overkill since K8s already has a service registry. I think I could use labels but they are size restricted to 64 chars AFAIR. Services could offer their prefixes via an HTTP endpoint but that would require polling from fabio and it would not support 3rd party services. Anybody with Kubernetes experience has an idea on how to solve this?\n. @silentred Got an idea where the meta-data can be stored (e.g. host/path and other options) Couldn't find something suitable in the k8s API last time I looked but granted I didn't dig very deep. Suggestions are welcome.. @taemon1337 fabio does not store routes in Consul. You can store routes in consul or some external program. fabio generates its primary routing table from the service information in Consul.\n\nThe reason it supports the KV store is that you'd want a way to manually patch a routing table in case of a broken deployment. Or you want to add some routes to services which are not in Consul. \nTo support k8s you wouldn't need to do this. As @leprechau suggested, you just need to create a new backend implementation and implement the WatchServices function which generates the routing table in the string format, e.g.\nroute add <svc name> host/path http://host:port\nIf we can do this with a simple REST call then I'd prefer that instead of pulling in the k8s go-client. If you send me the REST call then I can help.. @taemon1337 Didn't see your earlier comment. Yes, WatchServices is sufficient. I should probably break that interface up. It is too big.. That sounds like a good idea. However, I would like to use a different templating mechanism also because I need something similar for the access log configuration from #80. I think we should just use text/template and be done with it. \nThen this could look like \n{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.{{clean targetURL.Host}}\n. @leprechau Where would this be used? \nLets try not to morph this PR into a multi-issue discussion. If there is another use-case for templates then lets open a separate ticket and collect thoughts there. Could you do that @leprechau ?\n. An empty string since I can check the templates during startup. \n. (first think, then type): yes, Execute can return an error as well. It should still return an empty string and an error which I need to log somewhere. Otherwise, your metrics get polluted.\n. @leprechau no need to apologize. See what you can come up with.\n. I think this looks good enough. I'll probably add a log line for the error you've skipped in route.go since my guess is that people will use this for strange things. It should at least log. And we need to come up with a better name than routemetricname :)\nThanks for the work. Really appreciate it.\n. @maier I've taken your changed some smaller parts since my tests were failing. Also changed routemetricname to just names. Pls have a look whether there is a glaring omission otherwise I'll merge it tomorrow.\n. Merged to master.\n. Right now you can't since fabio does not route by header. Adding this to the proxy code isn't the main issue. At present I don't have a way to let you configure this. See #111 \nThe way we're doing this - since we are taking exactly this versioning approach - is to have all services handle all versions. The content type versions should be deprecated over time anyway so ideally you might have only 1-2 versions of a given entity to support. \nDo you have this problem right now which prevents you from using fabio or are you considering this a potential roadblock for adoption?\n. Not yet, but that can change.\n. Release v1.3.1 is released.\n. @vhuang01 I think that's something for you.\n. Could you add the config from the log please and maybe the startup parameters?\n. I think I know what the problem is. I'll fix it later and push a patch. Thanks for submitting\n. I thought I had fixed that one already. The meteredRoundtripper is not checking whether the http.Response is valid before trying to get the statusCode.\n. Merged and released v1.3.2\n. @md2k I agree about the default behavior. Pls add this as an alias for the new template.\n. fabio talks to the local consul agent which you should keep running. Also, you should have multiple fabio instances running and sending traffic to them. If you have only one fabio and one consul then you have a single point of failure.\nCan you explain the problem you're having a bit more?\n. The first thing is that you need to setup a proper consul cluster, i.e. some master nodes and local agents on all the machines handling traffic. From your description it is not clear whether you have a functional consul cluster or just individual consul instances.\nI agree that fabio could be a bit smarter when the local consul agent is down but this hasn't been an issue for us. Other stuff breaks first. If you're concerned about that you could hide the consul agents behind a load balancer but I'm not aware of people doing that. Maybe someone from the community can comment?\nI need to double check but AFAIR fabio will not update the routing table when the local consul agent is down. It will just continue to serve traffic with the last known good routing table. \nSo my advice is:\n1. Setup 3 node consul cluster for the servers\n2. Install the consul agent on all the nodes pointing to the masters\n3. Install fabio on all the nodes (or just all frontend nodes)\n4. Configure your external load balancer to forward all traffic to the fabio nodes\nPlease let me know whether that helps.\n. As I've said before: we see other stuff break way before our consul agents die. As long as the setup does not change the fabio instance with the dead consul agent should still forward traffic with the last known routing table. Your monitoring should catch the consul agent failing and ideally just restart it. If the consul agent does not come up my guess is you have bigger issues since it then cannot access the consul servers or the configuration is fixed. \nYes, fabio could handle this more gracefully by trying a backup consul agent but first see whether that is a real issue on your platform.\n. Right now you can't. \n. @pangzheng If I understand your question correctly then you are asking why the fabio health check is OK if one of the registered services in consul is not OK, correct?\nThe fabio health check does not depend on the health of registered services. The fabio health check becomes not OK if fabio itself is not working anymore. If a service health check fails then fabio will not route traffic to it. \nDoes that answer your question?\n. @dcparker88 That is the current behavior since the assumption is that your setup cannot function without Consul anyway. Having said that, we could add an option to not update the routing table when consul is gone. Anyone up for a PR?. Isn't the glob matcher doing this already? Checking\n. Ah, no. This only checks globs against the path. Might make sense to extend this to the full URL. Want to work on a PR?\n. #45 has a lengthy discussion about the topic. Might be useful to dive into this first. Can I leave the investigation for this one with you for the moment? I'm a bit time constrained. Otherwise, it will have to wait a bit. \n. Fabio does not support path stripping right now. There is a ticket open for this where you can read the reasoning. I'm probably going to add this in the future but I'm going to focus on other things first. \n. I'm closing this as a duplicate of #44. Change for path stripping is in progress. See branch.. It may but I don't know. Someone else implemented the statsd support. Can you give an example ?\n. Is that compatible with the standard statsd client?\n. If they are substantially different then we can just add it as another metric provider. If they were compatible then it could have made sense to just keep one of the two. You want to try a PR or want me to work on this?\n. ok, but then you'll have to wait a couple of days since I'm reworking the the parser for the configuration to support the path stripping that people seem to really want - besides other things. \n. Not yet. Just back from vacation and digging through the backlog.. I should have some time this week. I'll wrap up the other change I'm working on and then have a look. You're up for testing?. Looks like there is an open issue on the go-metrics library to add tags support: https://github.com/rcrowley/go-metrics/issues/135 but that isn't going anywhere. \nWe need to define an option to define the tags per route. What about mtags=foo=1;bar or metricsTags=foo=1;bar?\nSince the go-metrics lib does not support tags natively at this point the best approach is to encode the tags in the key name (e.g. key#tag1;tag2) and then parse them out again before reporting the metrics. That would require forking the statsd driver so that it understands the key format.. Right now I am assuming that the tags are static per route. Is that a valid assumption?. @jippi This is #207.\nCan you explain your first statement a bit more? I'm not sure I get it. I thought I just add the #tag1;tag2 to the statsd format and that's it.. @jippi Created https://github.com/pubnub/go-metrics-statsd/pull/1 to fix #207 . @jippi and @killcity I've pushed a proof-of-concept into the branch which hopefully does what you want. You need to add mtags=tag1;tag2 to your urlprefix-/foo definitions so that they look like urlprefix-/foo mtags=tag1;tag2. \nThis is not the final code since I've hacked this into the pubnub/statsd implementation. I'd just like to check that I got the format right and that it does what it should do. Could you have a look please?. Got it. Thx. @killcity so you're also in favor of pushing the status code as a tag instead of the metric name just like @jippi suggested?\nThe main reason the change takes a bit longer is that the go-metrics library doesn't natively support tags which means that depending on the metrics backend fabio needs to report different metric names and put values into different places (e.g. service name, urlprefix, status code, ...)\nI'm mulling over adding a full metrics abstraction layer which handles this or add a handful if dogstatdMetrics statements. Not so clean but much less work. I can do the nice refactor later.. Since 1.4 is out and the TCP proxy stuff is released I think I'll pick this one up again next together with the other metrics related issues #211, #253, #126 . Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. @csawyerYumaed That sounds like an interesting idea.. I'm not sure I like the fact that the password is stored in clear in the route tags. This is stored in consul and can be accessed via the api. Storing secrets feels like abusing the tags a bit too much. Also, this has to be deployed which means it has to be in some config file. \nSecrets management is hard. That's why Vault exists. \nI'm not saying that we shouldn't offer basic auth but keeping the passwords out of the route tags would be helpful IMO.. @nmaludy Then your deployment is broken just as if you'd have different services announcing the same route. I don't think there is much you can do about this. I might see a legit use case in migrating between auth sources as long as the underlying databases are in sync. . #573 implements some form of authentication so lets close this and have requests for other auth mechanisms in separate issues.. Do these headers have static or dynamic values, i.e. does the header value depend on the request?\n. If the headers need to be dynamic I might be able to re-use the formatting language I'm using for the access logger from #80. In this case I would need to wrap the values in {} or something similar to support the ${msec}000 use case. I'll think about that.. I guess they should be configurable per route as well so this needs to become part of the urlprefix- tag options.. @jippi there is no pipeline. Generally, I pick up things that people are asking for and for which I have an idea on how to implement it. Adding a static option to add a set of headers to all requests is a no-brainer. But is that really enough? I think I have an idea on how to approach this but for this I need to understand what you need and I'd like to ask you to think a bit outside the box of your specific use-case, if possible.\nI think it is reasonable to expect that people would want to modify headers per route. The main challenge with this approach is that if different services announce different options for the same route then the behavior is undefined. As long as that is documented I think I can live with that. This problem will remain for all other features that modify a route. fabio could detect these things and log them to make detection easier.\nAlso, I'm thinking that there are three operations: set, add and del for setting, adding and deleting headers, e.g.\nurlprefix-/foo header_set=\"X-Request-Start=${time_us}\" header_add=\"Strict-Transport-Security: max-age=60; includeSubDomains\" header_del=X-Client-IP\nDoes that look like a reasonable approach?\nThis requires to first update the k/v parser to accept quoted values. Then I'd have to figure out which values would be needed and whether the access logging code could be re-used for that. Then I need to actually modify the headers.\nQuestion: Should the route header modification happen before or after the normal header mangling (e.g. X-Forward-Proto, ...). @jippi like what? fabio doesn't remove headers AFAIK, or does it?. @bkmit Can you provide a concrete example of what it is you're trying to do?. I need to think a bit on how to express that since I think I've moved myself somewhat into a corner with the config language. For example, should the header definition be part of the opts (which leads to quoting issues) or separate? \nroute add svc /foo 1.2.3.4 opts \"foo=bar baz=bang hdr='x-foo: bar' hdr='del x-foo' hdr='add x-foo: baz'\"\nvs\nroute add svc /foo 1.2.3.4 opts \"foo=bar baz=bang\" hdr=\"x-foo: bar\" hdr=\"del x-foo\" hdr=\"add x-foo: baz\"\nHow should I translate this from the urlprefix- tag which assumes every key=val pair after the path is part of opts?\nurlprefix-/foo foo=bar baz=bang hdr=\"x-foo: bar\" hdr=\"del x-foo\" hdr=\"add x-foo: baz\"\n. Why do you want to use plain HTTP on port 443?\n. OK, I figured as much.\nThe problem is that in order to distinguish TCP+SNI from HTTPS I can only look at the hostname to make the routing decision since for TCP+SNI I cannot decrypt the traffic. In that case you could just setup two listeners on fabio for two different ip addresses for the two hostnames. \n. @mildred Would the proposed solution with the two listeners solve your problem?\n. @mildred ping\n. @mildred so based on the hostname you either want fabio to pass through the encrypted traffic or decrypt it and forward it as a regular HTTP request. Is that correct?\n. Wouldn't it be simpler to just use two different ip addresses for this or is that not possible? You already have the different host names.\n. OK, but ip addresses aren't that scarce that you could not get another one or can't you? I'm just wondering whether this feature is an edge case which is solved better in infrastructure than in code. Do you know if any other proxy provides this feature?\n. What I'm saying is that if you get a second ip address for your server your problem is solved as far as I understand it since you already have two different hostnames. You just need one to point to the TCP+SNI listener and the other one pointing to the standard HTTPS listener.\n. I don't think you're leaking anything here since you're already exposing different hostnames for the different routes. So people will see that - if they care - and whether they resolve to the same or different IPs is not an issue IMO. Virtual hosting is an optimization strategy for saving IPv4 address space not an architecture style. You wouldn't request this feature if you had IPv6 or if you  had a /24 routed to your server for example.\nBut in the end this is about solving a problem. I understand now what you are trying to do and my suggestion is to get a second ip for your server and be done with it. At this point I don't see an easy way of doing this with the code I have which means I'd have to do some digging. Since there is a solution to your problem I'd rather focus on other things first for which there isn't a solution yet (e.g. access logging, path stripping, ...) I'll keep this in mind since I think it is an interesting challenge nevertheless and might be useful to accept just any protocol on a given port. \n. I've decided not to add this feature. If there are more people requesting this I might reconsider this at a later point.\n. The TCP+SNI proxy mode is a pass-through TCP proxy which uses the SNI header for routing without decrypting the connection. It decodes the first packet to look at the SNI header and then uses that to forward the raw TLS packets including the ClientHello to the upstream server. Therefore, your tomcat would need to handle the TLS negotiation as well and would have access to the same certificates. Is that what you are after?\nWhat you are trying to do should work with the normal HTTP routing and a TLS listener since fabio will decrypt the message and can look at the request. \nMaybe I'm missing something here.. @Salmondx Thanks for the contribution. A couple of comments:\n1. That sounds like an interesting feature but I would prefer a different implementation. Right now the code that gets the services from consul and the code that builds the routing table from this service list is one. What would make sense is to separate fetching services and generating a routing table from a list of services into separate pieces to make both of them configurable independently. So in essence build an internal plugin like the Picker or Matcher that builds a routing table from a list of services based on some config. Then your approach for your legacy services would just be another filter. Or we could have multiple as long as they are exclusive.\n2. I think you can solve the external nodes problem by adding static routes to consul. Just add the routes you need. This is kind of a limitation of supporting only one service registry at a time. If you could have both consul and file then you can just copy a file somewhere. \n3. I'm already working on the path stripping. \nTaking these things into account I won't merge the change as is. Also, because it combines several features into one larger change. If the patch is working for you right now feel free to use it and I can refactor the code as described so that you can build a filter. Or you can provide some code if you want. Separate PR please.\n. As for 2. why don't you register them in consul on deployment or write a small tool which manages the registration? That seems like the Right Thing (TM) to do instead of patching the load balancer. This would also solve your first problem.\n. So please wait with another PR until we've settled on an approach.\n. Can't you just register a TCP check or a simple script that performs a function that concludes that the service is up? You don't need to have a specialized /health endpoint to perform the health check.\n. Sorry, missed the fact that there are several services on a single node. So the underlying problem is that fabio is looking for passing services in consul but your services do not have a health check. fabio has an option to specify the consul service status but that may be too broad. registry.consul.service.status. You could set this to passing,unknown\n. How do you know your service is up then?\n. Hmm, this registers an external service on my local consul including tags and fabio integration. What am I missing?\n```\nregister the service\n$ curl -i -XPOST -H 'Content-Type: application/json' -d '{\"ID\": \"marktplaats\", \"Name\": \"marktplaats\", \"Tags\": [\"urlprefix-www.marktplaats.nl/\"], \"Address\": \"91.195.49.34\", \"Port\": 80, \"EnableTagOverride\": false, \"Check\": {\"HTTP\": \"http://91.195.49.34/\", \"Interval\": \"15s\"} }' 'http://localhost:8500/v1/agent/service/register'\nHTTP/1.1 200 OK\ncheck that health check is passing\n$ curl -i 'http://localhost:8500/v1/health/state/passing?pretty'\nHTTP/1.1 200 OK\nContent-Type: application/json\nX-Consul-Index: 63\nX-Consul-Knownleader: true\nX-Consul-Lastcontact: 0\nDate: Fri, 30 Sep 2016 11:26:26 GMT\nTransfer-Encoding: chunked\n[\n    {\n        \"Node\": \"LM-AMS-00963965\",\n        \"CheckID\": \"serfHealth\",\n        \"Name\": \"Serf Health Status\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"Agent alive and reachable\",\n        \"ServiceID\": \"\",\n        \"ServiceName\": \"\",\n        \"CreateIndex\": 4,\n        \"ModifyIndex\": 4\n    },\n    {\n        \"Node\": \"LM-AMS-00963965\",\n        \"CheckID\": \"service:marktplaats\",\n        \"Name\": \"Service 'marktplaats' check\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"HTTP GET http://91.195.49.34/: 200 OK Output:   ...\"\n    }\n]\ncheck that fabio picks it up\n$ fabio\n...\n2016/09/30 13:27:31 [INFO] Updated config to\nroute add marktplaats www.marktplaats.nl/ http://91.195.49.34:80/ tags \"urlprefix-www.marktplaats.nl/\"\n...\ntest that it works (separate terminal)\ncurl -i -H 'Host: www.marktplaats.nl' 'localhost:9999/'\nderegister service\ncurl -i -XPOST http://localhost:8500/v1/agent/service/deregister/marktplaats\n```\n. If Fabio is supposed to route HTTP traffic to this service how can this not be an option? You need to have some monitoring around this which verifies that your external service is up. If you don't do this you can register a health check that never fails like shell with /bin/true. \nI'm not saying you don't have a case but right now I fail to see it. Please keep explaining what I'm missing. \n. The fake health check would indeed be just a workaround. \nThe hole in your argument is that you claim that you can reach the service via HTTP since fabio should forward traffic to it but you cannot use exactly the same mechanism to establish the consul health check. That doesn't make sense to me. \n. Hmm, I should have read your full response instead of just the first sentence. :/\nOK, so in essence you could monitor the external service but you don't want to since you don't think this is the right thing to do. You also do not want to provide a always-true health check to ensure that fabio works in your environment since you consider that a kludge. You would rather change the load balancer instead? Is this your argument?\nI get your point but I'm not sure I agree with it. You are basically saying that health checks should be actionable which is fine. But it falls short if your service depends on the availability of the external service. Then you want to know that your service is either failing or degraded because of an external factor even if you cannot change it. At least you can stop digging and maybe escalate the problem. This then is the action of your failing health check.\nFrom that perspective I'd absolutely would check external services if my own service depends on them.\nAnd by doing that it solves your first two problems at once without any code change which has to be maintained. Only the path stripping is missing.\n. @Salmondx Are you still using this patch? Path stripping has been added some time ago.. Closing because of age. Pls comment to re-open.. PEM but your path is incorrect. Use either v1/kv/ssl/foo.com.pem if you have key and cert in one file or v1/kv/ssl/foo.com-cert.pem and v1/kv/ssl/foo.com-key.pem if they are separate.\nLet me know whether that helps.\nFrom fabio.properties:\n```\nPath\n\n...\n\nTLS certificates are stored either in one or two files:\n\nwww.example.com.pem or www.example.com-{cert,key}.pem\n\nTLS certificates are loaded in alphabetical order and the first certificate\nis the default for clients which do not support SNI.\n\n...\nConsul\n\n...\nThe filenames follow the same rules as for the path source.\n...\n``\n. You need to provide only the base path in the properties. Then store the certificates under these filenames and fabio will pick them up. So you'd want something like this in yourfabio.properties`\ncs=cert;type=consul;cert=http://my.consul.server:8500/v1/kv/ssl&token=my-consul-token\n. You found a bug? I'll have a look later. Thx\n. I've filed this as a separate bug: #172 Fix is ready. Thx for finding this.\n. I've pushed the fix for #172 to master. Could you please check whether that fixes your issue? I'm going to close this question since we're now talking about a bug and I prefer not to morph discussions. \n. @cpredmann awesome. Thanks for testing. Closing.\n. Consider timezone. I have a look later.\n. The fact that fabio shows the routes means that the services are registered properly and healthy and that they have the right tag. The first thing I've noticed is the extra space in urlprefix- /tomcat which isn't necessary but I've checked that the parser ignores it. You should remove it nevertheless since technically you are now matching with host <space> and path /tomcat.\nI think your mistake is that you think that fabio is doing some path mangling/stripping/rewriting but that is not the case. Fabio uses the host/path for routing only, i.e. it uses the host/path only to determine which route to pick and then forwards the request as is. For example:\n```\ncurl http://localhost:9999/tomcat -> http://127.0.0.1:8888/tomcat\ncurl http://localhost:9999/ -> 404 Not Found (no route for '/'. check logs)\nroute add /tomcat http://127.0.0.1:8888/\nhttp://localhost:9999/ -> http://127.0.0.1:8888/\nroute add / http://127.0.0.1:8888/\n``\n. Does your tomcat instance respond tohttp://127.0.0.1:8888/tomcat?\n. This worked for me:\n- Download tomcat 7.0.72, unpack, runbin/startup.sh` and check that it is running\n```\n$ curl -i localhost:8080/tomcat\nHTTP/1.1 404 Not Found\nServer: Apache-Coyote/1.1\nContent-Type: text/html;charset=utf-8\nContent-Language: en\nContent-Length: 963\nDate: Tue, 04 Oct 2016 20:11:45 GMT\n...\n```\n- Register tomcat in consul\n$ curl -XPOST -H 'Content-Type: application/json' -d '{\"ID\": \"tomcat1\", \"Name\": \"tomcat\", \"Tags\": [\"urlprefix-/tomcat\"], \"Address\": \"127.0.0.1\", \"Port\": 8080, \"EnableTagOverride\": false, \"Check\": {\"HTTP\": \"http://127.0.0.1:8080/\", \"Interval\": \"15s\"} }' 'http://localhost:8500/v1/agent/service/register'\n- Run fabio without arguments (assuming consul on localhost:8500)\n...\n2016/10/04 22:09:44 [INFO] Updated config to\nroute add tomcat /tomcat http://127.0.0.1:8080/ tags \"urlprefix-/tomcat\"\n2016/10/04 22:09:44 [INFO] consul: Health changed to #10\n...\n- Test access via fabio\n```\n$ curl -i localhost:9999/tomcat\nHTTP/1.1 404 Not Found\nContent-Language: en\nContent-Length: 963\nContent-Type: text/html;charset=utf-8\nDate: Tue, 04 Oct 2016 20:10:13 GMT\nServer: Apache-Coyote/1.1\n...\n```\n. @krism74 I'm going to close this issue for now. Feel free to comment and I'll re-open if necessary.. fabio can handle incoming https requests in two ways:\n1. terminate ssl on fabio (incl. client cert auth if needed) and forward an http request downstream\n2. examine the SNI header of the TLS connection and route the encrypted tcp connection downstream based on the server name found in the SNI header. (full end-to-end encryption, tcp+sni proxy)\nFabio does not support to talk to downstream servers via https and therefore cannot authenticate via a client cert to the downstream server. I think this is what you're looking for, right?\nCan you explain what you are trying to achieve?\n. Yes and urlprefix-host/ only since the SNI extension in the TLS client hello message contains only the server name. \n. BTW, ./fabio -proxy.addr ':443;proto=tcp+sni' does the same job if you don't want a config file. Also note that the TCP+SNI proxy is still experimental in the sense that it works but it needs more timeouts. So if you are going to use it then let me know what your experiences are.\n. yes\n. Please have a look at https://github.com/eBay/fabio/wiki/Features#docker-support and let me know what is unclear or missing. \nYou can find this link in the right menu in the wiki page under Docker Support. \nAs a side note I would like to ask you to tone your language down a bit. Docker is not my native environment and so far nobody has complained about the lack of insufficiency of documentation. Asking nicely goes a long way. \n. I'm glad you've figured it out and please keep asking questions and make suggestions for improvements but stay constructive. It is OK to ask here! It is more helpful to me to understand what frustrated you instead of just reading that you are frustrated.\nSo far nobody has complained much about the documentation and the project has been around for over a year. The Docker images got pulled 50K+ times. It can't be all bad.\nThe documentation can always be improved but I don't feel that there is a lot of it missing. It may just not be in the place where you've expected it to be which can be fixed with a link.\nThe Quickstart is intentionally short since in a lot of situations this is how you want to run fabio and these are the things that most people stumble over. There isn't a whole lot of configuration required since this was the whole point of this project. fabio isn't nginx and it doesn't want to be. \nThe first sentence on the https://github.com/eBay/fabio/wiki/Features page says to look at the https://github.com/eBay/fabio/blob/master/fabio.properties file where the config options are all documented. \nSo for now I've added a link to the Docker support page, the fabio.properties file and the Features overview to the Quickstart page.\nI'm going to close this now. Feel free to re-open or open another issue for another question.\nFrank\n. You can have as many services as you want and each service can register as many different urlprefix-host/path prefixes as you need and they don't need to be disjoint. Service A and B can both register /foo. We've had a use case where a service was registering the URL for each individual page separately. I wouldn't recommend this but it was possible to do some service migration there. \nThe usual issues if you don't see a route in fabio are:\n1. your service does not have a health check\n2. the health check is not green (not the serf health check)\n3. multiple instances of the same service are not registered with the same id, e.g. two redis instances registered with id:redis name:redis instead of id:redis1 name:redis and id:redis2 name:redis\nCould you post the output of\ncurl localhost:8500/v1/catalog/service/<service>?pretty and curl localhost:8500/v1/health/service/<service>?pretty for the service in question?\n. Your service tags do not begin with urlprefix-\n. I have a test framework for TCP proxies in the release-branch-1.4 and plan to add an integration test for the PROXY protocol. ReadTimeout and WriteTimeout are now honored but that still needs testing.. merged to master. @jbye why not use the consul service discovery instead? Then you don't need fabio for this. That's what we're doing.\n. @shantanugadgil myservice would be a non-HTTP and non-HTTPS service, right?. The release-branch-1.4 contains a working implementation of a generic TCP proxy. It should also support TLS on the inbound socket but I haven't tested that yet. This should work by setting a certificate source with cs=name. I need to polish and document some more code but would appreciate some early feedback whether this is working in general. \nThe following command will start TCP proxy on port 1234 in fabio and route requests to all servers which have registered with tag urlprefix-:1234 proto=tcp\n./fabio -proxy.addr ':1234;proto=tcp'\nThe demo/server has been updated to provide a simple TCP echo server.\n```\ncd demo/server\ngo build\n./server -addr 127.0.0.1:5000 -proto tcp -prefix :1234 &\n./server -addr 127.0.0.1:5001 -proto tcp -prefix :1234 &\n...\nnc 127.0.0.1 1234\nHello\n[127.0.0.1:5001] Hello\n^C\n```\nYou can also register multiple tags to map several inbound ports to one service. You can try this with\n./server -addr 127.0.0.1:5000 -proto tcp -prefix :1234,:5678\nPlease note however, that fabio needs to have all listening ports configured upfront. That is something that I'd like to change in a subsequent change.\nOne side effect which I'd like to clean up before merging is that the route commands still contain URLs as target addresses, e.g.\n+ route add server :1234 http://127.0.0.1:5001/ tags \"urlprefix-:1234 proto=tcp\" opts \"proto=tcp\"\n+ route add server :1234 http://127.0.0.1:5000/ tags \"urlprefix-:1234 proto=tcp\" opts \"proto=tcp\"\nFeedback is very welcome!. One note: The release-branch-1.4 requires Go 1.8. @nugend Would it help if I provide a binary?. @nugend Here you go: https://github.com/eBay/fabio/releases/tag/v1.4beta1. @panga That's good to know. Thanks for testing this. To your questions:\n\ndynamic listening ports: yes, but that requires some more refactoring since I need to shut them down as well.\n\nI'd like to spend some more thought on how the tcp proxy support is expressed in the config language. Right now the upstream server is still referred to via http:// which is wrong.  I'd also like to get an idea on the state of the TLS support. Other than that, I don't foresee any other major changes for the 1.4 branch. I'll try to find some time to clean this up this week and aim for a release next week.. @nugend did you also get a chance to test the tcp proxy in 1.4beta1?. I've added a test which verifies that TLS termination works on the TCP proxy. This now allows the following options:\n\n\nProxy a raw TCP connection based on ports\n\nProxy a TLS encrypted TCP connection without decryption based on SNI server name\nProxy a TLS encrypted TCP connection and terminate TLS on fabio\n\nI've rebased the release-branch-v1.4 which means I had to re-roll the 1.4beta1 build. Probably, shouldn't have merged the small changes into master in the first place. \nIn any case, I've tagged and pushed v1.4rc1 which will become v1.4 unless someone finds a bug. \nP.S.: They're also on docker hub.. merged to master. Cool. I'll have a look later\n. Let me have another look. I took a stab at this in #163 Please have a look.. I'm going to close this PR since a change for #163 has been merged to master. Please open new tickets with a reference to #163 if there are issues with the provided implementation.. fabio does not support that yet. I'll probably add that at a later stage when I'm addressing #111 \n. @Narrowbeam It is on the list. I've spent some time refactoring the listener and proxy code in the release-branch-1.4 to make this simpler. The addition of the TCP proxy was already a step in that direction. So stay tuned. :). It could be. However, I think that you need to have some cert management options as well since upstream certs are probably self-signed. There may be more but I think that would be a good start. . Thanks @shadowfax-chc for implementing this. This is great progress. I'll release 1.4.2 soon with this.. Traveling now. I'll have a look later\n. @calvinmorrow I think I'm not initializing the Vault client properly. I've pushed a change that might do what you need. Would be great if you could test it since I'm shooting from the hip. \n. Cool. I'll merge it.\n. Merged to master.\n. Merged the fix to master. You'll have to build a version yourself for now. I'll release a fix version in a couple of days. I'll close this one now. Feel free to re-open or comment if this does not solve your issue.\n. Https backends are only supported via the tcp+sni proxy for now\n. Closing as duplicate of #181 . On vacation right now but I'll have a look later. That looks like an edge case I've missed. \n. You've indeed found a bug and it is in code for which I don't even have a test... How embarrassing. \nWhat happens is that the weighing algorithm which pre-computes the distribution of the target URLs based on weight allocates only 100 slots (= 100%) and when you create more than a couple hundred instances the rounding errors ensure that no instance is used. This then trips the random number function which never thought it would be called with zero. Why would anybody create more than 100 instances anyway? ;)\nTime to refactor. Not a biggie but I need to add a test first. For now stay <= 100 instances per prefix. \nI've got an ugly patch which you can apply if this is an urgent production issue. Otherwise, a fix is coming soon. \nThanks for finding this. \n. One of the next things on my list. . @killcity I'll have a look today whether there is a quick workaround. My guess is that changing 100 to 1000 or 10000 in https://github.com/eBay/fabio/blob/master/route/route.go#L222 would do the trick but I need to write a small test to verify. If that works then I could push this first and then deliver a real fix later.. @killcity Unfortunately, the really quick fix doesn't work. On the upside, I've found that I actually do have a test for the code. Just in a place where I didn't expect it :) I'll keep looking. . @killcity I've pushed a change which should fix the issue and which also adds a fast-path for the default case of all targets receiving equal amounts of traffic. The new code guarantees that a target with a computed weight > 0 will receive traffic eventually if you use the rr scheduler. For the default rnd scheduler this guarantee cannot be made. This should allow an unlimited number of targets per route. Would be great if you could test this.. tests fail on travis but work locally. I'll have a look tomorrow.. Tests are timing out. Parsing 2500 routes is somewhat slow. Need to check whether the new parser will be faster.. Test added a nice stress test for url.String() :) Fixed now (hopefully).. Merged to master. Still working on it. There is a PR open  it that still needs work. \n. Looking. Fixed wiki.. The parser for the key=val;key=val lists did not trim spaces from the keys. Removing the space in the argument works around the issue. This patch fixes that.. That code is there for a different reason. Could you please explain the problem you are trying to solve? This isn't clear from the Twitter communication. \nMy guess is that you just need to add the port to the host in the urlprefix tag but I'd need to see the details. \nThx\nFrank Schr\u00f6der\n\nOn 22 Nov 2016, at 01:55, AbhishekKr notifications@github.com wrote:\nSigned-off-by: AbhishekKr abhikumar163@gmail.com\nHey, as per our conversation today\nhttps://twitter.com/magiconair/status/800626305490259968\nI've made few changes to Fabio code to support request hostname provided with any port, not just 80|443.\nThis works for my use-case without me to provide Host: header in urlprefix-host/ scenario.\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/eBay/fabio/pull/190\nCommit Summary\nallowing route to match host running at any port aimed url\nFile Changes\nM route/table.go (10)\nPatch Links:\nhttps://github.com/eBay/fabio/pull/190.patch\nhttps://github.com/eBay/fabio/pull/190.diff\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. It doesn't support the PROXY protocol for outgoing connections but that sounds like a good idea. I'll add it to the list.. I've refactored the listeners and servers in the release-branch-1.4 to prepare for this. I want to finish the generic TCP proxying support first but aim for including this in the 1.4 release or shortly thereafter.. Hmm, that looks simple enough to be added as a listener option like read/write timeout. No need to duplicate the entire proxy for that. Let me see whether I can cook something up tomorrow or so.. I'm wondering whether this is something that needs to be configurable per upstream server, e.g. some upstream servers want PROXY protocol and others don't? @lukas2511 @tkald what's your take on that?\n\nThe reason I'm asking is that there is currently no support for upstream servers announcing their capabilities. This isn't difficult to add but more work than a global switch. . @lukas2511 since the route is announced by the upstream server through consul it needs to advertise this somehow. How do you envision this to work?. @pashinin Right now I have almost no time to work on this project other than urgent bug fixes and merging contributions. If you need this feature then the best chance is to submit a PR.. Then let\u2019s merge. Thanks for the detailed description. My suspicion is that this isn't Fabio related but you've done testing around this. I'm currently on vacation and will start picking up Fabio issues as of next week again. . @michaelmcguinness Did you make any progress with this? What do the fabio logs say?. If there is nothing in the fabio logs then that supports my suspicion that this is a docker and/or nomad issue. Maybe the way fabio interacts with docker or the way it shuts down triggers this. However, since you're running this with a single listener you could try to simulate this with a simple go program that runs a web server, then a reverse proxy, and then a reverse proxy that makes long polling http requests. \nBelow is a simple reverse proxy for testing. Store it in ~/gopath/src/fabiotest/main.go and then build with go build in that directory. Make sure you have set export GOPATH=~/gopath. When running you can test both endpoints with curl localhost:9998 and curl localhost:9999. Except for the long-polling outgoing connection to consul this is in essence the core of fabio. :) \nYou can use the following Dockerfile:\nFROM scratch\nADD / fabiotest\nEXPOSE 9998 9999\nCMD [\"/fabiotest\"]\nSee how far you get with this.\n```\npackage main\nimport (\n    \"flag\"\n    \"fmt\"\n    \"log\"\n    \"net/http\"\n    \"net/http/httputil\"\n    \"net/url\"\n)\nfunc main() {\n    var proxyAddr, uiAddr, proxyURL string\n    flag.StringVar(&proxyAddr, \"proxy\", \":9999\", \"host:port of the proxy\")\n    flag.StringVar(&uiAddr, \"ui\", \":9998\", \"host:port of the ui\")\n    flag.StringVar(&proxyURL, \"proxyURL\", \"https://www.google.com/\", \"proxy url\")\n    flag.Parse()\nlog.Println(\"fabiotest starting\")\n\ngo func() {\n    u, err := url.Parse(proxyURL)\n    if err != nil {\n        log.Fatal(\"proxyURL:\", err)\n    }\n    log.Println(\"proxy listening on\", proxyAddr, \"proxying\", u)\n    rp := httputil.NewSingleHostReverseProxy(u)\n    if err := http.ListenAndServe(proxyAddr, rp); err != nil {\n        log.Fatal(\"proxy:\", err)\n    }\n}()\n\ngo func() {\n    log.Println(\"UI listening on\", uiAddr)\n    http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n        fmt.Fprintln(w, \"UI is OK\")\n    })\n    if err := http.ListenAndServe(uiAddr, nil); err != nil {\n        log.Fatal(\"ui:\", err)\n    }\n}()\n\nlog.Println(\"Press CTRL-C to stop\")\nselect {}\n\n}\n```\n. I am interested and I'm glad you've figured it out. If you have a reference issue for nomad feel free to link it.\nThanks and merry christmas. Enjoy the holidays.. .count is the request counter for that target. If you want req/s from that number then you need to take the (non-negative) derivative from .count. .min and .max are the total min and max values for count AFAIK. Fabio does not directly keep track of the total number of open connections. You have to sum them up over all targets, e.g. nonNegativeDerivative(sumSeries(*.fabio.requests.count)) (pls look up the correct syntax since I'm winging this from memory)\nDoes that answer your question?. Sounds good and I'm looking forward to it. Let me know if you have more questions.. merged.. Good point. I have to think about that.. If I look at https://github.com/golang/go/issues/1435 then there might be a way as long as I don't need to chroot. Open socket, re-exec and pass FD to child process might work. This will become interesting for dynamic listeners :). @killcity consider this a first attempt of tackling this. The code is based on the idea from @bgilmore in https://play.golang.org/p/dXBizm4xl3. The only thing I've added is the forwarding of stdout and stderr to make logging work. \nI find the code still quite ugly and the whole listener setup could use a makeover but it should work. Would be great if you could test it. . I've tested this only on OSX so far with sudo ./fabio -user nobody which spawns the root process which then sets up the listeners and passes them on to the child process. The child process will then use the FDs to create the actual proxies. The root parent has a root: prefix in the logs and the child logs the user it runs as. As said in the comment the command line arg will most likely change. . Some tests are failing. I'll fix that tomorrow.. Yes. I've rebased the code and fixed the failing test. One effect is that the cmd line parameter is now -proxy.user instead of just -user since that picked up the $USER environment variable. Code is still ugly and needs work. Name of cmd like arg will most likely still change. Handle with care :). @killcity awesome. I'll spend some time on incorporating this into the master branch then.. What about windows and macOS? I'm not a fan of building per-os code in. OTOH, the proposed patch might also not work on other platforms. \nThis could be optional though. You can choose which approach you want to take with forking as the default. This would also leave the door open if Go makes this easier at a later stage.\nI like the idea of the root switch and making it the default. However, that will break existing setups and since fabio sits in the hot-path this might result in some angry users who have to scramble to get their sites back up. Only way to introduce this is very carefully and with enough lead time. Maybe issue the warning first and announce when it will become the default. Then make the switch.. Just keeping the patch in sync with master but I'm leaning towards @mterron. This sounds like the better approach. . I agree with @mterron and @stephane-martin that this is not the responsibility of fabio. Lets do the following instead:\n\nCompile a set of best-practices per operating system as outlined by @mterron and @stephane-martin and add them to the documentation\nAdd a stern warning message to the logs when fabio is run as root (if detectable) and point to the documentation for best-practices on how to solve it. Also indicate that the default behavior will change in the future, i.e. the -insecure switch that @mterron suggests.\n\n@mterron and @stephane-martin would you be willing to provide some documentation snippets for the various OSes you seem to have experience with? Not sure if what is already provided in this ticket is sufficient for the documentation.. I've compiled the best practices here in a wiki page: https://github.com/fabiolb/fabio/wiki/Binding-to-Low-Ports\nIs anybody up for reviewing this? If yes, then please comment here.\nI'm going to create another ticket for not allowing to run fabio as root.. Thanks everybody for the suggestions!. Since all flags work with - and -- and with the exception of v they're all long it would be more consistent. I'll add it.. Done.. Of course! And not that I'm aware of. :). Closing and waiting for PR.. Merged to master. Try adding the port, e.g. 1.2.34:8500. Can you share how you are running fabio (cmd line args, env vars) and the startup log including the runtime config?. This is a networking problem. Does 'telnet 192.168.196.XXX:8500' work?\nAlso, try the URL that is provided in the error message. As long as that doesn't work fabio won't work.\nhttp://192.168.196.xxx:8500/v1/agent/self. @vjappidi I am going to close this issue for now. If you find that this isn't a networking related issue on your end or if you have other related issues please feel free to comment and I can re-open the issue, if necessary.. Like route del svc tags \"tag\"? We were just talking about this. Not hard to add but not there yet. . I'll add that after I've fixed the weighing bug. (#186). Implementing this pushed me into refactoring the table parser tests a bit more. This patch adds support for \n```\ndelete routes of  which have tags 'a' and 'b'\nroute del svc tags \"a,b\"\ndelete routes which have tags 'a' and 'b'\nroute del tags \"a,b\"\n```. Merged the change to master. Please test.. That depends on your application but I get your point. Our apps are usually backwards compatible the blue/green scenario was to spin up the full set of instances but only send some amount of traffic to them to see whether an issue would show up and then flip. \nSticky routing usually creates more problems but I agree that this could be a useful feature. Need to think about this a bit. . I think the simplest thing that could work would be to add sticky routing based on the src address or a header, e.g. a sticky=src or sticky=hdr:name option to the route. . Assuming I use a hash function to compute a value for one or more input variables how do I ensure that fabio always routes to the same host without keeping a connection table which has to be shared across all fabio instances? This wouldn't be stateless anymore.\nThe list of hosts can change at any time and ordering won't help (see example below). To take this approach you'd have to guarantee that a given target host will always get the same identifier and that the hash function will always map to that id if it exists. \nExample:\n```\nlist of hosts for the given route in some stable order\nhosts = ['a', 'k', 'x']\nhash fn for some input params, e.g. src ip\nv = fn(\"1.2.3.4\") // e.g. 10\ntarget host\nhost = hosts[v % len(hosts)] // 'k'\nnow the host list changes\nhosts = ['a', 'b', 'k']\nhost = hosts[v & % len(hosts)] // 'b' and not 'k'\n```\nAnother consequence is that during brief times of unavailability of the target host requests would be sent to a different host and then again to the original target host once it comes back. That makes for very unpredictable behavior during times of deployments and upgrades. \nfabio would have to try to reach the target host for that session and fail the request if that target host isn't available even though other hosts are available to handle the request since it cannot safely route the request to a different host. Sessions would have to time out...\nA good example of why I don't like sticky lb :)\nWhat about a different approach? \nThe above approach assumes that fabio is doing some magic to route incoming requests to the same target host based on some computed criteria independent of the current cluster configuration. What if we flip this around and make the first instance responsible for providing fabio with enough data to route subsequent requests for the same session to it?\nI guess that is what you are already doing when setting a sticky session cookie but the canary use case doesn't necessary involve sticky session cookies. You just want people to be routed to a specific version of the service. \nfabio could use a route id header or request param to find the correct target host and it is the responsibility of the app to set that. The instance would have to publish to consul which route ids it handles.\nFor the canary use case apps could always set a route id with the current version which would ensure that current users stay on version they started on unless there is no instance available with that version. This way you don't need special magic of source ip addresses. You can have clusters of old and new instances and both user groups would remain distinct. You could use this for a/b testing or for real sticky load balancing if each instance has a unique id. \nDoes that make sense? What do you think?. Below I'll provide my reasoning for not doing this at this point but I'm interested to hear whether there is a pressing need for a different communication form. \nLive chat\nThere is a gitter channel which I've abandoned and I've used Slack with one user but would have to opt for a paid option to make it open I guess. Maybe there was a free tier for open-source projects but TBH I didn't dig very deep. \nThe main concern I have with live chat (or a mailing list) at this point is that it splits the conversation into multiple parts which then have to be merged again. Everybody will have to look in multiple places and needs to make a decision on whether to start a new conversation on the chat, the mailing list or github. Rules have to be made, maintained and people reminded.\nLive chat also interrupts the work flow. People may not want to respond at a given time or it may be inconvenient because of timezone. This can be frustrating since the expectation is that live chat is \"live\".\nAs imperfect as github is for this it centralizes the discussion in one place so everybody knows where to look and it eliminates this can of worms for now. It is searchable, people get notified if they want to and can opt out of certain discussions which is difficult in a global live chat. I'll try to respond as quick as possible and others can do the same. Depending on how active the community becomes this may not be sustainable, though. I'm open for suggestions.\nIf you want to discuss things that shouldn't be public then we can find something that works. LinkedIn, Skype or Google Talk are fine with me. We can do that on a case-by-case basis. \nFeel free to just ask what you'd like to know here.\nRapid development\nI've come back from vacation and am catching up on issues. There is no real roadmap or plan. Critical bugs and simple questions always get addressed first. After that it is what has the highest demand (assuming I have an idea on how to implement it) and/or what I'm interested in myself. Please let me know what bugs you and how you would like to use fabio but cannot right now. In general, I like to mull over solutions for a bit until I've got a good idea. \nContributions are always welcome. Please start with a discussion instead of code or a PR unless it is a trivial change. \nYour numbers\nI am very curious to hear about them. If you want I can include you - and everybody else who wants to as well - on the front README. Just drop me a note or send a PR.\nThanks for your comments and the issues you've opened so far. . @chiel1980 No, we didn't and yes, I'm interested. If you've found something then I'd prefer if you first disclose to me so that I can prepare a fix first and disclose publicly later. \nFrank. @chiel1980 Any news on this? Just curious.. Fair enough :) Closing this one then.. Check if one or more of your services have flapping or lagging health checks.. @hynek As for the awkwardness see my comment on #203. Please feel free to ask at any time.. @hynek I'm going to close this issue for now. Feel free to comment and I'll re-open it if necessary.. @jorgemarey I'll ping them as well. Thx.. This sounds like #120 which even has the same title.\nFrom https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html\n```\n10.2.5 204 No Content\nThe server has fulfilled the request but does not need to return an entity-\nbody, and might want to return updated metainformation. The response MAY\ninclude new or updated metainformation in the form of entity-headers, which if\npresent SHOULD be associated with the requested variant.\nIf the client is a user agent, it SHOULD NOT change its document view from\nthat which caused the request to be sent. This response is primarily intended\nto allow input for actions to take place without causing a change to the user\nagent's active document view, although any new or updated metainformation\nSHOULD be applied to the document currently in the user agent's active view.\nThe 204 response MUST NOT include a message-body, and thus is always\nterminated by the first empty line after the header fields.\n```\nCan you get and post the full trace of the inbound and outbound requests and responses? I'd like to see whether the response contains a Content-Length: 0 header and has a terminating empty line and/or if the upstream server is closing the connection. I'll do some testing on my end. . I've updated the demo server to return response with an arbitrary status code. You can run it as follows:\n```\nstart consul server (sep terminal)\nconsul agent -dev \nstart demo server (sep terminal)\ncd $GOPATH/src/github.com/eBay/fabio/demo/server\ngo build\n./server -prefix /foo -status 204\nstart fabio (sep terminal)\ncd $GOPATH/src/github.com/eBay/fabio\ngo build\n./fabio\nquery demo server directly and through fabio\ncurl -i 127.0.0.1:5000/foo # direct\ncurl -i 127.0.0.1:9999/foo # via fabio\n```\nThe demo server will not return any content when run with -status 204. You can try that by using a different status code, e.g. 200 or 203. When querying the /foo endpoint both directly and via fabio I get the same result as in immediate response without hanging. Therefore, I think that there is something specific about your configuration that triggers that behavior.. Found https://github.com/golang/go/issues/15647 which seems related.\nI'm curious: does fabio forward the 204 response and keep the connection open or does it wait 30 sec before forwarding the 204 response?\n. Here is a simple raw web server which only serves 204 responses and keeps the connection open after sending the response. When the response contains an empty line then fabio does what you want. If not, then it hangs. To simulate the hang remove the second \\r\\n from the body var.\n```\npackage main\nimport (\n    \"log\"\n    \"net\"\n    \"time\"\n)\nvar (\n    addr    = \":8080\"\n    timeout = 10 * time.Second\n    body    = []byte(\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n)\nfunc main() {\n    log.Println(\"Serving 204 responses on \", addr)\n    l, err := net.Listen(\"tcp\", addr)\n    if err != nil {\n        log.Fatal(\"listen: \", err)\n    }\nfor {\n    c, err := l.Accept()\n    if err != nil {\n        log.Fatal(\"accept: \", err)\n    }\n\n    go func(c net.Conn) {\n        defer c.Close()\n\n        log.Printf(\"sending %q\", string(body))\n        if _, err := c.Write(body); err != nil {\n            log.Fatal(\"write: \", err)\n        }\n\n        log.Println(\"waiting\", timeout)\n        time.Sleep(timeout)\n        log.Println(\"closing\")\n    }(c)\n}\nselect {}\n\n}\n```\nTest with\n```\nrun server (sep terminal)\ngo run main.go\nrun fabio (sep terminal)\n./fabio -registry.static.routes 'route add svc / http://127.0.0.1:8080' -registry.backend static -proxy.keepalivetimeout 5s\nmake request\ncurl -i -v http://127.0.0.1:9999/\n```\nCould you please capture a tcpdump of the roundtrip between fabio and mule? I'm suspicious that mule is not sending the response it should. Also, because this is the second time someone stumbled over exactly the same problem.. The blank line separates the headers from the body. It effectively terminates the header section. Without that the server can't know whether it has seen all the headers or not. . What I'm saying is that without the blank line after the headers fabio is waiting for more content since the header section hasn't been properly terminated yet. AFAIR, this is part of the HTTP protocol. I'll dig some more but this looks like a mule bug. Obviously you won't see this if mule closes the connection. . https://tools.ietf.org/html/rfc2616#section-4.1 defines an HTTP message as\ngeneric-message = start-line\n                          *(message-header CRLF)\n                          CRLF\n                          [ message-body ]\n        start-line      = Request-Line | Status-Line\nwhich means that there must be a blank line after the message headers. Since mule does not seem to send the final CRLF fabio waits for more headers until it times out. So to that extent I'd consider this a mule bug. Maybe dig through their issues to see whether someone else has reported it.. If they don't send the empty line then they are not behaving according to spec IMO and the other clients are more forgiving. My guess is that any Go based reverse proxy will show this problem.. @sadyou This is just the hex content and not a base64 encoded tcpdump capture, right?. The dump of the response you've provided contains the final CRLF and that works just fine. Either this isn't the content that is being sent to fabio or something else is going on. You can try it by replacing the body variable with this:\n\ufeff   // body    = []byte(\"HTTP/1.1 204 No Content\\r\\n\\r\\n\")\n    body = []byte{\n        0x48, 0x54, 0x54, 0x50, 0x2f, 0x31, 0x2e, 0x31,\n        0x20, 0x32, 0x30, 0x34, 0x20, 0x0d, 0x0a, 0x43,\n        0x6f, 0x6e, 0x74, 0x65, 0x6e, 0x74, 0x2d, 0x54,\n        0x79, 0x70, 0x65, 0x3a, 0x20, 0x61, 0x70, 0x70,\n        0x6c, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e,\n        0x2f, 0x78, 0x2d, 0x77, 0x77, 0x77, 0x2d, 0x66,\n        0x6f, 0x72, 0x6d, 0x2d, 0x75, 0x72, 0x6c, 0x65,\n        0x6e, 0x63, 0x6f, 0x64, 0x65, 0x64, 0x3b, 0x20,\n        0x63, 0x68, 0x61, 0x72, 0x73, 0x65, 0x74, 0x3d,\n        0x55, 0x54, 0x46, 0x2d, 0x38, 0x0d, 0x0a, 0x4d,\n        0x55, 0x4c, 0x45, 0x5f, 0x45, 0x4e, 0x43, 0x4f,\n        0x44, 0x49, 0x4e, 0x47, 0x3a, 0x20, 0x55, 0x54,\n        0x46, 0x2d, 0x38, 0x0d, 0x0a, 0x44, 0x61, 0x74,\n        0x65, 0x3a, 0x20, 0x54, 0x68, 0x75, 0x2c, 0x20,\n        0x32, 0x32, 0x20, 0x44, 0x65, 0x63, 0x20, 0x32,\n        0x30, 0x31, 0x36, 0x20, 0x32, 0x32, 0x3a, 0x34,\n        0x38, 0x3a, 0x31, 0x30, 0x20, 0x47, 0x4d, 0x54,\n        0x0d, 0x0a, 0x0d, 0x0a,\n    }. @sadyou That's good to know. Do I understand this correctly that this is a bug in Mule when Mule gets a 204 response from another Mule instance?. @drawks Which one?. Please have a look at https://github.com/ebay/fabio/wiki/Deployment and let me know whether that answers your question.. @tonysongtl I'm going to close this one for now. Feel free to comment and I'll re-open if necessary or create another issue.. Try \"-registry.consul.register.enabled=false\". Boolean flags should be passed with an =false AFAIR. That works for me here.. No worries. Glad you found it. :) Let me know if there is something else.. I'm going to close this one since most of the discussion happens on the consul ticket.. Somehow I knew that this was going to come :) I'm working on another metrics ticket right now and thought the same thing. I'll add it to the list.. I need to wrap my head around on how to configure the naming and to expose the tags. The issue is that some metrics system want a single string as name which flattens all parts of the name into a single value. Others have a base name and other parts as a tag. What makes this a bit more complex is that some of the names are auto-generated and the pattern is configurable. So either this mechanism needs to work for all providers or I need to come up with something else. It probably isn't that difficult but that's the hold-up. Same for #165 .. work on consul 1.0 has kept me quite busy. I plan to go through open issues soon. . working on it.. I've started and got distracted with family and personal stuff. Sorry man. I'll give it another push.. @marcosnils I'd love to have some help here to push this forward. I have an idea on how to do this since the problem is a bit bigger than just supporting prometheus. Look for the issues tagged theme-metrics. In short, none of the existing metrics libs solve all the problems and there needs to be some fabio specific glue code. My current thinking is to write a layer which handles the naming issues and configuration and then uses go-kit/metrics drivers since they are complete and seem to be maintained. Shall we do a conf call to discuss the approach and then document it here? Where are you located?. If someone else wants to help with this, too then pls just shout out.. I've finally got something that I think is worth working on. Please see #476 in the metrics4 branch. Right now I'm trying to validate the approach. So if someone wants to write a proof-of-concept provider for prometheus using the go-kit/metrics driver then this would be awesome. This would then allow us to integrate all existing go-kit/metrics drivers which covers most of the open issues. \nLets keep the discussion on the metrics in #476 since other backends are also affected. \nI'm not sure how we can collaborate on a PR on Github. I assume you fork the branch and create a patch. I'll try to incorporate patches into the metrics4 branch so that we all have the same base. \nThanks for your patience. This has been bugging me for a while so lets solve this properly.. See https://github.com/fabiolb/fabio/pull/476#issuecomment-434048436. @cjdxlgb Try using only one tag urlprefix-/website\nBy adding urlprefix- to the front fabio can find the tag and understand it.. @cjdxlgb I'm glad it works now. No sticky session support at this point but I am thinking about it.. @cjdxlgb Greetings from Amsterdam, NL :). @cjdxlgb Right now there isn't but I generally add features based on demand; when more people ask I'll add it. Please follow issue #202 for updates.. @cjdxlgb \n\n\nYou use multiple tags, e.g. urlprefix-/website/test, urlprefix-/website2/test and urlprefix-/website/website2/test\n\n\nYou can use the manual overrides to assign weights to different routes. See https://github.com/eBay/fabio/wiki/Features#traffic-shaping\n\n\nCheck the wiki https://github.com/eBay/fabio/wiki. fabio does not support path rewriting. If you need to access a service under /website then it must have an HTTP handler for /website. Hence, your three different services need to have handlers for all URLs on which they should respond. Then you can register all three URLs with fabio. Otherwise, register only the prefixes they do support but then there won't be any load balancing between services of different prefixes.\n\n\nTo test this make sure the following works:\n```\ncurl -i http://172.168.11.16:9290/website/test\ncurl -i http://172.168.11.16:9290/website2/test\ncurl -i http://172.168.11.16:9290/website/website2/test\nand\ncurl -i http://172.168.11.16:9190/website/test\ncurl -i http://172.168.11.16:9190/website2/test\ncurl -i http://172.168.11.16:9190/website/website2/test\n```. Is there another way to convince BitBucket that the connection is on HTTPS? Some way that fabio isn't supporting yet?. This is the code that handles the headers in addition to what the golang http library is doing. https://github.com/eBay/fabio/blob/master/proxy/util.go#L22-L94\nUnfortunately, the tests are only unit tests and not full integration tests which tests the combination of both. Might be a good idea to refactor them.\nI think the X-Forwarded-For header is set by the go lib and fabio only adds this for websocket connections. I don't see code for either the X-Forwarded-Host or the X-Forwarded-Server headers in either fabio or go. CONNECT may work but I would need to test that. Could you please open separate issues for the headers and CONNECT?. As for your first suggestion to check from least to most specific routes I think this isn't the right approach. You'd expect the more specific routes to be matched first. \nAlso, this isn't a problem of wanting to provide this but the two proxy implementations are quite different and I have a hard time coming up with a solution that could work. What you are trying to do here smells a lot like a refactoring issue that you should solve in the app instead of abusing the LB to do this. You could either introduce another ip address or just a different hostname for these endpoints. In the end you want very different behavior: either full end-to-end encryption for the entire conversation or man-in-the-middle decryption by the LB with more dynamic routing. I know that other LBs may be able to do this but I usually encourage people to try to solve this in the app itself since the solution is then independent of the LB. . If performance is your main concern and not full end-to-end encryption the I suggest to benchmark first. Users haven't complaining that fabio can't handle their workload. Also, you can always spin up more instances. I'll look at the websocket issue in the meantime. #413 could become relevant for this. Feel free to comment on that issue if that is a viable path for you.. fabio does not do that at the moment as routes for non-passing services are excluded from the routing table before parsing. So the code that decides on the return code doesn't even see that this would be an option. I'd have to add a route that says that there is no server for this prefix. I'll think about it.. Still awake but not much longer :) As long as the default return code is 404 there wouldn't be a change in external behavior. I also don't think that this would be such a big change but it is more than just adding an if statement somewhere and a config option. . I don't think that I'm going to add that. The routing table is constructed from what is there and not from what is not there. That's the whole point of fabio. Please let me know if I'm missing something fundamental and I'll revisit this. Hope you're still happy with fabio :). @smancke like this?. I'm trying to see an HTTP/2 request in the testSource() function in cert/source_test.go but I don't see it. Trying to print the proto and somehow expecting HTTP/2 here:\nsrv := httptest.NewUnstartedServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    fmt.Println(\"Proto:\", r.Proto)\n    fmt.Fprint(w, \"OK\")\n}))\nAny idea what I'm missing? . @smancke Awesome. Thanks a lot. I've updated the change to include the test. Testing for HTTP/2 feels grafted on though. Maybe its better to move this to a separate test but for now at least there is a test.. @smancke I can spin a 1.3.6 tomorrow. Also, time to wrap up the other lingering changes. Quick enough?. Thanks for finding and helping! Appreciated.. Merged to master and published in 1.3.6 release.. The fabio routing table is updated automatically every time the consul state changes. This can be triggered either by a new instance of your service appearing, an existing instance disappearing or the health status of an existing instance changing.. What I can see from the fabio logs is\n\nadd port 8081\nadd port 8080\nadd port 8082\nremove port 8081\nremove port 8080\nremove port 8082\n\nFinally, the routing table empty and all requests fail with 404 Not Found which is exactly what should happen. Also note, that a 404 response can come from both fabio and your service. Just because fabio routes the request to the service does not mean it has a handler to serve it. Check whether http://C40-BF91.india.rsystems.com:<port>/myworld provides a valid response for all three ports.\n2017/01/17 12:16:02 [INFO] consul: Health changed to #3818\n2017/01/17 12:16:03 [INFO] consul: Health changed to #3819\n2017/01/17 12:16:03 [INFO] Updated config to\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\n2017/01/17 12:16:10 [INFO] consul: Health changed to #3820\n2017/01/17 12:16:10 [INFO] Updated config to\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\n2017/01/17 12:16:12 [INFO] consul: Health changed to #3821\n2017/01/17 12:16:12 [INFO] Updated config to\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8082/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8082/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\n2017/01/17 12:16:35 [INFO] consul: Health changed to #3824\n2017/01/17 12:16:35 [INFO] Updated config to\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8082/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8082/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\n2017/01/17 12:17:28 [INFO] consul: Health changed to #3829\n2017/01/17 12:17:28 [INFO] Updated config to\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8082/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8082/ tags \"urlprefix-/myworld,urlprefix-/world\"\n2017/01/17 12:17:33 [INFO] consul: Health changed to #3833\n2017/01/17 12:17:33 [INFO] Updated config to\n2017/01/17 12:17:33 [WARN] No route for localhost:9999/myworld\n2017/01/17 12:17:33 [WARN] No route for localhost:9999/myworld\n2017/01/17 12:17:34 [WARN] No route for localhost:9999/myworld\n2017/01/17 12:18:03 [INFO] consul: Health changed to #3835\n2017/01/17 12:18:10 [WARN] No route for localhost:9999/myworld. @gagan2u2002 I am not sure I understand. If you have resolved the issue then it isn't a bug. If it is a bug can you point me to what you think the issue is?. Also, fabio just pulls information about running services from consul. If the consul service registration isn't updated properly then fabio will have an inconsistent routing table. Please make sure that you check that first. If I look at the fabio log then this doesn't look like you are shutting down the instance on port 8080 but the one on 8082.\n2017/01/18 11:30:12 [INFO] Updated config to\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8082/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8082/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\n2017/01/18 11:30:12 [INFO] consul: Health changed to #129\n2017/01/18 11:32:40 [WARN] No route for localhost:9999/route\n2017/01/18 11:33:04 [INFO] consul: Health changed to #140\n2017/01/18 11:35:59 [INFO] consul: Health changed to #152\n2017/01/18 11:36:27 [INFO] consul: Health changed to #154\n2017/01/18 11:36:27 [INFO] Updated config to\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8081/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\n2017/01/18 11:36:29 [INFO] consul: Health changed to #155\n2017/01/18 11:36:29 [INFO] Updated config to\nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\n2017/01/18 11:36:29 [INFO] consul: Health changed to #156\nAre you sure your instances are announcing the correct ports to consul? Is the service running on port 8080 actually registering to consul with port 8080?. This looks like a consul issue. How do you register the health checks in consul?. @gagan2u2002 My guess is that you don't wait long enough after you've killed the service. Spring cloud by default checks every 10 seconds and has by default no timeout for the service check. You might want to set healthCheckInterval and healthCheckTimeout to 1s to see if this changes the behavior. These are the settings the demo/server uses and with this I was not able to reproduce your problem. I've started consul agent -server -dev, consul monitor -log-level=debug, server -prefix /foo and fabio before running kill -9 on the server process. Both consul and fabio picked up the change within a second.\nhttps://github.com/spring-cloud/spring-cloud-consul/blob/master/spring-cloud-consul-discovery/src/main/java/org/springframework/cloud/consul/discovery/ConsulDiscoveryProperties.java. @gagan2u2002 in the screenshot the instances running on port 8081 and 8082 are marked as critical. That's why fabio will not include them in the routing table. The Serf Health Check is ignored by fabio since it only states whether the consul agent where the service registered is healthy. This is no good indication of the service being healthy itself. \nIf this is the case then this isn't a bug but how fabio is designed to work. You need to check why the instances on port 8081 and 8082 produce a critical health check if one of the other instances went down. . If you shut down one instance and the other instances become critical in consul then there is a problem with your service registration. My guess is that you use the same value for spring.cloud.consul.discovery.health-check-url for all instances. \nCan you post the output of curl localhost:8500/v1/health/service/slpconsulDemo?pretty or whatever your service name is, please?. @alvaroaleman the reason it is like this was that I've built it like that in 2015 since that was my understanding on how this worked. So far this hasn't been a big issue. We've constructed our service ids as servicename-host:port which should make them unique cluster wide with little effort. #383 is probably along the same lines.\nCan you elaborate why cluster wide unique service ids like I've described are not achievable? I'm curious for the motivation. \nI'll have a look at this again since I'm only interested for this to work not this specific implementation.. Yes, I made a boo-boo. master has the fix already. Sorry about that.. Released 1.3.7. Released 1.3.7. Thanks for reporting this. I will have a look at this. Can you provide an example of a raw HTTP request that triggers that behavior?. OK, so the RequestURI contains an absolute URL. If I read https://www.w3.org/Protocols/rfc2616/rfc2616-sec5.html correctly, then clients should send this only to proxies but servers should always handle this. . @jorgemarey This patch should fix that. Could you test that, please? It just occurred to me that I also need to extend the test cases to cover that case. I'll do that later today before I merge the fix.. Well, you've done the heavy lifting. Thanks a lot for that. Can you confirm that it works for both types of requests: the ones with and without an absolute URL?. Merged to master.. registry.consul.kvpath needs to be an absolute path. Try prepending a / as in the default /fabio/config. The section in https://github.com/eBay/fabio/blob/master/fabio.properties#L416-L424 should probably mention that.. I'm going to close this one for now. Please feel free to comment if you have new info and I'll re-open if necessary.. Fixed. Thx.. Don't you have to map port 8500 into the fabio container as well if you're running it like this? Sorry, Docker noob here. . Also, what do the fabio logs say? If they can't get to consul then you should see this:\n2017/01/29 20:04:58 [FATAL] Error initializing backend. Get http://localhost:8500/v1/agent/self: dial tcp [::1]:8500: getsockopt: connection refused\n. You can't map port 8500 into different containers but don't you have to tell fabio where to find consul? It will be looking for localhost:8500 but that would be inside the container. So either you map your external consul endpoint into the container (not sure whether that's even possible) so that localhost:8500 is reachable from within the container or you need to provide -registry.consul.addr <consul ip>:8500 to fabio. . Re logs: a quick search reveals a docker logs <container name> command. That should tell you more.. You've got an update on this?. @digiman999 According to this document docker container linking is deprecated:\nhttps://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/. I'm no docker expert but this sequence of commands starts up fabio with consul in a Docker container. Maybe someone with more experience can comment on this:\ndocker pull consul\ndocker pull magiconair/fabio\ndocker run -d --name=consul -e 'CONSUL_BIND_INTERFACE=eth0' consul\ndocker logs consul # to get the ip address, in my case 172.17.0.2\ndocker run -d --name=fabio --link consul -e 'registry_consul_addr=172.17.0.2:8500' magiconair/fabio\nI think the default bridge networking bridges the two eth0 interfaces between the containers but that doesn't (shouldn't) work for the lo0 interface. So the way I understand this is that 127.0.0.1 in the consul container is different from 127.0.0.1 in the fabio container since these two interfaces aren't bridged. But again, take all this with a huge grain of salt since I've just skimmed over the Docker networking documentation and augmented this with some assumptions on how networks can/should work.. Since there is no more feedback I'll close this one for now. Please comment if there is something to add and I'll re-open if necessary.. The routing table is created from combining the generated and the manual rules by simply appending and then parsing them. Any parse error prevents the routing table from being updated. This keeps things simple and means less edge cases. However, this only refers to syntax errors. Referencing a nonexistent service is not a syntax error, though. So this sounds like a bug.\n. Hmm, I can't reproduce this on current master. I ran consul agent -server -dev, ./fabio and demo/server -prefix /foo which registers a service server in consul. Then I've added the following rule to the manual overrides:\nroute add fump /bar http://1.2.3.4:5678/\nwhich refers to a non-existent service on a non-existent endpoint. fabio picks up the routing table properly and calls to localhost:9999/foo still work as expected. \nCan you share your manual override entry which caused the error? Was there anything in the logs that could help track down the root cause?. Same behavior with 1.3.5, 1.3.6 and 1.3.7.. @rodriguezrps Any update?. I'm going to close this for now. Please feel free to comment and update once you have more info and I'll re-open as necessary.. @rodriguezrps I can reproduce this now. Might be a good idea to have an issue template which asks for steps to reproduce the problem, e.g.\n```\nstart consul\n$ consul agent -server -dev\nstart fabio\n$ fabio\nstart first server\n$ demo/server/server -addr 127.0.0.1:5000 -name svc-a -prefix /foo\nstart second server\n$ demo/server/server -addr 127.0.0.1:5000 -name svc-b -prefix /bar\nset manual overrides to\nroute weight svc-a /foo weight 0.8\nroute weight svc-c /bar weight 1.0\nfabio 1.3.5 responds with\n2017/02/28 15:13:15 [INFO] Updated config to\nroute add svc-a /foo http://127.0.0.1:5000/ weight 0.80 tags \"urlprefix-/foo\"\nroute add svc-b /bar http://127.0.0.1:5001/ tags \"urlprefix-/bar\"\nfabio 1.3.8 responds with\n2017/02/28 15:48:38 [WARN] route: no target match\n```\nThe bug is actually in v1.3.5 since the parser does not check and return the error of the AddRouteWeight() function which already returns errNoMatch. (https://github.com/eBay/fabio/blob/v1.3.5/route/parse.go#L235-L236) Actually, all three command methods do not return the error. (cough) The new parser which was introduced in 1.3.6 properly reports the errors which leads to this behavior. \nThe current behavior is the one I've intended to write but I agree that the parser should not bail on the manual overrides. I'll think a bit on how to properly fix this. \nThanks for finding this!. Good question.\nJust to clarify: /etc/nginx/clientcrts contains client certs which were signed by a self-signed root cert? Now you're wondering where the root cert should be so that fabio accepts them?. OK, I'll try to reproduce this and get back to you.\ncaupgcn does something different AFAIR. It \"upgrades\" a self-signed certificate to be used for client cert authentication (IsCA flag set) if the CN matches the provided name. This allows you to use a self-signed cert generated by the AWS console as a client cert. Otherwise, Go wouldn't accept it since the CA flag isn't set.. Not sure yet. Looking now.. Try adding the ca cert block to the client ca directory. That should pick it up. At least it does for me here. I'll push a small change that generates test certs with openssl and I should also update the startup log messages of the cert stores a bit. . Glad to help. :). If you see a lot of these messages then you have a flapping service in your setup. This message is printed when the internal state of the consul cluster changes which happens on registration or deregistration of a service or when the health endpoint of a service is flapping. My suggestion is to run consul monitor --log-level=debug and see what is going on. . Oh, and to answer your question: Yes, fabio acts on any change in the consul state, pulls the full state to build the routing table. The assumption is that your setup is stable once it has converged and that there isn't a lot of change. Hence, if you see a lot of change your setup isn't stable and hasn't converged.. Since this is the way the consul and it's blocking API works. consul maintains a replicated state among its master nodes. This state is indexed with a number - the version. Every time I make a query I get the version that result is based on as meta data in the response so that I can use that for subsequent queries, e.g. please notify me if your state changes beyond version X. As long as the state does not change (no service deployment, health change) fabio just performs a blocking wait (long poll) on the consul API. Once the state changes fabio pulls the full state, e.g. all services, all health checks to determine the new routing table. If the routing table did not change then fabio won't do anything to the main proxy thread but it will report that the consul state has changed nevertheless. This is an indication that something is constantly changing in the consul state, e.g. a service which doesn't have a urlprefix- tag.\nI may not need to report a change every time I get notified of one but it also provides an indication that there is something else going on in your system. fabio could also identify the delta and log it.. What do you mean by \"storage of health check output\"? Sure, I can cache the response but that doesn't change the fact that fabio has to pull the new state from consul to determine that there was no change. Try running consul monitor --log-level=debug to find the source of the state changes and your log files will be much smaller. We had the same issue internally where another group was seeing this and asked to remove that log output. I've urged them to find the root cause of the problem and once they did it wasn't a problem anymore.. Number 2: don't include volatile data in the health response (e.g. timestamp). We ran into that as well.. I've just mentioned this in a PR: We log about 15.000 lines or 1MB per day for 5000 req/sec on production. 90% of the log messages are for routes that don't exist. Once we remove that we should be at 100KB of logs per day. . I think we can close this one. Please comment if there is something to add and I'll re-open if necessary.. At this point this is the expected behavior. I agree that only (or additionally) logging the delta may be beneficial for debugging purposes and I may do that in the future. As stated in #226 the reason you are seeing thousands of messages of the routing table is because something in your environment is not stable. That is the only information you can derive from that. Once you find and fix that problem then you will only see the updated routing table. I'll add the delta thing to the list of things to add. This would indeed be useful.. If this is a production issue which you can't fix easily them I'm open to bump the priority on this. Usually, I push back on adding features which mask a different problem. For now just comment out the log lines and build it yourself. I'll see what I can do.. The other thing we're doing in QA environments is to run fabio via upstart and rotate the log files once they've reached a certain size.. I think we can close this one. Please comment if there is something to add and I'll re-open if necessary.. It doesn't need to. Just run multiple instances and distribute traffic across them. Check the wiki for deployment scenarios. . @TargetFocussed Check this: https://github.com/eBay/fabio/wiki/Deployment. Going to close this since you seem to create new issues for different questions - which is fine.. I'm not sure I understand what you mean. Can you elaborate, please?. You can have different services using the same urlprefix tag when you are migrating one endpoint from one service to another. That's a valid use case. . To make this more explicit: It is perfectly fine to have different services A and B expose /foo if they both provide the same functionality for /foo. Only you can determine that. If they behave differently they this is most likely a mistake but there are valid use cases for this.\nClosing for now. Please feel free to comment and I'll re-open if necessary.. Fabio does that automatically. There is no special configuration needed. Once you register your services in consul with the correct urlprefix- tags fabio will update a routing table every time you start, stop, install or remove a service. \nhttps://github.com/eBay/fabio#getting-started. Going to close this since you seem to create new issues for different questions - which is fine.. This looks like a duplicate of #223. Please have a look at the comment from @raben2 which describes how to use docker-compose for this.. This is a duplicate of #223.. Again, I'm no Docker expert and I suggest you look at the Docker compose setup referenced by @raben2 in #223. However, the following steps work for me:\n```\nstart consul in a container and note the IP address it is using\nin my case 172.17.0.2\ndocker run -e 'CONSUL_BIND_INTERFACE=eth0' consul\nstart fabio and expose the ports\ndocker run -p 9999:9999 -p 9998:9998 -e 'registry_consul_addr=172.17.0.2:8500' magiconair/fabio\nquery proxy interface\n$ curl -i localhost:9999/\nHTTP/1.1 404 Not Found\nDate: Tue, 07 Feb 2017 13:06:34 GMT\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\nquery ui interface\n$ curl -i localhost:9998/\nHTTP/1.1 303 See Other\nLocation: /routes\nDate: Tue, 07 Feb 2017 13:06:19 GMT\nContent-Length: 34\nContent-Type: text/html; charset=utf-8\nSee Other.\n```. Going to close this since you seem to create new issues for different questions - which is fine.. This depends a lot on what it is that you're trying to do, the scale that you need to handle and the type of environment you are deploying into (cloud, physical machines, ...)\nFor small applications I'd go with three VMs since this is the minimum you need for consul to work. Install consul, fabio and your app on the same machines and run them. Then you've achieved load balancing and high-availability since you don't have a single point of failure. \nIf the CPU load becomes too high check who is generating too much load. My guess is that this will be your app so then you move it to separate nodes. If consul/fabio node is still overloaded move fabio to separate nodes. If that still isn't enough start adding consul agents and have your application and fabio use the agents instead of the servers. But you need some significant load or seriously constrained machines to get there IMO.\nStart small and make sure that you can scale. Better than starting big and getting overwhelmed with the complexity.. Going to close this since you seem to create new issues for different questions - which is fine.. First, let me thank you for the PR even though you've closed it. Generally, I prefer to start larger changes with a discussion as outlined in https://github.com/eBay/fabio/wiki/Contributing but I should make this more visible in the README, I guess. It is somewhat hidden at the bottom of the Wiki.\nAs for the change itself, the reason I didn't choose to use a leveled log package like glog or logrus is simplicity. The default log package and the level prefix are good enough for what fabio needs to do. Therefore, this is one less dependency to worry about. Also, log level filtering has the potential that people want to tune out excessive logging instead of finding the root cause. Issue #226 is such an example where investigating the excessive logging lead to the discovery of volatile health checks. \nOur production service which handles about 5.000 req/sec generates 15.000 log lines or 1 MB per day with most of the log messages about routes that don't exist. Once we address that, we should have about 100KB of logs per day. Therefore, IMHO fabio does not log much and if it does you should find out why and not suppress it. \nFrank. Since this came up in #227 as well I think it could make sense to just log the delta instead of the full route table. I'm not a fan of log filtering for the reasons I've outlined. If the logging of the full routing table is your main concern then lets work on that. Also, if you want to do log filtering then there are easier ways to do this without the mdllog package which doesn't change code all over the place.. I need to dig this up but I think the general approach is to put a filter writer in the log output stream which allows only strings with a certain prefix. Lets first see whether #238 fixes your problem.. What does curl http://10.193.6.129:8500/v1/health/hello-world say?. I'm sorry but I'm out of advice. My gut feel is that you are doing something fundamentally wrong and that this is most likely a simple issue. I do not believe that you have found a bug in either fabio or consul. However, you have chosen a complex setup with spring-boot, registration frameworks, and docker to start with.\nWhat I would suggest at this point is to throw your sample project away. Don't use Docker or a framework at this point. Start with a simple java program that has just a Main class and uses only the consul api library. Make sure you read the https://github.com/eBay/fabio#getting-started section and make sure your service follows that. If you need inspiration you can look at the main function in demo/server/server.go. It has only 120 lines and does everything you need to do. (https://github.com/eBay/fabio/blob/master/demo/server/server.go#L46-L166)\nRun consul, fabio and your app instances locally in separate terminal windows, binding to 127.0.0.1 (again do not use Docker at this point) and figure out how to make that work. Then start a second instance of your service and make that work. If it doesn't then read the fabio Getting Started again and figure out how to get data out of consul using the command line tools. Then one step at a time add a different component towards the setup you want to have. What you will learn with this approach is how to check whether something works and where and how to look if it doesn't. \nPlease feel free to ask more questions in the future. I'll try to answer them as well as I can. At this point however I think you need to cover your basics first.. Yes, your understanding is correct. Try simplifying your setup until it works.\nFirst you should see the services in the consul ui and they should all have a green health check other than the SerfCheck. If you run them on different ports you don't need different VMs. Don't use registrator for now. Start from first principles.\nThis should work on your machine:\n```\nterminal 1\nconsul agent -server -dev -ui-dir \nterminal 2\nfabio\nterminal 3\ngo get github.com/eBay/fabio\ncd $GOPATH/src/github.com/eBay/fabio/demo/server\ngo build\n./server -addr 127.0.0.1:5000 -prefix /foo\nat this point you should see 'server' in the consul ui at localhost:8500\nyou should also see one entry in the fabio ui at localhost:9998\nthe fabio log should also print\n2017/02/18 19:49:48 [INFO] Config updates\n+ route add server /foo http://127.0.0.1:5000/ tags \"urlprefix-/foo\"\nterminal 4\ncurl localhost:9999/foo\nServing /foo from server on 127.0.0.1:5000\nterminal 5 (2nd instance of server)\n./server -prefix /foo -addr 127.0.0.1:5100\nnow try the curl command in terminal 4 a couple of times\nyou should see responses from both servers\n``. Here is a working version of the patch.diffis the new default and it marks all additions with a+ prefix and all deletions with a- ` prefix. Example:\n2017/02/09 16:01:48 [INFO] Config updates\n+ route add server /foo http://127.0.0.1:5000/ tags \"urlprefix-/foo\"\n+ route add server /bar http://127.0.0.1:5001/ tags \"urlprefix-/bar\"\n2017/02/09 16:01:48 [INFO] consul: Health changed to #235\n2017/02/09 16:01:50 [INFO] consul: Health changed to #236\n2017/02/09 16:01:50 [INFO] Config updates\n- route add server /bar http://127.0.0.1:5001/ tags \"urlprefix-/bar\"\nI am still unsure about two things:\n\nThe name of the config option looks a bit ugly. If someone has a better idea then pls come forward.\nI'm not sure if none should be an option at all for the reasons I've outlined earlier. I'm concerned that people will tune out the noise instead of fixing it\n\nJust realized that I still need to update the fabio.properties file. Will do that now.\n. @avichalbadaya Lets drop none and see whether someone wants it. I think your config name is better.. full -> all. Merged to master. @avichalbadaya Would you be willing to share some details about the scale of your project? Would you be interested in being listed in the README as one of the companies using fabio?. TBH, that's a good question. \nWhat we are doing\nWe have separate consul server clusters for the masters and then distinguish between frontend, backend and infrastructure (e.g. redis, kafka, ...) All frontend nodes have fabio installed and our phy lb in front of them is configured to route to them. Note that this is a dedicated physical setup.\nWhen rolling setups with TF and OpenStack I have created nodes using a golden image with consul/nomad/fabio, a blank image and install packages based on hostname consul00x/nomad00x/fabio00x or a salt configured setup but that's where I left it and it is actually one of the areas we are going to investigate in the following weeks. \nOpinion\nI consider fabio infrastructure which needs to be there (like your databases, queues, caches, ...) and doesn't need to scale that dynamically. We usually run it and literally forget that it is there.\nSo you could just run a couple of fabio nodes and be done with it. Or you run fabio on every node, or on every frontend node. Running three extra nodes may be a big deal or not. Ultimately, it doesn't matter.\nDocker\nAs for Docker or not: again that depends on your setup. My personal opinion is that if you are using Go static binaries you don't need Docker and that's the direction I've pushed my team in. I consider this the better long-term investment. However, if you're deploying everything with Docker I'd use fabio inside Docker for consistency reasons unless you have a performance issue.\nRecommendation\nGiven the choices I'd start with installing consul and nomad on every node and deploy fabio through nomad via the exec driver along the other services. Just treat it as another app. I assume you can configure the AWS LB to route inbound traffic to the fabio instances. Then analyze and see whether that's working. fabio doesn't consume much CPU and you can easily scale up, down or out. Keep it simple.\nP.S.: I usually ask myself: \"What is the simplest thing that can possibly work?\". I have to think about this a bit more and would encourage/ask the community to chip in with their experiences and setups. If you consider fabio infrastructure and run it as an app on the node itself you could alleviate your root concerns with the #195 patch. Since fabio is stateless there is no need to deploy it along with your app for the same reason you don't deploy nomad every time. . Sure. You can find me on LinkedIn. . I'll close this as a duplicate of #181 . The quickest thing I can think of is to register a second health check with both services which is only green for the active instance. Then fabio should behave the way you want.. For that approach you can guard the active service with a consul lock. In essence, you're performing a leader election and only the leader is active.. Would you mind posting your experiences here?. Is there a window where both primary and secondary can handle requests? I'd guess so since you want the old primary to complete existing requests while the new primary starts handling requests.\nAlso, what kind of throughput are you looking at and what latency do you expect for the failover?. I still think that adding a second health check for the service with a short check interval (1s or 500ms) which is only green for the leader is the simplest option. No re-registration necessary and since you already have the leader election code you only need to expose its status via the health endpoint.\nAlso, I'd optimize for the normal case which is orderly failovers. \n\nPrimary and secondary start up and register both in consul with the urlprefix tag and a check for the leader (short interval). Both fail\nLeader election makes one of the health checks green and within the check interval fabio starts routing.\nOn shutdown the primary gives up the lock, waits N*check interval and then fails the health check. Then it waits whatever grace period you need to complete existing requests. This provides a window long enough for the routing table to be updated. If you're really concerned you could fail the health check on the old master only after you've confirmed that the new master is accepting requests through fabio. That might be tricky depending on your network.\n\nfabio will complete existing requests after switching the routing table. . The reason I didn't consider this to be an issue is that fabio shouldn't be used for routing in the backend IMHO since consul already provides the necessary tools to do this. Couldn't you register your internal microservice in consul and have your other services discover it through the consul DNS interface?\nIf that isn't sufficient - and I am curious about your setup - then fabio should register its listeners as services in consul to advertise the ports IMO. I wouldn't rely on configuration since this has to be managed and that opens a lot of other issues. fabio has all the information and it can publish it. The question for me remains whether it needs to. . yes, fabio could advertise its listening ports in consul or some other registry. However, the part that is missing is automating the ELB configuration based on that. So if I understand you correctly you would want to automate the ELB configuration at runtime so that when a fabio starts up it registers its listeners in consul and the magic code reconfigures the ELB to route traffic to the fabio instances. Correct?. What are you trying to achieve?. If I understand you correctly, you want fabio to start, collect and report the spans for your microservices. This should be zipkin protocol compliant with gRPC as your transport, right?\nThis sounds like an interesting idea. Do you want to volunteer implementing this?. You already have metrics in fabio which report the throughput and latency per endpoint. Your services could just announce multiple endpoints to get different metrics. I'm not a gRPC expert but I assume that you can use different transport protocols for it. Are you exposing gRPC on the outside then?\nIf you move the zipkin layer into your frontend services then you could also route via the raw tcp service that I've just added to the 1.4 release branch. \n. As for supporting gRPC: fabio can route HTTP and HTTPS and soon TCP. If gRPC can work with these transport protocols then it is already supported. What else would you need?. The re-enable http/2 patch was a regression. HTTP/2 has been supported for incoming connections for quite some time but fabio still lacks the HTTP/2 outbound connections which is probably required for gRPC. This is something that I have on my plate for the next weeks together with the HTTPS support for upstream servers. The refactoring in the 1.4 branch paves the way for that. \nHowever, one of the issues with the typical HTTP/2 and HTTPS upstream support is the re-encryption of traffic which uses CPU resources and is essentially a man-in-the-middle attack on your data stream by breaking end-to-end encryption. \nFabio has a TCP+SNI proxy mode where it routes the encrypted connection via the server name in the TLS connection without decryption (e.g. urlprefix-user.app.com/). You can't do path based routing this way but depending on your application that may be enough. . From reading the docs this should just work out of the box. @jippi did you test that this doesn't work? I'll have a look this week. . @wv-myoung I can easily fork the net/http/httputil package for the moment until 1.9 is out and add the change if that's all it takes. I think I need to add something to the TLSClientConfig as well. I've tried to simulate this with the demo/server but didn't succeed yet. It might be worthwhile to add a gRPC mode there as well. \nThe main question for me is whether this can work on a regular https listener with auto-detection or whether we need a separate proto=grpc listener? . ok, that's good to know. Then I'll add a gRPC test to the integration test and see where that fails.. @wv-myoung and @jippi I've pushed a change with a test. I think the main catch for enabling http2 is to call http2.ConfigureTransport in main.go since I didn't have to change anything in the proxy code itself to make this work. \nI've created a gRPC service and server which I'm testing in an integration test which fails with go1.8 but works with gotip. I'd like to extend the demo/server to serve gRPC and write a simple gRPC client for that server to test this end-to-end since the code in the integration test does not use the makeTransport function which is used in main.go.\n```\n$ ~/go1.8.3/bin/go test -v -run GRPC github.com/fabiolb/fabio/proxy\n=== RUN   TestGRPC\n2017/06/14 13:08:57 gRPC echo server listening on  https://127.0.0.1:60710/echosvc.EchoSvc\n2017/06/14 13:08:57 http/2.0 server listening on  https://127.0.0.1:60711\n=== RUN   TestGRPC/https_direct\n=== RUN   TestGRPC/https_via_proxy\n=== RUN   TestGRPC/gRPC_direct\n=== RUN   TestGRPC/gRPC_via_proxy\n--- FAIL: TestGRPC (0.01s)\n    --- PASS: TestGRPC/https_direct (0.00s)\n    --- PASS: TestGRPC/https_via_proxy (0.00s)\n    --- PASS: TestGRPC/gRPC_direct (0.00s)\n    --- FAIL: TestGRPC/gRPC_via_proxy (0.00s)\n        grpc_integration_test.go:197: echosvc.Send failed:  rpc error: code = Internal desc = server closed the stream without sending trailers\nFAIL\n2017/06/14 13:08:57 transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:60710->127.0.0.1:60717: use of closed network connection\nexit status 1\nFAIL    github.com/fabiolb/fabio/proxy  0.027s\n$ ~/gotip/bin/go version\ngo version devel +17ba830f46 Wed Jun 14 06:05:05 2017 +0000 darwin/amd64\n$ ~/gotip/bin/go test -v -run GRPC github.com/fabiolb/fabio/proxy\n=== RUN   TestGRPC\n2017/06/14 13:08:51 gRPC echo server listening on  https://127.0.0.1:60697/echosvc.EchoSvc\n2017/06/14 13:08:51 http/2.0 server listening on  https://127.0.0.1:60698\n=== RUN   TestGRPC/https_direct\n=== RUN   TestGRPC/https_via_proxy\n=== RUN   TestGRPC/gRPC_direct\n=== RUN   TestGRPC/gRPC_via_proxy\n--- PASS: TestGRPC (0.01s)\n    --- PASS: TestGRPC/https_direct (0.00s)\n    --- PASS: TestGRPC/https_via_proxy (0.00s)\n    --- PASS: TestGRPC/gRPC_direct (0.00s)\n    --- PASS: TestGRPC/gRPC_via_proxy (0.00s)\nPASS\n2017/06/14 13:08:51 transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:60697->127.0.0.1:60704: use of closed network connection\nok      github.com/fabiolb/fabio/proxy  0.025s\n```\nThere is still the stray log line about the closed network connection. I need to see where this comes from. What was also unexpected is when you call w.WriteHeader(0) you get a missing status pseudo header response. This happens when the HTTPProxy has no NoRouteStatus code configured.\nI would appreciate if you could review the test setup since it took my some time to cobble it together. You most likely have some more experience with this. . @wv-myoung I'm not sure I understand the last statement. The upstream server needs proto=https since go does not support HTTP/2.0 without https? Why would the client need a tag? What am I missing?. Does gRPC work with HTTP 1.1? Go does not support HTTP/2 without TLS. The tlsskipverify option disables cert verification in fabio. . Well, if we can make it work with all transports then we should. I'll have a look whether I can make this work with http. Help is appreciated.. @DennisPersson Oh wow, I forgot about this one. I will have another look but if you want to help then this would be more than welcome.. @DennisPersson I've rebased the branch, fixed go vet issues and added the missing dependencies. I need to get up to speed again on the state. . @DennisPersson I think it would help if you test the branch and let me know what works and what doesn't. The more specific the better.. I've somewhat lost track of this. Could someone interested in this check whether #575 solves this use-case?. @aerickson Check out the -registry.consul.tagprefix parameter which should do what you want. Please let me know if you're looking for something else.\nhttps://github.com/eBay/fabio/blob/master/fabio.properties#L467-L475. @aerickson I'm going to close this issue for now since I believe that the solution I've provided answers your question. If it does not then please feel free to comment and I'll re-open if necessary. Thank you.. How about a generic log.target parameter that can take any number of log targets? \nlog.target = stderr,graylog[;addr=host:port][;proto=udp][;format=gelf],...\nTo implement this you could use a similar approach as for the cert source and use f.KVSliceVar() for parsing. However, the current KVSliceVar() code requires all values to have a name. You would then have to format the values as\nlog.target = target=stderr,target=gelf, ...\nThis feels like stuttering and it would make sense to extend the KVSliceVar() method with a prefix which is automatically added to all values before parsing. So you would call KVSliceVar(\"target=\", ....\nThis would also make sense for the metrics.target parameter.\nAlso, you need to have tests for all new command line parameters.. Since a number of people are showing interest in #80 we should try to come up with a unified approach to cover both. @raben2 are you still working on this?. @raben2 Then this can wait. Vacation is more important. Ping me when you're back.. @raben2 if your patch includes the changes from master then the rebasing didn't work properly. Could you try again, please? If your change is small enough then just squash it and force push. I usually don't care how one got there and look only at the end result. \nMake sure the vendored lib is in a separate commit. Sometimes I put the refactoring that is necessary to implement a feature into a separate commit. (e.g. replacing all log calls with some custom interface) to separate the refactoring from the actual feature. . @raben2 I've just pushed a change to the #80 branch to rename the logging parameters. I've moved them to the global level with log.* My suggestion for this PR is this:\n```\nthese should be the default values\nlog.graylog.protocol = gelf\nlog.graylog.transport = udp\nlog.graylog.addr = 127.0.0.1:12201\nthese should be optional\nlog.error.target = graylog\nlog.access.target = graylog\n``. This is on master now. @raben2 Are you still working on this?. @raben2 ping. Not yet but I could add that, e.g.urlprefix-/foo method=GET,POST?. Yeah, I thought that would be a simple change and started working on that but that rabbit hole is a bit deeper than I thought. Need to give this a bit more thought.. @ket4yii I think that is a different feature you're asking for which isredirect a -> b`. Not right now but you haven't been the first to ask. I'll add it at some point. Sorry, if I can't be more specific.. OK, I'll have another look. Started with this at some point but it took more time than I expected.\n. I wouldn't persist the table but wait for a first update before starting the listeners. . @taharah I've written a small patch which should do the trick. Can you check whether this works for you?. That sounds like a good idea since it provides more control over the defaults. I'm inclined to consider this an option of the listener since it more about the TLS handshake than managing certificates. \nI'd go with adding a tlsmin and ciphers option to the listener config. The challenge here is that ciphers would be a comma-sep list inside a semicolon sep list inside a comma-sep list, e.g.\nproxy.addr = :9999,:443;cs=ssl;tlsmin=1.2;ciphers=\"TLS_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,...\"\nSo you would have to first update the flagset code to ignore commas in a quoted string. I'd also allow both the hex code and the named constants which you should try to resolve via reflection to avoid future maintenance.. For the values of the tlsmin option I suggest to use the lower-cased constants without the Version prefix, e.g. ssl30, tls10, tls11, tls12, .... @ajlake Are you going to pick this up or shall I do this?. I'll have a look.. I've pushed a branch which contains a fix for this issue. You can add tlsmin, tlsmax and tlsciphers as listener options and the values are the ones defined in https://golang.org/pkg/crypto/tls/#pkg-constants. The tlsciphers are specified as a comma-separated list in a quoted string. This required replacing the simple string.Split approach of the old config parser to be replaced with a proper lexer and parser. \nExample:\nproxy.addr = :443;cs=ssl;tlsmin=0x301;tlsciphers=\"0xc00a,0xc02b\"\nI still need to add a test and update the documentation in fabio.properties but it would be great if someone could test whether this works.. I've split this into two issues:\n\nspecify the balancing algorithm in the tag, e.g. urlprefix-/foo strategy=rr (see #251)\nsupport least connections balancing (this ticket). Since I want to avoid keeping state across a cluster of fabio instances each fabio would have to keep its own LCR table per route. I'm trying to think whether this would defeat the purpose of this feature. I don't think so but I'm open for suggestions.. I am wondering how least conn routing interacts with weighted routes. How should this work if you want lconn routing but send 5% of traffic to the services with the green tag? \n\nI think to make this work you'd need a multi-stage selection process.\n\nFind the services which serve the route\nFind the set of services which should handle the request based on weight\nFind the instance which should handle the request based on the strategy. \n\nI could hack this into the existing code but this feels quite messy. Maybe a multi-stage filtering approach is better and more maintainable in the long run. A generic route filter function like the one below is probably more maintainable in the long run.\ntype RouteFilter = func(r []*Route) []*Route\n\nhostFilter, prefixFilter, weightFilter, lconnFilter, rndFilter, rrFilter, ...\n\nStart with all routes and apply the filters in a given order. At the end pick the first remaining target. This could create a lot of allocations but I might get around this.\nI have to play with this a bit.. The use case is that you use weighted routing for blue/green deployments and the least conn target selection to handle heterogeneous setups. I think the two concepts are orthogonal.. The LB weights are computed automatically.. This patch implements configurable target selection strategies via the urlprefix tag. You can test this with the demo server as follows:\n./server -addr 127.0.0.1:5000 -prefix \"/foo strategy=rr,/bar strategy=rnd\"\n./server -addr 127.0.0.1:5001 -prefix \"/foo strategy=rr,/bar strategy=rnd\"\nThen try to access curl localhost:9999/foo and curl localhost:9999/bar repeatedly to see the difference in behavior. If no strategy is specified the default strategy as configured in proxy.strategy is used.\nOne requirement is that all servers announcing the same route must specify the same strategy for this to work reliably. Otherwise the behavior is undefined. The current implementation is that the last configured value wins. . @jamesrwu still need to implement the least conn routing (#250). I'm wondering whether this is related to #101 (sticky load balancing).. I already have variable expansion for the ${DC} variable which contains the consul data center. It is a trivial fix to also include the node meta data and lets say the node name and the address for example. However, since your services only have handlers for /service-A you would need to add the node name to the front and then use path stripping to get rid of it again, e.g. urlprefix-/${node}/foo strip=/${node} (note that this doesn't work yet since there is no expansion on the options) However, I don't know how this would affect your URLs.\nThe strip operator is really a strip prefix operator right now. I'd need to extend the syntax to do suffix stripping or general omission, e.g. strip=/${node}^ for suffix and strip=*/${node}/* or something similar. Another option could be to just say how many elements of the URL should be stripped since we know we're dealing with URLs. \n```\nstrip 1 element from the front of the URI '/foo'\nurlprefix-/foo/bar strip=1\nstrip 1 element from the back of the URI '/bar'\nurlprefix-/foo/bar strip=-1\n```\nI think this is very much sticky load balancing since in essence you want all your requests for a specific route to go to the same server except that the LB shouldn't make the initial routing decision. You want to pick the host yourself. If fabio would honor a cookie or a header you can set you could achieve the same thing. \nI haven't settled on an approach yet since I'm trying to figure out how to square this. Can you explain your specific use case?. Why don't you just announce a unique route for that host, e.g. urlprefix-/admin/$HOSTNAME?. You would need to have a handler for that on the upstream server though. yes, once I finish the refactoring to support tags in metrics.. Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. No, there isn't at the moment but I can add it. This is a duplicate of #168. Could you please subscribe to that issue? Thx. Not at the moment. What are you looking for?. How do you identify responses that can be cached and for how long?. Are both checks in consul green? Is the consul cluster healthy?\nCan you provide curl -i localhost:8500/v1/health/service/sampleservice?pretty ?\nAs a side note: use a unique id value for your service, e.g. <name>-<addr>-<port> Otherwise, this won't work with multiple instances.. what does curl -i http://192.168.0.11:8080/foo return?. Can you provide curl -i localhost:8500/v1/health/service/sampleservice?pretty?. My suspicion is that your consul servers aren't talking to each other. That fabio is talking to consul on 192.168.0.10 and your service is registered on 192.168.0.11.\nHow did you configure the consul cluster? Can you provide the full and exact commands you ran?\nCan you also provide the fabio log? When it starts up it should have a log line like this:\nroute add sampleservice /foo http://192.168.0.11:8088/\nCan you provide the output of curl -i http://192.168.0.10/v1/health/service/sampleservice?pretty. . ok, then fabio has found the service and added a route. Therefore, the consul setup is correct. Can provide the full command and output of these commands assuming fabio listens on port 9999:\ncurl -i http://192.168.0.10:9999/foo \ncurl -i http://192.168.0.11:8088/foo. Also, are you sure you've registered the second node with node name n1? The health check says n2. I suggest copying the commands you typed from the terminal or the shell history.. Sorry, grasping at straws here. I'm sure this is something trivial but I don't see it. If this wouldn't work nothing would work. So bear with me.. I'm glad you found it. Can you say what the problem was?\nFrank Schr\u00f6der\n\nOn 5. Apr 2017, at 03:38, badounan notifications@github.com wrote:\nClosed #256.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @shadowfax-chc Thanks for working on this but this isn't correct.\n\nThere are two TCP connections in play here: one inbound and one outbound/upstream. The listener is the inbound TCP connection and the proxy is the outbound TCP connection. To allow outbound https connections you only need to set the protocol in the target URL which your first patch accomplishes. The Go std library should do the rest. \nThis requires however that the certificates can be validated through the default root CAs as configured on the system. If you want to allow certificate verification with a custom certificate source then this must be configured in the route command/urlprefix- tag.\nLets start with supporting skipVerify on the outbound connection since this is rather simple and should solve most of the problems. Supporting custom root CAs would require to either override the http.Client that is used by the reverse proxy (which isn't possible ATM) or use a custom transport per request (which defeats connection caching). This most likely requires a somewhat larger refactor. \nTo support skipVerify you need to do several things:\n\nAdd a TLSSkipVerify bool flag to the route.Target and set it in the route.addTarget method in route/route.go\nCreate another http.Transport which has the InsecureSkipVerify flag set to true and store it in the HTTPProxy.\nPick which transport to use in the HTTPProxy.ServeHTTP method based on the flag in the selected target.\n\nOnce we find a way to have a custom client/transport per request this solution can easily be refactored.\nYou don't have to (and shouldn't) configure the Listener since this is for the inbound connection. skipVerify may be useful here as well but that's a different thing. \nAlso, please provide an integration test for both cases in proxy/http_integration_test.go.. Oh, I can actually change the files myself now. Interesting. Didn't know that.. I'll try that on the next PR, though.. LGTM. Merged it. Thank you!. Did you see the comment about using a cert store instead of certFile/keyFile?\n\nI'm wondering whether it would make more sense to just configure another cert source since there already is all the cert management there. Although this seems like a lean approach to the problem it feels redundant. What if you just add a cs= option to the ui listener?. @shadowfax-chc BTW, going to bed now. I'm on the CEST timezone. You're in NZ?. It just occurred to me again why the cert stores are there in the first place: so that you do not have to distribute the certificates to every fabio node with something like puppet or chef. Yes, there are the file and path stores if you have that in place already but the other stores are for a centralized cert management where you can just run a fabio instance and run it without further config.\n\nTherefore, this needs to use the cert stores. Sorry, that I didn't realize this sooner.\nWhat you need to change is the following:\nIf you replace the UI.Addr string field with a UI.Listen Listen field and update the config parser so that ui.addr is parsed with parseListen then you should have all the things necessary to do this. This would also allow to configure read and write timeouts on the UI listener. \nAt that point you can use proxy.ListenAndServeHTTP to start the admin server which will do the right thing. It might make sense to move the listen/serve code out of the proxy package but I can do that later. \nCheckScheme is then https if cfg.UI.Listen.CertSource != \"\"\nYou also wouldn't need a ui.cs since proxy.cs already have names and you can have more than one, e.g. ./fabio -proxy.cs 'cs=proxy;type=http;...,cs=ui;type=path;...' -proxy.addr ':443;cs=proxy' -proxy.ui ':9998;cs=ui'\nAt some point I want to refactor the code a bit to have generic providers like a CertProvider, RouteProvider, LogProvider, ... since this seems to become a bit messy but I need to think about that a bit more.. Thank you.. I can't figure out how I could push a set of simple changes to your branch since I prefer a single commit for a change. I'm used to the gerrit workflow where multiple people can collaborate on a single change until it is right without creating different branches but can't figure out a good way of doing this on github. Maybe you have an idea. \nI've done some simple cleanup. Basically, UIAddr -> UIListenerValue, drop else in favor of init with default value, drop else by checking pre-condition first and create... -> make... Could you pls review whether that broke anything? If not, then pls add this and I'll squash merge it tomorrow.\n```patch\ndiff --git a/config/default.go b/config/default.go\nindex 1abf758..3e187d5 100644\n--- a/config/default.go\n+++ b/config/default.go\n@@ -10,12 +10,12 @@ var defaultValues = struct {\n    CertSourcesValue      []map[string]string\n    ReadTimeout           time.Duration\n    WriteTimeout          time.Duration\n-   UIAddr                string\n+   UIListenerValue       string\n    GZIPContentTypesValue string\n }{\n    ListenerValue:    []string{\":9999\"},\n    CertSourcesValue: []map[string]string{},\n-   UIAddr:           \":9998\",\n+   UIListenerValue:  \":9998\",\n }\nvar defaultConfig = &Config{\ndiff --git a/config/load.go b/config/load.go\nindex d569360..d91b8fd 100644\n--- a/config/load.go\n+++ b/config/load.go\n@@ -109,9 +109,9 @@ func load(cmdline, environ, envprefix []string, props *properties.Properties) (c\n// config values\nvar listenerValue []string\n\n\nvar uiListenerValue string\n    var certSourcesValue []map[string]string\n    var readTimeout, writeTimeout time.Duration\n\nvar uiAddrValue string\n    var gzipContentTypesValue string\nf.IntVar(&cfg.Proxy.MaxConn, \"proxy.maxconn\", defaultConfig.Proxy.MaxConn, \"maximum number of cached connections\")\n@@ -164,7 +164,7 @@ func load(cmdline, environ, envprefix []string, props *properties.Properties) (c\nf.DurationVar(&cfg.Registry.Consul.CheckTimeout, \"registry.consul.register.checkTimeout\", defaultConfig.Registry.Consul.CheckTimeout, \"service check timeout\")\nf.IntVar(&cfg.Runtime.GOGC, \"runtime.gogc\", defaultConfig.Runtime.GOGC, \"sets runtime.GOGC\")\nf.IntVar(&cfg.Runtime.GOMAXPROCS, \"runtime.gomaxprocs\", defaultConfig.Runtime.GOMAXPROCS, \"sets runtime.GOMAXPROCS\")\n-   f.StringVar(&uiAddrValue, \"ui.addr\", defaultValues.UIAddr, \"Address the UI/API is listening on\")\n+   f.StringVar(&uiListenerValue, \"ui.addr\", defaultValues.UIListenerValue, \"Address the UI/API is listening on\")\nf.StringVar(&cfg.UI.Color, \"ui.color\", defaultConfig.UI.Color, \"background color of the UI\")\nf.StringVar(&cfg.UI.Title, \"ui.title\", defaultConfig.UI.Title, \"optional title for the UI\")\n\n\n@@ -192,8 +192,8 @@ func load(cmdline, environ, envprefix []string, props *properties.Properties) (c\n        return nil, err\n    }\n\nif uiAddrValue != \"\" {\ncfg.UI.Listen, err = parseListen(uiAddrValue, certSources, 0, 0)\nif uiListenerValue != \"\" {\n\ncfg.UI.Listen, err = parseListen(uiListenerValue, certSources, 0, 0)\n        if err != nil {\n            return nil, err\n        }\n@@ -204,10 +204,9 @@ func load(cmdline, environ, envprefix []string, props *properties.Properties) (c\n        return nil, err\n    }\n\n\ncfg.Registry.Consul.CheckScheme = defaultConfig.Registry.Consul.CheckScheme\n    if cfg.UI.Listen.CertSource.Name != \"\" {\n        cfg.Registry.Consul.CheckScheme = \"https\"\n\n} else {\n\ncfg.Registry.Consul.CheckScheme = defaultConfig.Registry.Consul.CheckScheme\n    }\nif gzipContentTypesValue != \"\" {\ndiff --git a/main.go b/main.go\nindex b893ed6..472fe7e 100644\n--- a/main.go\n+++ b/main.go\n@@ -161,17 +161,17 @@ func lookupHostFn(cfg *config.Config) func(string) string {\n}\n }\n\n\n-func createTLSConfig(l config.Listen) tls.Config {\n-   var tlscfg tls.Config\n-   if l.CertSource.Name != \"\" {\n-       src, err := cert.NewSource(l.CertSource)\n-       if err != nil {\n-           exit.Fatalf(\"[FATAL] Failed to create cert source %s. %s\", l.CertSource.Name, err)\n-       }\n-       tlscfg, err = cert.TLSConfig(src, l.StrictMatch)\n-       if err != nil {\n-           exit.Fatalf(\"[FATAL] Failed to create TLS config for cert source %s. %s\", l.CertSource.Name, err)\n-       }\n+func makeTLSConfig(l config.Listen) tls.Config {\n+   if l.CertSource.Name == \"\" {\n+       return nil\n+   }\n+   src, err := cert.NewSource(l.CertSource)\n+   if err != nil {\n+       exit.Fatalf(\"[FATAL] Failed to create cert source %s. %s\", l.CertSource.Name, err)\n+   }\n+   tlscfg, err := cert.TLSConfig(src, l.StrictMatch)\n+   if err != nil {\n+       exit.Fatalf(\"[FATAL] Failed to create TLS config for cert source %s. %s\", l.CertSource.Name, err)\n    }\n    return tlscfg\n }\n@@ -180,7 +180,7 @@ func startAdmin(cfg config.Config) {\n    log.Printf(\"[INFO] Admin server listening on %q\", cfg.UI.Listen.Addr)\n    go func() {\n        l := cfg.UI.Listen\n-       tlscfg := createTLSConfig(l)\n+       tlscfg := makeTLSConfig(l)\n        srv := &admin.Server{\n            Color:    cfg.UI.Color,\n            Title:    cfg.UI.Title,\n@@ -196,7 +196,7 @@ func startAdmin(cfg *config.Config) {\nfunc startServers(cfg *config.Config) {\n    for _, l := range cfg.Listen {\n-       tlscfg := createTLSConfig(l)\n+       tlscfg := makeTLSConfig(l)\n    log.Printf(\"[INFO] %s proxy listening on %s\", strings.ToUpper(l.Proto), l.Addr)\n    if tlscfg != nil && tlscfg.ClientAuth == tls.RequireAndVerifyClientCert {\n\ndiff --git a/registry/consul/backend.go b/registry/consul/backend.go\nindex e06f186..3ad0ece 100644\n--- a/registry/consul/backend.go\n+++ b/registry/consul/backend.go\n@@ -42,7 +42,7 @@ func (b *be) Register() error {\n        return nil\n    }\n\nservice, err := serviceRegistration(b.cfg.ServiceAddr, b.cfg.ServiceName, b.cfg.ServiceTags, b.cfg.CheckInterval, b.cfg.CheckTimeout, b.cfg.CheckScheme)\nservice, err := serviceRegistration(b.cfg)\n    if err != nil {\n        return err\n    }\ndiff --git a/registry/consul/register.go b/registry/consul/register.go\nindex 760e02b..021dbee 100644\n--- a/registry/consul/register.go\n+++ b/registry/consul/register.go\n@@ -76,12 +76,12 @@ func register(c api.Client, service api.AgentServiceRegistration) (dereg chan\n    return dereg\n }\n\n-func serviceRegistration(addr, name string, tags []string, interval, timeout time.Duration, checkScheme string) (api.AgentServiceRegistration, error) {\n+func serviceRegistration(cfg config.Consul) (*api.AgentServiceRegistration, error) {\n    hostname, err := os.Hostname()\n    if err != nil {\n        return nil, err\n    }\n-   ipstr, portstr, err := net.SplitHostPort(addr)\n+   ipstr, portstr, err := net.SplitHostPort(cfg.ServiceAddr)\n    if err != nil {\n        return nil, err\n    }\n@@ -101,23 +101,23 @@ func serviceRegistration(addr, name string, tags []string, interval, timeout tim\n        }\n    }\n\nserviceID := fmt.Sprintf(\"%s-%s-%d\", name, hostname, port)\n\nserviceID := fmt.Sprintf(\"%s-%s-%d\", cfg.ServiceName, hostname, port)\n\n\ncheckURL := fmt.Sprintf(\"%s://%s:%d/health\", checkScheme, ip, port)\n\ncheckURL := fmt.Sprintf(\"%s://%s:%d/health\", cfg.CheckScheme, ip, port)\n    if ip.To16() != nil {\ncheckURL = fmt.Sprintf(\"%s://[%s]:%d/health\", checkScheme, ip, port)\n\ncheckURL = fmt.Sprintf(\"%s://[%s]:%d/health\", cfg.CheckScheme, ip, port)\n    }\nservice := &api.AgentServiceRegistration{\n    ID:      serviceID,\n-       Name:    name,\n+       Name:    cfg.ServiceName,\n    Address: ip.String(),\n    Port:    port,\n-       Tags:    tags,\n+       Tags:    cfg.ServiceTags,\n    Check: &api.AgentServiceCheck{\n        HTTP:     checkURL,\n-           Interval: interval.String(),\n-           Timeout:  timeout.String(),\n+           Interval: cfg.CheckInterval.String(),\n+           Timeout:  cfg.CheckTimeout.String(),\n    },\n}\n```. LGTM. You mean in the UI?. Yeah, I missed that in the PR. Also the demo server needs some work and I'll update the docs on the wiki.. These are not individual tags but options for the route. A service can publish more than one route and they can all have different options. \n\n\nTry ci-fabio-/users proto=https tlsskipverify=true as one tag. That should produce the following route:\nroute add srv /users https://1.2.3.4:5678 opts \"tlsskipverify=true proto=https\"\nI'll make sure that this is clear in the documentation.. You register the tag as one value, e.g.\n\"ServiceTags\": [\n  \"ci-fabio-/users proto=https tlsskipverify=true\",\n],\n. Try opts instead of tags. I'll update the docs on the Wiki. I'll have a look. No, that isn't possible right now. You could use Traffic Shaping to send a small amount of traffic to another server but this isn't duplicating the request. \nCould you explain your use case a bit more? My guess is testing but then your R&D server would need to be able to handle production load. Are there other proxies that support this?. The reason I started doing this is to provide a build of the same code version but with a different go version if a security update for Go became available. This happened for v1.3.3 and v1.3.5 and I've also provided both v1.3.8 as a go1.7.5 and go1.8 build and for v1.2.1 to provide a go1.6.3 and a go1.7 build. This allows for testing of fabio with a new Go version and fall back to the older version if there are issues.\nI could solve this differently, mainly by spinning a new version when I upgrade Go and then add that to the changelog. However, since I merge current changes to master between releases this would mean that I would have to keep changes between versions in a branch or I would have to create release branches or more complex version numbers.\nI'm not against changing this but I want to retain the aforementioned abilities since I think they are useful. \nSince the fabio repo is completely self contained you can just build it yourself or just strip off the go version from the file name.\nDoes that make sense?. @kostyrev No worries. The idea is that you can have a different set of certificates for different listeners. Therefore, the thing that manages the certificates (cert store) is decoupled from the thing that uses them (listener). \nQuestions like this are good to understand where the documentation could use some love. So please keep asking.. How often did this happen and how many failures did you see? What was the CPU load during the test?I haven't seen this error but my guess is that you should see some aborted connections/requests on the upstream servers as well. Could you run the same test on the HTTP port as well? . Did you try the OpenBSD binary from the 1.4.2 release?\nhttps://github.com/fabiolb/fabio/releases/tag/v1.4.2\nGOMAXPROCS only affects how many OS threads are created. Since Go has a cooperative scheduler this has no effect on the number of requests it can handle. On a single core system GOMAXPROCS will be set to 1. However, I don't think that this is the problem. I'm no OpenBSD expert. Is this a 32 or 64 bit system?. Try with -tags \"netgo\". Good catch. I'll fix that. . Pushed a change for catching the errors. As for the listener you might want to try tcp6 or tcp4 here to see whether that makes a difference:\nhttps://github.com/fabiolb/fabio/blob/master/proxy/listen.go#L19. @rodrigoraval Are you sure you're in the right project? fabio is not haproxy. I'm going to close this since I believe you're posting this in the wrong project. Feel free to comment in case I'm wrong.. TCP Services are routed by port only. \nIf this is an HTTP service just drop the proto=tcp and register urlprefix-host/path as tag. \nCheck the Readme. It has examples. . Glad it works now :). fabio.properties also needs to be updated. Could you please add that?. You should remove the line from the defaultConfig only. Leave the rest. . Made some minor text changes in the fabio.properties and then merged it. Thanks for providing this patch! :). My bad. I need to update the docs more consistently. The opts from the config file are different than the opts on the routes. Right now the following opts are supported on a route:\nstrip=/foo         # strip '/foo' from the call to the upstream server\nproto=tcp          # tcp upstream\nproto=https        # https upstream\ntlsskipverify=true # skip upstream tls verification\nI'll update the docs.. What do you need this for?. How would this work for multiple fabio instances?. If you have one service that can handle 10 connections and announces it through consul this is simple to keep track of if you have a single fabio instance. However, once you spin up the next one (for LB or HA purposes) then all fabios need to coordinate since the service can only handle 10 connections. So how would this work in if the number of fabio instances is dynamic, i.e. they can come and go?. I've updated the main README, the route config language docs on the wiki (https://github.com/fabiolb/fabio/wiki/Routing#config-language), the Quickstart on the Wiki (https://github.com/fabiolb/fabio/wiki/Quickstart) and the online documentation in fabio itself.\nI'm going to merge this change and close this ticket since this the original question was about documentation and I don't want to morph tickets. I'll open another ticket for the maxconn question.. So wss:// works to the upstream server but not to fabio? Since WS is just HTTP this should just work and if it doesn't then this sounds like a bug. I can have a look but I'm a bit busy right now. Feel free to dig into this and send a PR, though.. I think this is the problem:\nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_proxy.go#L105\nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_raw_handler.go#L38-L43\nThe websocket traffic is tunneled via a TCP connection which isn't using the same TLS connection setup that is used for HTTPS.. @deuch I have provided a patch which should fix the problem. I think I've tested all the combinations. You can find the test in the proxy/ws_integration_test.go. Could you test whether that works for you, please?. Pls ignore the last commit about the access log field. I had a typo in the commit msg.. @deuch Cool and thanks. Enjoy your weekend.. @shadowfax-chc That's good to know. Thanks for testing this.. If this is a different issue then could you please open a separate issue?. merged. Sounds like #224 . @sielaq I'm falling a bit behind :( I'll try to catch up on open issues .... Good catch. . Merged. Sure. Was expecting that this would happen at some time.. @deuch I've pushed a change that should make the token renew interval configurable. You have to set the renewtoken option in the proxy.cs statement. Could you check whether that solves the problem for you?. @deuch Hmm, I could check whether the SO_REUSEADDR is used. How did you kill fabio? kill -9? \nCan you try with a different port or wait a bit? I think 2 min is the timeout. I just want to confirm that the vault change works. . That looks strange. I'll have a look.. also fails like this\n./fabio -proxy.addr ':9999,:10000'\n...\n2017/04/28 07:19:14 [FATAL] listen: Fail to listen. listen tcp :10000: bind: address already in use\n2017/04/28 07:19:14 [FATAL] http: Server closed\n2017/04/28 07:19:14 [FATAL] ui: http: Server closed\nI'll open another ticket. Thanks for finding this.. I've opened #279 and found the issue.. I've fixed #279 and rebased the patch. Could you please try again?. @vjeantet I think the patch from @jen20 looks OK. If you can rebase that for master then we can merge it.. Thanks. I'm glad you like it :)\nI've added a patch which should do what you want. This sounds like a good idea and the metrics should probably expose that as well. Could you let me know whether that works for you?. Erm, the metrics already export this. Time for \u2615\ufe0f Enjoy \ud83d\ude04 . yeah ;) it is merged now. Have fun. git bisect identifies 5a23cb19dc64a30ee40c42bd3ec1dde289a91033 for #265 but I have a feeling that this just exposes the problem since errors are now fatal. v1.4.3 works.. Since these are not fabio but protocol specific headers I'd prefer to drop the Fabio- prefix. Just use Tls-Version, Tls-Cipher and Http-Proto since the X-Forwarded-Proto also doesn't spell out Protocol. In general, I prefer the header names to be configurable to provide mechanisms for avoiding conflicts with existing setups. Disabling the header could then be achieved by setting them to empty values. However, then three parameters would have to be configured to fully disable them. \nI'm reluctant for a general info.disabled flag since info is too general. All the X-Forwarded-* and X-Real* headers also contain information. What qualifies a header as an info header?\nOpinions welcome.. @hkolk What if we add the fields to the Forwarded header instead of introducing new headers? It is already provided and contains information about the connection. We can just add some fields, e.g. tlsver, tlscipher and httpproto?. @hkolk I've pushed a change which adds the fields to the Forwarded header as described. Could you check whether this works for you? If possible, I'd like to merge this to next release this week.. Example:\nForwarded: for=1.2.3.4; proto=https; httpproto=http/1.1; tlsver=tls10; tlscipher=0xc023. I need to check the code but what happens when you define node-4 with weight 0? If I didn't special case it then it should receive 100% of the traffic if the other services are not there. However, weight is not the right concept here since weight 0 would be counter intuitive. Sounds more like a priority concept. . Yes, I understand what you're looking for. I was thinking whether weight 0 has the effect you're looking for as an unintended side-effect. Using a priority would allow to always register a maintenance page under / with prio 999 for example so that when no service is up the maintenance page is shown. I need to think about this a bit more. . Is this a weight for a non-existing service? See #224\nBut in general I agree. There needs to be better feedback. . I'm going to make fabio ignore syntax errors in routes and just log about them. Blocking the update of the routing table isn't a good approach.. For TCP proxying to work two things need to happen:\n\n\nfabio needs to know that traffic on a given port is to be handled by the TCP proxy (i.e. copy bytes around instead of parsing HTTP requests). This is why you have to configure the TCP listener with -proxy.addr :3306;proto=tcp. Port 3306 in this example is the port on which the exposed service is available to the outside world.\n\n\nservices which can handle that traffic need to tell fabio that they want traffic that arrives on port 3306 on fabio. The service itself runs on a random port. This is why the service advertises urlprefix-:3306 proto=tcp.\n\n\nSo with this in mind lets go through your questions:\n\nyes, you have to configure a TCP listener on fabio for every exposed port (not service) since I haven't implemented dynamic listeners at the moment. This will come but it isn't there yet.\nif you want to expose multiple ports do this -proxy.addr = :25;proto=tcp,:143;proto=tcp,:587;proto=tcp,:993;proto=tcp it is a comma separated list of semicolon separated k=v pairs (imagine the first entry having a default key like port)\nnot right now since this isn't a consul problem but there is no code in fabio ATM to bring up and shutdown listeners automatically. It'll come.\ntry the listener config in 2. and make sure your services are registered with the urlprefix-:25 proto=tcp, urlprefix-:143 proto=tcp ,... tags in consul \n\nLet me know if that answers your question.. proxy.header.* only matters for HTTP(S) proxies. You can terminate TLS on fabio or not. In plain TCP mode fabio should just copy the bytes it receives to the service. you can use openssl s_client for testing. . Service discovery is done through consul. Fabio finds the service instances that are registered in consul and starts routing to them once they appear and stops routing when they are gone. This is different from other proxies where you have to configure the upstream servers. \nAs for the bind address: proxy.addr=:587 is the same as proxy.addr=0.0.0.0:587 which will listen on all interfaces. Currently there is no method to say proxy.addr=eth0:587 but I'm planning on doing that. Therefore, you either have fabio listen on all interfaces or you have to configure it per host either through the config file or startup parameters or env vars. All will work for every parameter in fabio.properties. . Let me see what I can hack together. This isn't difficult. Didn't have the need for it yet since you would need to run fabio via something like supervisord, daemontools or systemd anyway which can do that little bit of shell magic.. You can always use the shell to get the ip address, e.g.:\nshell\nfabio -proxy_addr \"$(ifconfig eth0 | grep 'inet addr:' | awk '{print $2}' | cut -d: -f2):3600;proto=tcp\". listen_ip isn't going to happen since you can have more than one listener.. As I've said, use the shell to get the ip address(es) you want fabio to bind to and then run fabio -proxy.addr \"1.2.3.4:3306;proto=tcp,5.6.7.8:9876,...\". Maybe lets take a step back and explain what it is that you're trying to do. Since you mention marathon the setup is a bit more complex. (This should have registered when you mentioned PanteraS).\nThe usual deployment scenarios are listed here: https://github.com/fabiolb/fabio/wiki/Deployment\nCould you explain briefly what your setup looks like?. I'm sorry but I still don't fully understand the problem you're trying to solve. Could you please try to explain it briefly again? Who is connecting to whom, with which protocol and what isn't working?. 1. yes, no solution right now other than generating the config file using consul-template for example.\n2. use a shell script or consul-template to determine that\n3. using iptables and private ip addresses is like using belts and suspenders. When you use iptables to block all ports you can have fabio bind to :port. Otherwise, use consul-template for now. \nSo what I understand is that fabio basically works but the ip and listener configuration isn't flexible enough for your use case. While I can add something like bind to interface quickly I can't provide dynamic listeners that easily. \nI think for now consul-template is your best option to generate the config file you need and have fabio restarted on change. . Why can't you use a shell script to determine the ip address in the meantime as outlined here?\nhttps://github.com/fabiolb/fabio/issues/283#issuecomment-299138617\nThis shouldn't be blocking.. But if you run ./fabio -proxy.addr 'eth0:9999' you have the same problem. I think what you need is https://github.com/hashicorp/go-sockaddr and the template language to find a private ip address. This is what we're using in consul. . I was going to say that 880Kb of JavaScript is more than enough until I saw that Fabio almost doubles it :) Please let me know what you find. This is the first time I hear about it.. I don't see any compression headers. AFAIR, the Go http client automatically decompresses the response body. Can you check if the content is the same (md5 hash it to be sure)?. What should fabio conclude when consul is down? Does that mean your services are gone as well? How often do you have issues with your consul cluster? fabio will continue to serve the last known good routing table. In the two years I've had this in prod we didn't have issues with it. Just as with fabio consul was one of the tools we simply forgot was there. \nIf you don't want to rely on fabio then check consul instead.. This isn't a simple change since the configuration that is served via the config file is usually the static configuration like headers and listener config. However, I'm curious why you would want to do this in the first place? fabio is zero-conf in respect of the services. All service changes are handled without restart and loss of existing connections. We ran fabio for months without restarting it. \nWhat is it that you want to change on a regular basis that requires a fabio restart?. This isn't impossible but not a trivial change and I'd like to see more concrete examples of where this is really a recurring production issue. For the case of cert stores I might be able to handle this in a different way. \nI'm going to close this one but I'm open for additional suggestions and may re-open at a later point.. @SoMuchToGrok so in essence you want to refresh a cert after 50% of its TTL, right? Cert stores already provide a mechanism to reload certs on the fly. I could make that logic more flexible. What I'd like to avoid is to provide the sense of reloadable config in general since so far I'd like to see some more examples of where this is necessary.. @SoMuchToGrok please :). I can always fork httputil.ReverseProxy and hack this in. Then file an issue with the Go team and hope for a future fix. . What is the behavior you would like to see?. Also, I'm already injecting a single-use round tripper which captures the *http.Response so that I can use it for access logging. I've just pushed a change that captures the error there as well. This allowed me to simplify that code. \nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_handler.go#L31-L43. Checkout the path, consul, http or vault cert store. They all support multiple certs based on SNI.. https://github.com/fabiolb/fabio/blob/master/fabio.properties#L27-L51\nYou create a directory for the certificates and put them there. Then you configure a path cert source, e.g.\nfabio -proxy.cs 'cs=ssl;type=path;cert=path/to/certs' -proxy.addr ':443;cs=ssl'\nThen in path/to/certs you put\nfoo.com-cert.pem\nfoo.com-key.pem\nbar.com.pem # contains both cert and key\nFor a request on port 443 fabio will check whether it can find a matching cert based on the server name.. Cool. Glad I could help.. you're also correct with the logging.. Almost there. For testing I suggest you add a UUID function to the proxy similar to the Time function:\ngo\n// UUID returns a unique id in uuid format.\n// If UUID is nil, uuid.NewV4() is used.\nUUID func() string\nThen create in the uuid package:\ngo\nfunc NewV4() string {\n    return EncodeHex(NewRandom())\n}\nNow you can mock this in the test.. One thing I'd like to know though and maybe you can add a benchmark for this is how many UUIDs this approach can generate? Is this using a pseudo random number generator which can generate enough entropy for thousands of req/sec or will this become a limiting factor for the throughput? If yes, then we need to find a better way.. There are users with 20k req/sec (or more) on a single instance. I won't name you in public but you know who you are :). @leprechau very cool. Thx for digging. Want to add a fast formatter? That lib is also small enough to be vendored in.. Sorry. Got sidetracked. Looking now.. Looks good. One last request. Can you split this up into just two commits? One for the vendored in library and one for the feature change? I don't want to squash those two.. Once you're done pls force push the change so that it replaces the current list of commits.. merged it.. @bkmit Thanks for your patience :). For that the quality was quite high! Hats off.. 1. Try -proxy.cs 'cs=ssl;type=path;cert=/foo/bar' instead of -proxy.cs 'cs=ssl;type=path;path=/foo/bar' https://github.com/fabiolb/fabio/blob/master/fabio.properties#L27-L51\n2. yes, see docs in the same place about file name conventions.. That should work. You're sure that your urlprefix- tag does not contain the hostname?. @mitchelldavis Pls open another ticket in the future. I don't mind answering several questions but I'd prefer not to morph or merge issues. You probably need to add strip=/servicename to the urlprefix tag since fabio doesn't do automatic path stripping.. That looks like a bug.. Indeed - that should have been obvious. Sorry for pushing :). What does your consul service record look like? . Can you try setting the ServiceAddress ?. And the service is accessible under https://opesqzhtvl.execute-api.us-west-2.amazonaws.com/ ?. Can you use access logging to log the target url:\nfabio -log.access.format '$upstream_request_url` -log.access.target stdout. I'm getting a 403 since I don't have the access token.\n```\n$ curl -i https://opesqzhtvl.execute-api.us-west-2.amazonaws.com/dev\nHTTP/1.1 403 Forbidden\nContent-Type: application/json\nContent-Length: 42\nConnection: keep-alive\nDate: Fri, 12 May 2017 20:30:45 GMT\nx-amzn-RequestId: e07ebbf7-3751-11e7-a9b1-0b55e7aa1c29\nx-amzn-ErrorType: MissingAuthenticationTokenException\nX-Cache: Error from cloudfront\nVia: 1.1 4f41781811f1a69022318a8d308fd9f3.cloudfront.net (CloudFront)\nX-Amz-Cf-Id: rVQRObFNqJFaHmIOQjObLbqxZtrESrprFT4Ji_OaQvG2NPwMSgxDnA==\n{\"message\":\"Missing Authentication Token\"}\n```. ok, late here (AMS, NL). I'll look at it probably on Monday.. @mitchelldavis got sidetracked. I try to have a look later tonight or tomorrow morning.. No, it uses the host header for routing and then passes the request on as is.. OK, so the problem is this:\n```\nb.com advertises 'urlprefix-/status' with Address: b.com\nclient -> http://a.com/status -> fabio -> http://b.com/status 'Host: a.com'\n```\nb.com is supposed to either advertise a.com/status and accept requests with that hostname or advertise /status and accept requests with any hostname. \nYour case is different. You register the service without a hostname but the upstream service only accepts a specific hostname. fabio cannot do this right now.\nI can see two options:\n\ntell fabio through an option to replace the Host header with the hostname of the upstream server\ntell fabio which hostname to use when making the upstream request. \n\nI think this should only work if the upstream service advertises a route with /.\n. The following line to proxy/proxy_http.go adds the behavior you want but for all services. This needs to be exposed and made configurable which probably isn't difficult but I'd like to think about it a bit more. You can hack the work around in there for now to make it work. \n```patch\ndiff --git a/proxy/http_proxy.go b/proxy/http_proxy.go\nindex 4056d07..2e5d84f 100644\n--- a/proxy/http_proxy.go\n+++ b/proxy/http_proxy.go\n@@ -99,6 +99,7 @@ func (p HTTPProxy) ServeHTTP(w http.ResponseWriter, r http.Request) {\n        } else {\n                targetURL.RawQuery = t.URL.RawQuery + \"&\" + r.URL.RawQuery\n        }\n+       r.Host = targetURL.Host\n    // TODO(fs): The HasPrefix check seems redundant since the lookup function should\n    // TODO(fs): have found the target based on the prefix but there may be other\n\n``. I've pushed a branch which is WIP but contains an integration test to verify the behavior. The added line does what you want but now it needs to become configurable.. Can you try with vault 0.6.4?. The way I usually run the tests isVAULT_EXE=~/vault-0.6.4/vault make test`. merged PR #301 to master. @mitchelldavis Thanks for this patch!\n. Early next week. When this happens then the routing table changes and fabio should log the delta. The state change can also occur when there is no change in health but a change in the output of the health check. If you have volatile data like a timestamp or an ip address in the output then you can get a change like that without a routing table change.\nYou can run consul monitor to check what is going on in your cluster.. Although this isn't  a directly useful information for fabio it is for the operator as a secondary indicator for your cluster health. The usual problem - and you're not the first to ask - is to have either an unstable environment (which you should fix) or to have health check output with volatile data (your case) which puts stress on consul and the raft layer. \nI'm glad you like fabio. Please keep asking if there is anything that isn't clear.. See https://github.com/fabiolb/fabio/issues/226 for example. I think the Forwarded header is specified in an RFC. There was another issue about that recently. I'll check after lunch. . The main problem is that the AWS LB sets some but not other headers which leads to the discrepancy. But fabio also uses the actual connection type to determine the scheme which can only work reliably when the connection is terminated on fabio.\nWe could use the following heuristic to determine the scheme:\n\nIf X-Forwarded-Proto XOR Forwarded is set then use the value from the available header\nIf both headers are set prefer Forwarded since it is well defined (arguments against?)\nIf none is set, derive from connection\n\nWe might need to look at the remote ip as well even though this doesn't affect the AWS case since it uses the PROXY protocol.\n. I think this heuristic is flawed for case 2. When both headers are present fabio should not touch them since it isn't clear which is the source of truth.. I've pushed a change with the described behavior. Could you test it, please?. Yes, It requires go1.8 :)\nhttps://github.com/fabiolb/fabio#getting-started. What do you mean?. I'm closing this one but please feel free to comment.. The current behavior is for fabio not to interrupt existing connections. This stems from the fact that fabio started as an HTTP proxy which is presumed to have short living connections. That was already broken when supporting web sockets but TCP proxying makes this more visible since master/cluster failovers require an active component in the stream which terminates the connection. \nThis requires keeping track of certain types of connections which need to be disconnected when the routing table changes. Right now, the proxy code is wholly unaware of changes in the routing table and therefore cannot take action. Since this would interrupt existing connections anyway I'd suggest to restart fabio to kill the other connections until I have a better solution. Not sure whether this is an option for you.. You can use the one in fabio.properties:\nhttps://github.com/fabiolb/fabio/blob/master/fabio.properties#L365-L380. No problem :). Is this on master? I think I've touched this code recently. I'll have a look later tonight. . I'll fix that tonight. I've pushed a fix that I think should fix this. Still need to write a test. Could you test this, please?. It was worth a shot. I'll add a proper test and fix it. I've got a long weekend ahead so this will probably happen next week - just to set expectations.. Fixed it in the wrong place. The new patch should fix it.\nAlso, the websocket lib I'm using for testing doesn't make it easy to set headers. Therefore, writing a test requires a bit more work. I need to replace it anyway but I was able to reproduce the behavior with curl and the --compressed flag.\nCould you have another look, please?. Cool. I'll write a test and merge it.. You can replace the tests with this:\n```go\nfunc TestProxyUsehost(t testing.T) {\n    server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r http.Request) {\n        fmt.Fprint(w, r.Host)\n    }))\nproxy := httptest.NewServer(&HTTPProxy{\n    Transport: &http.Transport{\n        Dial: func(network, addr string) (net.Conn, error) {\n            addr = server.URL[len(\"http://\"):]\n            return net.Dial(network, addr)\n        },\n    },\n    Lookup: func(r *http.Request) *route.Target {\n        routes := \"route add mock /usehost http://a.com/ opts \\\"usehost\\\"\\n\"\n        routes += \"route add mock / http://a.com/\"\n        tbl, _ := route.NewTable(routes)\n        return tbl.Lookup(r, \"\", route.Picker[\"rr\"], route.Matcher[\"prefix\"])\n    },\n})\ndefer proxy.Close()\n\ncheck := func(uri, host string) {\n    resp, body := mustGet(proxy.URL + uri)\n    if got, want := resp.StatusCode, http.StatusOK; got != want {\n        t.Fatalf(\"got status %d want %d\", got, want)\n    }\n    if got, want := string(body), host; got != want {\n        t.Fatalf(\"got body %q want %q\", got, want)\n    }\n}\n\nproxyHost := proxy.URL[len(\"http://\"):]\nt.Run(\"use host\", func(t *testing.T) { check(\"/usehost\", \"a.com\") })\nt.Run(\"no host\", func(t *testing.T) { check(\"/\", proxyHost) })\n\n}\n```\n\n\nI mean to use usehost instead of usehost=(true|false). This changes on how you set the t.UseHost flag since checking for an empty string is not sufficient. \n\n\nusehost it is then. Pls also use t.UseHost internally.\n\n\nThx a lot. I'll let this sit for another day or two before I merge it. usehost is concise but also ambiguous. I'll see whether I can come up with something better. Thx for your patience.. How about host=dst?. Yes. I think that makes more sense and provides some flexibility for the future. boolean flags are always somewhat limiting unless you can be absolutely sure that there will ever only be two choices.. Can you make that change?. Two small changes and then we can merge it.. Not at the moment. What would be a good way of supporting this?. Read-Only and authentication are two different concepts. They're related but not the same. Setting the UI to read-only would allow you to have a set of public fabios and maybe one internal where you allow the overrides. I think that might be a good compromise that is simple enough and covers enough use-cases without full-blown auth. \nThe problem with authentication is that you need ssl for this which means you need a cert and you need to manage the secret or the integration into some auth system. There is #166 and #25 already open and to do this properly I'd need to add auth backends like ldap, pam, oauth, ... as a concept and integrate that with the UI. However, that would put the entire UI under access control. \nI want to add auth at some point but I'd prefer to provide you a solution now if possible.. I've added an ui.access option which is one of off, ro and rw. The default is rw. This should leave some room for future enhancements like auth, ... Could you please test whether this works for you?. @deuch do you have an opinion about the off switch since it does not fully disable the UI endpoint. You can achieve that by not setting ui.addr but then the consul registration of fabio becomes tricky since there isn't a health endpoint.. I think I'll just drop the off options for now until someone asks for it explicitly. . I've dropped off for now. We can always add it later if someone really wants it.. Hi Ramesh, did you checkout https://github.com/fabiolb/fabio/wiki/Quickstart on the wiki?. How many of these headers are there? :)\nWhat would it need to contain? The original request path?. @avarabyeu pushed a change with test. If you could verify that it works for you then I'll merge it and include it in the next release which I'll roll this week.. /value or /foo/bar ?. Ah, you want the stripped prefix to be in the header, e.g. X-Forwarded-Prefix: /myprefix. @avarabyeu I've pushed an update to the branch. Can you check, please?. I've refactored the code for parsing the proxy.addr values. Let me have a look.. The problem is the second = in the proxy.cs line. This is a bug in the parseKVSlice code. I'll fix it.. I've pushed a fix in the issue-305 branch. Could you check whether this fixes the problem for you?. Today or tomorrow. Is that soon enough?. Damn. Yes. I'll push a 1.5.2 soon. Might be early next week though.. It is correct that the TCP proxy does not collect metrics at the moment since most of the metrics I'm collecting only make sense in for HTTP. Which metrics would you like to see?. I've added the metrics but the naming needs some more work since I'd like to add the protocol to the metrics name. Right now you get:\ncounter tcp.conn\ncounter tcp.connfail\ncounter tcp.noroute\ncounter tcp_sni.conn\ncounter tcp_sni.connfail\ncounter tcp_sni.noroute\ncounter server._1234._.127_0_0_1_5000.rx\ncounter server._1234._.127_0_0_1_5000.tx\nI've defined rx and tx as follows:\n// rx measures the traffic to the upstream server (in <- out)\n// tx measures the traffic from the upstream server (out <- in)\nAlso, in order to support #211 I finally need to address the metrics naming problem ...\nCould you please have a look whether that works for you?. @InformatiQ and @csawyerYumaed are you still interested in this?. rt and wt sets the read and write timeout on the inbound connection, the one accepted on the listening socket and handed off to the TCPProxy. The upstream connection does not have timeouts right now. This is a bit hidden here: https://github.com/fabiolb/fabio/blob/master/proxy/tcp/server.go\nWhen you close the inbound connection the outbound connection should get closed as well if I read the code here correctly but maybe I need to brush up my TCP state knowledge.\nhttps://github.com/fabiolb/fabio/blob/master/proxy/tcp/tcp_proxy.go\nWhat is the problem you're having?. @InformatiQ Is this still an issue?. fabio does not touch the X-Forwarded-Proto header if it is set:\nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_headers.go#L48-L64\nand the way I read the AWS docs on the ELB and SSL termination the ELB should set it to https\nhttp://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html#x-forwarded-proto\nBased on your comment from #296 I assume that isn't the case. Do you know why?. Hmm, could you try using the port from the RemoteAddr instead?\nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_headers.go#L22\nand set it here with strconv.Itoa() ?\nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_headers.go#L67. Ah, ok. I thought you could make a simple patch and rebuild it since I was in a hurry but wanted to give something to you to test. I'll provide a proper patch and instructions.. You want a custom page or a custom url?. dup of #56 I'll have another look at this.. The search order is most to least specific. Registration order does not matter since this wouldn't be deterministic. Therefore, for /animal/cat/white you'll hit svc2 but for /animal/dog you'll hit svc1\nhttps://github.com/fabiolb/fabio/blob/master/route/table.go#L89-L92\nhttps://github.com/fabiolb/fabio/blob/master/route/routes.go#L16-L19. The only thing we ever did to tune memory usage was to reduce runtime.gogc to have more collections. Smaller number (e.g. 100) usually equal more collections, higher numbers less collections. The default value is tuned for throughput of short-living connections. \nIf you terminate TLS or have lots of long-running connections w/o timeout you may see increased memory usage. Also, there was a memory leak in the TCP proxy which was fixed in #321 but I don't know how big the impact was. This has been fixed in 1.5.2.\nMy suggestion is to run fabio with GODEBUG=gctrace=1 ./fabio ... and look at the output of the GC in the logs. Watch by how much the heap grows and whether the GC has an impact. Then slowly reduce the GOGC until this stabilizes.. @danielmotaleite the typical solution to this problem is to tune the runtime.gogc parameter to your use case. See the previous comment on how to address this. There was a memory leak in the TCP proxy which was addressed in #321 and is in 1.5.2. If you're using the TCP proxy then this might affect you.. The 800 value worked well for go1.4 and go1.5 for non-TLS connections and lots of short-lived requests. Might be time to run another test suite.. Thank you so much! :). Don't bother. I can squash the merge myself. . @pschultz Cheeky side question: Would you mind me adding your logo to the README? :). I think this is more readable. What do you think?\n```go\nfunc (s VaultSource) setAuth(c api.Client) error {\n    s.mu.Lock()\n    defer s.mu.Unlock()\nif s.auth.token != \"\" {\n    return nil\n}\n\nif s.vaultToken == \"\" {\n    return errors.New(\"vault: no token\")\n}\n\n// did we get a wrapped token?\nresp, err := c.Logical().Unwrap(s.vaultToken)\nif err != nil {\n    // unwrapping failed?\n    if !strings.HasPrefix(err.Error(), \"no value found at\") {\n        return err\n    }\n    s.auth.token = s.vaultToken\n} else {\n    log.Printf(\"[INFO] vault: Unwrapped token %s\", s.vaultToken)\n    s.auth.token = resp.Auth.ClientToken\n}\n\ns.auth.once.Do(func() { s.checkRenewal(c) })\nc.SetToken(s.auth.token)\nreturn nil\n\n}\n```. LGTM. What I understand is that you are doing two things here:\n\nrefactor the existing code to allow for dynamic cert generation\nadd vault pki as a dynamic cert generator\n\nWhat I usually do in these cases is to split the change into two commits: first the functional equivalent refactoring, then add the new feature on top of that new functionality.\nI like the Issuer interface but the first thing that came to mind is whether the cert store setup could be extended in general with different kind of issuers. Static onces, dynamic ones, ... That was the idea of the Store which would become a Cache. The other thing I was thinking of when I read this was what about LetsEncrypt? \nPlease note that this isn't fully thought out but it might make sense to look at the architecture of the cert stores as a whole and not just for Vault.\nAs a benefit I've learned about golang.org/x/sync/singleflight :)\nOne other thing caught my eye: the setting of StrictMatch in main.go if the source is an issuer. I think this should be caught during config loading and tested there and this should trigger an INFO message in the log.. @pschultz This has fallen a bit through the cracks for various reasons. I'd like to pick this one up again and merge it if you still feel comfortable about this.  Could you rebase this, please?. Lets merge this.. Fixes #135 . Thanks a lot @pschultz !. @pschultz The VaultPKI integration fails with go1.10rc1. I'm getting this. Would you be OK having a look at this?\n$ go test -run TestVaultPKISource ./cert\n--- FAIL: TestVaultPKISource (2.49s)\n    source_test.go:305: Starting vault: \"\\x1b[0;0mVault v0.9.3 ('5acd6a21d5a69ab49d0f7c0bf540123a9b2c696d')\\x1b[0m\\n\"\n    --- FAIL: TestVaultPKISource/renewable_token (0.46s)\n        source_test.go:564: got Get https://127.0.0.1:49363: x509: certificate signed by unknown authority want nil\n    --- FAIL: TestVaultPKISource/non-renewable_token (0.26s)\n        source_test.go:564: got Get https://127.0.0.1:49370: x509: certificate signed by unknown authority want nil\n    --- FAIL: TestVaultPKISource/renewable_orphan_token (0.30s)\n        source_test.go:564: got Get https://127.0.0.1:49378: x509: certificate signed by unknown authority want nil\n    --- FAIL: TestVaultPKISource/non-renewable_orphan_token (0.36s)\n        source_test.go:564: got Get https://127.0.0.1:49390: x509: certificate signed by unknown authority want nil\n    --- FAIL: TestVaultPKISource/renewable_wrapped_token (0.34s)\n        source_test.go:564: got Get https://127.0.0.1:49400: x509: certificate signed by unknown authority want nil\n    --- FAIL: TestVaultPKISource/non-renewable_wrapped_token (0.29s)\n        source_test.go:564: got Get https://127.0.0.1:49413: x509: certificate signed by unknown authority want nil\nFAIL\nFAIL    github.com/fabiolb/fabio/cert   2.507s. @pschultz I've found it. See #434 . Since the routing table is atomically swapped I'd check the fabio logs if the routing table was temporarily empty. null shouldn't be able to happen (but I need to check the code to be certain)\nSee: https://github.com/fabiolb/fabio/blob/master/admin/api/routes.go#L28-L70. Just provide multiple tags.. I'm glad you've figured it out. Let me know if there are other things. :). Can you post your runtime config?. on which route is fabio causing the error? Is that reproducible? Do you have write or read timeout set in the config?. Duplicate of #264 . Closing because of duplicate. This is your problem:\n+ route add DataService plk.me/dataservice http://localhost:5000/\n2017/07/07 17:03:35 [WARN] No route for plk.me:9999/dataservice/values\nYou register a route for plk.me/dataservice/values but access it as plk.me:9999/dataservice/values which does not match.. What does the log say now? You can also try this:\nhttps://github.com/fabiolb/fabio/wiki/Features#request-tracing. Glad you've found it :) Let me know if there are other issues.. @simonsparks Indeed. Fabio waits for consul but not the metrics. I've hijacked the registry retry config parameters and made this more robust. Could you check whether that solves your issue?. @pvandervelde I've taken the patch and added two proper metrics config parameters metrics.timeout and metrics.retry for it and merged it to master. The default behavior is now to retry every 500ms for 10s just like for the registry.. I really missed this? Wow. Thx. I'll have a closer look a bit later.. Which version are you running?. Also, can you please post a response from this endpoint. I'd need to see the headers. My guess is that there is no Content-Length header.. That shouldn't be too difficult.. That sounds interesting and there was https://github.com/fabiolb/fabio/issues/129#issuecomment-315313167 which seems related. It was always kind of clear that forking the reverse proxy would eventually happen but I'm glad that for the most part I didn't have to. \nSo my suggestion would be this:\n\n\nPlease send a PR but make using the streamed proxy configurable. If the streaming proxy is a drop-in replacement of the reverse proxy with more features then it should replace it in the long run. If it has a different feature set then it must be configurable.\n\n\nConsider pushing a PR towards Go to add this feature there as well. . The AWS Go client lib is a behemoth .... Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. If you want to help: now is the time :). You could ask the original committer of the approach or provide a better way of doing this. However, before you do this I'd like to understand what \"really bad\" means in this context. So far nobody has complained about it and aside from the one bug it seems to have been working for people. I usually prefer a fact based approach on discussions and I'm curious which problems the current implementation creates and how you would solve them.. Can you provide a specific example? Which metric, what is the current format, what is the desired format? Please keep in mind that I'm not a statsd expert and that you may have to explain more to me than to people already familiar with the matter. . Sorry for the delay but I'm on vacation with the family.\n\n\nThe key point here is that you want to send an event to statsd when it happens and want to do the aggregation yourself. So far I've relied on go-metrics to do The Right Thing (\u2122) but I recall some discussions around integrating the circonus support that the histograms in go-metrics aren't that useful. Mostly because they're a port of the codahale model from Java. I didn't dig deeper there. Maybe @maier can help here. \n@drawks thx for the PR. I'll try to look at it soon. Kids waking up now :). @drawks I think your PR would be good enough for an experimental inclusion. Don't you need to add newlines between multiple metrics?\nThe downside of metrics that are not pre-aggregated is that the API will no longer provide these values. If you are using this provider you probably don't care about that. \nHowever, integrating one of the libraries you suggested was simple enough that I've tried that in #329. To avoid the alloc per metrics I need to refactor the registry interface a bit but I'd appreciate if you could test the integration. \nYou should set:\n./fabio -metrics.target statsd_raw -metrics.interval 100ms\nI'll sleep a bit on the naming of statsd_raw vs raw_stats and the corresponding struct names. Also need to update the documentation. \n. I think a better solution is to remove the Counter and Timer structs from my metrics package and add Count and Time methods to the registry directly. Then every driver can choose whether or not to aggregate. That might also be a good path to supporting tags. . Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. @drawks I've addressed your comments but I'm unsure whether I should do prefix.name or prefix--name as in the other statsd impl. The [spec](https://github.com/b/statsd_spec} isn't clear on names and prefixes. Is -- a convention to separate prefixes from names?. This got pulled in via the statsd lib so I'm happy to change it. Maybe it is best not to add a separator at all then you can choose what you want.. I've integrated #331 but I want to take the opportunity to generally refactor the metrics approach to make supporting additional backends much simpler. I'll get rid of the Timer and Counter shims and just provide functions for metrics events just like statsd and circonus. However, I need to sweep through the code to replace metrics with just names. So bear with me for a couple more days until this is done.\nI'd also like to finally attack the tags issue for DataDog and Prometheus. . I've created #334 which is the metrics refactor code and then #335 for the raw statsd code on top of that. That looks simpler but needs testing.\nI haven't started with tag support and if you have an approach then I'm more than happy to use that. Can you show a proof-of-concept code so that we have a basis for discussion?\n. I\u2019ll work on it and try to get it in the next release. Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. That's no fun. I'm looking. . @manos Good catch and sorry for the trouble. The ws proxy was only using the Host part of the URL which made not obvious that I had to modify the request URL as well. It was literally a one line fix :) \nI'll address the logging separately.. Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. Done.. yeah, since I'm the owner and only maintainer I'm not sure that matters. That's kind of a left-over from the time at eBay.. I think this is a duplicate of #247.\nI'm glad you like it and that it works for you. I'll do my best.. Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. @tomstaijen I doubt that since the tcp proxy is not using the http package.\n@Crypto89 I have an idea on how to address this. There is a way to handle half-closed connections in Go.. @freeman This has been discussed before in the context of rate limiting and I'd like to add something like that. The main issue was on where to store the list of addresses while handling the high volatility of the data w/o overwhelming the consul server and raft updates.\nHowever, for static black lists consul could be sufficient since this would assume that some other process would maintain and update that list and fabio would be just a consumer. \nOne approach could be to allow something like this and store this in consul similar to the manual overrides and just append this to the routing table definition.\nroute block 1.2.3.4\nroute block 10.0.0.0/8\n.... That shouldn't be the case. I'll have a look. Do you have unique service ids?. This code filters out services which are not passing before doing anything else and this is AFAICT protocol agnostic:\nhttps://github.com/fabiolb/fabio/blob/master/registry/consul/passing.go#L13-L49\nCan you provide the output of curl 'localhost:8500/v1/health/state/any?consistent&pretty'?. @akissa Thx. This area of the code could indeed use some more tests. I'll have a look next week if that's OK. This is my last day of vacation. . Something like this?\nurlprefix-/var/run/mysql.sock proto=tcp\nfabio -proxy.addr '/var/run/mysql.sock;proto=tcp'\nI'm wondering whether this would be useful for HTTP, too?. Sorry for the delay. PR is welcome. This looks like a good addition.. Hi @Gufran this would be very nice. \nI think what you need is a way of specifying that the upstream server is a fastcgi server, e.g. urlprefix-/foo proto=fastcgi and then in the proxy/http_proxy.go you forward to the fastcgi server instead of an http server.. @i4s-pserrano @snh is correct. That flag only prevents fabio from registering itself in consul as a service but it still uses consul to get the routing table. . I didn't consider 2M routes a viable use case but I'm more than happy to make this a reality. What a showcase!\nYou are correct in that fabio cannot handle this dynamically right now because of the consul limitation which is not going to be lifted or made configurable any time soon. We get this request regularly. \nHowever, in addition of being a data source consul is the single source of truth and acts as a synchronization point. When consul gets updated all fabios pull the updated the new version from there. You don't have to know how many fabios there are or where they are. They will do the right thing. \nTherefore, using an API, or a dynamic file provider would put the burden on you to provide consistency and timeliness of updates. \nSupporting a different data source like a URL would be another option. Fabio could pull the routing table from a URL and could use the eTag, status code or some other header to determine whether the data has changed. Fabio could also pull an URL from the consul KV store to avoid the polling but that seems overkill.\nI'd still have to look at the speed of the routing parser. It is using regular expressions right now but I've gained some experience in coding my own parsers. \nHow often does the routing table change and how many fabio instances are you running?. Also, how many targets do you have per domain? Is it 2M domains or 2M route entries?. @smalot Is that still an issue for you since I'd like to pick that one up.. @danlsgiga Why do you want to dial it down? There is no DEBUG log and fabio shouldn't log that much. If it does then this usually points to something in your setup: a flapping health check or a check with volatile output like a timestamp for example. You'd want the INFO level since it logs how fabio is started including the runtime configuration.\n. Hi @danlsgiga,\nThe message should probably read consul: Raft index changed to #10372843 which explains its true nature. The reason I'm logging those as INFO is that a high rate of these messages points a problem in your consul setup because you are generating lots of writes on the consul master. This can either be caused by flapping health checks or health checks which have volatile output like a timestamp. In any case it points to an issue within your setup which should be fixed. Providing you with a switch to hide this makes it more likely to just tune it out. \nAt eBay we had exactly that issue where my team had a stable log which wouldn't grow and the other team was asking for log rotation since their log grew somewhat unbounded. Ultimately, they found the issue in their consul integration framework which was causing excessive writes on consul. They fixed it and it was stable ever since. \nSince the root cause for lots of these log messages is in almost all cases volatile output in the health check and the fix is usually trivial I'm still in favor of saying \"please fix your setup\". \nHowever, I've learned that there are other log messages that do not provide much value but can appear a lot in the output. I'll have a look at those on whether we really need them. I might add a debug log level which can be enabled and disabled but I'd still leave the above messages at INFO since they point to an issue in your cluster setup that needs fixing.\nAs for the runtime config: I agree that the consul tokens should be obfuscated and I'll add that since it is a good idea. However, I'd argue that the API endpoint for the config should exist in addition to adding the runtime config to the log since that provides you with historical information. So you can go back in time to see whether the config has been changed which you can't do with just an API endpoint. I'm curious which IP addresses you'd like to obfuscate since I don't consider them to be sensitive but I'm open to arguments.. If I obfuscate the token the consul ip becomes somewhat useless, doesn't it?. I've just merged #366 which allows you to control the log level.. docker run -it -e registry_consul_addr=host:port fabiolb/fabio should do the trick. Also, pls don't run consul behind an LB :). no worries. Let me know if you have more questions. ~~Is the %20 part of the route or the request?~~. ~~Another difference is fabio 1.3.7 was built with go1.7.5 and fabio 1.5.2 is built with go1.8.3. Could be something in the go http package but I'm looking.~~. nvm, I've found it. This is a consequence of #219 which uses req.URL.Path instead of req.RequestURI for the lookup. The first one is parsed whereas the other one isn't. Since you can encode a space in two ways in a URL (%20 and +) I think the new way is the correct one but then the entries in the routing table need to be URL decoded. I need to think about this a bit. Is there something you need from 1.5.2 and this is a blocker?. How urgent is this since a) I'm sick right now and b) need to get something ready for HashiConf next week. Can this wait a couple of days? . @jshaw86 will do :)\n. consul 1.0 beta1 is out the door. I have one more thing to look at and then I'll dig into this one. . There was a reason for this. Let me find the commit.. Sticky load balancing isn't supported right now. I assume you're using TCP?. No, this is a different problem. I've fixed it but forgot to merge it :( The pubnub code has both changes now so I should go back to their impl. However, they also have tag support in it and some other changes. I'll do this separately. Lets fix this one first.. \ud83d\udc4d . urlprefix-example.com/ weight=0.05 should do the trick. I probably need to update the docs.. I've just merged #315 which adds support for Vault as a native PKI store for fabio. Can you have a look whether we can make this more flexible for your needs?. There is the host=xxx option that you can set which sounds similar to what you are trying to do. host=dst will set it to the upstream hostname, e.g. google.com See #294 . I'm going to close this for now. Feel free to comment if the host=xxx option doesn't address your need.. Would you be willing to submit a PR?. Duplicate of #261 . @seanc- ?. If @seanc- does not have the time for it right now then this has to wait until after the next release. I'm open for a PR if you feel comfortable doing this. For the next release I want to fix metrics since issues have been piling up there. . @reinoud ui.color and ui.title should do the trick. We used this in our team for exactly that purpose:\nhttps://github.com/fabiolb/fabio/blob/master/fabio.properties#L856-L868. We used red (prod), yellow (test), green (dev). :) closing. I've just updated the wiki. Please let me know whether that is sufficient.\nhttps://github.com/fabiolb/fabio/wiki/Features#metrics-support. This sounds really weird. We - and all customers I know - are running multiple fabio instances with no noticeable problems. Are these the same types of machines? Same network? Same load? Congestion? Noisy neighbors?. I'm curious but also quite suspicious about this claim. There are some very large customers using fabio with significant throughput. This would have shown up sooner. If you have additional data to support that fabio is the root cause please provide them and I'll follow up. In the meantime I'll close this ticket.. Hi @deuch, this is what I understand so far:\ninternet -> https://foo.com/bar -> fabio -> https://1.2.3.4/bar (Host: foo.com)\nThe cert is for foo.com but not for 1.2.3.4 and setting the Host header isn't sufficient. I would need to dig but can't you add 1.0.0.0/8 to the cert?. Would the host=dst from #294 help? (I really need to work on the docs). host=dst is for the reverse proxy case. Let me think about this a bit more. . host=dst will effectively swap the hostname in the upstream request:\n https://a.com/foo -> fabio -> https://b.com/foo 'Host: b.com' (with host=dst)\n\nhost=dst will use the consul service address for the Host header and the target URL. If your container has a cert for its ip and that cert is trusted by fabio then this should work. But creating a cert per container is something you can't do right now.\nFor HTTPS, it isn't sufficient to set the Host header since it is transmitted after the TLS handshake. The right server name needs to be in the request URL, i.e. https://a.com/foo (TLS server name: a.com) and not https://1.2.3.4/foo Host: a.com (TLS server name: 1.2.3.4).\nIn essence, you want fabio to make the upstream request with the original hostname (e.g. a.com) since the cert in the docker container contains that name. \nfabio could either spoof the DNS lookup for that request or try to establish the TCP connection first and then run the TLS handshake with the original server name (which circumvents the DNS lookup).\nThis would then allow you to re-use the same cert on all upstream servers. \nDoes that make sense?. not yet. sorry.. @pvandervelde fabio is not intended to be a full nginx replacement which mangles routes and rewrites URLs. It is primarily a stateless router which forwards requests to services which claim that they can handle them without changing them.\nIf your service needs to handle requests from /artefacts/installers why not add a handler for this to the code?\nThe main motivation for the strip prefix option was that entire sets of services were proxied behind a common URI which made it impractical to change every service. I don't see that use case for stripping the suffix but maybe you can explain your use case a bit more.\n. @pvandervelde you could use strip=/artefacts/installers and access the other service under / I don't see the point in the upstream service to respond to /artefacts when in fact it is providing /installers. What am I missing?. My main lesson from the eBay team I ran was that adding this kind of complexity caused more issues downstream even if it fixed your immediate problem at hand. fabio was the result of that constant maintenance pain, the fact that everything had to be looked up instead of being derived. My main motivation for writing it was to simplify the architecture by actually removing entire components and workflows, e.g. you do not have to coordinate the deployment and maintenance of an LB configuration in tandem with your service config. The services announce what they can serve and fabio will just serve them. We literally ran fabio for months without restart/reconfigure and even more literally forgot that it was there at all. \nWhat you are trying to do feels like going against that very motivation and that usually makes me question the approach as a whole.\nTherefore, my advice is to push (invest time) for having the services advertise and handle what they actually claim they handle. It pays off. . You can go to http://localhost:9998/manual and set them there or use \nconsul kv put fabio/config '#foo' for example. Please note that you can change the prefix in fabio.properties with registry.consul.kvpath\nhttps://github.com/fabiolb/fabio/blob/master/fabio.properties#L531-L539. I don't think that this is a good idea in general as it introduces a circular dependency between fabio and consul. How should fabio find the consul instance and the KV path? The main reason to use fabio is that you do not have to maintain its configuration all the time. Therefore, I'm curious what it is that you want to change at runtime.. why? what's broken? our fabio instances weren't logging much (KBs/day). Simple log rotation was enough. Are you getting a lot of Health changed messages?. No, what you have there is either a flapping service or a service which has volatile data in its health check output (e.g. timestamp, pid, increasing number, ...) Each of these lines represents a write to the consul raft log which needs to be replicated and puts load onto your consul server cluster. Find the volatile data in the health check and fix it and you won't have that problem :). Still need to add a test for the LevelWriter. @manos I don't have code for that yet but for now you can set the -discard-check-output option in Consul.. @mterron I agree that the software should do the right thing but there is a valid case for running fabio as root inside a container if it is the only app. Static go binaries like fabio run from a SCRATCH container where there is no user management. Making this mandatory would mean to require a full-blown OS to support that which just increases the size and the attack surface. Also, containers provide the root abstraction for that reason, IMHO. You can be root but you're not root outside your container.\nAlso, if users will ignore a warning in the logs then they will just use the switch if is there. :)\nOK, then the path forward is to refuse to run as root unless you specify -insecure. Issue a visible warning at startup and one WARN log message every hour. . That's how I understand that but you'd have to break out of the container first, right? Isn't the point of containers to prevent that?. I've pushed a PR which will add a recurring warning which is written to the logs during startup and once an hour if fabio is run as root. The message of the warning changes slightly when the new -insecure flag is used noting that with version 1.7 fabio will refuse to start when run as root.. ```\n2017/10/23 16:37:48 [INFO] Running fabio as UID=0 EUID=0 GID=0\n2017/10/23 16:37:48 [WARN]\n************************************************************\nYou are running fabio as root with the '-insecure' flag\nPlease check the fabio wiki for alternatives\n************************************************************\n\n```\nand\n```\n2017/10/23 16:38:09 [INFO] Running fabio as UID=0 EUID=0 GID=0\n2017/10/23 16:38:09 [INFO] Setting GOMAXPROCS=8\n2017/10/23 16:38:09 [WARN]\n************************************************************\nYou are running fabio as root without the '-insecure' flag\nThis will stop working with fabio 1.7!\n************************************************************\n\n```. This way users have time to adjust to the change in default behavior.. No, but you use fabio to write the access log in the same format and there you can add the access log. \nhttps://github.com/fabiolb/fabio/blob/master/fabio.properties#L419-L467\nIf that doesn't solve your problem then I can think about how to generalize that since you probably want to configure this either globally or per route. I'd need to think about that a bit.. Yes, I'll pick that up with the metrics refactor.. Please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. @marcosnils Now is the time to provide input and help with #476 . You can have Fabio talk to a specific consul cluster or use different tag prefixes to separate name spaces. Can you explain more what you\u2019re trying to do? My gut feel tells me that you\u2019re trying to do smth that fabio wasn\u2019t designed for. The auto-discovery is the whole point of its existence. . I think you can use different tag prefixes for that. fabio-a[123] uses tag.prefix a- instead of urlprefix-, fabio-b[123] uses b- and so forth. This way multiple fabio clusters can share the same consul server cluster. The services then need to register a-/foo and b-/bar. You still need to route inbound traffic to them though. \nFrank Schr\u00f6der\n\nOn 16. Oct 2017, at 18:35, Victor Chan notifications@github.com wrote:\nWhile I personally agree that the automatic discovery is the best way to go, my use case is that I will get pushback from other stakeholders of the microservices that they may not want to 'share' the same set of fabio services for load balancing, while still using the same consul cluster for discovery.\nI think the best workaround, in this case, is to use seperate consul clusters just for that seperation.... But I was just wondering whether my use case is unique.. apparently it is....\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Hi @dansteen, I'm glad you like it. It should get out of your way as much as possible.\n\nI think the glob matcher should solve your problem. However, this is a global option.\nhttps://github.com/fabiolb/fabio/blob/master/fabio.properties#L296-L303\nLet me know whether that works for you.. I'll close this for now. Feel free to comment and I'll re-open if necessary.. I'll have a look.. @discobean I had the right instinct on #301. We would need to set host to something else as well. Looks like I was getting ahead of myself in the docs. Looks like this was an obvious thing. Could you test this?. The only thing where I'm not sure are the requests where users want to set arbitrary headers on the request. However, this solves a problem now.. That should already work but needs to be at the start of the line. I can add that it also ignores comments at the end of the line. I thought I had documented this since this was for sure one of the first things I've implemented in the parser. We used that when selectively enabling override rules while switching services.\nBut there is no test for that and it isn't documented :(\nhttps://github.com/fabiolb/fabio/blob/master/route/parse_new.go#L15\nhttps://github.com/fabiolb/fabio/blob/master/route/parse_new.go#L71-L72\n```\nthis is a comment\n// this is a comment as well\nroute add ...\n```. I've added a section to the docs just now:\nhttps://github.com/fabiolb/fabio/wiki/Routing#comments. Hi @LeReverandNox and @commarla, thanks for both the PR and the nudge. The last couple of weeks were a bit more stressful than expected. I've merged the PR and added some subsequent commits to clean it up (integration test, ordering, simplifying). Nothing major. \nThanks again!\nFrank. I'm not sure whether this enables an unwanted compiler optimization. Are the benchmark results different after you've removed the variable?. The intention was to not let the compiler optimize a function away where the return value is never used. I may have gotten this wrong but that was the idea.\nSee last paragraphs in https://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go. I think these two are unrelated. The var in the BenchmarkProxyLogger can go.. Thanks!. I need to check again but I agree that there should be a comment if it is necessary indeed.. Hi @antham, the last couple of weeks were a bit more stressful than expected. This LGTM. Merging and thanks for fixing! :). @antham Good idea. Done in 119bd53.. I haven't fully tested the maintenance use case but in general the ServiceName describes the type of service e.g. UserService and the ServiceID describes the specific instance which should be unique for the cluster and not just the agent. That's why Fabio registers itself as fabio-<host>-<port> and we did that for all other setups. Also, this is the usual cause of errors for new Fabio users which set the name and the id to the same value for multiple instances.. No. PR would be very welcome :). Found it. The opts are stored on the target itself but set on the route for all targets. \nhttps://github.com/fabiolb/fabio/blob/4dbab1b7be568100164272aa661d797cd243d006/route/table.go#L156-L157\nhttps://github.com/fabiolb/fabio/blob/4dbab1b7be568100164272aa661d797cd243d006/route/table.go#L162-L163\nOn my way to the airport now. I\u2019ll see what I can do before the flight. Otherwise tomorrow. . @discobean I want to write an integration test for the host option but if you want then you can test the patch in #388 in the meantime.. I am really sorry but I don\u2019t understand the question. . localhost:8500 is the default so you don't need to set that.. Hmm, the root CA path is currently not configurable. fabio will use whatever is in the system path.. Paths are already sorted from most to least specific. I think the issue is in the host matching. . ~~~The issue is in matchingHosts which assumes that there is only one entry that matches the host.~~~\nhttps://github.com/fabiolb/fabio/blob/master/route/table.go#L287-L298\n~~~You have setup where multiple entries match the hostname and in the current implementation the behavior is undefined. I think a better approach would be to find all matching entries, check for an exact match, and if none was found use the longest match.~~~\nI spoke too soon. Still looking.. The problem was in that function but not where I thought. The issue is that the matchingHosts function sorts the hostnames from least to most specific instead of the other way around. \nThe patch I've put in #390 fixes this but I still need to test whether it matches x.foo.com before *.foo.com as well. . I guess this should work since * is before any of the characters in the UTF-8 table.. This fix doesn't work properly yet. There is still a random element in there. Looking\n. Found it. This should work now.. I've tagged it now for 1.6 but I'll probably roll a 1.5.4 for this since the metrics refactor takes longer than expected.. Will be released this week.. Yes. I\u2019ll have a look later today. Sorry for the delay . Why do you need a key? This is for making TLS connections to consul, correct? Can\u2019t you just add the ca file to the trusted root CAs in /etc/ssl?. And use an https URL for consul obviously. Ah, the cert and key are used for client cert authentication. The example uses the Consul server cert and that doesn't seem correct. \nI can see several use cases:\n\n\nUse HTTPS: \n   add registry.consul.scheme=https option\n\n\nUse custom CA: \n   add registry.consul.tls.ca_path=/path/to/certs\n\n\ndisable cert validation\n   add registry.consul.tls.skip_verify = {true,false} to be (somewhat) consistent with the other options\n\n\nenable client cert authentication\n   add registry.consul.tls.client_cert=/path/to/cert.pem and registry.consul.tls.client_key=/path/to/key.pem The key should be optional if both cert and key are in the same file. In this case both should point to the same file.\n. I think the PROXY protocol is the most likely way to do this since the TCP proxy just shuffles a bunch of bytes. In that case this is #191 I can have another look at this since the TCP proxy has been around for a while :). I'm not sure I understand your problem. fabio needs to be able to connect to a consul agent which is usually localhost:8500. Maybe you can elaborate?. You're right, there is no control to this behavior right now. Fabio assumes that the consul cluster is vital and won't drop routes on consul outages. It cannot reasonably infer what the right answer to this situation is therefore it does nothing. However, I get your point and may make sense to add an option to control this behavior leaving the default at the current behavior. Then you could choose that fabio would drop the routes after a certain amount of time when a connection loss occurs.. The current work around would be to detect that the connection to consul is gone and restart fabio. However, if fabio cannot connect to consul at all it won't start the listeners so you won't even get a 404 Not Found.. OK, I'll have a look. Out of curiosity and since you are the first one to request this feature: How come the network between fabio and your consul cluster is broken for extended periods of time? I realize that everything can break but usually when your consul network connectivity is broken you have bigger things to worry about. . Hmm, that sounds like a case for a circuit breaker. I think fabio should do that to protect itself. . So the issue is that according to consul fabio can route traffic to a service but then discovers that it can't for whatever reason. \n\n\n~~~Since the ServeHTTP method doesn't bubble up the error I could translated this into some unused status code, e.g. 1504, disable the route and return 504 Gateway unavailable. This would handle the detection of the situation.~~~\n~~~Then I'd need some code for the backoff algorithm.~~~\nThe http code returns 502 on i/o timeout and https://github.com/rubyist/circuitbreaker provides all the CB functions. The question is how to integrate them. (see below). A narrow view of the problem would only look at \"connection refused\" or \"i/o timeout\" errors because of faulty network configuration. This would be a protection mechanism for fabio since Consul should reflect the true state of the cluster.\nIdeally, a circuit breaker for this failure should be per host:port and not per route since a service can have many routes. However, the challenges described below apply to any CB integration.\nThe challenge is where to store and maintain the circuit breakers.\nA simple approach would be to have a map in the http proxy and store a CB per host:port. However, that would add a global lock that all requests would have to go through which may limit throughput. The other issue is that fabio would still pick routes to unreachable hosts since the route.Picker does not have access to that map. fabio could retry the lookup until it finds a suitable target but that may not terminate. This approach would then have to be replicated for the TCP proxy as well.\nAnother approach would be to attach the CBs to the route.Target so that the route.Picker can filter routes to dead hosts. This would eliminate the lock contention and fabio would serve only valid routes. However, the route.Target objects are disposed every time the routing table is recreated (i.e. on every Consul state change) and with that the CB state would be lost. Also, the CBs would be per route (i.e. host:port/path) and would have to trigger for each route individually unless there is some code that scans the routing table and updates all matching CBs.\nI think the right approach is to automate what @beyondkmp is doing which is generating route del commands and append them to the routing table.\nIn that case the http/tcp/udp proxy could just notify the CB monitor of failures which would maintain the state and generate routing table updates which are then fed back into fabio. Since network issues could be local to a fabio instance I would not try to sync them across the fabio cluster.. I've started working on this having a single threaded circuit breaker monitor which gets OK/FAIL events from the proxies. The monitor will then issue a routing table fragment which will delete all routes that match the breaker. Once a breaker becomes ready again the route del command will be removed. \nThe config language was updated to support deleting all routes for a given destination, e.g.:\n```\ndelete all routes for 'host:port'\nroute del * * http://host:port\n```\nExample\n```\ngiven the routes\nroute add svc /foo http://1.2.3.4:8000\nroute add svc /foo http://5.6.7.8:8000\nroute del * * http://1.2.3.4:8000\nresults in\nroute add svc /foo http://5.6.7.8:8000\n```\nWith this approach the proxy, the routing table and the circuit breakers are decoupled and can be updated independently. \nThe monitor needs to be integrated into the TCP path and the Websocket path and there needs to be GC of OK breakers which are no longer used. The trickier part is to write a decent integration test.\nPlease let me know if you have feedback.. I will make the breakers configurable. As usual there is the challenge of making this configurable per route or globally but since we're talking basic networking errors I will start with a global config value. \nThe breakers are independent from Consul since the idea is that Consul knows the state of the cluster. Once Consul becomes available again fabio will already pick up the new routing table but it may take some time for the breakers to recover.. Yeah, I had thought about this a while ago. Shouldn't be too difficult. What's your use case?. Any special requirements in terms of performance and throughput?. What does that mean? Can you provide numbers?. Indeed. I'll do it. Can't be that hard, can it? (famous last words). @Verdoso Since UDP is a connectionless protocol fabio wouldn't buffer the data since it wouldn't know when data didn't get to the upstream server. I can have a look at the GELF logger in #246 and see if that is still ready to be merged.. I\u2019m still in the middle of moving my family to another country and meeting a deadline. If someone from the community wants to jump in then this is a good opportunity. This should not be too difficult. \n\u2014\nFrank Schr\u00f6der\n\nOn 12. Jul 2018, at 06:30, pj notifications@github.com wrote:\nI would like to respectfully ask if there was any progress on this issue (L4 UDP)?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thx a lot. A number of users have been asking for this. I\u2019ll have a look tonight. . lets disable tip for now then. I've got some cycles in the coming weeks to clean out the issue list. So lets get this done and merged.. This is doing the right thing in the http_proxy.go but the config implementation is more complex than it needs to be IMO. It should be enough if you add a redirect=<code> option since the syntax parsing is mostly there. The notable exception is https://github.com/fabiolb/fabio/blob/master/registry/consul/service.go#L120-L131 which you have covered already and which could use some tests (cough). Then you don't need an addRedirectTarget method and can just add that one option to addTarget method. \n\nI assume you need to make the changes for matching the ports in order to do the http -> https redirect. I'm wondering whether this wouldn't be more expressive\nurlprefix-example.com/ https://example.com proto=http redirect=302\nurlprefix-example.com/\nI'd also like to see an integration test in https://github.com/fabiolb/fabio/blob/master/proxy/http_integration_test.go. It may also make sense to get #385 fixed first. I have the patch but need to add the test.. The proto= option means whatever we want it to mean. It can mean different things in different contexts if its meaning can be unambiguously derived from the context. Lets get this down to the minimal and tested change first and then we can polish it.. I've just merged #388 so you want to rebase.. Got the kids today. So this might be tomorrow. . You missed one spot: \nroute/table_test.go:480:48: cannot use tt.req (type *http.Request) as type bool in argument to normalizeHost\n. Yeah, I'm not sure that matters since the target URL should always be absolute. There is no path mangling in fabio since the routing table is usually generated and the http://host:port/ is really just host:port. Originally, I wanted to keep this open and used URLs for that but this may be misleading. So in fabio you can't forward /foo to /bar/foo. This isn't supported and so far not many have complained about that. . I think the other thing that bugs me a bit but for which I don't have a good answer right now is the continued divergence between the syntax of the urlprefix- tags and the route commands. \n```\nurlprefix-/ redirect=302,http://www.google.com/\ntranslates to\nroute add svc / http://www.google.com/ opts \"redirect=302\"\n```\nI need to think about this a bit more.. That isn't something that I'd want to address in this PR anyway but I'd like to keep in mind. One approach could be to write a template instead of a special syntax.\n```\nfabio \ne.g.\nfabio route add $svc / $addr opts \"redirect=302\"\n```\nThen you'd have to learn only one syntax.. How do other load balancers address that?. Thx. That'd be nice. It's getting a bit late here in NL. Going to hit the pillow since the kids get up early. We're getting there.. We could add some magic with a terminating slash or not. redirect=301,http://foo.com would append the path from the original request and redirect=301,http://foo.com/bar would redirect to /bar. That wouldn't solve the path mangling if you want to redirect /foo to /foo/bar or /bar/foo. Another approach could be to add a pseudo-variable like $path at the end. This would give you full control over the redirect target.\n```\nrequest uri: http://bar.com/foo\nredirect=301,http://foo.com$path -> http://foo.com/foo\nredirect=301,http://foo.com/ -> http://foo.com/\nredirect=301,http://foo.com/bar$path -> http://foo.com/bar/foo\nredirect=301,http://foo.com/bar/$path -> http://foo.com/bar/foo # ignore double slashes\n``\n. @ctlajoie I will. This looks decent so far but I'll let it bake for a couple more days since I want to think a bit more about edge cases. If me or you can't think of anything major then I'll merge this early next week (Mon or Tue). Sounds good?. Even better. . I've merged this to master. I had to update the demo server to handle the comma in theredirect` option but that was a good time to make this change anyway.\nThanks a lot for this. This has been a long requested feature. . @ctlajoie Thanks. That's good to know.. The idea of the config language approach is that the routing table has a human readable text format where multiple fragments are just concatenated and parsed into a runtime representation. Right now, one fragment is generated from the service tags in consul and the other fragment comes from /fabio/config in the consul KV store. This approach makes parsing simple and robust but doesn't lend itself to API driven partial updates.\nAnother reason there is no real fabio API for this is that consul already provides an API and a client to manage all this. The idea of the API is from the time when I wanted to support multiple backends besides consul. Given external constraints that doesn't seem to be happening any time soon.\nMy suggestion is to write a script that generates the routing table and store that under /fabio/config in the consul KV store instead of, or in addition to using service tags. Update the full routing table on every change. This keeps the process simple. \nThis could be as simple as \nroutes.py | consul kv put fabio/config\nDepending on the size of the routing table there may be some space and/or performance issues. See #343. A single consul KV entry can hold only 512KB and it takes some time to parse lots of them.\nThe first problem can be addressed by supporting multiple nodes or treat /fabio/config as a directory and parse all subnodes in order. For the parsing speed I need to write a better parser.\nThe routing syntax is\n```\nhost:port is the address app listens on\nroute add app foo.example.com/ http://host:port\n```\nSee: https://github.com/fabiolb/fabio/wiki/Routing#config-language\nPlease let me know if that helps and whether the consul space constraint is an issue for you. . To find out on which ip addresses and ports app is running you can run a consul or DNS query\n```\ndig @localhost -p 8600 srv app.service.consul +short\ncurl -i localhost:8500/v1/catalog/service/fabio\n```. Depending on how you implement this you could use the consul watches for this:\nhttps://www.consul.io/docs/agent/watches.html\n. Now I get it. fabio could allow you to provide a template which fills in the host:port so that you just provide the service id and fabio pulls the address itself. That's an interesting case and shouldn't be too hard to add.. ### Incremental route updates\nThe issue with incremental route updates is that they are unbounded. So just\nkeeping a list of all changes and applying them every time won't work.\nfabio uses Consul for service discovery and coordination so pushing an\nexternal routing table into a separate Consul KV node seems like the simplest\nthing to do.\nConsul has a 512KB limit on KV store nodes which translates into 4-5k targets\nuncompressed. With gzip this can probably be pushed 2-5x so you'd end up with\n10-25k routes of an external routing table. And then you can always have\nmultiple KV nodes to get around that limit as long as your Consul cluster can\nkeep up with the write rate.\nDepending on the size of your routing table this may also require fixing #343.\nGenerating route targets\nIf you generate an external routing table but still want to refer to services\nin Consul then fabio can generate them for you. However, the current list of\nservices and their addresses is not stored and hidden in the registry/consul\npackage.\nI can see several approaches:\n\n\nThe registry/consul package caches that list and exposes it. \n   This would tie this approach to the consul implementation\n\n\nServices are defined separately as part of the routing table which extends the config language.\n   This would decouple the routes from the services. A bit like normalizing an SQL data model.\n\n\nservice svc-a 1.2.3.4:5000 proto=http\nservice svc-a 1.2.3.5:5000 proto=http\nservice svc-a 1.2.3.6:5000 proto=http\nroute add svc-a /foo\nroute add svc-a /bar\n\nfabio expands route add defintions without a target to all known targets.\n   This would be shorter but feels like magic and also depends on order. \n\nroute add svc-a /foo http://1.2.3.4:5000 \nroute add svc-a /foo http://1.2.3.5:5000 \nroute add svc-a /foo http://1.2.3.6:5000 \n...\nroute add svc-a /bar # would expand to three previously defined targets\nI think the last option is the last invasive but the second option looks like the cleanest solution.\nWe could do the last option first as a stepping stone to the second option.. The goal of the config language is to provide a textual representation of the routing table so that humans and machines can read it. Otherwise, manual changes would require a different syntax. The urlprefix- tag is already a different representation of the same route add command with a slightly different syntax.\nurlprefix-/foo strip=/foo\nbecomes\nroute add svc-a /foo http://1.2.3.4:5000 opts \"strip=/foo\"\nWhen I've developed fabio, nomad didn't really exist and we've deployed self-registering services. The idea was that services know which routes they can handle and by deploying them you make them routable. This way you never have to store a routing table in a separate system (e.g. Puppet) and coordinate deployment of the routing table with the deployment of the service. (routing table before services or after? How to handle roll-back?) You can just forget about this part altogether. \nHowever, different setups require different solutions and if you want to decouple service discovery from defining the routes then having the config language being able to express that would help. \nThis is why I think option 2 is the cleanest solution since it decouples the two concepts which also means that you can update the service list without knowing about the routing and vice versa.\nurlprefix-/foo strip=/foo\nbecomes\nservice add svc-a 1.2.3.4:5000\nroute add svc-a /foo opts \"strip=/foo\"\nNow you can easily integrate different service discovery mechanisms or update the routing or do both. However, when you update the routing manually you have to coordinate this again for every deployment.\nI don't think that there would need to be marker to the service name itself but it may be helpful to indicate the origin of the service definition, e.g.\nservice add svc-a 1.2.3.4:5000 src=consul\n. Ah, I think I've closed that one prematurely since this refers to multiple issues. #417 only addresses the 512kb limit. @stevenscg shall we pick the discussion up again if this is still relevant?. Good to know. I'll have a look.. @RiRa12621 That would be even better :) . Hi Tino, thanks for the contribution. I will have a look right away. Also, thanks for adding the Developing section to the Wiki. Your description is spot on!. Re mutex: I guess you're referring to this:\nhttps://github.com/fabiolb/fabio/blob/master/route/table.go#L47-L56\nThe reason a mutex is required here is that it changes two things: the table and the metrics registry.\nI'll have a look at the rest today.. I\u2019ll have a quick look today. This looks fine except that the name is still bugging me because it is too specific. How about we call it TemplatePath and keep a generic list of templates? Then for the no route case we use the noroute.html template.\nI can do this or you can pick this up. I'd like to get this merged as well.. What I suggested is a larger refactor. I'll pick that up myself later. I'm going to merge this and amend the code with some small cleanup. \nThanks for this!. Unfortunately, this is a known issue and a duplicate of #282. Fabio should probably ignore the bad line and log the syntax error instead of blocking all updates. Neither approach is fully satisfactory but not updating the routing table at all because of a typo has the bigger impact. I'm going to close this as duplicate but please subscribe to #282 for updates.\nDuplicate of #282 . That is somewhat intentional. The architecture isn\u2019t designed for hot reload since that\u2019s something that shouldn\u2019t happen often enough to need this. Which problem are you trying to solve?. I\u2019m not saying it can\u2019t happen but this is not a trivial change and if you need to do this only once every three months then this would have to wait. Especially, dynamic listeners is something I\u2019d like to have but they should show up when a service registers the port and disappear with the last instance.. Also downtime is a couple of seconds. How often do you have to apply changes to the config that require a restart? If you do a restart with a graceful period of 1 sec fabio will have restarted within 2 sec. How much of an impact is that?. It could ignore the HUP signal. For now I suggest to change the systemd config. ~~~Yes, you'd use urlprefix-site1.com/ strip=/site1~~~\nnvm. I misread. Path mangling is not supported at the moment. Your service1 would need to respond to /.. I would be open to a PR. The reason I've resisted so far is to avoid fabio trying to become nginx. However, I can see why this could be useful in some cases. Maybe, we can generalize strip option to prefix={+,-}/path where strip=/path would be translated to prefix=-/path. . From first reading I'd say that is exactly what fabio does. You register services in consul with their host:port and a urlprefix- tag which announces the /path (http) it can handle or the public :port (tcp) it should be contacted on and fabio does the load balancing. Somehow I think I'm missing something here. \nCan you try to explain it in a different way?. registrator has a command line option which allows you to add tags.\nhttp://gliderlabs.github.io/registrator/latest/user/run/. Not that I know of since Docker does not handle the service registration. That\u2019s what the registrator does. I could write a small app myself which does the same thing. . @leprechau That would be great. I think you can just edit the wiki yourself. . Make sure you add/update the link in the Docker section unless what is there isn't already sufficient:\nhttps://github.com/fabiolb/fabio/wiki/Features#docker-support. I forgot about that as well. Someone else provided that to me. Maybe add a link to a more prominent place?. I've added also a link to the Docker compose example to the side menu.. @leprechau thx for adding the link.\n@ethicalmohit do you have all the info you need?. Users must be able to create PRs for the website content and updating the site should be automatic. \nhttps://netlify.com/ looks like a good solution for this and they support Hugo. The only challenge is that the theme I chose is not free so it can't be stored it in a public repo. \nTwo options:\n\npublic repo with the content/ folder, private repo with the full site and the content/ folder as submodule\npublic repo with the website, private repo with the theme. I've moved the website to the docs/ folder from where it gets deployed with https://netlify.com/. Something wants to request /error but there is no mapping since your service is only announcing /cpm. Everything else will return a 404 Not Found. You need to have a service that can handle /error or add a second tag on the cpmservice if it handles it. \n\n\u2014\nFrank Schr\u00f6der\n\nOn 12. Dec 2017, at 02:28, k1ng87 notifications@github.com wrote:\nI'm having in issue where I can't get my nomad job to route with Fabio with anything except /\nfor example...this works:\n    cpu    = 1500\n    memory = 2048\n\n    network {\n      mbits = 50\n\n      port \"httpcontrolplane\" {\n\n      }\n    }\n  }\n\n  service {\n    name = \"cpmamadou\"\n    tags = [\"urlprefix-/\"]\n\n    port = \"httpcontrolplane\"\n\n    check {\n      type     = \"http\"\n      port     = \"httpcontrolplane\"\n      path     = \"/health\"\n      interval = \"10s\"\n      timeout  = \"2s\"\n    }\n  }\n\nbut this errors out..\n    cpu    = 1500\n    memory = 2048\n\n    network {\n      mbits = 50\n\n      port \"httpcontrolplane\" {\n\n      }\n    }\n  }\n\n  service {\n    name = \"cpmamadou\"\n    tags = [\"urlprefix-/cpm\"]\n\n    port = \"httpcontrolplane\"\n\n    check {\n      type     = \"http\"\n      port     = \"httpcontrolplane\"\n      path     = \"/health\"\n      interval = \"10s\"\n      timeout  = \"2s\"\n    }\n  }\n\nand it throws this error when I go the link:\nThis application has no explicit mapping for /error, so you are seeing this as a fallback.\nTue Dec 12 01:24:33 UTC 2017\nThere was an unexpected error (type=Not Found, status=404).\nNo message available```\nthis error is happening on all of my nomad jobs....a url prefix like this works: urlprefix-/ but not with anything after /.\nwhy is this happening?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. This new comes from https://github.com/fabiolb/fabio/blob/master/logger/level_writer.go#L35 which is probably triggered by a log.Print without a prefix. I\u2019ll grep through the code later. . That means your consul state changes every second. Check for flapping services or - more likely - volatile data in the health check output. Like time stamps or process ids or something else that changes every time the check is executed. There are mitigation procedures on the consul side. It in general I advise to try and fix the root cause first. . @ctlajoie no time stamps in the health check output? I\u2019ll switch that to debug and work on the consul change rate indicator as described in #368.\n  . Thanks @slackpad . Thanks for pointing that out. I\u2019ll update the wiki. FWIW, vault can be used in two modes: as encrypted KV store and as an on-demand CA. . Thanks. Can you provide the stack trace and the version you\u2019re using? I\u2019ll fix that. . I\u2019m not a Docker expert. If you have a suggestion on how to build or run the container better then please let me know. I\u2019d also like to have more practical use cases as examples. Working on a new website with more room for these things as we speak. . Hi @stevenscg, that would be cool. Please DM me on Twitter @magiconair. \n\nAs for getting the word out: maybe do the first one and then tweet about it? Depending on the feature write a blog post and see whether this is interesting for a conference. I\u2019m open for suggestions. . I'm also looking at https://opencollective.com. Still playing with this: https://opencollective.com/fabio\n. That looks simple enough. Can you update registry/consul/passing_test.go? It is time  for me to also write a test for service.go. Sorry, got a bit sick. I'll do this probably tomorrow and then try to run a release right away. Time to use goreleaser.. @alvaroaleman Thanks for the patch. Merged it and made some small changes in subsequent commits.. Thx :). I\u2019ll add a comment to the QuickStart. Glad you\u2019ve found it. . Thanks!. The quickest way for me to reproduce this would be to have the full routing table and the request that gets misrouted. Can you provide that? DM me on Twitter if you need a secure channel first. \n\u2014\nFrank Schr\u00f6der\n\nOn 18. Jan 2018, at 03:03, Craig Day notifications@github.com wrote:\nWe are experiencing multiple instances of Fabio routing requests to the wrong backend service. Once it starts happening it persists, typically until some change is made to the routing table by a service restart or similar. It's quite catastrophic because once it starts happening it's as if a whole bunch of URL/endpoints just disappear and start returning 404 not found because the requests are landing on a backend that doesn't serve them.\nWe have traced using tcpdump the requests coming in and out of Fabio and have proved beyond doubt that it is making the wrong routing decisions.\nThe attached dump shows a request coming into fabio for d2mx-prod-admin.dionglobal.com and then leaving fabio destined for a service on port 30398 but the routing table/consul indicates that the service on 30398 is analyser.sequoiadirect.com.au.\nWe were initially running on fabio-1.5.0-go1.8.3-linux_amd64 but moved to fabio-1.5.4-go1.9.2-linux_amd64 to see if fixed the problem, but it hasnt.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @craigday try curl localhost:9998/api/routes?raw or set log.routes.format = all. @craigday Is this still an issue?. Looking.. @craigday I'm awake now and DM'ing you on Twitter.. The way fabio currently handles websockets (via a raw tcp connection) makes detection a bit difficult. We can go back to a protocol proxy which relays WS messages instead. However, a first attempt is to inject a Connection: close header into the upgrade request since with HTTP/1.1 all connections are permanent unless declared otherwise. . @craigday Can you try that patch and see if it works? I'll add an integration test to simulate that behavior later.. I don't think there is a limit and if you need a limit I would have to add that. The simplest thing is to add a global option but I think a per-route parameter is also not more difficult. Is not having a limit a blocker for you using fabio at all?. Thanks!. Interesting. I assume you tested this since I thought you'd need to overwrite the ModifyResponse function in the reverse proxy. An integration test might be handy. If this works then I can refactor the ugly hack that I have for getting the response body size and status code. \n\nCould you please update config/load_test.go with the new arguments and add the docs as well? Then I'll merge this.\nThx. I think adding DeregisterCriticalServiceAfter with a sane default makes sense. Can you please add that as a separate commit within this PR?. Ah, and please add some tests to https://github.com/fabiolb/fabio/blob/master/route/parse_test.go. I think this is good enough as is. Thanks a lot!. I don't know. What would you expect to happen?. I can\u2019t decide on what\u2019s right for every setup so this should be configurable then. You want to send a PR?. @slackpad Thanks. That's good to know. In that case fabio should behave like Consul. Adding the setting and switching to 'strict' in a later release seems like the right approach.. Hmm, this seems a bit more complex than necessary. I think updating the passingServices function should be sufficient. Also, instead of the boolean config flag I'd probably go for a string flag like registry.consul.checksRequired = (one|all). Do you mind if I give the passingServices function a shot?. How about this:\n```go\nfunc passingServices(checks []api.HealthCheck, status []string, strict bool) []api.HealthCheck {\n    var p []*api.HealthCheck\n    for _, svc := range checks {\n        if !isServiceCheck(svc) {\n            continue\n        }\n        total, passing := countChecks(svc, checks, status)\n        if passing == 0 {\n            continue\n        }\n        if strict && total != passing {\n            continue\n        }\n        if isAgentCritical(svc, checks) {\n            continue\n        }\n        if isNodeInMaintenance(svc, checks) {\n            continue\n        }\n        if isServiceInMaintenance(svc, checks) {\n            continue\n        }\n        p = append(p, svc)\n    }\nreturn p\n\n}\n// isServiceCheck returns true if the health check is a valid service check.\nfunc isServiceCheck(c *api.HealthCheck) bool {\n    return c.ServiceID != \"\" &&\n        c.CheckID != \"serfHealth\" &&\n        c.CheckID != \"_node_maintenance\" &&\n        !strings.HasPrefix(\"_service_maintenance:\", c.CheckID)\n}\n// isAgentCritical returns true if the agent on the node on which the service\n// runs is critical.\nfunc isAgentCritical(svc api.HealthCheck, checks []api.HealthCheck) bool {\n    for _, c := range checks {\n        if svc.Node == c.Node && c.CheckID == \"serfHealth\" && c.Status == \"critical\" {\n            log.Printf(\"[DEBUG] consul: Skipping service %q since agent on node %q is down: %s\", c.ServiceID, c.Node, c.Output)\n            return true\n        }\n    }\n    return false\n}\n// isNodeInMaintenance returns true if the node on which the service runs is in\n// maintenance mode.\nfunc isNodeInMaintenance(svc api.HealthCheck, checks []api.HealthCheck) bool {\n    for _, c := range checks {\n        if svc.Node == c.Node && c.CheckID == \"_node_maintenance\" {\n            log.Printf(\"[DEBUG] consul: Skipping service %q since node %q is in maintenance mode: %s\", c.ServiceID, c.Node, c.Output)\n            return true\n        }\n    }\n    return false\n}\n// isServiceInMaintenance returns true if the service instance is in\n// maintenance mode.\nfunc isServiceInMaintenance(svc api.HealthCheck, checks []api.HealthCheck) bool {\n    for _, c := range checks {\n        if svc.Node == c.Node && c.CheckID == \"_service_maintenance:\"+svc.ServiceID && c.Status == \"critical\" {\n            log.Printf(\"[DEBUG] consul: Skipping service %q since it is in maintenance mode: %s\", svc.ServiceID, c.Output)\n            return true\n        }\n    }\n    return false\n}\n// countChecks counts the number of service checks exist for a given service\n// and how many of them are passing.\nfunc countChecks(svc api.HealthCheck, checks []api.HealthCheck, status []string) (total int, passing int) {\n    for _, c := range checks {\n        if svc.Node == c.Node && svc.ServiceID == c.ServiceID {\n            total++\n            if hasStatus(c, status) {\n                passing++\n            }\n        }\n    }\n    return\n}\n// hasStatus returns true if the health check status is one of the given\n// values.\nfunc hasStatus(c *api.HealthCheck, status []string) bool {\n    for _, s := range status {\n        if c.Status == s {\n            return true\n        }\n    }\n    return false\n}\n```. That would be great. It would be good as well if you could extend the existing test for the passing function. It could use some love in terms of naming the cases. If you want I can provide an example of what I mean. \n\u2014\nFrank Schr\u00f6der\n\nOn 31. Jan 2018, at 09:38, systemfreund notifications@github.com wrote:\nYes, that makes much more sense!\nSo should I incorporate your code into this PR and also change the setting to a string-based one?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @systemfreund are you still working on this?. I think that is OK. Can you please rebase the branch on master and update fabio.properties and the docs with the new option?. Thanks @systemfreund !. Can you provide an example? Would you be interested in submitting a PR?\n\n\u2014\nFrank Schr\u00f6der\n\nOn 29. Jan 2018, at 06:39, Saravana Kumar Periyasamy notifications@github.com wrote:\nFabio needs to emit the opentracing standard headers, and so it can participate in the distributed tracing.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @galen0624 of course! This would be quite cool.. Adding BGP support was on my list. Started working on a go bgp library and had something working but that stalled. I'm curious about your approach.\n\nYou can run govendor add +e to add all missing packages and check that in as a single commit as long as the vendored packages are separate from the code.\nLooking forward to this :). Just merged this.. Thanks. Can you send a PR?. nvm. Fixed it. Thanks again.. Thanks a  lot for putting in the work. I'll merge that.. Asked @pschultz whether he could have a look.. AppendCertsFromPEM fails here https://github.com/fabiolb/fabio/blob/master/cert/source_test.go#L656 when trying to add the cert which leaves the caPool empty and then generates the error. Trying to understand why.. ```go\npackage main\nimport (\n    \"crypto/x509\"\n    \"fmt\"\n)\nconst cert = -----BEGIN CERTIFICATE-----\nMIIDOzCCAiOgAwIBAgIUaFacnWI+18PkzWw3L1ZhDyWE6/UwDQYJKoZIhvcNAQEL\nBQAwGDEWMBQGA1UEAxMNRmFiaW8gVGVzdCBDQTAeFw0xODAyMDYwMjA0MTNaFw0x\nODAyMDYwNDA0NDNaMBgxFjAUBgNVBAMTDUZhYmlvIFRlc3QgQ0EwggEiMA0GCSqG\nSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDIBohqz/hHEN6y2emMDG/fgsggbAXzrIkw\n58orFVbK/+hGFMUPpBTZ15r5rYW5nNhIf/tyecLN1CSy/12HLbpx7ebpvMOj2i7b\n/VgiadSpTklJEGUIt+nYPeLT+8qLXqiOQA4CwsES/UgQ3h+QMtwjAdcaloho1Ara\nRDctRLlEf/VvBYVozPqYfbKRh4ofmqLo9KJFF8yMAOgkFsSmP8/Pv8Cii2fThyGB\nv4J56uPUxHW5ROuy1WGu25rEB7Txuvqgpl9m7lN/oqkUhHrUMwFUx5kcG0fWPc2t\nRv/mePw+cDh/5P8IsBLgYGpjGKUGgQduE4LHjjRyUf/xnzuW8jOrAgMBAAGjfTB7\nMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBTIDU8u\nKA3PavIxercuzYTMDcSDcTAfBgNVHSMEGDAWgBTIDU8uKA3PavIxercuzYTMDcSD\ncTAYBgNVHREEETAPgg1GYWJpbyBUZXN0IENBMA0GCSqGSIb3DQEBCwUAA4IBAQBr\n0Nn+msFZjAA4gpHxt/7EvyfbUTjNmvXKALvhuX6z0qgdlFWVFYutNIkbKPF3a06H\ngVW7zIvnKg2BX+bkhM/C/IC3oZsD3gK56A4Q71tK9q8QG0cWcqCyfqtG458Q1i8A\n05t9rJ1V6ppN9VWe11tvTgEz5FK0e7jnQQEXH8hNjAXQXX7sbQzI+5GagUA3/ZT4\n7bl/lkWg9yZCl/lM8UbFxlaRow4sVX5080ilrGlbCn29Ob6kFzWEv7rXs7BXrNgN\nYgWDKTrsa4uD7NTuMmoJvsIw7FLkE8XgNNwuURVLsJ4/+TPbfdbVsZW8qO0s0dR+\nAEFqi3JlxPWFVBU01oys\n-----END CERTIFICATE-----\nfunc main() {\n    p := x509.NewCertPool()\n    fmt.Println(p.AppendCertsFromPEM([]byte(cert)))\n    fmt.Printf(\"p: %#v\\n\", p)\n}\n```\n```\n$ ~/go1.9.2/bin/go run main.go\ntrue\np: &x509.CertPool{bySubjectKeyId:map[string][]int{\"\\xc8\\rO.(\\r\\xcfj\\xf21z\\xb7.\u0308\u0301\\xcc\\r\u0103q\":[]int{0}}, byName:map[string][]int{\"0\\x181\\x160\\x14\\x06\\x03U\\x04\\x03\\x13\\rFabio Test CA\":[]int{0}}, certs:[]x509.Certificate{(x509.Certificate)(0xc4200a4000)}}\n$ ~/go1.10rc1/bin/go run main.go\nfalse\np: &x509.CertPool{bySubjectKeyId:map[string][]int{}, byName:map[string][]int{}, certs:[]*x509.Certificate(nil)}\n``. Changing the common name of the generated cert to a DNS compatible name fixes it.. @Gufran Thanks. Can you please add some documentation to thedocs`? Then I can merge this.. Yeah, sorry, I know. Got a full plate right now and things are piling up. I'll try to look at this today or tomorrow.. @Gufran Not your fault. I'm moving to Sweden with the family, selling house, finding schools and stuff. So I've got my hands full. Could you please rebase the patch and fix the conflict and I'll try to have a look later this week. Sorry man .... Hi @Gufran, I get this when I run the tests:\n--- FAIL: TestBuildEnv (0.00s)\n    proxy_test.go:177: Key 'DOCUMENT_ROOT': expected value '/site', got ''\n    proxy_test.go:177: Key 'SCRIPT_FILENAME': expected value '/site/docs/index.php/user/profile', got '/docs/index.php/user/profile'\n    proxy_test.go:177: Key 'PATH_TRANSLATED': expected value '/site/user/profile', got '/user/profile'\nFAIL\nFAIL    github.com/fabiolb/fabio/proxy/fastcgi  0.036s. Tell me about it. Could you have a look at the tests? Otherwise, I have to back out the change.. I thought I did. Can you rebase?. The library is in the vendor folder. Why do you need to pull it?\nYou should not need to pull any libraries at all.. I didn't, so please don't. . Please use govendor and vendorfmt. . Because it works and there is no upside on using dep. I want to have the code self-contained to avoid exactly the question you're asking.. That's fine and please feel free to use dep for your projects if you think it is a better fit. But allow me the same courtesy and accept the choices I've made. . That is the very purpose of the vendor folder so that you do not have to rely on external repositories. :)\nPlease do me the favor and submit your PR according to the requirements of this project. \nFeel free to submit another PR where you switch the dependency control to another tool but at this point I will not merge this since I don't want to rely on external dependencies for building fabio.. Because they are all forked and checked into the main source repository. You have to check out one and only one git repository. Again, that is the purpose of the vendor folder - but I think you know this.\nLook I don't want to be a jerk and I would appreciate your contribution on this issue. I also think you know exactly what my motivation is and what I am trying to tell you. I have asked you to respect my choices and I've explained why changing this tooling is not interesting for me. \nIf this is a unacceptable choice for you then I accept that. However, I would like to ask you to stop arguing about this now since we're only going in circles. \nPlease make a choice to either pick this up or not but do not waste other peoples time to submit code that someone else has to clean up just because you feel like it.. I'm closing this in favor of #575. Please let me know if this is a mistake.. Is fabio still using consul for service discovery?. fabio can use a file registry but my guess is that this isn't what you're looking for.\nhttp://fabiolb.net/ref/registry.file.path/. Fabio needs access to the catalog and the registry.consul.kvpath prefix in the KV store. You can either provide an ACL token or give it read and list permissions. list should be required as of 1.5.7 since fabio will then use all sub keys as well.. If you have a working example I can add that to the docs: http://fabiolb.net/ref/registry.consul.kvpath/. Right now it isn't but I could allow an empty registry.backend.consul.kvpath to disable this. However, I still think that this should be possible with the right ACLs. @slackpad, can you help out?\nFWIW, I've tried this:\nshell\n$ curl\n   --request PUT\n   --header \"X-Consul-Token: secret\"\n   --data '{\n  \"ID\": \"anonymous\",\n  \"Type\": \"client\",\n  \"Rules\": \"node \\\"\\\" {policy = \\\"read\\\"} service \\\"consul\\\" {policy = \\\"read\\\"} service \\\"fabio\\\" {policy = \\\"write\\\"} key \\\"fabio/config\\\" {policy = \\\"write\\\"} agent \\\"\\\" {policy = \\\"read\\\"}\"\n}' http://127.0.0.1:8500/v1/acl/update. I'm pretty sure that this should work. I've asked an ex-colleague of mine for advice and will try myself a bit more. If all fails I'll add your suggestion.. I've tried that and don't get the log messages.\nrm -rf data ; consul agent --config-file master.hcl\n$ cat master.hcl\nacl_datacenter = \"dc1\"\nacl_default_policy = \"deny\"\nacl_down_policy = \"deny\"\nacl_master_token = \"secret\"\nacl_enforce_version_8 = false\ndata_dir = \"data\"\nserver = true\nbootstrap = true\ncurl -XPUT -d '{\"ID\":\"anonymous\",\"Name\":\"Anonymous Token\",\"Type\":\"client\",\"Rules\":\"key \\\"deploy/\\\" { policy = \\\"read\\\"} service \\\"\\\" { policy = \\\"read\\\"} key \\\"fabio/config\\\" {  policy = \\\"read\\\"} key \\\"fabio/\\\" {  policy = \\\"read\\\" } agent \\\"\\\" {  policy = \\\"read\\\"} node \\\"\\\" {  policy = \\\"read\\\"}\"}' http://127.0.0.1:8500/v1/acl/update?token=secret\n```\nstart fabio\n./fabio\n```\nI get this in the logs though:\n2018/02/14 09:43:01 [WARN] agent: Service \"fabio-frankbook.local-9998\" registration blocked by ACLs\n2018/02/14 09:43:02 [WARN] agent: Check \"service:fabio-frankbook.local-9998\" registration blocked by ACLs. I\u2019d like to add that to the docs . Done. Thanks!\n\u2014\nFrank Schr\u00f6der\n\nOn 20. Feb 2018, at 07:38, holtwilkins notifications@github.com wrote:\nWhile you're at it @magiconair , I also noticed that the fabio.properties and docs/content/ref/registry.consul.noroutehtmlpath.md docs says the default for registry.consul.noroutehtmlpath is /fabio/noroutes.html, but it's actually /fabio/noroutes.html as per config/default.go\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Ah, I think this is a regression from https://github.com/fabiolb/fabio/issues/396. I'll fix this. For now please use 1.5.6. No this is t supported right now but shouldn\u2019t be too hard to add. How often do these ip ranges change?\n\nAlso, no need to apologize :). That looks good. The only question I had what to do with the PROXY connections? You'd have to use the RemoteAddr field from the http.Request to make the decision but that gets overwritten by go-proxyproto. I'm not sure whether this is an issue. Just something to think about.. @leprechau IPv6 addresses, hostnames (dns reverse lookup timeout comes to mind...)\nI also thought about more complex use cases like testing for cookies and so forth but I think that should live in the app layer. \nWhile thinking about this: Is this something that should be configured on a per-route level or on a global level? What is the underlying use-case? . Just in case we change our minds and allow more complex rules should there be an indication that the value after allow is actually a list of ips?\nWild thinking:\nurlprefix-/foo allow=method:GET\nurlprefix-/foo allow=ip:1.2.3.4/5\nCould the first argument be something that's considered a filter function and the remainder the input values?\nCan you have more than one allow option on a single urlprefix-/foo?\nI'm not saying we need all this right now or ever but if we can design the syntax in a way that allows us to extend the use-case later then that might help.\nAlso, if you think this would be overkill and we can solve that differently then I'm fine with that, too.. @leprechau please keep it to ip matching for now unless you're confident that you thought the other option through.. You can use the glob matcher to achieve this. I've noticed that the documentation for this is a bit bare-bones and updated it on the website:\nhttp://fabiolb.net/ref/proxy.matcher/. Once you enable the glob matcher your urlprefix-/service/foo/*/bar should work. Please let me know if it doesn't.. I haven't fully nailed down the test failures. I'm punting by running on travis and codeship and if one of them is green I'm ok with that :-/ I'll have a look at the PR later.. @microadam and @leprechau thanks to both of you for working on this!. I\u2019ll have a look at the code later after coffee. One thought I had about the addresses is whether to automatically change 1.2.3.4 to 1.2.3.4/32. \nAlso, could we add an all alias which will just match any address?\nCan you do allow=ip:1.2.3.4/32 deny=all or is that implicit?. Should we do this for v6 addresses without netmask as well?\n\u2014\nFrank Schr\u00f6der\n\nOn 15. Feb 2018, at 14:22, Aaron Hurt notifications@github.com wrote:\nI added some code to add a /32 prefix to value strings that do not contain a / ... invalid or incomplete addresses will still error out in the ParseCIDR function.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. hrmpf, I've merged this but put the additional commit into the branch. This way github won't auto-close the PR ... This is on master now. \n\nThanks a lot for @leprechau and @microadam for working on this!. @kostyrev Thanks for reminding me.\nHowever, the 14M is not just the .git directory but also the vendor folder, the docs and the rest of the code. The savings don't seem worth a force push to master.\n$ git clone git@github.com:fabiolb/fabio fabio.clean\n$ cd fabio.clean/\n$ du -hs ../fabio.clean\n 14M    ../fabio.clean\n$ du -hs .git\n  8.7M  .git\n$ git filter-branch --index-filter \"git rm -rf --cached --ignore-unmatch fabio.exe\" HEAD\n$ rm -rf .git/refs/original/ && git reflog expire --all &&  git gc --aggressive --prune=now\n$ du -hs .git\n7.2M    .git\n$ du -hs ../fabio.clean/\n 13M    ../fabio.clean/\n. @kostyrev FWIW, running git gc trimmed my .git directory down from 20M to 8.1M. @taemon1337 if the documentation could be improved then please let me know where you looked and couldn't find the info or a good example.. Looking forward to it. Maybe time to add the UDP+SNI support .... Hmm, is this because of os.Getuid()? This works in the container I've built but I'm using CGO_ENABLED=0. Just tried docker run -it fabiolb/fabio:1.5.7-go1.9.2 but I didn't try that before. . Interesting. I thought I was using CGO_ENABLED=0 but I'm not .... Ah, the .goreleaser.yml uses that. Blessing of multiple build systems.... What\u2019s the problem?\n\u2014\nFrank Schr\u00f6der\n\nOn 16. Feb 2018, at 10:33, Robert Goldsmith notifications@github.com wrote:\nHas anyone worked out how to get SSH connections to work via the TCP Proxy facility?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Interesting. Please share a solution if you find one. \n\n\u2014\nFrank Schr\u00f6der\n\nOn 16. Feb 2018, at 10:59, Robert Goldsmith notifications@github.com wrote:\nI get ssh_exchange_identification: Connection closed by remote host\nThere's no real debug info available. My suspicion is that the handshake is failing because the IP address of the client doesn't match the IP address of the proxied connection - or the same in revers for the server.\nI don't think the problem is one Fabio can fix but I wondered if anyone else had worked out how to configure the ssh server and client so they don't get upset.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thanks!. That should work out of the box. Can you verify whether fabio forwards the request to the server (e.g. tcpdump -i eth0 -A -s 1520 port 20314 or ngrep -q -D eth0 port 20314 on the server itself?. @atillamas Can you post your full routing table with curl localhost:9998/api/routes?raw ?. I'll comment here to keep the discussion in one place. \n\nWhy only https? \nMaybe like this?\ngo\ntarget.RedirectCode != 0 && target.URL.Scheme == req.Header.Get(\"X-Forwarded-Proto\") . But will this change not have the same effect for https targets, e.g. https://foo.com/bar -> https://foo.com/baz?. I've merged the PR. Thanks a lot for the incredible patience and diligence of both of you!. As a side note people have been saying to put an nginx in front of fabio to handle cases like generic redirects, https enforcements and header mangling since fabio does not support this. If this would again sit behind an ELB you have the multi-layered proxy setup. . Hmm, not sure whether this creates a redirect loop.. Something like route add :80/ ... might be handy. Not sure if that fits well with the current syntax. Hey Shay,\nI think extending the current glob matcher with ** logic would be a good idea and it should be backwards compatible. \nAdding a regex matcher in addition to that would help, too. \nBonus points for adding a route option to select this per route instead of using a global flag. \nPR is very welcome. \nFrank\n\u2014\nFrank Schr\u00f6der\n\nOn 26. Feb 2018, at 17:05, Shay Arbov notifications@github.com wrote:\nHey,\nWe've been using fabio for a while now, and we recently started using the glob matcher.\nThe problem we've encountered was that once we switched the matching strategy it affected all the endpoints matching, in addition to that the glob matcher does not match the '/' signs. these two issues forced us to add many new tags to existing services in order to try and cover all of the possibilities of each endpoint\ne.g\nurlprefix-/service/foo/\nurlprefix-/service/foo//\nurlprefix-/service/foo/// ...\nThis is clearly not the preferred solution, I would like to suggest three ways to go about this issue:\nAdd a per tag matching strategy (e.g urlglob-/service/foo/).\nAdd support for double '' wild card, which will match '/' signs.\nAdd a new matcher - a regex matcher.\nIf any of these ideas sounds reasonable to you, I would be happy to open a pull request for them.\nThanks,\nShay\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I think this is the right approach. \n\nThe chain of ips you have to validate is client, proxy1, proxy2, ...., proxyN. The chain is composed of the xff header and the remote ip of your incoming connection which cannot be spoofed. Also, previous proxies only append the remote ip of their incoming connection to the xff header. \nFor this to work you have to trust a chain of proxies in front of you. The end of your trust chain contains the ip address of the inbound connection you care about and it cannot be spoofed. If someone sends a bogus xff header from an ip that is not in the list then this ip will be added to the xff header by your trusted proxy and the other trusted proxies in front of you will pass on that information to fabio which will see the ip and deny access.\n. With that in mind I wouldn't call this a work around. This is how this should work I think. @ctlajoie My main motivation is that there are two ways of expressing the same thing and there is a slight difference in syntax. Also, urlprefix- doesn't sit well with tcp services. Tech debt from the early days :)\nMaybe it is just me wanting to clean up but in the process I make things more complex. What do you think?. If we add the ability to remove arbitrary untrusted headers then this would become an improvement instead of a potential breaking change.. Along the same line we could also add the option of injecting headers.. But if the XFF problem is your main sticking point then we can start with removal.. Thanks a lot!. No, but I don't think this should be difficult to add. According to https://golang.org/pkg/crypto/tls/#Config the TLS client needs to either set Certificates or GetClientCertificate. \nThe http.Transports would need a GetClientCertificate function which would need to be configured here:\nhttps://github.com/fabiolb/fabio/blob/master/main.go#L171-L186\nThis should probably be provided by a cert store and could be similar to this:\nhttps://github.com/fabiolb/fabio/blob/master/cert/source.go#L89-L151\nIf you want to submit a PR for this I'd be more than happy to merge it.. No idea. Let me have a look.. After looking at https://github.com/golang/go/issues/19895 I think there could be an issue with the way your service responds to health checks. It seems to be sending data after it has responded to the health check. . The access log should go to stdout and the normal log to stderr via the leveled logger so they should not interfere with each other.\nThe leveled logger looks at the first two bytes of the log line to determine the level and if that isn't in the right format prints invalid log msg:. . Cool. Is this the default regex from the properties file?\nI\u2019m glad you like it \ud83d\ude42\n\u2014\nFrank Schr\u00f6der\n\nOn 6. Mar 2018, at 16:53, Tino de Bruijn notifications@github.com wrote:\nOkay, found the culprit!\nFABIO_proxy_gzip_contenttype = \"^(text/.|application/(javascript|json|font-woff|xml)|.+(json|xml))(;.*)?$\"\nRemoving that makes it work :). Tried other regexes but that didn't make a difference.\nPs. thanks for making fabio start so fast, tried a lot of different configs \ud83d\ude0a\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Ah, damn. The ugly hack for getting the response rears its head... I'll comment on the PR. That's a good catch. Thanks a lot for finding this!. @tino Could you try #470 ?. @jorgemarey By any means please do ! :). Can you rebase and test this on top of #457 since I want to merge that first.. I'll try to roll this into the next release. . Thanks a lot!. Try \n\nregistry.consul.register.enabled=false\n\u2014\nFrank Schr\u00f6der\n\nOn 15. Mar 2018, at 09:26, James Rasell notifications@github.com wrote:\nI wish to disable the default Fabio registration in Consul in order to use my own health checks and from its description am trying to use the -registry.consul.register.enabled flag to do this. Within my Nomad job specification file I am supplying the flag:\nargs = [ \"-registry.consul.register.enabled\", \"false\"]\nWhen submitting the job however, Fabio is configured with \"Register\": true, which is also reflected through the Consul UI which shows the service check Service 'fabio' check service:fabio-* registered.\nAdditional config:\n\"Addr\": \"localhost:8500\",\n            \"Scheme\": \"https\",\n            \"Token\": \"\",\n            \"KVPath\": \"/fabio/config\",\n            \"NoRouteHTMLPath\": \"/fabio/noroute.html\",\n            \"TagPrefix\": \"urlprefix-\",\n            \"Register\": true,\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thanks!. I'll have a quick look. I've created #470 for option 1 and added a test. I think that's a cleaner way of solving this. Again, thanks for tracking this down. Could you test #470, please?. Without trying it I'd say that this should work since the requests end up on different listeners. There is only one lookup table for all proxies. Did you try it and it didn't work?. OK, I need to look. Maybe having a single routing table isn't the right solution .... Sorry, I just started a new job traveling between Amsterdam and Stockholm. I'll try to find some time to review this but I'd love to merge this.. @kmfischer3 Sorry for the delay. Catching my breath after moving countries. Could you please rebase so that I can merge this? Thank you. Thank you.. This was just a monkey patch until this was fixed upstream. I\u2019ll update fabio to use the pubnub repo again. \n\n\u2014\nFrank Schr\u00f6der\n\nOn 22. Mar 2018, at 01:30, Jeremy Voorhis notifications@github.com wrote:\nFabio depends on magiconair/go-metrics-statsd, but the upstream repository has been removed. A copy of the repo currently resides in vendor, so builds are not affected.\nAre there any plans to restore the repo, or switch to an alternate implementation?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. ok, I've added code that checks for HTTP/1.1 101 in the first response sent back and only then switches to copying bytes. Could you check that?. Thanks!. As for approach please see https://github.com/fabiolb/fabio/issues/211#issuecomment-375880738. Lets first try to add one go-kit/metrics driver to verify the approach and then we can spread the work to support more.. To test this I'm currently doing this:\n\n```\nterminal 1\nconsul agent -dev\nterminal 2\ncd $GOPATH/src/github.com/fabiolb/fabio/demo/server\ngo build\n./server -prefix /foo\nterminal 3\ncd $GOPATH/src/github.com/fabiolb/fabio\ngo build && ./fabio -metrics.target=flat,label\nterminal 4\ncurl -i localhost:9999/foo\n```. I'm wondering whether https://opencensus.io/go.html might be a better foundation. Does someone have some experience with this?. Yeah, I know. I was switching jobs and moving my family to a different country. Lots of changes, new language and all. Also, fabio needs a bigger community of contributors since I have become a bottleneck. I am starting to catch my breath again and get some energy on working on fabio again. However, this project is now way more than what I've ever needed to build. As much as I like programming I'll never be able to keep up with the demand by myself. \nThe metrics code is still bugging me and I'd like to solve this properly but I could really use some help here. If someone wants to work with me on this we could finally tick this one off.. My guess is that your consul cluster has issues since fabio just waits for updates from Consul and then rebuilds the routing table. You can test that by having the fabios talk to the Consul servers instead of the local agents and see if the problem goes away. I would have a look at the Consul logs of these servers to see whether there were any strange things happening.. fabio relies on Consul to sync the state in the cluster and because of that they are all independent. They just route what Consul reports to be up. \nFabio always replaces the entire routing table whenever there is a change. You should see the services which were added and removed in the fabio logs. The normal setup is for fabio to talk to the local Consul agent and let it handle the cluster state.\nIf your service has more than one health check then you could be affected by #427. There is another issue with websocket connections behind a load balancer but that shows different behavior.\n. Did you pull the health data?. I meant the health data from Consul, https://www.consul.io/api/health.html#list-checks-in-state\nFabio runs this query to get the current health data for all services from Consul and then filters out the healthy ones. \ncurl http://localhost:8500/v1/health/state/any\nTwo observations:\n\nWhy is your health data changing all the time? This looks like either a flapping service or a volatile health data output, e.g. a timestamp or process id in the output of the script.\nI'm not sure why the Manual config is changing as well. Do you have a script that writes to the fabio/config KV key?\n\nAgain, fabio pulls its data from consul and all fabios are doing the same thing since they rely on Consul to provide the consistency. Your problem is way more likely in your Consul setup than in fabio. . Fabio keeps routes in memory. You should look for changes to the routing table which fabio logs as delta. They should be the same on every fabio instance. \nDo you have multiple health checks for a service? Do you have unique names for the service instances? . You can control the output format of the routing table with http://fabiolb.net/ref/log.routes.format/. Does the consul agent they are connected to still receive updates? Ideally, you want to check whether the raft log index moves forward. Trying to find a good API call to test that.. Fabio just does a long poll on the Consul API and waits for a notification of a raft change - any change. Once the Consul raft log changes fabio will pull all the data and rebuild the routing table. This is when you see all the Health changed to #nnnn messages. The number is the raft index. \nWhen there is no notification there is little I can do. Fabio could time out the Consul connection and retry after some time but I still think that the issue is somewhere in the Consul/Nomad setup.. Did you try different nomad and/or consul versions?. If you're comfortable building your own fabio you could try adding a WaitTime: 5 * time.Second to the client config in \nhttps://github.com/fabiolb/fabio/blob/master/registry/consul/backend.go#L23\nOtherwise, the wait calls will block until there is a change. Don't set this value too low since fabio will pull all data every time. To prevent this add this as well:\nhttps://github.com/fabiolb/fabio/blob/master/registry/consul/service.go#L31\ngo\nif meta.LastIndex == lastIndex {\n    continue\n}\nI can't see anything major related in the consul changelog but you could try the latest consul to see whether that makes a difference. The issue seems reproducible enough in your environment.\n. Building master does not fail. Tried this:\nmake ~/bla\nexport GOPATH=~/bla\ngo get github.com/fabiolb/fabio\nfind -type d ~/bla/src\n. See #436 for why fabio won't switch to dep.. Can you provide a PR?. Is this using TLS 1.2?. You can try the handshake with openssl s_client -connect geodb.myserver.nl:5432 and see whether that works. If you are on a Mac you might need to install a newer version with homebrew and use /usr/local/opt/openssl/bin/openssl since only there you have the -tls1_2 option.. You don\u2019t need to set the registry.consul.urlprefix option. That is only necessary if the tags do not start with \u2018urlprefix-\u2018\n. Other than that this looks fine. Probably a good idea to print out the bad line as well. I\u2019ll make a change. . Yeah. I don\u2019t know. I\u2019ll update the error reporting. If you are comfortable building fabio from source you can do that as well. \nhttps://github.com/fabiolb/fabio/blob/master/route/parse_new.go#L85\nThen run \u2018make\u2019 or \u2018go build\u2019 to build fabio\n. Try urlprefix-:2302 proto=tcp as tag when you register the service. Otherwise this is an HTTP service.. This is still starting the HTTP listener instead of the TCP. \n2018/04/20 10:57:20 [INFO] HTTP proxy listening on :2302\nThis is most likely an issue with semicolon in the proxy.addr parameter. Unfortunate choice of separators :(\nTry this:\nfabio -proxy.addr ':2302;proto=tcp'\nand you should see\n2018/04/20 20:30:52 [INFO] TCP proxy listening on :2302\n. @satishviswanathan Thanks for being patient and persistent!. Feel free to send a PR for the docs. Does that mean this fixes #347 and #486?. Yes.. That should work. Let me know if it doesn\u2019t.\n\u2014\nFrank Schr\u00f6der\n\nOn 16. May 2018, at 09:39, Robert Goldsmith notifications@github.com wrote:\nah, great :D I guess it's url-prefix-*.example.com/\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Fixed by #497 . Thank you!. Fabio is a proxy and not a router which means that for every incoming request there is a corresponding outgoing request and the bytes flowing back and forth are duplicated. \n\nFabio's HTTP client makes the backend request which is usually slightly different than what the client has sent. For example, fabio adds headers which indicate that the request is coming from a proxy but the Go HTTP client also normalizes the header names. content-type becomes Content-Type for example. HTTP header names are case-insensitive but some backend servers require the header name to be in a certain format. This is very rare but can happen. Then you need to fix the backend service. For all practical purposes, the HTTP connection is duplicated more or less \"as-is\".\nThe TCP proxy behaves the same way but since fabio is not interpreting the content but just copying bytes you end up with a direct connection between the client and the backend server and fabio is copying the bytes between the incoming and outgoing connection. So potentially, it can still look at the data.\nThe TCP+SNI proxy prevents that since it establishes a full end-to-end encrypted TCP connection between the client and the server. Fabio only parses the header of the TLS connection setup (the ClientHello) and reads the SNI server name which is sent unencrypted. It then establishes a TCP connection to the backend service and replays the ClientHello package. From that moment on the client and the backend server have a full end-to-end encrypted TLS connection even though fabio moves the bytes between two underlying TCP connections.. hmm, why doesn't codeship pick this one up?. When I change the versions in Makefile\n```patch\ndiff --git a/Makefile b/Makefile\nindex 6d2ff11..3a9ca94 100644\n--- a/Makefile\n+++ b/Makefile\n@@ -27,8 +27,8 @@ GOVENDOR = $(shell which govendor)\n VENDORFMT = $(shell which vendorfmt)\n# pin versions for CI builds\n-CI_CONSUL_VERSION=1.0.6\n-CI_VAULT_VERSION=0.9.6\n+CI_CONSUL_VERSION=1.1.0\n+CI_VAULT_VERSION=0.10.1\n CI_GO_VERSION=1.10.2\n# all is the default target\n```\nand run make docker-test I still get this:\n```\n--- FAIL: TestConsulSource (12.17s)\n    source_test.go:240: Starting consul: Consul v1.1.0\n    source_test.go:261: Timeout waiting for consul server after 12.0 seconds\n=== RUN   TestVaultSource\n--- FAIL: TestVaultSource (0.31s)\n    source_test.go:305: Starting vault: \"Vault v0.10.1 ('756fdc4587350daf1c65b93647b2cc31a6f119cd')\\n\"\n    source_test.go:429: logical.Write failed: Error making API request.\n    URL: PUT http://127.0.0.1:58421/v1/secret/data/fabio/cert/localhost\n    Code: 400. Errors:\n\n    * no data provided\n\n```\n. Thank you!. Feel free to send a PR. This shouldn't be hard to fix.. You can use the tcp+sni proxy mode to have full end-to-end encryption. \nYes, fabio is still maintained. However, I am currently relocating my family to another country which uses up a lot of my free time. \n\u2014\nFrank Schr\u00f6der\n\nOn 31. May 2018, at 16:37, BogetC notifications@github.com wrote:\nHi !\nI need to have 100% secure comunications.\nIs it possible to forward request to backends with HTTPS ?\nand also, is fabio still maintain\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Outbound PROXY protocol support might help .... This is a side-effect of http header normalization within the Go http library. HTTP header names are case-insensitive.. I can't reproduce this. When I add this test to the 1.5.6 codebase it works:\n\n``patch\nSun Jun 10 20:25 frank@fancypants ((v1.5.6) *) $ git diff\ndiff --git a/route/table_test.go b/route/table_test.go\nindex eb0fdea..7d2da44 100644\n--- a/route/table_test.go\n+++ b/route/table_test.go\n@@ -495,6 +495,7 @@ func TestTableLookup(t *testing.T) {\n        route add svc z.abc.com/foo/ http://foo.com:3100\n        route add svc *.abc.com/ http://foo.com:4000\n        route add svc *.abc.com/foo/ http://foo.com:5000\n+       route add svc *.def.abc.com/ http://foo.com:6000\n        route add svc xyz.com:80/ https://xyz.com\n@@ -530,6 +531,7 @@ func TestTableLookup(t *testing.T) {\n            // glob match the host\n            {&http.Request{Host: \"x.abc.com\", URL: mustParse(\"/\")}, \"http://foo.com:4000\"},\n\n\n{&http.Request{Host: \"x.def.abc.com\", URL: mustParse(\"/\")}, \"http://foo.com:6000\"},\n                {&http.Request{Host: \"y.abc.com\", URL: mustParse(\"/abc\")}, \"http://foo.com:4000\"},\n                {&http.Request{Host: \"x.abc.com\", URL: mustParse(\"/foo/\")}, \"http://foo.com:5000\"},\n                {&http.Request{Host: \"y.abc.com\", URL: mustParse(\"/foo/\")}, \"http://foo.com:5000\"},\n```. Same for 1.5.9 and when I let the test run in a loop.\n\ncd route ; go test -c ; while true ; do route.test -test.run TableLookup ; done. Hmm, I can reproduce this with the test server.. ```\nterm 1\nconsul agent -dev\nterm 2\ncd $GOPATH/src/github.com/fabiolb/fabio/demo/server\ngo build\n./server -prefix '*.edge.foo.com/gizmo' -addr 127.0.0.1:5000\nterm 3\ncd $GOPATH/src/github.com/fabiolb/fabio/demo/server\n./server -prefix '*.foo.com/gizmo' -addr 127.0.0.1:9999\nterm 4\ncd $GOPATH/src/github.com/fabiolb/fabio\ngo build\n./fabio\nterm 5\ncurl -H 'Host: api.edge.foo.com' http://127.0.0.1:9999/gizmo\n```\nThe demo server responds with 404 not found which is a bug in the demo server but the request gets routed to the wrong backend.. Looks like a bug.. I think I know what is going on. This line doesn't do what I think it does:\nhttps://github.com/fabiolb/fabio/blob/master/route/table.go#L306\nThe problem is not that fabio does not respect the longer host but that edge < foo. If you replace edge with zzz it \"works\".\nThe issue is that domain names have the most significant part at the front whereas the request URIs have the most significant part at the end. [foo.com edge.foo.com] needs to be sorted as [com.foo com.foo.edge] for this to work.\n. That's also the reason the test case works since def > abc. Fabio should always go from most specific to least specific when picking a match. However, it also allows a glob pattern anywhere in the host name. *.a.com and *.b.a.com should be sorted as *.b.a.com, *.a.com. However, I am not sure what the order should be for *.a.com and a.*.com. I am OK with leaving this undefined for now. The current implementation - which reverses the strings before sorting - would sort it as *.a.com, a.*.com. ForHost: a.a.com both matches seem equally good. (https://play.golang.org/p/uIMR2rpHOlw). Thank you!\nYou can submit a PR since this looks like a simple change. All the code is in https://github.com/fabiolb/fabio/blob/master/admin/ui/route.go\nHappy to merge it.. Closed by #587 . I think what you are looking for is https://fabiolb.net/ref/registry.consul.service.status/. Thanks!. @netik Accessing consul through an LB is generally not a good idea.. No. This should be handled by your supervisor which does the log file redirection. \n\u2014\nFrank Schr\u00f6der\n\nOn 28. Jun 2018, at 09:46, Matthias Rosenauer notifications@github.com wrote:\nHi guys,\nis there a possibility to write the console output from fabio to a log file?\nThe only way I found so far was logging the access to stdout, but not a file.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I'm not a vault expert. @pschultz do you have an idea?. Would it make sense to add this to the documentation? https://fabiolb.net/feature/vault/. ~~Could be this line: https://github.com/fabiolb/fabio/pull/423/files#diff-7c73f6a0cf2ff2671c80a43d0aad92a3R46~~\n\nthis is the sni proxy. sorry. So this is broken for TCP proxies which do not use the PROXY protocol and where the client is waiting for an initial handshake from the server which never comes b/c fabio does not forward the connection (i.e. MySQL)? And this started to become an issue when we added access control since we're looking at the RemoteAddr which is a blocking call in the ProxyListener? HTTP is not affected since this was fixed in the stdlib, AFAICT.\nMaking the PROXY protocol configurable is the better solution, IMO. (I should have done this when I added that.) People know when they are using it, one would assume. The question is what to do with the default. We can have on and off but both settings have drawbacks. Switching to off by default may break existing setups. Leaving it on by default means to keep it broken for users. \nWho is affected if we switch the default to off? Users on AWS with access control, for example. If we disable PROXY and they upgrade then the protocol breaks since the server is getting the PROXY header. Or it may silently work since the server can handle the PROXY protocol. \nThe 1.5.8 behavior was that TCP just worked and I'd prefer if we can get back to that state.\nMaybe we also add an auto mode as the new default, where we establish the connection, buffer the first 100 bytes from the client and check for the PROXY header in the TCP proxy directly to handle access control (if there is any). \nHowever, keeping it simple also has advantages. If we decided to switch to off by default we should mitigate the impact:\n\nBig warning sign in the CHANGELOG and on top of the README\nNotice in the Release Notes and the Twitter release notification\nCan we detect the PROXY header on a TCP connection where PROXY is disabled and issue a warning in the logs?\n\n. @pschultz I've invited you to be a collaborator so that we can work on the same branches.. Please note that this change disabled PROXY protocol by default and you have to enable it if you need it. If you feel this is a grave mistake, the please let us know. (I'll mull over this a bit more before creating a new release).. @pschultz I've enabled your account to be a collaborator with write permissions. That should be sufficient. If you want to use a deploy key instead then it has to be unique for this repo since you cannot use the same key for multiple repos. Trying to add this key returns \"key already in use\".. I'll try to release 1.5.11 tonight CET time.. Thanks @galen0624 for the digging and the subsequent fix. Time to pick up the slack on fabio again. I need to back out the FastCGI change which currently breaks the build and then we can push a new release.. LGTM. \nCould you also please add an entry to the website docs? https://github.com/fabiolb/fabio/tree/master/docs/content/ref\nThx. @samm-git thx for your patience. Thanks for this! And sorry for the long delay. I was moving countries during that time and am slowly catching my breath again... . Yeah, I somewhat suspected this. I've left some comments on the PR and I think that you can cache the compiled globs. See glob cache code in the PR.. Closed by #550 . @Rachitmehrotra you can configure static routes directly in fabio.properties or point to a file with routes:\nhttps://fabiolb.net/ref/registry.backend/\nhttps://fabiolb.net/ref/registry.file.path/\nhttps://fabiolb.net/ref/registry.static.routes/. That's fine. Lets get this working first so that this regression is fixed. That's more important.. I've merged it and changed DisableGlobMatching to GlobMatchingDisabled. Didn't want you to do another roundtrip. \nThanks for your patience!. You could probably use the https://fabiolb.net/ref/registry.consul.tagprefix/ feature for this and register SvcC and SvcD with a prefix other than urlprefix-. This assumes that the services are sharing the same Consul instance.. This is the default behavior of the Go http package since HTTP headers are case-insensitive. Your mobile app needs to treat the header names case-insensitive.. Thank you and sorry that it took so long!. This looks OK. If you rebase this then we can merge this as well. I assume you're using that in production as well?. I'll keep this open as the issue which is the motivation for the PR.. Hi @galen0624, thanks for the patch! After looking at it I thought that this was an excellent opportunity to finally refactor the service monitor code for Consul and also add some tests for the route generation code. I hope that is OK with you?\nI've also taken a slightly different approach for the concurrent fetching by limiting the number of concurrent go routines running. \nIt would be awesome if you could test #564 and see whether it has the desired effect.\nOne thing I've noticed is that the current code also looks up the datacenter for every service. Moving this out of the code should already save some cycles but generally that is a cheap call.\nI am curious on why you a) created a custom http client for the consul client and b) why you limited the number of idle connections. Could you elaborate on this?. I'll close this in the meantime.. #564 supersedes this.. Hmm, should this then be in the common code? Does it hurt?. No need to apologize. :). 100 seems a lot. I\u2019d set this to a multiple of the number of cores and start with 8, 16,... to find the smallest number. Remember that all Fabios in your cluster will hit your consul cluster at the same time. . Maybe even start with 2,4 to see what is acceptable. Why do you have so manny changes? Flapping services?. I was thinking the same thing. Either wait for changes or poll. I think this would go nice with the refactoring. I could add @galen0624 as contributor so that we can work on the same branch instead of merging small bits back and forth.. Just did. @galen0624 do you have a GPG key to sign your commits? I should update the contrib guidelines with that.. If not, here is a good guide on how to create a good set of keys: https://github.com/drduh/YubiKey-Guide. #564 is on the issue-558 branch. If you keep it safe then it is good enough for me.. @galen0624 I've left some comments on https://github.com/galen0624/fabio/commit/474d896768c761d68ce60142fafaea6703eb9616. \nAny objection on merging #564?. Just merged it. Could you also add documentation for the new option in docs/ref, please?. Just did. Thx for the reminder and the patience ... :). Not at this point. Good catch though. Thx.. Thx!. Discussion is on #559 . Sounds good to me. This would also fit well into the refactor of the service monitor in #564. Do you feel like submitting a PR based on that code?. LGTM. Thank you and yes to htpasswd.. @andyroyle  can you rebase this, please? Then I'll merge it.. Thanks Paul!. Thanks a lot @andyroyle for this. Are you running this in prod already?. Thx Paul.. Is this the same as https://github.com/fabiolb/fabio/pull/436?. Hi @IxDay , If you are referring to https://fabiolb.net/cfg/#routing-rules then there is no such rule. Routing is solely based on hostname and path. The service name is only used for filtering. Can you point to where you've read that?. Is it possible to have multiple authors on a single commit? Then you could attribute @pschultz as well. More curious than asking.. @sean- would disabling PROXY by default affect you?. You'll learn something new every day. Thx for looking.. Lets do this. Thank you all!. @leprechau shoot, we forgot something. Can you provide another PR with an updated fabio.properties and documentation? Feel free to merge right away. I'll work on the CHANGELOG.. Also, fabio users: if you find this change and think disabling PROXY by default was a grave mistake please let us know. Thx. @leprechau does this disable proxy for tcp only or also for http?. I'm having second thoughts on disabling by default. Will sleep on it a night. :). This feature is in master and not the latest 1.5.10 release. Are you using a master build?. No worries. I've merged this yesterday and the wrong version in the docs slipped through. I'll try to push a 1.5.11 release in the coming days. Just updated the documentation.. Resolved this and I'll merge this for 1.5.11. Hope I did this correctly. @pschultz could you have a quick look, please? . @andyroyle can you maybe help here?. Thank you!. Try this one:\nsh\ngpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 9494081A4C1007E3EBCA396B2F9F9BA22C84FCEE. I've been experimenting with a different gpg key setup.. Hi @sielaq, is this a Fabio or Consul bug?. I'm fine. Thanks for asking. It has been a while indeed :). My time to work on this project is quite limited. Maybe someone from the community can pick this up?\n\u2014\nFrank Schr\u00f6der\n\nOn 10. Mar 2019, at 07:28, Wojciech Sielski notifications@github.com wrote:\nps: My suspicious is: that Consul remove all health checks even if only one service was removed, so Fabio loose all routes.\n(The reason, why in my case, was so hard to understand what was going on, was that Registrator constantly was trying to heal the situation...)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Can someone update the readme, please?. Can you explain better in the comment why this is necessary and which problem it solves? Also, s/originalDirector/d/\n. output pattern is got X want Y\n. got X want Y\n. s/mockServer/server/ to be consistent with your other test. \n. pls inline this unless you call the function multiple times.\n. Either single line in both tests or multi-line in both tests\n. typo: present\n. The comment does not match the new behavior using text/template\n. s/Fqdn/FQDN/\n. You should move the whole prefix init code to a helper function\n. This should be log.Fatalf(\"[FATAL] prefix template failed: %s\", err)\n. This will set the hostname to-fon Solaris\n. Pls drop\n. s/AcceptableStates/States/\n. Pls replace backticks with single quotes\n. Update comment\n. Don't use double quotes unless you want to send them. Also, if this is the default then you need to set this inconfig/default.go. Same formetrics.circonus.apiurl. s/cgmProvider/cgmRegistry/\n. Isn't this the value frommetrics.circonus.apiapp? If not, then either make it configurable or inline it below instead of usingfmt.Sprintf`\n\nUpdate: nvm, missed that this is the default name. I'd still prefer this to come from the defaults or fabio should not start if this is a config error. \n. Don't you need to return here or can you start the metrics even though you have an error? This would be different than for the other metrics libs.\n. Pls drop the interface comments. Just leave the comments that explain that circonus does not support this.\n. What exactly is this testing? How do you know that this test has passed? \n. s/circonusBackend/circonusRegistry/\n. Hmm, if you set a default in config/default.go then this needs to be reflected here. Why did you remove it?\nshould be metrics.circonus.apiapp = fabio \n. Pls make this an anonymous struct and drop the prefixData type , e.g.\nb := new(bytes.Buffer)\nvar data struct { Hostname, Exec string}{ host, exe }\nif err := t.Execute(b, &data); err != nil { ... }\nreturn b.String(), nil\n. pls add a proper comment\n. Can you make the comment similar in wording to the one for metrics.names ?\n. As discussed in the thread default should still work to avoid breaking existing behavior.\n. Would be nice to test this in TestParsePrefix to avoid regressions. Could you please add that and then I'll merge it.\n. This is enough since this is also in line with the option parser in config\ngo\nt.TLSSkipVerify := r.Opts[\"skipverify\"] == \"true\". Pls add a comment.. \"TLSSkipVerify disables certificate validation for upstream TLS connections.\"\nCould you also move the variable below the StripPath variable, please?. Maybe move this into a local newTransport := func(tlscfg *tls.Config) http.Transport func to avoid the duplication.. this should be either http or https without ://. These are redundant. Pls remove.. You can store a cert and key in a single file. Make keyfile optional.. same here. keyfile optional. CheckScheme should be https. one test per arg. http doesn't look right. I don't think this is how this works. Probably more like this:\n```go\ncertFile, keyFile := s.Cfg.UI.CertFile, s.Cfg.UI.KeyFile\nif certFile == \"\" {\n    return http.ListenAndServe(addr, nil)\n}\nif keyFile == \"\" {\n    keyFile = certFile\n}\nreturn http.ListenAndServe(addr, certFile, keyFile)\n``. I'm thinking that you could default to\"\" == \"http\". Would save you anelse. What do you think?. I see two spacesdefault__is. Also, default should beui.certfile = `. Same below.\n```\nui.certfile contains the path to the TLS certificate for the UI/API endpoint\nwhich enables serving the UI and API over HTTPS.\n\nIf the file containing the certificate also contains the private key then the\nui.keyfile option can be omitted.\n\nThe default is\n\nui.certfile =\n.\nui.keyfile contains the path to the private key of the TLS certificate for the\nUI/API endpoint.\n\nIf the file containing the certificate also contains the private key then the\nui.keyfile option can be omitted.\n\nThe default is\n\nui.keyfile =\n``. Fix here if you choosecheckScheme == \"\" -> \"http\". OK, I've just written that from memory from the time I've coded the cert stores. I'll have another look.. No it won't. Question is whether this should then be an error and fabio refuse to start since this config doesn't make sense.. You can omit that since this is the default. pls test withtruesincefalseis the default. This should beCheckTLSSkipVerifyand pls move it to the bottom belowCheckScheme. pls change toregistry.consul.register.checkTLSSkipVerifysince I've - unfortunately - used camelCase with the othercheckparameters as well. The comment should beservice check TLS verifcation. pls remove this sincefalseis the default. The field itself is defined inconfig.Configand not here. The value that you are setting indefaultConfigis automatically set by the compiler and therefore redundant.falseis the default value for anyboolvariable. . You add afunc UUID()to the proxy which you can mock. . typo. I thinkRequestIDis enough since they need to be unique for this to make sense..proxy.header.requestid configures the header for the adding a unique request id.. Can you add this to theaddHeaders()function and move your test to theTestAddHeaders()` fn as well, please? This isn't complex enough for a separate fn/test IMO. \n```go\nif p.Config.RequestID != \"\" {\n    id := p.UUID\n    if id == nil {\n        id = uuid.NewUUID\n    }\n    r.Header.Set(p.Config.RequestID, id())\n}. I see. Then just inline the couple lines into the HTTP proxy and use the integration test to test it.. This is redundant. Just use what I wrote initially\ngo\n_, t.UseHost = r.Opts[\"usehost\"]. UseHost determines whether the the origin or the target hostname\nis used for the upstream request. Can you drop the comment, too please? Don't want to be overly pick but it really is redundant.. This looks racy and should probably be inside the lock.. s/response/resp/. pls rewrite as switch statement. I try to avoid if/else cascades.. s/response/resp/. pls drop the 1* since it is redundant. . pls add a comment and explain the unit. Maybe a shorter name, e.g. renewTTL. pls use the Go doc standard here:\n```\n// token is the actual token\ntoken string\n// expireTime is ...\nexpireTime time.Time\n...\n``. The logging is thedefault` case, right?\npls change the log msg to Token is not renewable and expires in %s from now at %s. I don't insist but I'd prefer since it is redundant :). Right, since this is a local var but then this doesn't make sense. The defer function should then read and you can drop firstCall.\ngo\ndefer func() {\n    c.SetToken(s.auth.token)\n    if s.auth.token != \"\" {\n        s.checkRenewal(c)\n    }\n    s.mu.Unlock()\n}. I also suggest to remove the SetToken call from the defer method and put it where necessary. There is too much magic going on here which is hard to follow.. I've written a tool https://github.com/magiconair/vendorfmt to reformat the JSON to a more merge-friendly single-line format. If you run make vendorfmt it should format it.. This is still using the old syntax. gofmt?. old syntax here as well. The reason I've passed in *http.Request was that I needed both host and the TLS state. If you pass in the host then you might as well pass in the TLS state, e.g.\n```go\nfunc normalizeHost(host string, tls bool) string {\n    host = strings.ToLower(host)\n    if !tls && strings.HasSuffix(host, \":80\") {\n        return host[:len(host)-len(\":80\")]\n    }\n    if tls && strings.HasSuffix(host, \":443\") {\n        return host[:len(host)-len(\":443\")]\n    }\n    return host\n}\n...\nnormalizeHost(req.Host, req.TLS != nil)\n.go\n// RedirectCode is the HTTP status code used for redirects.\n// When set to a value > 0 the client is redirected to the target url.\n```. Can we log the error or catch this somewhere sooner and log it there?. Ah, I forgot that we need to be able to specify the redirect target. How about this?\nredirect=302,http://www.bar.com/. old syntax. This would then also become more obvious by looking for redirect=xxx. If you divide something by a float64 then the result can never be an int since Go doesn't auto-convert between numeric types. const values are the only exception.. No worries. You live and learn :). That could be added the route parser but then it would need to treat opts not as an opaque k/v string. I can have a look at this if and when I write a better parser.. You don't need this since you can store a string in an atomic.Value directly.. I usually add a comment after the value to indicate the type since it cannot be changed once it is set, .e.g.\ngo\nvar store atomic.Value // string. This then becomes \ngo\nreturn store.Load().(string). An atomic.Value is already synchronized. Therefore, you don't need a mutex here.. noroute.html is a magic value and would need to be configurable. . I would probably create a separate package for this since neither route nor proxy is a good place to keep this.. I'll fix that in a subsequent commit.. I think I'd prefer if this function would only determine the size of the buffer and not allocate it. Also, keep it in the tls_clienthello.go since this is where the parsing logic for the TLS ClientHello header is. Also, I'd keep data instead of tlsData since there is no difference.. Please add a comment where the 5: comes from (magic number).. I really like these test cases. Can you move them to the tls_clienthello_test.go since they test the parsing.\nWhen you refactor the method to just return the size of the buffer you can test for that as well. My suggestion is:\n```go\ntests := []struct {\n    name string\n    data []byte\n    fail bool\n    len int\n}{\n    {\n        name: \"bad handshake length\",\n        data: ...,\n        fail: true,\n    },\n    ...\n}\nfor _, tt := range tests {\n    t.Run(tt.name, func(t *testing.T) {\n        n, err := clientHelloBufferSize(tt.data)\n        if tt.fail && err == nil {\n            t.Fatal(\"should fail\")\n        }\n        if got, want := n, tt.len; !tt.fail && got != want {\n            t.Fatalf(\"got buffer size %d want %d\", got, want)\n        }\n    }\n}\n```\nAlso I. You can then probably roll that test case into the previous table driven test.. Can you check whether you can also write a table driven test like the one I've outlined above?. I think a better approach would be to just extend the register function since you need to keep the state of what is registered in the backend anyway. \ngo\ntype Backend interface {\n    Register(name ...string) error\n    DeregisterAll() error\n    ...\n}. Then here you first unregister names that no longer exist and register new names.. This function then deregisters all currently registered services.. Move the parsing code into the route/parse_new.go since there you already have all the parse helpers. Return a list of alias names to register, e.g.\ngo\nfunc ParseAliases(config string) (names []string, error) {...}. Then here you call\ngo\naliases, err := route.ParseAliases(config)\nregistry.Default.Register(aliases). Since DeregisterAll() exists I wouldn't use a magic value \"\" to deregister all services. Every now and then I am tempted to do that but then opt for simplicity. Deregister(service) deregisters a service if it is currently registered, otherwise it does nothing. DeregisterAll() deregisters all currently registered services.. pls drop the text in (...) since that is an implementation detail.. I prefer less indents\ngo\nfor name, dereg := range b.dereg {\n    if dereg == nil {\n        continue\n    }\n    ...\n}. less indents\ngo\nfor _, name := range services {\n    if b.dereg[name] == nil {\n        continue\n    }\n    ...\n}. Registered fabio as %q. Pls add a comment on what this function does. . Why is that important here? I'd just parse the aliases and let the backend decide what to do with them.. I don't think we should log that here. . you don't need this.. I think you don't need this and you should just add another option here:\nhttps://github.com/fabiolb/fabio/blob/master/proxy/http_proxy.go#L149-L168. strings.TrimPrefix/Suffix ?. You only need the host from the target and I usually just pass in the entire config object.\ngo\nfunc NewFCGIProxy(cfg *config.Config, upstream string) *Proxy { ... }. I'd actually like to see this as a separate commit with the commit sha of the fork in the commit msg, e.g.\nForking <sha> of https://github.com/mholt/caddy/...\nPls update the NOTICE file as well.\nI'm wondering whether we cannot just vendor this file in. Would require some tweaking but then it is clear where this is coming from.. go\ncontentLength := r.ContentLength\nif contentLength == 0 {\n    contentLength, _ := strconv.ParseInt(r.Header.Get(\"Content-Length\"), 10, 64)\n}. I'd prefer if you'd do env := map[string]string {...} below and drop this line. Pls write a unit test for this which populates all fields. Add separate functions and unit tests for transformation functions like the ip address parsing. buildEnv should not do any http error handling itself. It should report the error and let the caller handle it.. go\nreturn nil, fmt.Errorf(\"bad address: %s\", r.RemoteAddr)\nHowever, if this fails then your parser is broken. So you should factor this out and write some tests for that.. what does this do?. Pls add an IPv6 example as well. Pls add an ipv6 example and explain how the source ip is determined. Also add a comment that /32 and /128 is added automatically.. I'm pretty sure that someone will ask for a different status code here but we can leave it for now.. This should also log who was denied access.. same here. yeah, if someone asks for this.. I think if the inbound connection uses the PROXY protocol then this is mapped into the RemoteAddr field of the underlying connection. This should be the case for both TCP and HTTP since this is on the connection itself.\nhttps://github.com/fabiolb/fabio/blob/master/vendor/github.com/armon/go-proxyproto/protocol.go#L96-L113\nI'll update the docs before merging.. I'd prefer not to nest the ifs.\ngo\nif xip == host {\n    continue\n}\nif ip = net.ParseIP(xip); ip == nil {\n    log.Printf(\"[WARN] failed to parse xff address %s\", xip)\n    continue\n}\nif t.denyByIP(ip) {\n    return true\n}. don't you need to continue here?. Would you need to remove the other X-Forwarded-* headers as well?. Maybe backtick X-Fowarded-For and true and false? I need to work on the CSS a bit more though.. Is there a reason the order changed?. This comment doesn't match the result since the behavior changed. Can you double check?. I'd prefer if you compile the glob matcher in the test since this keeps the changeset smaller, e.g.\ngo\nfor _, tt := range tests {\n    t.Run(tt.uri, func(t *testing.T) {\n        tt.route.Matcher = glob.MustCompile(tt.route.path)\n        ...\n    })\n}\n    . I think Glob is a better name than Matcher.. Please name this glob and also remove the github.com/ryanuber/go-glob library in a separate commit.. What happens if this is an invalid pattern? Does it panic? You probably need to catch the error and return it.. Ah, I thought that because the XFF address and the remote address are allowed the request should be allowed. But 1.2.3.4 isn't whitelisted. This wasn't obvious to me. I'll clean up the comments after the merge.. Good question. I'll check.. Yes, you can have a route for *.example.com/foo. I wrote a small benchmark to verify performance. gobwas is fast but only when the expression is pre-compiled. It is only 1.4 ms but this sits in the hot-path. However, there is no easy way to refactor this since Table is just a map[string]Routes. Might be a good time to finally change this to a struct. I'll have a look.\n$ go test -bench .\ngoos: darwin\ngoarch: amd64\npkg: globbench\nBenchmarkGlob/ryanuber-8            20000000            91.4 ns/op\nBenchmarkGlob/gobwas-8               1000000          1385 ns/op\nBenchmarkGlob/gobwas-precompile-8           200000000            7.29 ns/op\nPASS\nok      globbench   5.537s\n```go\npackage main\nimport \"testing\"\nimport ryanuber \"github.com/ryanuber/go-glob\"\nimport gobwas \"github.com/gobwas/glob\"\nvar n int\nfunc BenchmarkGlob(b testing.B) {\n    b.Run(\"ryanuber\", func(b testing.B) {\n        for i := 0; i < b.N; i++ {\n            if ryanuber.Glob(\".example.com\", \"foo.example.com\") {\n                n++\n            }\n        }\n    })\n    b.Run(\"gobwas\", func(b testing.B) {\n        for i := 0; i < b.N; i++ {\n            m := gobwas.MustCompile(\".example.com\")\n            if m.Match(\"foo.example.com\") {\n                n++\n            }\n        }\n    })\n    b.Run(\"gobwas-precompile\", func(b testing.B) {\n        m := gobwas.MustCompile(\"*.example.com\")\n        for i := 0; i < b.N; i++ {\n            if m.Match(\"foo.example.com\") {\n                n++\n            }\n        }\n    })\n    b.Log(n)\n}\n```\n. This isn't really a glob matching function since glob matching is already enabled. This only finds https targets. . Agreed. See #477 . Can you make the Interval configurable? See https://github.com/fabiolb/fabio/blob/master/config/load.go#L161 for an example.\nPlease also update the website documentation at\nhttps://github.com/fabiolb/fabio/tree/master/docs/content/ref. Can you merge the two readXXX functions into one like this\ngo\nfunc readFile(path string, mtime time.Time) (string, error) {...}\n. Since true is the default case but not the zero value of bool I'd prefer DisableGlobMatching since then most code and tests will not have to change. . Isn't this the same as proxy.matcher = prefix ?. I'd prefer if you factor this out into two separate functions. Also, I think you can cache the compiled globs if you limit the size of the cache and evict older entries. The following code should do the trick. Maybe you can add another option to configure the size of the glob cache. Set the default to 1000.\n```go\npackage route\nimport (\n    \"sync\"\n\"github.com/gobwas/glob\"\n\n)\n// GlobCache implements an LRU cache for compiled glob patterns.\ntype GlobCache struct {\n    mu sync.RWMutex\n// m maps patterns to compiled glob matchers.\nm map[string]glob.Glob\n\n// l contains the added patterns and serves as an LRU cache.\n// l has a fixed size and is initialized in the constructor.\nl []string\n\n// h is the first element in l.\nh int\n\n// n is the number of elements in l.\nn int\n\n}\nfunc NewGlobCache(size int) *GlobCache {\n    return &GlobCache{\n        m: make(map[string]glob.Glob, size),\n        l: make([]string, size),\n    }\n}\n// Get returns the compiled glob pattern if it compiled without\n// error. Otherwise, the function returns nil. If the pattern\n// is not in the cache it will be added.\nfunc (c *GlobCache) Get(pattern string) glob.Glob {\n    // fast path with read lock\n    c.mu.RLock()\n    g := c.m[pattern]\n    c.mu.RUnlock()\n    if g != nil {\n        return g\n    }\n// slow path with write lock\nc.mu.Lock()\ndefer c.mu.Unlock()\n\n// check again to handle race condition\ng = c.m[pattern]\nif g != nil {\n    return g\n}\n\n// try to compile pattern\n// todo(fs): can this fail and should we return err?\ng, err := glob.Compile(pattern)\nif err != nil {\n    return nil\n}\n\n// if the LRU buffer is not full just append\n// the element to the buffer.\nif c.n < len(c.l) {\n    c.m[pattern] = g\n    c.l[c.n] = pattern\n    c.n++\n    return g\n}\n\n// otherwise, remove the oldest element and move\n// the head. Note that once the buffer is full\n// (c.n == len(c.l)) it will never become smaller\n// again.\ndelete(c.m, c.l[c.h])\nc.m[pattern] = g\nc.l[c.h] = pattern\nc.h = (c.h + 1) % c.n\nreturn g\n\n}\n```\n```go\npackage route\nimport (\n    \"reflect\"\n    \"sort\"\n    \"testing\"\n)\nfunc TestGlobCache(t *testing.T) {\n    c := NewGlobCache(3)\nkeys := func() []string {\n    var kk []string\n    for k := range c.m {\n        kk = append(kk, k)\n    }\n    sort.Strings(kk)\n    return kk\n}\n\nc.Get(\"a\")\nif got, want := len(c.m), 1; got != want {\n    t.Fatalf(\"got len %d want %d\", got, want)\n}\nif got, want := keys(), []string{\"a\"}; !reflect.DeepEqual(got, want) {\n    t.Fatalf(\"got %v want %v\", got, want)\n}\nif got, want := c.l, []string{\"a\", \"\", \"\"}; !reflect.DeepEqual(got, want) {\n    t.Fatalf(\"got %v want %v\", got, want)\n}\n\nc.Get(\"b\")\nif got, want := len(c.m), 2; got != want {\n    t.Fatalf(\"got len %d want %d\", got, want)\n}\nif got, want := keys(), []string{\"a\", \"b\"}; !reflect.DeepEqual(got, want) {\n    t.Fatalf(\"got %v want %v\", got, want)\n}\nif got, want := c.l, []string{\"a\", \"b\", \"\"}; !reflect.DeepEqual(got, want) {\n    t.Fatalf(\"got %v want %v\", got, want)\n}\n\nc.Get(\"c\")\nif got, want := len(c.m), 3; got != want {\n    t.Fatalf(\"got len %d want %d\", got, want)\n}\nif got, want := keys(), []string{\"a\", \"b\", \"c\"}; !reflect.DeepEqual(got, want) {\n    t.Fatalf(\"got %v want %v\", got, want)\n}\nif got, want := c.l, []string{\"a\", \"b\", \"c\"}; !reflect.DeepEqual(got, want) {\n    t.Fatalf(\"got %v want %v\", got, want)\n}\n\nc.Get(\"d\")\nif got, want := len(c.m), 3; got != want {\n    t.Fatalf(\"got len %d want %d\", got, want)\n}\nif got, want := keys(), []string{\"b\", \"c\", \"d\"}; !reflect.DeepEqual(got, want) {\n    t.Fatalf(\"got %v want %v\", got, want)\n}\nif got, want := c.l, []string{\"d\", \"b\", \"c\"}; !reflect.DeepEqual(got, want) {\n    t.Fatalf(\"got %v want %v\", got, want)\n}\n\n}\n. I understand that. I'd appreciate it if you could embed this code to the glob path after splitting the function and run some tests.. Makes sense. Since this is looping over the keys of t you could do this before the table is switched. However, my guess is that even with 1500 services your external hostnames are a bit more stable and you should have fewer. . My gut feel says that the LRU cache is probably easier to handle here.. Can't you just use a different Lookup function?. Why not just pass a `bool` and default to `false` or also accept a `nil` config to simplify the tests?. Maybe `nocase` . With respect to the case-insensitive prefix matching I think `iprefix` is a better name..\niprefix: case-insensitive prefix matching\n.go\n// todo(fs): if this turns out to be a performance issue we should cache\n// todo(fs): strings.ToLower(r.Path) in r.PathLower\nreturn strings.HasPrefix(strings.ToLower(uri), strings.ToLower(r.Path))\n```\n. s/Disables/disables/. What's the purpose of the var?. If you add this var to all tests you can also add some constants, e.g. \n`go\nconst (\n    // helper constants for the Lookup function\n    globEnabled = false\n    globDisabled = true\n). That's the default so you can remove it.. The `nil` check is redundant.. same here. Do you want to return `conn` even if there was an error?. `existent` :). same here.... you can use string literals here, e.g. Basic realm=\"testrealm\" ``. This would need to be 1.5.11. ",
    "jefferai": "Sounds good. Just remember, when you get around to it, that SNI is a must as it's really the only way to route when doing TCP routing (since mapping ports is just awful)!\n. @rvm2015 I assume you mean, \"within Fabio\"? Other services are capable of doing transparent TCP proxying,and have for a long time.\n. I thought you weren't supposed to ever close bug #1  :-D\nGreat job!. Vault guy here! Got pointed this way  :-)\nThis would be super cool -- you are probably aware of this, but there is a function that lets you get a certificate based on a client-supplied host name (GetCertificate at https://golang.org/pkg/crypto/tls/#Config) so you could definitely fetch-on-demand.\nLooked through the other ticket -- there's definitely room for both LE and Vault, as they really tackle different use-cases. LE is designed to provide certs in an automated way to the Internet infrastructure, but doesn't work well within an organization. Vault's PKI support is designed to provide certs in an automated way within an organization, where you don't need to issue certs acceptable to the wider Internet but you need to issue a large number from a root trusted internally. So for software like fabio, if Internet-facing, you can definitely see imagine fetching certs from LE for the front end, and your backend services fetching certs from Vault. If fabio isn't Internet-facing in your setup, it could also fetch from Vault.\n. Hi @magiconair \nThat sounds like much, much more traffic to Vault than should be needed (and many more token refreshes). Can you explain the design a bit more? Is there any reason not so simply key off refreshing from Vault based on the certificate's expected lifetime? (e.g. start checking at halfway until expiration, increasing frequency as you get closer to expiration)\n. @magiconair In case it got lost, another recommendation for the GetCertificate function in https://golang.org/pkg/crypto/tls/#Config. You could use this to fetch certificates on demand and then simply memoize them.\nIn fact, this is exactly how we implemented certificate reloading in Vault. That function fetches the certs from disk and stores the parsed objects in memory; when a connection comes in and that function is called it simply returns the cert. However, when a SIGHUP comes in, it forgets that cert and re-parses the file on disk, then memoizes the new value.\nThis way you don't need to keep hitting Vault looking for new certs -- you can simply return the ones you already have, and maybe check now and again to see if new versions are available.\n. You know when certs expire -- why not just fetch based on time, unless someone manually sends a signal to Fabio, at which point you could remove all certs from memory and treat all as fresh?\nI honestly don't see any reason for polling here.\n. > Everything else in fabio is automatic. There are no signals to be sent and nothing to be configured.\nThen don't use signals. I just suggested that if you wanted a way for an operator to explicitly tell fabio to reload.\n\nThe first option requires some refactoring and has the potential for blocking fabio while the certificates are being fetched. What if I get lots of requests for domains I don't have a cert for? That might kill the cert store\n\nIt can block fabio while certs are being fetched, but after the first fetch it'll be memoized. Besides, it should only be blocking that single goroutine. You can memoize negative results with a retry timer for certificates that aren't available.\n\nThe second option requires either some manual intervention or some glue code the user has to provide. Both are not in line with fabios design goals.\n\nI don't see why allowing an administrator to manually expire certificates is a bad thing.\n\nThe third option is how fabio works now but it requires a database which notifies fabio when something has changed (i.e. consul) or I have to poll for changes.\n\nI think this option is fine as long as you poll reasonably. Polling the entire cert store every three seconds is completely wasteful. You're better off using a timer per certificate to control when you next poll, based on certificate lifetime. But that ends up basically looking like option number one.\nMy strong suggestion is option number one (with flavors of option three). Store a backoff time value, rwmutex, and certificate information in a struct; use a thread-safe data type to look up the appropriate struct for a name, do a read lock, and return the info if valid.\nSeparately, have a management thread that checks each certificate; if the certificate will be expiring soon, or does not exist, get a write lock and attempt a read from the certificate store. In either case set the backoff time to half of the remaining time until expiration. If a certificate doesn't yet exist, or if it has expired without being refreshed, get a write lock and do a read from the certificate store...if nothing comes back set the backoff time to some near value (say, 3 seconds) and try again later.\n. @magiconair BTW, I'll be in Amsterdam next week for HashiConf EU. You should join us at http://www.meetup.com/Software-Circus/events/228747162/ !\n. Wow...I'm embarrassed -- I totally missed that you were talking at HC EU! Blame it on me being busy with releasing, blog posts, talks, training...\nLooking forward to talking to you then. BTW -- I have zero issue with you wanting admin interaction. I truly only brought it up as an alternate method on top of automatic, because, direct control gives people warm fuzzies. But as per my post above I think we can get a good automatic solution that isn't resorting to constant pulling.\n. ",
    "ghost": "+1 Transparent TCP is currently a gaping hole that no one has filled.\nedit: To clarify, a transparent TCP proxy that can work with a Consul/Etcd/Mesos/etc natively that can do connection draining.\n. If Fabio had the ability to do TCP as well as HTTP I'd have a reason to put in the work to extend the backend support to include Mesos/Maratho. I'd then be able to replace both Traefik and HAProxy/Mesos-DNS with a single service and greatly simplify my stack.\n. If you need any testing done let me know!\n. ",
    "doublerebel": ":+1: \n. Oh shoot, didn't double check my work on the go, you are quite right, thanks!\nI think the most important flags are the addresses and secrets:\nproxy.address\nproxy.localip\nproxy.header.clientip\nconsul.addr\nconsul.token\nui.addr\nSince these can all change between machines/deploys with the rest of the config the same.\nAlso I would find runtime.gomaxprocs useful, since a VM can be resized to add procs.\nHaving these as flags would follow the pattern of Consul, Vault, and the other Hashicorp tools.  Then envconsul (or my Solaris SMF) could be used to easily monitor and deliver the flags.\n. Thanks!  I'm looking at spf13/viper, it looks relatively straightforward to support env vars, flags, and config files.\n. Good news! Viper is able to load the Java properties config with minimal changes 1.  Working on the flags and env vars now.\n. This greatly simplifies Fabio configuration and setup, and ensures that it's easy to track config settings from the default Struct, env vars, and flags.  The unified format means there is no guessing where the default is set, or which env var or flag corresponds with the Config struct.\nFor instance, the change to fix #48 introduced a bug, which overwrites my fix from #30.  It introduces a new setting ServiceAddr, and no longer uses cfg.UI.Addr.  The example properties file still lists the service registration address as defaulting to ui.addr, and also incorrectly lists the default setting as registry.consul.register.ip.  The Config struct uses cfg.Consul.ServiceAddr, so it took me a while to figure out what had changed and what name of env var would override this setting.\nAs Fabio increases in complexity, naming and tracing settings will also become more complex.  For instance, the PR for Google Cloud Platform backend introduces a new list of settings.  Using Viper will eliminate the boilerplate code required to introduce new settings.\nTo iterate, test, and deploy Fabio, flags are even easier and quicker than env vars.  Env vars are important for 12-factor apps, but the use of flags as an override is common and helps support many more use cases.  With Viper we can also add flags with minimal additional code.\nThe extra file formats are not my primary goal -- but e.g. JSON is easy to generate from any language, which makes it simpler to automate deployment and configuration of Fabio.\nEDIT: Added flag for registry.consul.serviceaddr, and cleaned up commits with gofmt.\n. Thanks very much for considering my patch.  I know it is not a small change.\nThe FABIO_ prefix comes from the discussion in #43, I agree it's not required.  Although since --cfg will also be a breaking change, it may be a good time to change if wanted.\nI really like the intention of Fabio to be minimal config, so it can be downloaded and used right away.  One of my goals is to simplify from a developer perspective, so that it's easier to extend Fabio right away.  It might help if I explain how I am using Fabio and why I needed to extend it:\nMy architecture is designed to be reactive, as encouraged by Consul.  I have Fabio running on n machines with >=3 networks attached per machine.  The networks are defined as VLANs using Joyent's SDN.  For security the ui.addr, proxy.localip, and proxy.addr are all on different networks.  A machine may be detached and attached to any network at any time, or the image can be moved to another node.  Using Solaris SMF, the Fabio service is defined as dependent on the network service, so Fabio will restart whenever the network is changed.\nIn order to set the different networks each time Fabio launches, I looked at a few solutions:\n- Generate config using consul-template.  This seemed like overkill but would work.  However, I would have to setup another watch for the template, and state would still be stored in a file, leaving potential for bad state.\n- Set an env var for every network setting. This is simple and can be done in the service init script.  However, every service I use defines different env vars for their network settings.  Now instead of storing state in 1 config file, state exists in >3 vars of different names, leaving potential for bad state.\n- Extend Fabio to take flags.  Flags are how I set networks for the majority of my services, and it is very clean.  I can essentially do fabio --proxy.addr $(get_public_ip.sh), and state is not stored anywhere.  This ensures that the networks are set directly from the nic values and correct at every launch.\nFor me the variable is IP addresses, but for other reactive architectures the variable could be any setting.  That's why I support liberal acceptance of config via files, env vars, and flags.  I did not see a way to add many flags without also creating a lot of code duplication and potential for me to make an error.  Also debugging the config from all sources and saving to file became issues that I found already solved in viper.\nThanks again for your time, I really appreciate the discussion.\n. No problem, I have started working on these items:\n1. I was able to manually keep -cfg flag by removing it from the arguments list.  For reference, this is in commit dc6d851 so it may be removed later.  I also have kept -v as shorthand for version.\n2. Yes, magiconair/properties#9 is required since Viper does its own Unmarshal to Struct after merging defaults, env vars, flags, and config file.\n3. Yes, I can patch vendored Viper to support both: env vars with FABIO_ prefix, and deprecated without.\n4. I know the failed build is due to missing vendored packages, I will properly vendor all the dependencies and add them to this branch.\n. ",
    "yingfeng": "Transparent TCP proxy is useful when deploying such services as IM server, RPC services within docker container cloud, given this feature enabled, fabio could be a replacement for HAProxy totally for cloud environment.\n. For feature 2, there's an explanation on Netflix Hystrix:\nhttp://techblog.netflix.com/2012/02/fault-tolerance-in-high-volume.html\nAs to feature 4, it's still a pattern for API gateway:\nhttp://techblog.netflix.com/2012/07/embracing-differences-inside-netflix.html\nIf FabIO could support them all, it'll be very awesome!\n. The claimed design aim of fabio is to serve microservices' deployment. Routing is an important feature but not all, because microservices does not automatically mean better availability unless you have a fault tolerant architecture, these feature are fundamental requirements for the socalled \"resiliency\": circuit breaker, retries, bulk heading and fallbacks.\nCircuit breaker is not just a healthy check and then remove it from consul, because the backend services could be still healthy through the http api exposed to consul, however, it might be overloaded, or the connection between proxy and services have met some errors. The proxy should be able to protect the services from those situations. Retries and fallbacks are the by-products for circuit breaker. As to the bulk heading, it has the close relationship with \"isolation\", when a backend service is overloaded, it should not affect other requests sent to proxy. \nAs to the feature of multiple service calling in a single client request, it's very common in microservices: say a request would assemble and render the results for a shopping cat, while it has the dependent services including order management, user management, recommender engine,...,etc, if each request can only send a single service call, there would be lots of redundant network traffic which is unfriendly for mobile apps.\nThese are all required features for a microservice api gateway and not the definition coming from me. If fabio could not be an API gateway for microservices architecture, then an extra layer would be required for such purpose which would cause a traffic redundancy.\n. ",
    "JonathanBennett": "Don't want to be one of those \"me too\" people but did anyone manage to get anywhere with transparent TCP proxying (with or without SNI)? @magiconair I know above you said you were looking at this? \nIs there any WIP we can possibly help commit to if not finished? Else I might take a stab at this, as this is currently the one thing we're missing as we have lots of arbitrary TCP ports which would benefit hugely from fabio / only work through fabio.\nThanks in advance!\n. ",
    "mterron": "Hi, is anyone working on this one?\n. @magiconair if fabio could do straight TCP+SNI (+PROXY proto?) load balancing I wouldn't need to deploy certs to fabio. This will solve a transitive trust issue where you have to trust fabio with private keys for a service itself doesn't provide. It is much easier to only deploy certs to the server/container/vm that need access to the plain text and keep an end-to-end encrypted connection, especially in environments where security is important.\n. @magiconair is there a binary for this feature or do I have to compile it myself?\n. Looks like this: https://github.com/inconshreveable/slt have all the needed functionality for TCP+SNI proxying.\n. As a MVP can you do something like url prefix-TCP(4|6)[s]:domain[:port]? The will allow for the use of the backend to define protocol (ipv4 or ipv6) with the [s] defining if it accepts TLS. I\u00b4m not quite sure if the (optional) :port part is necessary, will have to think a little bit about that one.\n. An alternative approach:\nYou can always use linux capabilities to allow the user that runs fabio to bind to low ports (I assume that's what you are after). \nJust run\nroot@fabio$ setcap 'cap_net_bind_service=+ep' $(which fabio)\nAfter that you can run fabio under an unprivileged account and it will work as expected. \nThat's the way I've been running it for months.\nCheers. It works on linux. Solaris/Illumos have privileges that are similar and can be applied to the user running fabio\n$ /usr/sbin/usermod -K defaultpriv=basic,net_privaddr fabio_user\nand check with:\n$ grep fabio_user /etc/user_attr\nfabio_user::::type=normal;defaultpriv=basic,net_privaddr\nor you can apply a privilege set to the process you are going to run (can't remember the exact syntax for this usage):\n$ /usr/sbin/ppriv -s LI+NET_PRIVADDR -e fabio\nFreeBSD have a sysctl to define the reserved port range :\n$ sysctl net.inet.ip.portrange.reservedhigh=79\nYou can add that to  /etc/sysctl.conf  so it's applied on boot.\nI don't know what the equivalent is for the other BSDs and OS X. I don't think there's anything similar on Windows though, but since you mention setuid I assume you're talking about some sort of unix system.. With my security hat on, I'd say that fabio should refuse to start as root. Maybe add an explicit option to allow it, so the user have to make a conscious decision to run as root. \nSomething like this user experience:\n```\n$ fabio -registry.consul.addr 192.168.0.100:8500\n2017/01/30 11:41:27 [ERR] root user detected. Aborting.\nWARNING! You are trying to run fabio as root, this is insecure and not recommended. \nIf you understand the security implications of running as root, run fabio with the \n-insecure flag.\n$ fabio -insecure -registry.consul.addr 192.168.0.100:8500\n2017/01/30 11:41:27 [WARN] Running as root\n2017/01/30 11:41:27 [INFO] Runtime config\n{\n     ...\n}\n2017/01/30 11:41:27 [INFO] Version 1.3.7 starting\n2017/01/30 11:41:27 [INFO] Go runtime is go1.7.3\n2017/01/30 11:41:27 [INFO] Using routing strategy \"rnd\"\n2017/01/30 11:41:27 [INFO] Using routing matching \"prefix\"\n2017/01/30 11:41:27 [INFO] Setting GOGC=800\n2017/01/30 11:41:27 [INFO] Setting GOMAXPROCS=4\n2017/01/30 11:41:27 [INFO] Metrics disabled\n```. @magiconair macOS have no root and I don't think Windows even has a concept of root.\nAllowing a user to bind to a low port (I'm guessing all this discussion is related to port 80 and 443, please correct me if I'm wrong) is an administrator's activity and different OSs will have different mechanisms to achieve that, as I've shown in my messages. A system administrator that is deploying internet facing services should be familiar with those mechanisms.\nI don't think that logic belongs with the fabio code at all, so no os specific tricks for you to code and maintain. What could be added to fabio is a warning message in case it couldn't bind to a port (maybe it already exists, I haven't run into it).\nI agree with giving ample warning about the implementation of the insecure switch as you don't want to break deployments though I'd argue that most people running fabio as root have not weighed in the pros and cons and run it like that \"cause it works\". \nIt is better to break a deployment with a clear error message and instructions on what to do next than having your system taken over due to some bug in fabio or golang.\nYou could even go as far as, depending on the OS, explaining how to fix the issue as I've shown in the comments above.. I think that between my original messages and @stephane-martin ones the basics are covered. \nYou have:\n Generic linux (my setcap comment)\n Linux with systemd\n Illumos/Solaris (2 options, privileges for the user or the process)\n FreeBSD (modify \"low ports\" limit)\n macOS (using launchd)\n OpenBSD (using PF redirection)\nIs there other OS that's missing?\nWe could add references to the man pages for capabilities and privileges for people that want to understand better what they are doing.. I stand by what I said in the original thread. It is the software responsibility to do the right thing, in this case refuse to run as root. If  you really really really want to (even though it is a bad idea in 99.9999% of the cases), there's a cli switch that will allow you to do that. \nLet's make doing the right thing the easy thing to do. +1 on the hourly WARNING when running as root, great idea.\nThe last ~25 years has proven beyond doubt that \"secure by default\" is the only reasonable choice, as the large majority of users/operators WILL NOT take steps to secure their deployments and WILL ignore \"a big obnoxious warning\" as long as the \"thing\" runs.\nIf you know what you are doing and want to run with decreased security for your environment, adding a cli switch that is clearly explained to you when you try to do something that's potentially unsafe is not a big deal. Same if you are building containers, adding a user on the build phase is trivial work and industry best practice.. Just 1 comment. Container root (in linux) IS the host system root. There's\na new user mapping feature but not widely deployed afaik.. This is probably semantics, but IMO as a Security professional, containers in linux don't exist. The kernel have no idea what a container is, the only thing it knows about is cgroups and namespaces. \nOn other OSs, a container is a kernel primitive so the control and segmentation is stronger (see Solaris/Illumos Zones) and multitenancy is possible (and encouraged).. ",
    "InAnimaTe": "To speak in parallel with some of the mentions earlier, I would find sni passthrough extremely desirable. I know a lot of people, including myself, like to keep encryption end-to-end and store their key/cert with the application itself, instead of maintaining it at the LB.\nAs a previous user said, most solutions out there which implement dynamic backends making them more juicy for micro-service deployment don't support this (fabio, traefik, hipache, etc), whilst the solutions which support this don't support dynamic backends (i.e. haproxy, nginx, caddy). Fabio could be one of the first All-In-One solutions that is flexible enough to do this!\n. You sir are a God among Men.\nI have a few services I plan to test this with sometime this week. Really glad you put forth the effort and time to get this initial version committed. Appreciate it!\n. I would absolutely love to see Fabio working on k8s. As I'm starting to build our own cluster, it seems the best course of action would be for Fabio to tap into the k8s API and work like other Ingress Controllers which load all Ingress registrations and serve them appropriately. \n. ",
    "sean-": "+100\n. FYI in case folks don't watch every commit that rolls into Consul's code base, something very close to what you were looking for, @madeddie, was added to Consul not long ago: https://github.com/hashicorp/consul/commit/2b2464403f93134a05eb5946e0b223199d364aa8\n. What I'm about to suggest is for creativity purposes only and not something I'm recommending, but: if Fabio did advertise its ports back to Consul, it would be possible to Consul-template listen on the k/v, render out a Terraform config file locally, and then run Terraform to mutate the ports in an elb/alb. Locking, state sync, a whole host of issues come into play, but... if someone wanted to Rube-Goldberg up a solution it's possible.. I'm going to be revisiting this in the next week now that lucas-clemente/quic-go#1097 has gone in.  Initial testing showed sub-optimal transfer rates over WAN links, but now that the performance is parity, I'm going to devote some cycles to this.. PostgreSQL does this and it\u2019s been a useful safety precaution that has probably prevented many incidents.  That said, it\u2019s also extremely irritating as an operator when diving into a problem as root.  Or even when I\u2019m in a secured contained environment and there is only one process, but now I have to manage the creation and lookup of a user/UID.  In an ideal world I\u2019d rather see a big obnoxious warning when the flag is used and a once-an-hour log entry nagging the user that the process is running as root (vs only at startup time).. @magiconair, no it wouldn't.  We're not using the TCP PROXY protocol anywhere.  We're using gRPC now (successfully) and auth.. ",
    "nugend": "Any chance of vanilla TCP support?\n. Internal app using a custom connection oriented protocol. A number of client teams that don't really have the ability to be aware of our multiple instances.\n. @magiconair subbed, thanks.\n. I'd like to test, but I'd have to spend some time figuring out how to install go in a custom root.. Yes. Thank you.. Will test it out first thing tomorrow! Thanks!. Yes! Sorry for the delay. Seems to work great! We'll probably try using it for inbound client connections when we have some time on our schedule.. ",
    "holtwilkins": "Hey @magiconair , I can't seem to get the ELB PROXY and tcp+sni pieces work together, should they, or am I missing something?\nI.e. curl -k --resolve hello-world.blah.com:9999:10.2.211.134 https://hello-world.blah.com:9999/hello_world.html works from a machine that's able to see that private IP, so I've seemingly verified that tcp+sni is working correctly.  But I'm trying to put fabio behind an AWS ELB, and whether I put the ELB into https 443 -> https 9999 or  tcp 443 -> tcp 9999 w/PROXY support, it doesn't work.  (Fabio was starting with just -proxy.addr ':9999;proto=tcp+sni' as its args here).  The curl command to hit the ELB is just curl -k https://hello-world.blah.com/\nIn the https case, my curl just hangs, I'm not sure where it's hanging.  Meanwhile fabio is spitting out 2016/10/11 03:51:57 [DEBUG] tcp+sni: server_name missing constantly, so I'm assuming something internal to the ELB is just spitting-out tons of request to fabio about something (the healthcheck is on 9998, so it shouldn't be that)?\nIn the tcp case, I get curl: (35) SSL received a record that exceeded the maximum permissible length. or curl: (35) Unknown SSL protocol error in connection to hello-world.blah.com:-9847.  On the Fabio side, the only log I get for each of these attempts is 2016/10/11 04:01:16 [DEBUG] tcp+sni: TLS handshake failed.  Any ideas?\n. I sure can, just point me at the branch when it's ready!\n. Thanks @magiconair , it worked for me!\n. Hey @magiconair thanks for getting this going!  I tried it out, and most of the fields look right to me, but the $upstream_* fields seem to be logging the remote fields, not the upstream fields.. I can confirm that $upstream_addr looks right now, thanks!. Hey @magiconair or @ctlajoie , can I get an example of the redirect feature that does carte-blanche http -> https redirection?\nNamely, what I want is, if you go to http://<host>/<URI>, I want to return you a 301 (or whatever) to https://<host>/<URI>.\nIt seems like it should be possible now, but I don't want to have to define this redirect for every urlprefix, but ideally can set it in fabio/config so that it applies automatically to all new tags being added.  Is this possible?. So only all paths on a host, and not for all hosts, eh.  I guess this isn't too bad, but a catch-all to set it once and never think about it again would be pretty cool.. Thanks @magiconair , looks like good discussions happening in the PR, I'd be happy with https-redirect or a :80/ catch-all or whatever lets me achieve my host-and-URI-agnostic http->https redirection :). It is still using consul for service discovery. Your question made me realise though that I have service \u201c\u201d readable by anonymous , so I could just do the same thing for /fabio/, is that the recommended approach for using fabio with acls?. So, I've tried adding read to fabio/ as well as pointing to another path which already definitely has anonymous read, and I'm still getting lots of permission denied in the consul logs.\nIdeally I can just turn off this integration altogether, and make fabio only use consul for service discovery, and not try to lookup anything in the consul kv - is this possible?. Yup, still not working for me.  I think an empty registry.backend.consul.kvpath sounds good for the config bit, what about the noroutehtml page, how do I disable that one?\nI do have acl_enforce_version_8 = false and acl_default_policy = \"deny\" set in my consul configs, if that's helpful.\nI've tried setting the following anonymous acl policy:\nroot@ip-10-2-211-215:~# curl http://127.0.0.1:8500/v1/acl/info/anonymous?token=${ACL_MASTER_TOKEN}\n[{\"ID\":\"anonymous\",\"Name\":\"Anonymous Token\",\"Type\":\"client\",\"Rules\":\"key \\\"deploy/\\\" { policy = \\\"read\\\"} service \\\"\\\" { policy = \\\"read\\\"} key \\\"fabio/config\\\" {  policy = \\\"read\\\"} key \\\"fabio/\\\" {  policy = \\\"read\\\" } agent \\\"\\\" {  policy = \\\"read\\\"} node \\\"\\\" {  policy = \\\"read\\\"}\",\"CreateIndex\":4,\"ModifyIndex\":19587932}]\nAnd my logs are still flooded:\nFeb 14 05:49:20 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:20 [ERR] http: Request GET /v1/kv/fabio/noroute.html?consistent=, error: rpc error making call: rpc error making call: Permission denied from=127.0.0.1:44383\nFeb 14 05:49:20 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:20 [ERR] consul: \"KVS.Get\" RPC failed to server 10.2.210.100:8300: rpc error making call: rpc error making call: Permission denied\nFeb 14 05:49:20 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:20 [ERR] http: Request GET /v1/kv/fabio/config?consistent=, error: rpc error making call: rpc error making call: Permission denied from=127.0.0.1:44382\nFeb 14 05:49:21 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:21 [ERR] consul: \"KVS.Get\" RPC failed to server 10.2.211.100:8300: rpc error making call: Permission denied\nFeb 14 05:49:21 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:21 [ERR] http: Request GET /v1/kv/fabio/noroute.html?consistent=, error: rpc error making call: Permission denied from=127.0.0.1:44389\nFeb 14 05:49:21 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:21 [ERR] consul: \"KVS.Get\" RPC failed to server 10.2.210.201:8300: rpc error making call: rpc error making call: Permission denied\nFeb 14 05:49:21 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:21 [ERR] http: Request GET /v1/kv/fabio/config?consistent=, error: rpc error making call: rpc error making call: Permission denied from=127.0.0.1:44388\nFeb 14 05:49:22 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:22 [ERR] consul: \"KVS.Get\" RPC failed to server 10.2.210.100:8300: rpc error making call: rpc error making call: Permission denied\nFeb 14 05:49:22 ip-10-2-211-215 consul[2985]:     2018/02/14 05:49:22 [ERR] http: Request GET /v1/kv/fabio/noroute.html?consistent=, error: rpc error making call: rpc error making call: Permission denied from=127.0.0.1:44397. Ah of course. This is because fabio is running from nomad, in docker, in host networking mode. Since consul acls don\u2019t stack, the one I need to change is the one for nomad, not anonymous. I\u2019ll do this tomorrow, but yeah, I\u2019m pretty sure this is it.. Yup, confirmed that adding\nkey \"fabio/\" {\n  policy = \"read\"\n}\nTo my worker's ACL token fixed all the errors in the logs.  Not sure if you want to alter documentation or just close this issue, but thanks for you help @magiconair !. While you're at it @magiconair , I also noticed that the fabio.properties and docs/content/ref/registry.consul.noroutehtmlpath.md docs says the default for registry.consul.noroutehtmlpath is /fabio/noroutes.html, but it's actually /fabio/noroute.html as per config/default.go. How about https://github.com/fabiolb/fabio/pull/544 instead?. So we've starting using route add syntax for lots of stuff right now, but we shove it into the fabio.config in consul.  I agreee that it doesn't make sense to support route add in a tag for the declarative vs imperative split.\nI guess I'm back to my original request of just wanting a catch-all https-redirector, and I'd prefer putting route add command in fabio.config to putting it in a job's tags - it applies to everything anyway, not just a single job, and definitely \"feels\" right to put it in fabio.config.. Hey @magiconair had a chance to think any more about a global https redirector?. Yup @leprechau that would be great.. Hey @leprechau I'm happy too, but not sure how to word it.  It seems like the old PR at https://github.com/fabiolb/fabio/pull/451 was meant to do something similar to this but was seemingly forgotten about?  Should I open an issue calling out host-less redirects?. Hey @leprechau & @magiconair , I started working on this, and did something similar to https://github.com/fabiolb/fabio/pull/451/files to get the $host substitution going.\nHowever, the issue I'm seeing now is that the :80 part doesn't seem to work.  I.e. route add mock :80/ https://a.com/ opts \"redirect=301\" doesn't work, but route add mock a.com:80/ https://a.com/ opts \"redirect=301\" does.  So, it seems like a / as the source is fine, but if you throw a port in there, it's no longer a catch-all.  Ideas on how to rectify that part (other than just run a separate instance of fabio that has a single / rule)?. Hey @leprechau & @magiconair , I figured out the missing bit, it was this line: https://github.com/fabiolb/fabio/pull/544/files#diff-416b5689da1c2696679b73504589fad3R362\nNow this global http -> https redirect seems to work great, what do you think?. Fixes https://github.com/fabiolb/fabio/issues/533. hey @leprechau it's failing a consul/vault test, not sure if that's normal or not\n``\ngofmt -s -wfind . -type f -name '*.go' | grep -v vendorgo build\ngo test -v -test.timeout 15sgo list ./... | grep -v '/vendor/'`\n?       github.com/fabiolb/fabio    [no test files]\n=== RUN   TestAdminServerAccess\n=== RUN   TestAdminServerAccess/ro/api/manual\n=== RUN   TestAdminServerAccess/ro/api/paths\n=== RUN   TestAdminServerAccess/ro/api/config\n=== RUN   TestAdminServerAccess/ro/api/routes\n=== RUN   TestAdminServerAccess/ro/api/version\n=== RUN   TestAdminServerAccess/ro/manual\n=== RUN   TestAdminServerAccess/ro/routes\n=== RUN   TestAdminServerAccess/ro/health\n=== RUN   TestAdminServerAccess/ro/logo.svg\n=== RUN   TestAdminServerAccess/ro/\n=== RUN   TestAdminServerAccess/rw/api/manual\n=== RUN   TestAdminServerAccess/rw/api/paths\n=== RUN   TestAdminServerAccess/rw/api/config\n=== RUN   TestAdminServerAccess/rw/api/routes\n=== RUN   TestAdminServerAccess/rw/api/version\n=== RUN   TestAdminServerAccess/rw/manual\n=== RUN   TestAdminServerAccess/rw/routes\n=== RUN   TestAdminServerAccess/rw/health\n=== RUN   TestAdminServerAccess/rw/logo.svg\n=== RUN   TestAdminServerAccess/rw/\n--- PASS: TestAdminServerAccess (0.03s)\n    --- PASS: TestAdminServerAccess/ro/api/manual (0.00s)\n    --- PASS: TestAdminServerAccess/ro/api/paths (0.00s)\n    --- PASS: TestAdminServerAccess/ro/api/config (0.00s)\n    --- PASS: TestAdminServerAccess/ro/api/routes (0.00s)\n    --- PASS: TestAdminServerAccess/ro/api/version (0.00s)\n    --- PASS: TestAdminServerAccess/ro/manual (0.00s)\n    --- PASS: TestAdminServerAccess/ro/routes (0.00s)\n    --- PASS: TestAdminServerAccess/ro/health (0.00s)\n    --- PASS: TestAdminServerAccess/ro/logo.svg (0.00s)\n    --- PASS: TestAdminServerAccess/ro/ (0.00s)\n    --- PASS: TestAdminServerAccess/rw/api/manual (0.00s)\n    --- PASS: TestAdminServerAccess/rw/api/paths (0.00s)\n    --- PASS: TestAdminServerAccess/rw/api/config (0.00s)\n    --- PASS: TestAdminServerAccess/rw/api/routes (0.00s)\n    --- PASS: TestAdminServerAccess/rw/api/version (0.00s)\n    --- PASS: TestAdminServerAccess/rw/manual (0.00s)\n    --- PASS: TestAdminServerAccess/rw/routes (0.00s)\n    --- PASS: TestAdminServerAccess/rw/health (0.00s)\n    --- PASS: TestAdminServerAccess/rw/logo.svg (0.00s)\n    --- PASS: TestAdminServerAccess/rw/ (0.00s)\nPASS\nok      github.com/fabiolb/fabio/admin  (cached)\n?       github.com/fabiolb/fabio/admin/api  [no test files]\n?       github.com/fabiolb/fabio/admin/ui   [no test files]\n?       github.com/fabiolb/fabio/assert [no test files]\n=== RUN   TestParseConsulURL\n=== RUN   TestParseConsulURL/empty_url\n=== RUN   TestParseConsulURL/invalid_url\n=== RUN   TestParseConsulURL/no_kv_store_url\n=== RUN   TestParseConsulURL/url_without_token\n=== RUN   TestParseConsulURL/https_url\n=== RUN   TestParseConsulURL/url_with_token\n--- PASS: TestParseConsulURL (0.00s)\n    --- PASS: TestParseConsulURL/empty_url (0.00s)\n    --- PASS: TestParseConsulURL/invalid_url (0.00s)\n    --- PASS: TestParseConsulURL/no_kv_store_url (0.00s)\n    --- PASS: TestParseConsulURL/url_without_token (0.00s)\n    --- PASS: TestParseConsulURL/https_url (0.00s)\n    --- PASS: TestParseConsulURL/url_with_token (0.00s)\n=== RUN   TestBase\n--- PASS: TestBase (0.00s)\n=== RUN   TestReplaceSuffix\n--- PASS: TestReplaceSuffix (0.00s)\n=== RUN   TestUpgradeCACertificate\n2018/09/12 08:53:59 [INFO] cert: Upgrading cert ApiGateway to CA cert\n--- PASS: TestUpgradeCACertificate (0.00s)\n=== RUN   TestTLSConfig\n--- PASS: TestTLSConfig (0.03s)\n=== RUN   TestNewSource\n=== RUN   TestNewSource/invalid\n=== RUN   TestNewSource/file\n=== RUN   TestNewSource/path\n=== RUN   TestNewSource/http\n=== RUN   TestNewSource/consul\n=== RUN   TestNewSource/vault\n--- PASS: TestNewSource (0.00s)\n    --- PASS: TestNewSource/invalid (0.00s)\n    --- PASS: TestNewSource/file (0.00s)\n    --- PASS: TestNewSource/path (0.00s)\n    --- PASS: TestNewSource/http (0.00s)\n    --- PASS: TestNewSource/consul (0.00s)\n    --- PASS: TestNewSource/vault (0.00s)\n2018/09/12 08:53:59 [INFO] cert: Store has certificates for [\"localhost\"]\n=== RUN   TestStaticSource\n--- PASS: TestStaticSource (0.07s)\n=== RUN   TestFileSource\n--- PASS: TestFileSource (0.08s)\n=== RUN   TestPathSource\n2018/09/12 08:54:00 [INFO] cert: Store has certificates for [\"localhost\"]\n--- PASS: TestPathSource (0.11s)\n=== RUN   TestHTTPSource\n2018/09/12 08:54:00 [INFO] cert: Store has certificates for [\"localhost\"]\n--- PASS: TestHTTPSource (0.64s)\n=== RUN   TestConsulSource\n--- FAIL: TestConsulSource (12.10s)\n    source_test.go:240: Starting consul: Consul v1.2.2\n    source_test.go:261: Timeout waiting for consul server after 12.1 seconds\n=== RUN   TestVaultSource\n--- FAIL: TestVaultSource (0.22s)\n    source_test.go:305: Starting vault: \"Vault v0.11.0 ('87492f9258e0227f3717e3883c6a8be5716bf564+CHANGES')\\n\"\n    source_test.go:429: logical.Write failed: Error making API request.\n    URL: PUT http://127.0.0.1:58421/v1/secret/fabio/cert/localhost\n    Code: 404. Errors:\n\n=== RUN   TestVaultPKISource\n=== RUN   TestVaultPKISource/renewable_token\n=== RUN   TestVaultPKISource/non-renewable_token\n=== RUN   TestVaultPKISource/renewable_orphan_token\npanic: test timed out after 15s\ngoroutine 917 [running]:\ntesting.(*M).startAlarm.func1()\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:1296 +0xfd\ncreated by time.goFunc\n    /usr/local/Cellar/go/1.11/libexec/src/time/sleep.go:172 +0x44\ngoroutine 1 [chan receive]:\ntesting.(T).Run(0xc000176000, 0x13cac53, 0x12, 0x13df5e0, 0x107b000)\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:879 +0x37a\ntesting.runTests.func1(0xc00011a100)\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:1119 +0x78\ntesting.tRunner(0xc00011a100, 0xc0000b3e08)\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:827 +0xbf\ntesting.runTests(0xc000140340, 0x1678be0, 0xe, 0xe, 0x100d4ff)\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:1117 +0x2aa\ntesting.(M).Run(0xc000116c00, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:1034 +0x165\nmain.main()\n    _testmain.go:68 +0x13d\ngoroutine 35 [syscall]:\nos/signal.signal_recv(0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/runtime/sigqueue.go:139 +0x9f\nos/signal.loop()\n    /usr/local/Cellar/go/1.11/libexec/src/os/signal/signal_unix.go:23 +0x22\ncreated by os/signal.init.0\n    /usr/local/Cellar/go/1.11/libexec/src/os/signal/signal_unix.go:29 +0x41\ngoroutine 248 [select]:\nnet/http.(persistConn).readLoop(0xc0000ca5a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 173 [select]:\nnet/http.(persistConn).readLoop(0xc000270120)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 198 [select]:\nnet/http.(persistConn).writeLoop(0xc000270360)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 251 [select]:\nnet/http.(persistConn).writeLoop(0xc0000ca6c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 174 [select]:\nnet/http.(persistConn).writeLoop(0xc000270120)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 355 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cb200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 220 [select]:\nnet/http.(persistConn).readLoop(0xc0000ca7e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 177 [select]:\nnet/http.(persistConn).readLoop(0xc0004ec240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 310 [select]:\nnet/http.(persistConn).readLoop(0xc0000ca900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 605 [chan receive]:\ntesting.(T).Run(0xc000169700, 0x13ccae9, 0x16, 0xc000576190, 0x1)\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:879 +0x37a\ngithub.com/fabiolb/fabio/cert.TestVaultPKISource(0xc000176000)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source_test.go:501 +0x868\ntesting.tRunner(0xc000176000, 0x13df5e0)\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:827 +0xbf\ncreated by testing.(T).Run\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:878 +0x353\ngoroutine 226 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ec240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 191 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ec360)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 147 [chan receive]:\ngithub.com/fabiolb/fabio/cert.TLSConfig.func2(0x14291c0, 0xc00038e240, 0xc0004dc5d0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:145 +0xa7\ncreated by github.com/fabiolb/fabio/cert.TLSConfig\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:144 +0x1fa\ngoroutine 247 [select]:\nnet/http.(persistConn).writeLoop(0xc000192480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 317 [select]:\nnet/http.(persistConn).writeLoop(0xc0000caea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 125 [chan receive]:\ngithub.com/fabiolb/fabio/cert.TLSConfig.func2(0x1429200, 0xc000355e00, 0xc000317d10)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:145 +0xa7\ncreated by github.com/fabiolb/fabio/cert.TLSConfig\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:144 +0x1fa\ngoroutine 176 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ec120)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 314 [select]:\nnet/http.(persistConn).readLoop(0xc0000cad80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 206 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ecfc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 250 [select]:\nnet/http.(persistConn).readLoop(0xc0000ca6c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 236 [select]:\nnet/http.(persistConn).writeLoop(0xc0002705a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 175 [select]:\nnet/http.(persistConn).readLoop(0xc0004ec120)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 228 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ec480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 244 [select]:\nnet/http.(persistConn).readLoop(0xc000192240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 190 [select]:\nnet/http.(persistConn).readLoop(0xc0004ec360)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 217 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ec5a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 214 [select]:\nnet/http.(persistConn).readLoop(0xc000270240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 215 [select]:\nnet/http.(persistConn).writeLoop(0xc000270240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 227 [select]:\nnet/http.(persistConn).readLoop(0xc0004ec480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 253 [select]:\nnet/http.(persistConn).writeLoop(0xc0002706c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 216 [select]:\nnet/http.(persistConn).readLoop(0xc0004ec5a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 245 [select]:\nnet/http.(persistConn).writeLoop(0xc000192240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 249 [select]:\nnet/http.(persistConn).writeLoop(0xc0000ca5a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 246 [select]:\nnet/http.(persistConn).readLoop(0xc000192480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 197 [select]:\nnet/http.(persistConn).readLoop(0xc000270360)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 221 [select]:\nnet/http.(persistConn).writeLoop(0xc0000ca7e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 233 [select]:\nnet/http.(persistConn).readLoop(0xc000270480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 234 [select]:\nnet/http.(persistConn).writeLoop(0xc000270480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 238 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ec7e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 235 [select]:\nnet/http.(persistConn).readLoop(0xc0002705a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 263 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ec900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 252 [select]:\nnet/http.(persistConn).readLoop(0xc0002706c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 260 [select]:\nnet/http.(persistConn).readLoop(0xc0004ec6c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 261 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ec6c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 287 [select]:\nnet/http.(persistConn).writeLoop(0xc0001927e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 237 [select]:\nnet/http.(persistConn).readLoop(0xc0004ec7e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 265 [select]:\nnet/http.(persistConn).writeLoop(0xc0001925a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 262 [select]:\nnet/http.(persistConn).readLoop(0xc0004ec900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 264 [select]:\nnet/http.(persistConn).readLoop(0xc0001925a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 292 [select]:\nnet/http.(persistConn).writeLoop(0xc0002707e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 241 [select]:\nnet/http.(persistConn).readLoop(0xc0004eca20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 290 [select]:\nnet/http.(persistConn).writeLoop(0xc0004eca20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 291 [select]:\nnet/http.(persistConn).readLoop(0xc0002707e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 273 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ecc60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 278 [select]:\nnet/http.(persistConn).readLoop(0xc000270900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 279 [select]:\nnet/http.(persistConn).writeLoop(0xc000270900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 270 [select]:\nnet/http.(persistConn).readLoop(0xc0004ecb40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 271 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ecb40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 323 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ecea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 272 [select]:\nnet/http.(persistConn).readLoop(0xc0004ecc60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 284 [select]:\nnet/http.(persistConn).readLoop(0xc0001926c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 285 [select]:\nnet/http.(persistConn).writeLoop(0xc0001926c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 325 [select]:\nnet/http.(persistConn).writeLoop(0xc00036ad80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 286 [select]:\nnet/http.(persistConn).readLoop(0xc0001927e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 306 [select]:\nnet/http.(persistConn).readLoop(0xc0004ecd80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 307 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ecd80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 322 [select]:\nnet/http.(persistConn).readLoop(0xc0004ecea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 311 [select]:\nnet/http.(persistConn).writeLoop(0xc0000ca900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 205 [select]:\nnet/http.(persistConn).readLoop(0xc0004ecfc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 315 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cad80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 316 [select]:\nnet/http.(persistConn).readLoop(0xc0000caea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 304 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cb8c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 297 [select]:\nnet/http.(persistConn).readLoop(0xc0000cafc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 298 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cafc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 320 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed0e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 321 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed0e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 357 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cb680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 343 [select]:\nnet/http.(persistConn).readLoop(0xc0000cb0e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 344 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cb0e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 354 [select]:\nnet/http.(persistConn).readLoop(0xc0000cb200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 363 [select]:\nnet/http.(persistConn).writeLoop(0xc000192a20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 356 [select]:\nnet/http.(persistConn).readLoop(0xc0000cb680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 365 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cbb00)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 351 [select]:\nnet/http.(persistConn).readLoop(0xc0000cb7a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 352 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cb7a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 360 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 361 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 301 [select]:\nnet/http.(persistConn).readLoop(0xc000192900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 302 [select]:\nnet/http.(persistConn).writeLoop(0xc000192900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 303 [select]:\nnet/http.(persistConn).readLoop(0xc0000cb8c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 362 [select]:\nnet/http.(persistConn).readLoop(0xc000192a20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 438 [select]:\nnet/http.(persistConn).writeLoop(0xc00036a240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 371 [select]:\nnet/http.(persistConn).readLoop(0xc000192b40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 372 [select]:\nnet/http.(persistConn).writeLoop(0xc000192b40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 389 [select]:\nnet/http.(persistConn).readLoop(0xc0000cb9e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 390 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cb9e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 403 [select]:\nnet/http.(persistConn).writeLoop(0xc000192c60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 364 [select]:\nnet/http.(persistConn).readLoop(0xc0000cbb00)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 377 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed320)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 378 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed320)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 368 [select]:\nnet/http.(persistConn).readLoop(0xc0000cbc20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 369 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cbc20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 402 [select]:\nnet/http.(persistConn).readLoop(0xc000192c60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 406 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed440)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 407 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed440)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 400 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed560)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 383 [select]:\nnet/http.(persistConn).readLoop(0xc0000cbd40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 384 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cbd40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 398 [select]:\nnet/http.(persistConn).writeLoop(0xc0000cbe60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 395 [select]:\nnet/http.(persistConn).readLoop(0xc000192d80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 396 [select]:\nnet/http.(persistConn).writeLoop(0xc000192d80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 397 [select]:\nnet/http.(persistConn).readLoop(0xc0000cbe60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 399 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed560)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 410 [select]:\nnet/http.(persistConn).readLoop(0xc000192ea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 411 [select]:\nnet/http.(persistConn).writeLoop(0xc000192ea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 435 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 436 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 440 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed8c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 437 [select]:\nnet/http.(persistConn).readLoop(0xc00036a240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 424 [select]:\nnet/http.(persistConn).writeLoop(0xc0004edc20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 421 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed7a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 422 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed7a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 442 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ed9e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 439 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed8c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 426 [select]:\nnet/http.(persistConn).writeLoop(0xc0004edd40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 441 [select]:\nnet/http.(persistConn).readLoop(0xc0004ed9e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 452 [select]:\nnet/http.(persistConn).readLoop(0xc000192fc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 453 [select]:\nnet/http.(persistConn).writeLoop(0xc000192fc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 456 [select]:\nnet/http.(persistConn).readLoop(0xc0004edb00)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 457 [select]:\nnet/http.(persistConn).writeLoop(0xc0004edb00)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 423 [select]:\nnet/http.(persistConn).readLoop(0xc0004edc20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 428 [select]:\nnet/http.(persistConn).writeLoop(0xc0004ede60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 460 [select]:\nnet/http.(persistConn).readLoop(0xc0001930e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 461 [select]:\nnet/http.(persistConn).writeLoop(0xc0001930e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 425 [select]:\nnet/http.(persistConn).readLoop(0xc0004edd40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 471 [select]:\nnet/http.(persistConn).writeLoop(0xc00036a7e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 427 [select]:\nnet/http.(persistConn).readLoop(0xc0004ede60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 447 [select]:\nnet/http.(persistConn).readLoop(0xc00036a360)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 448 [select]:\nnet/http.(persistConn).writeLoop(0xc00036a360)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 469 [select]:\nnet/http.(persistConn).writeLoop(0xc000193200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 466 [select]:\nnet/http.(persistConn).readLoop(0xc00036a480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 467 [select]:\nnet/http.(persistConn).writeLoop(0xc00036a480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 468 [select]:\nnet/http.(persistConn).readLoop(0xc000193200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 473 [select]:\nnet/http.(persistConn).writeLoop(0xc000193320)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 499 [select]:\nnet/http.(persistConn).readLoop(0xc00036a6c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 500 [select]:\nnet/http.(persistConn).writeLoop(0xc00036a6c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 470 [select]:\nnet/http.(persistConn).readLoop(0xc00036a7e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 508 [select]:\nnet/http.(persistConn).writeLoop(0xc000193440)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 483 [select]:\nnet/http.(persistConn).readLoop(0xc00036a900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 484 [select]:\nnet/http.(persistConn).writeLoop(0xc00036a900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 472 [select]:\nnet/http.(persistConn).readLoop(0xc000193320)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 476 [select]:\nnet/http.(persistConn).readLoop(0xc0002a6000)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 477 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a6000)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 505 [select]:\nnet/http.(persistConn).readLoop(0xc0002a6120)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 506 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a6120)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 510 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a6240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 507 [select]:\nnet/http.(persistConn).readLoop(0xc000193440)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 512 [select]:\nnet/http.(persistConn).writeLoop(0xc000193560)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 509 [select]:\nnet/http.(persistConn).readLoop(0xc0002a6240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 532 [select]:\nnet/http.(persistConn).writeLoop(0xc0001937a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 516 [select]:\nnet/http.(persistConn).readLoop(0xc0002a6360)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 517 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a6360)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 530 [select]:\nnet/http.(persistConn).writeLoop(0xc000193680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 511 [select]:\nnet/http.(persistConn).readLoop(0xc000193560)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 513 [select]:\nnet/http.(persistConn).readLoop(0xc000193680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 534 [select]:\nnet/http.(persistConn).writeLoop(0xc0001939e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 531 [select]:\nnet/http.(persistConn).readLoop(0xc0001937a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 522 [select]:\nnet/http.(persistConn).writeLoop(0xc000193b00)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 519 [select]:\nnet/http.(persistConn).readLoop(0xc0001938c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 520 [select]:\nnet/http.(persistConn).writeLoop(0xc0001938c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 536 [select]:\nnet/http.(persistConn).writeLoop(0xc000193c20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 533 [select]:\nnet/http.(persistConn).readLoop(0xc0001939e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 553 [select]:\nnet/http.(persistConn).writeLoop(0xc000270b40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 521 [select]:\nnet/http.(persistConn).readLoop(0xc000193b00)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 562 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a65a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 535 [select]:\nnet/http.(persistConn).readLoop(0xc000193c20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 539 [select]:\nnet/http.(persistConn).readLoop(0xc00036aa20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 540 [select]:\nnet/http.(persistConn).writeLoop(0xc00036aa20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 550 [select]:\nnet/http.(persistConn).readLoop(0xc0002a6480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 551 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a6480)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 543 [select]:\nnet/http.(persistConn).readLoop(0xc00036ac60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 544 [select]:\nnet/http.(persistConn).writeLoop(0xc00036ac60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 327 [select]:\nnet/http.(persistConn).writeLoop(0xc00036aea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 545 [select]:\nnet/http.(persistConn).readLoop(0xc0002a65a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 324 [select]:\nnet/http.(persistConn).readLoop(0xc00036ad80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 570 [select]:\nnet/http.(persistConn).writeLoop(0xc000270ea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 326 [select]:\nnet/http.(persistConn).readLoop(0xc00036aea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 567 [select]:\nnet/http.(persistConn).readLoop(0xc000270a20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 568 [select]:\nnet/http.(persistConn).writeLoop(0xc000270a20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 335 [select]:\nnet/http.(persistConn).writeLoop(0xc000193e60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 552 [select]:\nnet/http.(persistConn).readLoop(0xc000270b40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 332 [select]:\nnet/http.(persistConn).readLoop(0xc000193d40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 333 [select]:\nnet/http.(persistConn).writeLoop(0xc000193d40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 611 [select]:\nnet/http.(persistConn).readLoop(0xc000270fc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 334 [select]:\nnet/http.(persistConn).readLoop(0xc000193e60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 578 [select]:\nnet/http.(persistConn).readLoop(0xc000270c60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 579 [select]:\nnet/http.(persistConn).writeLoop(0xc000270c60)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 558 [select]:\nnet/http.(persistConn).readLoop(0xc000270d80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 559 [select]:\nnet/http.(persistConn).writeLoop(0xc000270d80)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 587 [select]:\nnet/http.(persistConn).writeLoop(0xc00036b0e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 569 [select]:\nnet/http.(persistConn).readLoop(0xc000270ea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 584 [select]:\nnet/http.(persistConn).readLoop(0xc00036afc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 585 [select]:\nnet/http.(persistConn).writeLoop(0xc00036afc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 573 [select]:\nnet/http.(persistConn).readLoop(0xc000516000)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 574 [select]:\nnet/http.(persistConn).writeLoop(0xc000516000)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 586 [select]:\nnet/http.(persistConn).readLoop(0xc00036b0e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 596 [select]:\nnet/http.(persistConn).readLoop(0xc000516120)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 597 [select]:\nnet/http.(persistConn).writeLoop(0xc000516120)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 589 [select]:\nnet/http.(persistConn).writeLoop(0xc00036b200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 600 [select]:\nnet/http.(persistConn).readLoop(0xc000516240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 601 [select]:\nnet/http.(persistConn).writeLoop(0xc000516240)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 614 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a66c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 588 [select]:\nnet/http.(persistConn).readLoop(0xc00036b200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 612 [select]:\nnet/http.(persistConn).writeLoop(0xc000270fc0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 616 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a67e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 613 [select]:\nnet/http.(persistConn).readLoop(0xc0002a66c0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 630 [select]:\nnet/http.(persistConn).writeLoop(0xc00036b560)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 615 [select]:\nnet/http.(persistConn).readLoop(0xc0002a67e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 627 [select]:\nnet/http.(persistConn).readLoop(0xc00036b320)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 628 [select]:\nnet/http.(persistConn).writeLoop(0xc00036b320)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 622 [select]:\nnet/http.(persistConn).writeLoop(0xc000271200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 619 [select]:\nnet/http.(persistConn).readLoop(0xc0002710e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 620 [select]:\nnet/http.(persistConn).writeLoop(0xc0002710e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 836 [select]:\nnet/http.(Transport).getConn(0xc0008e4900, 0xc0002fadb0, 0x0, 0xc000751700, 0x5, 0xc00048b6c1, 0xf, 0x0, 0x0, 0xc0004d1ee0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1004 +0x58e\nnet/http.(Transport).roundTrip(0xc0008e4900, 0xc000169a00, 0x203000, 0xc0008f3a60, 0x127daca)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:451 +0x690\nnet/http.(Transport).RoundTrip(0xc0008e4900, 0xc000169a00, 0xc0008e4900, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/roundtrip.go:17 +0x35\nnet/http.send(0xc000169a00, 0x1426340, 0xc0008e4900, 0x0, 0x0, 0x0, 0xc000290120, 0xc0002fac30, 0xc0008f3af0, 0x1)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:250 +0x14b\nnet/http.(Client).send(0xc0003fe000, 0xc000169a00, 0x0, 0x0, 0x0, 0xc000290120, 0x0, 0x1, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:174 +0xfa\nnet/http.(Client).do(0xc0003fe000, 0xc000169a00, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:641 +0x2a8\nnet/http.(Client).Do(0xc0003fe000, 0xc000169a00, 0xc000751700, 0x17, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:509 +0x35\nnet/http.(Client).Get(0xc0003fe000, 0xc000751700, 0x17, 0x100e95d, 0x13aa860, 0xc00008d040)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:398 +0x9d\ngithub.com/fabiolb/fabio/cert.roundtrip(0x13c7cce, 0x9, 0xc00083ca80, 0xc0003fe000, 0x0, 0x0, 0x0, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source_test.go:600 +0x124\ngithub.com/fabiolb/fabio/cert.testSource.func2(0xc0003fe000, 0x13c84b4, 0xb)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source_test.go:562 +0x67\ngithub.com/fabiolb/fabio/cert.testSource(0xc000169700, 0x1428000, 0xc0001ad020, 0xc0001c8330, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source_test.go:575 +0x310\ngithub.com/fabiolb/fabio/cert.TestVaultPKISource.func1(0xc000169700)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source_test.go:512 +0x1af\ntesting.tRunner(0xc000169700, 0xc000576190)\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:827 +0xbf\ncreated by testing.(T).Run\n    /usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:878 +0x353\ngoroutine 621 [select]:\nnet/http.(persistConn).readLoop(0xc000271200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 644 [select]:\nnet/http.(persistConn).readLoop(0xc00036b440)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 645 [select]:\nnet/http.(persistConn).writeLoop(0xc00036b440)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 632 [select]:\nnet/http.(persistConn).writeLoop(0xc00036b680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 629 [select]:\nnet/http.(persistConn).readLoop(0xc00036b560)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 631 [select]:\nnet/http.(persistConn).readLoop(0xc00036b680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 661 [select]:\nnet/http.(persistConn).readLoop(0xc0002a6900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1761 +0x6b9\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 662 [select]:\nnet/http.(persistConn).writeLoop(0xc0002a6900)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 816 [select]:\nnet/http.(persistConn).roundTrip(0xc00036b9e0, 0xc000996ab0, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:2101 +0x56a\nnet/http.(Transport).roundTrip(0xc0002a7200, 0xc0001dae00, 0xc000996a80, 0xc0008a5c88, 0xc0008a5c90)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:465 +0x9b1\nnet/http.(Transport).RoundTrip(0xc0002a7200, 0xc0001dae00, 0xc0002a7200, 0xbede2fd4acfefb60, 0x1172b1f751)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/roundtrip.go:17 +0x35\nnet/http.send(0xc0001dad00, 0x1426340, 0xc0002a7200, 0xbede2fd4acfefb60, 0x1172b1f751, 0x167ec00, 0xc00000e100, 0xbede2fd4acfefb60, 0xc000882888, 0x1)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:250 +0x14b\nnet/http.(Client).send(0xc0001c8ab0, 0xc0001dad00, 0xbede2fd4acfefb60, 0x1172b1f751, 0x167ec00, 0xc00000e100, 0x0, 0x1, 0x1)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:174 +0xfa\nnet/http.(Client).do(0xc0001c8ab0, 0xc0001dad00, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:641 +0x2a8\nnet/http.(Client).Do(0xc0001c8ab0, 0xc0001dad00, 0x0, 0x0, 0xc000761110)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:509 +0x35\ngithub.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api.(Client).RawRequest(0xc0002da960, 0xc0007610a0, 0xc000996930, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api/client.go:277 +0x7d\ngithub.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api.(Logical).Write(0xc000882cc8, 0x13cbed1, 0x14, 0xc000996930, 0x0, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api/logical.go:62 +0x10f\ngithub.com/fabiolb/fabio/cert.(VaultPKISource).Issue(0xc00040a5a0, 0xc00001bab7, 0x9, 0x1, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_pki_source.go:62 +0x208\ngithub.com/fabiolb/fabio/cert.(VaultPKISource).Issue.func1()\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_pki_source.go:114 +0x58\ncreated by time.goFunc\n    /usr/local/Cellar/go/1.11/libexec/src/time/sleep.go:172 +0x44\ngoroutine 840 [chan receive]:\nnet/http.(persistConn).addTLS(0xc0002a6c60, 0xc00048b6c1, 0x9, 0x0, 0xc00048b6cb, 0x5)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1177 +0x1a7\nnet/http.(Transport).dialConn(0xc0008e4900, 0x142a000, 0xc000090008, 0x0, 0xc000751700, 0x5, 0xc00048b6c1, 0xf, 0x0, 0xc0004af5c0, ...)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1250 +0x15ad\nnet/http.(Transport).getConn.func4(0xc0008e4900, 0x142a000, 0xc000090008, 0xc0002fae40, 0xc0004af7a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:999 +0x6e\ncreated by net/http.(Transport).getConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:998 +0x3d7\ngoroutine 898 [select]:\nnet/http.(persistConn).writeLoop(0xc00036b9e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 846 [select]:\nnet/http.setRequestCancel.func3(0x0, 0xc0004cb1d0, 0xc00074bd60, 0xc000791890, 0xc000309200)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:321 +0xcf\ncreated by net/http.setRequestCancel\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:320 +0x24e\ngoroutine 855 [select]:\nnet/http.(persistConn).writeLoop(0xc000271680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 750 [chan receive]:\ngithub.com/fabiolb/fabio/cert.TLSConfig.func2(0x1428000, 0xc000386f60, 0xc000165bd0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:145 +0xa7\ncreated by github.com/fabiolb/fabio/cert.TLSConfig\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:144 +0x1fa\ngoroutine 689 [chan receive]:\ngithub.com/fabiolb/fabio/cert.(vaultClient).keepTokenAlive(0xc0004ca420)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_client.go:118 +0x219\ncreated by github.com/fabiolb/fabio/cert.(vaultClient).Get\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_client.go:70 +0x276\ngoroutine 849 [IO wait]:\ninternal/poll.runtime_pollWait(0x1b56088, 0x72, 0xc000882a88)\n    /usr/local/Cellar/go/1.11/libexec/src/runtime/netpoll.go:173 +0x66\ninternal/poll.(pollDesc).wait(0xc00047aa98, 0x72, 0xffffffffffffff00, 0x14273c0, 0x1644588)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:85 +0x9a\ninternal/poll.(pollDesc).waitRead(0xc00047aa98, 0xc000a0c000, 0x1000, 0x1000)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\ninternal/poll.(FD).Read(0xc00047aa80, 0xc000a0c000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_unix.go:169 +0x1d6\nnet.(netFD).Read(0xc00047aa80, 0xc000a0c000, 0x1000, 0x1000, 0xf, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/fd_unix.go:202 +0x4f\nnet.(conn).Read(0xc0003c9740, 0xc000a0c000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/net.go:177 +0x68\nnet/http.(persistConn).Read(0xc00036b9e0, 0xc000a0c000, 0x1000, 0x1000, 0x100649f, 0xc0006e9c70, 0x102c092)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1497 +0x75\nbufio.(Reader).fill(0xc0000b7bc0)\n    /usr/local/Cellar/go/1.11/libexec/src/bufio/bufio.go:100 +0x106\nbufio.(Reader).Peek(0xc0000b7bc0, 0x1, 0xc000077020, 0xc0006e9d58, 0x1, 0x13cc900, 0x5)\n    /usr/local/Cellar/go/1.11/libexec/src/bufio/bufio.go:132 +0x3f\nnet/http.(persistConn).readLoop(0xc00036b9e0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1645 +0x1a2\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 656 [chan receive]:\ngithub.com/fabiolb/fabio/cert.TLSConfig.func2(0x1428000, 0xc00040a5a0, 0xc00048c480)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:145 +0xa7\ncreated by github.com/fabiolb/fabio/cert.TLSConfig\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:144 +0x1fa\ngoroutine 883 [select]:\nnet/http.setRequestCancel.func3(0x0, 0xc000996a80, 0xc0009a0410, 0xc0008a5c88, 0xc0000768a0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:321 +0xcf\ncreated by net/http.setRequestCancel\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:320 +0x24e\ngoroutine 852 [IO wait]:\ninternal/poll.runtime_pollWait(0x1b56228, 0x72, 0xc000555940)\n    /usr/local/Cellar/go/1.11/libexec/src/runtime/netpoll.go:173 +0x66\ninternal/poll.(pollDesc).wait(0xc0003cfe98, 0x72, 0xffffffffffffff00, 0x14273c0, 0x1644588)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:85 +0x9a\ninternal/poll.(pollDesc).waitRead(0xc0003cfe98, 0xc000973800, 0x400, 0x400)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\ninternal/poll.(FD).Read(0xc0003cfe80, 0xc000973800, 0x400, 0x400, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_unix.go:169 +0x1d6\nnet.(netFD).Read(0xc0003cfe80, 0xc000973800, 0x400, 0x400, 0xc000973800, 0x0, 0x400)\n    /usr/local/Cellar/go/1.11/libexec/src/net/fd_unix.go:202 +0x4f\nnet.(conn).Read(0xc00000e120, 0xc000973800, 0x400, 0x400, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/net.go:177 +0x68\ncrypto/tls.(block).readFromUntil(0xc000376a20, 0x1b14000, 0xc00000e120, 0x5, 0xc00000e120, 0x119bb1f)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/conn.go:492 +0x89\ncrypto/tls.(Conn).readRecord(0xc0008e2a80, 0x13e0116, 0xc000555c90, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/conn.go:593 +0xdd\ncrypto/tls.(Conn).readHandshake(0xc0008e2a80, 0xc000946816, 0xc000946820, 0x9b, 0x9b)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/conn.go:955 +0x9a\ncrypto/tls.(clientHandshakeState).handshake(0xc000555e80, 0xc0009388c0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/handshake_client.go:191 +0xaa\ncrypto/tls.(Conn).clientHandshake(0xc0008e2a80, 0x13e0158, 0xc0008e2ba0)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/handshake_client.go:168 +0x397\ncrypto/tls.(Conn).Handshake(0xc0008e2a80, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/conn.go:1272 +0xf1\nnet/http.(persistConn).addTLS.func2(0x0, 0xc0008e2a80, 0x0, 0xc0002ad860)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1171 +0x42\ncreated by net/http.(*persistConn).addTLS\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1167 +0x17e\ngoroutine 868 [chan receive]:\ngithub.com/fabiolb/fabio/cert.TLSConfig.func2(0x1428000, 0xc0001ad020, 0xc000165440)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:145 +0xa7\ncreated by github.com/fabiolb/fabio/cert.TLSConfig\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:144 +0x1fa\ngoroutine 881 [IO wait]:\ninternal/poll.runtime_pollWait(0x1b55d48, 0x72, 0xc00058ea88)\n    /usr/local/Cellar/go/1.11/libexec/src/runtime/netpoll.go:173 +0x66\ninternal/poll.(pollDesc).wait(0xc0003ce698, 0x72, 0xffffffffffffff00, 0x14273c0, 0x1644588)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:85 +0x9a\ninternal/poll.(pollDesc).waitRead(0xc0003ce698, 0xc0009b2000, 0x1000, 0x1000)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\ninternal/poll.(FD).Read(0xc0003ce680, 0xc0009b2000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_unix.go:169 +0x1d6\nnet.(netFD).Read(0xc0003ce680, 0xc0009b2000, 0x1000, 0x1000, 0xf, 0x17b0f10, 0x1058720)\n    /usr/local/Cellar/go/1.11/libexec/src/net/fd_unix.go:202 +0x4f\nnet.(conn).Read(0xc00000e0b8, 0xc0009b2000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/net.go:177 +0x68\nnet/http.(persistConn).Read(0xc0008e5d40, 0xc0009b2000, 0x1000, 0x1000, 0x100649f, 0xc00058ec70, 0x102c092)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1497 +0x75\nbufio.(Reader).fill(0xc000074b40)\n    /usr/local/Cellar/go/1.11/libexec/src/bufio/bufio.go:100 +0x106\nbufio.(Reader).Peek(0xc000074b40, 0x1, 0xc00014c000, 0xc0006ead58, 0xc0003d1cc0, 0xc0003d1c80, 0xc0000bfae0)\n    /usr/local/Cellar/go/1.11/libexec/src/bufio/bufio.go:132 +0x3f\nnet/http.(persistConn).readLoop(0xc0008e5d40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1645 +0x1a2\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 869 [IO wait]:\ninternal/poll.runtime_pollWait(0x1b562f8, 0x72, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/runtime/netpoll.go:173 +0x66\ninternal/poll.(pollDesc).wait(0xc000470e18, 0x72, 0xc000503600, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:85 +0x9a\ninternal/poll.(pollDesc).waitRead(0xc000470e18, 0xffffffffffffff00, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\ninternal/poll.(FD).Accept(0xc000470e00, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_unix.go:384 +0x1a0\nnet.(netFD).accept(0xc000470e00, 0xc000553ea0, 0x12c7860, 0xc0003867c4)\n    /usr/local/Cellar/go/1.11/libexec/src/net/fd_unix.go:238 +0x42\nnet.(TCPListener).accept(0xc0003c9768, 0xc0b79a8000, 0xc000386780, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/tcpsock_posix.go:139 +0x2e\nnet.(TCPListener).Accept(0xc0003c9768, 0xc0195d7c08, 0x195d7c0800553ea0, 0x5b984796, 0xc000553ea0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/tcpsock.go:260 +0x47\ncrypto/tls.(listener).Accept(0xc0004d1fe0, 0xc000553ef0, 0x18, 0xc00083d500, 0x128d835)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/tls.go:52 +0x37\nnet/http.(Server).Serve(0xc00008d110, 0x1429a80, 0xc0004d1fe0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/server.go:2826 +0x22f\nnet/http/httptest.(Server).goServe.func1(0xc000386780)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/httptest/server.go:280 +0x6d\ncreated by net/http/httptest.(Server).goServe\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/httptest/server.go:278 +0x5c\ngoroutine 870 [select]:\nnet/http.(persistConn).roundTrip(0xc0008e5d40, 0xc0004cb200, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:2101 +0x56a\nnet/http.(Transport).roundTrip(0xc0008e4ea0, 0xc00086a300, 0xc0004cb1d0, 0xc000791890, 0xc000791884)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:465 +0x9b1\nnet/http.(Transport).RoundTrip(0xc0008e4ea0, 0xc00086a300, 0xc0008e4ea0, 0xbede2fd4a2826190, 0x11683570f8)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/roundtrip.go:17 +0x35\nnet/http.send(0xc00086a000, 0x1426340, 0xc0008e4ea0, 0xbede2fd4a2826190, 0x11683570f8, 0x167ec00, 0xc0003c9738, 0xbede2fd4a2826190, 0xc000ad71b8, 0x1)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:250 +0x14b\nnet/http.(Client).send(0xc0003fe9c0, 0xc00086a000, 0xbede2fd4a2826190, 0x11683570f8, 0x167ec00, 0xc0003c9738, 0x0, 0x1, 0x1)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:174 +0xfa\nnet/http.(Client).do(0xc0003fe9c0, 0xc00086a000, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:641 +0x2a8\nnet/http.(Client).Do(0xc0003fe9c0, 0xc00086a000, 0x0, 0x0, 0xc000741650)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:509 +0x35\ngithub.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api.(Client).RawRequest(0xc000996360, 0xc0007415e0, 0xc0004caff0, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api/client.go:277 +0x7d\ngithub.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api.(Logical).Write(0xc000ad75f8, 0x13cbed1, 0x14, 0xc0004caff0, 0x0, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api/logical.go:62 +0x10f\ngithub.com/fabiolb/fabio/cert.(VaultPKISource).Issue(0xc0001ad020, 0xc00060a880, 0x9, 0xd0, 0x1389b60, 0x1)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_pki_source.go:62 +0x208\ngithub.com/fabiolb/fabio/cert.TLSConfig.func1.1(0x1013f12, 0x1389b60, 0xc00008d520, 0x8e5d3469277c884d)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:129 +0x41\ngithub.com/fabiolb/fabio/vendor/golang.org/x/sync/singleflight.(Group).doCall(0xc0001653d0, 0xc00065e190, 0xc00060a880, 0x9, 0xc0009b1a08)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/vendor/golang.org/x/sync/singleflight/singleflight.go:93 +0x2e\ngithub.com/fabiolb/fabio/vendor/golang.org/x/sync/singleflight.(Group).Do(0xc0001653d0, 0xc00060a880, 0x9, 0xc0009b1a08, 0xc0001ad020, 0xc0009b1a01, 0x0, 0x1426120, 0xc0000870f0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/vendor/golang.org/x/sync/singleflight/singleflight.go:63 +0x142\ngithub.com/fabiolb/fabio/cert.TLSConfig.func1(0xc00089c210, 0xc0009b1a78, 0x100dd88, 0xb0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/source.go:128 +0x212\ncrypto/tls.(Config).getCertificate(0xc00083d200, 0xc00089c210, 0xc000751820, 0x20, 0x20)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/common.go:726 +0x30f\ncrypto/tls.(serverHandshakeState).readClientHello(0xc000ad7c50, 0xc0009b1c40, 0xf, 0x8)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/handshake_server.go:217 +0x3bc\ncrypto/tls.(Conn).serverHandshake(0xc000878a80, 0x13e0158, 0xc000878ba0)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/handshake_server.go:47 +0xb6\ncrypto/tls.(Conn).Handshake(0xc000878a80, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/crypto/tls/conn.go:1274 +0x177\nnet/http.(conn).serve(0xc000824280, 0x142a080, 0xc0003fe930)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/server.go:1762 +0x187\ncreated by net/http.(*Server).Serve\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/server.go:2851 +0x2f5\ngoroutine 914 [select]:\nnet/http.setRequestCancel.func3(0x0, 0xc0009ac300, 0xc0009c0140, 0xc0006cc17c, 0xc000292a20)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:321 +0xcf\ncreated by net/http.setRequestCancel\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:320 +0x24e\ngoroutine 845 [chan receive]:\ngithub.com/fabiolb/fabio/cert.(vaultClient).keepTokenAlive(0xc000273f20)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_client.go:118 +0x219\ncreated by github.com/fabiolb/fabio/cert.(vaultClient).Get\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_client.go:70 +0x276\ngoroutine 854 [IO wait]:\ninternal/poll.runtime_pollWait(0x1b55fb8, 0x72, 0xc000511a88)\n    /usr/local/Cellar/go/1.11/libexec/src/runtime/netpoll.go:173 +0x66\ninternal/poll.(pollDesc).wait(0xc000116518, 0x72, 0xffffffffffffff00, 0x14273c0, 0x1644588)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:85 +0x9a\ninternal/poll.(pollDesc).waitRead(0xc000116518, 0xc000a34000, 0x1000, 0x1000)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d\ninternal/poll.(FD).Read(0xc000116500, 0xc000a34000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/internal/poll/fd_unix.go:169 +0x1d6\nnet.(netFD).Read(0xc000116500, 0xc000a34000, 0x1000, 0x1000, 0xf, 0xc0001113bc, 0xc00011139c)\n    /usr/local/Cellar/go/1.11/libexec/src/net/fd_unix.go:202 +0x4f\nnet.(conn).Read(0xc00009c020, 0xc000a34000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/net.go:177 +0x68\nnet/http.(persistConn).Read(0xc000271680, 0xc000a34000, 0x1000, 0x1000, 0x100649f, 0xc000111470, 0x102c092)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1497 +0x75\nbufio.(Reader).fill(0xc0000f91a0)\n    /usr/local/Cellar/go/1.11/libexec/src/bufio/bufio.go:100 +0x106\nbufio.(Reader).Peek(0xc0000f91a0, 0x1, 0xc00014c1e0, 0xc000111558, 0x1, 0x13cc900, 0x5)\n    /usr/local/Cellar/go/1.11/libexec/src/bufio/bufio.go:132 +0x3f\nnet/http.(persistConn).readLoop(0xc000271680)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1645 +0x1a2\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1338 +0x941\ngoroutine 882 [select]:\nnet/http.(persistConn).writeLoop(0xc0008e5d40)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1885 +0x113\ncreated by net/http.(Transport).dialConn\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1339 +0x966\ngoroutine 817 [select]:\nnet/http.(persistConn).roundTrip(0xc000271680, 0xc0009ac330, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:2101 +0x56a\nnet/http.(Transport).roundTrip(0xc0008e4000, 0xc000168300, 0xc0009ac300, 0xc0006cc17c, 0xc0006cc170)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:465 +0x9b1\nnet/http.(Transport).RoundTrip(0xc0008e4000, 0xc000168300, 0xc0008e4000, 0xbede2fd4b0e0dcf8, 0x117693d275)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/roundtrip.go:17 +0x35\nnet/http.send(0xc000168200, 0x1426340, 0xc0008e4000, 0xbede2fd4b0e0dcf8, 0x117693d275, 0x167ec00, 0xc000290038, 0xbede2fd4b0e0dcf8, 0xc000590888, 0x1)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:250 +0x14b\nnet/http.(Client).send(0xc0003ff020, 0xc000168200, 0xbede2fd4b0e0dcf8, 0x117693d275, 0x167ec00, 0xc000290038, 0x0, 0x1, 0x1)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:174 +0xfa\nnet/http.(Client).do(0xc0003ff020, 0xc000168200, 0x0, 0x0, 0x0)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:641 +0x2a8\nnet/http.(Client).Do(0xc0003ff020, 0xc000168200, 0x0, 0x0, 0xc000a30070)\n    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:509 +0x35\ngithub.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api.(Client).RawRequest(0xc0004cb110, 0xc000a30000, 0xc0009ac1b0, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api/client.go:277 +0x7d\ngithub.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api.(Logical).Write(0xc000590cc8, 0x13cbed1, 0x14, 0xc0009ac1b0, 0x0, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/vendor/github.com/hashicorp/vault/api/logical.go:62 +0x10f\ngithub.com/fabiolb/fabio/cert.(VaultPKISource).Issue(0xc000386f60, 0xc000621730, 0x9, 0x1, 0x0, 0x0)\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_pki_source.go:62 +0x208\ngithub.com/fabiolb/fabio/cert.(VaultPKISource).Issue.func1()\n    /Volumes/git/gopath/src/github.com/fabiolb/fabio/cert/vault_pki_source.go:114 +0x58\ncreated by time.goFunc\n    /usr/local/Cellar/go/1.11/libexec/src/time/sleep.go:172 +0x44\nFAIL    github.com/fabiolb/fabio/cert   15.128s\n=== RUN   TestParseFlags\n=== RUN   TestParseFlags/cmdline_should_win\n=== RUN   TestParseFlags/env_should_win\n=== RUN   TestParseFlags/env_with_prefix_should_win\n=== RUN   TestParseFlags/props_should_win\n=== RUN   TestParseFlags/string_slice_in_cmdline\n=== RUN   TestParseFlags/string_slice_in_env\n=== RUN   TestParseFlags/string_slice_in_props\n--- PASS: TestParseFlags (0.00s)\n    --- PASS: TestParseFlags/cmdline_should_win (0.00s)\n    --- PASS: TestParseFlags/env_should_win (0.00s)\n    --- PASS: TestParseFlags/env_with_prefix_should_win (0.00s)\n    --- PASS: TestParseFlags/props_should_win (0.00s)\n    --- PASS: TestParseFlags/string_slice_in_cmdline (0.00s)\n    --- PASS: TestParseFlags/string_slice_in_env (0.00s)\n    --- PASS: TestParseFlags/string_slice_in_props (0.00s)\n=== RUN   TestDefaults\n--- PASS: TestDefaults (0.00s)\n=== RUN   TestParseKVSlice\n=== RUN   TestParseKVSlice/empty\n=== RUN   TestParseKVSlice/key=val\n=== RUN   TestParseKVSlice/key_with_spaces\n=== RUN   TestParseKVSlice/quoted_value\n=== RUN   TestParseKVSlice/single_quoted_value\n=== RUN   TestParseKVSlice/quoted_value_with_backslash\n=== RUN   TestParseKVSlice/ignore_empty_map_front\n=== RUN   TestParseKVSlice/ignore_empty_map_back\n=== RUN   TestParseKVSlice/ignore_empty_value_front\n=== RUN   TestParseKVSlice/ignore_empty_value_back\n=== RUN   TestParseKVSlice/multiple_values\n=== RUN   TestParseKVSlice/multiple_maps\n=== RUN   TestParseKVSlice/multiple_values_and_maps\n=== RUN   TestParseKVSlice/first_key_empty\n=== RUN   TestParseKVSlice/first_key_empty_and_more_values\n=== RUN   TestParseKVSlice/first_key_empty_and_more_maps\n=== RUN   TestParseKVSlice/first_key_empty_and_more_maps_and_values\n=== RUN   TestParseKVSlice/issue_305\n=== RUN   TestParseKVSlice/issue_305#01\n=== RUN   TestParseKVSlice/issue_305#02\n--- PASS: TestParseKVSlice (0.00s)\n    --- PASS: TestParseKVSlice/empty (0.00s)\n    --- PASS: TestParseKVSlice/key=val (0.00s)\n    --- PASS: TestParseKVSlice/key_with_spaces (0.00s)\n    --- PASS: TestParseKVSlice/quoted_value (0.00s)\n    --- PASS: TestParseKVSlice/single_quoted_value (0.00s)\n    --- PASS: TestParseKVSlice/quoted_value_with_backslash (0.00s)\n    --- PASS: TestParseKVSlice/ignore_empty_map_front (0.00s)\n    --- PASS: TestParseKVSlice/ignore_empty_map_back (0.00s)\n    --- PASS: TestParseKVSlice/ignore_empty_value_front (0.00s)\n    --- PASS: TestParseKVSlice/ignore_empty_value_back (0.00s)\n    --- PASS: TestParseKVSlice/multiple_values (0.00s)\n    --- PASS: TestParseKVSlice/multiple_maps (0.00s)\n    --- PASS: TestParseKVSlice/multiple_values_and_maps (0.00s)\n    --- PASS: TestParseKVSlice/first_key_empty (0.00s)\n    --- PASS: TestParseKVSlice/first_key_empty_and_more_values (0.00s)\n    --- PASS: TestParseKVSlice/first_key_empty_and_more_maps (0.00s)\n    --- PASS: TestParseKVSlice/first_key_empty_and_more_maps_and_values (0.00s)\n    --- PASS: TestParseKVSlice/issue_305 (0.00s)\n    --- PASS: TestParseKVSlice/issue_305#01 (0.00s)\n    --- PASS: TestParseKVSlice/issue_305#02 (0.00s)\n=== RUN   TestLoad\n=== RUN   TestLoad/-v\n=== RUN   TestLoad/--version\n=== RUN   TestLoad/-v_with_other_args\n=== RUN   TestLoad/--version_with_other_args\n=== RUN   TestLoad/default_config\n=== RUN   TestLoad/-insecure=true\n=== RUN   TestLoad/-profile.mode_foo\n=== RUN   TestLoad/-profile.path_foo\n=== RUN   TestLoad/-proxy.addr_:5555\n=== RUN   TestLoad/-proxy.addr_:5555;proto=http\n=== RUN   TestLoad/-proxy.addr_:5555;proto=tcp\n=== RUN   TestLoad/-proxy.addr_:5555;proto=tcp+sni\n=== RUN   TestLoad/-proxy.addr_with_tls_configs\n=== RUN   TestLoad/-proxy.addr_with_named_tls_configs\n=== RUN   TestLoad/-proxy.addr_with_file_cert_source\n=== RUN   TestLoad/-proxy.addr_with_path_cert_source\n=== RUN   TestLoad/-proxy.addr_with_http_cert_source\n=== RUN   TestLoad/-proxy.addr_with_consul_cert_source\n=== RUN   TestLoad/-proxy.addr_with_vault_cert_source\n=== RUN   TestLoad/-proxy.addr_with_vault-pki_cert_source\n2018/09/12 08:51:43 [INFO] vault-pki requires strictmatch; enabling strictmatch for listener :5555\n=== RUN   TestLoad/-proxy.addr_with_vault-pki_cert_source,-proxy.cs_first\n2018/09/12 08:51:43 [INFO] vault-pki requires strictmatch; enabling strictmatch for listener :5555\n=== RUN   TestLoad/-proxy.addr_with_cert_source\n=== RUN   TestLoad/-proxy.addr_with_cert_source_with_full_options\n=== RUN   TestLoad/issue_305\n=== RUN   TestLoad/-proxy.localip_1.2.3.4\n=== RUN   TestLoad/-proxy.strategy_rnd\n=== RUN   TestLoad/-proxy.strategy_rr\n=== RUN   TestLoad/-proxy.matcher_prefix\n=== RUN   TestLoad/-proxy.matcher_glob\n=== RUN   TestLoad/-proxy.noroutestatus_555\n=== RUN   TestLoad/-proxy.shutdownwait_5ms\n=== RUN   TestLoad/-proxy.responseheadertimeout_5ms\n=== RUN   TestLoad/-proxy.keepalivetimeout_5ms\n=== RUN   TestLoad/-proxy.dialtimeout_5ms\n=== RUN   TestLoad/-proxy.readtimeout_5ms\n=== RUN   TestLoad/-proxy.writetimeout_5ms\n=== RUN   TestLoad/-proxy.flushinterval_5ms\n=== RUN   TestLoad/-proxy.maxconn_555\n=== RUN   TestLoad/-proxy.header.clientip_value\n=== RUN   TestLoad/-proxy.header.tls_value\n=== RUN   TestLoad/-proxy.header.tls.value_value\n=== RUN   TestLoad/-proxy.header.requestid_value\n=== RUN   TestLoad/-proxy.header.sts.maxage_31536000\n=== RUN   TestLoad/-proxy.header.sts.subdomains_true\n=== RUN   TestLoad/-proxy.header.sts.preload_true\n=== RUN   TestLoad/-proxy.gzip.contenttype^text/.$\n=== RUN   TestLoad/-proxy.gzip.contenttype_^(text/.|application/(javascript|json|font-woff|xml)|.+(json|xml))(;.)?$\n=== RUN   TestLoad/-proxy.log.routes_foobar\n2018/09/12 08:51:43 [WARN] proxy.log.routes has been deprecated. Please use 'log.routes.format' instead\n=== RUN   TestLoad/-registry.backend_value\n=== RUN   TestLoad/-registry.timeout_5s\n=== RUN   TestLoad/-registry.retry_500ms\n=== RUN   TestLoad/-registry.file.path_value\n=== RUN   TestLoad/-registry.file.noroutehtmlpath_value\n=== RUN   TestLoad/-registry.static.routes_value\n=== RUN   TestLoad/-registry.static.noroutehtml_value\n=== RUN   TestLoad/-registry.consul.addr_1.2.3.4:5555\n=== RUN   TestLoad/-registry.consul.addr_http://1.2.3.4:5555/\n=== RUN   TestLoad/-registry.consul.addr_https://1.2.3.4:5555/\n=== RUN   TestLoad/-registry.consul.addr_HTTPS://1.2.3.4:5555/\n=== RUN   TestLoad/-registry.consul.token_some-token\n=== RUN   TestLoad/-registry.consul.kvpath_/some/path\n=== RUN   TestLoad/-registry.consul.noroutehtmlpath_/some/path\n=== RUN   TestLoad/-registry.consul.tagprefix_p-\n=== RUN   TestLoad/-registry.consul.register.enabled=false\n=== RUN   TestLoad/-registry.consul.register.addr_1.2.3.4:5555\n=== RUN   TestLoad/-registry.consul.register.name_fab\n=== RUN   TestLoad/-registry.consul.register.checkTLSSkipVerify=true\n=== RUN   TestLoad/-registry.consul.register.tags_a,b,_c,\n=== RUN   TestLoad/-registry.consul.register.checkInterval_5ms\n=== RUN   TestLoad/-registry.consul.register.checkTimeout_5ms\n=== RUN   TestLoad/-registry.consul.service.status_a,b,\n=== RUN   TestLoad/-log.access.format_foobar\n=== RUN   TestLoad/-log.access.target_foobar\n=== RUN   TestLoad/-log.routes.format_foobar\n=== RUN   TestLoad/-log.level_foobar\n=== RUN   TestLoad/-metrics.target_some-target\n=== RUN   TestLoad/-metrics.prefix_some-prefix\n=== RUN   TestLoad/-metrics.names_some_names\n=== RUN   TestLoad/-metrics.interval_5ms\n=== RUN   TestLoad/-metrics.timeout_5s\n=== RUN   TestLoad/-metrics.retry_500ms\n=== RUN   TestLoad/-metrics.graphite.addr_1.2.3.4:5555\n=== RUN   TestLoad/-metrics.statsd.addr_1.2.3.4:5555\n=== RUN   TestLoad/-metrics.circonus.apiapp_value\n=== RUN   TestLoad/-metrics.circonus.apikey_value\n=== RUN   TestLoad/-metrics.circonus.apiurl_value\n=== RUN   TestLoad/-metrics.circonus.brokerid_value\n=== RUN   TestLoad/-metrics.circonus.checkid_value\n=== RUN   TestLoad/-runtime.gogc_555\n=== RUN   TestLoad/-runtime.gomaxprocs_555\n=== RUN   TestLoad/-ui.access_ro\n=== RUN   TestLoad/-ui.access_rw\n=== RUN   TestLoad/-ui.addr_1.2.3.4:5555\n=== RUN   TestLoad/-ui.addr_:9998;cs=ui_-proxy.cs_cs=ui;type=file;cert=value\n=== RUN   TestLoad/-ui.color_value\n=== RUN   TestLoad/-ui.title_value\n=== RUN   TestLoad/ignore_aws.apigw.cert.cn\n=== RUN   TestLoad/config_from_environ\n=== RUN   TestLoad/config_from_url\n=== RUN   TestLoad/config_from_file_I\n=== RUN   TestLoad/config_from_file_II\n=== RUN   TestLoad/config_from_file_III\n=== RUN   TestLoad/config_from_file_IV\n=== RUN   TestLoad/cmdline_over_config_file_I\n=== RUN   TestLoad/cmdline_over_config_file_II\n=== RUN   TestLoad/environ_over_config_file\n=== RUN   TestLoad/cmdline_over_environ\n=== RUN   TestLoad/-proxy.addr_with_unknown_cert_source_'foo'\n=== RUN   TestLoad/-proxy.addr_with_unknown_proto_'foo'\n=== RUN   TestLoad/-proxy.addr_with_proto_'https'requires_cert_source\n=== RUN   TestLoad/-proxy.addr_with_cert_source_and_proto'http'requires_proto'https'or'tcp'\n=== RUN   TestLoad/-proxy.addr_with_cert_source_and_proto_'tcp+sni'requires_proto'https'or'tcp'\n=== RUN   TestLoad/-proxy.noroutestatus_too_small\n=== RUN   TestLoad/-proxy.noroutestatus_too_big\n=== RUN   TestLoad/-cfg\n=== RUN   TestLoad/-cfg=''\n=== RUN   TestLoad/-cfg=\"\"\n--- PASS: TestLoad (0.06s)\n    --- PASS: TestLoad/-v (0.00s)\n    --- PASS: TestLoad/--version (0.00s)\n    --- PASS: TestLoad/-v_with_other_args (0.00s)\n    --- PASS: TestLoad/--version_with_other_args (0.00s)\n    --- PASS: TestLoad/default_config (0.00s)\n    --- PASS: TestLoad/-insecure=true (0.00s)\n    --- PASS: TestLoad/-profile.mode_foo (0.00s)\n    --- PASS: TestLoad/-profile.path_foo (0.00s)\n    --- PASS: TestLoad/-proxy.addr_:5555 (0.00s)\n    --- PASS: TestLoad/-proxy.addr_:5555;proto=http (0.00s)\n    --- PASS: TestLoad/-proxy.addr_:5555;proto=tcp (0.00s)\n    --- PASS: TestLoad/-proxy.addr_:5555;proto=tcp+sni (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_tls_configs (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_named_tls_configs (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_file_cert_source (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_path_cert_source (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_http_cert_source (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_consul_cert_source (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_vault_cert_source (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_vault-pki_cert_source (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_vault-pki_cert_source,-proxy.cs_first (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_cert_source (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_cert_source_with_full_options (0.00s)\n    --- PASS: TestLoad/issue_305 (0.00s)\n    --- PASS: TestLoad/-proxy.localip_1.2.3.4 (0.00s)\n    --- PASS: TestLoad/-proxy.strategy_rnd (0.00s)\n    --- PASS: TestLoad/-proxy.strategy_rr (0.00s)\n    --- PASS: TestLoad/-proxy.matcher_prefix (0.00s)\n    --- PASS: TestLoad/-proxy.matcher_glob (0.00s)\n    --- PASS: TestLoad/-proxy.noroutestatus_555 (0.00s)\n    --- PASS: TestLoad/-proxy.shutdownwait_5ms (0.00s)\n    --- PASS: TestLoad/-proxy.responseheadertimeout_5ms (0.00s)\n    --- PASS: TestLoad/-proxy.keepalivetimeout_5ms (0.00s)\n    --- PASS: TestLoad/-proxy.dialtimeout_5ms (0.00s)\n    --- PASS: TestLoad/-proxy.readtimeout_5ms (0.00s)\n    --- PASS: TestLoad/-proxy.writetimeout_5ms (0.00s)\n    --- PASS: TestLoad/-proxy.flushinterval_5ms (0.00s)\n    --- PASS: TestLoad/-proxy.maxconn_555 (0.00s)\n    --- PASS: TestLoad/-proxy.header.clientip_value (0.00s)\n    --- PASS: TestLoad/-proxy.header.tls_value (0.00s)\n    --- PASS: TestLoad/-proxy.header.tls.value_value (0.00s)\n    --- PASS: TestLoad/-proxy.header.requestid_value (0.00s)\n    --- PASS: TestLoad/-proxy.header.sts.maxage_31536000 (0.00s)\n    --- PASS: TestLoad/-proxy.header.sts.subdomains_true (0.00s)\n    --- PASS: TestLoad/-proxy.header.sts.preload_true (0.00s)\n    --- PASS: TestLoad/-proxy.gzip.contenttype^text/.$ (0.00s)\n    --- PASS: TestLoad/-proxy.gzip.contenttype_^(text/.|application/(javascript|json|font-woff|xml)|.+(json|xml))(;.)?$ (0.00s)\n    --- PASS: TestLoad/-proxy.log.routes_foobar (0.00s)\n    --- PASS: TestLoad/-registry.backend_value (0.00s)\n    --- PASS: TestLoad/-registry.timeout_5s (0.00s)\n    --- PASS: TestLoad/-registry.retry_500ms (0.00s)\n    --- PASS: TestLoad/-registry.file.path_value (0.00s)\n    --- PASS: TestLoad/-registry.file.noroutehtmlpath_value (0.00s)\n    --- PASS: TestLoad/-registry.static.routes_value (0.00s)\n    --- PASS: TestLoad/-registry.static.noroutehtml_value (0.00s)\n    --- PASS: TestLoad/-registry.consul.addr_1.2.3.4:5555 (0.00s)\n    --- PASS: TestLoad/-registry.consul.addr_http://1.2.3.4:5555/ (0.00s)\n    --- PASS: TestLoad/-registry.consul.addr_https://1.2.3.4:5555/ (0.00s)\n    --- PASS: TestLoad/-registry.consul.addr_HTTPS://1.2.3.4:5555/ (0.00s)\n    --- PASS: TestLoad/-registry.consul.token_some-token (0.00s)\n    --- PASS: TestLoad/-registry.consul.kvpath_/some/path (0.00s)\n    --- PASS: TestLoad/-registry.consul.noroutehtmlpath_/some/path (0.00s)\n    --- PASS: TestLoad/-registry.consul.tagprefix_p- (0.00s)\n    --- PASS: TestLoad/-registry.consul.register.enabled=false (0.00s)\n    --- PASS: TestLoad/-registry.consul.register.addr_1.2.3.4:5555 (0.00s)\n    --- PASS: TestLoad/-registry.consul.register.name_fab (0.00s)\n    --- PASS: TestLoad/-registry.consul.register.checkTLSSkipVerify=true (0.00s)\n    --- PASS: TestLoad/-registry.consul.register.tags_a,b,_c, (0.00s)\n    --- PASS: TestLoad/-registry.consul.register.checkInterval_5ms (0.00s)\n    --- PASS: TestLoad/-registry.consul.register.checkTimeout_5ms (0.00s)\n    --- PASS: TestLoad/-registry.consul.service.status_a,b, (0.00s)\n    --- PASS: TestLoad/-log.access.format_foobar (0.01s)\n    --- PASS: TestLoad/-log.access.target_foobar (0.00s)\n    --- PASS: TestLoad/-log.routes.format_foobar (0.00s)\n    --- PASS: TestLoad/-log.level_foobar (0.00s)\n    --- PASS: TestLoad/-metrics.target_some-target (0.00s)\n    --- PASS: TestLoad/-metrics.prefix_some-prefix (0.00s)\n    --- PASS: TestLoad/-metrics.names_some_names (0.00s)\n    --- PASS: TestLoad/-metrics.interval_5ms (0.00s)\n    --- PASS: TestLoad/-metrics.timeout_5s (0.00s)\n    --- PASS: TestLoad/-metrics.retry_500ms (0.00s)\n    --- PASS: TestLoad/-metrics.graphite.addr_1.2.3.4:5555 (0.00s)\n    --- PASS: TestLoad/-metrics.statsd.addr_1.2.3.4:5555 (0.00s)\n    --- PASS: TestLoad/-metrics.circonus.apiapp_value (0.00s)\n    --- PASS: TestLoad/-metrics.circonus.apikey_value (0.00s)\n    --- PASS: TestLoad/-metrics.circonus.apiurl_value (0.00s)\n    --- PASS: TestLoad/-metrics.circonus.brokerid_value (0.00s)\n    --- PASS: TestLoad/-metrics.circonus.checkid_value (0.00s)\n    --- PASS: TestLoad/-runtime.gogc_555 (0.00s)\n    --- PASS: TestLoad/-runtime.gomaxprocs_555 (0.00s)\n    --- PASS: TestLoad/-ui.access_ro (0.00s)\n    --- PASS: TestLoad/-ui.access_rw (0.00s)\n    --- PASS: TestLoad/-ui.addr_1.2.3.4:5555 (0.00s)\n    --- PASS: TestLoad/-ui.addr_:9998;cs=ui_-proxy.cs_cs=ui;type=file;cert=value (0.00s)\n    --- PASS: TestLoad/-ui.color_value (0.00s)\n    --- PASS: TestLoad/-ui.title_value (0.00s)\n    --- PASS: TestLoad/ignore_aws.apigw.cert.cn (0.00s)\n    --- PASS: TestLoad/config_from_environ (0.00s)\n    --- PASS: TestLoad/config_from_url (0.00s)\n    --- PASS: TestLoad/config_from_file_I (0.00s)\n    --- PASS: TestLoad/config_from_file_II (0.00s)\n    --- PASS: TestLoad/config_from_file_III (0.00s)\n    --- PASS: TestLoad/config_from_file_IV (0.00s)\n    --- PASS: TestLoad/cmdline_over_config_file_I (0.00s)\n    --- PASS: TestLoad/cmdline_over_config_file_II (0.00s)\n    --- PASS: TestLoad/environ_over_config_file (0.00s)\n    --- PASS: TestLoad/cmdline_over_environ (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_unknown_cert_source_'foo' (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_unknown_proto_'foo' (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_proto_'https'requires_cert_source (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_cert_source_and_proto'http'requires_proto'https'or'tcp' (0.00s)\n    --- PASS: TestLoad/-proxy.addr_with_cert_source_and_proto_'tcp+sni'requires_proto'https'or'tcp' (0.00s)\n    --- PASS: TestLoad/-proxy.noroutestatus_too_small (0.00s)\n    --- PASS: TestLoad/-proxy.noroutestatus_too_big (0.00s)\n    --- PASS: TestLoad/-cfg (0.00s)\n    --- PASS: TestLoad/-cfg='' (0.00s)\n    --- PASS: TestLoad/-cfg=\"\" (0.00s)\nPASS\nok      github.com/fabiolb/fabio/config (cached)\n?       github.com/fabiolb/fabio/demo/server    [no test files]\n?       github.com/fabiolb/fabio/demo/wsclient  [no test files]\n=== RUN   TestExit\n--- PASS: TestExit (0.00s)\nPASS\nok      github.com/fabiolb/fabio/exit   0.065s\n=== RUN   TestLevelWriter\n=== RUN   TestLevelWriter/TRACE\n=== RUN   TestLevelWriter/DEBUG\n=== RUN   TestLevelWriter/INFO\n=== RUN   TestLevelWriter/WARN\n=== RUN   TestLevelWriter/ERROR\n=== RUN   TestLevelWriter/FATAL\n--- PASS: TestLevelWriter (0.00s)\n    --- PASS: TestLevelWriter/TRACE (0.00s)\n    --- PASS: TestLevelWriter/DEBUG (0.00s)\n    --- PASS: TestLevelWriter/INFO (0.00s)\n    --- PASS: TestLevelWriter/WARN (0.00s)\n    --- PASS: TestLevelWriter/ERROR (0.00s)\n    --- PASS: TestLevelWriter/FATAL (0.00s)\n=== RUN   TestParse\n--- PASS: TestParse (0.00s)\n=== RUN   TestLog\n=== RUN   TestLog/$header.Referer\n=== RUN   TestLog/$header.X-Forwarded-For\n=== RUN   TestLog/$header.user-agent\n=== RUN   TestLog/$remote_addr\n=== RUN   TestLog/$remote_host\n=== RUN   TestLog/$remote_port\n=== RUN   TestLog/$request\n=== RUN   TestLog/$request_args\n=== RUN   TestLog/$request_host\n=== RUN   TestLog/$request_method\n=== RUN   TestLog/$request_proto\n=== RUN   TestLog/$request_scheme\n=== RUN   TestLog/$request_uri\n=== RUN   TestLog/$request_url\n=== RUN   TestLog/$response_body_size\n=== RUN   TestLog/$response_status\n=== RUN   TestLog/$response_time_ms\n=== RUN   TestLog/$response_time_ns\n=== RUN   TestLog/$response_time_us\n=== RUN   TestLog/$time_common\n=== RUN   TestLog/$time_rfc3339\n=== RUN   TestLog/$time_rfc3339_ms\n=== RUN   TestLog/$time_rfc3339_ns\n=== RUN   TestLog/$time_rfc3339_us\n=== RUN   TestLog/$time_unix_ms\n=== RUN   TestLog/$time_unix_ns\n=== RUN   TestLog/$time_unix_us\n=== RUN   TestLog/$upstream_addr\n=== RUN   TestLog/$upstream_host\n=== RUN   TestLog/$upstream_port\n=== RUN   TestLog/$upstream_request_scheme\n=== RUN   TestLog/$upstream_request_uri\n=== RUN   TestLog/$upstream_request_url\n=== RUN   TestLog/$upstream_service\n--- PASS: TestLog (0.00s)\n    --- PASS: TestLog/$header.Referer (0.00s)\n    --- PASS: TestLog/$header.X-Forwarded-For (0.00s)\n    --- PASS: TestLog/$header.user-agent (0.00s)\n    --- PASS: TestLog/$remote_addr (0.00s)\n    --- PASS: TestLog/$remote_host (0.00s)\n    --- PASS: TestLog/$remote_port (0.00s)\n    --- PASS: TestLog/$request (0.00s)\n    --- PASS: TestLog/$request_args (0.00s)\n    --- PASS: TestLog/$request_host (0.00s)\n    --- PASS: TestLog/$request_method (0.00s)\n    --- PASS: TestLog/$request_proto (0.00s)\n    --- PASS: TestLog/$request_scheme (0.00s)\n    --- PASS: TestLog/$request_uri (0.00s)\n    --- PASS: TestLog/$request_url (0.00s)\n    --- PASS: TestLog/$response_body_size (0.00s)\n    --- PASS: TestLog/$response_status (0.00s)\n    --- PASS: TestLog/$response_time_ms (0.00s)\n    --- PASS: TestLog/$response_time_ns (0.00s)\n    --- PASS: TestLog/$response_time_us (0.00s)\n    --- PASS: TestLog/$time_common (0.00s)\n    --- PASS: TestLog/$time_rfc3339 (0.00s)\n    --- PASS: TestLog/$time_rfc3339_ms (0.00s)\n    --- PASS: TestLog/$time_rfc3339_ns (0.00s)\n    --- PASS: TestLog/$time_rfc3339_us (0.00s)\n    --- PASS: TestLog/$time_unix_ms (0.00s)\n    --- PASS: TestLog/$time_unix_ns (0.00s)\n    --- PASS: TestLog/$time_unix_us (0.00s)\n    --- PASS: TestLog/$upstream_addr (0.00s)\n    --- PASS: TestLog/$upstream_host (0.00s)\n    --- PASS: TestLog/$upstream_port (0.00s)\n    --- PASS: TestLog/$upstream_request_scheme (0.00s)\n    --- PASS: TestLog/$upstream_request_uri (0.00s)\n    --- PASS: TestLog/$upstream_request_url (0.00s)\n    --- PASS: TestLog/$upstream_service (0.00s)\n=== RUN   TestAtoi\n--- PASS: TestAtoi (0.00s)\nPASS\nok      github.com/fabiolb/fabio/logger (cached)\n=== RUN   TestRegistry\n--- PASS: TestRegistry (0.00s)\n    circonus_test.go:12: Testing registry interface\n    circonus_test.go:16:    Names()\n    circonus_test.go:22:    Unregister()\n    circonus_test.go:25:    UnregisterAll()\n    circonus_test.go:28:    GetTimer()\n=== RUN   TestTimer\n--- PASS: TestTimer (0.00s)\n    circonus_test.go:36: Testing timer interface\n    circonus_test.go:40:    Percentile()\n    circonus_test.go:46:    Rate1()\n=== RUN   TestAll\n--- SKIP: TestAll (0.00s)\n    circonus_test.go:57: skipping test; $CIRCONUS_API_TOKEN not set\n=== RUN   TestParsePrefix\n--- PASS: TestParsePrefix (0.00s)\n=== RUN   TestTargetName\n--- PASS: TestTargetName (0.00s)\nPASS\nok      github.com/fabiolb/fabio/metrics    (cached)\n=== RUN   TestStoreSetGet\n--- PASS: TestStoreSetGet (0.00s)\nPASS\nok      github.com/fabiolb/fabio/noroute    (cached)\n=== RUN   TestAddHeaders\n=== RUN   TestAddHeaders/error\n=== RUN   TestAddHeaders/http_request\n=== RUN   TestAddHeaders/https_request\n=== RUN   TestAddHeaders/ws_request\n=== RUN   TestAddHeaders/wss_request\n=== RUN   TestAddHeaders/set_client_ip_header\n=== RUN   TestAddHeaders/set_Forwarded_with_localIP\n=== RUN   TestAddHeaders/set_Forwarded_with_localIP_for_https\n=== RUN   TestAddHeaders/set_httpproto,tlsver_and_tlscipher_on_Forwarded_for_https\n=== RUN   TestAddHeaders/set_httpproto_on_Forwarded\n=== RUN   TestAddHeaders/extend_Forwarded_with_localIP\n=== RUN   TestAddHeaders/set_tls_header\n=== RUN   TestAddHeaders/set_tls_header_with_value\n=== RUN   TestAddHeaders/overwrite_tls_header_for_https,_when_set\n=== RUN   TestAddHeaders/drop_tls_header_for_http,_when_set\n=== RUN   TestAddHeaders/do_not_overwrite_X-Forwarded-Proto,_if_present\n=== RUN   TestAddHeaders/set_scheme_from_X-Forwarded-Proto,_if_present_and_Forwarded_is_missing\n=== RUN   TestAddHeaders/set_scheme_from_Forwarded,_if_present_and_X-Forwarded-Proto_is_missing\n=== RUN   TestAddHeaders/do_not_modify_scheme_when_both_Forwarded_and_X-Forwarded-Proto_are_present\n=== RUN   TestAddHeaders/set_X-Forwarded-Port_from_Host\n=== RUN   TestAddHeaders/set_X-Forwarded-Port_from_Host_for_https\n=== RUN   TestAddHeaders/do_not_overwrite_X-Forwarded-Port_header,_if_present\n=== RUN   TestAddHeaders/set_X-Forwarded-Host_from_Host\n=== RUN   TestAddHeaders/do_not_overwrite_X-Forwarded-Host,_if_present\n=== RUN   TestAddHeaders/do_not_overwrite_X-Real-Ip,_if_present\n--- PASS: TestAddHeaders (0.00s)\n    --- PASS: TestAddHeaders/error (0.00s)\n    --- PASS: TestAddHeaders/http_request (0.00s)\n    --- PASS: TestAddHeaders/https_request (0.00s)\n    --- PASS: TestAddHeaders/ws_request (0.00s)\n    --- PASS: TestAddHeaders/wss_request (0.00s)\n    --- PASS: TestAddHeaders/set_client_ip_header (0.00s)\n    --- PASS: TestAddHeaders/set_Forwarded_with_localIP (0.00s)\n    --- PASS: TestAddHeaders/set_Forwarded_with_localIP_for_https (0.00s)\n    --- PASS: TestAddHeaders/set_httpproto,_tlsver_and_tlscipher_on_Forwarded_for_https (0.00s)\n    --- PASS: TestAddHeaders/set_httpproto_on_Forwarded (0.00s)\n    --- PASS: TestAddHeaders/extend_Forwarded_with_localIP (0.00s)\n    --- PASS: TestAddHeaders/set_tls_header (0.00s)\n    --- PASS: TestAddHeaders/set_tls_header_with_value (0.00s)\n    --- PASS: TestAddHeaders/overwrite_tls_header_for_https,_when_set (0.00s)\n    --- PASS: TestAddHeaders/drop_tls_header_for_http,_when_set (0.00s)\n    --- PASS: TestAddHeaders/do_not_overwrite_X-Forwarded-Proto,_if_present (0.00s)\n    --- PASS: TestAddHeaders/set_scheme_from_X-Forwarded-Proto,_if_present_and_Forwarded_is_missing (0.00s)\n    --- PASS: TestAddHeaders/set_scheme_from_Forwarded,_if_present_and_X-Forwarded-Proto_is_missing (0.00s)\n    --- PASS: TestAddHeaders/do_not_modify_scheme_when_both_Forwarded_and_X-Forwarded-Proto_are_present (0.00s)\n    --- PASS: TestAddHeaders/set_X-Forwarded-Port_from_Host (0.00s)\n    --- PASS: TestAddHeaders/set_X-Forwarded-Port_from_Host_for_https (0.00s)\n    --- PASS: TestAddHeaders/do_not_overwrite_X-Forwarded-Port_header,_if_present (0.00s)\n    --- PASS: TestAddHeaders/set_X-Forwarded-Host_from_Host (0.00s)\n    --- PASS: TestAddHeaders/do_not_overwrite_X-Forwarded-Host,_if_present (0.00s)\n    --- PASS: TestAddHeaders/do_not_overwrite_X-Real-Ip,_if_present (0.00s)\n=== RUN   TestAddResponseHeaders\n=== RUN   TestAddResponseHeaders/set_Strict-Transport-Security_for_TLS,_if_MaxAge_greater_than_0\n=== RUN   TestAddResponseHeaders/set_Strict-Transport-Security_for_TLS,_if_MaxAge_greater_than_0_with_options\n=== RUN   TestAddResponseHeaders/skip_Strict-Transport-Security_for_non-TLS,_if_MaxAge_greater_than_0\n--- PASS: TestAddResponseHeaders (0.00s)\n    --- PASS: TestAddResponseHeaders/set_Strict-Transport-Security_for_TLS,_if_MaxAge_greater_than_0 (0.00s)\n    --- PASS: TestAddResponseHeaders/set_Strict-Transport-Security_for_TLS,_if_MaxAge_greater_than_0_with_options (0.00s)\n    --- PASS: TestAddResponseHeaders/skip_Strict-Transport-Security_for_non-TLS,_if_MaxAge_greater_than_0 (0.00s)\n=== RUN   TestLocalPort\n--- PASS: TestLocalPort (0.00s)\n=== RUN   TestUint16Base16\n--- PASS: TestUint16Base16 (0.00s)\n=== RUN   TestProxyProducesCorrectXForwardedSomethingHeader\n--- PASS: TestProxyProducesCorrectXForwardedSomethingHeader (0.01s)\n=== RUN   TestProxyRequestIDHeader\n--- PASS: TestProxyRequestIDHeader (0.00s)\n=== RUN   TestProxySTSHeader\n--- PASS: TestProxySTSHeader (0.00s)\n=== RUN   TestProxyChecksHeaderForAccessRules\n2018/09/12 08:51:46 [INFO] route rules denied access from 1.2.3.4 to http://127.0.0.1:50550\n--- PASS: TestProxyChecksHeaderForAccessRules (0.00s)\n=== RUN   TestProxyNoRouteHTML\n--- PASS: TestProxyNoRouteHTML (0.00s)\n=== RUN   TestProxyNoRouteStatus\n--- PASS: TestProxyNoRouteStatus (0.00s)\n=== RUN   TestProxyStripsPath\n--- PASS: TestProxyStripsPath (0.00s)\n=== RUN   TestProxyHost\n=== RUN   TestProxyHost/host_eq_dst\n=== RUN   TestProxyHost/no_host\n=== RUN   TestProxyHost/host_is_custom\n--- PASS: TestProxyHost (0.01s)\n    --- PASS: TestProxyHost/host_eq_dst (0.00s)\n    --- PASS: TestProxyHost/no_host (0.00s)\n    --- PASS: TestProxyHost/host_is_custom (0.00s)\n=== RUN   TestHostRedirect\n--- PASS: TestHostRedirect (0.00s)\n=== RUN   TestPathRedirect\n--- PASS: TestPathRedirect (0.00s)\n=== RUN   TestProxyLogOutput\n=== RUN   TestProxyLogOutput/uncompressed_response\n=== RUN   TestProxyLogOutput/compression_enabled_but_no_match\n=== RUN   TestProxyLogOutput/compression_enabled_and_active\n--- PASS: TestProxyLogOutput (0.01s)\n    --- PASS: TestProxyLogOutput/uncompressed_response (0.00s)\n    --- PASS: TestProxyLogOutput/compression_enabled_but_no_match (0.00s)\n    --- PASS: TestProxyLogOutput/compression_enabled_and_active (0.00s)\n=== RUN   TestProxyHTTPSUpstream\n--- PASS: TestProxyHTTPSUpstream (0.00s)\n=== RUN   TestProxyHTTPSUpstreamSkipVerify\n--- PASS: TestProxyHTTPSUpstreamSkipVerify (0.00s)\n=== RUN   TestProxyGzipHandler\n=== RUN   TestProxyGzipHandler/plain_body-compressed_response\n=== RUN   TestProxyGzipHandler/plain_body-compressed_response(with_charset)\n=== RUN   TestProxyGzipHandler/compressed_body_-compressed_response\n=== RUN   TestProxyGzipHandler/plain_body-plain_response\n=== RUN   TestProxyGzipHandler/compressed_body-plain_response\n=== RUN   TestProxyGzipHandler/plain_body-plain_response(no_match)\n--- PASS: TestProxyGzipHandler (0.02s)\n    --- PASS: TestProxyGzipHandler/plain_body_-compressed_response (0.00s)\n    --- PASS: TestProxyGzipHandler/plain_body-compressed_response(with_charset) (0.01s)\n    --- PASS: TestProxyGzipHandler/compressed_body_-compressed_response (0.00s)\n    --- PASS: TestProxyGzipHandler/plain_body-plain_response (0.00s)\n    --- PASS: TestProxyGzipHandler/compressed_body-plain_response (0.00s)\n    --- PASS: TestProxyGzipHandler/plain_body-plain_response(no_match) (0.00s)\n=== RUN   TestGracefulShutdown\n--- PASS: TestGracefulShutdown (0.11s)\n    listen_test.go:40: ListenAndServeHTTP:  http: Server closed\n=== RUN   TestTCPProxy\n--- PASS: TestTCPProxy (0.00s)\n    tcp_integration_test.go:52: ListenAndServeTCP:  accept tcp 127.0.0.1:57778: use of closed network connection\n=== RUN   TestTCPProxyWithTLS\n2018/09/12 08:51:46 [INFO] cert: Store has certificates for [\"example.com\"]\n--- PASS: TestTCPProxyWithTLS (0.26s)\n=== RUN   TestTCPSNIProxy\n--- PASS: TestTCPSNIProxy (0.11s)\n    tcp_integration_test.go:159: ListenAndServeTCP:  accept tcp 127.0.0.1:57778: use of closed network connection\n=== RUN   TestProxyWSUpstream\n=== RUN   TestProxyWSUpstream/ws-ws_direct\n=== RUN   TestProxyWSUpstream/wss-wss_direct\n=== RUN   TestProxyWSUpstream/ws-ws_via_http_proxy\n=== RUN   TestProxyWSUpstream/wss-ws_via_https_proxy\n=== RUN   TestProxyWSUpstream/ws-wss_via_http_proxy\n=== RUN   TestProxyWSUpstream/wss-wss_via_https_proxy\n=== RUN   TestProxyWSUpstream/ws-wss_tlsskipverify=true_via_http_proxy\n=== RUN   TestProxyWSUpstream/wss-wss_tlsskipverify=true_via_https_proxy\n=== RUN   TestProxyWSUpstream/ws-ws_via_http_proxy_with_gzip\n=== RUN   TestProxyWSUpstream/ws-ws_via_http_proxy_with_strip\n--- PASS: TestProxyWSUpstream (0.05s)\n    ws_integration_test.go:28: Started WS server:  http://127.0.0.1:50628\n    ws_integration_test.go:34: Started WSS server:  https://127.0.0.1:50629\n    ws_integration_test.go:51: Started HTTP proxy:  http://127.0.0.1:50630\n    ws_integration_test.go:65: Started HTTPS proxy:  https://127.0.0.1:50631\n    --- PASS: TestProxyWSUpstream/ws-ws_direct (0.00s)\n    --- PASS: TestProxyWSUpstream/wss-wss_direct (0.00s)\n    --- PASS: TestProxyWSUpstream/ws-ws_via_http_proxy (0.00s)\n    --- PASS: TestProxyWSUpstream/wss-ws_via_https_proxy (0.00s)\n    --- PASS: TestProxyWSUpstream/ws-wss_via_http_proxy (0.00s)\n    --- PASS: TestProxyWSUpstream/wss-wss_via_https_proxy (0.01s)\n    --- PASS: TestProxyWSUpstream/ws-wss_tlsskipverify=true_via_http_proxy (0.00s)\n    --- PASS: TestProxyWSUpstream/wss-wss_tlsskipverify=true_via_https_proxy (0.01s)\n    --- PASS: TestProxyWSUpstream/ws-ws_via_http_proxy_with_gzip (0.00s)\n    --- PASS: TestProxyWSUpstream/ws-ws_via_http_proxy_with_strip (0.00s)\nPASS\nok      github.com/fabiolb/fabio/proxy  (cached)\n=== RUN   TestContentTypes\n=== RUN   TestContentTypes/text/foo\n=== RUN   TestContentTypes/text/foo;charset=UTF-8\n=== RUN   TestContentTypes/text/plain\n=== RUN   TestContentTypes/text/plain;_charset=UTF-8\n=== RUN   TestContentTypes/application/json\n=== RUN   TestContentTypes/application/json;_charset=UTF-8\n=== RUN   TestContentTypes/application/javascript\n=== RUN   TestContentTypes/application/javascript;_charset=UTF-8\n=== RUN   TestContentTypes/application/font-woff\n=== RUN   TestContentTypes/application/font-woff;_charset=UTF-8\n=== RUN   TestContentTypes/application/xml\n=== RUN   TestContentTypes/application/xml;_charset=UTF-8\n=== RUN   TestContentTypes/vendor/vendor.foo+json\n=== RUN   TestContentTypes/vendor/vendor.foo+json;_charset=UTF-8\n=== RUN   TestContentTypes/vendor/vendor.foo+xml\n=== RUN   TestContentTypes/vendor/vendor.foo+xml;_charset=UTF-8\n--- PASS: TestContentTypes (0.00s)\n    --- PASS: TestContentTypes/text/foo (0.00s)\n    --- PASS: TestContentTypes/text/foo;_charset=UTF-8 (0.00s)\n    --- PASS: TestContentTypes/text/plain (0.00s)\n    --- PASS: TestContentTypes/text/plain;_charset=UTF-8 (0.00s)\n    --- PASS: TestContentTypes/application/json (0.00s)\n    --- PASS: TestContentTypes/application/json;_charset=UTF-8 (0.00s)\n    --- PASS: TestContentTypes/application/javascript (0.00s)\n    --- PASS: TestContentTypes/application/javascript;_charset=UTF-8 (0.00s)\n    --- PASS: TestContentTypes/application/font-woff (0.00s)\n    --- PASS: TestContentTypes/application/font-woff;_charset=UTF-8 (0.00s)\n    --- PASS: TestContentTypes/application/xml (0.00s)\n    --- PASS: TestContentTypes/application/xml;_charset=UTF-8 (0.00s)\n    --- PASS: TestContentTypes/vendor/vendor.foo+json (0.00s)\n    --- PASS: TestContentTypes/vendor/vendor.foo+json;_charset=UTF-8 (0.00s)\n    --- PASS: TestContentTypes/vendor/vendor.foo+xml (0.00s)\n    --- PASS: TestContentTypes/vendor/vendor.foo+xml;_charset=UTF-8 (0.00s)\n=== RUN   Test_GzipHandler_CompressableType\n--- PASS: Test_GzipHandler_CompressableType (0.00s)\n=== RUN   Test_GzipHandler_NotCompressingTwice\n--- PASS: Test_GzipHandler_NotCompressingTwice (0.00s)\n=== RUN   Test_GzipHandler_CompressableType_NoAccept\n--- PASS: Test_GzipHandler_CompressableType_NoAccept (0.00s)\n=== RUN   Test_GzipHandler_NonCompressableType\n--- PASS: Test_GzipHandler_NonCompressableType (0.00s)\nPASS\nok      github.com/fabiolb/fabio/proxy/gzip (cached)\n?       github.com/fabiolb/fabio/proxy/internal [no test files]\n=== RUN   TestClientHelloBufferSize\n=== RUN   TestClientHelloBufferSize/valid_data\n=== RUN   TestClientHelloBufferSize/not_enough_data\n=== RUN   TestClientHelloBufferSize/not_a_TLS_record\n=== RUN   TestClientHelloBufferSize/TLS_record_too_large\n=== RUN   TestClientHelloBufferSize/TLS_record_length_zero\n=== RUN   TestClientHelloBufferSize/Not_a_client_hello\n=== RUN   TestClientHelloBufferSize/Invalid_handshake_message_record_length\n=== RUN   TestClientHelloBufferSize/Fragmentation(handshake_message_larger_than_record)\n--- PASS: TestClientHelloBufferSize (0.00s)\n    --- PASS: TestClientHelloBufferSize/valid_data (0.00s)\n    --- PASS: TestClientHelloBufferSize/not_enough_data (0.00s)\n    --- PASS: TestClientHelloBufferSize/not_a_TLS_record (0.00s)\n    --- PASS: TestClientHelloBufferSize/TLS_record_too_large (0.00s)\n    --- PASS: TestClientHelloBufferSize/TLS_record_length_zero (0.00s)\n    --- PASS: TestClientHelloBufferSize/Not_a_client_hello (0.00s)\n    --- PASS: TestClientHelloBufferSize/Invalid_handshake_message_record_length (0.00s)\n    --- PASS: TestClientHelloBufferSize/Fragmentation_(handshake_message_larger_than_record) (0.00s)\n=== RUN   TestReadServerName\n=== RUN   TestReadServerName/valid_client_hello_with_server_name\n=== RUN   TestReadServerName/valid_client_hello_but_no_server_name_extension\n=== RUN   TestReadServerName/invalid_client_hello\n--- PASS: TestReadServerName (0.00s)\n    --- PASS: TestReadServerName/valid_client_hello_with_server_name (0.00s)\n    --- PASS: TestReadServerName/valid_client_hello_but_no_server_name_extension (0.00s)\n    --- PASS: TestReadServerName/invalid_client_hello (0.00s)\nPASS\nok      github.com/fabiolb/fabio/proxy/tcp  (cached)\n?       github.com/fabiolb/fabio/proxy/tcp/tcptest  [no test files]\n?       github.com/fabiolb/fabio/registry   [no test files]\n=== RUN   TestParseTag\n2018/09/12 08:51:48 [WARN] consul: Invalid p- tag \"\" - You need to have a trailing slash!\n2018/09/12 08:51:48 [WARN] consul: Invalid p- tag \"\" - You need to have a trailing slash!\n--- PASS: TestParseTag (0.00s)\n=== RUN   TestPassingServices\n=== RUN   TestPassingServices/expect_no_passing_checks_if_checks_array_is_nil\n=== RUN   TestPassingServices/expect_no_passing_checks_if_checks_array_is_empty\n=== RUN   TestPassingServices/expect_check_to_pass_if_it_has_a_matching_status\n=== RUN   TestPassingServices/expect_all_checks_to_pass_if_they_have_a_matching_status\n=== RUN   TestPassingServices/expect_that_internal_consul_checks_are_filtered_out\n=== RUN   TestPassingServices/expect_no_passing_checks_if_consul_agent_is_unhealthy\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"\" since agent on node \"node\" is down:\n=== RUN   TestPassingServices/expect_no_passing_checks_if_node_is_in_maintenance_mode\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"\" since node \"node\" is in maintenance mode:\n=== RUN   TestPassingServices/expect_no_passing_check_if_corresponding_service_is_in_maintenance_mode\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"abc-1\" since it is in maintenance mode:\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"abc-1\" since it is in maintenance mode:\n=== RUN   TestPassingServices/expect_no_passing_check_if_node_and_service_are_in_maintenance_mode\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"\" since node \"node\" is in maintenance mode:\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"\" since node \"node\" is in maintenance mode:\n=== RUN   TestPassingServices/expect_no_passing_check_if_agent_is_unhealthy_or_node_and_service_are_in_maintenance_mode\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"\" since agent on node \"node\" is down:\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"\" since agent on node \"node\" is down:\n=== RUN   TestPassingServices/expect_check_of_service_which_is_not_in_maintenance_mode_to_pass_if_another_instance_of_same_service_is_in_maintenance_mode\n=== RUN   TestPassingServices/expect_that_no_checks_of_a_service_which_is_in_maintenance_mode_are_returned_even_if_it_has_a_passing_check\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"abc-1\" since it is in maintenance mode:\n2018/09/12 08:51:48 [DEBUG] consul: Skipping service \"abc-1\" since it is in maintenance mode:\n=== RUN   TestPassingServices/expect_that_a_service's_failing_check_does_not_affect_a_healthy_instance_of_same_service_running_on_different_node\n=== RUN   TestPassingServices/service_in_maintenance_mode_does_not_affect_healthy_service_running_on_different_node\n=== RUN   TestPassingServices/expect_that_internal_consul_check_and_failing_check_are_not_returned\n=== RUN   TestPassingServices/expect_that_internal_consul_check_is_filtered_out_and_check_with_warning_is_passing\n=== RUN   TestPassingServices/expect_that_warning_and_passing_non-internal_checks_are_returned\n=== RUN   TestPassingServices/expect_that_warning_und_passing_non-internal_checks_are_returned\n=== RUN   TestPassingServices/in_non-strict_mode,expect_that_checks_which_belong_to_same_service_are_passing,_if_at_least_one_of_them_is_passing\n=== RUN   TestPassingServices/in_strict_mode,_expect_that_no_checks_which_belong_to_same_service_are_passing,_if_not_all_of_them_are_passing\n=== RUN   TestPassingServices/in_strict_mode,_expect_that_a_failing_check_of_one_service_does_not_affect_a_different_service's_passing_check\n=== RUN   TestPassingServices/in_strict_mode,_expect_a_check_to_pass_if_all_of_the_other_checks_that_belong_to_the_same_service_are_passing\n--- PASS: TestPassingServices (0.00s)\n    --- PASS: TestPassingServices/expect_no_passing_checks_if_checks_array_is_nil (0.00s)\n    --- PASS: TestPassingServices/expect_no_passing_checks_if_checks_array_is_empty (0.00s)\n    --- PASS: TestPassingServices/expect_check_to_pass_if_it_has_a_matching_status (0.00s)\n    --- PASS: TestPassingServices/expect_all_checks_to_pass_if_they_have_a_matching_status (0.00s)\n    --- PASS: TestPassingServices/expect_that_internal_consul_checks_are_filtered_out (0.00s)\n    --- PASS: TestPassingServices/expect_no_passing_checks_if_consul_agent_is_unhealthy (0.00s)\n    --- PASS: TestPassingServices/expect_no_passing_checks_if_node_is_in_maintenance_mode (0.00s)\n    --- PASS: TestPassingServices/expect_no_passing_check_if_corresponding_service_is_in_maintenance_mode (0.00s)\n    --- PASS: TestPassingServices/expect_no_passing_check_if_node_and_service_are_in_maintenance_mode (0.00s)\n    --- PASS: TestPassingServices/expect_no_passing_check_if_agent_is_unhealthy_or_node_and_service_are_in_maintenance_mode (0.00s)\n    --- PASS: TestPassingServices/expect_check_of_service_which_is_not_in_maintenance_mode_to_pass_if_another_instance_of_same_service_is_in_maintenance_mode (0.00s)\n    --- PASS: TestPassingServices/expect_that_no_checks_of_a_service_which_is_in_maintenance_mode_are_returned_even_if_it_has_a_passing_check (0.00s)\n    --- PASS: TestPassingServices/expect_that_a_service's_failing_check_does_not_affect_a_healthy_instance_of_same_service_running_on_different_node (0.00s)\n    --- PASS: TestPassingServices/service_in_maintenance_mode_does_not_affect_healthy_service_running_on_different_node (0.00s)\n    --- PASS: TestPassingServices/expect_that_internal_consul_check_and_failing_check_are_not_returned (0.00s)\n    --- PASS: TestPassingServices/expect_that_internal_consul_check_is_filtered_out_and_check_with_warning_is_passing (0.00s)\n    --- PASS: TestPassingServices/expect_that_warning_and_passing_non-internal_checks_are_returned (0.00s)\n    --- PASS: TestPassingServices/expect_that_warning_und_passing_non-internal_checks_are_returned (0.00s)\n    --- PASS: TestPassingServices/in_non-strict_mode,_expect_that_checks_which_belong_to_same_service_are_passing,_if_at_least_one_of_them_is_passing (0.00s)\n    --- PASS: TestPassingServices/in_strict_mode,_expect_that_no_checks_which_belong_to_same_service_are_passing,_if_not_all_of_them_are_passing (0.00s)\n    --- PASS: TestPassingServices/in_strict_mode,_expect_that_a_failing_check_of_one_service_does_not_affect_a_different_service's_passing_check (0.00s)\n    --- PASS: TestPassingServices/in_strict_mode,_expect_a_check_to_pass_if_all_of_the_other_checks_that_belong_to_the_same_service_are_passing (0.00s)\nPASS\nok      github.com/fabiolb/fabio/registry/consul    (cached)\n?       github.com/fabiolb/fabio/registry/file  [no test files]\n?       github.com/fabiolb/fabio/registry/static    [no test files]\n=== RUN   TestAccessRules_parseAccessRule\n=== RUN   TestAccessRules_parseAccessRule/valid_ipv4_rule\n=== RUN   TestAccessRules_parseAccessRule/valid_ipv6_rule\n=== RUN   TestAccessRules_parseAccessRule/invalid_rule_type\n=== RUN   TestAccessRules_parseAccessRule/ip_rule_with_incomplete_address\n=== RUN   TestAccessRules_parseAccessRule/ip_rule_with_bad_cidr_mask\n=== RUN   TestAccessRules_parseAccessRule/single_ipv4_with_no_mask\n=== RUN   TestAccessRules_parseAccessRule/single_ipv6_with_no_mask\n--- PASS: TestAccessRules_parseAccessRule (0.00s)\n    --- PASS: TestAccessRules_parseAccessRule/valid_ipv4_rule (0.00s)\n    --- PASS: TestAccessRules_parseAccessRule/valid_ipv6_rule (0.00s)\n    --- PASS: TestAccessRules_parseAccessRule/invalid_rule_type (0.00s)\n    --- PASS: TestAccessRules_parseAccessRule/ip_rule_with_incomplete_address (0.00s)\n    --- PASS: TestAccessRules_parseAccessRule/ip_rule_with_bad_cidr_mask (0.00s)\n    --- PASS: TestAccessRules_parseAccessRule/single_ipv4_with_no_mask (0.00s)\n    --- PASS: TestAccessRules_parseAccessRule/single_ipv6_with_no_mask (0.00s)\n=== RUN   TestAccessRules_denyByIP\n=== RUN   TestAccessRules_denyByIP/allow_rule_with_included_ipv4\n=== RUN   TestAccessRules_denyByIP/allow_rule_with_exluded_ipv4\n2018/09/12 08:51:49 [INFO] route rules denied access from 1.2.3.4 to http://testing.test/\n=== RUN   TestAccessRules_denyByIP/deny_rule_with_included_ipv4\n2018/09/12 08:51:49 [INFO] route rules denied access from 10.10.0.1 to http://testing.test/\n=== RUN   TestAccessRules_denyByIP/deny_rule_with_excluded_ipv4\n=== RUN   TestAccessRules_denyByIP/allow_rule_with_included_ipv6\n=== RUN   TestAccessRules_denyByIP/allow_rule_with_exluded_ipv6\n2018/09/12 08:51:49 [INFO] route rules denied access from 1234:5678::1 to http://testing.test/\n=== RUN   TestAccessRules_denyByIP/deny_rule_with_included_ipv6\n2018/09/12 08:51:49 [INFO] route rules denied access from 1234:dead:beef:cafe::5678 to http://testing.test/\n=== RUN   TestAccessRules_denyByIP/deny_rule_with_excluded_ipv6\n--- PASS: TestAccessRules_denyByIP (0.00s)\n    --- PASS: TestAccessRules_denyByIP/allow_rule_with_included_ipv4 (0.00s)\n    --- PASS: TestAccessRules_denyByIP/allow_rule_with_exluded_ipv4 (0.00s)\n    --- PASS: TestAccessRules_denyByIP/deny_rule_with_included_ipv4 (0.00s)\n    --- PASS: TestAccessRules_denyByIP/deny_rule_with_excluded_ipv4 (0.00s)\n    --- PASS: TestAccessRules_denyByIP/allow_rule_with_included_ipv6 (0.00s)\n    --- PASS: TestAccessRules_denyByIP/allow_rule_with_exluded_ipv6 (0.00s)\n    --- PASS: TestAccessRules_denyByIP/deny_rule_with_included_ipv6 (0.00s)\n    --- PASS: TestAccessRules_denyByIP/deny_rule_with_excluded_ipv6 (0.00s)\n=== RUN   TestAccessRules_AccessDeniedHTTP\n=== RUN   TestAccessRules_AccessDeniedHTTP/single_denied_xff_and_allowed_remote_addr\n2018/09/12 08:51:49 [INFO] route rules denied access from 1.1.1.2 to http://testing.test/\n=== RUN   TestAccessRules_AccessDeniedHTTP/allowed_xff_and_denied_remote_addr\n2018/09/12 08:51:49 [INFO] route rules denied access from 1.1.1.2 to http://testing.test/\n=== RUN   TestAccessRules_AccessDeniedHTTP/single_allowed_xff_and_allowed_remote_addr\n2018/09/12 08:51:49 [INFO] route rules denied access from 1.2.3.4 to http://testing.test/\n=== RUN   TestAccessRules_AccessDeniedHTTP/denied_xff_and_denied_remote_addr\n2018/09/12 08:51:49 [INFO] route rules denied access from 200.17.18.20 to http://testing.test/\n=== RUN   TestAccessRules_AccessDeniedHTTP/all_allowed_xff_and_allowed_remote_addr\n--- PASS: TestAccessRules_AccessDeniedHTTP (0.00s)\n    --- PASS: TestAccessRules_AccessDeniedHTTP/single_denied_xff_and_allowed_remote_addr (0.00s)\n    --- PASS: TestAccessRules_AccessDeniedHTTP/allowed_xff_and_denied_remote_addr (0.00s)\n    --- PASS: TestAccessRules_AccessDeniedHTTP/single_allowed_xff_and_allowed_remote_addr (0.00s)\n    --- PASS: TestAccessRules_AccessDeniedHTTP/denied_xff_and_denied_remote_addr (0.00s)\n    --- PASS: TestAccessRules_AccessDeniedHTTP/all_allowed_xff_and_allowed_remote_addr (0.00s)\n=== RUN   TestIssue57\n--- PASS: TestIssue57 (0.00s)\n=== RUN   TestPrefixMatcher\n=== RUN   TestPrefixMatcher//foo\n=== RUN   TestPrefixMatcher//fools\n=== RUN   TestPrefixMatcher//fo\n=== RUN   TestPrefixMatcher//bar\n--- PASS: TestPrefixMatcher (0.00s)\n    --- PASS: TestPrefixMatcher//foo (0.00s)\n    --- PASS: TestPrefixMatcher//fools (0.00s)\n    --- PASS: TestPrefixMatcher//fo (0.00s)\n    --- PASS: TestPrefixMatcher//bar (0.00s)\n=== RUN   TestGlobMatcher\n=== RUN   TestGlobMatcher//foo\n=== RUN   TestGlobMatcher//fool\n=== RUN   TestGlobMatcher//fool#01\n=== RUN   TestGlobMatcher//fools\n=== RUN   TestGlobMatcher//fools#01\n=== RUN   TestGlobMatcher//foo/x/bar\n=== RUN   TestGlobMatcher//foo/x/y/z/w/bar\n=== RUN   TestGlobMatcher//foo/x/y/z/w/bar#01\n=== RUN   TestGlobMatcher//fo\n=== RUN   TestGlobMatcher//fools#02\n=== RUN   TestGlobMatcher//fo#01\n=== RUN   TestGlobMatcher//fools#03\n=== RUN   TestGlobMatcher//foo/x/y/z/w/baz\n--- PASS: TestGlobMatcher (0.00s)\n    --- PASS: TestGlobMatcher//foo (0.00s)\n    --- PASS: TestGlobMatcher//fool (0.00s)\n    --- PASS: TestGlobMatcher//fool#01 (0.00s)\n    --- PASS: TestGlobMatcher//fools (0.00s)\n    --- PASS: TestGlobMatcher//fools#01 (0.00s)\n    --- PASS: TestGlobMatcher//foo/x/bar (0.00s)\n    --- PASS: TestGlobMatcher//foo/x/y/z/w/bar (0.00s)\n    --- PASS: TestGlobMatcher//foo/x/y/z/w/bar#01 (0.00s)\n    --- PASS: TestGlobMatcher//fo (0.00s)\n    --- PASS: TestGlobMatcher//fools#02 (0.00s)\n    --- PASS: TestGlobMatcher//fo#01 (0.00s)\n    --- PASS: TestGlobMatcher//fools#03 (0.00s)\n    --- PASS: TestGlobMatcher//foo/x/y/z/w/baz (0.00s)\n=== RUN   TestParse\n=== RUN   TestParse/Parse-FailEmpty\n=== RUN   TestParse/Parse-FailNoRoute\n=== RUN   TestParse/Parse-FailRouteNoCmd\n=== RUN   TestParse/Parse-FailRouteAddNoService\n=== RUN   TestParse/Parse-FailRouteAddNoSrc\n=== RUN   TestParse/Parse-RouteAddService\n=== RUN   TestParse/Parse-RouteAddTCPService\n=== RUN   TestParse/Parse-RouteAddServiceWeight\n=== RUN   TestParse/Parse-RouteAddServiceWeightTags\n=== RUN   TestParse/Parse-RouteAddServiceWeightOpts\n=== RUN   TestParse/Parse-RouteAddServiceWeightTagsOpts\n=== RUN   TestParse/Parse-RouteAddServiceWeightTagsOptsMoreSpaces\n=== RUN   TestParse/Parse-RouteAddTags\n=== RUN   TestParse/Parse-RouteAddTagsOpts\n=== RUN   TestParse/Parse-RouteAddOpts\n=== RUN   TestParse/Parse-RouteDelTags\n=== RUN   TestParse/Parse-RouteDelTagsMoreSpaces\n=== RUN   TestParse/Parse-RouteDelService\n=== RUN   TestParse/Parse-RouteDelServiceTags\n=== RUN   TestParse/Parse-RouteDelServiceTagsMoreSpaces\n=== RUN   TestParse/Parse-RouteDelServiceSrc\n=== RUN   TestParse/Parse-RouteDelTCPServiceSrc\n=== RUN   TestParse/Parse-RouteDelServiceSrcDst\n=== RUN   TestParse/Parse-RouteDelTCPServiceSrcDst\n=== RUN   TestParse/Parse-RouteDelServiceSrcDstMoreSpaces\n=== RUN   TestParse/Parse-RouteWeightServiceSrc\n=== RUN   TestParse/Parse-RouteWeightServiceSrcTags\n=== RUN   TestParse/Parse-RouteWeightServiceSrcTagsMoreSpaces\n=== RUN   TestParse/Parse-RouteWeightSrcTags\n=== RUN   TestParse/Parse-RouteWeightSrcTagsMoreSpaces\n--- PASS: TestParse (0.00s)\n    --- PASS: TestParse/Parse-FailEmpty (0.00s)\n    --- PASS: TestParse/Parse-FailNoRoute (0.00s)\n    --- PASS: TestParse/Parse-FailRouteNoCmd (0.00s)\n    --- PASS: TestParse/Parse-FailRouteAddNoService (0.00s)\n    --- PASS: TestParse/Parse-FailRouteAddNoSrc (0.00s)\n    --- PASS: TestParse/Parse-RouteAddService (0.00s)\n    --- PASS: TestParse/Parse-RouteAddTCPService (0.00s)\n    --- PASS: TestParse/Parse-RouteAddServiceWeight (0.00s)\n    --- PASS: TestParse/Parse-RouteAddServiceWeightTags (0.00s)\n    --- PASS: TestParse/Parse-RouteAddServiceWeightOpts (0.00s)\n    --- PASS: TestParse/Parse-RouteAddServiceWeightTagsOpts (0.00s)\n    --- PASS: TestParse/Parse-RouteAddServiceWeightTagsOptsMoreSpaces (0.00s)\n    --- PASS: TestParse/Parse-RouteAddTags (0.00s)\n    --- PASS: TestParse/Parse-RouteAddTagsOpts (0.00s)\n    --- PASS: TestParse/Parse-RouteAddOpts (0.00s)\n    --- PASS: TestParse/Parse-RouteDelTags (0.00s)\n    --- PASS: TestParse/Parse-RouteDelTagsMoreSpaces (0.00s)\n    --- PASS: TestParse/Parse-RouteDelService (0.00s)\n    --- PASS: TestParse/Parse-RouteDelServiceTags (0.00s)\n    --- PASS: TestParse/Parse-RouteDelServiceTagsMoreSpaces (0.00s)\n    --- PASS: TestParse/Parse-RouteDelServiceSrc (0.00s)\n    --- PASS: TestParse/Parse-RouteDelTCPServiceSrc (0.00s)\n    --- PASS: TestParse/Parse-RouteDelServiceSrcDst (0.00s)\n    --- PASS: TestParse/Parse-RouteDelTCPServiceSrcDst (0.00s)\n    --- PASS: TestParse/Parse-RouteDelServiceSrcDstMoreSpaces (0.00s)\n    --- PASS: TestParse/Parse-RouteWeightServiceSrc (0.00s)\n    --- PASS: TestParse/Parse-RouteWeightServiceSrcTags (0.00s)\n    --- PASS: TestParse/Parse-RouteWeightServiceSrcTagsMoreSpaces (0.00s)\n    --- PASS: TestParse/Parse-RouteWeightSrcTags (0.00s)\n    --- PASS: TestParse/Parse-RouteWeightSrcTagsMoreSpaces (0.00s)\n=== RUN   TestParseAliases\n=== RUN   TestParseAliases/ParseAliases-FailEmpty\n=== RUN   TestParseAliases/ParseAliases-FailNoRoute\n=== RUN   TestParseAliases/ParseAliases-FailRouteNoCmd\n=== RUN   TestParseAliases/ParseAliases-FailRouteAddNoService\n=== RUN   TestParseAliases/ParseAliases-FailRouteAddNoSrc\n=== RUN   TestParseAliases/ParseAliases-RouteAddServiceWithoutAlias\n=== RUN   TestParseAliases/ParseAliases-RouteAddServiceWithAlias\n=== RUN   TestParseAliases/ParseAliases-RouteAddServicesWithoutAliases\n=== RUN   TestParseAliases/ParseAliases-RouteAddServicesWithAliases\n--- PASS: TestParseAliases (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-FailEmpty (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-FailNoRoute (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-FailRouteNoCmd (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-FailRouteAddNoService (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-FailRouteAddNoSrc (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-RouteAddServiceWithoutAlias (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-RouteAddServiceWithAlias (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-RouteAddServicesWithoutAliases (0.00s)\n    --- PASS: TestParseAliases/ParseAliases-RouteAddServicesWithAliases (0.00s)\n=== RUN   TestRndPicker\n--- PASS: TestRndPicker (0.00s)\n=== RUN   TestRRPicker\n--- PASS: TestRRPicker (0.00s)\n=== RUN   TestSyncRegistry\n2018/09/12 08:51:49 [INFO] Unregistered timer svc-b../bbb.localhost_5678\n--- PASS: TestSyncRegistry (0.00s)\n=== RUN   TestTableParse\n=== RUN   TestTableParse/1_service,1_prefix\n=== RUN   TestTableParse/1_service,_1_prefix,_3_instances\n=== RUN   TestTableParse/1_service,_1_prefix_with_option\n=== RUN   TestTableParse/1_service,_1_prefix,_2_instances_with_different_options\n=== RUN   TestTableParse/2_service,_1_prefix\n=== RUN   TestTableParse/1_service,_2_prefix\n=== RUN   TestTableParse/2_service,_2_prefix\n=== RUN   TestTableParse/sort_by_more_specific_prefix\n=== RUN   TestTableParse/sort_prefix_with_host_before_prefix_without_host\n=== RUN   TestTableParse/add_more_specific_prefix_to_existing_host\n=== RUN   TestTableParse/delete_route_by_service,_path_and_target\n=== RUN   TestTableParse/delete_route_by_service_and_path\n=== RUN   TestTableParse/delete_route_by_service\n=== RUN   TestTableParse/delete_route_by_service_and_tags\n=== RUN   TestTableParse/delete_route_by_tags\n=== RUN   TestTableParse/weigh_fixed_weight_0->auto_distribution\n=== RUN   TestTableParse/weigh_only_fixed_weights_and_sum(fixedWeight)<1->normalize_to_100%\n=== RUN   TestTableParse/weigh_only_fixed_weights_and_sum(fixedWeight)>1->normalize_to_100%\n=== RUN   TestTableParse/weigh_multiple_entries_for_same_instance_with_no_fixed_weight->de-duplication\n=== RUN   TestTableParse/weigh_multiple_entries_with_no_fixed_weight->even_distribution\n=== RUN   TestTableParse/weigh_multiple_entries_with_de-dup_and_no_fixed_weight->even_distribution\n=== RUN   TestTableParse/weigh_mixed_fixed_and_auto_weights->even_distribution_of_remaining_weight_across_non-fixed_weighted_targets\n=== RUN   TestTableParse/weigh_fixed_weight==100%->route_only_to_fixed_weighted_targets\n=== RUN   TestTableParse/weigh_fixed_weight>_100%->route_only_to_fixed_weighted_targets_and_normalize_weight\n=== RUN   TestTableParse/weigh_dynamic_weight_matched_on_service_name\n=== RUN   TestTableParse/weigh_dynamic_weight_matched_on_service_name_and_tags\n=== RUN   TestTableParse/weigh_dynamic_weight_matched_on_tags\n=== RUN   TestTableParse/weigh_more_than_1000_routes\n=== RUN   TestTableParse/weigh_more_than_1000_routes_with_a_fixed_route_target\n--- PASS: TestTableParse (0.63s)\n    --- PASS: TestTableParse/1_service,_1_prefix (0.00s)\n    --- PASS: TestTableParse/1_service,_1_prefix,_3_instances (0.00s)\n    --- PASS: TestTableParse/1_service,_1_prefix_with_option (0.00s)\n    --- PASS: TestTableParse/1_service,_1_prefix,_2_instances_with_different_options (0.00s)\n    --- PASS: TestTableParse/2_service,_1_prefix (0.00s)\n    --- PASS: TestTableParse/1_service,_2_prefix (0.00s)\n    --- PASS: TestTableParse/2_service,_2_prefix (0.00s)\n    --- PASS: TestTableParse/sort_by_more_specific_prefix (0.00s)\n    --- PASS: TestTableParse/sort_prefix_with_host_before_prefix_without_host (0.00s)\n    --- PASS: TestTableParse/add_more_specific_prefix_to_existing_host (0.00s)\n    --- PASS: TestTableParse/delete_route_by_service,_path_and_target (0.00s)\n    --- PASS: TestTableParse/delete_route_by_service_and_path (0.00s)\n    --- PASS: TestTableParse/delete_route_by_service (0.00s)\n    --- PASS: TestTableParse/delete_route_by_service_and_tags (0.00s)\n    --- PASS: TestTableParse/delete_route_by_tags (0.00s)\n    --- PASS: TestTableParse/weigh_fixed_weight_0->auto_distribution (0.00s)\n    --- PASS: TestTableParse/weigh_only_fixed_weights_and_sum(fixedWeight)<1->normalize_to_100% (0.00s)\n    --- PASS: TestTableParse/weigh_only_fixed_weights_and_sum(fixedWeight)>1->normalize_to_100% (0.00s)\n    --- PASS: TestTableParse/weigh_multiple_entries_for_same_instance_with_no_fixed_weight->de-duplication (0.00s)\n    --- PASS: TestTableParse/weigh_multiple_entries_with_no_fixed_weight->even_distribution (0.00s)\n    --- PASS: TestTableParse/weigh_multiple_entries_with_de-dup_and_no_fixed_weight->even_distribution (0.00s)\n    --- PASS: TestTableParse/weigh_mixed_fixed_and_auto_weights->even_distribution_of_remaining_weight_across_non-fixed_weighted_targets (0.00s)\n    --- PASS: TestTableParse/weigh_fixed_weight==100%->route_only_to_fixed_weighted_targets (0.00s)\n    --- PASS: TestTableParse/weigh_fixed_weight>_100%->_route_only_to_fixed_weighted_targets_and_normalize_weight (0.00s)\n    --- PASS: TestTableParse/weigh_dynamic_weight_matched_on_service_name (0.00s)\n    --- PASS: TestTableParse/weigh_dynamic_weight_matched_on_service_name_and_tags (0.00s)\n    --- PASS: TestTableParse/weigh_dynamic_weight_matched_on_tags (0.00s)\n    --- PASS: TestTableParse/weigh_more_than_1000_routes (0.30s)\n    --- PASS: TestTableParse/weigh_more_than_1000_routes_with_a_fixed_route_target (0.32s)\n=== RUN   TestNormalizeHost\n--- PASS: TestNormalizeHost (0.00s)\n=== RUN   TestTableLookupIssue448\n--- PASS: TestTableLookupIssue448 (0.00s)\n=== RUN   TestTableLookup\n--- PASS: TestTableLookup (0.00s)\n=== RUN   TestTarget_BuildRedirectURL\n--- PASS: TestTarget_BuildRedirectURL (0.00s)\nPASS\nok      github.com/fabiolb/fabio/route  (cached)\n?       github.com/fabiolb/fabio/uuid   [no test files]\nmake: *** [test] Error 1\n```. ",
    "rokka-n": "This makes a lot of sense, app should understand the routes it announces.\nBtw, where did the docker-compose go? I remember there was a demo with compose.. @magiconair Are you considering letsencrypt integration?. Yeah, right.  Having backends info is what logging would be very useful for. However, I was looking at the docs and there is trace mode. Which kinda provides this information.\nIs it possible to enable it, maybe dynamically for all requests? \n. \ud83d\udc4d Thank you!. ",
    "jeinwag": "Thanks, looks good to me!\n. ",
    "sandstrom": "Ah, nice! Didn't find it on the website, but I probably just missed it.\n. ",
    "volkantufekci": "fabio doesn't perform health check, it watches health changes in consul, right? \nfabio-example and my service are both running on the same node, so the node is not in maintenance mode and my service seams to be healthy according to \"/v1/health/service/\" check of Consul:\n\"Checks\": [\n            {\n                \"Node\": \"ASDF\",\n                \"CheckID\": \"serfHealth\",\n                \"Name\": \"Serf Health Status\",\n                \"Status\": \"passing\",\n                \"Notes\": \"\",\n                \"Output\": \"Agent alive and reachable\",\n                \"ServiceID\": \"\",\n                \"ServiceName\": \"\"\n            }\n        ]\nIs there a debug mode or may i increase log level of fabio?\n. I was not passing a health check configuration while registering the service to consul, which was preventing the route for that service to be added by fabio. After I did that fabio added routes perfectly. Thanks for pointing that.\nAs you mentioned it would be nice to have a line in README that a health check must be defined while registering a service to consul for fabio...\nThanks for implementing fabio.\n. ",
    "jrusiecki": "Hi,\nFirst of all - fabio it's great !\nYesterday I've bumped into same problem of required check ... fixed it but the question remains: WHY do u need ckeck registered ? \nU can call some API endpoints with ?passing parameter (e.g. /v1/health/service/mywebbackend?passing ) to get proper list of running service instances - both when check is registered & passing AND when consul assumes it is passing because no check is registered for service instance. \nSo maybe checks are not required (such behavior looks to me more consul-consistent)\nRegards and thanks againfor great fabio LB, Jakub\n. Dear @magiconair thanks for prompt reply. I fully agree with you that fabio shall route locations to live instances only. My suggestion was based solely on the responsibility separation- the service discovery service (via endpoint /v1/health/service/mywebbackend?passing and via DNS as well) tells everybody if service instance is alive (\"passing\"). Thereby, service discovery consumers (e.g. fabio) should dully accept it and not take/care for service discovery (consul) responsibilities. This way we'd have cleaner responsibility separation and less coupling for future consul changes or new service discovery agents. Thanks again and best regards.\n. Fully agree. We agree on facts, we just differ on elements responsibility approach.  I think that in this case it's upstream service responsibility to properly register, consul responsibility to properly report service state and any consumer (e.g. fabio) should just list working service instances (passing). \nLess knowledge in fabio how service producer (consul)  works => less code in fabio and it is less dependent on consul internals => less changes to fabio when consul changes and less chances future consul versions break fabio's code...  It is just architectural risk for the future. Regards and thanks for your time and all the explanations.\n. ",
    "emicklei": "Thank you adding suppport for websockets. Before I stress test the current state, I like to share with you a snippet I got from Brad Fritzpatrick (see go-nuts link) which it more compact and appearantly does not require the websockets package.\n```\n// https://groups.google.com/forum/#!topic/golang-nuts/KBx9pDlvFOc\nfunc websocketProxy(target string) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        d, err := net.Dial(\"tcp\", target)\n        if err != nil {\n            http.Error(w, \"Error contacting backend server.\", 500)\n            log.Printf(\"Error dialing websocket backend %s: %v\", target, err)\n            return\n        }\n        hj, ok := w.(http.Hijacker)\n        if !ok {\n            http.Error(w, \"Not a hijacker?\", 500)\n            return\n        }\n        nc, _, err := hj.Hijack()\n        if err != nil {\n            log.Printf(\"Hijack error: %v\", err)\n            return\n        }\n        defer nc.Close()\n        defer d.Close()\n    err = r.Write(d)\n    if err != nil {\n        log.Printf(\"Error copying request to target: %v\", err)\n        return\n    }\n\n    errc := make(chan error, 2)\n    cp := func(dst io.Writer, src io.Reader) {\n        _, err := io.Copy(dst, src)\n        errc <- err\n    }\n    go cp(d, nc)\n    go cp(nc, d)\n    <-errc\n})\n\n}\n```\n. ",
    "composer22": "I'd request one for the docker/swarm API. This would eliminate consul and registrator background containers completely. \nDocker API allows you to query networks (incl overlay network) for running containers. You can use this to extract running services and IP addresses. Another interesting resource, with overlay networks and custom bridge networks in Docker, you get a /etc/host file in every running container which points to other running containers in the network(s). If a container is stopped or destroyed, it is pulled from the host file by docker automatically. This could also be used to wire up services. \nContainers can be run in multiple custom networks, hence one Fabio instance could be a service point for consolidating needs.\nThe metadata that is attached to a container which propogates via registrator to Consul could still be used to create services in Fabio with no change IMHO.  Hence current config patterns should not be affected except they would need to be started or join a network the Fabio instance is sharing.\n. @magiconair @Kosta-Github \nYes, monitoring events \u221a\nLoot at the package:\nhttps://github.com/fsouza/go-dockerclient\nand I think this particularly:\nhttps://godoc.org/github.com/fsouza/go-dockerclient#Client.AddEventListener\nI'm performing some EXP work on the API usage. Not sure how it would evolve with an enhancement to Fabio. \nHere are some thoughts.\n- Fabio will need to perform it's own health checks instead of Consul. Not sure fabio is performing these now.\n- Create Facade objects within Fabio that appear to resemble Consul service objects in memory and let Fabio go to town on these. This will allow for a common interface to both providers.\n. You're performing this now indirectly.\nA status or heartbeat check isn't state. It's not maintaining state for the service. It's checking status from the service to determine it's state. You're currently querying through Consul for it which is the same thing. What's the diff except the loss of a middle man?\nI don't know any router/lb out there that doesn't perform some status check. \nFabio =status check=> Consul =status check => Service\nvs\nFabio =status check=>  Service\nYou only need an object representing the service in Fabio for a Heath Check which you need now anyway. Moreover, the config information doesn't need to be kept after the initial query, since you've already performed your own config of a route on the initial discovery.\nhttps://github.com/eBay/fabio/blob/master/registry/consul/service.go\nconfig = append(config, fmt.Sprintf(\"route add %s %s%s http://%s:%d/ tags %q\", name, host, path, addr, port, strings.Join(svc.ServiceTags, \",\")))\n. I understand the position you are taking. You want the backend to be a lightweight interface for an API for determining container state and route status. In this case, I assume you're spinning off a go routine that blocks until the state is modified:\nfunc watchServices(client *api.Client, tagPrefix string, config chan string) {\n    var lastIndex uint64\n    for {\n        ...\n              checks, meta, err := client.Health().State(\"any\", q)\n        ..\n        }\n}\nThis might be replaced with the docker event check API call for state of the containers that are running. However docker doesn't know anything about health of each route provided by the container. To do this, either fabio would have to be enhanced to also perform health checks, or a facade would need to be written that runs in parallel and emulates the same information that Fabio needs from Consul. This would essentially spoof Consul's role:\nFabio <=> DockerMon == hc => Containers\n                          ^ \n                          ||\n                           <======> docker API ===> docker daemon\n...and provide the same blocking function.\nDockerMon basically is emulating a light subset of features from Consul and registrator. It's a question of where to put DockerMon features. I can see two competing ways to go here:\n- fabio++: add the DockerMon features within Fabio.\n- fabio-dockermon: create a stand alone DockerMon server that Fabio communicates to -- similar to Consul. API's that fabio needs will still be available.\nThe first benefits eliminating a fat environment of services running at the cost of additional code.\nThe second keeps things simple at the cost of still retaining a fatter environment of services. Fabio would still need to be modified to accept this registry instead of Consul.\nAnother option is to enhance Consul to monitor Docker API for service discovery instead of registrator. Currently Consul does have limited health checks against docker API\n{\n\"check\": {\n    \"id\": \"mem-util\",\n    \"name\": \"Memory utilization\",\n    \"docker_container_id\": \"f972c95ebf0e\",\n    \"shell\": \"/bin/bash\",\n    \"script\": \"/usr/local/bin/check_mem.py\",\n    \"interval\": \"10s\"\n  }\n}\n. When I get some time I'm going to try and create an app (Dockermon) that essentially looks like a Consul instance for Fabio. Therefore the same API calls will still work, yet the app will poll Docker API instead of using Consul/Registrator.  It will be an interesting experience.  Thanks\n. +1\n. @magiconair I like it. \nLet your imagination fly!\n. Thanks for your patience. I'm not sure I understand fully, but I will try and qualify my question.\nI'd like all paths to fall through to the targets based only on the hostname. To do so, I want to only have to do this:\nSERVICE_TAGS=urlprefix-lb-hello-world.example.com/\nor this:\nSERVICE_TAGS=urlprefix-lb-hello-world.example.com/*\nand no matter what i send as a path, as long as the hostname matches, it will send to one of the assigned targets in the table for lb-hello-world.example.com/ or lb-hello-world.example.com/*.\nIf, for example, lb-hello-world.example.com was in the DNS as pointing to fabio's IP address, lets as 192.168.1.4. \n(and I'm also using fabio for multiple lb endpoints to other services):\n```\n/etc/hosts:\n192.168.1.4    fabio        \n192.168.1.4    lb-hello-world.example.com\n192.168.1.4    lb-checkout.example.com\n```\nThese requests for lb-hello-world.example.com => favio...\nhttp://lb-hello-world.example.com:9999/v1.0/hello\nhttp://lb-hello-world.example.com:9999/v.10/health\nhttp://lb-hello-world.example.com:9999/\n...would all resolve to the following single rule:\nlb-hello-world.example.com/*\n        hello_world_1       10.0.0.2:32789\n        hello_world_2       10.0.0.3:32872\n...and hello_world_1 or hello_world_2 services would receive these requests as:\nhttp://10.0.0.2:32789/v1.0/hello\nhttp://10.0.0.3: 32872/v.10/health\nhttp://10.0.0.2:32789/\nThis is not happening now. Here is what is happening...\nFrom my hosts file (scrubbed):\n52.35.xxx.xxx   lb-hello-world.example.com\nFrom my fabio logs using curl testing:\n2016/02/03 18:37:36 [WARN] No route for lb-hello-world.example.com:9999/v1.0/health\n2016/02/03 18:37:51 [WARN] No route for lb-hello-world.example.com:9999/v1.0/health/\n2016/02/03 18:38:10 [WARN] No route for lb-hello-world.example.com:9999/v1.0/hello\n2016/02/03 18:38:18 [WARN] No route for lb-hello-world.example.com:9999/v1.0/hello/\nFrom my routing table:\n```\nService         Host                   Path  Dest                        Weight\n1   hello_world_1   lb-hello-world.example.com   /  http://10.0.77.64:32772/    100%\n```\nI do not want to pass on the hostname as apart of the path for example:\nNot this; no host:\n```\nService         Host                   Path  Dest                        Weight\n1   hello_world_1            /lb-hello-world.example.com    http://10.0.77.64:32772/    100%\n```\n...or this:\n```\nService         Host                   Path  Dest                        Weight\n1   hello_world_1            /hello-world   http://10.0.77.64:32772/    100%\n```\nor send fabio this:\nhttp://fabio:9999/hello-world/v1.0/hello\nhttp://fabio:9999/hello-world/v.10/health\nhttp://fabio:9999/hello-world\nas hello_world_1 and hello_world_2 are receiving this...\nhttp://10.0.0.2:32789/hello-world/v1.0/hello\nhttp://10.0.0.3: 32872/hello-world/v.10/health\nhttp://10.0.0.2:32789/hello-world\nThat is what is happening now.\nAgain I don't want to define every path that a server/service is providing. There might require hundreds of entries per service. \nAgain I don't want to parse out the higher level path in the service as a work around. e.g defining routes in the application with /hello-world/v.10/health\n```\nNO:\nmux.HandleFunc(\"/lb-hello-world.example.com/v.10/health\", s.helloHandler)\nor\nmux.HandleFunc(\"/hello-world/v.10/health\", s.helloHandler)\nYES:\nmux.HandleFunc(\"/v.10/health\", s.helloHandler)\n```\n. Ok, let me try some examples and report back my results. bbiab\n. Feedback:\nHere is my test...\nhosts file changes (scrupped):\n```\n$ cat /etc/hosts\n\nHost Database\n\nlocalhost is used to configure the loopback interface\nwhen the system is booting.  Do not change this entry.\n\n127.0.0.1   localhost\n255.255.255.255 broadcasthost\n::1             localhost \n52.35.xxx.xxx   lb-hello-world.example.com\n```\ndocker command to start service end point:\ndocker run -d \\\n  -P \\\n  -e constraint:com.military.role==worker  \\\n  -e \"SERVICE_NAME=hello_world_1\"  \\\n  -e \"SERVICE_CHECK_HTTP=/v1.0/health\"  \\\n  -e \"SERVICE_CHECK_INTERVAL=5s\" \\\n  -e \"SERVICE_CHECK_TIMEOUT=15s\"  \\\n  -e \"SERVICE_TAGS=urlprefix-lb-hello-world.example.com/\"  \\\n  --restart=always  \\\n  --name hello_world_1  \\\n  composer22/hello-world\nRegisters with fabio. Yippie!:\n\nCurl examples:\ncurl -v http://lb-hello-world.example.com:9999/v1.0/health/\ncurl -v http://lb-hello-world.example.com:9999/v1.0/health\ncurl -v http://lb-hello-world.example.com:9999/v1.0/hello/\ncurl -v http://lb-hello-world.example.com:9999/v1.0/hello\nFabio Log Results:\n2016/02/03 20:42:22 [WARN] No route for lb-hello-world.example.com:9999/v1.0/health\n2016/02/03 20:42:25 [WARN] No route for lb-hello-world.example.com:9999/v1.0/health/\n2016/02/03 20:42:31 [WARN] No route for lb-hello-world.example.com:9999/v1.0/hello\n2016/02/03 20:42:33 [WARN] No route for lb-hello-world.example.com:9999/v1.0/hello/\nCommand line partial example results:\n```\n$ curl -v http://lb-hello-world.example.com:9999/v1.0/health\n   Trying 52.35.xxx.xxx...\n Connected to lb-hello-world.example.com (52.35.xxx.xxx) port 9999 (#0)\n\nGET /v1.0/health HTTP/1.1\nHost: lb-hello-world.example.com:9999\nUser-Agent: curl/7.43.0\nAccept: /\n< HTTP/1.1 404 Not Found\n< Date: Wed, 03 Feb 2016 20:46:06 GMT\n< Content-Length: 0\n< Content-Type: text/plain; charset=utf-8\n< \n Connection #0 to host lb-hello-world.example.com left intact\n[12:46:06]\n$ curl -v http://lb-hello-world.example.com:9999/v1.0/health/\n   Trying 52.35.xxx.xxx...\n Connected to lb-hello-world.example.com (52.35.xxx.xxx) port 9999 (#0)\nGET /v1.0/health/ HTTP/1.1\nHost: lb-hello-world.example.com:9999\nUser-Agent: curl/7.43.0\nAccept: /*\n< HTTP/1.1 404 Not Found\n< Date: Wed, 03 Feb 2016 20:46:09 GMT\n< Content-Length: 0\n< Content-Type: text/plain; charset=utf-8\n< \n* Connection #0 to host lb-hello-world.example.com left intact\n[12:46:09] \n$ \n```\n\nI know the endpoint is good.\nI know it never reached the endpoint because a) no log entry b) it would return a UUID in the response header.\n. Bingo! Beautiful!\nVERY VERY interesting.\n```\n$ curl -v -H \"Host: lb-hello-world.example.com\" \"http://lb-hello-world.example.com:9999/v1.0/hello\"\n   Trying 52.35.xxx.xxx...\n Connected to lb-hello-world.example.com (52.35.xxx.xxx) port 9999 (#0)\n\nGET /v1.0/hello HTTP/1.1\nHost: lb-hello-world.example.com\nUser-Agent: curl/7.43.0\nAccept: /\n< HTTP/1.1 200 OK\n< Content-Length: 12\n< Content-Type: application/json;charset=utf-8\n< Date: Wed, 03 Feb 2016 20:57:35 +0000\n< X-Request-Id: BC46FB26-8E0C-47AF-BD5E-B3DA729B564E\n< \n* Connection #0 to host lb-hello-world.example.com left intact\n```\n\nThis might be a challenge then. I guess if I have a Proxy front end, it will have to set the host header in the RedirectRule before calling fabio.example.com:9999. This unless because I am testing locally with a hacked host file, it isn't propagated correctly.\nThanks again for your help. \u221a :+1: :100: \n. Didnt see in docs so perhaps an update there.\nthanks again\n. It's deeply embedded in the docs under testing. I see this now. I was trying to follow the examples in the context of automated service discovery with Consul. There wasn't anything here which demonstrated hostname/ default with the idea of fabio acting as a general router/lb to many different hostnames.\nWhere we are headed is rather simple and somewhat based on what we have now in prod.\nInternet traffic being directed to first layer proxy servers with redirect. These servers direct traffic with complex set of rules to a fabio layer.\nThe fabio layer lbs directs main site or subservices.\nThe fabio layer might be split:\n3 fabios highly available each handling:\n- www.foo.com\n- mobile.foo.com\n- news.foo.com\nanother 3 fabios each handling:\n- auth.foo.com\n- checkout.foo.com\n- etc.\nand so on.\nThe subservices also access the fabio instances directly.\nThe question for me which I don't know is if, for example, I created a rewrite rule directing traffic away from the main site to a subdomain/service, whether it will carry forward the new HOSTNAME\nex:\nDNS is pointing to same...\n192.168.2.3        lb1-fabio.foo.com\n192.168.2.3        lb1-news.foo.com\nproxy rule in Apache, nginx, or HAProxy maps via Virtual Load Balancer to three Fabio instances in RR.\nwww.foo.com/latest/$1  ==>   \n     lb1-news.foo.com:9999/latest/$1\n     lb2-news.foo.com:9999/latest/$1\n     lb3-news.foo.com:9999/latest/$1\nSay lb1-fabio.foo.com is chosen...\nThe routes in lb1-fabio.foo.com:\nlb1-news.foo.com/\n       news_1         10.0.0.2\n       news_2         10.0.0.3\n lb1-mobile.foo.com/\n       mobile_1         10.0.0.4\n       mobile_2         10.0.0.5\nQ: Will HOSTNAME be set appropriately in the proxy redirected call to fabio http://lb1-news.foo.com:9999?\nI need to explore this...\n. I think the registrator/consul/fabio combination will work fine for us. I've dramatized a bit about how we might partition but this is a bit extreme. My biggest concern was finding a solution for dynamic ip/port service discovery for a Docker environment w/o the need to fall into a trap of generating config files and forcing reboots of a proxy (which I detest for all the reasons you've described in your into).\nThis is probably a side conversation, but we are not in a greenfield and we still need to hybridize things as we move to the future.\nIf we run into problems we cannot work around we can probably fork a version for host header issues.\nThank you for giving us this solution. I think it's an awesome project.\n. PS. Im going to check out the code in more detail to see if I can tune it up. Perhaps there is some cache padding etc that can be done to increase thru-put from 10K+ tps\n. Fun-damentally, Fabio is still just a consumer. What I am proposing, albeit a bit flawed, is a way for us to register any registry by way of API. You have an interface right now which requires a compilation. If you provided an API for us to wire up an external registry (or multiple ones), this would make it easy for any 3rd party to build their own.\nPerhaps I might propose this api strategy\n/register - register a registry with Fabio\n/unregister - unregister a registry with Fabio\nThe register would give any metadata that Fabio needs to poll from the registry service.\nEmbracing Consul is only one half the equation since for Docker we need a registrator service as well. This propagates more points of failure in the system. Trying to eliminate this. Could easily provide a etcd solution or a Docker API solution or a proxy to another DNS. Whatever we dream. Could do all these things if you provided an API so we could easily tell Fabio what registry to use. As long as the API is available to us and you, we don't need Fabio to be compiled for every registry need out there. NOR do we have to clone or create any basturdization of your efforts for each one. We can continue to take advantage of your strong solution while plugging in our own registry service whatever it may be. You can continue as is and not provide state (even though you are providing state for each Route/Target).\n. I counter. You've just increased it by forcing only one provider down our throats. Your interface is useless internally. If you add another one we still have a complexity issue of having infrastructure complexity OUTSIDE of Fabio.\nI recommend:\nContinue to provide Consul built in. No change.\nCreate a generic registry using your interface.\nBut you set the API rules. This is a contract which we, as registry providers, must adhere to.\n- how to register\n- how to unregister\n- how fabio will call to check the registry and what the registry must provide back as a response. This can be same format as what you expect for services and k/v interaction from Consul. We, the providers, must strictly follow it and give you the info back exactly, or whatever you expect Consul would have done.\nThis is NOT hard for us and opens up a whole world of tools.\n////\nHow to register might be nothing more than:\n- an api token (set in config)\n- a registry name string\n- an IP address and a path, or it might be a IP address and a port for WS\n  returns back a unique token (optional)\nHow to unregister:\n- api token\n- unique token from before (optional) or a name\nFabio callback format (when Fabio calls this endpoint above)\n- This can be the same layout as what you expect from Consul for all features you are using now.\n. Your concerns are understood. But I would not be concerned about API refactoring or enhancement. Your functionality is not so dynamic that it should be dynamic. Yes, previous features do need to be continued to be supported but that (at least in my experience) has never prevented an API to continue to respond to new features. You can either simply add additional attributes or features in the current set (w/o disrupting the interface -- for example extra json attributes) or if you have a dramatically different set, simply version them e.g. /v1.0, /v2.0 in the standard way API's do when big changes occur. \nBut serious, how many api routes do you really anticipate? Usually there are almost hundreds when versioning is ever needed, or the app is very close to \"business requirements\" where that happens (like a MVC web site) but not pure engineering lb.\nBe comfortable, you _aren't _responsible for supporting other providers needs. You set that boundary with the API interface. It should be a black box for us.\nHow many registry's are there out there? It grows all the time with imagination. Its not the registry behind the scene, but the proxy between fabio and the registry source. That source could be anything. You shouldn't care or worry:\nBasic:\nFabio <= api => CustomProxy <= tbd => Registry\nClassic:\nFabio <= yourapi => CustomProxy <= network => SkyDNS\nFabio <= yourapi => CustomProxy <= api => etcd\nFabio <= yourapi => CustomProxy <= network => zookeeper\nFabio <= yourapi => CustomProxy <= api => Docker\nFabio <= yourapi => CustomProxy <= api => Consul =)\nImagination:\nFabio <= yourapi => CustomProxy <= network => MicrosoftDNS <= app\nFabio <= yourapi => CustomProxy <= network => MySQL <= app\nFabio <= yourapi => CustomProxy <= internet => CustomProxy <= MaraDNS <= customregistrator\nFabio <= yourapi => CustomProxy <= internet => CustomProxy <= KnotDNS <= customregistrator\nwhatever you desire.\n. Another idea instead of api\nhttps://github.com/hashicorp/go-plugin\n. Any features you are dependent on now from Consul should not change. The registry should be a black box as far as Fabio is concerned. I thought I had done enough to highlight this importance.\nThe proxy layer (or whatever you want to call it. perhaps driver is a better word) is responsible for keeping these dependent features intact.  You should not be testing it.\nAnother example to look at is how docker allows for custom engines. \nhttps://docs.docker.com/engine/extend/plugins_network/\nDo you think Docker needs to be responsible for testing third party plugins?  I think not. It's the developers responsibility. Why do you keep returning to that idea fixee that you are responsible??  I'm baffled.\nThe docker interface is something I want to do, but I dont want to compile it into your code, hence why an API of sorts would be a help.\n. Sorry, been tied up here with security patching and other fires.\nI'm sort of confused myself here so I will first sum up what I was thinking.\nWhere your argument breaks down for me is that you state you are not dependent on consul. We are mixing things here a bit. The fact that someone has to have another registry compiled into your code to be able to use it indicates there is a dependency issue - on you officiating and making available these alternatives for us. We, in the meantime, wait around. Also, you are linking in third party libraries for interfaces we don't need. That would mean bloat and overhead.\nWhat I'm suggesting is to provide a plugin framework of some sort that is totally abstract and has no dependencies on any other services running via the Fabio Codebase. No consul compiled in drivers. Fabio is a black box to the registry services through a dynamic plug interface; the registry service is a black box to fabio. In fact, I would externalize your Consul registry code into a plugin and create another repo for it. \nWhen I say plugin I mean either API  or code. I will let you decide. Its just an external service similar to a database -- say MySQL -- running through JDBC.  Only in this case, JDBC is really some fabio specification you came up with that developers must meet in order for fabio to work.\nWhen fabio boots, you tell fabio what plugins to utilize and any config information it might need to utilize the plugin. \nK/V overrides are responsible by whatever plugin is being called. Fabio should not care as long as it gets the informatino back.  For example, Foo.fabreg might store that in a local yaml file, while Bar.fabreg might utilize redis.  Fabio shouldn't care as long as it gets back the info it needs through an API/plugin standard that Fabio is expecting.\n. concerning authentication. \nLet the configs for both the running registry and fabio contain a simple Bearer like token No need for fancy dancy stuff. We just want two services running close together on the same box anyway.\nThis is what I would code out. All as Docker images and containers...\nFabio <== api/rpc ==> RegistryPlugConsul <= api => Consul\nand\nFabio <== api/rpc ==> RegistryPlugDocker <= api => Docker\n                                       ||\n                                      <======> Local Map Storage (for K/V request handing from Fabio)\nFabio doesn't care. Just another IP address + port similar to a DB\n. > consul as the KV store also provides one additional function which is essential to fabio clusters: change notification. Without that you have to revert to polling.\nI don't see the issue. I have no problem with adding a WS connection with the driver for callbacks as long as you provide a payload spec that Fabio expects. Long polling is also possible but any registry proxy/driver can easily implement a WS. \nI'm confused where you are going with this but at least you are going. =D\nMy only gripe is having any hard boiled/compiled in libraries. As long as a metadata is defined and followed and you use a consistent fast transfer mechanism (such as RPC, WS) to that driver/proxy layer (which handles the key features that Fabio needs e.g. redis, etcd, consul, dockerapi for registry) then it will work.\nIdeally, looking at fabio code should be very vanilla without references to any specific implementation of the kv/registry. Simple code. \nThen, separate repos for drivers/proxy or whatever the name should be.\ne.v.\neBay/fabio     - base router\neBay/fabio-consul - driver for consul\neBay/fabio-docker - driver for docker\neBay/fabio-etcd - driver for etcd.\netc...\n. You don't have to provide any plugin except one for Consul. We, out here, can do the rest as we need them. Just create an plugin protocol for us to follow.\nAlso you don't have to deal with two -- one of kv and one for services.  Assume the plugin, whatever we develop will handle both requests. ONE plugin for both.\nJust to show you that it's possible, we could do this now without your coding anything. All we have to do is create a MOCK of Consul...make a server that looks like Consul to Fabio but really its just a hash of structures for the KV and using Docker API. Fabio would never know. It would just make Consul calls to a IP/Port/ Consuls API become the standard we implement. It would SPOOF Fabio by making it think it was a Consul instance.\nBut is this a solution? I don't think so. Removing your internal consul libraries and building a RPC/plugin would be the more mature way, using the Consul commands you are using as a standard to call other things.\nI still don't believe you grasp this elegence yet.\n. and so...\nhttps://traefik.io\n. +1\n. ",
    "Kosta-Github": "You can hook into the docker events via this HTTP endpoint: https://docs.docker.com/engine/reference/api/docker_remote_api_v1.21/#monitor-docker-s-events\nIt looks like the anchor is not positioning the page correctly, so you probably have the search for \"monitor docker's events\"...\n. ",
    "pascalandy": "Hey folks!\nCore user of Traefik here. Looking to try an alternative like fabio :) So far this is what i could understand from the docs (wiki) but I'm there yet\n```\ntouch /etc/fabio/fabio.properties\nfabio.properties is empty at this point\ndocker run -d --name fabio \\\n-p 9999:9999 -p 9998:9998 \\\n-v /etc/fabio/fabio.properties:/etc/fabio/fabio.properties \\\nmagiconair/fabio\ndocker run -d \\\n--name consul \\\n-p \"8400:8400\" -p \"8500:8500\" -p \"8600:53/udp\" \\\nconsul \\\nconsul agent -server -dev -client=0.0.0.0 -ui -bootstrap -log-level warn\ndocker run -d \\\n--name=registrator \\\n--net=host \\\n-v /var/run/docker.sock:/tmp/docker.sock \\\ngliderlabs/registrator:latest \\\nconsul://localhost:8500\ndocker run -d \\\n--name nginxfoo \\\n--expose 80 \\\n-e SERVICE_TAGS=urlprefix-/foo \\\nnginx:alpine\ndocker run -d \\\n--name nginxbar \\\n--expose 80 \\\n-e SERVICE_TAGS=urlprefix-/bar \\\nnginx:alpine\n```\nIf someone have a docker-compose or a docker stack I could try I'll be happy to test. I run Docker Swarm Mode. Cheers!. ",
    "joeblew99": "OK I guess I have to wait for 1.6.\nI was not sure what the integration aspects would be.\nWell http/2 allows lots of thinks, and saying adi\u00f3s to web sockets is one for sure.\nBut for microservices, it allows me to update all parts of a client in one hit, thus reducing / eliminating the need to manage cross web component update time latencies.\nI really like Fabio. Is there a roadmap ?\n. @nartamonov i have the same HA issue\nDid you end up finding a solution with fabio or other to get a pure golang LB that is \"clustered\" ?\nThe other option is to use clent side load balancing with consul / DNS\nThe web clients boot off S3 for wwww.example.com\nWithin this is a call to a consul proxy to get the server list (prioritised by least load). Its just a list in Javascript. \nThe clients then use the top on to make their calls to api.example.com.\nIf course there are LOTS of issues with this super simle approach:\n1- the client can cheat, and DDos a single server.\n2. bidirectional stuff like web sockets that are highly latency related need to have a bit more smarts baked in i suspect.\nAnyway, i am really needed a HA LB written in golang if anyone has ideas. \n. ",
    "strarsis": "Edit: One can use environment variables in the config properties file\n(https://github.com/magiconair/properties#v110-20-jan-2014).\nOr a hostname assigned by docker-compose.. Yes, I was missing go get for the repository and tried to run the go scripts directly.. https://github.com/strarsis/consul-fabio-example/. Log file attached: log.txt\n. Thank you for your answer.\nI removed the registrator service (and also ensured that it has been really stopped + removed), \nbut the route still persists in the fabio routing table.\nconsulfabioexample_consulx1_1   /bin/consul agent -server  ...   Up      8300/tcp, 8301/tcp, 8301/udp, 8302/tcp, 8302/udp, 8400/tcp, 0.0.0.0:8500->8500/tcp, 8600/tcp, 8600/udp\nconsulfabioexample_fabio_1      /fabio -cfg /etc/fabio/fab ...   Up      0.0.0.0:9998->9998/tcp, 0.0.0.0:9999->9999/tcp\nI updated the example repo so it can be directly tested.\nhttps://github.com/strarsis/consul-fabio-example/blob/master/docker-compose.yml\n. I updated the docker-compose and can confirm that it works now.\n. Thank you for your answer.\nYes, go get will also build the binary.\nThe binary will be in folder ./bin/, \nso it may be helpful to change the example \n(\"To start fabio run\") in documentation from \n./fabio\nto\n./bin/fabio\nI expected the binary being directly in work dir because of ./fabio.\n. If I want to use fabio in production now, how can I prevent issues when adding/removing certificates for existing apps?\nSpawning up a second fabio container and shutting down the old one (blue/green deployment)?\nIs there a config reload command for fabio?. Thank you for your response.\nFor example: Let's Encrypt (LE) requires certificate renewal in intervals (90 days).\nAlso apps may be just added, new domains assigned to them,\nin any of these cases there would be a small but existing downtime/disruption.\nThe vault PKI Secret Backend could be used to retrieve the PKI files:\nhttps://www.vaultproject.io/docs/secrets/pki/index.html\nFor fabio authenticating itself against vault, using an Auth Backend, \nthe most straightforward for containers/apps would be App ID:\nhttps://www.vaultproject.io/docs/auth/app-id.html\nThe main concern would be how to offer the configuration \nfor all these different Auth Backends in the fabio configuration.\nAs fabio is already opinionated insofar that it uses Consul and its protocol for service discovery, \nadding vault as definite backend for obtaining the certificate keys/data would of course force the fabio operator to implement and maintain a vault server, too.\nAs kind of compromise, one could offer a pure HTTP API, similar to the existing one for adding routes to fabio (\"overriding\"), to allow assigning certificates to routes on-the-fly.\nThen a kind of Vault-HTTP-adapter could be plugged in when vault should be used.. Thank you for your answer.\nAs vault already handles the authentication of apps against itself in order to retrieve secrets,\nwouldn't it be already sufficient to store the actual PEM files without passphrase?\nInstad of a cert passphrase, fabio itself would auth against vault with a Auth Backend,\nthen vault will or will not give out the requested PEM files according to the permissions set for fabio in vault.\n. So in nginx configuration for example, there is often an extra *_key file provided \nwhich contains the passphrase\nhttp://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_password_file\nFor haproxy config, the passphrase is always stripped first, otherwise it will ask for it at each restart.\nhttp://blog.armbruster-it.de/2010/03/remove-the-passphrase-from-a-pkcs12-certificate/\nThe \"password server\" mentioned in this thread comes close to describing vault: http://comments.gmane.org/gmane.comp.web.haproxy/14943\nIt is often recommended that the passphrase is stripped from the cert when it is used in an automated way (like restarting a web server that uses it).\nShouldn't rather vault PKI backend offer an option to automatically strip + offer the unencrypted PEM to the authenticated vault client?\nSo for the non-vault API, there could be an extra parameter to the passphrase file, if needed, \nwhen vault is used, a cert without passphrase is expected to be given to fabio.\nConcerning the Auth Backend for fabio against vault:\nWith an app authenticating against vault, a token is generated by vault \nand given back that then can be used for retrieving secrets from vault.\nOne way could be offering some kind of pre-auth script \nso the admin is free to any use authentication backend of vault \nwhich has to return a token to be used by fabio, each time when a cert has to be loaded or updated.\nThat pre-auth script should be ran as same user / in some system/container as vault itself.\n. I am really excited by this feature, together with HTTP2 support by Go 1.6 seeming soon coming out,\nI can finally use fabio as elastic HTTP2/1 reverse proxy solution.\nThere is a similar reverse HTTP proxy, https://github.com/EmileVauge/traefik, \nwhich from what I can find out about in its documentation, \nonly offers assigning certificate files via its config file,\nit doesn't seem to be planned to implement dynamic addition/update during runtime, \nneither vault backend support - so fabio would really have its edge here.\n. Further thoughts:\nCerts are assigned to common names which in turn are used by routes (route-prefixes).\ndomain1.com -> cert1.pem.\ndomain2.com -> cert2.pem\nroute1: domain1.com/whatever -> uses cert for domain1.com\nroute2: domain1.com/abc          -> uses cert for domain1.com\nroute3: domain2.com/123          -> uses cert for domain2.com\nSetting a cert that for an existing common name would override it (=reload),\nthis is necessary for certificate renewal.\n1. Fabio API: Set certificate for CN domain1.com\n2. Consul informs fabio about new service with prefix which uses CN domain1.com\n   The other way around would mean that fabio would first serve only HTTP, \n   when the certificate becomes available would start serving HTTPS, too.. OK, so Traefik reads the CN of each passed certificate file \nto determine automatically to what domains (and their routes) it applies:\nhttps://github.com/emilevauge/traefik/blob/4e9ff45747f9172809065fb63c6d0baca782dad1/integration/fixtures/https/https_sni.toml\nSomething similar with HTTP API would be great for fabio.\n. Addition: It may be a good starting point when for the beginning a folder of directories can be passed \nand fabio determines the right cert/key/chain files to use by CNAME (SNI).\nThis would allow using letsencrypt-auto with fabio.. Go 1.6 Beta came out: https://github.com/golang/go/releases/tag/go1.6beta1\nDocker image: strarsis/golang-nightly:build-1.6beta1-nightly-e2093cdeef8dcf0303ce3d8e79247c71ed53507d\n. Thank you for your answer.\nI got some old legacy PHP apps I want to put into containers and behind fabio, too.\nAnd those are not sharing their Session data.\nI guess it would make more sense refactoring them so they use a central session storage.. So I think I can close this issue now because this is an issue with the backend app, \nnot with the HTTP(S/2) frontend which shouldn't be used to fix this on a wholly different level?. ",
    "tino": "Is there any work being done on letsencrypt integration? I've started it as my first Go project this weekend, in the form of a separate binary that ~implements~ copies the registry code (and a lot more code \u263a\ufe0f) from here and generates certs for each domain if they don't exist yet. I envision a file and Vault store, that fabio then can use.\nOnce I get it roughly working I'll push it to a repo. Still got to think about reusing the urlprefix-mydomain.com/ tag, or going with a new letsencrypt-mydomain.com tag though. Think the latter would be cleaner.. Am I correct in reading this is only possible as a manual route override, and not in the urlprefix- service tag? Would be nice If I could set this directly on the service definition. Or how about fetching the basic auth credentials from Vault? Seems like a sensible place to put 'em.. What about a second tag?\nheaders-/foo hdr=\"x-foo: bar\" hdr=\"del x-foo\" hdr=\"add x-foo: baz\". We see the \"context cancelled\" at a rate of about 3% of all requests. \n\"TLS handshake error\" at about 0.3%.\nCPU load is negligable (couple %), RAM usage ~50MB.. weight 0 doesn't work in my testing (v1.5.2), as it sets the weight to be balanced, as is also mentioned in the Route weight docs: https://github.com/fabiolb/fabio/wiki/Routing#route-weight. I don't think it sorts correctly now, as it uses sort.String here, which yields: https://play.golang.org/p/-FwwAv39C0. There I've also tried sorting with the \"*\" removed, which makes sense for domains without url path I think.\nThe first question to answer is which part is more important: the domain part or the url part. Because basically all route definitions are domain.com/*, but you don't have to write that last *.\nI would say this makes sense for a default order of precedence:\n\nfoo.domain.com/bar/baz/\n/bar/baz/  <= Usefull if you always want to handle /auth/ centrally, or send /.well-known/challenge to letsencrypt \n*.domain.com/bar/baz/\nfoo.domain.com/bar/\nfoo.domain.com/\n*.domain.com/\n\nThis works based on length now, besides 2 (which might also be controversial), but it doesn't if we use:\n\npreeeefix.short.com/b/z/\n/b/z/  <= Usefull if you always want to handle /auth/ centrally, or send /.well-known/challenge to letsencrypt \n*.short.com/b/z/\npreeeefix.short.com/b/\npreeeefix.short.com/\n*.short.com/. That would be awesome! I'm up for working on a PR, but I've got no idea where to start atm \u263a\ufe0f. BTW, I added https://github.com/fabiolb/fabio/wiki/Contributing#developing, as it took me quite a while to find out how this works with Go. Might need some rewriting?. On the mutex part, I copied this from the route/table.go. Why is it needed there and not here?\n\nI held off on multiple custom error pages. In my view if you set an error code in the upstream service, you should also provide the content you want to serve, and fabio should not overwrite it.\nThis page is just for when the complete service could not be found, and is in sync with the Proxy.NoRouteStatus value, hence the \u2013 bit clumsy, but clearer then other things I could come up with \u2013 name. . Ah okay. I missed that.. I decided not to add a default HTML message. Although I would like not to serve a browsers default 503/404 by default to humans, it took me too much effort to cleanly implement with templates how I had it in mind.\nIs this mergeable as-is, or do you need some more changes? If so, we can start to remove our nginx instances that are in front of fabio atm \u263a\ufe0f. \"shouldn't happen often enough\" still means => I need to find time when I can incur downtime (albeit short). I agree with sielaq that this is the \"default\" behaviour of most daemon processes.\nI would for example use it when adding new listening ports for an TCP proxy implementation, FTP for example.\nOf course this can be done staggered when multiple fabio instances are used, but being able to combine with nomad + templating and SIGHUP would make it also possible on a single instance.. Agreed. True, I see that response on a HEAD request, where it shouldn't return that.\nHowever, would that block all logging? I don't see any other log besides those health checks that produce invalid logs, while fabio is routing a lot of traffic.\nRunning fabio locally (against the production Consul) I get:\n172.17.0.1 - - [06/Mar/2018:08:59:20 +0000] \"GET /status/ HTTP/1.1\" 200 117\ninvalid log msg: 2018/03/06 08:59:30 Unsolicited response received on idle HTTP channel starting with \"{\\\"services\\\": {\\\"mysql\\\": \\\"green\\\", \\\"postgresql\\\": \\\"green\\\", \\\"rabbitmq\\\": \\\"green\\\", \\\"redis\\\": \\\"green\\\"}, \\\"version\\\": \\\"2018.8.5\\\"}\"; err=<nil>\n172.17.0.1 - - [06/Mar/2018:08:59:30 +0000] \"HEAD /status/ HTTP/1.1\" 200 117\nwhich was 1 GET and 1 HEAD request. So then they both show up. \nAlso, the healtch checks that occur are actually GET requests (generated by Nomad), so I don't think the HEAD part is the problem?. Okay, found the culprit!\nFABIO_proxy_gzip_contenttype = \"^(text/.*|application/(javascript|json|font-woff|xml)|.*\\+(json|xml))(;.*)?$\"\nRemoving that makes it work :). Tried other regexes but that didn't make a difference.\nRenamed the issue.\nPs. thanks for making fabio start so fast, tried a lot of different configs \ud83d\ude0a. Yes, it is. But ^(text/.*)(;.*)?$ didn't work either. And when I break the regex fabio will crash so that shouldn't be the case.. Okay, I'm getting somewhere. If I apply this patch, it still doesn't log (so this doesn't change the handler, but just wraps it):\n```patch\ndiff --git a/proxy/gzip/gzip_handler.go b/proxy/gzip/gzip_handler.go\nindex 9cdf70d..0bc6ad3 100644\n--- a/proxy/gzip/gzip_handler.go\n+++ b/proxy/gzip/gzip_handler.go\n@@ -11,6 +11,7 @@ import (\n        \"bufio\"\n        \"compress/gzip\"\n        \"errors\"\n+       \"fmt\"\n        \"io\"\n        \"net\"\n        \"net/http\"\n@@ -36,17 +37,23 @@ var gzipWriterPool = sync.Pool{\n // body if the client supports it (via the Accept-Encoding header) and the\n // response Content-Type matches the contentTypes expression.\n func NewGzipHandler(h http.Handler, contentTypes regexp.Regexp) http.Handler {\n-       return http.HandlerFunc(func(w http.ResponseWriter, r http.Request) {\n-               w.Header().Add(headerVary, headerAcceptEncoding)\n+       fmt.Printf(\"Old handler: %z\\n\", h)\n+       nh := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n+               // w.Header().Add(headerVary, headerAcceptEncoding)\n            if acceptsGzip(r) {\n\n\ngzWriter := NewGzipResponseWriter(w, contentTypes)\ndefer gzWriter.Close()\nh.ServeHTTP(gzWriter, r)\nfmt.Println(\"GZIPPED\")\n// gzWriter := NewGzipResponseWriter(w, contentTypes)\n// defer gzWriter.Close()\nh.ServeHTTP(w, r)\n// fmt.Printf(\"GZIPPED\", )\n                } else {\nfmt.Println(\"NOT GZIPPED\")\n                        h.ServeHTTP(w, r)\n                }\n        })\nfmt.Printf(\"New handler: %z\\n\", nh)\nreturn nh\n }\n\ntype GzipResponseWriter struct {\nOutput:\nNew handler: %!z(http.HandlerFunc=0x1363f90)\nGZIPPED\nOld handler: &{%!z(func(http.Request)=0x136cb80) %!z(proxy.transport=&{0xc42013e0f0  }) %!z(time.Duration=0) %!z(log.Logger=)  %!z(func(http.Response) error=)}\n```\nIf I just make NewGzipHandler return h, logging works.\n~So appearently the new handler is making the logging change?~ Nvm, proxy.HTTPProxy.ServeHTTP actually exits at line 200, because h is not a direct httputil.ReverseProxy anymore but a http.Handler. I fail to see how the *httputil.ReverseProxy return value from proxy.newHTTPProxy becomes a http.Handler and couldn't figure out a way to prevent this.\nAny suggestions on how to tackle this?. \ud83d\udc4d\nWorks like a charm. Thanks!. I really don't know. From what I read psql (client and server) find the highest supported version by both. But it's fabio that takes care of the TLS, I haven't set up anything in the postgres server config.\nAny suggestion on things to check?. ",
    "ont": "@magiconair what is current state of fabio and letsencrypt integration?  mholt/caddy has letsencrypt integration but miss consul auto configuration. Fabio has autoconfiguration but miss letsencrypt auto-certificates. And traefik has very strange configs and bugs... . @leprechau yes, I understand it. But main benefit from integrating letsencrypt into fabio is to avoid management hell with webroot/.well-known dirs for each service which need SSL support.  And some services expose no webroot at all, only their api routes at http endpoint.. ",
    "leprechau": "@ont it's not currently supported IN fabio but there are ways of getting it done.  Vault is supported as a certificate store for fabio and there are third party projects that will handle renew of lets encrypt and push to vault (https://github.com/ketchoop/letsencrypt-to-vault).  There is also support for reading/refreshing certificates directly from the filesystem builtin to fabio so any system that writes letsencrypt certs to disk should work as well.. @ont Understood.  I was just trying to offer options until someone has time to work on full integration of letsencrypt with fabio.. Expanding a comment I made in #69 that linked to this issue.  I would not like to see a global option as that would not work with our current deployment.  We definitely need the ability to strip the route prefix from some applications but not others.\nThis requirement is absolutely due to the points raised by @msabramo about legacy and vendor applications were we do not have control over the observed prefix for the application without placing additional hacks before the application (htaccess/haproxy/etc..).  I find it much more convenient and sane to keep this logic in as few places as possible.  Spreading out individual hacks across several applications is much harder to maintain than keeping all of that close to the actual entry point (the load balancer).\nWe also run the majority of our applications out of docker containers including frontend javascript applications that don't have any real prefix knowledge and simply reference all resource relative to the request.  These applications benefit greatly from the ability to change routing prefixes without modifying the underlying code.\n. This is absolutely needed in our environment.  We're currently using a very complex consul-template design that is based on tags including \"proxy-standard\" and \"proxy-nostrip\".  Our standard tag does a regrep on the request and strips the route prefix before passing it on the the backend whereas the nostrip does the opposite.\n. I'm not sure I see the rationale to have this goto a file natively.  Running fabio under systemd, upstart or in a docker container allows you to easily get any stdout/stderr into a file with standard tools.. Termination of SSL/TLS enforcement of that access is extremely important in the LB stack.  I would expand this to say that the LB should also allow you to enforce ciphers and acceptable SSL/TLS versions.  This way you have a single place to configure your secure service policy.\n. It's currently a route setting.  You can set it for all paths on a host though. \nExample:\nroute add http-redirect www.example.com:80 https://www.example.com$path opts \"redirect=301\"\nThis will redirect any path coming to www.example.com on 80 to www.example.com with an https scheme.\n. We're currently doing something very similar with consul-template and HAProxy.  We let consul-template loop over all services in all DCs and enumerate them all as server lines under backend sections.  The services that are pulled from DCs NOT matching the local DC are added as backup under the backend block.  This is in effect a combination of a few of the above suggestions listing all services and having a weight attribute.. @jralph The consul-template file we're using is on GitHub but I wouldn't wish the task of using and/or maintaining this beast on anyone.  We're currently running fabio across our dev/qa/prod environments and trying to eliminate our HAProxy/consul-template implementation.\nhttps://github.com/myENA/consul-template-rpm/blob/master/SOURCES/consul-template-haproxy-template.ctmpl\n... and ...\nhttps://github.com/myENA/consul-template-rpm/blob/master/consul-template-haproxy.md\nIt's probably not an exaggeration to say this is an abuse of consul-template but it does work and served us in a production environment for over two years.. @jralph We're planning on deploying all services in at least two datacenters.. @jamessammut Did you ever find a solution to this?  We're seeing something similar with the latest 1.4.3 fabio release and rancher 1.6.0 . Just some quick researching it appears there isn't a real standard for what X-Forwarded-Proto should contain but Amazon and Mozilla at least seem to indicate it should only be http or https.  @magiconair have any thoughts about that?\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-Proto\nhttp://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html#x-forwarded-proto. @ket4yii awesome.  Thank you everyone for the work on this issue.. There are a few pieces of optional configuration stored in consul but the bulk of the route configuration comes from the specified registry backend.\nThe registry backends all conform to an interface defined in https://github.com/fabiolb/fabio/blob/master/registry/backend.go\nToday there are three existing registry definitions: file, static and consul\nSupporting kubernetes or rancher or any other provider of service information would involve contributing another registry backend.. This could potentially solve another issue for us that we are currently working around in text/template language using consul-template and HAProxy.  We have some legacy services that want to be exposed like /app.something.foo/ and consul doesn't support dots in service names so we register them with dashes and inside our template do this ...\n{{if in .Tags \"proxy-dash2dots\"}}{{.Name | replaceAll \"-\" \".\"}}{{else}}{{.Name}}{{end}}\nHaving support for templates and template options in fabio would be a great feature.\n. @magiconair Yes, sorry I'll get my thoughts together and submit another PR for that use case.  It really just occurred to me when you mentioned text/template in this discussion.\n. So out of curiosity how do you see this working?\nvault that would take a method and raw kv arguments...\nopts \"auth=vault:method=method:arg1=value:arg2=value\"\nhttp basic auth...\nopts \"auth=basic:user1:pass1,basic:user1:pass2\"\nhttp digest auth...\nopts \"auth=digest:user1:realm1:hash1,digest:user2:realm2:hash2\"\ndigest and basic...\nopts \"auth=digest:user1:realm1:hash1,basic:user1:pass1\"\nSeem reasonable?  Just trying to think how this could be implemented.  Would it try the definitions in order with fall-through? First match wins?. The reason I'm asking ... I could see this being an expansion to the ACL support that was recently added.. I was thinking that auth=vault: would indicate it was from vault.  The others would be handled strictly by fabio so we could have basic and digest handled by fabio for person(s) without vault running.\nMaybe it could be: auth=vault:method:path:arg1=val1:arg2=val2:arg3=val3\nExample for github to keep config short: auth=vault:github:auth/github/foo:token=xxxx\nThat would make the order of the options relevant but I think that would be okay as you would always need a method and path.  The prefix vault:, basic:, digest: would always be stripped off and used to signal how to parse the rest of the string.. I agree secrets are hard, but I can\u2019t think of a great way to offer basic auth without vault.  You could reference an htpasswd file stored in consul?  That\u2019s better than password in the route.. I also think it would be nice to add auth without needing to restart fabio.  If you only define the auth sources in the config you can\u2019t dynamically add auth to a route without restarting fabio.\nAllowing a file= or path= option on the route tag for basic and digest could work.  Allowing the user to reference an on disk or consul stored htpasswd file.. The route should be explicit.  When doing bath based routing even in HAProxy we always make sure our ACLs are /route/ ... terminated with a trailing slash.  This ensures that the behavior you posted doesn't happen.\n. I'd be happy to review/comment on the PR.. @TargetFocussed we use anycast  BGP within our infrastructure to provide scale out and resiliency of our reverse proxy layer.\nThat's just one way though ... you can do similar with standard Linux hosts using keepalived or other similar tools that provide virtual IP sharing between hosts.. As pointed out by Frank above, you can have a different urlprefix tag configured on each Fabio instance.   You could have alb1 and alb2 instead of the default urlprefix on those instances and tag the consul services accordingly.. @shantanugadgil I mean that in your example above you have two fabio instances:\nalb1.foo.com and alb2.foo.com both pointing to the same consul cluster ...\nYou want alb1 to only expose services meant for v1 apps and alb2 to only expose services for v2 apps. You can do this by setting the tag prefix on each host.  From the documentation:\n```\nregistry.consul.tagprefix configures the prefix for tags which define routes.\n\nServices which define routes publish one or more tags with host/path\nroutes which they serve. These tags must have this prefix to be\nrecognized as routes.\n\nThe default is\n\nregistry.consul.tagprefix = urlprefix-\n```\nIf you modify the configuration for alb1.foo.com to be registry.consul.tagprefix = alb1- and alb2.foo.com to be registry.consul.tagprefix = alb2- then you can choose which proxy advertises a service by how it is tagged.\nWhen you register \"appv1foo\" you tag it alb1-/foo/ and when you register \"appv2foo\" you tag it alb2-/foo/.  Now, when you access alb1.foo.com/foo/index.html you will be sent to the service tagged with alb1-/foo/ and when you access alb2.foo.com/foo/index.html you will be sent to the service tagged with alb2-/foo/.\nDoes that help?. @shantanugadgil Great, glad that helped.. So it seems as though golang isn't properly telling OpenBSD how to configure the socket.  The protocol not available error is a raw OpenBSD errno (http://man.openbsd.org/errno.2).  These are wrapped by the golang syscall package (https://golang.org/src/syscall/zerrors_openbsd_amd64.go).\nIs it possibly related to this bug: https://golang.org/src/net/ipsock.go?s=233:577#L3 ??. Disabling keepalive probably isn't a good solution for a production workload.. Nice, gotta love OpenBSD for those network tunables. . @sethvargo Sorry if this got put to the backlog.  Is this still something that's needed mainline in fabio?  Sorry for asking a redundant question if this has already be covered elsewhere.. Think I found a winner ... it's not RFC 1422 compliant but it does generate unique IDs and it does it very fast.  The other standard UUID packages around github do won't meet the 20k/s request requirement.\nCode\n```go\npackage main\nimport (\n    \"fmt\"\n    \"testing\"\nguuid \"github.com/google/uuid\"\nmuuid \"github.com/m4rw3r/uuid\"\nfuuid \"github.com/rogpeppe/fastuuid\"\nsuuid \"github.com/satori/go.uuid\"\n\n)\nfunc BenchmarkV4Google(b *testing.B) {\n    for i := 0; i < b.N; i++ {\n        guuid.NewRandom()\n    }\n}\nfunc BenchmarkV4Satori(b *testing.B) {\n    for i := 0; i < b.N; i++ {\n        suuid.NewV4()\n    }\n}\nfunc BenchmarkV4m4rw3r(b *testing.B) {\n    for i := 0; i < b.N; i++ {\n        muuid.V4()\n    }\n}\nfunc BenchmarkFastUUIDRaw(b *testing.B) {\n    g := fuuid.MustNewGenerator()\n    for i := 0; i < b.N; i++ {\n        g.Next()\n    }\n}\nfunc BenchmarkFastUUIDFormatted(b *testing.B) {\n    g := fuuid.MustNewGenerator()\n    for i := 0; i < b.N; i++ {\n        _ = fmt.Sprintf(\"%x\", g.Next())\n    }\n}\n```\nResults\nahurt1:uuid-test ahurt$ go test -bench . -benchtime 10s\nBenchmarkV4Google-4             10000000          1292 ns/op\nBenchmarkV4Satori-4             10000000          1272 ns/op\nBenchmarkV4m4rw3r-4             10000000          1285 ns/op\nBenchmarkFastUUIDRaw-4          1000000000          20.0 ns/op\nBenchmarkFastUUIDFormatted-4    30000000           505 ns/op\nPASS\nok      github.com/leprechau/uuid-test  80.111s\nahurt1:uuid-test ahurt$\nEven with the formatting being done by the relatively heavy fmt package the fastuuid package is the clear winner and would exceed the required performance metric.. @magiconair Done.  I put the formatter and test here: https://github.com/leprechau/uuid-test\n@bkmit Feel free to use/adopt as needed.. @johnypony3 feel free to submit a PR to adjust the project Dockerfile.  The required changes should be adding a USER directive and a setcap execution before dropping privileges.. Would you consider this to be duplicative of support for consul connect and intentions?. No, I'm trying to think of the use case for client certificate authentication and evaluate the work required vs audience for that feature vs other methods of authenticating/authorizing services like consul connect and intentions.. Just a general question as it relates to some things we've been investigating as well.  Do you specifically need route prioritization or would a general most specific match priority work?\nWith a most-specific-match first assuming you had the following tags:\nurlprefix-foo.domain.com/foo\nurlprefix-foo.domain.com/\nurlprefix-*.domain.com/\nA request to https://foo.domain.com/foo/bar would always hit the first route.  Requests to https://foo.domain.com/asdf would hit the second and a request to https://bar.domain.dom/foo would hit the last 'catch all' route.. It wouldn't be perfect but I think you could get very close to 'most-specific' by just checking the matches (urlprefixes) sorted by length (longest first).  This might be easier to implement and also resolve the issue along with documentation of how it works?. Right, that was the 'very close' part of the above comment :) ... it's absolutely not perfect but it may be less logic than actually trying to analyze the specify of the match.  I have no real skin in the game at the moment, just trying to float some ideas.  I'm sure @magiconair has his own thoughts on the matter.. Looking at the code a bit this may be how it is already supposed to function:\nhttps://github.com/fabiolb/fabio/blob/master/route/table.go#L90-L93. Looked through the code some more and found the sort.Sort() definitions.  If I'm not mistaken it should work as you want now.\nhttps://play.golang.org/p/ZfspewZRxC\nReally curious about the exact routes you are using now.  Doing it by length is definitely wrong after looking at the output of my playground test.. @tomwganem Could you post a trace log?\nhttps://github.com/fabiolb/fabio/wiki/Features#request-tracing. I can imagine a similar but maybe slightly different situation where fabio and the consul cluster it is attached to are healthy.  The consul health checks are passing because the agents responsible for those checks can reach the services but fabio cannot reach those services.\nSomething like:\nfabio (10.1.0.12) -> consul localhost:8500\nservice (172.16.0.22) -> consul localhost:8500\nThe consul agent nodes are communicating properly with the server nodes and updating the catalog health data but fabio on 10.1.0.12 cannot route directly to the service running on 172.16.0.22 for whatever reason.\nI believe that situation would result in fabio timing out when trying to route traffic to that service.  I have no idea how that situation should be handled or if that is even fabio's responsibility.. Yes, we were just discussing doing this last week but it looks like you beat us to it.  Thank you, this is one of the few things we're still using HAProxy for on the frontend. . Looks like golang tip and the Vault checks aren't getting along.. I can comment on how it's done with HAProxy where we do our http to https redirects.\nredirect scheme https code 301 if { hdr(Host) -i my.ena.com } !{ ssl_fc }\nWe have that syntax in our main frontend that binds on both 80 and 443 and redirects any request coming in with a Host header of  my.ena.com to the exact same URI but using the https scheme.  \nWhen I request http://my.ena.com/foo/bar/thing.html I will get a 301 redirect to https://my.ena.com/foo/bar/thing.html with the above configuration. . The pseudo variable would be very flexible and is also less ambiguous than magic based on trailing vs non-trailing slash paths.. This is indeed not trivial and even load balancers that implement reload still have downtime.  HAProxy is a perfect example where you can reload an entire configuration but there is much more to consider.  What happens to existing connections if the route to them is deleted?  What about websockets and other long-running connections that prevent a graceful shutdown and reload?  That's just a few of the issues but those were enough to make us restart HAProxy vs reload anytime the configuration changed and live with a few possible dropped connections between the anycast instances.\nTrue zero downtime reload isn't in the scope of the load balancer process itself.  There is a good blog post from Yelp about how they got a real zero downtime reload working with os level connection queuing.  The same should in theory work with fabio or any other network service.. Registrator will read environment variables from the container to set the service name, port and tags sent to consul.  You can put those in a docker-compose file, in the actual Dockerfile, or via docker cli with the -e switch.. See here for the general service options:\nhttp://gliderlabs.github.io/registrator/latest/user/services/#service-object\nHeath checks (you will need one) here:\nhttp://gliderlabs.github.io/registrator/latest/user/backends/#consul. You need consul to register the service with the urlprefix- tag and setup a health check for the service before fabio will publish it.  To do that via registrator only using docker without a modified Dockerfile or a compose file you will need to pass the various SERVICE_  environment variables to define the service entry and health check.  This is exactly what we do with our non-consul aware frontend containers.. You don\u2019t need to pass anything to the registrator run command ... you need to pass environment settings to the containers you want registrator to handle.. The -tags option to registrator itself is global.  It doesn't make much sense to set the exact same urlprefix- tag on every service.  You want that tag to reflect the actual path and/or port of each service so it should be set per container.  That is why you want to use the environment variables and the various SERVICE_ options such as SERVICE_NAME and SERVICE_TAGS.. @magiconair Seems like this question has come up before.  Would you like a PR with some documentation around fabio+registrator in the wiki?  Possibly under the Service Configuration section?. Okay, I'll give it a go.. You already have a full example there for registrator.  I just didn't see that before.  That's the answer to the issue.\nhttps://github.com/fabiolb/fabio/wiki/Features#registrator. I added a link to the registrator information into the side menu to make it easier to find with a search of the main page.. @GastroGee @talksinmath @k1ng87 ...\nWe're using nomad and fabio for multiple deployments with path based routing.  This is probably reaching your container but not at the path the container expects.  You probably want the tags to look like:\ntags = [ \"urlprefix-/foo/ strip=/foo\" ]\nWith this tag the underlying service will get the request on / and not /foo which it doesn't know how to handle.. fixed and forced pushed, will create another pr. I put the response header bits in a new function  under http_headers.go called addResponseHeders and added a new TestAddResponseHeaders to http_headers_test.go.  Currently the STS headers are the only things being added via the addResponseHeaders function but I assume that could change in the future.. Yes, I have this running in a dev environment and the STS header is added to the response.\nI\u2019ll get the docs and extra tests going today.\n. Okay, the docs, configuration tests and integration test are now committed.. You may be able to register existing services and checks with CatalogRegistration but I'm not sure that has the intended result.  I'll check locally and see how it works.\nUpdate: No, that does not have the intended effect.. We currently run gobgp as a route reflector and quagga on our load balancers and use anycast BGP for our HA as well.  We've been talking internally about linking fabio with the gobgp library or weather it makes more sense to have a generic fabio like service that publishes BGP routes based on Consul data rather than HTTP routes.\nOn the other hand if you think of fabio as a generic routing table with multiple publishing options (HTTP, HTTPS, TCP, TCP+SNI) maybe BGP is just one more publishing method that could be used with a similar routing table syntax.\nWe've had alot of discussions on how this would work and would like the solution to be able to not only publish fabio itself but also publish containers for direct access on the LAN.. To elaborate further we have a pair of upstream Cisco devices that are the authoritative peers that we call service routers.  These pair with a set of GoBGP VMs that act as route reflectors for applications participating in anycast BGP advertisements.  The load balancers, dns cache, etc. currently run quagga and advertise a /32 route up to the route reflectors.  This works very well to provide HA within and across datacenters for our public services.  We want to expand this system internally to expose our Docker network in a simpler manner.\nToday our Docker hosts are running with a fixed CIDR block carved our of a larger super block.  Each host is part of a VXLAN that terminates to a pair of machines acting as the gateway for the superblock.  The VXGs (VXLAN Gateways) advertise a route for the superblock upstream and in turn know where to send a request for any particular container because it is aware of the fixed CIDR assigned to each Docker host.  We would like to eliminate the VXGs and the need for fixed CIDR blocks per Docker host by having a service on each host that would directly advertise /32 routes for each container up to the route reflectors.  I think this is a case fabio could handle and give us a familiar interface for HTTP, TCP and BGP services.. @galen0624 yes, we have looked at Calico and that is what we're currently playing with in the lab.  Calico goes far further and is far more complex however than what we actually need for our environment.  That being said we are also looking at k8s which again is far more complex than anything we actually need.. > @leprechau Are you still using gobgp for your route reflectors? We are looking to stand up some route reflectors as well in the near future and gobgp looks like a good option. Just wondering how your experience has been.\n@murphymj25 sorry for the late reply.  Yes we are still using gobgp in combination with fabio and aardvark (an application we wrote) to expose our containers on a weave network via bgp.  Feel free to reach out via email if you want to discuss further.. I was working on a PR for this exact thing or very similar.  A few options to allow simple ACL type behavior.\nExample:\nonly allow traffic from the specified source blocks (default deny)\nurlprefix-/foobar/ allow=172.16.0.0/12,10.0.0.0/8,192.168.0.0/16\nallow all traffic except traffic from the specified source blocks (default allow)\nurlprefix-/foobar/ deny=1.0.1.0/24,1.0.2.0/23\nSpecifying an allow and deny option on the same route would result in an error.. @microadam would that address your need?  @magiconair have any suggestions around that approach?. That's true, it wouldn't be the actual source at that point but the \"declared\" source from proxyproto.  I think that's addressable via documentation unless you feel otherwise.  The other option would be to preserve the original remote address separate from proxyproto but I haven't looked how much structural change that would entail.. In our use case we have some services that need to be exposed via the load balancer but shouldn't necessarily have complete unrestricted access.  We could use firewall rules on the load balancer itself but that would require dedicated IPs or bind ports for those specific services.  Having a light ACL option on the route would allow this to happen without needing dynamic listeners.. To the IPv6 part the net.ParseCIDR and the IPNet.Contains function support IPv6 blocks and addresses.. Those are all valid points.  I agree that having a single allow with a filter function is preferred over having allowCIDR=, allowMethod=, etc..  that could messy pretty quick.. Yes, I was going to isolate that into a separate getRemoteIP function or something similar.  I have the CIDR processing done but I need to work on putting the option processing into it's own function to check for subgroups (allow=ip:1.2.3.4,method:GET) processing.  Hope to have a PR ready early next week, possibly Monday, depending on the weekend schedule.  I need to write some test cases too :). @magiconair It currently only supports the ip: prefix for the allow and deny tags but I think I made if flexible enough to be expanded in the future if anyone so desires.. @microadam would appreciate your feedback as well ... especially if you can build the code in the PR and let me know how it works for you.. Oops, forgot to link this to #439. It seems the tests are randomly failing with a timeout around some consul interaction.  I've seen the different go versions succeed and fail at different times with the same code by just amending the commit and doing force push.. I've fixed the security hole in the latest commit.. @magiconair I think that's it unless you have other suggestions or requests.. @microadam are you able to test and verify?. @microadam I could post a binary at my fork of the repo if that makes it easier.  Not sure how comfortable you would be with that though ... and I completely understand.. Linux amd64?. Okay, awesome ... let me know if you need anything else.. Interesting ... can you turn on access logging just to see what IP fabio sees your connection coming from?  There is probably a NAT between you and the vbox host.  To be really sure you could switch it to  deny=0.0.0.0/0 that would block everything ... or almost the same an allow=127.0.0.100/32 should pretty much block everything.. @microadam np, thanks for the testing!  There are some markdown docs in the commit but I think you have the syntax right now.. Also, just realized my own example up there was wrong ... sorry about that.  At least the error message works \ud83d\ude02. Thanks for the feedback.  Internally the code is using the golang core net package.  Specifically it's using the ParseCIDR and Contains functions.\nhttps://golang.org/pkg/net/#ParseCIDR\nhttps://golang.org/pkg/net/#IPNet.Contains\nThey support both IPv4 and IPv6 but will not transit boundaries.  So, for the first example with deny=ip:0.0.0.0/0 that will match ALL IPv4 addresses but will not match IPv6 addresses.  The [::1] request source is IPv6 localhost.\nThe second part is also a side affect of the ParseCIDR function.  192.168.0.252 is not in proper CIDR notation.  To specify a single IP address in CIDR form it would be 192.168.0.252/32 (a 32 bit mask denotes a single address).\nTo stopping server operation and/or ignoring the route I have mixed feelings.  The current behavior for invalid options adds the route but just ignores the bad options.  I kept his same behavior for the allow and deny options.  It is completely possible to either skip the route (not add it) or stop the server if route parsing fails.  However, since routes may be added dynamically I don't think stopping the server for an invalid route option makes any sense.. Awesome, thank you for the feedback and testing.\n@magiconair any other thoughts or concerns?  What do you think about skipping the route on failure for allow/deny processing?  Just putting a continue in the loop if the process function returns error?. You could check for a string contains and add the /32 prefix when there isn\u2019t a match.  I can see this possibly confusing some people.\nI\u2019m not sure an all is needed with the current behavior.  The code currently only allows one of allow or deny to be specified.  When using the allow option all sources not matched by the allow are denied (default deny).  When using the deny option all sources not matched by the deny are allowed (default allow).\nI tried to explain that in the added documentation as well.. I added some code to add a /32 prefix to value strings that do not contain a / ... invalid or incomplete addresses will still error out in the ParseCIDR function.. That's a good question ... would require a bit more pre-parsing but I think it's doable and probably good to be consistent.. Latest commit should properly add a /32 prefix to plain IPv4 addresses and a /128 prefix to plain IPv6 addresses.. Last commit added equal test coverage for IPv4 and IPv6 addresses.. I had to export the ProcessAccessRules function that hangs off of route.Target in access_rules.go in order to process the rules for the integration test.\nI also moved the deny logging into the denyByIP function in access_rules.go to make it easier to alter if needed in the future.. @taemon1337 Usually that's due to using an image that doesn't have /bin/bash such as a scratch or Alpine Linux container.  The default entrypoint being /bin/bash causes that problem.  More generally it's because whatever you have specified as your entrypoint doesn't exist inside the container.. something like ...\nroute add http-redirect www.example.com:80 https://www.example.com$path opts \"redirect=301\". when doing http -> https the match host needs to have the port or else you will get a redirect for sure. That's odd ... that's literally the exact copy/paste from our production config with the hostname changed.. So, I'm assuming that go.staging.budbee.com == some.domain.example.com ...\nSecondly have you tried removing the trailing slash from the route match?\nMeaning some.domain.example.com:80 instead of some.domain.example.com:80/ ... also are you sure the target backend service is not doing any additional redirect?  I find it a bit odd that you are getting mixed HTTP/1.1 and HTTP/2 redirects.. Can you post a full log of ...\ncurl --http1.1 --max-redirs 3 -vL go.staging.budbee.com. So it looks like you switch to a different host for the port 443 request than the port 80 request.  Is it possible there is a difference in configuration between those two hosts?. Something really strange is happening ... it's almost like there are two redirect rules defined.  The first request clearly matches go.staging.budbee.com:80 that you have defined for the posted http-redirect.  However it looks like the second request to go.staging.budbee.com:443 is also matching a redirect route.  That could be a specific route for https://go.staging.budbee.com/ or a plain non-port specific host route go.staging.budbee.com.. Hrm.... I wonder ... what if you try something like ...\nroute add http-redirect echo.staging.budbee.com:80/ https://echo.staging.budbee.com$path opts \"redirect=301\"\nroute add http-echo / http://10.0.62.158:26296/ tags \"http-echo\"\nroute add http-echo / http://10.0.61.154:23384/ tags \"http-echo\"\n. So in the service definition ...\nname = \"http-echo\"\n                tags = [\"http-echo\",\"urlprefix-/\"]\n. Okay, I'm stumped.  The above config looks pretty simple to reproduce I'll see if I can make this happen locally.. One last thought ... you have the AWS load balancers in-front of fabio in this case, right?  I don't have much experience with AWS ... is it possible this is a case where the two load balancers are fighting?  Is the AWS load balancer terminating SSL and then forwarding as plain HTTP back to fabio?  Do you have a way to test direct to the fabio instance without going through the AWS load balancer?. Looks related to #450 ... is this the same issue?. @atillamas Yes, I think this is the same problem being described in #450 for sure and you're already on the same track.\nI was just looking at that same spot in the code but I think the logic needs to go elsewhere.  Basically we need it to not even mark the target as a redirect which would happen much earlier.. @atillamas  maybe something like this in the Lookup function in table.go around line 318 ...\ngo\n    // find matching hosts for the request\n    // and add \"no host\" as the fallback option\n    hosts := t.matchingHosts(req)\n    hosts = append(hosts, \"\")\n    for _, h := range hosts {\n        if target = t.lookup(h, path, trace, pick, match); target != nil {\n            if target.RedirectCode != 0 {\n                redirectURL := target.GetRedirectURL(requestURL)\n                if redirectURL.Scheme == \"https\" && req.Header.Get(\"X-Forwarded-Port\") != \"443\" {\n                    continue\n                }\n            }\n            break\n        }\n    }\nCompletely untested but I think we need to prevent the redirect route from being returned by the lookup function based on your condition.. Maybe try something like that and post some logs with tracing enabled?. @atillamas gotcha ... sorry about that.  I was just trying to think of how to prevent the redirect from occurring and get the \"correct\" target returned.  Maybe it could be as simple as still returning the target but setting the redirect code to 0 ... that would effectively return the same route target but ignore the redirect option.. @atillamas understood.  I'll try and take a stab at a few options using your example route table above.. Okay, so I think I have working code but I'm not sure it's the best way as it assumes that an upstream https source is always going to be 443 but maybe that's okay.\nThe patch ...\ndiff\ndiff --git a/route/table.go b/route/table.go\nindex 8e74bde..898ff1a 100644\n--- a/route/table.go\n+++ b/route/table.go\n@@ -326,6 +326,10 @@ func (t Table) Lookup(req *http.Request, trace string, pick picker, match matche\n        hosts = append(hosts, \"\")\n        for _, h := range hosts {\n                if target = t.lookup(h, path, trace, pick, match); target != nil {\n+                       if target.RedirectCode != 0 && target.URL.Scheme == \"https\" && req.Header.Get(\"X-Forwarded-Port\") == \"443\" {\n+                               log.Print(\"[DEBUG] Ignoring https redirect from https upstream\")\n+                               continue\n+                       }\n                        break\n                }\n        }\nThe test table:\nroute add http-redirect echo.localtest.me:80/ https://echo.localtest.me/$path opts \"redirect=301\"\nroute add http-echo1 echo.localtest.me/ http://localhost:15678/ tags \"http-echo1\"\nroute add http-echo2 echo.localtest.me/ http://localhost:25678/ tags \"http-echo2\"\nRunning fabio as:\nsudo ./fabio -log.level=TRACE -proxy.addr=\":80\" -insecure\nXFP 80 request:\n```\n$ curl -vvv -H \"Trace: xxx\" -H \"X-Forwarded-Port: 80\" http://echo.localtest.me/\n   Trying 127.0.0.1...\n TCP_NODELAY set\n* Connected to echo.localtest.me (127.0.0.1) port 80 (#0)\n\nGET / HTTP/1.1\nHost: echo.localtest.me\nUser-Agent: curl/7.54.0\nAccept: /\nTrace: xxx\nX-Forwarded-Port: 80\n< HTTP/1.1 301 Moved Permanently\n< Content-Type: text/html; charset=utf-8\n< Location: https://echo.localtest.me/\n< Date: Tue, 13 Mar 2018 20:20:13 GMT\n< Content-Length: 61\n<\nMoved Permanently.\n\n\nConnection #0 to host echo.localtest.me left intact\n```\n\n2018/03/13 15:20:13 [TRACE] xxx Tracing echo.localtest.me/\n2018/03/13 15:20:13 [TRACE] xxx Match echo.localtest.me:80/\n2018/03/13 15:20:13 [TRACE] xxx Routing to service http-redirect on https://echo.localtest.me/$path\nXFP 443 request:\n```\n$ curl -vvv -H \"Trace: xxx\" -H \"X-Forwarded-Port: 443\" http://echo.localtest.me/\n   Trying 127.0.0.1...\n TCP_NODELAY set\n* Connected to echo.localtest.me (127.0.0.1) port 80 (#0)\n\nGET / HTTP/1.1\nHost: echo.localtest.me\nUser-Agent: curl/7.54.0\nAccept: /\nTrace: xxx\nX-Forwarded-Port: 443\n< HTTP/1.1 200 OK\n< Content-Length: 6\n< Content-Type: text/plain; charset=utf-8\n< Date: Tue, 13 Mar 2018 20:20:39 GMT\n< X-App-Name:\n< X-App-Version: 0.2.4\n<\nhello\n* Connection #0 to host echo.localtest.me left intact\n```\n\n2018/03/13 15:20:39 [TRACE] xxx Tracing echo.localtest.me/\n2018/03/13 15:20:39 [TRACE] xxx Match echo.localtest.me:80/\n2018/03/13 15:20:39 [DEBUG] Ignoring https redirect from https upstream\n2018/03/13 15:20:39 [TRACE] xxx Match echo.localtest.me/\n2018/03/13 15:20:39 [TRACE] xxx Routing to service http-echo2 on http://localhost:25678/. From the caps you posted above it looks like AWS is also sending X-Forwarded-Proto ... that might be better to check than X-Forwarded-Port.. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html#x-forwarded-proto\nJust confirmed this diff also works ... new tests and config below ...\nThe patch:\ndiff\ndiff --git a/route/table.go b/route/table.go\nindex 8e74bde..0ac8dd2 100644\n--- a/route/table.go\n+++ b/route/table.go\n@@ -326,6 +326,10 @@ func (t Table) Lookup(req *http.Request, trace string, pick picker, match matche\n        hosts = append(hosts, \"\")\n        for _, h := range hosts {\n                if target = t.lookup(h, path, trace, pick, match); target != nil {\n+                       if target.RedirectCode != 0 && target.URL.Scheme == \"https\" && req.Header.Get(\"X-Forwarded-Proto\") == \"https\" {\n+                               log.Print(\"[DEBUG] Ignoring https redirect from https upstream\")\n+                               continue\n+                       }\n                        break\n                }\n        }\nThe test table:\nroute add http-redirect echo.localtest.me:80/ https://echo.localtest.me/$path opts \"redirect=301\"\nroute add http-echo1 / http://localhost:15678/ tags \"http-echo1\"\nroute add http-echo2 / http://localhost:25678/ tags \"http-echo2\"\nRunning fabio as:\nsudo ./fabio -log.level=TRACE -proxy.addr=\":80\" -insecure\nX-Forwarded-Proto http request:\n```\n$ curl -vvv -H \"Trace: xxx\" -H \"X-Forwarded-Proto: http\" http://echo.localtest.me/\n   Trying 127.0.0.1...\n TCP_NODELAY set\n* Connected to echo.localtest.me (127.0.0.1) port 80 (#0)\n\nGET / HTTP/1.1\nHost: echo.localtest.me\nUser-Agent: curl/7.54.0\nAccept: /\nTrace: xxx\nX-Forwarded-Proto: http\n< HTTP/1.1 301 Moved Permanently\n< Content-Type: text/html; charset=utf-8\n< Location: https://echo.localtest.me/\n< Date: Tue, 13 Mar 2018 20:36:43 GMT\n< Content-Length: 61\n<\nMoved Permanently.\n\n\nConnection #0 to host echo.localtest.me left intact\n```\n\n2018/03/13 15:36:43 [TRACE] xxx Tracing echo.localtest.me/\n2018/03/13 15:36:43 [TRACE] xxx Match echo.localtest.me:80/\n2018/03/13 15:36:43 [TRACE] xxx Routing to service http-redirect on https://echo.localtest.me/$path\nX-Forwarded-Proto https:\n```\n$ curl -vvv -H \"Trace: xxx\" -H \"X-Forwarded-Proto: https\" http://echo.localtest.me/\n   Trying 127.0.0.1...\n TCP_NODELAY set\n* Connected to echo.localtest.me (127.0.0.1) port 80 (#0)\n\nGET / HTTP/1.1\nHost: echo.localtest.me\nUser-Agent: curl/7.54.0\nAccept: /\nTrace: xxx\nX-Forwarded-Proto: https\n< HTTP/1.1 200 OK\n< Content-Length: 6\n< Content-Type: text/plain; charset=utf-8\n< Date: Tue, 13 Mar 2018 20:35:10 GMT\n< X-App-Name:\n< X-App-Version: 0.2.4\n<\nhello\n* Connection #0 to host echo.localtest.me left intact\n```\n\n2018/03/13 15:35:10 [TRACE] xxx Tracing echo.localtest.me/\n2018/03/13 15:35:10 [TRACE] xxx Match echo.localtest.me:80/\n2018/03/13 15:35:10 [DEBUG] Ignoring https redirect from https upstream\n2018/03/13 15:35:10 [TRACE] xxx Match /\n2018/03/13 15:35:10 [TRACE] xxx Routing to service http-echo1 on http://localhost:15678/\n. Maybe the log message should be TRACE instead of DEBUG .. but it works.  Just not sure if there are side affects unknown.  The builtin test suite still passes with the above patch applied.. I'll open a PR for further discussion.. I thought about that ... but would you want to skip an upstream http request that matched an http redirect to a different location?  I guess what we really want is to only do the redirect if the upstream scheme == redirect target scheme AND upstream host == redirect target host.  I'm not sure how we get the upstream host though.. That's a very good point.\nSo more generically we want to prevent redirect loops.  The initial case was a simple scheme redirect (http -> https) but that does not cover all use cases.\nHow about this ...\n\ntarget.RedirectCode != 0\ntarget.URL.Scheme == X-Forwarded-Proto\ntarget.URL.Hostname() == req.URL.Hostname()\ntarget.URL.Path == req.URL.Path\n\nIf all the above are true ... skip to prevent a redirect loop.\n. I added another commit to the PR to address these cases and make the redirect protection more generic while still satisfying the original request.. Interesting ... wonder how the request hostname is empty?  The path I can see that / and empty should be considered the same.  Maybe a blank host should be considered a match as well?. Yes, I reworked it an pushed another commit to PR #466 ... can you see if this now works in your AWS environment as expected?  I was trying to avoid calling GetRedirectURL in the lookup function initially.  However, that's probably where it belongs.  I renamed GetRedirectURL to BuildRedirectURL and modified it's behavior to cache the build URL object in the target.  This means we can call it in the lookup function (when target.RedirectCode !=0) and not have to call it again in http_proxy.go.. I\u2019m assuming in this case that req.URL.Path is just / and that should be the default for the redirect target?  I\u2019ll make another update shortly.. @atillamas Great!  Just pushed one last commit that should make it work without having to fully qualify the redirect target in your config.. Awesome, thanks for the patience and testing.. @magiconair Thank you!  Without you Fabio wouldn't exist :). @atillamas That is intentional.  Trusting the XFF header without also validating the source IP makes adding rules pointless.\nThink of this scenario:\nYou have an allow=ip:127.0.0.1/8 because you want to restrict a route to localhost.  If you do not validate both source and XFF header anyone on the internet can do: curl -H 'X-Forwarded-For: 127.0.0.1' some.host/route and gain access to your route.\nThe only way to make it secure is to validate both the XFF header you expect AND the actual upstream load balancers.  Meaning you will need at least two allows.. The allow rule should enforce that the remote address and the XFF, if present, be inside the allowed mask(s).. The test cases should cover that.  There are several scenarios around XFF and the remote source address.  Keep in mind that the code currently only inspects the first member of the XFF header as per spect that should be the nearest upstream peer.\nhttps://github.com/fabiolb/fabio/blob/master/route/access_rules_test.go#L167-L202. Right, that bit of code should be correct.  The leftmost element of the field should be the client.\nhttps://en.wikipedia.org/wiki/X-Forwarded-For#Format\nThe behavior of proxies is to add/set the XFF header to the remote address (client) if it is not present or append the header if it already exists.\nThat should mean that if you allow the address(s) of the ALB and the address(s) of the client(s) you want to be able to access the route it should work.\nMaybe I am missing something here.. More specifically if you have this sequence of events:\nClient (1.2.3.4) -> Proxy (3.4.5.6) -> fabio (7.8.9.0) -> The XFF at fabio should be 1.2.3.4,3.4.5.6 and you would need to allow both the client 1.2.3.4 and the immediate prior proxy 3.4.5.6\nThe reason ... fabio needs to know who it can trust in this scenario and not blindly accept the XFF header.  You can use the XFF header to allow clients but we also need to validate the remote peer (the proxy) so we don't accept XFF headers from unknown parties.\nOnly the client part of the XFF will be validated and the proxy address will be validated by the remote addresses seen by fabio.  The \"client\" to fabio ... the re-originator of the request.\nMake sense?\n. That is because you are tricking the ALB by sending an XFF header with curl.  If you do not pass an XFF header with curl the XFF after the ALB should only be the client.  The ALB (like most proxies) will not replace an existing XFF it will simply append it.. So you are saying you can bypass the allow list?. Sorry, I wasn't following that.. That is the correct behavior ... like I said proxies will only append.  If an XFF header already exists it will append what it sees as the client (the client that connected to that proxy) to the end of the header.  However, the original client (client that was before any proxy) should still always be the first member of the XFF header.\nThat being said ... I think what you are describing is another issue.  Let me clarify if possible.\n\nYou are using the 1.5.8 release\nYou have a rule on a route that says: allow=ip:10.0.0.0/8,ip:1.2.3.4\nThe proxy is listening on 3.4.5.6 which is not in any of the allowed blocks\nYour client is coming from 7.8.9.0 which is not contained in either of the allowed blocks\nYou can make a request from 7.8.9.0 with an XFF header using an allowed host and the request succeeds\n\nIs that all correct?. XFF header semantics aside ... what is the IP of the ALB that sits before fabio?  What does fabio see as the \"source\" of that connection?. Just looking at the code a client should have to fall through both checks in order to be allowed.  The only exception would be an error in the first part of the AccessDeniedHTTP function.\nIf this error is printed the request would be allowed ...\nhttps://github.com/fabiolb/fabio/blob/master/route/access_rules.go#L22-L26\nMoving on the next check is for the actual remote address ... this only returns on a deny ...\nhttps://github.com/fabiolb/fabio/blob/master/route/access_rules.go#L22-L26\nNext we have the whole XFF parsing and checking ... this also only returns on a deny ...\nhttps://github.com/fabiolb/fabio/blob/master/route/access_rules.go#L22-L26\nLastly we return false if and only if the previous two sections did not return ....\nhttps://github.com/fabiolb/fabio/blob/master/route/access_rules.go#L53-L54\nI'll setup some local test cases and see what if anything I can pinpoint.. With stock 1.5.8 with a very basic setup I cannot reproduce this.\nHere is my setup .. all running locally on one machine.  I have made an ip alias for 127.0.0.2 on the loopback the test a different source.  On a mac that is sudo ifconfig lo0 127.0.0.2 netmask 255.255.255.255 alias\nTerminal 1:\ngo get github.com/hashicorp/http-echo\nhttp-echo -text=\"hello\"\nTerminal 2:\nconsul agent -dev\nTerminal 3:\nfabio -log.level=TRACE\nTerminal 4:\n$ curl --request PUT --data 'route add http-echo / http://127.0.0.1:5678 opts \"allow=ip:10.0.0.0/8,ip:127.0.0.1\"' 127.0.0.1:8500/v1/kv/fabio/config\ntrue\n$ curl --interface 127.0.0.1 http://127.0.0.1:9999/\nhello\n$ curl --interface 127.0.0.1 -H \"X-Forwarded-For: 1.2.3.4\" http://127.0.0.1:9999/\naccess denied\n$ curl --interface 127.0.0.2 http://127.0.0.1:9999/\naccess denied\n$ curl --interface 127.0.0.2 --header \"X-Forwarded-For: 10.0.0.1\" http://127.0.0.1:9999/\naccess denied\nThis is the expected behavior.  What am I missing here?\nRelevant logging from fabio for the denied requests ...\n2018/02/26 13:24:09 [INFO] route rules denied access from 1.2.3.4 to http://127.0.0.1:5678\n2018/02/26 13:24:19 [INFO] route rules denied access from 127.0.0.2 to http://127.0.0.1:5678\n2018/02/26 13:24:32 [INFO] route rules denied access from 127.0.0.2 to http://127.0.0.1:5678. Actually ... I think I see the problem with multiple proxies in this case ...\n$ curl --interface 127.0.0.1 --header \"X-Forwarded-For: 10.0.0.2\" http://127.0.0.1:9999/\nhello\nHrmm... so you need to validate the source in this case the upstream proxy but you also need to validate the header.  However when you have an upstream proxy and you are forced to allow it you let anyone on the net to spoof the header.. What we really need is an 'allow xff from' type setting.  Does that exist within the ALB?. > It would probably be easiest to just check if there is a X-Amzn-Trace-Id Header present, and if so, use the rightmost XFF header, (even though I've understood that you don't want to do this). But it would make this whole thing work.\nIt's not about a want ... it's about actually enforcing the given ruleset.\nWe could add some odd if header Z then look at this part of the XFF else look at somewhere else ... but that's just adding more layers of obfuscation and not actually preventing the actual problem when you have another proxy in-front of fabio.\nThe problem being: in the current implementation when you have another proxy before fabio you are open to arbitrary bypass of the access list by simply sending the right XFF header.\nThe reason I made the AccessDeniedHTTP function check both the actual source as well as the XFF header was to try and prevent this arbitrary bypass.  However, in the case of another proxy before fabio you are forced to blindly trust the source of the proxy which then means you are blindly trusting arbitrary XFF headers.\nTrusting client side XFF headers in general is a big security hole in my opinion.  Sane load balancers should replace ... not append ... the XFF unless they are operating in a completely trusted environment.   If you have the ability to strip client sent XFF on the ALB ... force the ALB to set, not append ... that would be your best option now.. Currently fabio does not add the XFF header itself but rather allows the upstream core function do that work.  The core function respects client sent XFF which is the real problem with using it for access control in my opinion.\nhttps://github.com/golang/go/blob/master/src/net/http/httputil/reverseproxy.go#L186-L194\nI think another bool option to fabio like proxy.trust.xff that would strip the XFF from the request before it enters the proxy would be beneficial.  This could default to false for backwards compatibility but be set to true in cases where there is not another proxy before fabio and fabio wants to ensure unverified client sent XFF are not interpreted or passed on to other applications.. @magiconair do you have any thoughts on the above proposed option?  I could submit a quick PR to handle that if you agree.. @atillamas the other option may be to validate ALL components of the XFF instead of just an arbitrary first or last element.  In the case of an allow rule all parts of the XFF plus the actual remote address would have to match for the request to be passed onto the backend.  Similarly for a deny rule if any part of the XFF or the actual remote address matched the request would be denied.\nI think this would be acceptable.  Thoughts?. See the proposed \"fix\" in the #453 referenced above.. Validating all elements shouldn\u2019t break anyone needing to use XFF for a layered proxy setup.  It also ensures that we are not exclusively trusting client sent headers.\nI know that in this particular instance it\u2019s the last element.  But the last element just means the client to the proxy before fabio.  I don\u2019t want to assume that there will never be a case where there is more than one hop before fabio.  This wouldn\u2019t be a good design but I can\u2019t really control what others deploy.\nIn all cases I can imagine validating all the elements of the header seems to be the best option without having any control over what the upstream peer, or more importantly the internet facing peer, is sending.. Yes, the last element should always be the closest peer to where you are reading the header.  However, like I said just reading the last element doesn't ensure it's the client address ... it could be the address of the proxy before the proxy before fabio.\nProxies behind proxies is just kind of a mess and should really be avoided if at all possible.  I think the solution in #453 will address the case of any number of proxies before fabio and handle them in the best way possible.\nTo this PR, yes you can close it if you're happy with the solution in the #453 PR.. Correct, I have another PR coming to address the blind trust of client XFF headers in cases where fabio is indeed the internet facing authoritative load balancer (my personal deployment).. Also not directly related but I think fabio is quickly addressing those use cases.  It now supports generic redirects, https enforcement and some header injection.  There are also quite a few discussions around the structure for full on header manipulation that could be implemented.\nWe've been tracking fabio for quite some time and over the last few months have decided all of our needs are addressed.  We have fabio deployed to production for a small set of applications and have plans to fully replace our haproxy/consul-template setup in the near future.\nThank you!. There shouldn't be an issue with redirect loops unless you are telling both the ALB and fabio to do an HTTP to HTTPS schema redirect.  When the ALB is terminating TLS and relaying plain HTTP to fabio there is no need to have fabio do a redirect or even listen for TLS connections.. Why do you need both fabio and the ALB to do redirects?. Ohh, I see your problem.  The ALBs are forcing you to only pass plain HTTP without allowing you to force HTTPs incoming.\nSo, yes there are two options.\n\n\nMake fabio look at the forwarded proto when it is processing redirects.\n\n\nJust use fabio for both.  It does support IP access control now.  There was also a PR merged recently that will handle multi level proxy setups as well.. @jrasell more talk going on in #448 along with some proposals.. If we interpret that https-redirect as only valid for originating http that should be redirected to https I think this works.  Meaning that https-redirect will never match an incoming https request.\n\n\nOtherwise we could keep the same http-redirect with the additional $host pseudo var and restrict on port in the rule something like...\nroute add http-redirect :80 https://$host$path opts \"redirect=301\". Sorry, just looked at the code ... there's not a new option it is just adding the pseudo var.  So I think that you would get a redirect loop with a path / match but shouldn't with a port :80 match.. Agreed a host agnostic match with a port and path is exactly what you would want for this specific use case.. @magiconair What are your thoughts on this as a solution for handling layered proxies?. I updated the commit description and PR title to reflect the discussion.. > If someone sends a bogus xff header from an ip that is not in the list then this ip will be added to the xff header by your trusted proxy and the other trusted proxies in front of you will pass on that information to fabio which will see the ip and deny access.\nYes, exactly which is why I settled on validating all the elements contained within the XFF header.  If some client wants to be clever and inject a bogus XFF header, including a header of an allowed netblock, they will still be denied if any member of the header fails to match.. @magiconair anything else that is still needed with this one?. I could see this being useful as fabio gradually moves to supplant the major reasons people give for deploying another more traditional reverse proxy like nginx or haproxy before fabio.  These primarily seem to revolve around header mangling which could be tricky to express with the short tags unless there it becomes yet another csv style option.\nTake the following example for header manipulation with pseudo variables:\nroute add <svc> / http://<addr>/ opts \"headers_front=x-forwarded-for=$remote,x-my-header=my static value,remove-some-header,append-some-header+=with this value,headers_back=remove-from-response-\"\nVersus something maybe more legible and dynamic...\nroute add <svc> / http://<addr> opts fe.x-forwarded-for=$remote fe.x-my-header=\"my static value\" fe.remove-some-header- fe.append-some-header+=\"with this value\" be.remove-from-response-\nMaybe not the best example?. @holtwilkins you can already do the \"catch all\" HTTP->HTTPS redirect.  We're doing that today with the following route:\nroute add http-redirect host.domain.tld:80 https://host.domain.tld$path opts \"redirect=301\"\n. To get exactly what you are wanting we could probably add another pseudo-variable for $host that could be used similarly to the existing $path variable.  Then you could basically add a route for :80 that would target https://$host$path with your redirect code specified in the options.\n. So, after actually looking at the code I think we could do this without introducing another variable.  I think we could just add a single code block to the end fo the BuildRedirectURL function in route/target.go that would use the request host as the redirect host if the redirect host is empty.  This would allow you to specify something like... \nroute add global-redirect :80 https://$path opts \"redirect=301\"\nDoes that look reasonable?  Should we add the pseudo-variable just to make it more explicit?. @holtwilkins would you care to open a new issue around this specifically?. Generic header trust is definitely something I am concerned with and would love to address in a more elegant fashion.  The main reason for this pull request is to address what I see as broken behavior in the core golang reverse proxy (and AWS).\nIn my opinion the internet facing authoritative load balancer should not blindly append and pass an XFF header from an untrusted client.  There are probably other headers that we should allow/deny on a per header and possibly even per route instance.  The most obvious of those to me however is the XFF header.. I can see fabio eventually having something similar to the header_upstream and header_downstream directives available in Caddy (https://caddyserver.com/docs/proxy).  These allow the user to control per header weather to add/set, append, or remove headers coming from the client before being passed to the backend and similarly filtering headers coming from a backend before being sent to the client.. Closing this in favor of a more robust header manipulation system.. The \"tags\" are for specifying a route and are usually applied to a specific service in consul.  If you are just wanting to statically route something you can do that via the consul config folder \"KVPath\": \"/fabio/config\",. @murphymj25 Thank you for the analysis.. The dep experiment is doomed to fail.  It was supposed to be part of the 1.10 official releases but it missed the mark.  In my opinion this was largely due to internal fighting and ivory tower perspectives that you can read in the project GitHub issue list.  I don't see that project overcoming those issues nor do I ever see it gaining widespread adoption.  Case in point there is already another vending tool being pushed vgo that according to the white paper is slated to replace dep that still hasn't been adopted.. @pschultz Got it, thank you!. What do you have in your KV at /fabio/config?  The attached log looks like it is reading your command line parameters correctly.  That only leaves the contents of the keystore unknown.. Yes, but what is inside the /fabio/config path.. Navigate to fabio/config in your key store.  Something like: http://10.208.6.98:8500/ui/#/dc1/kv/fabio/config/edit. Sorry, that was just an example ... you're actual path might be different depending on your datacenter name.  Really I was just wanting to know if you had anything in your consul KV store under fabio/config.  That's the default path for additional configuration and what I see being used in the log segment you attached.\n\"Addr\": \"10.208.6.98:8500\",\n            \"Scheme\": \"http\",\n            \"Token\": \"\",\n            \"KVPath\": \"/fabio/config\",\n            \"NoRouteHTMLPath\": \"/fabio/noroute.html\",. Ohh, I think I may see the issue ... can you try leaving registry.consul.tagprefix as the default value?  Also the default consul address is localhost (127.0.0.1) ... so you shouldn't need to pass registry.consul.addr as it looks like you have consul and fabio running on the same host.. You should be able to start consul agent -dev and fabio on the same machine without any other options and get a working example.  The addition of proto=tcp is also telling fabio to run as a TCP load balancer vs an HTTP load balancer.. Literally...\nWindow 1:\nconsul agent -dev\nWindow 2:\nfabio. @satishviswanathan I think you need to start with a known clean state and then add as you progress.  The errors you are seeing don't make sense with a clean configuration.. Ahh, okay so ... what do your service registrations look like?  What is your urlprefix tag on the service?. There is work and discussion going on in #489 ... would you be able to test if that patch fixes your issue?. @tuempeltaucher that's with the code from #489 applied?\n. If you need a TCP listener and also an HTTP listener to enable the HTTP features you will need to define multiple listeners on different ports and/or different IPs.\nExample from our lab configuration:\nproxy.addr = 172.27.18.68:80;proto=http;rt=60s;wt=30s,\\\n             172.27.18.68:443;proto=https;rt=60s;wt=30s;cs=all;tlsmin=10, \\\n             172.27.18.68:8443;proto=tcp+sni\nThis binds to 172.27.18.68 on three different ports 80, 443, and 8443 using three different protocols for each listener.. Np, I'll see about adding a more complete example to the documentation.. Sorry, I forgot about this ... I'll add to the docs today.. Better late than never I guess.  Sorry for the delay.. @vjeantet @nuriel77 You can add static routes within consul itself.  When you are using the consul backend you can add route information via the KV store specified with the registry.consul.kvpath setting in the properties file.\nExample KV entry to redirect all HTTP traffic to HTTPS on a particular domain:\nroute add http-redirect fbdev.ena.net:80 https://fbdev.ena.net$path opts \"redirect=301\"\nYou can specify multiple routes within that KV one entry per line.. There is a tcp+sni listener that should work for that case.  We are using it for services that terminate TLS directly and enforce client certificate authentication.  Look at the proto=tcp+sni option on the proxy.addr setting.\nThe full documentation is available here: https://fabiolb.net/ref/proxy.addr/. You basically have two options for end-to-end TLS communication:\n\n\ntcp+sni listener will route to the desired backend based on the SNI header of the incoming request and do a simple TCP proxy.  In this case fabio does not terminate TLS and leaves it up to the backend to terminate the TLS connection with the proper certificate chain.\n\n\nhttps listener will route to the desired backend based on host, path or port just like a regular HTTP listener.  In this case fabio will terminate the TLS connection and then re-originate optionally also  https to a backend system.. To get mostly end-to-end TLS with an https type listener you should add the tags as described in the documentation to your backend services:\n\n\nhttps://github.com/fabiolb/fabio/wiki/Features#https-upstream-support\nKeep in mind the backend must support terminating HTTPS and provide proper certificates.  You may skip validation if needed.. What does your routing table look like?  Could you post the output of curl localhost:9998/api/routes?raw. So, this seems like your backend isn't offering HTTPS or you are making an HTTPS request to an HTTP port.. I don't see the proto=https option there.  Secondly, are you doing TLS on port 8002?\nEDIT: Sorry, I see the https scheme ... that's from the proto=https route option. That's fine, just making sure I was making the correct assumption.  The routing table looks a bit odd then.  You have https destinations going to both port 8001 and 8002 and I am assuming that port 8001 is plain HTTP.  So my guess is that you have proto=https on both services? The 8001 service and the 8002 service?. So for clarification ... is this annotation correct?\nservice listening for HTTPS with a self-signed cert on port 8002\nroute add s2 /C https://137.74.25.188:8002 opts \"tlsskipverify=true\"\nservice listening for HTTPS with a valid cert on port 8001\nroute add s1 /B https://137.74.25.192:8001\nservice listening for HTTPS with a self-signed cert on port 8002\nroute add s2 /A https://137.74.25.188:8002 opts \"tlsskipverify=true\"\nservice listening for HTTPS with a valid cert on port 8001\nroute add s1 /A https://137.74.25.192:8001. Okay but I'm specifically concerned about what port the services listen on.  If port 8001 is HTTP your routing table is wrong.. It's only wrong if port 8001 is an HTTP listener.  If both port 8001 and port 8002 terminate TLS then it's fine.\nCould you test a curl?\ncurl --head -v -k https://137.74.25.192:8001\nand ...\ncurl --head -v -k https://137.74.25.188:8002\n. I will be here.. Okay, that's pretty informative.  The certificate you are providing isn't parsable for 137.74.25.192:8001 and it doesn't look like 137.74.25.188 is even listening on port 8002. Understood about the ports.  To the certificate issue...\nWith an HTTPs listener fabio is going to terminate the TLS handshake from the client and then re-originate a request to a backend server.\nUsing an https fabio listener and a standard backend (no special proto option) ...\n[client] <--- HTTPs ---> [fabio] <--- HTTP ---> [backend]\nUsing an https listener with an https backend (declared with proto=https option) ...\n[client] <--- HTTPs ---> [fabio] <--- HTTPs ---> [backend]\nIn each situation fabio is acting as a server (handling request from client) and as a client (making request to the backend).  When you define the backend as an https endpoint that backend needs to be able to terminate TLS requests.  Fabio will provide the certificate for the original client connection (frontend) but it can not provide the certificate for the backend as it's acting as a client to the backend.  The backend system will need to provide the certificate and handle the TLS termination.  This is not specific to fabio ... this is the basic design and flow for any reverse proxy.\nIn short, if you cannot make an https curl request to the backend, fabio will also not be able to make an https request to the backend system.. @BogetC you can do client cert auth if you configure a tcp+sni listener and simply pass the stream through to the backend.  You can only route by host in that case (SNI header) but this will work for client certificate passthrough and authentication.\nIt doesn't make much sense for the proxy to pass the client certificate.  That wouldn't actually validate external clients ... it would just authenticate the proxy which would always have the required certificate.. TCP listeners including the TCP+SNI listener are passthtough to the backend.  If you want fabio to add headers you will need to use an HTTP and/or an HTTPS listener.  The HTTPS listener will terminate TLS at fabio and can optionally reoriginate with TLS to the backend if you specify proto=https as a route option.. Sorry, I see what you are asking now.  The current answer is no.  The TCP and TCP+SNI proxy do not currently have any access logging.  I can see this being a nice feature and would offer parity with the HTTP proxy.. The HTTP access logging was originally added in #80 . Could you see if you can reproduce the same behavior and b the current version?  I thought this was covered in a router test case.. The behavior you described is correct.  I'm concerned that any feature that allowed keeping a route that was no longer present in the backend could lead to a stale routing table which would also cause problems.\nThe easiest \"fix\" here would be to have your UI container present a \"pretty\" 404 page.  I don't see how Fabio could ever know that /sales/api is a valid route that should not match /sales but /sales/css/something.css should map to the /sales route.. Sorry, I just read your issue again and I think I understand your actual request.  You basically want to define the behavior for \"unhealthy\" prefix matches?\nWhat would you think of some sort of maintenance page feature?\nBasic idea... if a incoming request would match a route but that service is either failed or marked as maintenance you could specify a custom response.  This would be similar to how the noroutestatus and noroutehtmlpath options currently work.. Currently noroute means no route match in the table.  That's not what is happening here.  There is a route matching the request in the table.  Fabio is currently doing the right thing.  This would be new functionality that would be similar but different than the current noroute* options.. Okay, I understand what you're asking for now and I can see the use case.  Would you be able to submit a PR?. No problem, I'll try and take a look at it in the next few days.. Absolutely, that would be great!\n\nOn Jun 22, 2018, at 2:06 AM, Ianislav Vasilev notifications@github.com wrote:\n@leprechau https://github.com/leprechau I've always wanted to join fabio project and this seems like a suitable case to do. Do you mind if I try to prepare a PR in next few days? :)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/fabiolb/fabio/issues/511#issuecomment-399343566, or mute the thread https://github.com/notifications/unsubscribe-auth/ABYLTj_u_9a9WbXc6NN-M2tEwz3M3Ijgks5t_JeTgaJpZM4UtfiZ.\n\n\n. @kuskmen @mantasaudickas I see the reasoning but I'm a bit concerned about adding more state to the current routing table.. Consul service \"watches\" are implemented as long poll blocking HTTP requests.  Ideally you would have a local consul agent running in client mode on the same box as fabio.. You will see multiple connections from fabio to consul but in a typical deployment those are all to the same localhost node not multiple cluster members.. @netik Just for clarification you only need a consul agent in client mode on the fabio host.. @Roseidon how are you running fabio today?. Closing due to lack of response.  Future users - your system should be more than capable of taking the stdout of fabio and writing it to a system log.  Check the systemd/docker/upstart documentation for more information.. You should click on 'Overrides' and see a dropdown like ...\n\nOnce you click on 'default' there you should be taken to the manual routes section ...\n\nIn this case I have exactly one manual route entered.  That route is contained within the consul kv store and in my case is located at /lb/fabio/config per the registry.consul.kvpath setting.  The default is /fabio/config.\nIf I look at that key in consul I see the same content as the screenshot above ...\n\nI hope that helps.. The ui.access settings needs to be rw which is the default.. Good, closing this issue.  Feel free to re-open if it's not actually resolved.. Added some markdown to the comment to better show the ascii part of the graph.. What you are asking is actually outside the scope of fabio and most other load balancers.  It sounds like you want a single public facing virtual IP (VIP) to be load balanced across multiple service instances.\nThat's a job usually reserved for the network layer.  In our case we use Anycast BGP to accomplish this task.  Check out this link for more information: https://en.wikipedia.org/wiki/Anycast. I'm not exactly sure what you are wanting fabio to do with Connect enabled services.  Are you wanting them to be added as straight TCP proxy targets?. @nutbunnies @artyomturkin I definitely think this is something we want to support and after doing more reading on connect I can see the benefit, especially in public cloud environments.\nI believe there is also overlap at some level between this request and https://github.com/fabiolb/fabio/issues/566. The Consul has been updated to v1.4.0 (first release with connect out of beta) in #571.  If anyone is wanting to work on adding this support it should now be available in the current vendored library version.. What happens if you run the same test through fabio and direct to the backend at the same time?  Does the call through fabio fail and the call direct work or do they both fail at the same time?. The error you posted from the log looks like fabio (10.0.0.1) timed out during the tcp handshake while trying to establish a connection to the backend (10.0.0.2) over port 80 tcp.. There could be many reasons including resource exhaustion.  Is the test client and/or the backend properly closing the socket?  Could you be running out of available outbound ports?  Is it an open file handle limit?. Wasn't trying to invalidate your results.  Just trying to think through the problem to identify the root cause.  The error above is generated from the underlying golang network library.  This could be because something isn't closing sockets.  When the test fails does it fail once or repeatedly?  Could you capture a netstat -untap|grep fabio output on the fabio host when the tests are failing? . How long do the connections stay in TIME_WAIT and about how many are there?  I'm wondering if traefik is more aggressively closing sockets on behalf of the client.  Do you see the same number of TIME_WAIT connections with traefik and direct test?. That's not fabio connecting (the arrow is a bit misleading) that's fabio getting a connection on it's 9999 listening port from random out bound source ports on those 100.x.x.x hosts.  Those addresses  are within the CGN space.  Could these be coming from your provider? Portscan?. That's currently handled by a / route.  You could make that a static route or an advertised service with a urlprefix-/ tag.. The current behavior of the route matching is 'longest-match-first' so if you have a route for / and a route for /foo/ a request that comes in for /foo/bar will goto /foo/ and a request for /bar/blah will hit the / route.. Awesome, glad  you got it figured out.\n\nAnd does Fabio support route configuration threw env variables, like >FABIO_REGISTRY_CONSUL_ADDR?\n\nNo, the route/registry backends are static (in config), file (reloadable), and and consul currently.. The current vendored vault version is v0.6.0 which is quite old.  I can look at getting that updated to the latest release in preparation for vault v1.0 that appears to be right around the corner.  That should at least give us a more modern starting point for possible refactor/improvement if needed.. @sugdyzhekov Interesting, could you attach a tcpdump in addition to the nc output?. Interesting and thank you for detailed troubleshooting.  That makes a lot of sense.  We use TCP proxy but haven't noticed any breakage but in our case it is all client initiated.. ... and it seems I may be to blame :)\n@pschultz could you try reproducing this with master?  I just made some changes to the ip access control that might be the solution.  In short that section wasn't properly getting the remote connection address previously.. digging into this now ... using your steps I can reproduce it on master. It is indeed the AccessDenied check but I'm not yet sure why.  Will continue to investigate but commenting out the relevant lines in proxy/tcp/tcp_proxy.go does make both test scenarios work.. I found the issue but I'm going to need to do a bit of research ... steps so far:\nUsing the same test scenario as above with these code changes in route/access_rules.go:\ngo\n// AccessDeniedTCP checks rules on the target for TCP proxy routes.\nfunc (t *Target) AccessDeniedTCP(c net.Conn) bool {\n    log.Printf(\"[DEBUG] in AccessDeniedTCP 0\")\n    var addr *net.TCPAddr\n    var ok bool\n    // validate remote address assertion\n    if addr, ok = c.RemoteAddr().(*net.TCPAddr); !ok {\n        log.Printf(\"[ERROR] failed to assert remote connection address for %s\", t.Service)\n        return false\n    }\n    log.Printf(\"[DEBUG] in AccessDeniedTCP 1 addr=%+v\", addr)\n    // check remote connection address\n    if t.denyByIP(addr.IP) {\n        return true\n    }\n    log.Printf(\"[DEBUG] in AccessDeniedTCP 2\")\n    // default allow\n    return false\n}\nWatching the fabio logs when telnetting to port 8026 from a remote host on the LAN ...\n2018/12/06 14:12:49 [DEBUG] in AccessDeniedTCP 0\n2018/12/06 14:12:53 [DEBUG] in AccessDeniedTCP 1 addr=100.127.255.1:22900\n2018/12/06 14:12:53 [DEBUG] in AccessDeniedTCP 2\nThe 0 logging line is printed right after telnet collects.  The 1 logging line is printed as soon as I press <enter> on the remote machine.  It appears that golang is blocking and not returning from the RemoteAddr() function until input is received from the client.. This looks potentially related: https://github.com/golang/go/issues/12943. This as well: https://github.com/armon/go-proxyproto/issues/1. The issue seems to be in the proxy protocol implementation ...\ngo\n// RemoteAddr returns the address of the client if the proxy\n// protocol is being used, otherwise just returns the address of\n// the socket peer. If there is an error parsing the header, the\n// address of the client is not returned, and the socket is closed.\n// Once implication of this is that the call could block if the\n// client is slow. Using a Deadline is recommended if this is called\n// before Read()\nfunc (p *Conn) RemoteAddr() net.Addr {\n    p.once.Do(func() {\n        if err := p.checkPrefix(); err != nil && err != io.EOF {\n            log.Printf(\"[ERR] Failed to read proxy prefix: %v\", err)\n        }\n    })\n    if p.srcAddr != nil {\n        return p.srcAddr\n    }\n    return p.conn.RemoteAddr()\n}\nWe would either have to disable proxy protocol or get the remote IP without checking for proxy protocol for server initiated requests.. Commenting out the proxy protocol wrapper allows the test to proceed.\nWith ln = &proxyproto.Listener{Listener: ln} commented out in proxy/listen.go the tests work with the ip access checks.\nLogging output from a telnet check against the mock server from a remote host on the LAN:\n2018/12/06 15:45:13 [DEBUG] in AccessDeniedTCP 0\n2018/12/06 15:45:13 [DEBUG] in AccessDeniedTCP 1 addr=100.127.255.1:22982\n2018/12/06 15:45:13 [DEBUG] in AccessDeniedTCP 2\nHow do we want to proceed?. My initial thoughts:\n\nMake proxy protocol selectable per listener (default to false)\nproxy.addr = 1.2.3.4:443;proxyproto=tue, \\\n             1.2.3.5:3306;proto=tcp\nSkip access rule checking before requesting the remote address if there are not rules defined\nUpdate documentation to indicate that enabling proxyproto on a tcp listener with access or deny rules defined will break with server initiated services\n\nI think making people explicitly enable proxy protocol is also better from a security perspective.. I made a few commits to a new branch referenced above that address the core points mentioned thus far.  The current proxy-protocol toggle defaults to false but that may need to change per @magiconair comment's above.\nRegardless of the default setting I believe additional documentation and release notes will be warranted.. Sorry for the late response ... but you could probably do all of this through fabio.\nYou could register Nomad with a urlprefix-/nomad/ strip=/nomad and do the same with Consul and Vault and others.   In theory that should work.  Assuming you had mydomain.org pointing to an instance of fabio.. There has been quite a bit of discussion around header manipulation.\nMost notably #110 and #168 which mention adding and removing headers.  I'm going to close this as a duplicate of #168 as I think that issue covers your use case.\nPlease feel free to on #168 with this use case.. Thank you for that detailed analysis.  I'll try to dig in and review the metrics code and see if I can find the leak over the next few days.. Doing a bit more digging I think this relates to #476 and provides a bit of a push to get that going.. I agree it's related to go-metrics.  I was looking through their issue feed and found a few older issues that may be related:\nhttps://github.com/rcrowley/go-metrics/issues/201\nhttps://github.com/rcrowley/go-metrics/issues/163\nhttps://github.com/rcrowley/go-metrics/pull/197\nhttps://github.com/rcrowley/go-metrics/pull/206\nOther project referenced in go-metrics issues ...\nhttps://github.com/Shopify/sarama/issues/897\nThe upstream fixes in 197 and 206 look to be added to a later version of go-metrics than is currently vendored into fabio.  We may be able to get some resolution of the leak by updating the vendored version.. Right, that was in-line with what I was reading.  The Stop() func for the return from NewMeter() was added after go-metrics was pulled into Fabio.. I definitely think you're on the right path.. That sounds logical.  Unregistering the service should definitely stop collecting metrics on said service.. Awesome, great news.  Thank you for all the work and analytics on this issue.. @samm-git Thank you for your patience.  I see the docs.  LGTM!\nThank you!. Closing this as a duplicate of #211 ... please feel free to  comment on that issue.. @holtwilkins Sorry, just getting caught back up on things.  I'll try and get this reviewed soon.. Could you please attach a make test since the Travis tests are no longer running?. Tests look good, from what I see they are all passing.. I'm not sure I understand the request.  Fabio is a consul aware load balancer and should already be capable of replacing a consul-template/haproxy or consul-template/nginx setup for most purposes.  What exact feature do you feel is missing from fabio?. I see.  That would put more dependencies on service names within consul that are largely irrelevant today.  Is there any reason you cannot add the required tags to existing services?. Today the service name is irrelevant to fabio because it's not used anywhere in the routing table.  There is no correlation to a service route and it's name in consul.\nTo the overlapping endpoints, that's not an issue that prevents the use of tags.  Take the following example.\nServices:\nservice foo-stuff on 1.2.3.4:8000 provides /stats\nservice bar-stuff on 4.5.6.7:9001 provides /stats\nSolution:\nfoo-stuff has tag `urlprefix-/foo/ strip=/foo`\nbar-stuff has tag `urlprefix-/bar/ strip=/bar`\nRequests to <fabio>/foo/stats will be routed to 1.2.3.4:8000/stats and a request to <fabio>/bar/stats will be routed to 4.5.6.7:9001/stats.  There is no dependency on the service name to route the request.. Done, and I think this is the appropriate place.  There has been a lot of discussion around reworking the metrics within fabio and this could relate.. Sorry to leave you hanging.  Having a look now.. Maybe a larger question ... but why would host comparisons ever be case sensitive?. Moving conversation from #542 over here.  Looking a bit deeper into the code it seems a bit inconsistent.  When adding a route via a service tag the host is always forced lowercase as you have observed via parseURLPrefixTag (https://github.com/fabiolb/fabio/blob/master/registry/consul/parse.go#L48)\nFurthermore, incoming hosts are not always forced lower-case before searching the table.  To be consistent we may want to modify the underlying addRoute (https://github.com/fabiolb/fabio/blob/master/route/table.go#L137) function to also force lowercase the host in addition to forcing a lowercase lookup.. I think we can make all lookups and adds lowercase by making two simple changes in route/table.go like this ...\n```diff\ndiff --git a/route/table.go b/route/table.go\nindex bb689dc..1646e74 100644\n--- a/route/table.go\n+++ b/route/table.go\n@@ -136,6 +136,7 @@ func NewTable(s string) (t Table, err error) {\n // addRoute adds a new route prefix -> target for the given service.\n func (t Table) addRoute(d *RouteDef) error {\n        host, path := hostpath(d.Src)\n+       host = strings.ToLower(host) // maintain compatibility with parseURLPrefixTag\n    if d.Src == \"\" {\n            return errInvalidPrefix\n\n@@ -383,6 +384,7 @@ func (t Table) LookupHost(host string, pick picker) *Target {\n }\nfunc (t Table) lookup(host, path, trace string, pick picker, match matcher) *Target {\n+       host = strings.ToLower(host) // routes are always added lowercase\n        for _, r := range t[host] {\n                if match(path, r) {\n                        n := len(r.Targets)\n``\nThis wouldn't require any changes to thelookupHostFninmain.goas that function callsLookupwhich in turn calls thelookupfunction intable.go. Running amake testthose two changes totable.godon't appear to break existing tests.. @shantanugadgil Thank you!. @holtwilkins looks good.  Would you mind attaching amake testrun?. @holtwilkins yes, that's something that needs to be fixed.  Tests with newer consul and vault are failing.  Thanks for attaching though.  LGTM.. Good catch.  Want to submit a PR?\n. Thank you, I can take the minor edits.. The syntax in your route doesn't match.  To use SNI routing of a request you want to setup a TCP listener using theproxy.addrdirective in your configuration file withproto=tcp+sni.  The route added will then just have a standard source and destination.  To send to an HTTPs backend you will want to haveproto=httpson your route and optionallytlsskipverify=trueif the backend cert cannot be validated.. I mean you shouldn't needproto=tcp+snior any options on the route to get SNI routing.  If the backend is HTTPs then you will needproto=httpsand optionallytlsskipverify=true.  You should not need any other options.. I'll have to check the code to be sure.  I think it uses the same matcher but I'll have to verify.. Ahh yes, the table lookup function.  That's a host key based map lookup.  I'll take a look at the PR ... I merged a small change to the lookup function yesterday to force the host portion of all route additions and lookups to be lowercase.. I'd like to see the table expanded to include pre-compiled matches.  This would allow those to be used elsewhere and fix additional issues like SNI wildcard matching.. Was just in the middle of a long response ... and you're definitely on the right track.. The currentTabletype is a simple map ofRouteswhich is a slice ofRoutestructs.  To avoid compiling matches in-real-time we need to maintain a map of pre-compiled matches that can cross-referenced when looping over the table.  This should be populated whenever an entry is added to the table.  That could be stored separately from theTabletype or part of a new object that would be referenced by the currentTable` map.\nThoughts?  I'm very open but would like to think it through.. In the immediate example I'm afraid you could still have a penalty at least the first time the table is queried as population of the NormalizedPatternGlobs would still be done in real-time the first time the route is hit.  I think it would be better if that could be done when the route is added to the table.. This could also alleviate the reasoning behind not implementing glob matches on SNI as being discussed in #547. Awesome, thank you.. Very nice, thank you so much for the analysis and work.. I've used the Sync.Map implementation successfully for a few high transaction environments.  It works well when you have few updates but many concurrent reads which should be the case here.  Will be interesting to see the results.. You probably want to do something like ...\ngo\n    var val interface{}  // hold onto it after the if block\n    if val, ok := mymap.Load(pattern); !ok {\n        // value didn't load ... bail?\n    }\n    var obj my.Type  // same thing\n    if obj, ok := val.(my.Type); !ok {\n        // probably shouldn't happen ... bail\n    }\n    // you should have a valid obj of correct type to work with here. I think the diagram is a bit out of order from the traditional deployment.  In most scenarios only fabio is exposed to the end-user/actor.  The frontend/backend services are only available to users inside the network or via fabio.  Leaving consul and the data services only accessible by internal users and the applications themselves.. If you are wanting to expose DNS via consul outside of your internal network you probably want to front it with a caching/forwarding service like unbound ... see the docs here:  https://www.consul.io/docs/guides/forwarding.html. To the earlier point of the number of Fabio instances and service monitors and the potential load on Consul ... would it make sense to incorporate the ability to use the new agent cache added upstream in v1.3.0?. Maybe make an available global tunable to set a cache interval for the health calls?  I could introduce a separate PR for that specifically.. Completely removing the tag model would almost certainly break many deployments including our deployment.  This would result in quite a bit of code change to solve a non-problem.  I definitely see the appeal of service metadata but do not think the tag model should be abandoned.. @DavidRutqvist I'll build and test a local version with v1.4.0 to support service metadata and consul connect.. I updated consul to v1.4.0 in #571 . Could you update the go modules with the proper semantic versioning tag and ensure it matches the vendor in sources?\nSee here for more information with working with the new go modules system: https://github.com/golang/go/wiki/Modules. @andyroyle this is also needed for #517 and #566 ... do you have the time to update it to use v1.4.0 as a module or would you like me to close it?. @andyroyle I hope I didn't step on your toes.  There were a few other PRs waiting on an update of the library.  Thank you very much for the contribution ... and the motivation to get it updated :). The access log is written to stdout and should be very efficient.  I would only be concerned about performance in a VERY high load environment.. I'd want to split load between multiple fabio processes for either of those loads for resiliency if nothing else ... with access logging enabled you would want to validate that how you are capturing stdout from the fabio process is capable of keeping up with the required IOPs generated via the access logging.  You definitely don't want to create a situation where the flushing of access logs to local disk via systemd/journalctl or similar is causing IO wait and blocking other local tasks on the machine.. Thoughts of supporting htpasswd format for the file?. I would lean to making that default.  The tooling to create htpasswd files is already present on most *nix systems and users of a load balancer are probably familiar with them and know how to create/manage those files.  What do you think?\nSideline: Thanks for picking up the torch on that old issue.. Awesome, and thank you again!. @andyroyle Sorry for the delay, just getting caught back up after a short vacation.  I'll try to give this a review today.. I\u2019ll take a look today.  Thank you for the report.. @KEZHwMlXV1vFzs6QvY8v5WjX5 I can't reproduce the issue locally.  I've created a branch with increased DEBUG level logging.  Could you build that branch and report the results?. The branch is here:  https://github.com/fabiolb/fabio/tree/issue-576-ip-access\nYou should be able to checkout and make to build the binary.  If you're on a mac and deploying to linux you will need to run make linux instead.. @KEZHwMlXV1vFzs6QvY8v5WjX5 Nice catch.  Doing the assertion to a net.TCPAddr pointer and checking the assertion is the correct.. I pushed to the same branch and created https://github.com/fabiolb/fabio/pull/577\nLet me know if that corrects the issue for you.. @KEZHwMlXV1vFzs6QvY8v5WjX5 awesome, I'll merge it.  Thanks again.. That's the current expected behavior.  When a container is stopped and there is no service registration and/or that service is unhealthy it will not be routed by fabio ... hence the 502 \"Bad Gateway\" response.. I think this may be what you are wanting ... https://github.com/fabiolb/fabio/issues/511. @JeanBaptisteWATENBERG no problem, looking at your repo now.  Totally unrelated but if you want a command similar to envsubst with a few more features when templating you might check out sigil ... it's what we've been using for awhile for that same task.  Hasn't been updated in awhile but it still works and does what it says ... https://github.com/gliderlabs/sigil. Okay, I see what you are saying and currently the behavior is exactly as you have stated.  The \"health\" of a service is determined completely by consul and fabio honors what consul reports.  To avoid the problem you are describing you have a few options:\n\nMake the applications consul aware so they de-register when stopped\nRegister the services with consul via something like registrator which will remove the service when the container is stopped\nPut the service instance in maintenance mode before stopping the container: https://www.consul.io/docs/commands/maint.html\n. @JeanBaptisteWATENBERG not a problem.  Let me know if you run into any issues or have additional questions.. Are you terminating TLS on fabio or are you trying to pass HTTPS directly to the backend?  Additionally, you can make your second route in the example more explicit by specifying port 443.\n\nIn our setup we have one redirect for the main domain that looks very close to yours ...\nroute add http-redirect foo.com:80 https://foo.com$path opts \"redirect=301\"\nWe have fabio listening on port 80 and 443 ...\nproxy.addr = 1.2.3.4:80;proto=http;rt=60s;wt=60s,\\\n             1.2.3.4:443;proto=https;rt=60s;wt=60s;cs=all;tlsmin=10\nIn this setup anything that comes in on port 80 hits the redirect and thus arrives at the port 443 listener.. @pschultz @magiconair PR to address #524 . I'm not sure about the commit itself ... I don't know.  I fully agree though that @pschultz should get credit in the changelog and release notes at a minimum.. @magiconair Any more thoughts on changing the default state of proxy-protocol on the listener?  Do we want to keep it false as-is in the current PR?\nI also noticed that in the updated go-proxyproto package there is a function to check for allowed sources for proxy-protocol.  That would elevate some of the security concerns but I think that's a later feature enhancement.. @magiconair per earlier question...you definitely can with GitHub:\nhttps://help.github.com/articles/creating-a-commit-with-multiple-authors/\n. @magiconair absolutely.. This disables PROXY protocol on all listeners by default unless enabled with pxyproto=true.. Okay, I have the documentation done.  I'll push it to a new branch and create a PR.  For what it's worth HAProxy has it disabled by default unless specified on the listener as well.. Updated documentation here: https://github.com/fabiolb/fabio/pull/583. oops... that branch name no longer applies. Merging this to ensure master is functional and documentation matches current master functionality.  We can update/revert as needed if we decide to change direction at a later date.. @geohuz are both logs empty? The stdout and stderr logs are kept and displayed separately with Nomad.  To check both you need to look at nomad alloc logs -stderr 890b1f82 and nomad alloc logs 890b1f82.  Secondly, would you mind sharing your Nomad job spec?. @geohuz The service file you found is a systemd service file.  That's the init daemon on RedHat/CentOS/etc.. if you wanted to run consul on the actual host.  Is that what you are planning on doing or do you want to run consul under docker?\nThe error from the log means fabio can't connect to consul.  The default location for the consul endpoint is localhost:8500.  There are two easy ways to fix that and they both accomplish the same thing:\n\nIf you are running Consul under docker use host networking and have it bind to all interfaces.\nIf you are running it on the local box outside of Docker just have it bind to all interfaces.\n\nWith that in place you can tell Nomad to export an environment variable so fabio can find out where to talk to consul.  For example something like this in your task section:\nhcl\n      env {\n        \"CONSUL_HTTP_ADDR\" = \"${attr.driver.docker.bridge_ip}:8500\"\n      }\nThat will tell fabio that it can communicate with Consul via the Docker bridge IP (the container's default gateway).  If Consul is running with host networking or on the host itself it should be listening on that address.\n. Second point ... we (me/my company ... not fabio project) publish a GitHub project that builds RPMs for our production Consul installs that includes the service definition.  You should be able to install them on any standard Enterprise Linux environment.\nhttps://github.com/myENA/consul-rpm\n. Currently the ACLs are only configurable per route.  If you would like to control access to the entire project I'd suggest looking into system level firewalling.  The idea of allowing a person to \"group\" rules and apply the same policy is intriguing.  Maybe we could leverage consul and/or for something like this in a future feature addition.. @vinodbala Yes, if you had route level rules applied and the traffic was allowed to reach Fabio then the route rule would still be applied.  My point towards the system firewall was in reference to the \"global\" rules.. By whitelist do you mean block everyone except the \"admin\" group?  In addition for each service you then want to be even more exclusive?\nExample....\nSystem firewall:\n$adminIps = { 1.2.3.0/24, 4.5.6.7/32 }\nblock all tcp in on {80, 443}\nallow tcp in on {80, 443} from $adminIps\nIn Fabio:\nroute /foo (no restrictions - should only be hit by $adminIps from system rules)\nroute /bob allow=ip:4.5.6.7/32 (this would only allow 4.5.6.7/32 but not anyone from 1.2.3.0/24 that was allowed in the system rules)\nIs that what you are wanting to do?. No, not currently.  The ACL option is per route.. Thank you!. Hello and welcome to the Fabio community.\nThe first point seems to be a duplicate of #594 ... is that correct?\nSecondly, Fabio already supports web sockets is there something additional you are targeting with your custom handler?\n. Yes, 1.5.11 was released yesterday!  Thank you everyone for your patience.. Thanks for the work and review everyone.  @mfuterko would you mind also updating the relevant documentation on the auth feature?. Thank you @mfuterko!. Late to the conversation but looking at the code examples provided above it doesn't look like you are using the correct separator for the package and service.  You have /protopkg/protoservice/ and the example shows /foo.bar with an example package of foo and a service bar.  I assume that should make your tag urlprefix-/protopkg.protoservice proto=grpc.\n. @andyroyle provided some stub example code ... should be able to expand that to a small PoC.  If you do it would be great to post it back here.. You could route via hostname instead of path ... create multiple A records (or CNAME entries) that resolve to the address of your fabio server.  Then you could urlprefix-svc1.domain.com and urlprefix-svc2.domain.com to different backends.. Hrm ... HTTP/2 does require SNI by specification though.  So, if we're not already using SNI to match host routes on HTTP/2 we should.  I'll look into the code in more detail when I get a chance.. Ohh right, that would only affect HTTP/2 and/or GRPC over TLS but yes ... it would be better than nothing in the absence of a host header.   Ideally we would have a documented and logical search order.  Something like HOST header, SNI, CN from cert, IP, ???. As in you want Fabio to read user agent strings and only redirect mobile devices?  That\u2019s not currently a feature we support.. There is a library that I have used in other applications that could make this possible as qualifiers to the http-redirect statement: https://github.com/mssola/user_agent. Sorry, I'll try to get a review in on this today or tomorrow.. We recently updated a lab to 1.4.3 ... I\u2019ll take a look Monday and see if I can reproduce this behavior.\n-- Aaron\n\nOn Mar 10, 2019, at 12:39 AM, Frank Schr\u00f6der notifications@github.com wrote:\nMy time to work on this project is quite limited. Maybe someone from the community can pick this up?\n\u2014\nFrank Schr\u00f6der\n\nOn 10. Mar 2019, at 07:28, Wojciech Sielski notifications@github.com wrote:\nps: My suspicious is: that Consul remove all health checks even if only one service was removed, so Fabio loose all routes.\n(The reason, why in my case, was so hard to understand what was going on, was that Registrator constantly was trying to heal the situation...)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. ~~@magiconair will do~~\n\n\nSorry, guess you meant Consul readme ;p. Fabio takes certificates in a combined PEM format.  With consul the path you specify is interpreted as a prefix.  In your example it's expected that you would have a structure similar to this in your Consul KV store:\n/ssl-certificates/\n                 /cert1\n                 /cert2\nIn each of those keys you should have a concatenated combined pem ... if cert1 was a file you would create it by doing:\ncat domain-cert.pem intermediate-signing-cert.pem domain-cert.key > cert1\nThat make sense?  With LetsEncrypt it would be the fullchain bundle concatenated with the private key.. The KV and/or file name isn't important.  Fabio will pick the most specific matching CN of the available certificates.. You'll need the fullchain + key in the key store (in the cert01 key).  The server needs the certificate (public key) chain plus the private key to initiate an encrypted connection.. Ohh, okay ... so fabio can do HTTPs termination for you on the front ... and it can also do HTTPs termination to backend services.  The proto=https option to the urlprefix- tag tells fabio it should use https when communicating with the backend.\nI think what you are wanting is for fabio to handle all HTTPs termination and then use plain HTTP to the backend?  If that's the case you simply need to configure the urlprefix- without the proto=https option and connect to fabio via an HTTPs listener.  To do that you need to configure the certificate store like you have done AND specify an HTTPs listener via the proxy.addr option:\nhttps://fabiolb.net/ref/proxy.addr/\nYou can also have fabio automatically redirect HTTP to HTTPS using a redirect.\nhttps://fabiolb.net/feature/http-redirects/\nHope that helps!. Here's an example configuration from our development environment where we have several listeners defined:\nproxy.cs = cs=files;type=path;cert=/etc/fabio/certs;refresh=60s\nproxy.addr = 11.22.33.65:80;proto=http;rt=90s;wt=60s,\\\n             11.22.33.65:443;proto=https;rt=90s;wt=60s;cs=files;tlsmin=tls10, \\\n             11.22.33.68:80;proto=http;rt=69s;wt=60s,\\\n             11.22.33.68:443;proto=https;rt=90s;wt=60s;cs=files;tlsmin=tls10, \\\n             11.22.33.68:8443;proto=tcp+sni, \\\n             11.22.33.65:26257;proto=tcp\nThe above config creates one certificate store as a file base where I have the concatenated certs in /etc/fabio/certs.  It also defines multiple listeners some service HTTPS on port 443, HTTP on port 80, TCP+SNI passthrough on port 8443 and standard TCP on port 26257.\nRequests inbound on port 80 will be standard HTTP ... requests on port 443 fabio will terminate TLS and us the configured certificate store to find a certificate matching the SNI of the request.\nTo force HTTPS we place the following in the consul KV config:\nroute add http-redirect dev.ena.net:80 https://dev.ena.net$path opts \"redirect=301\"\n. It's not a command.  That is just config syntax.  The urlprefix- tags are actually converted into fabio route syntax when processed.  The actual route syntax can be used within the config file or placed in the Consul K/V to provide static routing information.. I have mixed feelings about this section.  In the event that fabio is deployed behind another load balancer you would want to check the XFF header but then what about the actual source?  Would it be better to check both the XFF (if present and different) as well as the actual RemoteAddr and return true (deny) if either of those checks return true on their own?. Yes, I definitely don't like this.  It's an open exploit as is since there is no validation on who is allowed to pass an XFF header to fabio.\nExample with allow=ip:172.16.0.0/12 and a client that is not sourcing from that network.\n$ curl -H 'X-Forwarded-For: 172.16.1.1' https://test-site/foo\n{}\n$ curl https://test-site/foo\naccess denied\nI think it needs to check both XFF and RemoteAddr or it's basically useless.. done!. I can see that being a request but not sure there is much more appropraite than forbidden for a denied request.  Would you want that to be a config option at some point?. Moving this block doesn't do what you think.  You have orphaned the actual source IP parsing above making this function do the same thing as the XFF check block. Which means that the remote address is not even checked.. This block belongs with the block above.  The ip that is being checked here is the result of the parse of the remote address in the previous block.. Can do.. The behavior of denyByIP is to immediately return false when passed a nil ... so it is effectively doing a continue.  However, I can see the point that adding a continue would be more explicit and be more future proof should additional code be added between this statement and the denyByIP call.. Only a single element of the XFF is allowed.  The others are denied.. Not particularly, the result is the same regardless of the order.  I can\u2019t remember why it was changed.. Ohh, the old code only checked the first element.  I moved it to ensure it was looping over the elements and still denying on a middle element.. In the old code this was allowed as it only checked the first element.. Yes, that was part of the new behavior.  If any one of the addresses presented in the XFF fail to match an allow/whitelist rule the request is denied.  If any one of the addresses match a deny/blacklist rule the request is denied.. @magiconair I know this already got merged but I was thinking maybe the above if statement should be t.RedirectCode != 0 && t.RedirectURL != nil just to be safe?. Good point.  I always forget that nil and typed nil behave very differently.. These are all strings.  No need for the overhead of a fmt call here.. same thing here ... and here ... I know it's just a test but it keeps it consistent. ",
    "smancke": "Maybe it would be a good idea to allow a list of certificates for each listener, so that multiple Domains can be served on the same port.\nAs I saw, golang supports a slice of Certificates in tls.Config{} and should be able to create a mapping of the CommonName and SubjectAlternateName provided in the certificate (see also tls.Config.BuildNameToCertificate())\nMaybe the configuration then should be something like:\nproxy.listen..tlsCert.0 =\nproxy.listen..tlsCert.1 =\n. Hi @magiconair,\nok - thanks for your comments.\nI'll close this pull request and do the overwork in a clean branch with a new pull request\nThe current behaviour for the X-Forwarded-For has in my opinion two errors, leading to strange behaviour:\n1.  The LocalIP has nothing to do in X-Forwarded-For. If needed, it could be placed in a X-Forwarded-Server.\n2. The double implementation of addHeaders and the go Proxy brings some errors.\nI have collected the cases, how it is and how it should behave. In my opinion, it's nothing worth to preserve the current behavior by a configuration flag, since it currently is to buggy and strange. \ncase A:\nconfig.Proxy{LocalIP: \"\", ClientIPHeader: \"\"})\nreq.RemoteAddr = \"2.2.2.2:...\" \nX-Forwarded-For: 2.2.2.2\n--> Correct, but not expected when I read read the documentation of fabio.properties\ncase B:\nconfig.Proxy{LocalIP: \"\", ClientIPHeader: \"X-Forwarded-For\"})\nreq.RemoteAddr = \"2.2.2.2:...\" \nX-Forwarded-For: 2.2.2.2, 2.2.2.2\n--> Wrong: Doubled\n--> Should be 2.2.2.2\ncase C:\nconfig.Proxy{LocalIP: \"1.1.1.1\", ClientIPHeader: \"X-Forwarded-For\"})\nreq.RemoteAddr = \"2.2.2.2:...\" \nX-Forwarded-For: 2.2.2.2, 1.1.1.1, 2.2.2.2\n--> Doubled and mixed up with the local ip \n--> Should be  2.2.2.2\ncase D:\nconfig.Proxy{LocalIP: \"1.1.1.1\", ClientIPHeader: \"\"})\nreq.RemoteAddr = \"2.2.2.2:...\" \nreq.Header.Add(\"X-Forwarded-For\", \"3.3.3.3\")\nX-Forwarded-For:  3.3.3.3, 1.1.1.1, 2.2.2.2\n-->  mixed up with the local ip \n--> Should be  3.3.3.3, 2.2.2.2\ncase E:\nconfig.Proxy{LocalIP: \"1.1.1.1\", ClientIPHeader: \"X-Forwarded-For\"})\nreq.RemoteAddr = \"2.2.2.2:...\" \nreq.Header.Add(\"X-Forwarded-For\", \"3.3.3.3\")\nX-Forwarded-For:  2.2.2.2, 1.1.1.1, 2.2.2.2\n-->  mixed up with the local ip, and the original client address got los \n--> Should be  3.3.3.3, 2.2.2.2\n. Here is an example. Lets think about the following case of proxy servers:\nbrowser -> nginx -> apache -> fabio -> tomcat-app\nThen fabio would see:\nX-Forwarded-For: browser-ip, nginx-ip\nreq.RemoteAddr: apache-ip\nAnd fabio has to add the apache-ip to the X-Forwarded-For list.\nSo that tomcat would see:\nX-Forwarded-For: browser-ip, nginx-ip, apache-ip\nRemoteAddr: fabio-ip\nSo, the LocalIP of fabio is send to the tomcat as RemoteAddr, not forwarded for.\n. Yes, it is. Here is the part from the docs:\nhttps://github.com/eBay/fabio#configuration\n. OK, I have done the style changes.\nSquashing everything together to one commit is no problem, if everything is final.\nBut I got one question in mind, concerning the host header change, I made to the \ndirector of the SingleHostReverseProxy.\nI think, my implementation is on the http standard and also the common way how e.g. nginx behaves. But, if someone is relying on the current behavior of fabio, than it's code may break. It would be an option, to make the behavior configurable with the current state as default. But this would mean that the default behavior of fabio would stay in being not correct.\nSo the decision is: Correct by default  vs.  full backwards compatible.\n. Hi @magiconair magiconair,\nyes, you understood this correctly.\nIn my opinion it would be a bad practice, not to rewrite the host header, since this is how http usually woks in such an architecture. If an application wants to construct the url's, it has to respect the Forwading header. Every serious framework is doing so. Even without rewriting, you have to respect the headers, for the correct protocol scheme (http/https). \nBut the world is full of opinions ;-)\nSo, please decide, how it should be:\na) Should I make the rewrite of the host header configurable, with the current behavior as the default? \nb) Or should I remove the host header rewriting from the pull request?\n. Here #74 is a new pull request with the squashed commits, excluding those which are relevant to host header. (I also removed the code for X-Forwarded-Host and so, since it is only needed if we would rewrite it.)\nAn Issue for the Host Header thing is created at: #75\n. I'have recently written a mime type aware gzip handler,\nafter reviewing some existing solutions out there:\nhttps://github.com/smancke/handler/blob/master/gzip/gzip_handler.go\nIf you like, just copy over the code and tests to fabio.\n. @magiconair Yes, please just take it.\n. @magiconair yes. the go http client does not do http2 by default, if you configure it with a custom tls config:\nin net/http/transport.go\ngo\nfunc (t *Transport) onceSetNextProtoDefaults() {\n...\n    if t.TLSClientConfig != nil || t.Dial != nil || t.DialTLS != nil {\n        // Be conservative and don't automatically enable\n        // http2 if they've specified a custom TLS config or\n        // custom dialers. Let them opt-in themselves via\n        // http2.ConfigureTransport so we don't surprise them\n        // by modifying their tls.Config. Issue 14275.\n        return\n    }\n...\n}\nThere must be a way to force the transport by hand, but I don't found how ..\n. @magiconair \nThis works for configuring the client, using the golang/x http2 package:\n```go\n      import \"golang.org/x/net/http2\"\nclientTransport := &http.Transport{\n    TLSClientConfig: &tls.Config{\n        RootCAs: rootCAs,\n    },\n}\nhttp2.ConfigureTransport(clientTransport)\nclient := http.Client{\n    Transport: clientTransport,\n}\n\n```\nProto: HTTP/2.0\n. Cool!!\nAny idea, when this will be in a release?. Yes, would be very great!\nThanks a lot!!. ",
    "maxadamo": "this is still a problem. The issue is old, but after two years not all the applications are stateless. If you have weblogic or jboss you share a session ID among the cluster. If you don't have a clever application server, and you can't change the code of your application, you need to ask your load-balancer to perform the task. \nIf it's not a mobile app, you have plenty of options. Linux LVS is perfectly suitable. \nOtherwise, Nginx, HAProxy are probably your best friends. . ",
    "lensen": "So far I've tested 1.0.7, 1.0.6 and 1.0.5.\n. Consul v0.6.0\n. https://gist.github.com/lensen/0a7814ba07ce6c41718e\nThe first healthcheck of that node is currently in a critical state, and should be removed. \nKilling the consul agent and causing the serfHealth healthcheck to fail as well doesn't seem to remove the node either.\n. I think the problem is that it isn't so much the service is failing (the 002 node is still working, so the service is technically OK), but just one of the nodes is.\nAnyway, here is the routing table:\n```\nService Host    Path    Dest    Weight\n1   local-overview-swap     /overview   http://local-overview-swap-002.localdomain:8080/    50%\n2   local-overview-swap     /overview   http://local-overview-swap-001.localdomain:8080/    50%\n3   local-content-swap      /content    http://local-content-swap-002.localdomain:8080/ 50%\n4   local-content-swap      /content    http://local-content-swap-001.localdomain:8080/ 50%\n```\n. Specifying a (unique) ServiceID seems to fix it. Looks like a part of the consul puppet module bit me in ***:\ndefine consul::service(\n  $ensure         = present,\n  $service_name   = $title,\n  $id             = $title,\nI dunno if you want to keep this issue open or not, but it might make sense to change some logic here, since the consul DNS interface does seem to assume those nodes are really broken and doesn't return them.\nAnyway, thanks for the help.\n. ",
    "jblackburn21": "Thanks for the quick response.  We are looking at using this with several ASP.NET Web API projects, which is case-insensitive.  However, I believe we can make adjustments for this to work.\n. ",
    "herbrandson": "This is actually preventing us from migrating to using Fabio. We have been using dcos/marathon-lb which allows for case insensitive urls. Because of this, switching to using Fabio would be a breaking change for us. It would be awesome if perhaps we could do something like urlprefix-SomeService strip=/SomeService ignoreCase=true. After thinking about that request some more, I don't think we really care about ignoring case on a route-by-route basis. I think a command line switch to ignore case on all routes would be better (and I suspect significantly easier to implement in a performant way).. I can't tell you how happy this makes me :)\nI'll try to send a PR in the next couple of days.. PR sent: https://github.com/fabiolb/fabio/pull/553. I've never done GoLang before, but this seemed pretty straight forward based on the other examples. Let me know if I missed anything.. I believe I've addressed all of your comments. I just wanted to make sure there wasn't something I missed that you're still waiting on. Are there any other changes you'd like to see on this?. Any update on this? We really need this in order to migrate to fabio. I feel like this might be a terrible name, but it's the best I could come up with this evening. I'm open to suggestions. After looking at this again, I think this should be a case insensitive prefix match. Originally I was using EqualFold. Thoughts?. ",
    "vpol": "Yes, works fine. Thnx.\n. ",
    "alexherington": "Works perfectly. Thank you!\n. ",
    "rjes": "I don't have a specific use case yet, other than deliver a huge amount of content lightning fast.\nAnd I understand if it not the top10 of your features since it requires a very specific environment to operate in. (hosting partners doesn't often like the idea to implement asymmetric routing).\n. Another important use case for using DSR is not to be limited by the load balancer interface speed but be able to push content with the bandwidth of *.\nBtw, thank you for a good job, fabio seems very nice and i really like the integration with consul.\n. ",
    "tiago-msilva": "Hi guys,\nAny news on this matter?\nI'm really interested in getting weights on TCP proxy mode.\nThanks!. @magiconair \nFirst of all thank you for looking into this matter.\nI don't know a thing about go.\nI tried to build this with:\ngit clone ...\ngit checkout issue-42-weigh-targets\ncd  fabio\ngo build .\nand I got this:\n./main.go:399: t.Dump undefined (type route.Table has no field or method Dump)\nDoes this help out?. Thanks!\nI also set the GOPATH to \"~/go\" and cd to it before running go get.\nYep, it' worked. \nWill test this now.. @magiconair \nFantastic.\nI tried it with a simples 20/80 weight distribution and it worked.\nMoreover I tested it with my use case.\nWe're going to have a fallback TCP port like in haproxy, when one service is down just move to the fallback so I got one with weight=100 and another with 0.\nIt worked perfectly.\nOnly the 100 weighted service got traffic when it was up but if I killed it, once it went down on the consul check, only the 0 weighted service started getting traffic.\nThank you so much.\nGreat work.\nAny idea when this will be on an official release?. ",
    "nanoz": "Maybe we can help developing this feature ? If so, what would be the syntax ?\n/path weight=xxx ?. Any news on the Prometheus /metrics endpoint ?\nThis feature would be very helpful to us to measure things like requests throughput, call latencies and status codes, globally and maybe per entrypoint/endpoint as well ? :). This looks awesome, can't wait for this feature to hit a release !. Nooooooo !!! :). ",
    "jarrettj": "Hi,\nGood day.\nCould you maybe add a working example? I tried:\ntags = [ \"fabio-:6379 weight=1 proto=tcp\" ]\ntags = [ \"fabio-:6379 weight=1.0 proto=tcp\" ]\ntags = [ \"fabio-:6379 weight=100 proto=tcp\" ]\nI start fabio with:\nargs = [\n                \"-proxy.addr\", \":11211;proto=tcp, :6379;proto=tcp\",\n                \"-registry.consul.tagprefix\", \"fabio-\"\n                ]\nI'm using \nhttps://github.com/fabiolb/fabio/releases/download/v1.5.10/fabio-1.5.10-go1.11.1-linux_amd64\nThe weights are not update though. Might be missing something simple? Thanks.\nRegards.\nJJ. Agreed, adding a couple of examples would be awesome! :) . No worries :). Nevermind:\nargs = [ \"-proxy.addr\", \":6379;proto=tcp\" ]\nWorks now. :). ",
    "armand1m": "Is this defined anywhere in the docs? I couldn't find it there. ",
    "jeanblanchard": "OK I get the reasoning.\nI would argue that this introduces a requirement that services need to know the route they serve.\nYou can't change the \"mount\" path for a service, say from /myservice to /legacy/myservice without changing the service itself (which may not be an option).\n. ... And I'm back...\nIt turns out I really need this after all. I tried to make all services have their prefix configurable, but this introduces a bit of complexity everywhere in the service, which I really want to avoid.\nI think you'll agree that the services should not depend on the host where they are deployed. I believe the same is true for the path.\nStripping the prefix would allow services to work the same, regardless of the path where they are deployed.\nNote that I do not suggest rewriting the urls in the responses (or maybe just Location headers), but instead encourage services to use relative urls.\nAnyway, would you accept a pull request to add this option, or should I maintain my own fork ?\n. On the configuration side, I'm thinking a global configuration flag in fabio.properties (proxy.prefix.strip?).\nIt's probably not necessary to allow each service/route to override the behavior. \nAfter a first look at the code, the global config case seems to be pretty straightforward. I'm not sure yet how to handle the websocket case, I'll look into it.\n. I don't think it should work for a single global prefix. I think there should be a global option to strip the configured prefix for all services.\nBasically to access an app behind a fabio proxy, you need to add a prefix to identify the app. I propose to remove the prefix from the requests so that the app works as if there were no proxy.\nhttp://fabioserver/serviceprefix/user/index.html -> http://serviceserver/user/index.html\nThe idea for my case is that the services are third-party developed plugins, that should work the same regardless of where they are deployed.\n. ",
    "SathishN": "+1 for stripping service prefix. \nIn my case, I have multiple version of a web api, I'll have version prefix in the url. \nI would like the option of striping the prefix at fabio.\ne.g:\nhttp://api.client:9999/v1/clients/1234 (tag: urlprefix-api.client/v1) -> http://server1:8030/clients/1235\nhttp://api.client:9999/v2/clients/1234 (tag: urlprefix-api.client/v2) -> http://server1:8041/clients/1235\nI like the strip prefix to be per route/registration(at fabio) and ideally be managed as a consul tag(like urlprefix).\n. @magiconair client is a resource, v1 and v2 are versions of the client resource, they are served under host name is api.client. Integration tests are contained with in the code base/repository,  they don't need to know on api versions.\nYour right on web api's should know it routes, yes it'll and when web api starts up, it will publish it's route to the consul. But I don't want to inject the version info in the source code, it's a config value. I have few ways to handle this routing within web api itself. If fabio handles it, it moves the complexity out of my web api.\n. ",
    "msabramo": "This is interesting. I see @magiconair's point about how services should advertise the exact endpoint they respond to. \nIn my case though, I'm part of an infrastructure team and we work with dozens of existing services that are owned by about a dozen teams. Changing the services is not really an option. \nBut maybe fabio is not designed for this use case of integrating a bunch of legacy services. \n. @magiconair Nope, I haven't tried. I just happened upon fabio yesterday while searching around for the latest on using consul-template to configure nginx or HAProxy. I've been thinking through what the possible roadblocks could be.\nThanks for sharing fabio!\n. ",
    "jovandeginste": "Is there a way to pass this option via the Consul tags?. Just tried this, and it works! Although spaces in the tags give some very strange side-effects :-). For completeness sake, the stripped part is not added as a Request header?. The side effects are completely unrelated to fabio. We use service name and tags to create some automatic entries in consul's kv store like /services/$service_name/$service_tag/$container_id/, for each tag of the container. This becomes weird when the tags now start containing / and spaces by design ;-)\nAbout the stripping, I'm still not sure if I want to use it. It's nice to have, but dangerous in practice. It works for specific cases. Why the header would be useful? Because the web app could refer to it's root by the header (/$header/) for assets and thus work irrespective of that root.\nThe actual use case I have is on demand spawning of docker containers for our dev teams, running their git branches of different services for internal testing. Since there will be numerous parallel branches, they should be easily discernible. My two main options are branchname.servicename.commondomain/ and commondomain/servicename/branchname/. Not sure if I need to explain pro's and cons of each option... I sadly don't have a well funded opinion about the way you implemented it.. I thought about it a bit more and I now think the tag system is not ideal. The better way would be to use consuls kv store for all the parameters including the urlprefix. Not sure if this still fits inside the scope of this project then...?. @magiconair maybe fabio does not need to care about populating and cleaning the kv store (just like it doesn't care about adding the service tags); this can be an entirely separate process indeed, like the registrator we use. Fabio would only be a consumer of that information.\nIn this story, fabio reads the (relevant part of the) consul kv store to find out what services it is supposed to serve, and in that kv store it will find what consul service it should forward incoming requests to. Fabio will then monitor those backend services like it does now (health checks). If there is configuration in the kv store but no (healthy) backend, it could respond with the proper http code (502?)\nThen again, maybe this is entirely out of scope for this project. . ",
    "if6was9": "Reading through this thread, I was thinking of Traefik.  It is very agnostic about the underlying config plane. \nFabio seems much more complete, though. \nOur distributed config and service registry is converging around etcd.  It has certainly crossed my mind to build an etcd/consul gateway to get Fabio to play nice. \nI totally understand the author's indifference to this if consul is entrenched with his employer. \nWe are also looking at building a supervisory daemon around HAProxy as another option.  Something like vamp.io but a bit simpler.   This would couple a newfangled control plane with a battle tested runtime. \nThe most interesting thing about all of this is how dynamic (and unsolved) this problem space is.  Lots of good stuff out there.  No obvious long term winner. \nLike what you have built here though.   I think that maybe that accounts for the strong opinions in this thread.  \nFabio could totally be the load balancer for the next 10 years.\n. ",
    "r0ps3c": "Thanks, will check it out\n. Now hitting an issue I'd noticed previously (but not yet reported :-): in serviceRegistration, unless config.LocalIP() can't find a local address, the addr supplied to it is always ignored. I'd say move the \ngivenip := net.ParseIP(ipstr)\n                if givenip == nil {\ncheck earlier and only call LocalIP() if the given addr doesn't have a hostip part\n. Please see #49 for fix\n. Thanks, should be able to do that in the next couple of days, will get back to you with results soon after\n. Hi @magiconair,\nin testing, the docker image seems to be working well for me, so I'd say this issue can be considered resolved.\nThanks\n. Hi,\nhave these changes or the issue 12 branch been merged into the 1.0.9 release? I see the docker image with these has been removed so wondering what the plan is if they haven't been merged\n. Thanks for the clarification, will check out the new images\n. ",
    "CLAassistant": " All committers have accepted the CLA.\n.  All committers have accepted the CLA.\n.  You should sign our Contributor License Agreement in order to get your pull request merged.Ernest Micklei seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account (for further information, click here).\n.  All committers have accepted the CLA.\n.  All committers have accepted the CLA.\n.  All committers have signed the CLA..  All committers have accepted the CLA.\n.  All committers have signed the CLA.\n.  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.1 out of 3 committers have signed the CLA.:white_check_mark: erikvanoosten:x: Sander van den Berg:x: svdbergSander van den Berg seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account.\n.  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.\n.  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.Avichal Badaya seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.zjj seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA.. ",
    "xiaods": "@magiconair what reason for support docker api? cloud you please give more information?\n. @magiconair i have run consul cluster in our infra. then you know the fabio one by one registered to local consul agent. then i manually stop a local agent, i need a way to let fabio know the local agent is down, then the fabio should be handle the case and can switch the fabio to another consul?\nactually @magiconair could you please share some best practice to deploy fabio and consul. we need some guide on this production direction.\n. @magiconair thanks for your patience guide. let me testing it again. then give more feedback on your suggest.\n. ",
    "skymaster420": "+1. ",
    "ilya-pi": "Sweet!\nUI-wise, don't you think it might be cool to mark all overriden Weights? So that it will show something like: 16% (Overriden), 0% (Overriden).\n. ",
    "sielaq": "Seems like this is related to \nhttps://github.com/golang/go/issues/3665\nwhich is fixed in go1.6\n@jacekmaza we can verify it tomorrow.\n. we have tried today with 1.1 (with go1.6.rc2) but unfortunately same problem still exists.\nWonder if some extra flag need to set to turn on a proper behavior of library.\n. ok this is just documentation issue\nin \nhttps://raw.githubusercontent.com/eBay/fabio/master/fabio.properties\n```\nregistry.consul.register.addr configures the address for the service registration.\n\nFabio registers itself in consul with this host:port address.\nIt must point to the UI/API endpoint configured by ui.addr and defaults to its\nvalue.\n\nThe default is\n\n-# registry.consul.register.ip = :9998\n+# registry.consul.register.addr = :9998\n. +1 for access logs, also to a file too. ![please](http://danhairfield.files.wordpress.com/2011/12/2005_07_21_shrek_cat1.jpg). ![please](http://danhairfield.files.wordpress.com/2011/12/2005_07_21_shrek_cat1.jpg). any news ?. true, but then it shouldn't just die.\nRather informing `[INFO] restart/reload has to be done in a controlled way. Application will not be reloaded.`\nand let fabio still running.Otherwise we have to overwrite the daemon's behavior in systemd for something hack'y like:\nExecReload=/bin/true\n```. As I said, it is not always about changing config - it about upgrading fabio in a Debian/Ubuntu way.\nSince we do Debian wrapper package for Fabio, each installation triggers (by default, not by us)\nservice reload -  which makes Fabio die (since it doesn't handle with HUP signal).  \nAs I said - we can overwrite systemd behavior - but better is to align all \"perfect trinity\" :pray: behavior (consul, nomad, fabio) - Fabio is behaving differently here.. suspecting this, but not 100% sure:\nhttps://github.com/hashicorp/consul/commit/2aac4d5168cc761ca58f2500e65ec1874cb9f168. and might be connected with\nhttps://github.com/hashicorp/consul/pull/5457. @magiconair, At the begging I was suspecting an incompatibility - sort of change in api behavior.\nBut now, I suspect, that this is a Consul bug. Since this is a serious accusation (A consul bug? can't be) I would prefer also you to verify that :) . ps: My suspicious is: that Consul remove all health checks even if only one service was removed, so Fabio loose all routes.\n(The reason, why in my case,  was so hard to understand what was going on, was that Registrator constantly was trying to heal the situation...). thx for confirming !. right, we could add to readme some note\nthat 1.4.3 is broken. ",
    "jrwren": "AFAICT net/http automatically replies with 100-continue BEFORE ServeHTTP is called, thus preventing step 3 from happening before other steps in the given expected cases above.\nhttps://go.googlesource.com/go/+/master/src/net/http/server.go#1680\n. ",
    "jmheidly": "why hasn't this PR been merged yet?. ",
    "pushkaradsule": "I am trying to validate/decrypt  JWT token and passing information in request headers to host ( where api are running)\n. I got you point, i am just thinking how this will be achieved without having to duplicating code on every service, as we have services in different languages. \n. Thanks for prompt reply \n. ",
    "voanhduy1512": "Hi\nIn nginx you can do authentication https://developers.shopware.com/blog/2015/03/02/sso-with-nginx-authrequest-module/. \nRight now i need to do something like this\ninternet -- HTTP/HTTPS --> Authentication layer -> fabio -- HTTP --> internal services\nNow i need another balancer in authentication layer because they have multiple instance of authentication services.\nI think it would be nice if fabio let me inject some code to run or make http call before process like nginx\n. Thank you for your suggestion.\n. Thank you for your quick respond. I want fabio not registered to consul at all\n. ",
    "susl": "I'm not sure what you mean by rewriting, but I imagine that it may blow up routing table.\n. ",
    "erikvanoosten": "Another variation is to allow for switching a given service (all URLs they support). E.g.:\nroute weight service-1 * weight 0.05 tags \"canary\"\n(where the * is any URL)\nThe following could be used to describe switching the given URL (all services that support it):\nroute weight * /api/service1 weight 0.05 tags \"canary\"\n(where * is any service)\n. > s/AcceptableStates/States/\n@magiconair In the last commit the field was renamed to AcceptableStatus to reflect Consul terminology. I have no idea what the plural is of status is. Please advice.\n. I am closing this and I will create a new PR.\n. @magiconair in #116 you commented:\n\ns/AcceptableStates/States/\n\nHowever, the field was renamed to AcceptableStatus to reflect Consul terminology. I have no idea what the plural is of status is. Please advice.\n. @magiconair you can just checkout the branch and ask @svdberg for push rights on his repo.\n. That's already gone in the last commit. I couldn't figure out how to squash the commits. I can spend more time on that if you wish.\n. Already done in the last commit.\n. @svdberg please rename here also\n. @svdberg please rename here also\n. @svdberg please rename here also\n. @svdberg please rename here also\n. ",
    "ketzacoatl": "\nEach property value can also be configured via a corresponding environment variable which has the dots replaced with underscores.\n\nYes, I am so silly, thanks!\n. @marcosnils did you have any luck diving it?. Until support for Prometheus lands, what is the current recommended method for getting stats from fabio to prometheus?. Maintaining a project like this can be such an under-appreciated, and often times thankless investment, so thanks for letting us know what you've got going on and what help you need. Good luck on the move and all the transitions that has with it.\nAs far as getting metrics incorporated.. I won't be much help with go, but I would be happy to make myself available for testing metrics in an updated fabio. It'd be most easy for me to test with prometheus, but I can help with others too.. Where \"VERY high load environment\" == 100's of thousands of requests per second? or 10's?\nThanks for the info and feedback.. yea, I think it'd be best to run load tests to confirm how well the IO is processed and how much is too much before the underlying system blocks fabio. Thanks for the feedback!\nI'll close this for now, and maybe be able to post results if we are able to run those tests.. ",
    "discobean": "I am using python consul client to register our checks, everything appears ok in the Consul GUI.  \nI'm also running Fabio 1.0.8.  I'm trying with 1.1.1 now\n. I checked and 1.1.1 has the same issue, here is the log:\nWhen I start fabio, one service is running, but the other health check is failing in consul:\n2016/03/30 14:08:24 [INFO] Updated config to\nroute add ErrorTestingService-40 api-40.prod/ErrorTestingService/v1 http://10.90.44.52:41114/ tags \"urlprefix-api-40.prod/ErrorTestingService/v1\"\nroute add ErrorTestingService-40 api-40.prod/ErrorTestingService/v1 http://10.90.34.115:40414/ tags \"urlprefix-api-40.prod/ErrorTestingService/v1\"\n-- So the above 2 routes are wrong, because one health check is failing\n2016/03/30 14:08:39 [INFO] consul: Health changed to #339283\n-- This health status is now a change from critical -> OK for one service above\n2016/03/30 14:09:08 [INFO] consul: Health changed to #339289\n-- This health status is now a change from OK -> critical, but no route removed\n-- At this point only 1 server is running, but 2 routes exist in fabio\n-- Now below, I stopped the last single service, and it unregistered both the services\n2016/03/30 14:11:32 [INFO] consul: Health changed to #339315\n2016/03/30 14:11:32 [INFO] Unregistered timer errortestingservice-40.api-40_prod./errortestingservice/v1.10_90_44_52_41114\n2016/03/30 14:11:32 [INFO] Unregistered timer errortestingservice-40.api-40_prod./errortestingservice/v1.10_90_34_115_40414\nNot sure what is going on here :(\n. Could it be because the service name is the same for the 2 checks?  Even though they are on different nodes?  I would have thought that was ok.\n\n. Thanks mate, I will update and I'm sure it will fix it as it makes sense now.\n. Haha it worked :D Thanks so much once more.\n. Considering the web is moving to https by default, adding a default redirect to https would make migrating 10s or 100s of microservices behind fabio much easier.\nWe'd love this feature very much :). We use nginx for offloading SSL, ACLs, rewrites and these sorts of more complicated tasks.\nIf fabio were to route to another DC then it would solve another problem we have - where if one microservice fails in DC1 all nginx routes all microservices attached to that upstream to DC2.\nI'll test your patch next week and let you know.  Thanks so much as usual!\n. Hi, can confirm this now works! \ud83d\udc4d \n. Managing CORS though fabio would certainly be something that we would use\n. Actually after more debugging I think it is mule keeping the connection open\n. Just an update, confirmed this is an issue with mule 204 response, there is a scenario where mulesoft will return a 204 response, but the connection will remain open waiting for more response data.\nie. when I try the mule service via curl and no proxies, I get the 204 response, but then mule just keeps the connection open and curl times out after 30 seconds.  Which explains the 30+ seconds delay.\n. Yes that is correct, if the service is registered under the domain using HTTPS the problem goes away.\nThe SSL certificate and site responds to just one domain (mydomain.com) and doesn't work against the hostname of the server (site just redirects to mydomain.com).  This is a problem when there is more than 1 backend.\nI was looking for a workaround, maybe the solution is an option to ignore SSL verification.\n. I think this could also be solved with issue #1 being implemented, and just use TCP with passthrough direct to the backend\n. Closing it now, thanks so much!\n. No problem I will investigate, thanks so much\n. Thanks, I also think the iterating in the glob matching would slow it down with many hosts and some sort of index cache would have been good, but just didn't have enough time on this first version.\n. I can foresee some problems when matching routes based on order - because I think in the code the ordering is based on the path, not the domain.\nSo ideally the code should find all the matching hosts and paths, and return the most restrictive result.\n. I think there is more to it also, say you have 2 routes:\n1. urlprefix-*.abc.com/myurl\n2. urlprefix-foo.abc.com/myurl\nA request to foo.abc.com/myurl would need to match against route 2, my hacky code doesn't take this into account.\nAnd given more complicated globs, which should have the priority?  Should there be some priority field then?  :S I'd rather it remain simple somehow keeping to the original goal of Fabio.\n. Yep that was the original problem I had, totally agree it can be done better, but I didn't want to dig too much into it without more experience with go.  I'll look into the code a bit more tomorrow.\n. @osigida, unfortunately no, my fork is actually working but it is not the best way of doing it, so it needs a rewrite. Thanks @magiconair . Using raw metrics when sending to statsd would certainly make life simpler. I have found a few key points that are frustrating us:\n\nThe metrics for count are absolute count received since the process started\nI actually have no idea what min/max/mean/std-dev/50-percentile etc actually show\nThe metrics for one-minute, five-minute are not correct\n\nI'll elaborate on 2 and 3:\nmin/max/mean/std-dev/50-percentile:\nAs a test I have pushed through some data to fabio and recorded the metrics.  The initial values for min/max/mean are: 0/0/0\nI push through one request, the values are now each: 44462314.0/44462314.0/44462314.0.\nWhat exactly is 44462314.0? My guess is it is latency, but is it in ms? microseconds? Probably it is just me, but I have no idea.  The actual request time from my client was ~353ms\nNow each flush of metrics the value of min/max/mean remains the same, even though I am not putting any traffic through.  So the mean is always 44462314.0, forever.\nSo the value is the min/mean/mean value for all the requests since the beginning of the process?  That data is not really usable.\none-minute, five-minute issue\nI found after putting through requests over time, the one-minute value never goes to 0.  Even though there is no traffic going out for the past minute :S\nIf I wait sometime, and then push traffic through for a minute, the 1 minute value != the values of traffic I actually sent in that last minute.\nWhat would be a solution\nI think the metrics required would be:\n\nthe number of requests\nthe min/max/mean/average latency\n\nImportantly they would be relative to that metrics period.  So if metrics.interval is set to 60, the data would be the total request count for 60 seconds, etc..\nFor our purposes only, we just require metrics per service, 2 values: count/latency, we do not require a full suite of metrics per URL/host/fabioserver combination as that is just too much (and we push metrics to cloudwatch which makes it more expensive). \nie. service-xyz.count and service-xyz.latency_min/max/avg/mean \nOr something along those lines.... Yep, this patch is confirmed working now :)\nWe also use the dst feature too. Hey, cool thank you :D. All good mate, no need to rush so much :P. It might come or it might not :P. ",
    "manos": "+1\nI'm trying to add a route for /favicon.ico -> www.domain.com/ and www.domain.com is fronted by cloudfront. If it doesn't get Host: www.domain.com, it can't serve favicon.ico for me.\nPerhaps a workable solution here would be adding opts \"host=www.domain.com\" to the route -- if it supported that :). @magiconair does the above comment make sense? . \ud83c\udf7f watching with excitement. Happy to help test.. Regarding the authorization of the domain, I don't think fabio needs to be involved. If someone asks for foo.company.com and vault allows that cert to be fetched, fabio can serve the cert it fetches (and cache it). If vault doesn't allow it, fabio can serve a default cert or throw an error?. ok, all user error it looks like. I didn't read closely :). Ooh, I think you're right. This is mostly happening when I see:\n[INFO] agent: Synced check '2d2b8e084ac62d104f97b46a3eb1031e0de165da'\nThanks again :)\nLoving fabio, by the way. It's working wonderfully.. BTW, I'm not sure fabio should be logging anything unless the cluster state change impacts a service with urlprefix- tag(s), but knowing that I can ignore this is helpful.. Amazing turnaround time, thanks @magiconair  :). I started seeing this again too. Suspecting a regression.. @magiconair is this possible to add to 1.5.3, if it's not too late? :). oh, right. Thanks :). ",
    "ragunathp": "Hi,\nIs this feature available in 1.5.2? Based on the document reference  https://github.com/fabiolb/fabio/wiki/Routing#manual-overrides, it seem to be available with the option for \"host=name\".  Could you please confirm?\nMy use case is to configure docker HRM endpoint in fabio and I face the issue.\nWorks fine when I do,  curl -H 'Host: xyz.docker-hrm.example.com\" http://fabio-ip:9999/app/somepath \nBut the issue exists while hitting from browser http://fabio-ip:9999/app/somepath.\nOption configured in fabio as \"strip=/app host=xyz.docker-hrm.example.com\"\nThe '$request_host' in fabio is not changed to 'xyz.docker-hrm.example.com'\nIs it something I am missing?\n. Thank you looking forward for  1.5.3 release.. However, my colleague helped me with the below option and it worked.\nThat is to set CONSUL_HTTP_SSL_VERIFY=false and start Fabio. This helped to avoid the above issue. ",
    "rutchkiwi": "thx for the quick reply!\nIn my case I'd like to log to stdout, since I'm running the docker image and all my other containers send their logs off to a log aggregation service using a docker log driver. \n. That would be perfect for me\n. No strong preference really, but json would be easy to parse. The data I capture in other places would be \n- the http method/hostname/path\n- the response time & status\n- which (upstream) server it got routed to\n- the local time\n- the user agent\nOf course for a first version it would be really nice just having the first two! Let me know if there is anything I could do to help with this. :)\n. ",
    "osigida": "I guess, the format should be configurable, say we'd like to have some headers as well.\nHere is implementation from logback, might be useful: http://logback.qos.ch/access.html\n. hi all,\nthe feature looks interesting, any progress on it?. ",
    "sfleiter": "What is still missing to be able to merge this?\nLooking forward to the feature.\n. Thanks a lot for your fast feedback Frank,\nhope you have a wonderful vacation!. ",
    "ElliotG": "Also wanted to add that access logging would be super awesome.. ",
    "ak66982": "$upstream_host logs protocol pre-pended to the host, $upstream_port leaves slash after the port:\nIs this intentional ?\nproxy.log.format = addr:\"$upstream_addr\" host:\"$upstream_host\" port:\"$upstream_port\"\nMar 28 23:33:14 30383225-ce3b-42ec-a292-8b770212d5b9 fabio: addr:\"http://10.1.6.227:1991/\" host:\"http://10.1.6.227\" port:\"1991/\"\n. By the way, thanks for the wonderful piece of software!\n$response_body_size sometimes logs '-1' instead of proper size (redacted):\n```\nMar 29 21:19:56 local fabio: 2017-03-29T21:19:56.415Z [remote]:44876 [host] 10.1.7.195:1991 6.852 200 -1 \"POST [URI] HTTP/1.1\" \"[DATA]\"\nMar 29 21:19:56 local fabio: 2017-03-29T21:19:56.598Z [remote]:44876 [host] 10.1.7.195:1991 0.175 200 -1 \"GET [URI] HTTP/1.1\" \"[DATA]\"\nMar 29 21:19:57 local fabio: 2017-03-29T21:19:57.222Z [remote]:44876 [host] 10.1.6.75:1991 0.084 200 -1 \"PUT [URI] HTTP/1.1\" \"[DATA]\"\nproxy.log.format = $time_rfc3339_ms $remote_addr $request_host $upstream_addr $response_time_ms $response_status $response_body_size \"$request\" \"$request_args\"\n``\nI checked the tcpdump, there was nothing strange in these requests.Content-Lengthis missing from reply, but$response_body_size` was logged correctly in other requests with content-length missing.. @gagan2u2002 \nSorry to interfere, but I had exactly the same issue. The cause was health checks configuration in consul. Make sure that each service and each health check that you defined has a unique id.. ",
    "md2k": "Hi Frank, you right and templates for prefixes will be more elegant way, but solution above was faster and allow me solve the problem with namespaces instantly with minimal changes of Fabio code and reduce amount of possible problems with it.\nI'll also check other possibilities to do it better way, since i'm in demands of that feature.\n. Also need add possibility to use short hostname and fqdn (hostname -f), because currently it use only short hostname of the server. \n. @magiconair check my latest commit please. templates use native text/template library\nand now custom prefix can be set next way: metrics.prefix = myapp.{{.Fqdn}}.{{.Exe}}\nNot final variant, but feedback will be useful.\nYour advice to use ENV, not very suitable for me at this moment.\n. About hostname -f on solaris i know, this why it have error handler where it use normal hostname in case of error, but not have solaris to test this part, but we can add OS detection for example for Win/Sol to fallback FQDN to hostname. i'll check more precisely with cleanups/fixes.\n. @favoretti , i know, but in GoLang i not found any other way to do so. if you have other ideas , shoot :)\nOther way to reconfigure hostnames. ok, i'll check tomorrow if there nothing better except hostname -f.\nmain target of patch allow to use custom prefixes.\n. @magiconair because then it require take care about recipes to manage dynamic variables and use those variables in application declaration files. I think this killing some part of automation, because then i should ensure that those variables are set. If variables static like environment=production or GOGC iti s fine, but if variables unknown before application start, like FQDN of instance, or IP where application listening i should take care with some amount of scripting around or keep in my deployment tool map of variable=value per host, definitely i wanna escape those scenarios if possible and this why i came with idea which allow use templates in prefix configuration. All depends from internal structure of projects, in my case i trying to minimize amount of scripting around application during its deployment and startup.\nBut i agreed with @favoretti, and i not should use binary exec because it is OS dependent.\n. METRIC_PREFIX=${ENV}.$(hostname -f) will work good only for bash based bootstrap applications like daemontool or similar with ability to accept and execute bash commands, we for example use another approach to start applications where i unable to pass bash executable commands, unfortunately. \nI agreed that my solution not portable because i use hostname -f, and i think we can skip that part for now and just cleanup template solution. If you fine with text/template functionality i can try to clean it or find another template solution.\n@favoretti, your solution may work but then you should ensure about IP address passed to function and that your PTR record correctly maintained. I think lets skip hostname detection. more easy change instances hostnames to fqdn and simply allow to user customise prefix by template.\n. if you bind proxy.addr to 0.0.0.0 then you should care about proxy.localip manually or no?\n. may cause problems if instance have multiple interfaces with more then one network and if IPs have different PTR records or /etc/hosts records\n1.1.1.1 server.external.example.com\n2.2.2.2 server.internal.example.com\nit means that localip can be set differently between starts and have different hostnames in metrics, chances not so big, but exists.\n. Hi @magiconair, any ETA when you planing to take a look for this improvement? \nNo rush, of course :)\n. Hi @magiconair, was busy with other things. Thanks for the patch, i will check it as soon as possible (within 1-2 weeks). i did required changes, hopefully it now much better.\nand thanks for the tip about anonymous structures. \n. and also i'm not sure if i should keep metrics.prefix = default processing or no, for backward compatibility if someone who use Fabio and uncommented this option?\nNew functionality will broke old style prefix immediately :)\n. Oki, i'll push changes tomorrow.\n. ok, will do shortly\n. ",
    "favoretti": "@md2k calling system binaries in portable software is a huge no-no. Something in line of net.LookupHost() on your non-localhost IP would probably do the trick. \n. One could do something like:\nfunc externalIP() (string, error) {\n    addrs, err := net.InterfaceAddrs()\n    if err != nil {\n        return \"\", err\n    }\n    for _, addr := range addrs {\n        var ip net.IP\n        switch v := addr.(type) {\n        case *net.IPNet:\n            ip = v.IP\n        case *net.IPAddr:\n            ip = v.IP\n        }\n        if ip == nil || ip.IsLoopback() {\n            continue\n        }\n        ip = ip.To4()\n        if ip == nil {\n            continue // not an ipv4 address\n        }\n        return ip.String(), nil\n    }\n    return \"\", errors.New(\"are you connected to the network?\")\n}\nAnd then basically convert that IP to a hostname. Not 100% fool-proof, but better than calling hostname.\n. We set gogc to 100 and memory remains relatively under control. That said, maybe the default of 800 is a bit too royal?. ",
    "cookandy": "I'm actually trying to use TCP proxying, but it doesn't look like Fabio support it yet.  I thought maybe websockets would work for TCP connections, but I'm not sure that is true.  In the case of my TCP connections, we won't be able to change the header before the request is sent - so I guess websockets won't work.  I guess what I really need is TCP proxying.  WDYT?\n. Thanks - I will watch for updates.\n. ",
    "stevej": "Hi, thanks for the reply!\nI went ahead and added urlprefix-/ tags but am still getting a 404 and an error No route for web/ from fabio's stdout. Are my tags still malformed?\n```\n$ cat consul.d/web.json\n{\n  \"services\": [\n    {\n      \"name\": \"web\",\n      \"id\": \"perf-target-1\",\n      \"tags\": [\"urlprefix-web-/\"],\n      \"address\": \"10.240.0.6\",\n      \"port\": 4140,\n      \"checks\":[{\"script\": \"/bin/true\"}]\n    },\n    {\n      \"name\": \"web\",\n      \"tags\": [\"urlprefix-web-/\"],\n      \"id\": \"perf-target-2\",\n      \"address\": \"10.240.0.5\",\n      \"port\": 4140,\n      \"checks\":[{\"script\": \"/bin/true\"}]\n    },\n    {\n      \"name\": \"web\",\n      \"tags\": [\"urlprefix-web-/\"],\n      \"id\": \"perf-target-3\",\n      \"address\": \"10.240.0.7\",\n      \"port\": 4140,\n      \"checks\": [{\"script\": \"/bin/true\"}]\n    }\n  ]\n}\nstevej@proxy-test-16:~$ curl -H \"Host: web\" -vvv localhost:9999\n Rebuilt URL to: localhost:9999/\n Hostname was NOT found in DNS cache\n   Trying 127.0.0.1...\n Connected to localhost (127.0.0.1) port 9999 (#0)\n\nGET / HTTP/1.1\nUser-Agent: curl/7.38.0\nAccept: /\nHost: web\n< HTTP/1.1 404 Not Found\n< Date: Fri, 15 Apr 2016 17:18:26 GMT\n< Content-Length: 0\n< Content-Type: text/plain; charset=utf-8\n<\n* Connection #0 to host localhost left intact\n``\n. Unfortunately, I get the same 404 withurlprefix-/`\n\nHere is some output from fabio's stdout in case it's useful.\n2016/04/15 19:01:21 [INFO] Setting GOGC=800\n2016/04/15 19:01:21 [INFO] Setting GOMAXPROCS=16\n2016/04/15 19:01:21 [INFO] Metrics disabled\n2016/04/15 19:01:21 [INFO] consul: Connecting to \"localhost:8500\" in datacenter \"dc1\"\n2016/04/15 19:01:21 [INFO] consul: Registered fabio as \"fabio-proxy-test-16-9998\" with address \":9998\" and health check to \"http://[10.240.0.9]:9998/health\"\n2016/04/15 19:01:21 [INFO] Admin server listening on \":9998\"\n2016/04/15 19:01:21 [INFO] consul: Using dynamic routes\n2016/04/15 19:01:21 [INFO] consul: Using tag prefix \"urlprefix-\"\n2016/04/15 19:01:21 [INFO] consul: Watching KV path \"/fabio/config\"\n2016/04/15 19:01:21 [INFO] Using routing strategy \"rnd\"\n2016/04/15 19:01:21 [INFO] HTTP proxy listening on :9999\n2016/04/15 19:01:21 [INFO] consul: Health changed to #8\n2016/04/15 19:01:21 [INFO] consul: Manual config changed to #1\n2016/04/15 19:01:21 [INFO] Updated config to\n2016/04/15 19:01:21 [INFO] consul: Health changed to #9\n2016/04/15 19:01:25 [WARN] No route for web/\n. Switching to http-based health checks brought the cluster up. Sorry for the consul noobishness, it's not something I use on a regular basis.\n. I have this working now so I'm going to close this ticket. The numbers i'm seeing are better than advertised: 28k qps using 6 cores on a 16-core GCE vm instance using about 45mb of RAM. p90 was 1ms, p95 was 5, p99 was 600.\nThank you for all your help!\n. ",
    "mazhack": "Thanks for answer, i write bad common name, it was .domain-2.com instead of .domain.com, thanks for say it.\ni am waiting for this change, it is very useful for me.\nthank you again.\n. if fabio is behind of another proxy, then this has not sense, but if it is directly connected to internet is very useful\n. I use X-Forwarded-Proto header before, but all domain is secure, so i want to do the redirection out of application, for me is better do it in reverse proxy and not load all php application in symfony for do a redirection.\nI am using now 2 fabio instances one for http and another for https and work fine. \nmany thanks for the answer.\n. I use ServiceAddress for health check and expose an old IIS web application on windows server 12, consul agent host and windows host are different, so if you change ServiceAddress to Address my prod environment will be break.\nSo, is good for me that fabio uses Address only if ServiceAddress is empty.\n. i change the tag, and now do not work without 443\n2016/04/26 15:43:45 [INFO] consul: Health changed to #2208\n2016/04/26 15:43:45 [INFO] Updated config to\nroute add losmovilesapi_lostaxis losmovilesapi.lostaxis.com:443/ http://192.168.100.123:32775/ tags \"losmovilesapi.lostaxis.com,fabio_prod-losmovilesapi.lostaxis.com:443/\"\n2016/04/26 15:43:52 [WARN] No route for losmovilesapi.lostaxis.com/losmoviles/api/driver/1095923341/993\n2016/04/26 15:43:52 [WARN] No route for losmovilesapi.lostaxis.com/losmoviles/api/driverphoto/1095923341\n2016/04/26 15:43:52 [WARN] No route for losmovilesapi.lostaxis.com/losmoviles/api/driver/1095923341/993\n2016/04/26 15:43:52 [WARN] No route for losmovilesapi.lostaxis.com/losmoviles/api/driver/1095923341/993\n. finally it works but i need define 2 routes\n2016/04/26 15:46:29 [INFO] Updated config to\nroute add losmovilesapi_lostaxis losmovilesapi.lostaxis.com/ http://192.168.100.123:32776/ tags \"losmovilesapi.lostaxis.com,fabio_prod-losmovilesapi.lostaxis.com:443/,fabio_prod-losmovilesapi.lostaxis.com/\"\nroute add losmovilesapi_lostaxis losmovilesapi.lostaxis.com:443/ http://192.168.100.123:32776/ tags \"losmovilesapi.lostaxis.com,fabio_prod-losmovilesapi.lostaxis.com:443/,fabio_prod-losmovilesapi.lostaxis.com/\"\nall traffic is https, only 443 port is open, see the first comment. it is a bug or a feature?\n. Perfect, this fix my problems in ticket #87 too. Now i can redirect traffic using the protocol default port. Thank you. I am using fabio in production and is amazing!!!\n. @SkyRocknRoll do not use ports for micro-services, is a nightmare with proxies and firewalls, better use paths or subdomains.\nif prefer subdomains using a wildcard domain and wilcard ssl.\n. see #90 \n. ",
    "freeman": "Thanks for your answer. I'll try it out and will let you know.\n. ",
    "floekke": "I'm at the moment experimenting with running fabio on Windows. So far it's working.. Do you see any reasons why that might not be the case now or in the near future? \n. Perfect! \n. Thank you!. ",
    "RXG0": "We are mostly a windows team and would like to know if there are installation instructions and/or binaries for fabio?. ",
    "iadknet": "I agree with @mazhack and am looking for a similar solution.\nI understand that service configuration should be decoupled from the load balancer, but something as basic and universal as enforcing ssl definitely belongs with the load balancer.\n. I disagree with the philosophy that this is a service-level configuration.\nServices should not have to worry about http/https.  That is a product of the environment they live in and should be decoupled from the service itself.\n. @magiconair I still disagree that ssl is a service-specific configuration.  It is an environment configuration.  What fabio does to decouple routes from the load balancer config is fantastic.  Routes are something specific to the service.  But https is a function of the environment, not the service.\nLet's say you have a mix of 100 microservices running java, nodejs, and go.  When these services come up, all they know is that they start up and listen on a port.  If you want each service to be responsible for forcing ssl, then they need the following logic:\ndoes my upstream lb support an ssl endpoint?\n   if yes && the request came in on a non-ssl endpoint:\n       redirect to the https endpoint\nThis requires the service to have knowledge of its environment that it shouldn't need to have.  How does it know that it is running in an environment that has an ssl endpoint?  How does it know what that endpoint is?  These are all functions of the environment that should be completely decoupled from the service.\nIt gets even more complicated because there is inter-service communication that doesn't go through the load balancer (such as consul health checks).  So then the logic needs to look like this:\ndid the http request come through a lb?\n   if yes\n     if lb request was non-ssl && lb supports ssl\n       redirect to ssl\nelse \n   serve content without redirect\nAnd this logic has to be written into all 100 services, instead of at one entrypoint at the lb.\nSo, in my environment to solve this problem, I have to have nginx in the mix solely for the purpose of doing https redirects.\n(80) AWS ELB -->  nginx (301 -> https)\n(443) AWS ELB --> fabio --> microservices\n. @magiconair Yes, I'm sorry to be contrarian :)  I agree that ideally whatever the top level entrypoint is into your app (in this case the AWS ELB) should ultimately be responsible for enforcing SSL.  Hopefully with the introduction of the ALB, Amazon will add this functionality.\nWe terminate SSL at the ELB because of the ease of integration with the AWS certificate service.  \nFabio, as the router, is the glue that holds all the microservices together and makes them function as a single platform, with a single entrypoint.\nTo give some insight into how we're using fabio for a multi-tenant platform:\nEach service registers with consul and sets their urlprefix tag to register a route. \nhttps://tenant1.domain.com/admin -> (443) ELB -> (9999) fabio -> admin frontend service (serves index.html that references static content in cloudfront/s3)\nhttps://tenant1.domain.com/api/user -> (443) ELB -> (9999) fabio -> user service\nhttps://tenant1.domain.com/api/forms -> (443) ELB -> (9999) fabio -> forms service\nFor us, SSL is a function of the platform and not of each individual service that composes the platform.   Either the platform is SSL terminated or it is not.  It might be ignorance on my part, but I can't imagine why you would want to have SSL on some endpoints and not others? \n. ",
    "avarabyeu": "Not sure if it's right place to ask the question, but can i configure redirect from http to https? Seems no, so do you have plans to implement it?. In my personal case i'd like to have the same behaviour that i had with Zuul :)\nFor example,\nurlprefix-/myprefix opts strip=/myprefix\nSince /myprefix is being stripped, X-Forwarded-Prefix=/myprefix should be added to be able to build valid request URL from upstream proxy. \nSo yeah, it's original request path. But seems like only when you strip some part of it. \nbtw, as far as i know, the following list are usually added:\n\nForwarded\nX-Forwarded-Host\nX-Forwarded-Port\nX-Forwarded-Proto\nX-Forwarded-Prefix\n\nAnother important point is that you have to keep those headers from upstream proxy (if fabio itself  is placed behind proxy). In this case i should have two X-Forwarded-*** headers, one from upstream proxy and another one from fabio.. @magiconair Just checked it. Seems like i didn't understand your question about original request path :) Header is added, but value should contain only the part that was truncated by proxy. \nFor example:\nWe have registered service with the following params: urlprefix-/myprefix opts strip=/myprefix\nI'm executing some GET /myprefix/foo/bar\nIn current fix x-forwarded-prefix: /myprefix/foo/bar, but the correct value is just /value\nAlso, it should be added only in case prefix is being stripped. \nbtw, thanks a lot for prompt answers!. @magiconair Checked. Works as expected! Thank you very much, looking forward for the release. . ",
    "akobyakov": "What if redirection would be based on a tag, something like:\nroute add very-https-service example.com/ http://10.0.0.1:12345/ tags \"forcehttps;code=301\" \nStill unclear though, what to do if multiple https listeners are defined. . ",
    "ctlajoie": "You're welcome. Was a pleasure working with you on the PR. \ud83d\udc4d . Happy to help! I hope the syntax for indicating a redirect is acceptable. It's not even close to what was discussed in #87 but it enables you to redirect to any given URL, which I find valuable.\nAlso what's up with travis? The failure doesn't seem legit.. Ok I'll see what I can get done on this tonight. Understood regarding tests.. will add those too.\n\nI assume you need to make the changes for matching the ports in order to do the http -> https redirect. \n\nCorrect. This makes it possible to define a route explicitly on http but not https (and vice versa), which was required for this feature. \nMy understanding is that the proto= option tells fabio what protocol to use for comms with upstream. I wouldn't recommend using it to define route-matching behavior.. I implemented your suggestions, minus the proto=http one.\nIn writing the integration test I discovered some issues that I'm not comfortable resolving without feedback. The integration test fails... have a look at it and I think you'll see the problem. It's copying the Path part of the request URL over to the target. In many cases this will be desired, but not always. I am considering adding another opt like absolute=true to indicate the target URL shouldn't be tampered with. Thoughts?. I made the requested changes but we're not done yet unfortunately. As I mentioned in an earlier comment the integration test fails due to the way the targetURL is constructed in http_proxy.go. With \nroute add mock  /foo   http://a.com/abc   opts \"redirect=301\", we get redirected to http://a.com/foo. So I was considering implementing some way to indicate you want the target URL to be absolute, in case this behavior is not desired. Can you comment on that?. I'm not so sure we always want it to be absolute. Suppose you have these routes\nroute add svc example.com:80 / https://example.com redirect=302\nroute add svc example.com:443 / 1.2.3.4:5678\nIf you hit http://example.com/some/deep/link you get redirected to https://example.com/some/deep/link. This seems very useful, but I can also see how it might not be desired, depending on the purpose of your redirect route.. Don't know.. I'll do a bit of research.. I really like the pseudo-variable idea. Pushed changes. Have a close look at http_proxy because I rearranged some code in there since I am no longer using the targetURL var as the redirect target. . Sounds good. I'm actually using it right now in a semi-production environment (accessed by people working in my office) so it's getting some real-world testing.. The only thing I can think of that this implementation does not cover would be complex URL rewriting based on regexps (like mod_rewrite). I think it's fair to say that's out of scope.\nDo you want me to squash everything down to 1 commit before this gets merged? Are there any other changes you want me to make?. @magiconair You might want to know that there was/is a problem with current versions of nomad/consul where if you have :// in a service tag, nomad is unable to deregister that service. See https://github.com/hashicorp/nomad/issues/3620\nShould be fixed in the next nomad release.\n. @magiconair I also have an excessive number of these in my logs. Every few seconds or so, and sometimes several in rapid succession. None of my services are flapping. I think maybe the consul state changes every time a check is performed. I have many service checks that are performed every 10 seconds. I agree with OP, I think DEBUG level would be more appropriate for these messages.. I think you would want to use a different prefix for the raw tags.\nWhat is the real impetus for adding this capability? Are you intending for there to be new extensions to the route syntax that can't be expressed using the \"short\" urlprefix- style tags?. \nYou can think about the difference between the two as being declarative vs imperative.\nIf I add a tag urlprefix-example.com/ to a service, I am declaring that I want requests for example.com to be routed to this service.\nA tag like fabio route add $service / http://$addr/ is imperative. You are issuing a command to fabio, as opposed to just declaring \"route requests here\".\nAllowing route commands like that in tags also implies other things are also possible to do with the tag, such as fabio route del someothersvc. Doing so would be stupid, but you know someone will try it.\nIMO it makes more sense to use a declarative syntax for service tags.. I am probably biased because I have never needed to manually add routes using the route add syntax. I consider the urlprefix- tags to be the \"normal\" method of adding routes.. Sure I can do that syntax for the consul service tags.. I made this change because I thought it was a bug. VS Code was telling me that dynamic is an int. But then I ran some tests under the debugger and it is definitely not an int. Now I know I can't trust VS Code to determine var types correctly.\n\n\n. Yup, good call.. Ok, this makes sense. My bad.. Ideally these kind of errors should prevent the route from being added, but that would take some refactoring.. ",
    "chy168": "Thanks for your replay. I also try to find the document describe about this behavior but in vain. I would like to help on this topic, please let me know if any clue we can dig into or do any experiment.\n. Hi @magiconair,\nSorry for late reply, I've tested this scenario on my end via the latest release 1.1.2.\nThanks for your time and fabio rocks!!\n. +1 for this idea.\nIn my case, I might separate HTTP and HTTPS for different backend, for example:\n- HTTP for nginx\n- HTTPS for API server\nFor API server, i don't want it exposed via HTTP.\nin mean time to workaround this, i create TWO fabio containers and use different prefix\nregistry.consul.tagprefix = urlprefix- to serve nginx and API server independently.\n. ",
    "codekoala": "I could definitely use the option to select Address over ServiceAddress. I'm trying to use nomad to run some services, and it currently doesn't seem to expose a way to specify ServiceAddress (because nomad decides where to run each service). I'd be happy to learn that I'm mistaken if that's the case.\nAnyway, for my use case, Address is the server's private IP address and ServiceAddress is the server's public IP address. In order to save on bandwidth charges and improve response times, I would like to use the Address value. Also, almost all ports must be locked down against all public traffic (with exceptions for 22, 80, 443, etc).\nHere's an example of what I'm seeing in consul's service catalog:\njson\n[\n{\n  \"ID\": \"11b53a97-489e-1d5f-8af3-91ffc29d903e\",\n  \"Node\": \"node-01.domain.com\",\n  \"Address\": \"192.168.0.1\",\n  \"Datacenter\": \"us-west\",\n  \"TaggedAddresses\": {\n    \"lan\": \"192.168.0.1\",\n    \"wan\": \"192.168.0.1\"\n  },\n  \"NodeMeta\": {},\n  \"ServiceID\": \"_nomad-executor-e0a22377-8362-83d8-40e5-ca12c9103150-server-something-urlprefix-something.domain.com/\",\n  \"ServiceName\": \"nomad-ui\",\n  \"ServiceTags\": [\n    \"prom\",\n    \"urlprefix-something.domain.com/\"\n  ],\n  \"ServiceAddress\": \"172.104.a.b\",\n  \"ServicePort\": 3000,\n  \"ServiceEnableTagOverride\": false,\n  \"CreateIndex\": 19297,\n  \"ModifyIndex\": 19297\n},\n{\n  \"ID\": \"b6aece04-f1d0-3811-63d3-2392102b3905\",\n  \"Node\": \"node-02.domain.com\",\n  \"Address\": \"192.168.0.2\",\n  \"Datacenter\": \"us-west\",\n  \"TaggedAddresses\": {\n    \"lan\": \"192.168.0.2\",\n    \"wan\": \"192.168.0.2\"\n  },\n  \"NodeMeta\": {},\n  \"ServiceID\": \"_nomad-executor-1ddb350c-7656-e502-50b8-b48f455b645a-server-something-urlprefix-something.domain.com/\",\n  \"ServiceName\": \"nomad-ui\",\n  \"ServiceTags\": [\n    \"prom\",\n    \"urlprefix-something.domain.com/\"\n  ],\n  \"ServiceAddress\": \"172.104.y.z\",\n  \"ServicePort\": 3000,\n  \"ServiceEnableTagOverride\": false,\n  \"CreateIndex\": 19296,\n  \"ModifyIndex\": 19296\n}\n]. ",
    "nartamonov": "@magiconair, thanks! :)\n. ",
    "ksoftirqd": "Would it make any sense to strip away fabio's own port entirely from Host header for http services?\nIt seems like it's hard to run fabio as a service in e.g. mesos/marathon and use a host+url based routing.. If fabio gets assigned a dynamic port on which it is available for other services, services would need to connect to http://host:/ and routing and tags in consul would need to have that port as well.\nE.g. even for default port 9999, every rule has to have :9999 in the end if one wants to use host based routing.. What i tried to say is that fabio's own port should not probably be taken into account in routing rules.\nJust to illustrate my point, here is an analogy with nginx:\nserver {\n    listen 1234;\n    server_name qqq;\n    return 200 \"qqq\\n\";\n}\nserver {\n    listen 1234;\n    server_name zzz;\n    return 200 \"zzz\\n\";\n}\nNo matter what port is used by nginx to listen on, second server stanza will be used for all requests where Host header contains \"zzz\". Regardless of port portion:\n$ curl -H 'Host: zzz' localhost:1234\nzzz\n$ curl -H 'Host: zzz:1234' localhost:1234\nzzz\n$ curl -H 'Host: zzz:8888' localhost:1234\nzzz\nAs of now, if we want to use host based routing in fabio, we have to append fabio's port to all services' tags (prefix-url-myhostname:<fabios_port>/).\nNow if we run fabio in e.g. mesos/marathon and it is accessible on randomly assigned port 12345, all routing rules need to have that port.\nIf fabio instance gets restarted -- it'll become available under a new port and all services' rules have to be adjusted. \n. Yes, we want to use it for BE-BE routing/load balancing, only because service discovery by itself doesn't do a very good job of spreading a load between available instances.\nIf you run fabio on port 80/443 it works as expected (change 23a1aca). It would be really great if fabio could be used in the same way on any port (without a need to append fabio's current non standard port to any of the routing rules).\nMy question is why not just strip away a port portion from every request's hostname before looking it up in the routing table? :-)\nThanks. ",
    "jamesrwu": "I think the issue is similar with http clients adding the port to the host header when connecting via a non-standard port:\ncurl --verbose 'http://blah/' sets the host header in the request to \"Host: blah\"\ncurl --verbose 'http://blah:80/' sets the host header to \"Host: blah\"\nbut\ncurl --verbose 'http://blah:1234/' sets the host header to \"Host: blah:1234\"\nIMHO, I am ok with the way fabio treats this, as it is explicit in its urlprefix host registration. However, I can see the usefulness of adding a config option to have fabio match the host header while ignoring the port. IE: for a service with tag urlprefix-blah/, fabio would route a http request with Host: blah or Host: blah:1234 to that service.. +1 to not keeping state across a cluster of fabio instances. I don't think it is necessary and is more of a hard to implement \"nice to have\".. I am not even sure if it makes sense to have least connections and weighted routes. They seem to be incompatible concepts by nature. \nAlthough the approach above you suggested might work, I fail to imagine what use cases one might run into where they would need both least connections and weighted routes on the same service. From my POV, I would be ok with treating them as incompatible and exclusive settings.. I see, I misunderstood weighted routing for load balancing weights. This does make sense.... Awesome, thanks @magiconair, we'll let test it and let you know how it goes.. Understood. ",
    "jhorwit2": "Not a known bug i was mainly curious! Thanks!\n. ",
    "skyrocknroll": "@magiconair Thanks :) \n. ",
    "stevenscg": "Fantastic work on the project @magiconair!\nI wanted to see if there were any new considerations for this request (routing based on ports) after HashiConf EU 2016.\nKelsey mentioned running Fabio as a system service on all nodes of a Nomad cluster to stabilize the ports registered with upstream load balancers (ELB, etc).\nHost and/or path-based routing makes total sense when the requested host names are stable.\nHowever, some of our edge applications use the requested subdomain for multi-tenancy purposes (possibly via CNAME in the future), so port-based routing into a particular application seems like the safest way to go.\nRight now, we run EC2 instances behind ELBs for edge applications on static ports (8080 and up) and there is an ELB for each application.\nThe rate of change on the applications and their ports is extremely low, so I was looking at consul-template for fabio.properties listeners or updating the nomad job whenever a change is needed.\nI'll detail a scenerio I tried below in case I misunderstood something.\n\nA web application needs to respond to *.example.com where * may be one of thousands of possible customer subdomains (too many to keep in consul, etc).\nAn ELB for this application is listening on port 80 and sending all traffic to registered EC2 instances on 8085 where Fabio is listening:\nproxy.addr = :8085 # <= port per edge application (8080 and up), comma-separated\nThe application is running on port 30000 on one of the instances and would register with consul with the following:\n{\n  \"ID\": \"web\",\n  \"Name\": \"web\",\n  \"Tags\": [\n    \"urlprefix-:8085/\"\n  ],\n  \"Address\": \"127.0.0.1\",\n  \"Port\": 30000,\n  \"Check\": {\n    \"HTTP\": \"http://127.0.0.1:30000/health_check\",\n    \"Interval\": \"10s\"\n  }\n}\nThe fabio UI shows host = :8085 and path = / as expected.\nHowever, routing doesn't work as I think we are discussing in this issue:\n2016/07/18 20:56:51 [WARN] No route for localhost:8085/\n. The ELB makes the request to port 8085 on the instance(s). So, I believe that Fabio would see the request as coming in on port 8085 and be able to use it in decision making.\nI picked 30000 just as an example of a random unprivileged port that Nomad or raw docker might select for the app.\n- Chris\n\nOn Jul 18, 2016, at 4:32 PM, Frank Schr\u00f6der notifications@github.com wrote:\nAlso, I'm starting to think that a different matcher implementation (with some small refactoring) might be a solution to this instead of waiting for the full tag prefix refactor. The lookup function gets the full request and has the full routing table available so any two pieces which allow a matcher to link request and target should work. Right now I'm linking incoming request uri to service uri (or prefix). But one could also build a matcher that matches destination port to some advertised host:port. However, the part that I don't get in the described scenario is how the decision is made that xyz.example.com should end up on that instance running on port 30000. There is nothing that links the domain to that port (or 8085) unless the client is requesting the resource on that port instead of 80.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Yes, exactly!\n\nI haven't worked through it yet, but should be able to do rolling updates with nomad or Ansible on the rare occasions when the apps or listener ports need to change. TBH, we have always assigned a 8000-series port for internal/dev use when we create a new service and haven't had to make any changes to those edge applications.\nHappy to test and/or write up more examples with/without Fabio in the architecture if that helps.\n- Chris\n\nOn Jul 18, 2016, at 5:35 PM, Frank Schr\u00f6der notifications@github.com wrote:\n@stevenscg So the ELB has the domain -> port mapping and fabio acts as a second level dynamic router, right? If that's the case then this should be doable at least in step one without dynamic listeners. This assumes that you have either automated the listener configuration and handle fabio restarts or that you don't add new ports that often.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @johnypony3 I was just back checking on this as well. We are moving all of our containers away from root user, so I will probably build my own on alpine and a non-root user.. Thanks @magiconair!\n\nThe current design certainly makes sense and I like the suggestion of regenerating the routing table with a script in consul. Will try that.\nUsing multiple consul kv nodes under fabio/config is really interesting and has solid semantics for those of us that work with Consul regularly. I don't see the 512KB as a limiting factor right now.\nHowever, having to watch/manage the dst (http://host:port) is probably the bigger problem for my use case. I think of this more as a \"manual route\" or a \"static route\" vs an \"override\" and a way to provide the same routes as the urlprefix- tags we use when registering consul services.\nIt sounds like this is not supported today because the dst needs to be a URL and I am trying to use the service name (for dynamic IP:PORT lookup from consul):\nroute add app foo.example.com/ app\nWould this be possible?:\nroute add app foo.example.com/\nIt says send requests to foo.example.com/ to the service named app in consul.\n. @magiconair Yup, I think so! I was just trying to replicate what we do in consul service tags with urlprefix to wire up routes.. @magiconair https://github.com/fabiolb/fabio/pull/417 looks good to get around the consul 512KB limitation.\nOption 2 above (\"Services are defined separately as part of the routing table\") looks interesting.\nThis would allow a service to be targeted for routing even if it was not in the consul service catalog, right?\nIf svc-a is already registered in consul, could it be defined like this?\nservice svc-a http://${ADDR}:${PORT} proto=http\nor\nservice svc-a :${PORT} proto=tcp\nWould \"tags\" mentioned as part of route add be included as part of the service definition then?\nservice svc-a http://${ADDR}:${PORT} proto=http tags=\"t1\"\nIs some kind of a marker needed for the parser to target?\nservice svc-a consul:http://${ADDR}:${PORT} proto=http\nor\nservice svc-a consul::${PORT} proto=tcp\nOption 1 above (registry/consul) seems really interesting even in light of tighter coupling to consul. This could be a competitive and usability advantage (vs something like nginx+, etc.) if I understand what you are proposing.\nStepping back for just a minute...\nWe have access to really good tooling (git2consul, etc) these days for using consul KV as a configuration store backed by git repositories and have already worked out handling of multiple-regions and multiple environments.\nIf Fabio gave us the ability to define all routes in consul and also use consul services by name, I would try to use it in lieu of the urlprefix tags.\nHere is a real-world example of an api service block in a nomad job that we use within 2 different regions and 2 environments:\nhcl\nservice {\n    name = \"api\"\n    port = \"http\"\n    tags = [\n        \"http\",\n        \"urlprefix-api.example.com/\",\n        \"urlprefix-api.us1.example.com/\",\n        \"urlprefix-api.eu1.example.com/\",\n        \"urlprefix-api.example-dev.com/\",\n        \"urlprefix-api.us1.example-dev.com/\",\n    ]\n}\nI'm not sure how other users are handling this. Maybe they are templating the job file on submit to nomad, or outside of nomad, have some business logic that provides the appropriate routes as tags for the region and environment. I'm just registering everything for convenience, but it adds weight to the routing table and feels a bit clunky. I also might want the developer of the service to not have to worry about the routing if another team is handling it.\nAs we discussed earlier in this issue, the urlprefix routes shown are just the static ones that are always present. Subdomain and CNAME routes can be added, changed, or removed for one of our applications dynamically and that's where idea of having Fabio route to healthy members of a service by service name comes in.\nIdeally, these route commands (all stored in fabio/config/api or similar) could replace the urlprefix tags from the example and handle the subdomain/CNAME routes:\nroute add svc-a api.example.com/ tags \"http\"\nroute add svc-a api.us1.example.com/ tags \"http\"\nroute add svc-a subdomain.example.com/ tags \"http\"\nThese route commands omit the <dst> parameter, which is currently required by the parser.\nAs I understand it, the remaining piece is how to use consul service entries when <dst> is not provided, or as you noted, allow some kind of templating that indicates the service host and port should be obtained from consul.\nI prefer the lack of a <dst> parameter to indicate a dynamic lookup, but the templating version could look like:\nroute add svc-a api.example.com/ http://${ADDR}:${PORT} tags \"http\"\nroute add svc-a api.us1.example.com/ http://${ADDR}:${PORT} tags \"http\"\nroute add svc-a subdomain.example.com/ http://${ADDR}:${PORT} tags \"http\". Hey @magiconair. Just checking in on the project and found this issue.\nI can think of a few features that would be extremely helpful for my use cases. What's the best way to get in touch with you? Gitter PM?\nAlso, how can we can help get the word out to the community for this? I mentioned it in the nomad gitter room a few minutes ago.. ",
    "cjdxlgb": "@magiconair \nmy english is so poor, and i need some help from you, can you help me?\nI regist a service in consul like this:\ncurl -X PUT -d '{\"ID\": \"redis31\",\"Name\": \"redis31\",\"Tags\": [\"primary31\",\"v31\"],\"Address\": \"172.168.11.16\",\"Port\": 9190,\"EnableTagOverride\": false, \"Check\":{\"id\": \"Health31\",\"name\": \"Health31\",\"http\": \"http://172.168.11.16:9190/website/login\",\"interval\": \"5s\",\"timeout\": \"2s\"}}' http://127.0.0.1:8500/v1/agent/service/register\ncurl localhost:8500/v1/health/state/any?pretty\n{\n        \"Node\": \"localhost.localdomain\",\n        \"CheckID\": \"service:redis31\",\n        \"Name\": \"Service 'redis31' check\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"HTTP GET http://172.168.11.16:9190/website/login: 200 OK \",\n        \"ServiceID\": \"redis31\",\n        \"ServiceName\": \"redis31\",\n        \"CreateIndex\": 13,\n        \"ModifyIndex\": 14\n}\nand i start fabio by default:\n2017/01/10 19:23:05 [INFO] Version 1.3.5 starting\n2017/01/10 19:23:05 [INFO] Go runtime is go1.7.3\n2017/01/10 19:23:05 [INFO] Using routing strategy \"rnd\"\n2017/01/10 19:23:05 [INFO] Using routing matching \"prefix\"\n2017/01/10 19:23:05 [INFO] Setting GOGC=800\n2017/01/10 19:23:05 [INFO] Setting GOMAXPROCS=4\n2017/01/10 19:23:05 [INFO] Metrics disabled\n2017/01/10 19:23:05 [INFO] consul: Connecting to \"localhost:8500\" in datacenter \"dc1\"\n2017/01/10 19:23:05 [INFO] Admin server listening on \":9998\"\n2017/01/10 19:23:05 [INFO] consul: Using dynamic routes\n2017/01/10 19:23:05 [INFO] HTTP proxy listening on :9999\n2017/01/10 19:23:05 [INFO] consul: Using tag prefix \"urlprefix-\"\n2017/01/10 19:23:05 [INFO] consul: Watching KV path \"/fabio/config\"\n2017/01/10 19:23:05 [INFO] consul: Health changed to #16\n2017/01/10 19:23:05 [INFO] consul: Manual config changed to #1\n2017/01/10 19:23:05 [INFO] Updated config to\n2017/01/10 19:23:05 [INFO] consul: Registered fabio with id \"fabio-localhost.localdomain-9998\"\n2017/01/10 19:23:05 [INFO] consul: Registered fabio with address \"10.1.22.12\"\n2017/01/10 19:23:05 [INFO] consul: Registered fabio with tags \"\"\n2017/01/10 19:23:05 [INFO] consul: Registered fabio with health check to \"http://[10.1.22.12]:9998/health\"\n2017/01/10 19:23:05 [INFO] consul: Health changed to #18\n2017/01/10 19:23:58 [WARN] No route for 10.1.22.12:9999/urlprefix/website/login\n2017/01/10 19:24:02 [WARN] No route for 10.1.22.12:9999/urlprefix-/website/login\n2017/01/10 19:24:05 [WARN] No route for 10.1.22.12:9999/urlprefix-website/login\n2017/01/10 19:28:14 [INFO] consul: Health changed to #18\n2017/01/10 19:33:19 [INFO] consul: Health changed to #18\n2017/01/10 19:37:17 [WARN] No route for 10.1.22.12:9999/urlprefix-/website/login\n2017/01/10 19:38:35 [INFO] consul: Health changed to #18\n2017/01/10 19:41:28 [WARN] No route for 10.1.22.12:9999/redis31/website/login\n2017/01/10 19:41:42 [WARN] No route for 10.1.22.12:9999/urlprefix-/website/login\n2017/01/10 19:41:43 [WARN] No route for 10.1.22.12:9999/urlprefix-redis31/website/login\n2017/01/10 19:43:35 [INFO] consul: Health changed to #18\nand now I do not how to access my service by fibio proxy, the origin service url is: http://172.168.11.16:9190/website/login\nI read the doc of fibio github, but i can not understand what the means, what is urlprefix? how to add to my url.\nthank you very much!  . +1. @magiconair \nit works, thank very much, I spend about 8 hours on it, so hard...\nby the way, is fabio enable to do session sticky like nginx?\nthank you, best wish from china. . @magiconair \nthank you for reply.\nno sticky session support, \nso is there any other way to keep session status, if I use fabio to load balance for a stateful services.. thank you so much!\nlast 2 question:\n1, if my target services access by different url like this\uff1a\n/website/test\n/website2/test\n/website/website2/test\ni want to use fabio proxy this 3 service, how can i config the tags to register to consul, do it is support?\n2, i read fabio.properties, there is no config like the weigth in nginx, i want to proxy for each service with different wight, do it is support?\nwhere cant i find more fabio document besides this github site.\n. @magiconair as last reply.. @magiconair \nThank you for your patience.\n\nSorry, I reply you by google translate, I think I did not express what I meant.\nMy target service in 3 different host:port and access by different url prefix as bellow, they support same service and just access by different url prefix: /website/test, /website2/test, /website/website2/test\n\nNow I want to use fabio proxy for this 3 service, and I want to use same url access this 3 service through fabio. for example: 10.1.21.22:9999/website/test, fabio will load banlance to 3 target service.\nHow can I do, register 3 service with different serviceId or register 1 service with 3 tags, if I register 1 service with 3 tags, how can I config 3 different Health Check http url.\nI hope you understand what I mean.\n\nI read the wiki, what the mean is add the config to fabio.properties like this?\nroute weight service-b www.kjca.dev/auth/ weight 0.05 tags \"version-15,dc-fra\"\n\n. @magiconair \nI try like this:\n```\ncurl -X PUT -d '{\"ID\": \"redis30\",\"Name\": \"redis30\",\"Tags\": [\"urlprefix-/website/\",\"urlprefix-/website2/\"],\"Address\": \"172.168.11.16\",\"Port\": 9190,\"EnableTagOverride\": false, \"Check\":{\"id\": \"Health30\",\"name\": \"Health30\",\"http\": \"http://172.168.11.16:9190/website/test\",\"interval\": \"5s\",\"timeout\": \"2s\"}}' http://10.1.22.12:8500/v1/agent/service/register\ncurl -X PUT -d '{\"ID\": \"redis31\",\"Name\": \"redis31\",\"Tags\": [\"urlprefix-/website/\",\"urlprefix-/website2/\"],\"Address\": \"172.168.11.16\",\"Port\": 9290,\"EnableTagOverride\": false, \"Check\":{\"id\": \"Health31\",\"name\": \"Health31\",\"http\": \"http://172.168.11.16:9290/website2/test\",\"interval\": \"5s\",\"timeout\": \"2s\"}}' http://10.1.22.12:8500/v1/agent/service/register\n2017/01/12 11:55:51 [INFO] Version 1.3.5 starting\n2017/01/12 11:55:51 [INFO] Go runtime is go1.7.3\n2017/01/12 11:55:51 [INFO] Using routing strategy \"rnd\"\n2017/01/12 11:55:51 [INFO] Using routing matching \"prefix\"\n2017/01/12 11:55:51 [INFO] Setting GOGC=800\n2017/01/12 11:55:51 [INFO] Setting GOMAXPROCS=4\n2017/01/12 11:55:51 [INFO] Metrics disabled\n2017/01/12 11:55:51 [INFO] consul: Connecting to \"10.1.22.12:8500\" in datacenter \"dc1\"\n2017/01/12 11:55:51 [INFO] Admin server listening on \":9998\"\n2017/01/12 11:55:51 [INFO] HTTP proxy listening on :9999\n2017/01/12 11:55:51 [INFO] consul: Using dynamic routes\n2017/01/12 11:55:51 [INFO] consul: Using tag prefix \"urlprefix-\"\n2017/01/12 11:55:51 [INFO] consul: Watching KV path \"/fabio/config\"\n2017/01/12 11:55:51 [INFO] consul: Health changed to #26\n2017/01/12 11:55:51 [INFO] consul: Manual config changed to #1\n2017/01/12 11:55:51 [INFO] Updated config to\n2017/01/12 11:55:51 [INFO] Updated config to\nroute add redis31 /website2/ http://172.168.11.16:9290/ tags \"urlprefix-/website/,urlprefix-/website2/\"\nroute add redis30 /website2/ http://172.168.11.16:9190/ tags \"urlprefix-/website/,urlprefix-/website2/\"\nroute add redis31 /website/ http://172.168.11.16:9290/ tags \"urlprefix-/website/,urlprefix-/website2/\"\nroute add redis30 /website/ http://172.168.11.16:9190/ tags \"urlprefix-/website/,urlprefix-/website2/\"\n2017/01/12 11:55:51 [INFO] consul: Registered fabio with id \"fabio-testserver-9998\"\n2017/01/12 11:55:51 [INFO] consul: Registered fabio with address \"10.1.22.12\"\n2017/01/12 11:55:51 [INFO] consul: Registered fabio with tags \"\"\n2017/01/12 11:55:51 [INFO] consul: Registered fabio with health check to \"http://[10.1.22.12]:9998/health\"\n2017/01/12 11:55:51 [INFO] consul: Health changed to #32\n```\nAnd I access http://10.1.22.12:9999/website2/test, have 50% return http 404, I think it is route to wrong service.\n. @magiconair \nok, thanks.\nI know what your means, my 3 service only support one of the 3 URLs, so if fabio does not support path rewriting like nginx, it does not support load balanceing for them. fabio only load balance for the service access by same url prefix. right?\nYou forgot to reply to the question 2 about load wight:\nI read the wiki, what the mean is add the config to fabio.properties like this?\nroute weight service-b www.kjca.dev/auth/ weight 0.05 tags \"version-15,dc-fra\".\n. ",
    "sriyer": "hi @magiconair is the feature to be able to create listeners dynamically available yet ? \nWe use fabio as an ingress router for our services that require tcp based ingress, its kind of implemented in a way that for every new service that needs tcp ingress, an instance of fabio is brought up, the tcp requests are routed via the fabio instance.\nThe fabio instances are brought up on special hosts that act as ingress router hosts, now we se quite a few containers running on these router hosts and each of them are bound to only a singe back end service in terms of the listener. \nIt would help if we could run only one instance of fabio and dynamically bring up listeners as new services are brought up.\nThere is also the concern of the cpu that the fabio instances are using, with the number of instances increase, the cpu shares although set to 0.1 cores, the usage seems to be at an average of 1.4% when idle ( no request activity). This seems to be overloading the host and the consul process running on it. Although this is a separate ticket that we would create for the cpu usage concern, it'd help if we could run a single instance and just bring up multiple listeners.\nCC: @samart\n. ",
    "robholland": "Yeah, I'll give that a test, cheers!\n. I didn't check the log output, but the tags are set properly :)\n. We got bitten by this again today. We use a wildcard DNS entry to point at fabio.service.consul and if consul goes down and comes back, that service entry will stop working even though consul and fabio are both up. I'll see if I can create a PR.\n. Actually we can use the patch in #99 as registrator will automatically maintain a fabio service for us.\n. It's because we restart it sometimes to adjust configuration.\n. This breaks origin checks on applications using rack-protection as it expects the Origin header to include the port number that the backend server is listening on, which is unlikely to ever be correct unless everything happens to be using port 80 internally as well.\n. Yep, that fixed it for us, cheers!\n. Frank, we're going to have to halt our fabio experiments as our priorities have changed. If you're keen on getting this merged and need some testing then I'll try and make some time for it in a few weeks.\nThanks for your efforts getting us this far, hopefully we'll be back :)\n. That was the driver I had in mind. As I've mentioned in the other issue we won't be able to do any testing for a bit, as riemann is perhaps a little obscure and it carries more deps than you'd like I'd suggest just drop it. When/if we come back to experimenting with fabio I'll pick it back up.\nThanks for all your help.\n. ",
    "mitchellh": "Ah fair enough. I'm happy enough with the workaround. Glob matching to the host would be great but I don't need it (I can statically set the port).\nWell, the issue is actually that I need to run a pure SSL => TCP listener on the ELB to allow websocket connections through, since HTTP on ELB won't allow it. However, I want to run the HTTP endpoints for 80/443 for normal web traffic so that I can get forwarded headers.\nSO, the actual solution here would be if fabio supported the HAProxy proxy protocol that ELB also uses, then I can just run everything in TCP mode and avoid all of this. :) \n. hey @magiconair, thanks for the quick response!\nI can't terminate SSL on Fabio because I'm using Amazon Certificate Manager which only allows certs to be tied to a few things (ELBs, Cloudfront, probably some others). They don't give you the certs directly. \nThe proxy protocol is what the ELB uses to send the X-Forwarded-* equivalent information on TCP connections. See here: http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/enable-proxy-protocol.html\n. Hah yeah setting up/enabling PROXY protocol is a PITA. Use Terraform ;) (if you weren't already).\nThat looks great! Would it be possible to actually inject the X-Forwarded-* headers from the PROXY protocol? I'm asking for a lot more here but that'd be great. But this is already really wonderful. Thanks!\n. Looks awesome. I'll give it a try tonight or sometime (using Fabio for a for-fun project). Is the Docker container automatically updated? Using that as wel.\n. Thanks will let you know tonight or tmrw night!\n. ",
    "EvertMDC": "Ok thank you for the explanation.\n. ",
    "leolux": "\nI could hash the source ip or a cookie, modulo it by number of instances and send it to the resulting instances.\n\nI was searching for source ip hashing in the documentation because I need this feature :)\nThis would be a good alternative for those clients which need to stick with one server.. ",
    "shantanugadgil": "Hi @magiconair \nI stumbled upon this accidentally! This feature is great. I too have a use case for this.\nI guess this hasn't made it to master?. My use case is:\n* non HTTPS services; launched using Nomad and registered into Consul.\nI wanted to use Fabio to discover a named service within Consul; say \"myservice\" and then roundrobin between the registered backends (IP:PORT) for that single service.\n*** The backend port could vary as I am using Docker with Nomad's ephemeral port logic.\nThanks and Regards,\nShantanu. @magiconair yes, that's correct, \"myservice\" would be custom app.. The Consul could have multiple services registered, right?\nIf multiple services register the same 'tag', I think wrong backends could get pick up.\nWhere I am coming from is:\nhttp://gobetween.io/documentation.html#Discovery\n(ref the 'consul' section)\n* I hope I am missing something obvious in the Fabio config ?!\nRegards,\nShantanu. ... and I am back ...\nI'll try to elaborate on my new use case. (pretty similar to the first one, but L7 this time).\nI have a Nomad + Consul cluster used by dev/qa. This cluster is used to run \"services\" pertaining to various versions of an app.\n(Lets call them appv1 and appv2)\nEach team run their own version of the app outside the cluster. (minor implementation detail, not relevant to problem at hand)\nServices needed by the apps run on this cluster as Docker containers; potentially multiple on a single machine.\nThe way the app talks to the \"serivces\" is via an \"alb\" (Fabio)\nWithin the cluster there are two types of machines; \"alb\" and \"worker\".\nEach instance of the app will get its own \"alb\" instance (running Fabio) within the cluster.\nThe \"worker\" machines host services corresponding to multiple apps.\nThe actual services corresponding to each app instance could be run anywhere in the cluster (they are Docker containers)\nLets assume there are two albs; alb1 and alb2 (for the two versions of the same appv1 and appv2)\nEach \"app\" has two services:\n    appv1foo (/foo), appv1bar (/bar)\n    appv2foo (/foo), appv2bar (/bar)\nMy problem start here; which was and is my question:\nHow would alb1 know that the \"/foo\" traffic it receives, has to be routed ONLY to Docker containers of \"appv1foo\" and NOT to containers of \"appv2foo\"\nSo, if the individual services were \"under\" a specific name, Fabio could be then configured to forward only to services of a particular name.\nThus if \"appv1foo\" and \"appv1bar\" were under a Consul service named \"appv1svc\", then I could configured \"alb1\" to forward traffic only to services under \"appv1svc\".\nThis would prevent traffic pertaining to \"appv1\" going to backends of \"appv2\"\nBTW, my original need for the L4 (TCP+SNI) running quite well using Gobetween.\nGobetween does have this additional \"service name\" filter.\nHope this clarifies my use-case.\nRegards,\nShantanu. @leprechau \nI am experimenting with the L7 thing again, and will report back if things work as I expect/want them to.\nThough, I am still confused by a few things ...\nYou do mean that there will be multiple \"Fabio\" instances within the same Consul cluster, right? (diverting traffic to only to the relevant services of appv1 and appv2 from the example above)\nAlso, I have always thought that the urlprefix tag is a backend tag thing and nothing to do with the Fabio instance itself.\nAnyway, I launch multiple versions of the services and see how things fare.\nRegards,\nShantanu\n. Beautiful .... This should work for me.\nJust happened to stumble upon another older similar issue:\nhttps://github.com/fabiolb/fabio/issues/551\nCross posting just for reference.. It would be good if the backend could decide if it wants to be enable PROXY or not.\nI dunno if thats doable (single listener on Fabio sends PROXY to one backend but not PROXY to another backend). @magiconair any thoughts?. @leprechau\nThanks for looking into this.\nI understand that the servername field need/should not be case sensitive, but my use case is that of an existing application which already has a sizable install base.\nThe case sensitive servername field is hard coded in the client software and we cannot do anything about it immediately, and so this workaround fix.. @leprechau my Go skills are pretty basic and I had suggested this change as it worked for me.\n(I have tested the binary for my use case)\nI am perfectly fine with any other changes as well.\nShould I resubmit with the other changes?. hehe @leprechau thank you !!! \ud83d\udc4d . I stumbled upon this, and I wonder if it would solve my use case?\n(Looking at the diff it seems so, based on the explanation, atleast)\nMy use case it to provide an \"https + password\" frontend to the Consul/Nomad GUI via Fabio.\nCurrently, I am making do with HAProxy http basic auth on a separate port.\nEagerly looking forward to this getting merged. :clap:  :clap: \n. Same question, different reason :)\nhttps://github.com/fabiolb/fabio/issues/592\nI too am waiting for the new release! \ud83d\ude04 . Hi, what happened here? Until Consul 1.4.4 is out, folks should stick with 1.4.2, right? And not deploy Consul 1.4.3?. Hi, just a hunch but wildcard certs I have seen  are usually *.domain.tld and not for *.*.*.domain.tld\nWould it possible to verify the cert and key first using a tls web server like \nhttps://github.com/udhos/gowebhello. ",
    "rumstattd": "so, you're suggesting to narrow the scope of whats being routed by tagging containers with 'two' URL's, one being the real URL, and the other to aid in version identification.  Then use the proxy in front to sort out the header parsing and route to the appropriate fabio instance/port?  \nIf I'm understanding you correctly, we could use the proxy in front to sort the versioning, and container tagging to group the containers by versions within fabio, but the URL would remain the same between the proxies (I believe a re-write is a no-go with the way our services are written/structured).  \nSomething like this could work if we could set fabio to listen for /this-url & /this-version on a specific port, and /this-url & /that-version on a different port.   Is that possible?\n. Thanks, we'll try to make it work.  I'm thinking that we'll need to make an array of values for register.consul.tagprefix   like:\nservice x, y, z\nversion v1, v2, v3\nenvironment q1, q2, q3\nso register.consul.tagprefix=urlprefix_x_v1_q1-/pathtox\nand register.consul.tagprefix=urlprefix_x_v2_q1-/pathtox  (on different port)\nand so on....   three versions on each service, in 8 environments.  \nI think we can cover it with 3x8 ports.  It sounds a little messy, but I think I can use the K/V store to set the URL Prefix/Port combinations to link the front proxy (parsing headers) to the back proxy (matching URL's to services.\n. ",
    "simonsparks": "@magiconair Yes this did work for me; thanks for your response.\np.s. Really pleased with Fabio's capability on our platform, great work!\n. @magiconair Yes, that's a fair comment. I agree it can't be assumed that all client certs would require this conversion.\nWould such a tool be able to parse the pem content, modify the structure as appropriate, and serialize out to a modified pem file which could be used in Fabio? Not being too familiar with go programming and it's crypto package, I don't know if this is how it would work.\n. I'm building Amazon AMIs with Packer.\nFabio is currently installed from a script which runs: go get github.com/eBay/fabio\np.s. really appreciate your support!\n. I can log in to the deployed servers and manually update fabio for the time being.\n. That would be good. I'd be happy to test.\n. @magiconair I can confirm that these latest changes, with the configurable option, do work for our scenario.\n. That sounds reasonable @magiconair. Thanks again for your support with this issue.\n. Looks like this is due to the domain name resolution failing when the Registry is created, and the same pattern applies to other metrics implementations:\n```go\nfunc gmStatsDRegistry(prefix, addr string, interval time.Duration) (Registry, error) {\n    if addr == \"\" {\n        return nil, errors.New(\" statsd addr missing\")\n    }\na, err := net.ResolveUDPAddr(\"udp\", addr)\nif err != nil {\n    return nil, fmt.Errorf(\" cannot connect to StatsD: %s\", err)\n}\n\nr := gm.NewRegistry()\ngo statsd.StatsD(r, interval, prefix, a)\nreturn &gmRegistry{r}, nil\n\n}\n```\nBecause we use Consul as the dns for our StatsD service, the address is unresolvable until the service has started and registered. Perhaps a configuration option to postpone / retry address resolution would be helpful. . ",
    "raben2": "Hi, \nI was trying to fetch the update because i have the same issue even though i do not run AWS. I issue client certs based on a self signed root cert (no CA)\nJul 04 08:24:22 Web-01 fabio[27551]: 2016/07/04 08:24:22 http: TLS handshake error from xxxxxx: tls: failed to verify client's certificate: x509: certificate signed by unknown authority (possibly because of \"x509: cannot verify signature: insecure algorithm MD5-RSA\" while trying to verify candidate authority certificate\nwhen i try to update fabio to 1.1.5 i run into this error: \nstderr\": \"# github.com/ebay/fabio\\n/usr/local/go/packages/src/github.com/ebay/fabio/listen.go:101: l.AWSApiGWCertCN undefined (type config.Listen has no field or method AWSApiGWCertCN)\"\n. Thanks that helped. \n. Behind a dns LoadBalancher i have two fabio and nginx proxies with a shared KV for the global configuration of routes.\nThis KV contains something like a global routing set for my services. \nIf i could set routes in a seperate KV on each proxy i could create something like a blue/green deployment by switching the route configuration to global. \n. i see this does the trick. Thanks a lot!\n. @magiconair i have to say you are doing a great job with this project. Thanks!\n. thank you, it purrs like a kitten now. +1. The Containers have to be within the same docker network. \nHere is a docker compose example using the host network https://github.com/raben2/0conf-routing-demo/blob/master/docker-compose.yaml\nalternatively you can create a own network for the container stack which allows you to communicate via container name and port.\n. yes right.. Ah ok i see.\nThe problem is the same if i leave out the caupgcn flag. \nimagine i want to accept all client certs from my self signed ca. What can i do?. As always it works like a charm. Thank you!. Sure great idea, i will look into that. \nAm i wrong or is the travis build failing because you have to reconfigure the dependencies? . Yeah sure, i will try to look at it asap. Right now i am doing a very important vacation ;) . Oh great thanks for adding this. I try to fix up the pr ASAP. Sorry i lost track of this project. I will close this.. ",
    "ptqa": "@magiconair I'm not sure how to determine which gorouting hangs up, so here is an output\nhttps://gist.github.com/ptqa/dd1ee29d3c67d966a2f5b4de5aa50b04\n. It's just a short for 127.0.0.1. But sure:\n```\nroot@akuma:~# curl -v  http://127.0.0.1:9999/\n Hostname was NOT found in DNS cache\n   Trying 127.0.0.1...\n* Connected to 127.0.0.1 (127.0.0.1) port 9999 (#0)\n\nGET / HTTP/1.1\nUser-Agent: curl/7.35.0\nHost: 127.0.0.1:9999\nAccept: /\n^C\n```\n\nStill hangs up. Logs https://gist.github.com/ptqa/733ddf555506b37b6408a90da24f921e\nIt's not a really an issue for me, I can use 1.6 compiler, just wanted to let you know.\n. Yeah, I've added this for profiling. Sure you can add this to README.\n. @aerickson current requirement for fabio is go 1.7 or higher. ",
    "aerickson": "Just experienced hangs with Fabio 1.3.5 and Go 1.5.1. \nWas using https://galaxy.ansible.com/lobsterdore/fabio/ that defaults to 1.5.1. 1.7.4 works fine.. @magiconair Thanks, that's perfect. :). ",
    "boyvinall": "Hi @magiconair, sorry for going quiet, got swamped with some things.  A really simplistic example would be something like this:\nAccess-Control-Allow-Origin: *\nAccess-Control-Allow-Methods: *\nAccess-Control-Allow-Headers: Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization\n(I should say, I'm not hugely familiar with CORS, I just needed to add support for it to something that also fabio - and it seemed to me that this might be a nice feature-add.)  The * above might be better tied down somewhat to say exactly which origin domains and HTTP methods are permitted.  As I got a little further into this, I started to suspect that this feature request might actually be more generalised as adding in any desired response headers - indeed, the relevant bit of my (still development) nginx config is basically this:\n```\nserver {\n    listen :80 default_server;\n    listen :443 default_server ssl;\n    ssl_certificate        /path/to/cert-chain.pem;\n    ssl_certificate_key    /path/to/privkey.pem;\n    server_name _;\n    add_header 'Access-Control-Allow-Origin' '' always;\n    add_header 'Access-Control-Allow-Methods' '' always;\n    add_header 'Access-Control-Allow-Headers' 'Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';\nlocation / {\n    if ($request_method = 'OPTIONS') {\n        return 200;\n    }\n    proxy_pass \"http://127.0.0.1:8000\";\n}\n\n}\n```\nSo, it's just adding the headers and maybe forcing an empty HTTP 200 if you get an OPTIONS request.\n. I'm going to close this as I don't need it any more, and also I think the more generic header support mentioned in #168 should cope with it.. ",
    "far-blue": "I think the OPTIONS request really should be passed on to the backend server rather than just 200'ing. Services not written with CORS in mind tend not to handle the OPTIONS preflight but those written for CORS often make use of it for validation checks.\n. Each service in Consul is a single ip/port combination so this is really a 1-2-many mapping problem. This one ip/port could be routed differently (in theory) for http, https, wss and tcp. Clearly not all combinations of these make sense but you get the idea.\nSo I suggest 1 tag per protocol with each tag starting with the protocol and then providing the protocol-specific details. For http this would be the hostname/path to be routed, for tcp I assume it would just be the listening port, then followed by generic details such as weighting and logging etc.\nSo you'd have something like:\nfabio-http foo.com/wibble\nfabio-wss foo.com/api strip=/path\nfabio-tcp 6789 log=true\nyou could also support mixed protocols such as:\nfabio-http-https foo.com/wibble\nIf tags can't contain spaces then still best to avoid commas because of how Registrator works. Maybe use something like:\nfabio-http=foo.com/wibble;log=true\n. you could use fabio-proxy to refer to http & https & wss all at once.\n. Maybe it would help to understand why you are trying to create an orphan token?\nMy assumption was that I would be responsible for supplying a token and keeping it renewed and all Fabio would do was use the token it was given. If you prefer to generate short-lived tokens based on the supplied token on startup and then cycle them internally for your own reasons then I think that will still work. \nOrphaning the token would mean it wasn't revoked when the parent token was revoked which is probably not the behaviour you want - and, of course, orphaning can only be done by root.\nIn fact, the token I'm supplying is itself orphaned as I didn't want it related to my login token but I think that's something for the Vault admin to deal with rather than Fabio :)\n. To combat the problem of the token being visible you could make use of the new 'wrapping' capability in Vault. With this facility, the token supplied to Fabio would be a one-use token and fabio would query Vault using the unwrap endpoint to fetch the actual token to use. Other than this extra step the token will behave as normal.\nThe problem with this approach is that a new wrapped token would be needed every time Fabio is started meaning some form of automated script would prob. be needed to do it and that script would then need its own token in order to generate the wrapped token. I guess the advantage here is that this script would be short-lived and while you'd need to protect the token on disk you'd not see it in memory. After all, we are used to storing private cert keys on disk and if the token was stolen then it would only give access to the same private certs that could have been stolen from disk with the same level of access as the token - and the token can at least be revoked easily!\nThe other problem is one of renewing the token because this is another task prob. best automated and so, again, another script needing a token.\nI'd be interested in what @jeffrai suggests :)\n. I don't think fabio needs to create child tokens and I don't think it should create orphan tokens. Fabio's token is basically a password or an oauth type key and so it would make sense for an external system to create a token with specific permissions (i.e. policy) and hand it to fabio to use.\nFirstly, it makes sense for the token to expire if not used. But it looks like there is support for self-renewal of a token (assuming the token, when created, was set to allow renewal and the policy is configured to allow it as well).  See the '/auth/token/renew-self' POST endpoint in the docs (link at the end of the comment). I'm not sure how you can find out the expiration of the token given to fabio but when you renew-self you get back info on the lease duration which you could log in consul so as to renew again in good time (and rinse/repeat).\nI don't think it's a good idea to create orphan child tokens because whoever / whatever gave the token to fabio should retain the ability to revoke access. If orphan child tokens are created the revocation process is significantly harder or possibly even impossible.\nTo cover your concerns about the token being provided to fabio in a way that is sniffable, I suggest support for wrapped tokens. The token provided to fabio on startup would be a one-shot wrapped token which fabio would use to fetch the actual token. Pretty much anything in Vault starting v0.6 can be wrapped and this functionality makes use of the cubbyhole secret backend. \nA final and somewhat different approach would be to skip the tokens entirely and use the AppID auth backend to authenticate. Here, you could accept the appId via an env var and calculate the userId through some machine-specific value (mac address is suggested but not sure that's sensible in a container). You can also lock the appId/userId combinations down to a certain CIDR. Authentication is linked to a policy and so you still end up with a token with ACLs which you can, I assume, renew as needed as long as fabio is running. Arguably, however, this authentication could be the job of a pre-launch helper script which does the login and fetches a wrapped token which is then supplied to fabio as in the previous paragraph.\nhttps://www.vaultproject.io/docs/auth/token.html\nhttps://www.vaultproject.io/docs/secrets/cubbyhole/index.html\nhttps://www.vaultproject.io/docs/auth/app-id.html\n. Thinking about it, maybe @jeffrai was referring to these 'wrapped' tokens when he talked about the short-lived startup tokens.\n. That's great. I'm on holiday for a couple of days but I'll try and test the patch out and let you know :)\nI assume if Fabio tries to refresh the token it will need permissions to do this so does the policy also need to include auth/token/renew-self and possibly auth/token/lookup-self?\n. Hello :) Yes, been catching up on work after holiday but have had a chance this morning to test things. The log doesn't mention much about vault and tokens but I can confirm that when I provide a non-root token with the policy you mentioned above then fabio does indeed start for me without error and can access the specified vault path. Changing the path in the config causes an error and fabio will quit - so the policy is working and the token is working.\nThe one thing I'm still not sure about is when and whether the token will renew. I'm not sure what the \"Refresh\": 3000000000, means in the vault section of the config output on startup - is it 30 seconds, 5 mins, 34 days etc. I've tried querying the token via vault but either Fabio is renewing the token expiry every few seconds or querying the token with vault changes its last-renewal time because every time I query I get effectively the current date/time.\nI'll keep experimenting and I'm yet to see any log output suggesting fabio tried and failed to renew the token - but I've also yet to see any log output suggesting fabio tried and succeeded either. Some additional log output might be quite useful to confirm to users on startup that accessing Vault was successful and when tokens have renewed.\nI've yet to test and confirm wrapped tokens so I'll try that next.\n. Ok, I can confirm unwrapping and I can confirm correct termination of fabio if the unwrapping token itself has expired or already been accessed. \n. I think really 3s is a little too often for my needs. The default expiry for a vault token is 1 hour although you can set it when you create the token. It might be good to fetch the token TTL when fabio first starts (as I assume it will refresh the token as soon as it starts anyhow) and then set the refresh period to something related to the TTL - such as 75%. That way the creator of the token can control the renewal rate.\n. I've left fabio running far longer than the TTL on the token I gave it and it has not complained so I assume it is correctly refreshing the token. However, as I've not got much fabio might be fetching from vault at the moment I don't know whether it might fail to fetch if it tried. Overall, looks good to me :)\n. Regarding the refresh, are you supplying a renewal increment? Because it looks like although you are refreshing every few seconds the lease is actually being renewed for an hour (the default lease length in Vault). Again, this could be based on the creation TTL from the token info instead.\n. I can see your concerns regarding the time it takes to pick up a new certificate for a domain and your concerns about stampeding. My gut reaction to such a problem would be to do an initial fetch of all certs during startup and then an on-demand fetch for certs for domains where no cert currently exists in order to pick up new ones. You could combine this with a longer periodic refetch to handle updates and revocations and I believe there is already support for signals for force-reloading the config in case of emergency. \nYou are correct in saying Vault doesn't have events and watch capabilities but I think rapid polling is not really appropriate and maybe something 'out-of-band' using a better trigger such as a consul gossip event, kv change or os signal would be worth considering. I think I'll also suggest to the Vault developers the option to configure consul events on actions on definable paths. Technically they already have the framework because they have audit backends.\nWhatever option(s) you choose for checking and refreshing certs, I don't think the vault auth token needs to be renewed every few seconds. I think it needs decoupling from any fetching of data from vault and run on a longer period - possibly, as I suggest, based on a percentage of the TTL of the token when it was created. You don't need to renew the token on every use.\n. fyi: https://github.com/hashicorp/vault/issues/1712\n. Are those 1000 req/sec fetching data from vault backed by consul? Just curious as I've really not tested the performance of my setup :)\nI guess the only problem that might be caused by the frequent renewing of the token is if you have auditing turned on as each renewal will be logged. Maybe for the moment it could just be a configuration option so people can tune it like they can the consul healthcheck.\n. I've not seen a config option to change the refresh time for vault - does it support the same 'refresh' option as the http cert store?\n. That makes sense and will certainly do for me for now :)\n. Regardless of the discussion on refresh rates etc. do you feel the improvements for handling vault tokens will be released soon? The fixes will at least allow me to use Vault without needing to supply a root token :)\n. I can manually issue a cert using the following:\n\nvault write pki/issue/server-dev common_name=foo.server.dev\n\nIn this example I've set up a pki backend with an internally generated root cert for *.server.dev and then I've created a role 'server-dev' that is allowed to serve certs for .server.dev based on the root cert. Using the above command will return both the private and public parts of the new cert as well as a copy of the CA.\nThe vault cli just wraps the rest api so I assume the http request would be pretty similar.\n. I'm just running the docker container (in the foreground) via docker-compose and when I want to make changes I'm using ctl-c to shut it down and just running docker-compose up again.\n. What's the race? Is it that docker-compose isn't giving enough time for the shutdown? If that's the case I can tell docker-compose to wait longer before sending the kill signal.\nIf it's something internal then yes, I can prob. build my own docker image from the source or, if not, I can wait for a new image release. As long as I know the problem is being sorted I can cope with cleaning out the Consul data manually during testing :)\n. Ah, right, I think I see the problem. My mistake. It must be that it only leaves the data in Consul if it dies for some reason while processing the config file or it fails to talk to Vault. I think I'd miss-counted the number of left-over healthchecks vs the number of times I'd started and stopped the container.\n. It also doesn't help that the 'Down' line and all after it are not visible via docker-compose during the shutdown - although if you run docker-compose logs after the container has terminated you can then see the log output :)\nThanks for looking into things and sorry it was my error!\n. ah, that would be great :) I guess leaving the health check in place to turn critical when/if Fabio fails is a good thing as long as Fabio has started up correctly and has been running for a few seconds.\nAs I run consul-alert I find out pretty quickly if health checks are left dangling!\n. I've tried building but I'm not a go developer and the build is failing with a weird error I don't understand: \n\nsrc/github.com/eBay/fabio/admin/server.go:17: cannot use cfg (type \"github.com/eBay/fabio/vendor/github.com/eBay/fabio/config\".Config) as type \"github.com/eBay/fabio/vendor/github.com/eBay/fabio/vendor/github.com/eBay/fabio/config\".Config in assignment\n\nI suspect this is just because something is set up wrong for building but it might be better for someone else to test ;)\nFor reference, if you want to repeat the exit I was getting that was leaving the service registration in Consul I think you can replicate it by simply pointing a vault cs config at an invalid url.\n. e.g. set an invalid VAULT_ADDR and VAULT_TOKEN and setup a cs in the config\n\nproxy.cs = cs=foo;type=vault;cert=wibble\nproxy.addr = :443;cs=foo\n. ah, great, that did it. Managed to build and package into a docker image on my home machine and push up to the work server for testing and it now appears to correctly deregister after it encounters an error. I tested it with the setup I was using with the invalid vault token:\nfabio_1  | 2016/07/26 18:40:21 [INFO] Version v1.2-4-g75c5c70 starting\nfabio_1  | 2016/07/26 18:40:21 [INFO] Go runtime is go1.6.3\nfabio_1  | 2016/07/26 18:40:21 [INFO] Setting GOGC=800\nfabio_1  | 2016/07/26 18:40:21 [INFO] Setting GOMAXPROCS=8\nfabio_1  | 2016/07/26 18:40:21 [INFO] Metrics disabled\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Connecting to \"bar:8500\" in datacenter \"foo\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] Admin server listening on \":9998\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] Using routing strategy \"rnd\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] Using routing matching \"prefix\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Using dynamic routes\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Using tag prefix \"urlprefix-\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Watching KV path \"/fabio/config\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Manual config changed to #8719119\nfabio_1  | 2016/07/26 18:40:21 [INFO] Updated config to\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Health changed to #8719118\nfabio_1  | 2016/07/26 18:40:21 [FATAL] vault: client: Error making API request.\nfabio_1  | \nfabio_1  | URL: POST http://ping:8200/v1/auth/token/create\nfabio_1  | Code: 400. Errors:\nfabio_1  | \nfabio_1  | * root or sudo privileges required to create orphan token\nfabio_1  | 2016/07/26 18:40:21 [INFO] Graceful shutdown over 0\nfabio_1  | 2016/07/26 18:40:21 [INFO] Down\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Registered fabio with id \"fabio-c49206c22615-9998\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Registered fabio with address \"192.168.5.3\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Registered fabio with tags \"\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Registered fabio with health check to \"http://[192.168.5.3]:9998/health\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Deregistering fabio\nfabio_1  | 2016/07/26 18:40:21 [INFO] Updated config to\nfabio_1  | route add Test-Nginx wibble/ http://192.168.5.2:80/ tags \"urlprefix-wibble/\"\nfabio_1  | 2016/07/26 18:40:21 [INFO] consul: Health changed to #8719122\n. One question - does the health check always get removed on any termination or does your patch only mean any problems during startup are caught?\n\nI'm pretty new to health checks so maybe my thinking is a bit wrong but to my mind if a process has been running for more than a 'grace' period of maybe a few mins and then terminates there are situations where leaving the health check in place (so it then fails) is a good thing. If you are not using any form of orchestration system and Fabio fails unexpectedly after it's been running for a while then the health check is a way to be informed of this so shouldn't be cleared up. If you are using an orchestration system then I assume it will notice if the container exits and re-instantiate it so Fabio will just update its details and health check anyhow on restart.\nOr, as I said, maybe I'm thinking this wrong :)\n. ok, so if Fabio crashes out with an exception then the service and health check will be deregistered in all cases? Maybe it would be good to document what situations will cause the health check to fail and what situations will cause fabio to exit and deregister the health check so the scope of the health check as a warning of incorrect operation is understood :)\n. Great, that's what I hoped would happen! I'd like to be alerted when / if Fabio was ever to die unexpectedly and just wanted to make sure the changes you made to clean up on exit after config error etc. didn't change that behaviour :)\nI'm glad to hear Fabio has been so stable and I've had the same experiences as you with Consul - I've never had any unexpected behaviour from it and it's been as stable as a rock.\n. I would say it's prob. a property of the listener as the cert source is all about fetching certs while the listener is all about serving them. I'd prob. opt for fallback defaulting to true. I'm not keen on double-negatives (we have a few in our legacy codebase and they just cause you to stop and have to think more!) :)\n. well, if you are talking about the code vs the config, you could present the config as fallback with a default of true but internally represent it as something else such as strictMatch with a default of false. Or you could have something like preventfallback with a default of false if you don't like inverting a config value in code.\n. great! thanks :)\n. Hmm, yes, good point :)\nAs for why make the admin interface easy to find:\nI'm actually a dev, not a sysad, and I architect and maintain the cluster of servers we use for our dev environment - basically a simulacrum of the production environment but with the flexibility to change things around, run multiple copies of services, try out new stuff etc. As I'm actually mostly a dev I am trying to make the dev cluster environment approachable to the other devs so I'm not the only one who can spin up services, recover accidentally deleted data from backup, tweak admin settings etc.\nAs a result, I try to make all the admin interfaces easily available to make documentation and training easier :)\nAs an aside - of course, in this more open and dynamic environment some stuff still needs to be kept secret and out of reach of devs who might accidentally reveal important keys or, almost as bad, delete them. Hence my keen interest in vault integration :D\n. I have no idea what it is using to check. TBH, it's really an issue for Atlassian because BitBucket really shouldn't care. It should just use '//' on the protocol for ajax calls etc. I've raised a support ticket for them.\nHowever, in general, I could see how a setup with fabio being used as edge proxies for a cluster running multiple separate and distinct services could have other needs for mixing HTTPS and SNI+TCP style proxying on the same port.\nI figure the easiest way to achieve that would be to check an incoming request against a regex of hostnames that should be using SNI+TCP and, if it doesn't match then fall back to using HTTPS. Does Fabio add the proxy headers in the same way Apache does? Specifically:\n\nX-Forwarded-For: The IP address of the client.\nX-Forwarded-Host: The original host requested by the client in the Host HTTP request header.\nX-Forwarded-Server: The hostname of the proxy server.\n\nAnd does Fabio support CONNECT style tunnelling?. I get ssh_exchange_identification: Connection closed by remote host\nThere's no real debug info available. My suspicion is that the handshake is failing because the IP address of the client doesn't match the IP address of the proxied connection - or the same in revers for the server.\nI don't think the problem is one Fabio can fix but I wondered if anyone else had worked out how to configure the ssh server and client so they don't get upset.. I worked it out and it wasn't an ssh issue after all :) I use Nomad and Bitbucket Server and had created 1 service with 2 tags - one for http and one for the tcp proxying. Nomad had created the service in a way that resulted in both the http proxy and the tcp proxy routing to the container's http port 8080.\nThe solution was to split the config into 2 services, each with a specific port number in the nomad config.. ah, great :D I guess it's url-prefix-*.example.com/. \\o/ yes, that works fine :)\nThanks :). ",
    "MilesBehind": "Fantastic work on the project @magiconair!\nWhen do you think, this key=val key=val may be implemented? Since spring-cloud-consul supports only this configuration in an application.yml file:\nspring:\n  cloud:\n    consul:\n      discovery:\n        tags: foo=bar, baz=foobar\nit would be nice if these key=val key=val expressions would be supported.\n. ",
    "kelseyhightower": "Yeah, I found it by looking through the code. Thanks for the fast response.\n. ",
    "vhuang01": "@raben2 @magiconair definitely agree that Frank is doing a fantastic job with the Fabio project.  eBay has noticed the effort that Frank is putting in, and we're thrilled that it's benefiting the community\n. Agreed, I\u2019ll try to find a brand approved logo.  Thanks!\n. Done, closing this issue.  Thanks for bringing this to my attention!\n. ",
    "calvinmorrow": "Our use case doesn't really fit having the containers announce both URLs at service creation time (which is when the agent would be started).  We deploy new versions of containers with web code attached and then put them through regression testing;  currently once they pass regression we then assign the public facing names (api.example.com) to the existing container to essentially promote it live.\nAs described, we would either have to redeploy those containers with the added names, or find a way to modify the service definitions via the consul api to include them.  We would also have to remove that name from any other containers/services that used to have them.  \nAll told, we have ~8 names that we move between containers fairly frequently.\n. We're using Joyent's ContainerPilot (https://github.com/joyent/containerpilot) to setup the service registration and health check.\n. Your understanding is pretty much correct.  We have a couple different apps that use similar processes;  the api example I already gave, though our website follows a similar pattern with www being assigned to a fleet of containers after we've gone through our development process and any changes (and possible pre-launch processes) have been executed/verified.  Its worked well for that because it gives us an active/inactive configuration style.\nOnly the host portion of the name changes at the moment.\nWe're currently using consul-template to create an nginx configuration that 1) creates a service_name -> backend mapping, and then 2) watches a set of keys for the custom mappings;  The keys/values are just setup as key=alias value=backend (defined by enumerating the consul catalog in step 1), so the nginx configuration is:\nserver_name <key>;\nproxy_pass <value>;\nYou hit the challenges on the head pretty well I think.  We have a lot of ways of accomplishing the same thing, but most would require us to use some form of custom glue to marry the catalog with an extra name.  Additionally, redeploying to swap names means that we have to bring down old servers at the same time as new ones with a small amount of time for downtime while our application(s) start up.\n. I appreciate your patience.\nAll of our containers have at least one name which we announce at container start time.  Regarding having multiple versions running simultaneously, this actually causes problems for us since we version our static files such as CSS and JS, which means that two versions may be serving HTML which references CSS and/or JS which aren't present on half of the containers.  That means half of the containers would return 404 if the CSS content changed between deployments.\nThe \"goal\" as you stated, of having the load balancer configured based on the service catalog is one of the main reasons we are attracted to Fabio;  We also will need to do some routing based on prefixes in the near future which is difficult with our current consul-template solution.\nBefore opening this issue, we tried to see if we could trick Fabio into performing the correct behavior.  Specifically:\nTried using manual routes to do a route add our-deployed-service api.example.com http://our-deployed-service.example.com;  This actually routed via DNS and hit our current load balancer (which makes sense) ... but not what we were hoping.\nTried using manual routes to do a route weight our-deployed-service api.example.com weight 1;  This didn't work ... according to the docs it does a lookup and attempts to match based on the combination of service and source, where the source (api.example.com) doesn't already exist in our case.\nOf course, copying the backend server configuration with a route add our-deployed-service api.example.com http://1.2.3.4:80 works, although it requires us to keep track of the container health outside of Fabio and update the routes.\nPossibilities I've thought of:\nWe're using Haproxy currently for initial SSL termination as well as some HTTP traffic policing;  We could use consul-template and rewrite the Host HTTP header to the backend server, but this masks the true Host from the backend servers which seems ugly.  Besides this, we'd like to reduce the number of existing layers and have one solution do most of the heavy lifting.\nWe could try to register new services in the Consul Catalog with the correct tags;  Unfortunately if a container dies and restarts, it won't be added automatically to the new service.  We would have to maintain health and membership ourselves.\nWe could use consul-template to write manual routes to the backend service with our custom names.  This seems like the easiest solution.\nUnfortunately my grasp of Go is still pretty limited;  What I hoped for originally was that it wouldn't be hard to add support for something similar to a route add out-deployed-service api.example.com, simply adding a new Host: to an existing group of routes.\n. Startup time used to be ~5-10 minutes;  We've got that down to about 1-2 minutes now.  By versioning, I actually mean that the filenames are essentially a hash of the contents (/js/17c616ea4772.js).\nPart of the reason we're down this road is we're in that awkward transition between \"legacy\" and \"microservice.\"\nThat said, I'll admit that doesn't necessarily mean we're doing it right, and what you're suggesting is definitely more transparent and straight forward.  If we didn't have a race between startup of new code and shutdown of old, we could probably fit it into the existing mold.  I'll have to think about how to best solve that problem.\n. I think the route-by-host-and-tag would be helpful in a variety of situations, and as you mentioned, also help with our traffic cutover issue.\nOur applications have been going through a lot of redevelopment over the last year or two.  It wasn't long ago that 1-2 minute startup would have been impossible, so we're making gains;  Unfortunately we've inherited some unfortunate design decisions and we're trying to work around some of them as best as possible.  We know where we want to go, its just time and money getting there.\n. @magiconair Thanks.  I can confirm your commit solves the issue.  Fabio is now pulling certificates from Vault.\n. ",
    "dsolsona": "Are prepared queries of any help here? https://www.consul.io/docs/agent/http/query.html\nJust throwing a suggestion.\n. ",
    "madeddie": "For load balancing, @ptqa 's solution of retrieving all services from all datacenters and combining them seems the only reliable way. For failover setups, prepared queries would work nicely, although the query has to be created beforehand in consul by either fabio or the user.\nThe reason for this split is that prepared queries only ever give services in non-local DC's when there are no healthy instances in their local DC. So there is no way to have prepared queries give back all the services in all DCs.\nConversely, it'll be hard to use any native consul methods to determine specific nearness of services in the combined list of multi-DC services. They can be sorted on nearness, probably, but then \"manual\" filtering on DC would need to happen and this could get ugly with more than 2 DCs.\nThe weight parameter is hard for the latter reason, but an optional switch between no multi-DC awareness, failover, and loadbalancing should be relatively easy.\nI'll try to update the current POC to incorporate both options.\n. Your solution is the better solution by far, but I can use the practice :)\n. That actually doesn't change anything I described :) Prepared queries don't show containers in all DCs, they show non-local-DC containers only when the local-DC containers are all unhealthy. Unless that's changed too, in which case I'd be very interested :D\n. I didn't actually intend to, but seem to have accidentally opened a pull-request (#130) nonetheless.\n. Awesome, looks like what I need! Thanks. I've closed my PR.\nOw and will test in the morning and report.\n. It works like expected. There might be more situations where people want in-between flushes as well as configurable keepalive etc, so I think it's a good idea to keep it in the scope of #111 \n. I've set it to 1s in our env (we use Fabio both outside to container as well as container to container, so the time adds up sometimes) to keep the connection fast. We don't have a lot of users, so, no idea about any potential problems with load or anything. \nThe idea of SSE is that any event is separated from others by an empty line (so 2 line returns). So the strictest way of doing this is by flushing buffer on empty line, but I have no clue how to do that :) (it'll probably mean rewriting some basis net/http methods, so; non-trivial).\nIn short, as long as there are no obvious performance penalties, 1s for SSE buffer flush is an ok default, as long as it's specifically mentioned in the docs somewhere.\n. ",
    "stephane-martin": "Just to say that use case happens even if you don't have multiple datacenters.\nAFAIK in a \"consul datacenter\" every agent must able to talk with eachother using the mesh protocol.\nSo, if you have multiple isolated VLANs with different webapps in each VLAN, you have to run a distinct \"consul datacenter\" in each VLAN. \nI'd like a single fabio instance to be able to route trafic to the relevant VLANs. But for that it needs to discover the healthy services in the different \"datacenters\".. Well, in OSX you define a service with launchd, and launchd takes care of binding to the low port.\nOn Linux you can use capabilities to allow the low port binding for a non privileged user (and you can even do that in the systemd service definition nowadays).\nOn OpenBSD you just don't bind to a low port (instead use PF to port forward from a low port to a \"high\" port).\nSo on *NIX at least i would not expect a web proxy to take care of security stuff that are quite clearly OS responsibility.... For instance on Linux with systemd.\n/etc/systemd/system/fabio.service:\n```\n[Unit]\nDescription=Fabio proxy\nAfter=syslog.target\nAfter=network.target\n[Service]\nLimitMEMLOCK=infinity\nLimitNOFILE=65535\nType=simple\nunprivileged uid and gid\nUser=fabio\nGroup=fabio\nWorkingDirectory=/\nExecStart=/path/to/fabio -cfg /path/to/fabio.conf\nRestart=always\nno need that fabio messes with /dev\nPrivateDevices=yes\ndedicated /tmp\nPrivateTmp=yes\nmake /usr, /boot, /etc read only\nProtectSystem=full\n/home is not accessible at all\nProtectHome=yes\nto be able to bind port < 1024\nAmbientCapabilities=CAP_NET_BIND_SERVICE\nonly ipv4, ipv6, unix socket and netlink networking is possible\nnetlink is necessary so that fabio can list available IPs on startup\nRestrictAddressFamilies=AF_INET AF_INET6 AF_UNIX AF_NETLINK\n```. On *BSD with Packet Filter, if fabio is directly facing internet, the best practice is only listen on a non-privileged port (4343), and use PF to forward trafic:\n/etc/pf.conf:\n```\nEXT_IF = \"eth0\"\nHTTPS_PORT = 443\nHTTPS_PORT_BACKEND = 4343\nLOCAL_IP = \"127.0.0.1\"\n...\npass in quick on $EXT_IF inet proto tcp from any to $LOCAL_IP port $HTTPS_PORT rdr-to $LOCAL_IP port $HTTPS_PORT_BACKEND\n```\nRunning fabio in a jail (FreeBSD) or chroot (OpenBSD) doesn't harm too. You just need to copy the relevant C libraries to the jail (eg. libc.so, ld.so and libpthread.so)..     Let the administrator configure Fabio's proxy port(s) using the Consul KV store.\nThis is what i do so far: \nbash\nconsul kv put XXX/fabio/FABIO_PROXY_ADDR 10.1.2.3:9999\n/usr/local/bin/envconsul -prefix=XXX/fabio -pristine /bin/bash -c '/usr/local/bin/fabio -cfg /etc/fabio.conf'\nAnd for the nginx in front of fabio:\nbash\n/usr/local/bin/envconsul -prefix=XXX/fabio -upcase -pristine -sanitize /usr/local/bin/bash -c '/usr/local/bin/envsubst < /etc/nginx/nginx.conf.tmpl > /etc/nginx/nginx.conf \\$FABIO_PROXY_ADDR && /usr/local/sbin/nginx -c /etc/nginx/nginx.conf'\nnginx.conf.tmpl has something like:\nupstream fabio_backend {\n    server ${FABIO_PROXY_ADDR};\n}\nNo really painful, but indeed it would be easier to have fabio registering itself.\n. It's a 64bits VM (at vultr.com), with OpenBSD 6.1.\nI tried to recompile fabio 1.4.3 with go 1.8. This time it works properly.\nI also tried the official release from github. It works properly too :)\nOne thing strikes me though:\n- on your binary ldd fabio gives \"not a dynamic executable\"\n- on the binary from my compilation ldd gives:\n/usr/lib/libpthread.so.22.0\n/usr/lib/libc.so.88.0\n/usr/libexec/ld.so\nHow do you avoid the shared libraries dependencies ?. Correction: i was stupidly pointing curl to the fabio instance on a linux box. I did retry to run fabio 1.4.3 on OpenBSD, and it still doesn't answer HTTP requests at all (binary from Releases or recompile, same).. (thanks for the netgo tag. for reference: https://golang.org/doc/go1.5). I understood part of the problem. In main.go there are lines in func startServers like: go proxy.ListenAndServe...\nIn fact the ListenAndServe... functions can fail and return and error. But that error stays invisible because it is swallowed by the goroutine go statement. Would be good to catch those errors and log them.\nOn the OpenBSD box the network operations are indeed failing with error \"protocol not available\". I don't understand why ,yet. Maybe related to IPv6.\n. Not really, got \"[FATAL] ui: set tcp4 127.0.0.1:9998->127.0.0.1:XXX: protocol not available\" instead of \"[FATAL] ui: set tcp 127.0.0.1:9998->127.0.0.1:YYY: protocol not available\" (here trying to query the UI, but same on the proxy port). Commenting ln = tcpKeepAliveListener{ln.(*net.TCPListener)} removes the problem. Not sure why.... I don't think it's related, anyway I disabled IPv6 on the interface during the bug hunt. Anyway I do have a workaround now, and the bug is most probably not in fabio source code. So don't bother too much.. Further workaround: http://man.openbsd.org/sysctl.3\n(net.inet.tcp.always_keepalive) Act as if the option SO_KEEPALIVE was set on all TCP sockets.\n. ",
    "bogdanov1609": "The feature will be very useful for us too!\n. ",
    "jralph": "@leprechau I've been looking at doing something similar with HAProxy. How did you go about configuring this?. @leprechau Thanks for the info. How did you get around fabio not supporting multi-datacenters?. @leprechau But fabio is unable to detect services in another dc, so services would only be able to find other services within their own dc when using fabio? If so, that makes sense. I've been experimenting today and decided to stick with services only talking to their local services, using public domains to access other services if needed.. ",
    "zakk4223": "For those looking to use HAProxy, 1.8 added the ability to dynamically change backend destinations based on DNS SRV records. Might simplify writing out config files via consul-template. ",
    "tanuck": "Cool - has there been work pushed on this already?\n. @magiconair no, i was focusing on apply compression to responses proxied by fabio - what @smancke has suggested with his gzip handler\nCheers\n. no, just leave that to the browser/client - but if it's present, have the same sort of feature as nginx, to compress the response from the upstream service before sending it to the client and then setting the Content-Encoding header in the response.\n. @magiconair no not quite. So i'm trying to get a fabio setup that can replicate my current \"nginx as a reverse proxy\" configuration.\nSo right now I have an nginx service, proxying requests to various dockerized microservices. The microservices don't perform any gzip compression. Instead, we use the nginx gzip module. If the browser sends Accept-Encoding: gzip then nginx will compress the response from the upstream microservices and set Content-Encoding: gzip before returning the response to the browser. I hope that's more clear.\nSo my question is whether this can be replicated with fabio, whether responses from upstream services can be compressed returning the response to the client/browser.\nThe http.Handler that @smancke linked is pretty much what I mean, so some way to integrate that into fabio based on a config setting?\nCheers\n. Awesome :) I'm happy to help out with the implementation if needed.\nWhat do you think is the best way to configure this? In fabio.properties or as part of the route tags in consul etc?\n. I think from prior experience that RequestClientCert is the correct constant to replicate what nginx can do with the optional_no_ca option\n. Was the OP more about writing an example k8s Pod or Deployment. Rather than using k8s as a registry for fabio?\n. ",
    "numard": "+1 please :)\n. hi Frank, any update on this ?\ncheers!!. ",
    "kivoli": "Client\u2019s who are asked to provide a client cert but don\u2019t just proceed fine. At least my (manual) tests so far have not shown any problems. Also I did not hear about any problems in production but only new customers are affected by this change so the sample is limited.\nThe greatest issue is that, and that\u2019s the reason for using an SNI based limitation, browsers with a client certificate installed will ask the user to select / confirm the certificate. In an environment with mixed m2m and u2m communication where only m2m would use client certificates this is an issue.\nOn top of that, at least Safari and Chromium based browsers on Mac OS X do not provide an option to remember the selection (incl. \u201cnone\u201d).\nRegarding SNI & TLS settings, this is actually the point of SNI: To be able to use different configurations based on the server name indicated. Most commonly this is used to use different certificates but theoretically it should work for all TLS settings. With nginx I think we even used to vary the available ciphers to support customers with outdated systems. \n. Sorry for the late reply, the last few weeks have been quite busy and I missed your reply. Unfortunately your suggestion would not work around the issue (although it helps us in another regard) since we prefer to do TLS offloading on the frontend. This way the application nodes do not need to care about certificates and certainly do not need access to the private keys.\n. ",
    "cabrinoob": "ok, thank you. It's clearer. \n. ",
    "hamann": "Any concerns about detecting SSE by response instead of request headers, like when the server is sending \"Content-Type: text/event-stream\"? Afaik you can't set accept headers in browsers without js.. Ok, thanks for clarification. I asked, because we have a resource which we open in the browser (without any js or html at all) and get server-sent events (like content from log files). That stopped working as we switched from haproxy to fabio, but I guess it should be solveable with a few lines of js.. Any progress on this? . ",
    "beyondblog": "@magiconair Thanks.Your suggestion is very good.I will try to correct.\n. @magiconair Thanks. I will improve my code under your suggestion.\n. @magiconair  Thanks. I look forward to this feature.\n. ",
    "roman-gliffy": "Would be nice to have logs.\n@magiconair, any suggestions how to deal with the absent of logs in production for the time being?\n. ",
    "jamessammut": "What is the best option to run fabio with verbose logs?\nI see this error in the Rancher logs, so I guess fabio is routing this request to Rancher:\n2016-07-25 14:38:42,545 ERROR [:] [] [] [] [1976473931-1222] [i.g.i.g.s.ApiRequestFilterDelegate  ] Unhandled exception in API for request [ws://rancher.cloud.XXXX.com/v1/projects/1a16602/subscribe] io.github.ibuildthecloud.gdapi.exception.ClientVisibleException: null\nI might also raise something on their forums.\n. I've taken Fabio out of the path and Rancher works fine. I will attempt to\ngather some info for a possible trouble shoot when I get the chance.. @juliamgamble Julian is this still a problem?\nI don't work on that project currently but Julian is still involved. Julian\ndo you still see this issue?. ",
    "ketchoop": "I've got the same thing with rancher. And, maybe, can collect some needed data that is necessary to work it out. @magiconair What is needed? Tcpdump, access logs, response and request headers?. It seems to be the problem with theirs parser as far as I can get it from logs. If someone is interested I'll stack trace of rancher here.. @magiconair ok, I'm going to do this. And it's the string that throws exception. Obviously, that we get 500 response code because of it. Maybe this information can help.. The same story with plain HTTP. \nDump behind fabio: Fabio <-> Capturing(ngrep) <-> Rancher:\n```\nT x.x.211.37:36254 -> 10.0.30.11:8080 [AP]\n  GET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=14 HTTP/1.1..Host: rancher.x.x.x..User-A\n  gent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36..Accept-Encoding:\n   gzip, deflate, sdch, br..Accept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4..Cache-Control: no-cache..Connection: Upgrade..Co\n  okie: _ym_uid=1480687797947545909; _ga=GA1.3.1084697215.1480687797; PL=rancher; token=LoxoWkymzCuwZ3NrH5SccmGKFrE6U4PHxVkKdHNc; \n  CSRF=55CD8433FA..Forwarded: for=10.2.24.253; proto=wss; by=x.x.211.37..Origin: https://rancher.x.x.x..Pragma: no-cac\n  he..Sec-Websocket-Extensions: permessage-deflate; client_max_window_bits..Sec-Websocket-Key: MtZ0QxeTQSdQXF87guU6HQ==..Sec-Webso\n  cket-Version: 13..Upgrade: websocket..X-Forwarded-For: 10.2.24.253..X-Forwarded-Port: 443..X-Forwarded-Proto: wss..X-Real-Ip: 10\n  .2.24.253....                                                                                                                   \n\nT 10.0.30.11:8080 -> x.x.211.37:36254 [AP]\n  HTTP/1.1 500 Server Error..Date: Wed, 10 May 2017 16:40:02 GMT..X-Rancher-Version: v1.5.5..Content-Type: text/html; charset=ISO-\n  8859-1..Cache-Control: must-revalidate,no-cache,no-store..Content-Length: 321..Server: Jetty(9.2.11.v20150529)......\n  .Error 500 Server Error..HTT\n  P ERROR 500.Problem accessing /v2-beta/projects/1a28/subscribe. Reason:. Pow\n  ered by Jetty://....                                                                             \n\n```\nDump before fabio Outside <-> Capturing(ngrep) <-> Fabio <->  Rancher:\n```\nT 10.2.24.253:48730 -> x.x.211.37:80 [AP]\n  GET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1..Host: rancher.x.x.x..Connect\n  ion: Upgrade..Pragma: no-cache..Cache-Control: no-cache..Upgrade: websocket..Origin: http://rancher.x.x.x..Sec-WebSocket\n  -Version: 13..User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.\n  36..Accept-Encoding: gzip, deflate, sdch..Accept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4..Cookie: PL=rancher; token=Y6APWT\n  UxqxMwVf1TDPq38fQ2HzRKmP9UFbzBaY7D; CSRF=E84259568E..Sec-WebSocket-Key: O1tgYw0qtqmj12P0AiFyCA==..Sec-WebSocket-Extensions: perm\n  essage-deflate; client_max_window_bits....                                                                                      \n\nT x.x.211.37:80 -> 10.2.24.253:48730 [AP]\n  HTTP/1.1 500 Server Error..Date: Wed, 10 May 2017 16:49:36 GMT..X-Rancher-Version: v1.5.5..Content-Type: text/html; charset=ISO-\n  8859-1..Cache-Control: must-revalidate,no-cache,no-store..Content-Length: 321..Server: Jetty(9.2.11.v20150529)......\n  .Error 500 Server Error..HTT\n  P ERROR 500.Problem accessing /v2-beta/projects/1a28/subscribe. Reason:. Pow\n  ered by Jetty://....\n```. > These can't be the same requests. Look at the cookie and the websocket key.\nOh, sorry, I lost it. Ok, I will do it right way.\nP.S. I found something about this exception. I'm not sure that this it hasn't been resolved, but the problem with  MalformedURLException is because it doesn't support websocket protocol. But It seems strange and maybe this is old information.. Second try:\nDump behind fabio Fabio <-> Capturing(ngrep) <-> Rancher:\n```\nT x.x.211.37:48514 -> 10.0.30.11:8080 [AP]\nGET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1.\nHost: rancher.x.x.x.\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36.\nAccept-Encoding: gzip, deflate, sdch.\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4.\nCache-Control: no-cache.\nConnection: Upgrade.\nCookie: PL=rancher; token=UFpPFaQTPfCwn3yCqmVeTSNUHiwDDZCpdQgJ8rWo; CSRF=115909254B.\nForwarded: for=10.2.24.253; proto=ws; by=x.x.211.37.\nOrigin: http://rancher.x.x.x.\nPragma: no-cache.\nSec-Websocket-Extensions: permessage-deflate; client_max_window_bits.\nSec-Websocket-Key: lGEnYPVpBoP7o5autfutNQ==.\nSec-Websocket-Version: 13.\nUpgrade: websocket.\nX-Forwarded-For: 10.2.24.253.\nX-Forwarded-Port: 80.\nX-Forwarded-Proto: ws.\nX-Real-Ip: 10.2.24.253.\n.\nT 10.0.30.11:8080 -> x.x.211.37:48514 [AP]\nHTTP/1.1 500 Server Error.\nDate: Thu, 11 May 2017 07:50:18 GMT.\nX-Rancher-Version: v1.5.5.\nContent-Type: text/html; charset=ISO-8859-1.\nCache-Control: must-revalidate,no-cache,no-store.\nContent-Length: 321.\nServer: Jetty(9.2.11.v20150529).\n.\n\n\n\nError 500 Server Error\n\nHTTP ERROR 500\nProblem accessing /v2-beta/projects/1a28/subscribe. Reason:\n Powered by Jetty://\n\n```\nDump before fabio Outside <-> Capturing(ngrep) <-> Fabio <-> Rancher:\n```\nT 10.2.24.253:49984 -> x.x.211.37:80 [AP]\nGET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1.\nHost: rancher.x.x.x.\nConnection: Upgrade.\nPragma: no-cache.\nCache-Control: no-cache.\nUpgrade: websocket.\nOrigin: http://rancher.x.x.x.\nSec-WebSocket-Version: 13.\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36.\nAccept-Encoding: gzip, deflate, sdch.\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4.\nCookie: PL=rancher; token=UFpPFaQTPfCwn3yCqmVeTSNUHiwDDZCpdQgJ8rWo; CSRF=115909254B.\nSec-WebSocket-Key: lGEnYPVpBoP7o5autfutNQ==.\nSec-WebSocket-Extensions: permessage-deflate; client_max_window_bits.\n.\nT x.x.211.37:48514 -> 10.0.30.11:8080 [AP]\nGET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1.\nHost: rancher.x.x.x.\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36.\nAccept-Encoding: gzip, deflate, sdch.\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4.\nCache-Control: no-cache.\nConnection: Upgrade.\nCookie: PL=rancher; token=UFpPFaQTPfCwn3yCqmVeTSNUHiwDDZCpdQgJ8rWo; CSRF=115909254B.\nForwarded: for=10.2.24.253; proto=ws; by=x.x.211.37.\nOrigin: http://rancher.x.x.x.\nPragma: no-cache.\nSec-Websocket-Extensions: permessage-deflate; client_max_window_bits.\nSec-Websocket-Key: lGEnYPVpBoP7o5autfutNQ==.\nSec-Websocket-Version: 13.\nUpgrade: websocket.\nX-Forwarded-For: 10.2.24.253.\nX-Forwarded-Port: 80.\nX-Forwarded-Proto: ws.\nX-Real-Ip: 10.2.24.253.\n.\nT 10.0.30.11:8080 -> x.x.211.37:48514 [AP]\nHTTP/1.1 500 Server Error.\nDate: Thu, 11 May 2017 07:50:18 GMT.\nX-Rancher-Version: v1.5.5.\nContent-Type: text/html; charset=ISO-8859-1.\nCache-Control: must-revalidate,no-cache,no-store.\nContent-Length: 321.\nServer: Jetty(9.2.11.v20150529).\n.\n\n\n\nError 500 Server Error\n\nHTTP ERROR 500\nProblem accessing /v2-beta/projects/1a28/subscribe. Reason:\n Powered by Jetty://\n\n\nT x.x.211.37:80 -> 10.2.24.253:49984 [AP]\nHTTP/1.1 500 Server Error.\nDate: Thu, 11 May 2017 07:50:18 GMT.\nX-Rancher-Version: v1.5.5.\nContent-Type: text/html; charset=ISO-8859-1.\nCache-Control: must-revalidate,no-cache,no-store.\nContent-Length: 321.\nServer: Jetty(9.2.11.v20150529).\n.\n\n\n\nError 500 Server Error\n\nHTTP ERROR 500\nProblem accessing /v2-beta/projects/1a28/subscribe. Reason:\n Powered by Jetty://\n\n\n```\n. X-Forwarded-Proto: ws makes Java url parsing fail. Without this one I connection to ranhcer(of course direct) is good.\nWith:\n```\nGET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1\nHost: x.x.spb.ru\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36\nAccept-Encoding: gzip, deflate, sdch\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4\nCache-Control: no-cache\nConnection: Upgrade\nCookie: PL=rancher; token=UFpPFaQTPfCwn3yCqmVeTSNUHiwDDZCpdQgJ8rWo; CSRF=115909254B\nForwarded: for=x.x.211.37; proto=ws; by=x.2.211.37\nOrigin: http://x.x.spb.ru\nPragma: no-cache\nSec-Websocket-Extensions: permessage-deflate; client_max_window_bits\nSec-Websocket-Key: oKEV2Pr3vC1gXe6bC9UvAw==\nSec-Websocket-Version: 13\nUpgrade: websocket\nX-Forwarded-For: x.x.211.37\nX-Forwarded-Port: 80\nX-Forwarded-Proto: ws\nX-Real-Ip: x.x.211.37\nHTTP/1.1 500 Server Error\nDate: Thu, 11 May 2017 16:50:31 GMT\nX-Rancher-Version: v1.5.5\nContent-Type: text/html; charset=ISO-8859-1\nCache-Control: must-revalidate,no-cache,no-store\nContent-Length: 321\nServer: Jetty(9.2.11.v20150529)\n\n\n\nError 500 Server Error\n\nHTTP ERROR 500\nProblem accessing /v2-beta/projects/1a28/subscribe. Reason:\n Powered by Jetty://\n\n\n```\nWithout : \n```\n$ nc 10.0.30.11 8080\nGET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1\nHost: x.x.spb.ru\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36\nAccept-Encoding: gzip, deflate, sdch\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4\nCache-Control: no-cache\nConnection: Upgrade\nCookie: PL=rancher; token=UFpPFaQTPfCwn3yCqmVeTSNUHiwDDZCpdQgJ8rWo; CSRF=115909254B\nForwarded: for=x.x.211.37; proto=ws; by=x.x.211.37\nOrigin: http://x.x.spb.ru\nPragma: no-cache\nSec-Websocket-Extensions: permessage-deflate; client_max_window_bits\nSec-Websocket-Key: oKEV2Pr3vC1gXe6bC9UvAw==\nSec-Websocket-Version: 13\nUpgrade: websocket\nX-Forwarded-For: x.x.211.37\nX-Forwarded-Port: 80\nX-Real-Ip: x.x.211.37\nHTTP/1.1 101 Switching Protocols\nDate: Thu, 11 May 2017 16:48:26 GMT\nX-Rancher-Version: v1.5.5\nX-API-Schemas: http://x.x.spb.ru/v2-beta/projects/1a28/schemas\nX-API-ACCOUNT-ID: 1a28\nX-API-USER-ID: 1a5\nX-API-Client-IP: x.x.211.37\nSet-Cookie: CSRF=115909254B;Path=/\nExpires: Thu, 01 Jan 1970 00:00:00 GMT\nConnection: Upgrade\nSec-WebSocket-Accept: z1bv4M21Lz2sfQf99fAomyd1OTk=\nUpgrade: WebSocket\nContent-Type: text/plain\n```. P.S. Did something wrong in edited message meant: \"I forgot how TCP works and saw strange things\" :smile:. Yeah, it's about Java URL parsing. It reads X-Forwarded-Proto and doesn't know about ws protocol and throws exception. it works fine with http or https in Forwarded-Proto. So this bug isn't only about Rancher, but about apps that were written in Java and uses stdlib function for URL.  . @magiconair I think, there is a lot of legacy code that can be suffered from this. But anyway, thank you! I'm going to open issue about it in rancher repo. I hope they will read another issue which I opened.... And issue in Traefik repo. It seems that they use http for ws and https for wss.. > The Forwarded header though is specified and there is no such restriction: https://tools.ietf.org/html/rfc7239#section-5.4\nWow. I've lost this section when I read this RFC. \n\n@ket4yii can you put a link to the rancher issue you've opened here?\nhttps://github.com/rancher/rancher/issues/8745\nCould you test whether that works for you?\n\nOk, I'll do it tommorow and send you response. Thank you a lot!. @magiconair It seems to work perfect. Here is a few packets that were captured between rancher and fabio when WS connection was established.\nWS packets:\n```\nT x.x.211.37:36968 -> 10.0.30.11:8080 [AP]\nGET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1.\nHost: rancher.x.x.x.\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36.\nAccept-Encoding: gzip, deflate, sdch.\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4.\nCache-Control: no-cache.\nConnection: Upgrade.\nCookie: PL=rancher; token=jzw6KHCtd1KPyLiiA6qCzFTV5tq4U24iQ2zGu93J; CSRF=3696332F83.\nForwarded: for=10.2.24.253; proto=ws; by=x.x.211.37.\nOrigin: http://rancher.x.x.x.\nPragma: no-cache.\nSec-Websocket-Extensions: permessage-deflate; client_max_window_bits.\nSec-Websocket-Key: ylxlhTGmeJM4DtkEzwfWWg==.\nSec-Websocket-Version: 13.\nUpgrade: websocket.\nX-Forwarded-For: 10.2.24.253.\nX-Forwarded-Port: 80.\nX-Forwarded-Proto: http.\nX-Real-Ip: 10.2.24.253.\n.\nT 10.0.30.11:8080 -> x.x.211.37:36968 [AP]\nHTTP/1.1 101 Switching Protocols.\nDate: Fri, 12 May 2017 15:09:04 GMT.\nX-Rancher-Version: v1.5.5.\nX-API-Schemas: http://rancher.x.x.x./v2-beta/projects/1a28/schemas.\nX-API-ACCOUNT-ID: 1a28.\nX-API-USER-ID: 1a5.\nX-API-Client-IP: 10.2.24.253.\nSet-Cookie: CSRF=3696332F83;Path=/.\nExpires: Thu, 01 Jan 1970 00:00:00 GMT.\nConnection: Upgrade.\nSec-WebSocket-Accept: aieDS0nAQheGmrrijsIfST4QkOs=.\nUpgrade: WebSocket.\nContent-Type: text/plain.\n```\nWSS packets:\n```\n x.x.211.37:38642 -> 10.0.30.11:8080 [AP]\nGET /v2-beta/projects/1a28/subscribe?eventNames=resource.change&limit=-1&sockId=1 HTTP/1.1.\nHost: rancher.x.x.x.\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36.\nAccept-Encoding: gzip, deflate, sdch, br.\nAccept-Language: ru-RU,ru;q=0.8,en-US;q=0.6,en;q=0.4.\nCache-Control: no-cache.\nConnection: Upgrade.\nCookie: PL=rancher; token=jzw6KHCtd1KPyLiiA6qCzFTV5tq4U24iQ2zGu93J; CSRF=3696332F83.\nForwarded: for=10.2.24.253; proto=wss; by=x.x.211.37.\nOrigin: https://rancher.x.x.x.\nPragma: no-cache.\nSec-Websocket-Extensions: permessage-deflate; client_max_window_bits.\nSec-Websocket-Key: 38niATh2tnbfErkt9+BHDg==.\nSec-Websocket-Version: 13.\nUpgrade: websocket.\nX-Forwarded-For: 10.2.24.253.\nX-Forwarded-Port: 443.\nX-Forwarded-Proto: https.\nX-Real-Ip: 10.2.24.253.\n.\nT 10.0.30.11:8080 -> x.x.211.37:38642 [AP]\nHTTP/1.1 101 Switching Protocols.\nDate: Fri, 12 May 2017 15:12:28 GMT.\nX-Rancher-Version: v1.5.5.\nX-API-Schemas: https://rancher.x.x.x/v2-beta/projects/1a28/schemas.\nX-API-ACCOUNT-ID: 1a28.\nX-API-USER-ID: 1a5.\nX-API-Client-IP: 10.2.24.253.\nSet-Cookie: CSRF=3696332F83;Path=/.\nExpires: Thu, 01 Jan 1970 00:00:00 GMT.\nConnection: Upgrade.\nSec-WebSocket-Accept: DO3pXQWXQ1WieG86VY2JLCjQDbU=.\nUpgrade: WebSocket.\nContent-Type: text/plain.\n```. What about to make this feature is able to support protocols? Because a lot of users, for example, make requests to http when you've got https server and their requests will fail. I know, that there are many ways, to do it, like make another tls terminator, proxy and so on, but it would be really convenient if you implement this.. @magiconair Yeah, maybe it's the better way. Is there any way to do it?. Ok, thx. If it's hard to implement this then I think it's not really important. But a couple of times I needed to change certificate stores and pathes to certs in vault and had a little downtime.. ",
    "dahendel": "@ket4yii I see that as well, but when I switch back to HAProxy I have no issues. I also have logs etc readily available.\n. ",
    "juliangamble": "Confirming I'm still using this. (Just got to this thread). @magiconair thanks for your work. @ket4yii thanks for testing. Am keen to know which version this fix goes into. . ",
    "blalor": "I'd really like to see Vault's PKI backend supported, as well.   I've been chewing on this for an hour or so and I think the model of multiple certs per cert store doesn't exactly mesh with Vault's PKI backend, but if each vault-pki certificate source has a single pki secret path instead of multiples, that would probably work fine. One of the config options to the vault-pki cert source would be a list of SANs that would be on the cert, perhaps?. @magiconair what help do you need to get this branch where you're comfortable with merging it?. ",
    "pschultz": "The Vault operator defines what certificates can be issued on a given path.\nFrom fabios perspective there is almost no difference to fetching certs from the generic secret backend. In Go, it looks something like this:\n```go\nimport \"github.com/hashicorp/vault/api\"\nvar client *api.Client\nresponse, err := client.Logical().Write(\"pki-fabio/issue/example.com\", map[string]interface{}{\n    \"common_name\": \"foo.example.com\",\n    \"alt_names\": \"localhost,127.0.0.1\",\n    \"ttl\":         \"24h\", // uses Vault's default if omitted\n})\npemKey := response.Data[\"private_key\"].(string)\ncertChain := response.Data[\"certificate\"].(string) + \"\\n\"\nfor _, cert := range response.Data[\"ca_chain\"].([]interface{}) {\n    certChain += cert.(string) + \"\\n\"\n}\n```\nSo very similar to what the current vault store does. client.Logical().Read is replaced with client.Logical().Write, and the data structure is a bit different from what the current store expects. The \"pki-fabio/issue/com.example\" path has to be configured in fabio (like for the Consul store).\nEach Write() call generates a new certificate. It will not return previously generated certs. Previously generates certs remain valid. This is different from how Letsencrypt works.\nFor completeness, this is what a Vault operator might do in advance:\n```sh\nMount a pki backend for fabio to use. Certificates will expire after 7 days\nby default (7*24=168), and attempting to issue certificates with a validity\nperiod of more than 30 days will be denied (30*24=720).\nvault mount \\\n    -path pki-fabio \\\n    -default-lease-ttl=168h \\\n    -max-lease-ttl=720h \\\n    pki\nDefine which certificates can be issued via the pki-fabio/issue/example.com path.\nvault write pki-fabio/roles/example.com \\\n    allowed_domains=\"example.com\" \\\n    allow_subdomains=\"true\" \\\n    allow_localhost=\"true\"\n```\nMany more role options are available. I omitted the commands for configuring the CA for the pki-fabio mount.\nWould you be interested in a PR with a rough draft for an implementation?. In the \"pki-fabio/issue/example.com\" path, \"pki-fabio\" represents a single CA, and \"example.com\" represents the constraints for issuing certs from that CA, such as allowed domains (what Vault calls a role). . That's exactly what the PR currently implements. If a cert cannot be issued fabio drops the request. There is no default cert because strictmatch is implied with the vault-pki source.. Renewing the token before further API calls are made is fine. Setting renewtoken=7m just ensures that the token is valid for at least another 7 minutes before the certificates are looked up. If the token's TTL is longer than that, nothing happens. What did you expect to happen instead?. Sorry about the commit noise.\n@deuch Mind taking a look at #314? . I should mention that the tests still work with 0.6:\n--- PASS: TestVaultSource (4.55s)\n        source_test.go:304: Starting /home/pschultz/bin/vault-0.6.5: \"Vault v0.6.5 ('5d8d702f33b5fd965cbe8d6d0728295de813a196')\\n\"\n    --- PASS: TestVaultSource/renewable_token (0.76s)\n    --- PASS: TestVaultSource/non-renewable_token (0.60s)\n    --- PASS: TestVaultSource/renewable_orphan_token (0.74s)\n    --- PASS: TestVaultSource/non-renewable_orphan_token (0.74s)\n    --- PASS: TestVaultSource/renewable_wrapped_token (0.93s)\n    --- PASS: TestVaultSource/non-renewable_wrapped_token (0.61s)\nPASS\nok      github.com/fabiolb/fabio/cert   4.555s. The builds failed because of network issues between Travis and HashiCorp:\n\n$ wget https://releases.hashicorp.com/consul/0.8.3/consul_0.8.3_linux_amd64.zip\n--2017-06-28 14:01:50--  https://releases.hashicorp.com/consul/0.8.3/consul_0.8.3_linux_amd64.zip\nResolving releases.hashicorp.com (releases.hashicorp.com)... 151.101.89.183, 2a04:4e42:11::439\nConnecting to releases.hashicorp.com (releases.hashicorp.com)|151.101.89.183|:443... failed: Connection timed out.\nConnecting to releases.hashicorp.com (releases.hashicorp.com)|2a04:4e42:11::439|:443... failed: Network is unreachable.\n\nI don't think I can retry them.. Please take another look. I will fixup into a single commit once you're good with the PR.. Sure, you can add the logo. We don't have an English site you can link to though, only the one in German.. Yeah, that's better. The last if/else statements can even be done with a nice switch. See f6e2463.. I will re-arrange the commits to keep the Vault stuff separate, and at the same time move the StrictMatch check into the config package. While it is nice that this check can now be tested, it also means that it will have to be done for all future Issuer implementations (which is easily forgotten).\nThe store is unaware of any sources (and, in fact, the sources are unaware of the store). The only part that is aware of both is cert.TLSConfig. In my opionion that's a good thing.\nAdding other on-demand sources doesn't require more changes to either the store or cert.TLSConfig, just a new Issuer implementation and config support. I threw together two more examples in this gist - please handle with care; it compiles if you drop it in certs, but I haven't checked it for correctness or anything. One is for the ACME protocol (e.g. Letsencrypt) and the other takes a CA cert file and private key and issues certs directly.\nThe ACMESource in particular would require lots of configuration, and each challenge provider you'd want to support comes with its own rabbit hole, but none of that relates to the store I think.\nBy the way, as far as I know Letsencrypt will only allow one non-revoked certificate per common name at any given time, so it has to be revoked before a new certificate can be issued. If more than one fabio instance serve a domain they have to coordinate accordingly. That's out of scope of this MR though I think.\nIt's apparent to me now that a Store.ReplaceCertificate method would be useful. Then the Issuers don't have to keep track of all the certs they ever issued. Apart from that I don't see any beneficial changes I could make to the store.\n. Rebased on master.. Will do, but not before the 12th because I'm off on vacation.. @Narayanan170, it's documented in fabio.properties.\n```txt\nVault PKI\n\nThe Vault PKI certificate store uses HashiCorp Vault's PKI backend to issue\ncertificates on-demand.\n\nThe 'cert' option provides a PKI backend path for issuing certificates. The\n'clientca' option works in the same way as for the generic Vault source.\n\nThe 'refresh' option determines how long before the expiration date\ncertificates are re-issued. Values smaller than one hour are silently changed\nto one hour, which is also the default.\n\ncs=;type=vault-pki;cert=pki/issue/example-dot-com;refresh=24h;clientca=secret/fabio/client-certs\n\nThis source will issue server certificates on-demand using the PKI backend\nand re-issue them 24 hours before they expire. The CA for client\nauthentication is expected to be stored at secret/fabio/client-certs.\n```. @danlsgiga, judging from the patch in #497, it looks like all you have to do to use the V2 backend is to update your Fabio config from\ncs=<name>;type=vault;cert=secret/fabio/certs\n\nto\ncs=<name>;type=vault;cert=secret/data/fabio/certs\n\nThere doesn't seem to be a change required in Fabio itself.\nUpdate: My test runs were false negatives. There are changes required after all.. This is addressed by #497 and can be closed now.. With this patch all tests passed for me with Consul 1.0.6, 1.0.7, and 1.1.0, so this may fix #494 entirely.. Turns out the API isn't directly backward compatible after all. I amended my commit, so that Fabio detects a v2 backend and modifies Vault requests accordingly. It's not exactly pretty but it works. The new methods are almost verbatim copies from Vault's cli implementation.\nThis makes Fabio support the v2 backend automatically; no config change is required. The Vault policy must be updated, but that's not unique to Fabio. I seem to remember that a working sample policy is documented somewhere (in the wiki perhaps?) but I can't find it right now.\nThe Consul tests failed because your sneaky readiness check stopped working when they introduced gzip support, and I addressed that too.. We are running our fabio instances with periodic tokens, which never expire:\n$ vault token create -help 2>&1 | grep -A3 period\n  -period=<duration>\n      If specified, every renewal will use the given period. Periodic tokens\n      do not expire (unless -explicit-max-ttl is also provided). Setting this\n      value requires sudo permissions. This is specified as a numeric string\n      with suffix like \"30s\" or \"5m\".\nThis is what such a token looks like. Note that the token has been issued much earlier than 32 days ago but the last renewal happened today. Our Vault server uses the standard max_lease_ttl:\n$ vault token lookup -accessor 9f0bbc18-2b02-c936-7a3f-c1b0e2443586\nKey                  Value\n---                  -----\naccessor             9f0bbc18-2b02-c936-7a3f-c1b0e2443586\ncreation_time        1530181359\ncreation_ttl         259200\ndisplay_name         token\nentity_id            n/a\nexpire_time          2018-11-19T02:41:22.742165478Z\nexplicit_max_ttl     0\nid                   n/a\nissue_time           2018-06-28T10:22:39.082648509Z\nlast_renewal         2018-11-16T02:41:22.742165886Z\nlast_renewal_time    1542336082\nmeta                 <nil>\nnum_uses             0\norphan               false\npath                 auth/token/create\nperiod               259200\npolicies             [default fabio]\nrenewable            true\nttl                  234363\nThat being said, supporting AppRoles isn't a bad idea, for flexibility. However I don't have time to work on this myself in the foreseeable future.. That would be great, in particular for setups where fabio runs in a Nomad cluster. Nomad already provides the Vault token in a file (in addition to the environment variable) and updates that file if necessary.. Just discovered this issue too (I assume it's the same). We noticed because our SMTP server seemed to be unresponsive.\nIf the server starts the conversation after a client connects (as opposed to the client sending the first message, which works fine), fabio doesn't send data to the client.\nBoth SMTP and MySQL servers start a connection by sending a banner first.\nHere is my reproducer:\n```go\n// smtp_mock.go\npackage main\nimport (\n    \"fmt\"\n    \"log\"\n    \"net\"\n)\nfunc main() {\n    log.Println(\"Listening on :8025\")\n    l, err := net.Listen(\"tcp\", \":8025\")\n    if err != nil {\n        log.Fatal(err)\n    }\nfor {\n    conn, err := l.Accept()\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    log.Println(\"serving\", conn.RemoteAddr())\n    fmt.Fprintf(conn, \"220 localhost ESMTP Go\\r\\n\")\n    conn.Close()\n}\n\n}\n```\n$ go run smtp_mock.go\n2018/12/06 14:48:42 Listening on :8025\nNext shell:\n$ curl -XPUT localhost:8500/v1/agent/service/register -d@-<<<'\n{\n    \"Address\": \"127.0.0.1\",\n    \"Check\": {\n        \"Interval\": \"5s\",\n        \"TCP\": \"localhost:8025\"\n    },\n    \"ID\": \"09bf6151-243b-487e-a062-ea9741839818\",\n    \"Name\": \"mock-smtpd\",\n    \"Port\": 8025,\n    \"Tags\": [\n        \"dev-fabio-:8026\"\n    ]\n}'\n$ fabio \\\n    -registry.consul.tagprefix=dev-fabio- \\\n    -proxy.addr=':8026;proto=tcp' \\\n    -log.level=TRACE\nNext shell:\n```\nConnect directly\n$ telnet localhost 8025\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\n220 localhost ESMTP Go go1.11.2\nConnection closed by foreign host.\nConnect via fabio\n$ telnet localhost 8026\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\n\nasdf\n220 localhost ESMTP Go go1.11.2\nConnection closed by foreign host.\n```\nThere's nothing interesting in fabio's logs, not even at TRACE level. Git bisect points fingers at a28d24440a78c441e189e90d8671332122fea90f:\n```\na28d24440a78c441e189e90d8671332122fea90f is the first bad commit\ncommit a28d24440a78c441e189e90d8671332122fea90f\nAuthor: Aaron Hurt\nDate:   Mon Feb 12 21:24:00 2018 -0600\nadd basic ip centric access control on routes\n\n:040000 040000 8c2e3c4fd614bac972c3e5cf7f3c5d4403e4b462 3cdbf0b8f4e80bf5a4a0a6567227c936cb0cc77a M      docs\n:040000 040000 e046f4421d2a958f63712cc59a843509ae486d86 5681ab0cef7610c12c29a35a6fb262d856f7a952 M      proxy\n:040000 040000 34db75362cd6f9ab3a9125f8802e32f892bdc678 491cb45fa2072e457fec37e32cdb49cb1ae383b5 M      route\n. Here's a tcpdump. Note the two second gap after the third packet. That's where telnet was connected to fabio, but I didn't do anything. Then I hit enter, and *then* fabio established a connection to the backend.\n15:15:26.826545 IP 127.0.0.1.53618 > 127.0.0.1.8026: Flags [S], seq 2552979650, win 43690, options [mss 65495,sackOK,TS val 3127993891 ecr 0,nop,wscale 7], length 0\n15:15:26.826565 IP 127.0.0.1.8026 > 127.0.0.1.53618: Flags [S.], seq 193147615, ack 2552979651, win 43690, options [mss 65495,sackOK,TS val 3127993891 ecr 3127993891,nop,wscale 7], length 0\n15:15:26.826586 IP 127.0.0.1.53618 > 127.0.0.1.8026: Flags [.], ack 1, win 342, options [nop,nop,TS val 3127993891 ecr 3127993891], length 0\n15:15:28.529959 IP 127.0.0.1.53618 > 127.0.0.1.8026: Flags [P.], seq 1:3, ack 1, win 342, options [nop,nop,TS val 3127995594 ecr 3127993891], length 2\n15:15:28.529988 IP 127.0.0.1.8026 > 127.0.0.1.53618: Flags [.], ack 3, win 342, options [nop,nop,TS val 3127995594 ecr 3127995594], length 0\n15:15:28.530519 IP 127.0.0.1.54084 > 127.0.0.1.8025: Flags [S], seq 2746406685, win 43690, options [mss 65495,sackOK,TS val 3127995595 ecr 0,nop,wscale 7], length 0\n15:15:28.530559 IP 127.0.0.1.8025 > 127.0.0.1.54084: Flags [S.], seq 2444991286, ack 2746406686, win 43690, options [mss 65495,sackOK,TS val 3127995595 ecr 3127995595,nop,wscale 7], length 0\n15:15:28.530587 IP 127.0.0.1.54084 > 127.0.0.1.8025: Flags [.], ack 1, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 0\n15:15:28.530775 IP 127.0.0.1.8025 > 127.0.0.1.54084: Flags [P.], seq 1:25, ack 1, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 24\n15:15:28.530805 IP 127.0.0.1.54084 > 127.0.0.1.8025: Flags [.], ack 25, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 0\n15:15:28.530844 IP 127.0.0.1.8025 > 127.0.0.1.54084: Flags [F.], seq 25, ack 1, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 0\n15:15:28.530846 IP 127.0.0.1.54084 > 127.0.0.1.8025: Flags [P.], seq 1:3, ack 25, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 2\n15:15:28.530898 IP 127.0.0.1.8025 > 127.0.0.1.54084: Flags [R], seq 2444991311, win 0, length 0\n15:15:28.531008 IP 127.0.0.1.8026 > 127.0.0.1.53618: Flags [P.], seq 1:25, ack 3, win 342, options [nop,nop,TS val 3127995595 ecr 3127995594], length 24\n15:15:28.531030 IP 127.0.0.1.53618 > 127.0.0.1.8026: Flags [.], ack 25, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 0\n15:15:28.531097 IP 127.0.0.1.8026 > 127.0.0.1.53618: Flags [F.], seq 25, ack 3, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 0\n15:15:28.531151 IP 127.0.0.1.53618 > 127.0.0.1.8026: Flags [F.], seq 3, ack 26, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 0\n15:15:28.531178 IP 127.0.0.1.8026 > 127.0.0.1.53618: Flags [.], ack 4, win 342, options [nop,nop,TS val 3127995595 ecr 3127995595], length 0\n```. I'll see if I can put together a PoC for automatic detection. \nThat being said, if there is a toggle for PROXY Protocol this enables another use-case: checking that a connection is from a particular proxy (as opposed to a particular client downstream). Not sure how common that is, or if it's ever been asked for, though.\n. armon/go-proxyproto#4 adds a ProxyHeaderTimeout option for the listener. If there is no proxy header within that timeout, it falls back to plain TCP proxying.\nAfter some superficial testing, updating goproxy to at least 49fdb5c and exposing that option seems to be a good compromise. We can have it default to something sensible (say, 5ms), and we can interpret zero or a negative value as \"disable PROXY protocol support\". \nIn addition we shouldn't call RemoteAddr() unless there are access rules defined.\nThis will make fabio work for MySQL in the default configuration, costing a slight increase in connect latency, for exactly those users that use access rules and no PROXY protocol.\nThere is also a chance of subtle breakage by choosing too small a timeout.. If you want to play around, I just pushed to https://github.com/classmarkets/fabio/tree/fix-tcp (classmarkets/fabio@7246b924d892dc146ec0c3c8790045632225e71a). > @pschultz I've invited you to be a collaborator so that we can work on the same branches.\n@magiconair, thank you very much. Would you also add my SSH key, please?\necdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFNuN8ltMS1Eg034DHD0fekzKSkdlzlWeSMbJy/LJxOYEUQMgNdtQ7GzDZUsArTObenJRKMnpyP6I2mcwesw0xM= pschultz. What do the health checks do? Can you share the Nomad job specification?\n\nWhat is registry.consul.checksRequired set to?. @magiconair, yes, looks good to me.. TestGetCertificate isn't failing:\n--- PASS: TestGetCertificate (0.04s)\n\nLook at the test output again, and find out which one is actually failing. Then run it by itself (with the -run flag), and paste the output here.. I can reproduce the failure with Vault 0.9.1 and will look into it. \nNote that 0.9.1 is pretty old. The tests pass with 1.0.2.. With #497 we essentially dropped support for Vault versions before 0.10.1, specifically because we rely on this change to figure out if the secret backend uses the K/V engine in version 1 or version 2:\n\n\nMount information visibility: Users that have access to any path within a mount can now see information about that mount, such as its type and options, via some API calls.\n\n\nGiven that 0.10.1 has been released in April 2018, and 1.0 has been released in December 2018, I'm not convinced that it's worth the effort of making this work. I suggest updating to a more recent Vault version instead.\nIf it's just about getting the tests to pass, you can set VAULT_EXE to specify which vault binary to use. You don't have to replace the system-wide installed vault, if any.\n/cc @magiconair, @leprechau . consul agent -dev binds to 127.0.0.1 only. That isn't reachable for clients in Docker containers unless you use the \"host\" networking mode.. That's an allocation profile, isn't it? The inuse_space profile would be relevant if you're investigating memory consumption.. I cannnot reproduce this on Firefox 65. Are you sure you had scrolled all the way up before taking the screenshot?. Looks good to me.\nIs there any harm in enabling refresh by default, say, every 30 seconds or so?\nIn my experience mtime isn't as reliable as you might expect, especially when network filesystems are involved. How about checking the hash of the file contents instead? A simple ioutil.ReadFile + sha1.Sum should do.\nI also suggest to reload the file on SIGHUP. That helps configuration management software that expects a change to the file to work immediately. That would require an update to the log message in exit/listen.go.. Another thing: currently, if the file is deleted we don't do anything (besides logging a warning). Should we disable basic auth instead (for instance by reloading an empty temp file)?. > As regards to SHA checksum, I think it's a bit overkill to check it every so often so even if there's some delay on NFS etc the file will be re-read whey mtime eventually changes.\nThere are filesystems such as davfs that may not support mtime at all (maybe depending on the server). But I admit that this is an edge-case that is not likely to come up in practice and we can change it if and when it becomes a problem for someone.\n\nFrom the security point of stand removing the htpasswd file should rather fail all login attempts but definitely should not disable auth completely.\n\nThat is what I meant, my wording was a bit misleading. In the current implementation all logins continue to work even after removing the file, because the error is logged but otherwise ignored:\n```\nsh1 $ echo foo:{PLAIN}bar > htpasswd\nsh1 $ fabio \\\n    -proxy.addr=:9999 \\\n    -proxy.auth='name=basic;type=basic;file=htpasswd;refresh=1s' \\\n    -registry.static.routes='service-a /a http://127.0.0.1:8080/ opts \"auth=basic\"'\nsh2 $ curl -u foo:bar -I http://localhost:9999/a\nHTTP/1.1 502 Bad Gateway\nDate: Tue, 05 Mar 2019 11:31:54 GMT\nsh2 $ mv htpasswd{,.off}\nWait for reload and warning messages\nsh2 $ curl -u foo:bar -I http://localhost:9999/a\nHTTP/1.1 502 Bad Gateway\nDate: Tue, 05 Mar 2019 11:31:56 GMT\nfoo:bar still works; expected 401 instead.\n```\n. tg123/go-htpasswd#3 has been merged, so clearing all credentials on error should be as simple as\ngo\nsecrets.ReloadFromReader(&bytes.Buffer{}, bad)\n@mfuterko, do you want to submit a follow-up or do you want me to take care of it?. In the Go client do not add a path when dialing. gRPC will construct the path automatically based on the method call.\nUse\ngrpc.Dial(\"fabio.service.consul:8888\")\n\nnot\ngrpc.Dial(\"fabio.service.consul:8888/some-path\"). Looks good to me. Thank you very much.\n\nNote to future reviewers: the vendored consul and its protobuf dependencies should have changed in 9c1766f993cac563eb603f505eb84ff054523c25 already. Presumably they are updated here now as a side effect of updating github.com/tg123/go-htpasswd.. This does seem to be an issue with Consul, actually.\n```sh\nregister services\nfor port in 31508 31226 31767 31788; do\n    jq --arg port $port -n '{\n        \"Address\": \"127.0.0.1\",\n        \"Port\": $port|tonumber,\n        \"Check\": {\n            \"Interval\": \"5s\",\n            \"HTTP\": (\"http://localhost:\"+$port+\"/smooth\")\n        },\n        \"Name\": \"python-smooth\",\n        \"ID\": (\"python-smooth-\"+$port),\n        \"Tags\": [\n            \"urlprefix-/smooth\"\n        ]\n    }' | curl -XPUT localhost:8500/v1/agent/service/register -d@-\ndone\n```\nConsul logs and UI show four healthy instances:\ntxt\n    2019/03/11 09:39:17 [INFO] agent: Synced node info\n    2019/03/11 09:39:19 [INFO] agent: Synced service \"python-smooth-31508\"\n    2019/03/11 09:39:19 [INFO] agent: Synced service \"python-smooth-31226\"\n    2019/03/11 09:39:19 [INFO] agent: Synced service \"python-smooth-31767\"\n    2019/03/11 09:39:19 [INFO] agent: Synced service \"python-smooth-31788\"\n    2019/03/11 09:39:20 [INFO] agent: Synced check \"service:python-smooth-31226\"\n    2019/03/11 09:39:21 [INFO] agent: Synced check \"service:python-smooth-31767\"\n    2019/03/11 09:39:23 [INFO] agent: Synced check \"service:python-smooth-31508\"\n    2019/03/11 09:39:24 [INFO] agent: Synced check \"service:python-smooth-31788\"\nHowever after deregistering one service, Consul 1.4.3 removes all four checks where 1.4.2 removes only the service:python-smooth-31508 check (as expected):\n$ consul services deregister -id python-smooth-31508\n\ntxt\n    2019/03/11 09:40:31 [INFO] agent: Deregistered service \"python-smooth-31508\"\n    2019/03/11 09:40:31 [INFO] agent: Deregistered check \"service:python-smooth-31226\"\n    2019/03/11 09:40:31 [INFO] agent: Deregistered check \"service:python-smooth-31767\"\n    2019/03/11 09:40:31 [INFO] agent: Deregistered check \"service:python-smooth-31788\"\n    2019/03/11 09:40:31 [INFO] agent: Deregistered check \"service:python-smooth-31508\". hashicorp/consul#5456 fits the bill.. Wrapping is explained in detail here: https://www.vaultproject.io/docs/concepts/response-wrapping.html\nIn short: it may not be desirable to pass an actual Vault token (or any other secret, really) around, especially if it ends up in a file on disk.\nVault offers the possibility to wrap secrets to get around this. Instead of returning the secret directly, Vault creates a so-called wrapping token that can be used exactly once and stores the secret in that wrapping token's cubbyhole. You then give the wrapping token to fabio, and fabio trades it for the actual token. The corresponding CLI commands look something like this:\ntxt\n$ vault token create -policy fabio -wrap-ttl=5m\nKey                              Value\n---                              -----\nwrapping_token:                  s.E0mxDIk9sZBTvDtZXe7ZMH3S\nwrapping_token_ttl:              5m\n[...]\ntxt\n$ vault token lookup s.E0mxDIk9sZBTvDtZXe7ZMH3S\nKey                 Value\n---                 -----\nexplicit_max_ttl    5m\nnum_uses            1\npolicies            [response-wrapping]\n[...]\ntxt\n$ vault unwrap s.E0mxDIk9sZBTvDtZXe7ZMH3S\nKey                  Value\n---                  -----\ntoken                s.Lcxkbr1PYZ5R2chAcALh0XMV\n[...]\ntxt\n$ vault token lookup s.Lcxkbr1PYZ5R2chAcALh0XMV\nKey                 Value\n---                 -----\nexplicit_max_ttl    0s\nnum_uses            0\npolicies            [default fabio]\n[...]\nunwrap returns what token create would have returned if the -wrap-ttl flag hadn't been specified.\nIn this example the wrapping token is revoked after 5 minutes, or after the first unwrap request, whichever happens first. This makes it pretty safe to store it on disk. Even if someone gets their hands on it, it's worthless, assuming they don't beat fabio to the punch.\nThe consequence is that it is not enough to compare the file content with client's token. If the token was wrapped, they will be different. You have to remember the file content separately after a reload and compare against that value.. It is redundant, but it reads as \"one minute\" which I prefer. This is a constant expression that will be evaluated at compile time, so there is no runtime impact. If you insist I'll change it though.. Technically not a race (all reads and writes are inside the lock), but I moved it down anyway to remove any doubts.. s.auth.token will never be empty when the deferred function executes (assuming there is no error). Apparently I made this is too confusing. I think we can use sync.Once to make it obvious. Let my try that.. See 49767dd. The very last entry in this list is new (singleflight), everything else only re-formatted. Did you change the vendor tool?. Does the attribute have to be escaped? What happens if r.dst contains a quote, for instance?.. I suppose this code is already vulnerable to XSS. I'm gonna fix this in another PR.. dst is an arbitrary string from the configuration and may contain <script>evilCode();</script>. But again, I've addressed this in #588, so don't worry about it here.. Do we need two settings here? It seems a non-empty VaultTokenPath is enough to indicate that refreshing tokens from a file is desired.. This should be named vaulttokenpath or vaulttokenfile or something like that, so it doesn't conflict with any future settings (such as a Consul ACL token, for instance).\nAnd a nit: don't put theses cases between cert and key, please. Before or after refresh should be good.. You forgot to set theses fields in the vault-pki case.. The token should only be modified if the file has been read successfully and the token isn't empty after stripping whitespace. Otherwise we should continue to use the existing token I think.\nAlso, when configuring the client with the initial token we support wrapped tokens, but here we don't. We can probably re-use the logic below, but it's a bit tricky.\nWe can reasonably expect that a wrapped token only works once, since that's the whole point of wrapping. In other words, the token stored in the file may be useless after the inital setup, so we can't blindly re-set the token here. We must do that only if the file contents changed, and do the unwrapping step again.. Capitalize Vault, please, and also update the docs for the Vault KV source a few paragraphs above, where it says \"The token must be provided in the VAULT_TOKEN environment variable.\". Any reason to not call strings.TrimSpace here? Some config management tools are finicky about whitespace in their template engines, for instance. Copy-pasting can also easily add whitespace by accident.. nit: Token From File should be lowercase. In the debug message below it should say \"fetched\", not \"fetch\".. ",
    "klpauba": "I know, bad form replying to my own issue ...\nI'm suspecting that the problem is due to my not having a health check for the service ... I'll add that and see if that's it.\n. Doh!  Things are working now as expected.  Thanks @magiconair.  Onward in my fabio training ...\n. ",
    "jshaw86": "thanks!\n. @magiconair we upgraded to 1.5.2 for better TLS+SNI support which we need for one of our backend microservices(SOC Compliance).. @magiconair any idea on effort on this? We are trying to decide whether or not to invest our resources into this issue or not.. @magiconair not urgent enough to warrant doing sick. I'll personally take a look at it in my free time and send a patch if I can solve it until you can get around to it. A few days is fine. Tell alex at hashi Jordan at PubNub says Hi. :). @magiconair have you had a chance to look at this? We're still looking at options outside fabio to work around this but still wanted your thoughts.. ",
    "adersberger": "Sorry, no Fabio issue.\n. ",
    "artburkart": "I'll open a ticket that is relevant to my question then! Thanks :)\n. Not sure where I got the idea that my config was correct, but it definitely was not. This was sufficient:\njson\n{\n    \"service\": {\n        \"name\": \"helloworld\",\n        \"tags\": [\n            \"urlprefix-/hello\"\n        ],\n        \"port\": 80,\n        \"check\": {\n            \"http\": \"http://localhost\",\n            \"interval\": \"10s\",\n            \"timeout\": \"1s\"\n        }\n    }\n}\nThank you for your assistance. The fact that the ServiceId was not being defined was because my config was no good. By default, it takes the value in the name field, but I must've fallen into some \"undefined behavior\" land.\n. ",
    "lennart": "I just stumbled upon this issue since I had a space within the consul service name. I wasn't expecting fabio to use the service name for route add. Service ID and check ID were unique (and without spaces).\nMaybe this should be noted within the Quickstart?. ",
    "devsprint": "You can use the environment variable when you run the container as:\n-e SERVICE_TAGS=urlprefix-/burrow\nRegistrator will add it to tags entry into service definition in consul.\nFabio will build the route automatically if there will be a health check also configured for the service.\n. you can specify it in docker compose file as:\n```\nburrow:\n  environment:\n    - SERVICE_TAGS=urlprefix-/burrow\n```\n. @magiconair the env should be passed to the service (the docker image that will be register by registrator) and not to registration itself. \nI guess that you should mention that using a label instead of env variable also will work with registration.\n. @magiconair Let's say that you have the service test/foo that you want to get register by registrator in consul.\nFirst, you have to make sure that you are running the consul agent on the machine, than start the registrator, after you can run the foo/bar service as:\n```\n$ docker run -d \\\n    --name=registrator \\\n    --net=host \\      \n    --volume=/var/run/docker.sock:/tmp/docker.sock \\\n    gliderlabs/registrator:latest \\\n    consul://localhost:8500\n$ docker run -d -p 8000:8000 \\\n  -e SERVICE_8000_CHECK_HTTP=/foo/healthcheck  \\\n  -e SERVICE_8000_NAME=foo \\\n  -e SERVICE_CHECK_INTERVAL=10s \\\n  -e SERVICE_CHECK_TIMEOUT=5s  \\\n  -e SERVICE_TAGS=urlprefix-/foo \\\n  test/foo\n```\nThis example shows how to specify the url prefix and the http health check for a service, both of them are required to have fabio route traffic to the service.\n. @magiconair LGTM excepting the port binding. I have edited my reply just to avoid confusion.\n. @pdoreau sure but this is a decision that the developer may take. there will be services where you must bind to a specific host port.\n. ",
    "pdoreau": "Thanks I'll try that. How should I handle this in my local computer for development ? Should I specify the tags through Docker compose file ?\n. Alright. It would be usefull to update the documentation with such an example.\nAbout AWS, why does the demo file doesn't show any inclusion/execution of Registrator ?\n. Alright thanks but is port 80 param useful ?\ndocker run -d -p 80:8000\nAs consul provide us the host port number when needed, It would be better to let docker choose it\ndocker run -d -p 8000\n. ",
    "maier": "just discussed a shim approach which sounds like it will solve the issue. if there is a metric interface in fabio itself then swapping out backends which want/support full raw measurement values will be easier.\n. Cool, thanks, I'm working off that branch to do an integration.\n. I'll pull down the latest commit and check it out to see what the delta is between what I've got working and the updated method. Ok, I think this will still work. I'll reorganize what I have and kick the tires.\n. I just pulled down master, rebuilt and tested. It works, I like the addition of the status code histograms.\n. Circonus doesn't keep a persistent set of metrics in memory (like gometrics does). The metrics are flushed after each submission. If a given metrics stops being used, it would no longer be sent to Circonus. Which is also why things like Percentile and Rate1 are not applicable.\n. ok. so what you want is:\ncommit vendor.json and all vendor source updates as \"Vendoring github.com/circonus-labs/circonus-gometrics plus dependencies\"\ncommit with just my changes to source tree\npull request\n. ```\nmetrics.circonus.apikey configures the API token key to use when\nsubmitting metrics to Circonus. See: https://login.circonus.com/user/tokens\nThis is required when ${metrics.target} is set to \"circonus\".\n\nThe default is\n\nmetrics.circonus.apikey =\n. that's the one setting which is required, the rest are optional.\n. testAll actually _does_ the job, it connects to the api and performs all of the steps. verification is two-fold, if the code fails and then checking manually in the UI for the metric coming through. the code will fail in finding/creating the check, then i go over to the ui and verify that a) the fake metric was created and b) a submission came through for it. it's gated by the env vars so that it doesn't thrash the checks.\n. go\ntype cgmCounter struct {\n    metrics *cgm.CirconusMetrics\n    name    string\n}\nfunc (m *cgmRegistry) GetCounter(name string) Counter {\n    metricName := fmt.Sprintf(\"%s`%s\", m.prefix, name)\n    return &cgmCounter{m.metrics, metricName}\n}\nfunc (c cgmCounter) Inc(n int64) {\n    c.metrics.IncrementByValue(c.name, uint64(n))\n}\n```\n. Since template.Execute() can return an error, what are your thoughts on what TargetName should return? An error or have a backup default action if the template execution fails? Or, are you thinking about putting together a more generic set of template handling helper functions? \n``` go\npackage main\nimport (\n    \"bytes\"\n    \"fmt\"\n    \"log\"\n    \"net/url\"\n    \"strings\"\n    \"text/template\"\n)\nvar routeMetricNameTemplate *template.Template\ntype routeMetricNameAttributes struct {\n    Service, Host, Path string\n    TargetURL           *url.URL\n}\nfunc clean(s string) string {\n    if s == \"\" {\n        return \"\"\n    }\n    s = strings.Replace(s, \".\", \"\", -1)\n    s = strings.Replace(s, \":\", \"_\", -1)\n    return strings.ToLower(s)\n}\n// TargetName blah\nfunc TargetName(service string, host string, path string, targetURL *url.URL) (string, error) {\n    var metricName bytes.Buffer\n    data := &routeMetricNameAttributes{service, host, path, targetURL}\n    err := routeMetricNameTemplate.Execute(&metricName, data)\n    if err != nil {\n        return \"\", err\n    }\nreturn metricName.String(), nil\n\n}\nfunc main() {\n    funcMap := template.FuncMap{\n        \"clean\": clean,\n    }\n    nametemplate := \"{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.{{clean .TargetURL.Host}}\"\n    routeMetricNameTemplate = template.Must(template.New(\"routeMetricName\").Funcs(funcMap).Parse(nametemplate))\n    service := \"hashiapp\"\n    host := \"hashiapp.com\"\n    path := \"/\"\n    target, err := url.Parse(\"http://10.1.2.3:12345\")\n    if err != nil {\n        log.Fatalln(err)\n    }\nmetricName, err := TargetName(service, host, path, target)\nif err != nil {\n    log.Fatalln(err)\n}\n\nfmt.Println(metricName)\n\nnametemplate = \"{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.latency_ns\"\nrouteMetricNameTemplate = template.Must(template.New(\"routeMetricNameCustom\").Funcs(funcMap).Parse(nametemplate))\n\nmetricName, err = TargetName(service, host, path, target)\nif err != nil {\n    log.Fatalln(err)\n}\n\nfmt.Println(metricName)\n\n}\n``\n. cool, yeah, agree on the pollution, soTargetName(...) (name string, error err)`. \n. Updated to use text/template. Hoping it might be close enough to make it easier for you to shuffle it around the way you'd prefer. The main things I wasn't sure about are handling of the return from TargetName in route.go and where I put the template verification.\n. Yeah, that's good, cleaner. \n. Similar situation to the one we faced with the Circonus integration. The receiving system (Circonus, StatsD, etc.) need the individual samples for metrics not a single value from the registry.. ok, will change.\n. Added a default for CirconusAPIApp to defaults. I reworded the description of the API URL parameter, I'd prefer to keep that default localized in the library so that if it changes there isn't a waterfall of PRs to update.\n. doh! yeah, good catch, thanks.\n. ",
    "guidob": "Using -registry.consul.register.enabled=true  does work. Is this behavior intended? You have to use = when using a boolean? -ui.addr :8080 works fine without =.\n. Ah, I should've searched a little bit more. Thanks for clarifying and the prompt reply.\n. No worries, thanks for the heads-up. Enjoy the remaining of your vacation!\n. Thanks for diving into this, no ugly patching needed. :) This was found during testing 100+ nodes. But don't hesitate to ping me if I can help testing.\n. Canary releasing support in fabio sounds like a really useful feature to us as well.. ",
    "silentred": "using k8s as a registry would be the ideal way to do it. . @Bregor  good idea. I did a little searching, and found this nginx reverse proxy, which just keeps querying Ingress resource to reload nginx for load balancing.. Thanks. Another problem is ReverseProxy returns 502 without body to the client. I am hoping to customize the body according to each err type. It seems I have to copy ReverseProxy and make my own version. I wonder if there is a simpler way to achieve that. . I guess I found a work-around. Replace the out writer of ErrorLog in ReverseProxy with a custom one, which writes a JSON format body to the client. I am working on it.\nUpdate:\nIt works fine for me.. ",
    "Bregor": "\nGot an idea where the meta-data can be stored (e.g. host/path and other options) Couldn't find something suitable in the k8s AP\n\n@magiconair, maybe you should look at the ingress?\nExample for host/path:\nyaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: test\nspec:\n  rules:\n  - host: foo.bar.com\n    http:\n      paths:\n      - path: /foo\n        backend:\n          serviceName: s1\n          servicePort: 80\n      - path: /bar\n        backend:\n          serviceName: s2\n          servicePort: 80. Main problem (for now) with ingress is TLS. You can use tls section only once before any host sections, so you automagically lost tls-sni support.. ",
    "taemon1337": "I am looking at doing an abbreviated integration with Kubernetes (specifically only the TCP+SNI) portion and letting Kubernetes handle the health checking.  I am just trying to implement a custom Backend that will retrieve a list of all Kubernetes services from a REST url and inject those service routes into Fabio's routing table.  I'm not very good with go.\nIt looks like Fabio stores it's configuration in Consul's KV store, is that right?  Why does it do that, since isn't it building the config dynamically using Consul services?\n(should we take this offline?)\n. Yes, I'm currently working on adding a Kubernetes backend, though because Kubernetes itself handles health checking and service discovery, the only func I think I need to implement is the WatchServices.  \nIf I understand how Fabio works (and this is my question), can I just implement WatchServices such that each Fabio instance gets the list of services directly from the Kubernetes API and adds a route for each service?  Or will it break Fabio to not implement the other functions?\nMy use case is limited to TCP+SNI only, so all my solution really needs to go is route \n{service}.{namespace}.{external-domain-name} --> {service}.{namespace}.{kubernetes-internal-domain} \nKubernetes will then route each service to the actual pod(s).\n. From the k8s api, '/api/v1/services'\nhttps://kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#list-all-namespaces-173\nand here is the watch endpoint (i was going to start by just polling the above):\nhttps://kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#watch-list-all-namespaces-176\n. So I've got a very basic version working (https://github.com/taemon1337/fabio-k8).  There is a readme in the registry/kubernetes which kinda explains it, it still allows k8 to do the service discovery and health checking as fabio just routes external traffic to k8 services.. I think this is a valid use case, for me as well. \nSome clients/services that are using the fabio load balancing may want to use its HTTPS termination for free while others may want TCP+SNI for end-to-end encryption with their own certificate.\np.s. great work on fabio!\n. Duplicate of https://github.com/fabiolb/fabio/issues/169\nThe tcp+sni is an awesome feature which is one of the reasons we are looking to use fabio for client load balancing, and would definitely like the flexibilty to choose tcp+sni or https termination.. Don't forget the TLS client authentication information like Common Name. Nevermind, that did seem to work, I just needed double quotes for opts, not single, sorry\n. I looked at the examples in 'route/parse_test.go' as well as the 'Config Language' section on the site and couldn't find any example with tcp+sni, it was pretty obvious and I got it myself, mostly just my newness with go I think, but you could always add the above to parse_test.go if you wanted.\nBtw, I'm testing my Kubernetes backend shortly. Crap!  So I can compile fabio just fine and I can build it using the provided Dockerfile, but it does not execute inside that container, it always says:\nstandard_init_linux.go:187: exec user process caused \"no such file or directory\"\nyou ever seen this before?  Do I need to use the 'Makefile' to build the container or something?\n. I think this is my problem: http://blog.xebia.com/create-the-smallest-possible-docker-container/\nthanks, I should be able to get it working.. Sweet!  That blog post got it.  I compiled like this:\ndocker run --rm -e CGO_ENABLED=0 -v $(pwd):/go/src -w /go/src golang:1.9.3 go build -a -ldflags '-s' github.com/fabiolb/fabio\nThe CGO_ENABLED=0 forced Go to compile all deps (not cgo) and the ldflags reduced the image size to 7.5M\n. ",
    "wstaples": "Thank you for the fast response! I would not consider this issue a roadblock. For simplicity sake I'm likely going to force all api servers to handle all versions anyway. This only becomes an issue if a second version of the API actually existed. Again thank you for the fast response. \n. ",
    "rgardam": "Ok thanks for the feedback! :)\n. ",
    "igorwwwwwwwwwwwwwwwwwwww": "Awesome, thanks for the quick response and fix! \ud83d\udc96\n. ",
    "pangzheng": "For example: the deployment of the three consul master the same number of fabio nginx, fabio front is haproxy, close one consul.\nhaproxy on fabio node is still 3, but has been working error exception. (Unable to service discovery)\nNow think of ways to haproxy background set consul dns resolve exceptions fabio problem.\nThis deployment scenario is right? @magiconair \n. @magiconair \nThank you for your answer\u3002\nHow to set up a backup consul agent in fabio?\n. @magiconair \nThanks\nSetting a consul two health in a service, a health check is exception.\nWhy fabio this service is normal?\n\"checks\": [{\"id\": \"chk-borg-'${IP}'\", \"http\": \"http://'${IP}':5013/v1/health\", \"interval\": \"10s\",\"timeout\": \"1s\"}, {\"id\": \"chk-fabio-'${IP}'\", \"http\": \"http://'${IP}':9998/health\", \"interval\": \"10s\",\"timeout\": \"1s\"}]\n. ",
    "dcparker88": "\nI need to double check but AFAIR fabio will not update the routing table when the local consul agent is down. It will just continue to serve traffic with the last known good routing table.\n\nI've been doing some testing here, and it seems like Fabio starts to 404 every route if we disable the local consul-client. Is there a way to cache the latest routing table in Fabio, or could I be doing something wrong with my test? I would expect Fabio to not add/remove routes at all if the local consul connection is down . yeah - we'll take a look (sorry for late response, was on vacation). ",
    "killcity": "In it's simplest form:\nhttps://help.datadoghq.com/hc/en-us/articles/206441345-Send-metrics-and-events-using-dogstatsd-and-the-shell\nI also found a dogstatsd client written in Go.\nhttps://github.com/ooyala/go-dogstatsd\nInstead of having a bunch of metrics named explicitly per consul agent, we would have them sending with the same metric name and use tags to identify host, etc.. I found one written by Datadog themselves. \nhttps://github.com/DataDog/datadog-go/tree/master/statsd https://github.com/DataDog/datadog-go/tree/master/statsd\nI\u2019m pretty certain this supports traditional statsd as well as extended tagging support for Dogstatsd users. I will confirm with Datadog.. To my chagrin, it doesn't support standard statsd. The datagram format is different.\nhttp://docs.datadoghq.com/guides/dogstatsd/#datagram-format\nI'm discussing some plausible solutions with a couple other engineers.\n. The reporter you might be looking for? \nBoth of these look like they woud do the job: https://github.com/ooyala/go-dogstatsd and https://github.com/DataDog/datadog-go .\nI'm a hack of a Go dev :) Perhaps if you have the cycles you can try? Thanks again for all the hard work on this project. Looking forward to pushing some serious traffic at a tier of Fabio LBs!\n. That sounds fantastic. Thanks!\n. Same here. I think we would want to auto publish the following tags (which would be used in conjuction with the paths that appear in Datadog):\nservice:\ncode:\nurlprefix:\nand the following paths:\nfabio.http.status.code\nfabio.http.request.count\nfabio.http.request.min\nfabio.http.request.max\nCan you guys think of any others? Does this make sense? One thing I'm not totally sure of is if we want to use:\nfabio.http.status.code\nWe would need to auto publish all the various response codes along with the ones listed above sans \"code:\".\n. Sorry for the long delay. Yes, I am also in favor of pushing the status code as a separate tag. Thanks for working on this one.. I am also wondering if this will eventually be supported. Static would be fine on my end.\nCheers. Thanks for posting this bug :) I'm going to be rolling out a single urlprefix to more than 100 nodes, relatively soon (production).\n. @magiconair Any idea when this might be resolved? I know you've been all over the place :) We will be rolling out to a couple hundred nodes sometime in Jan/Feb timeframe.\nCheers. @magiconair Thanks! . Thanks Frank. It does. In order for my Datadog graphs to auto add/remove nodes from our aggregate graphs, it will need to be done with tags (since each metric reported through the standard namespace is slightly different). Definitely looking forward to tagging support for Datadog. \nWe should be putting Fabio into production soon, in multiple datacenters. Looking at some serious req/s. Mostly all very short lived sessions.\nCheers. You are too quick :) I will give this a go in the morning (here in the US northeast). Thank so much for working this in. Super awesome!. Wasn't sure if this was one of the failing tests? TBH, I haven't compiled much in Go. \n~~~~5 errors occurred:\n--> linux/amd64 error: exit status 2\nStderr: # _/root/gopath/fabio-drop-privs\n./main.go:50: cfg.Username undefined (type config.Config has no field or method Username)\n./main.go:100: cfg.Username undefined (type config.Config has no field or method Username)\n./main.go:102: cfg.Username undefined (type config.Config has no field or method Username)\n./main.go:145: cfg.Username undefined (type config.Config has no field or method Username)\n./main.go:147: cfg.Username undefined (type *config.Config has no field or method Username)\n...\n~~~~. Thanks. Going to beat her up a bit! :)\nfabio     5850  0.8  0.0 583664 20184 ?        Ssl  11:44   0:00 ./fabio-1.3.5-branch_195 -cfg /etc/fabio/fabio.properties. Update: No issues. Been running with this since Dec 1.. This only works on Linux, correct? I would think it would still be nice to have the functionality regardless of operating system, although it does add some slight overhead.. Cool. I figured most modern unix variants have something that can accommodate. \nThoughts on whether this should or shouldn't be built into the app?. Yah, precisely. Looks like you read my comment before I edited with examples. You're too quick. :). Thanks again. Need to learn Go for 2017 so I can contribute :). +1. +1. You should be able to see the services listed in the Fabio UI (:9998), assuming you have set proper urlprefix tags on the agents advertising your services.\nFabio will connect to the API via local agent. It doesn't have to be running on a node with server running. An agent running in client mode is fine.\n. @kostyrev This can be easily stripped out using regex. All config mgmt tools offer some way of parsing these filenames and extracting whatever you want to remove/variable-lize. . Go version is set to a specific var in my playbooks and I drop that in the filename. Are you blindly wanting to download the latest version without respect to changes in Go versions and the version of Fabio itself?. cs is where you declare the cert store name.\nproxy.cs is where you point to a specific cert store with respective type and path, if using a path. \nHere's an example.\nproxy.cs = cs=my-certs;type=path;cert=/opt/fabio/ssl;refresh=3s. This was for an existing service. Would it be relatively easy to enforce better strictness for the route format? Maybe fire off something in the logs showing:\nBad route format: route weight xxxx xxxxxxx, route table not modifed . ",
    "aporcano": "Hey folks, is there any news on this functionality? \n. ",
    "jippi": "Any love for this? :D. @magiconair Yep, I can test! :). I've written up a small statsd proxy that can convert fabio statsd path into tagged metrics; https://github.com/bownty/statsd-rewrite-proxy :) . @magiconair for me the tags would be per route, ala https://github.com/bownty/statsd-rewrite-proxy/blob/master/rules.go#L5-L7 . tagged metrics is a bit tricky, since they also require the actual statsd path name to change, for it to make sense within UIs like datadog\nupdate\nnot sure if its relevant in this project or upstream somewhere, but while writing the tool I noticed the following (invalid) metric being exposed\nfabio.--admin-demo.example.com./.192.168.1.100_38473.mean:%!|(float64=0)gf`\nlooks like the float is badly encoded \n. @magiconair for tagged metrics to be useful inside datadog UI, the path need to be \"tag\" less.\ne.g. fabio.http.status.{code} make sense to emit as fabio.http.response_code \nthen in the UI you can select fabio.http.response_code in the UI and group by the {code} (as its emitted as a named tag code:200 example, and use these tags as facets.\nSo for me, tagged metrics is about a new path structure where the \"value\" from the normal statsd path is moved into named tags code:200 or service:example-service - that structure works really really well inside datadog - datadog docs; http://docs.datadoghq.com/guides/metrics/#tags. :+1: on this, for my case static headers would also be sufficient :). Well, static was a lie...\nMy usecase is proxy_set_header X-Request-Start \"t=${msec}000\"; from nginx. which is needed by https://docs.newrelic.com/docs/apm/applications-menu/features/configuring-request-queue-reporting to monitor routing latency :). where is this ticket in the OSS pipeline @magiconair ? :) . the use-cases i've had multiple times is only allowing pure forwarding of headers - by whitelisting -\nnot injecting anything new :). A gentle bump to this issue, any 2017 / 2018 timeframe @magiconair ? :). amazing @magiconair & @wv-myoung !. ",
    "csawyerYumaed": "or authenticate against vault auth directly. Then you can get LDAP or user/pass/etc auth \"for free\" as it were, without having to bring in all the LDAP libs directly into fabio.  Bonus would be getting assigned vault policies to decide if they have access or not.. I'm ok with what @leprechau is saying:\n\nMaybe it could be: auth=vault:method:path:arg1=val1:arg2=val2:arg3=val3\nExample for github to keep config short: auth=vault:github:auth/github/foo:token=xxxx\n\n\nBut it would be super awesome if we could also say this vaultRole(which is returned as part of the token JSON after auth) can access or not.\nauth=vault:method:path:roles=roleName1,roleName2:arg1=val1, etc.\nSo in this example you must have either roleName1 or roleName2 (as defined in vault) AND properly authenticate to get passed on.\n. I'd love to see prom support, but in the meantime you should be able to work-around it with statsd in fabio and https://github.com/prometheus/statsd_exporter. You have to download the binary, or build it yourself.  releases (tarball's and binaries) are available from the releases page:https://github.com/fabiolb/fabio/releases\nthe ./server in the quickstart is a demo server, you would need to compile that yourself, the source is here: https://github.com/fabiolb/fabio/tree/master/demo/server\nAlternatively, use your own service, something you want to run behind fabio.. number of connections and tx & rx would be good.. Hi sorry, I somehow missed this back when.  This looks fine for me.  We can group by server.1234.* to count total traffic in/out.  Thanks!. ",
    "nmaludy": "+1 for some sort of auth on routes, i really like the vault integration idea!. @leprechau Yeah i think something along the lines of:\n```\nauth : the name of the auth provider in the config (for things like secrets and htpasswd paths)\ntype : what type of auth backend this is (vault, basic, digest)\npath : this is vault specific, maybe it makes sense to have this in the config?\narg1=value1 : Backend specific key/value pairs to set in the auth request API call (for Vault) or maybe username=myuser for basic auth\nauth=myvault:type=vault:method=ldap:path=ldap:arg1=value1:arg2=value2\n```\nThinking the Vault token should probably be stored in the Fabio config instead of the route tags.\nAlso probably makes sense for basic auth to store the local path of the htpasswd file in the Fabio config?\nJust brainstorming here.. I agree with @magiconair \nSort of what i envisioned was the following (taking after the existing proxy.cs pattern)\nConfig - /etc/fabio/fabio.conf\nproxy.auth = auth=myvaultname;type=vault;method=ldap;path=myldappath;token=xyz123 \\\n            auth=mybasicname;type=basic;file=/etc/fabio/htpasswd\nService Definition - /etc/consul/myapp.json\n{\n  \"services\": [\n    {\n      \"name\": \"myapp\",\n      \"tags\": [\"myapp\", \"urlprefix-/myapp proto=https tlsskipverify=true auth=myvaultname\"],\n      \"address\": \"\",\n      \"port\": 443,\n      \"enable_tag_override\": false,\n      \"checks\": [\n        {\n          \"tcp\": \"127.0.0.1:443\",\n          \"interval\": \"10s\",\n          \"timeout\": \"1s\"\n        }\n      ]\n    }\n  ]\n}\nI haven't decided yet if the auth reference should be on the route tag, or in the config file. My only concern with having it on the route tag is: what if multiple instances of a service have conflicting auth references?. @magiconair That's a very good point! Like you said the application deployment should be consistent via a Config Management tool or identical settings in your docker image(s). Also, your point about migrating to a different auth source is an interesting use case.. Here is the reference HAproxy configuration https://github.com/zalando/patroni/blob/master/haproxy.cfg  . ",
    "tholu": "Basic support for a consul stored htpasswd/htdigest file would be very nice and a good simplification before LDAP/Vault support.. ",
    "danilobuerger": "I would say this should be static only\n. ",
    "bkmit": "@magiconair: We also need this facility for modifying response headers. \nAnd using logging formatting facility will allow send dynamic headers.\nIMHO: Headers modification need to be happen after request processed by upstream before sending response to client.. @magiconair We use nginx (and we want to get rid) for adding Access-Control-*, Public-Key-Pins headers with different values depending on route. Also I want to add X-Request-Id generated by fabio and maybe others to response for debug/investigation purpose.. @leprechau FYI: Proxy protocol for outgoing connections implemented on PR #598. Wow! Great research! I'll definitely use fastest library.. @magiconair Do I need to make some more improvements?. @magiconair Many thanks for your patience! This was my first public golang development (micro) project!. Made changes you suggest.. Fixed.. Shortened option name. Logging can be made by using $header.ConfiguredHeaderName format already present in fabio.. I have did it in separate function because it need HTTPProxy, which is not available in addHeaders.\nChanging addHeaders signature lead to massive change of it unit tests.\n. ",
    "mafonso": "I'm looking at fabio to replace a consul aware openresty setup. \nI would love to have the ability to inject headers (static at least) in order to be able to replace my custom gateway.  Similar use cases as described above. CORS handling included. \n. ",
    "thijs": "I like the idea of add and delete (set could just be delete and add, right?), but currently my main issue is adding a static header to the request that is passed on. ",
    "samm-git": "Adding my use-case, as suggested in https://github.com/fabiolb/fabio/issues/528\nI would like to remove some of the custom headers added by my load balancer to not expose their values to the registered services. In my configuration it would be enough to set value of this headers globally, but probably per-route configuration could be even better. I see exactly same issue in our env. We have about 12 fabios and sometime (not often) one of them stalling on update. To detect this i wrote a flapping service and checking for the [INFO] Config updates every few minutes. This allows me to detect this easily. It happens ~once a week, so not very easy to reproduce.\nIn my env fabio 1.5.8 is connected to the local consul 1.0.2. At the time of checking consul agent looks healthy and contains correct routing. May be it would be possible to add some kind of watchdog feature which would trigger reconnect to consul in case if updates are not received for > n minutes? . @magiconair i think we can try to build a patched version to see if it helps. Only problem here is that we will have to wait few weeks to see if it solves the issue. . @magiconair not sure if proposed workaround will change anything. From the consul doc:\n\nIn addition to index, endpoints that support blocking will also honor a wait parameter specifying a maximum duration for the blocking request. This is limited to 10 minutes. If not set, the wait time defaults to 5 minutes. \n\nSo it should be already set to 5 minutes. And i saw fabio-s hanged in \"no-updates\" state for at least few hrs. This makes me thinking that consul update thread is just hanged in that case.. Ok, i got this problem again. Fabio been not updating configuration. At the same time there was another instance on the same vm which was working just fine, so unlikely to be a consul problem. \nI terminated it with a SIGTRAP command to get the trace. After restart it starts to work fine again. Trace is available at https://gist.github.com/samm-git/23963653d57045218a00564184f0647f. @magiconair hi, thank you for review! it is already in this PR if i understand you properly - https://github.com/fabiolb/fabio/pull/531/files#diff-b10f488af9bd0792cae6f6d2280472dc. @magiconair hi, do you have any updates? Would be great to see it merged.. @magiconair ping again :). @magiconair any chance to see it merged?. ",
    "danlsgiga": "I'd like to be able to remove response headers as well like \"Server\" or \"X-Powered-By\" added by some servers.. I'm also noticing lots of context cancelled messages in the error log and they are mostly correlated with requests being logged with Response 502 in the access log.\n@magiconair do you know if the context cancelled error can be causing lots of 502 in our access logs and why? I've done some research and people have this issue in the Caddy proxy server as well and it seems to be related to clients closing the connection prematurely.\nFrom my understanding, 502s should be thrown only if Fabio is unable to connect to upstreams which I believe is not the case in our environment.\nReference\nhttps://caddy.community/t/error-context-canceled/2034\nhttps://github.com/mholt/caddy/issues/1345\nhttps://github.com/mholt/caddy/issues/1925. Hey @magiconair, thanks for the quick follow up.\nSo, I'm getting lots of log entries with:\n2017/09/06 14:45:07 [INFO] consul: Health changed to #10372843\nI understand fabio should not be logging that much but it is and as you mentioned, how can I understand the above log message without more details? These details would usually be provided by a lower log level like DEBUG or in the worst cases even TRACE. And the option to be able to silence those in case I need for could be available for greater control.\nIMHO having the runtime configuration dumped into the logs are not great as well. A better approach imo would be to provide an authenticated api endpoint where we could grab that. In our case, since we have central logging, the runtime configuration is readable by a lot of people and that include IP addresses and even consul tokens. If that's not going to change, I think obfuscating those sensitive data should be something to think about.. Hi @magiconair, thanks for the great insight! I'll surely look into my consul environment and check what is causing so much flaping on the health checks.\nReally appreciated for the effort on making fabio even more awesome!\nSo, if the runtime config is being dumped into the logs and this is being centralized in our environment... having the consul IP address and the token there is pretty much giving access to your whole consul infra. Hence my request to have log verbosity since it is the most common way of controlling what goes or not to the logs.\nHaving the default logging at INFO is totally fine and I encourage it actually, but at the same time having the ability to choose the log level would be great. . IMHO, not in the scenario where someone uses consul in an acl_default_policy = \"allow\" setup.\nMy position towards this is that dumping any configuration (even the ones with no secrets) should be seen as bad practice and discouraged. Configuration should never be dumped into logs for the same reasons Stack Traces should never be exposed to users. Simply because it may or may not contain sensitive data.. Hey @magiconair, was this impacting Fabio not logging 502s? I've noticed that any release after 1.5.8 I'm getting 502s in the logs when I was not before.. Hi @pschultz, yeah, before submitting the issue I've tried Fabio with the newer path structure used in v2 but it didn't work. Thanks for looking into it though!. ",
    "mildred": "Sorry, I didn't explain correctly.\nThere are two use cases:\n- public port 443, HTTPS\n- fabio SNI+TCP proxy\n- private service, HTTPS, random port\nand\n- public port 443, HTTPS\n- fabio HTTPS wrapping\n- private service, unencrypted HTTP, random port\nThere is no plain HTTP on port 443.\n. To know if a private service is talking HTTP or HTTPS, we could define a consul tag that would let us differentiate between the two. For example, if a service is registered in consul with the tag ssl, then fabio wouldn't try to find a certificate for this service and forward the whole TCP stream. If the tag ssl is absent, then fabio would manage the encryption with the external client and talk unencrypted with the internal service.\n. > The problem is that in order to distinguish TCP+SNI from HTTPS I can only look at the hostname to make the routing decision since for TCP+SNI I cannot decrypt the traffic.\nCorrect\n\nIn that case you could just setup two listeners on fabio for two different ip addresses for the two hostnames\n\nThe problem is in case the two hostnames are linking to the same public IP. That's the main use case of virtual hosts, saving on public IPs.\n. correct\n. As I said, the IP address is public and I only have one.\nBit it is still possible to have another frontend that does this. This is what I am currently doing, especially considering I also need to add basic authentication for some endpoints. Currently, I am using haproxy where I generate automatically the configuration file\n. Perhaps I'm trying to use fabio for something it is not designed for. My setup is only a single physical server. No VM, no infrastructure as code here. Deployment is manual. The system boundary is the physical machine itself.\nIf you say this is out of scope for fabio, I would completely understand, even though I would expect this to be useful for some other use cases.\nI also know infrastructure as code is very interesting, but I'm not using it where it matters. I much prefer small systems owned by the people themselves instead of relying on third party services.\n. Yes, it would work, but it would impact outside of the system boundary (need to allocate and route another IP address, and leak internal details to the DNS zone). Having a HAProxy configured to distinguish between the hostnames that it needs to encrypt itself and the hostnames that it forwards with the SSL layer intact is also a good solution that I prefer since it impact less outside of the system boundary.\n. Yes, but I checked again, and I cannot reproduce it with JavaScript enabled. However with JavaScript disabled, I have this problem.. ",
    "OursDesCavernes": "Hello, i'm trying to reopen this issue for a different use case.\nI've setup a fabio and try to have SNI and HTTPS on the same port.\nThe idea is that some micro services are served only with FQDN (myservice.domain.com) so SNI is OK for that, and some have path based routing (api.gw.com/locate/v1 or api.gw.cm/deal/v1.2 etc ...)\nI can not use both of those system with fabio because SNI take the lead above HTTPS. So i need 2 ports to do that and it's not so easy because developpers need to know the ports of the fabio. I would prefer to use the 443 for the both (like a nginx or haproxy).\nIs it possible to fabio to check the table a little differently : If fabio has a request, check the SNI hostname, if you find a exact match, do with SNI and if not, check the global url to find match\nexample : \nsrc : tomcat.demo.com/ dest : http://192.168.1.2:32225 --> with SNI\nsrc : tomcat.demo.com/book/v2 dest : http://192.168.1.2:32225 --> Classical https\nsrc : api.demo.com/locate/v1 : http://192.168.4.2:17554 --> Classical https\nOne other thing, if i use the same port for HTTPS and SNI and set proto=https and tlsskipverify=true, SNI is used rather that HTTPS and HTTPS upstream ...\n. ",
    "Salmondx": "@magiconair Thanks for review!\n1. Ok, i'll fix this and make a separate PR.\n2. Hm, static route is not a solution for me. For example, in my company we register legacy soap services as services on external node. So, node test has lots of services and its not possible to describe them in external config file, especially when fabio doesn't support dynamic config reload.\nMay be there are another solution for my problem?\n3. Ok, it'll be really cool feature!\n. @magiconair they are registered in consul on external node.\nE.g. soap-services node has several registered services. But there is no possibility for us to register healthcheck cause they doesn't provide such endpoint.\n. I cant, cause consul api doesn't return services without registered health checks through /v1/health/state endpoint that used in fabio.\n. It's a third party services and we have no control over them and no fallback is possible. Like in consul doc's, external node points on google service :)\n. With service you also register a healthcheck, and in my case its not an option:\n\"Check\": {\"HTTP\": \"http://91.195.49.34/\", \"Interval\": \"15s\"}\n. Because a fake healthcheck is a work around, and external services shouldn't be monitored cause you can't change anything if they fail. For example, if i have a google as external service, i should also use an http health check and add unnecessary load on my consul cluster? May be i'm wrong.\n. ",
    "cpredmann": "Thanks for the quick response, and that makes sense, although I still must be missing something.\nIn the logs, I see: \n[181840.928314] fabio[5]:     \"CertSources\": {\n[181840.928541] fabio[5]:         \"cert\": {\n[181840.928814] fabio[5]:             \"Name\": \"cert\",\n[181840.929040] fabio[5]:             \"Type\": \"consul\",\n[181840.929301] fabio[5]:             \"CertPath\": \"http://my.consul.server:8500/v1/kv/ssl/.foo.bar.com-cert.pem?token=my-consul-token\",\n[181840.929543] fabio[5]:             \"KeyPath\": \"http://my.consul.server:8500/v1/kv/ssl/.foo.bar.com-key.pem?token=my-consul-token\",\n[181840.929886] fabio[5]:             \"ClientCAPath\": \"\",\n[181840.930148] fabio[5]:             \"CAUpgradeCN\": \"\",\n[181840.930412] fabio[5]:             \"Refresh\": 3000000000,\n[181840.930675] fabio[5]:             \"Header\": null\n[181840.930914] fabio[5]:         }\n[181840.931165] fabio[5]:     },\nWhere those key and cert paths are reachable using the specified token.  They are wildcard certs, and I've tried with and without *. to see if that makes a difference, I'm sure I'm just overlooking something simple\n. Great, thanks again\n. After getting it to work without a token, but then failing with a supplied token, it looks like there may be an issue with the Consul path when using a token.  In consul_source.go parseConsulURL, the token is parsed as a query parameter from the config, but still remains as part of the URL.  So, when using key = u.RequestURI()[len(stripPrefix):], the Consul request is v1/key/ssl?token=my-token?consistent=&recurse=&token=<hidden> where token is added twice (with incorrect formatting).  Changing to key = u.Path[len(stripPrefix):] looks to resolve correctly, though\n. In testing, it looks like this now works; thanks for the fix\n. ",
    "krism74": "Anybody out there that can guide me here?\n. Frank\nThank you for taking a look at it. \n\nFabio uses the host/path for routing only, i.e. it uses the host/path only to determine which route to pick and then forwards the request as is. \n\nI don't think I understand, Does this mean that for each micro-service that I would like to LB/proxy I would need to use a different port and have them served at \"/\" ? \nMy Intention was to do the following,  a request to the Fabio external end-point \nex: http(s)://mysite.xyz.com/tomcat    gets resolved to one of the underlying instances (proxy + load balancing) \n+-----> HTTPS(S)    ------> tomcat-a\n                                              |\n               Request \u2014> HTTP(S) --> fabio -------> HTTP(S)  -----> tomcat-b\n                                              |\n                                               +\u2014----> HTTP(S)    -- \u2014>tomcat-c\nAre you saying I have to do something like this\nhttp://localhost:9999/ -> http://127.0.0.1:8888/\nhttp://localhost:9997/ -> http://127.0.0.1:8887/\nhttp://localhost:9996/ -> http://127.0.0.1:8889/\nCan you please correct me If I am wrong\nthanks\nkris\n. ",
    "terusus": "\nFabio does not support to talk to downstream servers via https and therefore cannot authenticate via a client cert to the downstream server. I think this is what you're looking for, right?\n\nThat's what I was thinking of.\nThe goal of the entire configuration is to have 100% encrypted traffic - internal and external. Users (external traffic) authenticate with username and password. Internal traffic is authenticated with client certificates. That's why the first option does not work for me. So, option 2 it is - TCP+SNI.\nCan tell more on how to make the appropriate setup with Fabio in the picture?\n```\nJust this in the fabio.properties? No CS right?\nproxy.addr = :443;proto=tcp+sni\n```\nAnd the the corresponding backed services must have the certificates for mysite.com? And register in consul with a tag urlprefix-mysite.com/path?\n. If I have more than one microservice that responds to a different portion of mysite.com can I use subdomains? Like urlprefix-api1.mysite.com/ for one service and urlprefix-api2.mysite.com/ for another service?\n. Thank you for the quick feedback. I'll setup my environment and I'll update you promptly regarding my experience.\n. Hello @magiconair. After quite some work it turned out that it is quite hard to securely distribute the user-facing certificates directly on the exposed backend microservices.\nA much faster way to achieve the effect we needed (work with self-signed certificates internally) was to use Consul Template. Setting up a container with Consul Template and nginx took me about a day. In the template I used Consul service tag syntax that is compatible with Fabio in order to be possible to switch in the future.\nI also found it quite useful to be able to expose only a specific path from a microservice. The idea is to obfuscate some parts of a service to the public.\nSo, if my use case is similar to the needs of other people, please, consider adding some features like:\n1) different certificates for client and proxy connections\n2) a tag to expose only a specific service path. ",
    "BogetC": "This feature would be so usefull.. Ok that's what i need. Thanks :)\nI ll have to wait for this to be on the master but for now, i'm using a proxy between fabio and consul to redirect http in https.. Thanks for this quick answer !\nI will have a look at that. I'll keep you update.\nThanks again.. Hi again ! \nI'm trying to store certificates in consul, and would like fabio to send the right certificate when a request is forwarded. \nHow tell fabio to pick the right certificates in consul to forward HTTPS request ? Is there a keyword to bind fabio and consul certificates ? \nFor now i'm only getting -> \"http: proxy error: remote error: tls: bad certificate\" whereas i'm sure that my certificate is all right.\nMy config is: \nproxy.cs = cs=myCS;type=file;cert=/path/to/cert;key=/path/to/key\nproxy.addr = :9999;proto=https;cs=myCS\nMy service tags are: \nurlprefix-/A proto=https\nurlprefix-/B proto=https\nurlprefix-/C proto=https\n. Am i force to use tcp+sni ? \nI only want HTTPS protocol use between fabio and my service.\nI really like fabio and it's the last thing i need to be sure my project will use fabio.\nThis is really easy to do with Go. So i think fabio is able to do that.\nIs there a simple way to do that ? . Ping.\nHello again.\nI'm getting crazy. Fabio is great but for one last feature i need, i cannot move forward.\nMy services have to listen in https. Is there a way to configure fabio to send https request ? \ntcp+sni proto seems to be to much constraint. i get : [WARN] No route for IP\ntlsskipverify doesn't work for me. i get :  tls: client didn't provide a certificate\nand i get this last error with every config i try.\nI think the documentation needs more examples.\n. @magiconair I could need your help. \nSorry to spam this issue but there is not enought documentation and not enought place to talk about fabio.. with https listener i get : \nfor my service : tls: client didn't provide a certificate\nfor fabio http: proxy error: remote error: tls: bad certificate. done. skip validation doesn't work\nmy service tags are : urlprefix-/A proto=https tlsskipverify=true. even with that i get : tls: client didn't provide a certificate. route add s2 /C https://137.74.25.188:8002 opts \"tlsskipverify=true\"\nroute add s1 /B https://137.74.25.192:8001\nroute add s2 /A https://137.74.25.188:8002 opts \"tlsskipverify=true\"\nroute add s1 /A https://137.74.25.192:8001. My backend is write in golang, and seems to be ok but i ll have a look at that to be sure. My service tags are : urlprefix-/A proto=https tlsskipverify=true\", \"urlprefix-/C proto=https tlsskipverify=true. yeah for 8002, which port should i use ? 443 is already in use. yeah but they are both running on different machines. I understand very well. Thanks to making it so clear !\nThanks to you i did found an issue in certificates that i provide to backend.\nLet me work on that and report my result to close the issue. \nThanks a lot. You helped the noob that i am about SSL/TLS to become less noob x). Problem solved. i used mutual tls verification between server and client. This is not possible with fabio.\nSo i reconfigure my backends with no client cert authentification and that work.\nThanks for your time @leprechau.. ",
    "babatundebusari": "After days of aggressive learning i finally found out how to use this fabio of a thing\nMan comparing what i know now to what documentation  is on this repo, i can tell you that the tone may seem bad but its really honest truth. I mean i am not directing my frustration on any one or you the author, just an honest feeling of what really is.\nLike for example where does it state where one can look at the various parameters when running the services to use fabio? How can one make fabio see routes for services? (for docker containers) i mean there are so many things missing.\nI know those now after searching and searching and trial and error for days.\nAnyways thanks for this great project; really awesome, just the documentation need some more work.\n. I think there is an issue with either consul or registrator because i have services for example named wordpress-1 and mysql-1 but on consul it is seen as wordpress and mysql respectively\nI think that may be the reason why fabio not seeing it.\nThis service has correct service name on consul and it is seen under fabio route\nroot@debian-docker-6:~# curl localhost:8500/v1/catalog/service/ghost-1?pretty\n[\n    {\n        \"Node\": \"debian-docker-6\",\n        \"Address\": \"10.247.1.63\",\n        \"TaggedAddresses\": {\n            \"lan\": \"10.247.1.63\",\n            \"wan\": \"10.247.1.63\"\n        },\n        \"ServiceID\": \"debian-docker-6:ghost-1:2368\",\n        \"ServiceName\": \"ghost-1\",\n        \"ServiceTags\": [\n            \"microservices-ghost-1.com/\"\n        ],\n        \"ServiceAddress\": \"\",\n        \"ServicePort\": 8081,\n        \"ServiceEnableTagOverride\": false,\n        \"CreateIndex\": 51705,\n        \"ModifyIndex\": 51708\n    }\n]\nroot@debian-docker-6:~# curl localhost:8500/v1/health/service/ghost-1?pretty\n[\n    {\n        \"Node\": {\n            \"Node\": \"debian-docker-6\",\n            \"Address\": \"10.247.1.63\",\n            \"TaggedAddresses\": {\n                \"lan\": \"10.247.1.63\",\n                \"wan\": \"10.247.1.63\"\n            },\n            \"CreateIndex\": 51652,\n            \"ModifyIndex\": 51811\n        },\n        \"Service\": {\n            \"ID\": \"debian-docker-6:ghost-1:2368\",\n            \"Service\": \"ghost-1\",\n            \"Tags\": [\n                \"microservices-ghost-1.com/\"\n            ],\n            \"Address\": \"\",\n            \"Port\": 8081,\n            \"EnableTagOverride\": false,\n            \"CreateIndex\": 51705,\n            \"ModifyIndex\": 51708\n        },\n        \"Checks\": [\n            {\n                \"Node\": \"debian-docker-6\",\n                \"CheckID\": \"serfHealth\",\n                \"Name\": \"Serf Health Status\",\n                \"Status\": \"passing\",\n                \"Notes\": \"\",\n                \"Output\": \"Agent alive and reachable\",\n                \"ServiceID\": \"\",\n                \"ServiceName\": \"\",\n                \"CreateIndex\": 51652,\n                \"ModifyIndex\": 51652\n            },\n            {\n                \"Node\": \"debian-docker-6\",\n                \"CheckID\": \"service:debian-docker-6:ghost-1:2368\",\n                \"Name\": \"Service 'ghost-1' check\",\n                \"Status\": \"passing\",\n                \"Notes\": \"\",\n                \"Output\": \"HTTP GET http://:8081/: 200 OK Output: s/screen.css?v=fcee095f50\\\" /\\u003e\\n    \\u003clink rel=\\\"stylesheet\\\" type=\\\"text/css\\\" href=\\\"//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400\\\" /\\u003e\\n\\n    \\u003clink rel=\\\"canonical\\\" href=\\\"http://localhost:2368/\\\" /\\u003e\\n    \\u003cmeta name=\\\"referrer\\\" content=\\\"no-referrer-when-downgrade\\\" /\\u003e\\n    \\n    \\u003cmeta property=\\\"og:site_name\\\" content=\\\"Ghost\\\" /\\u003e\\n    \\u003cmeta property=\\\"og:type\\\" content=\\\"website\\\" /\\u003e\\n    \\u003cmeta property=\\\"og:title\\\" content=\\\"Ghost\\\" /\\u003e\\n    \\u003cmeta property=\\\"og:description\\\" content=\\\"Just a blogging platform.\\\" /\\u003e\\n    \\u003cmeta property=\\\"og:url\\\" content=\\\"http://localhost:2368/\\\" /\\u003e\\n    \\u003cmeta name=\\\"twitter:card\\\" content=\\\"summary\\\" /\\u003e\\n    \\u003cmeta name=\\\"twitter:title\\\" content=\\\"Ghost\\\" /\\u003e\\n    \\u003cmeta name=\\\"twitter:description\\\" content=\\\"Just a blogging platform.\\\" /\\u003e\\n    \\u003cmeta name=\\\"twitter:url\\\" content=\\\"http://localhost:2368/\\\" /\\u003e\\n    \\n    \\u003cscript type=\\\"application/ld+json\\\"\\u003e\\n{\\n    \\\"@context\\\": \\\"https://schema.org\\\",\\n    \\\"@type\\\": \\\"Website\\\",\\n    \\\"publisher\\\": {\\n        \\\"@type\\\": \\\"Organization\\\",\\n        \\\"name\\\": \\\"Ghost\\\",\\n        \\\"logo\\\": \\\"http://localhost:2368/ghost/img/ghosticon.jpg\\\"\\n    },\\n    \\\"url\\\": \\\"http://localhost:2368/\\\",\\n    \\\"mainEntityOfPage\\\": {\\n        \\\"@type\\\": \\\"WebPage\\\",\\n        \\\"@id\\\": \\\"http://localhost:2368\\\"\\n    },\\n    \\\"description\\\": \\\"Just a blogging platform.\\\"\\n}\\n    \\u003c/script\\u003e\\n\\n    \\u003cmeta name=\\\"generator\\\" content=\\\"Ghost 0.11\\\" /\\u003e\\n    \\u003clink rel=\\\"alternate\\\" type=\\\"application/rss+xml\\\" title=\\\"Ghost\\\" href=\\\"http://localhost:2368/rss/\\\" /\\u003e\\n\\u003c/head\\u003e\\n\\u003cbody class=\\\"home-template nav-closed\\\"\\u003e\\n\\n    \\u003cdiv class=\\\"nav\\\"\\u003e\\n    \\u003ch3 class=\\\"nav-title\\\"\\u003eMenu\\u003c/h3\\u003e\\n    \\u003ca href=\\\"#\\\" class=\\\"nav-close\\\"\\u003e\\n        \\u003cspan class=\\\"hidden\\\"\\u003eClose\\u003c/span\\u003e\\n    \\u003c/a\\u003e\\n    \\u003cul\\u003e\\n            \\u003cli class=\\\"nav-home nav-current\\\" role=\\\"presentation\\\"\\u003e\\u003ca href=\\\"http://localhost:2368/\\\"\\u003eHome\\u003c/a\\u003e\\u003c/li\\u003e\\n    \\u003c/ul\\u003e\\n        \\u003ca class=\\\"subscribe-button icon-feed\\\" href=\\\"http://localhost:2368/rss/\\\"\\u003eSubscribe\\u003c/a\\u003e\\n\\u003c/div\\u003e\\n\\u003cspan class=\\\"nav-cover\\\"\\u003e\\u003c/span\\u003e\\n\\n\\n    \\u003cdiv class=\\\"site-wrapper\\\"\\u003e\\n\\n        \\n\\u003cheader class=\\\"main-header no-cover\\\"\\u003e\\n    \\u003cnav class=\\\"main-nav overlay clearfix\\\"\\u003e\\n        \\n            \\u003ca class=\\\"menu-button icon-menu\\\" href=\\\"#\\\"\\u003e\\u003cspan class=\\\"word\\\"\\u003eMenu\\u003c/span\\u003e\\u003c/a\\u003e\\n    \\u003c/nav\\u003e\\n    \\u003cdiv class=\\\"vertical\\\"\\u003e\\n        \\u003cdiv class=\\\"main-header-content inner\\\"\\u003e\\n            \\u003ch1 class=\\\"page-title\\\"\\u003eGhost\\u003c/h1\\u003e\\n            \\u003ch2 class=\\\"page-description\\\"\\u003eJust a blogging platform.\\u003c/h2\\u003e\\n        \\u003c/div\\u003e\\n    \\u003c/div\\u003e\\n    \\u003ca class=\\\"scroll-down icon-arrow-left\\\" href=\\\"#content\\\" data-offset=\\\"-45\\\"\\u003e\\u003cspan class=\\\"hidden\\\"\\u003eScroll Down\\u003c/span\\u003e\\u003c/a\\u003e\\n\\u003c/header\\u003e\\n\\n\\u003cmain id=\\\"content\\\" class=\\\"content\\\" role=\\\"main\\\"\\u003e\\n\\n    \\u003cdiv class=\\\"extra-pagination inner\\\"\\u003e\\n    \\u003cnav class=\\\"pagination\\\" role=\\\"navigation\\\"\\u003e\\n    \\u003cspan class=\\\"page-number\\\"\\u003ePage 1 of 1\\u003c/span\\u003e\\n\\u003c/nav\\u003e\\n\\n\\u003c/div\\u003e\\n\\n\\u003carticle class=\\\"post tag-getting-started\\\"\\u003e\\n    \\u003cheader class=\\\"post-header\\\"\\u003e\\n        \\u003ch2 class=\\\"post-title\\\"\\u003e\\u003ca href=\\\"/welcome-to-ghost/\\\"\\u003eWelcome to Ghost\\u003c/a\\u003e\\u003c/h2\\u003e\\n    \\u003c/header\\u003e\\n    \\u003csection class=\\\"post-excerpt\\\"\\u003e\\n        \\u003cp\\u003eYou're live! Nice. We've put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by \\u003ca class=\\\"read-more\\\" href=\\\"/welcome-to-ghost/\\\"\\u003e\\u0026raquo;\\u003c/a\\u003e\\u003c/p\\u003e\\n    \\u003c/section\\u003e\\n    \\u003cfooter class=\\\"post-meta\\\"\\u003e\\n        \\n        \\u003ca href=\\\"/author/ghost-owner/\\\"\\u003eGhost Owner\\u003c/a\\u003e\\n         on \\u003ca href=\\\"/tag/getting-started/\\\"\\u003eGetting Started\\u003c/a\\u003e\\n        \\u003ctime class=\\\"post-date\\\" datetime=\\\"2016-10-07\\\"\\u003e07 October 2016\\u003c/time\\u003e\\n    \\u003c/footer\\u003e\\n\\u003c/article\\u003e\\n\\n\\u003cnav class=\\\"pagination\\\" role=\\\"navigation\\\"\\u003e\\n    \\u003cspan class=\\\"page-number\\\"\\u003ePage 1 of 1\\u003c/span\\u003e\\n\\u003c/nav\\u003e\\n\\n\\n\\u003c/main\\u003e\\n\\n\\n        \\u003cfooter class=\\\"site-footer clearfix\\\"\\u003e\\n            \\u003csection class=\\\"copyright\\\"\\u003e\\u003ca href=\\\"http://localhost:2368\\\"\\u003eGhost\\u003c/a\\u003e \\u0026copy; 2016\\u003c/section\\u003e\\n            \\u003csection class=\\\"poweredby\\\"\\u003eProudly published with \\u003ca href=\\\"https://ghost.org\\\"\\u003eGhost\\u003c/a\\u003e\\u003c/section\\u003e\\n        \\u003c/footer\\u003e\\n\\n    \\u003c/div\\u003e\\n\\n    \\u003cscript type=\\\"text/javascript\\\" src=\\\"https://code.jquery.com/jquery-1.12.0.min.js\\\"\\u003e\\u003c/script\\u003e\\n    \\n    \\u003cscript type=\\\"text/javascript\\\" src=\\\"/assets/js/jquery.fitvids.js?v=fcee095f50\\\"\\u003e\\u003c/script\\u003e\\n    \\u003cscript type=\\\"text/javascript\\\" src=\\\"/assets/js/index.js?v=fcee095f50\\\"\\u003e\\u003c/script\\u003e\\n\\n\\u003c/body\\u003e\\n\\u003c/html\\u003e\\n\",\n                \"ServiceID\": \"debian-docker-6:ghost-1:2368\",\n                \"ServiceName\": \"ghost-1\",\n                \"CreateIndex\": 51705,\n                \"ModifyIndex\": 51708\n            }\n        ]\n    }\n]\nBUT this is the one i cannot see under fabio routes and consul has name wrong, should be wordpress-1 but consul sees it as wordpress\nroot@debian-docker-6:~# curl localhost:8500/v1/catalog/service/wordpress?pretty\n[\n    {\n        \"Node\": \"debian-docker-6\",\n        \"Address\": \"10.247.1.63\",\n        \"TaggedAddresses\": {\n            \"lan\": \"10.247.1.63\",\n            \"wan\": \"10.247.1.63\"\n        },\n        \"ServiceID\": \"debian-docker-6:wordpress-1:80\",\n        \"ServiceName\": \"wordpress\",\n        \"ServiceTags\": [\n            \"microservices-wordpress-1.com/\"\n        ],\n        \"ServiceAddress\": \"\",\n        \"ServicePort\": 8082,\n        \"ServiceEnableTagOverride\": false,\n        \"CreateIndex\": 51811,\n        \"ModifyIndex\": 51811\n    }\n]\nroot@debian-docker-6:~# curl localhost:8500/v1/health/service/wordpress?pretty\n[\n    {\n        \"Node\": {\n            \"Node\": \"debian-docker-6\",\n            \"Address\": \"10.247.1.63\",\n            \"TaggedAddresses\": {\n                \"lan\": \"10.247.1.63\",\n                \"wan\": \"10.247.1.63\"\n            },\n            \"CreateIndex\": 51652,\n            \"ModifyIndex\": 51811\n        },\n        \"Service\": {\n            \"ID\": \"debian-docker-6:wordpress-1:80\",\n            \"Service\": \"wordpress\",\n            \"Tags\": [\n                \"microservices-wordpress-1.com/\"\n            ],\n            \"Address\": \"\",\n            \"Port\": 8082,\n            \"EnableTagOverride\": false,\n            \"CreateIndex\": 51811,\n            \"ModifyIndex\": 51811\n        },\n        \"Checks\": [\n            {\n                \"Node\": \"debian-docker-6\",\n                \"CheckID\": \"serfHealth\",\n                \"Name\": \"Serf Health Status\",\n                \"Status\": \"passing\",\n                \"Notes\": \"\",\n                \"Output\": \"Agent alive and reachable\",\n                \"ServiceID\": \"\",\n                \"ServiceName\": \"\",\n                \"CreateIndex\": 51652,\n                \"ModifyIndex\": 51652\n            }\n        ]\n    }\n]\nBelow is all services running on server node so you can see the names\nroot@debian-docker-6:~# docker ps\nCONTAINER ID        IMAGE                           COMMAND                  CREATED             STATUS              PORTS                    NAMES\n37f4b8cb11f3        wordpress                       \"docker-entrypoint.sh\"   13 minutes ago      Up 13 minutes       0.0.0.0:8082->80/tcp     wordpress-1\nf24c88482f5d        mariadb                         \"docker-entrypoint.sh\"   13 minutes ago      Up 13 minutes       0.0.0.0:1306->3306/tcp   mysql-1\nec2e30d5434e        ghost                           \"/entrypoint.sh npm s\"   24 minutes ago      Up 24 minutes       0.0.0.0:8081->2368/tcp   ghost-1\n417217654cd2        magiconair/fabio                \"/fabio -cfg /etc/fab\"   26 minutes ago      Up 26 minutes                                fabio\n729591d82beb        gliderlabs/registrator:latest   \"/bin/registrator con\"   27 minutes ago      Up 27 minutes                                registrator\n7453915b64e8        consul                          \"docker-entrypoint.sh\"   28 minutes ago      Up 28 minutes                                consul-agent\n. ok i have tested with  other apps and issue seems to be with registrator and/or consul\nthey are not registering the correct services name.\nThanks\n. @magiconair \noh i see, but it still works though but i will change that back\nwas using because i thought one could change to any name\nthanks for pointing that out\nUPDATE:\ni used this when running fabio\n-e REGISTRY_CONSUL_TAGPREFIX='microservices-'\nso when i run the services i used the prefix microservices- \nis that a good practice?\n. ",
    "jbye": "Subbed.\nMy use case is that I would like to use Fabio to load balance Thrift-based microservices that are registered in Consul.\n. ",
    "panga": "+1\n@magiconair I'm using Fabio to route Docker based microservices, so it binds to random ports on host.\nI would like use Fabio to route TCP based traffic through a fixed port.... @magiconair,\nI've tested the new TCP proxy settings, it works like I expected!\nJust a few questions:\n1. Do you plan to add support for dynamic listening ports?\n2. When do you plan to release 1.4 branch?\nThank you!!. ",
    "tkald": "+1\nI'd like to balance imap / smtp traffic\nProxy protocol support to tcp would be also awsome :). ",
    "ptariche": "\ud83d\udc4d . ",
    "rodrigoraval": "Guys,\nI am facing some issue close to this one, could you please help me on that?\nhttps://github.com/fabiolb/fabio/issues/266\nThanks. ",
    "Narrowbeam": "Would be really good to see this - its the only feature stopping our adoption of this project.  Fingers crossed you can add it fairly soon.\n. ",
    "shadowfax-chc": "@magiconair is this as simple as adding a new conditional in registery/consul/service.go?\nNot sure what kind of configuration you might want around it.. Ah, that makes sense. Let me make sure I am setting this option in the correct place now, and I will get some tests.. @magiconair made the requested changes and added tests. I think I addressed all the requested changes.\nAs for the config names, I just used similar options to what consul itself has, but I can easily change them if you prefer something else.\nAnd as for basic auth, I can look into that, but can it be in a separate PR?. I would have to look into how the cert stores are being used. From what it looks like to me the UI is starting up differently than the proxy listeners, but it could probably be refactored to use a http.Server with a TLSConfig that was created from the cert store, rather than calling the http.ListenAndServe functions.\nI'm not sure what the config would then be like, are you thinking something like:\nui.cs = cs=some-name;type=file;cert=p/a-cert.pem;key=p/a-key.pem\nui.addr = :9998;cs=some-name\nI think I kind of see how using the cert store could be nice as it would allow for getting the UI's certs from any of the supported cert store backends. But I also like the idea of having the cert stores only be for the proxy listeners, and having the UI just use a simple file based configuration, since the UI/API is a special case.\nAnd no, I'm on EDT time.\n. Addressed some more of the comments.\nHowever, if you would rather the certs come from a cert store, I can refactor this. Just need some clarification on what the configuration would look like.. Makes sense, I can get this refactored to use the cert store.. Refactored to use the CertStore. It might still need some cleanup to reduce duplication, but let me know if this is the right idea.. Did the requested refactoring, and squashed it down to one commit.. I was running into this issue as well. The 94beb91 patch fixes it for me.. I can try that out, but I think how I had it at first was correct, in that you should be specifying a certFile which contains the server's certificate and any intermediates. Then the private key should be specified as the keyFile.\nThat seems in line with http.ListenAndServeTLS's docs.. The way this is currently coded it is, in that if you just specify a keyFile it will ignore it and still server http, as you need to specify a certFile to get https. I don't think it would work with just a private key.. An error sounds better, rather than silently defaulting to http. I can make that change. Did some experimenting and it looks like your code should work. I'm not sure what you mean by this and the change in registry/consul/register.go. ",
    "fjromerom": "Thanks!\n. ",
    "abhishekkr": "@magiconair ah, now I get it... wrong PR, closing it. ",
    "lukas2511": "I also would like to see this feature.\nI'm currently using haproxy in front of a few nginx boxes using proxy protocol and I'd like to switch to fabio for a more dynamic setup.\nFor now I've tried to implement this myself but since I didn't know a nice way to get to route tags / options inside of the SNI Proxy I wasn't able to make the PROXY header optional... Since I also have software running that doesn't understand the proxy protocol I need to have both options and I'd like to run both on the same port, works perfectly with haproxy.\nI am hoping that your version will have an option to set the header on an as-needed basis so a single port can be shared between tcp+sni and (what i call it) tcp+sni+proxy.\nMy very crude implementation can be found here: https://github.com/lukas2511/fabio/commit/deaa518b1991c2fec11def21b808aaa64311372b\nIt's not 100% correctly implemented (e.g. fixed TCP4 for now), but it worked for me while playing around with the software.. @magiconair I would like to have this on a per-route basis, upstream server shouldn't be involved in making this decision, just the consul services.. @magiconair the project readme has a few examples for other tags:\n```\nHTTP/S examples\n[...]\nurlprefix-/foo/bar strip=/foo    # route with path stripping (forward only '/bar' to upstream)\nTCP examples\nurlprefix-:3306 proto=tcp        # route external port 3306\n```\nMaybe something like\nurlprefix-example.com/ proxy\nOr is this not possible?. Sorry i think I just misunderstood what you meant with \"upstream server\", for me that was the upstream webserver, but now I notice that you mean the whole system, so yea, this should come from the upstream server, sorry for the confusion.. ",
    "pashinin": "Thank you for 1.5.11 release. It helped me to understand that I actually have a problem described in this issue. I thought Fabio can talk Proxy protocol in any direction. Hope this will be fixed.. Tested Fabio with mentioned PR. Works with 2 Exim servers configured for Proxy protocol.\nIf you want you can docker pull pashinin/fabio:fix-191. When will this change be released? Can you make 1.5.11?. ",
    "michaelmcguinness": "No. Running it as raw_exec to work around the issue. Would I be right in saying that you mean the logs exposed by \n$ nomad logs -verbose -stderr <allocid>\nThat being the case there is nothing interesting there...\n2016/12/17 15:52:58 [INFO] Version 1.3.4 starting\n2016/12/17 15:52:58 [INFO] Go runtime is go1.7.3\n2016/12/17 15:52:58 [INFO] Using routing strategy \"rnd\"\n2016/12/17 15:52:58 [INFO] Using routing matching \"prefix\"\n2016/12/17 15:52:58 [INFO] Setting GOGC=800\n2016/12/17 15:52:58 [INFO] Setting GOMAXPROCS=1\n2016/12/17 15:52:58 [INFO] Metrics disabled\n2016/12/17 15:52:58 [INFO] consul: Connecting to \"localhost:8500\" in datacenter \"vpc-poc\"\n2016/12/17 15:52:58 [INFO] Admin server listening on \":9998\"\n2016/12/17 15:52:58 [INFO] HTTP proxy listening on :9999\n2016/12/17 15:52:58 [INFO] consul: Using dynamic routes\n2016/12/17 15:52:58 [INFO] consul: Using tag prefix \"urlprefix-\"\n2016/12/17 15:52:58 [INFO] consul: Watching KV path \"/fabio/config\"\n2016/12/17 15:52:58 [INFO] consul: Health changed to #2443304\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_prometheus-node-exporter-http\" since agent on node \"dns_slave\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_prometheus-node-exporter-process\" since agent on node \"dns_slave\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_nomad-server-nomad-serf\" since agent on node \"nomad_server1\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_nomad-server-nomad-rpc\" since agent on node \"nomad_server1\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_nomad-server-nomad-serf\" since agent on node \"nomad_server2\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_nomad-server-nomad-rpc\" since agent on node \"nomad_server2\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_nomad-server-nomad-http\" since agent on node \"nomad_server2\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_nomad-server-nomad-serf\" since agent on node \"nomad_server3\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_prometheus-node-exporter-http\" since agent on node \"nomad_server3\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Skipping service \"_prometheus-node-exporter-process\" since agent on node \"nomad_server3\" is down: Agent not live or unreachable\n2016/12/17 15:52:58 [INFO] consul: Manual config changed to #2409046\n2016/12/17 15:52:58 [INFO] Updated config to\n2016/12/17 15:52:58 [INFO] consul: Registered fabio with id \"fabio-ip-10-75-70-74-9998\"\n2016/12/17 15:52:58 [INFO] consul: Registered fabio with address \"10.75.70.74\"\n2016/12/17 15:52:58 [INFO] consul: Registered fabio with tags \"\"\n2016/12/17 15:52:58 [INFO] consul: Registered fabio with health check to \"http://[10.75.70.74]:9998/health\"\n2016/12/17 15:52:58 [INFO] consul: Health changed to #2443305\nand then just repeated messages about Consul.. Thanks I'll give this a go and let you know the result. Actually I upgraded to Nomad 0.5.1 just in case but no change. . This issue remains with this test code so as you suspected it is a more generic issue. I actually also tested it with the Consul binary and got the same thing. Thank you for your time on this. I'll head over to the Nomad issues page with it. \nAs a side note, what should have I been expecting from 'curl localhost:9999'. I am getting a 404.\nAlso I noticed that you posted a Dockerfile. As the issue was specifically for the exec driver I was not sure what you wanted me to do with it.. You may (or may not :)) be interested to know that this issue is something to do with the kernel version and the LVM storage driver implementation. Haven't quite figured it out but switching to AUFS makes the issue go away.\nThanks again for your attention and a great utility.. I raised this up with Kelsey Hightower as it was his demo that made me look at it. Not for a fix but just for some info about his env. I'm not sure I am going to burn time raising it with Nomad as we are way behind here with our kernel revision (one of the many things on my to-do list). It seems to me that LVM may not be the strategic storage option for Docker so I think fixing forward by upgrading is the way to go.. ",
    "siepkes": "Even if Fabio could do it I personally would never rely / trust any daemon to drop it's privileges after it's done with them. I remember from the \"old\" days (say 10 years ago) that a good number of root exploits in Linux used processes which relied on privilege dropping (Apache HTTP server for example). Because even though they might poses root rights for only a couple of milliseconds; At some point in time they will have them; It's an opening. If there is a vulnerability in Fabio the exploiter will only have to wait until the daemon is restarted at some point to obtain root rights.. @kostyrev On SmartOS deployments I use SMF to grant the NGINX, Apache, etc. process the net_privaddr privilege. This allows the process to bind to < 1024 ports without root privileges. The process it self is always started as a unprivileged user by SMF. On Linux with systemd you can use the Capabilities= option to achieve the same effect.\nSo the process never has root rights. It only has the rights to bind to the ports below 1024.. @kostyrev Yes only the NGINX user has read rights on the private key. The certificate is world readable since it is obviously public anyway. Since the worker processes have the private key loaded in their memory when they are spawned there is not much point in shielding them from the actual private key file.. ",
    "kostyrev": "@siepkes so how do you manage Apache or Nginx services now?\n. You grant read perms on private certificates to apache/nginx user?. someone, please implement this feature. @killcity yes, I could strip out the name of resulting binary (that is not the inconvenience I'm talking about) but to do that I have to download it first. And to download it I need to specify go version in url path.\n. yep, for as of now I have to update role with two vars: one for fabio_version and second one for fabio_go_version.\nThat was the thought. But @magiconair explained above the rationale behind specifying go version in Releases pages.\nSo I'm closing this issue 'cause not very often I have to update versions in my role.\n. I ended up with:\nproxy.cs = cs=fast;type=file;cert=fast.com.c;key=fast.com.key\nproxy.addr=:9999;cs=fast\nand fabio did start with those in fabio.properties.\nbut I do not understand the purpose of this in docs.\nUPD. Ok, after more careful reading I do understand that I just misinterpreted the whole thing.\nSorry for the fuzz. I see those errors every time I run wrk.\nover https\ntop shows 33.0%\nthere's one error of 2017/04/14 22:08:38 http: TLS handshake error from 188.123.241.55:12061: EOF\nand 13-14 errors of 2017/04/14 22:09:38 http: proxy error: context canceled\nover http\ntop show 27~31%\n16-22 errors of 2017/04/14 22:14:58 http: proxy error: context canceled\nI see no errors in nginx error.log on upstream servers.\n. from user perspective something like this will do.. @magiconair I confirm. Setting to ro and off are working as expected.\nThanks!\n. Hi! I'd like to point out that though you've removed binary from the tree the binary is still there in history\n$ git rev-list --all --objects | sed -n $(git rev-list --objects --all | cut -f1 -d' ' | git cat-file --batch-check | grep blob | sort -n -k 3 | tail -n1 | while read hash type size; do echo -n \"-e s/$hash/$size/p \"; done) | sort -n -k1\n12059648 fabio.exe\nand cloning this repo still takes 14M of space\n$ du -s -h ../fabio/\n14M ../fabio/. FYI: I used steps from github guide and get those results\n$ du -sh ../fabio.clean\n8.9M    ../fabio.clean\n$ du -sh ../fabio.master\n14M ../fabio.master. ",
    "vjappidi": "I tried  adding port ipaddr:8500,but getting the same error\nThanks,\nVijay. Please find below the log\nC:\\fabio>fabio-1.3.4-go1.7.3-windows_amd64 -registry.consul.addr 192.168.196.XXX:8500\n2016/12/01 08:56:43 [INFO] Runtime config\n{\n    \"Proxy\": {\n        \"Strategy\": \"rnd\",\n        \"Matcher\": \"prefix\",\n        \"NoRouteStatus\": 404,\n        \"MaxConn\": 10000,\n        \"ShutdownWait\": 0,\n        \"DialTimeout\": 30000000000,\n        \"ResponseHeaderTimeout\": 0,\n        \"KeepAliveTimeout\": 0,\n        \"ReadTimeout\": 0,\n        \"WriteTimeout\": 0,\n        \"FlushInterval\": 1000000000,\n        \"LocalIP\": \"192.168.196.XXX\",\n        \"ClientIPHeader\": \"\",\n        \"TLSHeader\": \"\",\n        \"TLSHeaderValue\": \"\",\n        \"GZIPContentTypesValue\": \"\",\n        \"GZIPContentTypes\": null\n    },\n    \"Registry\": {\n        \"Backend\": \"consul\",\n        \"Static\": {\n            \"Routes\": \"\"\n        },\n        \"File\": {\n            \"Path\": \"\"\n        },\n        \"Consul\": {\n            \"Addr\": \"192.168.196.XXX:8500\",\n            \"Scheme\": \"http\",\n            \"Token\": \"\",\n            \"KVPath\": \"/fabio/config\",\n            \"TagPrefix\": \"urlprefix-\",\n            \"Register\": true,\n            \"ServiceAddr\": \":9998\",\n            \"ServiceName\": \"fabio\",\n            \"ServiceTags\": null,\n            \"ServiceStatus\": [\n                \"passing\"\n            ],\n            \"CheckInterval\": 1000000000,\n            \"CheckTimeout\": 3000000000\n        }\n    },\n    \"Listen\": [\n        {\n            \"Addr\": \":9999\",\n            \"Proto\": \"http\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false\n        }\n    ],\n    \"CertSources\": {},\n    \"Metrics\": {\n        \"Target\": \"\",\n        \"Prefix\": \"{{clean .Hostname}}.{{clean .Exec}}\",\n        \"Names\": \"{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.{{clean .TargetURL.Host}}\",\n        \"Interval\": 30000000000,\n        \"GraphiteAddr\": \"\",\n        \"StatsDAddr\": \"\",\n        \"CirconusAPIKey\": \"\",\n        \"CirconusAPIApp\": \"fabio\",\n        \"CirconusAPIURL\": \"\",\n        \"CirconusCheckID\": \"\",\n        \"CirconusBrokerID\": \"\"\n    },\n    \"UI\": {\n        \"Addr\": \":9998\",\n        \"Color\": \"light-green\",\n        \"Title\": \"\"\n    },\n    \"Runtime\": {\n        \"GOGC\": 800,\n        \"GOMAXPROCS\": 4\n    },\n    \"ListenerValue\": [\n        \":9999\"\n    ],\n    \"CertSourcesValue\": null\n}\n2016/12/01 08:56:43 [INFO] Version 1.3.4 starting\n2016/12/01 08:56:43 [INFO] Go runtime is go1.7.3\n2016/12/01 08:56:43 [INFO] Using routing strategy \"rnd\"\n2016/12/01 08:56:43 [INFO] Using routing matching \"prefix\"\n2016/12/01 08:56:43 [INFO] Setting GOGC=800\n2016/12/01 08:56:43 [INFO] Setting GOMAXPROCS=4\n2016/12/01 08:56:43 [INFO] Metrics disabled\n2016/12/01 08:56:44 [FATAL] Error initializing backend. Get http://192.168.196.XXX:8500/v1/agent/self: dial tcp 192.168.196.XXX:8500: connectex: No connection could be made because the target machine\nactively refused it.\nThanks,\nVijay. Could you please help on the above issue.\nThanks,\nVijay. ",
    "chiel1980": "Hi, because of the costs of the code review of the components we wanted to review and since you/eBay is running it in production, we decided to not do the code review and focus on higher risk components.\nA cost/risk tradeoff so to speak.. ",
    "hynek": "yes thank you, I\u2019m still investigating :-/\nnothing is flapping but i'm not sure what a lagging health check would be?  in any case this is probably not a fabio issue\u2026\nhappy holidays anyways. :). ",
    "jorgemarey": "Hi, I've seen this exact same behaviour on my cluster. Just to throw some ideas, I've been debugging and found that is nomad the one causing this. \nThe check that is performed on nomad is on /v1/agent/servers which outputs the servers of the cluster. \nThe problem is that this array is not ordered and changes randomly (it's not random actually, but it is not guaranteed to be the same) on each request, so when there's more than one the check becomes the one causing the blocking query to end. \nI'll open an issue on nomad to see what they think about this.. Yes.\nI run tcpdump on the machine where fabio is running (chaning the protocol to http) and saw the next:\nIn my case I have a s3 compatible service behind fabio.\nUsing the aws-sdk-go\nThis happens when I use the aws-sdk-go\nGET http://s3.mydomain.com/mybucket?delimiter=%2F&max-keys=1000&prefix= HTTP/1.1\nHost: s3.mydomain.com\n....other headers....\nThis when I use curl\nGET /mybucket?delimiter=%2F&max-keys=1000&prefix= HTTP/1.1\nHost: s3.mydomain.com\n....other headers..... That was quick! I tried it. It works perfectly fine!. Glad to help! Yes, I tried with both types of requests and It worked for both of them.. Ok. Will do!. OK. Great!. ",
    "dadgar": "This PR should fix the issue: https://github.com/hashicorp/nomad/pull/3214. ",
    "sadyou": "Are you sure that your demo server is using a persistent connection?\nif the upstream server is not using persistent connections then fabio will not wait for any response on receiving a 204 No content.  This problem is seen within fabio when the server has persistent connection enabled.. I have confirmed that no Content-Length header is sent when 204 No Content is returned.  This is correct behavior as per According to section 3.3.2 of RFC 7230 (Proposed Standard, RFC 7230):\nA server MUST NOT send a Content-Length header field in any response\nwith a status code of 1xx (Informational) or 204 (No Content). \nI have turned verbose on for a curl invocation and the problem is in bold below\n```\n* Connected to localhost (127.0.0.1) port 8089 (#0)\n\nPOST / HTTP/1.1\nUser-Agent: curl/7.40.0-DEV\nHost: localhost:8089\nAccept: /\nContent-Length: 3\nContent-Type: application/x-www-form-urlencoded\n\nupload completely sent off: 3 out of 3 bytes\n< HTTP/1.1 204\n< Content-Type: application/x-www-form-urlencoded; charset=windows-1252\n< MULE_ENCODING: windows-1252\n< Date: Wed, 21 Dec 2016 11:08:23 GMT\n<\n*##  Connection #0 to host localhost left intact\n```\n\n\nThe line above is where the server has persistent connection enabled.  Fabio waits for a response and will only stop when the connection idle timeout is exhausted.  If I change the server config and set the persistent connection as OFF (disabled) then fabio behaves correctly\n. It waits 30 seconds before forwarding the 204 response.  It waits for whatever value I specify as the idle timeout. 30 seconds is our default but if I reduce it to 5 seconds then it will wait for 5 seconds before sending the 204.  . This issue is with a MuleSoft interaction as well:  Below is a dump of the response:\nThu Dec 22 09:14:39 EST 2016:DEBUG:<< \"HTTP/1.1 204 [\\r][\\n]\"\nThu Dec 22 09:14:39 EST 2016:DEBUG:<< \"Content-Type: text/xml; charset=UTF-8[\\r][\\n]\"\nThu Dec 22 09:14:39 EST 2016:DEBUG:<< \"MULE_ENCODING: UTF-8[\\r][\\n]\"\nThu Dec 22 09:14:39 EST 2016:DEBUG:<< \"Date: Wed, 21 Dec 2016 22:14:39 GMT[\\r][\\n]\"\nThu Dec 22 09:14:39 EST 2016:DEBUG:<< \"[\\r][\\n]\"\nYou will notice the /r/n is there but I notice in your sample you have two occurrences of this.  Why should there be two?\n. Are you saying that the dump that I have provided will cause fabio to hang until the idle timeout is exhausted?. I have raised a support ticket with Mule in parallel and my support team in MuleSoft is across this dialogue as well.  Their argument at this stage is that any other client whether it be POSTMAN, SOAP-UI, curl, tibco,etc seem to behave differently to fabio at this stage. I will do some more digging on my side as well.. I have attached below the raw tcpdump of the request and response\n504f5354202f20485454502f312e310d0a486f73743a203132372e302e302e313a383038390d0a557365722d4167656e743a206375726c2f372e35312e300d0a4163636570743a202a2f2a0d0a436f6e74656e742d4c656e6774683a20330d0a436f6e74656e742d547970653a206170706c69636174696f6e2f782d7777772d666f726d2d75726c656e636f6465640d0a0d0a323034\n485454502f312e3120323034200d0a436f6e74656e742d547970653a206170706c69636174696f6e2f782d7777772d666f726d2d75726c656e636f6465643b20636861727365743d5554462d380d0a4d554c455f454e434f44494e473a205554462d380d0a446174653a205468752c2032322044656320323031362032323a34383a313020474d540d0a0d0a. The above is the raw content.  I have also attached below the UTF-8 content from wireshark\nPOST / HTTP/1.1\nHost: 127.0.0.1:8089\nUser-Agent: curl/7.51.0\nAccept: /\nContent-Length: 3\nContent-Type: application/x-www-form-urlencoded\n204HTTP/1.1 204 \nContent-Type: application/x-www-form-urlencoded; charset=UTF-8\nMULE_ENCODING: UTF-8\nDate: Thu, 22 Dec 2016 22:48:10 GMT\nEND. This issue can be closed now.  We have identified the problem is with Mule.\nIn the scenario Client->Fabio->Mule everything is OK when Mule sends 204 back and the new line character is there.  In the scenario Client->Fabio->Mule-Mule, the second Mule listener will send the 204 and the first Mule listener will copy the 204 status back to Fabio but it omits the new line.. ",
    "drawks": "I'm still seeing this problem in a recent build.. statsd metrics being emitted with a type of \"gf\". Any progress on updating the internal Registry api to support labels? It would be a boon to both prometheus support as well as datadog style statsd+labels and others.\nIMHO, part of the solution could be as simple as passing into the Registry's update functions a context object which contains the same information that is currently being used to flatten out into a name. And leave it up to the Registry to do the work of either flattening in accordance to the configured template OR using the attributes of the context in whatever other manner makes sense.. Any updates here?. statsd is meant primarily as a stat aggregator. a typical pattern for using statsd is to emit events on instrumented code paths and allow the statsd implementation handle the aggregation. For example emit a counter event when a code path is hit and then allow for statsd to flush that counter at a configurable interval so you get roll up aggregates in hits per time unit where time unit is a property of the statsd server. Or to emit a timer event when an instrumented code path is hit and allow for statsd to bucket that timer into a configurable histograms/calculate quantiles etc.\nThe pattern in use in fabio is to handle aggregation internally and expose pre-aggregated metrics only as gauges. This limits the ability of consumers of the metrics to shape the data as desired. For instance a consumer is limited to only the quantiles which you've chosen to expose via the code.\nAFAICT it looks like this is a side effect of using github.com/rcrowley/go-metrics which handles aggregation with intent of periodic flushing as gauges to backends that depend on that model, i.e. graphite. I'm not sure I can give a better explanation without just writing an example PR. but....\nWithin the fabio code you've got the notion of a Registry interface that has a few functions to service counters and timers. In order to implement a more normally functioning statsd client each call to Registry.Counter.Inc(n) would emit a single statsd udp packet destined for a statsd server and likewise for Registry.Timer.Update and Registry.Timer.UpdateSince.\nThe current implementation of statsd sending relies on github.com/magiconair/go-metrics-statsd which is pasted on top of github.com/rcrowley/go-metrics that has a notion of storing the aggregates internally to the process.. I've issued a quick PR which demonstrates how a simple raw statsd sink can be implemented which doesn't do any internal aggregation and fits more directly into the ~~intended~~ typical statsd instrumentation model. This PR probably isn't appropriate to merge as written, but builds and works as intended in some limited local testing.. Closing this in favor of work being done in #329. the -- is not used in any statsd implementation I've touched. There is no notion of \"prefixes\" really in statsd. Some statsd client implementations allow for prepending an arbitrary string to help with namespacing metrics, but -- is another strange quirk that seems specific to fabio.... I'd just use the Prefix convenience function in the library you've chosen \nhttps://godoc.org/gopkg.in/alexcesaro/statsd.v2#Prefix\nIt looks like it uses a \".\" separator, so you'd have to special case when prefix is \"\" to not pass the empty string.. I've just issue a PR against your branch issue-327-raw-statsd to use the statsd client library's own prefixing routine.\nI've done some testing with your branch and it seems to work and address the issues identified in #327 \nThe only lingering doubt I have about this branch is that the library you've chosen doesn't seem to have much active development and has some IMHO questionable UDP socket handling behavior (I.E. failing to initialize a statsd client if the destination isn't listening but subsequently handling re-establishing connection if there was a listener on startup. In my experience it is often the expectation that instrumentation shouldn't block a service from starting as it can often times be victimized by deployment/startup/name resolution changes and races.). If you are actively working on adding tag support I'll pull back from my effort to do the same. I will reiterate that I /think/ the appropriate approach here is to make available all the values normally used for filling in the metrics.name template available in a struct stored in Route.targets and grab any other interesting client connection scoped data from the request and pass that as a context.Context into the Counter/Timer update functions. The template from metrics.name can then be passed into the metrics.Registry and leave it up to each metric backend to do what it wants with the 3 pieces of info.\nThis would allow:\n existing flat namespaced non-label metrics to operate the same\n hybrid flat+labels (DataDog) to do a combination of a templated flat name and additional labels\n* name + label only (prometheus/influx/opentsdb) to have simple metric names with full (or configurable) label sets\n. @magiconair awesome\nBTW: probably worth it for you to sign your own CLA ;) I've noticed your pulls on this project all trigger the CLA enforcement bot.. Conflating a gauge and a counter here is going to cause problems. Counters reset between flushes unlike gauges (at the statsd server.)  It seems like the only time you use this is in newRawProxy to track the number of active conns, in order to do this correctly with a gauge you should track the actual number and report that number as a gauge.\nHowever if you want to use the relative updates for a gauges (a questionable feature in statsd) you should always make sure that you reset the gauge value to 0 when you first update it in your app, otherwise a crash will leave you with an invalid base value.. ",
    "momania": "Shit, was just about to reply since I just figured that out myself too. \ud83d\ude06 \nThanks for the reply anyway, and sorry for the noise!. Any idea when this will be fixed (I'm on 1.5.9 now)? \nThis will be very helpful to be able to have a set of standard manual overrides for canary deployments.\nCurrently this is not possible while you cannot create route weights for tags that don't exist yet.. That problem is related to this issue: https://github.com/fabiolb/fabio/issues/224 \nAs soon as there is an error in the manual override (in this case the tag can't be matched anymore), the auto updating of the routing table stops.\n. ",
    "pipozzz": "+1. Great, I checked that, everything works properly, thanks. When do you plan to merge that fix to new release?\nThanks. Great !!, I'm just asking\nThanks. Did you forget on this issue in new release?\nI would like to use latest version of fabio, if possible.\n. Thanks, it would help me a lot \ud83d\udc4d . ",
    "mdirkse": "+1. ",
    "deuch": "+1 for me too !. Hello, i've a use case for that too :)\nI've setuped a fabio and try to have SNI and HTTPS on the same port.\nThe idea is that some micro services are served only with FQDN (myservice.domain.com) so SNI is OK for that, and some have path based routing (api.gw.com/locate/v1 or api.gw.cm/deal/v1.2 etc ...)\nI can not use both of those system with fabio because SNI take the lead above HTTPS. So i need 2 ports to do that and it's not so easy because developpers need to know the ports of the fabio. I would prefer to use the 443 for the both (like a nginx or haproxy).\nIs it possible to fabio to check the table a little differently : If fabio has a request, check the SNI hostname, if you find a exact match, do with SNI and if not, check the global url to find match\nexample :\nsrc : tomcat.demo.com/ dest : http://192.168.1.2:32225 --> with SNI\nsrc : tomcat.demo.com/book/v2 dest : http://192.168.1.2:32225 --> Classical https\nsrc : api.demo.com/locate/v1 : http://192.168.4.2:17554 --> Classical https\nOne other thing, if i use the same port for HTTPS and SNI and set proto=https and tlsskipverify=true, SNI is used rather that HTTPS and HTTPS upstream .... An other thought about it and maybe a start for an algorithm ...\nImagine to have a setup like this: \nproxy.addr=:443;proto=tcp+nsi,:443;proto=https;cs=mysslcs\nSo we have multiple scenarios with our url-prefix and tags : \n1) urlprefix = mysite.domain.com/\n2) urlprefix = mysite.domain.com/ proto=https\n3) urlprefix = mysite.domain.com/v1/prod/myapi\n4) urlprefix = mysite.domain.com/v1/prod/myapi proto=https\nFor 3) and 4) it's pretty obvious ...\n3) Retrieve the certificate, do the SSL termination and call the backend with HTTP\n4) Retrieve the certificate, do the SSL termination and call the backend with HTTPS (for full SSL end to end)\n2) Retrieve the certificate, do the SSL termination and call the backend with HTTPS (for full SSL end to end)\nFor the 1) it can be a little more complex, but in fact you have just to check if you have a certificate in Fabio. If it's the case, do the SSL Termination. If not use SNI instead.\nOr if you do not have SNI information, check the certificate and do the SSL termination. \nWhat do you think ?\n. Our fabio will be mutualized (at a certain level) between application, and we have 1500 applications to serve.\nFor me applications do not have to understand how it works behind the scenes. Put a certificate in Vault and an urlprefix and they do not need to do more. Everything else is not the responsability of the service. \nWe have automation for certificate, dns record, fabio installation and configuration. But some applications will handle their certificates out of a vault, and we need to adress those needs.\nMy proposal is just to be able to use the same port for tcp+sni and https. The order to check the rules is not from least to more specific, its just examples of each examples can be treated.\nOnly the scenario 1) can have 2 possibilities. And the decision to do sni is based of a presence of certificates in fabio. if not, do sni, if you have a certificate, terminate ssl ... or maybe you can add a tag to help for deciding which method to use. Like terminateSSL=true or false ?\nMy concern is to have to use other port than 443. It start to be complicated to have 2 port for SSL or different hostnames to the same thing (for a developer point of view).\nAnyway i can use man in the middle for both but it seems just not the best approach for performance. and websocket seems to not work with https upstream :). I've the same use case with cqrs micro-service. We would like to have the ability to have the same service/path and route request to the right backend regarding http method (GET for read and POST/PUT for write).. I've got the same error during my bench with vegeta tools ...\nhttps://github.com/tsenart/vegeta\n1500req/s , 10 workers during 3minutes. A lot of errors like this : \n\n2017/05/23 11:49:07 http: proxy error: context canceled\n2017/05/23 11:49:07 http: proxy error: context canceled\n2017/05/23 11:49:07 http: proxy error: context canceled\n2017/05/23 11:49:07 http: TLS handshake error from 184.13.64.47:46838: EOF\n2017/05/23 11:49:07 http: TLS handshake error from 184.13.64.47:59158: EOF\n2017/05/23 11:49:08 http: proxy error: context canceled\n2017/05/23 11:49:08 http: proxy error: context canceled\n2017/05/23 11:49:08 http: TLS handshake error from 184.13.64.47:39837: EOF\n2017/05/23 11:49:09 http: TLS handshake error from 184.13.64.47:51372: EOF\n2017/05/23 11:49:12 http: TLS handshake error from 184.13.64.47:46966: EOF\n2017/05/23 11:49:12 http: TLS handshake error from 184.13.64.47:45049: EOF\n2017/05/23 11:49:12 http: TLS handshake error from 184.13.64.47:36919: EOF\n2017/05/23 11:49:12 http: TLS handshake error from 184.13.64.47:40404: EOF\n2017/05/23 11:49:13 [INFO] consul: Health changed to #308644\n2017/05/23 11:49:18 http: TLS handshake error from 184.13.64.47:53264: EOF\n2017/05/23 11:49:18 http: TLS handshake error from 184.13.64.47:54748: EOF\n2017/05/23 11:49:19 http: TLS handshake error from 184.13.64.47:35223: EOF\n2017/05/23 11:49:19 http: TLS handshake error from 184.13.64.47:52443: EOF\n2017/05/23 11:49:20 http: TLS handshake error from 184.13.64.47:36657: EOF\n\n1 fabio, listening in HTTPS, 5 backend (just 5 nginx with a hello world) serving in HTTP (fabio soes the SSL terminaison)\nSee the error in vegeta : \n\nRequests      [total, rate]            270000, 1500.01\nDuration      [total, attack, wait]    3m23.559738851s, 2m59.999153185s, 23.560585666s\nLatencies     [mean, 50, 95, 99, max]  9.012213368s, 4.520873ms, 38.542513598s, 45.01141293s, 1m0.000954494s\nBytes In      [total, mean]            105788484, 391.81\nBytes Out     [total, mean]            0, 0.00\nSuccess       [ratio]                  64.02%\nStatus Codes  [code:count]             200:172857  0:96521  502:622\nError Set:\nGet https://192.163.167.143:10443/: dial tcp 0.0.0.0:0->192.163.167.143:10443: bind: address already in use\n502 Bad Gateway\nGet https://192.163.167.143:10443/: net/http: TLS handshake timeout\nGet https://192.163.167.143:10443/: net/http: timeout awaiting response headers\nGet https://192.163.167.143:10443/: dial tcp 0.0.0.0:0->192.163.167.143:10443: i/o timeout\n\nNginx use standard configuration (i can maybe tune it a little ...) but only 300req/s per NGINX so not so much.\nFabio use 102400 value for nofile and 32768 for nproc and this : \nsudo sysctl -w fs.file-max=\"9999999\"\nsudo sysctl -w fs.nr_open=\"9999999\"\nI do not know if the client failed (32 cores and 512GB of RAM for running the benchmark), or fabio or nginx ... nor explicit log in nginx . With fabio it is perfectly working with SNI or ssl termination done by fabio. Directly to the upstream it works too.\nIt doesn't work when using man in the middle approach of fabio with the new feature HTTPS Upstream.  To be more precise, i'm using the same certificate in fabio and in the upstream. Tlsskipverify=true is set too. My backend is a tomcat. I will try with sse to check if it's working.. I will test it tuesday and the 274 issue (consul token renewal) too !\nThanks !. Hello, for websocket (wss) it seems to work, thanks !\nBut i've an another issue. To do my testing i'm using the official examples from Tomcat.\nIt exists a Comet testing that fails with https upstream (works in SNI and HTTPS --> HTTP).\nComet processing example:\nSee the \"Advanced IO\" chapter in the User Guide for details. This example only works with the HTTP NIO or HTTP APR/native connectors as these are the only connectors that support Comet.\nThis is the path to test it when you deploy tomcat (normally those examples are in the official tomcat docker images) :\nhttps://tomcat-example/examples/servlets/chat/\nCan you have a look to check why it doesn't work please ? . Ok i will check with some ajax stuff and if it fails, i will open a new issue.. Seems to work for me with Ajax too !. Hello,\nI've made the test and it doesn't seem to work, fabio doesn't want to start, telling me that the port is already used ... Stop fabio, kill every instance, check with netstat (root) and nothing is listening on that port.\nRevert back to 1.4.3 and it works fine (with exact same properties file) ...\nPlease find the logs : \n2017/04/27 09:31:25 [INFO] Runtime config\n{\n    \"Proxy\": {\n        \"Strategy\": \"rr\",\n        \"Matcher\": \"prefix\",\n        \"NoRouteStatus\": 404,\n        \"MaxConn\": 10000,\n        \"ShutdownWait\": 0,\n        \"DialTimeout\": 30000000000,\n        \"ResponseHeaderTimeout\": 0,\n        \"KeepAliveTimeout\": 0,\n        \"FlushInterval\": 1000000000,\n        \"LocalIP\": \"192.163.167.143\",\n        \"ClientIPHeader\": \"\",\n        \"TLSHeader\": \"\",\n        \"TLSHeaderValue\": \"\",\n        \"GZIPContentTypes\": null\n    },\n    \"Registry\": {\n        \"Backend\": \"consul\",\n        \"Static\": {\n            \"Routes\": \"\"\n        },\n        \"File\": {\n            \"Path\": \"\"\n        },\n        \"Consul\": {\n            \"Addr\": \"dckdevdck075.mydomain.com:8543\",\n            \"Scheme\": \"https\",\n            \"Token\": \"xxxxxxxxxxxxxxxxxxxxxxxxx\",\n            \"KVPath\": \"/l7demo1/config\",\n            \"TagPrefix\": \"urlprefix-\",\n            \"Register\": true,\n            \"ServiceAddr\": \":9998\",\n            \"ServiceName\": \"l7demo1\",\n            \"ServiceTags\": null,\n            \"ServiceStatus\": [\n                \"passing\"\n            ],\n            \"CheckInterval\": 1000000000,\n            \"CheckTimeout\": 3000000000,\n            \"CheckScheme\": \"http\",\n            \"CheckTLSSkipVerify\": false\n        },\n        \"Timeout\": 10000000000,\n        \"Retry\": 500000000\n    },\n    \"Listen\": [\n        {\n            \"Addr\": \"dckdevdck075:11443\",\n            \"Proto\": \"tcp+sni\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"RenewToken\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false\n        },\n        {\n            \"Addr\": \"dckdevdck075:12443\",\n            \"Proto\": \"https\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"ssl-vault\",\n                \"Type\": \"vault\",\n                \"CertPath\": \"secret/fabiodemo-001/certs\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 3000000000,\n                \"RenewToken\": 900000000000,\n                \"Header\": null\n            },\n            \"StrictMatch\": false\n        }\n    ],\n    \"Log\": {\n        \"AccessFormat\": \"$remote_host - - [$time_common] \\\"$request\\\" $request_proto $response_status $response_body_size $upstream_addr $upstream_host $upstream_port $upstream_request_url $upstream_request_uri\",\n        \"AccessTarget\": \"stdout\",\n        \"RoutesFormat\": \"delta\"\n    },\n    \"Metrics\": {\n        \"Target\": \"statsd\",\n        \"Prefix\": \"{{clean .Hostname}}.{{clean .Exec}}\",\n        \"Names\": \"{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.{{clean .TargetURL.Host}}\",\n        \"Interval\": 30000000000,\n        \"GraphiteAddr\": \"\",\n        \"StatsDAddr\": \"184.44.245.74:8125\",\n        \"Circonus\": {\n            \"APIKey\": \"\",\n            \"APIApp\": \"fabio\",\n            \"APIURL\": \"\",\n            \"CheckID\": \"\",\n            \"BrokerID\": \"\"\n        }\n    },\n    \"UI\": {\n        \"Listen\": {\n            \"Addr\": \":9998\",\n            \"Proto\": \"http\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"RenewToken\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false\n        },\n        \"Color\": \"light-green\",\n        \"Title\": \"\"\n    },\n    \"Runtime\": {\n        \"GOGC\": 800,\n        \"GOMAXPROCS\": 1\n    }\n}\n2017/04/27 09:31:25 [INFO] Version  starting\n2017/04/27 09:31:25 [INFO] Go runtime is go1.8.1\n2017/04/27 09:31:25 [INFO] Sending metrics to StatsD on 184.44.245.74:8125 as \"dckdevdck075.fabio\"\n2017/04/27 09:31:25 [INFO] Sending metrics to StatsD on 184.44.245.74:8125 as \"dckdevdck075.fabio\"\n2017/04/27 09:31:25 [INFO] Setting GOGC=800\n2017/04/27 09:31:25 [INFO] Setting GOMAXPROCS=1\n2017/04/27 09:31:25 [INFO] consul: Connecting to \"dckdevdck075.mydomain.com:8543\" in datacenter \"dcfabio\"\n2017/04/27 09:31:25 [INFO] Admin server listening on \":9998\"\n2017/04/27 09:31:25 [INFO] Waiting for first routing table\n2017/04/27 09:31:25 [INFO] consul: Using dynamic routes\n2017/04/27 09:31:25 [INFO] consul: Using tag prefix \"urlprefix-\"\n2017/04/27 09:31:25 [INFO] consul: Watching KV path \"/l7demo1/config\"\n2017/04/27 09:31:25 [INFO] consul: Manual config changed to #1\n2017/04/27 09:31:25 [INFO] TCP+SNI proxy listening on dckdevdck075:11443\n2017/04/27 09:31:25 [INFO] consul: Health changed to #21965\n2017/04/27 09:31:25 [INFO] Config updates\n+ route add l7demo1-tomcatfabiosni tomcat-sni.mydomain.com/ http://dckdevdck012:30005/\n+ route add l7demo1-tomcatfabio tomcat-fabio.mydomain.com/ https://dckdevdck012:30030 opts \"proto=https tlsskipverify=true\"\n2017/04/27 09:31:25 [INFO] consul: Registered fabio with id \"l7demo1-dckdevdck075-9998\"\n2017/04/27 09:31:25 [INFO] consul: Registered fabio with address \"192.163.167.143\"\n2017/04/27 09:31:25 [INFO] consul: Registered fabio with tags \"\"\n2017/04/27 09:31:25 [INFO] consul: Registered fabio with health check to \"http://[192.163.167.143]:9998/health\"\n2017/04/27 09:31:25 [INFO] HTTPS proxy listening on dckdevdck075:12443\n2017/04/27 09:31:25 [INFO] Writing access log to stdout\n2017/04/27 09:31:25 [INFO] Using routing strategy \"rr\"\n2017/04/27 09:31:25 [INFO] Using route matching \"prefix\"\n2017/04/27 09:31:25 [FATAL] listen: Fail to listen. listen tcp 192.163.167.143:12443: bind: address already in use\n2017/04/27 09:31:25 [FATAL] accept tcp 192.163.167.143:12443: use of closed network connection\n2017/04/27 09:31:25 [INFO] consul: Deregistering fabio\n2017/04/27 09:31:25 [FATAL] ui: http: Server closed. I try an another port, and no need to wait, the fabio process is immediatly killed with the fatal error.\nPlease find the commands i use to show you the issue. I've started with the issue-274 branch and just after with the 1.4.3. You will see that the 1.4.3 works fine on the same server with the same config (i've just changed the symbolink link for the fabio binary).\n-bash-4.2$ netstat -an | grep 12443\n-bash-4.2$ ps -edf | grep fabio\nwebdev01 27842 26465  0 10:45 pts/2    00:00:00 grep --color=auto fabio\n-bash-4.2$ ./fabio.start start\n Starting  Fabio\n-bash-4.2$ tail -f logs/fabio.out\n2017/04/27 10:45:10 [INFO] consul: Registered fabio with tags \"\"\n2017/04/27 10:45:10 [INFO] consul: Registered fabio with health check to \"http://[192.163.167.143]:9998/health\"\n2017/04/27 10:45:10 [INFO] HTTPS proxy listening on dckdevdck075:12443\n2017/04/27 10:45:10 [INFO] Writing access log to stdout\n2017/04/27 10:45:10 [INFO] Using routing strategy \"rr\"\n2017/04/27 10:45:10 [INFO] Using route matching \"prefix\"\n2017/04/27 10:45:10 [FATAL] listen: Fail to listen. listen tcp 192.163.167.143:12443: bind: address already in use\n2017/04/27 10:45:10 [FATAL] accept tcp 192.163.167.143:12443: use of closed network connection\n2017/04/27 10:45:10 [INFO] consul: Deregistering fabio\n2017/04/27 10:45:10 [FATAL] ui: http: Server closed\n-bash-4.2$ cd bin/\n-bash-4.2$ rm fabio\n-bash-4.2$ ls\nfabio-1.4.2-go1.8.1-linux_amd64  fabio-1.4.3-go1.8.1-linux_amd64  fabio-custom\n-bash-4.2$ ln -s fabio-1.4.3-go1.8.1-linux_amd64 fabio\n-bash-4.2$ netstat -an | grep 12443\n-bash-4.2$ ps -edf | grep fabio\nwebdev01 28201 26465  0 10:49 pts/2    00:00:00 grep --color=auto fabio\n-bash-4.2$ cd ..\n-bash-4.2$ ./fabio.start start\n Starting  Fabio\n-bash-4.2$ tail -f logs/fabio.out\n+ route add l7demo1-tomcatfabio tomcat-fabio.mydomain.com/ https://dckdevdck012:30030 opts \"proto=https tlsskipverify=true\"\n2017/04/27 10:49:41 [INFO] consul: Registered fabio with id \"l7demo1-dckdevdck075-9998\"\n2017/04/27 10:49:41 [INFO] consul: Registered fabio with address \"192.163.167.143\"\n2017/04/27 10:49:41 [INFO] consul: Registered fabio with tags \"\"\n2017/04/27 10:49:41 [INFO] consul: Registered fabio with health check to \"http://[192.163.167.143]:9998/health\"\n2017/04/27 10:49:41 [INFO] HTTPS proxy listening on dckdevdck075:12443\n2017/04/27 10:49:41 [INFO] Writing access log to stdout\n2017/04/27 10:49:41 [INFO] Using routing strategy \"rr\"\n2017/04/27 10:49:41 [INFO] Using route matching \"prefix\"\n2017/04/27 10:49:41 [INFO] cert: Store has certificates for [\"tomcat-fabio.mydomain.com,tomcat-sni.mydomain.com\"]\n. Find something with the proxy address : \nIf i put 2 listeners in proxy.addr fabio fails to start ...\nproxy.cs=cs=ssl-vault;type=vault;cert=secret/fabiodemo-001/certs;renewtoken=900s\nproxy.addr = dckdevdck075:10080;proto=http,dckdevdck075:10443;proto=https;cs=ssl-vault\nWith this config it works with your patch (only 1 listener): \nproxy.cs=cs=ssl-vault;type=vault;cert=secret/fabiodemo-001/certs;renewtoken=900s\nproxy.addr = dckdevdck075:10443;proto=https;cs=ssl-vault. Hi, i've made some test and i think it doesn't work as expected. In fact, the renewSelf function is called in the load function (vault_source.go) each time you want to refresh the certificates list.\nIn my configuration i've a lease of 20mn for a token , i set the refresh to 1m and the renewtoken to 7mn in Fabio : \nproxy.cs=cs=ssl-vault;type=vault;cert=secret/fabiodemo-001/certs;renewtoken=7m;refresh=1m\nBut at the end, the token is renew every minutes : \n{\"time\":\"2017-05-02T15:22:10Z\",\"type\":\"response\",\"error\":\"\",\"auth\":{\"client_token\":\"\",\"accessor\":\"\",\"display_name\":\"approle\",\"policies\":[\"default\",\"fabiodemo-001/fabio-certs\"],\"metadata\":{}},\"request\":{\"id\":\"b849194f-1e95-7209-87da-3158bbba1def\",\"operation\":\"update\",\"client_token\":\"hmac-sha256:97a2695fb7001d40834599dee3d3b8fe3b0928747c4e026382c0662e93d04ccf\",\"path\":\"auth/token/renew-self\",\"data\":{\"increment\":\"hmac-sha256:58e823f12d627954719c9004391839f8cb6d39d9efa5269727700c04026b9ee7\"},\"remote_address\":\"192.160.120.50\",\"wrap_ttl\":0},\"response\":{\"auth\":{\"client_token\":\"hmac-sha256:97a2695fb7001d40834599dee3d3b8fe3b0928747c4e026382c0662e93d04ccf\",\"accessor\":\"hmac-sha256:ffbdbe987b69e3fde640542b39ee04a69ead65572b841a2469716e07125378e5\",\"display_name\":\"approle\",\"policies\":[\"default\",\"fabiodemo-001/fabio-certs\"],\"metadata\":{}}}}\n{\"time\":\"2017-05-02T15:23:10Z\",\"type\":\"response\",\"error\":\"\",\"auth\":{\"client_token\":\"\",\"accessor\":\"\",\"display_name\":\"approle\",\"policies\":[\"default\",\"fabiodemo-001/fabio-certs\"],\"metadata\":{}},\"request\":{\"id\":\"1a9b65c7-2cde-1d6d-77a3-6c308fed0973\",\"operation\":\"update\",\"client_token\":\"hmac-sha256:97a2695fb7001d40834599dee3d3b8fe3b0928747c4e026382c0662e93d04ccf\",\"path\":\"auth/token/renew-self\",\"data\":{\"increment\":\"hmac-sha256:58e823f12d627954719c9004391839f8cb6d39d9efa5269727700c04026b9ee7\"},\"remote_address\":\"192.160.120.49\",\"wrap_ttl\":0},\"response\":{\"auth\":{\"client_token\":\"hmac-sha256:97a2695fb7001d40834599dee3d3b8fe3b0928747c4e026382c0662e93d04ccf\",\"accessor\":\"hmac-sha256:ffbdbe987b69e3fde640542b39ee04a69ead65572b841a2469716e07125378e5\",\"display_name\":\"approle\",\"policies\":[\"default\",\"fabiodemo-001/fabio-certs\"],\"metadata\":{}}}}. Any update on this topic ?. I want to decorelate the certificate renew and the token renewal. I can set the renewal token to 20mn for example and certificate every 1mn. But in the current implementation, the token is refreshed everytime the certificates are updated. So the Vault logs are flooded by token renewal. And i do not need to to refresh every minute ...\nSo i would like to have those parameters working as expected.. Even if the node-4 has a 0 weight it can not be served if node-1 2 or 3 are up. Node 4 or 5 (regardless the weight) can not serve request if one of the node 1,2 or 3 is up. The main idea if it's the service can not answer, use a fallback node to have a response anyway and not a 503 or 404 error. It's like the concept of circuit breaker like hystrix. \nNormally if node 1, 2 and 3 are down, they do not appear in the routing table, so the only node that can respond are node 4 and 5. But when a normal node come back, the tag fallback must discard node 4 and 5 to serve request and the priority is done to normal nodes.\nDoes it make sense to you ?. Yep but playing with weight can be confusing sometimes :) A good named flag to define the route to go in case of no service is clearer to understand and setup :). Ok cluster consul doesn't fail easily (we've issue but ok). Agent (client) consul can failed, and we are using it at localhost fot the HTTPS port (8543). So a LB can not have access to it to check the state ...\nIf we change that, we need to do a health check in HTTPS to consul agent and our load balancer do not handle HTTPS health check (need to have our root ca in it and/or certificates, and it's a nightmare to handle).\nAnd yes, i prefer to disabled a fabio that can not access consul, because if a route is changed during the outage, the client will have error from fabio and it's rood because you have an another fabio instance that can respond correctly ... If the LB discard the fabio instance without consul, traffic will be redirected to the good one.\nI can add a route or something like that, but a user can delete it and failed the fabio ... (and only in HTTPS) I dont want to open http and https (only https).\n. A read-only option, a secure way to access (LDAP, oauth2 etc...) or a disable switch will be good solutions regarding security.\nThe Best is authentication for me. But it's not the simpliest one for a first shot :) a read-only option can be a good start !. I understand it becomes tricky for the off option. A ro and rw option can do it actually.\nAn another option : Set a token in the UI (ACL with write right) like in the Consul UI to be able to modify some routes for example ? It's just a thought :) By default it's RO and to be able to modify, you need a consul token, so it can bring some \"security\".\n. Hello,\nOur fabio are not exposed to internet so it's more like that:\nLoad Balancer (Appliance) https://foo.com/bar --> Fabio (4 instances at least) --> https://1.2.3.4/bar\nWe can not use wildcard for our certificates (forbidden by the security) in a banking context.\nFabio and services are containers running on the same platform. For each application, we deploy a Load Balancer (Appliance), 4 Fabio instances on  a dedicated overlay network and the services (containers too) are connected to this overlay network.\nOn the same platform we have multiple time this setup for each application and environment (dev, int, uat ...) So i can not use a 10.0.0.0/8 wildcard certificate (because it can not be generated by our PKI) and it will break the multi-tenancy of the platform.\nWe are using a mutualized platform for running containers of many applications.\nSo to be sure that a service is served by the right Fabio (or to ensure that Fabio serve the right service), it will be a good thing to check the CN of the certificate backend and not it's IP. Of course it's not the normal behaviour and must be an option for some use case like mine. The normal behaviour is to check the CN/SAN of the back-end with the back-end FQDN registered in consul (for my use case an IP).\nWith containers, generate a certificate each time a container is created its a too heavy operation and difficult to maintain (certificate revocation will be a nightmare ...). I think that i'm not the only one in that case :)\n. I'm not sure to understand the behaviour of this : With host=dst, what will be the header when connecting the upstream ? The upstream hostname/ip ? Or the hostname header coming to Fabio ?  . Yes it makes sense. In my use case, the TLS server name has to be the original hostname indeed.\nI do not know what is the best thing to do. DNS spoofing or TCP connection first and TLS handshake after. What is the most secure ?\n. Hello, did you have time to try some stuff for this use case ?. Did you put the three options in the same consul tag ?. You need to install a local consul agent and to configure this consul agent to connect to the consul cluster.\nGenerally, the local consul agent listens on localhost:8500, so you have to set in fabio.properties this parameter : \nregistry.consul.addr = localhost:8500\nAnd adapt to your needs.\nFor consul agent, you need to check the setup with consul documentation : \nhttps://www.consul.io/docs/agent/options.html. Hello,\nI've the same issue here -->\nFabio (container), API (containers) and Consul Agent (process) are on the same host.\nHealth Check are done by docker-exec health check from the agent to the containers.\nFabio and API use the same overlay network. Sometimes we have some network issue on the overlay and fabio can not access to some containers. For example, we have 4 instances of our containers, and 2 can not be reached by fabio. We can see errors in log (no backend error etc ...). We try a ping or curl from the fabio container to API and we have the same error.\nBUT, consul health-check is OK ... because it's a docker exec that run a script in the container itself (like a curl localhost/health).\nSo if the consul health-check is OK but the network failed between fabio and the containers, the route still the same and fabio continue to reach the backend that can not be reached ...\nSo, if fabio can blacklist backend that can not be reached, event if the health-check is OK will be a very important feature for application availability ...\n. Or put the ca-certificate in a docker secret and retrrieve it on the container statup. With that, you do not need to mount volume. In the fabio config file, use the /run/secret/my-ca-certificate-crt (your secret name) as a ca-certificate.\nDoes it make sense ?\n. Did you check the X-Forwared-For header in your backend ? Proxies set this value to pass the IP of the  client of the initial request.. ",
    "agonzalezandino": "+1 that'd be cool!. ",
    "tbouvet": "+1. Same problem.\nI try to add a route like : \n\nroute add new_service xx.domain.com http://a-new-url.zz.com\n\nFabio log : \n2017/09/27 14:21:34 http: proxy error: context canceled\n2017/09/27 14:21:34 http: proxy error: context canceled\n2017/09/27 14:21:34 http: proxy error: context canceled\n. + service-a service.production.mydomain.com/ http://192.168.100.10:80/ \n+ new-service service.mydomain.com/ http://service.production.mydomain.com\n```` . The error is when I test `http://service.mydomain.com` .\nMy simple config :\nproxy.addr = :9999,:443;proto=tcp+sni,:1234;proto=tcp\n. @magiconair For example, I want to change log level.. Yes too many health changed :\n2017/09/28 07:30:03 [INFO] consul: Health changed to #42680\n2017/09/28 07:30:03 [INFO] consul: Health changed to #42683\n2017/09/28 07:30:50 [INFO] consul: Health changed to #42690\n2017/09/28 07:30:50 [INFO] consul: Health changed to #42693\n2017/09/28 07:31:00 [INFO] consul: Health changed to #42696\n2017/09/28 07:31:00 [INFO] consul: Health changed to #42698\n2017/09/28 07:31:00 [INFO] consul: Health changed to #42699\n2017/09/28 07:31:05 [INFO] consul: Health changed to #42701\n2017/09/28 07:31:05 [INFO] consul: Health changed to #42703\n2017/09/28 07:31:05 [INFO] consul: Health changed to #42704\n2017/09/28 07:31:58 [INFO] consul: Health changed to #42713\n2017/09/28 07:31:58 [INFO] consul: Health changed to #42716\n2017/09/28 07:32:10 [INFO] consul: Health changed to #42718\n2017/09/28 07:32:10 [INFO] consul: Health changed to #42721\n2017/09/28 07:32:29 [INFO] consul: Health changed to #42726\n2017/09/28 07:32:29 [INFO] consul: Health changed to #42729\n2017/09/28 07:32:41 [INFO] consul: Health changed to #42730\n2017/09/28 07:32:41 [INFO] consul: Health changed to #42733\n```\nSo maybe a log level should be good (debug/info/warn). ok thank you for your help \ud83d\udc4d . ",
    "nuriel77": "+1. Ok, I see that it is not possible to combine both consul and static routes in the config file, as this is what I initially tried to do.\nI will find a solution using the consul kv.. @vjeantet as noted in my last comment: I did not find a way to do that. If I understand correctly, this is not possible.. @leprechau @vjeantet Thanks. I completely forgot this is how I solved it (solution is already in production for a while now).\nThe reason I initially said I thought it was not possible was because I tried to set static route in the fabio.properties file.\nI can confirm that I am setting static routes via consul KV along side having fabio read routes from Consul services.\nWhat I have done was edit the systemd control file (/etc/systemd/system/fabio.service) to run a ExecStartPost command to set a static route I had to add:\nExecStartPost=/usr/bin/curl -X PUT -H \"Content-Type: application/json\" -k http://consul:8500/v1/kv/fabio/config -d \"route add svc health.app.some.domain/ https://app.other.domain/\"\nExecStart=/opt/fabio/bin/fabio $OPTIONS. ",
    "marcosnils": "@magiconair I'd love to use this feature natively instad of the statsd prometheus exporter. Do you need a hand with this?. Do you have a branch with this feature where I can collaborate?.\nOn a different subject Hashicorp's Nomad uses their on go-metrics  (https://github.com/armon/go-metrics) package that translates metrics directly to graphite, statsd and prometheus. I haven't evaluated how difficult would be to change the current go-metrics package for his one, but seems like this would solve a lot of issues and remove some extra dependencies as well.. > I'm not sure how we can collaborate on a PR on Github\nWe can fork your code and open a PR to the metrics4 branch directly. If you merge your PR will get updated automatically. \nThanks for the hard work @magiconair . I'll give it a look this week and contribute in whatever I can.. Not really, been extremely busy with some other stuff. Might be able to take a look some time this week. Can't promise anything though. @KHiis not really. I'm currently using fabio statsd support and  statsd_exporter (https://github.com/prometheus/statsd_exporter) to push metrics to prom. Would love to add native prom support it's just that I don't have the time.. @kikdevops here's my mapping config\nyaml\nmappings:\n- match: ^([^.]*)\\.([^.]*)--http.status.([^.]*).count\n  match_type: \"regex\"\n  name: \"fabio_http_status_count\"\n  labels:\n    code: \"$3\"\n    instance: \"$1\"\n- match: .\n  match_type: \"regex\"\n  action: drop\n  name: dropped. Ping?. Any ideas?. Seems like certificate is now valid. I'll close this. \nAs a suggestion it might be recommended to bundle UI assets so an internet connection is not required to serve them. Will try if I find the time.. IIUC fabio should match the routes from the most specific to the most generic one. So, in this particular case I'd expect to match the *.edge.foo.com for the hostname api.edge.foo.com. @magiconair thanks a lot for taking the time to test this. I haven't checked but in @arrodriguez example there's a path in the URL. Maybe that's causing the issue?. right. Please go ahead and close this if you consider it's not necessary to support linux builds.. ",
    "alexebird": "@magiconair @marcosnils I'd like to help out with this if it's still needed.. ",
    "rileyje": "@magiconair has there been any progress on labeled metrics? I'm also willing to help with this.. Thanks @magiconair. I tried to address your feedback with these changes:\n\nremoved UpdateAliases() and moved parse code to ParseAliases() in route/parse_new.go. Implements a subset of Parse(), so there is some redundancy. Better to just call Parse()?. Had to import config to check if fabio should register itself. Can't get that from the private config member of the backend. Brought in log for some visibility.\nAdded DeregisterAll(), but kept Deregister() for single deregistrations. I wasn't sure if that's what you had in mind.\nExtended Register() to handle removal and addition of aliases.\nChanged option name to register (much better :)\nStill tracking registered services in b.dereg map. Is that OK? Wasn't clear on \"you need to keep the state of what is registered in the backend anyway\"\n\nI had a couple of questions while working on this:\n\nWould you be OK with adding \"DeregisterCriticalServiceAfter\" to registrations so that if fabio exits uncleanly, Consul will clean up services? That was added in Consul 0.7.0, not sure if you have a minimum support Consul version or we could check version with the API before including that option.\nAny concerns about duplicate health checks? Would be nice if Consul allowed you to specify an existing health check when registering a service. I can open a feature request against Consul.\nDo you have any thoughts on test coverage for Register() and Deregister(All)()?\n\nI see the Travis CI build failed, I'll look in to that.. @magiconair here is the latest version of the patch.\n- Updated Commands const to included register. I noticed that host was missing and took the liberty of adding it.\n- Updated docs to include register option.\n- Removed config check from ParseAliases() and moved it to Consul backend\n- Added comment for ParseAliases()\n- Added tests for ParseAliases()\n- Removed unneeded magic value from Deregister()\n- Factored out excess indents\n- Cleaned up logging statements\n- Added DeregisterCriticalServiceAfter as a separate commit. Used the 90m default from Consul docs. Not sure if that fits your definition of sane :) We will likely set it to something much shorter in production.. Great, thank you!. ",
    "KHiis": "Any updates on this?. @marcosnils Do you have any answers?. ",
    "kikdevops": "@marcosnils can you provide statsd_exporter mappings? Can't figure out why my mappings don't working.. @marcosnils Thanks a lot.. ",
    "gregoryguillou": "You're fast! I understand it is quite a big change for that exact reason. It would also change the UI and it would impact existing/well tested systems. I was just curious if that could be of some interest to people. It would be to us.. I am, very much and we are using it for more than 1 year now. I especially like the access log now to monitor internal calls. I assume I should try to implement it at some point.. ",
    "gagan2u2002": "But in my case if you are looking fabio screen no service removed from UI .\nservice registered on 8080 port is not UP on my box and it still shows its there.\nTest case is : i have run 3 instance of my service on my local box with port 8080, 8081 and 8082 and when i stopped service on port 8080 then after some time i am getting response from  http://localhost:9999/ - in my case service name is world/myworld\n as 404 because it divert me that port which is not UP on my box. \n. Hi ,\ni am going to share fresh logs file with you , \nReproduce steps \nSTEP 1:  i have run 3 instance of my service on port 8080, 8081 and 8082 , [ my service code is already on git you can use this (https://github.com/gagan2u2002/springboot-consul-Fabio-Integration-example)]\nSTEP 2:  when i close my service instance on 8080 then fabio is not responding even my service is responding me on port 8081 and 8082.  Please refer the screen below  -\n\nrefer today  (01/18/2017) log of consul and fabio-\nconsul_log_18_01_2017.txt\nFabio_log_18_01_2017.txt\nEven if you want i can have skype session with you so that i will show you the error demo  but i think you can reproduce it your own to follow steps which i mention.\n. i think i have resolve your query can we change issue label to Bug if you are okay with it .. @magiconair \nif you looking consul log then it say 8080 service is stopped \n2017/01/18 11:44:02 [WARN] agent: http request failed 'http://127.0.0.1:8080/health': Get http://127.0.0.1:8080/health: dial tcp 127.0.0.1:8080: connectex: No connection could be made because the target machine actively refused\n it.\nbut if you looking Fabio log then it say its there \nroute add slpconsulDemo /world http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\nroute add slpconsulDemo /myworld http://C40-BF91.india.rsystems.com:8080/ tags \"urlprefix-/myworld,urlprefix-/world\"\nMy test cases are very simple , i have run 3 instances as i already described you earlier and i have stopped 1 instances , if i am hitting my fabio url then after some time it will through error but still my service is UP and responding in my box and same i can see in consul but fabio routing table is not updated on it's UI might be this is the root course of the problem. \n. And yes still this issue is open at my end . So if you can close this , this would be good at my end . \nif any of the assistance needed please let me know.. @magiconair \nspring.cloud.consul.discovery.health-check-url=http://127.0.0.1:8080/health\nthis code help me to register health check in consul.\nBut i don't think so this could be consul issue because fabio routing table need to update by fabio itself. Consul doing its job as expected.. @magiconair  i have even wait for long than 10 seconds after killing 1 st instance of services on 8080 but Fabio not able to route services on 8081 and 8082 port  ,  also i observed Fabio is not updating its routing table  too but my services return me the results on my dev environment on port 8081 and 8082.\ni  have attach log of fabio and consul for your reference. Please refer the same.\nconsul UI screen after killing 8080 instance -\n\nconsul_log_27_01.txt\nFabio_log_27_01.txt\n. @magiconair i think i have resolve your query , is there is any update regarding this .... or we can mark this issue as BUG .....if you validate this issue at your end.\nIf this is not clear i am okay to have skype call with you as i already told you earlier.. @magiconair when i down first instance of service then other instances of that service become critical but when i check health of each instance then  they will return me Response code 200. \nbut as per your statement like Fabio even not pick those service they are critical that seems more dangerous for implementation perspective in Production because practically this is possible first instance of service will down and if Fabio will not pick other instances then my whole system will break down in this case. So as per my view this is a clear BUG and it should be resolved , what you suggest.. ",
    "alvaroaleman": "So, I just found this after testing Fabio and finding out it doesn't remove routes for unhealthy services which was caused by non-unique service IDs. To quote the fabio docs regarding that:\n\nMake sure that each instance registers with a unique ServiceID and a service name without spaces.\n\nThis directly contradicts the Consul docs which state:\n\nID (string: \"\") - Specifies a unique ID for this service. This must be unique per agent\n\n@magiconair Can you explain what is the reason fabio requires the service id to be unique per consul cluster?\nAlso I think it would be smart to have Fabio at least emit a warning in case multiple services instances with the same id exist, because that is actually the way it is supposed to be done in Consul.. Ill just continue our conversation from #216 here since this issue here is more specific about the same problem.\n\nCan you elaborate why cluster wide unique service ids like I've described are not achievable? I'm curious for the motivation.\n\nWell, it is achievable but the Consul doc explicitly states that this is not required so people won't be doing it. This also means if someone doesn't explicitly test this he or her will only realize on service failure that Fabio expects Consul to be used in a different way than the actual Consul docs say its supposed to be used.\nAre you currently working on this? Otherwise I'd like to prepare a PR.. Updated passing_test.go.\nThanks btw for your awesome work and really fast reaction on issues/PRs!. @dropje86 Does that actually result in Go not evaluating the other conditionals?\n@magiconair Is there still something missing from your POV?. Interesting, thanks for the link @dropje86!\nI've added a second commit that simplifies the conditional logic in passing.go and avoids unnecessary evaluations, depending on what @magiconair thinks I can either squash it or put it in a separate PR. . ",
    "ygersie": "@magiconair this can be closed as well, fixed in #414 . I understand how to workaround it but the thing is, this is Consul spec. A serviceID is optional and will be set to serviceName if unset. Quote from James in gitter.im/hashicorp-consul:\n\nAh that's interesting - yeah Fabio probably needs to use \\<node>.\\<service id> as a key or something similar.\n(that's what the Consul servers do internally)\n\nIf this behavior is intentional than it should be clearly noted somewhere:\nNOTE: Fabio expects a service registration with a \"global\" unique serviceID\nAnd maybe document what happens if you don't so ppl running into this issue can find the reason for unexpected behavior. I think in general c.Node == svc.Node should be the first thing to evaluate, right? The Node will always be the most specific condition in that loop, while for example serfHealth will be hit for every consul agent. . @alvaroaleman Although not clearly documented, Go does use \"Short circuit evaluation\". See here: https://kuree.gitbooks.io/the-go-programming-language-report/content/22/text.html. If you want to align with what Consul servers internally do:\nfmt.Sprintf(\"%s.%s\", check.Node, check.ServiceID). ",
    "bluen": "Screen shots:\nfabio-1.3.5 - \nfabio-1.3.6 - \n. ",
    "digiman999": "Hi Frank, thanks for the response.  Adding -p 8500:8500 gives \ndocker: Error response from daemon: driver failed programming external connectivity on endpoint fabio3 (61a7aa092b0486bc33157b996b52c0c44a22208029d75fa321d953bb8d472a86): Bind for 0.0.0.0:8500 failed: port is already allocated.\n8500 is already allocated for Consul.\nNot sure if I can access the logs because it looks like they're inside the (would be) container.. **docker run -d -p 443:443 -p 9998:9998 magiconair/fabio**\ncreates a container but exits immediately.  docker logs <id> shows\n[INFO] Runtime config\n{\n    \"Proxy\": {\n        \"Strategy\": \"rnd\",\n        \"Matcher\": \"prefix\",\n        \"NoRouteStatus\": 404,\n        \"MaxConn\": 10000,\n        \"ShutdownWait\": 0,\n        \"DialTimeout\": 30000000000,\n        \"ResponseHeaderTimeout\": 0,\n        \"KeepAliveTimeout\": 0,\n        \"FlushInterval\": 1000000000,\n        \"LocalIP\": \"172.17.0.3\",\n        \"ClientIPHeader\": \"\",\n        \"TLSHeader\": \"\",\n        \"TLSHeaderValue\": \"\",\n        \"GZIPContentTypes\": null\n    },\n    \"Registry\": {\n        \"Backend\": \"consul\",\n        \"Static\": {\n            \"Routes\": \"\"\n        },\n        \"File\": {\n            \"Path\": \"\"\n        },\n        \"Consul\": {\n            \"Addr\": \"localhost:8500\",\n            \"Scheme\": \"http\",\n            \"Token\": \"\",\n            \"KVPath\": \"/fabio/config\",\n            \"TagPrefix\": \"urlprefix-\",\n            \"Register\": true,\n            \"ServiceAddr\": \":9998\",\n            \"ServiceName\": \"fabio\",\n            \"ServiceTags\": null,\n            \"ServiceStatus\": [\n                \"passing\"\n            ],\n            \"CheckInterval\": 1000000000,\n            \"CheckTimeout\": 3000000000\n        }\n    },\n    \"Listen\": [\n        {\n            \"Addr\": \":9999\",\n            \"Proto\": \"http\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false\n        }\n    ],\n    \"Metrics\": {\n        \"Target\": \"\",\n        \"Prefix\": \"{{clean .Hostname}}.{{clean .Exec}}\",\n        \"Names\": \"{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.{{clean .TargetURL.Host}}\",\n        \"Interval\": 30000000000,\n        \"GraphiteAddr\": \"\",\n        \"StatsDAddr\": \"\",\n        \"Circonus\": {\n            \"APIKey\": \"\",\n            \"APIApp\": \"fabio\",\n            \"APIURL\": \"\",\n            \"CheckID\": \"\",\n            \"BrokerID\": \"\"\n        }\n    },\n    \"UI\": {\n        \"Addr\": \":9998\",\n        \"Color\": \"light-green\",\n        \"Title\": \"\"\n    },\n    \"Runtime\": {\n        \"GOGC\": 800,\n        \"GOMAXPROCS\": 8\n    }\n}\n2017/02/01 09:08:25 [INFO] Version 1.3.7 starting\n2017/02/01 09:08:25 [INFO] Go runtime is go1.7.4\n2017/02/01 09:08:25 [INFO] Metrics disabled\n2017/02/01 09:08:25 [INFO] Setting GOGC=800\n2017/02/01 09:08:25 [INFO] Setting GOMAXPROCS=8\n2017/02/01 09:08:25 [FATAL] Error initializing backend. Get http://localhost:8500/v1/agent/self: dial tcp [::1]:8500: getsockopt: connection refused\n**docker run -d -p 9999:9999 -p 9998:9998 --link consul magiconair/fabio**\ntrying to link to the consul container shows\n[INFO] Runtime config\n{\n    \"Proxy\": {\n        \"Strategy\": \"rnd\",\n        \"Matcher\": \"prefix\",\n        \"NoRouteStatus\": 404,\n        \"MaxConn\": 10000,\n        \"ShutdownWait\": 0,\n        \"DialTimeout\": 30000000000,\n        \"ResponseHeaderTimeout\": 0,\n        \"KeepAliveTimeout\": 0,\n        \"FlushInterval\": 1000000000,\n        \"LocalIP\": \"172.17.0.3\",\n        \"ClientIPHeader\": \"\",\n        \"TLSHeader\": \"\",\n        \"TLSHeaderValue\": \"\",\n        \"GZIPContentTypes\": null\n    },\n    \"Registry\": {\n        \"Backend\": \"consul\",\n        \"Static\": {\n            \"Routes\": \"\"\n        },\n        \"File\": {\n            \"Path\": \"\"\n        },\n        \"Consul\": {\n            \"Addr\": \"localhost:8500\",\n            \"Scheme\": \"http\",\n            \"Token\": \"\",\n            \"KVPath\": \"/fabio/config\",\n            \"TagPrefix\": \"urlprefix-\",\n            \"Register\": true,\n            \"ServiceAddr\": \":9998\",\n            \"ServiceName\": \"fabio\",\n            \"ServiceTags\": null,\n            \"ServiceStatus\": [\n                \"passing\"\n            ],\n            \"CheckInterval\": 1000000000,\n            \"CheckTimeout\": 3000000000\n        }\n    },\n    \"Listen\": [\n        {\n            \"Addr\": \":9999\",\n            \"Proto\": \"http\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false\n        }\n    ],\n    \"Metrics\": {\n        \"Target\": \"\",\n        \"Prefix\": \"{{clean .Hostname}}.{{clean .Exec}}\",\n        \"Names\": \"{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.{{clean .TargetURL.Host}}\",\n        \"Interval\": 30000000000,\n        \"GraphiteAddr\": \"\",\n        \"StatsDAddr\": \"\",\n        \"Circonus\": {\n            \"APIKey\": \"\",\n            \"APIApp\": \"fabio\",\n            \"APIURL\": \"\",\n            \"CheckID\": \"\",\n            \"BrokerID\": \"\"\n        }\n    },\n    \"UI\": {\n        \"Addr\": \":9998\",\n        \"Color\": \"light-green\",\n        \"Title\": \"\"\n    },\n    \"Runtime\": {\n        \"GOGC\": 800,\n        \"GOMAXPROCS\": 8\n    }\n}\n2017/02/01 08:49:30 [INFO] Version 1.3.7 starting\n2017/02/01 08:49:30 [INFO] Go runtime is go1.7.4\n2017/02/01 08:49:30 [INFO] Metrics disabled\n2017/02/01 08:49:30 [INFO] Setting GOGC=800\n2017/02/01 08:49:30 [INFO] Setting GOMAXPROCS=8\n2017/02/01 08:49:30 [FATAL] Error initializing backend. Get http://localhost:8500/v1/agent/self: dial tcp [::1]:8500: getsockopt: connection refused\n**docker run -d -p 9999:9999 -p 9998:9998 -p 8500:8500 --link consul magiconair/fabio**\ntrying to make 8500 available via consul<>host<>fabio gives no docker logs but shows\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint flamboyant_leavitt (f85bd085108754f63ccadb448a00dd11fbcd131f132c324b0367429d959be01b): Bind for 0.0.0.0:8500 failed: port is already allocated.\nBin On Host Approach\nI need a little time to test this.. ",
    "sprutner": "Thanks for this, the environment variable is what really helped me here. I am going to submit a change to the readme.MD with req commands to run docker container.. Thanks nir0s. I solved that problem many months ago. We are running this in Nomad so docker run is not really relevant...thanks.. ",
    "nir0s": "Um.. you can just run\ndocker run -p 9999:9999 -p 9998:9998 --net host fabiolb/fabio and it will use the host's network, where the consul port should be available.\nOf course, this will work assuming that you don't provision fabio instances dynamically.. Glad to hear. Actually wrote it for future reference.. . ",
    "rodriguezrps": "yes, sure! I will do soon as I have time, probably later this evening.. Hi, sorry for the late reply, I was quite busy.\nWell, I just simulated on my local within the following steps:\n- Started a local consul and fabio\n- started 2 demo app's (svc-a and svc-b)\n- added 2 manual override's \n   route weight svc-a /foo weight 0.8\n   route weight svc-c /bar weight 1.0\nthe weight of svc-a didn't change and I got '[WARN] route: no target match'\nnot sure if this should be the normal behavior, but as I said, it was working on version 1.3.5 \n. ",
    "stevehorsfield": "This sounds wrong to me, but perhaps I am missing something. Why would you consider an index change to be equivalent to a state change?. Understand that, especially the part of how Consul works. However, Consul's design also allows storage of the health check output. I don't really mind that fabio resets the routing table on changes of that kind (although it seems like wasted effort), but the resulting logging is enormous.\nI'm trying to establish how Consul handles health checks. We use a variety (scripted, TCP, HTTP) and several of them include substantial data in the response and occur frequently.. To give an example, we have health checks that review DNS connectivity or systemd unit status. For example:\n\u25cf docker.service - Docker Application Container Engine\n   Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled)\n  Drop-In: /etc/systemd/system/docker.service.d\n           \u2514\u2500docker-bridge.conf, docker-opts.conf\n   Active: active (running) since Fri 2017-01-27 01:44:46 UTC; 1 weeks 0 days ago\n     Docs: http://docs.docker.com\n Main PID: 1068 (dockerd)\n    Tasks: 11\n   Memory: 731.2M\n      CPU: 4min 2.334s\n   CGroup: /system.slice/docker.service\n           \u2514\u25001068 dockerd --host=fd:// --containerd=/var/run/docker/libcontainerd/docker-containerd.sock --log-level=warn --dns 172.17.42.1 --dns-search=service.consul --bip=<redacted> --selinux-enabled\nOK - docker is active.\nThis data changes on every health check but the status passing remains constant. My guess is this causes a K/V index change every time the health check runs.  This particular health check isn't  a service health check, so doesn't affect Fabio, but I see three possibilities:\n\nThe Consul health check index changes on every health check execution\nThe Consul health check index changes on every health check execution where the output changes\nThe Consul health check index only changes when the health status changes\n\nWe'll do some investigation to identify which of these cases is the actual behaviour. The second case may require us to change how we respond to health checks. The third is ideal. The first case means we have no control but would also suggest that other users would see high logging levels.. We're looking at removing volatile data from the health checks. Thanks for the confirmation.. We have a lot of services, some of which do flap (particularly in pre-prod). However, I'm pretty sure our logging isn't due to flapping per se (it may be due to the way Consul is handling health check changes). In any case, if we can't get this output reduced through some mechanism we'll have to fork. Another option is to control the logging detail through feature flags. Is that something you are open to?. We're shipping our logs directly to a SaaS log vendor, so rotation isn't needed for us. I'm looking at Consul to see if I can find the logic that might link to this behaviour. Appreciate your feedback.. Thanks for pushing this forward.. ",
    "avichalbadaya": "@magiconair \nHi frank,\nThanks for acknowledging ! Appreciate you getting back on this. I wanted to create PR on my fork and it was mistakenly created on main Fabio repo.  I am still working on code to make my PR more crisp and less impactful on current way of logging. It will just add an capability of filtering out logs based on levels, but users wouldn't see any difference incase they dont opt for filtering. \nThat said, Yes, log volume is one of our main driving force behind filtering. I could imagine your log volume in production (which has most of the services stable), consul k/v for service getting updated rarely and hence route add .. log entries are not adding much to log volume. Our case is little different. We have three env, say dev-qa-prod. Each env has minimum of 3-4 worker nodes ( we use nomad ), each running fabio. If I take Dev env which has ~ 200 services and as it is dev, you will see services coming up and down very frequently. Now, whenever even a single service is changed, fabio re-configs all the services pushing out huge volume of logs. Also, there are some logs related to consul health index change. Not sure if you can handle our case by current log package, by not logging route add... logs if the routes config for that service doesn't change.\nCheers,\nAvi   . @magiconair : Yes, I am glad to hear that. If we can log just delta instead of full route table, it would certainly solve our issue with log volume.. Hi Frank,\nThanks much creating #238 . I also wanted to ask on point you mentioned about easier ways of log filtering. Can you share some details on what ideas you have to achieve it without much change in code ?. +1 . Thanks Frank !. Looking good. I think this config param/options might be better - proxy.log.routes=(none|all|delta)). I don't have a strong opinion for none type. As delta or diff will be filtering out most of the noice, I don't think none would add value and as you said, could be misused. . \ud83d\udc4d . Thanks for pushing changes to master. Me and my team is quite appreciative of your support. We would be glad to share more details about our scale/stack, but first we need to get \ud83d\udc4d  from our stakeholders. I have already put it forward and should get back to you on this once I get updates from them.\nCheers,\nAvichal. ",
    "TargetFocussed": "empty ... no values / output. Thank you for taking time. I believe fundamentally I missing some thing simple here....\nhere is my understanding ....\n\nfabio reads updated configuration (list of avaiable service) from consul-server (i.e \nBased on running healthy services, it load balance between them.\n\nVery simple.\n\nI am asking the question / documentation on where can I find list of services in fabio docker instance \nIf I run fabio + consul-server on one VM instance and consul-client+registrator+serviceA-1 + serviceB1 +serviceA-2+serviceB-2 on a different VM instance, does it make sens  or works ?\n\nsorry to bother ....I like fabio .....I believe ...I am looking for a documentation that helps in general\nthanks\n. ",
    "alexandruast": "Thanks for the detailed answer.\nLet me describe my setup and the issues I see with some of the\nimplementations.\nPacker - ami builds for vpn (pritunl), consul, vault, nomad. One for\npritunl, one for servers (nomad, consul and vault - don't know if it's the\nright choice) and one for nomad nodes.\nBlank AWS account -> terraform global (dns, iam) -> terraform multiregion\n(everything else) -> terraform global (inter region discovering nomad over\ninternet via security groups - again, don't know if it's right). At this point, \nI just log into vpn and fire a job on nomad (the mongodb database for the \nvpn is external, so it just works without any manual intervention).\nCI environment (jenkins, nexus) is deployed as nomad jobs (same, don't know\nif it's right).\nThe ways I tested fabio:\nInside nomad as docker container - had problems with it registering\nmultiple checks via consul - maybe because I put consul.service.consul as\nconsul server. The checks it registered I had to remove manually from\nconsul.\nInside nomad as exec - worked fine, more control, but running nomad as root\nis not very attractive (required for the exec driver), and registering all\nthe nomad nodes in amazon alb/elb seems counter-intuitive.\nStandalone - worked fine, although the instance type required to actually\nget a decent network performance is overkill.\nI am thinking of creating a special type of nomad node with exec driver and\nrun fabio along with other exec and docker tasks on these special nodes\n(although there is no exec task at this time other than nomad). Having 3 or\n5 instances registered in elb and not all of them (200+ in prod) looks\nbetter.\nAnother option that I think of is to use latency based dns in route53 and\ndirectly hook fabio into it with a lambda function (although I don't know\nif fabio can even work like that at this time).. ",
    "kaspergrubbe": "Thanks for your question, and for your write-up @alexandruast, it would be interesting to know what you ended up doing.\nIt would also be interesting to know what other people do.. Consul 1.4.4 incoming, thanks for noticing @sielaq . @leprechau Hi Aaron, thanks for getting back to me.\nThat does make sense, does Fabio read the domains from the certificates and use the correct one automatically based on the request, or do I need to name my keys accordingly?. @leprechau That is good to know, that sounds almost magical :)\nI am having some issues and the log-file isn't helping me so much.\nMy service is tagged with: \"urlprefix-clusterapp.prod.mothership.billett.ooo/ proto=https\".\nI've installed the fullchain certificate inside of consul and it lives at kv/sslcerts/cert01:\n\nAnd I am using the default Fabio configuration, only thing changed is the proxy.cs like this:\nproxy.cs = cs=billettocerts;type=consul;cert=http://localhost:8500/v1/kv/sslcerts\n\nHowever, the log doesn't show anything related to the proxy.cs setting, and when visiting the site https://clusterapp.prod.mothership.billett.ooo/ I get an error:\n\nHere is the full fabio log:\n```\n2019/03/15 14:20:31 [INFO] Setting log level to INFO\n2019/03/15 14:20:31 [INFO] Runtime config\n{\n    \"Proxy\": {\n        \"Strategy\": \"rnd\",\n        \"Matcher\": \"prefix\",\n        \"NoRouteStatus\": 404,\n        \"MaxConn\": 10000,\n        \"ShutdownWait\": 0,\n        \"DialTimeout\": 30000000000,\n        \"ResponseHeaderTimeout\": 0,\n        \"KeepAliveTimeout\": 0,\n        \"FlushInterval\": 1000000000,\n        \"GlobalFlushInterval\": 0,\n        \"LocalIP\": \"10.1.1.192\",\n        \"ClientIPHeader\": \"\",\n        \"TLSHeader\": \"\",\n        \"TLSHeaderValue\": \"\",\n        \"GZIPContentTypes\": null,\n        \"RequestID\": \"\",\n        \"STSHeader\": {\n            \"MaxAge\": 0,\n            \"Subdomains\": false,\n            \"Preload\": false\n        }\n    },\n    \"Registry\": {\n        \"Backend\": \"consul\",\n        \"Static\": {\n            \"NoRouteHTML\": \"\",\n            \"Routes\": \"\"\n        },\n        \"File\": {\n            \"NoRouteHTMLPath\": \"\",\n            \"RoutesPath\": \"\"\n        },\n        \"Consul\": {\n            \"Addr\": \"localhost:8500\",\n            \"Scheme\": \"http\",\n            \"Token\": \"\",\n            \"KVPath\": \"/fabio/config\",\n            \"NoRouteHTMLPath\": \"/fabio/noroute.html\",\n            \"TagPrefix\": \"urlprefix-\",\n            \"Register\": true,\n            \"ServiceAddr\": \":9998\",\n            \"ServiceName\": \"fabio\",\n            \"ServiceTags\": null,\n            \"ServiceStatus\": [\n                \"passing\"\n            ],\n            \"CheckInterval\": 1000000000,\n            \"CheckTimeout\": 3000000000,\n            \"CheckScheme\": \"http\",\n            \"CheckTLSSkipVerify\": false,\n            \"CheckDeregisterCriticalServiceAfter\": \"90m\",\n            \"ChecksRequired\": \"one\"\n        },\n        \"Timeout\": 10000000000,\n        \"Retry\": 500000000\n    },\n    \"Listen\": [\n        {\n            \"Addr\": \":9999\",\n            \"Proto\": \"http\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false,\n            \"TLSMinVersion\": 0,\n            \"TLSMaxVersion\": 0,\n            \"TLSCiphers\": null\n        }\n    ],\n    \"Log\": {\n        \"AccessFormat\": \"common\",\n        \"AccessTarget\": \"\",\n        \"RoutesFormat\": \"delta\",\n        \"Level\": \"INFO\"\n    },\n    \"Metrics\": {\n        \"Target\": \"\",\n        \"Prefix\": \"{{clean .Hostname}}.{{clean .Exec}}\",\n        \"Names\": \"{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.{{clean .TargetURL.Host}}\",\n        \"Interval\": 30000000000,\n        \"Timeout\": 10000000000,\n        \"Retry\": 500000000,\n        \"GraphiteAddr\": \"\",\n        \"StatsDAddr\": \"\",\n        \"Circonus\": {\n            \"APIKey\": \"\",\n            \"APIApp\": \"fabio\",\n            \"APIURL\": \"\",\n            \"CheckID\": \"\",\n            \"BrokerID\": \"\"\n        }\n    },\n    \"UI\": {\n        \"Listen\": {\n            \"Addr\": \":9998\",\n            \"Proto\": \"http\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false,\n            \"TLSMinVersion\": 0,\n            \"TLSMaxVersion\": 0,\n            \"TLSCiphers\": null\n        },\n        \"Color\": \"light-green\",\n        \"Title\": \"\",\n        \"Access\": \"rw\"\n    },\n    \"Runtime\": {\n        \"GOGC\": 800,\n        \"GOMAXPROCS\": 1\n    },\n    \"ProfileMode\": \"\",\n    \"ProfilePath\": \"/tmp\",\n    \"Insecure\": false,\n    \"GlobMatchingDisabled\": false\n}\n2019/03/15 14:20:31 [INFO] Version 1.5.10 starting\n2019/03/15 14:20:31 [INFO] Go runtime is go1.11.1\n2019/03/15 14:20:31 [INFO] Running fabio as UID=0 EUID=0 GID=0\n2019/03/15 14:20:31 [WARN] \n\nYou are running fabio as root without the '-insecure' flag\n  This will stop working with fabio 1.7!\n\n2019/03/15 14:20:31 [INFO] Metrics disabled\n2019/03/15 14:20:31 [INFO] Setting GOGC=800\n2019/03/15 14:20:31 [INFO] Setting GOMAXPROCS=1\n2019/03/15 14:20:31 [INFO] Running fabio as UID=0 EUID=0 GID=0\n2019/03/15 14:20:31 [WARN] \n\nYou are running fabio as root without the '-insecure' flag\n  This will stop working with fabio 1.7!\n\n2019/03/15 14:20:31 [INFO] consul: Connecting to \"localhost:8500\" in datacenter \"eu-central-1\"\n2019/03/15 14:20:31 [INFO] Admin server access mode \"rw\"\n2019/03/15 14:20:31 [INFO] Admin server listening on \":9998\"\n2019/03/15 14:20:31 [INFO] Waiting for first routing table\n2019/03/15 14:20:31 [INFO] consul: Using dynamic routes\n2019/03/15 14:20:31 [INFO] consul: Using tag prefix \"urlprefix-\"\n2019/03/15 14:20:31 [INFO] consul: Watching KV path \"/fabio/config\"\n2019/03/15 14:20:31 [INFO] consul: Watching KV path \"/fabio/noroute.html\"\n2019/03/15 14:20:31 [INFO] HTTP proxy listening on :9999\n2019/03/15 14:20:31 [INFO] Running fabio as UID=0 EUID=0 GID=0\n2019/03/15 14:20:31 [WARN] \n\nYou are running fabio as root without the '-insecure' flag\n  This will stop working with fabio 1.7!\n\n2019/03/15 14:20:31 [INFO] Access logging disabled\n2019/03/15 14:20:31 [INFO] Using routing strategy \"rnd\"\n2019/03/15 14:20:31 [INFO] Using route matching \"prefix\"\n2019/03/15 14:20:31 [INFO] consul: Registered fabio as \"fabio\"\n2019/03/15 14:20:31 [INFO] consul: Registered fabio with id \"fabio-ip-10-1-1-192.eu-central-1.compute.internal-9998\"\n2019/03/15 14:20:31 [INFO] consul: Registered fabio with address \"10.1.1.192\"\n2019/03/15 14:20:31 [INFO] consul: Registered fabio with tags \"\"\n2019/03/15 14:20:31 [INFO] consul: Registered fabio with health check to \"http://[10.1.1.192]:9998/health\"\n2019/03/15 14:20:32 [INFO] Config updates\n+ route add whoami www.billett.ooo/ http://10.1.2.147:25262/\n+ route add whoami www.billett.ooo/ http://10.1.1.192:31507/\n+ route add whoami www.billett.ooo/ http://10.1.1.192:29010/\n+ route add whoami billett.ooo/ http://10.1.2.147:25262/\n+ route add whoami billett.ooo/ http://10.1.1.192:31507/\n+ route add whoami billett.ooo/ http://10.1.1.192:29010/\n+ route add nomad-ui nomad.prod.mothership.billett.ooo/ http://10.1.3.173:4646/ opts \"allow=ip:192.168.0.42/32 pxyproto=true\"\n+ route add nomad-ui nomad.prod.mothership.billett.ooo/ http://10.1.2.178:4646/ opts \"allow=ip:192.168.0.42/32 pxyproto=true\"\n+ route add nomad-ui nomad.prod.mothership.billett.ooo/ http://10.1.1.243:4646/ opts \"allow=ip:192.168.0.42/32 pxyproto=true\"\n+ route add consul-ui consul.prod.mothership.billett.ooo/ http://10.1.3.5:8585/ opts \"allow=ip:192.168.0.42/32 pxyproto=true\"\n+ route add consul-ui consul.prod.mothership.billett.ooo/ http://10.1.2.107:8585/ opts \"allow=ip:192.168.0.42/32 pxyproto=true\"\n+ route add consul-ui consul.prod.mothership.billett.ooo/ http://10.1.1.156:8585/ opts \"allow=ip:192.168.0.42/32 pxyproto=true\"\n+ route add clusterapp-group-web clusterapp.prod.mothership.billett.ooo/ https://10.1.2.147:22822\n2019/03/15 14:20:33 [INFO] Config updates\n+ fabio-ui fabio.prod.mothership.billett.ooo/ http://10.1.2.147:9998/ opts \"allow=ip:192.168.0.42/32\"\n+ route add\n2019/03/15 14:20:35 [INFO] Config updates\n+ fabio-ui fabio.prod.mothership.billett.ooo/ http://10.1.1.192:9998/ opts \"allow=ip:192.168.0.42/32\"\n+ route add\ninvalid log msg: 2019/03/15 14:21:48 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:21:52 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:21:54 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:22:02 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:22:02 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:22:06 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:22:08 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:22:12 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:22:12 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:23:02 http: proxy error: tls: oversized record received with length 20527\ninvalid log msg: 2019/03/15 14:23:03 http: proxy error: tls: oversized record received with length 20527\ninvalid log msg: 2019/03/15 14:23:04 http: proxy error: tls: oversized record received with length 20527\ninvalid log msg: 2019/03/15 14:23:48 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:26:09 http: proxy error: context canceled\ninvalid log msg: 2019/03/15 14:26:09 http: proxy error: context canceled\n```\nAm I missing something obvious?. @shantanugadgil Thanks for your suggestion. I did have some issues with the wildcard certs, so I've decided to just use full domains and skip the wildcard certs for now, it is more important to get some https working than get wildcards working :) I will take a look at gowebhello when I toy with wildcard certs again. \nEdit: These are the domains in my certificate:\n\n. @leprechau I see, I didn't read what you wrote, I have now done the cat fullchain.pem privkey.pem > cert01.pem and pasted it into Consul, but still no change.\nI noticed this from the logs:\nroute add clusterapp-group-web clusterapp.prod.mothership.billett.ooo/ https://10.1.2.147:22822\n\nDoes that look right? It look like Fabio is doing a https connection to my service, I thought Fabio would serve the cert and do http internally.. @leprechau Thank you so much for your patience and examples, very handy to know about the \\ for newlines, and the http redirection.\nI've now done the changes you recommended, so my config is now like this:\nproxy.cs = cs=billettocerts;type=consul;cert=http://127.0.0.1:8500/v1/kv/sslcerts\nproxy.addr = :9999;proto=http,:9995;proto=https;cs=billettocerts\n\nAnd now Fabio also picks up the configuration on boot:\n{\n    \"Addr\": \":9995\",\n    \"Proto\": \"https\",\n    \"ReadTimeout\": 0,\n    \"WriteTimeout\": 0,\n    \"CertSource\": {\n        \"Name\": \"billettocerts\",\n        \"Type\": \"consul\",\n        \"CertPath\": \"http://127.0.0.1:8500/v1/kv/sslcerts\",\n        \"KeyPath\": \"\",\n        \"ClientCAPath\": \"\",\n        \"CAUpgradeCN\": \"\",\n        \"Refresh\": 0,\n        \"Header\": null\n    },\n    \"StrictMatch\": false,\n    \"TLSMinVersion\": 0,\n    \"TLSMaxVersion\": 0,\n    \"TLSCiphers\": null\n}\n\nHowever, when I visit any of the sites the log shows this:\n2019/03/16 06:24:20 [INFO] cert: Store has certificates for [\"\"]\ninvalid log msg: 2019/03/16 06:33:38 http: TLS handshake error from 139.162.191.30:61064: cert: no certificates stored\n\nIt turned out that the key had to be named cert01.pem instead of just cert01 to work \ud83d\udc4d . ",
    "sgrimm-sg": "Ah, that's an interesting idea. I think a variant of it might be better: rather than a second health check for the same service, instead register a second service with its own health check and tag that one with urlprefix-. That way the service for the hot spare node still shows up as healthy in Consul (meaning it can do stuff like create Consul sessions).\nThanks -- will give that a try.. Yes, that's actually exactly what we're doing so our application knows internally when it has become the primary, but you can only start a session if you have a passing health check; without a healthy service to use for session establishment, the hot spare can't attempt to acquire the Consul lock. Kind of a chicken-and-egg problem.. Yesterday I tried switching to this setup (adding a second service with the urlprefix- tag and a health check that passed only when the instance was the primary). It worked fine, but after finishing it I realized it ended up being more code than my original approach. It was also slightly slower in that it couldn't switch over to the new primary until after a health check which might mean waiting for the health check interval, whereas with the \"reregister when you get the lock\" approach, the tags can be updated immediately when the lock is acquired.\nWhat I'm currently doing looks roughly like this. It is a little complex because I want to ensure that, when I'm doing a clean shutdown of the current primary (software upgrades, etc.), there's never a period when Fabio has nowhere to route a client request.\n\nAt startup:\nDeregister health check (in case it was in critical state due to an earlier unclean shutdown)\nRegister service without routing tag\nCreate Consul session\nPoll the value of the primaryAddress Consul key and store it locally\nWhile running:\nAttempt to acquire lock on primaryAddress with our address as the value\nIf the lock is not held:\nIf local copy of primaryAddress is set:\nForward incoming client requests to the primary\nIf local copy of primaryAddress is not set:\nQueue incoming client requests for later processing\n\n\nWhen the lock is initially acquired:\nUpdate local copy of primaryAddress with our address\nReregister service with routing tag and health check\nProcess any queued-up client requests\n\n\nWhen shutting down:\nIf we were the primary instance:\nClear our local copy of primaryAddress\nWait for in-progress requests to complete\nRelease the lock on primaryAddress\nIf there are other instances registered in Consul:\nWhile local primaryAddress copy is not set:\nSend an HTTP request via Fabio's proxy port to hit an API endpoint that returns the value of the local primaryAddress copy of whichever instance answers the request\nIf it is not our address, set the local primaryAddress copy to its value\n\n\n\n\nDeregister service\nStop listening for requests\nIf any requests were queued, forward them to the new primary\nWait for forwarded requests to finish\n\nThe \"send a request through Fabio\" sequence at the end means that during shutdown, there will be a brief window when both hosts' services are tagged with urlprefix-, but there should only be one host that actually does work at any given time.\nThe reason that the shutdown sequence queries the primary address through Fabio rather than relying on the state of the Consul key is because there is some nonzero amount of time between my service updating Consul and Fabio updating its routing tables, and I want to make sure the old primary doesn't stop accepting work until after I've confirmed that Fabio has started sending requests to the new one; otherwise there'd be a brief period of unavailability. Only tens of milliseconds, but my service's clients seem to excel at sending requests at the exact moment it goes offline briefly! The alternative would have been to query Fabio's routing config from Consul but then I'd have to parse Fabio's routing configuration in my application which seemed unnecessarily complex.\nFeedback welcome, of course. Perhaps there's a simpler approach that would provide the same availability.. Or I guess 3. Have a machine-friendly query endpoint on the administrative listen port that a client can use to get a list of the proxy ports. Not ideal (more round trips required to discover the port number) but it would work.. Our use case is a bit more specific than the one I described in the issue. Fabio sits in front of a service that's used both by other components of our system (which can indeed discover the underlying service addresses directly in Consul) and third-party clients. Our application runs in AWS and the third-party clients connect through an ELB frontend that sits in front of Fabio.\nThe shutdown sequence from issue #242 is where I'd use this feature. When failing over to a new instance of the service I want to make sure that third-party clients are connecting to the new instance rather than the old one. Fabio is the source of truth there: if Fabio actually routes a request to the new instance, then the new instance is reachable and it's safe for the old one to deregister itself.\nThe ELB configuration needs to know the Fabio listen port, so there's no way to make the entire setup fully dynamic, but the fewer explicit config options I have to set the better, and this seems like the sort of thing that could be discovered at runtime.. ",
    "cosaques": "Hi @magiconair ! Our system will consist of microservices communicating via gRPC with each other. We use Nomad to run them and fabio for load balancing. Now we try to achieve the distributed tracing (trace the processes that passes through different microservices). To adapt it I see 2 solutions :\n1. manually add the code that traces inside each microservice (using Zipkin for example) \n2. switch to Linkerd that allows usage of Zipkin inside of it without need to add some code in microservices.\nI would like to know how if it is possible to achieve the same result (solution 2) using fabio.\nThanks in advance for any help and sorry if I put my question in inappropriate place. @magiconair , yes it's exactly this! I would like to try to implement this.\nCould you just give some advises how it is better to do it ? (coding always on C#, I'm not yet really strong in Go :) )\nAlso the question about gRPC. Do you plan to continue to support gRPC in fabio ?. @magiconair thanks a ton for these inputs. \nConcerning gRPC, it uses HTTP/2. As I saw the check-in with the comment \"Re-enable Http/2\" I wonder what is the future plans for supporting http/2 ?\nThanks again. ",
    "wv-myoung": "@magiconair was there any progress towards an HTTP/2 supported upstream that you mentioned with the HTTPS upstream support?  I only am seeing activity related to the HTTPS work but not HTTP/2.\nI am also investigating load balancing options for gRPC and Fabio looks like a potentially great fit to the overall design short of the need on the HTTP/2 upstream.\nI've tested and validated load balancing functionality with nghttpx but that does not have the consul driven configuration of fabio.\nI was able to use fabio with the tcp load balancing but that does not balance per request for gRPC since the requests are multiplexed inside of the connection.  It is only balancing on connection initiation.. I have been looking into this and yes it may work out of the box when the http/1.1 to http/2 upgrade negotitation is handled for normal browser and web servers.  This is not the case with gRPC as it is only an http/2 protocol on client and server it is acting strictly on http/2.\nI added an additional proto value of h2 to indicate the upstream should be explicitly http/2 and used an appropriate transport for that.\nThe other part is that gRPC uses trailers and the handling of trailers in the core library ReverseProxy was not compatible with that for http/2 purposes.  This has now been addressed but did not appear to be in 1.8.3.  See issue https://github.com/golang/go/issues/20437 and commit https://github.com/golang/go/commit/1611839b29a5447f3132e93f14c75b1639a34490 addressing it.\ngRPC will fail without the grpc-message and grpc-status trailers passed back with the response and there are others that may also be passed.\nI am planning to contribute my changes but as we have not done so previously I need to go through steps to make sure I have clearance to do so.  I can discuss it further in the meantime.. @magiconair I did not have to manipulate the listener at all and do not think there would be a need for a dedicated type.  The routing works well as the service name, class and action go into the uri such as /TestServer.HelloWorld/SayHello.  Therefore port and prefix matching are both capable for the routing, I do believe host was working as well.\nTLSClientConfig worked fine with the existing settings for handling TLSSkipVerify.  I do want to further explore unsecured gRPC which I hadn't yet get to function through fabio but does work client to server directly. The http/2 transport has an option for AllowHTTP but it didn't seem to help and comment states it doesn't enable h2c so not sure if it is the correct approach.. I was attempting to treat it generically as http/2 instead of specifically gRPC.  The trailers was the only thing I had to do gRPC specific and the net/http/util fix will address that.. @magiconair I was able to confirm usage of http2.ConfigureTransport along with latest go from master to address the trailers functional with my gRPC harness as well.\nRunning your above test from the issue-244-grpc branch I am not seeing the closed network log line mentioned\n~ # go version\ngo version master-nightly-17ba830f4663816c3270860fad96373a833a3b26 linux/amd64\n~ # go test -v -run GRPC github.com/fabiolb/fabio/proxy\n=== RUN   TestGRPC\n2017/06/14 20:36:37 gRPC echo server listening on  https://127.0.0.1:40617/echosvc.EchoSvc\n2017/06/14 20:36:37 http/2.0 server listening on  https://127.0.0.1:40451\n=== RUN   TestGRPC/https_direct\n=== RUN   TestGRPC/https_via_proxy\n=== RUN   TestGRPC/gRPC_direct\n=== RUN   TestGRPC/gRPC_via_proxy\n--- PASS: TestGRPC (0.02s)\n    --- PASS: TestGRPC/https_direct (0.00s)\n    --- PASS: TestGRPC/https_via_proxy (0.00s)\n    --- PASS: TestGRPC/gRPC_direct (0.00s)\n    --- PASS: TestGRPC/gRPC_via_proxy (0.00s)\nPASS\nok      github.com/fabiolb/fabio/proxy  0.023s\nThe issue does remain that it only works over https both grpcClient to fabio and fabio to grpcServer and so grpc services need to be tagged with the proto=https option.  I would consider that a separate issue for later review as this does give a working path.. @magiconair I was stating that both the fabio proxy listener and upstream need to be configured for https for it to work currently.  Even though if you go direct from grpc client to server it is able to work without https.\nFor the grpc service registering itself with consul to be served via fabio it needs to include the proto=https option.\nAs well, the listener that the grpc client connects to fabio on will need an appropriate certificate store configured.\nBoth grpc client and server also have settings for client certificate, ignoring validation issues and on the server side certificate and key values so those need to be done appropriately as well.\nEssentially, all 4 edges (client, fabio listener, fabio upstream request and server) all need proper https configuration in place for it to currently work from my testing.\nIdeally, we would be able to also use unsecured transports on either or both legs of the communication based upon use case.. gRPC is HTTP/2 only and supports use of h2c.  I've tested it with go based grpc client and server with http2debug=2 and can see that it is over HTTP/2 as shown below (note the scheme is http).\nI believe the gRPC libraries may not be using the net/http2 libraries or using them in a lower level fashion as I have seen framer handling within their code.\nThis is mainly just a note that at this time that using fabio in the middle will require that it is https traffic.  Perhaps later if there is better h2c support implemented to the core libraries then that will change.\n2017/06/16 16:16:46 http2: Framer 0xc4201161c0: wrote SETTINGS len=0\n2017/06/16 16:16:46 http2: Framer 0xc4201161c0: wrote WINDOW_UPDATE len=4 (conn) incr=983025\n2017/06/16 16:16:46 http2: Framer 0xc4201161c0: read SETTINGS len=0\n2017/06/16 16:16:46 http2: Framer 0xc4201161c0: read WINDOW_UPDATE len=4 (conn) incr=983025\n2017/06/16 16:16:46 http2: Framer 0xc4201161c0: read HEADERS flags=END_HEADERS stream=1 len=73\n2017/06/16 16:16:46 http2: decoded hpack field header field \":method\" = \"POST\"\n2017/06/16 16:16:46 http2: decoded hpack field header field \":scheme\" = \"http\"\n2017/06/16 16:16:46 http2: decoded hpack field header field \":path\" = \"/myWorld.World/SayHello\"\n2017/06/16 16:16:46 http2: decoded hpack field header field \":authority\" = \"localhost:5100\"\n2017/06/16 16:16:46 http2: decoded hpack field header field \"content-type\" = \"application/grpc\"\n2017/06/16 16:16:46 http2: decoded hpack field header field \"user-agent\" = \"grpc-go/1.4.0-dev\"\n2017/06/16 16:16:46 http2: decoded hpack field header field \"te\" = \"trailers\"\n2017/06/16 16:16:46 http2: Framer 0xc4201161c0: read DATA flags=END_STREAM stream=1 len=12 data=\"\\x00\\x00\\x00\\x00\\a\\n\\x05Test0\". ",
    "DennisPersson": "Any updates on when / if the issue-244-grpc branch is expected to be merged to master? We have confirmed that this branch seems to work fine proxying our gRPC service (using proto=https and tlsskipverify=true). \nBut we cannot get it to work with the latest release, even when building fabio with go1.10rc1, where the fix mentioned above (golang/go@1611839) is supposed to be included. \nThanks!. @magiconair Thanks for the quick response. Sorry, I don't think I'm familiar enough with Go to help with the coding, would be happy to help with another round of testing before you release if needed though. . I did some more testing on the rebased branch; regular service calls seems to work fine still. I noticed this warning message in our Java service, but calls and responses go through (this was present before the rebase as well): \n2018-02-07 14:17:25,277 [grpc-default-worker-ELG-4-2] WARN  io.grpc.netty.NettyServerHandler  - Expected header TE: trailers, but null is received. This means some intermediate proxy may not support trailers\nI suspected the above was due to the Go bug mentioned above, so I tried to rebuild with go1.10.rc1, but still got the same message.\nOne thing that didn't seem to work is the ProtoReflectionService that is included in gRPC-java (https://github.com/grpc/grpc-java/blob/master/documentation/server-reflection-tutorial.md). That didn't work before the rebase either though.\nI think the difference between that service and our own service might be that the ProtoReflectionService streams back its responses, not sure if that is something that is even possible to support. I've attached the log file from the ProtoReflectionService call in case it is helpful. \nreflectionServiceCall.log\nWe don't use any streaming in our own services, so for us that use case is not important. . ",
    "memelet": "That would work just great.. Ok, no hurry. Thanks!. ",
    "lucaslim": "Hey @magiconair, is least connection support on fabio still in the radar? :). ",
    "gamefundas": "I don't think this is related to #101 or sticky sessions. Perhaps my explanation is misleading.\nIn my scenario, fabio is able to create a load balanced route http://fabio.host:port/service-A\nand accessing that lands me in one of the nodes. But what I need is the ability to hit Node-1, Node-2 and Node-3 independently.\n. Mine is not really a load balancing use case. Its merely routing calls to specific nodes. We have maintenance service endpoints on each nodes that requires us to reach the specific faulty node to either restart or perform basic support operations like purge cache etc. A load balancer would randomly route the call. We would like to target the faulty nodes and be able to hit the specific host. \nInstead of numerical sequence, host names will also work.\n. This might work. Didn't think that I could very much control how to create my route path.\nThanks. \nClosing this one.. ",
    "ujenmr": "as workaround you can use telegraf's statsd input plugin\ntelegraf.conf\n[[inputs.statsd]]\n    service_address = \":8127\"\n    percentiles = [90]\n    metric_separator = \"_\"\n    parse_data_dog_tags = false\n    allowed_pending_messages = 10000\n    percentile_limit = 1000\n    templates = [\n        \"fabio.* measurement.service-id.field*\"\n    ]\nfabio.properties:\nmetrics.target = statsd\nmetrics.prefix = {{clean .Exec}}.{{clean .Hostname}}\nmetrics.names = {{clean .Service}}\nmetrics.statsd.addr = 172.17.0.1:8127\n. ",
    "ryudice": "@magiconair  Something like this https://github.com/wshirey/kong-plugin-response-cache. You can configure caching by headers, query string, and uri. I guess the duration would have to be set for all responses.. ",
    "badounan": "I only started the http service on 192.168.0.11.There is only one instance of the service.\nIf I put fabio, consul and http services are deployed on a machine. no problem.. If the address is wrong, the output \"No route for ...\", which is very correct.\nBut when i visit a normal address:http://192.168.0.10:9999/foo, without any response, has been waiting.there is no log output.. yes, when curl -i http://192.168.0.11:8080/foo,the return is normal. but when curl -i http://192.168.0.10:9999/foo\uff0cnoo response, no output, has been waiting for the state. [\n    {\n        \"Node\": {\n            \"Node\": \"n2\",\n            \"Address\": \"192.168.0.11\",\n            \"TaggedAddresses\": null,\n            \"CreateIndex\": 3,\n            \"ModifyIndex\": 20\n        },\n        \"Service\": {\n            \"ID\": \"sampleservice\",\n            \"Service\": \"sampleservice\",\n            \"Tags\": [\n                \"urlprefix-/foo\"\n            ],\n            \"Address\": \"192.168.0.11\",\n            \"Port\": 8088,\n            \"EnableTagOverride\": false,\n            \"CreateIndex\": 18,\n            \"ModifyIndex\": 20\n        },\n        \"Checks\": [\n            {\n                \"Node\": \"n2\",\n                \"CheckID\": \"serfHealth\",\n                \"Name\": \"Serf Health Status\",\n                \"Status\": \"passing\",\n                \"Notes\": \"\",\n                \"Output\": \"Agent alive and reachable\",\n                \"ServiceID\": \"\",\n                \"ServiceName\": \"\",\n                \"CreateIndex\": 3,\n                \"ModifyIndex\": 3\n            },\n            {\n                \"Node\": \"n2\",\n                \"CheckID\": \"service:sampleservice\",\n                \"Name\": \"Service 'sampleservice' check\",\n                \"Status\": \"passing\",\n                \"Notes\": \"\",\n                \"Output\": \"\",\n                \"ServiceID\": \"sampleservice\",\n                \"ServiceName\": \"sampleservice\",\n                \"CreateIndex\": 18,\n                \"ModifyIndex\": 20\n            }\n        ]\n    }\n]. ```\nconsul agent -server -bootstrap-expect 2 -data-dir /data/test -node n1 -bind=192.168.0.10 -ui-dir ./consul_ui -dc=dc1\nconsul agent -server -bootstrap-expect 2 -data-dir /data/test -node n1 -bind=192.168.0.11 -dc=dc1\n```\nThen on 192.168.0.10,enter: \"consul join 192.168.0.11\"\nAutomatic election leader.. Yes, Fabio have a log:\nroute add sampleservice /foo http://192.168.0.11:8088/. Hello!\nI use Nancy as the http server. When I curl -i http://192.168.0.10:9999/foo, close the http server, fabio have the following error:\nhttp:proxy error:read tcp 192.168.0.10:60188->192.168.0.11:8088: wsarecv:An existing connection was forcibly closed by the remote host.. Hello!\nI have solved this problem.This is the Http server Nancy problem.. Thank you for your answer.. ",
    "satishviswanathan": "@badounan If you don't mind can you add the resolution for this issue?. Are you referring to the KV store in consul? attaching the consul KV\n. I'm sorry would you be able to guide me where to find this?. When I access the url I'm getting this error.\n\n. \nCurrently I was trying to get it working on my dev box which is Windows operating system and I have both Consul and Fabio running on the same box but I'm using my machine IP instead of  localhost (127.0.0.1)\n. \nYou are right we can start consul agent -dev but that will use localhost right, but I want to use my machine IP. Am I missing any configuration here, any help is highly appreciated\n@magiconair . I've now started clean \n\nRunning consul as localhost \nRegistered health check \nRegistered TCP services\nTried running Fabio with 2 different options with following results.\n\nfabio-1.5.8-go1.10-windows_amd64.exe -proxy.addr :2302;proto=tcp\nFabio-log1.txt\nfabio-1.5.8-go1.10-windows_amd64.exe -proxy.addr :2302;proto=tcp -registry.consul.tagprefix urlprefix-:2302\nFabio-log2.txt\n. Thank you for your support.\nThis is the config I've used for service registration.\nRegister-Service.txt\n. \nWhen I remove the option registry.consul.urlprefix I get the following error.\nsyntax error: 'route add' invalid\n. Thank you. I added the log and identified that while registering the consul service I had a \"space\" in the name. eg: \"Service Check 1\" which was causing the issue.\nNow when i start fabio i can see the routes getting added. But when i access from my client application I'm getting the following error.\n```\n-registry.consul.addr 10.203.xxx.xx:8500 -proxy.addr :2302;proto=tcp\n[WARN] No route for 10.203.xxx.xx:2302/v1/kv/orleans/Order_Cluster1?recurse\n```\n. My consul service registration is having urlprefix\n{\n   \"ID\": \"ServiceCheck1\",\n  \"Name\": \"ServiceCheck1\",\n  \"Notes\": \"serviceService 1\",\n  \"Address\": \"10.208.x.xx\",\n  \"Port\": 11111,\n  \"Tags\": [\"urlprefix-:2302 proto=tcp\"],\n  \"EnableTagOverride\": false,\n  \"Check\":{\n    \"DeregisterCriticalServiceAfter\": \"90m\",\n    \"TCP\": \"10.208.x.xx:11111\",\n    \"Interval\": \"10s\"\n  }\n}\nwhile running fabio do I need to get this same option too?\n. 2018/04/20 10:57:20 [INFO] HTTP proxy listening on :2302\n2018/04/20 10:57:20 [INFO] Access logging disabled\n2018/04/20 10:57:20 [INFO] Using routing strategy \"rnd\"\n2018/04/20 10:57:20 [INFO] Using route matching \"prefix\"\n2018/04/20 10:57:20 [INFO] consul: Registered fabio as \"fabio\"\n2018/04/20 10:57:20 [INFO] consul: Registered fabio with id \"fabio-9998\"\n2018/04/20 10:57:20 [INFO] consul: Registered fabio with address \"10.203.xxx.xx\"\n2018/04/20 10:57:20 [INFO] consul: Registered fabio with tags \"\"\n2018/04/20 10:57:20 [INFO] consul: Registered fabio with health check to \"http://[10.203.106.62]:9998/health\"\n2018/04/20 10:57:20 [INFO] Config updates\n+ route add ServiceCheck1:2302 tcp://10.208.x.xx:11111\nNow when I access 10.203.xxx.xx:2302 from my client application, I'm getting the following error\nNo route for 10.203.xxx.xx:2302/v1/kv/orleans/Cluster1?recurse\n. I'm using the following command where I've mentioned the proto as tcp\n -registry.consul.addr 10.203.xxx.xx:8500 -proxy.addr :2302;proto=tcp\nBut still the log shows \n[INFO] TCP proxy listening on :2302\nNot sure what I'm missing\n. Got it, my mistake I was missing the quotes 10.203.xxx.xx:8500 -proxy.addr : '2302;proto=tcp'\nNow trying to get the client connected via fabio. \nNow when my client application try to connect to fabio @ port 2302, I'm getting the following error.\ntcp:  read tcp 10.xxx.x.xx:50690->10.xxx.x.xx:11111: wsarecv: An existing connection was forcibly closed by the remote host.\nOne of my service is running @ 10.xxx.x.xx:11111 and it is also listed in fabio routing table.\nPlease advice what can be done to resolve this issue.\n. @magiconair Do you think it is possible to expose my TCP services at 2303 and HTTP services at 9999.\nFabio Routing table \n\n. My apologies if my questions are very basic.\nCurrently I'm using consul for service discovery and the routing table is populated with all the registered services in consul. What I'm trying to achieve is overrides and changes the weight for the routes.\nI've been trying to access the link \"Overrides\" on the right hand side top corner, but nothing seems to be working. Please advice.\n\n. \nThank you sharing the steps. \nBut when I click on the Overrides I don't see any drop down with the options like you have shown in your screen shot. Am i missing any configuration to enable this feature.. Thank you that worked !\n. What is the error that you are getting?\nYou have mentioned service1 as the urlprefix and your actual end point url might not be having service hence you might require to do strip that prefix.\nWhile registering the consul service you can define the urlprefix and strip it as shown below.\nEx:\n \"Tags\": [\"urlprefix-/service1 strip=/service1\"]. Glad to hear it worked for you !. ",
    "itatabitovski": "Yes, in the UI I see that the upstream is http://. Having the service registered with the tags above does not seem to add it as HTTPS, it is not just a UI issue.\nTrying to access a service resulted in:\nhttp: proxy error: malformed HTTP response \"\\x15\\x03\\x01\\x00\\x02\\x02\"\nManually registering the service as described in #260 does not give this error.. Manually adding the route with one combined tag \"tlsskipverify=true proto=https\" works as expected!\nHow do I register this tag in consul?. Everything works fine now. Thank you. Upstream is properly registered and displayed in the UI.. I am not sure if opts worked. I still get proxy error: x509: cannot validate certificate\nHowever when I curl --insecure https://... the upstream, it works OK.. ",
    "chenjpu": "+1. +1. Is there progress?. ",
    "hankerepo": "I think I got to \"hell bent\" on using tcp.  I went back to http and ensured I had the trailing slash in the service tag and all is well.  \nThanks!!. ",
    "Ginja": "@magiconair Thanks for the review! Made the changes, and squashed everything into one commit.. Changes made.. It is, but then how do I expose the parameter? \nhttps://github.com/fabiolb/fabio/pull/268/files?diff=unified#diff-f1ea9ed43b0b0ed74a6cf0f71dad3196R165\nDo you want defaultConfig.Registry.Consul.CheckTLSSkipVerify just to be false in the link above?. Edit: Ignore that last question, need more coffee this morning! I'll update this PR later today.\nThanks for your help!. ",
    "jemc": "Thanks for agreeing to update the docs; it's appreciated.\nIs the per-instance maxconn feature something you would consider adding to fabio? traefik currently supports this feature.\nShould I open a separate issue to discuss the maxconn feature request?. We have some Ruby-based web servers that use forking processes to handle requests (a la unicorn), with each process handling one request at a time. Thus, the maximum number of simultaneous requests that each server can serve at a time is a fixed number (equal to the number of forked processes). Any additional requests that come in to the web server will be queued on listen socket until one of the forked processes becomes available.\nHowever, these additional requests can be served more efficiently if they get queued at the proxy instead of the web server (because they can go to the next available web server in the entire pool, instead of getting stuck in an arbitrary round-robin-selected web server socket, which may happen to be serving very long-running requests). In HAProxy, we are currently using a per-server maxconn to achieve this behaviour. Since we are trying to replace our HAProxy + consul-template solution with fabio because of the traffic-interruption-during-reload issue, so we'd like to do something analogous with maxconn in fabio.. @magiconair - Sorry, I'm not sure I understand the implication of the question. Can you elaborate?. Good question. We haven't had to deal with that issue because we use a static number of HAProxy servers that is known by our Chef recipe at the time when we deploy our HAProxy configuration template.. ",
    "erenfro": "I definitely need this as well.. In my test environment, I had a very simple consul setup. But in my main environment where I was going to deploy fabio, consul is setup to be fully encrypting gossip and tls communications, which for fabio that means it won't work, at all.. @magiconair Yep. I looked further into this and vault, at least with 0.9.1 and up, has a default token max_lease_ttl of 32 days, so this poses a serious problem having to constantly renew, manually, these tokens for an application such as this, which as a result, also requires restarting the fabio service when changing the token.\n. ",
    "vjeantet": "Hello, need this too, deployment compromised.\nHow can we help to see fabio able to connect to consul via TLS and TLS with client connect ?. Hello, i need this functionality too.\nCurrently blocked because of lack of https to search consul. :(\nHow can we help ?. Hello, how did you manage to combine routes coming from consul, with additional static routes ?\nI did not find any solutions on issues, docs and google, thanks a lot !. ",
    "spicykoala": "Perfect. That's exactly what I was looking for! Enjoy I shall.. I realized I should probably leave this open until it's merged in :) \n. I was actually just about to put this issue in. We've been using some automation to handle route overrides and cleanup directly in consul /fabio/config. The ideal functionality would be to log the bad route command and skip it (but not ignore the rest). Are there downsides to this behavior?\nWe made adjustments to the cleanup processes so that orphaned routes shouldn't happen, but it does scare me a little for when we're managing a large number of services. Also, there's a scenario where a service goes entirely offline and is pulled from the route table completely - causing a once valid route weight to become invalid and cause updates issues prior to cleanup.\nI'd love to hear thoughts and/or suggestions on this.. I was wondering what the status of this issue was? It's been causing some stability issues for large numbers of servers. If the route table stops updating, any scaling events or anything that happen during that state, the new/old nodes registered in consul aren't updated in the route table and everything starts dying. \nThis seems to happen if a manual route is added that points to a non-existent service. (E.g., adding a new service record, where no docker containers have come online yet and haven't had a chance to create consul entries).. ",
    "murphymj25": "We encountered this same issue when users added the URL prefix tag to consul with a \"/n\" at the end.. @leprechau Are you still using gobgp for your route reflectors?  We are looking to stand up some route reflectors as well in the near future and gobgp looks like a good option.  Just wondering how your experience has been.\n. We're seeing a similar behavior with delays in Fabio reflecting route updates.  We are using fabio 1.5.9 and consul 1.2.2 (upgraded from 1.0.2 to see if that would help).  The interesting thing is that when Fabio does update a few minutes after the consul local agent updates, we do not see the route change in the logs.  We are also seeing memory continue to grow.  With the routes stored in memory, not sure if this is relates.   It seems like this starts to happen when the devices have been up for a while and memory usage on the linux server is above 60%.\nI have tried restarting the consul agent, but that doesn't seem to make a difference, after restarting fabio however, thing appear to go back to normal.. It looks like the memory may be related to the metrics.  We have opened a separate issue #530 and provided the detail in that thread.. Would it be an option to have Fabio watch for changes to the token in a file?  This way the token could be updated without having to restart.  I think we're going to need to do something like this since we won't be able to get tokens that won't expire.  We can create a PR once we have a working solution.  Let me know if there are any suggestions or concerns with this approach.. I have a working solution to have the token pulled in from a file at every vault refresh interval.  This allows me to use other automated means to refresh the token without having to restart the process.  I'll try and get a PR out there early next week.. @pschultz I just created a pull request, #620.. I have just completed testing our update with the switch for glob matching.  For the test, the fabio load balancer has 8 cores and 8GB of memory.  In this environment Fabio currently has 2400 routes.  For testing we used wrk2 with a connection close header set to prevent keepalive connections.\nTest 1: \n    Volume: 1,000 TPS \n    Duration: 90 seconds \n    Setting: Glob Enabled\nTest 1 Result: CPU 70-72%\nTest 2: \n    Volume: 10,000 TPS\n    Duration: 90 seconds\n    Setting: Glob Disabled\nTest 2 Result: CPU 39-44%\nI also uploaded a screenshot of our test results, it's a little difficult to see the request volumes because of the large difference in volume between the two tests, but you can clearly see the difference in CPU.\nWe've also verified that the older glob package (glob/ryanuber-8) performed significantly better than the new glob package (gobwas/glob).  Based on #457, a compiled gobwas/glob might get performance closer to what we are seeing with glob disabled.\n@galen0624 feel free to add anything i might have missed.\n\n. Ah yes, i looked a little further and see the test that fails.  It looks like it is \"TestVaultSource\".  When i run the test manually, i get the following:\n=== RUN   TestVaultSource\n--- FAIL: TestVaultSource (3.30s)\n    source_test.go:316: Starting vault: \"Vault v0.9.1 ('87b6919dea55da61d7cd444b2442cabb8ede8ab1')\\n\"\n    source_test.go:465: Vault: KV backend: V1\n=== RUN   TestVaultSource/renewable_token\n2019/01/16 15:46:34 [ERROR] cert: Cannot load certificates from secret/fabio/cert. vault: query mount path: Error making API request.\n. I updated my local vault to v1.0.2 and the tests now pass.  Thanks everyone for the help!\nClosing this issue.. @pschultz I need to update my post, i think my pprof was pointing to the wrong culprit within WatchBackend.  I'll provide more detail shortly.. Looking at the updated pprof, we see the following:\nROUTINE ======================== main.watchBackend in /Users/spjaw2/code/go/src/github.com/fabiolb/fabio/main.go\n    1.38GB     1.45GB (flat, cum) 79.31% of Total\n         .          .    395:        case mancfg = <-man:\n         .          .    396:        }\n         .          .    397:\n         .          .    398:        // manual config overrides service config\n         .          .    399:        // order matters\n    1.38GB     1.38GB    400:        next := svccfg + \"\\n\" + mancfg\n         .          .    401:        if next == last {\n         .          .    402:            continue\n         .          .    403:        }\n         .          .    404:\n         .   165.05kB    405:        aliases, err := route.ParseAliases(next)\n         .          .    406:        if err != nil {\n         .          .    407:            log.Printf(\"[WARN]: %s\", err)\n         .          .    408:        }\n         .          .    409:        registry.Default.Register(aliases)\n         .          .    410:\n         .    68.43MB    411:        t, err := route.NewTable(next)\n         .          .    412:        if err != nil {\n         .          .    413:            log.Printf(\"[WARN] %s\", err)\n         .          .    414:            continue\n         .          .    415:        }\n         .          .    416:        route.SetTable(t)\n         .     2.35MB    417:        logRoutes(t, last, next, cfg.Log.RoutesFormat)\n         .          .    418:        last = next\n         .          .    419:\n         .          .    420:        once.Do(func() { close(first) })\n         .          .    421:    }\n         .          .    422:}. @pschultz the above pprof is an inuse_space profile.. I'm still digging into this issue.  I've been unsuccessful in recreating the behavior in a lab environment.  I'm gathering some more pprofs from devices to try and narrow down what's happening.  It's possible that our solution to address #611 will resolve this behavior as well.. Need to re-add, looks like some changes from another branch got pulled in.. Closing, will re-open. Thanks for the feedback!  I'll look to incorporate your suggestions.  Do you have a link that gives an overview of wrapped tokens?  That may help my understanding, but I think i get the general idea based on your comments.. Got it, i think i can put something together for that.  Thanks for the additional detail!. I think that makes sense.  I'll get this updated.. Will do.. For my use case, i trust that the token in the file is always a valid token, so i would want to grab the valid token every time fabio does a new check to vault, but i can see where that might be a challenge. I'll add some logic to only set the token if it has changed in the file (the current token no longer matches the token in the file), and account for if the file is blank or missing.. Will do. I'll update to TrimSpace.. Will do. ",
    "kopax": "Hi, thanks. It get more clear for 1,2,3.\nInteresting that you use mysql port :3306 for your example, is this really working ?\nI was trying on panteras and haproxy to proxy postgresql and mysql database and it never worked I never used the TCP proxy for them and I never knew why.\nI have tried in fabio.properties:\n proxy.addr = :25;proto=tcp,:143;proto=tcp,:587;proto=tcp,:993;proto=tcp\n\nThis work fine I can do telnet on each port. I want to send an email using port 587 with STARTTLS.\nI wasn't configuring anything in HAproxy. \nI have this error when I try to send an email from thunderbird: \nSending of the message failed.\nAn error occurred while sending mail: Unable to establish a secure link with Outgoing server (SMTP) mail.domain.com using STARTTLS since it doesn't advertise that feature. Switch off STARTTLS for that server or contact your service provider.\n\nI am reading this but not sure if it is the right direction. Maybe it is related to proxy.header.tls proxy.header.tls.value\nI haven't configured anything regarding certificate. It's always a mess to understand what needs to be configured and how it should be. Do I really have to do that here in Fabio ? I use to do SSL terminaisons on nginx. I never had to configure anything with haproxy when doing TCP proxying.. Thanks for your indication, apparently I have verified and SSL is fine using plain TCP, the handshake is done after Fabio.\nI might have misunderstood the basic usage scenario...\nI use to have HAproxy installed, and I was registering my TCP services using haproxy_tcp=587\nNow I am registering with urlprefix-:587 proto=tcp AND I have to configure proxy.addr in fabio.properties\nI noticed that using proxy.addr without listen address (:587;proto=tcp) will open that port on all my interfaces. \nThis is fine, my mail server needs to be public, but how about if I need to keep it private ? I though, ok just set the ip like (172.16.0.3:587;proto=tcp), this work, but how about if I don't know on what slave will run my application ? \nShould the fabio.properties be the same for all my masters ? I was only able to access the services if I configure Fabio on that same master host (which is also a slave).\nI have this assumption, if I open :587 using proxy.addr, it appear it is just for the current host application and it does not load balance anything except the local application. If this is true with what configuration can I do load balancing from a single fabio instance ?. :cry: I will revert to HAproxy, but only because it's impossible to proxy using a specific interface yet and I have services that require it. For when (approx) do you schedule your release ? I am waiting for it with impatience, from what I have seen and what I have played with, it is a great tool. Very easy and handy. Thanks for sharing it. . Sure, just tell me how I can help. \n~~It would be nice if you could create a de configuration variable. for example, instead of using the default :3600 for 0.0.0.0:3600, use a proxy.listen_ip='172.16.0.1' variable that would be used as a default interface. \nThis is standard variable and it could be used in panteras with the LISTEN_IP env settings.~~\n. Sorry, I meant having the possibility to configure a default interface instead of 0.0.0.0\nI have set some iptables rules that configure my public interface by first allowing a few public ports then dropping the rest. It was working fine enough with HAproxy. I only had to configure one ENV tag and consul_haproxy_template was updating haproxy proxy configuration. All HAproxy exposed TCP service are accessible through the private lan interface. If I needed to open a service I only had to add a new allow rules for that new port into the iptables chain. For some reason, Fabio is exposing on top of my firewall rules because of the default 0.0.0.0, is there a way to avoid that ?. >  have this assumption, if I open :587 using proxy.addr, it appear it is just for the current host application and it does not load balance anything except the local application. If this is true with what configuration can I do load balancing from a single fabio instance ?\nThis is the other part that I don't understand, how do I know the ip address from the host that run Fabio ? I though load balancing was for that. If I scale up on marathon I have no way to send the new  application ip to Fabio. \nThis is also why I do need fabio to listen by default on a different interface than 0.0.0.0 otherwise, to stop Fabio placing rules on top of mine.. So far, I only have 3 hosts Master+Slave where PanteraS is installed.\nThey all have a private interface and together create a private cloud network on 172.16.x.x\nI am using consul and HAproxy for HA and load balancing.\nI have installed on one of them NGINX, which is used as the public https proxy and all the public accesses. \nIn PanteraS, HAproxy can also be used to proxy TCP. I sometimes open publicly on the public interface a new port proxied by HA proxy. (587,993) for example. \nNote that all my Master+Slave hosts all have the same HAproxy configuration setup and could be used has an emergency proxy if needed.. Any update on this ? I hope I can migrate soon but the security requirement can't replace the HAproxy completely.. > Who is connecting to whom\nAll my services are using consul service discovery, see panteras, they use environment tags in the container to register services into LB. \n\nwhich protocol \n\nTCP\n\nwhat isn't working\n\nI tried to replace HA proxy with Fabio and it doesn't fit all the previous requirements yet. \n\nThere is no dynamic listeners at the moment like in HA proxy.\nThe load balancer Fabio can't bind on my private interface eth3 and :587;proto=tcp is by default listening on all interface, I need to be able to specify the bind interface dynamically (by not specifying the address ip directly / by setting it in the configuration)\nHAproxy is running on the 3 masters (A/B/C) and by default I dropped all ports in the iptables for my public interface. Re-enabling ports one one host (C) allow me to nominate a public proxy easely. With Fabio the load balancing TCP configuration is more complicated because of (2), if the application starts on (A) the first time or (B) the second time it will always use the host port. The two fabio's instance left are not able to do the load balancing to the service.. We need to be able to bind to interface with at least a default interface. The possibility to do that using the ip address instead will block us in different use case. I will use it, please let me know if you decide do to it.\n\nI will take your advice and implement the consul-template next, I though panteras was already taking care of that when using START_FABIO=true but after looking at the code I couldn't find anything like that except for HAproxy. \nI understood from @sielaq that Fabio didn't need to be restarted but maybe it changed?\nThanks again for your answer.. For keeping flexibility of configuration. I don't always have the same interface name used. Also, on some host I have up to 3 network interfaces. . That work for me. I think I got all the advice I needed to try one more migration. I haven't play with consul-template yet, the one I am using has been made by sielaq.\nClosing for now. Thanks you again. . ",
    "jamesdmorgan": "Good spot yeah that doesn't make any sense. I'll re-check thanks. I upgraded to the latest version and it works so i'll close this. Thanks for your help.. ",
    "SoMuchToGrok": "@magiconair I'd definitely be in favor of this functionality. I'm currently working towards securing my entire infrastructure with end to end TLS. I use Vault's PKI backend to generate an x509 server certificate for Fabio itself. \nThe server certificate is used for:\n- Fabio routing to itself (UI)\n- Consul health checks against Fabio\nThis certificate has a short TTL of 30 days, so it gets rotated at the mid-way point (15 days). When this certificate does rotate, we need Fabio to start using it. The typical pattern here would be to send a SIGHUP (Vault itself follows this pattern). Currently, we're sending a full restart to Fabio on a rotation (and doing this restart in a highly-available manner introduces additional complexities).\n. Yeah, precisely. I definitely understand your rationale around general config reloading. \nI can open another issue to get discussion going around this specific use-case. Any objections?. Sorry for the late response - been very busy and distracted lately. I'll take a look within the next day and get back to you. Thanks!. Alright, it's been a very busy couple of weeks - thanks for pinging me on this @magiconair!\nThis is awesome - so happy to see this kind of integration. Just a few thoughts from my perspective:\n- It would be ideal to enable passing more options to Vault's PKI backend, such as:\n  - common name\n  - alt names\n  - ip sans\n  - From what I can tell, these are the only \"blockers\" preventing me from switching to this new config :)\n- Is anything currently handling the refresh of the clientca? From what I can see, nothing in the code is explicitly doing so. However, it may be inadvertently happening when the server cert refreshes (i.e. the entire TLS config gets refreshed)?\n- Just a general thought + improvement: I think it makes more sense for the refresh logic to take a fraction of a lifetime of a cert (i.e. 50%). Transitioning to a PKI-backed infrastructure takes some time, and I think many people will be running various TTLs in different environments. Additionally, this logic is closer to the default behavior of most of the hashicorp tooling around renewals. Ultimately, this becomes one less thing to keep track of. This is definitely something I can help implement if desired.\n. ",
    "tecnobrat": "I'm not sure I understand.  SNI makes the upstream handle the cert, does it not?\nI'd like to handle the cert in fabio.. I'm very confused, I can't find any example of multiple certs on the same listener in teh docs, so if you can point me in the right direction I'd be appreciative.. Oh crap, so path instead of file, and then fabio will do the magic! ... I was using file, and didn't realize that subtle difference.\nThanks muchly!. That worked perfectly, thanks muchly.. @jrasell @sev3ryn is this abandoned? I also need this as well as its a blocker .. let me know if I can help, happy to try to refactor this PR.. ",
    "mitchelldavis": "To piggy back on @CGreenburg question.  We're hoping to get Fabio to work like a reverse proxy (I think).  HTTP -> HTTPS in this case so our users can simply hit Fabio and Fabio routes the traffic to the backend services.  (An obvious use case for the tool.)  However, we're stubbing our toes somewhere.\nhttp://<fabio machine>/<service name>/<path> --> https://<service address>/<path>\n\nI think I understand that a straight through proxy wouldn't work in this case because the traffic would need to be terminated in Fabio and then continued on to the service and back in order to handle the certificates.  \nWe were able to get this to work if we added the Host: <service address> to the request which is prohibitive.  If the software knew the host header then it could go strait there.\n\nWhat are we missing?  Are we fundamentally missing something on how this should all work, or missing something in the Fabio configuration?. Here is my configuration for a Serverless REST API in Fabio:\n/registrar  https://<garble>.amazonaws.com:443  proto=https tlsskipverify=true  100.00%\n(purposefully garbling the url there.)\nI get a Bad Request from Amazon when I run even though this is the use case we're looking for...\ncurl http://<ip>:9999/registrar\nI should also note that I'm using the latest version of the magiconair/fabio docker container to run Fabio.. @magiconair Sorry to confuse.  @CGreenburg sits behind me, and we're working through the same problem.. [\n    {\n        \"Node\": \"api\",\n        \"Address\": \"opesqzhtvl.execute-api.us-west-2.amazonaws.com\",\n        \"TaggedAddresses\": null,\n        \"ServiceID\": \"registrar\",\n        \"ServiceName\": \"registrar\",\n        \"ServiceTags\": [\n            \"urlprefix-/registrar proto=https strip=/registrar\"\n        ],\n        \"ServiceAddress\": \"\",\n        \"ServicePort\": 443,\n        \"ServiceEnableTagOverride\": false,\n        \"CreateIndex\": 517,\n        \"ModifyIndex\": 517\n    }\n]. I did and same result:\n[\n    {\n        \"Node\": \"api\",\n        \"Address\": \"opesqzhtvl.execute-api.us-west-2.amazonaws.com\",\n        \"TaggedAddresses\": null,\n        \"ServiceID\": \"registrar\",\n        \"ServiceName\": \"registrar\",\n        \"ServiceTags\": [\n            \"urlprefix-/registrar proto=https strip=/registrar\"\n        ],\n        \"ServiceAddress\": \"opesqzhtvl.execute-api.us-west-2.amazonaws.com\",\n        \"ServicePort\": 443,\n        \"ServiceEnableTagOverride\": false,\n        \"CreateIndex\": 745,\n        \"ModifyIndex\": 745\n    }\n]. Yes.  We can curl it directly no problem.. you should be able to curl it at:  https://opesqzhtvl.execute-api.us-west-2.amazonaws.com/dev. I was doing that already actually:\n\"192.168.16.145 - [12/May/2017:20:24:33 +0000]\n        upstream_addr: opesqzhtvl.execute-api.us-west-2.amazonaws.com:443\n        upstream_host: opesqzhtvl.execute-api.us-west-2.amazonaws.com$;\n        upstream_request_url: https://opesqzhtvl.execute-api.us-west-2.amazonaws.com:443/dev\n        upstream_request_uri: /dev\n        upstream_request_scheme: https\n        upstream_service: registrar\"\n(That extra dollar sign on the upstream_host was a typo on the log.access.format in the properties). That's expected, Sorry, we're not going to give you access.. No Worries.  Thank you!. @magiconair, anymore thoughts on this?. @magiconair, We got a response back from the Cloud Front Engineers at AWS and it turns out that it's not working with the API Gateway because we're passing the wrong host header.  In this case, we're passing the IP of the fabio machine as the host header.  Cloud Front can't do anything with that host header and is expecting a header with the URL of the service we're trying to hit.\nDoes Fabio attempt to \"re-write\" the host header to the URL it's routing to?. You've nailed it @magiconair.  That's the issue.  Do you see this as a viable pull request that won't destroy existing functionality?  If so, I may be able to spend some cycles trying to get it implemented.. This is awesome.  Thank you for looking into this!. @magiconair, I was thinking that a tag would be a great way to configure this.  Just like the tlsskipverify boolean tag, we could add a usedesthostheader boolean tag that simply surrounds the code you outlined above in an if statement.  Do you think that would work?  Also, I'm not a GO guru, so could you give me a few hints on what needs to be updated in order for me to get this pull request started?. Thanks @magiconair, I'm currently working on a pull request.  I'm having trouble getting the vault tests to pass, but we'll get it in when we can.. @magiconair, changing to vault 0.6.4 worked.  Thank you so much for your guidance and I was able to run the changes against AWS API Gateway and it worked like a charm.. You're very welcome!  What kind of timeline are we looking at to get this released in a docker container?. * So if the two tests are redundant, should I roll them into one or just get rid of the second?\n I set UseUpstreamHostname on line 73 in route.go.  Is that not correct?\n usehost works for me and the only one I can come up with otherwise is resetHost.. @magiconair, how about usedesthost?. ooooo.... that's way better.  Default will be src?. I'm on it!. Thats a bummer.  It looks like an unstable test. :-(. No Worries.  It looks like I need to rerun the build anyways. :-D. ",
    "CGreenburg": "@magiconair yes, the tag does not contain the hostname. I've noticed when running curl -v <fabio-ip>:9999/status, the Host header gets set to <fabio-ip>:9999. If I set the Host header to only the ip, I get the same result.\nI registered a service pointing to www.google.com port 443 with a tag urlprefix-/google proto=https strip=/google. When I run curl -v -L <fabio-ip>:9999/google, the Host gets set to <fabio-ip>:9999 but I don't get the html from google. If I run curl -v -L -H 'Host: <fabio-ip>' http://<fabio-ip>:9999/google without the port specified in the host header, everything works like a charm.\nSo.... I'm unsure as to why the API Gateway URL is so picky about the Host header.... ",
    "systemfreund": "I am quoting from the RFC 7239:\n\nFor example, in an environment where a reverse proxy is also used as\n   a crypto offloader, this allows the origin server to rewrite URLs in\n   a document to match the type of connection as the user agent\n   requested, even though all connections to the origin server are\n   unencrypted HTTP\n\nSo obviously this is not what happens in fabio. As I described above the Forwarded header contains proto=http. However I'd expect it to be proto=https as that would be the \"connection [type] as the user agent requested\"\nOk admittedly, in my case the \"crypto offloading\" is done one layer above in the AWS loadbalancer. However, shouldn't we still forward the correct the user agent's \"connection type\" origin/upstream server?. I have tested your change and it's working now.\nAlso I agree with your objection to case 2. It's probably better to not change anything, if both headers are passed to fabio. Yes I can reproduce this on master. I was experimenting with master, because a similar issue regarding 500 errors and Websockets has been fixed recently and I was hoping that would solve my problem as it sounded very much like the same problem I am having. However, as you can see it was not the case.. I appreciate your fast reaction! Unfortunately, the fix did not seem to help. For reference, I am running fabio with these parameters:\n./fabio  -proxy.gzip.contenttype='^(text/.*|application/(javascript|json|hal+json|xml)|.*\\+(json|xml))(;.*)?$'\nThen I am doing the problematic request:\nnc localhost 9999 < /failing-request\nGET /upstream HTTP/1.1\nHost: localhost:9999\nConnection: Upgrade\nUpgrade: websocket\nAccept-Encoding: gzip, deflate, sdch, br\nI've added a fmt.Println() at the same location described above (http_raw_handler.go#28) and it indeed is running into the \"not a hijacker\" block again.. Here's how you can reproduce the problem:\n\nrun python -m http.server 1234\ncreate file upstream.json:\n   { \"service\": { \"name\": \"upstream\", \"port\": 1234, \"tags\": [\"urlprefix-/upstream\"], \"check\": { \"id\": \"upstream\", \n   \"http\": \"http://localhost:1234\", \"interval\": \"10s\", \"timeout\": \"1s\" } } }\nrun consul agent -dev -config-file=upstream.json\nrun \n   fabio  -proxy.gzip.contenttype='^(text/.*|application/(javascript|json|hal+json|xml)|.*\\+(json|xml))(;.*)$'\nrun nc localhost 9999 < failing-request  (for contents of failing-request see previous comment). I can confirm now that the fix is working. Thank you very much!. In my particular case I'd expect fabio to remove the route. I am not saying that the current implementation is wrong, neither would my particular expectation be general enough for all use-cases.\n\nMaking it configurable would perhaps be the best option:\n All health checks must pass (my use-case)\n At least one health-check must pass (current behaviour)\nI can live with the current limitation and remove the secondary health-check from my service. Anyways, would an option to configure the behaviour desirable?. Sure, go ahead!. Yes, that makes much more sense!\nSo should I incorporate your code into this PR and also change the setting to a string-based one?. No problem, however I won't be able to do anything until the weekend.. Yes, I do and I'm going to update the PR this evening.. I've updated the PR, however some unrelated test seem to fail (at least it looks unrelated)\nFAIL   github.com/fabiolb/fabio/cert   15.015s. done :). ",
    "hauleth": "I have somewheat similar problem, though I get http on both headers which prevents me from redirecting from HTTP to HTTPS as I have no way to distinguish origin protocol. However I am using tcp and ssl LB instead of http and https as I need to provide support for WebSockets also.. Ok, after further investigation it seems that there are no support in ELB for WebSockets so when one connect to ELB and termination happens then there are no x-forwarded- headers. However this still presents a bug in Fabio as PROXY protocol reveals connection port (which I could use as a replacement), however it always set it to 80 from what I see.. @magiconair I am not familiar with Go and Fabio internals, so I am not quite sure what you are saying.. TBH doesn't matter. ",
    "Superman132": "We should update the performance section with 1.8 metrics :). ",
    "thisLambo": "I have an idea of a work around until you're able to solve it.\nThanks for the quick response. ",
    "muravitskiy": "Ok so now I'm asking for this option :). ",
    "Rameshera-xx": "Thank you fir the update. from below command i am unable to find from my server. Where can i find ./server binary?\n./server -addr 127.0.0.1:5000 -name svc-a -prefix /foo. ",
    "InformatiQ": "out of the top of my head i would expect to see\n number of connections\n tx and rx stats per service\n. we will be proxying carbon (graphite project) which opens up a connection and keeps it up, and we need to be able to balance the conn over the list of nodes.\nThe thing is it does not close the connection untill it is restarted. some sort of a health check on the upstream (such as CPU or queue size) would greatly help.\n. ",
    "shuoyenl": "Hi, I was looking into the same recently. My understanding is aws ELB does support WebSockets with TCP/SSL being used. It also supports proxy protocol v1 to carry over the original connection information. Fabio however only sets X-Forwarded-For when it's websocket (i.e. header Upgrade is set to \"websocket\".) And that could potentially break backend services relying on the header but doesn't use websocket. Also, proxy protocol v1 does not seem to keep the protocol of the original request. So there may be no way for fabio to know the protocol used between the client and the elb. Please let me know if it makes sense / if I miss anything. Thanks. . ",
    "aalba6675": "Thanks ! . ",
    "danielmotaleite": "6191 root       20   0 15.4G  9.9G  5352 S  3.2 15.8     0     0 26h34:23 /usr/local/bin/fabio -cfg /etc/fabio.conf\n10GB of ram! but i'm using 1.5.0, i will upgrade to 1.5.2 to see how much it will help. After the upgrade and more that 24h later:\nfabio    26033  4.8  0.1  96852 68932 ?        Ssl  Aug07  67:45 /usr/local/bin/fabio -cfg /etc/fabio.conf\nmuch better... so yes, the memory leak in 1.5.x <1.5.2 was big, but it's now fixed!  :)\ni will also play with the runtime.gogc. thanks for the help!. ",
    "jstoja": "Indeed, already tried but the syntax wasn't good. Wasn't even linked to fabio!\nFor next people, you can specify multiple tags by splitting them with a comma:\nSERVICE_TAGS=urlprefix-/hello/ strip=hello, urlprefix-/world/. ",
    "plkumar": "\n. I changed the tags and updated the source, but I'm still seeing 404.\n\nWhat am i doing wrong here.. here is how the trace looks.\n$ curl -v -H 'Trace: abc' -H 'Host: plk.me' 'http://plk.me:9999/dataservice/values'\n timeout on name lookup is not supported\n   Trying 127.0.0.1...\n TCP_NODELAY set\n Connected to plk.me (127.0.0.1) port 9999 (#0)\n\nGET /dataservice/values HTTP/1.1\nHost: plk.me\nUser-Agent: curl/7.51.0\nAccept: /\nTrace: abc\n< HTTP/1.1 404 Not Found\n< Date: Fri, 07 Jul 2017 12:37:25 GMT\n< Content-Length: 0\n< Content-Type: text/plain; charset=utf-8\n<\n Curl_http_done: called premature == 0\n Connection #0 to host plk.me left intact. BTW, with the url \"http://plk.me:9999/dataservice/values\" nothing is being logged in the Fabio log, does it mean the routing is working, but i still see 404.\n\nbut if i access the service directly, it is working.. i found the, issue, it is something to do with my ASP.NET WebApi routing, fixed it.\nThanks\nLakshman. ",
    "pvandervelde": "We just ran into this issue this week when fabio came up before the local consul instance did. We're running with fabio 1.5.2 at the moment. Sweet. I'll grab the next release :) Thanks for fixing it!. @magiconair What are the odds these statsd metrics changes are going to make it into a release in the near future? We would love to have the improved statsd metrics.. @magiconair Has this issue ever been fixed? I am seeing the same problem with Fabio 1.5.9 with services with multiple health checks. For me the output of  curl 'localhost:8500/v1/health/state/any?consistent&pretty'? is (unrelated nodes and services filtered out)\n[\n    {\n        \"Node\": \"NZDINH10-01\",\n        \"CheckID\": \"notifications-NZDINH10-01 - mode.operating\",\n        \"Name\": \"mode.operating\",\n        \"Status\": \"critical\",\n        \"Notes\": \"\",\n        \"Output\": \"Maintenance mode:enabled\",\n        \"ServiceID\": \"notifications-NZDINH10-01\",\n        \"ServiceName\": \"notifications\",\n        \"ServiceTags\": [\n            \"http\",\n            \"edgeproxyprefix-/services/notifications strip=/services/notifications\"\n        ],\n        \"Definition\": {},\n        \"CreateIndex\": 19375125,\n        \"ModifyIndex\": 19468443\n    },\n    {\n        \"Node\": \"NZDINH10-01\",\n        \"CheckID\": \"notifications-NZDINH10-01 - dependency: http.metrics\",\n        \"Name\": \"dependency: http.metrics\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"http.metrics - Passing\",\n        \"ServiceID\": \"notifications-NZDINH10-01\",\n        \"ServiceName\": \"notifications\",\n        \"ServiceTags\": [\n            \"http\",\n            \"edgeproxyprefix-/services/notifications strip=/services/notifications\"\n        ],\n        \"Definition\": {},\n        \"CreateIndex\": 19375124,\n        \"ModifyIndex\": 19375358\n    },\n    {\n        \"Node\": \"NZDINH10-01\",\n        \"CheckID\": \"notifications-NZDINH10-01 - dependency: http.queue\",\n        \"Name\": \"dependency: http.queue\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"http.queue - Passing\",\n        \"ServiceID\": \"notifications-NZDINH10-01\",\n        \"ServiceName\": \"notifications\",\n        \"ServiceTags\": [\n            \"http\",\n            \"edgeproxyprefix-/services/notifications strip=/services/notifications\"\n        ],\n        \"Definition\": {},\n        \"CreateIndex\": 19375123,\n        \"ModifyIndex\": 19375343\n    },\n    {\n        \"Node\": \"NZDINH10-01\",\n        \"CheckID\": \"notifications-NZDINH10-01 - vault.authentication\",\n        \"Name\": \"vault.authentication\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"Credentials: authenticated\",\n        \"ServiceID\": \"notifications-NZDINH10-01\",\n        \"ServiceName\": \"notifications\",\n        \"ServiceTags\": [\n            \"http\",\n            \"edgeproxyprefix-/services/notifications strip=/services/notifications\"\n        ],\n        \"Definition\": {},\n        \"CreateIndex\": 19375126,\n        \"ModifyIndex\": 19375975\n    },\n    {\n        \"Node\": \"NZDINH10-01\",\n        \"CheckID\": \"serfHealth\",\n        \"Name\": \"Serf Health Status\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"Agent alive and reachable\",\n        \"ServiceID\": \"\",\n        \"ServiceName\": \"\",\n        \"ServiceTags\": [],\n        \"Definition\": {},\n        \"CreateIndex\": 18772817,\n        \"ModifyIndex\": 18772817\n    },\n]\n\n. For all those that come across this at some point. It looks like there might be a fix for this in PR #428 which adds strict health checking.. Looks good to me. The only additional question that comes up is what is the time unit for the timers? Is it milliseconds?. Yes, that entire line is one single consul tag. I've got other services (with other prefixes / strip / host options) and those work just fine but they strip either just the start of the prefix or the entire prefix.. In our case we're proxying using fabio to proxy a set of sites / services that we use in our build infrastructure. Most of these services aren't our own services, they're third party tools that we run so we have very little control over what handlers there are. The goal is to provide the developers with a single 'site' that looks like it has all the services they need to interact with our build infrastructure. So for instance the site that fabio presents to the users looks like\nmyhost.mycompany.com\n    builds\n    artefacts\n        installers\n        images\n    services\n        rabbitmq\n\nWhere builds points to a jenkins instance, artefacts/files points to a caddy webserver instance, artefacts/images points to a web service and services/rabbitmq points to a local RabbitMQ instance. The problem described was that the caddy webserver was serving pages on \nmyotherhost.mycompany.com/artefacts\n\nBecause we have multiple artefacts sites we wanted to combine them under the artefacts directory, hence we decided to put it under artefacts/files.\nI get that this is probably not what fabio was designed for and we can probably figure a way around it with some effort. I was just interested to see if I configured something wrong or if this was by design (which is perfectly fine by us).. Probably the fact that my explanation is crap. There are several other web services running on that machine so we can't use the machine root because it could collide with the other services, however we might be able to make it respond to /installers instead. \nIn the end it doesn't matter very much we'll be able to work around it :) I was just curious to see if I'd missed anything because I assumed that strip just replaced whatever term with an empty string, but that is not the case. Maybe it's more of a case of me not reading the documentation correctly. \n. Sounds sensible. For the immediate time we'll work around it while we update the services. Thanks. @magiconair Any progress on this. Would still love to have some decent metrics from Fabio.. ",
    "DiamondYuan": "I use docker magiconair/fabio:1.5.2-go1.8.3\nregister a spring boot project in fabio\n2017-07-25 16:59:17:fabio|192.168.15.49|GET|0.002851322|200|-1|/doctor-kb/health\n. when i use postman to access the web use fabio\n{\n    \"status\": \"UP\",\n    \"diskSpace\": {\n        \"status\": \"UP\",\n        \"total\": 482765783040,\n        \"free\": 107016912896,\n        \"threshold\": 10485760\n    },\n    \"db\": {\n        \"status\": \"UP\",\n        \"database\": \"MySQL\",\n        \"hello\": 1\n    }\n}\n````\nContent-Length \u2192155\nContent-Type \u2192application/vnd.spring-boot.actuator.v1+json;charset=UTF-8\nDate \u2192Tue, 25 Jul 2017 09:03:42 GMT\nX-Application-Context \u2192application:swagger:80\n````\n. yes the api don't have Content-Length header.\nplease close the issues .thanks. ",
    "awalterschulze": "I am also wondering how to get response_body_size efficiently in go.\nnginx seems to be able to do this with their body_bytes_sent variable.. I found a solution here\nhttps://github.com/containous/traefik/blob/7399a83c747a4fef9942cca72643a363bb62b617/middlewares/accesslog/capture_response_writer.go. ",
    "lforehan": "It seems that instead of a direct cloudwatch integration, a user could configure fabio to send to local statsd that is configured to use the cloudwatch backend\nhttps://github.com/Jc2k/statsd-cloudwatch. ",
    "mqasim1983": "Thanks a lot.\n. ",
    "tomstaijen": "Does that result in a \"http: proxy error: context canceled\" in the fabio output?. ",
    "akissa": "Yes the service ids and names are unique, the are based on service-hostname. The output is below. I think it happens when a service has more than one check. I tried it with just the one check and it was working okay. With the two checks per service as below it adds the route even when 1 of the checks is critical.\nConsul\ncurl '192.168.1.34:8500/v1/health/state/any?consistent&pretty'\n[\n    {\n        \"Node\": \"db.home.topdog-software.com\",\n        \"CheckID\": \"service:pgsql-db.home.topdog-software.com:1\",\n        \"Name\": \"pgsql replica on db.home.topdog-software.com\",\n        \"Status\": \"critical\",\n        \"Notes\": \"\",\n        \"Output\": \"HTTP GET http://192.168.1.15:8008: 503 Service Unavailable Output: {\\\"database_system_identifier\\\": \\\"6428526973303804376\\\", \\\"postmaster_start_time\\\": \\\"2017-08-25 06:54:28.913 UTC\\\", \\\"xlog\\\": {\\\"received_location\\\": 2229388368, \\\"replayed_timestamp\\\": \\\"2017-08-25 07:08:22.186 UTC\\\", \\\"paused\\\": false, \\\"replayed_location\\\": 2229388368}, \\\"patroni\\\": {\\\"scope\\\": \\\"baruwa\\\", \\\"version\\\": \\\"1.3.3\\\"}, \\\"state\\\": \\\"running\\\", \\\"role\\\": \\\"replica\\\", \\\"server_version\\\": 90604}\",\n        \"ServiceID\": \"pgsql-db.home.topdog-software.com\",\n        \"ServiceName\": \"pgsql-db.home.topdog-software.com\",\n        \"ServiceTags\": [\n            \"urlprefix-:5432 proto=tcp\"\n        ],\n        \"CreateIndex\": 45331,\n        \"ModifyIndex\": 45471\n    },\n    {\n        \"Node\": \"db3.home.topdog-software.com\",\n        \"CheckID\": \"service:pgsql-db3.home.topdog-software.com:1\",\n        \"Name\": \"pgsql replica on db3.home.topdog-software.com\",\n        \"Status\": \"critical\",\n        \"Notes\": \"\",\n        \"Output\": \"HTTP GET http://192.168.1.34:8008: 503 Service Unavailable Output: {\\\"database_system_identifier\\\": \\\"6428526973303804376\\\", \\\"postmaster_start_time\\\": \\\"2017-08-25 06:54:29.518 UTC\\\", \\\"xlog\\\": {\\\"received_location\\\": 2229388368, \\\"replayed_timestamp\\\": \\\"2017-08-25 07:08:22.186 UTC\\\", \\\"paused\\\": false, \\\"replayed_location\\\": 2229388368}, \\\"patroni\\\": {\\\"scope\\\": \\\"baruwa\\\", \\\"version\\\": \\\"1.3.3\\\"}, \\\"state\\\": \\\"running\\\", \\\"role\\\": \\\"replica\\\", \\\"server_version\\\": 90604}\",\n        \"ServiceID\": \"pgsql-db3.home.topdog-software.com\",\n        \"ServiceName\": \"pgsql-db3.home.topdog-software.com\",\n        \"ServiceTags\": [\n            \"urlprefix-:5432 proto=tcp\"\n        ],\n        \"CreateIndex\": 45424,\n        \"ModifyIndex\": 45474\n    },\n    {\n        \"Node\": \"db.home.topdog-software.com\",\n        \"CheckID\": \"serfHealth\",\n        \"Name\": \"Serf Health Status\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"Agent alive and reachable\",\n        \"ServiceID\": \"\",\n        \"ServiceName\": \"\",\n        \"ServiceTags\": [],\n        \"CreateIndex\": 40965,\n        \"ModifyIndex\": 45328\n    },\n    {\n        \"Node\": \"db.home.topdog-software.com\",\n        \"CheckID\": \"service:pgsql-db.home.topdog-software.com:2\",\n        \"Name\": \"pgbouncer on db.home.topdog-software.com\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"TCP connect 192.168.1.15:5432: Success\",\n        \"ServiceID\": \"pgsql-db.home.topdog-software.com\",\n        \"ServiceName\": \"pgsql-db.home.topdog-software.com\",\n        \"ServiceTags\": [\n            \"urlprefix-:5432 proto=tcp\"\n        ],\n        \"CreateIndex\": 45333,\n        \"ModifyIndex\": 45470\n    },\n    {\n        \"Node\": \"db2.home.topdog-software.com\",\n        \"CheckID\": \"serfHealth\",\n        \"Name\": \"Serf Health Status\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"Agent alive and reachable\",\n        \"ServiceID\": \"\",\n        \"ServiceName\": \"\",\n        \"ServiceTags\": [],\n        \"CreateIndex\": 40965,\n        \"ModifyIndex\": 40965\n    },\n    {\n        \"Node\": \"db2.home.topdog-software.com\",\n        \"CheckID\": \"service:pgsql-db2.home.topdog-software.com:1\",\n        \"Name\": \"pgsql replica on db2.home.topdog-software.com\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"HTTP GET http://192.168.1.33:8008: 200 OK Output: {\\\"database_system_identifier\\\": \\\"6428526973303804376\\\", \\\"postmaster_start_time\\\": \\\"2017-08-25 06:46:43.462 UTC\\\", \\\"xlog\\\": {\\\"location\\\": 2229387608}, \\\"patroni\\\": {\\\"scope\\\": \\\"baruwa\\\", \\\"version\\\": \\\"1.3.3\\\"}, \\\"replication\\\": [{\\\"sync_state\\\": \\\"sync\\\", \\\"sync_priority\\\": 1, \\\"client_addr\\\": \\\"192.168.1.15\\\", \\\"state\\\": \\\"streaming\\\", \\\"application_name\\\": \\\"db.home.topdog-software.com\\\", \\\"usename\\\": \\\"replicator\\\"}, {\\\"sync_state\\\": \\\"async\\\", \\\"sync_priority\\\": 0, \\\"client_addr\\\": \\\"192.168.1.34\\\", \\\"state\\\": \\\"streaming\\\", \\\"application_name\\\": \\\"db3.home.topdog-software.com\\\", \\\"usename\\\": \\\"replicator\\\"}], \\\"state\\\": \\\"running\\\", \\\"role\\\": \\\"master\\\", \\\"server_version\\\": 90604}\",\n        \"ServiceID\": \"pgsql-db2.home.topdog-software.com\",\n        \"ServiceName\": \"pgsql-db2.home.topdog-software.com\",\n        \"ServiceTags\": [\n            \"urlprefix-:5432 proto=tcp\"\n        ],\n        \"CreateIndex\": 45381,\n        \"ModifyIndex\": 45458\n    },\n    {\n        \"Node\": \"db2.home.topdog-software.com\",\n        \"CheckID\": \"service:pgsql-db2.home.topdog-software.com:2\",\n        \"Name\": \"pgbouncer on db2.home.topdog-software.com\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"TCP connect 192.168.1.33:5432: Success\",\n        \"ServiceID\": \"pgsql-db2.home.topdog-software.com\",\n        \"ServiceName\": \"pgsql-db2.home.topdog-software.com\",\n        \"ServiceTags\": [\n            \"urlprefix-:5432 proto=tcp\"\n        ],\n        \"CreateIndex\": 45383,\n        \"ModifyIndex\": 45459\n    },\n    {\n        \"Node\": \"db3.home.topdog-software.com\",\n        \"CheckID\": \"serfHealth\",\n        \"Name\": \"Serf Health Status\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"Agent alive and reachable\",\n        \"ServiceID\": \"\",\n        \"ServiceName\": \"\",\n        \"ServiceTags\": [],\n        \"CreateIndex\": 40965,\n        \"ModifyIndex\": 45004\n    },\n    {\n        \"Node\": \"db3.home.topdog-software.com\",\n        \"CheckID\": \"service:pgsql-db3.home.topdog-software.com:2\",\n        \"Name\": \"pgbouncer on db3.home.topdog-software.com\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"TCP connect 192.168.1.34:5432: Success\",\n        \"ServiceID\": \"pgsql-db3.home.topdog-software.com\",\n        \"ServiceName\": \"pgsql-db3.home.topdog-software.com\",\n        \"ServiceTags\": [\n            \"urlprefix-:5432 proto=tcp\"\n        ],\n        \"CreateIndex\": 45425,\n        \"ModifyIndex\": 45475\n    }\n]\nFabio\n```\n./fabio -cfg fabio.properties\n2017/08/25 09:13:11 [INFO] Runtime config\n{\n    \"Proxy\": {\n        \"Strategy\": \"rnd\",\n        \"Matcher\": \"prefix\",\n        \"NoRouteStatus\": 404,\n        \"MaxConn\": 10000,\n        \"ShutdownWait\": 0,\n        \"DialTimeout\": 30000000000,\n        \"ResponseHeaderTimeout\": 0,\n        \"KeepAliveTimeout\": 0,\n        \"FlushInterval\": 1000000000,\n        \"LocalIP\": \"192.168.1.20\",\n        \"ClientIPHeader\": \"\",\n        \"TLSHeader\": \"\",\n        \"TLSHeaderValue\": \"\",\n        \"GZIPContentTypes\": null,\n        \"RequestID\": \"\"\n    },\n    \"Registry\": {\n        \"Backend\": \"consul\",\n        \"Static\": {\n            \"Routes\": \"\"\n        },\n        \"File\": {\n            \"Path\": \"\"\n        },\n        \"Consul\": {\n            \"Addr\": \"192.168.1.34:8500\",\n            \"Scheme\": \"http\",\n            \"Token\": \"\",\n            \"KVPath\": \"/fabio/config\",\n            \"TagPrefix\": \"urlprefix-\",\n            \"Register\": false,\n            \"ServiceAddr\": \":9998\",\n            \"ServiceName\": \"fabio\",\n            \"ServiceTags\": null,\n            \"ServiceStatus\": [\n                \"passing\"\n            ],\n            \"CheckInterval\": 1000000000,\n            \"CheckTimeout\": 3000000000,\n            \"CheckScheme\": \"http\",\n            \"CheckTLSSkipVerify\": false\n        },\n        \"Timeout\": 10000000000,\n        \"Retry\": 500000000\n    },\n    \"Listen\": [\n        {\n            \"Addr\": \":5432\",\n            \"Proto\": \"tcp\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false,\n            \"TLSMinVersion\": 0,\n            \"TLSMaxVersion\": 0,\n            \"TLSCiphers\": null\n        }\n    ],\n    \"Log\": {\n        \"AccessFormat\": \"common\",\n        \"AccessTarget\": \"\",\n        \"RoutesFormat\": \"delta\"\n    },\n    \"Metrics\": {\n        \"Target\": \"\",\n        \"Prefix\": \"{{clean .Hostname}}.{{clean .Exec}}\",\n        \"Names\": \"{{clean .Service}}.{{clean .Host}}.{{clean .Path}}.{{clean .TargetURL.Host}}\",\n        \"Interval\": 30000000000,\n        \"GraphiteAddr\": \"\",\n        \"StatsDAddr\": \"\",\n        \"Circonus\": {\n            \"APIKey\": \"\",\n            \"APIApp\": \"fabio\",\n            \"APIURL\": \"\",\n            \"CheckID\": \"\",\n            \"BrokerID\": \"\"\n        }\n    },\n    \"UI\": {\n        \"Listen\": {\n            \"Addr\": \":9998\",\n            \"Proto\": \"http\",\n            \"ReadTimeout\": 0,\n            \"WriteTimeout\": 0,\n            \"CertSource\": {\n                \"Name\": \"\",\n                \"Type\": \"\",\n                \"CertPath\": \"\",\n                \"KeyPath\": \"\",\n                \"ClientCAPath\": \"\",\n                \"CAUpgradeCN\": \"\",\n                \"Refresh\": 0,\n                \"Header\": null\n            },\n            \"StrictMatch\": false,\n            \"TLSMinVersion\": 0,\n            \"TLSMaxVersion\": 0,\n            \"TLSCiphers\": null\n        },\n        \"Color\": \"light-green\",\n        \"Title\": \"\",\n        \"Access\": \"rw\"\n    },\n    \"Runtime\": {\n        \"GOGC\": 800,\n        \"GOMAXPROCS\": 2\n    },\n    \"ProfileMode\": \"\",\n    \"ProfilePath\": \"/tmp\"\n}\n2017/08/25 09:13:11 [INFO] Version 1.5.2 starting\n2017/08/25 09:13:11 [INFO] Go runtime is go1.8.3\n2017/08/25 09:13:11 [INFO] Metrics disabled\n2017/08/25 09:13:11 [INFO] Setting GOGC=800\n2017/08/25 09:13:11 [INFO] Setting GOMAXPROCS=2\n2017/08/25 09:13:11 [INFO] consul: Connecting to \"192.168.1.34:8500\" in datacenter \"dc1\"\n2017/08/25 09:13:11 [INFO] consul: Not registering fabio in consul\n2017/08/25 09:13:11 [INFO] Admin server access mode \"rw\"\n2017/08/25 09:13:11 [INFO] Admin server listening on \":9998\"\n2017/08/25 09:13:11 [INFO] Waiting for first routing table\n2017/08/25 09:13:11 [INFO] consul: Using dynamic routes\n2017/08/25 09:13:11 [INFO] consul: Using tag prefix \"urlprefix-\"\n2017/08/25 09:13:11 [INFO] consul: Watching KV path \"/fabio/config\"\n2017/08/25 09:13:11 [INFO] consul: Manual config changed to #45610\n2017/08/25 09:13:11 [INFO] consul: Health changed to #45609\n2017/08/25 09:13:11 [INFO] TCP proxy listening on :5432\n2017/08/25 09:13:11 [INFO] Config updates\n+ route add pgsql-db3.home.topdog-software.com :5432 tcp://192.168.1.34:5432\n+ route add pgsql-db2.home.topdog-software.com :5432 tcp://192.168.1.33:5432\n+ route add pgsql-db.home.topdog-software.com :5432 tcp://192.168.1.15:5432\n2017/08/25 09:13:15 [INFO] consul: Manual config changed to #45611\n```. No problem, i have actually refactored my workflow to remove the services of the slaves and only add the master so its okay. That way i do not have to deal with the logs filling up with service check errors for the slave systems.\nOn failover the demoted master gets removed and the promoted one inserted.\nThe fix would come in handy though for other scenarios where you are actually load balancing the connections.. Exactly, my use case is for postgresql failover. The unix socket cuts down on the tcp connection setup cost.. Actually this can be done via tags, sorry about the noise. ",
    "tomtakan": "Yes that is correct. I do not see a use case for HTTP though.. ",
    "Gufran": "@magiconair I wish to work on this but I'm going to need a helping hand.\nIt looks like most of the work is implementing the fastcgi client. [Caddy][] has a robust fastcgi client implementation that can be borrowed under Apache2 + BSD license.\nIf I'm correct about rest of the rig, I'll need to add another listener in proxy package and its configuration options in config package, register the listener in main. startServers and that should be enough. is that right?\nIs there anything else that I need to keep in mind?\n[Caddy]: https://github.com/mholt/caddy/blob/master/caddyhttp/fastcgi/fcgiclient.go. @magiconair Thanks for detailed feedback, much appreciated.\nLet me make changes and hopefully wrap it up this weekend.. @magiconair It is still kinda half baked, I need to test it properly because at this point I\u2019m not sure if it is even working. I\u2019ll write documentation and a couple more tests and let you know when ready.. @magiconair Ready for review now.. @magiconair let me know if there is anything else you want me to address.. @magiconair Ping!. @magiconair Do you think you can review this? Can I help here in any way?. @magiconair all done. please take a look now.. Shoot! this is an old one. @magiconair I hope you were able to resolve the problem with tests? Life took a few turns in last 6 months so I wasn't able to address this.. sure. I'll break it down into separate commits when I'm done with changes.. It returns the index at which the path should be split according to fastcgi configuration.. ",
    "snh": "I believe that * will only match non / characters, as fabio is using the Path.Match function for the matcher, which like most glob implementations doesn't match the / path separator character:\nhttps://github.com/fabiolb/fabio/blob/bc264cdc09364b888324046f2cbd659e3d4172e7/route/matcher.go#L26\nTherefore /s0/v1/call won't match the glob pattern /s0*, though /s0v1call for example would.\nhttps://github.com/golang/go/issues/11862 is a semi-related discussion related to the Go Path package.. 2017/08/30 11:08:28 [WARN] Error initializing backend. Get http://localhost:8500/v1/agent/self: dial tcp 127.0.0.1:8500: getsockopt: connection refused\nThis error appears to indicate that fabio was unable to connect to the local consul agent. Is there a consul agent running locally?\nAs you can see from the following output, even with registration disabled, fabio will still connect to consul to obtain routes and whatnot:\n$ fabio -registry.consul.register.enabled=false\n2017/08/30 19:26:05 [INFO] Runtime config\n...\n2017/08/30 19:26:05 [INFO] Version 1.5.2 starting\n2017/08/30 19:26:05 [INFO] Go runtime is go1.8.3\n2017/08/30 19:26:05 [INFO] Metrics disabled\n2017/08/30 19:26:05 [INFO] Setting GOGC=800\n2017/08/30 19:26:05 [INFO] Setting GOMAXPROCS=8\n2017/08/30 19:26:05 [INFO] consul: Connecting to \"localhost:8500\" in datacenter \"dc1\"\n2017/08/30 19:26:05 [INFO] consul: Not registering fabio in consul\nIf you don't wish to use consul as the backend, then you will need to select a different backend using -registry.backend, such as -registry.backend file or -registry.backend static.. ",
    "SachinMule": "Thanks a lot for the info @snh.. ",
    "i4s-pserrano": "is not a issue! We found the problem. We have consul with tls at other port, exist any way to present a valid cert to auth to consul with tls. ",
    "smalot": "In fact, in terms of routes, we need to handle in a near future up to 2 million rules (may be more).\nThis is due to a huge amount of domain names.\nFabio seems to be the more efficient tool to handle our needs.\nBut there are 3 main limitations:\n\nThe route file is really long to be parsed\nConsul can't store more than 512 K of data\nThere isn't any API to dynamically update routes without using Consul\n\nAm I right ?. ",
    "multipathmaster": "Magiconair, GRATSI AMIGO!!!!  -- MM. I'm going to go ahead and close this issue, Magiconair, know you are a busy dude, thank you again for the information!. ",
    "pims": "@magiconair thoughts on this issue?. ",
    "jefflequeux": "No, I'am using HTTP.. ",
    "Smithx10": "@magiconair Is that 1 tag space separated?\ntags: [\n  \"urlprefix-example.com/ weight=0.05\",\n  \"foo\"\n]\nLike this?\n. @magiconair,\nI just confirmed that this works.  Are there more things I can set via tags at registration?\nYou can close this :) . @magiconair\nIs there a way to view the version tag in the UI for each service?  \nThe following image displays 0.05 for version 1.0.1 and 0.15 for version 1.0.2 .  I'd like to be able to identify that... I'm assuming there is something I'm missing?\n\n. Any word / idea?. ",
    "lbrucher": "Similar need here.\nBuilding a \"maintenance mode\" feature where I'd like to re-route traffic going to serviceA to another service (serviceB for instance).\nWould have liked to simply add a manual route like this:\nroute add serviceA serviceA.domain.com/ http://serviceB.domain.com weight 1 opts \"proxy=true\"\nThe \"proxy=true\" would in fact rewrite the Host HTTP header to \"serviceB\" otherwise we'd endup with an infinite loop in Fabio once it receives a request for serviceA.\nAlternatively we could also update serviceA's tags as suggested in the feature description.\nIn that case, \"proxy = http://api/\" should also rewrite the Host HTTP header accordingly.\nFinally, the original Host header should also be kept, probably in a new HTTP header (\"x-host-original\"?)\n. ",
    "reinoud": "Thanks!\nReinoud\n. ",
    "jaxim": "Just to add to this. We are updating the weighting of our microservices via consul.\nwe retrive the current value of fabio/config and then append to it using consul kv put fabio/config '#foo'.\nMy question is what is the best way to maintain the routing that has been added to the kv?\ne.g. \nI update the weighting rules for service-a\nI update the weighting rules for service-b\nservice-a is no longer required and is removed from the environment. How would I tidy up the rules by removing service-a in fabio/config without affecting service-b? I didn't want to do this manually. I wanted it so that if service-a is un-deployed from an environment via a scripts, it would also tidy up the routing for that service too.\nIs it possible that you could have fabio/config/service-a and fabio/config/service-b? so services are maintained separately? so when a microservice is terminated I can remove the kv entry just for that service. ",
    "johnypony3": "It is now almost a year later. the dockerhub image is still running as root. why?. ",
    "xqliang": "Thank you, I need to use Nginx to write access log for monitoring the entire request time consuming (including Nginx to Fabio). \nCurrent, global configuration will meet my needs.. ",
    "vchan2002": "Ok.... after going a bit further.... it's a consul ACL issue where I have my k/v s set to default deny with the anonymous token.... So I imagine either adding an ACL to the consul agent where fabio runs, or relaxing the ACL for the anon token, is an option.... \nIt is interesting, however, that the 403 error only occurs if you tried to enter the override from the GUI, as it tries to write to the KV.  However, it does not complain when it, at 1st, cannot read from the k/v.\nGiven that.... i am still trying the use case of basically having it add a service without doing a prefix tagging.... so I tried something like this on the config, where I want it to automatically find the service and route it to the destination, and now it is complaining that the syntax is invalid.\nIs such a config currently supported?\nroute add {service} {path}. While I personally agree that the automatic discovery is the best way to go, my use case is that I will get pushback from other stakeholders of the different microservices that they may not want to 'share' the same set of fabio services for load balancing, while still using the same consul cluster for discovery.\nI think the best workaround, in this case, is to use separate consul clusters just for that seperation....  But I was just wondering whether my use case is unique.. apparently it is..... Oh yeah... that's right... I see that it is something you can setup in fabio.properties.... I did not think about utilizing that.  \nThat would definitely satisfy the use case that I have......\n. ",
    "dansteen": "Nice! that looks like it should do it.  I'll give it a test.  Thanks!. ",
    "commarla": "Hey can we have a feedback on this one? \nThanks!. Thanks to you @magiconair . ",
    "LeReverandNox": "Thanks a lot @magiconair ! We owe you one :). ",
    "antham": "Before the change, I have this : \ngo test -bench=BenchmarkProxyLogger github.com/fabiolb/fabio/proxy\n2017/11/07 13:00:19 [INFO] cert: Store has certificates for [\"example.com\"]\ngoos: darwin\ngoarch: amd64\npkg: github.com/fabiolb/fabio/proxy\nBenchmarkProxyLogger-4            100000             11171 ns/op\nPASS\nok      github.com/fabiolb/fabio/proxy  1.781s\nand after the change that : \n2017/11/07 13:01:32 [INFO] cert: Store has certificates for [\"example.com\"]\ngoos: darwin\ngoarch: amd64\npkg: github.com/fabiolb/fabio/proxy\nBenchmarkProxyLogger-4            100000             11111 ns/op\nPASS\nok      github.com/fabiolb/fabio/proxy  1.670s. It's the same here with http_headers_test you have from tests : \nproxy/http_headers_test.go:390:6: s declared but not used\nit's for the same reason you told before this statement exists ?. It's written in the article that you need to store the result in a package variable : \nalways store the result to a package level variable\nso the compiler cannot eliminate the Benchmark itself.. And the var in http_headers_test is necessary ? If it's the case, if think a little comment could avoid another discussion about its usage. . @magiconair What about this PR ?. Maybe you could add the -s flag to gofmt in your Makefile, it's what I ran.. ",
    "prologic": "Also interested in this. I don't see any mention of client authorisation based on certificates.. I don\u2019t understand whY you mean ?  Are you saying client  certificate based\nauthentication already exist as feature?\nOn Wed, 6 Mar 2019 at 11:18, Aaron Hurt notifications@github.com wrote:\n\nWould you consider this to be duplicative of support for consul connect\nand intentions?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/fabiolb/fabio/issues/384#issuecomment-469926389, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-h3EZxd-8wr1vxltbjGuv3GEhjcYks5vTxdegaJpZM4QWtn5\n.\n-- \n\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\n. > No, I'm trying to think of the use case for client certificate authentication and evaluate the work required vs audience for that feature vs other methods of authenticating/authorizing services like consul connect and intentions.\nOur use-case is quite simple. We want to be able to authenticate remote clients at the \"edge\" (that would be Fabio in this case if we decide to adopt it) and be able to control certificate revocation and renewal (which we can do through Vault APIs). ",
    "xw340721": "sorry! what i mean is how to connect consul cluster using fabio. Is there any configuration that i need to do? . ",
    "tomwganem": "What @leprechau is describing, a most-specific-match, is ultimately what we want.. Sure, I would be fine with that implementation. It would solve my use-case. . Although, just going by length would mean \na.domain.com\nand\n*.domain.com\nwould have the same precedence. I don't have any single character subdomains I need to be concerned about, but someone might.. I was unable to get tracing working. Not sure what i'm doing wrong. For reference, I am using docker image fabiolb/fabio:1.5.3-go1.9.2. Here are my routes\n#  | Service | Source | Dest | Options | Weight\n-- | -- | -- | -- | -- | --\n1 | files | *.asperafiles-dev.com/ | http://172.22.0.17:80/ | \u00a0 | 100.00%\n2 | a8-fe | analytics.asperafiles-dev.com/ | http://172.22.0.27:80/ | \u00a0 | 100.00%\n3 | a8-be | api-analytics.asperafiles-dev.com/ | http://172.22.0.26:9595/ | \u00a0 | 100.00%\n4 | api | api.asperafiles-dev.com/ | http://172.22.0.24:9292/ | \u00a0 | 100.00%\n5 | files | asperafiles-dev.com/ | http://172.22.0.17:80/ |   | 100.00%\nSo in the above routing table, most of all of our requests are going to the service called 'files', which will serve up a webpage with some javascript.\nHere's me curling a page I know should be routed to the files container. The response is correct.\n```\n$ curl -v -H 'Trace: abc' -H 'Host: foobar.asperafiles-dev.com' http://localhost:9999\n Rebuilt URL to: http://localhost:9999/\n   Trying ::1...\n TCP_NODELAY set\n Connected to localhost (::1) port 9999 (#0)\n\nGET / HTTP/1.1\nHost: foobar.asperafiles-dev.com\nUser-Agent: curl/7.54.0\nAccept: /\nTrace: abc\n< HTTP/1.1 200 OK\n< Cache-Control: max-age=0\n< Content-Type: text/html; charset=utf-8\n< Date: Wed, 15 Nov 2017 07:25:22 GMT\n< Etag: W/\"5a0be5a5-691\"\n< Expires: Wed, 15 Nov 2017 07:25:22 GMT\n< Last-Modified: Wed, 15 Nov 2017 06:58:45 GMT\n< Server: nginx\n< Content-Length: 1681\n<\n<!DOCTYPE html>    Aspera Files                angular.module('f4')\n        .constant('API_URL','//api.asperafiles-dev.com/api/v1')\n        .constant('ANALYTICS_FRONTEND_URL', '//analytics.asperafiles-dev.com')\n        .constant('OAUTH_URL','//api.asperafiles-dev.com/api/v1')\n        .constant('OAUTH_CLIENT_ID','f4.com')\n        .constant('CONNECT_URL','//d3gcli72yxqn2z.cloudfront.net/connect/v4')\n        .constant('ORGANIZATION',location.hostname.split('.')[0])\n        .constant('LOGIN_NOTICE','')\n        .constant('IBM_METRIC_URL', '//nebula-cdn.kampyle.com/we/28600/onsite/embed.js')\n        ;    (window.IBM_Meta = {\n          offeringName: 'IBM Aspera Files',\n          language: 'en',\n          offeringId: '5725Y72',\n          quarterlyIntercept: 'light',\n          testData: false,\n          highLevelOfferingName: 'Aspera (SaaS)'\n<em> Connection #0 to host localhost left intact\n        });    % \nAnd now I will try to curl api.asperafiles-dev.com. As you can see, I am still getting routed to the`files` container.\n$ curl -v -H 'Trace: abc' -H 'Host: api.asperafiles-dev.com' http://localhost:9999/api/v1/self\n Rebuilt URL to: http://localhost:9999/\n   Trying ::1...\n TCP_NODELAY set\n Connected to localhost (::1) port 9999 (#0)\nGET / HTTP/1.1\nHost: api.asperafiles-dev.com\nUser-Agent: curl/7.54.0\nAccept: /*\nTrace: abc\n< HTTP/1.1 200 OK\n< Cache-Control: max-age=0\n< Content-Type: text/html; charset=utf-8\n< Date: Wed, 15 Nov 2017 07:18:47 GMT\n< Etag: W/\"5a0be5a5-691\"\n< Expires: Wed, 15 Nov 2017 07:18:47 GMT\n< Last-Modified: Wed, 15 Nov 2017 06:58:45 GMT\n< Server: nginx\n< Content-Length: 1681\n<\n<!DOCTYPE html>    Aspera Files                angular.module('f4')\n        .constant('API_URL','//api.asperafiles-dev.com/api/v1')\n        .constant('ANALYTICS_FRONTEND_URL', '//analytics.asperafiles-dev.com')\n        .constant('OAUTH_URL','//api.asperafiles-dev.com/api/v1')\n        .constant('OAUTH_CLIENT_ID','f4.com')\n        .constant('CONNECT_URL','//d3gcli72yxqn2z.cloudfront.net/connect/v4')\n        .constant('ORGANIZATION',location.hostname.split('.')[0])\n        .constant('LOGIN_NOTICE','')\n        .constant('IBM_METRIC_URL', '//nebula-cdn.kampyle.com/we/28600/onsite/embed.js')\n        ;    (window.IBM_Meta = {\n          offeringName: 'IBM Aspera Files',\n          language: 'en',\n          offeringId: '5725Y72',\n          quarterlyIntercept: 'light',\n          testData: false,\n          highLevelOfferingName: 'Aspera (SaaS)'\n* Connection #0 to host localhost left intact\n        });    \n```. I can confirm that #390 fixes the behavior I was seeing \ud83d\udc4d . +1. \n",
    "pklingem": "I don't see this issue listed in the existing milestones, is this to be included in 1.6 or in a 1.5.x release?  And is there an ETA on that release?. ",
    "orthecreedence": "EDIT: Forgive me, I just found https://github.com/fabiolb/fabio/issues/506, which appears to be this exact issue.\n\nHello, I'm seeing an issue with route precedence in the 1.5.9 release.\nWe have the rules:\nroute add fe-app-stage *.stage.myapp.com/ http://172.27.20.146:22712/\nroute add fe-app-qa *.qa.myapp.com/ http://172.27.10.211:20979/\nroute add fe-app *.myapp.com/ http://172.27.20.123:21445/\nRunning curl 127.0.0.1:9999/ -H'Host: test.qa.myapp.com' -H'Trace: LOL' returns the result from the fe-app route:\n2018/09/04 15:40:57 [TRACE] LOL Tracing test.qa.myapp.com/\n2018/09/04 15:40:57 [TRACE] LOL Match *.myapp.com/\n2018/09/04 15:40:57 [TRACE] LOL Routing to service fe-app on http://172.27.20.123:21445/\n(Same result for test.stage.myapp.com)\nI would expect it to take the longest/most specfic host first, and match the *.qa or *.stage routes before going to *.myapp.com\nIt appears that non-wildcard routes take precedence, but among wildcard routes themselves, there is noe specific precedence. Is there any way to work around this for now without having to use paths? Like any way to use regexes in the hosts so *.myapp.com could be (?!=(stage|qa).*).myapp.com?\nThanks!\n. ",
    "jrasell": "The test failures seem to be sporadic and I do not believe they are related to my changes.. @magiconair would it be possible to get some feedback on this PR? . @magiconair yes that is an option and is what I currently do in my setups. I was merely adding this feature as detailed in the ticket #276 . @leprechau thanks for the reply. The issue I am facing is that the ALB performs the SSL offload which means HTTPS traffic from the ALB appears to Fabio as only HTTP traffic and therefore does not currently allow me to use Fabio to perform the HTTP > HTTPS redirect as traffic gets stuck in a redirect loop. Allowing routes to be configured using the headers such as x-forwarded-port would allow me to resolve this situation be performing redirects based on the header which is added by the ALB and represents the client origin port, rather than the forwarded port.. I don't; AWS ALBs do SSL offloading as standard and this behaviour cannot be changed from what I can see; ALBs do not do HTTP > HTTPS redirects. \nI could use a network load balancer and then use Fabio to do both the SSL offloading and redirection, but this would mean any IP whitelisting (I run services which are only exposed to internal ranges) would happen at the instance level (private subnet) where I prefer this to take place at the LB level (public subnet) thus meaning traffic doesn't get close to the servers.. Exactly. So in my current setup supporting 1 would be excellent although I can indeed update my setup to use an NLB and let fabio do both redirect and SSL offloading if not.. @leprechau thanks for all the work, please close this ticket out as a duplicate if you wish and I can track 448.. @magiconair thanks a lot, that does sort it. Thanks also for the project, I am a big fan of it!. ",
    "sev3ryn": "Hi, I also faced a need for this functionality today.\nBut code in this PR have few issues and is not fully working -  @jrasell  see my comments on File changes tab.\nBTW. @jrasell, if you abandoned this PR - I can pick it to implement changes that @magiconair requested. uppercase words are not parsed by flag library. If you change it to lower case flag will parse it correctly. I mean - registry.consul.enableSSL change to registry.consul.enablessl\nsame for other added parametes\n+ change to lowercase if property file. tls variable is shadowed here. Here should be\ntls = api.TLSConfig{. ",
    "eagle1981": "How about merge to next release? It's blocker feature for our deployment.. Same issue, same config, but return 502\n< HTTP/1.1 502 Bad Gateway\n< Date: Fri, 22 Feb 2019 05:47:22 GMT\n< Content-Length: 0\n. ",
    "KEZHwMlXV1vFzs6QvY8v5WjX5": "this is what I tried using a patch from another issue from @lukas2511\nlooks like the core idea is doing this:\nheader := fmt.Sprintf(\"PROXY TCP4 %s %s %d %d\\r\\n\", source_addr, dest_addr, source_port, dest_port)\n```diff\nFrom 7d4b660a500043aaa01947421253c7ee632ff3a3 Mon Sep 17 00:00:00 2001\nFrom: \"nobody\" does@notmatter.invalid\nDate: Fri, 18 Jan 2019 16:33:37 +0100\nSubject: [PATCH] Added tcp+sni+proxy from https://github.com/lukas2511/fabio\n\nconfig/load.go               |   2 +-\n main.go                      |  13 +++\n proxy/tcp/sni_proxy_proxy.go | 168 +++++++++++++++++++++++++++++++++++\n 3 files changed, 182 insertions(+), 1 deletion(-)\n create mode 100644 proxy/tcp/sni_proxy_proxy.go\ndiff --git a/config/load.go b/config/load.go\nindex 11f9b4d..7241f76 100644\n--- a/config/load.go\n+++ b/config/load.go\n@@ -345,7 +345,7 @@ func parseListen(cfg map[string]string, cs map[string]CertSource, readTimeout, w\n        case \"proto\":\n            l.Proto = v\n            switch l.Proto {\n-           case \"tcp\", \"tcp+sni\", \"http\", \"https\", \"grpc\", \"grpcs\":\n+           case \"tcp\", \"tcp+sni\", \"tcp+sni+proxy\", \"http\", \"https\", \"grpc\", \"grpcs\":\n                // ok\n            default:\n                return Listen{}, fmt.Errorf(\"unknown protocol %q\", v)\ndiff --git a/main.go b/main.go\nindex aa8e02c..8ebdba2 100644\n--- a/main.go\n+++ b/main.go\n@@ -338,6 +338,19 @@ func startServers(cfg config.Config) {\n                    exit.Fatal(\"[FATAL] \", err)\n                }\n            }()\n+       case \"tcp+sni+proxy\":\n+           go func() {\n+               h := &tcp.SNIProxyProxy{\n+                   DialTimeout: cfg.Proxy.DialTimeout,\n+                   Lookup:      lookupHostFn(cfg),\n+                   Conn:        metrics.DefaultRegistry.GetCounter(\"tcp_sni.conn\"),\n+                   ConnFail:    metrics.DefaultRegistry.GetCounter(\"tcp_sni.connfail\"),\n+                   Noroute:     metrics.DefaultRegistry.GetCounter(\"tcp_sni.noroute\"),\n+               }\n+               if err := proxy.ListenAndServeTCP(l, h, tlscfg); err != nil {\n+                   exit.Fatal(\"[FATAL] \", err)\n+               }\n+           }()\n        default:\n            exit.Fatal(\"[FATAL] Invalid protocol \", l.Proto)\n        }\ndiff --git a/proxy/tcp/sni_proxy_proxy.go b/proxy/tcp/sni_proxy_proxy.go\nnew file mode 100644\nindex 0000000..370bb5d\n--- /dev/null\n+++ b/proxy/tcp/sni_proxy_proxy.go\n@@ -0,0 +1,168 @@\n+package tcp\n+\n+import (\n+   \"bufio\"\n+   \"fmt\"\n+   \"io\"\n+   \"log\"\n+   \"net\"\n+   \"time\"\n+\n+   \"github.com/fabiolb/fabio/metrics\"\n+   \"github.com/fabiolb/fabio/route\"\n+)\n+\n+// SNIProxyProxy implements an SNI aware TCP proxy using Proxy protocol\n+// which captures the TLS client hello, extracts the host name and uses it\n+// for finding the upstream server. Then it sends a PROXY Protocol header,\n+// replays the ClientHello message and copies data transparently allowing\n+// to route a TLS connection based on the SNI header without decrypting it.\n+type SNIProxyProxy struct {\n+   // DialTimeout sets the timeout for establishing the outbound\n+   // connection.\n+   DialTimeout time.Duration\n+\n+   // Lookup returns a target host for the given server name.\n+   // The proxy will panic if this value is nil.\n+   Lookup func(host string) route.Target\n+\n+   // Conn counts the number of connections.\n+   Conn metrics.Counter\n+\n+   // ConnFail counts the failed upstream connection attempts.\n+   ConnFail metrics.Counter\n+\n+   // Noroute counts the failed Lookup() calls.\n+   Noroute metrics.Counter\n+}\n+\n+func (p *SNIProxyProxy) ServeTCP(in net.Conn) error {\n+   defer in.Close()\n+\n+   if p.Conn != nil {\n+       p.Conn.Inc(1)\n+   }\n+\n+   tlsReader := bufio.NewReader(in)\n+   tlsHeaders, err := tlsReader.Peek(9)\n+   if err != nil {\n+       log.Print(\"[DEBUG] tcp+sni+proxy: TLS handshake failed (failed to peek data)\")\n+       if p.ConnFail != nil {\n+           p.ConnFail.Inc(1)\n+       }\n+       return err\n+   }\n+\n+   bufferSize, err := clientHelloBufferSize(tlsHeaders)\n+   if err != nil {\n+       log.Printf(\"[DEBUG] tcp+sni+proxy: TLS handshake failed (%s)\", err)\n+       if p.ConnFail != nil {\n+           p.ConnFail.Inc(1)\n+       }\n+       return err\n+   }\n+\n+   data := make([]byte, bufferSize)\n+   , err = io.ReadFull(tlsReader, data)\n+   if err != nil {\n+       log.Printf(\"[DEBUG] tcp+sni+proxy: TLS handshake failed (%s)\", err)\n+       if p.ConnFail != nil {\n+           p.ConnFail.Inc(1)\n+       }\n+       return err\n+   }\n+\n+   // readServerName wants only the handshake message so ignore the first\n+   // 5 bytes which is the TLS record header\n+   host, ok := readServerName(data[5:])\n+   if !ok {\n+       log.Print(\"[DEBUG] tcp+sni+proxy: TLS handshake failed (unable to parse client hello)\")\n+       if p.ConnFail != nil {\n+           p.ConnFail.Inc(1)\n+       }\n+       return nil\n+   }\n+\n+   if host == \"\" {\n+       log.Print(\"[DEBUG] tcp+sni+proxy: server_name missing\")\n+       if p.ConnFail != nil {\n+           p.ConnFail.Inc(1)\n+       }\n+       return nil\n+   }\n+\n+   t := p.Lookup(host)\n+   if t == nil {\n+       if p.Noroute != nil {\n+           p.Noroute.Inc(1)\n+       }\n+       return nil\n+   }\n+   addr := t.URL.Host\n+\n+   if t.AccessDeniedTCP(in) {\n+       return nil\n+   }\n+\n+   out, err := net.DialTimeout(\"tcp\", addr, p.DialTimeout)\n+   if err != nil {\n+       log.Print(\"[WARN] tcp+sni+proxy: cannot connect to upstream \", addr)\n+       if p.ConnFail != nil {\n+           p.ConnFail.Inc(1)\n+       }\n+       return err\n+   }\n+   defer out.Close()\n+\n+   // send PROXY protocol header\n+   source_addr, source_port, err := net.SplitHostPort(in.RemoteAddr().String())\n+   if err != nil {\n+       log.Print(\"[WARN] tcp+sni+proxy: parsing source address has failed. \", err)\n+       return err\n+   }\n+\n+   dest_addr, dest_port, err := net.SplitHostPort(addr)\n+   if err != nil {\n+       log.Print(\"[WARN] tcp+sni+proxy: parsing destination address has failed. \", err)\n+       return err\n+   }\n+\n+   header := fmt.Sprintf(\"PROXY TCP4 %s %s %d %d\\r\\n\", source_addr, dest_addr, source_port, dest_port)\n+   , err = out.Write([]byte(header))\n+   if err != nil {\n+       log.Print(\"[WARN] tcp+sni+proxy: sending PROXY protocol header failed. \", err)\n+       return err\n+   }\n+\n+   // write the data already read from the connection\n+   n, err := out.Write(data)\n+   if err != nil {\n+       log.Print(\"[WARN] tcp+sni+proxy: copy client hello failed. \", err)\n+       if p.ConnFail != nil {\n+           p.ConnFail.Inc(1)\n+       }\n+       return err\n+   }\n+\n+   errc := make(chan error, 2)\n+   cp := func(dst io.Writer, src io.Reader, c metrics.Counter) {\n+       errc <- copyBuffer(dst, src, c)\n+   }\n+\n+   // rx measures the traffic to the upstream server (in <- out)\n+   // tx measures the traffic from the upstream server (out <- in)\n+   rx := metrics.DefaultRegistry.GetCounter(t.TimerName + \".rx\")\n+   tx := metrics.DefaultRegistry.GetCounter(t.TimerName + \".tx\")\n+\n+   // we've received the ClientHello already\n+   rx.Inc(int64(n))\n+\n+   go cp(in, out, rx)\n+   go cp(out, in, tx)\n+   err = <-errc\n+   if err != nil && err != io.EOF {\n+       log.Print(\"[WARN]: tcp+sni+proxy:  \", err)\n+       return err\n+   }\n+   return nil\n+}\n-- \n2.20.1\n```\nunfortunately the nginx ingress controller we used does not seem to understand what fabio sends him. A test using haproxy with send-proxy option was working.. ok this could be it\ndiff\n-       header := fmt.Sprintf(\"PROXY TCP4 %s %s %d %d\\r\\n\", source_addr, dest_addr, source_port, dest_port)\n+       header := fmt.Sprintf(\"PROXY TCP4 %s %s %s %s\\r\\n\", source_addr, dest_addr, source_port, dest_port)\nworks for me now.. yes outbound PROXY protocol would be really great!. yes proxy.addr=:443;proto=tcp+sni was set in the fabio.properties. And during startup fabio also states it's using tcp+sni on port 443.\nWhat do you mean by standard source and destination?. ok understood. But does this help regarding the wildcard in the src of the route?. yep it does not even arrive at that part of the code. From what I can see it already stops here\nhttps://github.com/fabiolb/fabio/blob/faf228d1529f1b59a9d33e6c9cd42e365a937fe1/route/access_rules.go#L77\nand in my case IP is nil and the allow opts is correctly set in the map\nip is already nil within AccessDeniedTCP while c.RemoteAddr().String() in that function is the public client IP:SourcePort\nis it okay to feed https://golang.org/pkg/net/#ParseIP with an IP:PORT combo instead of only an IP?\n-> no it's not ok. We might want something like this (found at https://stackoverflow.com/a/41602018)\ngo\nif addr, ok := conn.RemoteAddr().(*net.TCPAddr); ok {\n    fmt.Println(addr.IP.String())\n}. ok when I change the function to this it works for me.\n```diff\ndiff --git a/route/access_rules.go b/route/access_rules.go\nindex 3901042..b3ce639 100644\n--- a/route/access_rules.go\n+++ b/route/access_rules.go\n@@ -64,7 +64,8 @@ func (t Target) AccessDeniedHTTP(r http.Request) bool {\n// AccessDeniedTCP checks rules on the target for TCP proxy routes.\n func (t Target) AccessDeniedTCP(c net.Conn) bool {\n-       ip := net.ParseIP(c.RemoteAddr().String())\n+        addr := c.RemoteAddr().(net.TCPAddr)\n+        ip := net.ParseIP(addr.IP.String())\n        if t.denyByIP(ip) {\n                return true\n        }\n```. positive. It passed my checks.. ",
    "beyondkmp": "When fabio generate three routes through consul, but the network is broken between a route and fabio's host. Fabio still send some requests to the route until meeting http proxy timeout error. How can I deal with this situation?. You can implement it like nginx, add max_failed params. Then when fabio failed about max_failed times , delete or the route.. @leprechau I have the same problem with you. Now I write a python script to check that the network is ok. If not, I will delete this route through my script(route del command).. ",
    "jcomeaux": "Just wanted to chime in here that this would be a very important feature for our environment; we really like the ability to frequently replace our ec2 infrastructure on a rolling basis.  Right now, we have a management type VPC in which the consul servers live, but the machines were fabio runs are on our \"staging\" and \"production\" app servers.  We see regular issues when we're doing rolling replacement of our \"management\" VPC ec2 instances, thus knocking out consul, and, concurrently, we're doing rolling replacements of either \"staging\" or \"production\" app servers.  Since fabio's sole knowledge of node up/down status comes from consul, if the consul connection is interrupted AND one of the \"neighbor\" machines is also down, fabio cheerfully continues to route traffic to a downed instance.\nMaybe this would be such a big deal if I knew how to make traffic coming into fabio only get passed to the upstream endpoint running on the same host as fabio...but I don't know how to do that \ud83d\ude04 \nInstead, our traffic flows are ALB -> fabio_listener -> one-of-several app servers that are members of the relevant consul service.  So, yeah, consul goes away, and app server \"B\" is being switched out...traffic coming into fabio on app server \"C\" or \"A\" will get routed to \"B\" 33% of the time.. This looks great Frank! This certainly addresses our situation of a Consul that may \"go away\" with concurrent proxy outages, but also handles spurious network disconnections between the monitor and proxies.  \nWould it make sense to have the ok/fail thresholds configurable for the monitor?  Also, I'm assuming \"once a breaker becomes ready again\" means that we've gotten updated information from Consul?. ",
    "pjebs": "I have a program in a docker container that listens to udp. It would be nice if it could match nginx. Just a joke. As fast as possible is nice. . Not expecting nginx performance in immediate future. I would like to respectfully ask if there was any progress on this issue (L4 UDP)?. ",
    "kelvinji2009": "UDP proxy support is good for IoT. :) . ",
    "Verdoso": "As for use cases, I just came up with one. I'm planning on sending logs from my apps to logstash using GELF, and it uses UDP. Having Fabio in front of the Logstash cluster so I don't lose the logs while doing some maintentance or due to one node going down would be nice \ud83d\udc4d . Good to know, LordFPL. I'd rather not add another element to the mix, but if I have to, it's nice to see there are alternatives. But yeah, it doesn't seem to be very active, so I'll keep an eye on it just in case.\nBut if we had this and the GELF logger (PR 246), Fabio would be sending its logs through itself, hehehe.. Yes, I guess the balancing part is just using the consul stated to decide if one server should be sent or not packets. UDP being as it is, I doubt other proxies are doing more than that.\nThat could be enough. I'm checking also if going the tcp route would be performant enough.. Maybe one routing table would work if there was another level with the protocol (if specified)?. ",
    "LordFPL": "For information, i have a similary use case... and found this : http://gobetween.io/\nIt's just work... stable since one month... but not very active project.. ",
    "joshuaclausen": "This would be a really interesting solution for video game servers, especially with the ACLs we can set on remote IPs.  Being able to update in realtime which remote IPs should be permitted to even talk into a gameserver instance UDP port would be useful.  I'd seriously consider running all gameserver traffic through a Fabio instance running locally on a host.\nAnother use case is sending telemetry to statsd relays/servers (over UDP 8125, for instance).  Being able to provide high availability for those would make me sleep better at night ;). I realize this is a closed issue, but I figured I'd ask about wildcards in other places in a hostname:\nservices-live.example.com\n *services-*-north-america.example.com\nI tried briefly with services-live*.example.com, but it didn't seem to work, so it seemed worth asking on the subject.. ",
    "RiRa12621": "i put a ticket on our internal board to get some time for this so that either @sielaq or me can work on this an bring a pull request. ",
    "urosgruber": "Ok, let me try to do something I had in mind and you can decide if it's ok.. ",
    "ethicalmohit": "Thanks Frank for your reply. \nRight now, I have not registering service to the consul. Registrator is does that automatically. As you run the registrator on Amazon ECS cluster, It picks up the task running in there and add them up in consul. Is there any other way to do that? Or Anyway to ask regiatrator to append tags while registering services? . @magiconair Hey, Thanks, man. Is there any way to pass the -tag parameter with the docker run?. @leprechau It just needs a -tag parameter while running the registrator, as mentioned by @magiconair . I will just run the docker command as mentioned in the registrator docs. I am not creating the docker file for registrator. Do you want me to create a Dockerfile with the \"-tag\" parameter? \nDocker run command for registrator:\ndocker run -d \\\n    --name=registrator \\\n    --net=host \\\n    --volume=/var/run/docker.sock:/tmp/docker.sock \\\n    gliderlabs/registrator:latest \\\n      consul://localhost:8500\n. @magiconair No, Thanks a lot.. ",
    "k1ng87": "I'm a bit confused on that then...so if I configure the tag like this tags = [\"urlprefix-/\"]...shouldn't I get the same error then?\nthis is the case on all nomad jobs too....for example...on another job if I tag it like this, tags = [\"urlprefix-/\"]...that works when I go to this link: http://nomad-clients-dev-e.aws-dqa.cb.com/jolokia/search/kafka.consumer\nbut if I tag it like this: tags = [\"urlprefix-/logstashjmx\"]...and then go to this link: http://nomad-clients-dev-e.aws-dqa.cb.com/logstashjmx/jolokia/search/kafka.consumer...I get this 404 error:\n```\n404 Not Found\nNo context found for request\n```\nall the health checks in consul are up and running and in my fabio routes I do see this:\n| Service | Source | Dest | Options | Weight\n1 | logstashparser | /logstashjmx | http://10.46.41.38:29936/ | \u00a0 | 2.22%\n. ",
    "talksinmath": "I'm running into the same problem.\nI have jobs deployed via nomad and can only reach the exact path exposed viaurl-prefix .\nE.g., I have a restheart running (exposes rest-interface to mongodb).\nRoute via fabio:\nrestheart | /restheart | http://127.0.0.1:25200/ -- | -- | --\nWhen trying to access restheart via fabio, only / is reachable. The UI that is running under /browser is unreachable.\nMaybe I'm making a beginners mistake, but any help is greatly appreciated.. ",
    "GastroGee": "i have this same problem as well. I have a grafana service running with this configuration\nservice {\n        name = \"grafana\"\n        port = \"http\"\n        tags = [\"urlprefix-/\"]\n        check {\n          name     = \"Grafana HTTP\"\n          type     = \"http\"\n          path     = \"/api/health\"\n          interval = \"5s\"\n          timeout  = \"2s\"\n           check_restart {\n            limit = 2\n            grace = \"60s\"\n            ignore_warnings = false\n          }\n        }\n      }\nas soon as i change it to \nservice {\n        name = \"grafana\"\n        port = \"http\"\n        tags = [\"urlprefix-/grafana\"]\n        check {\n          name     = \"Grafana HTTP\"\n          type     = \"http\"\n          path     = \"/api/health\"\n          interval = \"5s\"\n          timeout  = \"2s\"\n           check_restart {\n            limit = 2\n            grace = \"60s\"\n            ignore_warnings = false\n          }\n        }\n      }\ni am not able to reach the service. ",
    "sksegha": "it still does not work with the tag you provided @leprechau \nHowever i think the problem might be with the grafana configuration itself. \nThanks . @leprechau this actually worked, the problem was with the local service (grafana) that i had running in the cluster. As soon as i updated the root_url config in grafana to reveal the path (https://{server}:{port}/grafana); the service came up with no issues. ",
    "targeting": "Is there any fix available for this issue?. ",
    "slackpad": "This issue (https://github.com/hashicorp/consul/pull/3642) fixed in 1.0.2 could cause a lot of extra churn for services with tags.. Consul internally for deciding whether to return an instance in a DNS query will AND all the service-level check statuses as well as the node-level ones, so if any are failing it is taken out of service.. ",
    "fsuste": "@magiconair is there any documentation on configuring Fabio to use Vault PKI interface?. Thank you! Didn't really dig in the properties file.. ",
    "rurounijones": "A way that I can assign a bounty to a feature would be really good. Something like https://www.bountysource.com/ maybe? It would allow people to contribute to bounties for features that they care about. ( https://salt.bountysource.com/ also has a monthly contribution setup like open-collective)\n  . ",
    "inmchfw": "oh.. just figured it out. it should be in nomad job spec.. ",
    "craigday": "Thank's Frank. What's the best way or format to capture the routing table? The table doesn't actually change very often, and AFAIK, the table as it is now will be the same as when the failure starts to occur.. Yep. Have sent you the routing table just now.. This hit us again this morning. Is there any further info we can provide? Can you enumerate any possible theories or code paths that might be suspect, so we can help with the analysis?. @atillamas FYI we believe we know what is causing this issue. Websocket requests that fail upgrade are left open and connected to their original back end. Nnginx out front is pooling these and sending requests straight through to this backend, completely bypassing the Fabio routing. Our workaround, for now, was to isolate the websocket onto an isolated fabio cluster. \nI believe Fabio should be detecting these failed upgrades and closing the connections.. ",
    "atillamas": "Got hit by this as well running fabio 1.5.7\nRequests to all our services started to get routed intermittent to our hash-ui service. Causing lots of weirdness. Stopping/Purging the hashi-ui service and starting it again made the problem dissapear for now.. @leprechau Hi. thanks for the suggestion, unfortunately i get a redirect loop using that example. @leprechau \nIn fabio UI:\n26 | http-redirect | some.domain.example.com:80/ | https://some.domain.example.com$path | redirect=301 | 100.00% |\nAnd a curl:\n```\ncurl -iL some.domain.example.com\nHTTP/1.1 301 Moved Permanently                  \nDate: Thu, 22 Feb 2018 16:39:26 GMT\nContent-Type: text/html; charset=utf-8\nContent-Length: 65\nConnection: keep-alive\nLocation: https://some.domain.example.com/\nHTTP/2 301 \ndate: Thu, 22 Feb 2018 16:39:26 GMT\ncontent-type: text/html; charset=utf-8\ncontent-length: 65\nlocation: https://some.domain.example.com/\nHTTP/2 301 \ndate: Thu, 22 Feb 2018 16:39:26 GMT\ncontent-type: text/html; charset=utf-8\ncontent-length: 65\nlocation: https://some.domain.example.com/\nHTTP/2 301 \ndate: Thu, 22 Feb 2018 16:39:26 GMT\ncontent-type: text/html; charset=utf-8\ncontent-length: 65\nlocation: https://some.domain.example.com/\n\ncurl: (47) Maximum (50) redirects followed\nIf i remove the redirect accessing both http and https://some.domain.example.com works fine.. @leprechau yes that is correct, silly me missed the curl :)\nAnyway\nIn the ui i type in this:\n`route add http-redirect go.staging.budbee.com:80 https://go.staging.budbee.com$path opts \"redirect=301\"`\nbut it shows the trailing slash when i look at the rules. \nThe mixed HTTP/1.1 and HTTP/2 redirecets could be that it's two services listening, one is listening on the original go.staging.budbee.com and one is listening on go.staging.budbee.com/api\n.\ncurl --http1.1 --max-redirs 3 -vL go.staging.budbee.com\n Rebuilt URL to: go.staging.budbee.com/\n   Trying 54.229.60.69...\n TCP_NODELAY set\n Connected to go.staging.budbee.com (54.229.60.69) port 80 (#0)\n\nGET / HTTP/1.1\nHost: go.staging.budbee.com\nUser-Agent: curl/7.53.1\nAccept: /\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 17:37:32 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 65\n< Connection: keep-alive\n< Location: https://go.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #0 to host go.staging.budbee.com left intact\n Issue another request to this URL: 'https://go.staging.budbee.com/'\n   Trying 34.250.238.214...\n TCP_NODELAY set\n Connected to go.staging.budbee.com (34.250.238.214) port 443 (#1)\n Initializing NSS with certpath: sql:/etc/pki/nssdb\n   CAfile: none\n  CApath: none\n loaded libnssckbi.so\n ALPN, server accepted to use http/1.1\n SSL connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\n Server certificate:\n   subject: CN=budbee.com\n   start date: May 17 00:00:00 2017 GMT\n   expire date: Jun 17 12:00:00 2018 GMT\n   common name: budbee.com\n   issuer: CN=Amazon,OU=Server CA 1B,O=Amazon,C=US\nGET / HTTP/1.1\nHost: go.staging.budbee.com\nUser-Agent: curl/7.53.1\nAccept: /*\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 17:37:32 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 65\n< Connection: keep-alive\n< Location: https://go.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host go.staging.budbee.com left intact\n Issue another request to this URL: 'https://go.staging.budbee.com/'\n Found bundle for host go.staging.budbee.com: 0x55c7b23436c0 [can pipeline]\n Re-using existing connection! (#1) with host go.staging.budbee.com\n Connected to go.staging.budbee.com (34.250.238.214) port 443 (#1)\nGET / HTTP/1.1\nHost: go.staging.budbee.com\nUser-Agent: curl/7.53.1\nAccept: /\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 17:37:32 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 65\n< Connection: keep-alive\n< Location: https://go.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host go.staging.budbee.com left intact\n Issue another request to this URL: 'https://go.staging.budbee.com/'\n Found bundle for host go.staging.budbee.com: 0x55c7b23436c0 [can pipeline]\n Re-using existing connection! (#1) with host go.staging.budbee.com\n Connected to go.staging.budbee.com (34.250.238.214) port 443 (#1)\nGET / HTTP/1.1\nHost: go.staging.budbee.com\nUser-Agent: curl/7.53.1\nAccept: /\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 17:37:32 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 65\n< Connection: keep-alive\n< Location: https://go.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host go.staging.budbee.com left intact\n* Maximum (3) redirects followed\ncurl: (47) Maximum (3) redirects followed\n```. They are running behind an ALB in different docker-containers, 2 with go.staging.budbee.com and 2 with go.staging.budbee.com/api and the configuration is identical. Only different is the random listening port they get allocated.. @magiconair Sure thing, i created a completely new stack, exact copy of our staging, just running one single job, exactly the same behaviour\n\n```\njob \"http-echo\" {\n    datacenters = [\"eu-west-1\"]\n    group \"service\" {\n        count = 2\n    constraint {\n        operator = \"distinct_hosts\"\n        value = \"true\"\n    }\n        update {\n                max_parallel = 1\n                min_healthy_time = \"30s\"\n                healthy_deadline = \"5m\"\n        }\n        task \"http-echo\" {\n            driver = \"docker\"\n            config {\n                image = \"hashicorp/http-echo\"\n                port_map {\n                        echo = 5678\n                }\n                args  = [\"-text\", \" version4: ${node.unique.name}\"]\n            }\n            service {\n                name = \"http-echo\"\n                tags = [\"http-echo\",\"urlprefix-echo.staging.budbee.com/\"]\n                port = \"echo\"\n                check {\n                    type     = \"http\"\n                    path     = \"/\"\n                    interval = \"5s\"\n                    timeout  = \"2s\"\n                    port     = \"echo\"\n                }\n            }\n            resources {\n                cpu = 500\n                network {\n                    port \"echo\" { }\n                }\n            }\n        }\n    }\n```\nubuntu@ip-10-0-62-158:~$ curl localhost:9998/api/routes?raw\nroute add http-redirect echo.staging.budbee.com:80/ https://echo.staging.budbee.com$path opts \"redirect=301\"\nroute add http-echo echo.staging.budbee.com/ http://10.0.62.158:26296/ tags \"http-echo\"\nroute add http-echo echo.staging.budbee.com/ http://10.0.61.154:23384/ tags \"http-echo\"\n```\ncurl --http1.1 --max-redirs 3 -vL echo.staging.budbee.com\n Rebuilt URL to: echo.staging.budbee.com/\n   Trying 52.30.193.125...\n TCP_NODELAY set\n Connected to echo.staging.budbee.com (52.30.193.125) port 80 (#0)\n\nGET / HTTP/1.1\nHost: echo.staging.budbee.com\nUser-Agent: curl/7.55.1\nAccept: /\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 20:36:58 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 67\n< Connection: keep-alive\n< Location: https://echo.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #0 to host echo.staging.budbee.com left intact\n Issue another request to this URL: 'https://echo.staging.budbee.com/'\n   Trying 52.30.193.125...\n TCP_NODELAY set\n Connected to echo.staging.budbee.com (52.30.193.125) port 443 (#1)\n ALPN, offering http/1.1\n Cipher selection: PROFILE=SYSTEM\n successfully set certificate verify locations:\n   CAfile: /etc/pki/tls/certs/ca-bundle.crt\n  CApath: none\n TLSv1.2 (OUT), TLS handshake, Client hello (1):\n TLSv1.2 (IN), TLS handshake, Server hello (2):\n TLSv1.2 (IN), TLS handshake, Certificate (11):\n TLSv1.2 (IN), TLS handshake, Server key exchange (12):\n TLSv1.2 (IN), TLS handshake, Server finished (14):\n TLSv1.2 (OUT), TLS handshake, Client key exchange (16):\n TLSv1.2 (OUT), TLS change cipher, Client hello (1):\n TLSv1.2 (OUT), TLS handshake, Finished (20):\n TLSv1.2 (IN), TLS handshake, Finished (20):\n SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256\n ALPN, server accepted to use http/1.1\n Server certificate:\n  subject: CN=budbee.com\n  start date: May 17 00:00:00 2017 GMT\n  expire date: Jun 17 12:00:00 2018 GMT\n  subjectAltName: host \"echo.staging.budbee.com\" matched cert's \".staging.budbee.com\"\n  issuer: C=US; O=Amazon; OU=Server CA 1B; CN=Amazon\n  SSL certificate verify ok.\nGET / HTTP/1.1\nHost: echo.staging.budbee.com\nUser-Agent: curl/7.55.1\nAccept: /*\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 20:36:58 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 67\n< Connection: keep-alive\n< Location: https://echo.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host echo.staging.budbee.com left intact\n Issue another request to this URL: 'https://echo.staging.budbee.com/'\n Found bundle for host echo.staging.budbee.com: 0x55795ae5a090 [can pipeline]\n Re-using existing connection! (#1) with host echo.staging.budbee.com\n Connected to echo.staging.budbee.com (52.30.193.125) port 443 (#1)\nGET / HTTP/1.1\nHost: echo.staging.budbee.com\nUser-Agent: curl/7.55.1\nAccept: /\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 20:36:58 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 67\n< Connection: keep-alive\n< Location: https://echo.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host echo.staging.budbee.com left intact\n Issue another request to this URL: 'https://echo.staging.budbee.com/'\n Found bundle for host echo.staging.budbee.com: 0x55795ae5a090 [can pipeline]\n Re-using existing connection! (#1) with host echo.staging.budbee.com\n Connected to echo.staging.budbee.com (52.30.193.125) port 443 (#1)\nGET / HTTP/1.1\nHost: echo.staging.budbee.com\nUser-Agent: curl/7.55.1\nAccept: /\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 20:36:58 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 67\n< Connection: keep-alive\n< Location: https://echo.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host echo.staging.budbee.com left intact\n Maximum (3) redirects followed\ncurl: (47) Maximum (3) redirects followed\n.\nubuntu@ip-10-0-62-158:~$ curl localhost:9998/api/routes?raw\nroute add http-redirect echo.staging.budbee.com:80/ https://echo.staging.budbee.com$path opts \"redirect=301\"\nroute add http-echo / http://10.0.62.158:26296/ tags \"http-echo\"\nroute add http-echo / http://10.0.61.154:23384/ tags \"http-echo\"\n\ntags = [\"http-echo\",\"urlprefix-/\"]\n\n curl --http1.1 --max-redirs 3 -vL echo.staging.budbee.com\n Rebuilt URL to: echo.staging.budbee.com/\n   Trying 52.19.94.85...\n TCP_NODELAY set\n Connected to echo.staging.budbee.com (52.19.94.85) port 80 (#0)\nGET / HTTP/1.1\nHost: echo.staging.budbee.com\nUser-Agent: curl/7.55.1\nAccept: /*\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 20:54:37 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 67\n< Connection: keep-alive\n< Location: https://echo.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #0 to host echo.staging.budbee.com left intact\n Issue another request to this URL: 'https://echo.staging.budbee.com/'\n   Trying 52.19.94.85...\n TCP_NODELAY set\n Connected to echo.staging.budbee.com (52.19.94.85) port 443 (#1)\n ALPN, offering http/1.1\n Cipher selection: PROFILE=SYSTEM\n successfully set certificate verify locations:\n   CAfile: /etc/pki/tls/certs/ca-bundle.crt\n  CApath: none\n TLSv1.2 (OUT), TLS handshake, Client hello (1):\n TLSv1.2 (IN), TLS handshake, Server hello (2):\n TLSv1.2 (IN), TLS handshake, Certificate (11):\n TLSv1.2 (IN), TLS handshake, Server key exchange (12):\n TLSv1.2 (IN), TLS handshake, Server finished (14):\n TLSv1.2 (OUT), TLS handshake, Client key exchange (16):\n TLSv1.2 (OUT), TLS change cipher, Client hello (1):\n TLSv1.2 (OUT), TLS handshake, Finished (20):\n TLSv1.2 (IN), TLS handshake, Finished (20):\n SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256\n ALPN, server accepted to use http/1.1\n Server certificate:\n  subject: CN=budbee.com\n  start date: May 17 00:00:00 2017 GMT\n  expire date: Jun 17 12:00:00 2018 GMT\n  subjectAltName: host \"echo.staging.budbee.com\" matched cert's \".staging.budbee.com\"\n  issuer: C=US; O=Amazon; OU=Server CA 1B; CN=Amazon\n  SSL certificate verify ok.\nGET / HTTP/1.1\nHost: echo.staging.budbee.com\nUser-Agent: curl/7.55.1\nAccept: /*\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 20:54:37 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 67\n< Connection: keep-alive\n< Location: https://echo.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host echo.staging.budbee.com left intact\n Issue another request to this URL: 'https://echo.staging.budbee.com/'\n Found bundle for host echo.staging.budbee.com: 0x55c9cb3c4090 [can pipeline]\n Re-using existing connection! (#1) with host echo.staging.budbee.com\n Connected to echo.staging.budbee.com (52.19.94.85) port 443 (#1)\nGET / HTTP/1.1\nHost: echo.staging.budbee.com\nUser-Agent: curl/7.55.1\nAccept: /\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 20:54:37 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 67\n< Connection: keep-alive\n< Location: https://echo.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host echo.staging.budbee.com left intact\n Issue another request to this URL: 'https://echo.staging.budbee.com/'\n Found bundle for host echo.staging.budbee.com: 0x55c9cb3c4090 [can pipeline]\n Re-using existing connection! (#1) with host echo.staging.budbee.com\n Connected to echo.staging.budbee.com (52.19.94.85) port 443 (#1)\nGET / HTTP/1.1\nHost: echo.staging.budbee.com\nUser-Agent: curl/7.55.1\nAccept: /\n< HTTP/1.1 301 Moved Permanently\n< Date: Thu, 22 Feb 2018 20:54:38 GMT\n< Content-Type: text/html; charset=utf-8\n< Content-Length: 67\n< Connection: keep-alive\n< Location: https://echo.staging.budbee.com/\n< \n Ignoring the response-body\n Connection #1 to host echo.staging.budbee.com left intact\n* Maximum (3) redirects followed\ncurl: (47) Maximum (3) redirects followed\n```\n. Yes the ALB (Application Load Balancer) is in-front of Fabio and terminating the SSL. I'm starting to believe that this is the issue also, i bet a normal Network Loadbalancer would work, i choosed the ALB to quickly get a way to be able to control access to our \"internal\" public exposed services with WAF, I now see that Fabio has support for IP-restriction so i might try to migrate it over to a Network Load Balancer instead.\n\nHaven't been able to test it without going through the loadbalancer in an easy way. If I run a curl with host header behind the loadbalancer the first request goes directly to Fabio, but then the next request go through the LB and into the redirect loop.... @leprechau it appears so.\ntcpdump of the headers\n```\nHEAD / HTTP/1.1\nX-Forwarded-For: 178.132.77.232\nX-Forwarded-Proto: http\nX-Forwarded-Port: 80\nHost: echo.staging.budbee.com\nX-Amzn-Trace-Id: Root=1-5a951fae-4604c7d214c51fcc8dea3620\nUser-Agent: curl/7.55.1\nAccept: /\nHTTP/1.1 301 Moved Permanently\nContent-Type: text/html; charset=utf-8\nLocation: https://echo.staging.budbee.com/\nDate: Tue, 27 Feb 2018 09:06:54 GMT\nHEAD / HTTP/1.1\nX-Forwarded-For: 178.132.77.232\nX-Forwarded-Proto: https\nX-Forwarded-Port: 443\nHost: echo.staging.budbee.com\nX-Amzn-Trace-Id: Root=1-5a951fae-a95257c2eb57be56fd699d02\nuser-agent: curl/7.55.1\naccept: /\nHTTP/1.1 301 Moved Permanently\nContent-Type: text/html; charset=utf-8\nLocation: https://echo.staging.budbee.com/\nDate: Tue, 27 Feb 2018 09:06:54 GMT\nHEAD / HTTP/1.1\nX-Forwarded-For: 178.132.77.232\nX-Forwarded-Proto: https\nX-Forwarded-Port: 443\nHost: echo.staging.budbee.com\nX-Amzn-Trace-Id: Root=1-5a951fae-3295da6666d938b6b009b2ae\nuser-agent: curl/7.55.1\naccept: /\n``\n. This code fixes the redirect problem for me but introduces the problem that i don't get any content at all :) \nI wanted to put the if-statement together on this line: https://github.com/fabiolb/fabio/blob/master/proxy/http_proxy.go#L101\nbut just couldn't get it to work with:if t.RedirectCode != 0 && (strings.HasPrefix(t.GetRedirectURL(requestURL).String(), \"https://\") && r.Header.Get(\"X-Forwarded-Port\") != \"443\") {`\nSomething with the logic is off, but i don't understand what. Maybe you can take a quick look?\n```\ngit diff proxy/http_proxy.go \ndiff --git a/proxy/http_proxy.go b/proxy/http_proxy.go\nindex 0898d7a..3778409 100644\n--- a/proxy/http_proxy.go\n+++ b/proxy/http_proxy.go\n@@ -100,7 +100,9 @@ func (p HTTPProxy) ServeHTTP(w http.ResponseWriter, r http.Request) {\n    if t.RedirectCode != 0 {\n            redirectURL := t.GetRedirectURL(requestURL)\n\n\nhttp.Redirect(w, r, redirectURL.String(), t.RedirectCode)\nif strings.HasPrefix(redirectURL.String(), \"https://\") && r.Header.Get(\"X-Forwarded-Port\") != \"443\" {\nhttp.Redirect(w, r, redirectURL.String(), t.RedirectCode)\n}\n. @leprechau Thanks for the suggestion, Unfortunately I get the redirect loop when implementing the code there, I'll see if i can find some time during the weekend to troubleshoot some more.\n. @leprechau No worries at all, I'm grateful for all your help!\nUnfortunately I haven't had time doing anything more with this, but I will when I get time, although it would probably be a lot faster if someone with  knowledge dug in instead :). @leprechau Thanks for this. I got it to work with  your patch if i removed this check:\ntarget.URL.Hostname() == req.URL.Hostname() && target.URL.Path == req.URL.Path\nthis is the content of all the variables when doing a request (values inside ' '):\ntarget.RedirectCode '301', target.URL.Scheme 'https', req.Header.Get(\"X-Forwarded-Proto\"): 'https', target.URL.Hostname(): 'echo.staging.budbee.com', req.URL.Hostname(): '', target.URL.Path: '', req.URL.Path: '/'\n```\n\nand this is the config used:\ntags = [\"http-echo\",\"urlprefix-echo.staging.budbee.com:80/  redirect=301,https://echo.staging.budbee.com\",\"urlprefix-/\"]\ncurl localhost:9998/api/routes?raw\nroute add http-echo echo.staging.budbee.com:80/ https://echo.staging.budbee.com tags \"http-echo\" opts \"redirect=301\"\nroute add http-echo / http://10.0.62.211:29790/ tags \"http-echo\". @leprechau this is the content of the entire req object:\n'&{GET / HTTP/1.1 1 1 map[User-Agent:[curl/7.55.1] Accept:[*/*] X-Forwarded-For:[178.132.77.196] X-Forwarded-Proto:[https] X-Forwarded-Port:[443] X-Amzn-Trace-Id:[Root=1-5aaafeb6-9b7eaa7054e311c6f394c52c]] {} <nil> 0 [] false echo.staging.budbee.com map[] map[] <nil> map[] 10.0.62.195:19938 / <nil> <nil> <nil> 0xc420333900}'\nLooks like it should be:\nreq.Host\nand it works with:\nif target.RedirectCode != 0 && target.URL.Scheme == req.Header.Get(\"X-Forwarded-Proto\") && target.URL.Hostname() == req.Host {. @leprechau Nice work. Almost there now :)\nJust one tiny problem: the matching of the target.RedirectURL.Path == req.URL.Path does not work. Without it everything seems to be working fine.\nLooks like target.RedirectURL.Path is empty. @leprechau Yes if i add the trailing / in the redirect redirect=301,https://echo.staging.budbee.com/ everything works!. @leprechau forgot to say that it worked  with $path previously also, But now I've tested your latest change and it does work as it should! :+1:  great job! Thanks!\nEverything seems to work exactly as it should!. @leprechau Hi. Thank you for the info. But using 1.5.8 i can still access a rule that has allow=ip:10.0.0.0/16,ip:X.X.X.X and then using curl -H 'X-Forwarded-For: X.X.X.X' hostname  or even any of the 10.0.0.0/16 adresses give me access where ip from the curl host is something completely different. Should i just close this PR and open an Issue ticket? . @leprechau Ok, i think I've found the problem.. Apparently AWS decides to append the ip of the client to the end of the XFF list (this is for classic loadbalancer but it seems to apply to Application Loadbalancer also: https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html), so if i do:\ncurl -H 'X-Forwarded-For: 87.9.15.28' host\nprinting xff variable give me this:\n87.9.15.28, 80.13.7.2\nis the X-Forwardeded for header set by curl\nand 80.13.7.2 is the ip of the client doing the curl\nThe culprit is here:\nhttps://github.com/fabiolb/fabio/blob/master/route/access_rules.go#L39-L40\n. @leprechau No, since it's the rightmost value that is the true client IP, I can manipulate the leftmost value with the curl -H 'X-Forwarded-For: whateveripiwant'\nand whateveripiwant will be the leftmost value and then fabio will let it pass, even though it should be blocked...\nThis is in AWS behind a LB. Well if \"tricking\" it with just adding a Header with an allowed IP is the only thing needed to bypass it i wouldn't consider it secure at all.\nIf this indeed is the intended behaviour I'll continue to stick with WAF.. Yes, that's what i've been saying all along. Wasn't very clear maybe but here is the post again:\n@leprechau Hi. Thank you for the info. But using 1.5.8 i can still access a rule that has allow=ip:10.0.0.0/16,ip:X.X.X.X and then using curl -H 'X-Forwarded-For: X.X.X.X' hostname or even any of the 10.0.0.0/16 adresses give me access where ip from the curl host is something completely different. Should i just close this PR and open an Issue ticket?. > Right, that bit of code should be correct. The leftmost element of the field should be the client.\nhttps://en.wikipedia.org/wiki/X-Forwarded-For#Format\nWell i guess AWS doesn't follow the standard then:\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html\n\nIf a request from a client already contains an X-Forwarded-For header, Elastic Load Balancing appends the IP address of the client at the end of the header value. In this case, the last IP address in the list is the IP address of the client. For example, the following header contains two IP addresses added by the client, which might not be trustworthy, plus the client IP address added by Elastic Load Balancing:\nX-Forwarded-For: ip-address-1, ip-address-2, client-ip-address\n. job \"http-echo\" {\n    datacenters = [\"eu-west-1\"]\n    group \"service\" {\n        count = 1\n        constraint {\n                operator = \"distinct_hosts\"\n                value = \"true\"\n        }\n        update {\n                max_parallel = 1\n                min_healthy_time = \"30s\"\n                healthy_deadline = \"5m\"\n        }\n        task \"http-echo\" {\n            driver = \"docker\"\n            config {\n                image = \"hashicorp/http-echo\"\n                port_map {\n                        echo = 5678\n                }\n                args  = [\"-text\", \" version4: ${node.unique.name}\"]\n            }\n            service {\n                name = \"http-echo\"\n                tags = [\"http-echo\",\"urlprefix-/ allow=ip:67.209.115.14,ip:10.0.0.0/8\"]\n                port = \"echo\"\n                check {\n                    type     = \"http\"\n                    path     = \"/\"\n                    interval = \"5s\"\n                    timeout  = \"2s\"\n                    port     = \"echo\"\n                }\n            }\n            resources {\n                cpu = 500\n                network {\n                    port \"echo\" { }\n                }\n            }\n        }\n    }\n}\nfrom  a client with ip 178.132.77.232\ncurl echo.staging.budbee.com\naccess denied\n\nfrom  a client with ip 178.132.77.232\ncurl -H 'X-Forwarded-For: 67.209.115.14' echo.staging.budbee.com\nversion4: ip-10-0-60-99\nPrinting the xff variable for debugging gives me:\nxff = 67.209.115.14, 178.132.77.232\nand here fabio takes xff[0] as allowed, when AWS clearly states that this is untrusted and that it is xff[-1] that is the ip from the true client...\n. > XFF header semantics aside ... what is the IP of the ALB that sits before fabio? What does fabio see as the \"source\" of that connection?\nThe Loadbalancer connects from random ips from the subnets specified for the clients. for example \n10.0.60.132\n10.0.61.12\nHere's some tcpdumps on port 9999 on the fabio client with the request headers:\nFrom 67.209.115.14\ncurl echo.staging.budbee.com\n```\nGET / HTTP/1.1\nX-Forwarded-For: 67.209.115.14\nX-Forwarded-Proto: http\nX-Forwarded-Port: 80\nHost: echo.staging.budbee.com\nX-Amzn-Trace-Id: Root=1-5a946e06-bde747b0116cf72811e9e6a2\nUser-Agent: curl/7.29.0\nAccept: /\nHTTP/1.1 200 OK\nContent-Length: 25\nContent-Type: text/plain; charset=utf-8\nDate: Mon, 26 Feb 2018 20:28:54 GMT\nX-App-Name: http-echo\nX-App-Version: 0.2.3\nFrom 178.132.77.232\n`curl -H 'X-Forwarded-For: 67.209.115.14' echo.staging.budbee.com`\nGET / HTTP/1.1\nX-Forwarded-For: 67.209.115.14, 178.132.77.232\nX-Forwarded-Proto: http\nX-Forwarded-Port: 80\nHost: echo.staging.budbee.com\nX-Amzn-Trace-Id: Root=1-5a946e22-f9626e80398045b8c1ae4376\nUser-Agent: curl/7.55.1\nAccept: /\nHTTP/1.1 200 OK\nContent-Length: 25\nContent-Type: text/plain; charset=utf-8\nDate: Mon, 26 Feb 2018 20:29:22 GMT\nX-App-Name: http-echo\nX-App-Version: 0.2.3\nFrom 178.132.77.232\n`curl echo.staging.budbee.com`\nGET / HTTP/1.1\nX-Forwarded-For: 178.132.77.232\nX-Forwarded-Proto: http\nX-Forwarded-Port: 80\nHost: echo.staging.budbee.com\nX-Amzn-Trace-Id: Root=1-5a946e29-a4a8610d9e7ac71d926d84f2\nUser-Agent: curl/7.55.1\nAccept: /\nHTTP/1.1 403 Forbidden\nContent-Type: text/plain; charset=utf-8\nX-Content-Type-Options: nosniff\nDate: Mon, 26 Feb 2018 20:29:29 GMT\nContent-Length: 14\n```\nIt would probably be easiest to just check if there is a X-Amzn-Trace-Id Header present, and if so, use the rightmost XFF header, (even though I've understood that you don't want to do this). But it would make this whole thing work.\nCome to think about it, that wouldn't work. since it then would be possible to just add the header on a non-aws host, and manipulate what XFF headers it would read.. >  It's not about a want ... it's about actually enforcing the given ruleset.\n\nWe could add some odd if header Z then look at this part of the XFF else look at somewhere else ... but that's just adding more layers of obfuscation and not actually preventing the actual problem when you have another proxy in-front of fabio.\nThe problem being: in the current implementation when you have another proxy before fabio you are open to arbitrary bypass of the access list by simply sending the right XFF header.\n\nI just don't get it. We can trust the headers given by AWS Loadbalancers, atleast the LAST ENTRY it will be appended by AWS and will always be the client IP connecting to the loadbalancer, it is to be trusted as the source of the connection and cannot be manipulated. As long as you trust AWS you can trust that value.\n\n@atillamas the other option may be to validate ALL components of the XFF instead of just an arbitrary first or last element. In the case of an allow rule all parts of the XFF plus the actual remote address would have to match for the request to be passed onto the backend. Similarly for a deny rule if any part of the XFF or the actual remote address matched the request would be denied.\nI think this would be acceptable. Thoughts?\n\nYes this would work for our usecase  atleast. But as soon as someone needs to actually use XFF headers it will become a problem i would assume?. >I know that in this particular instance it\u2019s the last element. But the last element just means the client to the proxy before fabio. I don\u2019t want to assume that there will never be a case where there is more than one hop before fabio. This wouldn\u2019t be a good design but I can\u2019t really control what others deploy.\nIsn't that how it's supposed to work? That's how firewall rules work. You take the source ip and base the rules of that. Is it allowed, is it denied.\nAnyways. Don't feel like it's any point in discussing this further.\nThanks for taking the time with this.\nShould i just close this PR?. @leprechau \nYes I'm happy with it.\nThanks for your effort.\nClosing this. ",
    "johnjolet": "no, not having a limit is not a blocker.  having a limit i can't modify would be.  Thanks!. ",
    "DanSipola": "Thanks for the review! I will have a look at it and get it fixed.. All valid comments. Thanks for that! I hope that I got it right. I'm not used to the github flow so let me know if I should change something.. ",
    "saravanakumar-periyasamy": "yes, I am planning to work on this. \nHere's a quickstart on how to do it in golang. http://opentracing.io/documentation/pages/quick-start#go. ",
    "galen0624": "@magiconair  - A team and I have been working on this request.  We have a working demo and are in the process of load testing.  Would you still be interested in seeing a PR?  Our OpenTrace Support currently is for a ZipKin collector.  Jaeger could easily be added at a later date.. Sounds good.  We should have something ready in the next few days. Load testing today showed about a 1 millisecond of added  latency sampling 100% of traffic. (10,000 RPS)\nI would like to say we are not developers by trade so the govendor and other git components are a little new to us.   I'm not sure how to add each vendor package individually yet.\nOn a side note we have incorporated BGP into each of the Fabio boxes in order to provide HA.  BGP announces the \"VIPs\" into the underlying network Fabric.   If you are interested we can chat further about the details.. Our setup for HA is to also use Quagga on our Fabio VMs then have the BGPD and Fabio processes dependent on each other through systemD.  We announce /32 or host routes into our Spine/Leaf Fabric which allows for ECMP (Equal Cost MultiPath).  We have the timers set in BGP to re-converge quickly.  This enables us to support A/B data center constructs.  We will also have Fabio baked into an Image so we can destroy/recreate new Fabio instances at will.  . @leprechau  have you looked at Calico?  -- https://www.projectcalico.org/ \nWe are currently investigating how that fits with Containers and routable POD IPs.. @magiconair Any thoughts on this PR?  Should we continue to work on this or should we go in a different direction?. @magiconair I rebase lined this PR with the current 1.5.10 release.. We disabled Metrics and let Fabio run for 24 hours.  The memory consumption was level.. I agree with #476 being pushed up.  I think it's slated for 1.6.  We would rather see the raw metrics instead of rolled up ones.  I was looking into rcrowley/go-metrics and my colleague and I are thinking it's related to the churn of node health.  We have over 1200 services registered in Consul so the node health is always updating.  Meaning the blocking query from Fabio to Consul is sort of pointless in our ENV because the Index is always being updated.  This leads to the metric sets being updated constantly.  We are wondering if the go-metrics doesn't clean up the old sets if a node health refreshes.\nTo put it another way -- If a node health flaps and the Metrics package doesn't reuse the old data set for that node it might be keeping those stale records.  In our ENV that would create a lot of stale data and would explain the memory leak.\n. I vendored in the latest from rcrowley/go-metrics and turned metrics back on.   I'll watch the memory consumption over the next day and update the issue with findings.  I'll PR my fork/branch if it looks good and Fabio performs as expected.\n{\"path\":\"github.com/rcrowley/go-metrics\",\"checksumSHA1\":\"an5RM8wjgPPloolUUYkvEncbHu4=\",\"revision\":\"e2704e165165ec55d062f5919b4b29494e9fa790\",\"revisionTime\":\"2018-05-03T17:46:38Z\"},. After Vendoring in the latest go-metrics it appears that the memory leak is still persistent.  Digging further into the issue the NewMeter() function is consuming most of the memory.  github.com/rcrowley/go-metrics/meter.go \nThe \"constructor\" function has a new comment stipulating that Stop() should be called once the meter isn't needed any more.  -- see below.\n// NewMeter constructs a new StandardMeter and launches a goroutine.\n// Be sure to call Stop() once the meter is of no use to allow for garbage collection.\nfunc NewMeter() Meter {\n-- SNIP\n    m := newStandardMeter()\n-- SNIP\n}\nLooking through the Fabio Code I don't see where the Metrics Stop() func is called.  If Stop isn't called then our assumption about route/node health churn might hold true based on the comments in the NewMeter function.\nI'm wondering if that can be added to the func (t Table) delRoute(d *RouteDef) error {} in route/table.go?  I haven't dug enough into the metrics code to see where it potentially would be added. . Digging further it looks like the rcrowley/go-metrics Registry Interface has been updated in the lastest release with new method signatures.     So metrics/gometrics.go gmRegistry struct methods will have to be updated.  \nOne of the new method signatures GetOrRegister(string, interface{}) interface{} Can return a Meter Interface that has the Stop() func that I believe should be used.    I'm a little new to GoLang so I can take a shot at this but I'm looking for confirmation that I'm heading down the right path.. I was totally wrong on updating the gmRegistry struct as that implements the fabio Metrics Registry not the rcwroley/go-metrics Registry.  \nLooks like the appropriate spot to do this is in route/table.go func syncRegistry(t Table) {}\nJust before the ServiceRegistry.Unregister(name)   . So it already does that but I don't see where the Stop() func is called in the Unregister function.  So my guess is that the data set is still hanging around and not being allowed to be GCed.\n// Be sure to call Stop() once the meter is of no use to allow for garbage collection.\nWe may have to add it in addition to the Unregister..  Again I was wrong with my previous statement.  Unregister eventually does call a Stop() func so I'm not sure what's wrong.  I did update the code with \nmetrics/registry.go\n// Timer defines a metric for counting and timing durations for events.\ntype Timer interface {\n    // Stop allows the metrics to be garbage collected.\n    Stop()\n}\nAnd route/table.go \n```\nfunc syncRegistry(t Table) {\n--SNIP\n// unregister inactive timers\nfor name, active := range timers {\n    if !active {\n        t := ServiceRegistry.GetTimer(name)\n        t.Stop()\n        ServiceRegistry.Unregister(name)\n        log.Printf(\"[INFO] Unregistered timer %s\", name)\n    }\n}\n\n}\n```\nI redeployed it in the lab to see if this has any impact.  I'll update tomorrow if it does.\n. I realized earlier today that I had a mistake in my GOPATH.  I am currently re-testing the updated github.com/rcrowley/go-metrics package.  After a few hours things look promising.  I will update tomorrow with a definitive answer.  If all goes well I will generate a PR.  . After a roughly 24 hour run it looks like the Memory Leak is fixed by vendoring in the lastest from github.com/rcrowley/go-metrics.  Below is an example graph. I'll submit a PR later today.\n\n. No worries.  Glad to help.. #530 . PR530-Make-Test.txt\nLet me know if I need to fix any of those tests.. So something like below?  I know the code wont work as is but just an example.\n```\nvar NormalizedPatternGlobs []glob.Glob\n// matchingHosts returns all keys (host name patterns) from the\n// routing table which match the normalized request hostname.\nfunc (t Table) matchingHosts(req *http.Request) (hosts []string) {\n    host := normalizeHost(req.Host, req.TLS != nil)\n    for pattern := range t {\n        normpat := normalizeHost(pattern, req.TLS != nil)\n                compiledGlobMatch(\n                 if g.Match(host) {\n            hosts = append(hosts, pattern)\n        }\n    }\n--SNIP\n}\nfunc compiledGlobMatch(pattern string) glob.Glob {\n            for i, v := range NormalizedPatternGlobs {\n                 //Not sure exactly how to do the comparison \n                 if pattern == v {\n                    return v\n                 } else {\n                   //not exactly sure the compile command yet\n                  g:=glob.Compile(pattern)\n                  //Memory leak here with no clean up\n                  NormalizedPatternGlobs = append(NormalizedPatternGlobs, g)\n                }\n}\n}\n```. OK let me see what we can do over the next few days.  At this point we have to fix our ENV.  We are planning on moving to the previous package and redeploying.  We will work on compiled globs and submit a PR after that.  Also looks like Fabio moved to gomod.  Have you had any issues with the experimental package?  \nTo answer your other question -- Yes I think as routes get added the table should be updated.  That makes the most sense.  Also cleanup when a route is removed gets rid of the memory leak potential.. FYI - After migrating to the previous glob package the performance issue disappeared.  CPU usage with 4k TPS was around 30-40% with an 8 core VM.   We will monitor over the next few days and then start working on an update to handle this situation in a more performant way.. @leprechau @murphymj25 \nUpdate - After working through our requirements we decided that Glob matching isn't required for our configuration.  I have updated Fabio to include a config item glob.matching.enabled (default true) so we have the option to disable it and use standard string compare.  This will provide the best performance for our config.  We are currently load testing with/without GLOB matching and will update this Issue with the results.  I will submit the PR with the changes once I get the Go Tests updated either today or early next week.. attached is the make test for this.\nPR-550.txt\n. I added a separate func with the latest commit for the globMatching disabled.  Below is the recent load test we performed.\n8Core, 8G VM,  4K TPS for each test.  The first test was with glob.matching.disabled = false.  We only could get to about 1200TPS and 90% CPU usage.  The second test glob.matching.disabled = true shows the full 4K TPS and about 20% CPU usage.\n\n. Sounds good.  I'll update and commit this afternoon.   Also I have started testing the Glob Cache and we are running into performance issues.  I would like to collaborate under a different branch/issue if you don't mind.  . It doesn't appear that the compiled globs helped the CPU issue all that much.  My testing details are below.    I'm going to run a CPU Profile at high load and post the details. \nLoad test on an 8core 8G VM.  \nSep 20 21:46:49  fabio: \"GlobMatchingDisabled\": true,\nSep 20 21:46:49  fabio: \"GlobCacheSize\": 5000\nTest 1 - 10K TPS 37% CPU\nSep 20 21:51:26 fabio: \"GlobMatchingDisabled\": false,\nSep 20 21:51:26 fabio: \"GlobCacheSize\": 5000\nTest 2 - 2K TPS 30% CPU\nTest 3 - 3K TPS 38% CPU\nTest 4 - 4K TPS 98% CPU (TPS didn't exceed 3.7K)\nTest 5 - 10K TPS 98% CPU (TPS didn't exceed 4.0K)\n\n. We have about 1500 Services in this ENV.\nglob.cache.size = 5000\nprofile.mode = cpu\nprofile.path = /tmp\n5K TPS Test\nBased on the CPU profile (See below)  it looks like the RLock and RUnlock are taking most of the CPU.  I'm not sure how to avoid using those without creating race conditions and panics.\nAnother func we could look at is the stings.ToLower but that is tertiary to the Mutex locks\ncpu1.pdf\n. I will PR the current code to double check my logic.. Is this something we could look into - https://golang.org/doc/go1.9#sync-map\n. If we moved the compiled glob cache add/remove functions to the Route add/del functions using the Mutex locks we in theory should be able to remove the fast path lookup mutex Rlock/UNlock.     That way we move the CPU intensive part (Rlock/RUnlock) to the \"control plane\" side of Fabio instead of the \"data plane\" . \nThoughts?\n. Working through the previous comment I found that the read lock is still needed.  There is another option sync.Map.  \nhttps://medium.com/@deckarep/the-new-kid-in-town-gos-sync-map-de24a6bf7c2c\nGoing to try and test that other method.\n. @leprechau How have you dealt with the sync.Map.Load() returning an interface{}.  I tried to type cast the return to a glob.Glob but the system panics.\nI probably am not going about this the correct way.\n```func (c *GlobCache) Get(pattern string) (glob.Glob, error) {\n    // fast path with read lock\n    //c.mu.RLock()\n    g, _ := c.m.Load(pattern)\n    gr := g.(glob.Glob)\n//c.mu.RUnlock()\nif gr != nil {\n    return gr, nil\n}\n\n`` interface conversion: interface is nil, not glob.Glob`\n. OK I tested using the sync.Map and it seems to be much better.  I was able to achieve 6500 TPS.  At 7000 TPS it would start dropping connections.  The below test went from 1k,2k,3k,4k,5k,6k,7, 6.5k TPS.  8 core 8 gig fabio VM\n\"GlobMatchingDisabled\": false,\n\"GlobCacheSize\": 5000\nSee graph.  I'll PR the new code for review.\n\n. @leprechau I could use some advice on how to handle some type assertions.  The Glob is an interface and there are 21 types that implement the interface. When the glob compiles it returns that type but the sync.Map returns the interface{}.  I have to find a way to assert to the specific type.  I could put in a switch statement with the 21 types but that seems inefficient.   Is there a way to cast the type at return?  something like this return glb.(reflect.TypeOf(glb))   That snippet doesn't work BTW.. #555 This code is complete, load tested, make test passes and ready for merge.\n. @leprechau @magiconair Any thoughts on this PR?  Should I update/change anything?. #554 The use of sync.Map increased the performance from 3500 TPS to 6500 TPS.\nThe glob_cache_test file needs refactoring as you have to use sync.Map.Range and there is no ability to get the len of a sync.Map currently. #554 Updated glob_cache to support all types that implement the glob.Glob Interfaces.  Make test now passes all checks.. #554  Updated to remove type switch and assert type to glob.Glob interface.. We are not using this in prod.  We don't use GLOB matching.  That being said we have tested it.  -- https://github.com/fabiolb/fabio/issues/554#issuecomment-425276410\nI will rebase line and PR.. rebased this PR.. Closing and recreating with new PR #615 . Closing with #564 . @magiconair Thank you for refactoring.  I'll test the update sometime tomorrow.  I added in the new custom HTTP Client due to a requirement on our side.  I built a stand alone application that sits on the same VMs as Fabio.  It acts like a Consul server to Fabio.  On the back end it aggregates service information from two seperate Consul Environments.  This allows us to provide data center failover in the event that all services go down in a single data center.  It run similar logic to Fabio for \"Passing\" services and based on some business logic will present the services information to Fabio that we want.  \nHaving both Fabio and the \"Shim\" running on the same host I ran into issues with TIME_WAIT connections filling up the local ports.  Adding in MaxIdleConnsPerHost and MaxIdleConns to the custom Transport fixed that issue.. No it shouldn't.  I apologize I neglected to remove it before the PR.. @magiconair  OK I tested the update and it behaved as expected.  I observed a 5-10% CPU increase using registry.consul.serviceMonitors = 100 on an 8 Core box.  Memory was not impacted that I could tell.   \nI was also thinking about the issue with the custom http.Transport.  If the consul backend is consistent (meaning same URL/Host) the TIME_WAIT issue will still be something to solve regardless if Fabio is talking to localhost or a remote consul.  The MaxIdleConnsPerHost is per host.  During out testing today I observed around 25K TIME_WAIT connections with roughly 2000 services. \nBelow is somewhat of an explanation on the settings.  \nhttp://tleyden.github.io/blog/2016/11/21/tuning-the-go-http-client-library-for-load-testing/\n. With 2000 + services there is always changes.  The Consul blocking query is irrelevant in our ENV because of that.   I instituted a configurable query timer in the \"Shim\" instead.  It acts like a blocking query to Fabio.  The expectation is that route updates in Fabio happen within the query timer interval.  Without concurrent service updates each Fabio was taking 20+ seconds to run through all of the services.   Additionally we have sized our Consul ENV to support the amount of queries that we are sending from the FabioShims.  \nI'll continue testinging with various registry.consul.serviceMonitors and see where it breaks down.. After testing it seems that registry.consul.serviceMonitors = 16 is the sweet spot for meeting our current query interval.  . Also I have updated and tested your issue-558 branch with the new custom http.Transport if you want me to PR it back.. I have one through KeyBase.  Will that work?  If not I'll get another one setup tonight.. @leprechau Can you elaborate on the V1.3.0?  Is that Consul?  \nAre you talking about the Agent Cache described below for /catalog/service/my-serivce\nhttps://www.consul.io/api/catalog.html\nand \nhttps://www.consul.io/api/index.html#agent-caching\n. I was thinking about this further.  Blocking queries might be an option per service query with a low amount of services.  One open connection per service.  Also the Background refresh cache opens a blocking query from the local agent.  This would produce the same effect as a direct call from Fabio leaving a connection per service open from the fabio host to Consul.\nAdditionally I spoke with the Consul team here and the are not concerned about the Requests per Second coming from Fabio.  Currently we have 8 (4 per data center) Fabio instances per ENV.  Each Fabio instance is generating around 2K requests every 2 seconds.   At our current load they have no concerns.  Lastly there are other clients to consul besides Fabio. . @magiconair @leprechau I started the updates for polling intervals.  Not 100% complete yet but a starting point.  I'm not sure if you want me to submit a PR or commit to the issue-558 branch?  The interval only affects the Services updates.  KV and noroute.html are still using blocking queries. The code can be found here for now.\nhttps://github.com/galen0624/fabio/tree/issue-558\n. @magiconair No objections on Merging #564.  We have been using it in production for the last few weeks.  I will be updating the other request and submitting an update based on your feedback.. I will.. Code for your review - https://github.com/fabiolb/fabio/tree/issue-611-custom-backend\n. make test file for your review \nissue-611-make-test.txt\n. After further testing the dedup isn't an issue as we had our 50K routes installed incorrectly.  The dedub was crawling those as if it was a single service.  Once we have the proper data being ingested the table load times are subsecond for 50K routes.  Just for fun the table load took  2 seconds for 170K routes and 20 seconds for 1.7M routes.  \ud83d\ude04 . @magiconair @leprechau Any thoughts on this idea/PR?  Any improvements/changes we can make? \n We most likely will move forward internally with this approach but would like to stay as close to the public master branch as possible.  . No worries.  I know everyone is crazy busy.  . If you remove that line from the go.sum file it should compile.  . @magiconair @leprechau Would either of you be able to grant me access to - continuous-integration/codeship ?  I see that the builds are failing for our recent PRs and I would like to dig into why.  I'm assuming its a go mod issue but I'll need access to confirm.   Also please add @murphymj25 if possible.  Thank you.. @magiconair @leprechau any chance I could be added to the codeship site to debug the build issues?  I assume it's related to the go mod/sum.  Below is a make test output that shows it working.\nissue-623-make-test.txt\n. I think they are similar but we do not use URI matching.  Just Host Matching.  We are looking for this feature to avoid using Globs at all and use straight string matching on the host. . We are not looking to use Globs at all in the short term but we can spend some time testing this code and adding to a future PR to hedge against our requirements changing in the future.  . This makes sense I'll update.  The tests will still have to be updated to support passing config.Config into the Lookup func in main.go\nreturn &proxy.HTTPProxy{\n        Config:            cfg.Proxy,\n        Transport:         newTransport(nil),\n        InsecureTransport: newTransport(&tls.Config{InsecureSkipVerify: true}),\n        Lookup: func(r *http.Request) *route.Target {\n            t := route.GetTable().Lookup(r, r.Header.Get(\"trace\"), pick, match, cfg)\n--SNIP\n. Would it make more sense to add/delete the compiled glob at route add/route del?\nNot sure what kind of performance impact that would have.  Especially in our kind of ENV where we have with 1500+ services all adding/deleting routes constantly. . Not passing the config.Config down into the route package would require doubling up the public Lookup func as well as the matchingHosts func as that is where the glob is compiled.  If we keep the config being passed in we can apply the logic directly in the matchingHosts.   This would keep a single Lookup func and a single matchingHosts func.  Also we could add in some additional tests/bench_marks to test with/without glob matching.  That would also help with future comparisons of compiled globs/non-compiled globs/non-globs.    \nI could also just set a local var and pass that along to the funcs to apply the logic but that would still require updated tests. \nThoughts?. Not needed.  I'll update.. ",
    "james-xiang": "Hi magiconair,\nI am currently evaluating fabio with gRPC load balancing support.  I could not figure it out how the routing table works for the gRPC endpoints. Is this feature ready or when it will be added ?\nThanks a lot.. ",
    "phedoreanu": "Hi @magiconair, I'm trying to get this PR to work, but one of your repos is private?\n```\ndep init failed: unable to solve the dependency graph: Solving failure: no valid source could be created:\n    failed to set up sources from the following URLs:\nhttps://github.com/magiconair/go-metrics-statsd\n: remote repository at https://github.com/magiconair/go-metrics-statsd does not exist, or is inaccessible: ERROR: Repository not found.\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights\nand the repository exists.\n: exit status 128\n```\nCan you please make it public? Or repalce it with github.com/pubnub/go-metrics-statsd?\nThanks!. Sure, but it's still private.\n$ curl -D-  https://github.com/magiconair/go-metrics-statsd                                                             HTTP/1.1 404 Not Found\nServer: GitHub.com\nDate: Wed, 11 Apr 2018 12:52:53 GMT\nContent-Type: text/plain; charset=utf-8\nTransfer-Encoding: chunked\nStatus: 404 Not Found. Because I switched to dep - https://github.com/golang/dep.. Do you have a good reason why?. I'm sorry, but I don't agree with you.\n\ndep is the official experiment, but not yet the official tool.\n\nAnd it has 3.63x the number of contributors than govendor. 149 (dep) vs 41 (govendor).\nAlso last dep commit was 5 days ago, as opposed to govendor which was on the 9th of Feb.. Of course, feel free to decline the PR with dep, but at least be open to new proposals.\nAlready by running dep init it highlighted the problem that one dependency (go-metrics-statsd) isn't available (like all the others are), but it's manually hardcoded inside vendor/.. How are you not dependent on external repositories?! \ud83d\ude06 \n$ cat vendor/vendor.json\n{\"path\":\"github.com/armon/go-proxyproto\",\"checksumSHA1\":\"eAall4ACaMG40mzSJ5Oc95GiF1A=\",\"revision\":\"609d6338d3a76ec26ac3fe7045a164d9a58436e7\",\"revisionTime\":\"2015-02-06T18:58:55-08:00\"},\n{\"path\":\"github.com/circonus-labs/circonus-gometrics\",\"checksumSHA1\":\"ZAdLZ0e/hin4AXxdS9F8y0yi/bg=\",\"revision\":\"f8c68ed96a065c10344dcaf802f608781fc0a981\",\"revisionTime\":\"2016-08-30T16:47:25Z\"},\n...\n{\"path\":\"github.com/cyberdelia/go-metrics-graphite\",\"checksumSHA1\":\"8/Q1JbAHUmL4sDURLq6yron4K/I=\",\"revision\":\"b8345b7f01d571b05366d5791a034d872f1bb36f\",\"revisionTime\":\"2015-08-25T20:22:00-07:00\"},\n{\"path\":\"github.com/fatih/structs\",\"checksumSHA1\":\"zKLQNNEpgfrJOwVrDDyBMYEIx/w=\",\"revision\":\"5ada2f449b108d87dbd8c1e60c32cdd065c27886\",\"revisionTime\":\"2016-06-01T09:31:17Z\"},\n{\"path\":\"github.com/gobwas/glob\",\"checksumSHA1\":\"/RE0VzeaXdaBUNeNMUXWqzly7qY=\",\"revision\":\"19c076cdf202b3d1c0489bdfa2f2f289f634474b\",\"revisionTime\":\"2018-02-08T21:18:42Z\"},\n...\n{\"path\":\"github.com/hashicorp/consul/api\",\"checksumSHA1\":\"GsJ84gKbQno8KbojhVTgSVWNues=\",\"revision\":\"402636ff2db998edef392ac6d59210d2170b3ebf\",\"revisionTime\":\"2017-04-05T04:22:14Z\",\"version\":\"v0.8.0\",\"versionExact\":\"v0.8.0\"},\n{\"path\":\"github.com/hashicorp/errwrap\",\"checksumSHA1\":\"cdOCt0Yb+hdErz8NAQqayxPmRsY=\",\"revision\":\"7554cd9344cec97297fa6649b055a8c98c2a1e55\",\"revisionTime\":\"2014-10-27T22:47:10-07:00\"},\n{\"path\":\"github.com/hashicorp/go-cleanhttp\",\"checksumSHA1\":\"Uzyon2091lmwacNsl1hCytjhHtg=\",\"revision\":\"ad28ea4487f05916463e2423a55166280e8254b5\",\"revisionTime\":\"2016-04-07T17:41:26Z\"},\n...\n{\"path\":\"github.com/hashicorp/vault/api\",\"checksumSHA1\":\"9/RHDTjqflfK3/f2Tfvwx+82I40=\",\"revision\":\"f627c01df8d7bebb403cf899ca1beb24f5fc84cd\",\"revisionTime\":\"2016-06-14T07:51:08Z\",\"version\":\"v0.6.0\",\"versionExact\":\"v0.6.0\"},\n{\"path\":\"github.com/magiconair/go-metrics-statsd\",\"checksumSHA1\":\"1I3MjrGSOw5rPtlrHcGI8bJfLyA=\",\"revision\":\"380638b554e36fe109711b41e09917d94b235e86\",\"revisionTime\":\"2017-01-25T16:17:32Z\"},\n...\n{\"path\":\"github.com/mitchellh/go-homedir\",\"checksumSHA1\":\"AXacfEchaUqT5RGmPmMXsOWRhv8=\",\"revision\":\"1111e456ffea841564ac0fa5f69c26ef44dafec9\",\"revisionTime\":\"2016-06-06T03:01:22Z\"},\n...\n{\"path\":\"github.com/pascaldekloe/goe/verify\",\"checksumSHA1\":\"4tr8yNUt5DB8GXc5y+uq6J7TJ54=\",\"revision\":\"f99183613f483cd9b8c79359d572836e243e0763\",\"revisionTime\":\"2015-07-19T21:56:08+02:00\"},\n{\"path\":\"github.com/pkg/profile\",\"checksumSHA1\":\"C3yiSMdTQxSY3xqKJzMV9T+KnIc=\",\"revision\":\"5b67d428864e92711fcbd2f8629456121a56d91f\",\"revisionTime\":\"2017-05-09T09:25:25Z\"},\n{\"path\":\"github.com/rcrowley/go-metrics\",\"checksumSHA1\":\"ODTWX4h8f+DW3oWZFT0yTmfHzdg=\",\"revision\":\"3e5e593311103d49927c8d2b0fd93ccdfe4a525c\",\"revisionTime\":\"2015-07-19T09:56:14-07:00\"},\n{\"path\":\"github.com/rogpeppe/fastuuid\",\"checksumSHA1\":\"ehRkDJisGCCSYdNgyvs1gSywSPE=\",\"revision\":\"6724a57986aff9bff1a1770e9347036def7c89f6\",\"revisionTime\":\"2015-01-06T09:31:45Z\"},\n{\"path\":\"github.com/sergi/go-diff/diffmatchpatch\",\"checksumSHA1\":\"iWCtyR1TkJ22Bi/ygzfKDvOQdQY=\",\"revision\":\"24e2351369ec4949b2ed0dc5c477afdd4c4034e8\",\"revisionTime\":\"2017-01-18T13:12:30Z\"},\n{\"path\":\"golang.org/x/net/http2\",\"checksumSHA1\":\"N1akwAdrHVfPPrsFOhG2ouP21VA=\",\"revision\":\"f2499483f923065a842d38eb4c7f1927e6fc6e6d\",\"revisionTime\":\"2017-01-14T04:22:49Z\"},\n{\"path\":\"golang.org/x/net/http2/hpack\",\"checksumSHA1\":\"HzuGD7AwgC0p1az1WAQnEFnEk98=\",\"revision\":\"f2499483f923065a842d38eb4c7f1927e6fc6e6d\",\"revisionTime\":\"2017-01-14T04:22:49Z\"},\n{\"path\":\"golang.org/x/net/idna\",\"checksumSHA1\":\"GIGmSrYACByf5JDIP9ByBZksY80=\",\"revision\":\"f2499483f923065a842d38eb4c7f1927e6fc6e6d\",\"revisionTime\":\"2017-01-14T04:22:49Z\"},\n{\"path\":\"golang.org/x/net/lex/httplex\",\"checksumSHA1\":\"3xyuaSNmClqG4YWC7g0isQIbUTc=\",\"revision\":\"f2499483f923065a842d38eb4c7f1927e6fc6e6d\",\"revisionTime\":\"2017-01-14T04:22:49Z\"},\n{\"path\":\"golang.org/x/net/websocket\",\"checksumSHA1\":\"xvuVB+aMh4udpinGsmtK31pcWC0=\",\"revision\":\"9946ad7d5eae91d8edca4f54d1a1e130a052e823\",\"revisionTime\":\"2015-10-20T22:50:55Z\"},\n{\"path\":\"golang.org/x/sync/singleflight\",\"checksumSHA1\":\"VhUZFUuhLFSBFUfskMC4am5RIdc=\",\"revision\":\"8e0aa688b654ef28caa72506fa5ec8dba9fc7690\",\"revisionTime\":\"2017-07-19T03:38:01Z\"}\n...\nAre they all owned by you? \ud83d\ude15 . After adding the missing dependencies, now I get:\ngithub.com/test/fabio/vendor/github.com/circonus-labs/circonus-gometrics/api\nvendor/github.com/circonus-labs/circonus-gometrics/api/account.go:150:46: undefined: SearchFilterType\nvendor/github.com/circonus-labs/circonus-gometrics/api/acknowledgement.go:155:87: undefined: SearchFilterType\nvendor/github.com/circonus-labs/circonus-gometrics/api/alert.go:96:77: undefined: SearchFilterType\nvendor/github.com/circonus-labs/circonus-gometrics/api/annotation.go:188:82: undefined: SearchFilterType\nvendor/github.com/circonus-labs/circonus-gometrics/api/checkbundle.go:13:6: CheckBundleConfig redeclared in this block\n    previous declaration at vendor/github.com/circonus-labs/circonus-gometrics/api/check_bundle.go:33:6\nvendor/github.com/circonus-labs/circonus-gometrics/api/checkbundle.go:20:6: CheckBundleMetric redeclared in this block\n    previous declaration at vendor/github.com/circonus-labs/circonus-gometrics/api/check_bundle.go:20:6\nvendor/github.com/circonus-labs/circonus-gometrics/api/checkbundle.go:28:6: CheckBundle redeclared in this block\n    previous declaration at vendor/github.com/circonus-labs/circonus-gometrics/api/check_bundle.go:36:6\nvendor/github.com/circonus-labs/circonus-gometrics/api/checkbundle.go:89:6: (*API).CreateCheckBundle redeclared in this block\n    previous declaration at vendor/github.com/circonus-labs/circonus-gometrics/api/check_bundle.go:156:6\nvendor/github.com/circonus-labs/circonus-gometrics/api/checkbundle.go:89:6: method redeclared: API.CreateCheckBundle\n    method(*API) func(*CheckBundle) (*CheckBundle, error)\n    method(*API) func(CheckBundle) (*CheckBundle, error)\nvendor/github.com/circonus-labs/circonus-gometrics/api/checkbundle.go:110:6: (*API).UpdateCheckBundle redeclared in this block\n    previous declaration at vendor/github.com/circonus-labs/circonus-gometrics/api/check_bundle.go:118:6\nvendor/github.com/circonus-labs/circonus-gometrics/api/checkbundle.go:110:6: too many errors\nmake: *** [build] Error 2. ",
    "vincenthuynh": "Thanks for the feedback! Yes, reverting to v1.5.6 fixes this!. ",
    "microadam": "Good to know is relatively easy! I wouldn't have thought they would change TOO often. Being easily updatable is always nice though. Possibly another urlprefix- option?. The proposed approach definitely fulfils my use case! @leprechau awesome that you are working on this!. On an implementation point, it would probably need to look at any x-forwarded-for headers, in case of upstream proxys. I will see if I can give it a go! Not a go developer, but will give compiling it a shot. @leprechau yeah that would definitely work! Hitting lots of errors trying to compile (probably just me not knowing how to do it!). Perfect!. Have managed to compile it! will try and test it out. I assume I must be doing something wrong, but with options of allow=172.14.0.0/12 and accessing it from an address of 192.168.0.x, I don't get denied, which is what I was expecting\nI am on Mac OSX running fabio on a Vagrant box, so there are a few networks to contend with. No joy with the deny all either. I can only assume I have compiled it wrong. Perhaps if you could provide a binary after all?\nSteps to compile were:\ngit clone git@github.com:myENA/fabio.git\ngit checkout feature/route-acl\ngo get ./...\nmake linux\nI assume something in there is not quite right! (first time actually trying to compile a GO project...). Think I have it compiled correctly now. Getting this error:\n[ERROR] failed to process access rules: invalid access item, expected <type>:<data>, got [0.0.0.0/0]\nMy urlprefix looks like: urlprefix-my-site.com/ deny=0.0.0.0/0\nEDIT: Im a muppet, should have been deny=ip:0.0.0.0/0 my bad! Will get back to you once I have run some tests, apologies for the newbie questions :). Finally got around to doing some tests, apologies for the delay!\nA few things I have spotted, some are possibly edge cases and not worth worrying about (possibly all).\n\n\nwith deny=ip:0.0.0.0/0 I can still access it from localhost. Request comes through like:\n[::1] - - [14/Feb/2018:20:38:10 +0000] \"GET / HTTP/1.1\" 200 68744\n\n\nIf it put in allow=ip:192.168.0.252 I correctly get:\n[ERROR] failed to process access rules: failed to parse CIDR ip:192.168.0.252 with error: invalid CIDR address: 192.168.0.252\nHowever it then defaults to allowing all traffic through. As we don't have any concept of \"validation\" before the server runs, perhaps this should prevent the server from running, or at least, if its an allow rule, it should block EVERYTHING, at least you then know something is wrong? Not sure how to handle the case of where its a deny rule though, as you wouldn't want to default to ALLOWING everything as you wouldn't know there was an issue. Just trying to think of the case where this is all automated and people aren't paying attention to the logs.\n\n\nSeems to work in all the other trivial tests I have done! I haven't managed to test it behind another proxy yet, as I don't have that easily setup, but from the looks of the code it should handle that!\nThanks a lot for doing this :). Sure. That all makes sense. \nJust trying to think if there is a way to make it really obvious that it has failed without checking the logs. There isn\u2019t really a clean way of doing it I suppose. I guess if you do mess it up and don\u2019t notice the logs, you will just not see the change you were expecting I.e person still won\u2019t have access or the traffic you are trying to block will still come through. I guess that is the best that can be done!\nDefinitely a nice addition to this project, certainly covers my use case :)\n\nOn 13 Feb 2018, at 18:14, Aaron Hurt notifications@github.com wrote:\n@microadam are you able to test and verify?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "sharbov": "Indeed it worked once I configured the glob matcher.\nThanks for your help @magiconair!. Hey @magiconair,\nI've implemented the fixes you've requested.\nAs far as I can tell the two glob packages are compatible, \nI used the same test to validate it (and extended it to test the new capabilities).. I'm not sure why you used the glob matcher here in the first place, can a host contain wildcards ?. ",
    "Abroxa": "This is strange, I do not get any output from tcpdump on enp0s3 which is the interface for 10.0.2.15 on my VM. However, when I tcpdump interface docker0 I can see the packets from the browser for the web app container. This is true for both direct and fabio access. Maybe this is somehow related to the Docker bridge network. Here is what sudo tcpdump -i docker0 -A -s 1520 port 27181 receives (a bit truncated, this should be the interesting part and: ports have changed due to container restarts...):\n```\nGET /mlab4d4c4142/SegmentationAnnotationTool/null HTTP/1.1\nHost: sat-140-patched.applications.fme.lan\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\nAccept-Encoding: gzip, deflate\nAccept-Language: en-US,en;q=0.5\nCache-Control: no-cache\nConnection: keep-alive, Upgrade\nForwarded: for=10.0.2.15; proto=ws; by=172.17.0.3; httpproto=http/1.1\nOrigin: http://sat-140-patched.applications.fme.lan\nPragma: no-cache\nSec-Websocket-Extensions: permessage-deflate\nSec-Websocket-Key: aRP8Qa51fz7l6q3/8ntT2w==\nSec-Websocket-Version: 13\nUpgrade: websocket\nX-Forwarded-For: 10.0.2.15\nX-Forwarded-Host: sat-140-patched.applications.fme.lan\nX-Forwarded-Port: 80\nX-Forwarded-Proto: http\nX-Real-Ip: 10.0.2.15\n14:57:38.284923 IP sat-140-patched.applications.fme.lan.27181 > 172.17.0.3.58992: Flags [.], ack 818, win 240, options [nop,nop,TS val 26095356 ecr 2428573482], length 0\nE..4..@.@...\n.......j-.p3.d..n.P.....I.....\n.......\n14:57:38.296351 IP sat-140-patched.applications.fme.lan.27181 > 172.17.0.3.58992: Flags [P.], seq 1:335, ack 818, win 240, options [nop,nop,TS val 26095367 ecr 2428573482], length 334\nE.....@.@...\n.......j-.p3.d..n.P...........\n../....<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n\n502 Bad Gateway\n\nBad Gateway\nThe proxy server received an invalid\nresponse from an upstream server.\n\n\nApache/2.4.18 (Ubuntu) Server at sat-140-patched.applications.fme.lan Port 80\n\n```\nSo this apache web server is the internal web server of the web app. It has enabled mod_proxy_wstunnel meaning itself is another reverse proxy for the websocket connection due to historical reasons. Could that be a problem for fabio or the browser? Although it might be inefficient, the proxies actually should not care, I thought.\nFor completeness here is some more detailed information about my setup:\n[daniel@manjaro-vm Jobs]$ ip address\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether 08:00:27:92:c1:2d brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic noprefixroute enp0s3\n       valid_lft 82534sec preferred_lft 82534sec\n    inet6 fe80::77:7071:f9e:6bba/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:eb:88:9f:70 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:ebff:fe88:9f70/64 scope link \n       valid_lft forever preferred_lft forever\n9: veth86ae636@if8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default \n    link/ether a2:fd:c1:27:bf:14 brd ff:ff:ff:ff:ff:ff link-netnsid 1\n    inet6 fe80::a0fd:c1ff:fe27:bf14/64 scope link \n       valid_lft forever preferred_lft forever\n13: vetheb7eba1@if12: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default \n    link/ether 86:b5:cc:dd:a4:d1 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet6 fe80::84b5:ccff:fedd:a4d1/64 scope link \n       valid_lft forever preferred_lft forever\n[daniel@manjaro-vm Jobs]$ docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                                                NAMES\n4d2b2daadfd3        c63a210d0c34        \"/tini -- /usr/bin/s\u2026\"   17 minutes ago      Up 17 minutes       443/tcp, 10.0.2.15:27181->80/tcp, 10.0.2.15:27181->80/udp                                            worker-3810089d-73a9-5fff-e7e0-e7ee563009d9\n4e04e3bb2d02        417d06d1888f        \"/fabio -cfg /etc/fa\u2026\"   About an hour ago   Up About an hour    10.0.2.15:9998->9998/tcp, 10.0.2.15:9998->9998/udp, 10.0.2.15:80->9999/tcp, 10.0.2.15:80->9999/udp   balancer-b4171dad-947a-a6d7-06d5-7e80fe66456d\nThe first thing is the web app, the second container is fabio, both started by Nomad.. After thinking a bit longer about apache's message The proxy server received an invalid\nresponse from an upstream server. I come to the conclusion that it means that within the setup of two WS proxies (1. fabio 2. apache mod_proxy_wstunnel) somehow make the request bad for the actual WS server endpoint. I will try to get the logs of this internal stuff if existing.... Ok, I debugged it using tcpdump within the container on the internal websocket server. To begin with, I am not sure whether it's fabio's fault, as everything works when fabio directly connects to this internal server. When there is an additional apache in between, things break. And I think it is somehow related to the additional header information.\nFeel free to close this issue, but maybe you or someone else can comment on the reasons why the internal server does not accept the request.\nAgain, this the setup:\nWithin a Docker container, there is\n- An internal websocket server (I think it's written in Qt or so) that does some remote rendering and streams it back, we call it workerservice\n- An Apache that acts as frontend for the container, it ships the website and has a reverse proxy (mod_proxy_wstunnel) for the websocket connection that it redirects to the thing above\nThis is the tcpdump for firefox->fabio->apache->workerservice:\n```\nGET /mlab4d4c4142/SegmentationAnnotationTool/null HTTP/1.1\nHost: 127.0.0.1:4114\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\nAccept-Encoding: gzip, deflate\nAccept-Language: en-US,en;q=0.5\nCache-Control: no-cache\nForwarded: for=10.0.2.15; proto=ws; by=172.17.0.3; httpproto=http/1.1\nOrigin: http://sat-140-patched.applications.fme.lan\nPragma: no-cache\nSec-Websocket-Extensions: permessage-deflate\nSec-Websocket-Key: dp9S5KzoVXY+hLVgUAh8jg==\nSec-Websocket-Version: 13\nX-Forwarded-For: 10.0.2.15, 172.17.0.1\nX-Forwarded-Host: sat-140-patched.applications.fme.lan, sat-140-patched.applications.fme.lan\nX-Forwarded-Port: 80\n08:17:05.537042 IP localhost.4114 > localhost.59830: Flags [.], ack 744, win 353, options [nop,nop,TS val 2582068373 ecr 2582068373], length 0\nE..45d@.@..^...............jG[.....a.(.....\n..<...<.\n08:17:05.537051 IP localhost.59830 > localhost.4114: Flags [P.], seq 744:866, ack 1, win 342, options [nop,nop,TS val 2582068373 ecr 2582068373], length 122\nE...N.@.@..^............G[.....j...V.......\n..<...<.X-Forwarded-Proto: http\nX-Real-Ip: 10.0.2.15\nX-Forwarded-Server: 172.17.0.2\nUpgrade: WebSocket\nConnection: Upgrade\n```\nAs you can see, the internal server already responds (probably drops the connection) although the request is not finished yet. I don't know why. It could have something to do with the additional headers.\nThis is the tcpdump for firefox->fabio->workerservice:\n```\nGET /mlab4d4c4142/SegmentationAnnotationTool/null HTTP/1.1\nHost: sat-140-patched.applications.fme.lan:4114\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\nSec-WebSocket-Version: 13\nOrigin: http://sat-140-patched.applications.fme.lan\nSec-WebSocket-Extensions: permessage-deflate\nSec-WebSocket-Key: uiL6yTHOkNL6zsrAWwEHqA==\nConnection: keep-alive, Upgrade\nPragma: no-cache\nCache-Control: no-cache\nUpgrade: websocket\n09:00:27.630351 IP 239cd1a9af10.4114 > 10.0.2.15.47728: Flags [.], ack 599, win 236, options [nop,nop,TS val 1215400654 ecr 2329613429], length 0\nE..4q.@.@.......\n......pK.....$Z.....H.....\nHq.....u\n09:00:27.631456 IP 239cd1a9af10.4114 > 10.0.2.15.47728: Flags [P.], seq 1:139, ack 599, win 236, options [nop,nop,TS val 1215400656 ecr 2329613429], length 138\nE...q.@.@.._....\n......pK.....$Z...........\nHq.....uHTTP/1.1 101 WebSocket Protocol Handshake\nUpgrade: WebSocket\nConnection: Upgrade\nSec-WebSocket-Accept: dPaXiIz5P8Qmvu+6l8AiiJMDSTI=\n```\nEverything OK\nFor completeness, here are the dumps where fabio was not involved:\nThis is the tcpdump for firefox->apache->workerservice:\n```\nGET /mlab4d4c4142/SegmentationAnnotationTool/null HTTP/1.1\nHost: 127.0.0.1:4114\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\nSec-WebSocket-Version: 13\nOrigin: http://10.0.2.15:21681\nSec-WebSocket-Extensions: permessage-deflate\nSec-WebSocket-Key: 3gXLMaDnE7FkBEX5tLMpHg==\nPragma: no-cache\nCache-Control: no-cache\nX-Forwarded-For: 10.0.2.15\nX-Forwarded-Host: 10.0.2.15:21681\nX-Forwarded-Server: 172.17.0.2\nUpgrade: WebSocket\nConnection: Upgrade\n08:22:43.613468 IP localhost.4114 > localhost.32890: Flags [.], ack 634, win 352, options [nop,nop,TS val 2582406449 ecr 2582406449], length 0\nE..4..@.@.!!...........z.X....v.....(.....\n..e1..e1\n08:22:43.614959 IP localhost.4114 > localhost.32890: Flags [P.], seq 1:139, ack 634, win 352, options [nop,nop,TS val 2582406450 ecr 2582406449], length 138\nE.....@.@. ............z.X....v...........\n..e2..e1HTTP/1.1 101 WebSocket Protocol Handshake\nUpgrade: WebSocket\nConnection: Upgrade\nSec-WebSocket-Accept: afbGHM7N8PpAhnmNDmUcbqg3ZCY=\n```\nEverything OK.\nThis is the tcpdump for firefox->workerservice:\n```\nGET /mlab4d4c4142/SegmentationAnnotationTool/null HTTP/1.1\nHost: 10.0.2.15:4114\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\nSec-WebSocket-Version: 13\nOrigin: http://10.0.2.15:27382\nSec-WebSocket-Extensions: permessage-deflate\nSec-WebSocket-Key: Y5aAOWQDI/qTGM+Lnqbdjg==\nConnection: keep-alive, Upgrade\nPragma: no-cache\nCache-Control: no-cache\nUpgrade: websocket\n09:02:10.405834 IP 239cd1a9af10.4114 > 10.0.2.15.48128: Flags [.], ack 551, win 235, options [nop,nop,TS val 1215503430 ecr 2329716205], length 0\nE..4l.@.@.......\n........M.V~.m......H.....\nHs.F....\n09:02:10.406079 IP 239cd1a9af10.4114 > 10.0.2.15.48128: Flags [P.], seq 1:139, ack 551, win 235, options [nop,nop,TS val 1215503430 ecr 2329716205], length 138\nE...l.@.@.......\n........M.V~.m............\nHs.F....HTTP/1.1 101 WebSocket Protocol Handshake\nUpgrade: WebSocket\nConnection: Upgrade\nSec-WebSocket-Accept: S7EEsyKvKg+1XaJfToTb0lA0yck=\n``\nEverything OK.\n. It was a problem with the internal WebSocket server which had problems understandingX-Forwarded-Forheaders when there were multiple forwards (separated by comma). I turned them off usingProxyAddHeaders Off` in the apache \"middleware\".\nThanks for the tcpdump suggestion, that worked great!. ",
    "eliasbrange": "Just stumbled upon this and installed 1.5.9 to fix the problem. However, now it seems to work with both * and **. E.g. /some/path/here is matched by both /some/** and /some/*. What are the preferred way?. Thanks. Did not find that when searching through the configuration options.. ",
    "rverpillot": "In the UI, http and https targets have a weight of 50%. I enabled table detail mode in logs and I get this:\n+-- host=demo.myapp.com\n|   |-- path=/team/\n|   |    +-- addr=192.168.101.20:33266 weight 1.00 slots 1/1\n|   +-- path=/\n|       |-- addr=192.168.101.20:33267 weight 0.50 slots 1/2\n|       +-- addr=192.168.101.20:33268 weight 0.50 slots 1/2\nThe port 33267 is for https and 33268 is for http.. Moreover with a single routing table, you could get an another similar issue with this PR #463. The lookup function stops when route matches, whatever the protocol used (you could get a http route instead of a tcp+sni route).. I'm currently trying a fix with a routing table modified with protocol. It seems to work. But some regressions are possible.. ",
    "tobexyz": "hi, I've got the same problem. Is work on a fix for that planned?. ",
    "kmfischer3": "@magiconair We are working on fixing the Travis CI build, cleaning up the tracing code, and adding tests.. @magiconair We have added some tests for the tracing feature. Please let us know if there are any changes needed before this gets merged.. ",
    "lazystone": "I know that issue is closed but it looks that one must provide host and port of zipkin server in order to push spans there.\nWill it be possible to use service discovery instead of that?\nSo you can provide tracing.connectString=\"http://zipkin-service\" where zipkin-service is a service name in Consul instead of http:port pair?. ",
    "dekimsey": "I ran into this problem myself. There is no way (currently) to avoid the warnings with the container as-is. It appears to be an issue with the Dockerfile. It isn't set-up to run in userspace, but complains when run as root.. ",
    "codyja": "I should also note that when I queried services against the consul agent on\nthe host where the problematic fabio was, I was getting an accurate list of\nservices and destinations. We did check the Consul cluster and from what we\nsaw, couldn't find any issues occuring during this time. Also, each time,\nit was just 1 out of about 10 fabios in a node class, and out of about 40\nor so fabios in the entire cluster that had issues. Does this info change\nanything?\nAlso, what do you recomend as far as having fabio talk to consul, talking\nto the local consul on each host, or talking to the Consul servers directly?\nThank you\nOn Mon, Apr 2, 2018 at 9:12 AM, Frank Schr\u00f6der notifications@github.com\nwrote:\n\nMy guess is that your consul cluster has issues since fabio just waits for\nupdates from Consul and then rebuilds the routing table. You can test that\nby having the fabios talk to the Consul servers instead of the local agents\nand see if the problem goes away. I would have a look at the Consul logs of\nthese servers to see whether there were any strange things happening.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/fabiolb/fabio/issues/481#issuecomment-377937665, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AWCWpZExn49is8w5J2fM197-7w0KaC7Lks5tkjG2gaJpZM4TDimc\n.\n. We ran a script across the environment to pull the services from consul, then query every fabio and compare the routes in fabio to consul services destinations. We still have 3 (now 2 after I restarted one) fabios that have stale data. Is there anything I can gather or do before I restart them? Anything you'd like to see on these 2 remaining fabios that have old data in the route table? I'd be happy to do a zoom if desired. Thanks. I hit the :9998/health endpoint and it returns OK. Is there anything else I can look at? Here's from the docker logs on one host. Around 02:49:54, the log pattern seemed to change up a little, no more consul messages. After that point, the logs look the same as the do right now.\n\n2018/04/02 02:48:24 [INFO] consul: Manual config changed to #13223716\n2018/04/02 02:48:27 [INFO] consul: Health changed to #13223724\n2018/04/02 02:48:28 [INFO] consul: Manual config changed to #13223725\n2018/04/02 02:48:28 [INFO] consul: Manual config changed to #13223726\n2018/04/02 02:48:28 [INFO] consul: Manual config changed to #13223727\n2018/04/02 02:48:28 [INFO] consul: Manual config changed to #13223728\n2018/04/02 02:48:29 [INFO] consul: Manual config changed to #13223729\n2018/04/02 02:48:30 [INFO] consul: Health changed to #13223731\n2018/04/02 02:48:30 [INFO] consul: Health changed to #13223732\n2018/04/02 02:48:31 [INFO] consul: Health changed to #13223736\n2018/04/02 02:48:31 [INFO] consul: Health changed to #13223739\n2018/04/02 02:48:33 [INFO] consul: Manual config changed to #13223740\n2018/04/02 02:48:33 [INFO] consul: Manual config changed to #13223741\n2018/04/02 02:48:33 [INFO] consul: Manual config changed to #13223742\n2018/04/02 02:48:33 [INFO] consul: Manual config changed to #13223743\n2018/04/02 02:48:34 [INFO] consul: Manual config changed to #13223744\n2018/04/02 02:48:34 [INFO] consul: Health changed to #13223745\n2018/04/02 02:48:34 [INFO] consul: Health changed to #13223768\n2018/04/02 02:48:35 [INFO] consul: Health changed to #13223770\n2018/04/02 02:48:36 [INFO] consul: Health changed to #13223771\n2018/04/02 02:48:36 [INFO] consul: Health changed to #13223772\n2018/04/02 02:48:37 [INFO] consul: Health changed to #13223784\n2018/04/02 02:48:38 [INFO] consul: Health changed to #13223785\n2018/04/02 02:48:38 [INFO] consul: Health changed to #13223786\n2018/04/02 02:48:38 [INFO] consul: Manual config changed to #13223787\n2018/04/02 02:48:38 [INFO] consul: Manual config changed to #13223788\n2018/04/02 02:48:38 [INFO] consul: Manual config changed to #13223789\n2018/04/02 02:48:38 [INFO] consul: Manual config changed to #13223790\n2018/04/02 02:48:39 [INFO] consul: Manual config changed to #13223791\n2018/04/02 02:48:40 [INFO] consul: Health changed to #13223793\n2018/04/02 02:48:41 [INFO] consul: Health changed to #13223794\n2018/04/02 02:48:41 [INFO] consul: Health changed to #13223796\n2018/04/02 02:48:41 [INFO] consul: Health changed to #13223797\n2018/04/02 02:48:42 [INFO] consul: Health changed to #13223798\n2018/04/02 02:48:42 [INFO] consul: Health changed to #13223802\n2018/04/02 02:48:43 [INFO] consul: Health changed to #13223803\n2018/04/02 02:48:43 [INFO] consul: Manual config changed to #13223804\n2018/04/02 02:48:43 [INFO] consul: Manual config changed to #13223805\n2018/04/02 02:48:43 [INFO] consul: Manual config changed to #13223806\n2018/04/02 02:48:43 [INFO] consul: Manual config changed to #13223807\n2018/04/02 02:48:44 [INFO] consul: Manual config changed to #13223808\n2018/04/02 02:48:44 [INFO] consul: Health changed to #13223809\n2018/04/02 02:48:46 [INFO] consul: Health changed to #13223811\n2018/04/02 02:48:46 [INFO] consul: Health changed to #13223818\n2018/04/02 02:48:47 [INFO] consul: Health changed to #13223819\n2018/04/02 02:48:47 [INFO] consul: Health changed to #13223820\n2018/04/02 02:48:47 [INFO] consul: Health changed to #13223821\n2018/04/02 02:48:48 [INFO] consul: Health changed to #13223827\n2018/04/02 02:48:48 [INFO] consul: Manual config changed to #13223828\n2018/04/02 02:48:48 [INFO] consul: Manual config changed to #13223829\n2018/04/02 02:48:48 [INFO] consul: Manual config changed to #13223830\n2018/04/02 02:48:48 [INFO] consul: Manual config changed to #13223831\n2018/04/02 02:48:49 [INFO] consul: Manual config changed to #13223832\n2018/04/02 02:48:51 [INFO] consul: Health changed to #13223834\n2018/04/02 02:48:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:48:53 [INFO] consul: Manual config changed to #13223835\n2018/04/02 02:48:53 [INFO] consul: Manual config changed to #13223836\n2018/04/02 02:48:53 [INFO] consul: Manual config changed to #13223837\n2018/04/02 02:48:53 [INFO] consul: Manual config changed to #13223838\n2018/04/02 02:48:54 [INFO] consul: Manual config changed to #13223839\n2018/04/02 02:48:55 [INFO] consul: Health changed to #13223841\n2018/04/02 02:48:55 [INFO] consul: Health changed to #13223846\n2018/04/02 02:48:58 [INFO] consul: Health changed to #13223854\n2018/04/02 02:48:58 [INFO] consul: Manual config changed to #13223862\n2018/04/02 02:48:58 [INFO] consul: Manual config changed to #13223863\n2018/04/02 02:48:58 [INFO] consul: Manual config changed to #13223864\n2018/04/02 02:48:58 [INFO] consul: Manual config changed to #13223865\n2018/04/02 02:48:59 [INFO] consul: Manual config changed to #13223866\n2018/04/02 02:48:59 [INFO] consul: Health changed to #13223861\n2018/04/02 02:49:02 [INFO] consul: Health changed to #13223868\n2018/04/02 02:49:02 [INFO] consul: Skipping service \"_nomad-task-kqo3mpf33r6zu5fr453x5sxltmsjoeg3\" since agent on node \"server01.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:02 [INFO] consul: Skipping service \"_nomad-task-i2v4zgkkhrark6on3yxgt4utmlevy2h6\" since agent on node \"server01.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:02 [INFO] consul: Skipping service \"_nomad-client-ti5iwc442lgxgolvuvtv3e65xx6jkpxh\" since agent on node \"server01.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:02 [INFO] consul: Skipping service \"_nomad-task-g4gcd4axdsybzyn4phavcij4efe4dvgq\" since agent on node \"server01.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:03 [INFO] consul: Health changed to #13223869\n2018/04/02 02:49:03 [INFO] consul: Skipping service \"_nomad-task-kqo3mpf33r6zu5fr453x5sxltmsjoeg3\" since agent on node \"server01.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:03 [INFO] consul: Skipping service \"_nomad-task-i2v4zgkkhrark6on3yxgt4utmlevy2h6\" since agent on node \"server01.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:03 [INFO] consul: Skipping service \"_nomad-client-ti5iwc442lgxgolvuvtv3e65xx6jkpxh\" since agent on node \"server01.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:03 [INFO] consul: Skipping service \"_nomad-task-g4gcd4axdsybzyn4phavcij4efe4dvgq\" since agent on node \"server01.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:03 [INFO] consul: Manual config changed to #13223870\n2018/04/02 02:49:03 [INFO] consul: Manual config changed to #13223871\n2018/04/02 02:49:03 [INFO] consul: Manual config changed to #13223872\n2018/04/02 02:49:04 [INFO] consul: Manual config changed to #13223873\n2018/04/02 02:49:04 [INFO] consul: Manual config changed to #13223874\n2018/04/02 02:49:04 [INFO] consul: Health changed to #13223875\n2018/04/02 02:49:05 [INFO] consul: Health changed to #13223877\n2018/04/02 02:49:05 [INFO] consul: Health changed to #13223881\n2018/04/02 02:49:06 [INFO] consul: Health changed to #13223882\n2018/04/02 02:49:06 [INFO] consul: Health changed to #13223883\n2018/04/02 02:49:07 [INFO] consul: Health changed to #13223887\n2018/04/02 02:49:08 [INFO] consul: Manual config changed to #13223888\n2018/04/02 02:49:08 [INFO] consul: Manual config changed to #13223889\n2018/04/02 02:49:08 [INFO] consul: Manual config changed to #13223890\n2018/04/02 02:49:08 [INFO] consul: Manual config changed to #13223891\n2018/04/02 02:49:09 [INFO] consul: Manual config changed to #13223892\n2018/04/02 02:49:09 [INFO] consul: Health changed to #13223893\n2018/04/02 02:49:09 [INFO] consul: Health changed to #13223902\n2018/04/02 02:49:09 [INFO] consul: Health changed to #13223905\n2018/04/02 02:49:10 [INFO] consul: Health changed to #13223907\n2018/04/02 02:49:11 [INFO] consul: Health changed to #13223908\n2018/04/02 02:49:11 [INFO] consul: Health changed to #13223912\n2018/04/02 02:49:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:49:13 [INFO] consul: Health changed to #13223913\n2018/04/02 02:49:13 [INFO] consul: Health changed to #13223917\n2018/04/02 02:49:13 [INFO] consul: Manual config changed to #13223922\n2018/04/02 02:49:13 [INFO] consul: Manual config changed to #13223923\n2018/04/02 02:49:13 [INFO] consul: Manual config changed to #13223924\n2018/04/02 02:49:13 [INFO] consul: Manual config changed to #13223925\n2018/04/02 02:49:14 [INFO] consul: Health changed to #13223921\n2018/04/02 02:49:14 [INFO] consul: Manual config changed to #13223926\n2018/04/02 02:49:15 [INFO] consul: Health changed to #13223928\n2018/04/02 02:49:15 [INFO] consul: Health changed to #13223929\n2018/04/02 02:49:16 [INFO] consul: Health changed to #13223930\n2018/04/02 02:49:16 [INFO] consul: Health changed to #13223931\n2018/04/02 02:49:17 [INFO] consul: Health changed to #13223932\n2018/04/02 02:49:18 [INFO] consul: Health changed to #13223933\n2018/04/02 02:49:18 [INFO] consul: Health changed to #13223942\n2018/04/02 02:49:18 [INFO] consul: Manual config changed to #13223948\n2018/04/02 02:49:18 [INFO] consul: Manual config changed to #13223949\n2018/04/02 02:49:18 [INFO] consul: Manual config changed to #13223951\n2018/04/02 02:49:18 [INFO] consul: Manual config changed to #13223952\n2018/04/02 02:49:19 [INFO] consul: Health changed to #13223950\n2018/04/02 02:49:19 [INFO] consul: Manual config changed to #13223953\n2018/04/02 02:49:19 [INFO] consul: Health changed to #13223954\n2018/04/02 02:49:19 [INFO] consul: Health changed to #13223955\n2018/04/02 02:49:20 [INFO] consul: Health changed to #13223959\n2018/04/02 02:49:20 [INFO] consul: Health changed to #13223963\n2018/04/02 02:49:21 [INFO] consul: Health changed to #13223964\n2018/04/02 02:49:23 [INFO] consul: Manual config changed to #13223965\n2018/04/02 02:49:23 [INFO] consul: Manual config changed to #13223966\n2018/04/02 02:49:23 [INFO] consul: Manual config changed to #13223967\n2018/04/02 02:49:23 [INFO] consul: Manual config changed to #13223968\n2018/04/02 02:49:24 [INFO] consul: Manual config changed to #13223969\n2018/04/02 02:49:24 [INFO] consul: Health changed to #13223970\n2018/04/02 02:49:25 [INFO] consul: Health changed to #13223972\n2018/04/02 02:49:26 [INFO] consul: Health changed to #13223974\n2018/04/02 02:49:27 [INFO] consul: Health changed to #13223999\n2018/04/02 02:49:27 [INFO] consul: Health changed to #13224000\n2018/04/02 02:49:28 [INFO] consul: Manual config changed to #13224011\n2018/04/02 02:49:28 [INFO] consul: Manual config changed to #13224012\n2018/04/02 02:49:28 [INFO] consul: Manual config changed to #13224013\n2018/04/02 02:49:28 [INFO] consul: Manual config changed to #13224014\n2018/04/02 02:49:29 [INFO] consul: Manual config changed to #13224019\n2018/04/02 02:49:29 [INFO] consul: Health changed to #13224018\n2018/04/02 02:49:29 [INFO] consul: Health changed to #13224024\n2018/04/02 02:49:30 [INFO] consul: Health changed to #13224025\n2018/04/02 02:49:31 [INFO] consul: Health changed to #13224027\n2018/04/02 02:49:33 [INFO] consul: Manual config changed to #13224028\n2018/04/02 02:49:33 [INFO] consul: Manual config changed to #13224029\n2018/04/02 02:49:33 [INFO] consul: Manual config changed to #13224030\n2018/04/02 02:49:33 [INFO] consul: Manual config changed to #13224031\n2018/04/02 02:49:34 [INFO] consul: Manual config changed to #13224032\n2018/04/02 02:49:34 [INFO] consul: Health changed to #13224033\n2018/04/02 02:49:35 [INFO] consul: Health changed to #13224038\n2018/04/02 02:49:39 [INFO] consul: Manual config changed to #13224053\n2018/04/02 02:49:39 [INFO] consul: Manual config changed to #13224058\n2018/04/02 02:49:39 [INFO] consul: Health changed to #13224057\n2018/04/02 02:49:39 [INFO] consul: Health changed to #13224059\n2018/04/02 02:49:40 [INFO] consul: Health changed to #13224082\n2018/04/02 02:49:40 [INFO] consul: Health changed to #13224086\n2018/04/02 02:49:41 [INFO] consul: Health changed to #13224087\n2018/04/02 02:49:41 [INFO] consul: Skipping service \"_nomad-client-tkfk2zv5z6gnkyqsdyaeg2yl4rvn6ev3\" since agent on node \"server03.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:41 [INFO] consul: Skipping service \"_nomad-task-v6gtjcqonomkoyp6leey2oqc4wazwjfx\" since agent on node \"server03.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:41 [INFO] consul: Skipping service \"_nomad-task-lmknmojjyl5jgufcy3nlece4sz7nkh7z\" since agent on node \"server03.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:41 [INFO] consul: Skipping service \"_nomad-task-m75il25sxrkxn7f4rrxtmfmtehnfynsg\" since agent on node \"server03.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:41 [INFO] consul: Skipping service \"_nomad-task-oy7dkh3hfhnhoc4y7i5sf2khd6bg7pb7\" since agent on node \"server03.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:41 [INFO] consul: Skipping service \"_nomad-task-4mu5ghi5jyoslzorvx3vbt5mgt5f2ivm\" since agent on node \"server03.domain.local\" is down: Agent not live or unreachable\n2018/04/02 02:49:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:49:54 [INFO] consul: Manual config changed to #13224109\n2018/04/02 02:50:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:50:37 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:50:37 http: TLS handshake error from 192.168.124.77:51545: remote error: tls: unknown certificate\n2018/04/02 02:50:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:51:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:51:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:52:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:52:52 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:53:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:53:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:54:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:54:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:55:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:55:37 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:55:37 http: TLS handshake error from 192.168.124.77:58153: remote error: tls: unknown certificate\n2018/04/02 02:55:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:56:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:56:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:57:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:57:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:58:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:58:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 02:59:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 02:59:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 03:00:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 03:00:37 [WARN] No route for 192.168.15.244:443/\n2018/04/02 03:00:37 http: TLS handshake error from 192.168.124.77:64395: remote error: tls: unknown certificate\n2018/04/02 03:00:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 03:01:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 03:01:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 03:02:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 03:02:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 03:03:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 03:03:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 03:04:13 [WARN] No route for 192.168.15.244:80/\n2018/04/02 03:04:51 [WARN] No route for 192.168.15.244:443/\n2018/04/02 03:05:13 [WARN] No route for 192.168.15.244:80/. Ok very interesting. I'll look into your observations. \nI hit that consul health/state/any endpoint on this host where the fabio container with stale routes is running. I see my specific service with accurate dst IP:port info, and it shows passing. Also, If I hit localhost:8500/v1/catalog/service/, on this host, I get the accurate dst IP:port info. It seems like consul (cluster and local agent) both have the accurate service details, but this fabio (out of about 40) has old routes. Is there a way I can confirm or check to see if this running fabio is actively polling against the local consul agent or not? Just curious, does fabio persist the route table in memory, or to a file on disk? Thanks\n. So I looked back through the logs on multiple fabios. I can see the '[INFO] Config updates' messages along with the route adds. What's interesting is all the fabios have the same log entries including this problem fabio container up until 02:38:48 today. Then the next Config updates message was at 02:54:42 am, this was logged on every fabio except the problem fabio container. The problem fabio container hasn't logged anymore Config update messages today, or infact any additional consul messages today. . Also, regarding the service names, we should have unique names for all services. Occasionally, when we launch a nomad job, we'll register a few different service names for the same service (we do this for fabio too).\n  service {\n    name = \"fabio-oln-lb-a\"\n    tags = [\"fabio\"]\n    port = \"lb\"\n\n    check {\n      type     = \"tcp\"\n      port     = \"lb\"\n      path     = \"/\"\n      interval = \"10s\"\n      timeout  = \"2s\"\n    }\n\n  }\n  service {\n    name = \"fabio-oln-lb\"\n    tags = [\"fabio\"]\n    port = \"lb\"\n\n    check {\n      type     = \"tcp\"\n      port     = \"lb\"\n      path     = \"/\"\n      interval = \"10s\"\n      timeout  = \"2s\"\n    }\n\n  }\n  service {\n    name = \"fabio-oln-ui-a\"\n    tags = [\"fabio\"]\n    port = \"ui\"\n\n    check {\n      type     = \"tcp\"\n      port     = \"ui\"\n      path     = \"/\"\n      interval = \"10s\"\n      timeout  = \"2s\"\n    }. Before I restart the last two fabios in prod that aren't receiving updates from consul anymore, is there anything else I can capture or look at?. Yes, the consul agent on the host where this fabio was running was definately seeing updates. If I queried consul agent on this host, I could see the service in question, and the destinations were the correct IP:port location. I didn't look at the raft index though. If I queried host:9998/api/routes, and found the service in question, it had old ip:port locations though. . Hi @magiconair,\n\nWe did a production nomad deployment this morning to change a nomad job's app container version. Out of about 24 fabios running, 3 of them are showing old routes for this updated service. I got on a zoom with Sabin with Consul support, and he looked over the environment. He doesn't believe the cause is consul directly, but thinks this is being caused by fabio. He wanted to see if it was possible to get all on a zoom to potentially look at this more. Is this something we could possibly do? Thanks. Another thing I just noticed was that yesterday, when we hit this issue on 3 fabios, we actually did 2 updated nomad job deployments at almost exactly the same time. The first job (called primary) is the one that had it's service not be updated on 3 of the 24 fabios. The second job (called secondary) was deployed later and DID have it's service updated on all fabios, including the 3 problematic ones. . Hi @magiconair ,\nI figured out what was happening here. The local consul agent either hangs or loses connectiity to the  consul cluster. Nomad logs:\n\nApr  9 04:53:08 hostname nomad: 2018/04/09 04:53:08.099597 [WARN] consul.checks: check \"healthcheck\" for task \"mytaskname\" alloc \"d65871db-x\" timed out (2s)\nApr  9 04:53:13 hostname nomad: 2018/04/09 04:53:13.463818 [WARN] consul.checks: update for task \"mytaskname\" alloc \"d65871db-x\" check \"healthcheck\" failed: Put http://127.0.0.1:8500/v1/agent/check/update/7cd03a152b3xxxxxxxx: net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nApr  9 04:53:22 hostname nomad: 2018/04/09 04:53:22.696985 [INFO] fingerprint.consul: consul agent is unavailable\n\nIt seems like when consul agent becomes healthy again, the fabio on this host doesn't ever recover. Would it be possible to handle this situation a little differently? This also seems related to https://github.com/fabiolb/fabio/issues/162 \nThanks Frank. \n. We're testing the latest fabio in our staging env, and should be putting into production soon. We're running the latest nomad and consul is 1.0.1. I will mention too that the consul agent on the host doesn't seem to fully go down, I think it's just hung up. We're thinking it's something on the host level, possibly backup process. The problem I think is when consul agent becomes healthy again on these hosts, fabio has gotten into an odd state and doesn't seem to do any further lookups until I restart it. . ",
    "tpwow": "i got the same problem with successive health changes in fabio. i look through the consul both consul server and the local consul agent log, but found nothing werd. . ",
    "tuempeltaucher": "Any chance to see a fix here? We have the same problem with https://domain.tld as a path param.. No, that didn't change anything.\n[TRACE] abc Tracing xxx/stella/v1/xzy/https://wwwi.screenwork.de/\n[...]\n[TRACE] abc Routing to service stella on http://10.0.1.4:25853/\n\"GET /stella/v1/xyz/https%3A%2F%2Fwww.screenwork.de%2F HTTP/1.1\" 404 43 \"\" \"curl/7.29.0\" http://10.0.1.4:25853/v1/xyz/https://www.screenwork.de/\nBut I traced it done and added a few \"RawPath\"s:\nhttps://github.com/tuempeltaucher/fabio/commit/a06f98503d063e88b123176296f79a03bf0bf3ea. Yes, I forked valentin-krasontovitsch:url_decoding_in_routing, that is the branch from his pull request.. Any news here?. ",
    "valentin-krasontovitsch": "So it turns out that one can utilize the internal mechanisms of net/url to handle encoded parts of an uri. One just has to keep track of RawPath, whenever necessary, which is what this commit attempts to do...\nAs a side note, I got carried away and tried enabling encoded characters in rewrite rules as well, and in the strip prefix, which worked fine, until you combined say a rule like\nroute add svc / http://bar.com/a%2fc/$path\nwith a request for \n/%20 \nthe space in the request won't get escaped, as it's unambiguous on its own (I guess, cf. docs for function that sets Path and RawPath in net/url package), but would get escaped in the context of %2f, i.e. if one looked at the whole url http://bar.com/a%2fc/%20.\nOne may inspect the more involved changes on my corresponding branch - in particular, a link to the failing test case.\nSince I didn't see an easy and quick fix for that, I decided that it's maybe not the most needed use-case and that supporting what we have here might be enough.. I'm so sorry, saw your comment, but kinda ignored it O_o - let me see, I honestly don't know anymore, gotta check out the code... did I add some test cases? : )\n... yes, I did. Please take a look at those, I'm sure you're more familiar with the code base and can say with more confidence which cases I have covered, and whether I forgot any cases / should add some cases.\nBut at least the test cases are covered! ... and I think, to answer your original question, yes, that solves those issues, as far as I understand.. ",
    "scalp42": "Any chance to see this merged @magiconair ?. ",
    "makepanic": "We were also hit with this issue. \nIs there anything one can do to proceed with the issue/PR? . ",
    "shibukraj": "Is this can be done in Fabio? Or do we need to configure separate fabio instances per Protocol?. Thanks that worked perfectly. What I have seen is we need to define TCP first and then HTTP. \nThanks again.. ",
    "zpeterg": "Thanks, @leprechau , I looked for some time for how to chain protocols. The documentation seems to omit this.. ",
    "tristanmorgan": "I wonder if Consul-ESM could help with adding the \"services\" with the right tags?.... Fabio is tightly integrated with Consul is doesn't really make sense to run it without Consul. If you are using a different service-discovery tool there is probably an alternative load balancer better suited.\nDisclosure: I'm not from the Fabio Team but I love the tool.. ",
    "ashish235": "@leprechau , thanks will give it a try. . ",
    "stack72": "There is a fix in #391. @magiconair yeah we have this in production now for about 3 weeks - it was a replacement for us using HaProxy and it\u2019s integrated well with consul :). ",
    "gnoymmij": "2nd that. any work around or the intention to fix this?. ",
    "doctorj": "Hi deuch,\nYes, I did check \"X-Forwarded-For\" header. It is empty. \"Forwarded\", \"X-Real-Ip\", \"X-Forwarded-Port\", \"X-Forwarded-Proto\", \"X-Forwarded-Host\" also.\nFabio is not setting headers when runing TCP-SNI Proxy. I haven't tried, but headers are probably set when fabio is running TCP Proxy when TLS termination is done on fabio.\n. Hi leprechau, thanks for replying\nI understand that headers are not set when running TCP-SNI Proxy, but I was wondering is there some other way to find out client address.\nIt doesn't have to be on backend. Is it possible for fabio to log requests that are passed through?\nI have set \"log.access.target = stdout\", but have nothing on stdout. Am I doing something wrong or fabio is not logging requests when running TCP-SNI Proxy?. ",
    "mfuterko": "It would be great if somebody could test it, please? https://github.com/fabiolb/fabio/pull/598. Hi! Thanks for the code review and merging the PR.. Hi. Thanks for the review and comments.\nI disabled refresh by default only for backward compatibility as there was no such functionality before. \nAs regards to SHA checksum, I think it's a bit overkill to check it every so often so even if there's some delay on NFS etc the file will be re-read whey mtime eventually changes.\nProvided Fabio was created to work in zero configuration scenarios via Consul etc adding SIGHUP handler to re-read configuration would be somewhat contradictory on my opinion?\nFrom the security point of stand removing the htpasswd file should rather fail all login attempts but definitely should not disable auth completely. . @leprechau, no problem, happy to be helpful to the project!. @pschultz, thanks for the comments - I'll submit the patch in next day or so.. Hi @pschultz, please take a look at #610. Thanks.. ",
    "arrodriguez": "Yes, i would expect the same result, but navigating old issues and doing some testing , the results were this:\n\nif the host is a complete match, it take precedence over the glob route. \n```\nTest:\n\nhost: \napi.edge.foo.com/lalala\nroutes:\nurlprefix-api.edge.foo.com/lalala ,  urlprefix-*.foo.com/lalala\n```\n\nWhen two or more glob routes are compiting , the most general  one is taking precedence over the more specific.\n\n```\nTest\nhost: \napi.edge.foo.com/lalala\nroutes:\nurlprefix-.edge.foo.com/lalala ,  urlprefix-.foo.com/lalala\nIn this scenario urlprefix-*.foo.com/lalala  matches\n```\nFabio version is v1.5.6.\nRegards. @magiconair Thank you for your response. I understand the problem.\nHow do you think that fabio has to work in this cases ?\nwhile ago i had an issue in some project of firewall rules which uses wildcard host for matching. The difference with fabio is that this project permits the wildcard in any positiion.\nThe solution were to use \"permuterm indexes\". (https://nlp.stanford.edu/IR-book/html/htmledition/permuterm-indexes-1.html)\nSo in my opinion makes sense to rotate de entries in the route table index.\nBut i dont know if fabio wants this scope. . Yes you are right.  Its make sense leaving this like #507 . ",
    "kuskmen": "Hmm thanks mate it looks like it is indeed, but shouldnt we change the getting started page then?\nIn case you change your mind: https://github.com/fabiolb/fabio/pull/510. Hi guys, I looked upon the implementation in fabio and I was wondering if you can provide some more detailed description/requirement of what exactly is needed/desired.\n\nIn my case services with urlprefix-/sales/api tags are already in Consul, but lets say for some reason all these instances are failing and /status endpoint is returning 503. In that case Fabio is simply forgetting this route and searching another match, while practically - service route is known, just not functional.\n\nAs far as I saw these routes are indeed \"forgotten\" (unless I didn't see something in the implementation) so I was wondering are we saying that we should keep those routes even if the health check is critical and respond with 503 when such routes are requested or I completely misunderstood the idea?\nRegards,\nkuskmen. @leprechau , @magiconair  do you agree with the terms guys?. @leprechau yes I also don't like this very much, on the other hand described behavior is kind of unfortunate.\nI also don't know how making some kind of \"unhealthy\" prefix matching functionality will work out in conjunction with already existing fallback partial prefix matching.. ",
    "mantasaudickas": "Well.. Consul is Fabio database.. so it just needs to use it.\nIn my case services with urlprefix-/sales/api tags are already in Consul, but lets say for some reason all these instances are failing and /status endpoint is returning 503.\nIn that case Fabio is simply forgetting this route and searching another match, while practically - service route is known, just not functional.\nSo in that case responding to client with noroutestatus or 'noroutehtmlpath` would be fine as long as I don't have to specify anything manually for each service (we have many of them).\n. Yes, you are right.. Never tried to code in GO.. might take a while :). Yes, that's correct. Routes are available in Consul, but if all registered instances are down (warning and/or critical state) - fabio should respond with 503 instead of selecting another matching route.\nWhich consul states are unroutable should be decided using 'registry.consul.service.status' variable.. ",
    "netik": "Increasing this timeout on the ELB to 120 seconds only delays the error message.\nIt's provable that the ELB closing the connection is the root cause of this issue. \n2018/06/23 03:50:33 [INFO] HTTP proxy listening on :9999\n2018/06/23 03:50:33 [INFO] Access logging disabled\n2018/06/23 03:50:33 [INFO] Using routing strategy \"rnd\"\n2018/06/23 03:50:33 [INFO] Using route matching \"prefix\"\n2018/06/23 03:50:33 [INFO] consul: Registered fabio as \"fabio\"\n2018/06/23 03:50:33 [INFO] consul: Registered fabio with id \"fabio-ip-10-1-0-228-9998\"\n2018/06/23 03:50:33 [INFO] consul: Registered fabio with address \"10.1.0.228\"\n2018/06/23 03:50:33 [INFO] consul: Registered fabio with tags \"\"\n2018/06/23 03:50:33 [INFO] consul: Registered fabio with health check to \"http://[10.1.0.228]:9998/health\"\n2018/06/23 03:52:32 [WARN] consul: Error fetching config from /fabio/config. Unexpected response code: 504\n2018/06/23 03:52:33 [WARN] consul: Error fetching config from /fabio/noroute.html. Unexpected response code: 504. I am also guessing that it makes more sense to have consul's address (in DNS) report the actual server IPs and not the Loadbalancer, as fabio attempts to open multiple connections to consul...\n```\nfabio   19128  jna    3u  IPv4 3633444      0t0   TCP 10.1.0.228:49072->10.1.2.13:8500 (ESTABLISHED)\nfabio   19128  jna    4u  0000    0,11        0  7195 anon_inode\nfabio   19128  jna    5u  IPv6 3632420      0t0   TCP :9998 (LISTEN)\nfabio   19128  jna    6u  IPv4 3633449      0t0   TCP 10.1.0.228:36128->10.1.0.51:8500 (ESTABLISHED)\nfabio   19128  jna    7u  IPv4 3633746      0t0   TCP 10.1.0.228:49102->10.1.2.13:8500 (ESTABLISHED)\nfabio   19128  jna    8u  IPv4 3633774      0t0   TCP 10.1.0.228:36158->10.1.0.51:8500 (ESTABLISHED)\nfabio   19128  jna    9u  IPv6 3632424      0t0   TCP :9999 (LISTEN)\n[root@ip-10-1-0-228 jna]# nslookup consul.staging.dc1.str\nServer:     10.1.0.2\nAddress:    10.1.0.2#53\nNon-authoritative answer:\nName:   consul.staging.dc1.str\nAddress: 10.1.2.13\nName:   consul.staging.dc1.str\nAddress: 10.1.0.51\n```. Aha. Thank you. I\u2019ll set up local consul servers on our api hosts. . Running a local client solved this problem for us. Thanks.. ",
    "ggerritsen": "You can put configuration for manual overrides in the web ui (https://fabiolb.net/feature/web-ui/). \nSee e.g. https://fabiolb.net/cfg/#route-add for how to add a route. . ",
    "artyomturkin": "connect helps us to secure services with mTLS that do not use TLS themselves. But because of this Fabio can not connect to them to expose them.\nRight now the work around is to run connect alongside Fabio and manually configure all the services locally in connect and Fabio. One of the best parts of Fabio is autoconfiguration from discovery systems, but this does not work with connect enabled services.\nIf Fabio is natively connect enabled, automatic configuration will be possible and connection from Fabio to backend service will be highly secure.\nAs to how to expose (tcp or http) them can be determined as usual through consul tags or metadata.. ",
    "nutbunnies": "Our shop would like to use connect to avoid having to update each service to use TLS as well.   Anyone working on this or have an implementation design in mind?  I have some free cycles to code a solution or test someone's branch.. ",
    "imcitius": "I will try to direct test without lb, and update this thread.\nfabio/traefik and ws server is on same lan in all cases, so I think any network related problems should hit traefik as well.\nConcerning system resources - fabio has 100 000 descriptors available, and there is no production load on it now, so fabio's resources cannot exhaust.\nSame with network, problems on the ws server side should hit traefik as well.\nAlso, I think good traefik's work cannot be just bad test or randomness, because traefik works for month, and problem with fabio arise immediately after we try to put it in the chain.\n. No offence, please excuse my poor english, if I can look too rough.\nI tried direct test, and had no problems with it.\nOn ws server side I can see some connections, going from ESTABLISHED to TIME_WAIT state after python script finish and exit.\nAlso netstat -untap|grep fabio does not show any stuck connections on fabio.\nDo we have some way to deeper debug underlying go library?\nThanks.\n. ",
    "luke123abc1": "After some research, I have learned if you do not add a url tag, it will auto forward the uri. I am now wondering how you can forward the uri with a url prefix. ",
    "peiwenjian": "Plus: I don't have these 100.x.x.x.x's in my cluster. ",
    "andreyshamray": "Hi, thanks for fast response. I will try to implement this approach today. . Hm strange, but routing is not working for me. Could you pls give an advice on this.\n1. I have added config like this:\ncat fabio.properties \nregistry.static.routes = \\\n    route add svc / http://rpc-fabio.kube.com:9999/\n2.  Now I am starting Fabio:\n./fabio -cfg fabio.properties\n3. Hit in browser something like this:\nmy-fabio.com:9999/my-service\n and it give's me 404, but I am expecting to be redirected to \nrpc-fabio.kube.com:9999/my-svc\nIn logs of Fabio I see an errot:\n[WARN] No route for rpc-fabio.kube.com:9999/my-svc\n4. And does Fabio support route configuration threw env variables, like FABIO_REGISTRY_CONSUL_ADDR? . Hi, guys. Did you have a chance to take a look at my previous comment?\nThanks a lot.. So finally we have configured it, the problem was with the host header.\nroute add product-svc / http://rpc-fabio.kube.com/ opts \"host=dst\"\nAnd does Fabio support route configuration threw env variables, like FABIO_REGISTRY_CONSUL_ADDR?. Ok, thanks a lot!) I think I will use put method to just add the desired route to consul KV). ",
    "volym3ad": "Also faced with this problem... Restart of fabio helped but this is not an option. @magiconair what do you think about this?. ",
    "nkissebe": "I no longer care about this issue. Can't do this with other hashicorp tools anyway so wouldn't matter to me if fabio could do this or not.. ",
    "jorjika": "@satishviswanathan  thanks. I needed \"strip\" option. It worked well :). ",
    "1941198": "cla Already agree.\n\n. already updated. update to commited.. ",
    "postelrich": "@leprechau to use fabio, I have to register the service with tags that specify the endpoints the service can handle and fabio uses that list of tags to route. I'm asking if fabio could be extended to instead route by the service name registered with consul. \nFor example, I have an http api service called restaurant-service that has various endpoints such as  /,  /restaurants, etc. I want to make an http request to the service via fabio by doing http://myfabio.server.com:9998/restaurant-service. So to hit the restaurants endpoint I could do http://myfabio.server.com:9998/restaurant-service/restaurants.. Why are service names irrelevant? It's how I identify groups of the same service.\nOne reason the endpoint tag scheme doesn't work for me is that a lot of my services have overlapping endpoints for things like stats, health check, management.. Ah I see, yes I was asking if fabio could make use of the service name in the routing table. Might be irrelevant since the strip part of the tag would take care of what im looking for. Thanks!. ",
    "msvbhat": "Looks like I can't label this issue as question. Can someone else do this for me please?. I got tripped by the doc page that when either of the source IP and XFF is matched, the rule will allowed. But in reality both of them should match the rule to be allowed. It took me sometime to go through the source code (and original PR) to find out. Hence updating the documentation page, so that other's don't have to spend time there :). @leprechau Thanks for reviewing and merging the PR. And apologies for late response. Was on holiday yesterday. . ",
    "adesaegher": "I got this error after a while:\n2018/10/04 15:03:49 [WARN] route: no target match\nIt seems related to this issue : https://github.com/fabiolb/fabio/issues/224\n. ",
    "calvix": "Hello, \nthe TCP SNI wildcard routing indeed doesn't work in a current state.\nI have PR that allows the wildcard routing here https://github.com/calvix/fabio/pull/1\nQuestion is if this fits the general fabio code and doesn't bring any issues.\n. ",
    "Avonasac": "actually you're right, it's out of order I need to use the consul DNS to establish a connection between front back and database and then expose the Fabio to balance the instances of each microservice. In which case I have no idea on how to use consul's DNS to connect my back and database through Fabio so I can Balance my own microservices connection. I know it can be a bit odd, but it's hard explain the arquitecture in english becuase it's not my first language.. ",
    "khanhhua": "The issue is not there if I use Fabio 1.4. Please check. @magiconair . ",
    "DavidRutqvist": "\nCompletely removing the tag model would almost certainly break many deployments including our deployment. This would result in quite a bit of code change to solve a non-problem. I definitely see the appeal of service metadata but do not think the tag model should be abandoned.\n\nYeah, that is why I proposed keeping it for backwards compatibility and only changing the documentation to gradually move towards service metadata.\n@magiconair I could try finding time to submit a PR. I am a bit short of time during the following weeks but we'll see. It did not seem to difficult to add this kind of support.\nAny suggestions for \"discovery tag\". Currently fabio searches for the prefix \"urlprefix-\", this does not seem to be a candidate according to me. . Yesterday I started implementing this. To do this we obviously have to update the Consul dependency to a later version. After doing this I realised there is a lot of changes which is not necessary to this use case. Only the newly added ServiceMeta field to the CatalogService is needed in order to fulfill this use case.\nWhat are your thoughts on this @magiconair ? Should we update the whole API-catalog or just add the field to the CatalogService struct?. > @DavidRutqvist I'll build and test a local version with v1.4.0 to support service metadata and consul connect.\nSuper, I'll leave this to you then. It will be very much appreciated.. ",
    "andyroyle": "My first time using go modules, sorry. Cheers!. Not at all, I just wanted the updated consul client :+1:. Dead easy to add, do we want to make htpasswd the default for basic auth?. Htpasswd is pretty standard stuff. Will make the changes first thing Monday :+1:. @magiconair  / @leprechau htpasswd support added. \nAlso added support for an optional realm (used in the WWW-Authenticate: Basic realm=\"<realm>\" response). So I vendored in a new library, which depends on golang.org/x/crypt but it seems to have brought with it updates to golang.org/x/net and golang.org/x/text, yet go.mod only shows a single change. Colour me confused.. @shantanugadgil this is exactly what we are using it for as well \ud83d\ude04 . @magiconair thanks for the review (and for merging #575). I've fixed those issues and also rebased on top of master, so this should be good-to-go now.. So this PR doesn't include those http/2 changes from #436 in, because it creates an entirely separate transport. It might still be worth merging that.. The grpc:// prefix is purely an implementation detail for the Fabio config language. Since the grpc proxy is separate from the http proxy (in spite of the fact that grpc runs over http2), Fabio needs to be able to differentiate between http routes and grpc routes, hence the proto=grpc option.\nA URL in the routing table that looks like grpc://127.0.0.1:3456 is normal. When connecting to the downstream service Fabio will just use the host and port.\nThe clients and backend services should be completely unaware of the internal grpc:// prefix.\nCan you post more information about your setup and the errors you are seeing?. Ah, I need to confirm but I am pretty sure that the urlprefix (i.e. /grpc-server) isn't supported by the grpc proxy.\nI don't know whether it is possible to add support for it.. In the case of the my.service, it's specifically the grpc service name (grpc calls are routed by service and method name). Unfortunately arbitrary prefixes aren't supported in the way that they are for http/s proxying\nThe docs are unclear so that's a failure on my part.\nThe grpc service is defined by the package name and service name defined in your proto, e.g.\n```\npackage foo\nservice bar {\n  rpc Baz (BazReq) returns (BazResp) {}\n  rpc Flarg (FlargReq) returns (FlargResp) {}\n}\n// message definitions\n```\nSo in the above example, the service is foo.bar and the method is Baz or Flarg.\nYou can route using only the service name:\n- urlprefix-/foo.bar proto=grpc\nOr using both the service and method\n- urlprefix-/foo.bar/Baz proto=grpc\nOr using just a catch-all\n- urlprefix-/ proto=grpc. That's not to say that arbitrary prefixes and rewriting and stripping and the like couldn't be supported, it's just the current implementation doesn't. As far as I am aware, yes the routing is case sensitive. Sorry @tommyalatalo I've been on vacation this past week. \nYeah, it seems like the docs need updating. I'll hopefully get to it this week.\nIn terms of your question about prefixes, whilst they aren't currently supported, we essentially need to hook up the path stripping. In theory it might already be supported (if you add the strip=/v1 option to the tag), I've just never tested it.\nI need to test to see how this works. Hopefully I will get to it soon.. Ah bum. You're right. Since the path is constructed by the proto client the. We can't just add arbitrary bits to it.\nI suspect the only way to achieve what you want is to create two separate proto services pkg.service.v1 and pkg.service.v2 and register them separately.. The problem there is that the host matching doesn't work for GRPC. GRPC uses http2, for which the host header isn't required, so at routing time, we don't have any information as to what host the request came in on. All we know is what server config can tell us i.e. the IP we bound to or the server name that is in the certificate we are using (good luck if you are using a wildcard cert). Presumably SNI is only required for TLS, so that wouldn't cover non-TLS deployments. Still, it's better than nothing I guess.. the grpcservername option was added for use with TLS backends. Fabio connects to backends using <ip>:<port>, so if the certificate presented by your backend doesn't include an IP SAN, then you can set grpcservername to specify the serverNameOverride field in the tls config: https://github.com/fabiolb/fabio/blob/master/proxy/grpc_handler.go#L245\nAn example would be:\nurlprefix-/ proto=grpcs grpcservername=grpcapi.service.consul. ",
    "JeanBaptisteWATENBERG": "Hi\nThanks for your quick reply.\nSorry I submitted the issue a bit fast without providing a comment. I just editted the issue and provided some more context. As stated i was wondering whether Fabio could perform some retries on other containers to give time to consul to execute it's health check.. @leprechau It looks great, thank you very much ! I will have a look at those options and see whether i can catch the sigterm sent by docker swarm when updating services to unregister it in consul, i guess this is indeed the simplest solution. Thank you very much for your help :+1: . ",
    "IxDay": "I mostly inferred it from the screenshots as service-a is coming before service-b even if the hostnames are not alphabetically ordered. \nMy main issue is to force a service to be https only, as, if the order is based on hostname only, the redirection will be in the form:\nroute add some.name:80/ https://some.name/$path opts \"redirect=301\"\nroute add some.name service.endpoint proto=https\nBut some.name:80 will always come after some.name and thus making the redirection never happening.. Ok, I came with a proper one line example:\nbash\nfabio -proxy.addr=\":80,:443;proto=tcp+sni\" -registry.backend=static -insecure -log.level TRACE -registry.static.routes='\nroute add foo rulz.xyz/ https://172.17.0.4:443/ opts \"proto=https tlsskipverify=true\"\nroute add bar rulz.xyz:80/ https://rulz.xyz/$path opts \"redirect=301\"'\nHere I have a https service at 172.17.0.4, I use tcp+sni, when connecting to https endpoint I get the proper behavior: \nbash\ncurl -Lkvvv --resolve \"rulz.xyz:80:172.17.0.3\" --resolve \"rulz.xyz:443:172.17.0.3\" https://rulz.xyz\nresult:\n```txt Added rulz.xyz:80:172.17.0.3 to DNS cache\n Added rulz.xyz:443:172.17.0.3 to DNS cache\n Hostname rulz.xyz was found in DNS cache\n   Trying 172.17.0.3...\n TCP_NODELAY set\n Connected to rulz.xyz (172.17.0.3) port 443 (#0)\n ALPN, offering h2\n ALPN, offering http/1.1\n successfully set certificate verify locations:\n   CAfile: /etc/ssl/certs/ca-certificates.crt\n  CApath: none\n TLSv1.3 (OUT), TLS handshake, Client hello (1):\n TLSv1.3 (IN), TLS handshake, Server hello (2):\n TLSv1.2 (IN), TLS handshake, Certificate (11):\n TLSv1.2 (IN), TLS handshake, Server key exchange (12):\n TLSv1.2 (IN), TLS handshake, Server finished (14):\n TLSv1.2 (OUT), TLS handshake, Client key exchange (16):\n TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):\n TLSv1.2 (OUT), TLS handshake, Finished (20):\n TLSv1.2 (IN), TLS handshake, Finished (20):\n SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384\n ALPN, server did not agree to a protocol\n Server certificate:\n  subject: CN=foo.com\n  start date: Dec 11 09:06:57 2018 GMT\n  expire date: Dec 11 09:06:57 2019 GMT\n  issuer: CN=foo.com\n*  SSL certificate verify result: self signed certificate (18), continuing anyway.\n\nGET / HTTP/1.1\nHost: rulz.xyz\nUser-Agent: curl/7.62.0\nAccept: /\n\nHTTP 1.0, assume close after body\n< HTTP/1.0 200\n< Content-Type: text/plain\n<\nHello World!\nTLSv1.2 (IN), TLS alert, close notify (256):\nClosing connection 0\nTLSv1.2 (OUT), TLS alert, close notify (256):\n```\n\n\nHowever, If I try to use the http endpoint:\nbash\ncurl -Lkvvv --resolve \"rulz.xyz:80:172.17.0.3\" --resolve \"rulz.xyz:443:172.17.0.3\" http://rulz.xyz\nresult:\n```txt\n Added rulz.xyz:80:172.17.0.3 to DNS cache\n Added rulz.xyz:443:172.17.0.3 to DNS cache\n Hostname rulz.xyz was found in DNS cache\n   Trying 172.17.0.3...\n TCP_NODELAY set\n Connected to rulz.xyz (172.17.0.3) port 80 (#0)\n\nGET / HTTP/1.1\nHost: rulz.xyz\nUser-Agent: curl/7.62.0\nAccept: /\n< HTTP/1.1 200 OK\n< Content-Type: text/plain\n< Date: Tue, 11 Dec 2018 12:58:00 GMT\n< Content-Length: 13\n<\nHello World!\n* Connection #0 to host rulz.xyz left intact\n```\n\nNo redirection occurs, checking the routes in alphabetical order push rulz.xyz:80/ after the service declaration, and avoid the redirection,\nIf I declare my routes this way:\nbash\nfabio -proxy.addr=\":80,:443;proto=tcp+sni\" -registry.backend=static -insecure -log.level TRACE -registry.static.routes='\nroute add foo rulz.xyz:443/ https://172.17.0.4:443/ opts \"proto=https tlsskipverify=true\"\nroute add bar rulz.xyz:80/ https://rulz.xyz:443/$path opts \"redirect=301\"'\nI get: 2018/12/11 13:00:03 [WARN] No route for rulz.xyz. ",
    "GoingFast": "fabio is logging:\ninvalid log msg: 2018/12/08 20:49:57 http: proxy error: dial tcp 10.0.2.15:29526: connect: connection refused\ninvalid log msg: 2018/12/08 20:49:58 http: proxy error: dial tcp 10.0.2.15:21078: connect: connection refused\ninvalid log msg: 2018/12/08 20:49:58 http: proxy error: dial tcp 10.0.2.15:21078: connect: connection refused\ninvalid log msg: 2018/12/08 20:49:58 http: proxy error: dial tcp 10.0.2.15:21078: connect: connection refused\nhowever I'm checking consul and they are healthy.. I figured it out. Consul was pointing to 10.0.2.15 its local and I have 3 node cluster on vagrant so it tried to access some random ports on local that arent existant. I had to put address_mode = \"driver\" to the nomad service and it got the right interface addresses. Thanks for trying to help btw @pschultz . ",
    "alexesDev": "@magiconair oh, sorry. I am use docker image fabiolb/fabio:1.5.10-go1.11.1. ",
    "jbrinnand": "Well the problem was the health check. As soon as I added it, fabio was happy. Basically the deployment descriptor looked like this:\n{\n    \"id\":\"indigovertx\",\n    \"cpus\": 2.0,\n    \"mem\": 4086,\n    \"instances\": 1\n<img width=\"1016\" alt=\"screen shot 2018-12-29 at 2 04 42 pm\" src=\"https://user-images.githubusercontent.com/587313/50542457-8a8a2f80-0b72-11e9-96e7-3d847f48f085.png\">\n,\n    \"env\": {\n        \"CHANNEL_NAME\": \"ch\",\n        \"NUM_ACTORS\": 10,\n        \"DATA_FILENAME\": \"/tmp/data-alpha\",\n        \"DISCOVERY_HOST\": \"172.17.0.7\",\n        \"PORT\": 6080,\n        \"PUBLISHED_ID\": 31,\n        \"SERVICE_TAGS\":\"urlprefix-/ping,urlprefix-/x509Certificate\",\n        \"SERVICE_NAME\":\"indigovertxquasar\",\n        \"SERVICE_CHECK_HTTP\":\"/ping\",\n        \"SERVICE_CHECK_INTERVAL\":\"10s\",\n        \"SERVICE_CHECK_TIMEOUT\":\"5s\"\n    },\n    \"container\": {\n        \"docker\": {\n            \"type\": \"DOCKER\",\n            \"image\": \"indigovertxquasar:latest\",\n            \"network\": \"BRIDGE\",\n            \"portMappings\": [\n                { \"containerPort\": 6080, \"hostPort\": 0, \"protocol\": \"tcp\" }\n            ]\n        }\n    }\n}\nAnd I added a ping endpoint to the target service. And fabio's log looks like this:\n2018/12/27 21:28:59 [INFO] Config updates\n+ route add indigovertxquasar /ivq http://172.17.0.9:6080/ tags \"url-prefix:-6080/indigovertx\"\n+ route add indigovertxquasar /indigovertx http://172.17.0.9:6080/ tags \"url-prefix:-6080/indigovertx\"\nAnd fabios UI looks like this:\n\nHappy coding in the New Year!. Health check added, fabio added the route as specified.. ",
    "vinodbala": "@leprechau @magiconair Could you please give any update on this if possible ?. Thanks for prompt response @leprechau. Thanks for considering the idea of enforcing group rules. On the idea of using system level firewalling for all services, wouldn't Fabio still block traffic from a \"firewall whitelisted\" IP address unless its route for the service was configured with the specific IP ?. @leprechau Got it. The solution you mention work well for blacklisting IPs. The one I am struggling with is the following. I want to whitelist a group of \"admin\" IPs for all services along with an individual unique set of whitelisted IPs for each service. Hope that makes sense. Any ideas would be appreciated.. @leprechau What I want is:\nSystem firewall:\n$maliciousIps = { 1.2.3.0/24, 4.5.6.7/32 }\nblock all tcp in on {80, 443} from $maliciousIps\nallow tcp in on {80, 443}\nIn Fabio:\n$adminIps = { 50.1.2.3/24, 75.1.2.3/32 }\nroute /foo allow IP-A IP-B $adminIPs\nroute /bar allow IP-C  $adminIPs\nroute /bob IP-D IP-A  $adminIPs\nInstead of mentioning  $adminIPs in each route can I configure it in one single place ?. @leprechau Understood. Thanks for taking the time. It would be cool to see some form of \"group policy\" for rules in the future. Appreciate your input here.. Accidentally closed this - will leave it open as it is labelled \"enhancement\".. ",
    "geohuz": "@leprechau, thanks for prompt reply! I guess I may missed something, the getting started guide doesn't  mention how to setup consul service and I think that should be the problem? So I found something in this link: https://github.com/hashicorp/nomad/blob/master/demo/vagrant/consul.service,\n```\n[Unit]\nDescription=consul agent\nRequires=network-online.target\nAfter=network-online.target\n[Service]\nRestart=on-failure\nExecStart=/usr/bin/consul agent -dev\nExecReload=/bin/kill -HUP $MAINPID\n[Install]\nWantedBy=multi-user.target\n```\nBut I don't know how to use this file :-( , so I guess what I want is consul + fabio + apache in the simplest vagrant nomad setup, could you please help me? \nThanks!\nBTW, I get the error log as you pointed out:\n2019/01/21 17:34:28 [WARN] Error initializing backend. Get http://localhost:8500/v1/agent/self: dial tcp [::1]:8500: connect: connection refused\nThat should be a missed consul service right?\nand in the getting start guide, the client.hcl file:\n```\n...\nEnable the client\nclient {\n    enabled = true\n# For demo assume we are talking to server1. For production,\n# this should be like \"nomad.service.consul:4647\" and a system\n# like Consul used for service discovery.\nservers = [\"127.0.0.1:4647\"]\n\n}\n```\nAnd I can't find anywhere in the documentation on how to setup consul and make the corresponding change in the client.hcl . ",
    "ArulDhanaSaamPrakash": "Hi , \nThank you for your prompt response. Issue  #594 seems to be the same as the one which we are dealing with. Is Fabio considering currently it as a feature request and is there a pull request for it in the code base already ?. Also, if considered kindly let me know when we can expect a release from Fabio. If you are aware of any timeline for Fabio's next release, kindly let me know. \nYes. I looked into Fabio's web socket support. Fabio's WebSocket support is an end to end web socket based connection.  Our custom use case demands us to have an HTTP request upgraded into a web socket and issue a TCP connection to host. The response we got from the host will be put back into the WebSocket and given as the response for the HTTP request. The reason for upgrading an HTTP request is that the firewall put in place blocks web socket traffic. Such a firewall exists for many applications not just for the one which we are building. Eg: data centers.  If Fabio supports this in any way which I am unaware of, kindly let me know. I will be happy to use that. \nThanks and regards,\nA.Arul Dhana Saam Prakash \n. ",
    "tommyalatalo": "Also very interested in this, I don't know the history here, but I see many files already have the case for \"proto=grpc\" added. However you're saying it's not enabled in 1.5.10?\nThat would explain why I'm getting \"[FATAL] 1.5.10. unknown protocol \"grpc\"\" when trying to run a grpc proxy.... 1.5.11 is out now. > The grpc:// prefix is purely an implementation detail for the Fabio config language. Since the grpc proxy is separate from the http proxy (in spite of the fact that grpc runs over http2), Fabio needs to be able to differentiate between http routes and grpc routes, hence the proto=grpc option.\n\nA URL in the routing table that looks like grpc://127.0.0.1:3456 is normal. When connecting to the downstream service Fabio will just use the host and port.\nThe clients and backend services should be completely unaware of the internal grpc:// prefix.\nCan you post more information about your setup and the errors you are seeing?\n\nI'm running a grpc server in a docker container registered as a service in a consul cluster which fabio is part of too. I'm dialing using \n c, err := grpc.Dial(serverAddr, grpc.WithInsecure(), grpc.WithBackoffMaxDelay(5*time.Second))\nThe server is running a bidirectional stream, but the client stops dead since it cant connect (no error output, just a println describing which step the client streaming is at before it fails connecting), this happens when I point the client to fabio.service.consul:8888/grpcserver/ (serverAddr above).\nI can match this behavior exactly by pointing my client manually to ip:port (it works) and then to grpc://ip:port, and it fails in the same manner as above when targeting the consul dns fabio address.\nThe consul service is basically set up like this in my Nomad job for the container:\nservice {\n        name = \"grpcserver\"\n        port = \"grpc\"\n        tags = [\"grpc\",\n                \"urlprefix-/grpcserver/ proto=grpc \"]\n        check {\n          name     = \"grpcserver tcp\"\n          type     = \"tcp\"\n          interval = \"10s\"\n          timeout  = \"2s\"\n        }\n      }\nI haven't specified the RPCs as the endpoints here, but I tried that too, and it makes no difference.\nFrom my end it seems that the implementation doesn't work the way you're saying it does, if fabio would have resolved the path to just ip:port then my client should definitely be able to connect, instead now it seems very much like it resolves to the \"grpc://\" path, or something else thats not connectable.\nHere is my fabio job for completeness:\n`job \"fabio\" {\n  datacenters = [\"dc\"]\n  type        = \"system\"\nupdate {\n    stagger      = \"60s\"\n    max_parallel = 1\n  }\ngroup \"fabio\" {\ntask \"fabio\" {\n  driver = \"docker\"\n\n  config {\n    image = \"fabiolb/fabio:latest\"\n    dns_servers = [\"169.254.1.1\"]\n    network_mode = \"host\"\n  }\n\n  env {\n    registry_consul_addr = \"169.254.1.1:8500\"\n    proxy_addr = \":9999;proto=http,:8888;proto=grpc\"\n  }\n\n  service {\n    name = \"fabio-http\"\n    tags = [\"http\", \"load-balancer\", \"proxy\"]\n    port = \"http\"\n\n    check {\n      type     = \"tcp\"\n      interval = \"10s\"\n      timeout  = \"2s\"\n    }\n  }\n\n  service {\n    name = \"fabio-ui\"\n    tags = [\"ui\", \"load-balancer\"]\n    port = \"ui\"\n    check {\n      type     = \"http\"\n      path     = \"/\"\n      interval = \"30s\"\n      timeout  = \"3s\"\n    }\n  }\n\n  resources {\n    cpu    = 500\n    memory = 64\n    network {\n      mbits = 20\n      port \"http\" { static = 9999 }\n      port \"ui\" { static = 9998 }\n      port \"grpc\" { static = 8888 }\n    }\n  }\n\n}\n\n}\n}\n`\nThat is to say unless something in my configuration above is incorrect? Can I provide you with more information?. > Ah, I need to confirm but I am pretty sure that the urlprefix (i.e. /grpc-server) isn't supported by the grpc proxy.\n\nI don't know whether it is possible to add support for it.\n\nThat seems to be the opposite of what is shown on the Fabio Quickstart page (https://fabiolb.net/quickstart/) Where my use case would be the second from the top (see the list below), having a service specific route not pointing to a specific rpc.\n\nurlprefix-/my.service/Method proto=grpc                      # method specific route\nurlprefix-/my.service proto=grpc                             # service specific route\nurlprefix-/my.service proto=grpcs                            # TLS upstream\nurlprefix-/my.service proto=grpcs grpcservername=my.service  # TLS upstream with servername \noverride\nurlprefix-/my.service proto=grpcs tlsskipverify=true         # TLS upstream and self-signed cert\n\nAm I understanding you correctly in that this doesn't work, or are you referring to something else when you say that the url prefix \"/grpcserver\" isn't supported? Is \"my.service\" supposed to be something specific in the examples above?. Sorry for a delayed reply. I've been trying this out a bit, but I'm still not getting my streams through to the grpc server. I added \"urlprefix-/protopkg/protoservice proto=grpc\" to my tags, and tried routing using service name and the catchall ''/\", but still nothing.\nUsing the urlprefix I'm targeting fabio.service.consul:8888/protopkg/protoservice\nI've set 8888 as the grpc listener port in fabio's nomad job as seen in my previous post, and the port is allocated to fabio as static.\nNot sure what to try next at this point?. > Late to the conversation but looking at the code examples provided above it doesn't look like you are using the correct separator for the package and service. You have /protopkg/protoservice/ and the example shows /foo.bar with an example package of foo and a service bar. I assume that should make your tag urlprefix-/protopkg.protoservice proto=grpc.\nI tried it with '.' as well, typoed it into my reply unfortunately. Is the route case sensitive?. This is still not working, I've set up my urlprefix as urlprefix-/protopkg.protoService proto=grpc and trying to stream to it at fabio.service.consul:8888/protopkg.protoService, but the grpc client still can't connect.\nCan I do some step-by-step verification to see that the grpc listener port is working to begin with, and then look further into why the grpc client isn't connecting?. I'm using this line to dial:\nc, err := grpc.Dial(grpcServerAddr, grpc.WithInsecure(), grpc.WithBackoffMaxDelay(5*time.Second))\nwhere grpcServerAddr is \"fabio.service.consul:8888\", but it's still not connecting.\nThere are no limitations in fabio as to what kind of communication is supported for grpc? I'm trying to do a bidirectional stream, is that a problem?\nA followup question to this is; how do I run two versions of the same grpc server with the same protobuf services with fabio, so that I'm able to send traffic deliberately to either one, v1 or v2? Just point to fabio.service.consul:8888 doesn't give me any control over which server I will reach?. All right! Finally got it to connect, you were right, the dial address needs to be EXACTLY \"fabio.service.consul:8888\". Even a trailing slash will prevent it from connecting, i.e. \"fabio.service.consul:8888/\" \nThis documentation needs to be updated, it's impossible to derive this from what is stated in the docs.\nI'm really in need of an answer to my other question though which was how I can explicitly route traffic to a certain version of a service. Say I have service A with version 1 and 2 running side-by-side in blue/green or canary deployment, how can I route one client to v2 and keep the rest on v1 (i.e. I don't want to route percentages, I want to be able to point a certain client at the newer version of the service)?\nDoes this require url prefixes support? Like:\nfabio.service.consul:8888/v1/\nfabio.service.consul:8888/v2/\nOr can it be done some other way?. Any input to my last question here?. > Sorry @tommyalatalo I've been on vacation this past week.\n\nYeah, it seems like the docs need updating. I'll hopefully get to it this week.\nIn terms of your question about prefixes, whilst they aren't currently supported, we essentially need to hook up the path stripping. In theory it might already be supported (if you add the strip=/v1 option to the tag), I've just never tested it.\nI need to test to see how this works. Hopefully I will get to it soon.\n\nI tried some path stripping with grpc now, and it doesn't seem to work.\nI'm guessing implementing path stripping for grpc should be very similar to the http stripping, so how is hoping this would be almost a cut-and-paste update for the grpc side of things?\nReally appreciate your help and support!. @andyroyle How long do you think it would be until you could get some path stripping implemented? \nDays, weeks, months?. @andyroyle By the way, I was thinking, is path stripping going to be enough to allow routing to different endpoints in this case?\nWon't it end up like this:\nfabio.service.consul:8888/v1/ strip=/v1 -> fabio.service.consul:8888/pkg.service\nfabio.service.consul:8888/v2/ strip=/v2 -> fabio.service.consul:8888/pkg.service\nBoth will end up at fabio.service.consul:8888 and grpc resoplver will add the protobuf service after the port, and both paths will end up at the same grpc server?\nIsn't it essentially required that the fabio grpc protocol supports path prefixes that actually route to different host:port combinations? The problem at the moment being that all grpc requests are served through \"fabio.service.consul:8888\"?\nSo that\nfabio.service.consul:8888/v1/ -> 10.10.10.10:1111 (grpc server version 1)\nfabio.service.consul:8888/v2/ -> 10.10.10.10:2222 (grpc server version 2)\nMaybe I'm misreading your last post, and you're actually saying that in order to do the above you need to support path stripping as well to complement the prefixes.. @andyroyle @leprechau \nHaving two separate proto services is not viable, can't have all devs creating duplicates of services for upgrade purposes, that would be incredibly error prone.\nBear with me if I'm not quite on the same wavelength as you guys, but what I gather is that this could be solved using TLS certified connections, how would that work? I'm looking at setting up TLS for our traffic in the future anyway.\nAlso curious about the host header, is it possible to use that with GRPC and add it to the requests for routing purposes? I have full control over the clients so if that would be a way forward I would be interested in that too.\nA thought that I had earlier, which might not be feasible at all, was that my particular issue could perhaps solvable by having the option to set up multiple listener ports for the same protocol, which would have unique routes. Say port 8888 could route to v1 of a service and port 7777 could route to v2. This is a bit ugly and the use cases for it in general probably pretty slim, so maybe leave it as just a thought.. I'm trying to set up TLS with SNI, but the docs are lacking a bit here, can you give an example of how to use this line:\nurlprefix-/ proto=grpcs grpcservername=my.service.hostname\nis this also supposed to be protopkg.protoService.hostname and what should the hostname be in this case? A consul dns address, or something else?. > the grpcservername option was added for use with TLS backends. Fabio connects to backends using <ip>:<port>, so if the certificate presented by your backend doesn't include an IP SAN, then you can set grpcservername to specify the serverNameOverride field in the tls config: https://github.com/fabiolb/fabio/blob/master/proxy/grpc_handler.go#L245\n\nAn example would be:\nurlprefix-/ proto=grpcs grpcservername=grpcapi.service.consul\n\nIs this the same as overriding SNI?\nAlso, will this work if terminating the TLS at fabio? Since fabio would hold the certificate which contains the common name of the host I'm trying to reach?\nEdit: Furthermore, if terminating TLS at fabio, should the backend service be set as using grpc or grpcs protocol in fabio? Do you have a more complete example of how GRPC TLS termination (incl SNI?) should be set up?. ",
    "mangy84": "Indeed, the documentation was updated but the version 1.5.10 doesn't have support for grpc. The commit for grpc support was made on master branch (the branch 1.5.10 doesn't contain this commit).. ",
    "lverba": "Nice feature, good to have it!. ",
    "suconghou": "so I need execute it as \nconsul kv put \"fabio/config\"  'route add srv1 / http://domain.com opts \"host=dst\" '\nis it right ?. ",
    "jonmorehouse": "I was digging through this, and it seems like the Target object could have a Modify method which accepts an http.Request object and modifies the request to its liking. In the case that we had more modifier tags, this could be quite useful\n. This needs refactoring, was just getting something working :smile: \n. Would love to hear thoughts on naming here. I'm not overly opinionated, I also considered urlmodifier-/strip-prefix and modifier-/strip\n. What do you think about a NewTarget method, which accepts the raw parameters and makes some decisions based upon which tags are specified?\n. ",
    "kneufeld": "I've only seen dst be an ip:port combo, not sure how clicking on a link has anything to do with XSS?. "
}