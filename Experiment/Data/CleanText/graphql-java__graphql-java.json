{
    "andimarek": "Thanks!\n. thanks\n. @hannesj just wanted to let you know that I fixed some minor issue in the git history with push force .. so don't be confused when you see different hashs. I'm sorry for that  ... a history rewrite should never happen again. Thanks again for using graphql-java and contributing!\n. @parallelcross Could you please try the latest development build '2015-08-01T00-17-47'? (How to include this in your project here: https://github.com/andimarek/graphql-java#development-build)\nI updated the dependency to antlr 4.5.1, which itself removed the unnecessary dependency to org.abego.treelayout. I hope this will fix your issue.\n. There seems to be a typo in your dependencies statement:\ngroovy\ndependencies {\n       compile 'com.graphql-java:graphql-java:2015-08-01T00-17-47'`\n}\nThere is a \"backtick character\" at the end of the line.\nThis should give you graphql-java, slf4j and the antlr-runtime  jar.\nYou need all three jar files to run graphql-java.  A missing antlr-runtime might explain your last Exception.\n. ok .... what error message do you get?\n. I just realised that you of course  also need mavenCentral() as repository.\nDo you have \n``` groovy\nrepositories {\n    mavenCentral()\n}\n```\nanywhere in your build file?\n. Cool ... thanks a lot for your feedback. I also updated the README.\nI will close this issue. Please open a new one, if you have any other problems/feedback.\n. Embarrassing mistake ... thanks for fixing this.\n. I think we could. But the built-in types are not in any way special. You can easily declare your own new Type:\n``` java\npublic static GraphQLScalarType GraphQLLong = new GraphQLScalarType(\"Long\", \"Long type\", new Coercing() {\n        @Override\n        public Object coerce(Object input) {\n            if (input instanceof String) {\n                return Long.parseLong((String) input);\n            } else if (input instanceof Long) {\n                return input;\n            } else {\n                throw new GraphQLException(\"\");\n            }\n        }\n    @Override\n    public Object coerceLiteral(Object input) {\n        if (!(input instanceof StringValue)) return null;\n        return Long.parseLong(((StringValue) input).getValue());\n    }\n});\n\n```\n. Thanks for taking your time and creating this PR, but there is an Issues with this approach:\nWe can't just add a new language element like LongValue. We want to conform to the spec and there is simply no literal for representing long values. The official way for new scalar types is to represent them as Strings.\nThis is done in the coerceLiteral method: Converting String to Long. So I would suggest I will add something like the code snippet I pasted here: https://github.com/andimarek/graphql-java/issues/6\nI hope this is ok for you and will fit your needs.\n. I added the type in this commit: https://github.com/andimarek/graphql-java/commit/948231fb92ea39c47ed639ba8ce44c8e8ea82412\n. I added a Bugfix. Could you please try it with latest version '2015-08-18T16-47-45'?\n. Hi,\nI'm not sure I understand your proposal: You want a DataFetcher on a Type? I don't know if this makes sense ... could you give an example?\nThanks\n. Ok ... I think I understand your proposal.\nThe problem with this change is, it might confuse more than it helps (Just my impression) \nThats because it's a little bit against the idea, that you just describe a type with newObject()... and not where this data comes from. This you have todo on a concrete field.\nSo I would like wait for more feedback on this one: If more people wants this, I will add it.\nBut thanks for taking your time to report it and make it clear with your last comment,\nAndi\n. @pli2014 Hi,\nthere is no batching strategy yet. But we have a PR, which is not merged yet. Maybe you could have a look at it and give some feedback if it would help you:\n49\n. @pli2014 The batching feature is now available in the latest dev build.\n. Your get Method must be public, because it implements a Interface Method, which are always public.\nSo please try this:\njava\nnew DataFetcher() {\n  @Override\npublic Object get(DataFetchingEnvironment environment) {\n    // some code returning an Object\n  }\n}\nThe example in the README makes the same mistake ... I will update it. \nThanks for reporting!\n. Could you provide more details? E.g. the exception stracktrace\nThe literal 10.0 is parsed as a float value, so I'm little bit unsure where this problem comes from.\nThanks\n. Hi @hannesj,\ncould you provide more details about this?\nThanks\n. @hannesj The problem should be fixed:  https://github.com/andimarek/graphql-java/commit/34145726d7a335ca3d70a84bad9abcdfe6e45af8 \nFloat accepts now also int as input\n. I'm not sure I understand this ... which serialization do you mean?\nThanks\n. ok thanks ... that makes it more clear. I will have a look at in detail.\nJust a quick thought: I'm not sure the problem is the coercion of  the string. Maybe the graphql schema is not correct: The cursor field should not be of type String, but maybe of type Connection? (I maybe totally wrong ;-) )\n. Thanks for the link ... these are indeed the details I have missed in the first prototype. It might take me a few days to look at in more detail .. sorry for the delay.\n. Yes,\nthe problem is indeed that the type of the cursor field is declared as String. So every Object is coerced into toString().\nProbably a custom scalar type might be the best solution, but as a quick fix I changed the toString of ConnectionCursor.\nDoes this for now solve you problem?\nThanks\n. Hi,\nhow does your schema looks like?\nRegards\n. Thx\n. Could you  give an example, which use-case this would solve? Thanks!\n. I'm sorry, but I think the implementation is correct: When id is notNull and you declare a variable as Nullable, the query is invalid. Because you could assign null to $id and then it would crash when executing the query.\nCan't you declare the variable as NonNull: m($id: String!) ?\n. I'm sorry that this has such a negative effect.\nI looked at it again and I think your root problem seems to be that the whole query is invalid. I didn't see this before and I fixed just recently a problem where an invalid query didn't raise any error.\nThe problem is the { id: $id }. You can't specify a dynamic field in graphql. So if you specify an alias for an field, the field must be a constant. For example id: myField. \n. No problem. \nI took your gist and changed the query argument (in the failing section) to Non-Null: ... m(\\$id : String!) ... Now it works.\nAnd like I said, I'm sorry, but I think this is correct: \n\"I'm sorry, but I think the implementation is correct: When id is notNull and you declare a variable as Nullable, the query is invalid. Because you could assign null to $id and then it would crash when executing the query.\"\nIs this helpful/possible for you to change the variable type?\n. Thx\n. I'm not sure I understand you completely, but you want to have access to the office argument, when fetching the person?\nI think you should model it in another way then, because depending on the something deeper in the graph is against the idea of graphql. If the office argument influences the person, it should be a person argument.\nI hope this helps. \nRegards,\nAndi\n. You have access to the user object via the source attribute of the DataFetchingEnvironment .\nThe user is resolved before the DataFetcher for the profilePic is called, so you can access the User in there.\nOr you could also fetch the User AND all possible profilePics in all supported sizes at once, but still you would need a simple DataFetcher to return only the desired size.\nAnd yes: If you really need or want only one DataFetcher with the User AND the one specific profilePic, you would need to move the argument for the size to the User. But then of course you loose the ability to select different sizes without knowing the User.\n. you're right ... thx\n. I'm sorry to hear that so much is unclear.\nBut you're right: To really understand the details you have to read the source code.\nI can't really promise anything when the documentation will be improved: I'm doing this is my free time and my resources are limited. \nBut thanks for raising awareness.\nTip: This is a more or less direct port the graphql JavaScript Implementation. So nearly every concept and some documentation about it can be found in here and here.\nAgain: I'm sorry that I can't give you a better answer at this time. Feel free to open a new Issue for specific questions.\nBest regards,\nAndi\n. I will let this Issue be open, as long as the documentation isnt't improved.\n. Yes, of course. Thanks for your help.\n. @danielkwinsor about your last comment in #89:\nMy personal philosophy for source code comments is very puristic: I add rarely javadoc comments. For example I don't think adding author infos is useful (use git for getting the history of the file)\nInstead I try to make the source code as readable as possible plus adding tests, which also document whats going on.\nI also differentiate between public classed and private implementation details: I think the javadoc for public classes should be improved (e.g. the GraphQL or Relay class). On the other hand implementation details should not be documented in the same way. Because they are subject to change and if you really want to know whats going on you should read the source-code. \n. @danielkwinsor Thanks for your feedback. \nI agree that some things are currently hard to understand and also that the documentation should be improved.\nThe current state of the documentation is simply the result of this being a private project, where I invest my free time. \nThis means I depend on others to improve the current situation:\nSo maybe you could create a PR to extend the README to answer exactly the questions which were hard to answer for yourself? That would be totally awesome.\nThanks!\n. we improved the overall documentation including javadoc quite a bit since this issue was created. \nTherefore I am closing it for now.\nPlease feel free to open specifc Issues for missing or unclear documentation.\nThanks. Thanks a lot for your PR and especially adding also a test!\nWhat I'm not so sure about is the fetchField in the builder. Don't you think it would be better just to set the DataFetcher instead having extra field? This also doesn't scale very well: Imagine we add a third or fourth provided DataFetcher. \nWhat do you think?\nThanks\n. Yes, you are right. Not having to specify the name twice is a good thing. I will merge this now. But probably I will change it to something more generic like your suggested \"DataFetcherStrategy\" field to make it more stable for other DataFetchers in the future.\nThanks again,\nAndi\n. Can you give an example request which is rejected?\nThanks\n. The problem is the declaration of the variable type: SpaceInviteInput[]!.\nAn array is declared as [type] in graphql. So you probably meant [SpaceInviteInput]!. But even this will not work (I think), because newRights is not declared as NonNull. \nSo you could just change the variable to [SpaceInviteInput] or change the schema, so that newRights is NotNull. Both ways should be fine.\nI'm currently looking into the problem, that SpaceInviteInput[]! is not reported as an error. This shouldn't be happen.\n. Hi,\nI improved the error handling in this commit: https://github.com/andimarek/graphql-java/commit/fb53067cc862c654046d555863093c67edf76afa\nSo now you get directly an error, when you try executing something like A[].\n. @weebl2000 Could you solve your problem? I would close in this case. Thanks\n. Thanks for this PR! \nI will comment on specific code issues.\n. Yes, this is the \"compare the names in equals\" version implementation of #85. \nI would suggest to add two tests for every type, to show that equals and hashCode are working as intended. \nAlso equals uses getName() while hashCode uses name directly. This I think should be changed.\nAnd I think it is only a first step because there might code which uses == to compare types instead equals.\n. I am closing this Issue: The main problem here is that a schema contains not only data but also logic (DataFetcher, TypeResolver). This is something we can't easily change for now, so we will not add equals/hashcode to them.. Thanks.\nAnd especially for the tests!\n. Hi,\nI added a test for a missing argument.\nhttps://github.com/andimarek/graphql-java/commit/1bc181089b5d8933bbb19cb6e1e09fd7576a7bb5#diff-3eca2508c3f86d5d839beca2e0e520faR132\nI get a ValidationError, so it seems to work.\nDid you mean this?\nThanks\n. With the latest version I don't get a ClassCasteException. But I get an validation error because the field \"defaultValue\" is not known. You can't query a defaultValue on a type, but on the args, so you can do this:\nquery IntrospectionQueryTypeQuery { __schema { queryType { fields { name args { name description defaultValue type { name kind ofType { name kind } } } } } } }\n. Thanks for this PR.\nI have a question: Shouldn't we do this also  for mutation? I think this is \"restricted\" in the same way currently ...\n. Thanks!\nIs this PR related to this one https://github.com/andimarek/graphql-java/pull/28 in your opinion?\nTo understand the use-case better: Do I understand this right, that you generate the schema automatically and sometimes you have for example a InterfaceType and a some  ObjectTypes implementing this Interface, but nobody is referencing the ObjectType, just the Interface?\n. ok ... I understand .... interesting approach to use TypeReference as default.\nI comment on some minor issues I thought could be improved, but nothing seriously.\n. Thanks \n. Quick Thought: I think have I excluded InputType on purpose, because TypeReferences are not always replaced with the real object ... currently you can't use them just everywhere (I think).\nI must look at it in detail.\n. Thanks a lot for fixing this!\n. We will finally try to tackle this issue in the next release. See #283. I am closing this issue: the issue will be handled in #324 . I'm closing this issue, because as @tberman mentioned the bug is fixed and I don't think that adding a specific query should be part of the library.\nAlso the solution of just copying the string from graphql-js is I think a very simple solution currently. \n. Thanks!\n. Hi,\nif you have a patch, I would recommend that you open a Pull Request.\nThanks\n. This should be solved with the latest dev build.\n. @lelong71 Thanks for this info. Please try again with the latest version, this should be fixed by now.\n. The described problem is solved in the latest dev build. I solved it slightly different: https://github.com/andimarek/graphql-java/blob/f56171f47a050bd1f35ce7d28109c7ff685a3ccf/src/main/java/graphql/execution/ValuesResolver.java#L66 \nBecause this PR is now obsolete I'm closing it.\n. Yes, you are right ... it makes sense to release a version 1.3.\nI will try to do it around the next weekend.\nThanks for your input.\n. Is now released ... therefore I close this issue.\n. Thanks for fixing this!\n. I'm not sure, but looking over your example I think the reason is, that you don't return anything for \"profiles\". You should add a DataFetcher or staticValues for it.\n. Glad it works ... i'm closing the issue\n. Hi,\ncurrently Type-references are only resolved on Objects or Interfaces. This means that even when  we merge #34 you don't get the behaviour you want.\nAlso: When you look at the graphql spec about Input Objects (http://facebook.github.io/graphql/#sec-Input-Objects) they say they created Input Objects to not allow circular references. So I'm currently not sure it's even possible what you want.\nCould you give an example of your schema? I think this would really help.\nThanks\n. I think InputObject was not meant to be used in this way. \nFor your first example: User referencing another User. This could be cyclic, but you can't express that in a literal. I think that's exactly the type of case they wanted to avoid.\n. Also: Yes, it's kind of RPC style.\n. Thanks for this PR!\nDo I understand this correct that this is BugFix and currently input types are not collected when they are not top level input types in the Schema?\n. Thanks .... I merge it.\n. Thanks a lot for this PR!\nI will get back to you, when I looked at it in detail.\n. Thanks again for this amazing PR. \nOne formal thing about the tests: We are using Spock as the test framework. Is it possible for you to rewrite the tests using Spock?\nI'm sorry for that, but I really would like to avoid having two different test framework in this small projects .. I hope you understand.\nIf you need any help with Spock, please ask.\nAnother question: You are already using this code in production (or production like environment)?\n. Thanks @cardinalraven for your awesome work. I merged your PR into master. Especially for also writing docs and changing the tests into spock. \nThanks!\n. Just a tip: You might wanna configure your email address ... see screenshot:\n\n. Now its fine :-)\n. Thanks for reporting this error.\nIn general I would recommend that you use the latest development jar. \nIf that is not possible you will probably have to wait another few weeks. I will try to release a new version in this year.\nI'm closing this issue because the bug is already fixed.\n. As I currently understand it, the only thing this library could do, is to call a provided function which basically says: Register this subscription. The main work how the the data is then delivered, is out of scope and app depended. Is this your expectation?\nSo yes ... I think Subscriptions will be added. But currently subscriptions are not in the graphql spec.\n. Hi,\nI just added a small change to at least support the subscriptionType field in the query: https://github.com/andimarek/graphql-java/commit/3a96047a25c46db27f4c1743755215c0982b35ab\nCould you give it try with the latest build to see if it solved your problem?\nThanks\n. @dbryand Can you confirm that this issue is resolved? Thanks\n. @hbeaufils Thanks for this info. I'm closing this issue.\n. Hi,\nfor an example how to build an http endpoint which executes graphql requests have a look at this:\nhttps://github.com/andimarek/todomvc-relay-java/blob/master/src/main/java/todomvc/GraphQLController.java\nSchema Introspection in general is already available. But how you call it, http or something else, is totally up to you and not in the scope of this library.\nI hope that helps.\nRegards,\nAndi\n. Ok ...I misunderstood you ... yes, this is not possible currently...you're right.\nI would like to understand your use case: Why do you need a remote schema to execute a query?\n. Hi,\nof course the schema could be build in another way. But generating from classes seems not perfect. For example where to do you specify such things as the documentation. Also it's not always the case that you have a class for every GraphQLObject or GraphQLInterface.\nIn general I don't plan to add another schema definition soon, but I'm open for any idea/contributions.\nAndi\n. List is not a valid type. I think you want \"[String]\".\n. Hi,\nI think you solution is the preferred (or currently the only) way. If you want to access some contextual data you access the source object  and the previous datafetcher is responsible to provide the informations you want to access.\n. ExecutionStrategy is a non \"public\" class, so I don't think it should become a part of the API.\nBut yes: The naming might be a bit confusing. \nI'm also interested: You changed it in you fork. What part of the ExecutionStrategy are you using. Maybe we can add this to the instead the DataFetchingEnvironment instead the whole object to support your use case.\n. @FernsPaanakker I'm sorry and don't want to be rude, but could you please edit your last comment and format the code properly? It's really not readable. Thanks.\n. I merged the PR ... thanks again!\n. @xuzb The AST Node FloatValue is using BigDecimal, but scalars.GraphQLFloat is using Float.\nSo I think @nikolajosipovic is right, it should also support double (or only double, I'm not sure)\n. I changed the implementation of GraphQLFloat to return double instead float to comply with the spec:\nhttps://github.com/andimarek/graphql-java/commit/3062e2b48503ec02c9e2364d4c063baa798352a4\nWhat do you think? @nikolajosipovic \n. @nikolajosipovic No problem ... I'm closing this Issue now.\n. Thanks for your PR ... looks fine to me ... I merge it now.\n. No there is none yet. \nDo you personally (or your company) need one?\n. @trackzer0 I understand and appreciate any help. I will look into that and try to find a solution.\n. Thanks everybody for your interest to contribute ... I really would like to make it possible.\nTo help moving forward could you please post/reference an acceptable CLA? I don't want to maintain multiple CLAs.\nAlso: The CLA would be signed with me personally. This is a private project with no organization/company behind it. Is this ok for you all? \n@trackzer0 @mduarte @okorz001 @drkarl \n. closing it for now: we don't currently plan to add a cla to this project. If we get more feedback that it is needed, we will reconsider. . Thanks for your PR!\nDue to recent changes which caused merge problems I decided to pull your changes by hand instead of merging. (It was simply easier)\nPlease have a  look at: https://github.com/andimarek/graphql-java/commit/8d7e3f359a518ed40f258681c2d20b2888017e60 \nThanks!\n. Thanks ... I merged your PR and did some refactoring and added a test ... See: https://github.com/andimarek/graphql-java/commit/e10e5244ba3f8b83953a537e3bffbab14d78b2a7\n. Hi,\ncould you please create a small example of what you mean? Or maybe past the stacktrace of the exception you mentioned? \nThis would be really helpful.\nThanks!\n. Thanks for the explanation ... this makes it clear. After having a quick look I think the  problem is the serialize function of boolean: It should return null and not throwing exceptions. And then \nthis code: https://github.com/andimarek/graphql-java/blob/master/src/main/java/graphql/execution/ValuesResolver.java#L85 will use the default value.\n. You are right: This bug affected other scalars too. It should be fixed with this commit: https://github.com/andimarek/graphql-java/commit/43d5f57abe49a16349676aa9c144ce1fa9670187 \n. I think this solves your problem:\nhttps://github.com/andimarek/graphql-java#recursive-type-references\n. Closes, because solved already by TypeReferences. But thanks for creating a PR!\n. Thanks!\nThe relay part is not the nicest thing currently ... so thanks for improving that.\n. Thanks a lot for documenting this.\n. Please try again with the latest version ... this should be fixed now.\n. Closing, because it should be fixed. Please reopen if it's not working for you.\n. Pleas try again with latest master ... this should be fixed now.\n. @lelong71 @kristofdepypere  Please try again with the latest build.\n. @lelong71 @kristofdepypere This should be fixed now. Please try the latest version. \n. probably related to #427 . Closing this issue, because this is changed/fixed in the upcoming release:\n\nomitting hobbies completely results in a map without a key hobbies\nhobbies: null results in a map containing a value null for hobbies\nhobbies: [null] results in a map containing a List with one value null for hobbies. Hi,\n\nI could imagine that a time limit or a time tracking mechanism could be useful, but probably only for some small use-cases. And to be honest I will not have the time to implement it. \nBut I would be happy to give you feedback if you want to develop it youself.\nThanks.\n. Hi,\nwhat do you mean with deserialize it? \nThanks\n. closing it.\nI don't think it is wise to make it work for Jackson: Jackson is flexible enough to handle it with additional config.. Hi,\ncould you please be more specific and maybe post a example?\nThanks\n. Thanks a lot for your PR.\nBut I decided to solve a bit different than in your PR and I also wanted to add some test. So unfortunately this PR is obsolete and I'm closing it now.\n. Thanks for this PR and thanks for your effort.\nAbout supporting Java 1.6 in general: I'm thinking about it now for some time I don't really now yet, if we should do this. Because even Java 7 is EOL, and I would rather to prefer to switch to Java 8 in the near future.\nBut of course there are still projects out there which use Java 1.6 (or even older).\nI created a entry in the mailing-list to gather some feedback: https://groups.google.com/forum/#!topic/graphql-java/iCCN2T1RgyI \nAbout this PR specifically: I think the second the second commit doesn't belong in this change and did break the builds.\nThanks,\nAndi\n. This is already discussed here: #24 \n. Hi,\nno I don't think so: By Java convention the getter for a boolean is named is<PropertName> ... so isIsSelected is correct.\nYou might wanna change the field to just selected.\n. Thanks for fixing this!\n. The graphql schema was designed to be based on the principle that for each type there is exactly one Java Instance representing this type. That's the reason the ckecks are using reference equality. This is just simpler.\nOf course we could change that, but I am not sure about the overall consequences.\n. @yrashk Not sure about how to implement it best: Of course just checking names is enough, but I fear unclear side-effects or bugs, when it is not fully checked. Therefore I would say it should be a real deep equal check.\n. I was just thinking: You have a two different objects with the same name but different properties: And object 1 is used for validation and object 2 is used for executing. This is very unfortunate and we should try to avoid such a scenario.\n. I would like to tackle this issue, either by closing or implementing some kind of equally check:\nThinking about the java classes involved I see one major problem: the data fetcher. This is a class which is only equal by reference ... nothing else makes sense, because it is logic.\nThis means that a GraphQLFieldDefinition can't have any deep equal check and should not have a name equals check either because of the data fetcher. \nThis is somehow unfortunate I must say and I am not really happy with it.. closing it, because we will not implement equals/hashcode for Types, because they contain DataFetcher and TypeResolver.. This is a bug: I recently changed the impl for GraphQLFloat to return doubles to match the spec: https://github.com/andimarek/graphql-java/commit/3062e2b48503ec02c9e2364d4c063baa798352a4 \nBut the literal is currently still interpreted as float .. this needs to be changed to double.\n. This should be now fixed with this commit: https://github.com/andimarek/graphql-java/commit/113a9d01891084649f144c6fc5980c5d5d55feb6 \n. @pt-achang Thanks for your effort. I decided to merge it. So please test it with the newest build and  open a new Issue if you encounter any problems.\nThanks.\n. Hi,\nyes, I would also think it would be good to fail early. Would you willing to create a PR for that?\nThanks\n. This is implemented by #102 \n. Thanks for this RP and I really appreciate it a lot that you are willing to improve graphql-java.\nBut unfortunately I will not merge this PR: Imho almost all of this auto generated javadoc comments have no value at all. They are even worse than having no JavaDoc, because they just clutter the source code with useless informations.\nThat said, I'm not against javadoc in general, and I'm aware that it would be nice to have more documentation, but not in this way.\nI would recommend to add specific manual written documentation to some classes/methods if you are still willing to help.\nAgain: I'm sorry that you invested your time and I know that it's never nice to have a PR rejected. \nThanks,\nAndi\n. I'm closing this PR, because it will not get merged. Let's discuss general javadoc questions here: #24 \n. Hi,\nI'm sorry, but I have no plan currently to add xml schema configuration.\nAndi\n. Closing, because nothing todo here currently.\n. @fredrik-hultin Thanks for your PR. I commented on some specific aspects in the commit (including the versioning, thanks @aschrijver for pinging)\n. Thanks @okorz001 for answering: I would suggest the same. \n@edsal2 I'm closing this issue. If you have any more questions about how to use graphql-java, please consider posting it on the mailing-list (https://groups.google.com/forum/#!forum/graphql-java).\n. The exception is not pretty, but I think it is correct not to parse such big values:\nAccording to the spec Integers which are too big should raise errors:\nhttp://facebook.github.io/graphql/#sec-Int\nIf you wanna use Long Values, you can write them down as Strings.\nI hope this helps. \n. This is solved by #94 and https://github.com/andimarek/graphql-java/commit/aabed3ae8f08550740f58b1f83c727ed24630437\n. I don't think this is the right way: The graphql language only supports Integers on the language level. And this library aims to conform to that.\nTo quote the spec:\n\nNumeric integer values larger than 32\u2010bit should either use String or a custom\u2010defined Scalar type, as not all platforms and transports support encoding integer numbers larger than 32\u2010bit.\n\nSee also this Issue: https://github.com/facebook/graphql/issues/73\n. You have a point here. I don't think this should work, but I maybe wrong. To clarify this I asked for help: https://github.com/facebook/graphql/issues/73#issuecomment-190310810 \n. You were right (https://github.com/facebook/graphql/issues/73#issuecomment-190322457). This means graphql-java must be changed to support this.\n. I don't think this is a problem: Creating BigIntegers  is the right thing todo.\n. This is merged now. Thanks @okorz001 \n. @oembedler is right: See http://facebook.github.io/graphql/#sec-Evaluating-operations\n\nIf the operation is a mutation, the result of the operation is the result of evaluating the mutation\u2019s top level selection set on the \u201cMutation Root\u201d object. This selection set should be evaluated serially.\n. Long is now supported, see #94.\n. Thanks for this PR. I understand why you want to change this. But you didn't change any code using this Exception. I'm curious: Is this for a 3rd-party project? \n. Thanks .. I'm going to merge this.\n. Thanks!\n. Thanks a lot for this PR. Looks good.\n. Thanks a lot. \n. I am not sure about this change: When we convert a Number to Int we might loose something. (e.g. 3,14 -> 3) \n\nWhat do you think? (See http://facebook.github.io/graphql/#sec-Int)\n. You can do this with the GraphQLTypeReference class: https://github.com/andimarek/graphql-java#recursive-type-references \n. A schema.json is generated as a result of an introspection query against a server. The query can be found here: https://github.com/graphql/graphql-js/blob/master/src/utilities/introspectionQuery.js\n. No ... this schema.json it totally out of scope of the responsibility of graphql-java. How and when you generate it is up to you.\nPlease consider asking those question in the future at the mailing-list (https://groups.google.com/forum/#!forum/graphql-java): This is the better for this general how-to-use problems.\nThanks\nAndi\n. Thanks. I added a related project section: https://github.com/andimarek/graphql-java#related-projects\n. @pli2014  as mentioned you can access the friend context via getSource: It contains the resolved value for queryMyFriends.\nI am closing that for now: Please reopen it, if it still a problem for you. Thank you.\n. Thanks for this PR!\nIs this case specified somewhere (by Relay) how this should be handled? I mean is this even \"legal\" that the number of edges is changed?\n. @dalenavi It took some time to merge it, but is is finally it. :-) Thanks. Thanks for this PR. You are right: This should be changed. I'm merging this.\n. I don't think null is a valid value in GraphQL (see http://facebook.github.io/graphql/#sec-Types.Non-Null).\nWhat do you think?\nThanks\n. closing because resolved. Thanks!\n. In the resolved schema there should no TypeReference left. If this is not the case, it's definitely a bug.\n. @yrashk I don't think we need to go \"deeper\" if we visit every type (at least that was the idea)\n. Thanks.\n. Thanks\n. Thanks.\n. A direct jackson dependency is not an option, imho: We should add only dependencies we really need or want.\n. Thanks for your feedback.\nYou are right: While we state graphql-java is written in Java 6 and we try to support it, the current CI task doesn't  compile with 6, but rather 7. We need not fix that or be more clear how we support Java 6.\nI also updated the old forum question that the PR was merged.\n. @okorz001 It is automatically build with jdk7, but with source and target set to 6. It is not perfect, but when it successfully builds you can use it with Java6, unless we have used some jdk7 library function, which didn't exist in 6. \nJust to make it clear: I am also not happy with the current solution: We need to build with it Java6 (or drop Java6 support). But travis doesn't support jdk6 out of the box anymore, this means we need to put more work into this.\n. Please have a look at #145. \nThe problem with building it with a jdk6 is caused by limitations and bugs from the compiler. The solution is to build it with java7 or java8. #145 ensures that it is fully compatible with java6, because it uses the java runtime of 6.\n. Hi @aschrijver: I am closing this Issue, because it seems there is nothing left to. Thanks.\n. Closing this issue, because it is more than a year old. \nBut as a general info: we are supporting (or trying to do so) the latest graphql version (Oct 2016) and some additional features (IDL, subscriptions). \nBut for example null literal support is currently still missing, which will be added soon and we can't  be 100% sure to support all aspects of the spec, because there are no automated spec tests. (It is a manual process to read the spec and make sure we support everything). Please have a look at #145. \nThe problem with building it with a jdk6 is caused by limitations and bugs from the compiler. The solution is to build it with java7 or java8. #145 ensures that it is fully compatible with java6, because it uses the java runtime of 6.\n. @aschrijver Thanks for the PR. \nI would prefer to split it up in several PRs: I think it mixes too much different aspects.\nThe CoC is placed on purpose so high in the README because I want people to be aware that we have it before they open an issue or create a PR.\n. Hi,\nmaybe you can create a PR for that change? That would be great.\nThanks\n. Thanks a lot!\n. closing because as mentioned it is out of scope for this library to hande file uploads. @0x6e6562 always happy to improve the documentation. Could you create a PR to document it? that would be great!. @devtomk @SebastianWjertzoch variables are fully supported ... your query is wrong.\nyou have to declare each variable with type ...  for example:\ngraphql\nquery nameOfTheQuery($nameOfTheVariable: Int) { \n  foo(someArgument: $nameOfTheVariable) \n}. @SebastianWjertzoch as mentioned above:  you have to declare the variable. \nyou query is \ngraphql\nquery { person(id: $personId) { id, name } }\nbut it is missing the declaration of the variable. It should like this:\ngraphql\nquery myQuery($personId: Int) { person(id: $personId) { id, name } }\nI hope this helps. well ... if you wanna use a variable you have to declare the variable. \nthe query you mention works fine, because you don't use a variable, hence you don't have to declare it.. @weebl2000 Did you figure it out or is it still not working?. @weebl2000 thank you. @weebl2000 closing it for now, it will be reopened if the problem still exists. Thanks!\n. @trevor-morris Thank you for reporting. We will look at it.. Hi @mkrouwer-lv,\nI can't reproduce it. It  works fine as far as I can tell.\nDo you still have this problem? \n. closing it for now, will be reopened if the problem still exists. Closing this now because the initial problem was solved and nobody reported something similar so far. . This is fixed with #455 . Hi @aschrijver,\nbecause of personal reasons I am currently not really maintaining this project. And I can't say when (or even if) this will change. The second maintainer is @yrashk, but he is also not very active currently. \nThe CoC is not up to discussion, but I am open for every process which will improve the current situation. But it is true, that currently it is not clear that we would welcome more maintainers or how to become one.\nBut I don't intent to be a strong gatekeeper in that sense: If somebody has contributed a PR and is willing to be a maintainer and to follow the CoC I am happy to give that person commit rights.  (That's basically how @yrashk became a maintainer)\nRegards,\nAndi\n. @aschrijver I added a note to make clear that we are looking for help.\n@kaqqao If Scala is an option I can recommend Sangria. I know the maintainer and he is very active and Sangria has some very interesting advanced features.\n. @aschrijver I am closing this Issue because I think we addressed your initial questions.\n. closing for now, because inactivity for a long time. This Is solved by #398 . @aschrijver Now that we support IDL schema definitions, would directives solve your Problem?\nNot saying we will not add more support for custom metadata, I am just curios. \nI agree with @kaqqao: Not being implemented in the reference-implementation is no a reason to not add it. We will add what makes sense.. I don't think so: The whole project is under MIT license, but some parts are of course contributed by different people.\n. I asked how the people feel about closing the group: https://groups.google.com/d/msg/graphql-java/nEoT6lhZFXQ/NUPisHrUAQAJ\nIf there are no strong objections I will close it.\n. Removed the link to google group: asked to open an Issue instead: https://github.com/graphql-java/graphql-java/commit/5b892a67bae53e7e74f1f35d252c75d60182f981. sorry, this is not planned currently: we just have enough other things to do. I hope you understand.\nBut if you would create PR, we will of course consider it.\nThanks!. closed: see #28 . this is done with #122 merged. It think this Issue solved by #387, isnt' it?  @pcarrier @bbakerman . solved by #387 . closing it for now: I like the general idea, but we will not add such a info for now. Hopefully later.. ~~Currently our context argument is presented as root to DataFetchers. This is confusing and I would be happy to clear it up.~~ This is not true: context is passed as context.. This will not come in 3.0.0, added to 4.0.0.. This is the proposal:\n\nWe will add a root object: This will be presented as root to DataFetchers\nroot will be the source object for the first query\n\nThis is a breaking change.. PR: #456 . the PR is merged and will be in the next release. @dminkovsky looks good to me. I will merge it.\n. thanks a lot.. @Jimexist Is this solved with https://github.com/graphql-java/graphql-java/pull/361 ?. is already done. Is this still relevant @bbakerman? . this solved by #353. @bbakerman @corydolphin @dllx Is this issue solved with #387 merged?. solved by #387 . @bmsantos The reason we still support Java 6 is that a lot of companies are still using it, even if there are no updates for it.. FYI: We are discussing an upgrade to Java 8: https://github.com/graphql-java/graphql-java/issues/338. fyi: we will look at that topic for version 4. Please have a look at #324  for the overall disucssion. closing it, it will not get merged: we solved the different aspects of this PR in the meantime and we we just merged #380 as a first step in supporting async execution.\nThanks a lot @dminkovsky \n. Because we are planning for a breaking change release I suggest that we use that to try to make it more clear what api vs internal is.\nBut I think moving everything is not acceptable imho. Breaking stuff should be limited to what we think is really necessary. Annotating seems fine.. I like the idea to add two annotations @PublicApi and @InternalApi for example.. First shot: #411. we added annotations in #411 ...closing it therefore now: we will add the annotations as we go.. As suggested we brought the mentioned project into the org: https://github.com/graphql-java/graphql-spring-boot . I would like to see some kind of solution for malicious queries in the next version: the question what to do about it comes up all the time and I think graphql-java needs to have some kind of answer to that.. this is now solved with #655: based on query depth and/or query complexity you can now prevent the execution of certain queries. . @ersimont Could you create a PR for that? That would be great ... thanks!. @bbakerman could you have a look at this PR and how it relates to #499 ? thanks. closing the issue as suggested by @bbakerman . we will not remove the ErrorType: I think it is quite useful and as @tklovett pointed out it is spec conform.. That we produce an Error instead of null is fixed with #455 (and further modified with  #487 ). Please have a look at #380: This is the first PR we will merge.. We will use this issue to track the overall topic: PR #380 is just first step. this is done with #590: it will be included in the next release . Thanks @hepin1989 for offering your help.\nBut I agree with @bbakerman: They are already written and we will not reimplement them. Therefore I am closing the issue. . We are discussing the general Java 8 topic here: https://github.com/graphql-java/graphql-java/issues/338. The initial motivator for breaking up is now obsolete: We switched to Java 8.\n@dminkovsky Do you think it should still be done?\nThe most obvious candidate is probably the relay package imho: this should really live in its own module. ( @aschrijver ). I am closing this issue, because we don't have a todo here right now: Like @bbakerman said it is currently out of scope.. I was the one who initially decided to support Java 7 and then merged a PR to downgrade to Java 6, because there is not really a big difference between 6 and 7 (on the language level).\nBut my initial goal was never to support always 2 older versions, only one.\nJava 9 will be released soon (in a few months) so I think the time to change to Java 8 is now (or very soon.)\n. We decided to go with Java 8 in the next release.\nVersion 2.4.0 is now out and  we will switch to java 8 soon on master for the next release (version 3).\nThanks everybody for the input.. Yes, this means you need at least Java 8 for version 3. \nI am sorry to hear that you can't switch to Java 8 any time soon, but we decided to go with Java 8 after gathering as much input as we could.\nPlease consider that Java 7 is no longer updated since April 2015 and Java 9 is out in a few months. This means we will support the latest two version of Java (8+9) with the new major release.. Here is the switch to Java 8: https://github.com/graphql-java/graphql-java/issues/359. @GrigoryPtashko \nAgain, I am sorry that you will not be able to run the latest graphql-java version. But we will not switch back Java 7 and we will not support Java 7 (except maybe bugfixes for 2.4.x).\nThis project (as many OSS) is based on voluntary work: nobody earns money with it and we all do this in our free time. We simply can't afford investing any real time in keeping it Java 7 compatible. \nIf your company can't switch to Java 8, but still wants to use graphql-java I recommend to fork it and maintain a compatible fork.\n. Closing, because nothing to do here. \n@satishrajgure Please reopen or create a new Issue if you still have problems. Thanks!\n. reference to the javadoc page is removed now ... we ill provide another form of documentation . @bbakerman Could you update you PR? Thanks!. @bbakerman I think it would be interesting how other implementations handle that. Do you have any info about that?. @vaant Thanks for this PR. \nHow does this PR relate to https://github.com/facebook/graphql/pull/267 ?. @vaant Would you mind giving us the right to modify the PR (https://help.github.com/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork/) ? We wanna add some documentation for example before we merge it.. @vaant thanks a lot!. Done with this commit: https://github.com/graphql-java/graphql-java/commit/3abfdd7f830e76b9a618c4bd351647b300b5dac4. Hi,\nthanks for the PR.\nIt seems like you also reformatted quite a few things: Could you please change it so that it only changes the Base64 related stuff?\nThanks!. closed ...see PR . Hi,\nthanks for your PR.\nIt seems like you already toke advantage of Java 8: Could you create a separate PR for these changes to make it more clean?\nAbout the change: Why making schema util static? \nThanks!. @Jimexist The problem with static calls ist that you can't mock it easily and it is in general a very \"strong\" dependency. \nTherefore I never use static methods anymore, except very very simple methods, even when I call the class *Util.\nAnd SchemaUtil is definitely not simple, there I prefer to keep it a \"real\" class.\n. I am closing this PR, because it will not get merged. \nI know that this is to some degree a matter of taste, but based on my experience I avoid static methods as much as I can, except maybe very very simple little helper methods. \nIt is simply to dangerous to have such a strong, not mockable dependency, which is also somehow \"hidden\" if you use static imports. It never ends well in the long-term. \nBut thanks @Jimexist for the PR and your help!. Nice ... thank you.. thans. I am not sure about such a brute force method: Using the diamond operator (for generics) for example was straight forward, but as you said: it is not always clear that you should use a lambda, even if it is possible.. @kaqqao Please add the default implementation again: We are on Java 8 now and if that helps not breaking stuff, we will take it.\nBecause changing such a central interface we should avoid almost always, I prefer adding a better alternative side by side.\nThanks!. @kaqqao @bbakerman I would try to avoid such a big breaking change: TypeResolver is probably implemented quite often. \nMaybe we could subclass TypeResolver and therefore detect if somebody is using the new resolve method or the old? Not sure this is a great idea though.\n. @kaqqao Thanks ... this goes in the direction I would prefer. But do we need the new method in TypeResolver with the default Implementation? This seems confusing to be honest.. @hepin1989 Could you please open an extra issue for that? We should not mix it with this PR. \nYou could also implement it ... that would be great. :-). @hepin1989 Oh ... I am sorry .. I misread your comment. \n@bbakerman What do you think about that?\n. @bbakerman What do you think about introducing a Comment class as suggested by @hepin1989 ? I am thinking about avoiding a breaking change in the future, if we need more informations than just the content.. @bbakerman about the lost comment: Is this the same behaviour as in the reference impl? . @opshubdata As @bbakerman mentioned you can't have to types with the same name: but you used attributes1 two times. We will improve the error message, but this will not fix your problem: you have to use unique type names.. @ronaldborman Thanks for reporting it.\nWould you mind creating a PR? That would be great.. thanks!. merged PR. Thanks!. As discussed, we will do it in version 4. looks good for me as a first step.. @kaqqao I agree. We should use async everywhere imho.. @hepin1989 we decided to use CompletableFuture everywhere for now, rather than the interface. @stevehu There will be no 2.5.0: We are already using Java 8 and did other breaking changes on master, so there can't be a 2.5.0. You have to wait for 3.0.0, sorry.\nCheers,\nAndi. This is solved by #386 and will be included in 3.0.0. @Jimexist I don't think we should make it dry, just because dry is often a good thing. We should tackle specific issues, when we encounter them.. @bbakerman @kaqqao This is a breaking change, right? \nI remember some discussion using java 8 default implementations to avoid a breaking change, but I can't find it anymore. \nThanks!. Ping @kaqqao (author of PR #172). @bbakerman @dminkovsky \nI don't think this is a too big change and the migration is straight forward and on the other side we really simplify the API. We already had a question about it: https://github.com/graphql-java/graphql-java/issues/382. @kaqqao Thanks for your input!\nI think you have a point there: I must agree that I don't like this part either:\njava\npublic List<GraphQLInterfaceType> getInterfaces() {\n        if (this.interfaces == null) {\n            return this.tmpInterfaces\n                    .stream()\n                    .filter(TypeOrReference::isType)\n                    .map(TypeOrReference::getType)\n                    .collect(Collectors.toList());\n        }\n          return new ArrayList<>(interfaces);                \n}\nI will definitely think about it more, before it will get merged.\nAbout the type safety part: I think the current implementation doesn't provide any, even if it looks like it:  GraphQLObject.reference(\"foo\") returns a GraphQLObject instance, but the resolved object could be something totally different. I wanted to tackle this problem in a separate PR.  \n. @kaqqao After thinking about it more I changed it so that getTypes() and getInterfaces() return now GraphQLTypeReferences before they are resolved. Nothing special filtering any more. \nThe downside now is that the return type of the Methods needed to be a more generic: e.g.GraphQLOutputType instead GraphQLInterface, because as already mentioned GraphQLTypeReference is not a GraphQLInterface.. @kaqqao Yes, I thought about redesigning the whole hierarchy, but my main focus was:\n\nbreak as little as possible\nstreamline the API\n\nI tried to redesign it in a better/cleaner way, but was just too much for now. So this is the best I came up with and I'm ok with it for now.\nThanks a lot for your feedback!\n. @bbakerman Documentation update is still missing ... after that I will merge it.. I agree with @bbakerman sounds good. \ud83d\udc4d . @bbakerman why is this a breaking change?. As an alternative we could create a specific PR, which will get merged after the new version is released. That might be better, because with an open PR we can just merge it without having to deal   with conflicts manually. . switched to readthedocs.io and they support different versions.. LGTM. @ieugen we already do that: every commit is built and available on bintray: https://github.com/graphql-java/graphql-java#development-build \n. @marcelalburg Could you please check the latest release? This should solve your problems. If not, please reopen this Issue. Thanks!. @bbakerman Changed it to @Internal add added @Documented.\nI am not really sure about the \"rules\" where to put these annotations: I added the on the class/interface, but not on every method. I quietly assume that every method is public or internal if the type itself is so. If this is not the case I added a extra annotation: for example the constructor is marked as internal, but the class itself is public.\n. It is a first start: we will add new annotations before 3.0.0. @kaseyreed thank you for the PR!. @bbakerman is there a graphql-js or spec reference?. @dh94 this features doesn't enforce any tight coupling between the schema and the implementation. Yes, you can use it to to build something like @bbakerman suggested: adding meta informations (via directives) for DataFetchers and TypeResolvers. But you could also use it to select the DataFetcher based on some naming of the types for example.\nIn general it is just a way to connect schema and Implementation when the schema is created. It gives you more flexibility, if you need it or prefer it. . merged. see #419 . @bbakerman Interesting discussion about directives in the IDL and for example how to make directives accessible: https://github.com/graphql/graphql-js/pull/746#issuecomment-301554231 . @acidbluebriggs master is not stable at all: it is the current development branch, so we can't promise anything.. @ieugen   this issue is not about our workflow, so please open a new one if you have a question or recommendation how we can improve things. thanks!. https://github.com/graphql-java/graphql-java/commit/126873af40ab39dc4af7fa941445ec4818e11dc6. done with #429 . maybe I was not clear: not used should not mean \"is not called\".\nI meant: If I register a DataFetcher for a field which doesn't exist, it should cause an Exception.. I agree with @bbakerman and therefore closing it. comment by @bbakerman:\nWe could extend the grammar to allow a NullValue to be captured in syntax eg:\nfield (arg : null)\nThe trick then would be how best to tell DataFetchers that the value is null literal versus not present. see #434 . done with https://github.com/graphql-java/graphql-java/commit/5eae29a4ee9aee316930b14b3acd10d5d2a9232a . Thanks!\n. @dh94 would you mind looking at the latest comment by @bbakerman? He has a good suggestion for  even better error messages ... thanks a lot. @dh94 yes, that would be great .... thanks!. done with https://github.com/graphql-java/graphql-java/commit/07e139732e70e680461fe425b79ae0306b72011e . hi @jamespedwards42,\nwe currently don't support multiple queries per execute: you have to make two calls.. This is a duplicate of #427 . ### The current behaviour is as following:\ngraphql\ntype query {\n  foo (bar: String): String\n  foo2 (bar: ComplexInput): String\n}\ninput ComplexInput {\n  complexKey: String\n}\n\nQuery foo(bar: \"test\") -> Arguments Map contains key \"bar\" with value \"test\".\n\nQuery foo -> Arguments Map contains key \"bar\" with value null.\n\n\nQuery foo2 ->  Arguments Map contains key \"bar\" with value null.\n\nQuery foo2(bar: {}) ->  Arguments Map contains key \"bar\" with value empty Map.\nQuery foo2(bar: {complexKey: \"complexValue\"}) ->  Arguments Map contains key \"bar\" with value a Map \"complexKey\" ->\"complexValue\"`.\n\nThe important aspect here ist that there is a difference between a \"first level argument\" (bar at foo), which is never \"not there\" and a key for a InputObject (complexKey at ComplexInput), which can be completely missing. \nNull values:\nWhen we allow explicit null values (foor(bar: null) or foo2(bar: {complexKey: null}) we must provide a way to distinguish it from other cases.  \nWhile it may enough for InputObject to transform null queries into a Map with \"complexKey\" -> null (Java null) this is not enough for direct arguments: e.g. foo can't be distinguished from foo(bar: null)  (both result in \"foo\" -> null)\nIt is important to note that we should not change the current behaviour: changing it would be a very subtle runtime change, which would probably lead to bugs.\n~~### Suggestion: Explicit Null Value~~ (See  https://github.com/graphql-java/graphql-java/pull/434#issuecomment-301383103 for the solution)\nI think the best solution without breaking anything is to add a GraphQLNull Value class, similar to this:\njava \nclass GraphQLNullValue {\n  private static final NULL = new GraphQLNullValue();\n  private GraphQLNullValue() {\n  }\n}\nThis would result in:\n\nQuery foo(bar: null) -> Arguments Map contains key \"bar\" with value GraphQLNullValue.NULL.\nQuery  foo2(bar: {complexKey: null}) -> Arguments Map contains a key \"bar\" with a Map \"complexKey:\" -> GraphQLNullValue.NULL\n\nThis way we would have a consistent way how we treat null arguments and it would be very explicit.\nBut: While this would be consistent and explicit, it would be a breaking change: suddenly there could be another value in the arguments Map, which is not of the expected type.\nI think we must make it optional (and turned off by default), if someone really wants to distinguish between null and not provided.\nUpdate: See  https://github.com/graphql-java/graphql-java/pull/434#issuecomment-301383103 for the solution. @kaqqao yes,\nI am also not totally happy with it, because if you allow null values, now you have to check for an additional type (is it == GraphQLNullValue.NULL).\nWhich is a breaking change, when I think about it: If someone upgrades graphql-java and allows null values, suddenly there can be a new value in the arguments Map, which can't be cast to the expected value (e.g. String or boolean).\n\ud83e\udd14  Not sure this is good. \n. @bbakerman I agree that it would be unnatural and in case of a complex InputObject your idea feels nice, but what about foo vs foo(bar: null) (my example from above)? How do you handle that?. and btw: I would prefer not to add that topic to 3.0.0 ... it is already a lot. We should aim for 4.0.0 for that change.. just so that we don't forget to think about that case:\nthis change also allows null in lists: This is a valid query:\ngraphql\nsomeField(value: [\"Value1\", null, \"Value3\"])\n. @kaqqao that is exactly the problem: It won't:\nfoo results in an argument map with \"bar\"-> null. This is the current behaviour: bar is never missing\nAs you can see there is no way to differentiate between foo and foo(bar: null): Under the constraint that we do not wan't to change the current behaviour both would result in \"foo\" -> null.. After talking with @bbakerman we came to the following solution:\nIt is the best for the future to map \"not provided\" to \"no key in map\" and null to a java map with a key and java null as value. This is very straight forward and intuitive.\nBut:\nAs mentioned before it breaks the current behaviour for foo (see my example above): After that change there would be no \"bar\" key in the arguments map.\nLegacy Option:\nThis is a very subtle change and it might break stuff. To adress that we will add a legacy arguments option in 4.0.0: this flag keeps the current behaviour and results in  the same arguments map for foo and foo(bar: null). \nThis option will be removed in version 5.\nThe special Enum case (https://github.com/graphql-java/graphql-java/pull/434#issuecomment-301370721) will just be documented.\n. @kaqqao I agree it is a very subtle change. But especially with these changes we try to be empathic with our users.. These tests document the current behaviour: https://github.com/graphql-java/graphql-java/commit/d8bfa00494548e2259a2851cd21a70a3519bf962\nThe first test (https://github.com/graphql-java/graphql-java/commit/d8bfa00494548e2259a2851cd21a70a3519bf962#diff-3eca2508c3f86d5d839beca2e0e520faR360) would break with the introduction of null values.\nThe more I think about, the more I am convinced that we don't need a legacy option flag: it is a very subtle change, but I believe it would not really break anything.  (\nTo break something the code would need to relay on the existing of a key in a map being null.\nBut the following would be still okay:\njava\nif (arguments.get(\"bar\") != null) ...\nfor a query {foo}.  @bbakerman . @kaqqao Yes, you right. Didn't want to neglect your comment ... just needed some time let that sink in.. @benmccann Thanks for this PR, but we migrated to readthedocs recently, so this is obsolete. Thanks again!. @dh94 thanks! @bbakerman should have a look at this :-). @ieugen closing it, because it seemed answered. . Hi,\nI am sorry, but graphql-java doesn't deal with tables or any persistence technology.\nYou will have to write a mutation which updates your tables. For more about Mutations have a look here: https://github.com/graphql-java/graphql-java#causing-mutation-during-execution . @ajmalsha I am sorry, but we can't help you with implementing the mutation: as I said graphql-java has nothing to do with how you save or update your data.\nFeel free to open a new issue if you have a specific question.\nThank you.. @emmulator yes, please update your java version: I had the same problem with an early java 8 build.. @emmulator no problem. Here is a test illustrating one of the current problems: https://github.com/graphql-java/graphql-java/commit/be44723b8e5fb1201a0bf9adc2ad575d372307fc\nparseLiteral of GraphQLInt throws an exception instead of returning null.. #455 fixes everything except NonNull Handling error (#438). closing it ... #438 is still open and will be handled there. @vojtechmasa Thanks for your kind words.\nUnfortunately you are right: IDL doesn't support descriptions currently.  You can have a look for the current discussion: https://github.com/facebook/graphql/pull/90 . @vojtechmasa I must correct myself: @bbakerman did an awesome job and already added descriptions based on the current discussion in the PR.\nyou can add descriptions via comments preceding the type:\n``` graphql\nthis is a description\ntype Foo {\n  # description for bar\n  bar: String\n} \n```\nBut be aware that this is not really final and might change in the future. You should also avoid empty lines in the comment, they will probably used to distinguish between a comment and a description:\n``` graphql\nthis is just a comment and will be ignored in the future but is currently added to the description\n\nthis is a description\ntype Foo {\n...\n}\n```\nThis is probably something we will change soon.\nDoes this help you?\n. See #449 . @vojtechmasa PR #449 is merged. this means after the next release we will honor empty lines as separation between comments and descriptions.\nand yes: we will also document it.\nI'm closing this now, because we answered your initial question. :-) . done with #465 . @bbakerman changed it so that we don't trim anything ... please have a look. I think providing values should not be part of the IDL, but it is on the same level as TypeResolver and DataFetcher. We should extend the RuntimeWiring to support such a mapping from Enum Name -> Enum Value.\nIs this similar to your EnumFactory @bbakerman ?\n. @vojtechmasa Please have a look at #458 ... this should solve this Issue.. closing it ... will be in the next release. @ajmalsha creating a schema with the Schema defintions language (also called IDL) is supported. Please have a look at the documentation for details: http://graphql-java.readthedocs.io/en/latest/schema.html. @ajmalsha this is not a fully working program: it is just a snippet to illustrate how to use it. For example the Imports are missing and the error message tells you that you need to import SchemaGenerator.  . yes, lets merge it. @bbakerman yes, thank you. I am not sure if we covered everything, but it looks really great in general.\nGood to merge! . @bbakerman great \ud83d\udc4d . https://repo1.maven.org/maven2/com/graphql-java/graphql-java/3.0.0/graphql-java-3.0.0-sources.jar contains all sources for the latest release. . @bbakerman I know it is a rather big PR, but I would appreciate if you could have a look. Thx . This solved #211 . @bbakerman I improved the javadoc . Your thoughts @bbakerman? . @bbakerman we must also do it on the SchemaPrinter: only emit schema ... if the root types are not named Query etc. solves #450 . Fixed in #487 . I will tackle this together with #459 . unfortunately not: you can abort the execution before the execution, but the exception is not handled correctly while executing. Should not be too complicated, but needs to be done.. Lets plan that for 5.0. @bbakerman I like the idea to grab the results which are already finished and then return what we have. \ud83d\udc4d . do you mean something like a  Accept-Language header?. ok .. I understand.\nThe answer is: graphql-java doesn't give you access to the header, because it is outside of the scope of this library: it has nothing todo with HTTP or how your transport protocol looks like.\nIf you need access to some environment/query specific info, graphql-java gives you the context argument when executing a Query:  https://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/GraphQL.java#L178\nThis means you could read the Accept-Header before executing the query and provide this info via context. context is then available to each DataFetcher.\nI hope this helps.\n. @bbakerman no, it is still open.. This is fixed in #485 . nice ... thanks @bbakerman and @Jimexist . See PR #480 for further discussion. Please look at the release notes for 3.0.0: https://github.com/graphql-java/graphql-java/releases/tag/v3.0.0\nTypeResolver was changed to accept TypeResolutionEnvironment instead of an Object.. Hi,\nnormally this means you have defined the type Authors twice: you can only define it once.\n. closing it now ... \n@SeenaLibin if you think it is a bug and you don't actually habe two types with the same name, please reopen it again. Thanks!. Hi,\ndo you really need a WiringFactory? You could use the normal .type of RuntimeWiring to define the DataFetcher for SomeUserType.\nAnd you can additionally use a WiringFactory if needed. But this is only intended for some dynamic uses cases which can't be solved otherwise.\n. Ok ... then answering your original question: We only provide the FieldDefinition currently. But you could use the TypeDefinitionRegistry to access the possible parent and check if the FieldDefinition is part of it:\nsomething like that:\n```java\nif( ((ObjectTypeDefinition)typeDefinitionRegistry.getType(\"SomeUserType\")).getFieldDefinitions.contains(fieldDefinition) ) {\n.... \n}\n```. well .... I can see it that it would make sense to provide the parent. \nWe would be happy to accept a PR to change that. :-) . thanks . As mentioned before: these are not fully working examples. It is just a code snippet. You have to implement the missing parts yourself.\nJust a general note, because you posted a few questions lately: it seems that a lot of your problems are not graphql-java related, but are general Java questions.\nWe can't help with you that, I am sorry. We can only help with graphql-java here. I hope you understand. Thanks!. @guy120494 sorry for the delay.\nI get the idea that we should make it easy to conform to the spec, but in general we don't support any specific json libraries.\nI think the best thing would be to just return a real Map with errors missing, if none happened.  @bbakerman  your thoughts?. @guy120494 yes, but I think a Map would be just be easier: there is no need for any real class here.. @charliechang Please have a look at #380 for a first start. . closing it, because we decided to make ExecutionStrategy itself async and we already merged a first step in this direction: #380. \n@charliechang thanks a lot for this PR and the work you have put into it!\n. I am sorry to hear that you can't use Java 8, but we just recently switched to Java 8 and we are already using the new features all over the place and we don't have the resources and the time to support something else.\nI'am afraid the answer is no.\nPlease have a look at this Issue where we discussed it: https://github.com/graphql-java/graphql-java/issues/338\nThanks!\n. This is a breaking change because we removed the field completely. . not sure this is a breaking change because I changed the output format of SchemaPrinter a bit. @bbakerman \ud83d\udc4d . @omaraya11 could you create a PR for that? That would be awesome ... thanks!. closed with #513 . @tklovett thanks for this PR and your effort to improve graphql-java.\nBut this PR is too unfocused and too broad to be merged. \nPlease create separate PRs for each change you wanna do, so that we can discuss it there.\nThanks!. @bbakerman Could you write down the breaking changes in a a short notice including how to migrate? This will make writing the release notes easier. Thanks!. @tklovett thanks. @bbakerman how does this PR relates to #506 ?. great ... thanks!. @bbakerman I added a test for it. I also realized that the naming is probably not good: I think we should name it what it is: fieldDefinition. I stumbled across it myself: getFields() returns Field but field returns GraphQLFieldDefinition. This is unexpected imho.. thank you!. thanks. just to make that clear: my initial solution for that was the NaturalEnumValuesProvider.\nThe problem doesn't occur with a java schema definition because of this subtle line: ;https://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/schema/GraphQLEnumType.java#L152. @bbakerman I think it is the more convenient solution to map java enums in the core directly, so I am fine with this solution. \nMaybe we should even remove the NaturalEnumValuesProvider then, because it is basically useless. . @tdraier  thanks!. Could you open a PR for that? Thanks a lot. @piotrblasiak What version of graphql-java are you using? This should be fixes in the latest dev build. It would be great if you try this, if you haven't already.\nThanks!. @piotrblasiak you can find informations how to use the lastest dev build here: http://graphql-java.readthedocs.io/en/stable/getting_started.html#using-the-latest-development-build. @LarsKrogJensen Our plan is indeed to handle the returned value from a DataFetcher  differently based on the type: If it is a CompletableFuture all is good, if it is not, we will wrap it. So even if we can't express it with types (the return value is just Object) it is basically Object | CompletableFuture.\n. closing this issue: it was a spike and never intended to be merged. \nthe real implementation is PR #590 . @danielFesenmeyer thank your for reporting and providing a test case!\nIt will be fixed in the next release: #549 . we will look at this issue again after we implemented full async support. . @A1m7331 thank you for this PR!\nCould you add a test for this bugfix? That would be great.. when you execute ./gradlew build it should be fine. . @AndiMiko sorry for the delay ... I will try to take care of it next week.. thanks again @AndiMiko . @emrul Im sorry, that you feel disappointed, but we are a small team of currently 3 maintainers (working on this project in our free time) and we have carefully to consider if we add a new feature. \n@bbakerman and I talked about it and I wasn't sure if we should really support it, because it makes it slightly more complex and I am not convinced this is a problem/use case enough of our users have. That's all: there was no big decision or shadow process.  \nAnd this issue was not left dormant: sometimes we need a few weeks or even months to get back to an issue. We try of course that doesn't take too long, but we can't promise anything.\n. @emrul thanks for understanding. I will talk with @bbakerman about this issue again and we will get back to you soon.. @emrul I am bit surprised, but maybe we didn't communicate it clearly: Option 2 was specifically designed for your use case:\nYou would define n different schemas for n different roles and select the appropriate one for the introspection per request.\n@bbakerman also just wanted to point out that we don't plan to actually enforce the security in graphql-java, meaning that you would have to ensure yourself that the user doesn't access a forbidden field.\nI am interested in your feedback, even if you decide to maintain a fork with your own solution: Wouldn't that solve your problem?\nThanks!\n. @emrul thanks for your (repeated) explanation: I understand it better now. We will have to think about it again.. @backjo thank you for your PR. \nCould you provide a test to verify that this is the correct implementation? That would be great.. Hi @donbeave,\nthanks for the hint and thanks for the projects, but currently we don't add new projects to the organisation: We are a small team and just maintaining the current projects is challenging. \nOur way of promoting of related projects is the awesome-list: https://github.com/graphql-java/awesome-graphql-java \nI am happy to accept a PR there.\nCheers,\nAndi. @bbakerman LGTM ... do you have any pending objections? . @huangd0ng Thanks a lot for the PR! I did a review and found some issues, but I am sure we can resolve them.. @imrikoch1212 yes, it contains some breaking changes, but as always we aim for \"simple\" changes meaning you get a clear upgrade path.\nyou can get a preview of the breaking changes here: https://github.com/graphql-java/graphql-java/pulls?q=is%3Apr+is%3Aclosed+milestone%3A4.0.0+label%3A%22breaking+change%22 . @soudmaijer I am sorry, but we don't have the time or resources to publish milestones to maven. Please use the development build if you wanna test it before release. Thanks and I hope you understand!. @raderio thanks for the offer, but there is nothing you can do: you can build it yourself or use use a development build via bintray. If you can't do both you will have to wait until we release the new version... closing this now, because 4.0 is released. @JWGmeligMeyling thanks a lot for this PR! But unfortunately we don't want to add a new dependency: we are really trying to minimize the dependencies we have. Every new dependency makes it harder to integrate a library and therefore we require a very strong reason to add a new one.\nBut of course we wanna improve our support for different getter/setter bean styles.. I am closing this, because it will not be merged how it is. (see previous comment)\n@JWGmeligMeyling Thanks again for creating the PR, even if it will not be merge.. @bbakerman maybe squash it when you merge :-) . thanks. Thank you! We will merge it soon.. thanks!. Closing because, this is not a exception from graphql-java but from graphql-java-tools.\n The issue is tracked there: https://github.com/graphql-java/graphql-java-tools/issues/49\nThanks!. @michaelplavnik thank you very much for this PR.\nOne suggestion: Could you split it up and make different PRs out of it? Because some aspects we could merge right away (the documentation fix for example) and others we need to talk about a bit.\nIt would really help to stay focused.\nThanks!. Note: The documentation fix is now done: see #636 . @jameskleeh maybe you wanna create a PR to add your project to https://github.com/graphql-java/awesome-graphql-java ?. @bbakerman About the conflicts: SerialExecutionStrategy is already deleted and BatchedExecutionStrategyis changed quite a bit. . thanks!. Hi @tylerhjones,\nthe hello world you are referring to requires the latest not released version of graphql-java.\nPlease have a look here for the documentation for 3.0.0: http://graphql-java.readthedocs.io/en/stable/getting_started.html\nThanks!\n. We have this validation rule: https://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/validation/rules/NoFragmentCycles.java . I am closing this issue, because there is nothing to do for us now \n@cliren I hope this answered your question.. Thank you for this PR!. Please have a look here: https://github.com/graphql-java/graphql-java/issues/568 ... thanks. @undernorthernsky thanks for reporting. Yes I think this should be fixed.\nWould you like to make a PR for that? That would be awesome. Thanks a  lot.. this is fixed by #643 ... . I am sorry, but we will not provide a example for getting data from a database: graphql-java lets you implement the DataFetchter Interface, but is not concerned with where the data comes from. \nFor a starting point see our documentation about it: http://graphql-java.readthedocs.io/en/stable/schema.html#datafetcher-and-typeresolver\nThanks\n. yes, you are right: of course we could improve our documentation and provide are more complex example. But every full application example needs to be maintained and is time consuming to create in the first place and we didn't have time and the resources to do it so far.\nI can recommend asking questions in our gitter channel: https://gitter.im/graphql-java/graphql-java and I can recommend this introduction: https://www.howtographql.com/graphql-java/0-introduction/ . I am sorry, but we will not add this slack channel: it is not supported by the maintainers of this project. I. No, graphql-java doesn't support pre-approved queries currently. . No ... currently it is not planned. I am also not sure this is something graphql-java should implement at all: As far as I understand it it could easily be added on top of graphql-java.. I propose to follow our convention we used for ExecutionResult and implement a toSpecification: This way we don't have a implicit don't rename private fields rule and we would make clear what we support.\nThis would also solve this PR: https://github.com/graphql-java/graphql-java/pull/647 . Custom data can be added after toSpecification.. But more reasons to provide a specific method to convert it something which can easily be converted by every json library, or do I miss something?. yes, my initial design idea was to classify the errors without creating specific subclasses. But I am not sure how up to date this list is and I am not sure how useful it is overall. . this will be solved by #650 . You have to run this example with the latest version on master. \nIf you are using the latest released version please have a look at the documentation: http://graphql-java.readthedocs.io/en/stable/getting_started.html \nthanks\n. I am sorry, but this will not happen: uploading a file is out of scope for graphql-java.\nI recommend asking in our gitter channel and or at SO for help.\n. my fault :-) . I am not completely sure about the Exception: maybe we can handle it better, like returning an error or so.. the thing is: this only supports relay classic, not sure what has been changed for the current relay version.. and it is not really tested at all .... It was only a proof of concept for https://github.com/graphql-java/todomvc-relay-java at the time.. @bbakerman can this be merged?. @drewolson thank you for reporting. This PR #666 should fix that. Can you confirm that? Thanks!. @drewolson We just released version 4.1. Please try it out ... thanks!. yes I think we can loosen that restriction ... I don't see a reason why not.. @drewolson could you post an example query? thanks. @drewolson I can't reproduce it. I modified the test a bit and it is green now: https://gist.github.com/andimarek/841b539fa199d4c8d7a2b445442329c4 . @drewolson yes, please try to come up with a failing test where the NPE occurs ... thank you.. @drewolson thank you for creating the example test. \nThis is indeed a bug, but it is a problem with the instrumentation, rather than with  QueryTraversal itself.  This PR should fix this: #670 \n. @drewolson Just to be clear:\nThe root problem is that your query itself is not valid: You can't query {a} if a is an Interface: you have to select one or more subfields. . Thanks for reporting: This #682 should fix it.. maybe .. we haven't planned it yet.\nBut could you please test it before we release it?\nAfter the PR is merged you just have to use the latest dev build: http://graphql-java.readthedocs.io/en/v4/getting_started.html#using-the-latest-development-build . @drewolson it is merged .... could you try the latest dev build? Thank you!. @drewolson thanks ... closing this issue now: the fix will be in the next release. the calculation is correct: if you always return 1 the overall complexity of your example query is 1.\nThe Calculator calculates the complexity based on the sum of of complexity values of its childs. So if you wanna have every field count as one, the Calculator should look like this (env, childComplexity) -> childComplexity + 1. This is also the default one.. yes, we will do 4.2.. Hi @vincentDAO,\nI am sorry, but this fix didn't make it into 4.2. (my fault)\nWe will release 5.0 in a few weeks, until then I recommend you use the latest development build: http://graphql-java.readthedocs.io/en/v4/getting_started.html#using-the-latest-development-build \n. yes, we will definitely support it. I think the algorithm for stripping indentations is not finished yet (see: https://github.com/graphql/graphql-wg/blob/master/notes/2017-08-14.md#verbatim-string-literals-and-schema-descriptions). After that is done we can implement it and it should not be so complicated ( @bbakerman already looked into it). I am sorry, but graphql-java doesn't provide any special support for filtering the response (as graphcool does)\nAnd I don't think it will, because it is out of scope: defining arguments to fields and decide what they mean is extremely domain specific.\n. closing this issue because there is nothing to do currently. @rsmkrishna maybe this will help you: https://github.com/donbeave/graphql-java-datetime . @rsmkrishna I am sorry: this is not a graphql-java problem. Please open an issue at https://github.com/graphql-java/graphql-spring-boot if it is not solved yet. Thanks. Hi @ieugen, \nI am sorry, but graphql-java will not implement file upload (or anything similar) because anything dealing with HTTP (or JSON) is out of scope for this library. graphql-java only provides a way to execute graphql queries, nothing more.\nSee also: https://github.com/graphql-java/graphql-java/issues/652\n. @joesankey thanks for reporting.\nCould you also post  your Query or maybe an example derived from it? This would really help to fix that.\nThanks. and also maybe you could try to use the latest development build (graphql-java.readthedocs.io/en/v4/getting_started.html#using-the-latest-development-build) ... maybe it is already fixed.. @bbakerman any objections to get this merged?. the build fails currently because dataloader 2.0.0 could not be found in maven central. @zjchen82  we can't use the length of the list, because query complexity is calculated before the query is actually executed. \nYou can however provide a custom calculator and increase the complexity for the specific field. This will wait a bit more until it the spec is ready (or almost ready). lets reevaluate it again for 6.0. we will do that in 6.0 in order to get out 5.0 very soon. . thanks. Hi @MartinX3,\nI am not really sure what this issue is about: do you want us to change GraphQLList? This will not happen, because GraphQLList is designed to be immutable. \nMaybe this issue should be addressed in the graphql-spring-boot-starter project.. I get the idea behind it (and we should provide a solution for the underlying problem), but it breaks completely the immutability of the schema objects. I am not sure this is the right way .... @kaqqao you can put whatever you want into the Map and if you put something mutable into the Map and change it later the original graphql object is changed too.. @bbakerman yes we will not solve the general problem here.\nBut schema objects are immutable today (technically they are only after the schema was created if you use type references, without even before): every object referenced is itself immutable. \nBy adding arbitrary maps they are no longer and I don't think we should do that: immutability is a very nice property we should not give up.\nAlso: Copying a schema is currently very cheap and safe to do (even with multiple threads involved) exactly because we have full control over the full schema graph of objects. This would also no longer be true.\nI like @aschrijver suggestion to use Map<String,String> ... that would be perfectly fine and maybe it is enough for almost all use cases.. this will not be included in 5.0: we need to think about it a bit more.. Hi @marcelalburg, \ncould you try the latest dev build? It might be fixed in there. Thanks!. @marcelalburg thanks for confirming that it is fixed.. I am sorry, but this is not so easy:\n\n\nWe could add Guava as a dependency and check for Guava Optionals as well as for Java Optionals: The code itself is trivial, but we don't want to add Guava (or any other lib) as a dependency. So this is not an option.\n\n\nWe could check with reflections if the returned values is of type guava optional and then handle it without having a compile dependency. We would need to make sure that it does not have an negative overall impact and in general such reflection code is rather not nice. So I am not sure about this ... if you are really interested in having Guava Optional support it would be great if you could create a PR for that. But I can't promise if it gets merged.\n\n\nThanks!. @bbakerman nice solution, didn't thought of that \ud83d\udc4d . this is an issue of the general spec, not this library: see last comment. to be honest: I am not so sure about that. I get the idea, but still: should that be part of graphql-java? It seems a bit \"exotic\". :-) . see #744 . we already have the ability to construct a schema from a introspection query: https://github.com/graphql-java/graphql-java/blob/0ea9d3cae254512b30966ac88b36effc200309d0/src/test/groovy/graphql/introspection/IntrospectionResultToSchemaTest.groovy#L545 . This is somehow overlapping with AstPrinter, isn't it?. I this a direct adaption of the graphql-js implementation: https://github.com/graphql/graphql-js/blob/26023b30ff8dd083bdf60f2415909f18ebdda502/src/utilities/findBreakingChanges.js ?. thanks. I updated the title to make it more clear what this PR actually does.. This was merged into the v4 branch ..... this is not what we want: v4 will be deleted very soon.\nIt should be merged into master as all changes.\n@tdraier @bbakerman . could that change have some performance impacts when you have a large result (= a lot of DataFetchers)?. @bbakerman Yes I am not really happy but I don't really have a better solutions except maybe some bigger refactoring, which I don't wanna do atm. So \ud83d\udc4d  from me.. closing for now ... not sure when we will pick this up. @arlampin yes, we actually managed to ship it in 9.0. . closing it again, because it is fixed in 9.0. . @nlevy thanks for your contribution!\nCan you explain your use case a bit more? Maybe provide us with an code example?\nIn general I prefer strongly protected/public methods and not to make any fields protected (not private).\nThank you!. marked as breaking change ... correct @bbakerman ?. closing this issue: the original goal was addressed by #905 . @gkesler I decided to do some refactorings (and push) myself while reviewing. . @gkesler I will try to finish my review in the next few days.. @gkesler @exbe currently the new traverser is only used in one place: do you intend to use it more or create other PRs which build on top of that?. @exbe ok, looking forward to see the other PRs :-) . @gkesler ok ... I will try to make QueryTraversal a bit more readable and also rename the visit methods to visitXXX. After that we can merge it.. I am sorry for all the delay, but I tried working on a simplification on QueryTraversal, but didn't really succeed yet. In the current form it is just too complicated. @gkesler @exbe If you have any suggestions for simplifications would be great.. just to make it maybe a bit more clear: I expect that the general Traversal doesn't really decrease the readability of QueryTraversal. This should be the goal.. I would love to see some simplification in how QueryTraversal is using the Traverser: It is basically just a normal post-order/pre-order traversal of a Query, which inlucdes only SelectionSet and Fragments.\nThere are just too many inner classes, anonymous classes etc to understand it easily, imho. Especially compared to the previous versions.\nI don't think comments will help and in general we try to avoid internal comments as much as possible. \n. @gkesler I renamed the visit method to visitXXX as discussed earlier and I looked at QueryTraversal again. Thanks a lot for the refactoring. \nUnfortunately I still don't really get it, despite spending some time with it. \nCould you please try to explain the QueryTraversal usage of Traverser a bit more:\n- As I understand it does the Traversal class a Pre-order or post-order at the same time by using enter and leave for each node: by doing something in enter I get pre-order, by doing something in leave I get a post-order. Is that correct?\n\n\nAbout the contextStack which is used in QueryTraversal: I would not expect to maintain such a stack myself, but use TraverserContext for that. We have two \"Contexts\" now which is a bit unfortunate. In general I think that this is a very common pattern which should be supported in a abstract way. The overhead of maintaining such a stack yourself is significant here imho.\n\n\nThe enter method in QueryTraversalDelegate seems unnecessary: it is the same impl as in the super class.\n\n\nThe leave method in QueryTraversalDelegate seems a bit too much for me: I would replace it maybe with that: \n\n\njava\n        @Override\n        public Object leave(TraverserContext<Node> context, TraverserContext<Selection> data) {\n            if (context.thisNode() instanceof Field) {\n                QueryTraversalContext top = contextStack.pop();\n                visitorNotifier.notifyPostOrder(top.getEnvironment());\n            } else if (context.thisNode() instanceof Selection) {\n                contextStack.pop();\n            }\n            return context;\n        }\nBut again: if we could get rid of that manual stack management it would basically just be ...notifyPostOrder\n\nThe QueryTraversalNotifier could be replaced with just two different Consumer fields in QueryTraversalDelegate: basically inlining the whole class.\n\nWhat do you think @gkesler ?\nThanks you!\n. I am really sorry @gkesler @exbe but I will not merge this PR:\nI really struggled with this decision, because I see your genuine effort to contribute back to this project and I  (and everybody who is using graphql-java) can't thank you enough for it. Without contributors like you, this project would be long dead.\nBut graphql-java is a project run by @bbakerman and me (in our private time) and my experience with maintaining it told me, that I have to be comfortable with maintaining code which is contributed. \nAnd honestly: I spend a significant amount time with this PR (much more than with other PRs), but I still find the usage of the general Traverser in QueryTraverser hard to understand. \nI can appreciate the idea of extracting the general visitor logic in an extra class and I also like the double dispatch pattern to avoid instanceof checking. I also believe that it is faster, but on the other hand I don't really think it really matters in real life projects (if your experience is different I would appreciate if you could share some numbers).\nIn the end the negative aspects of using and introducing the general Traverser outweigh the positive aspects, at least from my current understanding.\nAgain: I am really sorry to come to this conclusion. Thank you very much for your effort and I hope this doesn't discourage you from future contributions.. @gkesler @exbe thanks for your understanding, but I gave it another shot and refactored a lot (details see below)\nAs a general info: BatchedExecutionStrategy is not really recommend from us and we want to fully deprecate it in the future, because it does some none standard stuff and contains some bugs in the edge cases. We recommend to use batched DataLoader in addition to async execution to achieve the same results. Would be good to know if you could replace it in your case too (cc @bbakerman ).\nBut even if we ignore the BatchedExecutionStrategy: I agree in general that we have several different traversal implementations (for example RuleVisitor ) and it would be nice to have a general mechanism including double dispatch.\nAlso Thanks @exbe for the example: I agree it is nicer.\nThe reason why I was not satisfied with the PR was not that I think it was not understandable, but it was not understandable enough (or not \"clean\" enough) in my opinion. But of course this is somehow subjective and especially for more complex code hard to communicate. \nI decided to give it another shot because I had rough idea what to improve (but it was hard to clearly communicate instead of doing it myself) and I am quite happy with the result:\nI made couple of changes: I try to summarize it: \n\nI removed the concept of data passed along to the visitor and put it into the TraversalContext in the form of initialData and per context result.\nThis enabled to change the visit (enter/leave) method to return clearly a TraversalControl instead of Object\nI made the NodeVisitor more coupled to the Traverser by explicitly passing the TraversalContext. It was coupled before by using special return values to influence the traversal (abort, exit etc). This is now more explicit.\nAlso introduced the NodeTraverser which bridges between the general Traverser and the specific ast nodes. This is cleaner imho instead of putting it into the NodeVisitorStub.\nI removed the not used TraverserVisitor.mapKey method: happy to add it if it is really needed at some point.\nI refactored the Traverser internally in a few places: made RecursionState a bit simpler in my opinion by removing the two subclasses. Also changed Traverser itself. \nMost importantly: QueryTraversal is now better understandable: we are using the new NodeTraverser to traverse depth first Selections and by differentiating between enter and leave in visitField we are implementing a pre order or post order. Gone  is the additional postOrderVisitor and the hard to understand (because very subtle) enter and leave implementations. \n\nIn general I am not happy with the test coverage: there are quite a few things which are not tested at all or not enough. This needs to improved a lot before it can get merged. \nBut before that: Please review it @exbe @gkesler. If you agree that this is the right direction from your point of view, we could polish it and test it more and the merge it.\nThanks!\n. I think the last real discussion point is the general NodeVisitor/TraverserVisitor Interface: \nI know it is not perfect: the general \"reduce like\" method looks a bit nice in general and especially if you just wanna do a one time double dispatch. I agree.\nBut I don't wanna introduce Exceptions for totally valid use cases like aborting the traversal. This is not an Exception. \nAlso having to return the TraversalContext just to conform to the nicer general method type is not the way I wanna go: Returning the Context just doesn't make really sense, if you look from user perspective of a NodeVisitor. Also setting the TraversalControl in the context is additionally weird. \nThe main goal was to make it nice for such use cases like QueryTraversal and others.\nThe tradeoff is that we don't have a very nice single double dispatch call: you should use the static helper method. \nI would like to stick to the current solution and and proceed int the next weeks with adding much more tests and just some cleanup all over the place.\nWe will release 8.0 at the end of March and our goal is that this PR is included.\nIs that ok for you @gkesler @exbe ?\nThanks!\nEdit: \nAlso: Just in general we are always happy to revisit and refactor stuff as we encounter problems or find better solutions. This means this is not meant as the \"final version\", but just the current one I would like to proceed with.. ok .. thanks for your feedback. As said the goal is to get it merged in the next three weeks and I will continue on testing on polishing until then.. thanks a lot @gkesler @exbe @bbakerman for creating/refactoring the PR and providing feedback.\nIt is not perfect, but I think we all agree that it provides value and goes into the right direction.\nIt has now a sufficient test coverage and it also clean enough overall that I feel comfortable merging it.\nI probably missed some details or maybe didn't respond to some feedback, but my time is unfortunately limited and this PR is already the biggest and most commented PR in graphql-java history I think.\nTherefore I will merge it now: it is only used internally which means we are free to refactor and improve it as we wish.\nThanks again everybody!\n. breaking change because we rename TypeExtensionDefinition to ObjectTypeExtensionDefinition. There is one commit in this PR which doesn't belong here. I need to clean it up before we can merge.. @bbakerman please give it a quick review ... thanks. Hi,\nwe don't deal with jackson or other serialization specific issues in this topic. So we can't add any annotations as you mentioned.\nWe provide this method https://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/ExecutionResult.java#L31 \nto help with such cases, but I am not sure out of my head if the location case is properly handled. . it is a small breaking change. @bbakerman maybe this should even be the default impl? I mean maybe an extra step after creating the schema with one single call to the DataFetcherFactory? This would make this thread safe lazy initialisation obsolete.. this will not merged: see #947 for the discussion.. This will not happen for 8.0.. the problem here is that each Interface can be implemented from a number objects. This means we can't just add this info to it without having the full schema resolved. There is a method  which does i want I think: SchemaUtil.findImplementations . I don't think I understood you correctly: what do u mean with \"specified by @GraphQLInterface(possibleTypes={..})\"?. closing this issue: the current plan is not to implement stitching in this library.. I think it is a real life requirement we should support at some point.\nBut I agree: the implementation is not really obvious.\nI think one of the most successful design decisions of graphql-java is not to deal with json parsing/http connection/mutlithreading (except very few occasions) and also only include very few dependencies.\nWithout knowing how it would look in detail I would strongly prefer to keep graphql-java this way. But I also think that we should provide some easy to use implementation (based on RxJava or whatever). So I think extracting the heart of the defer implementation  in a extra artifact like graphql-java-defer or so makes sense. We could achieve this without adding too much overhead by converting this repo into a gradle multiproject build. So far my thoughts on the meta level regarding dependenies/artifacts.\nI think I need so see some kind of spike to get a real feeling how an implementation could look like in detail. But again: I am totally for at least trying to implement it.\ud83d\udc4d \n. a first version of this is now shipped in 8.0: https://github.com/graphql-java/graphql-java/pull/967 . I am closing this issue because BatchedExecutionStrategy is deprecated by us and we recommend using Batched DataLoader: https://graphql-java.readthedocs.io/en/latest/batching.html \nPlease open an new issue if you experience the same problem with the new approach.\nSorry for the long delay.. yes, we will go with the other approach, thanks for providing different options! . I am not so sure:\nthe spec says: If an error can be associated to a particular field in the GraphQL result, it must contain an entry with the key path that details the path of the response field which experienced the error.\n(And the path is an list of Strings or Integers, why we have List<Object> as type in the GraphqlError)\nBut in this case path doesn't refer to to the response, but to the query (and path is no longer List<Object> but List<String> because in the query we don't have lists and hence no Index as Integer)\nI don't think we should mix up these two things. I think we should add the query path to the actual message (or maybe add a new query-path property, but this would not be covered by the spec) .. I see that @kaqqao answered your question.\nAbout the documentation: it is of course not perfect. Please open a new Issue or even a PR if you found a specific problem. If you have general usage questions I can also recommend the gitter channel where u can ask for help https://gitter.im/graphql-java/graphql-java . this is our current approach: https://github.com/graphql-java/graphql-java/pull/990 . @bbakerman can this be closed? . closing this issue and tracking it via #988. Cats is our (and the communities) best shot at the moment for this topic.. We will release 8.0 until the end of march.. version 8.0 is released. For the release notes: This is a breaking change . Thanks for the PR.\nCould you please add a test for it? It seems that we don't have a test for multiple Interfaces, so it is a good moment to create one. You should look at https://github.com/graphql-java/graphql-java/blob/master/src/test/groovy/graphql/schema/idl/SchemaPrinterTest.groovy for inspiration.\nThanks a lot!\n. note: we also have https://github.com/graphql-java/graphql-java/blob/1f1377201f89422e81de369ad06574e0f4c73e00/src/main/java/graphql/language/AstPrinter.java#L284 btw: this needs to changed too in order to be consistent.. thanks @henryqdineen . breaking change because of the change to the return type of ExecutionStrategyInstrumentationContext.beginExecutionStrategy.\nAlso because of the changed return values to completeValue etc.: they return now a FieldValueInfo.. this will go into 9.0. this will go into 9.0 . we should add a unit for for that. after looking it: no unit test is ok. the exception never surfaced because CF.completeExceptionally is silent when the CF is already completed.. solved with this PR: https://github.com/graphql-java/graphql-java/pull/1033. thanks!. @kaqqao is your last comment still up to date or is it taken care of?. We will improve this, but not in 9.0. We are aiming for 10.0. this is done in https://github.com/graphql-java/graphql-java/pull/1176. to give a bit more context about the general problem:\n(it was also raised before in https://github.com/graphql-java/graphql-java/issues/826)\nthe problem is how aliases are mapped to java objects/maps.\nFor example:\ngraphql\nfoo {\n  id\n  alias1: name\n  alias2: name(notDefault:true)\n}\nIf a DataFetcher for foo wants to return the fully resolved data for the whole sub-query (not only one value for foo which will be then used as source for id, and name (two times)) how can that be achieved?\nI am not really sure how special this requirement is and if we should make support it out of the box. \nAnother thought: Maybe this is also not really a DataFetcher issue at all and we wanna be able to return the already resolved sub-query and make the execution mark as done for that sub-query somehow? @bbakerman \n. fyi: this (or other solutions) will not go into 9.0. I will close that PR because this is a problem on the execution level: how can you delegate larger parts of the executions to something else, not just a DataFetcher.\nA DataFetcher is just responsible for getting the data for the field based on the source context. Taking the alias into account actually happens on the execution level. \n. closing it, because the question was answered, please reopen @FutureElement if something is still unclear. thanks @tipok for reporting it ... would you be interested in creating a PR for that? \nIt should consist of the changed grammar and at least one unit test which ensures that it works expected. (Under assumption this change doesn't have any other side-effects). Please have a look here: http://graphql-java.readthedocs.io/en/latest/execution.html#query-caching . Hi @tinnou,\nwhat is the status of this PR? \nThanks!. @tinnou thoughts on that change? thx. @tinnou yes it is the short version of the hash, which still should be enough to identify the commit. \n. I had to change the version to  (replace # with -) to make it work with the automatic maven central sync.\nIs that an issue @tinnou ?. yes it is already working. :-) . @mateusz-bajorek why is that problem for you? We publish the dev builds on purpose to maven central with real versions numbers so that people can actually use them if they need/want early releases. . I understand the first point, but it should not be such a big burden imho. I would expect that you have to look up the release notes  anyway on github if you want to upgrade.\nAlso please follow our twitter account https://twitter.com/graphql_java if you wanna be informed about new releases. \nThe problem with publishing to other repos than maven central is that some organizations don't allow easy access to them. So adding another repo is often not really an option in bigger enterprises.. This is fixed with #1083 . I am sorry, but we can't accept this PR in this form.: it contains a lot of changes including formatting changes.\nI would highly recommend that you reach out first before making bigger changes.\nAnd if you create a PR:\nPlease provide small PRs and focus on one change at the time. \nPlease provide a sufficient explanation for the change: just changing the style of from for loop to streams for example is not enough. \nAlso for example switching from putIfAbsent to computeIfAbsent for performance is not enough of a reason: we need to see evidence that the current implementation is a problem.\nThanks!. can you provide some details:\nthis is our dependency:\nxml\n<groupId>org.antlr</groupId>\n<artifactId>antlr4-runtime</artifactId>\n<version>4.7.1</version>\n<scope>compile</scope>\nso it should be fine imho.\nthanks. @exbe yes: the current build (getting the git hash part) is sometimes flaky.. We will probably make the NodeTraverser public, this includes TraverserContext. See #1097. So I don't see a problem to make this visitor also public. @exbe . I am really sorry for the delay @exbe. Will try to review it soon.. @exbe thanks for the patience ... looks good . I tried to find a definitive answer if the server side spec changed, but I could not find it. But the server side spec seemed to be unchanged, so we should assume for now that the relay support is also good for Modern.. should we deprecate the constructor?. SchemaUtil.getUnmodifiedType should be deleted and be replaced with unwrap. This includes making some parts of the general Traverser public, but not everything.. @bbakerman @gkesler @exbe I would like to link to some good explanation about general traversal and for example pre/post order is a special case of depthFirst. Any recommendations? thx. this is not the way we go ... closing for now. Hi,\ncan you please try the lastest dev build (2018-07-04T08-09-58-795c232). It maybe fixed with this PR: https://github.com/graphql-java/graphql-java/pull/1090\nThanks!. @kclaes thanks for confirming: it is released in 9.1 (released yersterday). breaking change because Nodes are created now by Builder. \nThe internal Parsing changes are just internal.\nIt is potentially a big breaking change because nearly every Node is now created in a different way and Nodes are not mutable anymore.. thanks a lot for reporting:\ncould you please try this build: \"2018-07-13T04-59-30-f72244a\". This should contain a fix for it.. Version 9.2 is now released. this is merged into 9.x branch. can you explain a lot more what you mean? CI via travis-ci is setup and runs on very PR and on master :-) . I am sorry, but this is not a constructive way to improve the project: please open a new issue where you specify what exactly you would like to see in commit messages and why you wanna see it: how would it help you? \nScreenshots of this way especially is not helpful and just blame people (me or others).\nThanks. this is a very small breaking change, but still breaking because we changed the signature of a public method. yea ... this is a pure compiler breaking change, so it is fine imho.. It is a tough one tbh: I see the need and I think we as graphl-java org should provide it. But I am not sure about the place:\nInside the base library is the most convenient place, but you could argue that it should not really be in there and depending on the complexity and feature requests around I might agree. (For example joda-time support support is not possible inside the base library, because we will not add a joda-time dependency.)\nThe separate project like @oexza suggested makes sense, but has of course the extra overhead of creating and maintaining an extra project.\nI don't have a clear favour atm and I would like to hear other opinions.\n. @rpmcdougall we will not add additional dependencies to graphql-java itself: this is a fundamental design decision of the library itself in order to keep our maintenance effort low and most importantly to avoid transitive dependency problems.. I am sorry that we didn't get back in time, but we are quite constrained regarding the time we can invest in this project.\nIn general I would like to see a proper \"official\" graphql-java date scalar support (and probably others) but this topic is quite complex and to be honest we don't have the time at the moment to tackle that.\nThanks for your understanding and for the PR in the first place!. Work will continue here: https://github.com/graphql-java/graphql-java/pull/1335. is this done @bbakerman ?\n. I think this is a duplicate of https://github.com/graphql-java/graphql-java/pull/1179 .. thanks a lot @tinnou.\nI looked at it and I think a synchronized on dispatchIfNeeded would be better, because it has smaller scope.\nWhat do you think?. @kdlan thanks for the further investigation: we will look more closer at which points we need to protect ourself from race conditions. \n(Removing the assertion is not an option, because the assertion is there for a reason: if the algorithm  is correct it should never happen.). @tsroka how did you come across this? . @tsroka could u use the graphql-java formatter (https://github.com/graphql-java/graphql-java/blob/master/graphql-java-code-style.xml) to avoid not needed changes? thanks. this should also go into stable 9.x. @tschuettel we are planing to release 10.0 very soon (couple of days hopefully). I guess there is just an explicit check for isTypeNameIntrospectonField missing:\n@bbakerman the code was added because__typename is the only field which is not contained in the parent field container, therefore you can't get the fieldsContainer.. After looking into it I see that this is more of a broader problem:\nI am not happy that GraphQLFieldDefinition is also a GraphQLType. I think that is missing the point. GraphQLType is misused here as a kind of a GraphqlSchemaNode. GraphQLFieldDefinition is not the only problem. For example GraphQLNonNull is also not really a GraphQLType: It doesn't  have name. It should just be a GraphQLSchemaNode.\n. @exbe can you have a look at this? your thoughts? thx. yes that should be fixed @bbakerman . solved with this PR: https://github.com/graphql-java/graphql-java/pull/1386. closing that in favour of #1221 . @vro101 Can you post the full source code for SingleCustomerDataFetcher with the correct line numbers matching the Stacktrace?\nthanks. @vro101 see my last comment. If this is not an issue anymore, please close it. Thanks. @bbakerman your opinion on the current state of it?. the implementation here looks good, but it is not fully tested and we will not merge it soon.. @Me1kaa I can't give you a forecast when we will continue working on that, sorry. so yes: if it is urgent for you I would recommend to build this brand yourself for now.. this is targeting 11.0 (master) at the moment.. Hi @ashu-walmart, \nThis line you linked sets the strategy calls for level 1 to 1: even if you have multiple toplevel fields you only have one strategy execute call.\nDo you have a failing test-case to describe your problem better?\nThanks,\nAndi. closing, because it was answered https://github.com/graphql-java/graphql-java/pull/1235#issuecomment-425697777 . @kaqqao what is the status of that? thanks. @kaqqao no worries :-) . Hi @tbo-axelor,\nplease provide more informations, I don't know what you mean.\nThanks. this is a pure server implementation: you can't use it as a client. Maybe https://github.com/apollographql/apollo-android is a good fit for your needs.. Thanks for reporting @tinnou!\nLooking at the thread dump it seems that the main threads locks (or wants to lock) two different CallStack instances. This is surprising: The Callsstack should be unique per request. Looking at the callstack it seems that one DataLoader triggers another execution.\nAlso your test code does something similar: the DataLoaderRegistry is shared across several requests.\nThe FieldLevel tracking approach was not really designed and tested across several Callstacks. Also in general we recommend that the BatchLoaders are not shared across executions, but we don't enforce that.\nCan you confirm that it is your intention that you want to batch across executions?\nThanks!. closing this in favour of #1255. . Thanks @ashu-walmart for the useful test:\nThe problem here is that the DataLoader on the first Level (the query) are all immediately resolved (there is no async code involved) and therefore the Execution progresses to fetch the Data for Level 2.\nThen Level 1 is marked to be fully fetched and we trigger dispatch on the DataLoaderRegistry and it dispatches the DataLoaders on Level 2 which are not all fetched yet. So this means the BatchLoader won't get all the keys you would expect but just a subset.\nThen the rest for Level 2 is fetched and the BatchLoader is dispatched again with the rest of the keys.\nThis is a known issue with the current approach: we don't wait explicitly (and there is no easy way of implementing it) on one Level: If the execution already progresses we don't hold it back. This is exactly what happens here.\nYou can change your example and add some async code in your queryDataFetcher to see the difference:\njava\n    DataFetcher<Data> queryDataFetcher = new DataFetcher() {\n        @Override\n        CompletableFuture get(DataFetchingEnvironment environment) throws Exception {\n            def input = environment.getArgument(\"id\");\n            return CompletableFuture.supplyAsync({\n                Thread.sleep(500);\n                return new Data(Integer.valueOf(input), null);\n            })\n        }\n    }\n. thanks @osi,\ncan you create a PR for that? That would be really create. Thanks!. would you mind creating a PR for docs to improve the documentation? That would be really awesome ... thanks a lot. Hi @mgljava, \nthis project doesn't have a GraphQLResolver: please open an Issue for the project your are using (graphql-java-annotation?)\nThanks. Hi @dnebing, \nthank for your issue, but I think this is a more a problem of spqr. Have you tried addressing your problem there?\nthanks. @dnebing: I get your point, but out Builders are not supposed to be used as objects passed around to collect data and then somebody just calls .build(): they are supposed to be used in one thread, in one place to ease the process of creating the actual object. We don't care about thread safety for example and we don't provide extensive getters or other convenient methods. \n@kaqqao Can you look into his use-case? What do u think? thanks. closing this now, because it is not in the scope of graphql-java. see @kaqqao previous comment.. Thank you for your PR, but we will not that merge that: our Builders follow a common pattern and making some fields public is something in general we don't do. . closing this PR as described by @bbakerman  ... Thanks again @mattes3 for taking your time to write it up!. thanks @juhovh . Hi @senzzzi,\ncan you please provide more details about it? A failing test or example code would be really nice. Also be aware that GraphqlResolver is not a graphql-java concept, so please provide a failing test just with graphql-java. If this is not possible it has to be a issue with graphql-spring-boot etc.\nThanks!. closing according to the last comment.. done via #1249 . thanks @felipe-gdr . GraphqlSchemaElement maybe?. @pete-proton I am sorry and I can understand your reaction, but this a private run project with limited time we can spend on it. This means unfortunately it can take quite some time until we get back to PRs, especially not urgent PRs.\nWe really appreciate your contribution and I hope we see more in the future.\nThanks,\nAndi. @tinnou BatchLoader can be reused across requests, but each DataLoaderRegistry should be come with new DataLoaders instances.. About the first question: \nPlease have a look here: https://www.graphql-java.com/blog/moving-projects/ for details about moving projects.\nThanks. @bbakerman 12.0 or later? thx. happy to duplicate it for ease of use. Just wanted to make sure we are doing it deliberately. . closing this issue now ... @ind1go please reopen if it is unclear or you wanna add something ... thanks. My first reaction is that it is actually a mistake that there is getName(). \nI am not sure about the consequences if we change it, but If we do it, we should not just the wrapped type name, but add [..] or !\nbut if the semantics of Introspection is currently implemented correctly with null name I guess moving forward with #1251 is the better way.. @bbakerman we should backport that to 9.x I think. What do u think?. thanks ... we will look into it.. @LarsKrogJensen I initially read it as a Java 11 problem. But you mean you updated from graphql-java 10 to 11, right?\nWhich java version are you using?\nthanks. can you please give us more details about what are you trying to do?\nThanks!. closing it now because of no feedback: please reopen it if needed....thx. this is done with the referenced PR above. this is a small breaking change, because the context was null before but now is not anymore by default.. @bbakerman we should update the coding guidelines too . @bbakerman please have a look. It is ready for merge except the build file modifications.. @kaqqao what brad said: it is rewrite of the core execution engine to allow for more powerful execution strategies which are still maintainable.\nThe old execution strategy will still be around for the foreseeable future, but the new one will offer a spec complaint first level batching implementation. Also things like defer or streaming or more advanced execution optimization should be possible or more easily possible compared to the current implementation.\nBecause there are still quite a few things to figure out this will be internal for now and will be public (or maybe experimental) once we are sure it does what it should.\nJust to be clear again: the are no plans to retire the old execution engine!\n. This will be merged despite not being ready: we are planning on evolving it incrementally on master.. @bbakerman can we move that to 13.0 or do u want that in 12.0?. I an not really happy with that so far. Will not merge it for now. this was merged in another branch, not master. There still might be some improvements, but I expect that all major parts for that change are in place:\nEvery Node is now immutable. \nIt introduces the concept of a Zipper: basically a pointer to a specific Node in a immutable Tree which also keeps track of where where the current Node is in respect to the parent. (see here )\nSome background details: the problem with an immutable Ast is, that it is very easy to change a Node and all the children, but is very hard then also to change the parents referencing the node you just changed, because a Node just knows about its children, nothing about it parent. Zipper is a general concept which helps with that. I can recommend http://learnyouahaskell.com/zippers as a more detailed explanation. I also took inspiration in implementing it from this book. (Warning: it actually talks about Haskell and not Java)\nAdditionally there is the class AstMultiZipper which is a list of Zippers and allows keeping track of multiple changes in a Tree at the same time.\nAstTransformer now allows for modifying the Ast (Document) and getting a new Tree back in a very convenient way by leveraging AstMultiZipper. \nIt will look like this:\nhttps://github.com/graphql-java/graphql-java/blob/5558e3dca0a5e13ed7c7351af9b24d2da40aa2a7/src/test/groovy/graphql/language/AstTransformerTest.groovy#L13-L33\nFeedback welcome.\nAlso: Now that every Node is immutable you can't change a query anymore at any point. If you have some use cases which requires changing the query after it was create, please comment here. We wanna offer specific hooks where a query can be modified.\n. Ping @tinnou for feedback. thanks. closing it for now: we provided a possibility to change the variables too: https://github.com/graphql-java/graphql-java/pull/1355. @xtaixe thanks for the PR. We decided to go with a slightly different approach: https://github.com/graphql-java/graphql-java/pull/1355 . Hi,\nthis is very likely caused by the PropertyDataFetcher .\nEach field in your DTO is accessed through the PropertyDataFetcher by reflection.\nAs an alternative you can register specific DataFetchers for each field of User which takes advantage of knowing that it is actually a UserDTO.\nIt would look something like that:\njava\nDataFetcher dfName = env -> {\n  UserDTO userDTO = env.getSource();\n  return userDTO.getName();\n}\nThis should be even faster than the Map approach.\n. A DataFetchingEnvironmentImpl will always be created because each field will be fetched via a call to a DataFetcher instance. \nAnd yes: For every field you don't explicitly set a PropertyDataFetcher is used. \nI am not sure why the explicit DataFetcher approach is actually slower compared to a Map in your case: in case of a Map there is this code: \nhttps://github.com/graphql-java/graphql-java/blob/18a4425f2f0fca1a28c8fd28abc77c88025802e1/src/main/java/graphql/schema/PropertyDataFetcher.java#L143-L145\nwhich still does an instance of check.\nA custom DataFetcher as described above is even simpler.\nCan you provide us with more details, for example some profiler results? thanks \n. @mrubin is it possible get some profiler results or maybe to get some example app up and running?. closing because it doesn't concern this library: please open this issue in the appropriate lib on top of GraphQL Java (depending on what you are using) thanks. Hi,\nI am not totally sure what you mean. Please provide more details. I would also recommend to ask this question on our spectrum chat: https://spectrum.chat/graphql-java.\nThanks. closing because of inactivity, please reopen if you have more details. Thanks. I would need to check the spec again, but I am not sure this is allowed: you will not get null as argument in a scalar, because null means null and no coercing is needed. The question is now if you are allowed to return null, and I don't think so (but I maybe wrong): A non null scalar value must result in a non null coerced value. . After looking more into this issues we agree: we should allow returning null values from a Scalar for serialize. \ngraphql-js also added it explicitly: https://github.com/graphql/graphql-js/commit/daa7759770fbe9d880ac18757b7a825ada40978b. @HenryLauu do you need it for parserLiteral or serialize? . hi ... please provide more informations: what are u filtering and what is the expected result? Thanks. Hi ... I am closing this issue, because this is not a problem of graphql java:\nFiltering a list of User objects with guava vs java 8 has nothing todo with graphql java. Please reopen with more detailed informations if you think it has something todo with this library. . Hi,\nas @dimdimych pointed out this is not allowed according to the spec and we are following the spec in general.\nthanks. thanks!. good fix, but I would change some things:\nI don't think adding acceptBackRef is worth it: just adding a new public TraversalControl backRef(TraverserContext<GraphQLType> context) to GraphQLTypeVisitor should be enough.. @cmonty thanks for your feedback: can you give use more details how you use it? Also just to be clear: the ExecutionContext is different from context in the DataFetcherEnvironment. I would expect that you use context (which is an Object) to pass down authorization data.\nThanks. @mlvandijk these are only test dependencies, they should never end up in your dependency tree.. Unfortunately there is no way in general to calculate the result size of a query before the execution.\nthe paper and the implementation makes some assumption we can't do:  we don't know what data is actually returned from each DataFetcher (Resolver) so we can't calculate the overall size before.. Hi @hartig, I would be interested in the idea. If you wanna have some feedback or help in implementing it, you can reach me at twitter https://twitter.com/andimarek,. closing this issue because nothing todo atm ... thanks @rrva for bringing it up. yes, I think we should make defer support disabled by default or make it possible to enable it. @bbakerman thoughts?. Please open descriptive issues, with what you want or what your question is. Please have a look at our documentation on how to get started: https://www.graphql-java.com/documentation/. @jexp doe the test from @bbakerman answer your question?. I am sorry, but the functionality that you describe is not supported: you can not reference the return value of some fields in another field.. @qzucas that is correct: 11.0 is the latest release. all the versions with a date and hash in it are development builds. We made some breaking changes for 12.0, but 12.0 is not out yet.\nSo please be aware that you trying out an unreleased version. Is that what you wanted?. @qzucas I am sorry, I can't give you a release date for 12.0 at the moment.. @qzucas version 12.0 is now released . thanks\n. Thanks a lot @gkesler for this effort! Looking forward to look into it more, but give us some time :-) \nA first glimpse showed a couple of changed files which are not really changes: could you make sure that you are using the graphql-java code style: https://github.com/graphql-java/graphql-java/blob/master/graphql-java-code-style.xml. Thanks!. closing it because it concerns another project. @kaqqao thanks for that.. you can see the dependencies in the build gradle file: https://github.com/graphql-java/graphql-java/blob/master/build.gradle#L52 \nRight now we have:\ncompile 'org.antlr:antlr4-runtime:4.7.2'\n    compile 'org.slf4j:slf4j-api:' + slf4jVersion\n    compile 'com.graphql-java:java-dataloader:2.1.1'\n    compile 'org.reactivestreams:reactive-streams:' + reactiveStreamsVersion. I am sorry that this approach doesn't work for your automatic tooling, but we decided to publish the dev versions via maven (as \"real\" releases) to make them as accessible as possible and to allow people  to depend on them if they really want.\nI recommend you follow us on twitter or spectrum or use the Github Notifications for releases. can you share what you mean with too long? 1 sec, 5 sec? thanks\n. merged the PR ... thanks. @tinnou thanks a lot for looking into the flaky test. I am not sure if you are on the right path ... will also have a look.. @tinnou you were right: it is very likely caused by theses sleeps combined with the general behaviour of the field level tracking approach. We will fix that test.. @tinnou the test is fixed. thanks. thanks. @jadedevin13 thanks for that PR. I agree that we are not spec conform in this matter. Can you please add a unit test for that? That would be great, thanks.. never mind: @jadedevin13 I added the test myself. @bbakerman breaking change, because before that we would have printed defer, right?. We talked about this, the real question is here, if we have to return null values.\n. I'm not really about adding AbstractGraphQLType with the only purpose is to not having duplicate equals/hashcode\n. I would prefer not to use null ... just a empty set\nand then assert that its not null\n. assuming that dictionary is never null would make this simpler\n. Do you mind removing this comment? Imho there is no real value in it.\n. This is used for deploying the newest build on bintray, by using a constant string we would always override the latest version, which is not what I want. The date is unique and clear for everybody who want's to use the latest (or one specific) build.\n. I am not sure what this does. Please open a separate PR for that, if this change was intentional.\n. I would highly suggest to use T (or K,V ..) instead T2. T2 is a very unusual Type Parameter name.\n. I am sorry, I have overlooked your comment about that change. But please still open a separate PR for that .... thanks a lot.\n. Is this class used anywhere else? If not we should just delete it.. I agree in general but the next release is a breaking release. So please delete it. :-) thanks. is this one comment per line? We should be clear about that. . I would prefer to assert that comments is not null and throw an exception if it is.. This is also implemented in NoUnbrokenInputCycles .. .maybe we can make it dry?. I think all of our Exceptions should derive from GraphQLException\nI know we are not consistent on this currently, but nevertheless I wanted to mention it.. I would suggest extracting the class into in its own file.. I think it is a bad practise to use instance initializers. I also think printers should be declared in the upper part of the class together with the others variables.  . If the constructor does nothing, It would not add one, imho.. This method seems a bit messy overall: would you mind extracting methods for the specific types? (GraphQLNonNull, GraphQLList ...). @bbakerman what do you mean with \"import all\"?. I must say this part is handled by IDEA and it was not really intentional :-). @bbakerman Ok ... I know what you mean: these wildcards imports are caused by wrong idea settings: I never want wildcard imports. . thanks. @bbakerman Does this mean ExecutionContext is now part of the public API?. @bbakerman we do have a special assertValidNamemethod.. maybe also a forEach here to be consistent? . This whole Method buildObjectType is too long imho. I suggest splitting it up into smaller parts. . I don't think such comments are very helpful: If you wanna document the following block I suggest extracting a method and name the method appropriately.. We should rename this to SchemaValidationRule or something similar ... ValidationRule too generic. here I think subscription is missing? . Maybe we can phrase that a bit diffrent: \"expected OutputType, but found %s type\" ?. Maybe we can phrase that a bit diffrent: \"expected InputType, but found %s type\" ?. @bbakerman I merged it already ... my bad.. right ... will change it. Could you revert it? This change is unrelated to the parsing.. Could you remove this comment? We don't maintain author comments.. We don't use assert statements in prod code: they are turned off by default and don't have any effect.\nAlso it is not really needed to ensure the length or that the string starts wit \", this is already ensured by the parser/lexer.. done. yes, they expose it too: https://github.com/graphql/graphql-js/blob/master/src/type/definition.js#L619 . this is actually defaulted later now: https://github.com/graphql-java/graphql-java/pull/456/commits/1028e3229f223542b02527d39c9f92e92bbcdc5d. I think this is great, but we only test Ast literal coercion here. We should also test input coercion from variables. For input coercion from variables it must also testet that:\n\nThis unordered map should not contain any entries with names not defined by a field of this input object type, otherwise an error should be thrown.\n\n. duplicate line. two quick unit tests would be nice :-). No, we don't really need to preserve the API here: It is a very new feature and I don't expect it to be used for the \"standard\" use-case.\nThe annotation was missing, but to be honest, we didn't clearly communicate it yet, what the annotations means and what to expect. This is still a todo. \nAnd yes: we should refactor all parameters to take an Parameter-Object to make it safe to expand it in the future.. @bbakerman yes, that is what I am suggesting . Please have a look here for how to use groovy and java 8 interfaces: https://github.com/graphql-java/graphql-java/blob/a0096cb2f95e3d471d3922de9d9389c56c518c54/src/test/groovy/graphql/schema/idl/SchemaPrinterTest.groovy#L22 . Ok ... then I misunderstood you, sorry. \nYes, please change it: I don't want to mix different Test frameworks, a \"not so perfect groovy syntax\" is the lesser evil. . why don't we just parse it as json?. Not sure how many different star wars schema we now have for different test cases :-) . I think we should remove this: graphql-java doesn't support it currently and ExecutionResult should be immutable imho.. This should use the new ExecutionInput object (just merged it).. @guy120494 could you describe your use case? thanks!. @bbakerman yes, this is what I meant: it is reserved for the server implementation do something with it and currently we don't use it. And on top of that it is just strange to have such a map, but it never used.\n@guy120494 Thanks for your feedback. I agree it is a separate PR.. this is now addressed here: #484 . Yes ... there is no common type here and I didn't want to introduce one just to make it more \"nice\" here. I am not really happy with adding that to the interface to be honest.. My 2cent: I think adding logic to an Interface should only be used if there is no alternative. In this case it is just an helper method, which is nice, but doesn't really belong in the Interface: it is not part of the contract an Interface describes. . Could you keep it as it were? Thx. any specific reason to delete this? . do we wanna still provide this method or break it?. do we wanna still provide this method or break it?. do we wanna still provide this method or break it?. yes, let us break the ExecutionStrategy but keep the blocking GraphQL.execute method.. yes, you are right: it would be nicer to just call the copy constructor directly and remove this method.. could you remove the final initialiser for the arguments?  also for the other methods? thanks. Can we separate this helper from the actual class? For examples in a class Directives following JDK Conventions.. I am not sure about this: These methods do not add any real new value to the interface: they are just convenient.\nIf we really need/want an Interface with these methods we should add something like DirectivesContainer and make all classes implement is directly instead via TypeDefinition.. just a tiny thing: argumentsByName (plural) :-) . This is fixed in #532 .. can you write tests for the lamba expression? \n. also: this should be extracted in an extra method. this should be unit tested. this instance fields should be final. preparsedDoc can be null, right? . no need for that comment imho. @tdraier Thank you. Could you add a short comment here what both plugins actually do? . naming: here it is still called last resort. naming: here it is still called last resort. naming: here it is still called last resort. naming: here it is still called last resort. this should also be async and non blocking at some point, right?. you can call .get() here instead of join. I think this comment is a bit confusing for people not knowing dataloader :-) . we can mark it internal if this is only proof of concept. just realized again that .get() throws Exception ... so join() is fine. \ud83d\udc4d . yes, I totally agree: execute(String) should not be deprecated. yes :(. we don't use wildcard imports: please change that to the previous style.. is this method a copy from somewhere? If not we should add more tests for the different cases . I don't think the official bean spec is relevant anymore: I think we should support here what is most convenient for the user and least surprising.\nI think removing something we supported is not what we wann do.. could you remove that comment? we avoid commenting without a very good reason.. yes, you are right. Not sure about this change: why is this better? looking at the code in checkTypeCondition it doesn't change anything but makes it more complicated: we are only interested in objects anyway.. the unwrapping is the real fix as far as I understand it: why do we check fro GraphQLFieldsContainer instead of GraphQLObject?. yes ... you are right ... too many different places where we use a default strategy.. I added this test: https://github.com/graphql-java/graphql-java/pull/590/commits/3cde546ccb44860783d8c230dcab92f08a4ac57d \nthis what you mean?. Fixed with: https://github.com/graphql-java/graphql-java/pull/590/commits/4b4be3bb4a1c163f0aea6d3570a384ad4ad9f59e. Fixed with: https://github.com/graphql-java/graphql-java/pull/590/commits/4b4be3bb4a1c163f0aea6d3570a384ad4ad9f59e. done: https://github.com/graphql-java/graphql-java/pull/590/commits/f0436f139c56723b30cc6b7924832c83e54d13b8 . done . this is outdated code and the NonNullHandlingTest works. @bbakerman which test is that? . yes, I agree: it is not the most readable code, but I don't of any better way.. I changed this on purpose to make it simpler: completedValue should never be null.. I would not call it simple anymore, because we don't have a simple strategy anymore.. I would not call it simple anymore, because we don't have a simple strategy anymore.. yes, this should be treated as internal error or something like that. (assertShouldNeverHappen e.g.). fine by me. do we need to restrict that at all? Isn't field restriction not enough?. Could we rename it to BlockedGraphqlFieldVisibility? . Or maybe just BlockedFields ... . typo: \"you should called\" -> \"you should call\". I don't like this helper inside an interface. Can we extract it to its own class/file?. yes ... don't know how this happened, now fixed. done. done. This is an interesting general design question: should we prefer interfaces over \"simple\" value classes? \nI opted for value classes recently: See FieldComplexityEnvironment.. I like to use the By naming: getFieldArgumentsByName() or getFieldArgumentsByValues.  . not sure ExecutionPath is unique for queries including fragments:\nfor example:\ngraphql\n{foo{ \n... on Bar1 {name}\n... on Bar2 {name}\n}}\nQueryTraversal visits every possible outcome: This means name is visited for Bar1 and for Bar2.. side note: I am not sure about your example: it should fail validation because informationString must be exactly the same field (including arguments) because at runtime it is only one field.\nI think the only time ExecutionPath is not unique is when you have two ore more fragments with different type conditions and both have have subfields with the same name/alias.\nBut how to solve the problem: I think a Map ExecutionPath -> List is a good solution. But sure: we can of course do both.. my thoughts:\nInterfaces are the more cleaner way to represent an API. The mocking argument is also true (if you are not using Spock or want to mock it by hand).\nThe only downside with interfaces is that it is a bit more overhead, but I think in the long term interfaces are more safer for an library to expose.\nSo ... sure: I agree to favor interfaces.. same comment as before: I don't think this is a valid query example, because it will fail general validation.. this is not needed: please use each(List<CompletableFuture<U>> futures). good idea :-). Not sure when this exception can happen at all: I would probably to except that we need to check the futures.. Something like CompletableFuture.anyOf(futures) ... . Sorry, I was not clear. \nIt was more about the style: I don't think a method returning a CF should also throw exceptions: It should return a CF which completed exceptionally.  (Which means we should catch sync exceptions inside of fetchField etc)\nBecause otherwise we are mixing async with sync code, which we should try to avoid. \nSo I don't think we should catch a exception here, but handle failed CF results. (But you are right: not with .anOf ... we have to deal with each CF separately).\nFor example one case I think is still missing: a DataFetcher returning a CF which completed exceptionally with a AbortExecutionException.\n. Another thought: maybe even Instrumentation itself should become async too ... so that you can return a CF from beginField for example.. could you please not remove this extra line?. could you please not remove this extra line?. we also have the 'transform' pattern with a lambda as argument ... maybe we should do that? or both?. not really sure about that one: Can we the static factory method to somewhere else?. this is confusing I think: until know we only have DataFetcher ... no we say DataFetcherFactory can't be null: maybe something like 'you have to provide a DataFetcher (or DataFetcherFactory)' ?. I think it is safer for the future provide an ....Environment Object containing the fieldDefitinion, but also the parent \"container\".. maybe it is better to throw an exception if no SchemaDefinition can be found?. sorry, but not sure I get this: this interface has one field, so what is the problem?. just as a note for future improvements: we should also really document how to build it via Docker.. We should document what it means 'can be thrown by the graphql engine'. Does it mean I get an exception in GraphQL.execute' or a special error etc ... . I don't think this exception can escalate to the end user as an exception thrown from.execute... we handle it inhandleCoercionProblem`. I would prefer to have a very explicit error message: This is not a expected behaviour in any way and we should provide as much help as we can to find the error as quickly as possible.. if there are really use cases where this error message it to 'internally' we will tackle this problem on another level (more outside). . yes, that should be Spock before it will be merged.. I don't think this is the right place: it should be handled directly when the DataFetcher result is returned.. class is fine if we want Users to directly instantiate it.. we have your own Assert class .... please adjust your JavaDoc formatting to add a extra new line. not sure, but don't we have this or similar error class. can we add tests for this class? thx. this is confusing: this is just a string equals right? if we want it as a helper method it should be moved to some other place imho. what is the purpose of that? it is only a null check, isn't it?. no we don't use/have such an annotation. it is meant to be directly instantiated and not to be implemented, therefore we prefer to an easy to use object.. I see your point, but I prefer to keep it simple and see if there is really a need for more complicated use cases. If it comes up we are not afraid to make changes (even breaking ones) to support it.. Could you please remove this comment: we don't maintain such references to this original author as comments.. Could you please remove this comment?. Could you please remove this comment?. Could you please remove this two comments (created and author)?. Could you please remove this comment?. Could you please remove this comment?. could you please break this class up in several files? each interface etc should live in its own file. maybe its own package if you think they should be recognizes as belonging together.. not sure we wanna add both method  .. seems a bit verbose. or maybe at least provide a default impl?. why unmodifiable in this case? maybe a copy which could makes the life of the caller easier?. please use Assert.assertNonNull.. please use Assert.assertNonNull.. please use Assert.assertNonNull.. please use Assert.assertNonNull.. please use Assert.assertNonNull.. please use Assert.assertNonNull.. why is this protected and not private?. please don't use protected variables and please put them on on the top of the class. Is there a reason why every method returns Object and not T? . maybe the name of the test is not 100% correct anymore?. thanks for the explanation ... makes sense.\nWhat do u think about making the methods more readable by changing it to visitArgument, vistArrayValue etc?. @exbe but every accept method knows what type it is, why is reflection needed? just call the appropriate method. Or do I miss something?. @exbe I would like to see it renamed and make it more explicit to improve the readability: I am not really happy for example with this:  https://github.com/graphql-java/graphql-java/pull/905/files?diff=split#diff-516be31e8c1f5179246f61a317781d1c \nI think making it explicit by naming it visitXXX makes it more readable. . I don't understand: we need to import the rules we wanna use ... why is this only needed for IDEA?. \ud83d\udc4d . I think we should use this PR and rename TypeExtensionDefinition to ObjectTypeExtension to make it in line with the other names. how about splitting it up in several tests?. ah ok .. the only consequence is that we actually generate code for every rule in graphqlCommon, even if it is not really used. But on the other side there should be not unused rule, so \ud83d\udc4d . lets rename this field to match the others. you could have used groovy here instead of Java 8 ... but not really sure it is better, but probably shorter. sure ... lets merge it. this only happens when the scalar value is defined as a literal as part of the query (as opposed to using a variable). typo in seralise. I think we copied the exact behaviour of the ref implementation, but reading this again it seems inconsistend: two times exception and one null value. maybe we should explain it more (if we can) or change it.. I really think we should rename it to CoercingParseValueOrLiteralException or something similar: I am happy to use the same exception in order to not make it not too difficult, but CoercingParseValueException is a perfect macht for parseValue and it is just confusing to use it it for parseLiteral too without aligning the name. . maybe not type safe rather than \"un\"?. Not sure a AtomicRefernce is needed ... this is done synchronously, so a normal variable should be sufficient, right?. I hope this doesn't copy anyone ... maybe using the new java date (since java 8) might be better?. ah right ... all good ... the bit hacky alternative would be new ExecutionInput[]{executionInput}, but atomic reference is definitely nicer. TraverserContext is used by the general Traverser, so I don't really want to  bound it to the Ast Node: I guess we can also use it to traverse a GraphQLSchema or other tree structures. I think one of you mentioned this also before. Or did I get this wrong?. First reason was to make TraverserVisitor and NodeVisitor more clear about the return type: Before that it was just Object which meant anything or a special Marker Enum. Now it is clear that you should return a enum and only a enum which controls the general Visitor (Abort, Exit etc). \nSecond reason was that passing some data along and maybe generating new data out of it is a special case of the general Context imho: the last result generated (the parent result) can be used to generate a new result. But not always and I didn't found a good reason to introduce a extra argument just for this case. Now TraverserContext encapsulates really the whole context. . because having two separate classes which are just different by a slightly different pushAll methods are more complicated than having this check here. (Both classes implemented the pop method basically the same way, but with a different method on `Deque. This became immediately clear after I merged them, but before that it was not obvious)\nBut having two inline classes in RecursionState might be a good alternative.. agreed. changed it. But not sure what redundant code you mean ... I don't see it.. ok, changed it.. true, but having a side effect in isVisited I consider not ok: it is extremely unexpected and makes understanding the code very hard. And I don't mind the double lookup, because I don't think it has a real measurable performance impact. . I would consider that a problem of the user of the Traverser: If you implement equals/hashCode and have two different Nodes in your Tree which equals you made something wrong.\nAnd the only user of the Traverser is graphql-java itself, this means we are responsible for that.. regarding the first point: good catch, that was not intended, that needs to be fixed and tested. thanks\nabout the second point: not sure I understand it correctly, but cycle true means we encountered an cycle regardless of how we deal with it. I guess cycle is not a good name here: in the TraverserResult it is called enounteredCycle which makes the intention a bit more clear I hope. \nAnd fullTraversal means we aborted or quit the tree. Does this makes sense?\n. this is not a great type: List. Can we make it more clear?. not really sure I agree with abstract. Union is not really abstract like Interface. maybe just rename it to isInterfaceOrUnion?. this method is complex enough to justify maybe a test just for that.\n. maybe this a spec level problem, but I don't see they point to allow union types here: you can't implement a union type. I was thinking of some validation, where you wanna handle cycles explicitly.\nBut you are right: maybe I wanna all of them etc.\nBecause it is not used atm I will remove the cycle and the  fullTraversal property again. Keep it simple for the moment. The important aspect was to introduce a proper Result class TraverserResult.. small typo: comma should be after 'schema', right?. I would suggest to make it true by default, because the spec says: \"Directives must only be used in the locations they are declared to belong in. In this example, a directive is defined which can be used to annotate a fragment definition:\". So I would argue the spec requires it.. I think we should try to make this more clear via Documention or JavaDoc that the GraphqlArgument is used in two different contexts: in the SDL when declaring an directive or field and when executing an query as argument for an directive.. maybe we could add some flag to make it more clear if this argument is for a directive or field?. @bbakerman ?. because it is declared in the super interface already ... just a clean up :-) . ok. maybe make it clear what the difference is between this apporach and just using normal RuntimeWiring: something along the line of using directive as some kind of indirection or additional layer?. Not sure this is really a concern here, but we also support DataFetcherResult and Optional values, both are automatically unwrapped when executed. We could do the same here ... . Should be internal. just in general: I think it is better never to call join but to wait for for the result only a limited amount of time. This way we don't have blocking tests (without any real timeout) if it fails. (We have more tests with a blocking join or similar stuff, so it is not a big deal, but we should maybe consider in the future). I think we should unit test each of the possible locations for directive wirings.. I extracted an Interface instead. . extracted an Interface. mh ... I get your point but the arguments are mutually exclusive: for example operation is only valid with a Document, same with root and rooParentType etc.\nIs it worth extracting a whole QueryTraversalBuilder? Other options?. yes let us collapse it . I added it initially as a abortion exception for failed max complexity and then it was added as a exception for FieldValidation. So I think it belongs to GraphQLQueryException. \nThe naming is my fault and should be handled in another PR. . why is this deprecated now?. why does this reordering happen?. extract method \ud83d\ude04 . I think your formatter settings is not correct :-) \nSee: https://github.com/graphql-java/graphql-java/blob/master/graphql-java-code-style.xml. please remove them: they are not used anywhere else and were only for one purpose . Class name: 'GraphQLTypeVisitor' not 'GrapqhlTypeVisitor' . why the difference here between Interfaces and concrete types?. naming: GraphQL.... unit testing is missing: have a look at NodeVisitorStubTest for inspiration.. naming: GraphQL.... please make every class public and extract in a extra file. Don't make them package protected, but mark them as @Internal. please remove it . yes, please make it @Internal for now.. why protected? I would say make it private. We don't really design for inheritance: if there is something that should be customizable it should be done in another way.. private .. see above. private static please if we keep it, but more important: simplify it please by only caring about enter, because we only support depthFirst atm.. I agree with @bbakerman: the original code for isLeafType and isInputType is so much simpler and I don't really see a non theoretical argument to replace that. So please revert it to the original code and delete the LeafVisitor.. typo: I think you wanted to use stategyName based on #stategyName . this should be called sdl or  maybe schema I would suggest . maybe also check the data?. agree .... I will update the formatting xml settings in a separate PR. isn't that a breaking change?. typo: ihas. source has always been a bit confusing name imho: I often try to describe it as the result of the parent field DF. Not sure this makes it clear, but it is technically correct.. can we instead of having a unmodifiable map, return always a copy in getArguments? I prefer it because it is less surprising for the client imho.. It is also the dominant pattern in graphql-java overall I think.. This should be public: we recently made the general Traverser also public, so nothing prevents us from making this public too. just as a hint: we also have assertNoNull . what do you think about putting this class into the other one GraphQLTypeResolvingVisitor? it is a very hard dependency and it would make it more readable imho. should be Internal. should be Internal. should be internal. should be internal. I always prefer LinkedHashMap as the default impl because order of the keys is kept. can this be null? => unboxing will cause NPE. we must remember that must be changed again before merge!. you could actually return the Assert. so default is we always have one?. can we mark the constructor as Internal and I am not sure we should always create a new DLR here.. I see: so instead a nullalble or Optional DRL we check for content here. DLR is immutable, right?. it should always be a new DLR, right?. public? . public? \nIt should also return new LinkedHashMap, not the original Map. as you said: It should named Differently: so please rename it :-) (or maybe in an extra PR if you prefer). use GraphqlTypeUtil and assertTrue . I must say unwrappedTypeName is highly confusing: I would expect for a [Foo] it is Foo, but it is [Foo]. Trade off: it was used so much that it makes sense to add it here imho. But always a judgment call of course. I thought it is already public. We should make it public.. javadoc is the same as before. suggestion\n    public static String simplePrint(GraphQLType type) {\nI feel like toAst is a bit unclear, because we actually don't return an Ast (it is not a Node or so). So I am thinking about print or simplePrint (to make it more more clear that it is not a full print compared to SchemaPrinter). can you make sure you are using the https://github.com/graphql-java/graphql-java/blob/master/graphql-java-code-style.xml codestyle? thanks. our preference is to return copies of Collections in order to make it more comfortable for the users.\nThis is common pattern we don't wanna change.. gradle is updated now on master. maybe more descriptive: doesn't throw exception. Or make the assertion more clear and check really that the type rerference can be replaced.. I agree with keeping the old ones, the question is more: what is the pattern for new code?. I like the idea of adding a ThreadSafe annotation.. not List? :-) . not sure this is really public api ..... LinkedHasMap. LinkedHashMap. yea ... tradeoffs :-) . I think that is wrong :-) . will change. yes, it was just temp. yes, it was just temp. it is actually in Node. yes, will change. yes. make the class public. It is marked as Internal, so everybody can choose.. this whole logic  could be even stronger and the dataFetcher could be removed form the FieldDefinition.. why not using the same logic as for the DataFetcher and put the TypeResolver in the CodeRegistry?. also: I don't think the name GraphQLTypeCodeVisitor is so good. One reason is the whole GraphQLType thing, but we can tackle that when we do https://github.com/graphql-java/graphql-java/issues/1251 .\nThe other is: just name it maybe like CodeRegistryBuilder or so to better reflect what it does.. CodeRegistryVisitor sounds good. my bad . done. done. well: you can't add children to a FloatValue, so we only allow empty children here. changed it no java doc. fixed. fixed. I think this is misleading: the source object is the source object for the execution. We should name it differently.. refactored it . a groovy map with closures/functions as value ... not so crazy, or?. done ... I forgot FloatValue somehow. I removed all not used methods for now.. AstZipper and AstMultiZipper is actually not coupled to transformations: it is a general concept.\nthe only two transformation classes are AstTransformer and AstTransformerUtil. Extra package for them?\n. added. added. added. added. done. done via helper method. done. changed the name and added transform. return a new linkedhasmap here I would say . I agree in theory both are valid options, but in graphql java we decided to return new copies everywhere. . I need three states, therefore Boolean . It is just purely used internal class inside TraverserState and Traversal. The reason for this a bit weird class is this: \nhttps://github.com/graphql-java/graphql-java/blob/4789c7b4f65dd4f00695ba5bdc307edadcb57b08/src/main/java/graphql/util/TraverserState.java#L39-L54\nThe list must be pushed first, but the Map is only available a bit later.\nIt is just used internally and not a public API at all.. changed. this is not so great I think, because it kinda violates the expectation for a builder: if I set a new fetchValue it should be ok. \nthe error should be add in the constructor or maybe in the build method imho. I would not care at this point tbh: if the lookup fails you are doing something wrong higher up. added. changed it to fineOne AND findOneOrNull: our preference for returning null makes it a very common use case for us.. just call this.errror.add ?. mabye we should provide a single factory function to make the life easier for the clients?. yea ... don't have an answer to that, maybe it is better do have just default methods.. we have our own Assert class, please us that . we can't change this logic: it is essential for traversing a changed tree.. please use graphql-java code style. we have Assert.assertNonNull . but this assert is not really anyway, because we assume the query is a valid one, right?. union is missing here. union and scalar are missing here. we could allow empty parentheses e.g: extend type Foo @directive {}. also union is missing. not sure we need interface and impl thing here. Do we expect a second impl?. I think you didn't want get... ...... Should this now also be QueryDirectives?. you want a private constructor here maybe. why did you change the index? the spec says \n\nwhere each location is a map with the keys line and column, both positive numbers starting from 1 which describe the beginning of an associated syntax element.. we should have a test for sourceName being null. there is a FpKit.map function :-) . I think we should call it visitFragmentDefinition. visitFragment is not clear enough.. same as above: QueryVisitorFragmentDefitintionEnvironment is more accurate and more future proof.. a toString would be nice, but is not strictly needed.. this seems wrong or the naming is off: it is not a InlineFragment. \ud83e\udd14 . sure ... do it in one ... thanks. typo :-) . formatter? :-) . we should have a filter helper method, if not we should add one ;-) . not sure about these javadoc formatting. are u using the right formatter?. \n",
    "parallelcross": "Thanks again. It says it can't find the dependency \nrepositories {\n        maven { url \"http://dl.bintray.com/andimarek/graphql-java\" }\n}\ndependencies {\n       compile 'com.graphql-java:graphql-java:2015-08-01T00-17-47'`\n}\n. I did download the jar from bintray. I don't get the DexException anymore, but I do get:\njava.lang.NoClassDefFoundError: Failed resolution of: Lorg/slf4j/LoggerFactory;\n. I added the slf4j dependency and was able to get past the NoClassDefFoundError. I now get:\njava.lang.NoClassDefFoundError: graphql.parser.antlr.GraphqlLexer\n            at graphql.parser.Parser.parseDocument(Parser.java:18)\n            at graphql.GraphQL.execute(GraphQL.java:63)\n            at graphql.GraphQL.execute(GraphQL.java:54)\n            at graphql.GraphQL.execute(GraphQL.java:46)\n            at graphql.GraphQL.execute(GraphQL.java:42)\n            at providerbrowser.wellmatch.com.providerbrowser.MainActivity.onCreate(MainActivity.java:39)\n            at android.app.Activity.performCreate(Activity.java:5990)\n            at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1106)\n            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2278)\n            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2387)\n            at android.app.ActivityThread.access$800(ActivityThread.java:151)\n            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1303)\n            at android.os.Handler.dispatchMessage(Handler.java:102)\n            at android.os.Looper.loop(Looper.java:135)\n            at android.app.ActivityThread.main(ActivityThread.java:5254)\n            at java.lang.reflect.Method.invoke(Native Method)\n            at java.lang.reflect.Method.invoke(Method.java:372)\n            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:903)\n            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:698)\n. Sorry, that was just me mis-typing the dependency, the back tick wasn't in my build.gradle. I still can't resolve the dependency.\n\n. That did it. I was able to confirm the the library is working for me now. Thanks. \n. ",
    "IHNEL": "I got the same error although already set mavenCentral()\n`Error:Execution failed for task ':app:transformClassesWithDexForDebug'.\n\ncom.android.build.api.transform.TransformException: com.android.ide.common.process.ProcessException: java.util.concurrent.ExecutionException: com.android.dex.DexException: Multiple dex files define Lorg/antlr/v4/runtime/ANTLRErrorListener;`\n\nIf I set multiDexEnabled true, I got new error message:\n`Error:Execution failed for task ':app:transformClassesWithJarMergingForDebug'.\n\ncom.android.build.api.transform.TransformException: java.util.zip.ZipException: duplicate entry: org/antlr/v4/runtime/ANTLRErrorListener.class. I use v2.2.0:  compile 'com.graphql-java:graphql-java:2.2.0'. I did google but no solution help. This is my full gradle:\n(I also putmavenCentral()` on project level gradle ). I can sync the libraries without error, but I can't run the app.\n\n````\napply plugin: 'com.android.application'\napply plugin: 'me.tatarka.retrolambda'\nandroid {\n    compileSdkVersion 25\n    buildToolsVersion \"25.0.0\"\n    defaultConfig {\n        applicationId \"photos.waldo.demo\"\n        minSdkVersion 16\n        targetSdkVersion 25\n        versionCode 1\n        versionName \"1.0\"\n        testInstrumentationRunner \"android.support.test.runner.AndroidJUnitRunner\"\n        multiDexEnabled true\n    }\n    buildTypes {\n        release {\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'\n        }\n    }\ncompileOptions {\n    sourceCompatibility JavaVersion.VERSION_1_8\n    targetCompatibility JavaVersion.VERSION_1_8\n}\n\n}\ndependencies {\n    // general\n    compile 'com.android.support:appcompat-v7:25.0.1'\n    compile 'com.android.support:design:25.0.1'\n//GraphQL\ncompile 'com.graphql-java:graphql-java:2.2.0'\n\n//reactive programming\ncompile 'io.reactivex:rxandroid:1.2.1'\ncompile 'io.reactivex:rxjava:1.1.6'\n\nandroidTestCompile('com.android.support.test.espresso:espresso-core:2.2.2', {\n    exclude group: 'com.android.support', module: 'support-annotations'\n})\ntestCompile 'junit:junit:4.12'\n\n}\n``. I fixed this by:compile('com.graphql-java:graphql-java:2.2.0') {\n        exclude group: 'org.antlr'\n    }\n`. Thanks\nIm really new on GraphQL, so many new things to learn. You guys did a great job.. ",
    "dminkovsky": "What version are you using?\n\u0447\u0442, 1 \u0434\u0435\u043a. 2016 \u0433. \u0432 21:07, IHNEL notifications@github.com:\n\nI got the same error although already set mavenCentral()\n`Error:Execution failed for task ':app:transformClassesWithDexForDebug'.\ncom.android.build.api.transform.TransformException:\ncom.android.ide.common.process.ProcessException:\njava.util.concurrent.ExecutionException: com.android.dex.DexException:\nMultiple dex files define Lorg/antlr/v4/runtime/ANTLRErrorListener;`\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/4#issuecomment-264354032,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZYbvUAQKQiMBTtkmrAjdzg3O7is1ks5rD31DgaJpZM4Fj15_\n.\n. I am sorry I am not sure then why you are having this error. Maybe google\nfor \"android debug antlr runtime?\"\n\n\u0447\u0442, 1 \u0434\u0435\u043a. 2016 \u0433. \u0432 21:32, IHNEL notifications@github.com:\nI use v2.2.0: compile 'com.graphql-java:graphql-java:2.2.0'\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/4#issuecomment-264357532,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZT04DlSCg2pX_a0UbP0dpGdRI131ks5rD4MfgaJpZM4Fj15_\n.\n. Oh wow I am sorry\u2014I thought 2.2.0 had a fix for #225 (\nhttps://github.com/graphql-java/graphql-java/issues/225), which is the\nissue you experienced, but that fix was merged just after 2.2.0 was\nreleased. That was why I asked you which version you were on. Anyway, I\nhope you didn't waste too much time. The next release will have this patch\nand you won't have to have this exclude in your build.\nOn Thu, Dec 1, 2016 at 10:59 PM, IHNEL notifications@github.com wrote:\n\nI fixed this by:\ncompile('com.graphql-java:graphql-java:2.2.0') { exclude group:\n'org.antlr' }\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/4#issuecomment-264368039,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZXdNrMKO2DXXIpZ6gdhx3dNrAAjXks5rD5e0gaJpZM4Fj15_\n.\n. Thank you!. @kroepke cool, thanks for checking in!\n\n@metacosm\n\ncalls FieldCollector.checkTypeCondition where the resolved type is instantiated by my type resolver:\n\nYes, this issue is mentioned at the bottom of https://github.com/graphql-java/graphql-java/issues/205#issue-176456291: it would be useful if the TypeResolver interface provided an instance of the schema in the resolution method. Otherwise, you need the schema somehow available in the TypeResolver's scope, which might require more work on your part. \nBut yes, as you see, the schema definition system as it stands is all about simplicity and therefore uses reference equality/identity. Not great, but at least simple. \nI, too, would prefer a value-based schema system. But, I am not really comfortable with a hashCode/equals that's based entirely on one field like \"name\".\n. Hey @zourzouvillys, thank you for this PR. Sorry it took so long to be resolved! Following up with some updates to the grammar in #243, I've incorporated your concept here in to #277. Will close this and merge that. Thanks again.. Closing this in favor of #204, which is more comprehensive.\n. @akhahaha Yeah I am interested in that too. How do you envision it would work, a bit more specifically? Thank you.\n. Hey everyone,\nI'm away for a few days and looking forward to catching up on this. Thanks for the PR. \n. Just took a look over this PR. Thank you again for it!\nI don't fundamentally understand why this library itself should provide the asynchronous behavior. For example, if the library is taken as it is today, and a user wants to make #execute() return a CompletableFuture, instead of changing this implementation, why not just wrap #execute() in something that creates and returns the future? That \"something\" can then complete the future whenever the query is resolved?\n. Perhaps such a wrapper that returns a CompletableFuture could be called GraphQL#executeAsync(), in the spirit of Bluebird promisification? That way we'll have APIs that are both sync and async. \n. The data fetchers would work the same. All that changes is the addition of this top-level wrapper and its other overloads:\npublic CompletableFuture<ExecutionResult> executeAsync(String query) {\n  return CompletableFuture.supplyAsync(() -> {\n      return graphQL.execute(query)\n  })\n}\nIf you want to parallelize field resolution, you use the executor service.\nThen again, this wrapper is so simple, and it forces JDK 6 to JDK 8, that I'm not sure it's necessary.\n. > Also, I could be wrong in my understanding of the implementation, but aren't DataFetchers at the moment required to return the various built-in GraphQL Scalars types (or GraphQL objects/maps/models built from said types)?\nYeah, they need to return values that can be coerced or the resolution fails. But I think the wrapper concept solves the broader problem?\n. > If I block for the result and return the User result directly, it succeeds. I would like to receive the ExecutionResult only when this (and all other) asynchronous DataFetchers resolve without blocking.\nI came to Java from JS and I think that trajectory causes me to think this way as well. But I'm not sure there's any reason not to block here, especially with the executor service-based strategy. Each data fetcher might as well just block and resolve synchronously.\nI mean the beautiful thing about Java is that you can block! And there are so many beautiful, clean, synchronous blocking APIs out there (Kafka an Kafka Streams, for example), it makes me dread the whole \"What Color is Your Function?\" JS experience. \n\nI still wonder if async behavior shouldn't be default, again pointing back to the JS implementation.\n\nI'm a huge proponent of having this implementation look and feel as much like the reference JS implementation as possible. But here we have a great JVM feature (first-class threads; the ability to write clean simple functions), that I think it makes sense to deviate and use this JVM feature.\n. @akhahaha I am sorry about my delayed responses. I am glad to hear it and am glad that my suggestion makes sense. I wasn't sure whether I was addressing your question, but I think we are on the same page. Yes\u2014we definitely want to improve the docs wherever possible. Where in the README do you think adding this would have greatest impact?\n@hepin1989 @oexza I am not sure I understand why the executor service strategy doesn't provided the flexibility you are looking for. Can't you still use your own thread pool / executor service in the data fetchers as they currently are?\nI should also emphasize that Java 6 compatibility is an important goal for this project that we are seeking to maintain for as long as possible. We have Java 6 users running this in production, and that is pretty cool in my opinion!\n. @hepin1989 by the way, if you are using Akka/Scala, have you checked out Sangria? \n. So I've spent the past few weeks attempting to enlighten myself on this issue. Here's what I've found:\nAt this time, there are too many disparate async libraries/mechanisms in the Java world for this library to adopt one particular approach. The JS implementation is simple: there are no types, and @leeb just tests results for .then() to determine if the result is a Promise. Very simple! \nBut no such thing in Java. Before Java 8 you had RxJava Observable and Netty's ChannelPromise. Now Java 8 adds another mechanism: CompletionStage/CompletableFuture. There are all different, and to me it doesn't make sense to bake any of them into this library as the canonical way to be async. \nCan we just have execution strategies for each of these? @pcarrier has one for RxJava; @akhahaha showed how one could be written for CompletionStage/CompletableFuture. \n. > Maybe the project could be improved to facilitate various extensions more easily\nSo my conclusion has been that implementing an ExecutionStrategy is simple enough. You have to implement execute() and you'll probably have to override resolveField, but between those two methods I think you can make anything happen. That's my opinion anyway. \nI'm in the process of writing an strategy for CompletableFuture and will share when it's finished.\n. @benhead thanks for your post. That page is about the reference, JS implementation. The asynchronous execution strategy I am working on uses Java 8's CompletableFuture interface...\n...which I just PR-ed. If anyone is interested in this, please comment there.\n. Closing this in favor if #172 which has PR #204.\n. Hi, thanks for posting. This is beyond the scope of this project, but check out some related things:\nhttps://github.com/graphql-java/graphql-java-annotations\nhttps://github.com/graphql-java/graphql-java-type-generator\nhttps://github.com/bpatters/schemagen-graphql. Hi, thank you for posting. I believe this issue is related to a misunderstanding of how GraphQL execution works and confusion around the root (passed to GraphQL#execute()) and \"source\" from DataFetchingEnvironment#source() in the DataFetcher, and even the \"execution context\" which is a private API. We should improve documentation, but I am closing this as this is not a bug/not something we'll change. Thanks.. Hi @hannesj. Thanks for the suggestion. A question:\n\nWould you be willing to accept a PR that refactors the current implementation to use the (non-time-limited version of) invokeAll instead of starting the execution of the futures individually, so that we could even offer the time limited version in the default ExecutorServiceExecutionStrategy?\n\nIf the current executor service strategy is modified to use the non-timed #invokeAll(), the result will be equivalent to what we currently have, right? How, then, will a timed version be provided?\n. Let's talk more about this. I don't have a ton of Java experience, especially in terms of seeing how Java libraries in practice practically solve such problems. \nI really like the idea of moving the schema definition types in the direction of value-based classes. However, I don't see exactly how a single string property like \"name\" is actually any sort of meaningful equivalence relation. \nThen again, I also see what @danielkwinsor means when he says:\n\nif we start worrying about DataFetcher equality we are in for a world of hurt.\n\nWhich is fine: for a field definition we don't have to look at data fetchers. And we shouldn't, because we want a field defined on an interface (does not have a fetcher) and a field defined on an object (has a fetcher) to possibly be equivalent, data fetcher aside.\nBut say we have two object types. How can we just compare their names and skip looking at their fields?\nFinally, circularity is also an issue. Types can be circular: a field on an object type can be of that same type. So, what: we ignore type in equality? Seems like a poor equivalence relation for an object/interface if you ignore its fields and their type.\n. > From this, I infer that two types with the same name must be equal or the schema is invalid.\nRight: they must be equal according to the spec. But what if due to say, a bug, they are not? \nSay I have one spot in my code where I have:\nnewObject\n  .name(\"Obj\")\n  .field(newFieldDefinition()\n    .name(\"field\")\n    .type(GraphQLString)\n    .build())\n  .build()\nand another where:\nnewObject\n  .name(\"Obj\")\n  .field(newFieldDefinition()\n    .name(\"field\")\n    .type(GraphQLInt)\n    .build())\n  .build()\nthen, say, in some other code I compare these definitions and the result is they are equivalent. Then how much longer down the line will this bug manifest? \nMy point is\u2014and sorry truly if I am missing something or am just being too pedantic\u2014that yes, the spec says a type's name should be unique. But from a runtime Java perspective, two object definitions with the same name can be totally different, and the usefulness of an equivalence relation that only compares their names seems, well, not useful, and even worse, bug prone?\n. > The error would be detected when the schema is built [...]\nNot if it's a type that's not included in a schema. It sounds like you're doing just that in a type resolver: returning a type by building it right then and there. If it's never part of a schema, there's no way to validate it against other types.\n\nIf we cannot provide a valid implementation of these methods that allows semantically equivalent objects to be recognized as equal, then we shouldn't allow direct instantiation of these types and always go through the schema as a factory/registry.\n\nYes, I agree... that's why, for example, I liked the idea that type resolvers should have access to the schema. But it would be better to figure out a way to have equals/hashCode... I think. My problem is that I spent like 4-5 hours on it one day and couldn't quite find a good way that works with all the aforementioned issues, like type circularity or data fetcher equivalence. I would love to have these classes be value-based, as long as the equivalence is meaningful and useful.\n\nThe reverse from a Java perspective is just as bad. It breaks pretty much all the Collections that semantically equal objects are considered different because they lack proper equals / hashCode implementations.\n\nYeah, I agree. I want to hear what other people have to in order to decide how to move forward. Right now we have three options:\n1. Keeping things as they are: you can construct definition types however you please, but we aware they only support reference equality.\n2. Definition types can be constructed only within the scope of a schema and can only be accessed from that schema.\n3. Definition types can be constructed ad-hoc but support equality/hashCode.\n. Thanks for this. I'll think about it a bit more. Also reading the link, which is very interesting considering it has a heading called \"What should equality mean?\" and it's by BG :D\n. Hi Grigory. There are no such plans at this time. There is interest in a\nJava 8 secondary artifact, but not changing the core. Thanks for posting.\n\u043f\u0442, 23 \u0434\u0435\u043a. 2016 \u0433. \u0432 2:21, Grigory Ptashko notifications@github.com:\n\n@corydolphin https://github.com/corydolphin @andimarek\nhttps://github.com/andimarek Guys, what are the plans for moving to\nsourceCompatibility to 1.8? We are using Java 7 in production and don't\nplan to move to 8. I work in the biggest russian touroperator. We've got a\nvery high loaded system and very-very bug codebase and just started to use\ngraphql. It is simply impossible to move to Java 8 and the moment. I'll be\nvery sad if the whole graphql-java project switch to Java 8 :(\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/87#issuecomment-268950261,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZXg1ySeIC7OfDxYy1dNiZk3amZrrks5rK3ZtgaJpZM4Haprx\n.\n. I've been thinking about making the default data fetcher configurable.\nWould that help?\n\n\u0432\u0441, 18 \u0434\u0435\u043a. 2016 \u0433. \u0432 2:20, Cory Dolphin notifications@github.com:\n\n@andimarek https://github.com/andimarek I'd love to re-open this\nconversation if you are interested.\nI think it would help the project to bump the source version to the much\nmore modern Java 8. This would allow us to remove the reflection based\nPropertyBasedDataFetcher, and instead simply use Java's native Method\nreferences.\nE.G. PropertyDataFetcher(\"booleanFieldWithGet\") could simply be replaced\nwith Object::booleanFieldWithGet.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/87#issuecomment-267807494,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZZjOZRhsJ5IDRzrr7bMkOFleMJYMks5rJN7YgaJpZM4Haprx\n.\n. @corydolphin great, good to hear.. Closing this in favor of #280, which includes all of the generics-related changes in this PR. Thank you @fredrik-hultin an reviewers.. Following up on #208. Closing this. Thank you.\n. This issue https://github.com/graphql-java/graphql-java/issues/259 is the same thing. I closed it because I don't think the built-in scalars should account for this. Writing a scalar with the exact behavior you want is easy. And could be contributed even as a side-project. \n\nBut, if this is an issue that affects many people, maybe it should be included? I don't know.. Yeah if we're talking least astonishment and we believe this is a common\nsource of astonishment then we should remove this source of astonishment\ndespite \"correctness\".\n\u043f\u043d, 30 \u044f\u043d\u0432. 2017 \u0433. \u0432 16:31, bbakerman notifications@github.com:\nI think this issue between \"strict correctness\" and developer expectations\nof \"least surprise\" are going to keep catching the code out.\nI know I got caught out using GSON and pumping it into the graphql lib and\nso will others.\nAt a minimum we should update the readme with examples about GSON etc...\nI would argue the library should co-erce much like JS would do. And then if\nyou want strict Scalars you could have a graphql.strict.Scalars say.\nOr we make it strict by default and have graphql.lenient.Scalars\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/105#issuecomment-276197371,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZawOp1_OPB8HFniTK7IZraFyEdQPks5rXlbOgaJpZM4Hw3kl\n.\n. Thank you for posting. This should be fixed with #156.. #123 was merged a few days ago. @yrashk Do you think that takes care of this issue?\n. @DomKM yes we're trying to figure out an approach for this, for the next breaking release. \n. Looks good to me.\nDaniel Windsor says he has a test case, if I understood\nhim correctly. Could add that too as part of another PR. Maybe open an\nissue for that if you merge this PR, so we don't forget.\n\u043f\u044f\u0442\u043d\u0438\u0446\u0430, 26 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Yurii Rashkovskii \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nGuys, any objections to merging this PR? It looks like the problem\naddressed here keeps popping up in different projects and this PR fixes it.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/123#issuecomment-242761322,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZRg4VGe6J9HQlGx8mdP0LcTmwBJXks5qjwDIgaJpZM4IOU3w\n.\n. @danielkwinsor this printer is for printing GraphQL AST Java Objects (graphql.language) into a GraphQL string. The use case for me is to manipulate input GraphQL AST and then print it back out into GraphQL string as a request to an upstream service.\n. @yrashk this is actually not a schema printer. This is an AST node printer. A schema printer is needed, too though, for the purpose you mention. Should also be pretty simple, but with tests.\n. Closing this for now. Can revisit with pull request.\n. Re-opening because we definitely want a printer. Just want it to be tested and on a PR. \n. I'm still confused regarding the mentions of JSON and specifically Jackson here. This printer produces GraphQL Documents from AST nodes. Is JSON relevant to this?\n. Makes sense to close this then!. I mean I think this is a bug. I convinced myself that this wasn't a bug some time ago, but now looking at it again, I don't see how.\n. I will add a test \n. Cool, thanks.\n\nBy the way, thanks to this issue/commit, I made this Maven plugin that helps accelerate iterating with Relay: https://github.com/dminkovsky/babel-relay-maven-plugin. If you use Maven and Relay, you'll find it useful? \n. Yeah I think this also should be added to the codebase. If you PR that would probably speed this up. Otherwise I'll get to it too.\n. Hi @iancw. Thanks for this PR!\nThis appears to be related to #164, which was recently merged.\nThe conversation on #164 touched upon the extent to which we want to make PropertyDataFetcher support various use-cases at the expense of being a very simple built-in data fetcher. google/auto is probably used quite commonly, but given how easy it is to make one's own data fetchers, I'm not sure it makes sense to extend the very simple built in to cover this scenario. The decision to support various boolean prefixes on #164 was based on repeated community demand.\n. Thanks for posting @Jimexist.. Thanks for this PR. Will review this and get this in for 2.1. We need to resolve this issue.\n. @camuthig thanks for pinging on this! Yes\u2014I noticed this was not resolved after we published 2.2.0. Slipped through the cracks. Looking forward to addressing this.\nI have not seen the Null RFC but funny you mentioned it I was just looking at something about Relay 2.0 yesterday that made reference to it. Will have to take a look. Thank you.\n@trevor-morris Thanks for your update!! I will review in the next few days. Looking forward to closing this out.\n. This is cool. Improving the builders would be nice. Some thoughts:\n- This project is implemented in Java 6. I don't think lambdas can be used unless that requirement is dropped.\n- Other improvements to the builder system can be to add overloads that allow builders to be passed in where completed objects are required. Meaning we don't need to explicitly .build()\nGraphqlObjectType obj = newObject()\n  .field(newFieldDefinition.name(\"...\").type(...).arguments(...))\n  .build();\n. @aschrijver I updated my example. I didn't mean to exclude required fields in the example.\nSo, I am saying that it might be worth exploring adding the overload GraphQLObjectType.Builder#field(GraphQLFieldDefinition.Builder field), and so on, everywhere an object that has a builder is expected. Such overloads call .build() on the builder, so you can just pass in the builders without calling .build() yourself.\nI don't know about it also filling in default values. I'd rather such an overload just call .build() on the field and otherwise behave completely the same. So you don't have a tail of .build()).build()).build()).build())... at the end of your schema.\n. @aschrijver oh, and regarding Java 6 vs Java 8\u2014yes, I figured that might be the case. But then the code should be written in Java 6 and a person using the Java 8 SDK will be able to use lambdas, right? The code needs to compile with the javac set to 1.6, right? I have also envisioned this lambda option wherein you don't actually have to instantiate your builders!\n. @IamCornholio I think we are all on the same page. Your proposed BuilderFunction will compile on 1.6 and then enable people on 1.8 to use lambdas. \nWhat do you think about adding overrides that let you pass unbuilt builders, too? (the overrides just call .build() on the builders, and nothing else). That would prevent a trail of .build()).build()).build())... at the end of your schema/type definitions.\n. Appreciate it! Thank you! Will review this afternoon/evening.\n\u043f\u044f\u0442\u043d\u0438\u0446\u0430, 19 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Nikhil Agarwal \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nSorry for the spam. I've updated this PR and it's scope.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/159#issuecomment-241142168,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZcNqpdCsAefmxXCwpxDhoKv06XPIks5qhiJpgaJpZM4IwdV8\n.\n. This looks good to me, thank you.\n\nI couldn't find any other places where the changes in this PR might also be applied. Also, I don't see unit tests for these schema classes, so there's no obvious existing place we could add tests for this, right?\nOnly thing I'd say is, if possible, could the commit message for 90b6b2f be split over several lines  (git rebase -i, if you're familiar with that?), like\n\nSummarize changes in around 50 characters or less\nMore detailed explanatory text, if necessary. Wrap it to about 72\ncharacters or so. In some contexts, the first line is treated as the\nsubject of the commit and the rest of the text as the body. The\nblank line separating the summary from the body is critical (unless\nyou omit the body entirely); various tools like log, shortlog\nand rebase can get confused if you run the two together.\n. Oh my, for some reason I thought 90b6b2f was from your pull request. Sorry for the confusion. I don't know the width thing to be a standard so much as a widely adopted convention I've seen. \n\nYeah if you feel like squashing these down you could do that. I wasn't going to suggest it but please do if you see some commits you think can be easily combined for clarity/atomicity. \nThank you!\n. I love git rebase -i or even just resetting a branch and redoing the\ncommits. But it can get way out of hand sometimes so I never wish that upon\nothers.\n\u0441\u0443\u0431\u0431\u043e\u0442\u0430, 20 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Arnold Schrijver \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nHa ha ha, I understand. I am also a bit of a fanatic sometimes, I must\nadmit \ud83d\udc4d\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/159#issuecomment-241237564,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZYc50bVo2O3T6671h49m_edRv2skks5qh8yXgaJpZM4IwdV8\n.\n. Hey. Back from vacation here. I added some line notes to your commit. But I think it would be easier if I just made the chances. I'll open a PR against your repo. Thanks.\n. @IamCornholio okay so I opened https://github.com/IamCornholio/graphql-java/pull/1 against your repo. Please review and let me know what you think over on that PR. \n. @IamCornholio Good morning! \n\nYeah, I think removing those .build() calls is a great way to test that this works. Looks good to me. Thanks.\nPlease feel free to squash/edit history however you want. I had those commits set up for clarity within the context of this PR. Combining them all before merging makes sense to me. \nThank you.\n. I think this would expand the API too much with little or negative gains given the added complexities. Take the example in this PR: the changes cover only scalars that are built-ins. But scalars can be defined ad-hoc. So if you define your own scalar and this API exists, the scalar you defined is somewhat of a second-class citizen because it doesn't have this API.\nThis also steps deviates from the JS implementation, in the sense that the JS implementation does not have this syntax. I know there is no requirement to make this implementation look like the JS implementation, but I do think it is best to follow the reference implementation's lead on look and feel to the extent that language differences allow. \nI want to improve the builder interface, but I don't think this is a step in the right direction.\n. Thank you for posting :D. Let's continue on #159. I want to get a next release going with some merges in the next two weeks.\n. Yes, thank you for this PR! Let's fix this, given the demand.\nWhat do you think about this: https://github.com/dminkovsky/graphql-java/blob/8efb230b58224488c335cc8409c17a73f0657b51/src/main/java/graphql/schema/PropertyDataFetcher.java\nI think it might be clearer?\n. Whoops didn't mean to overload getPropertyViaGetter there. One of those should be renamed.\n. @ayhanap cool. If you like that more, feel free to update your PR with that variant and we can see what other people think. Will be glad to close this one.\n. @ayhanap cool, thanks. I think there's also @markphilpot's question regarding that caught-and-then-immediately-thrown NoSuchMethodException in getPropertyViaGetterUsingPrefix(). It does seem that it's not necessary?\n. I kind of like the idea of keeping the surface of this class small, like it currently is. Property fetchers, after all, are a core public API. If people need some specific functionality they can write their own property fetcher and with lambda notation this is trivial for a simple property reference. To me, this PR is about responding to a specific repeated request from multiple users.\nSo, let's revisit adding more functionality to this property fetcher when there is repeated, specific demand? I like how it looks right now as of this PR, especially with the removed unused fields.\n. Thanks Mark\n\u0441\u0443\u0431\u0431\u043e\u0442\u0430, 20 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Mark Philpot \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nMerged #164 https://github.com/graphql-java/graphql-java/pull/164.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/164#event-762172609,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZYLq6dN71JDtpZLJ6U1ls95S2VlXks5qh4vQgaJpZM4I2vHN\n.\n. Oh no thankfully on the east coast of the US. Have my phone in Russian\nthough, so it does this. I try to get to sleep at a reasonable hour :)\n\n\u0441\u0443\u0431\u0431\u043e\u0442\u0430, 20 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Mark Philpot \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\n\u043f\u043e\u0436\u0430\u043b\u0443\u0439\u0441\u0442\u0430\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/164#issuecomment-241232258,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZRFzIo2I7fRWpEB5tFDen3vukEmgks5qh6AUgaJpZM4I2vHN\n.\n. @ntkoopman yeah you're right:\nYour code will fail if the dataFetcher returns something other than a Map.\n\nThat is unacceptable. Will close this.\n. Oh I did not notice this failed. Will review. \n. Closing for now. Can revisit later with PR\n. @kristofdepypere are you available to discuss this issue further? Is it still affecting you?\nRegardless, regarding making the validation optional: it is possible we could do this. The spec states:\n\nTypically validation is performed in the context of a request immediately before execution, however a GraphQL service may execute a request without explicitly validating it if that exact same request is known to have been validated before. For example: the request may be validated during development, provided it does not later change, or a service may validate a request once and memoize the result to avoid validating the same request again in the future. Any client\u2010side or development\u2010time tool should report validation errors and not allow the formulation or execution of requests known to be invalid at that given point in time.\n\nAs an immediate workaround, please see GraphQL#execute(). You can use that code to execute your own queries, excluding the validation bit\nValidator validator = new Validator();\nList<ValidationError> validationErrors = validator.validateDocument(graphQLSchema, document);\nif (validationErrors.size() > 0 {\n    return new ExecutionResultImpl(validationErrors);\n}\n. @kristofdepypere Looking at this again now. What a bummer you didn't open that 15.5% section that shows what's taking up all the time in LanguageTraversal.traverse :) If, by chance, you do this again in the future, please post. I'll have to get jprofiler or similar rolling soon, so will try to repeat this experiment. Do you, by chance, remember what kind of query you were using (large/small deep/shallow)?\nAnyway, thanks again for posting this.\n. Cool. Thanks for the update. Let's leave this open in case anyone else experiences this.\n. Merged #204. Hello everyone! I am Dmitry and I was recently added as a maintainer to this project. I am also invested in this library and look forward to spending time working through issues with you guys.\nSince I am new to this project, it would be helpful for me to find out which issues, if any, are most important to everybody, so we can turn our attention to them.\n. @kaqqao thank you for your feedback!\nPlease follow up re: #172 when you're back and have some time. It would be nice to see if we can unfork you. I've come across https://github.com/facebook/graphql/issues/189 in other contexts, too. It's an interesting part of the spec. \nI will work on #126. I don't want to add that printer without tests, and will most likely just port the tests from the JS reference. Nothing complicated there. Just a bit tedious. I also am not a huge fan that this printer replicates the type matching found in TraversalContext.java. Would be nice to factor this out. \n. Just wanted to leave a note here that I am on vacation this week, so my ability to work on issues here will be reduced until I am back next week. \n. @crazytoucan thanks for pinging on this. Nothing in particular was holding up this PR. Just lack of attention, unfortunately. With your interest, though, I will mark this for 2.3.0.\nAn update though; re:\n\n\nFix a problem with the KnownArgumentNames validation check. It was assuming all arguments belonged to a field, but they can also belong to directives. So changed the level of the check - we check fields and directives for unknown argument names, rather than looking at an argument and then assuming it must belong to a field.\n\n\nI recently merged a PR (#180) that fixed this rather embarrassing issue! So that is already on master.\nI will look at the rest of this in the coming days.. Hey @IamCornholio, thank you for these fixes. The second bullet point was already addressed in a #190. I had to merge this PR as a result, so in the process I broke the remaining two bullet points into PRs #274 and #275. Closing this and merging those. Thank you!. @xuzb can you please give a code example that demonstrates the problem? This implementation uses BigDecimal when parsing FloatValue input strings. \n\"Long\" is not in the grammar because it is not part of the GraphQL grammar.\n. Closing for now. \n. Hey sorry about the confusion here. @xuzb can you provide a value or example that lead to the exception?\n. The issue here is actually that the query is not valid. \nThe schema defines output type of mutation field \"testLong\" as a scalar GraphQLLong, not an object. The query provides a selection set for that field. That is not valid. The error in ExecutionResult is a validation error that asserts this problem.\nIf you remove the selection set, like so:\nExecutionResult result = new GraphQL(schema).execute(\"mutation mu { testLong (input: {longValue: \" + System.currentTimeMillis() + \"}) }\");\nyou get the expected result.\n. I don't see anything wrong. Try for yourself please:\n```\npackage graphql\nimport graphql.schema.*\nimport spock.lang.Specification\nimport static graphql.Scalars.GraphQLLong\nimport static graphql.schema.GraphQLArgument.newArgument\nimport static graphql.schema.GraphQLFieldDefinition.newFieldDefinition\nimport static graphql.schema.GraphQLInputObjectField.newInputObjectField\nimport static graphql.schema.GraphQLInputObjectType.newInputObject\nimport static graphql.schema.GraphQLObjectType.newObject;\npublic class LongTest extends Specification {\ndef \"longtest\"() {\n    when:\n\n    GraphQLObjectType mutation = newObject()\n        .name(\"mutationType\")\n        .field(newFieldDefinition()\n            .name(\"testLong\")\n            .argument(newArgument()\n                .name(\"input\")\n                .type(newInputObject()\n                    .name(\"LongInput\")\n                    .field(newInputObjectField()\n                        .name(\"longValue\")\n                        .type(GraphQLLong)\n                        .build())\n                    .build())\n                .build())\n            .dataFetcher(new DataFetcher() {\n                @Override\n                public Object get(DataFetchingEnvironment environment) {\n                    return environment.getArguments().get(\"input\").get(\"longValue\");\n                }\n            })\n            .type(newObject()\n                .name(\"LongOutput\")\n                .field(newFieldDefinition()\n                    .name(\"longValue\")\n                    .type(GraphQLLong)\n                    .dataFetcher(new DataFetcher() {\n                        @Override\n                        public Object get(DataFetchingEnvironment environment) {\n                            return environment.getSource();\n                        }\n                    })\n                    .build())\n                .build())\n            .build())\n        .build();\n\n    GraphQLSchema schema = GraphQLSchema.newSchema()\n            .query(mutation)\n            .mutation(mutation)\n            .build();\n\n    // Input a large long value\n    ExecutionResult result = new GraphQL(schema).execute(\"mutation mu { testLong (input: {longValue: \" + System.currentTimeMillis() + \"}) { longValue} }\");\n    for (GraphQLError error : result.getErrors()) {\n        System.out.println(error);\n    }\n\n    then:\n    null\n}\n\n}\n``\n. @IamCornholio #136 added thelocations` field but did not provide a data fetcher. I suppose that was enough for GraphiQL to work, but I don't know how it would actually provide true results for that field without #175. \nClosing this. Let's continue on #175. Thanks everyone.\n. Yes, indeed, the purpose of dictionary is to provide types to the schema in the event that you want to define types that are not reachable from the query or mutation roots. \nThis set is an array called types in the JS implementation. I agree that \"dictionary\" is an unfortunate name. It would be nice to change this, but not high priority given that this issue exists for reference and that most likely this is not a feature that many people are using. \n. I don't think this is worth adding to the codebase. Filtering out the introspection types in application code is easy enough that I do not think we need to expand this codebase to support that. \nFurther, and quite important in my opinion, is the fact that the introspection types are true, real types in the schema. I can see there might be many times when you are not interested in these types, but generally I don't think this implementation should provide a function that filters out real, legitimate, queryable types.\nHowever, if this becomes a popular request, we can definitely revisit. Closing for now. \n. This is interesting and seems harmless enough. Except I am unaware of such functionality in any other implementation. That said, I only follow the JS implementation, so please let me know if I am wrong. A goal of this implementation is to follow the spec and to also be as familiar as possible to people coming from other implementations. \nFurthermore, a work-around for the absence of this feature exists: one can (ab)use the description property to store metadata. You might have to employ serialization/deserialization if your metadata is structured. But still, at this time, I think description fits the bill sufficiently for metadata.\nSo I am closing this for now to possibly revisit later.\n. @aschrijver I see. I usually look through open and closed issues when searching for a topic. If the issue is closed, I check to see why it is closed. So I didn't know that there is a convention that Closed means Done or WontFix.\nBut yes, I can see how that might be confusing and counterproductive. So by that token, I guess this issue is re-opened, because this subject is by no means done or wontfix ever. \n. @aschrijver would #180 address this issue?\n. Cool. Sounds good. Closing for now.\n. Ditto. How did you poke it? I wasn't sure what to do.\n\u0441\u0443\u0431\u0431\u043e\u0442\u0430, 20 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Mark Philpot \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nPoked the build. This is the same query I used for introspection so I'm\nglad it's a part of the project now. Assuming the build goes through I'll\nmerge it.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/187#issuecomment-241232651,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZcyz63pX2NyiMAQAOFjlcYP7wmZ6ks5qh6MJgaJpZM4JmxJ9\n.\n. I'm fine with this and would prefer to just have GitHub for now. \n\nFurther, it might make sense to create a graphql-java tag on SO and direct question type issues there. (say #192, for example)\nOtherwise, I don't think we could sustain a Gitter/Slack/IRC chat. I'm not in the market for a dead or near-dead chat to monitor. \n. Yes, will be fixing this now. Patch and tests look good. Thank you.\nSorry about the horrible delay here! I had this patched locally and somehow didn't realize this hadn't been merged. \n\nCurrently graphql-java doesn't realistically support directives\n\nYes, yikes. I am going to see about getting this released to Maven soon. Please ping more if other issues are like are not addressed in the future.. Hi Daniel,\nCould you please post your schema definition code? Hard to tell without\nseeing that.\nThanks\n\u0441\u0440\u0435\u0434\u0430, 24 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Daniel Schonfeld \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nI have the following schema:\nquery {\n  viewer {\n    someInfo(type:X,id:500) {\n        name\n        address\n    }\n  }\n}\nI have modelled it so that the arguments type and id are put on the\nsomeInfo GraphQLObject and so is the dataFetcher(). I start my java\nserver in debug, breakpoint inside my DataFetcher and nothing.\nIs there a reason for that? Am I missing something really obvious or is\nthis a bug?\nI am using the viewer object to get over the limitation of relay JS\nallowing only 1 or 0 arguments in root queries.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/192, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZZ98PV90dkpUuF1rOUVkG55MfgjHks5qjNhYgaJpZM4JskIr\n.\n. Thanks for the code. How are you executing the query? What is the source argument? \n\nWhat is the result?\n. @danielkwinsor not interested so much your leaf data fetcher implementation as the ones that lead up to that leaf, and the source. By source I mean the context parameter that you can pass to GraphQL#execute(). This is the object against which the query is first executed against. \nAre you getting null as the result?\n. So something is going wrong before your data fetcher is reached. Some debug suggestions:\n1. You can examine the result of GraphQL#execute() to see if there is an error. I bet you'll get something here.\n2. You can implement a data fetcher at each level and debug step through these data fetchers to see which fails. I suspect this won't be necessary as your error will likely crop up in 1.\n. @danielschonfeld just as you did above with .dataFetcher(SomeInfoFetcher()):\n.dataFetcher((env) -> {\n   // break here \n})\nat every level, starting from your viewer field. Your result has viewer==null so if you have no errors, that data fetcher is returning null.\n. @danielschonfeld that the data fetcher is returning something. If it returns null, that's the end of that tree.\n. > so anytime null is returned the execution stops trying other datafetchers\nYeah, that's a general GraphQL thing (not specific to this implementation). If you return null, it can't keep going.\n\nand if i dont have any datafetchers as I do, what would be returning that null?\n\nhttps://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/schema/PropertyDataFetcher.java, which is the default implementation of DataFetcher used when none is provided.\n. > ok so indeed PropertyDataFetcher is broken into and because source is null it returns null thus stopping the execution.\nCool, that's what I was thinking.\n\nWhat does that teach us/me? Can I do something? \n\nImplement data fetchers where necessary. If you want to keep going down a tree while returning an empty value for a field's source, return anything but null.\n\nis this by design?\n\nYeah, that's how GraphQL is currently specified. null means that sub-tree is over. \n\nam I using GraphQL wrong?\n\nNope, just implement a data fetcher where the default one is not to your liking.\n. @danielschonfeld yeah, basically. It's not pretty, but you're passing null to #execute(), and then you're using the default data fetcher implementation to read a property off of that null. That won't take you very far in terms of resolving a nested tree of data, which is what GraphQL is all about :)\n. Great! You're welcome!\n\u0441\u0440\u0435\u0434\u0430, 24 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Daniel Schonfeld \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\n@dminkovsky https://github.com/dminkovsky you're right it's not pretty,\nbut it makes sense and works! Thank you very much!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/192#issuecomment-242254703,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZQIzz0hvHQFHtXmKiuog9cArF8KCks5qjOvAgaJpZM4JskIr\n.\n. #123 was merged a few days ago. @ceronman Do you think that takes care of this issue?\n. I believe this is the test case https://github.com/graphql-java/graphql-java/issues/118#issuecomment-212156330\n. Cool thanks. I'm working on #204 right now which is also related to\nTypeReferences. I'll probably get to this as part of that process. But in\ncase I don't, please feel free if you feel like it.\n\nOn Tue, Sep 13, 2016 at 1:17 PM, Mark Philpot notifications@github.com\nwrote:\n\nI'll work to incorporate that this week.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/194#issuecomment-246755365,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZUMCbz6LvvQzmZHDAT5AqPLiYa_Kks5qptqugaJpZM4Juw6j\n.\n. If anyone spots any other similar kind of typos or edits to the README, please do post here. \n. Thank you for opening this issue. Yes, implementing #equals() would be very nice for several reasons, including the one you mention.\n\nWe are exploring replacing the schema definition classes and their builders with code generated by immutables. The generated code would include #equals() and #hashCode() etc.\n. (What do you think?)\n. By the way, looks like there is a PR for this already: #28 \n. Thank you. Yes we will do this soon.\n\u0441\u0443\u0431\u0431\u043e\u0442\u0430, 3 \u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Jiayu Liu \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/199, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZTk2wtG76a492lCfb7gM5ivQOFp1ks5qmPh2gaJpZM4J0OKN\n.\n. Hi @Jimexist, we published a release: https://github.com/graphql-java/graphql-java/releases/tag/v2.1.0.\n\nThank you for noticing this issue.\n. Thank you for this PR. Out of curiosity, does this address a particular issue you were encountering?\n. Thanks @Jimexist \n. Hi @oexza. Can you please provide your thoughts regarding https://github.com/graphql-java/graphql-java/issues/37#issuecomment-245829611 and on?\n. @akhahaha thanks again for your work on this PR. Following the discussion on #37, I think it does make sense to close it for now. \nIf you see any other aspects of this project that you could improve\u2014especially docs are you mentioned on #37\u2014please do. We are chatting on Gitter. \n. I think this makes sense to do as a sub project, if anyone would like to do that.\n. @akhahaha I'm not sure! I would like to explore concrete use-cases. For example, @pcarrier wrote the other day\n\n@dminkovsky for example to run (strictly ordered) operations on netty's event loop\n@dminkovsky including non-blocking I/O \n\nI'd like see a code sample that shows this usage, so we can figure out how it might be targeted. If you're trying to get each field (and ultimately a whole query) resolved on an event loop, then those tasks need to somehow get on to that event loop. An appropriate execution strategy needs to somehow take this in to account.\nI've been Googling around for some pure Java examples of async request processing. Some things I've found:\n- Dropwizard async example: uses the AsyncContext API to asynchronously handle the request. AsyncContext#start() still delegates to an underlying pool of threads. An article that discusses this API uses an explicitly declared thread pool.\n- Jersey async documentation: like the Dropwizard example, the crux of this asynchronicity is suspending/resuming connections so that threads can be used for processing instead of maintaining idle connections.\nI've not explored Netty and am hoping @pcarrier will provide his use-case.\nhttp://www.nurkiewicz.com/2015/11/which-thread-executes.html\nhttps://www.mailinator.com/tymaPaulMultithreaded.pdf\n. @akhahaha thanks for you response.\n\nHave you shown him that thread and perhaps this PR?\n\nI @-tagged him in my post above, and just in case just highlighted him in the Gitter chat with a link here. \n\nTo reiterate, to accomplish the async functionality that I think and he and I were looking for, simply use blocking DataFetchers and then perform the serial execution using the ExecutorService \n\nYeah, that seems to be the Java/JVM way. But for some reason this topic keeps coming back up, in issues and in the Gitter chat. People seem to want to minimize blocking and context switching. My Google searching suggested that this approach might not actually yield performance gains, but this has come up time and time again. I personally like the simple code style that comes with blocking threads, and appreciate that Dropwizard claims 30-50k reqs/seq with a default 1024-count thread pool. Then again, maybe people can achieve even more on a tight event loop?\n\nIt's not intuitively async like we'd expect, but the result should be equivalent. I guess it does beg the discussion again of whether or not async functionality like this should be built-in by default.\n\nI think so too. But given the repeated interest I think I closed this PR too hastily. I would like to keep this main project on Java 1.6 to facilitate \"legacy\" users experimenting with GraphQL on Java. But at the same time perhaps a motivated, interested party will be interested in doing a sub-project.\n. Hi Alan,\nCool, sounds good.\nIn terms of getting this incorporated into this project or built out as a\nsubproject, I think it would make sense for people to discuss further to\ntarget particular use cases.\nOn Thu, Sep 22, 2016 at 1:11 AM, Alan Kha notifications@github.com wrote:\n\nI'm reworking this\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/202#issuecomment-248814318,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZfJxTkIFho32zyH13M7jazmVMgpXks5qsg3xgaJpZM4J4qKX\n.\n. @akhahaha that is pretty interesting. I thought about this yesterday and here are my thoughts:\n\n\n\nThis particular CompletableFuture class uses the streamsupport-cfuture backport library, which should be compatible at least back to 1.6, although I'm not entirely sure if it's interchangable with the native 1.8 versions.\n\nI was thinking this could be a subproject and therefore just simply target 1.8. I think the async/non-blocking crowd is all using 1.8.\n\nI think there should also be GraphQLAsync class that wraps the default GraphQL in an async wrapper (via callbacks or more CompletableFutures). It should also use an ExecutorService by default in order to achieve the parallel completion necessary for equivalent async performance. I'm not too familiar with the pattern, so I'm not sure if we can provided a default ExecutorService implementation or if users are supposed to provide their own.\n\nI'm not sure what to say about this because I don't know how this would integrate with the bigger picture for people who are doing async/non-blocking request handling already. These users already have a way they're handling concurrency, and I suspect they want this to integrate nicely with the way of handling concurrency. Take for example the RxJava README. There they mention as one of its features:\n\n\nNon-opinionated about source of concurrency (threads, pools, event loops, fibers, actors, etc)\n\n\nI wonder how they do this... If we have a slew of CompletableFutures that run on the default runtime pool, async people will definitely not want that. I suspect giving users the option to specify their own ExecutorService won't be what they're looking for either, at least not entirely. I think users will want fields to get resolved within their existing source of concurrency. \nSo, with all that said, I am not sure how to proceed. It's almost like there's no generic solution to be had? I want to further study the Servlet 3.0 asynchronous handling API and Netty. I think an answer, if there is one, might be found somewhere around there.\nPlease let me know if any of this is unclear or needs more elaboration. Thank you.\nPS. Please see also 8 Asynchronous & Non Blocking\n. Ahhh thank you @TomerSabags. This makes sense... so we can add VariableTypeMismatch to the list of rules that depend on == for validation (#85).\n. Some notes from #34\n- I wonder what this means:\n\nbecause TypeReferences are not always replaced with the real object .. \u2014@andimarek\n- Important this PR covers this issue:\ncan you provide in your PR some unit tests demonstrating that nothing breaks and that input refs cannot mix with output refs? \u2014@danielkwindsor\n. > but not really sure what you meant by demonstrating that nothing breaks... All the current tests are passing...\n\nYeah, sorry that was confusing. Yes, the existing tests are passing. I meant tests that have not yet been written :). I'll spend time in the next few days (most likely this weekend) writing tests for this PR if you don't get a chance first. \n. Oh cool. I just spent some time getting familiar with them too. I have\nlooked through most of them and am pretty comfortable with Spock\nbasics (Spock is really nice imo!) When you have some time ping me on\nGitter and we can discuss. Or here on this thread is good too.\n\u0441\u0440\u0435\u0434\u0430, 21 \u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Bojan Tomic \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nI was having trouble understanding how the current tests are organized and\nhow they actually work... didn't have much success to be honest. I have a\nvague idea where to put tests for this, but could use some pointers.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/204#issuecomment-248632846,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZacz8HhreuRXTyzWVnEafrdMpH2bks5qsUG8gaJpZM4J6ZZt\n.\n. @kaqqao I don't know: I think your code might be fine and this just might be a particularly rough corner of the implementation, with these mutable fields that need to be updated with types that might be recursive and have certain restrictions...\n\nIf you and @brimworks feel good enough about this in the sense that it adds spec functionality and doesn't break anything, then we should merge it. . Cool, let's merge this then. \nYes, going forward I think we'll want something like that, that also addresses the other issues with the definition types (hashCode/equals, circularity, validation). That can be for a breaking revision.. Yes, this is a breaking PR. Now if you expect a Map you should use MapDataFetcher. A main idea of this PR is that built-in data fetchers should be very specific/discrete in what they do.\n. If there is a PR for this, please note these lines.\n. \"Exception while fetching data\" is a hard-wired string that is logged. It is not returned to clients. Do you mean you want to be able to customize this log message? \n. Oh hey, I was misunderstanding this too. Sorry I was so slow about this. Yikes.\nAnyway, yes, we should improve this.. FWIW, here's a Jackson serializer (if anyone is using Jackson) for ExecutionResult that will skip printing the stacks if an error is an ExceptionWhileDataFetching:\nImplementation:\n```\nimport com.fasterxml.jackson.core.JsonGenerator;\nimport com.fasterxml.jackson.databind.SerializerProvider;\nimport com.fasterxml.jackson.databind.ser.std.StdSerializer;\nimport graphql.ExecutionResult;\nimport graphql.GraphQLError;\nimport graphql.language.SourceLocation;\nimport java.io.IOException;\nimport java.util.List;\npublic class ExecutionResultSerializer extends StdSerializer {\npublic ExecutionResultSerializer() {\n    this(null);\n}\n\npublic ExecutionResultSerializer(Class<ExecutionResult> t) {\n    super(t);\n}\n\n@Override\npublic void serialize(ExecutionResult executionResult, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {\n    Object data = executionResult.getData();\n    jsonGenerator.writeStartObject();\n    if (data != null) {\n        jsonGenerator.writeObjectField(\"data\", data);\n    }\n    List<GraphQLError> errors = executionResult.getErrors();\n    if (errors != null && !errors.isEmpty()) {\n        jsonGenerator.writeArrayFieldStart(\"errors\");\n        for (GraphQLError error : errors) {\n            jsonGenerator.writeStartObject();\n            jsonGenerator.writeFieldName(\"message\");\n            jsonGenerator.writeString(error.getMessage());\n            List<SourceLocation> locations = error.getLocations();\n            if (!locations.isEmpty()) {\n                jsonGenerator.writeArrayFieldStart(\"locations\");\n                for (SourceLocation location : locations) {\n                    jsonGenerator.writeObject(location);\n                }\n                jsonGenerator.writeEndArray();\n            }\n            jsonGenerator.writeEndObject();\n        }\n        jsonGenerator.writeEndArray();\n    }\n    jsonGenerator.writeEndObject();\n}\n\n}\n```\nTest:\n```\nimport com.fasterxml.jackson.databind.ObjectMapper\nimport com.fasterxml.jackson.databind.module.SimpleModule\nimport graphql.ErrorType\nimport graphql.ExecutionResult\nimport graphql.ExecutionResultImpl\nimport graphql.GraphQLError\nimport graphql.language.SourceLocation\nimport org.skyscreamer.jsonassert.JSONAssert\nimport spock.lang.Specification\nclass ExecutionResultSerializerTest extends Specification {\ndef mapper = new ObjectMapper()\n\ndef setup() {\n    SimpleModule module = new SimpleModule()\n    module.addSerializer(ExecutionResult.class, new ExecutionResultSerializer())\n    mapper.registerModule(module)\n}\n\ndef \"data and errors null\"() {\n    given:\n    def result = new ExecutionResultImpl(null, null)\n\n    when:\n    def serialized = mapper.writeValueAsString(result)\n\n    then:\n    JSONAssert.assertEquals('{}', serialized, false)\n}\n\ndef \"just data\"() {\n    given:\n    def result = new ExecutionResultImpl([field: 'value'], null)\n\n    when:\n    def serialized = mapper.writeValueAsString(result);\n\n    then:\n    JSONAssert.assertEquals('{ \"data\": { \"field\": \"value\" } }', serialized, true)\n}\n\ndef \"just errors\"() {\n    given:\n\n    def result = new ExecutionResultImpl(null, [\n      new GraphQLError() {\n\n          @Override\n          String getMessage() {\n              return \"message\"\n          }\n\n          @Override\n          List<SourceLocation> getLocations() {\n              return [new SourceLocation(1, 1)]\n          }\n\n          @Override\n          ErrorType getErrorType() {\n              return null\n          }\n      }\n    ])\n\n    when:\n    def serialized = mapper.writeValueAsString(result)\n\n    then:\n    JSONAssert.assertEquals('{ \"errors\": [ { \"message\": \"message\", \"locations\": [ { \"column\": 1, \"line\": 1 } ] } ] }', serialized, true)\n}\n\ndef \"data and errors\"() {\n\n    def result = new ExecutionResultImpl([field: 'value'], [\n      new GraphQLError() {\n\n          @Override\n          String getMessage() {\n              return \"message\"\n          }\n\n          @Override\n          List<SourceLocation> getLocations() {\n              return [new SourceLocation(1, 1)]\n          }\n\n          @Override\n          ErrorType getErrorType() {\n              return null\n          }\n      }\n    ])\n\n    when:\n    def serialized = mapper.writeValueAsString(result)\n\n    then:\n    JSONAssert.assertEquals('{ \"data\": { \"field\": \"value\" }, \"errors\": [ { \"message\": \"message\", \"locations\": [ { \"column\": 1, \"line\": 1 } ] } ] }', serialized, true)\n\n}\n\n}\n```. @lulzmachine thanks for the bugfix :). The NFL?\n. Hey, thanks for the report. I confirmed the problem. This query does appear to be valid and does get parsed by the reference impl. I opened a PR #214 with a test that demonstrates this failure.\n. @pcarrier Just pushed a commit to the PR that fixes the issue. Will merge/release pending review.\nThank you.\n. PS. The test added in this PR is in currently in a temporary location for easy visibility and needs to be moved to a better spot before merge.\n. Hey thanks! Cheers to your first PR! This looks good to me.\nBy the way, if you're using Maven you might be interested in this plugin I wrote today: https://github.com/dminkovsky/babel-relay-maven-plugin. Feedback welcome!\n. Hey, thanks for the PR.\nThe implementation change looks good to me. I just want to consider whether this has implications with regard to the spec. Off the top of my head I can't remember anything in the spec that says a GraphQL list's ordering needs to be consistent from execution to execution. \nRegarding the test, it should be re-written as a Spock Specification. If you're not familiar with Spock, not problem, I can do that for something this small.\n. Hey I made some cosmetic changes and re-did the test in Spock. To keep things simple I just opened a new PR: https://github.com/graphql-java/graphql-java/pull/235. Thanks!\n. Hey thanks for posting. I procrastinated responding to this when I first read it, thinking it would require more investigation. But actually it seems simple enough...\nIn summary, I think the problem is that your parseValue/parseLiteral methods aren't actually doing any parsing! They're just casting. And I'm not sure why it's working at all... \nIn both parseValue and parseLiteral you need to actually create the Duration you want from the input object. There's no reason why Object would actually be a Duration already, especially in parseLiteral, where Object would be an instance of IntValue if the input is 0. In parseValue you could already have a Duration for input.duration if you passed a Duration as input in the Map<String,Object> you provided as args to GraphQL.execute(). But anyway, you can't just cast, you need to \"parse\" the input. \n\n\nWhen I send this mutation query ... parseLiteral is not called on my custom type\n\nBecause in this case you are passing the variable as a variable reference, not a literal value in the query.\n\n\nBut I am not sure why this would work:\n\nThis should not work... I am not sure why any of it is working :).\n. Going to close this for now, since I think it's not a big. Please reopen if otherwise.\n. Hi, thank you for this PR.\nWhen you say \"cross-references\", do you mean something different from the GraphQLTypeReference that exists in the current implementation?\n. Cool thanks!\n\u0447\u0435\u0442\u0432\u0435\u0440\u0433, 13 \u043e\u043a\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c TKffTK \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nClosed #221 https://github.com/graphql-java/graphql-java/pull/221.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/221#event-822582117,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZfMg5pUOULPh7BcIp_olpoaLKT-4ks5qzkHQgaJpZM4KSfkY\n.\n. Hey, thank you very much for this. Will review in the coming days. \n. @drkarl Looking today and will update. Thanks for pinging.\n. Looks good to me. Thank you @herojan for the PR, and @drkarl for pinging. \n. Hey thanks for the ping. Will look at this today and update.\n\n\u0432\u0442\u043e\u0440\u043d\u0438\u043a, 25 \u043e\u043a\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c drkarl \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\n@dminkovsky https://github.com/dminkovsky any ETA when this will be\nmerged in?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/222#issuecomment-256023622,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZWVzh-Hkk0GIUwXcvml9EQD6hRU3ks5q3fkigaJpZM4KVKfF\n.\n. Hi @avinashdudi. Yes, we definitely could better examples of this in the README. I worked through this recently, and it wasn't too bad. Basically, you need to\n1. Set up a GraphQL server. An example of this can be found here https://github.com/graphql-java/todomvc-relay-java. That example uses Spring Boot, but you can use whatever HTTP server you like to get that going.\n2. Set up the GraphiQL server. That is a bit beyond the scope of this project, but basically you need to get GraphiQL talking to the server in step 1 above. It will use introspection to load the schema. \n\nPlease post if you have specific questions about 1 or 2, please post.\n. I would look for a Docker image, if you use docker. There must be some out there that make this easy.\nOtherwise, if you want to learn a bit, basically GraphiQL is a React Component. So you need to get a webpack project going that serves a React website that renders the GraphiQL React Component. You can then use the webpack dev server to serve the GraphiQL. Or you can build it and serve it with something like nginx.. Cool thanks for updating with the result. Glad to hear.\n\u0441\u0440, 11 \u044f\u043d\u0432. 2017 \u0433. \u0432 0:51, Dmitri Pisarenko notifications@github.com:\n\nYou can ignore my last question. I tried it out and it seems to work. Many\nthanks!\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/223#issuecomment-271784514,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZbTRN1LWtDtq-X-6WF0wZZAS5WuEks5rRG3fgaJpZM4KVMXm\n.\n. I'm sorry if I didn't read carefully enough but from what I saw\u2014isn't it\njust CORS configuration? which is what your one existing answer on SO says\ntoo, right?\n\n\u043f\u0442, 13 \u044f\u043d\u0432. 2017 \u0433. \u0432 11:28, Dmitri Pisarenko notifications@github.com:\n\n@dminkovsky https://github.com/dminkovsky There is an cross-site\nscripting (XSS) problem, when I try to run this locally. I've described the\nproblem on StackOverflow\nhttp://stackoverflow.com/questions/41589542/why-does-my-spring-controller-not-handle-an-options-request-sent-by-graphiql\n-- you are welcome to answer it and get 200 StackOverflow points of\nreputation (bounty).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/223#issuecomment-272481570,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZaogFTOLbmLfyN3BhB42rV5WAKydks5rR6YngaJpZM4KVMXm\n.\n. Yeah I just looked at the screenshot in your SO question. Your GraphQL is\non a different host than your front end (the ports are different). You need\nto set up a proper response to that OPTIONS request. It needs to return the\nappropriate Allow- headers. Check out CORS.\n\n\u043f\u0442, 13 \u044f\u043d\u0432. 2017 \u0433. \u0432 12:15, Dmitry Minkovsky dminkovsky@gmail.com:\n\nI'm sorry if I didn't read carefully enough but from what I saw\u2014isn't it\njust CORS configuration? which is what your one existing answer on SO says\ntoo, right?\n\u043f\u0442, 13 \u044f\u043d\u0432. 2017 \u0433. \u0432 11:28, Dmitri Pisarenko notifications@github.com:\n@dminkovsky https://github.com/dminkovsky There is an cross-site\nscripting (XSS) problem, when I try to run this locally. I've described the\nproblem on StackOverflow\nhttp://stackoverflow.com/questions/41589542/why-does-my-spring-controller-not-handle-an-options-request-sent-by-graphiql\n-- you are welcome to answer it and get 200 StackOverflow points of\nreputation (bounty).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/223#issuecomment-272481570,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZaogFTOLbmLfyN3BhB42rV5WAKydks5rR6YngaJpZM4KVMXm\n.\n. Oops I meant Access-Control- headers\n\n\u043f\u0442, 13 \u044f\u043d\u0432. 2017 \u0433. \u0432 12:35, Dmitry Minkovsky dminkovsky@gmail.com:\n\nYeah I just looked at the screenshot in your SO question. Your GraphQL is\non a different host than your front end (the ports are different). You need\nto set up a proper response to that OPTIONS request. It needs to return the\nappropriate Allow- headers. Check out CORS.\n\u043f\u0442, 13 \u044f\u043d\u0432. 2017 \u0433. \u0432 12:15, Dmitry Minkovsky dminkovsky@gmail.com:\nI'm sorry if I didn't read carefully enough but from what I saw\u2014isn't it\njust CORS configuration? which is what your one existing answer on SO says\ntoo, right?\n\u043f\u0442, 13 \u044f\u043d\u0432. 2017 \u0433. \u0432 11:28, Dmitri Pisarenko notifications@github.com:\n@dminkovsky https://github.com/dminkovsky There is an cross-site\nscripting (XSS) problem, when I try to run this locally. I've described the\nproblem on StackOverflow\nhttp://stackoverflow.com/questions/41589542/why-does-my-spring-controller-not-handle-an-options-request-sent-by-graphiql\n-- you are welcome to answer it and get 200 StackOverflow points of\nreputation (bounty).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/223#issuecomment-272481570,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZaogFTOLbmLfyN3BhB42rV5WAKydks5rR6YngaJpZM4KVMXm\n.\n. It's definitely CORS. But I'm sorry I don't know much about Spring.\nSometimes allowed origin can't be * but has to be a specific host. That\ncould be your problem but I'm just speculating.\n\nSorry you're spending so much time on CORS but it's everywhere you can't\nget by without it.\n\u0441\u0431, 14 \u044f\u043d\u0432. 2017 \u0433. \u0432 6:00, Dmitri Pisarenko notifications@github.com:\n@dminkovsky https://github.com/dminkovsky It probably is CORS. I already\nconfigure it in my Java application, but there are probably errors. I've\nupdated my SO question so that now it includes code fragments that show,\nhow exactly I configure CORS.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/223#issuecomment-272617036,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZc1VH7LutSWDABEdsFOL0OlJnwCEks5rSKrmgaJpZM4KVMXm\n.\n. Hi @nmn. What about what it says at the top of the spec?\n. Cool. Thank you!\n\u0432\u043e\u0441\u043a\u0440\u0435\u0441\u0435\u043d\u044c\u0435, 16 \u043e\u043a\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Naman Goel \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nInteresting, it was announced at a conference recently. I'll look for the\nsource, and open another PR.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/224#issuecomment-254076833,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZUxrvxN5l4gsel2RbRDlR7TSyLRpks5q0pjhgaJpZM4KWrIJ\n.\n. Hi @commonsguy. Thank you for reporting this.\n\nThe ANTLR dependency is current listed as a compile-time dependency:\ncompile 'org.antlr:antlr4-runtime:4.5.1'\nYet, in the resulting POM that arrives from Maven Central, you do get both of these dependencies:\n<dependency>\n      <groupId>org.antlr</groupId>\n      <artifactId>antlr4-runtime</artifactId>\n      <version>4.5.1</version>\n      <scope>runtime</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.antlr</groupId>\n      <artifactId>antlr4</artifactId>\n      <version>4.5.1</version>\n      <scope>runtime</scope>\n    </dependency>\nI am not sure why the current build.gradle configuration results in this POM. Do you or @GrigoryPtashko know?\n. @commonsguy Yeah that was my thinking too. That plugin was recently adopted as a fix to remove the antlr-built sources from the repo. Will have to see how to remove the main jar from the resulting POM. In the meantime, thanks for posting the workaround.\n. Thank you @foragerr, for your help with the Gradle PR and on Stack Overflow! So cool.\nThanks @IamCornholio for the patch. Will integrate it soon.\n. Oh, and for posterity: to build the to-be-published POM locally without publishing:\n./gradlew generatePomFileForGraphqlJavaPublication`\nThis build the POM in: \nbuild/publications/graphqlJava/pom-default.xml\n. Hi @metacosm. Thanks for posting this issue.\n\nThe spec explicitly state that arguments are named and order is irrelevant so it doesn't seem like there are any benefits to use a List to access a Field's Arguments instead of a Map.\n\nThe spec is really important to us, but I don't think the spec is relevant to this implementation detail. What would be the benefits of using a Map?\n\nAn added benefit would be to make it simpler to deal with Arguments in DataFetchers.\n\nWhat could be simpler than what we already have, which is\n<T> T env.getArgument(String name)\nYou don't even have to cast :)\n. > I iterate over fields \nWhen do you iterate over fields? Inside a DataFetcher? If so, are you saying you look at the List<Field> that can be retrieved via DataFetchingEnvironment#getFields()? And then want to see that the argument values these fields have?\n\nIt'd be useful to have the same  T getArgument(String name) method we have on DataFetchingEnvironment on Field as well.\n\nSo a Field does not have proper runtime argument values in its own right. Field is an AST node, so it might have a literal argument value or a variable reference. When a particular field is being resolved during a query execution, its arguments are normalized to an actual value. It is this value that you can retrieve from the DataFetchingEnvrionment. So if you are retrieving a list of fields using DataFetchingEnvrionment#getFields() as mentioned above, each of these fields' arguments must be normalized to get their actual useful runtime values. \n. > DataFetchingEnvironment#getArguments returns an empty Map while I do have Fields with arguments and associated values.\nDataFetchingEnvironment#getArguments() returns resolved argument values for the field your data fetcher is currently handling. By \"resolved argument values\" I mean that before the data fetcher was executed, the Field AST node was examined and its argument values were parsed from either literal values in the AST node, OR from variable references in the AST node. Either way, the values returned by #getArguments() and related methods are parsed and ready for usage.\nIn your code, however, you examine List<Field> and use the argument values directly from the Field AST node, like StringValue. You can do that, but that's not \"correct\" in the sense that you may have a VariableReference and not StringValue. All AST value nodes, are \"raw\" and need to be resolved into runtime values. That is what the ValueResolver does. Please look at that code.\n\nI still don't understand why the arguments have to be stored as a List when they are more usefully manipulated as Map\n\nI can't emphasize enough that List<Field> is a list of GraphQL AST nodes, and its arguments are also a bare list of GraphQL AST nodes. These AST nodes are the result of parsing the query. The order of arguments in the Field's arguments list is the order in which the parser saw them. But, as I've said a few times, these Arguments are not the arguments you should be using. As you've said, they are more useful as a map, which is what the ValueResolver does: it takes the raw AST nodes, the argument schemas, and variable values, and combines those three things into that useful Map.\n. In summary:\nThe Argument list in a Field is not mean to be used directly during execution. This argument list must first be processed (see ValueResolver). StringValue, for example, is a GraphQL query AST string value. It is not a GraphQLString or a Java String. Rather, a StringValue represents an array of characters in a GraphQL query that enclosed in double quotes and is located in the query where an input value is allowed to be found. It must be parsed by a GraphQLScalar's Coercing depending on the type of scalar. That scalar could be any type of scalar. That scalar's runtime value does not have to be a Java String.\nSo, do not use unresolved AST values as arguments. They are in a \"non-useful\" list because they are not meant to be used in that way. They are in a list because they are the product of linear parsing. To make arguments useful, they must be resolved with a ValueResolver, which places them in a Map.\n. One more thing:\n\nreturns an empty Map while I do have Fields with arguments and associated values\n\nIf getArguments() returns an empty map, then the arguments on the Fields in List<Field>s will be empty. Each Field in List<Field> will have the same arguments and values. The only difference might be their selection sets, which is why that list of fields is provided.\n. Hey you're welcome. I'm glad you got something out of it. I kept reading over my answer(s) and they were not great...\n\nwhy does ValuesResolver put the arguments in a LinkedHashMap, though?\n\nThat I am not sure about. I didn't write that detail in the implementation. The spec does say that \"arguments are unordered\". However, while I am no JVM expert, I doubt this adds much overhead, so I would not prioritize changing it to HashMap. Right now our biggest performance issue is probably input validation.\n\nI know you didn't ask about this, but if I may offer some more unsolicited insight as an attempt to re-phrase my answers above:\n(1) Regarding List<Field> as available from DataFetchingEnvironment#getFields():\nThis list is the ordered set of Field ASTs for the Field that is currently being fetched. It is a List because a field may be repeated in a selection set, and a field that is defined as an object may be repeated with different selection sets.\nI believe the main reason List<Field> is exposed in the DataFetchingEnvironment is to allow you to optimize remote data fetching. For example, suppose you have a table People in some remote SQL database and the following query:\nquery {\n  person(id: \"1\") {\n    name\n    address\n    phone\n  }\n  person(id: \"1\") {\n    age\n  }\n}\nWhen you are fetching data for field person(id: \"1\"), you may not want to retrieve the entire row for that entity but only the fields requested in the GraphQL query. So in the data fetcher for person(id: \"1\"), you iterate over each Field in List<Field>. There will be two Fields in this list: one for the first person(id: \"1\") field, and one for the second person(id: \"1\") field. Each of these will have its own selection set (the first will include \"name\", \"address\" and \"phone\"; the second will include \"age\"). So then in your data fetcher you can request SELECT name, address, phone, age FROM People where id=1 instead of SELECT * FROM ....\nBy the way, the equivalent in the JS implementation is called fieldASTs.\n\n(2) The GraphQL query language only defines several scalar literal types that might exist in a query: Int, Float, Boolean, String. These 4 scalar types are different from the data definition scalar schema types, which are use-definable and exist at execution/runtime by parsing one of the four above mentioned query language scalars. \n. That section refers to query documents (the spec does not deal very much with schema definition, if at all). We parse query documents with ANTLR, and names are validated per the spec.\nPlease see (2) in my response on our previous issue. It's important to differentiate between the query document and schema definition. \n. That said, the builders are kind of lacking IMO. For example, unlike the JS implementation, our builders do not validate that objects implement interfaces correctly. It would be nice if this were improved. Names might also be validated in the builders.\n. > the spec does not deal very much with schema definition\nIn terms of how that definition system is implemented.\n. Yeah, validation (name and other properties) is definitely a deficiency. In addition to this deficiency, there are several other problems that have been identified with the schema definition system:\n- #215\n- #198 and #28 \n- #172 \nI've explored these and discovered that these are all related in one way or another.\nI'm not entirely sure how best to resolve them at the moment. On one hand, it's easy to iterate on the simpler problems like validating names and interfaces. On the other hand, it's not as simple to work through the issues surrounding type references and hashCode()/equals(). But anyway, while all these things are issues, I wouldn't call them blocking issues and have been thinking about how to best address them while working more with the library in my applications.\nPlease feel free to submit PRs if you would like to iterate on these.\nThanks.\n. Thank you!\n. Thank you for posting.\nIt's correct actually. The master branch right now lets you provide Builder\nobjects in schema definition. Check out this commit\nhttps://github.com/graphql-java/graphql-java/commit/be0e7f3ae90a4c53fd4c5dfe43b4d9cff94f59dd\nWere you looking for something?\n\u0441\u0440\u0435\u0434\u0430, 19 \u043e\u043a\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u5ed6\u82b3\u624d \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nObject.staticValue(\"world\").build()\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/229, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZcU8bjd5sYezWtk9poWWK-Lscbnuks5q1tMJgaJpZM4KbqKD\n.\n. Yes! Do you feel like PRing this?\n. Thanks!\n. Hi, thank you for posting and for this PR. \n\nFortunately, this is not a bug in the repository. Please see https://github.com/graphql-java/graphql-java/issues/229#issuecomment-254996258 for more info!\nThank you, and sorry for the confusion.\n. Actually, I guess the Map-related parts of this PR are problems. Could you updated this PR to exclude the field builder issues and we'll merge?\nThank you.\n. Hey just saw you closed this PR. I am going to open an issue for the Map-related parts because I think they are, indeed, wrong on master.\n. Fixed by #218. Thank you.\n. > How to define the \"mutation sentence\".\nDo you mean: how do you construct mutation queries? If so, please see http://graphql.org/learn/queries/#mutations. I'm sorry that it's in English, but I am unaware of any non-English resources. \nIf that's not what you mean, can you rephrase your question?\n. Great to hear! \n. Fixed by #218\n. Looks good to me. Want me to merge?\n. @okorz001 yes that is very interesting indeed. Thank you!!!\n. Will add some tests, though this passes currently. \n. Hi @brimworks, thanks for posting.\nI would say yeah, definitely, to the the extent that the schema language is supported by the JS implementation. I'm not sure what that extent is, but it seems to be parsing.\n. Cool, thanks Brian. Post if you have any questions. Are you familiar with Spock?\n. Cool sounds great. No, please take your time :). Thank you.\n. By the way, a related issue if you have any time and interest is #126. I think it just needs tests ported-adapted from the JS implementation and any bug fixes that result. Would really bolster the tooling. \n. Cool, thank you. Yeah, that code will have to be updated to accommodate the\nAST symbols you're adding. It won't be anything.\n\u0441\u0440, 16 \u043d\u043e\u044f\u0431. 2016 \u0433. \u0432 17:42, Brian Maher notifications@github.com:\n\nI quickly skimmed that issue, but it was unclear to me what format the\nprinter prints in. I'm ASSUMING it iterates over the AST and pretty prints\nthe original input in GraphQL syntax. If that is the case, then all these\nnew AST symbols I'm adding will have a direct impact on the pretty printer\n(since there will be a host of new symbols to handle).\nUnfortunately, the work I'm doing currently doesn't require such a pretty\nprinter, but I do see value in it. So, I probably won't have time to\ncontribute to that effort in the near future.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/241#issuecomment-261096570,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZb50dSseQH1KsFZ7BfakJ1qA1N6Nks5q-4bpgaJpZM4K0Dv1\n.\n. Cool, thanks very much. I'll take a look today or tomorrow. . Hi Brian. Thank you for pinging! Always appreciate pings.\n\nDon't worry, you won't have to depend on your fork for much longer. I am\ngoing to review this soon, for the next (2.3.0) release, which I want to\nget out in the coming few days. There's a pretty ridiculous bug fix (\nhttps://github.com/graphql-java/graphql-java/pull/190) waiting on master.\nDmitry\nOn Tue, Dec 13, 2016 at 7:56 AM, Brian Maher notifications@github.com\nwrote:\n\nI'm waiting for feedback from @dminkovsky https://github.com/dminkovsky\n. I've got a code generator that uses this feature that I'd like to\nrelease, but it currently depends on my fork. I was hoping to get this\nmerged and released so I don't have to depend on a fork.\nThanks,\n-Brian\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/241#issuecomment-266731555,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZQ7Go5ag5xIrFzHZCb_aOOrNsNMxks5rHpXxgaJpZM4K0Dv1\n.\n. Brian, thank so much for updating here. This looks really cool. I haven't had a chance to try this and likely won't for some time, but I am really interested in this approach and look forward to any updates as you make progress.\n\nBest, and happy 2017,\nDmitry. Thanks Brian, to yours as well!\nI see the example uses the BatchedExecutionStrategy. How's that working for you?\nBy the way, are you looking to make this into a product?. > The BatchedExecutionStrategy seems to work fine, but I'll admit that I haven't done a ton of testing with it.\nCool. I've not played with it and it predates my time with this project. So, just wondering.\n\nI'm not currently think of turning this into a product, but if you have ideas toward that end, I would be interested :).\n\nYeah, me too! I'm not sure what one could do with this beyond something like reindex.io or apollo. I also came across this profile the other day, but the whole consulting/evangelist thing isn't very appealing to me (not related to apigen, either).\n. Will re-open with much simpler implementation soon.. Really appreciate the focus. I may have gotten a bit carried away there with the excitement of using the GitHub branch/network functionality. . Hi @wabrit,\nThank you for posting this issue. Yes, given the spec and reference impl, I do believe this is a defect. I just posted a fix: #252. \nThanks again,\nDmitry. Hey sorry I can look this up right now but there is a PR for this issue.\nYou'll find it if you take a look.\n\u0441\u0440, 23 \u043d\u043e\u044f\u0431. 2016 \u0433. \u0432 18:30, Brian Maher notifications@github.com:\n\nCurrently, you can not define a GraphQLTypeReference in places that\nrequire a GraphQLInputType. This is problematic for recursively defined\ninput types. It appears that we simply need to modify SchemaUtil so it also\nresolves GraphQLInputObjectType and add in a few replaceTypeReferences()\nimplementations to handle replacing input types.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/247, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZZfm16-OqIA-m6AJ6FwwcUvpQ3n1ks5rBMytgaJpZM4K7JNx\n.\n. Ah found it https://github.com/graphql-java/graphql-java/pull/204\n\n\u0441\u0440, 23 \u043d\u043e\u044f\u0431. 2016 \u0433. \u0432 18:32, Dmitry Minkovsky dminkovsky@gmail.com:\n\nHey sorry I can look this up right now but there is a PR for this issue.\nYou'll find it if you take a look.\n\u0441\u0440, 23 \u043d\u043e\u044f\u0431. 2016 \u0433. \u0432 18:30, Brian Maher notifications@github.com:\nCurrently, you can not define a GraphQLTypeReference in places that\nrequire a GraphQLInputType. This is problematic for recursively defined\ninput types. It appears that we simply need to modify SchemaUtil so it also\nresolves GraphQLInputObjectType and add in a few replaceTypeReferences()\nimplementations to handle replacing input types.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/247, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZZfm16-OqIA-m6AJ6FwwcUvpQ3n1ks5rBMytgaJpZM4K7JNx\n.\n. Take a look and see what you think of that one. I saw a commit was pushed\nto that yesterday but I don't know what it included. I was hoping tests :)\n\n\u0441\u0440, 23 \u043d\u043e\u044f\u0431. 2016 \u0433. \u0432 18:36, Brian Maher notifications@github.com:\n\nLooks like this is already done here: #248\nhttps://github.com/graphql-java/graphql-java/pull/248\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/248#issuecomment-262655941,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZbq00lWXlKuHkGPO2b-5_jsKjJphks5rBM4AgaJpZM4K7JWA\n.\n. Hi @jleskovar,\n\nThanks for opening this issue. So, in such an artifact, what will happen to all the org.slf4j.Logger.{log,info,warn,error} calls we have right now?. Cool, good to hear. Sorry we couldn't help here.. Hi @Jimexist,\nThanks for posting this. I wonder, maybe the client should be catching these exceptions? . Yeah those we can definitely add hashcode equals. I'll do that shortly, thanks.. Hey maybe this is related to #225. That issue is fixed but not-yet-released. Try this workaround:\ncompile('com.graphql-java:graphql-java:2.2.0') {\n        exclude module: 'antlr4'\n    }\nThis project doesn't use Guava, though. Its only runtime dependency is Slf4j.. Hi @bbakerman, thank you for posting. I see what you're saying. Do you know why GSON does that that conversion? Because of the whole JS Number type thing?\nI don't think this built-in scalar class should be changed to accommodate this though... I like how the built-ins are simple and do not attempt to perform any lossy conversions. I'll leave this open to see if other people want this feature, but otherwise I think it makes sense to write your own scalar type. It's a small class and then you can control exactly the behavior you desire.\n. By the way it looks like this is related to #105. That sounds good to me. Thank you!. Fixed in #301. Thank you @Jimexist!. How about this as a start? https://github.com/graphql-java/graphql-java/pull/262. Also c.f. https://github.com/graphql-java/graphql-java/pull/91. Closing this in favor of #280.. Thank you!. Looks like this was merged into #280, which itself should be merged soon. Closing in favor of #280.. Can I ask generally\u2014what's been your experience with the Relay classes? Personally, I've not found them very useful. I am wondering if I am using them incorrectly. . I meant the Relay implementations in this repo. I am a really big fan of Relay the front-end library, so let's skip (1).\nRegarding (2), the inability to set data fetchers on the fields generated by the Relay class methods have made using the class for me problematic. Do you just work with the default data fetcher?. Thanks for pointing this out. You are right. I will include a fix for this\nfor 2.3.0 unless you want to PR?\n\u0447\u0442, 15 \u0434\u0435\u043a. 2016 \u0433. \u0432 11:37, Dirk notifications@github.com:\n\nWhen an exception (field error) happens during resolution of a field,\ncompleteValue is called with a null resolvedValue. If the field is a\nGraphQLNonNull, that leads to a GraphQLException being thrown which is\nnever caught.\nAccording to the GraphQL spec, 6.4.4 Errors and Nullability (\nhttp://facebook.github.io/graphql/#sec-Errors-and-Non-Nullability), the\nnull value should be propagated up to the parent field in this case (and if\nthat is non-nullable, up again until ultimately a null value under the data\nkey of the response object), without adding additional errors to the result\nerror list.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/268, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZTCfVFqY8KgcEPeMpiy6ar28xBD7ks5rIWzTgaJpZM4LOTPc\n.\n. This didn't make 2.3.0 but should be included in 2.4.0. Thanks again for reporting @dllx.. I believe graphql-java-servlet is maintained by @yrashk. Any particular reason not 2.3.0, too?. Thank you!!. Excellent.. Fixed with #287. Thank you @sean-brandt.. I am not sure that this would be to spec. I think, and I definitely might\nbe wrong, but the way execution is specified, mutation fields that error\nare null and then execution continues?\n\nOn Tue, Dec 20, 2016 at 4:49 AM, Dirk notifications@github.com wrote:\n\nI'd like to put the whole GraphQL mutation operation in a database\ntransaction. To that end, I wrap the whole GraphQL.execute method in a\ntransaction.\nWhen a mutation of a toplevel field causes an error, that should roll back\nthe whole transaction. Resolving the rest of the toplevel fields is not\ndesirable in this case, because the transaction may be in an\ninconsistent/unusable state. Further, as in the case of when using\nHibernate, a ConstraintViolationException on the first toplevel field will\nbe reported for the following toplevel fields again.\nMutations are executed by the SimpleExecutionStrategy which inherits from\nExecutionStrategy, where the resolveFields method puts an\nExceptionWhileDataFetching into the errors list and continues with the next\nfield. The situation is not easily resolvable by using a different\nExecutionStrategy because for mutations, SimpleExcecutionStrategy is always\nused.\nFurther, other exceptions that don't come from the DataFetcher may also be\ncollected in the error list and execution continues with the next field.\nI suggest a configuration possibility to enable aborting the execution\nwhen an error occurs, returning an empty (null) data in the ExecutionResult\ntogether with the error in the errors list.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/282, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZS0bURlsZ0th6pQa9GNCw9wKNM88ks5rJ6SWgaJpZM4LRpUW\n.\n. Awesome, thank you.\n\nThere seems to be an issue where an error is swallowed. I am going to look\ninto it today or tomorrow and write a test that confirms it.\nAlso I need to make sure this strategy conforms to the issue described in\nhttps://github.com/graphql-java/graphql-java/issues/268\nBut I think all the non-error paths work fine.\nRe: the DataFetcher behavior you describe, if I understand you correctly I\nthink that's how it's set up right now. If you can think of how to write a\ntest that ensures fetchers execute in the correct order (that's important\neither way for accepting this PR) then I bet we could also describe what\nyou're saying here in those terms.\n\u0441\u0431, 31 \u0434\u0435\u043a. 2016 \u0433. \u0432 0:51, crazyfrozenpenguin notifications@github.com:\n\n@dminkovsky https://github.com/dminkovsky, I have just browsed through\nthe code but will soon test it.\nOne feature that it would be great to have would be the concept of\nDataFetcher dependencies when executing in parallel.\nA DataFetcher can depend on other DataFetchers or, a DataFetcher could\nunlock other DataFetchers.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/283#issuecomment-269851187,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZdf_0XnBgcS6DKtVRVk3i87Yul__ks5rNe1_gaJpZM4LR92_\n.\n. @crazyfrozenpenguin identified and fixed the above-mentioned bug. Also fixed another issue. The update is forced pushed to this PR. Happy New Year.. By the way, I also updated the SNAPSHOT version. It was 2.3.0-SNAPSHOT, but 2.3.0 is now released so I just set it to 3.0.0-SNAPSHOT which should work until this is merged or otherwise closed.. @oexza yeah the plan is for a separate artifact. I have this PR here now to aid in peer review.\n\nAs @andimarek says, there are still people on Java 6 using this, which I think is really cool. It would be nice to somehow isolate a 1.6 and 1.7 compatible core that they can keep using. \nWhat do you think? cc/ @bmsantos . @bmsantos Yeah that's the name I was thinking. . That would be greatly appreciated! \n\nBreaking this on its own jar might actually be a much better approach since async related releases/updates will be easier to do.\n\nYeah, that's what I am thinking too. For example, fixing #268 is a bit difficult because the maintainers need to verify that the problem does not exist in all of the execution strategies (simple, executor service, and batched). #284 is related: with a clearer demarcation of API vs SPI, I think this would be much easier.\n. Hi @Cafeinoman. Thanks for posting.\nI've had to take a few weeks away from this while I launch a project. I am using this in this project, so I will need to get back to it soon.\nI think this PR is in okay shape except for correct handling of null non-nullable field (#268). That issue needs to be fixed in the other execution strategies as well. I don't think it makes sense to \"release\" this until those issues are addressed. \nIn the mean time, have you played with this branch? If you use it, please report any issues or PR improvements.\n. Regarding #268, if anyone wants to tackle it:\n\nPlease review 6.4.4 Errors and Non-Nullability in the spec.\nPlease review graphql-js execution and see how null non-nullable fields are handled correctly. \n\nAs you will see, graphql-js execution tracks ResponsePath during execution, which aids in producing good errors. To me it appeared that to make our implementation work to spec and like graphql-js, we should not create and add errors during field resolution, but later during completion. We should also keep a response path, so that the errors we create can have that path in the error!. Just rebased this against master (f4ebaa1d6bcad4fa4a877a4f25af71617c8e4f0d). Hi @bsideup.\nNone at this time. I am still working through completing a product using this. I've not encountered any new issues with it in development. \nHave you tried this? Are you looking to get this released as an artifact?\nBest,\nDmitry. That would be great!! Thank you if you find time for that.\nDmitry\nOn Tue, Feb 21, 2017 at 1:26 PM Bruno Santos notifications@github.com\nwrote:\n\n@dminkovsky https://github.com/dminkovsky, I can have a stab into\nextracting the async related code into its own graphql-java-async lib if\nthat's alright with you.\nLet me know what you think.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/283#issuecomment-281432414,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZWctSfeIUvdzKkGqKiOP0gQ6IfZeks5reyw6gaJpZM4LR92_\n.\n. Let me know I can do a rebase for you first, if you want.\n\nI'll coordinate with @andimarek for whatever is necessary to get it on\nMaven Central.\nOn Tue, Feb 21, 2017 at 1:37 PM Dmitry Minkovsky dminkovsky@gmail.com\nwrote:\n\nThat would be great!! Thank you if you find time for that.\nDmitry\nOn Tue, Feb 21, 2017 at 1:26 PM Bruno Santos notifications@github.com\nwrote:\n@dminkovsky https://github.com/dminkovsky, I can have a stab into\nextracting the async related code into its own graphql-java-async lib if\nthat's alright with you.\nLet me know what you think.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/283#issuecomment-281432414,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZWctSfeIUvdzKkGqKiOP0gQ6IfZeks5reyw6gaJpZM4LR92_\n.\n. Starting now, hopefully won't take too long.\n\n\u0432\u0442, 21 \u0444\u0435\u0432\u0440. 2017 \u0433. \u0432 14:46, Bruno Santos notifications@github.com:\n\nSounds good. If you want to rebase, that will be great. Otherwise I can\nalways rebase it myself.\nThanks\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/283#issuecomment-281458305,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZVmge-Tg_8srM-3ABJhw46pEFwTXks5rez73gaJpZM4LR92_\n.\n. Cool. All set.\n\nOn Wed, Feb 22, 2017 at 10:23 AM, Dmitry Minkovsky dminkovsky@gmail.com\nwrote:\n\nStarting now, hopefully won't take too long.\n\u0432\u0442, 21 \u0444\u0435\u0432\u0440. 2017 \u0433. \u0432 14:46, Bruno Santos notifications@github.com:\n\nSounds good. If you want to rebase, that will be great. Otherwise I can\nalways rebase it myself.\nThanks\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/283#issuecomment-281458305,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZVmge-Tg_8srM-3ABJhw46pEFwTXks5rez73gaJpZM4LR92_\n.\n\n\n. Thank you @bmsantos! I will take a look soon.\n\nOn Thu, Feb 23, 2017 at 10:47 PM, Bruno Santos notifications@github.com\nwrote:\n\n@dminkovsky https://github.com/dminkovsky, I've created the\ngraphql-java-async project here\nhttps://github.com/bmsantos/graphql-java-async. In addition, a PR\nhttps://github.com/dminkovsky/graphql-java/pull/3 has been placed\nagainst your fork of graphql-java async branch.\nLet me know if you find any issues and/or have any questions.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/283#issuecomment-282196466,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZQndnTwSgomrQfTeOpBZffeFX8Irks5rflLSgaJpZM4LR92_\n.\n. You can do #toCompletableFuture() on a CompletionStage. Sorry for the late\nreply.\n\nOn Sat, Mar 11, 2017 at 1:38 PM, Denis Nedelyaev notifications@github.com\nwrote:\n\n@denvned commented on this pull request.\nIn src/main/java/graphql/GraphQLAsync.java\nhttps://github.com/graphql-java/graphql-java/pull/283#discussion_r105539434\n:\n\n+\n+    private static Logger log = LoggerFactory.getLogger(GraphQLAsync.class);\n+\n+    public GraphQLAsync(GraphQLSchema graphQLSchema) {\n+        super(graphQLSchema);\n+    }\n+\n+    public GraphQLAsync(GraphQLSchema graphQLSchema, ExecutionStrategy queryStrategy) {\n+        super(graphQLSchema, queryStrategy);\n+    }\n+\n+    public GraphQLAsync(GraphQLSchema graphQLSchema, ExecutionStrategy queryStrategy, ExecutionStrategy mutationStrategy) {\n+        super(graphQLSchema, queryStrategy, mutationStrategy);\n+    }\n+\n+    public CompletionStage executeAsync(String requestString) {\n\nIt would be more convenient if it returned CompletableFuture here.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/283#pullrequestreview-26428607,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZcQhqnd3ZDc5q0FTTazUB7c0Cb0Vks5rkuotgaJpZM4LR92_\n.\n. @andimarek yeah I've kind of been following that. Just still trying to finish my project which is woefully overdue :(. Looking forward to crawling out of my hole and rejoining the world. . Thank you. Looking forward.\n\n\u0447\u0442, 29 \u0434\u0435\u043a. 2016 \u0433. \u0432 0:39, Jiayu Liu notifications@github.com:\n\n@Jimexist commented on this pull request.\n\nIn src/main/java/graphql/execution/ValuesResolver.java\nhttps://github.com/graphql-java/graphql-java/pull/285:\n\n public Map<String, Object> getVariableValues(GraphQLSchema schema, List<VariableDefinition> variableDefinitions, Map<String, Object> inputs) {\n\n\n     Map<String, Object> result = new LinkedHashMap<String, Object>();\n\n     for (VariableDefinition variableDefinition : variableDefinitions) {\n\n\n\nresult.put(variableDefinition.getName(), getVariableValue(schema, variableDefinition, inputs.get(variableDefinition.getName())));\n\n\nObject variableValue = getVariableValue(schema, variableDefinition, inputs.get(variableDefinition.getName()));\n\n\nif (variableValue != null) {\n\n\nresult.put(variableDefinition.getName(), variableValue);\n\n\n}\n\n\nwill do - and i'll update this PR soon. thanks for the comment.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/285, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZT4PbG0RaI_QLLuCtdLcLR5qbcZhks5rM0eKgaJpZM4LTyWO\n.\n. No problem! Thank you for posting and apologies for my delay in responding. I'll be faster if the PRs are more direct and illustrate the problem directly. Will close this in a bit if it remains idle.. Will be released soon.\n\n\u043f\u0442, 23 \u0434\u0435\u043a. 2016 \u0433. \u0432 14:25, Peace Michaels notifications@github.com:\n\nThe title says it. 2.3.0 is not on maven\nhttps://mvnrepository.com/artifact/com.graphql-java/graphql-java\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/288, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZaeBzzdX__itppCUbFflS1tKgdQSks5rLC5QgaJpZM4LVDGM\n.\n. (thanks for opening the issue)\n\n\u043f\u0442, 23 \u0434\u0435\u043a. 2016 \u0433. \u0432 16:14, Dmitry Minkovsky dminkovsky@gmail.com:\n\nWill be released soon.\n\u043f\u0442, 23 \u0434\u0435\u043a. 2016 \u0433. \u0432 14:25, Peace Michaels notifications@github.com:\nThe title says it. 2.3.0 is not on maven\nhttps://mvnrepository.com/artifact/com.graphql-java/graphql-java\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/288, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZaeBzzdX__itppCUbFflS1tKgdQSks5rLC5QgaJpZM4LVDGM\n.\n. Looks like the artifact is up on central now. Thanks again.. Thank you @timtebeek and @shishuwu for reporting. . Also https://github.com/Distelli/graphql-apigen. > Probably we'd have to wrap all our DataFetchers in a wrapper class.\n\nThat's what I do. Whether you wrap or extend, I've not had problems with this approach. Check whether the field is allowed execution, and then execute or not. \n```\nabstract class AuthorizedDataFetcher extends DataFetcher {\n@Override\n  public Object get(DataFetchingEnvironment env) {\n    if (isAllowed(env)) {\n      return fetch(env);\n    }\n    // otherwise throw or return null;\n  }\n// perform actual data resolution\n  public abstract fetch(DataFetchingEnvironment);\n}\n```\nYou can clean the document too, but then you don't get null fields and errors for unauthorized fields, just the execution results you want allowed. \nWith regard to hooks, we are considering changing the API to facilitate this (#269) (@bbakerman)\n. Indeed, @oexza and @bbakerman's responses represent what the GraphQL authors suggest, too: http://graphql.org/learn/authorization/.. @oexza  @bbakerman I added a service layer to my application (gRPC), and indeed: having a service layer and thin fetchers is quite nice! . Thank you for reporting @herojan. \n@timtebeek mentions this might also be related https://github.com/oembedler/spring-graphql-common#protection-against-malicious-queries. Hi @kreed-rmn. What about Gitter: https://gitter.im/graphql-java/graphql-java ?. Sorry that's a typo in the readme. Try GraphQL.newGraphQL().\n\u0441\u0440, 11 \u044f\u043d\u0432. 2017 \u0433. \u0432 21:16, Darrin notifications@github.com:\n\nTrying the same Hello World after latest update and Android Studio is\ncomplaining about not finding the newObject().\nCode is as follows:\nimport android.os.Bundle;\nimport android.support.v7.app.AppCompatActivity;\nimport java.util.Map;\nimport graphql.GraphQL;\nimport graphql.schema.GraphQLObjectType;\nimport graphql.schema.GraphQLSchema;\nimport static graphql.Scalars.GraphQLString;\nimport static graphql.schema.GraphQLFieldDefinition.newFieldDefinition;\nimport static graphql.schema.GraphQLObjectType.newObject;\npublic class MainActivity extends AppCompatActivity\n{\n@Override\nprotected void onCreate(Bundle savedInstanceState)\n{\nsuper.onCreate(savedInstanceState);\n\nsetContentView(R.layout.activity_main);\n\n\n\nexample();\n\n}\nprivate void example()\n{\nGraphQLObjectType queryType = newObject()\n\n        .name(\"helloWorldQuery\")\n\n        .field(newFieldDefinition()\n\n                .type(GraphQLString)\n\n                .name(\"hello\")\n\n                .staticValue(\"world\"))\n\n        .build();\n\n\n\nGraphQLSchema schema = GraphQLSchema.newSchema()\n\n        .query(queryType)\n\n        .build();\n\n\n\nGraphQL graphQL = GraphQL.newObject(schema).build();\n\n\n\nMap<String, Object> result = (Map<String, Object>) graphQL.execute(\"{hello}\").getData();\n\n\n\nSystem.out.println(result);\n\n// Prints: {hello=world}\n\n}\n}\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/295, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZcqNfZeaGst4DNH3hZA7a41lgKKTks5rRY0MgaJpZM4LhTCv\n.\n. Oh sorry you're on the 2.3.0 released artifact.\n\nThe readme is for master, which isn't released yet.\nHave a look at the readme on a tagged release.\n\u0441\u0440, 11 \u044f\u043d\u0432. 2017 \u0433. \u0432 21:26, Darrin notifications@github.com:\n\nDidn't help. Looks like it can't find anything other than class for\nGraphQL. No methods at all associated with it from what I am seeing.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/295#issuecomment-272058392,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZWp4zdi8QfYjhZ-hEfay_hMrrjjqks5rRY9pgaJpZM4LhTCv\n.\n. > Will it be long before that is released? I may wait if it's just a few days or so.\n\nNot sure when the next release will be. Probably within the next month? 2.3.0 is fine for now, I think.\n\nAlso, do you know if there is an example of how to hit an endpoint? \n\nI'm not sure what you mean by hitting an endpoint. Those examples predate me and I didn't grok all of them. But it sounds like you got query execution going.\n. Whoops didn't meant to close.. But actually I think it makes sense to close this. Please post if you have another question or check out the Gitter channel or mailing list.. Thank you for the report! \nHere's a failing test: https://github.com/graphql-java/graphql-java/pull/297/files#diff-79600ba7380fb4f5a886ef11a5cc3aba. Hi. Please check out #297.\n\u0447\u0442, 12 \u044f\u043d\u0432. 2017 \u0433. \u0432 19:58, bbakerman notifications@github.com:\n\nCan you leave a code snippet to help with verification and unit testing\nany fix please\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/296#issuecomment-272331514,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZc_czJdaRi8zMHG6azBCCZDc_j5Dks5rRswxgaJpZM4LhWGu\n.\n. Yes definitely.\n\n\u0447\u0442, 12 \u044f\u043d\u0432. 2017 \u0433. \u0432 20:50, rayngwf notifications@github.com:\n\nThis unit test checks the exact reported issue. Thanks.\nTo make unit test for default value more complete, we should include\ntesting with other value types as well, including list and enum etc.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/297#issuecomment-272339560,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZbgJA6FOzpKc8TCethjNg3pe7x66ks5rRthygaJpZM4Lh5s9\n.\n. Makes sense. I'll bump the version. Thanks for reporting!\n\n\u0432\u0441, 15 \u044f\u043d\u0432. 2017 \u0433. \u0432 0:06, ersimont notifications@github.com:\n\nI'm hesitant because I don't have a build setup for this project, and I\nalso don't use Gradle. I assume it's just bumping the version number in\nbuild.gradle, and that's it? If so, I could make the PR, but it would\nprobably be faster for a project member to do it themselves than to verify\nthat I did it correctly...\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/300#issuecomment-272674161,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZazb15MyK1gCfSSp15Yf6EHeLXpdks5rSalFgaJpZM4Ljz9U\n.\n. parseDocument() parses GraphQL documents, which may include queries,\nfragments and schema definitions.\n\nWhat are you trying to parse? What errors are you receiving?\nOn Mon, Jan 16, 2017 at 8:54 AM, Huixiao Huang notifications@github.com\nwrote:\n\nSince we can do parseDocument() with the queryString, can we do\nparseQueryString() with the document, which is the AST?\nI tried it but turned out that it didn't work. However, parseQueryString()\nis extremely important when it comes to the two-way parse. I hope you can\nhelp me. Thanks.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/302, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZflGW4rPQSQOMlWulgG9LlHO17f7ks5rS3aegaJpZM4LklFY\n.\n. > for the information flow that is from Document document -> String input?\n\nOh do you mean like: https://github.com/graphql-java/graphql-java/issues/126\n?\n\u0432\u0442, 17 \u044f\u043d\u0432. 2017 \u0433. \u0432 0:05, Huixiao Huang notifications@github.com:\n\nSorry for my misdescribing. For parseDocument(), consider this infomation\nflow: String input -> Document document. So can we do a parseQueryString()\nfor the information flow that is from Document document -> String input?\nIn this case, we can do some operations between queries & fragments, such\nas appending a fragment into a query in runtime. Apperantly we can do this\nappending operation with a Document instance which is parsed from the\nString query. However, how can we get the updated String query from its\nupdated Document instance? This is my problem.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/302#issuecomment-273023588,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZSnMPPLYz_HuWL7y_iGtQs7KwKfOks5rTEwBgaJpZM4LklFY\n.\n. Yes, you are correct, I believe this is a defect: you would need to have\navailable the FragmentDefinition referenced by the FragmentSpread to know\nwhat fields the fragment spread is spreading. But in\nDataFetchingEnvironment, nothing has a reference to that fragment. I\nbelieve adding the ExecutionContext to the DataFetching environment has\nbeen suggested elsewhere. We should go ahead and do something like that.\n\nHowever, FragmentSpread is an AST node that describes the AST. In this\ncase, it's a fragment spread and it has no children. Directly having a\nreference to its FragmentDefinition is not appropriate for an AST class, I\nthink, since its focus is to model a language node as it appeared in the\ndocument.\nThank you for reporting this! Did you find a workaround?\nOn Wed, Jan 18, 2017 at 2:15 AM, Jimmy Shen notifications@github.com\nwrote:\n\nDataFetchingEnvironment.fields has information selected fields.\nBut when I run below query, I can't find a way to know the field\nselectionSet at emplPositionClasses field. Because it is explicit defined\nfragment, so it is the instance of selection in emplPositionClasses\nselectionSet is FragmentSpread. and there is no methods to get selectionSet\non FragmentSpread.\nFor the other two type of selection, Field and InlineFragment, there are\nmethods to get selectionSet, so inline fragment has no issue.\nthe field emplPositionClasses type is EmplPositionClassConnection\nquery {\n  mantle {\n    emplPositionClasses {\n      ...EmplPositionClassesFragment\n    }\n  }\n}\nfragment EmplPositionClassesFragment on EmplPositionClassConnection {\n  edges {\n    node {\n      id\n      emplPositionClassId\n      title\n      description\n    }\n  }\n}\nSo is it reasonable to also add getSelectionSet() method on class\nFragmentSpread?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/303, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZePrW1abBlaorCEmjTu7FQy8B8d_ks5rTbwlgaJpZM4LmjVJ\n.\n. > Field and InlineFragment has it.\n\nYes, they have them because these classes represent field and inline fragment nodes in the GraphQL query language. In the query language, those types of nodes can have a selection set. But the FragmentSpread, which models a fragment spread as it occurs in a written GraphQL query, by definition does not have a selection set.\nSee the Facebook reference implementation/modeling: FieldNode vs InlineFragmentNode vs FragmentSpreadNode. FieldNode and InlineFragmentNode have selection sets. FragmentSpreadNode does not.\nBut yes, of course, it is convenient to have those fragment definitions and their selection sets during execution. The fragment definitions are available in the ExecutionContext, which should be exposed in the DataFetchingEnvironment. \nRelated perhaps  #301 #260 . Hi @mrcirillo, thanks for investigating. Yes, this is intentional. executionContext.getRoot() in this case returns what is the \"context\" inside the DataFetcher, aka the root of the whole GraphQL execution, aka what you passed to GraphQL#execute() as the source.\nIndeed, we can pass the whole ExecutionContext into the DataFetcher via the DataFetchingEnvironment to get the fragment definitions. I think we should make this change.. Oh cool. Thanks. Something like https://github.com/graphql/graphql-js/blob/v0.8.2/src/type/definition.js#L560? (aka the DataFetchingEnvironment)\n. Also please see https://github.com/graphql-java/graphql-java/commit/d1af3ac677e4e85fed0e6b851088b06eb3c8d8f5 the most recent commit on master. Thank you!. Hi @dllx. Thank you for this! \nI just wrote some comments on my async execution strategy PR that stated the need for such a path mechanism. However, I also think error handling more broadly needs to be fixed in light of #268.\nAnd I'm not sure how to do it for all the execution strategies that are currently in the project. \nWhat do you think?. What is the official spec pretty vague about?. Also it's not actually used anywhere in the code base.. Hi @mattesja. The version you see by default at https://github.com/graphql-java/graphql-java/ is the latest master. Please select a tagged release or commit to browse other versions of this codebase.. I think some of the confusion regarding this class stems from the fact that most (if not all) of the built-in scalars call and return the result of serialize() from the parse methods.\nThis is just an implementation detail of the built-in scalars and the nature of those scalars themselves\u2014serialization and parsing behavior are desired to be the same.\nBut if you are implementing your own scalars, you may want the parse behavior to transform a simple type into a more complex type, and then serialization to transform a complex type into a simpler or more common type (say, a type that is well-known to Jackson).. For example, I have a class that provides a base for input-only scalars: \n```\nimport graphql.schema.Coercing;\npublic abstract class InputCoercing implements Coercing {\n    /*\n     * Input scalars should not be serialized\n     * @param input the input object\n     * @return always null\n     /\n    @Override\n    public final Void serialize(Object input) {\n        return null;\n    }\n}\n```. Music to my ears!. (Thank you for your review!). Thanks for this. More schema definition validation is necessary and this is a good step in that direction!. Sounds good. Thank you!\nOn Wed, Feb 8, 2017 at 3:44 PM, Duane notifications@github.com wrote:\n\nPlease don't accept this yet, I found a problem and have some additional\nvalidation to add.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/323#issuecomment-278455736,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZZUn9cTgfpi0uY-yRRCneF9qoMmyks5raikXgaJpZM4L697a\n.\n. Just dropping a few related notes:\n\n\n\n227 can be closed after this is merged\n\n\n215 is also good for follow up. Hi @karthicks. Thank you for posting! Have you seen https://github.com/graphql-java/graphql-java/pull/283?. Hi Karthick,\n\n\nThank you for this analysis and your implementation. I am sorry for my slow reply and my short initial reply to you. I am just very busy at this time. I've looked at your implementation and have some thoughts too, but I cannot lay them out at this time. I will update when I can get back to this. \nDmitry. Thank you for this! Really appreciate all testing improvements.. Thank you again for this!. Thanks yes this seems like a good thing to me. So the cast would happen\nthrough Class#cast()?\n\u0447\u0442, 16 \u0444\u0435\u0432\u0440. 2017 \u0433. \u0432 11:59, Guy Smorodinsky notifications@github.com:\n\nFor my opinion, it will be safer for programmers that way, because casting\nerrors will be caught at compile time rather than run time (and you wont\nget CastException)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/328, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZVLRvt4e9Oa1eatIWA68EgWvcf7Gks5rdIBngaJpZM4MDRmZ\n.\n. @bbakerman what do you think?. Thank you @guy120494 . By the way, I thought it about it some more and I'm not really sure this will improve compile-type safety. Does it actually?. That's correct but what it's checking there is that the right and left side\nmatch. At runtime if cast fails, you still get a class cast exception.\n\nNot a java expert either, and I think that's why I was confused about this\nat first! But I think my current understanding is correct.\n\u0447\u0442, 16 \u0444\u0435\u0432\u0440. 2017 \u0433. \u0432 14:47, Guy Smorodinsky notifications@github.com:\nwell, Im not a java expert (yed :P ) but I think it is.\nlets say that getSource suppose to return Integer.\nString s = env.getSource(); - compiles but we get ClassCastException\nString s =env.getSource(Integer.class) - doesnt compile\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/329#issuecomment-280438394,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZb_4ZEayhNmmZ591aGCFzUd3w4Wvks5rdKfpgaJpZM4MDXFA\n.\n. Hi Tyler,\nThe readme is current with master. Please see the tree at the v2.3.0 tag to\nsee that version's readme.\nThanks,\nDmitry\n\u0441\u0431, 18 \u0444\u0435\u0432\u0440. 2017 \u0433. \u0432 11:57, Tyler Nickerson notifications@github.com:\n\nI'm trying to get the Hello World code running on my server, and have\ninstalled version 2.3.0 using Gradle:\ncompile 'com.graphql-java:graphql-java:2.3.0'\nHowever, attempting to call\nGraphQL graphQL = GraphQL.newGraphQL(schema).build();\nthrows an errors saying that newGraphQL cannot be resolved. I checked the\ndecompiled class file and for some reason all of the static methods are\ngone and it just contains a bunch of execute() public methods. Any idea\nas to why?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/332, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZXf7h9SylfsiXChpoVICw5Uf7ih3ks5rdyL6gaJpZM4MFLUS\n.\n. It's mostly cosmetic with regard to the scheme definition API. You'll find\nit's pretty similar.\n\n\u0441\u0431, 18 \u0444\u0435\u0432\u0440. 2017 \u0433. \u0432 12:58, Tyler Nickerson notifications@github.com:\n\nClosed #332 https://github.com/graphql-java/graphql-java/issues/332.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/332#event-968071683,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZSriFqzk7MgvYBa1Cg7PGidEmlUIks5rdzFDgaJpZM4MFLUS\n.\n. @hepin1989 could you do it in Immutable? would those classes handle validation, or would there be another layer on top of the immutables that did schema validation?. Thanks for posting. Yes, this would be cool.\n\nYeah is there some reason these would need to be persisted beyond RAM?\n\u0432\u0442, 28 \u0444\u0435\u0432\u0440. 2017 \u0433. \u0432 12:29, mattesja notifications@github.com:\n\nI just want to preparse the queries on system startup and keep them in\nmemory.\nI don't think, that a persistent storage of parsed query Documents has a\nbig benefit on performance.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/335#issuecomment-283107956,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZfBtrlH-H_ihJ3YqUD9smLsm_QcOks5rhFmAgaJpZM4MNNk3\n.\n. > This got me thinking - what are we trying to achieve with multi module?\nIs it jdk6 / jdk8 split - that is code that runs on the base jdk6 base and some new code that is jdk8?\n\nYes, for me it's the JDK6/8 split.\nAlso, I know some people are using just the language features (i.e. @hepin1989 at Taobao) and have written their own execution code. \nIf I had time to do this split right now, I would separate out the (i) language and then (ii) parts of the execution framework that would be common to all execution strategies (coercing enum, coercing scalars, things like that).. Because if you look at all the execution strategies, they all copy paste that coercing code and complete value code one way or another.. Hello Andi and Arnold,\nIf someone can do it I think it should be done. I understood\ngraphql-relay-js to be more useful as an example implementation guide\n(who is actually using arrays as connection data?), and I experienced the\nsame with our Relay package. I really appreciate the simplicity of Andi's\ndecision to include it because it adds no dependencies and one whole class,\nbut it took me a while to get my head around Relay and in part it was\nbecause I was confused by the meaning of \"Relay support\" and what that\nactually entailed. People talk about the \"ergonomics\" of Relay being subpar\nand I definitely experienced that by way of these helper packages that just\nconfused me. But that may be just me.\nAnyway, if anyone can allocate time now to split things up, Relay would be\na good candidate for its own module. Or to be removed altogether.\nPS Relay is changing now. I don't know the details of the new Relay but I\nbet there are some differences in expectations from the backend.\n\u043f\u043d, 10 \u0430\u043f\u0440. 2017 \u0433. \u0432 12:24, Andreas Marek notifications@github.com:\n\nThe initial motivator for breaking up is now obsolete: We switched to Java\n8.\n@dminkovsky https://github.com/dminkovsky Do you think it should still\nbe done?\nThe most obvious candidate is probably the relay package imho: this should\nreally live in its own module. ( @aschrijver\nhttps://github.com/aschrijver )\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/336#issuecomment-293002351,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZaFz430bjYHxflds4RNcNlIDwOhVks5rulezgaJpZM4MNnVe\n.\n. And then you have PRs like https://github.com/graphql-java/graphql-java/pull/360 that actually improve the Relay support. So perhaps I'm just not a visionary :).. Looks like Relay Modern docs are out!! https://facebook.github.io/relay/docs\n\n\u043f\u043d, 10 \u0430\u043f\u0440. 2017 \u0433. \u0432 12:55, Dmitry Minkovsky dminkovsky@gmail.com:\n\nHello Andi and Arnold,\nIf someone can do it I think it should be done. I understood\ngraphql-relay-js to be more useful as an example implementation guide\n(who is actually using arrays as connection data?), and I experienced the\nsame with our Relay package. I really appreciate the simplicity of Andi's\ndecision to include it because it adds no dependencies and one whole class,\nbut it took me a while to get my head around Relay and in part it was\nbecause I was confused by the meaning of \"Relay support\" and what that\nactually entailed. People talk about the \"ergonomics\" of Relay being subpar\nand I definitely experienced that by way of these helper packages that just\nconfused me. But that may be just me.\nAnyway, if anyone can allocate time now to split things up, Relay would be\na good candidate for its own module. Or to be removed altogether.\nPS Relay is changing now. I don't know the details of the new Relay but I\nbet there are some differences in expectations from the backend.\n\u043f\u043d, 10 \u0430\u043f\u0440. 2017 \u0433. \u0432 12:24, Andreas Marek notifications@github.com:\nThe initial motivator for breaking up is now obsolete: We switched to Java\n8.\n@dminkovsky https://github.com/dminkovsky Do you think it should still\nbe done?\nThe most obvious candidate is probably the relay package imho: this should\nreally live in its own module. ( @aschrijver\nhttps://github.com/aschrijver )\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/336#issuecomment-293002351,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZaFz430bjYHxflds4RNcNlIDwOhVks5rulezgaJpZM4MNnVe\n.\n. From the current version of the spec:\n\n\"When submitting a query document with multiple operations to a GraphQL\nservice, the name of the desired operation to be executed must also be\nprovided.\"\nhttp://facebook.github.io/graphql/#sec-Executing-Operations\nI take this to mean that a single operation is executed.\nOn Mon, Mar 20, 2017 at 3:48 PM, Andrew Potter notifications@github.com\nwrote:\n\nI think this line is really the problem: https://github.com/graphql-\njava/graphql-java/blob/master/src/main/java/graphql/execution/\nExecutionContextBuilder.java#L50\nIf you have more than one operation in your query, it forces you to pick\none to run. Isn't that a huge breach of the spec?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/339#issuecomment-287876548,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZUl85wNaskkj3E5Lgtn79zFVS-w1ks5rntfwgaJpZM4MXxiD\n.\n. There is more in 6.1:\n\n\"To execute a request, the executor must have a parsed Document (as defined\nin the \u201cQuery Language\u201d part of this spec) and a selected operation name to\nrun if the document defines multiple operations, otherwise the document is\nexpected to only contain a single operation. \" \u2014\nhttp://facebook.github.io/graphql/#sec-Executing-Requests\nOn Mon, Mar 20, 2017 at 4:25 PM, Dmitry Minkovsky dminkovsky@gmail.com\nwrote:\n\nFrom the current version of the spec:\n\"When submitting a query document with multiple operations to a GraphQL\nservice, the name of the desired operation to be executed must also be\nprovided.\"\nhttp://facebook.github.io/graphql/#sec-Executing-Operations\nI take this to mean that a single operation is executed.\nOn Mon, Mar 20, 2017 at 3:48 PM, Andrew Potter notifications@github.com\nwrote:\n\nI think this line is really the problem: https://github.com/graphql-jav\na/graphql-java/blob/master/src/main/java/graphql/execution/E\nxecutionContextBuilder.java#L50\nIf you have more than one operation in your query, it forces you to pick\none to run. Isn't that a huge breach of the spec?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/339#issuecomment-287876548,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZUl85wNaskkj3E5Lgtn79zFVS-w1ks5rntfwgaJpZM4MXxiD\n.\n\n\n. No problem! Good to review spec and confirm understanding. Thanks for\nposting.\n\n\u043f\u043d, 20 \u043c\u0430\u0440\u0442\u0430 2017 \u0433. \u0432 17:10, Andrew Potter notifications@github.com:\n\nSorry, my mistake - it looks like that is the correct behavior. The query\nin the original comment isn't actually valid.\n@vijethpatil https://github.com/vijethpatil if you want to get multiple\nquery results in the same request, you can use something like this instead:\n{\n  q1: company {\n    ...\n  }\n  q2: company {\n    ...\n  }\n}\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/339#issuecomment-287898946,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZV31sDinoKBe4bPmtp4lcBG40T1aks5rnusygaJpZM4MXxiD\n.\n. Thanks for opening this issue. Your observation is clearly correct and is\nsomething I hope is fixed soon: either by me or by a PR from someone else.\nThis is also related to #268.\n\nI suspect this will be fixed in 3.0 as part of the transition to Java 8\n(see related issue #338)\nRelated is that errors do not list the field path that caused the error.\nThat is in part because this implementation does not track field path\nduring execution.\n\u043f\u0442, 24 \u043c\u0430\u0440\u0442\u0430 2017 \u0433. \u0432 17:35, Dom Kiva-Meyer notifications@github.com:\n\ngraphql-java does not currently handle this section of the GraphQL spec\nhttps://facebook.github.io/graphql/#sec-Errors-and-Non-Nullability\ncorrectly.\nSince Non-Null type fields cannot be null, field errors are propagated to be handled by the parent field. If the parent field may be null then it resolves to null, otherwise if it is a Non-Null type, the field error is further propagated to it\u2019s parent field.\ngraphql-java throws graphql.GraphQLException: Cannot return null for\nnon-nullable type instead of propagating up to the parent field.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/350, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZTrAcwBwWDIU7eFmTGa25SoxiPQXks5rpDcXgaJpZM4Moy2T\n.\n. By the way, in my playing with this, I experimented with fetchers that return:\n\n\nA future of a list of non-futures\nA future of a list of futures\nA non-future list of futures\n\n...and various other permutations.\nI think there should be limited support for which of these we support, as it gets weird and complicated pretty fast. Most importantly, given the recursive bottom-up resolution of GraphQL, I think only supporting async collections that you expect will be fully resolved made sense: https://github.com/dminkovsky/graphql-java/blob/async/src/test/groovy/graphql/execution/async/AsyncExecutionStrategyTest.groovy#L45.\nAlso, while we're talking about resolving future collections, this library is very useful until Java 9 comes out: https://github.com/spotify/completable-futures. Could we call and return the argument(GraphQLArgument.Builder builder) overload that's defined below? \n. Same as above?\n. Same as above?\n. As above?\n. One more\n. Could we add an override to query() that accepts a GraphQLObjectType.Builder, so that we don't have to call .build() above? Same with mutation() then.\nCan we do the same with GraphQLFieldDefinition#type()? For that it would be an overload that accepts a GraphQLObjectType.Builder. I think thats the only builder it should accept. \n. Thanks!\n. This PR includes a MapDataFetcher\n. I don't understand. Doesn't this return null if the key does not exist?\n. Why would env be null? \n. How does that relate to this?\n. Oh yeah, thanks!\n. Kind of wish this was a better example anyway. Also this section of the docs should document DataFetchingEnvironment, right?\n. Yeah, I don't either. You think maybe no default?\n. > Is this interchangeable with a FieldDataFetcher?\nNope. MapDataFetcher takes behavior that used to be part of both PropertyDataFetcher and FieldDataFetcher. Currently, both of these fetchers attempt to use the source as a Map before doing anything else. In this PR, neither of these fetchers attempt using the source as a Map.\n. > I get that an object has fields that can be \"fetched\".\nWell, an object only has fields in the Java sense of the word \"field\" if it has public fields that can be accessed like in FieldDataFetcher, using reflection.\n\nThose fields could potentially be fetched as properties too \n\nYes, if they can be fetched as properties too (because the object has getter methods that return the field values), you can alternatively use PropertyDataFetcher. \nWhat I am trying to do here is to avoid having something called PropertyDataFetcher that actually does 3 different things.\n. I just updated the README on this branch to fix the mistake you found. The README also explains what the data fetchers to. They have very discrete, specific functionality. \n. > Actually I don't know how one can assume that the fields or the getters will be publicly accessible\n@IamCornholio my assumption is that the developer knows what kind of object is returned by #getSource() at every level! The flexibility provided by the current PropertyDataFetcher is not because the user doesn't know what type of object they will be dealing with, but because PropertyDataFetcher is meant to work for maps, fields, and properties.\nSo, if you know that a field's source will be an object with a publicly accessible field, use FieldDataFetcher. If you know it will be a Map, use MapDataFetcher.\n\nI think PropertyDataFetcher is the one to go with.\n\n@markphilpot you don't think users are returning Maps more often than objects with getters? Map is the first test in the current implementation.\n. I'm having trouble wrapping my mind around this :). Wouldn't this have some pretty far reaching consequences?\n. so then #dataFetcher(DataFetcher fetcher) becomes #<T>dataFetcher(DataFetcher<T> fetcher) and then inside ExecutionStrategy#resolveField() you get something like T result = fetcher.get(...) and then all the completeValue() signatures change. Do you really get much added type safety from this?\n. Anyway, I think I'd prefer to leave this for a different PR. This one is already pretty big IMO.\n. No default fetcher at the GraphQLFieldDefinition.Builder level sounds\ngood to me too. I'll update the code and docs to reflect that.\nI do sort of wish there could be a good default, but the presence of the\ngood default has in its own right caused confusion.\n\u0432\u0442\u043e\u0440\u043d\u0438\u043a, 13 \u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Mark Philpot \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nIn src/main/java/graphql/schema/GraphQLFieldDefinition.java\nhttps://github.com/graphql-java/graphql-java/pull/206#discussion_r78621307\n:\n\n@@ -185,11 +163,7 @@ public Builder deprecate(String deprecationReason) {\npublic GraphQLFieldDefinition build() {\n         if (dataFetcher == null) {\n-                if (isField) {\n-                    dataFetcher = new FieldDataFetcher(name);\n-                } else {\n-                    dataFetcher = new PropertyDataFetcher(name);\n-                }\n-                dataFetcher = new PropertyDataFetcher(name);\n\nI personally use objects for the type safety, but I can understand a Map\nmight be a new user's first choice. In that light, would vote for being\nexplicit with no default since we are breaking out Map and Property\nfunctionality from Field\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/206/files/eb75d57f0bbcaed455812218fd81beda028a8379#r78621307,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZVdcsJiMykODP9z4d0kA-28aWE-jks5qpvDtgaJpZM4J7Pgu\n.\n. Done\n\nOn Tue, Sep 13, 2016 at 3:00 PM, Dmitry Minkovsky dminkovsky@gmail.com\nwrote:\n\nNo default fetcher at the GraphQLFieldDefinition.Builder level sounds\ngood to me too. I'll update the code and docs to reflect that.\nI do sort of wish there could be a good default, but the presence of the\ngood default has in its own right caused confusion.\n\u0432\u0442\u043e\u0440\u043d\u0438\u043a, 13 \u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Mark Philpot \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\nIn src/main/java/graphql/schema/GraphQLFieldDefinition.java\n\nhttps://github.com/graphql-java/graphql-java/pull/206#discussion_r78621307\n:\n\n@@ -185,11 +163,7 @@ public Builder deprecate(String deprecationReason) {\npublic GraphQLFieldDefinition build() {\n         if (dataFetcher == null) {\n-                if (isField) {\n-                    dataFetcher = new FieldDataFetcher(name);\n-                } else {\n-                    dataFetcher = new PropertyDataFetcher(name);\n-                }\n-                dataFetcher = new PropertyDataFetcher(name);\n\nI personally use objects for the type safety, but I can understand a Map\nmight be a new user's first choice. In that light, would vote for being\nexplicit with no default since we are breaking out Map and Property\nfunctionality from Field\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/206/files/eb75d57f0bbcaed455812218fd81beda028a8379#r78621307,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZVdcsJiMykODP9z4d0kA-28aWE-jks5qpvDtgaJpZM4J7Pgu\n.\n. Just realized an issue with not having a default fetcher means that\ninterface field definitions now require a fetcher. How about, instead, we\nreturn null fields without a fetcher?\n\n\nOn Tue, Sep 13, 2016 at 3:22 PM, Dmitry Minkovsky dminkovsky@gmail.com\nwrote:\n\nDone\nOn Tue, Sep 13, 2016 at 3:00 PM, Dmitry Minkovsky dminkovsky@gmail.com\nwrote:\n\nNo default fetcher at the GraphQLFieldDefinition.Builder level sounds\ngood to me too. I'll update the code and docs to reflect that.\nI do sort of wish there could be a good default, but the presence of the\ngood default has in its own right caused confusion.\n\u0432\u0442\u043e\u0440\u043d\u0438\u043a, 13 \u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044f 2016 \u0433. \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Mark Philpot \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\nIn src/main/java/graphql/schema/GraphQLFieldDefinition.java\n\nhttps://github.com/graphql-java/graphql-java/pull/206#discussion_r78621307\n:\n\n@@ -185,11 +163,7 @@ public Builder deprecate(String deprecationReason) {\npublic GraphQLFieldDefinition build() {\n         if (dataFetcher == null) {\n-                if (isField) {\n-                    dataFetcher = new FieldDataFetcher(name);\n-                } else {\n-                    dataFetcher = new PropertyDataFetcher(name);\n-                }\n-                dataFetcher = new PropertyDataFetcher(name);\n\nI personally use objects for the type safety, but I can understand a Map\nmight be a new user's first choice. In that light, would vote for being\nexplicit with no default since we are breaking out Map and Property\nfunctionality from Field\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/206/files/eb75d57f0bbcaed455812218fd81beda028a8379#r78621307,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AANWZVdcsJiMykODP9z4d0kA-28aWE-jks5qpvDtgaJpZM4J7Pgu\n.\n. > @dminkovsky has raised concern about the fetcher now being required by the field definition interface. ... Required how?\n\n\n\nThanks @IamCornholio. To clarify: we were thinking that perhaps there should be no default DataFetcher. If there is no default DataFetcher, and the user does not specify a data fetcher, then building a field will cause an exception. That's fine if you're specifying a field for a GraphQLObjectType. You want every field to have a DataFetcher. But if you're specifying a field for a GraphQLInterfaceType, then you want to be able to omit the data fetchers.\n. @bpatters yeah I was confused about that too (that's how it was in the current PropertyDataFetcher and FieldDataFetchers).\n\nSo you might as well cast the Map to a Map\n\nSo, like this?\nreturn ((Map) source).get(keyName);\nPer your comment and my confusion, why not:\nreturn ((Map<String, ?>) source).get(keyName);\n. As of a recently merged PR, GraphQLObjectType.Builder#field() accepts GraphQLFieldDefinition.Builder instances. It will call #build() for you, so you don't have to do it yourself all over the place. This PR will be in the next release. So this is not actually a mistake, at least not on master.\n. Yes, this looks like a mistake. Thank you.\n. I'm not sure Collections.synchronizedList() is good here anyway. Thanks, I'll check out CopyOnWriteArrayList. My serial implementation is async. The current serial implementation is not async. Both are serial though.. That's just in there while I work this out. That artifact is tiny (50 LOC?) and can be copy/pasted into this project license-permitting.. Thanks for taking a look!. thanks that's been bugging me :). yes, this is what i was thinking... had you seen https://github.com/graphql-java/graphql-java/pull/214/files? . Thanks for pointing this out @IamCornholio. Going to leave this for now, and consider @bbakerman's builder PR. Thanks. This for loop needs to be replaced with a construct that properly closes over the vars passed to resolveFieldAsync. DataFetcher<ComplicatedVal> on the left; but maybe instead of ComplicatedVal something simpler like Foo or Bar?. This is 100% a good change but maybe you could accumulate these on something like a \"cleanup\" branch and submit them without functionality changes. Or even submit them as one-off PRs. It would make evaluating PRs easier. \nSame for the comment addition below.. I am wondering what the compatibility implications are here. I can't imagine any, but I can't imagine many things :).\nRelated to the above question: Why would you want this to be the way this works? I mean, this method returns the resulting Map, and the client then get()s from that Map. With our without the PR, they'd get null for missing keys. Right?. Good call. Thank you. What do you think otherwise?. Thank you!. Please disregard my previous comment, I was confused. \nBut I am still confused. The input parameter may or may not be the result of deserialization, but at this stage of execution it doesn't matter where that Map came from. I'm sorry I'm not seeing this at all. A concrete example\u2014or even better a failing test\u2014would help a lot.. @hepin1989 replaced this with .collect(toMap()). Thanks again.. GraphQL.newGraphQL() I think is more in line with the other builder factory names. (newObject() is already \"taken\" by GraphQLObjectType). I think this should take into account the mutation strategy selection, which is already released https://github.com/graphql-java/graphql-java/pull/240/files. How about calling this provide() since this may providers may provide an id not by generating it?. thanks!. For example if http://stackoverflow.com/a/24910594/741970. Use TestUtil.schemaWithInputType(inputType). its -> it's . We could rename DataFetcher to Resolver.. Perhaps they will evolve the CompletionStage interface to make it useful. toCompletableFuture().get() is not horrible imo.. What is painfully missing? Waiting for an async collection to finish?. ",
    "creactiviti": "Yes, you are right. That's what I did on my project. I made PR for it though should you find it useful for others. \n. Cool @andimarek. I think that's very workable. Thanks. \n. Thanks @andimarek \n. ",
    "ntkoopman": "Turns out this is just me not reading the specification.\n. Why would it have a different type if the actual class is the same?\nAnyway, instead of using a User object directly, you could wrap it inside a TypedUser object that contained the the User object and the correct type.\n. It can be done, but it's something that should be handled by whatever is handling your http requests. The implementation is different depending on which framework you are using.\nYour framework should expose some sort of multipart file object that you can then add to the rest of the variables and execute as a normal GraphQL query.\n. You would implement this in every dataFetcher you pass to mutationWithClientMutationId or create a subclass. Your code will fail if the dataFetcher returns something other than a Map.\n. ",
    "Hellblazer": "So, this is due to my misunderstanding types and references in the top level schema.  In my schema generation, I believe I had multiple instances of the type I'm referencing.  Not good, I'm sure.  The randomness was due to my traversal and whether I emitted a concrete type, or a reference type in the given field definition based on lookup order from the db.  Not sure why I hit this class cast exception, but it was clearly due to me building the types and references between them incorrectly.\n. Sure.  I apologize for no tests, but groovy - while something I do know about - isn't anything I am fluent enough in to produce tests.  And gradle....  so sorry about that.\nMy test case is a query of the form\nquery m($id: String) { myQuery { id: $id } }\nwhere id is constrained to be non null string.\nWhat happens is that when the input is a variable, not explicit in the query text, the expected type is non null wrapped and the actual type is not.  The way the code was written, this will return false without ever checking if the wrapped expected type matches the actual type.\n. Sorry, somehow missed this notification for the comment.\nI must not have been clear.  The input argument to the query is declared as NonNull.  The problem with the current logic is that when I have a input argument declared as NonNull, I will get a NPE when I supply the input argument as a query variable.  The NPE does not occur if this input argument is supplied in the text of the query.  \nFor example:\nquery m($id: String) { myQuery { id: $id } }\nThe query variable \"id\" is not null and has value \"foo\".  This causes a NPE at the point in the code where I fixed this.\nquery m { myQuery { id: \"foo\" } }\nWill not throw an NPE.\nIf I was able to create a groovy test case for this, it's pretty easy to verify.  Unfortunately, groovy is pretty far out of band for me.  However, the test case is very simple.  Create a query that has an NonNull input argument.  Supply the value of that input in the variable map you pass when executing the query.  NPE will happen.  \nI certainly understand this may in fact not the way to fix this.  But this NPE pretty much prevents any use of NonNull input args when supplied by variables to the query.\n. Well, this is what I get for not writing a test ;)  So, I have corrected this.  You can find the gist here.\nApologies for this.  This is a completely different issue and I was confusing it with the NPE bug you already merged.\nThis problem is validating types and when NonNull argument, supplying argument values fails due to not navigating to the wrapped type.\n. omg.  Yes, you're absolutely correct.  I completely spaced about the !. \nWell, thanks for the patience ;)  Much appreciated.\n. Ugh.  I misplaced that.  Should be as you corrected.   So I looked at Introspection on master and indeed, line 87 (85 in 1.2) is where you are handling what I'm seeing a GraphQLArgument attempting to be cast as a GraphQLInputObjectField.\nExcellent.  Again, thanks!\n. Cool.\nAnd thanks for this project ;)\n. ",
    "hannesj": "Thanks, seems to work now!\n. Hi,\nThe problem seems to come from the fact that JavaScript does only have the Number type, so that values like 10.0 get outputted as 10 in queries created in JavaScript.\nHowever, the specification states that When expected as an input type, both integer and float input values are accepted. Integer input values are coerced to Float by adding an empty fractional part, for example 1.0 for the integer input value 1., which the code doesn't currently adhere to. The easiest fix is probably modifying this to check If the type is and casting its value to float.\n. Thanks @andimarek!\n. Sorry, serialization is not the correct word, but coercion.\nEg. when doing the following query:\nquery Stops {\n    stops(first: 1) {\n        edges {\n            cursor node {\n                stop {\n                    id\n                }\n            }\n        }\n    }\n}\nI get the following response:\n{\n    \"stops\": {\n        \"edges\": [{\n            \"cursor\": \"ConnectionCursor{value='c2ltcGxlLWN1cnNvcjA='}\",\n            \"node\": {\n                \"stop\": {\n                    \"id\": \"U3RvcDphZ2VuY3k6ZW50cmFuY2VfYg==\"\n                }\n            }\n        }]\n    }\n}\nInstead of the correct one:\n{\n    \"stops\": {\n        \"edges\": [{\n            \"cursor\": \"c2ltcGxlLWN1cnNvcjA=\",\n            \"node\": {\n                \"stop\": {\n                    \"id\": \"U3RvcDphZ2VuY3k6ZW50cmFuY2VfYg==\"\n                }\n            }\n        }]\n    }\n}\nThis is due to this executing this code instead of this\n. According to the specification it could be a custom scalar type, so we could just make ConnectionCursor extend GraphQLScalarType.\n. Thanks, works perfectly now\n. We implemented this as a new ExecutionStrategy. Java provides a nice ExecutorService#invokeAll method allowing us to limit the execution times of the futures. This approach is quite similar to the existing ExecutorServiceExecutionStrategy. Would you be willing to accept a PR that refactors the current implementation to use the (non-time-limited version of) invokeAll instead of starting the execution of the futures individually, so that we could even offer the time limited version in the default ExecutorServiceExecutionStrategy?\n. ",
    "skwakman": "ah crap, I'm wrong about the graphQL javascript library supporting .resolve() on type level. Like the java counterpart, we need to create a root-level type to implement this.\nStill though, it might be a handy addition?\n. I was thinking of being able to define a datafetcher at the type level. \nUsing the current API, setting a datafetcher would look like this:\n```\n GraphQLObjectType shoe = newObject()\n      .name(\"Shoe\")\n      .fields(Lists.newArrayList(\n        newFieldDefinition()\n          .name(\"id\")\n          .type(new GraphQLNonNull(GraphQLString))\n          .build()\n      )).build();\nGraphQLObjectType rootQuery = newObject()\n      .name(\"root\")\n      .field(newFieldDefinition()\n          .name(shoe.getName())\n          .type(shoe)\n          .dataFetcher(shoeFetcher)\n          .build()\n      ).build();\n```\nIn this example I have a service somewhere which can retrieve shoes. Defining how to fetch this shoe, requires me to add this to the query object as part of a field. \nHowever it might be handy if I can do this from within the Shoe type, for example:\nGraphQLObjectType shoe = newObject()\n      .name(\"Shoe\")\n      .fields(Lists.newArrayList(\n        newFieldDefinition()\n          .name(\"id\")\n          .type(new GraphQLNonNull(GraphQLString))\n          .build()\n      ))\n     .dataFetcher(shoeFetcher)\n     .build();\nOne advantage of this that I can define how shoes are retrieved at one place, even if the type is used in more than one query object. \nMy first post was created in the false assumption that the Javascript library supports this as well, but it doesn't. It's not much of a problem really, as using field level datafetchers it's still possible to create the same end-result. \nSo mainly a brain-barf on my side. Perhaps it's even better to keep feature-parity with the reference implementation to avoid any confusion.\n. ",
    "testower": "I believe what you are referring to is the \"resolve\" on fields on types. Any field can have a resolve or dataFetcher on it, in both the javascript reference implementation and in this particular java implementation. Whether that dataFetcher is on a field directly on the GraphQLObject given to the schema builder, or a sub-type, doesn't make a difference. It's still given on a field, not on a type.\n. Brilliant! Thanks didn't notice that one.\n. ",
    "pli2014": "hi andimarek\nwhen I integrated your code, I got a performance issue. for example, I searched a list data from server, which every snippet data need to be fetched again. \n{\n searchNewsList(status:0){\n  data:{\n       titile\n      userId\n      userFace\n   }\n}\n}\nuserFace field was mapping by userFaceDataFetcher.\nso userFace value need to be fetched again.  this is a N+1 issue.\nEven though you designed a concurrent strategy for data fetching, I wanted a batch strategy, how does it work?\n. got it, it is very useful, I had integrated it in our product. breadth-first search or depth-first search, which do you like? \nBTW, I change your code to implement another feature that pass parent data to variable, I think it should be a common feature. \nFor Example as below:\n```\nquery user {\n    userList{\n       name\n       userId\n       friends(userId:$userId){\n         name\n       }\n    }\n}\n```\ngenerally, parent userId should be passed to friends selectionset, because userList data source is search result,and \nfriends data source is another data fetching, but this variable depended $userId variable individually.\n. @andimarek \ngood job,  I have integrated this feature, it is very nice for me. expecting advance features.\n. if queryMyFriends function and profile are independent, I think it is necessary to implement this feature. recently, I completed this feature, so I raised this issue to you guys.\nIn my opinion, I mapped function calling to method of Java based code in my product, which brought many benefits for me, my target is implement Multidimensional Data Aggregation.  In my product, different data service need to be aggregated by Graphql. So I encountered this context-based passing variable.\n. yes,  I think graphql is lack of some function capacity with JavaScript,  because we want to unify all data process(e.g. JS) in graphql. function + DSL = graphql which is suitable for querying data and processing data.\nfrom async datafetcher, we need to async completable result for next reference of node. . ",
    "yrashk": "@pli2014 @andimarek \nConsidering #49 is in, can we close this issue?\n. @mmjd was your original issue resolved (i.e. can this ticket be closed)?\n. Considering that not all the javadoc is done yet, can we split this issue to specific issues that cover specific missing javadoc coverage?\n. It looks like #85 is somewhat related to this PR, unless I am missing something?\n. I think I ran into a similar case with fragments (PossibleFragmentSpreads), particularly this https://github.com/andimarek/graphql-java/blob/master/src/main/java/graphql/validation/rules/PossibleFragmentSpreads.java#L76 makes use of reference equality.\n.  @andimarek @alexkrebiehl @danielkwinsor\nI want to discuss this issue. I believe it is important to make GraphQL type information equality testing deep as I can't see where reference equality testing is more useful (prove me wrong?).\nWould it be sufficient to limit deep equality to names (as the names can't clash) or should we do full deep equality? For a quick fix, name equality works. What do you think?\n. Andreas, totally agree that this is simpler. However, I have a case where\nit is actually the opposite. In graphql-java-annotations I don't know all\nof the upcoming schema ahead of the time (it's being processed piece by\npiece, particularly important for dynamic schema composition I do with\nOSGi) and it's becoming a non-trivial problem, so right now my workaround\nis to subclass graphql classes to implement deeper type checks to avoid\nchecking by reference. I am not sure what would we lose if we were to ditch\nreference equality in favour of deeper equality, any thoughts?\nAlso, if you were to do the deeper equality check, how would you answer the\nquestion in my previous comment?\nOn Fri, May 6, 2016 at 12:47 AM, Andreas Marek notifications@github.com\nwrote:\n\nThe graphql schema was designed to be based on the principle that for each\ntype there is exactly one Java Instance representing this type. That's the\nreason the ckecks are using reference equality. This is just simpler.\nOf course we could change that, but I am not sure about the overall\nconsequences.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/85#issuecomment-217361404\n\n\nY.\n. Can you give me an idea of a potential side-effect or a bug? I understand your motivations, but I'd rather avoid defensive programming if you know what I mean.\nWe have to lay it out like that: if you do end up having multiple types with the same name, one of the variations of it will ultimately win during schema composition, correct? What if we specify and document how the winner is chosen?\n. If two instances are used for different purposes yet bear the same name, should it matter, though?\n. Since different DataFetcher wouldn't modify the interface, though should not be considered different types. All that matters (IMO) is the shape of the interface. \nThe reason why I suggested using just the name as an equality test is simply because we can't have multiple types with the same name. That said, verifying the structure (fields and field types) is also a reasonable approach.\n. I am fine with deeper equality (shape testing for the sake of catching weird issues), but I think we should adhere to one type one name principle. In graphql-java-annotation I solve this by having @GraphQLName annotation that can override type names.\nIn your case, my suggestion would be to generate different names for classes with the same name in different packages. That seems to be a better approach in terms of spec adherence. Thoughts?\n. Nothing is stopping them to do so. What we can do is to refuse adding two\nunequal types with the same name to the schema, proactively, so this type\nof mistake can be caught early.\nOn Friday, 6 May 2016, danielkwinsor notifications@github.com wrote:\n\nIn terms of my graphql-java-type-generator, it stores types with key ==\ntype name, so there cannot be duplicate GraphQL types. Further, the default\ntype name is the FQN with underscores, also with the ability to override\nthe name. (But actually I did realize something I could do better).\nSo actually I am thinking in the more general case. What is to stop a user\nfrom hand coding 2 AccountTypes, which then may or may not be equal if we\nmake an equality change?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/85#issuecomment-217508577\n\n\nY.\n. According to that spec, there could be nothing but an in integer as an input for Int. GSON doesn't make a best guess about number's type. \nWe can either handle this by coercing numbers to ints (as per this PR) or we can stipulate that whatever deserialization algorithm is used, it needs to return ints as ints. GSON with custom a type adaptor might be a solution for this (http://stackoverflow.com/questions/15507997/how-to-prevent-gson-from-expressing-integers-as-floats, http://stackoverflow.com/questions/24926786/make-gson-deserialize-numbers-to-integers-or-doubles, etc.)\nThis is all about where do we set the validation boundary.\n. I'd love to see those scalars in. If not in the core library, then in a compendium one\n. @andimarek the way I see the code I referenced above, the resolution only goes one level deep and stops there.\n. It looks like we have three independent cases where we experience unresolved type references. Not sure what's the ultimate cause, but I'll try to put more effort in figuring it out.\n. @dminkovsky yes, looks like the issue was resolved: https://github.com/graphql-java/graphql-java-annotations/commit/42ee9db7fd22b3106d9887d6b594ab299f9a00d5\n. 1. What would be the best and shortest way to model a test case here? \n2. If we address #85 (switch from reference to deep equality), would that help? According to the last comment by @alexkrebiehl on #118, there's an issue with multiple instances of what's effectively one type.\n. I would like to bump this issue up. I think the concern behind it is quite important.\n. Guys, any objections to merging this PR? It looks like the problem addressed here keeps popping up in different projects and this PR fixes it.\n. I think this would be a very valuable addition as it helps figuring out what went wrong with the design of the schema much faster than reading a JSON representation of the introspection query result.\n. From the looks of it, it seems that this patch is indeed addressing an implementation bug. Just wondering what was the reasoning that you used to convince ourself this wasn't a bug before, if you can remember?  Just want to make sure we're not missing something else here.\n. Thanks! This clearly makes graphql-java conform to that piece of the specification, so it should be in. Merged.\n. I am one of the recently added co-maintainers in the project. Even though my current usage of GraphQL has subsided, I am expecting this to change (meaning I am anticipating being able to provide a bit more time to the project at a later point). I am also trying to provide reasonable maintenance for https://github.com/graphql-java/graphql-java-annotations at this time.\n\nPersonally, I think establishing and nurturing an optimistic merging strategy might be a solution for this project. In my projects, I use C4 that was developed in the ZeroMQ project. I wrote a bit about this at https://blog.eventsourcing.com/productive-welcoming-vs-code-of-conduct-656b1571ddd6#.19ww1t2km but @hintjens explained the ideas behind it a lot better in his talk https://www.youtube.com/watch?v=uzxcILudFWM\n. ",
    "pasviegas": "The javascript version also converts null numbers to 0.\nThe specification does not say it clearly, but \"when possible\" would also hold for null as primitive/js int null is 0.\nGraphQL servers should coerce non\u2010int raw values to Int when possible otherwise they must raise a field error. Examples of this may include returning 1 for the floating\u2010point number 1.0, or 2 for the string \"2\".\nThis also affects floats as ints should be converted to floats.\n. This is what you want\n``` java\npublic class UpdateSchema {\nprivate static final ObjectMapper MAPPER = new ObjectMapper();\n  private static final String INTROSPECTION_QUERY = \"  query IntrospectionQuery {\\n    __schema {\\n      queryType { name }\\n      mutationType { name }\\n      types {\\n        ...FullType\\n      }\\n      directives {\\n        name\\n        description\\n        args {\\n          ...InputValue\\n        }\\n        onOperation\\n        onFragment\\n        onField\\n      }\\n    }\\n  }\\n\\n  fragment FullType on __Type {\\n    kind\\n    name\\n    description\\n    fields {\\n      name\\n      description\\n      args {\\n        ...InputValue\\n      }\\n      type {\\n        ...TypeRef\\n      }\\n      isDeprecated\\n      deprecationReason\\n    }\\n    inputFields {\\n      ...InputValue\\n    }\\n    interfaces {\\n      ...TypeRef\\n    }\\n    enumValues {\\n      name\\n      description\\n      isDeprecated\\n      deprecationReason\\n    }\\n    possibleTypes {\\n      ...TypeRef\\n    }\\n  }\\n\\n  fragment InputValue on __InputValue {\\n    name\\n    description\\n    type { ...TypeRef }\\n    defaultValue\\n  }\\n\\n  fragment TypeRef on __Type {\\n    kind\\n    name\\n    ofType {\\n      kind\\n      name\\n      ofType {\\n        kind\\n        name\\n        ofType {\\n          kind\\n          name\\n        }\\n      }\\n    }\\n  }\\n\";\n  private static final GraphQL GRAPHQL = new GraphQL(SchemaDefinition.schema);\npublic static void main(String[] args) throws IOException, URISyntaxException {\n    MAPPER.enable(SerializationFeature.INDENT_OUTPUT);\n    Files.write(jsonSchema(), jsonSchemaFile(), Charsets.UTF_8);\n  }\nprivate static String jsonSchema() throws JsonProcessingException {\n    return MAPPER.writeValueAsString(executeQuery());\n  }\nprivate static ExecutionResult executeQuery() {\n    return GRAPHQL.execute(INTROSPECTION_QUERY);\n  }\n}\n``\n. So, this is actually from my codebase,SchemaDefinition.schemais just where the schema lives andjsonSchemaFile()` returns the path to the json file I want to write too.\nBasically INTROSPECTION_QUERY is a copy from graphql.js, seems to me that the problem is in the differences this port has from handling nulls from the js one.\nI have tested with my schema removing the mutations and also getting the same issue.\n. ",
    "mmjd": "Hi, thank you for instant response. your question about schema informed me about the type I had been set to id (String) and changing that type to Integer solved my problem.\nthank you.\n. I noted that 'if' argument must be added to each field that may use include directive.\n. thanks Andi, but we have the following example in graphql specification draft:\n{\n  user(id: 4) {\n    id\n    name\n    profilePic(width: 100, height: 50)\n  }\n}\nsuppose that profilePic part is defined as fragment inside a relay container and has merged into the above query for fetching. how can I find user and its profile picture from database in user datafetcher while I have only access to profilePic arguments in its own dataFetcher? do I have to move profile picture arguments to user?\nRegards,\n. ",
    "danielkwinsor": "Would you accept pull requests of javadoc that others write?  I might want to write some javadoc myself, to aid my learning and perhaps any developers using this.\n. I won't add author fields.  How about version?\nWhen I develop something, I want to use my IDE to use context-assist and to read the javadoc, thereby figuring out from the API what is possible.  That workflow doesn't work here, instead I go to the Readme.md and to tests.\nOne feedback I have is that, for a given feature, it can be hard to look for example usage in the tests when the schema and groovy test are split among differently named files.  I do understand the background here of Garfield and Star Wars, I'm just saying.\nThe readme.md does a decent job, and is probably up-to-date except for missing 2 scalar types.  But to dive deep into the things that DataFetchingEnvironment provides, and what env.getSource means and how that is different from env.getParentType and what happens when I call env.getArgument on something that doesn't exist... all those things I have to now dive into the code for.\nLet me put it a different way.  Everyone knows what an Enum and an Interface is, no matter what language, and you just have to learn the syntax.  In GraphQL it should be straightforward to write unit tests around my code using these constructs, but in graphql-java I cannot find these things and I find myself reverse engineering this from readme, tests, and code, which is a very slow process.\n. @andimarek Yes, I would like to help with that, as I get free time myself.\n. Well great, you made me read the appendices of the spec, something I avoided until now, lol.\nYes, the spec is pretty clear in that practically anything can be a name.  Given the stated goal of keeping it simple I think they wouldn't care if keywords were used, but at the same time I'm not sure whether this was intentional or not.  I'll ask.\n. Also, there are a lots of line changes with either name changes or removing @NotNull.  Is it possible to create a patch that avoids this?  There is a conflict anyways.\n. I ran into this; I accidentally named a field called \"query\".  Problem was, graphiql was the thing complaining about a parse error, not graphql-java.  So unless most tools/libraries have this support, it may be premature to put this in?\n. Right, given the concern that TypeReferences might be handled in a special way, can you provide in your PR some unit tests demonstrating that nothing breaks and that input refs cannot mix with output refs?\n. I am interested in generating schema from .classes too.  I might even have bandwidth to help with contributing or helping clean up buma's reflection code for release.   For me, this is going to be a must have feature.\n. Hi guys,\nI have uploaded graphql-java-type-generator which currents operates on a .class basis, but the structure is such that I'll be designing a config based approach, and can fit in a .java approach as well.\nI appreciate your feedback.\n. Do you have a test case?  I ask because I'd also like to see this test with your type being [String] and [String!]\nAccording to the coercion rules, we'll attempt to coerce null to type, where type here happens to be List of String.  Check out http://facebook.github.io/graphql/#sec-List-Value\nAlso, this section on List Input Coercion puts it better than I can.\n\nIf the value passed as an input to a list type is not a list, it should be coerced as though the input was a list of size one, where the value passed is the only item in the list. This is to allow inputs that accept a \u201cvar args\u201d to declare their input type as a list; if only one argument is passed (a common case), the client can just pass that value rather than constructing the list.\n\nSo we are conforming to spec by providing a list of size 1, with null as the only element.  I fully admit that it doesn't seem the most obvious, from a java dev's point of view.  But there's an RFC on Null Values https://github.com/facebook/graphql/pull/83 that might change things, so let me consider and perhaps make some suggestions.\n. My position is somewhere between the 2.  I always refactor my own code, and I'll go so far as to reformat other people's code too.  But in the specifics here, we have a merge conflict.  So could I ask this: create 2 PRs, 1 with the minimalist changes necessary to support your feature, and if that looks good, a second PR that does the refactor.\nThing is, at this time I'm not sure whether nameAndFieldName is suitable on GraphQLFieldDefinition.Builder.  I'd prefer to see something clearer like\n.name(\"foo\")\n.fieldToFetch(\"bar\")\ninstead of\n.nameAndFieldName(\"foo\", \"bar\")\nBut even this is getting hairy when considering PropertyDataFetcher and other non-default fetchers.  Field-name-to-fetch is really a property of the FieldDataFetcher only (and after a PR, PropertyDataFetcher too).\nIs there another way that you can make this change, or can you live with\n.name(\"foo\")\n.dataFetcher(new FieldDataFetcher(\"bar\")\n. Remember that in GraphQL arguments are unordered, but Lists are ordered.\nIn the query, your type {ids: [\"abc\"]} is an input object with 1 field named ids, and ids has type List of Strings.  Therefore it's both ordered and can contain duplicates.  Now, I can't see what GraphQLType your schema declares this GraphQLInputObjectField as, but it must be a GraphQLList(GraphQLString) to work with the given query.  Is this the schema type and it still fails to convert?  But if your schema is something else, converting a GraphQL List to a Java Set is not something graphql-java does.\n. In graphql-java-type-generator we will take a *.class and create an object using some generated name.  There are a few problems here, but one is that you can have multiple java classes with the same name in different class loaders.  I consider this to be a problem of g-j-t-g, but there are so many other examples that might not be.\nAuthorization: I'm going to do per field authorization using a fetcher that optionally returns null, but someone else might want to have 2 different AccountTypes, 1 for customer, another for customer service.  In that case, makes sense to resolve based upon a Type Dictionary given to the schema -- but this is not a full solution in edge cases like the Type Dictionary containing multiple types same name.\nLast, I am thinking about duck typing, and it sounds like a per-field-name check would allow for duck typing.  Suppose we recursively do a comparison and see that all fields of 2 AccountTypes are equal in name.  Then duck typing says they are equal.  But what if DataFetcher is vastly different... are these equivalent types or not?\n. Right, if we start worrying about DataFetcher equality we are in for a world of hurt.\nYour second statement is true in GraphQL, that GraphQL cannot have multiple types same name, but for java it is possible.  If java types have overlapping FQNs, but different structure, what should I name a GraphQLObjectType based upon those java types?  I would feel safer with a deep field name/type check, and then our 2 AccountTypes are either equal or not, but both are permitted to exist simultaneously.\n. To clarify the last statement, that would mean we are taking the approach that is potentially against http://facebook.github.io/graphql/#sec-Type-System if the 2 AccountType GraphQLObjectTypes fail the equality check.\nIf we did that, we'd need another layer of check that only allows for 1 type, like the Type Dictionary or something.\n. In terms of my graphql-java-type-generator, it stores types with key == type name, so there cannot be duplicate GraphQL types.  Further, the default type name is the FQN with underscores, also with the ability to override the name.  (But actually I did realize something I could do better).\nSo actually I am thinking in the more general case.  What is to stop a user from hand coding 2 AccountTypes, which then may or may not be equal if we make an equality change?\n. Andi,\nThat's not a problem.  I respect that useless doc is worse than no doc.  I cringed at some of the javadoc generated for constants in the lexer and parser, for instance, and a second pass by hand would remove those.  And for instance, it pisses me off to see commented out lines of code, and I delete those every chance I get, so I'm with you there.\nAnyways, I have gone through this myself and I feel like it was a very wrong idea to autogenerate method level javadoc.  I did not realize how bad it was.  \"@param value a {@link java.lang.Object} object.\"  Yeah, thanks, really helpful... now tell me WHY the API was Object instead of some more specific type... that's what should go in.\nWhat do you think of class level autogenerated javadoc only, with the version/author info?  I can either submit auto-class for all, or generate auto-class and submit PRs as classes get handcrafted.  I would be in favor of the first one.\nYes, I still intend to do method level javadoc, and will auto-gen it first for ease, but will submit only that which has been through a hand-crafted process.\n. Hey Fredrik,\nI think it'll be fine to add generics, but there's a conflict right now.  Can you redo this, but also break it up into multiple PRs?  One for Coercing, another for DataFetcher, and I'm not yet ready to merge in any changes to the build, which itself would still need to be another PR.\n. As everyone has said, top level mutations must be serial.  Are you observing that second level mutations are not using your custom execution strategy?  If your custom execution strategy is being used, we should close this.\n. Furthermore, line terminators are in a similar condition, but I'd be more careful about this.  I'm trying to think of scenarios where a line separator may be interpreted incorrectly and escape out of a comment or string then cause havoc with a ",
    "aschrijver": "@yrashk That is not needed, I think. This is a common library public API methods should have JavaDoc documentation. For most of these this will be very minimal, as it corresponds one-to-one to the GraphQL spec that people can RTFM. So one-liners like Gets the name of the field definition. would suffice.\nExamples where JavaDoc comments are vital are in the Object parameters of DataFetchingEnvironment and other locations where it is unclear which types you can expect in the parameter.\nI might have a stab at creating a PR for this, but I have to find the time as well. Will let you know beforehand.\nIf creating additional issues, a TravisCI task for generating Github Pages output and adding to gh-pages branch and that is reference from the README would be nice. I'll create that issue.\n. Maybe this project should get an official branch with Java 8 and async-all-the-way targeted for a future 3.0.0 release. And an additional roadmap document.\n. Yes, that's an issue. I am working with Vert.x, yet another way to go asynchronously. In Vert.x the fetchers should be async as well. I am looking into using the above async branch, but with a Vert.x implementation of CompletableFuture.\nMaybe the project could be improved to facilitate various extensions more easily (have a more defined SPI). Maybe support the most basic callback handler overloads (similar to described above).\nThen extension projects can build on top of it.\n(Talking about extension: IMO the Relay code should be pushed out to an extension as well. It's just one client library. I intend to switch to Apollo Client, and no special node/edge server schema needed)\n. Ha Fredrik, you sneakily put in a different versioning scheme convention under this PR title, I see :open_mouth: :wink: . \nWhile I am all agreeing to that, as its cleaner and more 'rememberable' we should really ask @andimarek for that, and also ideally make it a separate PR. There may be a valid reason for the current scheme, like e.g. continuous delivery support (I dunno, just guessing).\nEdit: And, ah, he is just there as well. We have a concurrent group session going on here :dancer: :smiley: \n. @dminkovsky Your gist would be best. The ObjectMapper approach would be opinionated, leading to a Jackson dependency, just one of the popular Json parsers around.\nWhile I am using Jackson myself in most of my projects, you would probably be forcing this on, say 50 to 60% (just guessing) of developers using other json libraries.\n(Only problem is its Java 8, now turn the rest into 8 as well :wink:)\n. I just reacted on @danielkwinsor code snippet which used Jackson ObjectMapper. Json has not much to do with it except Jackson started originally as a json library (can now handle many formats)\n. Yes, thanks. I created some code similar to graphql-js and would like to do a pull request.\nBut first I have to install a JDK 6 (Using Oracle JDK8 myself) and have Gradle use this one too.\nNote that in JDK 8 the code does NOT compile by default because the Javadoc in the antlr-generated classes contains empty <p/> tags which is no longer allowed. Leads to 100 errors right now.\nMaybe this can be changed in the code generation.\n. I created a separate issue for the javadoc part. See #134 \n. Issue can be closed. Introspection query is present in codebase.\n. That's a coincidence. I am using Gradle and was just working on something similar.\nNice project. I will star it anyway.\nI don't have a very clean gradle way. At build time I invoke tools jar that creates the schema.json\nLooking into aggregating multiple schema's into one (one schema per microservice).\nThe hacky way is to just aggregate the generated json's.\n. PS It might be helpful if the README included explanation on how the ANTLR classes where generated. AFAICS this is not part of the project now, or I've missed it.\n. Fixed with #141 .  Thanks!\nClosing.\n. You mean workaround = use JDK 7? Yes, I found that too. Sorry I didn't see #124 before.\nTo fix these issues IMHO the project should provide a bit more clarity:\n1. It should compile on the JDK it is compatible with \n   - And preferably on newer JDK's as well without modification\n   - If this is not the case the build requirements should be mentioned in the README\n2. There should be a clear choice on minimum compatibility\n   - Now it is JDK 6, but there is an open question about it on the forum\nOn 2. I prefer a JDK that is not end-of-life and lacks the new language features that have become the norm in modern Java development, but that's personal :).\n. Thanks!\n. HI @andimarek @danielkwinsor ,\nI tried #146 both with OpenJDK (1.6.0_38) and Oracle JDK (1.6.0_45) and compiles without problem. So together with #145 everything should work well, even with TravisCI, I guess.\nAh, I see there is still a docker-related Travis error:\nThe command \"docker run -it --rm --volumes-from java6-rt -v `pwd .`:/build -e JDK6_HOME=/usr/lib/jvm/java-6-openjdk-amd64 -e BINTRAY_USER=$BINTRAY_USER -e BINTRAY_API_KEY=$BINTRAY_API_KEY -w /build java:8 bash -c \"./gradlew assemble && ./gradlew check && ./gradlew bintrayUpload -x check --info\"\" exited with 1.\nThis should be only due to the bintray publishing not working. If I run the docker commands from #145 locally with Daniels' code, then everything is fine.\n. Yep. I agree. I am bit quiet these days...taking some time off the deck :wink:\n. Oh, I see I must add a couple of lines to be backwards-compatible. Will do that tomorrow morning.\n. I added a small size() check on the SchemaUtils.collectAllTypes() test, because the test output below put me on the wrong track when there was just a missing type check for DirectiveLocation:\n```\nCondition not satisfied:\ntypes == [(droidType.name)                 : droidType, (humanType.name)                 : humanType, (queryType.name)                 : queryType, (characterInterface.name)        : characterInterface, (episodeEnum.name)               : episodeEnum, (GraphQLString.name)             : GraphQLString, (Introspection.__Schema.name)    : Introspection.__Schema, (Introspection.__Type.name)      : Introspection.__Type, (Introspection.__TypeKind.name)  : Introspection.__TypeKind, (Introspection.__Field.name)     : Introspection.__Field, (Introspection.__InputValue.name): Introspection.__InputValue, (Introspection.__EnumValue.name) : Introspection.__EnumValue, (Introspection.__Directive.name) : Introspection.__Directive, (GraphQLBoolean.name)            : GraphQLBoolean]\n|     |    |         |                       |           |         |                       |           |         |                       |           |                  |              |                    |           |                     |             |             |                   |                             |        |                        |                        |      |                          |                      |          |                      |                          |       |                         |                       |            |                    |                            |           |                     |                           |           |                     |             |              |                  |\n|     false|         Droid                   |           |         Human                   |           |         QueryType               |           |                  Character      |                    |           Episode               |             |             String              |                             |        __Schema                 |                        |      __Type                     |                      |          __TypeKind             |                          |       __Field                   |                       |            __InputValue         |                            |           __EnumValue           |                           |           __Directive           |             |              Boolean            GraphQLScalarType{name='Boolean', description='Built-in Boolean', coercing=graphql.Scalars$5@522be8d4}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          |                                 |                       |                                 |                            |                                 |                           |                                 |             GraphQLScalarType{name='Boolean', description='Built-in Boolean', coercing=graphql.Scalars$5@522be8d4}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          |                                 |                       |                                 |                            |                                 |                           |                                 GraphQLObjectType{name='__Directive', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@455073ad, description=graphql.schema.GraphQLFieldDefinition@7dcf6c9b, locations=graphql.schema.GraphQLFieldDefinition@535040dd, args=graphql.schema.GraphQLFieldDefinition@71121e5e, onOperation=graphql.schema.GraphQLFieldDefinition@3799d6ca, onFragment=graphql.schema.GraphQLFieldDefinition@3134df16, onField=graphql.schema.GraphQLFieldDefinition@60333745}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          |                                 |                       |                                 |                            |                                 |                           GraphQLObjectType{name='__Directive', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@455073ad, description=graphql.schema.GraphQLFieldDefinition@7dcf6c9b, locations=graphql.schema.GraphQLFieldDefinition@535040dd, args=graphql.schema.GraphQLFieldDefinition@71121e5e, onOperation=graphql.schema.GraphQLFieldDefinition@3799d6ca, onFragment=graphql.schema.GraphQLFieldDefinition@3134df16, onField=graphql.schema.GraphQLFieldDefinition@60333745}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          |                                 |                       |                                 |                            |                                 GraphQLObjectType{name='__EnumValue', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@7ff54ede, description=graphql.schema.GraphQLFieldDefinition@2e22c0bc, isDeprecated=graphql.schema.GraphQLFieldDefinition@1de67aed, deprecationReason=graphql.schema.GraphQLFieldDefinition@10064ccd}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          |                                 |                       |                                 |                            GraphQLObjectType{name='__EnumValue', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@7ff54ede, description=graphql.schema.GraphQLFieldDefinition@2e22c0bc, isDeprecated=graphql.schema.GraphQLFieldDefinition@1de67aed, deprecationReason=graphql.schema.GraphQLFieldDefinition@10064ccd}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          |                                 |                       |                                 GraphQLObjectType{name='__InputValue', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@155fadaa, description=graphql.schema.GraphQLFieldDefinition@530fcf80, type=graphql.schema.GraphQLFieldDefinition@23fe5f1b, defaultValue=graphql.schema.GraphQLFieldDefinition@3a7130cd}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          |                                 |                       GraphQLObjectType{name='__InputValue', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@155fadaa, description=graphql.schema.GraphQLFieldDefinition@530fcf80, type=graphql.schema.GraphQLFieldDefinition@23fe5f1b, defaultValue=graphql.schema.GraphQLFieldDefinition@3a7130cd}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          |                                 GraphQLObjectType{name='__Field', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@20c98bc9, description=graphql.schema.GraphQLFieldDefinition@6de24fe1, args=graphql.schema.GraphQLFieldDefinition@719ae97, type=graphql.schema.GraphQLFieldDefinition@4ce15ee7, isDeprecated=graphql.schema.GraphQLFieldDefinition@201a0371, deprecationReason=graphql.schema.GraphQLFieldDefinition@5ff8ddd4}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 |                          GraphQLObjectType{name='__Field', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@20c98bc9, description=graphql.schema.GraphQLFieldDefinition@6de24fe1, args=graphql.schema.GraphQLFieldDefinition@719ae97, type=graphql.schema.GraphQLFieldDefinition@4ce15ee7, isDeprecated=graphql.schema.GraphQLFieldDefinition@201a0371, deprecationReason=graphql.schema.GraphQLFieldDefinition@5ff8ddd4}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      |                                 graphql.schema.GraphQLEnumType@25adc3d0\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 |                      graphql.schema.GraphQLEnumType@25adc3d0\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        |                                 GraphQLObjectType{name='__Type', description='null', fieldDefinitionsByName={kind=graphql.schema.GraphQLFieldDefinition@44ea3a35, name=graphql.schema.GraphQLFieldDefinition@1f38641e, description=graphql.schema.GraphQLFieldDefinition@40b2e543, fields=graphql.schema.GraphQLFieldDefinition@726860c7, interfaces=graphql.schema.GraphQLFieldDefinition@67c6d72d, possibleTypes=graphql.schema.GraphQLFieldDefinition@3b02575f, enumValues=graphql.schema.GraphQLFieldDefinition@6c4d2581, inputFields=graphql.schema.GraphQLFieldDefinition@5d921e97, ofType=graphql.schema.GraphQLFieldDefinition@cbcc5b7}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 |                        GraphQLObjectType{name='__Type', description='null', fieldDefinitionsByName={kind=graphql.schema.GraphQLFieldDefinition@44ea3a35, name=graphql.schema.GraphQLFieldDefinition@1f38641e, description=graphql.schema.GraphQLFieldDefinition@40b2e543, fields=graphql.schema.GraphQLFieldDefinition@726860c7, interfaces=graphql.schema.GraphQLFieldDefinition@67c6d72d, possibleTypes=graphql.schema.GraphQLFieldDefinition@3b02575f, enumValues=graphql.schema.GraphQLFieldDefinition@6c4d2581, inputFields=graphql.schema.GraphQLFieldDefinition@5d921e97, ofType=graphql.schema.GraphQLFieldDefinition@cbcc5b7}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             |                                 GraphQLObjectType{name='__Schema', description='A GraphQL Introspection defines the capabilities of a GraphQL server. It exposes all available types and directives on the server, the entry points for query, mutation, and subscription operations.', fieldDefinitionsByName={types=graphql.schema.GraphQLFieldDefinition@51aef433, queryType=graphql.schema.GraphQLFieldDefinition@efc5f25, mutationType=graphql.schema.GraphQLFieldDefinition@6f3687f9, directives=graphql.schema.GraphQLFieldDefinition@e2a3fed, subscriptionType=graphql.schema.GraphQLFieldDefinition@28835d77}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 |                             GraphQLObjectType{name='__Schema', description='A GraphQL Introspection defines the capabilities of a GraphQL server. It exposes all available types and directives on the server, the entry points for query, mutation, and subscription operations.', fieldDefinitionsByName={types=graphql.schema.GraphQLFieldDefinition@51aef433, queryType=graphql.schema.GraphQLFieldDefinition@efc5f25, mutationType=graphql.schema.GraphQLFieldDefinition@6f3687f9, directives=graphql.schema.GraphQLFieldDefinition@e2a3fed, subscriptionType=graphql.schema.GraphQLFieldDefinition@28835d77}, interfaces=[]}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             |                                 GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$4@5c42d31f}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 |             GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$4@5c42d31f}\n|          |                                 |           |                                 |           |                                 |           |                                 |                    |                                 graphql.schema.GraphQLEnumType@12e53831\n|          |                                 |           |                                 |           |                                 |           |                                 |                    graphql.schema.GraphQLEnumType@12e53831\n|          |                                 |           |                                 |           |                                 |           |                                 GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}\n|          |                                 |           |                                 |           |                                 |           GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}\n|          |                                 |           |                                 |           |                                 GraphQLObjectType{name='QueryType', description='null', fieldDefinitionsByName={hero=graphql.schema.GraphQLFieldDefinition@1a31ff49, human=graphql.schema.GraphQLFieldDefinition@50e26945, droid=graphql.schema.GraphQLFieldDefinition@3e99311c}, interfaces=[]}\n|          |                                 |           |                                 |           GraphQLObjectType{name='QueryType', description='null', fieldDefinitionsByName={hero=graphql.schema.GraphQLFieldDefinition@1a31ff49, human=graphql.schema.GraphQLFieldDefinition@50e26945, droid=graphql.schema.GraphQLFieldDefinition@3e99311c}, interfaces=[]}\n|          |                                 |           |                                 GraphQLObjectType{name='Human', description='A humanoid creature in the Star Wars universe.', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1dae367b, name=graphql.schema.GraphQLFieldDefinition@3529f5d7, friends=graphql.schema.GraphQLFieldDefinition@7f390246, appearsIn=graphql.schema.GraphQLFieldDefinition@44268920, homePlanet=graphql.schema.GraphQLFieldDefinition@28576231}, interfaces=[GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}]}\n|          |                                 |           GraphQLObjectType{name='Human', description='A humanoid creature in the Star Wars universe.', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1dae367b, name=graphql.schema.GraphQLFieldDefinition@3529f5d7, friends=graphql.schema.GraphQLFieldDefinition@7f390246, appearsIn=graphql.schema.GraphQLFieldDefinition@44268920, homePlanet=graphql.schema.GraphQLFieldDefinition@28576231}, interfaces=[GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}]}\n|          |                                 GraphQLObjectType{name='Droid', description='A mechanical creature in the Star Wars universe.', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@52aabda1, name=graphql.schema.GraphQLFieldDefinition@65b6be80, friends=graphql.schema.GraphQLFieldDefinition@1529449f, appearsIn=graphql.schema.GraphQLFieldDefinition@67ceae1, primaryFunction=graphql.schema.GraphQLFieldDefinition@1bc183a}, interfaces=[GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}]}\n|          GraphQLObjectType{name='Droid', description='A mechanical creature in the Star Wars universe.', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@52aabda1, name=graphql.schema.GraphQLFieldDefinition@65b6be80, friends=graphql.schema.GraphQLFieldDefinition@1529449f, appearsIn=graphql.schema.GraphQLFieldDefinition@67ceae1, primaryFunction=graphql.schema.GraphQLFieldDefinition@1bc183a}, interfaces=[GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}]}\n[QueryType:GraphQLObjectType{name='QueryType', description='null', fieldDefinitionsByName={hero=graphql.schema.GraphQLFieldDefinition@1a31ff49, human=graphql.schema.GraphQLFieldDefinition@50e26945, droid=graphql.schema.GraphQLFieldDefinition@3e99311c}, interfaces=[]}, Character:GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}, String:GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$4@5c42d31f}, Episode:graphql.schema.GraphQLEnumType@12e53831, Human:GraphQLObjectType{name='Human', description='A humanoid creature in the Star Wars universe.', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1dae367b, name=graphql.schema.GraphQLFieldDefinition@3529f5d7, friends=graphql.schema.GraphQLFieldDefinition@7f390246, appearsIn=graphql.schema.GraphQLFieldDefinition@44268920, homePlanet=graphql.schema.GraphQLFieldDefinition@28576231}, interfaces=[GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}]}, Droid:GraphQLObjectType{name='Droid', description='A mechanical creature in the Star Wars universe.', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@52aabda1, name=graphql.schema.GraphQLFieldDefinition@65b6be80, friends=graphql.schema.GraphQLFieldDefinition@1529449f, appearsIn=graphql.schema.GraphQLFieldDefinition@67ceae1, primaryFunction=graphql.schema.GraphQLFieldDefinition@1bc183a}, interfaces=[GraphQLInterfaceType{name='Character', description='A character in the Star Wars Trilogy', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@1bd5f67e, name=graphql.schema.GraphQLFieldDefinition@e0b89fa, friends=graphql.schema.GraphQLFieldDefinition@4d60613f, appearsIn=graphql.schema.GraphQLFieldDefinition@3a86b85e}, typeResolver=graphql.StarWarsData$3@e54df76}]}, __Schema:GraphQLObjectType{name='__Schema', description='A GraphQL Introspection defines the capabilities of a GraphQL server. It exposes all available types and directives on the server, the entry points for query, mutation, and subscription operations.', fieldDefinitionsByName={types=graphql.schema.GraphQLFieldDefinition@51aef433, queryType=graphql.schema.GraphQLFieldDefinition@efc5f25, mutationType=graphql.schema.GraphQLFieldDefinition@6f3687f9, directives=graphql.schema.GraphQLFieldDefinition@e2a3fed, subscriptionType=graphql.schema.GraphQLFieldDefinition@28835d77}, interfaces=[]}, __Type:GraphQLObjectType{name='__Type', description='null', fieldDefinitionsByName={kind=graphql.schema.GraphQLFieldDefinition@44ea3a35, name=graphql.schema.GraphQLFieldDefinition@1f38641e, description=graphql.schema.GraphQLFieldDefinition@40b2e543, fields=graphql.schema.GraphQLFieldDefinition@726860c7, interfaces=graphql.schema.GraphQLFieldDefinition@67c6d72d, possibleTypes=graphql.schema.GraphQLFieldDefinition@3b02575f, enumValues=graphql.schema.GraphQLFieldDefinition@6c4d2581, inputFields=graphql.schema.GraphQLFieldDefinition@5d921e97, ofType=graphql.schema.GraphQLFieldDefinition@cbcc5b7}, interfaces=[]}, __TypeKind:graphql.schema.GraphQLEnumType@25adc3d0, __Field:GraphQLObjectType{name='__Field', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@20c98bc9, description=graphql.schema.GraphQLFieldDefinition@6de24fe1, args=graphql.schema.GraphQLFieldDefinition@719ae97, type=graphql.schema.GraphQLFieldDefinition@4ce15ee7, isDeprecated=graphql.schema.GraphQLFieldDefinition@201a0371, deprecationReason=graphql.schema.GraphQLFieldDefinition@5ff8ddd4}, interfaces=[]}, __InputValue:GraphQLObjectType{name='__InputValue', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@155fadaa, description=graphql.schema.GraphQLFieldDefinition@530fcf80, type=graphql.schema.GraphQLFieldDefinition@23fe5f1b, defaultValue=graphql.schema.GraphQLFieldDefinition@3a7130cd}, interfaces=[]}, Boolean:GraphQLScalarType{name='Boolean', description='Built-in Boolean', coercing=graphql.Scalars$5@522be8d4}, __EnumValue:GraphQLObjectType{name='__EnumValue', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@7ff54ede, description=graphql.schema.GraphQLFieldDefinition@2e22c0bc, isDeprecated=graphql.schema.GraphQLFieldDefinition@1de67aed, deprecationReason=graphql.schema.GraphQLFieldDefinition@10064ccd}, interfaces=[]}, __Directive:GraphQLObjectType{name='__Directive', description='null', fieldDefinitionsByName={name=graphql.schema.GraphQLFieldDefinition@455073ad, description=graphql.schema.GraphQLFieldDefinition@7dcf6c9b, locations=graphql.schema.GraphQLFieldDefinition@535040dd, args=graphql.schema.GraphQLFieldDefinition@71121e5e, onOperation=graphql.schema.GraphQLFieldDefinition@3799d6ca, onFragment=graphql.schema.GraphQLFieldDefinition@3134df16, onField=graphql.schema.GraphQLFieldDefinition@60333745}, interfaces=[]}, __DirectiveLocation:graphql.schema.GraphQLEnumType@1b225f3]\nat graphql.schema.SchemaUtilTest.collectAllTypes(SchemaUtilTest.groovy:16)\n\n``\n. I'll PR this one, thanks!\n. I had the same question and agree compatibility should be mentioned. I have created a PR for introspection that complies with0.5.0. Have a look at #132 , #136 and #138  \n. Since #144 is now done, spec should mostly comply to0.5.0`. If you find points where it is not, then best file separate issues for them.\n. Yeah that is fine. There are not that many changes to be made.\nShall I remove the text on Java and keep the mention on spec compliance?\n. PS I would also move the Code of Conduct down on the page. Focus on install and build info first (and how many trolls are there on github, really?)\n. Yes, I saw. Great! That's why I removed the text on JDK 7. See https://github.com/graphql-java/graphql-java/pull/143/commits/8b15936768e3fab09e194492b884424f96f67e70\n. #148 merged. Closing\n. Would be nice. Why did you only add this for the 3 builders and not all? \nBTW Without the accolades and return statement the example looks a bit cleaner. You would use it like this:\njava\n        GraphQLObjectType.newObject()\n                .field(field -> field\n                        .name(\"name\")\n                        .description(\"description\")\n                        .argument(argument -> argument\n                                .name(\"arg\")\n                                .defaultValue(\"val\"))\n                        .deprecate(\"deprecated\"))\n                .field(field -> field\n                        .name(\"name2\"));\n. I was thinking like for example GraphQLInterfaceType with fieldDefinitions, GraphQLUnionType with types and anywhere you can construct a list of nested graphql schema objects that have their own builder.\n. Yes, this is probably enough. :+1: \n. It doesn't matter if project is still Java 6. As long as it uses interfaces with a single method its okay. They  are identical to @FuntionalInterface but without the annotation (its just a marker) and can be used in lambda's.\nOn your second point: Could you clarify? The build() is needed to start constructing after fluently setting 'constructor parameters' for the instance. Is the newFieldDefinition populated with defaults\nEdit: your edit of code crossed my comment. Still some more background would be nice \n. Yes, that is correct.\nOn the Java 6 there is an old issue discussing it, and some people wanted 6 because that's what they are stuck with at their company (probably a bank or something).\nPersonally I am strongly in favour of Java 8. Its not 2007 anymore, that's stone age stuff in IT terms. 6 is no longer supported, 7 as well, and graphql-java misses out on opportunities to make a nice reactive API, use functional programming concepts, etc. Risks making itself irrelevant in the long run.\nI'd say to any Java 6 guy 'You have a nice round 2.0 release now, and there will be a 2.1 as a bonus, but then you'll have to upgrade your mainframe to get a 3.x :wink:'\n. @IamCornholio when talking on Java 8 goodness, I do not mean the odd functional interface, but using Function, Consumer, Supplier, Future and the like. But also ability to use with other Java 8 libraries, like RxJava, reactive streams, etc.\nA nice example of a Java 8 library that I recently found is JavaSlang. See http://www.javaslang.io/javaslang-docs/ It applies Java 8 to a much larger extend to create powerful new API's.\n. On Java 8 I would like to add that Java has lost many, many followers to other (arguably more sexy) language implementations already, because of its slow development.\nI looked at the upcoming features in Java 9 and was greatly underwhelmed (once again).\nI think using a modern Java version is essential to stay relevant in the long run.\n. Just curious, but why did @IamCornholio need to merge into single commit? For atomicity?\nIf you want that as a convention, it should be documented, because the rebasing/merging is tedious work for any contributor (unless they are real Git fanatics).\n. Ha ha ha, I understand. I am also a bit of a fanatic sometimes, I must admit :+1: \n. It could also have an additional clause with a search for any property that contains propertyName, and return the first match. This way you will catch any reasonable naming convention (only not the completely unrelated names).\n(BTW Many new codes do not use is and get prefixes any more, but what fits with the domain language and fluent coding e.g. shouldUpdateAccount, succeeded, canSubtractValue, etc.)\n. How do you think about earlier suggestion to allow any kind of prefix or postfix https://github.com/graphql-java/graphql-java/pull/164#issuecomment-241156317 ?\nI know classes with conventions like can, should, with, on, after, etc.\n. Yet another option, and easily added is a public overload that takes the prefix.\n. Yes, I agree, you are right with the search. It would be too much of a burden on the developer to get it right, and don't forget when adding a similarly-named member in future.\nPassing a prefix parameter could be solution.\nOn a different note, related but not the same, I have a need to be able to define field aliases. I am discussing that on the metadata-related issues I created earlier.\n. Yeah, that's no problem. Let's close this one. Given how busy I am it will be some time before I revisit this, maybe then I'll come up with a more elegant PR for other prefixes. We'll see..\n. @dminkovsky Hailing from Russia or Ukrain? Then you are making even more late-nighters than me :wink: \n. Lucky you, ha ha. I should be horizontal now at 04:00PM on the clock, not in S shape over laptop :grin:\n. Hi @kristofdepypere !\nI just created an initial version of vertx-dataloader (and https://github.com/facebook/dataloader/issues/36), a Java port of Facebook DataLoader that can be used with GraphQL to batch and cache queries (will make separate announce issue later).\nIt is based on vertx-core, but only using Future<V> and CompositeFuture from there. This would make the validation only occur once.\nI am intending to use the data loader in another project I am creating, namely vertx-graphql-service-proxy which creates a client-side proxy of a GraphQL Schema and then delegates all calls to type resolvers and data fetchers to a back-end microservice in asynchronous fashion, which could speed up query execution.\nYou are obviously way ahead in applying GraphQL. I am interested in your experiences and the hurdles you are now facing.\nBTW the profiling screenshot....did you do it with plain IntelliJ, or some other tool?\n. Nice to hear you are using it large scale and in production. Such experiences when shared are really useful to boost GraphQL (Java) and bring new people in the community. Something you may consider blogging about.. Thanks!\nI will probably also extend the open source projects into React/Relay realms in future, because that's what I am using myself also. The projects I referenced are still quit minimal, but I can see some interesting features on the horizon. Also I have created vertx-graphql-service-discovery to further usefulness of GraphQL in a Microservices architecture based on Vert.x.\n. Hi @yrashk ,\nThank you for your explanation. I wasn't aware there were more than one maintainer. Github doesn't show this anywhere (or I've missed it), so it might be good to mention in the README.\nI fully agree with you on the code of conduct and already remarked on it in PR #143. I think it is more off-putting than inviting, and the unacceptable behaviours described I have seen nowhere on Github yet. Would be more fitting to have on Facebook maybe...\nThe C4 spec and guidelines look very interesting and could give a good boost to the project, when implemented. If applying it I think a short, comprehensive bullet list with the procedure would be a good idea, and maybe a wiki page that provides some more background.\nOn the licensing aspect I am not an expert (par. 2.2.1). I know that real active community contributors (to which I see I can count you as well) the correct licensing is very important. I represent the average Github user so to say, and when I research projects for inclusion in my own project having it Apache2-licensed is an additional plus. Also I have worked for several employers that exclusively allowed Apache2 project into the organization.\nNot saying this is good, or how it should be, but just like reading privacy statements, finding out the subtle, legal differences of varying licenses is not something that excites me.\nBTW Nice choice the name for these specs. You'll probably find the NSA and FBI at your doorstep if you use it overly much these days :wink: \n. Thanks @andimarek for your clarification. I think the responses in this thread put my mind at rest.\nAnd if not, I could also request to become maintainer myself.\n(On the CoC, I don't mind the thing, of course, just found it odd first time I saw it. Haven't seen a troll, nor sexual remark since, so maybe its indeed working :wink:)\n. @andimarek Thanks :+1: \n@kaqqao Hee Bojan, nice to meet you! Send you a LinkedIn mesage.\n. no problem. agree :). Thanks. Well, I a am not using it right now, but I think as GraphQL is maturing and used in larger schema definitions this will be regularly used.\nI'll rename the issue, so its not a question.\n. Fair enough, no problem.\n. Yes, sure. \nThe metadata will serve as a general extension mechanism that you can use in functionality that is not directly related to querying (i.e. directives are a means to add metadata to a query string). What it will be used for is entirely up to the client and depends on use case, etc.\nSome of possible uses:\n- Server / client-specific cache settings for individual schema objects\n- Whether or not data can be asynchronously retrieved (but potentially unordered)\n- Access restrictions for specific types\n- Add keywords list and other stuff that don't neatly fit in description string\n- Information regarding clustering, proxying (see below), encryption, compression, other server settings, etc.\nA bit more information on my current use case: I am creating a remote service proxy for GraphQL schema's for use in microservices architectures (see vertx-graphql-service-discovery and vertx-graphql-schema-proxy. It works by marshalling a GraphQLSchema to JSON, and then rehydrating a proxy of it client-side.\nThis allows two styles of communication (or querying):\n- Offload entirely to the back-end by sending it the query string and await the JSON result\n- Invoke the schema proxy and execute at the client\nThe second option leads to a more chatty communication style where messages are sent to the backend for each dataFetcher and typeResolver that is encountered in query processing.\nWhile more chatty, it allows asynchronous processing and fine-grained control of query distribution.\nBut you don't always want the client to be invoking this way. There may be some parts of the whole query that should be executed exclusively at the backend, while others are not.\nMetadata in the schema definition would be a means to easily control this.\n. As you can see I have moved the discussion to the specification level as well.\n. The metadata concept is indeed harmless. A similar, simple mechanism is used throughout Vert.x toolkit and gives a lot of freedom and flexibility.\nAs you saw I have added an issue to the graphql spec project, as I, like you, think a mechanism like this should be more or less standardized across implementations.\nThe solution with description is IMHO more hack than work-around (so its abuse :wink:). The description will in most cases already be used to generate API documentation anyway.\nBTW If you close the issue, how do you get to revisit it later?\n. Hi @dminkovsky ,\nI see your general approach is to close issues that you intend to visit later (like https://github.com/graphql-java/graphql-java/issues/176 and https://github.com/graphql-java/graphql-java/issues/126).\nPlease, please, do not do that. Close should mean Done or WontFix. Not that you have memorized in the back of your head to revisit these issues later, or users should comb the closed issues list before they file a new issue. No one will ever check the list of closed issues to see which ones are really closed and which may be closed only temporarily.\n. Thanks :+1: \nThere is not a specific convention, but like you said confusing. I think for most developers Closed means it is history, unless a team / project explicitly agrees to deviate from it (and with good reasons).\nIf the goal is to keep a clean, short backlog of issues, an alternative could be to maintain a wiki page 'Future plans' or something, and give indication what might be in future releases 2.1, 2.x, 3.x, etc.\nOr you could create a separate project for graphql-java feature requests and enhancements. Then use the issue list on this project only for bugs (and close and move feature requests to other project)\n180 is a different issue. You can check out the project I created thus far (it is not finished) at: https://github.com/engagingspaces/vertx-graphql-service-proxy. You see the decorators are quite involved without clean interface implementations.\n. BTW I might add the metadata support to my decorators, as there I am free to extend the API.\n. Thanks @kaqqao , @andimarek ! I am not using IDL schema's at the moment, but I love the support for it in graphql-java. Great work!\nYes, I guess it could come a long way into supporting a proper metadata system.\nThis issue can be closed unless you have more plans with regards to metadata support (and there is also still the https://github.com/facebook/graphql/issues/200 open issue).. Oh, that is cool. Wasn't aware of that feature. Thanks.\n. One nice thing of JavaDocs is that they often pop up before the code in Google searches. I think they are used by many people in that way, where they take a quick peek when they hear mention of a class, then continue being productive :wink: again.\nA) does not seem a good option. Users of JavaDoc are most typically using a stable release\nOn the other 2: B) is nice and C) even nicer, but probably more work to configure?\n. :+1: Yeah best be KISS and add it to release procedure.\n. Looks good! :+1: \nIndeed a bit minimalistic, but that's no problem. Is the link in the footer the only way back to the main project page, or will that be the page header title as well after committing?\nAlternatively (or in addition) there can be a 'latest' entry under releases that drops you off at the main project page.\n. Bit late. But even though workaholic today was too nice weather in Netherlands :smile:\nIt looks really nice @markphilpot . Nice job!\n. Build needs a check-up. It didn't run due to some socket exception.\n. Cool :+1: \n. Great!! Thanks.\nI'll arrange something better soon, if you want.\nBut next day I'll be out of sweat. Euhh...sweatshop I mean, ha ha.\n. Yes, I think that will do the job just as well.\n. Sure.\n. I think the Relay code should also merit a separate module (or even a separate project) There are more client implementations such as Apollo Client.. maybe you could use Map<String, String> or an immutable Metadata.get(key) interface and impls that clone the data... maybe grapql-java could adopt the idea of data objects like vertx.io does for data transfer over the event bus. they are java classes that serialize / deserialize to json..\ni don't have much time to investigate further, but here is a link (vert.x can use codegen to generate java classes)\nhttps://github.com/vert-x3/vertx-codegen/blob/master/README.md#data-objects. @kaqqao might not be too much overhead (ps. i linkedin msg'ed you :). ",
    "erikogenvik": "Yeah, the builder methods aren't necessary. However, I liked the way you don't have to specify the name of the property twice. It removes a failure possibility.\nAnother option would be to have a \"DataFetcherStrategy\" field in the builder containing an enum. It would default to \"Property\", but could be set to \"Field\". If more provided DataFetcher's are added they would be represented by additional enums.\n. ",
    "weebl2000": "Complete query looked like this: SpaceInviteInput is the last object\n{\"query\":\"mutation event($space: ID!, $newRights: SpaceInviteInput[]!) { res: updateRights(id: $space, newRights: $newRights) {\\n                        id\\n                    } }\",\"variables\":\"{\\\"space\\\":\\\"sIp2evFViScOvu_IZ4pEdnw\\\",\\\"newRights\\\":[{\\\"invitee\\\":\\\"wessel.xxx@xxx.com\\\",\\\"rights\\\":[\\\"READ\\\"]}]}\"}\nso:\n[{\\\"invitee\\\":\\\"wessel.xxx@xxx.com\\\",\\\"rights\\\":[\\\"READ\\\"]}]\n. Thanks for looking into it.\n. @IamCornholio Thanks, changed this. The error still occurs, somehow a GraphQLScalar is always perceived as NotNull when on the backend. This also applies to GraphQLString.\n. Dear @andimarek - I will look into the code to see if we have figured this out yet.. ",
    "metacosm": "This fix (or a similar one that properly implements hashCode and equals) is actually needed to properly resolve fragments on union types when using graphql-java-servlet. Currently, FieldCollector.doesFragmentConditionMatch calls FieldCollector.checkTypeCondition where the resolved type is instantiated by my type resolver whereas the condition type is resolved from the schema. They are semantically identical but different instances thus resulting in conditionType.equals(type) failing.\n. I would argue for type uniqueness based on name as well: one name <-> one type. This seems like a reasonable assumption which doesn't constrain the model too much and allows for very simple equals and hashCode implementations.\n. The specification states:\n\nAll types within a GraphQL schema must have unique names. No two provided types may have the same name. No provided type may have a name which conflicts with any built in types (including Scalar and Introspection types).\n\nFrom this, I infer that two types with the same name must be equal or the schema is invalid. Considering a type's name should therefore be enough to ensure its identity, which is all that matters for equals and hashCode (and more importantly, how the JDK uses them).\n. The error would be detected when the schema is built (at least, I'd assume): an error should be thrown as soon as a new type is being added with an already registered name is added. At least, that's my understanding but I was indeed missing part of the picture.\nNot having a proper equals / hashCode implementation results in lots of bugs all over as demonstrated with the handful of issues that revolve around this problem. If we cannot provide a valid implementation of these methods that allows semantically equivalent objects to be recognized as equal, then we shouldn't allow direct instantiation of these types and always go through the schema as a factory/registry. This way there would only ever be one instance of each type and we could be sure of the object identity.\nIn the end, it doesn't matter (apart performance-wise) how equals and hashCode are implemented. Either each type is instantiated exactly once and we can rely on object identity for equals and hashCode, or we need a proper implementation of these methods. Without either, there are bounds to be subtle bugs so this issue needs to be addressed properly.\n. One last point :)\n\nBut from a runtime Java perspective, two object definitions with the same name can be totally different, and the usefulness of an equivalence relation that only compares their names seems, well, not useful, and even worse, bug prone?\n\nThe reverse from a Java perspective is just as bad. It breaks pretty much all the Collections that semantically equal objects are considered different because they lack proper equals / hashCode implementations. A good reference on that point: http://www.ibm.com/developerworks/library/j-jtp05273/\n. > The error would be detected when the schema is built [...]\n\nNot if it's a type that's not included in a schema. It sounds like you're doing just that in a type resolver: returning a type by building it right then and there. If it's never part of a schema, there's no way to validate it against other types.\n\nYes, I missed that part initially. :)\nRegarding the possible options, the easiest one in term of avoiding changes to existing client code would be option 3, providing sensible equals/hashCode implementations (for some value of \"sensible\").\nOption 2 is probably the best solution going forward as the schema should hold the \"truth\" about types. However, going through the schema would require significant re-write of the code I think, as well as change how you can use the API. I started looking into it (not too long) and I could already issues with the graphql-java-servlet project since we would need to get access to the schema from the query / mutation providers in order to create the needed types. On the other hand, the project I currently work on would definitely benefit from incremental updates of the schema (as GraphQL types could be generated on the fly based on OSGi bundle events and right now the only option I have is to redeploy my provider on each such event and re-generate the whole schema when a simple use case already has hundreds of types) so I might need to fork / implement an alternative to the current solution anyway. \nOption 1 is unacceptable for me as it completely breaks my application since I would require access to the schema to be able to retrieve the proper type instance when I resolve it, which I can't because I don't have access to the schema at the moment (due to the architecture of graphql-java-servlet). A partial solution here would be indeed to make the schema available in type resolvers.\n. Using immutables would be nice, especially since it would also help removing duplicated code but proper implementation of hashCode and equals is essential.\n. Hi @dminkovsky,\nMaybe I'm not using the API correctly but in my use case, I iterate over fields and retrieve arguments from the fields. In this case, the only way I have to retrieve the field's arguments is via Field.getArguments() which is not really helpful at all. It'd be useful to have the same <T> T getArgument(String name) method we have on DataFetchingEnvironment on Field as well.\nPS: I do agree that the spec shouldn't mandate implementation details but in this case, it helps ;)\n. > When do you iterate over fields? Inside a DataFetcher? If so, are you saying you look at the List that can be retrieved via DataFetchingEnvironment#getFields()? And then want to see that the argument values these fields have?\nYes. In my code (which might be going about solving the issue I'm facing the wrong way), DataFetchingEnvironment#getArguments returns an empty Map while I do have Fields with arguments and associated values (which are what I expect them to be, maybe out of pure luck or because I'm dealing with Strings so far). I have a quick and dirty proof of concept that uses that kind of code.\n\nWhen a particular field is being resolved during a query execution, its arguments are normalized to an actual value.\n\nI may be missing something but the ValuesResolver.getArgumentsValues method is converting the arguments list into a Map (even a linked one, not sure why since order is not supposed to be significant for arguments) and it seemed to me that it was a common occurrence in the code that the arguments list was converted to a Map. My point is that I still don't understand why the arguments have to be stored as a List when they are more usefully manipulated as Map (as even the implementation seems to denote).\n. OK, I think I understand more the issue now. Thank you.\nOne last question: why does ValuesResolver put the arguments in a LinkedHashMap, though? It would seem like this is unnecessary as the order of arguments is not meaningful.\n. I agree that the spec for names addresses only query documents. However, if the schema doesn't conform to this naming scheme, you won't be able to query your data. As an example, if you attempt to use a schema that doesn't follow this naming format, GraphiQL will throw an error. A possible spec oversight but shouldn't the schema produce names that can be queried, regardless?\n. I favor this introduction of a common abstract type to keep that logic in a single spot and to avoid lots of code duplication.\n. @andimarek The downside of this is that it makes it difficult to build a modified, local version of the project to be used and tested with downstream projects (e.g. graphql-java-servlet).\n. ",
    "kroepke": "Just popping in, because I received an email today about a comment I can't find now:\nI'm currently not actively using/trying to use GraphQL and have no spare cycles do maintain this.\nSo if someone wants to take this over, please feel free. I'm not even sure of what the state of Java-GraphQL is at the moment.\n. I understand, usually I would've turned GraphQLType into an abstract class to at least keep the name property and equals/hashcode in the same place, because this really is common behavior of all types, but I didn't want to make that incompatible change all over the code base either.\nIf you prefer I can easily push the property and method implementations down again.\n. I don't think that GraphQLModifiedType implementations are ever asked for their name.\nOf course that's a little bit hard to see from the interface hierarchy, because the base interface declares getName().\nTechnically we could return anything, it's never used anywhere. Of course that does not hinder any client to ask for name. The reference implementation uses GraphQLNamedType for this, I guess if we did that it would be clearer. Not sure if it's really worth it, though.\n. ",
    "tberman": "Yes, I am an idiot. Ignore me please!\n. I have an implementation of an ExecutionStrategy that uses rxjava that I will be publishing as open source soon.\n. https://github.com/nfl/graphql-rxjava is available now, readme coming soon, and trying to get it put into central ASAP\n. That is a bug in 1.2. If you use the latest version from bintray you won't have that issue with the introspection query.\nOn Thu, Oct 15, 2015 at 6:46 AM, Pedro Antonio Souza Viegas\nnotifications@github.com wrote:\n\nSo, this is actually from my codebase, SchemaDefinition.schema is just where the schema lives and jsonSchemaFile() returns the path to the json file I want to write too.\nBasically INTROSPECTION_QUERY is a copy from graphql.js, seems to me that the problem is in the differences this port has from handling nulls from the js one.\nI have tested with my schema with no mutations and also getting the same issue.\nReply to this email directly or view it on GitHub:\nhttps://github.com/andimarek/graphql-java/issues/39#issuecomment-148391668\n. So, obviously up to @andimarek, but to me, this patch represents an example of an open source etiquette issue. To read up: http://tirania.org/blog/archive/2010/Dec-31.html\n. \n",
    "zourzouvillys": "Yeah - along with 'on', 'true', and 'false' ... although, the GraphQL grammar isn't context free - so we can't always allow a Name where it should be allowed with ANTLR (at least - my knowledge of it - i've not used it since 3.x, and it would have been very hard if not impossible in it then).\nSigh; The updated patch does the best i can without some major work on the ANTLR grammar, or hand-rolling a parser. Specifically;\n- 'true' and 'false', and 'on' can't be used as parameter names, nor as a field name or alias.\n- 'on', 'true', or 'false' can't be used as a fragment name.\n. It's not directly related to #28.\nre use case: yes.  the one that bit me was using a TypeReference everywhere a given type if mentioned  is used (e.g, in parameters or return types), and so when it comes to building the schema, there is no reference to the actual ObjectType instance.\n. pushed and update re null instead of empty set usage!\n. ",
    "ghost": "Dear Andi,\nDo you have any updates about this? I currently have a use case where I would need this functionality (see https://github.com/andimarek/graphql-java/issues/46 ). \nThanks!\nPeter\n. Dear Andi,\nHere are two examples from my schema:\n1: recursivity: a User can have a referrer, who is also a User. \n2: bidirectionality: a User can have multiple Subscriptions, but a Subscription may be transferred and shared. Thus, it is a bidirectional relationship which I would like to be editable from both ends.\nCurrently I have done a workaround in which my argument is a JSON string with the object hierarchy. It would be great if this could be solved via a standard GraphQL way! Currently I have the impression that the mutation framework is rather only for RPCs than hierarchical data updates...\nThanks,\nPeter\n. Dear Andi,\nHere are two examples from my schema:\n1: recursivity: a User can have a referrer, who is also a User. \n2: bidirectionality: a User can have multiple Subscriptions, but a Subscription may be transferred and shared. Thus, it is a bidirectional relationship which I would like to be editable from both ends.\nCurrently I have done a workaround in which my argument is a JSON string with the object hierarchy. It would be great if this could be solved via a standard GraphQL way! Currently I have the impression that the mutation framework is rather only for RPCs than hierarchical data updates...\nThanks,\nPeter\n. Sorry, closed the issue just accidentally. The buttons were too close on my phone.\n. Yeah we've been using it lately and I was told we can't contribute bugfixes or anything without a CLA. \n. It's a company btw, if it was up to me I'd just start contributing.\n. I am reading documentation.\nThanks a lot.. ",
    "mrogg": "I'm going to presume the type containing the connection type should shape the data to fit the mold.\n. ",
    "ybayk": "That would be exactly what we are looking for. Any hint on how soon? :)\n. ",
    "akhahaha": "I would also like to second @ybayk's request to go async all the way (via fetchers and execute()). @tberman's work-around still leaves something to be desired.\nI'm new to GraphQL and have only looked at the Java implementation thus far, but it seems to me that this would more closely align with the Javascript specification, which states that ExecutionResults should be returned via a Promise, which are async.\nIf others agree with this sentiment, I'd be happy to start working or collaborate on a pull request to make this happen.\n. @dminkovsky I'd integrate some sort of callback interface as the primary method of returning data from execute() and fetchers.\nQuery executions would probably end up looking something like:\nnew GraphQL(schema).execute(\"{hello}\", new GraphQLCallback() {\n    @Override\n    public void onComplete(ExecutionResult result) {\n        // Handle result\n    }\n});\nand the DataFetcher interface would need to change to something like:\n```\npublic interface DataFetcher {\n    void get(DataFetchingEnvironment var1, DataFetchCallback callback);\n}\n// Sample async DataFetcher\nnew DataFetcher() {\n    @Override\n    public void get(DataFetchingEnvironment environment, DataFetchCallback callback) {\n       // Start async operation with callback, such as web or DB lookup\n       async(new AsyncCallback() {\n           @Override\n           public void onComplete(Object result) {\n               // Return value to ExecutionStrategy via callback to be collated\n               callback.onComplete(value); // Can also be called directly for sync operations\n           }\n       });\n    }\n};\n```\nThis implementation seems simple enough, although it does have the slight problem of requiring the DataFetchCallback to be manually called when implementing DataFetchers, and I'm not sure how to enforce that at the moment.\nAs for the callback interfaces themselves, I imagine a few simple classes would suffice, although I'm sure we can also use a more established callback library such as JDeferred (actual Promise functionality).\nThoughts?\n. You have a good point: we shouldn't be deprecating methods lightly.\nIt seems to me that in order to avoid deprecating the get() method, the ExecutionStrategy must decide to either wait for the DataFetchCallback or process the serial return value of get(). One workaround for this ambiguous situation would be to create a separate AsyncExecutionStrategy and perhaps an executeAsync() function to handle the callback methods. The drawbacks to this would be some likely code duplication, at the very least.\nMy point also remains that per GraphQL-JS specification, the library should be async capable by default, and I believe callbacks of some sort are the way to go about this. Perhaps the best solution for something this drastic would be to break backwards compatibility and roll it out as v3.0.0?\n. @hepin1989 I was looking at CompletableFutures as well, although I haven't personally used it before. It does seem to have the potential of being more elegant than simple callbacks. Does it address @IamCornholio's concern about backwards compatibility though?\n. @IamCornholio what do you mean?\n. @IamCornholio Ah gotcha. From what I can tell, that particular ExecutionStrategy is used to parallelize field resolution to speed up execution and is not related to the asynchronous functionality I'm looking to enable here.\n. @hepin1989 Yes I think I agree with you after studying up on CompletableFutures.\nI've completed a working conversion on my fork. execute() and fetchers now return CompletableFuture promises. I haven't updated the Groovy tests yet, but it seems to be playing nice with fetchers using Firebase calls as well as static information.\nThis will deprecate almost everything and will require Java 1.8, so I'd like more input before making any pull requests.\nThere are also a few questions/considerations I haven't resolved for myself yet:\n- Is there a better to way to resolve a collection of CompletableFuture promises than asking each promise to check if it is the last one to complete?\n- Should I be using the async methods of CompletableFuture anywhere?\n- I probably ought to return CompletableFuture exceptions up the chain in ExecutionResult somehow,.\n. The trouble I'm having with your proposal is figuring out how the future would be resolved from asynchronous operations within custom DataFetchers in this case?\n. Also, I could be wrong in my understanding of the implementation, but aren't DataFetchers at the moment required to return the various built-in GraphQL Scalars types (or GraphQL objects/maps/models built from said types)?\n. I think we may have our interpretations of what async entails. For my requirements, I wish to implement a DataFetcher that needs to perform a database lookup (Firebase, in this case). This database call is made asynchronously and is returned via callback, like follow:\n```\nDataFetcher userFetcher = new DataFetcher() {\n        @Override\n        public Object get(DataFetchingEnvironment environment) {\n            CompletableFuture promise = new CompletableFuture<>();\n            users.orderByChild(\"id\").equalTo(\"10154006247769055\").addListenerForSingleValueEvent(new ValueEventListener() {\n                @Override\n                public void onDataChange(DataSnapshot dataSnapshot) {\n                    User result = dataSnapshot.child(\"10154006247769055\").getValue(User.class);\n                    promise.complete(result);\n                }\n            @Override\n            public void onCancelled(DatabaseError databaseError) {\n\n            }\n        });\n\n        return promise;\n    }\n};\n\n```\nThis example does not work in the current implementation (returns null during value resolution). If I block for the result and return the User result directly, it succeeds. However, I would like to receive the ExecutionResult only when this (and all other) asynchronous DataFetchers resolve without blocking.\nAnd after writing all this, I realize that I can use blocking DataFetchers and simply run the execute() in another thread, so I finally see how wrapping the entire thing would work.\nI still wonder if async behavior shouldn't be default, again pointing back to the JS specifications.\n. > But I'm not sure there's any reason not to block here, especially with the executor service-based strategy. Each data fetcher might as well just block and resolve synchronously.\n@dminkovsky I think I'm seeing the light now. It took a while to see how the ExecutorService parallelism, blocking DataFetchers, and an async wrapper can be combined to achieve the equivalent result for async operations. Perhaps a short tutorial about this in the README might be in order?\nFeel free to reject the pull request. It was a fun exercise and a great learning experience, if nothing else.\n\nhow about a new AsyncExecutionStrategy with a new method executeAsync,eg:\n\n@hepin1989 It seems to be superfluous now, all things considered.\n. @oexza @hepin1989 Lol damn, well I just changed it to CompletionStage, but I can always revert it. What are the pros and cons?\n. What would that entail specifically?\n. @dminkovsky It sounds like @pcarrier might be having similar \"issues\" from what we discussed in #37. Have you shown him that thread and perhaps this PR?\nTo reiterate, to accomplish the async functionality that I think and he and I were looking for, simply use blocking DataFetchers and then perform the serial execution using the ExecutorService strategy on another thread using an async wrapper of your choice. Each DataFetcher will then resolve in parallel, and the async wrapper should return when all have been resolved.\nIt's not intuitively async like we'd expect, but the result should be equivalent. I guess it does beg the discussion again of whether or not async functionality like this should be built-in by default.\n. I'm reworking this\n. I think I'm onto a fairly simple solution right now. I've extended DataFetcher into an AsyncDataFetcher abstract class.\n```\nimport java8.util.concurrent.CompletableFuture;\nimport java.util.concurrent.ExecutionException;\npublic abstract class AsyncDataFetcher implements DataFetcher {\n    public Object get(DataFetchingEnvironment environment) {\n        try {\n            return getDataFuture(environment).get();\n            // TODO Handle exceptions\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } catch (ExecutionException e) {\n            e.printStackTrace();\n        }\n    return null;\n}\n\npublic abstract CompletableFuture<Object> getDataPromise(DataFetchingEnvironment environment);\n\n}\n```\nUsers can then return their data in a promise using getDataPromise(). This particular CompletableFuture class uses the streamsupport-cfuture backport library, which should be compatible at least back to 1.6, although I'm not entirely sure if it's interchangable with the native 1.8 versions.\nI think there should also be GraphQLAsync class that wraps the default GraphQL in an async wrapper (via callbacks or more CompletableFutures). It should also use an ExecutorService by default in order to achieve the parallel completion necessary for equivalent async performance. I'm not too familiar with the pattern, so I'm not sure if we can provided a default ExecutorService implementation or if users are supposed to provide their own.\nUnlike my previous implementation, this method should not require changing any other part of the library.\nI'd recommend this be placed into a subproject/module (requiring current graphql-java to be moved into a \"core\" module). It shouldn't be too hard to maintain this plugin alongside the main project.\nThoughts?\n. > Non-opinionated about source of concurrency (threads, pools, event loops, fibers, actors, etc)\nI think my proposed solution is in fact non-opinionated about the source of concurrency. From what I can tell, both CompletableFuture and Observable are simply fancy callback/runnable handlers. They do not themselves run on another thread.\nSome sort of ExecutorService is necessary to achieve the same functionality like we discussed. I agree that it does seem undesirable, but the other alternative is to follow the guidelines listed in your Ratpack link, namely:\n\n\"Request handling is organised as a pipeline of asynchronous functions.\"\n\nIncidentally, I believe this is how my original PR worked, by creating a pipeline of CompletableFutures from DataFetchers to ExecutionResult. However, I don't believe it would be possible to make this a subproject, nor should we maintain it as a sister project. If we are to use this method, I believe this should be become the default implementation.\n. ",
    "IamCornholio": "That would mean the original get() method would have to be deprecated. Why not add the callback reference to the environment? That way one can add a separate handling mechanism for the when the callback has been set in the environment.\n. The file ExecutorServiceExecutionStrategy seems to be doing a bit already..\n. @akhahaha I mean that this code seems to be using futures already and I wondered if that essentially represents the AyncExecutionStrategy that you were talking about:\n```\nMap> futures = new LinkedHashMap>();\nfor (String fieldName : fields.keySet()) {\n    final List fieldList = fields.get(fieldName);\n    Callable resolveField = new Callable() {\n        @Override\n        public ExecutionResult call() throws Exception {\n            return resolveField(executionContext, parentType, source, fieldList);\n    }\n};\nfutures.put(fieldName, executorService.submit(resolveField));\n\n}\ntry {\n    Map results = new LinkedHashMap();\n    for (String fieldName : futures.keySet()) {\n        ExecutionResult executionResult = futures.get(fieldName).get();\n    results.put(fieldName, executionResult != null ? executionResult.getData() : null);\n}\n\n```\nThis code is in that file ExecutorServiceExecutionStrategy.\nYour point about it not being the default async promise still remains.\n. Not sure about the NonNull business but there is a bug in your Coercer. The parseLiteral input argument is an instance of graphql.language.Value and in this case StringValue, not String. This is why it skips\nif ( input instanceof String )\n                return serialize( input );\nand then this \nif ( !( input instanceof OffsetDateTime ) )\n                return null;\nreturns null.\n. @aschrijver I don't know. object have fields. fields have arguments. What other builders would benefit from a supplier?\nPerhaps @Underzenith85 can explain better\n. Ah yes. I think this works well with GraphQLInterfaceType.Builder#field, GraphQLDirective.Builder#argument, GraphQLEnumType.Builder#value (bit much perhaps?)\nBut GraphQLUnionType.Builder#possibleType? Or even the non list schema objects like GraphQLFieldDefinition.Builder#type, GraphQLInputObjectField.Builder#type?  I'm not sure about that. I don't know if I'd want to define an object type inline. I would find that confusing ~~because defining that object type there in an anonymous class doesn't add that object type to the schema typeMap~~ it does! See SchemaUtil#allTypes. Also I'd rather define it outside so I can keep a reference to it and use it for other union types. You could argue that a reference variable could be maintained through the anonymous classes but I don't know if such a structure would be helpful or better to read.\n. @dminkovsky I may have misunderstood what you're trying to say or don't know enough. But the way I have been using this is that the graphql-java jar is being used by code written using JDK8 syntax.\nThe lamda syntax can't be used on the project itself but can be used by those using this project as a dependency right? And so I am currently able to use lambdas (as shown in my comments) in my code. I thought we could keep the project on java 6 and still be able to use the builder interface for a nicer jdk8 lamda syntax. Am I missing something?\n. @aschrijver Ah yes. I agree to the extent of missing out on the goodness of jdk8 and libraries. I will probably remain a skeptic until I see the goodness actually being used though :)\n@dminkovsky it took me a while to understand why one would ever see .build()) repeating. I finally got it when I saw the file Harness.java. Yes it is very awkward that we have to call the build on every thing. As I understand it. You are proposing this\npublic Builder argument(GraphQLArgument.Builder builder) {\n  this.arguments.add(builder.build());\n  return this;\n}\nin addition to this\n/**\n* Take a argument builder in a function definition and apply. Can be used in a jdk8 lambda\n* e.g.:\n* <pre>\n*     {@code\n*      argument(a -> a.name(\"argumentName\"))\n*     }\n* </pre>\n*/\npublic Builder argument(BuilderFunction<GraphQLArgument.Builder> builderFunction) {\n  GraphQLArgument.Builder builder = GraphQLArgument.newArgument();\n  builder = builderFunction.apply(builder);\n  this.arguments.add(builder.build());\n  return this;\n}\nI agree that should be done. ~~(or perhaps not, see following blurb).  Are you proposing this be done in the same pull request though?~~\n~~I have this other notion that fields and arguments are dependent on the existence of an object and as such shouldn't be allowed to build() without the context of the object type. That the build method should not be called in the first place and the schema should really build when the GraphQLSchema.build(dictionary) is called.~~\n. Sorry for the spam. I've updated this PR and it's scope.\n. @dminkovsky Yea I couldn't find an obvious place for the tests either.\nI'm familiar with editing commit messages but do you want me to change it for https://github.com/graphql-java/graphql-java/commit/90b6b2f51bb68df410c2a03306544c81abcd360d? That's not a commit I wrote. I'll check the format for the one's I wrote.\n. I didn't know that this 50/72 was a standard. Learn something new everyday I guess.\nRebase done now. Messages shortened. Added a simple field/argument test also.\nIs squashing commits a thing for us?\n. @dminkovsky I think it's ok as a single commit. I've updated the javadocs a bit too.\n. @aschrijver There were 5 commits. I didn't need to squash them. But I do prefer a clean history and so I asked @dminkovsky and he said sure. He clearly says he wasn't going to suggest it himself.\nI say atomicity is a good reason for squashing commits but then I am not a maintainer (yet \ud83d\ude09 )\nI can't share an unbiased opinion about my fanaticism either \ud83d\ude04 \n. @dminkovsky Ah yes. Looks like I missed some obvious ones there. The build() calls are still there in the tests. I wonder if we should remove them as part of this pull request?\nAlso I'm assuming that you want me to cherry-pick those commits and add them to this pull request?\n. @dminkovsky let me know if you want me to remove that last commit and/or squash others\n. @dminkovsky A good morning to you too :smile: \nAll done now\n. I missed that it could have become inconsistent with custom defined scalars. I accept that this is not a step in the right direction.\n. Also fixed a typo\n. A bit here: https://github.com/graphql-java/graphql-java/pull/34. Needs more work to deal with the circular references validation.\n. Adding @yrashk \n. This is failing because the grammar needs to be regenerated. It seems like @andimarek had some IDE settings that are different from mine and so my generated grammar diff is wildly different. In any case once https://github.com/graphql-java/graphql-java/pull/161 is merged then the generated grammar doesn't have to be checked in. It is unnecessary.\n. We have discovered that this has a bug where declaring a directive on an inline fragment doesn't work. Fix is in progress.\n. Fixed the inline fragment directive bug as well. Author (@trevor-morris) says this is a bug even on the graphql-js and graphiql.\n. Removed conflicts. Ready for review/merge.\n. I believe https://github.com/graphql-java/graphql-java/pull/175 addresses this issue as well. Also you could try removing locations and directives from graphiql's introspection query.\n. I thought https://github.com/graphql-java/graphql-java/pull/136 allowed the graphiql to work with graphql-java because without that the introspection would fail on account of the field location not being available. Do directives actually work with that fix?\n. What kind of metadata would you add? Can you provide some examples?\n. Based on this https://github.com/facebook/graphql/issues/189 it seems circular references are allowed just as long as the circularity can be broken. For e.g. (stealing code from the issue)\n```\ninput Something {\n  name: String,\n  somethingElse: Something //ok\n}\ninput Something {\n  name: String,\n  somethingElse: [Something!]! //empty list?\n}\n```\nPerhaps even this is fine\n```\ninput Something {\n  name: String,\n  blahReference: Blah\n}\ninput Blah {\n  name: String,\n  somethingReference: Something! //OK\n}\n```\nJust not this\ninput Something {\n  name: String,\n  somethingElse: Something! //bad!\n}\nOr this\n```\ninput Something {\n  name: String,\n  blahReference: Blah!\n}\ninput Blah {\n  name: String,\n  somethingReference: Something! //Bad!\n}\n```\nAlso I think you'll need to add a check to ensure that the type reference is to an instance of GraphQLInputType.\n. So it seems @dminkovsky posted this on stackoverflow\n@foragerr found that antlr plugin is unnecessarily adding a runtime dependency on the antlr generator. They suggested we use pom.withXml to remove the dependency. See their comment.\nThere is also a discussion on the gradle forums about this bug.\nSo I took @foragerr's suggestion and hacked up this patch which basically removes the dependency from the generated pom after the antlr plugin has done its thing.\nwhich is terrible but it does the job?\n. I think people are using the released version to try this out and the released version doesn't have that commit. Perhaps the readme should also point to a released version?\n. > I think the ExecutionConstraints should be built BEFORE being passed into the GraphQL object\n\nIt probably should be an interface\n\nI think these would go hand in hand. But do you mean built or defined? Could one define a constraint dependent on a graphql field that has not been \"built\" yet?\n\nThere is some challenges around depth here. If we use a multi threaded execution strategy and we pick apart a spec like\n{\ndata {\na,\nb,\nc\n}\n}\nand we spread a,b,c to threads each - are we at depth 1 or 4?\nPerhaps we should calculate depth BEFORE executing it. Eg run a tree count on the Document rather than execute it.\n\nI haven't spent much time on thinking but I can't think of a useful constraint that can safely run multi-threaded on multiple nodes of a tree at once. Any constraint trying to constrain a tree in anyway through traversal would fall in this category. If I'm missing the obvious then perhaps you could introduce a flag and/or a class hierarchy of two types of constraints (single threaded and multi threaded execution constraints). \nYou could also assume something safe and implement something that would act as a default. Since this is to become an extensible thing someone implementing graphql for their api would just implement what they need.. Uhh.. rename the variable source here?\n. I don't get why this has to be defaulted to a PropertyDataFetcher. Shouldn't this be defaulted to FieldDataFetcher if at all defaulted?\n. Question: Is this interchangeable with a FieldDataFetcher? I'm basically struggling to understand the use case of a MapDataFetcher/PropertyDataFetcher over a FieldDataFetcher. I get that an object has fields that can be \"fetched\". Those fields could potentially be fetched as properties too using their getters and since its all a json object one could possibly serialize it to a map (not sure how) and cast the object to a map and hence be able to use the MapDataFetcher. But when would a user choose one over the other. Sorry if I'm missing the obvious...\n. Yes. +1 to no default. Never liked em hidden defaults.\nMy question however was more specific to the code change. If isField then instantiate a FieldDataFetcher. Else a PropertyDataFetcher. Now you've removed the isField flag which tells me that this is always going to be a field. Right? And by that logic it should always sigh default to FieldDataFetcher. Did I miss something?\nStill maintain that it shouldn't default but I wonder what is the impact for those already in production with this.\nEdit: Actually I don't know how one can assume that the fields or the getters will be publicly accessible. Or is it that if field is being declared in the schema then the field should be available as a property at the very minimum? I think maybe I'm overthinking this :laughing: \n. @markphilpot agreed that verbose is not good. but i'd prefer verbose to ambiguous. edit: given that the property fetcher is changing  the ambiguity i think in using the propertyfetcher is the assumption that field is available with getters when it could very well be a map. or worse no getters or setters :laughing:. improbable but possible.\nEdit: Oops. didnt refresh comments before posting this.\n. Generics. I'm looking forward to that one too. No special reason. Like the thought of adding type safety as a feature. It has the potential for users to reduce code using generics. Doesn't sound like a breaking change though. Worst case scenario is that someone using the non typed version gets compilation warnings. I think.\nAgree though that the scope of this PR should be limited to the clean up of what a data fetcher does.\n. @dminkovsky has raised concern about the fetcher now being required by the field definition interface. This is my response to that. The original comments seem to have been lost in the diff update.\nHmm. I didn't quite get that. Required how?\nIn any case. I don't know about null. null is a valid value to return I say. I wish there was an undefined :wink:  how about throwing an exception from the build method? I've always thought of the builder as a mechanism to not just build but also validate the object being built.\n. @dminkovsky Ah! Yes I forgot about that.\nPerhaps we define (inner or static) a no op data fetcher whose get method will throw a unsupportedoperationexception. The field definition build method defaults the data fetcher to this no op data fetcher. When a user uses the interface to define an object they will update the field definition (I presume) and in the process re-write the data fetcher as well. If they use it in an object and don't define a data fetcher and then query the object they get a runtime exception.\nWe could make  this no op data fetcher a private inner class of the field definition builder class so that no one else may use it.\nEdit: Or if you don't like that runtime exception then we allow the data fetcher to be null when field definition is built but fail a validation when the GraphQLSchema is built and the types are being collected.\n. :+1: \n. Nit: I wonder if this should be deprecated with the new change.\n. Perhaps consider making this an interface? One could implement other forms of constraints. User would pass in a list of constraints when instantiating the execution object. Example of other constraints could be that this sort of large query can only be run by authenticated users on a Sunday evening. Although that would probably need more work.. These sort of changes I believe are more of a personal choice and occasionally also depends on the IDE you are using. While I too prefer this style, we shouldn't encourage such changes. If these are all the classes in the package then revert it would be my suggestion.. Why specify a maxdepth all all?. I'd have preferred returning a user error. But that choice can be allowed to be made through a flag. Again, you could allow the ExecutionConstraint to be an interface and provide a few default implementations such as a numerical depth based constraint. But im beginning to see that I don't know of a lot of use cases for execution constraint as an interface.. ",
    "hepin1989": "Go with CompletableFuture ,Task,Source or something else that compose,no callback.\neg:\nAsyncDataFetcher{\n  Source<T> get(..);\n}\n. In fact I am doing the parallelism thing currently ,I am going to be with https://github.com/monixio/monix and https://github.com/akka/akka/.\nWe should use something that monadic as the return type.just as what sangria choose scala's Future.\n. Another option is go with reactor project,then we could using https://github.com/reactor/reactor-core/blob/master/src/main/java/reactor/core/publisher/Mono.java.\n. @akhahaha \n1. scatter and gather pattern,java.util.concurrent.CompletableFuture#allOf\n2. id depends,for field reading,no need,for method invoking yes,maybe another executor too.\n3. it's monad,it composes,don't worry.\nbut I think I will try another way,make use of akka,to do further batching. \n. I am currently using monix and akka,to do the same thing too,but I think you could wrap around the original datafetcher too.in case that for the FieldDataFetcher or MethodDataFetcher which do things simple we should not enforce a async boundary but evaluate it now ,and we should think about the blocking datafetcher too,which we may need a dedicated thread pool.\nthe real parallelism used in production need more than this.What I am doing now is:\n1. totally asynchronous  from the ground up.\n2. auto batching ,duplicate and grouping\n3. auto parallelism\n4. cache layer\nyou could read the paper of facebook's haxl,it's really helpful.\na wrapping at the GraphQL.execute() will have no help for the RT.\n. @akhahaha how about a new AsyncExecutionStrategy with a new method executeAsync,eg:\njava\n    public Task<ExecutionResult> executeAsync(final ExecutionContext executionContext,\n                                              final GraphQLObjectType parentType,\n                                              final Object source,\n                                              final Map<String, List<Field>> fields,\n                                              final OperationDefinition operationDefinition){...}\n. @akhahaha Asynchronous operation which lazy evaluate will reduce the unnecessary asynchronous boundary,and enable future auto optimization,even CompletableFuture which is an eager one,may not fit for the unlimited optimization,for simple usage,the ExecutorService based one should be enough.\n. @dminkovsky Yes,thanks,but I implement it my self:)you know ,close source project,have much adoption.GraphQL is used at taobao.com for all the content service.\n. Yes, Go For Async, and we could rebuild the sync from the Async again.. @oexza in fact I like the syntax of \nreturn env -> CompletableFuture\n. async is for not blocking on IO,not for speed.\n. the behavior changes for First attempts to use the source as a Map. now it did not.\n. The spec does not say not allow query as an fieldName.\nhttp://facebook.github.io/graphql/#sec-Names\n. The only issue is the result of the list will have order changes over time:)\n. I am currently using monix to implement.. I think we could split it to these modules:\n\nQueryParser\nSchemaIDLParser\nSchemaAST and Builders\nIntrospection\nExcutionStrategySPI and default implememt\nAsyncExcutionStrategy for java 8\n\nWith this kind of structure,I think this will greatly help the commnity.. If this project is wrote in scala and then it could support both Java7 and Java 8 with scala2.11. but it's not:)\nNetty is currently still support Java 6,Java 8 is only required for compiling.\n@GrigoryPtashko Maintain a fork is hard really:). And yes, this is an open source project.. And should have support trailing comment too.. I mean\n```\nquery common{\n#this is the first comment\n#this is the second comment\nfield #this is the trailing comment\n   field2\n}\n```\nthen the all the three comments should be parsed ,and the trailing one should be belong to the \ncomments of the field,not field2\n. so for the AST of the comment,\nIt should then be \n```java\nclass Comment{\npublic final Integer colum;\npublic final Integer row;\npublic final String value;\npublic final boolean trailing;\n}\n``. @andimarek I am not good at antlr but I have implement it in scala ,when you do pretty ,this information would really help:). @bbakerman No , it's not.\nI think you could or maybe make a poll on that,and then decide how to handle the edge case .\n. And still ,the comment should be a *Class* not a just a simpleString. CompletableFuture should be CompletableStage. And Array:). lol,great!. @exbe I think the Reactive-Stream TCK is a nice reference.. refs https://github.com/graphql-java/graphql-java/issues/983 .. @bbakerman I want to handle all Scalar type:) including my custom one in oneinstanceOf:). it's done:) thanks.. Nice, I saw it https://travis-ci.org/graphql-java/graphql-java/builds/403421785?utm_source=github_status&utm_medium=notification , I missed that:)\n. @andimarek I would like to make more contribution to this project :). that's a good way to go .. +1\n. +1\n. fieldName\n. then we need aMapDataFetcher. if ... return map.get else return null \n. make sureenvis not null\n. I'm using Spring'sPropertyAccessorFactory. when user new one.\n. @markphilpot In fact I like the more typesafty too:)\nSee Sangria\n. could make use of java8's stream.map.collect thing. If we move to java 8 ,then it could be Optional\n. I would love to seeList`. CompletableStage. ",
    "oexza": "re-echoing @hepin1989 's comment the real benefit of asynchronous data fetchers is the ability to use custom thread pools/executionContext. Lets say we have a simplistic data fetcher that uploads a file to some file service,\n`DataFetcher fileUploadFetcher = new DataFetcher() {\n```\n    @Override\n    public CompletionStage get(DataFetchingEnvironment env) {\n    final GraphQLContext context = (GraphQLContext) env.getSource();\n\n    CompletionStage<String>  uploadedFileUrlPromise = CompletableFuture.supplyAsync(() -> {\n         final Optional<String> urlOption = Optional.ofNullable(fileUploadService.upload(context.getRequest().getFile(\"file\")));\n         if(urlOption.isPresent())\n               return urlOption.get();\n         else{\n               return null;\n          }\n         }, MyExecutorProvider.fileUploadPool);\n     return uploadedFileUrlPromise;\n}\n\n};`\n```\nthe upload routine which is a long running operation, will run in  MyExecutorProvider.fileUploadPool which is configured and tuned specifically for this purpose. This kind of execution isolation is for me the biggest benefit of non blocking fetchers. \n. very well possible with GraphQLTypeReference.\n. actually i think #136 fixes this, I use graphiql with graphql-java and it works well, you only have to build graphql-java from source. https://github.com/graphql-java/graphql-java#build-it\n. Hello @akhahaha nice work, I think its better to return CompletionStage rather than CompletableFuture, since CompletableFuture is an  implemention of CompletionStage, like its done in Akka and PlayFramework which use this Interface extensively for asyncronous operations. Thanks.\n. Good work! I think the last missing piece is a way to pass in a custom Executor in which the CompletableFuture's will execute.\nEdit: On a second look, i see that DataFetchers would be allowed to return a CompletionStage, therefore an Executor can be used by the user in their DataFetcher implementations. So i think this PR is good to go. . How do you intend  to release this? will the project move to java 8? or will you release this as a seperate project?. in our case, field result filtering/authorization is done at the\nservice layer(which is the single source of truth) such that if we\nwere to build a rest api atop it, it would still work seamlessly.\nDataFetchers should be kept as slim as possible.\nOn 1/3/17, Dmitry Minkovsky notifications@github.com wrote:\n\n\nProbably we'd have to wrap all our DataFetchers in a wrapper class.\n\nThat's what I do. Whether you wrap or extend, I've not had problems with\nthis approach. Check whether the field is allowed execution, and then\nexecute or not.\n```\nabstract class AuthorizedDataFetcher extends DataFetcher {\n@Override\n  public Object get(DataFetchingEnvironment env) {\n    if (isAllowed(env)) {\n      return fetch(env);\n    }\n    // otherwise throw or return null;\n  }\n// perform actual data resolution\n  public abstract fetch(DataFetchingEnvironment);\n}\n```\nYou can clean the document too, but then you don't get null fields and\nerrors for unauthorized fields, just the execution results you want allowed.\nWith regard to hooks, we are considering changing the API to facilitate this\n(#269) (@bbakerman)\n--\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/graphql-java/graphql-java/issues/290#issuecomment-270127741\n. I second this! this library is held back by java staying on java 6. . that it worked previously is actually a bug. no two types should have\nthe same name.\n\nOn 5/30/17, SeenaLibin notifications@github.com wrote:\n\nHi,\nBut the same code worked fine in version 2.1.0\n--\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/graphql-java/graphql-java/issues/475#issuecomment-304836653\n. Awesome!!!\n\nOn 8/8/17, Andreas Marek notifications@github.com wrote:\n\nMerged #590.\n--\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/graphql-java/graphql-java/pull/590#event-1196713071\n. I think a graphql-java-scalars project under the graphql-java organization\nis proper.\n\nOn Fri, Jul 27, 2018, 8:43 AM Brad Baker notifications@github.com wrote:\n\nI am torn by this issue of datetime support in graphql-java\nOn the one hand its is NOT defined by the graphql spec and hence not a\nfundamental scalar\nOn the other hand people clearly want it (in graphql-java and graphql-js)\nbecause a date/datetime is a pretty fundamental scalar value.\nI really dont know if we should accept a datetime scalar in the base\nimplementation since there are a number of alternatives.\nThoughts @andimarek https://github.com/andimarek ? @kaqqao\nhttps://github.com/kaqqao ? @tinnou https://github.com/tinnou ?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/1137#issuecomment-408339591,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGAfbEC1ASkFRoVvo2xdhYR4VnBPQboBks5uKsS1gaJpZM4VhBlV\n.\n. \n",
    "benhead": "Perhaps someone should add \"Coming soon\" to the \"Asynchronous resolvers\" section of this page on the official docs? It seems to be saying that this capability is baked into GraphQL. Especially that last line...\n\nDuring execution, GraphQL will wait for Promises, Futures, and Tasks to complete before continuing and will do so with optimal concurrency.\n. \n",
    "marcelalburg": "I found https://github.com/karthicks/graphql-java-async and it offers an non blocking (for vertx) possibility to fetch data from remote/slow systems in a async way. Maybe you can take a look and it fullfill all your needs. It wraps graphql-java and based on it.. Will this error fixed in the current version too (2.4.x) ? I mean the issue, that references are not working in unions ?\nThanks\nMarcel. Yes, it's my issue, but it looks like, that the fix will be released in version 3.x wich has more changes in it. I hope, it's possible to release a 2.4.1 version.\nThanks\nMarcel. I checked it and in general it works now for possibleTypes but not for the typeResolver.\n```\n    return GraphQLUnionType.newUnionType().name(\"Page\")\n                .possibleType( GraphQLObjectType.reference(\"Contact\") )\n                .possibleType( GraphQLObjectType.reference(\"Other\") )\n                .typeResolver(new TypeResolver() {\n                    @Override\n                    public GraphQLObjectType getType(Object object) {\n                        if (Contact.class.isInstance(object)) {\n                            return GraphQLObjectType.reference(\"Contact\");\n                        }\n                    if (Other1.class.isInstance(object)) {\n                        return GraphQLObjectType.reference(\"Other\");\n                    }\n                    return null;\n                }\n            })\n            .build();\n\n```\nthe error is\n[ValidationError{validationErrorType=InvalidFragmentType, sourceLocations=[SourceLocation{line=1, column=29}], description='Fragment cannot be spread here as objects of type graphql.schema.GraphQLUnionType@358c99f5 can never be of type GraphQLObjectType{name='Other1', description='null', fieldDefinitionsByName={id=graphql.schema.GraphQLFieldDefinition@61322f9d}, interfaces=[GraphQLInterfaceType{name='DefaultPage', description='', fieldDefinitionsByName={}, typeResolver=graphql.schema.TypeResolverProxy@6ad82709}]}'}]\nThanks Marcel. Looking forward to this release !. Yes, your're right. The tag 4.2 is not working, but the master is working correctly. i'll wait for the next release.\nThanks Marcel. @andimarek: do you know when the next release will be released ? . ",
    "raptortech-js": "Ah-ha! Turns out I was never adding these types to the type dictionary when I built the schema, and I was relying on the fact that a type that explicitly points to another type will automatically include that other type in the resulting schema, and but references won't get replaced.\n. ",
    "danielschonfeld": "@pasviegas not sure i understand.... in particular where does SchemaDefinition.schema comes from\nSame goes for jsonSchemaFile() but that i can figure out on my own what it does and how to write\n. Also currently when I run the INTROSPECTION_QUERY against a schema that has no mutation, it results in the following error:\nException in thread \"main\" graphql.GraphQLException: Cannot return null for non-nullable type: [Field{name='mutationType', alias='null', arguments=[], directives=[], selectionSet=SelectionSet{selections=[Field{name='name', alias='null', arguments=[], directives=[], selectionSet=null}]}}]\n. @dminkovsky sure!\n```\npublic class SomeInfoTestSchema {\n    public GraphQLSchema getSchema() {\n        return schema;\n    }\nprivate GraphQLSchema schema;\n\npublic SomeInfoTestSchema() {\n    GraphQLObjectType queryType = newObject()\n            .name(\"Query\")\n            .description(\"A query\")\n            .field(newFieldDefinition()\n                    .name(\"viewer\")\n                    .type(viewerType())\n                    .build()\n            )\n            .build();\n\n    schema = GraphQLSchema.newSchema()\n            .query(queryType)\n            .build();\n}\n\nprivate GraphQLObjectType viewerType() {\n    return newObject()\n            .name(\"Viewer\")\n            .field(\n                newFieldDefinition()\n                .name(\"someInfo\")\n                .type(someInfoType())\n                .argument(Lists.newArrayList(\n                        newArgument()\n                                .name(\"type\")\n                                .type(new GraphQLNonNull(depthType()))\n                                .build(),\n                        newArgument()\n                                .name(\"id\")\n                                .type(new GraphQLNonNull(GraphQLInt))\n                                .build()\n                ))\n                .dataFetcher(new SomeInfoFetcher())\n                .build()\n            )\n            .build();\n}\n\nprivate GraphQLObjectType someInfoType() {\n    return newObject()\n            .description(\"Some Random Info\")\n            .name(\"SomeInfo\")\n            .field(\n                    newFieldDefinition()\n                    .name(\"id\")\n                    .description(\"id\")\n                    .type(GraphQLInt)\n                    .build()\n            )\n            .field(\n                    newFieldDefinition()\n                    .name(\"name\")\n                    .description(\"Name\")\n                    .type(GraphQLString)\n                    .build()\n            )\n            .field(\n                    newFieldDefinition()\n                    .name(\"type\")\n                    .description(\"type of info\")\n                    .type(depthType())\n                    .build()\n            )\n            .field(\n                    newFieldDefinition()\n                    .name(\"address\")\n                    .description(\"address\")\n                    .type(GraphQLString)\n                    .build()\n            )\n            .field(\n                    newFieldDefinition()\n                    .name(\"hobby\")\n                    .type(GraphQLString)\n                    .build()\n            )\n            .build();\n}\nprivate GraphQLEnumType depthType() {\n    return newEnum()\n            .name(\"DepthType\")\n            .description(\"depth inspection level\")\n            .value(\"BASIC\")\n            .value(\"DETAILEDPLUS\")\n            .build();\n}\n\n}\n```\nTested with the following query:\nquery {\n  viewer {\n    someInfo(type:BASIC,id:500) {\n      name\n    }\n  }\n}\n. @dminkovsky do you mean you want my DataFetcher class implementation?\nwhere is the source argument? if you mean the one in DataFetchingEnvironment i don't know since it never gets invoked according to my breakpoint in the debugger.\n. @dminkovsky I am indeed getting null as the result.  The source i'm passing to the GraphQL#execute() is what I pasted above below my java code.\nIt's passed via Spring as in your example on the README.MD or the todomvc-java-graphql\nHere's some logging to the console from running it:\n2016-08-24 19:58:17.174  INFO 30352 --- [nio-9090-exec-8] graphql.GraphQL                          : Executing request. operation name: null. Request: query {\n  viewer {\n    someInfo(type:BASIC,id:500) {\n      name\n    }\n  }\n} \n2016-08-24 19:58:17.175  INFO 30352 --- [nio-9090-exec-8] c.g.g.controllers.GraphQLController      : RETURNED: {viewer=null}\nThe RETURNED statement is an additional log statement i added.\nPS: Please make sure you SCROLL TO THE RIGHT in the above excerpt\n. @dminkovsky just checked (1), the ExecutionResult has 0 errors.\nhow do I go about (2)? \n. @dminkovsky but what would we be checking doing this? we'll only learn which datafetcher gets invoked (which i'm pretty sure is the first level only... the viewer type). But aside from learning that, what else would we learn or are we looking for?\n. @dminkovsky so anytime null is returned the execution stops trying other datafetchers? and if i dont have any datafetchers as I do, what would be returning that null?\n. @dminkovsky i just checked, since there's only one place to check and indeed if you add dataFetcher() on the viewer field it breaks in there.  source and arguments are empty tho.\n. @dminkovsky ok so indeed PropertyDataFetcher is broken into and because source is null it returns null thus stopping the execution.\nWhat does that teach us/me? Can I do something? is this by design? am I using GraphQL wrong?\n. @dminkovsky so you're saying I'd implement something like like DataFetcher for viewer that returns lets say Maps.newHashMap(); ??\n. @dminkovsky you're right it's not pretty, but it makes sense and works! Thank you very much!\nwe can def close this issue\n. ",
    "lelong71": "I run into the same issue and wonder why this patch has not been accepted yet.\n. Awesome! Thanks for the quick response. I'll pull the latest version and try against my use case.\n. I pulled the latest code and still run into the same issue. The issue here is that the ValuesResolver.coerceValueForInputObjectField() assumes that all fields of an input type must be specified. I made the following change and it works\njava\nprivate Object coerceValueForInputObjectField(GraphQLInputObjectType inputObjectType, \nMap<String, Object> input) {\n    Map<String, Object> result = new LinkedHashMap<>();\n    for (GraphQLInputObjectField inputField : inputObjectType.getFields()) {\n        Object inputValueForField = input.get(inputField.getName());\n        // Only set input if users explicitly specify the field\n        if (inputValueForField != null) {\n            Object value = coerceValue(inputField.getType(), inputValueForField);\n            result.put(inputField.getName(), value == null ? inputField.getDefaultValue() : value); \n        } else if (inputValueForField == null && inputField.getType() instanceof GraphQLNonNull) {\n               throw new GraphQLException(inputField.getName() + \" is a required field but doesn't have value\");\n        }\n    }\n    return result;\n}\n. I ran into the same issue and the latest pull doesn't fix. This PR https://github.com/andimarek/graphql-java/pull/80 fix both - NPE and required field not validated.\n. I confirm that this is fixed. Thanks\n. If I update ValuesResolver.coerceValueForInputObjectField() with this piece of code, it seems to work. This also solves another issue which makes it not possible some input fields optional.\njava\nprivate Object coerceValueForInputObjectField(GraphQLInputObjectType inputObjectType, \nMap<String, Object> input) {\n    Map<String, Object> result = new LinkedHashMap<>();\n    for (GraphQLInputObjectField inputField : inputObjectType.getFields()) {\n        Object inputValueForField = input.get(inputField.getName());\n        // Only set input if users explicitly specify the field\n        if (inputValueForField != null) {\n            Object value = coerceValue(inputField.getType(), inputValueForField);\n            result.put(inputField.getName(), value == null ? inputField.getDefaultValue() : value); \n        } else if (inputValueForField == null && inputField.getType() instanceof GraphQLNonNull) {\n               throw new GraphQLException(inputField.getName() + \" is a required field but doesn't have value\");\n        }\n    }\n    return result;\n}\n. PR: https://github.com/andimarek/graphql-java/pull/80\n. I confirm that this is fixed. Thanks!\n. ",
    "oembedler": "Any updates on this issue?\n. @andimarek \nwell. I'm running query to get people object data inside profiles object (but not profiles object data itself).\nI'll run few tests with data fetcher for profiles. \nthanks\n. It works with fake static fetcher for profiles field.\n@andimarek would you mind to close this issue out? Thanks.\n. SimpleExecutionStrategy only used to execute actual mutation (it can not be calculated concurrently for instance) - however all other nested fields are resolved using provided custom strategy.\nsee this\n. ",
    "eugenpp": "Duplicate #172 \n. ",
    "davidscottcohen": "Oh, editor dropped some crap we don't want, will resubmit\n. Your understanding is correct.  The unit test I included in SchemaUtilTest will fail if you undo my change to SchemaUtil (it won't get the Range type).\n. Yes, I'm using this code in a production environment, plus a corresponding production-like test environment.  No issues reported thus far.  Only difference is that I backported the code to Java 7 and removed the Guava specifically to include in graphql-java.  \nI can take a crack at Spock.  Might be a little while.  I'll let you know if I hit issues -- for my previous PR I was able to fake knowledge of Spock by copying-and-pasting.\n. Sweet!\nOn Jan 17, 2016 10:54 AM, \"Andreas Marek\" notifications@github.com wrote:\n\nThanks @cardinalraven https://github.com/cardinalraven for your awesome\nwork. I merged your PR into master. Especially for also writing docs and\nchanging the tests into spock.\nThanks!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/andimarek/graphql-java/pull/49#issuecomment-172365162\n.\n. Thanks, I just added dcohen@palantir.com to github.  Do you still get that\n\"unrecognized author\"?\n\nOn Mon, Jan 18, 2016 at 10:10 AM, Andreas Marek notifications@github.com\nwrote:\n\nJust a tip: You might wanna configure your email address ... see\nscreenshot:\n[image: screen shot 2016-01-18 at 19 08 30]\nhttps://cloud.githubusercontent.com/assets/1706744/12398924/05be7dac-be17-11e5-89a6-46b68e684897.png\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/andimarek/graphql-java/pull/49#issuecomment-172609759\n.\n. \n",
    "naveensenagari": "I saw fix for the above issue in current development jar (2015-11-15T12-15-10) . Can you please let me know when can I expect new jar version (i.e graphql-java-1.4) to consume.\nRegards,\n. ",
    "dbryand": "I actually don't even need the subscriptionType, but I'm trying to keep up my introspectionQuery that I use to generate schema.json update to date with graphql-js.\nThe problem is that the newer introspectionQuery has a query for subscriptionType { name } which thows a Validation error of type FieldUndefined: Field subscriptionType is undefined when I run it:\nquery IntrospectionQuery {\n    __schema {\n      queryType { name }\n      mutationType { name }\n      subscriptionType { name }\n...\n. ",
    "hbeaufils": "Hi,\nI had the same issue, but I confirm it's currently fixed on master.\nThanks!\n. ",
    "jasiekkrk": "Hi,\nThanks for reply. I understand how to execute query. What I`m missing is how to build graphql schema, based on introspected JSON to be able to execute queries on remote servers (from Java).\nGraphQL JS has utlis which can build such schema from json file (http://graphql.org/docs/api-reference-utilities/#buildastschema)\nRegards,\nAndrzej\n. We have scenario like this\nEnd user (browser)  uses React+ Relay+GraphQL and connects to our backend, which defines schema build using remote schema, and adds our custom fields. So we have to execute query on remote server to get the data, and mix them with custom data loaded from database.\nBrowser <---> Our graphQl server <-----> remote graphql Server\nProbably for the time being we will use node to see if it`s even possible with reference js implementation.\nThanks a lot, \nAndrzej\n. ",
    "buma": "I have some kind of code generator for java classes and enums. It also adds documentation (description) nullability and defaultValue in operations. it reads those info from javadoc. For release I need to clean it if somebody is interested.\n. Finally I have uploaded code to the Github.\nFor examples of the classes you can look at R5. Basically all of this GraphQL schema was created with this generator from classes in api folder\n. Thanks for quick fix. It works great now.\n. ",
    "sanju-sfo": "I was really glad to find the Java based server for GraphQL, though the client side became simpler with GraphQL but the complexity is pushed to the server side.\nBeing said that, it feels like it's a different flavor of xsd/xml combination, However the I also do feel that the Creating Schema directly as GraphQL object is not intiutive and readable. \nI went thru the spec to find, if there is any text based language independent way of defining the schema (similar to xsd) which can be later use to create both Pojo's as well as GraphQL object using some code generator. or just Dynamically create the the GraphQL objects in runtime thru reflection. \nVery disappinted not to see the text based defintion thru the GraphQL spec though, or may be I have missed it please let me know if I am wrong here.\n. ",
    "edsalat": "Thank you! It works\n. ",
    "nikolajosipovic": "Thanks a lot Andi\n. Hey @andimarek Thanks a lot for doing the update :+1:  and sorry I did not catch time to contribute\n. ok thanks, closing\n. ",
    "FernsPaanakker": "I didn't mean that I think that ExecutionStrategy should become part of the API. I propose that in the file ExecutionStrategy.java, in the function resolveField we change this:\n``` java\n        DataFetchingEnvironment environment = new DataFetchingEnvironment(\n                source,\n                argumentValues,\n                executionContext.getRoot(),\n                fields,\n                fieldDef.getType(),\n                parentType,\n                executionContext.getGraphQLSchema()\n        );\n```\nto this:\njava\n        DataFetchingEnvironment environment = new DataFetchingEnvironment(\n                source,\n                argumentValues,\n                executionContext,\n                fields,\n                fieldDef.getType(),\n                parentType,\n                executionContext.getGraphQLSchema()\n        );\nThat way I can access the context from the DataFetchingEnvironment in a DataFetcher and add errors. Some sample code inside a DataFetcher:\njava\n<snip>\n.dataFetcher(new DataFetcher() {\n    @Override\n    public Object get(DataFetchingEnvironment environment) {\n    if (environment.getContext() instanceof ExecutionContext) {\n        ExecutionContext context = (ExecutionContext)environment.getContext();\n        if (!\"justATest\".equalsIgnoreCase(vehicle.getNumberPlate())) {\n            DataValidationError error = new DataValidationError(\"numberPlate\",\"Invalid number plate\");\n            context.getErrors().add(error);\n        }\n    }\n<snip>\nI apologize for the whacky code inserts, but I hope the proposed change and the usage example does make things more clear.\n. @andimarek No problem, the github 'reply using email' made a mess of formatting the code. It should be better now.\n. ",
    "xuzb": "See my pull request.\n. FloatValue is implemented with a BigDecimal. So it supports single and double-precision floating point numbers.\n. Sorry for replying so late. @dminkovsky \nThe following example can lead to the exception: \nimport graphql.ExecutionResult;\nimport graphql.GraphQL;\nimport graphql.GraphQLError;\nimport graphql.schema.*;\nimport static graphql.Scalars.GraphQLLong;\nimport static graphql.schema.GraphQLArgument.newArgument;\nimport static graphql.schema.GraphQLFieldDefinition.newFieldDefinition;\nimport static graphql.schema.GraphQLObjectType.newObject;\npublic class InputTypeTest {\n    public static GraphQLArgument newInputArgument(GraphQLInputType inputType) {\n        return newArgument().name(\"input\").type(inputType).build();\n    }\n```\npublic static void main(String[] args) {\nGraphQLInputObjectType inputLongType = GraphQLInputObjectType.newInputObject()\n        .name(\"LongInput\")\n        .field(GraphQLInputObjectField.newInputObjectField().name(\"longValue\").type(GraphQLLong).build())\n        .build();\n\nGraphQLObjectType mutation = newObject().\n        name(\"mutationType\").\n        field(newFieldDefinition()\n                .name(\"testLong\")\n                .type(GraphQLLong)\n                .dataFetcher(new DataFetcher() {\n                    @Override\n                    public Object get(DataFetchingEnvironment environment) {\n                        Object input = environment.getArguments().get(\"input\");\n                        return 10;\n                    }\n                })\n                .argument(newInputArgument(inputLongType))\n                .build())\n        .build();\n\nGraphQLSchema schema = GraphQLSchema.newSchema()\n        .query(mutation)\n        .mutation(mutation)\n        .build();\n\n// Input a large long value\nExecutionResult result = new GraphQL(schema).execute(\"mutation mu { testLong (input: {longValue: \" + System.currentTimeMillis() + \"}) { longValue} }\");\nfor (GraphQLError error : result.getErrors()) {\n    System.out.println(error);\n}\n\n}\n```\n}\n. Hi, If you define the output type as a object type, it still throws exception.\n. ",
    "drkarl": "Any updates on this? I saw you added a Code of Conduct but unfortunately that doesn't serve as CLA, the lawyers wouldn't let us contribute without that :cry: \n. :+1: LGTM\n. Looks good, it's been open for a while!!\n. @dminkovsky any ETA when this will be merged in?\n. ",
    "okorz001": "I am also curious when a CLA will be available.\n. You can change your schema to accept a list instead profile(ids: [33, 44]){...}\n. Alternatively, I just realized FloatValue is always parsed into a BigDecimal, so I suppose it could just unconditionally parse IntValue into BigInteger.\nhttps://github.com/andimarek/graphql-java/blob/master/src/main/java/graphql/parser/GraphqlAntlrToLanguage.java#L327-L330\n. Yes, for GraphQLInt values, I agree that there must be an exception thrown somewhere.\nI am currently working around this by using String as input and Long as output but this asymmetry is inconvenient to clients. It is possible to use GraphQLLong as output without any issues.\nI think we should defer the error from token parsing and wait until type deserialization. Instead of retrieving the value unconditionally here, we could error out if the value is out of range.\nGraphQLInt: https://github.com/andimarek/graphql-java/blob/master/src/main/java/graphql/Scalars.java#L31-L36\nGraphQLLong: https://github.com/andimarek/graphql-java/blob/master/src/main/java/graphql/Scalars.java#L58-L66\n. I am working on proof of this, but I am still having some test failures that I must investigate.\nhttps://github.com/andimarek/graphql-java/compare/master...okorz001:allow-longs\n. I have opened #94. I would like to add negative tests to prove GraphQLInt will still throw for values greater than MAX_INT, but I am unfamiliar with both Groovy and Spock.\n. Ah, it appears BigDecimal.intValueExact was added in Java 8. I will find a backwards compatible solution for Java 6.\nhttps://docs.oracle.com/javase/8/docs/api/java/math/BigInteger.html#intValueExact--\n. I think there is a distinction here between the query grammar and the runtime types.\nThe grammar does not specify a maximum number of digits in an IntValue token:\nhttp://facebook.github.io/graphql/#sec-Int-Value\nHowever, the built-in type Int is required to be a 32-bit integer. This PR retains this behavior.\nhttp://facebook.github.io/graphql/#sec-Int\nI believe it should be possible for users to register custom scalars (which includes the provided GraphQLLong) which can be parsed from IntValue with an arbitrary number of digits.\nThe Javascript reference implementation keeps all token values as strings until they are parsed into type instances. Here is parseLiteral for IntValue:\nhttps://github.com/graphql/graphql-js/blob/master/src/type/scalars.js#L38-L46\nProof of concept:\n``` js\nvar graphql = require('graphql');\nvar longType = new graphql.GraphQLScalarType({\n  name: 'Int',\n  description: '64-bit integral numbers',\n  // TODO: Number is only 52-bit\n  serialize: Number,\n  parseValue: Number,\n  parseLiteral: function parseLiteral(ast) {\n    if (ast.kind === graphql.Kind.INT) {\n      const num = parseInt(ast.value, 10);\n      return num;\n    }\n    return null;\n  }\n});\nvar queryType = new graphql.GraphQLObjectType({\n  name: 'Query',\n  fields: function fields() {\n    return {\n      foo: {\n        type: longType,\n        args: {\n          bar: {\n            type: longType,\n            description: 'The value to return'\n          },\n        },\n        resolve: function getFoo(root, args) { return args.bar || 0 }\n      }\n    } \n  }\n});\nvar schema = new graphql.GraphQLSchema({query: queryType});\ngraphql.graphql(schema, '{foo(bar:2147483648)}').then(function(err, data) {\n  if (err) return console.error(err);\n  console.log(data);\n});\n```\n$ node index.js\n{ data: { foo: 2147483648 } }\n. Do you think we should keep the token values as string until they are parsed into types? A downside of this change is unnecessary BigInteger instances being created and discarded.\n. Invalid.\nThe schema builder can be explicitly given the set of types which can include arbitrary types that may not be otherwise found by scanning:\nhttps://github.com/andimarek/graphql-java/blob/master/src/main/java/graphql/schema/GraphQLSchema.java#L90-L95\n. See #93 and #94.\n. Sorry, I forgot to get back to you. I am using a custom execution strategy that I currently do not have permission to publish. Thanks for merging!\n. This issue should be closed now\n. instanceof?\n. Is the id not in the returned User object?\n. Personally, I think it is rather difficult to support Java 6 without automated builds in a Java 6 environment. Without automated builds, you are relying on manual detection of Java 6 incompatibilities.\n. I wonder if the issue is related to input objects? I am using enums heavily in my schema and have no issues. However, I am not using input objects at all.\n. If you are running GraphQL in a HTTP servlet, I found it very helpful to include a GraphiQL as a static asset. Then you just need a couple lines of javascript to configure its HTTP agent and to bind the react component to a full width div. If you are really lazy you can find the bundled GraphiQL on some javascript CDNs.\n. +1 for detecting illegal fields at schema creation time instead of query execution time. There is no value in declaring a field that cannot be queried.\n. I think this is a bad change.\nSection 2.9.1 explicitly marks a list as optional (list, opt) while 2.9.2 does not. Thus I believe any list is one or more, unless explicitly marked as optional.\nHowever, if you believe that all lists are implicitly optional, then there are more grammar changes to be made, e.g. \"1e\" and \"1.e\" should also be valid floats.\n. It seems this issue could be closed?. I am using this property currently.\nHow do you propose determining if the query failed because of user input or server failure? I currently do something like this:\n```\n        switch (error.getErrorType()) {\n            case InvalidSyntax:\n                // fall through\n            case ValidationError:\n                return 400;\n        default:\n            // fall through\n        case DataFetchingException:\n            // some exception inspection omitted here...\n            return 500;\n    }\n\n```\nRelated: #239 . Minor detail, but I think there's value here in clarifying that these are non-standard types, assuming it was not a happy accident that GraphQLLong was not described as \"Built-in Long\".\n. ",
    "mduarte": "I would also need a CLA to be able to contribute.\n. ",
    "kristofdepypere": "Here is the stacktrace:\njava\ngraphql.GraphQLException\n    at graphql.Scalars$5.serialize(Scalars.java:121)\n    at graphql.Scalars$5.parseValue(Scalars.java:127)\n    at graphql.execution.ValuesResolver.coerceValueForScalar(ValuesResolver.java:92)\n    at graphql.execution.ValuesResolver.coerceValue(ValuesResolver.java:68)\n    at graphql.execution.ValuesResolver.coerceValueForInputObjectField(ValuesResolver.java:84)\n    at graphql.execution.ValuesResolver.coerceValue(ValuesResolver.java:74)\n    at graphql.execution.ValuesResolver.coerceValue(ValuesResolver.java:76)\n    at graphql.execution.ValuesResolver.coerceValueForInputObjectField(ValuesResolver.java:84)\n    at graphql.execution.ValuesResolver.coerceValue(ValuesResolver.java:74)\n    at graphql.execution.ValuesResolver.coerceValue(ValuesResolver.java:76)\n    at graphql.execution.ValuesResolver.getVariableValue(ValuesResolver.java:59)\n    at graphql.execution.ValuesResolver.getVariableValues(ValuesResolver.java:16)\n    at graphql.execution.ExecutionContextBuilder.build(ExecutionContextBuilder.java:55)\n    at graphql.execution.Execution.execute(Execution.java:32)\n    at graphql.GraphQL.execute(GraphQL.java:78)\n    at graphql.GraphQL.execute(GraphQL.java:55)\nSuppose you have a mutation input object with the following schema:\njavascript\n{\n    \"kind\": \"INPUT_OBJECT\",\n    \"name\": \"AddFriend\",\n    \"description\": \"The friend mutation input\",\n    \"fields\": null,\n    \"inputFields\": [\n      {\n        \"name\": \"name\",\n        \"description\": \"The friends name\",\n        \"type\": {\n          \"kind\": \"SCALAR\",\n          \"name\": \"String\",\n          \"ofType\": null\n        },\n        \"defaultValue\": \"Jef\"\n      },\n      {\n        \"name\": \"isFriend\",\n        \"description\": \"True if friend, false otherwise\",\n        \"type\": {\n          \"kind\": \"SCALAR\",\n          \"name\": \"Boolean\",\n          \"ofType\": null\n        },\n        \"defaultValue\": \"false\"\n      }\n    ],\n    \"interfaces\": null,\n    \"enumValues\": null,\n    \"possibleTypes\": null\n}\nIt has one field name and one field isFriend which is of type boolean. This boolean is optional and has a default value.\nHowever when you do a mutation request like this:\njavascript\nmutation myFriendMutation($input: AddFriend) {\n  addFriend(input: $input) {\n    clientMutationId\n  }\n}\nAnd no boolean field in the input object, if e.g. these are the variables:\njavascript\n{\n  \"input\": {\n    \"name\": \"Emma\"\n  }\n}\nThe above will always result in the stacktrace. A string can be optional, as the coerce method checks for null, however this is not the case for booleans and I think it will also fail for long values.\nBasically the problem is also if you nest fields inside a input object. The code path when you would do a request without an input object and with a flat set of arguments, will work as that takes the null values into account and performs different logic.  'coerceValueAst(type, variableDefinition.getDefaultValue(), null);\n}' like I mentioned above.\nI don't see a reason why a field in a complex input object should be treated differently than a field on the top level passed in as a argument ?\n. Indeed. That would fix it.\nBut also looking at all other types in scalars (Int, Long, Float, ID) they will all suffer from the same problem. They can currently never be optional in a Input object\n. Seems like a good fix\n. Hi, \nCurrently we subclassed the graphql class to make the validation optional. We are thinking to disabled it on Production at least as long as our graphql is not publicly exposed. Ideally it is always enabled but with this kind of performance this seems not acceptible. \nWe have a full relay-react ui with graphql Java backend en idd we do have some Challenges and some of them need to be solved in the naar future. \nProfiling is done with jprofiler. I'll Read up on your mentions as they look interesting\n. Hi,\nActually I tried to reproduce now but couldn't see this behaviour anymore. Perhaps I chose the wrong way of profiling leading to too much overhead while instrumenting a lot of small validation calls on methods.\nI chose sampling now and the profiling results say validation doesn't take much time of the total execution time.\n. ",
    "nmn": "This is awesome. Thanks!\n. Apparently there's an error as I didn't account for the fact that Runnables can throw. I'm not sure what the solution here is. But I'll keep looking.\n. Interesting, it was announced at a conference recently. I'll look for the source, and open another PR.\n. ",
    "tinnou": "No, kudos to you for building the Java implementation!\n. Yes, null is not a valid input value but it is a valid result value for enum. \nThe test I added tried to follow the FunWithStringsSchemaFactory test strategy but in this case it might be a little confusing. Let me try to explain.\nTheLegal null value for enum test checks that the execution strategies coerce a null enum result value.\nThe stringObjectValueFetcher takes a string as source and if the source value is \"null\" it transforms it to null. All the other cases it just returns the same string. \nDoes that make sense?\n. And now..I'm confused. What does the following mean? From the spec: An enum value cannot be \u201cnull\u201d in order to avoid confusion. GraphQL does not supply a value literal to represent the concept null. \nDoes it mean an enum result value is never null and therefore has to be one and only one of the declared values?\nIf yes, ExecutionStrategy is too lenient and we probably need to change the ExecutionStrategy.completeValue to disallow null by moving completeValueForEnum above the null check\nIf not we are back to our original issue and BatchedExecutionStrategy shouldn't throw a NPE.\n@danielkwinsor: Good catch, indeed the check shouldn't be in BatchedExecutionStrategy.handlePrimitives for the reason you stated. Now if we want to be consistent with the other handleXxx methods we could probably do the null check before calling BatchedExecutionStrategy.coerce. Like so https://github.com/graphql-java/graphql-java/pull/115/commits/cd6848f0648c88903688de32149e3af2ae797ea2.\nI also simplified the test method to only showcase the enum null result value coercion. We can clearly see the regular ExecutionStrategy let null return null but not the BatchedExecutionStrategy.\nEither way, we need to make the strategies consistent.\n. @danielkwinsor Made the changes per your comment. I added additional tests in GraphQLEnumTypeTest to cover the new code.\n. It's not really the place to ask questions but rather to surface potential bugs with the library. Gitter might be what you're looking for and you will also likely get faster answers. https://gitter.im/graphql-java/graphql-java\nThat said, looking at your code snippet, it seems like you are attempting to register two instances of the same class SampleEntity. If your build() method is doing what most build methods do, it will give you a different instance every time you call it. Hence graphql-java \"detecting\" two different types with the same name.\nWhat you want to do is reuse the same SampleEntity instance, probably like:\njava\nSampleEntity sampleEntity = SampleEntity.build();\nobjectType.field(GraphQLFieldDefinition.newFieldDefinition()\n                .name(\"SerachByFieldA\")\n                .argument(GraphQLArgument.newArgument()\n                        .name(\"FieldA\")\n                        .type(Scalars.GraphQLString))\n                .type(list(sampleEntity))\n                .dataFetcher(deleteFetcher));\nobjectType.field(GraphQLFieldDefinition.newFieldDefinition()\n                .name(\"SearchByFieldB\")\n                .argument(GraphQLArgument.newArgument()\n                        .name(\"FieldB\")\n                        .type(Scalars.GraphQLString))\n                .type(list(sampleEntity))\n                .dataFetcher(UpdateFetcher));\n. The issue I reported happens when the query doesn't match the schema for variable input types.\nWith your issue, your query seems to be valid against the schema, except the passed variable type doesn't match what your query declared. i.e item.nonNullableType is null but apparently your schema might declare it as non-null.\nThis is slightly different from my issue, as the variable coercion validation doesn't happen at the same place.\nAlso, in your case, the NonNullableValueCoercedAsNullException is the expected GraphQL error to be raised, and is technically a validation error. Look at this existing test that is doing exactly what you are describing https://github.com/graphql-java/graphql-java/blob/71f6fcdcfd30cac55f00cb06f88943fe773a9c08/src/test/groovy/graphql/NullVariableCoercionTest.groovy#L12\nLast, graphql-java doesn't raise any InternalServerError so it might be the code that is calling graphql-java that is probably wrongly raising it.. Yes, it is possible, the DataFetcher interface exposes the DataFetchingEnvironment via this method https://github.com/graphql-java/graphql-java/blob/276dfc89875db8d030402e01d9ab3aae64ccc158/src/main/java/graphql/schema/DataFetcher.java#L27\nEvery time the data fetcher linked to the concepts field gets executed, you are provided with an instance of the DataFetchingEnvironment. It contains context information about the query that is being executed and other request context information. The DataFetchingEnvironment exposes the current field selection set via the method https://github.com/graphql-java/graphql-java/blob/276dfc89875db8d030402e01d9ab3aae64ccc158/src/main/java/graphql/schema/DataFetchingEnvironment.java#L121\nThe fields on the selection set from your snippet are term and definition and you can access them with this method: https://github.com/graphql-java/graphql-java/blob/fe8a5d404dc39d01334dae70c8089e0a1466781a/src/main/java/graphql/schema/DataFetchingFieldSelectionSet.java#L42\n. Thank you for approving! And no worries at all, I merged master and solved conflicts. . Just tested and prints 2018-06-03T20-03-43#9348430. \nWith the entire hash length it would be:\n2018-06-03T20-03-43#93484301d902a48eb6d5fbc8d19ba87287158766\nLooks good to me.. Shouldn't be a problem, I'll confirm tomorrow.\nBy the way, I'm already seeing some versions in Bintray already https://bintray.com/andimarek/graphql-java/graphql-java/2018-06-04T05-35-18-e5b324e and Maven seems to have a couple of versions too http://search.maven.org/#artifactdetails%7Ccom.graphql-java%7Cgraphql-java%7C2018-06-04T04-37-12%7Cjar (without the hash though), I presume you were most likely testing it. Also, Maven Repository package propagation can be slow. \nIn all, a big thank you for adding maven sync for development versions! . Sounds good. I'm all for consistency, let me submit changes shortly.. yep, on every branch since it's a patch that doesn't break compatibility.. GraphQL-java requires java 8 or above. For projects built with gradle you\ncan find the minimum version in the build.gradle file.\nThis targetCompatibility = 1.8\nOn Wed, Jul 25, 2018 at 9:00 AM themanojshukla notifications@github.com\nwrote:\n\nToday, I was doing some source code R & D on Spring Framework for\nproperties file loaders, and suddenly I started looking into the source\ncode of graphql-java .... I found in it's source code, that graphql-java\nheavily uses lambdas and streams released in Java 8, that arose a\nquestion in my mind that how can we run graphql-java on jdks lower than 8??\nI couldn't find it on documentation too.. if any please provide me some\nlinks.\nThnaks\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/1134, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABdAl5HXp6k_lcr2NRRZnq_Y6tonh-sUks5uKJYZgaJpZM4VgW-F\n.\n. That works @andimarek and I believe it also covers more sources of dispatch. Now I'm not 100% clear on the dispatch checking algorithm to be confident it won't happen again. I would need to fully go over the approach with pen and paper... Would you be able to post a stack trace and put together a small unit test that compiles? Otherwise it will be hard to help.\n\nThat said, my feeling here is you might already have registered on your schema the Address type as an output object type and you're trying to register a field on an input type of type object type Address. However, remember per the spec that all fields on a input type must be input types, scalars or enums. i.e you can't use a field of object type on an input type.\nGraphQL specification - Input Objects:\n\nA GraphQL Input Object defines a set of input fields; the input fields are either scalars, enums, or other input objects. . thanks for this!. Regarding https://github.com/graphql-java/graphql-java/wiki/How-to-back-port-a-fix-from-master-to-the-stable-branch last step: \nlabel it as \"stable fix\" \n\nI don't think I have permissions to add labels.. Sorry Andi, you are probably right, I might have written the unit test in a\nway it was not designed for. Give me some time to take a second look at\nthis, and I'll get back to you.\nOn Mon, Oct 1, 2018 at 11:25 PM Brad Baker notifications@github.com wrote:\n\n@tinnou https://github.com/tinnou\nYou can supply the dataloaderRegistry now via a supplier\nDataLoaderDispatcherInstrumentation dispatcherInstrumentation\n        = new DataLoaderDispatcherInstrumentation(() -> new DataLoaderRegistry(...));\nThis will be called per request.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/1233#issuecomment-426162636,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdAl3cLL5N22gfGG06O55teDWKcyPjVks5ugwbygaJpZM4WvdKM\n.\n. So if I understand correctly, the DataLoaderRegistry would now be supplied per request. What about DataLoader and BatchLoader? It seems that they are still reused across requests, right?\n. ok sounds good, it's definitely not the way we have been using it, so it's good that this approach makes it harder to do the wrong thing.. I tried to reproduce your issue in master, to no avail. Would you be able to write a unit test?\n\nHere is the test I wrote to try to reproduce your issue (the test passes as expected):\n```java\npackage graphql\nimport graphql.schema.DataFetcher\nimport graphql.schema.DataFetchingEnvironment\nimport spock.lang.Specification\nimport static graphql.ExecutionInput.newExecutionInput\nimport static graphql.schema.idl.RuntimeWiring.newRuntimeWiring\nimport static graphql.schema.idl.TypeRuntimeWiring.newTypeWiring\nclass Issue1431 extends Specification {\ndef \"1431 - Arguments specified on properties are not returned with correct parent with alias query\"() {\n\n    given:\n\n    def spec = \"\"\"            \n        type MilestoneConnection {\n            edges : [MilestoneEdge]\n        }\n\n        type MilestoneEdge {\n            cursor: String\n            edge: Milestone\n        }\n\n        type Project {\n            id: ID\n            milestones(id: ID): MilestoneConnection\n        }\n        type Milestone {\n            id: ID\n        }\n\n        type Query {\n            project(id: ID) : Project\n        }\n    \"\"\"\n\n    def graphQL = TestUtil.graphQL(spec, newRuntimeWiring()\n            .type(newTypeWiring(\"Query\").dataFetcher(\"project\", new DataFetcher() {\n                @Override\n                Object get(DataFetchingEnvironment environment) {\n                    return [id: environment.getArgument(\"id\")]\n                }\n            }))\n            .type(newTypeWiring(\"Project\").dataFetcher(\"milestones\", new DataFetcher() {\n                @Override\n                Object get(DataFetchingEnvironment environment) {\n                    return [edges:\n                                [[cursor: \"cursor-\" + environment.getArgument(\"id\"),\n                                 edge: [id: environment.getArgument(\"id\")]]\n                                ]\n                            ]\n                }\n            }))).build()\n\n    def query = \"\"\"\n    {\n        project1: project(id: \"Project-1\") {\n            id\n            milestones(id: \"Milestone-1\") {\n                edges {\n                    cursor\n                    edge {\n                        id\n                    }\n                }\n            }\n        }\n\n        project2: project(id: \"Project-2\") {\n            id\n            milestones(id: \"Milestone-2\") {\n                edges {\n                    cursor\n                    edge {\n                        id\n                    }\n                }\n            }\n        }\n    }\n    \"\"\"\n    def executionInput = newExecutionInput().query(query).build()\n\n    when:\n\n    def executionResult = graphQL.execute(executionInput)\n\n    then:\n\n    executionResult.errors.size() == 0\n    executionResult.data == [\n            project1: [id:'Project-1', milestones:[edges:[[cursor:'cursor-Milestone-1', edge:[id:'Milestone-1']]]]],\n            project2: [id:'Project-2', milestones:[edges:[[cursor:'cursor-Milestone-2', edge:[id:'Milestone-2']]]]]\n\n    ]\n}\n\n}\n```. Hmm, looks like there is a flaky test. Have you seen this before? I'm unable to reproduce on my local so far. I'll try further.\n```\n<==========---> 83% EXECUTING [44s]> :test > 662 tests completed> :test > Executing test ...DataLoaderPerformanceWithChainedInstrumentationTest<==========---> 83% EXECUTING [44s]> :test > 662 tests completed> :test > Executing test ...DataLoaderPerformanceWithChainedInstrumentationTestentation.dataloader.DataLoaderPerformanceWithChainedInstrumentationTest > chainedInstrumentation: 970 ensure data loader is performant for multiple field with lists FAILED\n    Condition not satisfied:\n    batchCompareDataFetchers.departmentsForShopsBatchLoaderCounter.get() == 1\n    |                        |                                     |     |\n    |                        2                                     2     false\n    graphql.execution.instrumentation.dataloader.BatchCompareDataFetchers@60f76b0\n        at graphql.execution.instrumentation.dataloader.DataLoaderPerformanceWithChainedInstrumentationTest.chainedInstrumentation: 970 ensure data loader is performant for multiple field with lists(DataLoaderPerformanceWithChainedInstrumentationTest.groovy:66)\n``. I was able to reproduce the issue by running the single methodDataLoaderPerformanceTest.970 ensure data loader is performant for multiple field with lists.`\nIt looks like the departmentsForShopsBatchLoader gets called twice with two sets of 3 shop ids: ids[shop-1, shop-2, shop-3] and ids[exshop-1, exshop-2, exshop-3]\ninstead of once with a single set of 6 shop ids: ids[shop-1, exshop-1, shop-2, exshop-2, exshop-3, shop-3].\nThere is a random sleep in BatchCompareDataFetchers.sleepSome which I believe to be the culprit. The shops batch loader are dispatched at the same time, but with this random sleep the shop results might actually be resolved at different times. When configuring the sleep time to be 1ms for the shops and 1000ms for the expensive shops, the issue happens consistently.\nMy intuition is the random sleep was introduced for the deferred scenarios and is now randomly impacting the non-deferred test case. I can put together a PR to separate these use cases if you think I'm on the right path.. Thanks for this!. oh neat I didn't know you could do that! Thanks for the merge by the way.. AbortExecutionException is being raised when the query complexity has reached the limit so in this case it should fall under GraphQLQueryException. It's also being raised if there are errors when validating the query fields.\nLet me know if I missed something.. I got one right!. I agree Instance might be confusing, so to recap we would have:\nGraphQLException\n                                                 +\n                                                 |\n              +------------------------------------------------------------------------+\n              |                                  |                                     |\n              |                                  |                                     |\n              v                                  v                                     v\n  GraphQLQueryException                 GraphQLRuntimeException               AssertInternalException\n                                                 +\n                                                 |\n                                                 |\n                              +------------------------------------+\n                              |                                    |\n                              |                                    |\n                              v                                    v\n                     GraphQLExecutionException          GraphQLSchemaException\nLegend:\n GraphQLException: top level base class to identify exception thrown by GraphQL-java in general\n GraphQLQueryException: encompasses every thing that can go wrong when attempting to execute a GraphQL request (e.g: problems with operations, variables, graphql query parsing/validation, query too complex). This exception category is used for detecting client vs server errors.\n* GraphQLRuntimeException: encompasses issues emanating from the graphql application, i.e schema building/validating/wiring and at execution time such as problems coming from the data fetcher execution or type resolution execution.\nI'm still not very fond of the GraphQLRuntimeException but I can't find a better suggestion. Thoughts?\nIf we are good with this top level hierarchy I'll go ahead and update the PR.\n. Agreed! We could even contribute back to graphql-js for this one. . Good idea, will do.. Haha thanks!. wow, you're right! I was doing it mechanically but method arguments were never mandatory. It was only to make earlier versions of IntelliJ happy. \nFrom the Spock docs:\n\n\nThe idea behind allowing method parameters is to enable better IDE support. However, recent versions of IntelliJ IDEA recognize data variables automatically, and even infer their types from the values contained in the data table.\n1.1 Doc Link. Can you elaborate on this: an unsatisfied need to let a data fetcher abort the query which we don't have today but would like\nWhat are the reasons the data fetcher would abort the query? Can you give examples? The reason I'm asking is we probably want to let our users distinguish between data fetcher internal errors and query errors.. I'm good with that. (GraphQLExecutionException shows twice in your tree, you meant GraphQLSchemaException but I got the message)\n\n\nWe could use another set of eyes on this @andimarek. What do you think?. Ok sounds good, thanks for the tip. oh great catch. The FragmentsOnCompositeType is indeed using the wrong enum value. I would do another PR to fix it but since it's fairly small, I'll fix in this one if that's ok. . ",
    "bpatters": "I can open a PR after I've generated a Unit test for it.\n. I see the TypeRefrence option for solving this.\n. When you send a ConnectionCursor to the server it needs to turn the JSON into a ConnectionCursor object in order to process it. The way Jackson handles this, without annotations which would't be appropriate here, is that it uses the no argument constructor to create the object and then set's the fields based on the properties received. Without this constructor Jackson can't turn JSON into a ConnectionCursor object without a @JsonCreator annotation on the constructor.\nAn easy test is to:\n1. update build.gradle\ntestCompile(\"com.fasterxml.jackson.core:jackson-core:${jacksonVersion}\");\n    testCompile(\"com.fasterxml.jackson.core:jackson-databind:${jacksonVersion}\");\n2. Create a Simple test that:\nObjectMapper objectMapper = new ObjectMapper()\nConnectionCursor cursor = new ConnectionCursor(\"cursorValue\");\ncursor = objectMapper.readValue(objectMapper.writeValueAsString(cursor), ConnectionCursor.class);\nThe last line will blow up because it can't construct a ConnectionCursor object.\n. Yea here's my local repository version of the class:\nhttps://github.com/bpatters/schemagen-graphql/blob/master/src/main/java/com/bretpatterson/schemagen/graphql/relay/Edge.java\nAnd my local version of Connection.java class\nhttps://github.com/bpatters/schemagen-graphql/blob/master/src/main/java/com/bretpatterson/schemagen/graphql/relay/RelayConnection.java\nThese are both Generics so that I can use reflection to generate the GraphQL schema from the definition of the object. For example in my test case I have a:\nGameDTO which has a connection to the users in the game. I need to define this as:\nConnection and then have the type propagate down through the Connection object.\nIE:\npublic class Connection<T> {\n    private List<Edge<T>> edges;\n    private PageInfo pageInfo;\n}\nthis way I can define the Connection as above, and the schemgen generator can fully qualify the GraphQL schema based on the definition of:\npublic class GameDTO {\n     Connection<UserDTO> users;\n}\nSo that the GraphQL Schema generation can fully generate the schema from the definition.\n. I'm currently working on get my schemagen-graphql production ready for a large enterprise app in which I'm hoping to use GraphQL + Relay for, but will fall back to just GraphQL if Relay works out to not be a good fit. So let me give you more information in the context of a real world usage scenario\nI've got many top level queries that return Lists of objects (And objects containing lists of other objects). For example\njava\nList<AssetDTO>  findAssets(... filtering/paging parameters);\nList<AbstractCalendarItemDTO> findCalendarItems(... filter/paging parameters);\nBoth of these endpoints I'm converting to be Connection objects. What I'd like to do is use a Single RelayConnection Object and a single Edge object, since they're really just container objects and specializations would increase maintenance with no real value. However; I also want the Schema to be strongly typed so the UI team can browse the schema (GraphIQL is great!) and know what Objects are returned and their fields etc.\nThe interface I've implemented, and still working through details as I learn more, is:\n(These are actually Wrapped in top level Objects since Relay doesn't support multiple parameters nor object parameters for top level queries, though graphql itself does).\njava\nRelayConnection<AssetDTO>  findAssets(... filtering/paging parameters);\nRelayConnection<AbstractCalendarItemDTO> findCalendarItems(... filter/paging parameters);\nWhere RelayConnection is a simple Generic container around an Edge and PageInfo object. I pass down the Type Parameter to the Edge so that the Edge's Node object can be Strongly typed also. This looks like:\n``` java\npublic class RelayConnection {\n    private List> edges;\n    private PageInfo pageInfo;\n...\n}\npublic class Edge {\n    T node;\n    ConnectionCursor cursor;\n...\n```\nThis structure allows these two objects to be used for numerous types of connections and edges while maintaining strong typing. At Schema Generation time I traverse the Generics for all method signatures and POJO object signatures to generate a strongly typed GraphQL schema.\nSo the above actually turns into the following Object Types:\nRelayConnection_AssetDTO\nEdge_AssetDTO\nRelayConnection_AbstractCalendarItem\nEdge_AbstractCalendarItem\nHere I've replaced the Generic Type with fully qualified Type names using the Pattern of Class_TypeArg1_TypeArg2_..TypeArg_N_\nI'm still in the middle stages of development, so I'm still learning the finer points of Java Types with Generics ---> GraphQL schema definitions so it's quite possible I'm missing something. I'm learning a lot everyday. I also don't strictly need these objects changed, I can use my own internal ones, however I'd like to not cause confusing between my library and this library. As this GraphQL-java library is really well done and is the foundation I'm building upon by making Schema Generation and Connection between the Schema and Implementation declarative with minimal annotations.\nLet me know if you want more information or a PR. I'm happy to contribute. Excellent product btw.\n. Checkout https://github.com/bpatters/schemagen-graphql . It handles this by allowing you to define your own type converter for these method invocations (See JacksonTypeMapper in the examples for a simple default implementation). It can also will generate schema for you.\nStill under heavy development, but aiming for production use in 3-4 weeks for a large production application. \n. LGTM\n. Spredfast, Inc - We use it in production in conjunction with schemagen-graphql.\n. Casting to Map<?, ?> before calling get implies that the Map has unknown key/value, yet you are requiring the key be a String. So you might as well cast the Map to a Map\n. PropertyDataFetcher implies to me that it can fetch via a Method or via the field directly. If your changing this to only support methods then I'd rename it to MethodDataFetcher.\nPersonally I believe PropertyDataFetcher being capable of fetching from both a method or a field is much more inline with the Generic Bean Construct and more intuitive than splitting this into two different types of data fetchers.\n. whoops I didn't quote my code in a code tag. Yes:\nreturn ((Map<String, ?>) source).get(keyName);\n. ",
    "Macroz": "OK I'll see what I come up with regards to the execution limits at least. As far as I can see, when you start exposing your API as GraphQL to 3rd parties, you will want to be able to limit the resources those queries use. Like a typical REST microservice put behind an API gateway.\n. Hi,\nI have further improved the ExecutionStrategy to limit the number of resolves that are done. This is to impose some memory constraints in addition to the time tracking done by @hannesj changes. \nHere is an example use which throws if the limit is exceeded. \nThis requires adding support to the strategy like implemented in this commit.\nWhat do you think of these changes? Are you interested in merging them if I do a pull request? And if so, do you see the counting being a useful addition or should the extension point look like something else? Are these changes something that would be useful to others so the ResourceConstrainedExecutorServiceExecutionStrategy would be included in graphql-java itself?\n. See also issue https://github.com/graphql-java/graphql-java/issues/75. ",
    "bbakerman": "The new CompletableFuture support means that is possible to more easily implement this these days\nThat each data fetcher can be implemented asynchronously by submitting it to a Executor with a timeout out.\nThe CancellationException that will occur on time out will be captured as graphql errors.\nI dont think there really is anything here for the graphql-java engine to do any more and hence I am going to close this issue. Yup if you want to write a system that can timeout ANY call (and you dont have access to all the data fetcher code and hence submit the code with timeout) then use a Instrumentation that wraps each data fetcher with your own.\nYou would create a wrapping CompletableFuture as @kaqqao said and maintain a list.  In a separate thread you would check if the completed inside your timeout period and complete them exceptionally if they dont.\nHowever I would try to attack this inside your \"service layer\" and not inside the graphql wiring.  I would have a series of \"service calls\" that give back a CF that has the above attributes if you can.  . This is now in place. Going to close this as its now a year and no response on question asked. Your example of delegating to the .get() method is how you do it. I think this issue between \"strict correctness\" and developer expectations of \"least surprise\" are going to keep catching the code out.\nI know I got caught out using GSON and pumping it into the graphql lib and so will others.\nAt a minimum we should update the readme with examples about GSON etc... \nI would argue the library should co-erce much like JS would do.  And then if you want strict Scalars you could have a graphql.strict.Scalars say.\nOr we make it strict by default and have graphql.lenient.Scalars. I am putting together a PR for a LenientNumericalScalars if we want it to be strict by default, lenient by choice say\nIf its decided to reverse this policy, the code can be easily swapped\nhttps://gist.github.com/bbakerman/9bdb1cf835735113b83e16d64547bf49 . This has now been implemented via a lenient approach. is this related to #205 ?. The PR here now adds a pretty printer for reverse decompiling a schema\nhttps://github.com/graphql-java/graphql-java/pull/386. Thanks for the contribution\nThis has been sitting unactioned for a long time and hence is being closed.  . I dont think this is an particularly unusual case.  Just more forgiving.\nIt ascends the class hierarchy and finds the first public method on a the object that comes from a public class.  It exactly matches we have today and more.\nI think we should merge this.. Look at the spec we have this section \ud83d\udc4d \nhttp://facebook.github.io/graphql/#sec-Coercing-Variable-Values\n\nIf the operation has defined any variables, then the values for those variables need to be coerced using the input coercion rules of variable\u2019s declared type.\nIf a query error is encountered during input coercion of variable values, then the operation fails without execution.\n\nThat list bit is interesting.  The current ValueResolver.isValid() doesnt pass spec muster because it executions as execution happens.\nWe would need to run a pre execution step for this to be spec compliant.\nThis would also be an opportunity for  a pluggable \"input validation\" mechanism.\nFor example $inputName might be valid in a type sense but the value might need to be less than 255 chars  say so the pluggable interface provided by consumers will allow them to input such rules and have graphql-java facilitate it.\n. Covered by pluggable field validation. Fixed. I think we can close this issue as is since its hard to see it getting implemented given the code base, its usage and age. Added a PR for this in #716 . Seems this is done. I am goig to close this one.  UNsure if its status. Now covered in the readme. re implemented here : https://github.com/graphql-java/graphql-java/pull/464. Is this related to #122 ?. There is a PR for this in progress right now.  I dont have it handy to link sorry. https://github.com/graphql-java/graphql-java/pull/387. Thanks for that stack trace\nSee http://graphql-java.readthedocs.io/en/v4/execution.html#exceptions-while-fetching-data on how you can customize your output. @dminkovsky - how keen are you to break this?\nI think we should use a Parameter pattern so we can 1) reduce the number of arguments and 2) add new parameters without method overloading and breaking API. I have found that https://github.com/skevy/graphiql-app is a great way to run GraphiQL standalone without needing to bundle it in your server application.\nSince graphql-java supports the full meta data, this tool will query in to get it and give you auto complete etc. This is not a capability that the core graphql-java library provides so I will close this issue. I think this can be closed since it changed significantly since 2016. BTW you are not far of the mark in terms of implementation.  Here is an example from Shopify.  Its much like yours in that a Promise (CompletableFuture) is return and understood by the executoinStrategy\nhttps://github.com/Shopify/graphql-batch. @dminkovsky - I take your point about it the coercion being lossless as a design goal however I would say that GraphQL seems (to me at least) very much an \"approximation\" framework that to tend towards \"just working \" rather than being very precise.  It strikes me as a framework that follows Postels Law : \n(...) implementations should follow a general principle of robustness: be conservative in what you do, be liberal in what you accept from others.\n\nhttps://en.wikipedia.org/wiki/Robustness_principle\nThis StackOverflow question outlines why GSON does what it does\nhttp://stackoverflow.com/questions/15507997/how-to-prevent-gson-from-expressing-integers-as-floats\nA specific case could use a type adapter an make all Long looking Doubles into Longs and so on\nHowever the challenge for GrapQL Java is that this approache requires all consumers to strongly know the shape of their internal Schemas.  Some consumers might, but a generic system will not.\nSince the \"variables\" will come in over the wire as JSON then with the current GraphQL API we need to get it to Map some way.  People will trip up on this depending on what framework they use to JSON --> Map.\nAnyway thanks for taking the time to consider this issue.  I agree it can go either way.\n. No longer a problem. Can I make another suggestion... it should generic as well.\n    public DataFetcher exampleFetcher() {\n    return environment -> {\n        GraphContext context = (GraphContext) environment.getContext();\n        return supplierMethodCall(context);\n    };\n}\n\nWith no generics we have the above.  The ACTUAL return type is Object so its hard to maintain.  But the shape of fetched objects are really important.\nWhere as\npublic DataFetcher<FooObject> exampleFetcher() {\n    return environment -> {\n        GraphContext context = (GraphContext) environment.getContext();\n        return supplierMethodCall(context);\n    };\n}\n\nTells a maintainer what they need to know.  It must return a FooObject and hence so must the method call etc..\nIn fact this could be applied to a number of places in GraphQL Java.  I think I may raise another issue to cover this specifically rather than hijack this isssue. fixed. This had merge conflicts and rather than mess around trying to fork/merge your branch ( on the train to work) I simply did the same simple change via https://github.com/graphql-java/graphql-java/pull/301\nThanks for the contribution. I started to look into this problem and the code as is has some serious trouble in implementing this\nThe spec says\nhttp://facebook.github.io/graphql/#sec-Errors-and-Non-Nullability\n```\nSince Non-Null type fields cannot be null, field errors are propagated to be handled by the parent field. If the parent field may be null then it resolves to null, otherwise if it is a Non-Null type, the field error is further propagated to it\u2019s parent field.\nIf all fields from the root of the request to the source of the error return Non-Null types, then the  \"data\" entry in the response should be null.\n```\nCurrently the invocation of resolveField is recursive.  It descends down into the child fields but it does NOT allow for a result such that this non null precondition can bubble up to the calling layers.\nToday is considers the parent object \"resolved\" then looks for child field objects.  But if one of the children is non null then it must make the parent null and the code today cant easily do that.  I think this will take some refactoring to come to spec\nthis test should pass\n     def \"#268 - null child field values are allowed in nullable parent type\"() {\n\n    // see https://github.com/graphql-java/graphql-java/issues/268\n\n    given:\n\n\n    GraphQLOutputType parentType = newObject()\n            .name(\"parentType\")\n            .field(newFieldDefinition().name(\"nullChild\")\n            .type(new GraphQLNonNull(GraphQLString)))\n            .field(newFieldDefinition().name(\"nonNullChild\")\n            .type(new GraphQLNonNull(GraphQLString)))\n            .build()\n\n    GraphQLSchema schema = newSchema().query(\n            newObject()\n                    .name(\"RootQueryType\")\n                    .field(newFieldDefinition()\n                    .name(\"parent\").type(parentType)\n                    .dataFetcher({ env -> new ParentTypeImplementation() })\n\n            ))\n            .build()\n\n    def query = \"\"\"\n    query { \n        parent {\n            nonNullChild\n            nullChild\n        }\n    }\n    \"\"\"\n\n    when:\n    def result = GraphQL.newGraphQL(schema).build().execute(query)\n\n    then:\n\n    result.errors.size() == 0\n    result.data[\"parent\"] == null\n}. Also another hard problem here is the AbstractExecutionStrategy uses inheritance and hence each other type level code MUST now handle this exception themselves, and it cant be done in once place. OK having struggled with a fix for this locally I think the fundamental problem is that the graphql types system we have in the library does not hold hierarchy information and the concept of non nullness on the type itself\n\nThe spec says http://facebook.github.io/graphql/#sec-Errors-and-Non-Nullability it should bubble up to the parent type\nBut we cant currently do that since the code only knows about the \"current type\" and graphqlnonnull type is a dumb simple wrapper.  \nSo given a type T (that we have unwrapped) we cant easily answer the questions\n\nIs this a non null type\nWhat is the parent type of T (and its parents etc..)\n\nI think we need to introduce a TypeInfo kind of thing for \"execution\" so we can help answer these questions\n. Yeah I used exceptions in the new code which is logically equivalent to Either types X | Y. Looking more into this specifically its the DataFetchers (aka field resolving) that represents all the time in GraphQL and where (in an operational sense) you will want to know what is happening.\nI think the graphql.execution.ExecutionContext is the place to put a ExecutionInstrumentationListener interface in and say its the responsibility of ExecutionService to call that before and after doing some code operation.\nI will see if I can get a decent PR up in place  for further code discussion.... Ok so I can IF I start a review. Now merged. Ok fair enough\nOn 10 January 2017 at 09:55, Dmitry Minkovsky notifications@github.com\nwrote:\n\n@dminkovsky commented on this pull request.\nIn src/main/java/graphql/GraphQL.java\nhttps://github.com/graphql-java/graphql-java/pull/279#pullrequestreview-15815468\n:\n\n@@ -27,6 +28,18 @@\n     private final GraphQLSchema graphQLSchema;\n     private final ExecutionStrategy queryStrategy;\n     private final ExecutionStrategy mutationStrategy;\n+    //\n+    // later PR changes will allow api consumers to provide their own id provider\n+    //\n+    // see https://github.com/graphql-java/graphql-java/pull/276 for the builder pattern\n+    // needed to make this sustainable.  But for now we will use a hard coded approach.\n+    //\n+    private final ExecutionIdProvider idProvider = new ExecutionIdProvider() {\n+        @Override\n+        public ExecutionId generate(String query, String operationName, Object context) {\n\nHow about calling this provide() since this may providers may provide an\nid not by generating it?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/279#pullrequestreview-15815468,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSSHinorct5TylRRC6g19NcNNOLyoks5rQrrQgaJpZM4LQYTj\n.\n. If you really want this then you could provide your own specialisation of \"execution strategy\" and start your transactions etc.. as you require.\n. Yeah I think your PR is sensible (not for this issue probably in DB TXN terms) but in a general sense. I agree on .internal in the package name as well as .api in the packages however that would be a major breaking change.\n\nIdeally it would be\n graphql.api.AnApiClass\n\nand\ngraphql.internal.InternalImplementationClass\n\nthe use of annotations are a way to not break current API while better documenting what is API. I would have to agree with @oexza here.  The authorisation is best done in your \"service layer\" so that given a user it comes back with \"null fields\" if they are not allowed to see it or not.\nThen your data fetchers can be as thin as possible.\nThis will also allow better \"testing\" since the service layer can be unit tested outside the GraphQL \"fetch\" code. I had a go with this PR #299  to add constraints.  It only does depth for the moment but I think it can be extended to be the place for \"field complexity\". I looked into this further.  It does today do the wrong thing but the expected result linked here is not correct I don't think\nThe spec says is should be a field called \"defautValue\" and a graphql language encoded \"String representation\".\nLooking at the reference implementation they do this\nhttps://github.com/graphql/graphql-js/blob/master/src/type/introspection.js\n resolve: inputVal => isInvalid(inputVal.defaultValue) ?\n    null :\n    print(astFromValue(inputVal.defaultValue, inputVal.type))\n\nThis takes the input default value object and the logical graphql type and reverse runs it back though AST and then an AST printer.\nWe dont yet have an AST printer\nThere is a PR : https://github.com/graphql-java/graphql-java/pull/386 that provides a runtime type printer.  But not a printer of AST values\nThe AST vales in graphql-java are represented by classes such as graphql.language.IntValue and graphql.language.StringValue etc..\nIn order to fix this to spec we would have to write a AST printer and then reimplement the astFromValue method mentioned above.\nI will see if I can get this done\n. This PR fixes this issue and adds a shed load more functionality at the same time\nhttps://github.com/graphql-java/graphql-java/pull/388/files. This is no longer needed as is. This is not ready to be merged.  So please dont merge it.  \n\nI think the ExecutionConstraints should be built BEFORE being passed into the GraphQL object\nIt probably should be an interface\nThere is some challenges around depth here.  If we use a multi threaded execution strategy and we pick apart a spec like\n\n{ \n      data {\n        a,\n        b,\n        c\n    }\n}\nand we spread a,b,c to threads each - are we at depth 1 or 4?\nPerhaps we should calculate depth BEFORE executing it.  Eg run a tree count on the Document rather than execute it.. This should be able to be closed soon. I like this idea in general by the way.  Being able to examine errors better is a real win.. This has now be implemented by another PR, using this one as the starting point for the work\nThanks for making this contribution. I am tempted to close this issue as its not been actioned and is mostly an ask for general help not a bug / feature of the library. So looking at this the spec says directives can be on a number of different objects but that this is driven by the server implementation\nDirectives are always AFTER a named thing.\nThe grammar in graphql-java (as well as the reference js implementation) has it defined as being allowed on operations\nquery Root @directive(name : \"value\")\n\nNote implicit query operations without the name on them cant have directives according to the spec grammar eg:\n{ @directive(name : \"value\") hello }\n\nis not allowed\nDirectives are allowed also on fields, fragmentSpreads and inlineFragments\n{\n   hello @directive( name : \"value\")\n}\n\nA directive is defined as\ndirective :'@' name arguments?;\n\narguments : '(' argument+ ')';\n\nargument : name ':' valueWithVariable;\n\nhence mandatory name and optional arguments but once there is brackets there MUST be arguments\nSo from above\n graphQL.execute(\"@skipme{hello}\") // CORRECT InvalidSyntaxError - not allowed here\n graphQL.execute(\"@skipme(){hello}\") // CORRECT InvalidSyntaxError - brackets need arguments\n graphQL.execute(\"{@skipme hello}\") //CORRECT InvalidSyntaxError - wrong side of the name\n graphQL.execute(\"{@skipme() hello}\") //CORRECT InvalidSyntaxError - wrong side of the name\n graphQL.execute(\"{hello @skipme}\")  ??\n graphQL.execute(\"{hello @skipme()}\") //CORRECT InvalidSyntaxError - brackets need arguments\ngraphQL.execute(\"{hello}@skipme\") ??\ngraphQL.execute(\"{hello}@skipme()\") ??\n\nSo this leaves:\ngraphQL.execute(\"{hello @skipme}\") //ValidationError, UnknownDirective\n\nThijs would be expected since the runtime does not know about @skipme.  It knows skip and include but not skipme.  Unfortunately the runtime does not allow you to add custom directives into it yet.  But thats another issue\ngraphQL.execute(\"{hello}@skipme\") //OK, result returned w/o errors\ngraphQL.execute(\"{hello}@skipme()\") //OK, result returned w/o errors\n\nThis I am not 100% sure of.  I think its invalid but it might be being ignored because its out in space.  The second is definitely invalid because brackets require arguments.\nI didnt run the last 2 per say to assert they do succeed.  If they do I thinks it because they are dangling in the syntax tree and no code cares.  It should be an error I think\n. I recently changed the grammer parsing to throw and error if there are dangling tokens beyond what  is acceptable.  This will catch this last case. Can you expand more on what your expectations are here?\nI think your are right in that the spec says \ud83d\udc4d \nhttp://facebook.github.io/graphql/#sec-Validation.Arguments\nthat arguments with a non null \"type\" should not allowed to be non null at runtime.. I think I have it wrong.  The library requires you to wrap the type in a GraphQLNonNull type first\nso \n new GraphQLNonNull(GraphQLString)\n\nThats the equivalent of the JS implementation where you use !\nrollDice(numDice: Int!, numSides: Int): [Int]\n\nSo by default the Java API assumes its not required. GraphQLNonNull should have a factory for static import so you could do\n GraphQLNonNull.nonNull(GraphQLString)\n\nand hence\n .name(\"a\")\n .type(nonNull(GraphQLString))\n\n. I am not familiar with jacoco - how does it report its coverage results?. This is a breaking change however.  Anyone consuming this in their error handling  be broken.\nSemver says this must be a 3.x change\n. #308 was probably caused in part by readability.  This makes it more fluent. This is no longer needed.  We went lenient by default instead. I agree - I think it might be better as something like\n        if (input != null) {\n            return String.valueof(input);\n        }\n        return null;\n\nThe toString() of an object is a valid identifier in the absence of any other \"interface\" to say otherwise\n. The spec is ambiguous about this\nhttp://facebook.github.io/graphql/#sec-ID\nAs in its the graphql \"server\" implementations choice.  However it does say that errors should be raised if an input is not acceptable rather than null being generated.\nI think graphql-java should be more lenient on ID types in this case. A PR for this has been merged. https://github.com/graphql-java/graphql-java/pull/511. The main graphql page gives some great examples on how to approach AuthN / AuthZ\nhttp://graphql.org/learn/authorization/\nIn general the \"context\" object you pass into the original graphql.execute() method is of your choosing and is \"not used to carry the source\".\ngraphql.schema.DataFetchingEnvironment#getContext gives you a context object you passed in and its not changed by the framework\ngraphql.schema.DataFetchingEnvironment#getSource gives you the current \"source object\" in the graph as it executes and resolves field values.\nOne thing I would add (as outlined on that graphql link) is that authN belongs in the business layer code that your graphql code calls.  Dont put it in the DataFetchers or you will make your system more brittle.. Seem good to me.  I would merge. This looks great.  thanks. @deruf - do you have follow up commits you want?  This seems worthwhile as it is?. I am going to merge this PR and follow fixes can come in another one. I have been thinking on how we can introduce this without creating a completely separate graphql.GraphQL structure.  if we can leave the current graphql.GraphQL in place and yet offer asynch behaviour then we can preserve most of the code out there already.\nWe will have to break the ExecutionStrategy SPI however because the serial ExecutionResult is used as a way to resolve fields.  But that wont work in an async and serial manner.\nI was thinking we leave graphql.GraphQL as it but add a new executeAsync() method that returns a CompletableFuture in addition to the current ones\nWe would then require ExecutionStrategy to return CompletableFuture<ExecutionResult> rather than the current plan ExecutionResult.  Since all the current serial implementations can be made to return CompletableFuture<ExecutionResult> and still be serial it works for low effort.  \nBy re-using the current API we can introduce async execution while preserving the current code investment.  Only ExecutionStrategys would be required to be changed and most people do NOT write them but rather use them\nI will try to put together a PR to demonstrate the API shape (but not the implementation) since these exist already.. Also one thing that I think needs some thought is how far deep for we make the CompletableFutures inside ExecutionResults?\nWe could end up with a CompletableFuture which contains CompletableFuture which is in fact a List of CompletableFuture and so on\nAt some point we need to decide how deep the promises should go?\nThe outer most one is the easiest.  That is a we let the consumer decide WHEN to start consuming the result.  \nHowever the inner ones are more problematic as they wont inherently be resolved promises unless they are individually unpacked.\nSo should the outer promise be a simple delaying async mechanism or should it complete the inner objects when it itself is completed?. I put up a PR to add the API interfaces that will allow a proper async implementation to be put in place.\nThe PR does NOT add an async implementation, but rather the API signature to allow it.. One important design aspect to capture is outlined here\nhttps://dev-blog.apollodata.com/graphql-explained-5844742f195e\nAnd this  important point\n\nNote: GraphQL-JS waits for all promises in a list to be resolved/rejected before it calls the next level of resolve functions.\n\nI have been looking into the reference -js code and it seems that they only descend when all the fields at one level are resolved.  I need to investigate this further since my ability to deeply read complicated node.js is...limited. So I have been looking further into this and to me it seems that the current call pattern in ExecutionStrategy is incompatible with the reference implementation BUT does conform to spec\nThe spec says\nhttp://facebook.github.io/graphql/#sec-Normal-and-Serial-Execution\n{\n  birthday {\n    month\n  }\n  address {\n    street\n  }\n}\n\nA valid GraphQL executor can resolve the four fields in whatever order it chose (however of course  birthday must be resolved before month, and address before street).\n\nSo in this sense the current code allows for spec.\nToday the execution in SimpleExecutionStrategy / ExecutionStrategy is depth first.\nIt calls \n    execute() - with a list of fields\n       resolveField() - for 1st field\n            completeValue() - for that object\n                execute() - if its an object type\n                   resolveField() - for 1st sub field\n                       completeValue() - stops at scalar\n   resolveField() - for 2nd field\n        completeValue() - for that object\n            execute() - if its an object type\n               resolveField() - for 2nd sub field\n                   completeValue() - stops at scalar\n\nAnd so on in a depth first manner.\nSo given:\n{\n  gods {\n    name\n    invitedBy {\n      name\n    }\n  }\n  wizards {\n    name\n    invitedBy {\n      name\n    }\n  }\n}\nIt will descend all of \"gods\" first right down to the sub objects before moving onto \"wizards\".\nBut when writing an async implementation the current resolveField calling  completeValue inside itself means you can do parallel operations easily.\nThe \"fetch\" inside resolveField is the part that is likely to take the most time and hence firing off multiple fetches at once is where the win is.\nThe reference implementation in JS does this.\nHowever it waits for all asynch fetchs to complete together before moving onto the complete phase.\nThis then allows for libraries such as https://github.com/facebook/dataloader to \"batch\" together requests for similar objects.\nBut with the depth first approach we have today it means that we don get a \"batch\" of possible fields in order to 1) fire off at once and 2) use delayed \"batching\" to combine the requests.\nI propose we change the structure of ExecutionStrategy so that resolveField does not call completeValue.  \nThis will allow another async implementation to make breadth first data fetch requests (in parallel) and then complete them afterwards.\nThe alternative for another implementation is to \"copy\" all the code in resolveField and take out the complete call.\nAnother way would be to refactor it into\n resolveField\n     fetchField\n     completeField\n\nand then a new implementation can re-use the fetchField and completeField methods and not the resolveField (but rather write its own)\nThe reason I am really interested in this is to make async work better AND to make it  possible for https://github.com/bbakerman/java-dataloader to work efficiently like in graphql-js\n. I have submitted a PR for capturing comments. This is now on master. As discussed on the PR, the benefits for this change do not outweigh the costs.. I don't this this offers enough real value while making the DateFetcherEnvironment fiddlier to use\n  <T> T getSource();\n\n <T> T getSource(Class<T> type);\n\nThe really end up being the same.  That is if the source is NOT a  then you will get a class cast exception at runtime.\nI can see a small argument for better \"compile time\" protection but really since you have to assigned the left hand side to some type you are all ready telling the compiler what you know (as a human) the type you want.\nSo as a programmer if I write\nFoo foo = env.getSource() \nthen I am encoding that the value is expected to be  of type Foo and if its not an exception swill be thrown latter.  So writing\nFoo foo = env.getSource(Foo.class) \ndoes not get me anything really.  It MUST be a Foo on the left hand side.  The implementation here is\npublic <T> T getSource(Class<T> type) {\n    return type.cast(source);\n  }\n\nwhich is defined as\nCasts this Class object to represent a subclass of the class represented by the specified class     \nobject. Checks that that the cast is valid, and throws a ClassCastException if it is not. If this \nmethod succeeds, it always returns a reference to this class object.\n\nSo its throws a ClasscastException - same diff and yet we had to write \nT t = env.getSource(T.class)\n\nSo more code for the same effect.\nI would not like to accept this PR.  It does not offer enough benefit and makes the API that much fiddlier to work with.\nWe want people to submit PRs so thank you for doing that, but I cannot recommend that this API change be accepted.\nThat said if you can offer strong uses cases where this really helps, please outline them\n. As much as Immutables is cool...I am not sure there is a big benefit here.  The builders are already written and we dont write many of them like you would in a more CRUD project.\nSo its diminishing returns on for this new dependency.\nI like Immutables but in this case I am not sure its warranted. Yup - the graphql-java implementation does perform JSON serialisation, since this is best done by your other library code such as Jackson / Jersey / GSON etc..\nBut it gives you a object that will serialise out as \n{ \"data\" : { .... } }. The project would accept such pull request.\n\nIf you can serialise such as Document without changing Document itself then perfect.  \nOut of interest are you planning to serialize the Documents to some persistent storage or rather pre-parse them on system startup say and keep them in memory?\nIf they go to persistent storage (eg database) then you will want to make sure the read / reconstitution of the Document tree is much faster than a query parse otherwise you wont be buying much\n. Yeah it makes sense to have them persisted from a \"blessed query\" point of view.  For example you could be draconian in your system and say \"only approved queries that we have tested and stored server side\"    That way you guard against runaway queries... since there can be none... they are all build time created.. This has been added in 4.x.  At least the ability to make your own cache. http://graphql-java.readthedocs.io/en/v4/execution.html#query-caching. I had a go at this and the dependencies are execution are a bit skew if at the moment\nI split into\ngraphql-java-api\ngraphql-java-execution\nFor example graphql.execution.ExecutionStrategy is used by graphql.GraphQL both as an interface and it will slip in implementation classes such as SimpleExecutionStrategy.\nWe can split out \"execution\" say without re-arranging these code deps.\nThis got me thinking - what are we trying to achieve with multi module?\nIs it jdk6 / jdk8 split - that is code that runs on the base jdk6 base and some new code that is jdk8?\nIf thats the case we can simplify by having one main \"api\" dep and a separate \"jdk8\" only sub module. Closing this for now as its mostly been addressed.\nI appreciate that there are some other reasons for an extra module such as breaking out relay support but in general I dont think its worth it right now and good issue hygeine says close issues you are not doing. No not really.  The problem of client side query generation is not currently handled by this library.  Its concerned with server side schema definition and execution.. @bmsantos - we dont need to do #336 in order to move to Java 8, as the multi module call was mostly about getting to Java 8\nWe need to make a release with the current code as 2.x and then upgrade to Java 8 and release a 3.0 since its a major major breaking change. You can and should return the ExecutionResult object back via Jersey\nExecutionResult er = graphQL.execute(\"{result}\")\nreturn Response.ok(er)\n\nThe spec says that the reply should have either a \"data\" attribute\n    {\n     data : {....}\n     }\nor an errors attribute\n{\n  errors : ....\n\n}\nThe ExecutionResult will do that for you. the spec says nothing about HTTP status code etc.. Its up to you to decide what you want to send back\nsee: http://facebook.github.io/graphql/#sec-Response. Can you give a code example to help with reproduction.. I think we should close this as a duplicate of #268 since its the same thing and use 268 as the fix ticket.  I have been looking at this one and its a curly one in code refactor terms. fixed on master. base updated.  Can I get a tick for this before I merge so the other dependent PRs can merege please namely https://github.com/graphql-java/graphql-java/pull/369. Can you please leave more evidence on how this issue can be reproduced.\nA query for example would help a lot\nA code snippet showing it happening would be better\nAnd if you are feeling frisky, maybe a PR to help fix it. Ahh yeah I have hit this.  Nodes can have null children.  (Should have returned empty list but here we are)\nI think a recent PR fixed this. yeah there is a fix for this.  Its contained via PRs that address #268 . I am going to close this one as a duplicate and hence use #268 as the canonical issue. My inspiration is (amongst other things) Swagger extensions\nhttp://swagger.io/specification/. Also potentially the directives (in the graphql language) could also be available.  In fact one could argue that directives might be the extra \"attributes\" to put in place\nquery myQuery() {\n     field @directive(arg1: \"value\")\n }\ncould result in that field having \"extensions\" with the directive values.. talking with @andimarek he suggested we optionally link back to the XXDefinition file and hence we will gain the directives inherently via that\nWith objects that dont come from IDL - then it would be null. The use of directives and comments and IDL mean this is basicallty redundant. Thanks for this update. If you could rebase again and fix the conflict I am happy to accept this PR. I used to think that explicit inner classes was a good thing but as I worked more on Java8 code bases it became obvious that it wasn't needed very often and Lambdas tended to be quite clear.\nSo I would tend to prefer Lambdas unless it introduces exceptionally bad clarity (which is a judgment call I appreciate). Sorry to give you a bum steer here.  We also have another PR in the works that uses the \"parameters pattern\". re: https://github.com/graphql-java/graphql-java/pull/353\nI want to get this in place before this PR as the naming of the parameters is preferred.. I think @andimarek wants you to use the default keywords because we can now that we are on Java 8.  So yes people will have to implement the old as always but they can opt into the \"default\" implementation. @kaqqao  - since we changed the parameter calling structure quite a lot this has large conflicts.\nBut I forked your fork and made a new commit which is mostly your code but with fix ups\nIts here\nhttps://github.com/graphql-java/graphql-java/pull/395. I think I will close this one and use the other one (which is essentially yours) as the way forward. Now merged. regarding \nquery common{\n\n  #this is the first comment\n\n   #this is the second comment\n\n   field #this is the trailing comment\n   field2\n\n}\nThe trailing comment is example given is ACTUALLY a  comment on field 2 not field 1.  Remember the parser is not making whitespace between comments significant\nThe one place where comments get lost is\n  query {\n        field\n        # trailing comment after last thing\n  }\n\nin this case there was never a \"node\" visited and hence no comment associated wiht it\n. >>Is this the same behaviour as in the reference impl?\nNot sure.  I cant tell from the implementation but I dont think so\nhttps://github.com/graphql/graphql-js/blob/master/src/language/lexer.js . Added the Comment type - no trailing support but with class and source location. OK I tried for a few hours to get trailing comment support in Antlr but I could not make the grammar do it.\nThe Facebook reference implementation says:\n/*\n    * Given an ast node, returns its string description based on a contiguous\n    * block full-line of comments preceding it.\n    /\nand hence I think the # comments are only for preceding nodes.. The problem is here\n                    .argument(GraphQLArgument.newArgument().name(\"attributes\").type(new GraphQLList(attributeListObjectType)).build())\nGraphQLArgument types MUST be input types.  However you have defined attributeListObjectType as\n        final GraphQLObjectType attributeListObjectType = GraphQLObjectType.newObject().name(\"attributes\").description(\"attribute\")\n            .field(newFieldDefinition().type(GraphQLString).name(\"key\").build())\n            .field(newFieldDefinition().type(GraphQLString).name(\"value\").build()).build();\n\nwhich is clearly an output type.\nAlso you have confused the system some what by having 2 types named with the same name. \n GraphQLInputObjectType.newInputObject().name(\"attributes\")...\n GraphQLObjectType.newObject().name(\"attributes\")...\n\nThe spec say\nhttp://facebook.github.io/graphql/#sec-Type-System\n\nAll types within a GraphQL schema must have unique names. No two provided types may have the same name. No provided type may have a name which conflicts with any built in types (including Scalar and Introspection types).\n\nSo this is an invalid set of types.. I hope this helps. The cause is because type names in graphql MUST be unique.  However you have 2 objects with the same name but different types\nGraphQLInputObjectType otherDetailsInputObjectType = \nGraphQLInputObjectType.newInputObject()\n.name(\"otherdetails\")\n.field(GraphQLInputObjectField.newInputObjectField().type(GraphQLString).name(\"key\").build())\n.field(GraphQLInputObjectField.newInputObjectField().type(GraphQLString).name(\"detail\").build()).build();\n\nGraphQLObjectType otherDetailsObjectType = GraphQLObjectType.newObject()\n.name(\"otherdetails\")\n.field(newFieldDefinition().type(GraphQLString).name(\"key\").build())\n.field(newFieldDefinition().type(GraphQLString).name(\"detail\").build())\n.build();\n\nThe type reference resolving at the end runs the map of all types by name and clashes on the name.\nThe base library probably should have a check BEFORE this stage so we can give a better  error message. The spec says\n All types within a GraphQL schema must have unique names. No two provided types may have \n the same name. No provided type may have a name which conflicts with any built in types \n (including Scalar and Introspection types).\n\nSo you can have the same names.. Yeah I created a PR to better adddress this early\nhttps://github.com/graphql-java/graphql-java/pull/390. One other concern I had was around query proxiying.\nImagine you have this query\n  query {\n         handledByGraphqlProxyServer1 {\n                   name\n                   address {\n                       street\n                       postcode\n                  }\n                  age\n        }\n       handledByGraphqlProxyServer2 {\n                 height\n                 weight\n      }\n}\n\nNow imagine the backing data fetcher of handledByGraphqlProxyServer1 is in fact going to call out to a remote graphql server and pass on the inner query part\neg: effectively\n query {\n      name\n      address {\n             street\n             postcode\n      }\n      age\n}\n\nSo how could we implement this?  I dont think today we can.\nBecause the selection set (including deeply beyond this objecy) is available to the data fetcher.\n. I looked further into this issue and I think this is available now\n@apottere added https://github.com/graphql-java/graphql-java/pull/392\nI confirmed this locally using this little wrapper class\n class DataFetcherProxy implements DataFetcher {\n    final DataFetcher delegate\n\n    DataFetcherProxy(DataFetcher delegate) {\n        this.delegate = delegate\n    }\n\n    @Override\n    Object get(DataFetchingEnvironment environment) {\n        String fields = printFields(environment.getFields())\n        String fragments = printFragments(environment.getFragmentsByName())\n        System.out.printf(\"\\n\\nfields :\\n %s\",fields)\n        System.out.printf(\"\\nfragments :\\n %s\",fragments)\n        return delegate.get(environment)\n    }\n\n    String printFragments(Map<String, FragmentDefinition> fragmentDefinitionMap) {\n        return fragmentDefinitionMap.values().stream().map({ node -> AstPrinter.printAst(node) }).collect(Collectors.joining(\"\\n\"))\n    }\n\n    String printFields(List<Field> fields) {\n        return fields.stream().map({ f -> AstPrinter.printAst(f) }).collect(Collectors.joining(\"\\n\"))\n    }\n}\n\nI put it over the starwars schema like this : \nquery UseFragment {\n        luke: human(id: \"1000\") {\n            ...HumanFragment\n            homePlanet\n        }\n        leia: human(id: \"1003\") {\n            ...HumanFragment\n            appearsIn\n        }\n    }\n    fragment HumanFragment on Human {\n        name\n        ...FriendsAndFriendsFragment\n\n    }\n\n    fragment FriendsAndFriendsFragment on Character {\n        friends {\n            name \n            friends {\n                name\n            }\n       }\n    }\n\nThe DataFetchingEnvironment now has the selection set via fields and fragments.  You would need to combine them to synthesize a pure list of fields.\nThe system output is given below\nields :\n    luke: human(id: \"1000\") {\n    ...HumanFragment\n    homePlanet\n    }\n    fragments :\n    fragment HumanFragment on Human {\n    name\n    ...FriendsAndFriendsFragment\n    }\n    fragment FriendsAndFriendsFragment on Character {\n    friends {\n        name\n        friends {\n        name\n        }\n    }\n    }\n\n    fields :\n    friends {\n    name\n    friends {\n        name\n    }\n    }\n    fragments :\n    fragment HumanFragment on Human {\n    name\n    ...FriendsAndFriendsFragment\n    }\n    fragment FriendsAndFriendsFragment on Character {\n    friends {\n        name\n        friends {\n        name\n        }\n    }\n    }\n\n    fields :\n    leia: human(id: \"1003\") {\n    ...HumanFragment\n    appearsIn\n    }\n    fragments :\n    fragment HumanFragment on Human {\n    name\n    ...FriendsAndFriendsFragment\n    }\n    fragment FriendsAndFriendsFragment on Character {\n    friends {\n        name\n        friends {\n        name\n        }\n    }\n    }\n\n    fields :\n    friends {\n    name\n    friends {\n        name\n    }\n    }\n    fragments :\n    fragment HumanFragment on Human {\n    name\n    ...FriendsAndFriendsFragment\n    }\n    fragment FriendsAndFriendsFragment on Character {\n    friends {\n        name\n        friends {\n        name\n        }\n    }\n    }\n\nNotice how the fields are calculated as we go down but the fragments are global in the query.  This is defined in the grammar\ndocument : definition+;\n\ndefinition:\noperationDefinition |\nfragmentDefinition |\ntypeSystemDefinition\n;\n\nfragmentDefinition : 'fragment' fragmentName typeCondition directives? selectionSet;\n\nSo they will always be \"global\" and need replacing as your data fetcher executes.\nYou could nominally use FieldCollector but it requires ExecutionContext which you dont have\n        Map<String, List<Field>> subFields = new LinkedHashMap<>();\n        List<String> visitedFragments = new ArrayList<>();\n        for (Field field : fields) {\n              if (field.getSelectionSet() == null) continue;\n            fieldCollector.collectFields(executionContext, resolvedType, field.getSelectionSet(), visitedFragments, subFields);\n        }\n\nPerhaps we should fix DataFetchingEnvironement so it has the executionContext and hence can call fieldCollector\n. > Thinking of FieldCollector, perhaps it can be refactored a little to have methods that allow collecting based on fragment definitions only (when directives had already been processed) so that it can be used from within DataFetcher?\nCan you give examples of this.  Having the specific use cases allows for unit tests to be more easily written. Thanks for the idea.  I have implemented it in the way you suggested. In essence you need to have a type that takes arguments and a data fetcher that causes an mutation to you data store via jpa.\nI am not going to go into how to make a JPA update.  How you wire your mutating data fetchers together is up to you.\nI realised the data readme is sparse in terms of mutation examples and hence I have expanded it\nhttps://github.com/graphql-java/graphql-java/pull/394\nnew DataFetcher() {\n        @Override\n        public Review get(DataFetchingEnvironment environment) {\n            Episode episode = environment.getArgument(\"episode\");\n            ReviewInput review = environment.getArgument(\"review\");\n\n            // make a call to your store to mutate your database\n            Review updatedReview = reviewStore().update(episode, review);\n\n            // this returns a new view of the data\n            return updatedReview;\n        }\n    }\n\nIn the example above you need to get your JPA store and make updates based in input arguments. One other thing on this PR.   it brings the Java implementation inline with the reference JS one because the JS one returns  a Promise of a ExecutionResult and so does this (CompletableFure is the Java promise). This is the approach we will take with async support in graphql-java 4.0\n\n\nmake it return a promise aka a CompletionStage - it will still be sync under the covers because all execution strategies are sync\n\n\nthen add a more complete AsyncExecutionStrategy for people to use.  This will be a promise based on and not a reactive stream based one\n\n\nallow people to add their own which might well be a promise to a reactive stream say\n\n\nwhen Java 9 comes out, consider the new standardized reactive stream support then.  This might probably involve a graphql-java 5.x\n\n\n. to run tests in gradle just do\n./gradlew clean build\nThis will build and run all the tests.\nI personally use IDEA and run the tests from inside the project.. Ok I looked into this issue.  There is a way to do what you want but the method is perhaps hidden from you\nI created https://github.com/graphql-java/graphql-java/pull/393 to improve the documentation\nYou need to use this format\nnewUnionType()\n    .name(\"Pet\")\n    .possibleType(GraphQLObjectType.reference(\"Cat\"))\n    .possibleType(DogType)\n\nThis creates a reference that IS a GraphQLObjectType and also a TypeReference. So in implementation terms I would accept this PR\nBut the readme examples I dont want to include.\nA lambda data fetcher is efficient for some one who truly groks the programming model.\nBut the README.md examples (which come from that readme.java) are there to be explicit in showing the code\n DataFetcher<Foo> fooDataFetcher = new DataFetcher<Foo>() {\n         @Override\n         public Foo get(DataFetchingEnvironment environment) {\n             // environment.getSource() is the value of the surrounding\n             // object. In this case described by objectType\n             Foo value = perhapsFromDatabase(); // Perhaps getting from a DB or whatever\n             return value;\n         }\n\nvs\n    DataFetcher<Foo> fooDataFetcher = environment -> {\n         // environment.getSource() is the value of the surrounding\n         // object. In this case described by objectType\n         Foo value = perhapsFromDatabase(); // Perhaps getting from a DB or whatever\n         return value;\n      };\n\nThe second case does not tell you the DateFetchingEnvironment etc...\nCan you please take out the lambdas from example code please for this PR. This addresses #209 as well fyi. #373 is the issue (plus others). Are you looking to create a fix as well or just report a bug via a failing test. This is a re-implementation of https://github.com/graphql-java/graphql-java/pull/369. I think you should update the README.md and the ReadmeExamples.java to explain this decision.\nThe original update I made was to stop people failing into the trap of how to type reference.. So are we happy to merge this?. @kaqqao - this helps solve your selection problem.  I think all the parts are now in place. >  Basically, I was thinking it could be created once per execution (with all variables and fragment set) and passed into every DatafetchingEnvironment. \nThats brilliant - yes that what we should do.  Have an API wrapper for field collector and leave all the plumbing to the internals.. OK so I have created a DataFetcherSelectionSet interface so we can hide the details of how to get the selection set of fields from consumers.\nI used a supplier interface for DataFetchingFieldSelectionSet so that it can be lazy.  If you dont want the \"selection set\" of fields then it wont evaluate them.. Its a minor breaking change in that I refactored FieldCollector.  Fiven that we dont expect consumers to consume FieldCollector its debtateable.. My problems with the specific branch is that if some one works on \"branch A\" to add Foo support they really should document it as they go.  But now they need to go to another branch to make the documentation.\nAlso the ability to have \"compileable\" readme examples is low with this approach since they need to be maintained across 2 branches. Yeah maybe having a \"how to use graphql\" .md file would be more easy to manage from a version point of view.  The current system would always stay stable.  . This is now in master and will be released in 3.0. Naming is hard.\nI would use @Internal rather than @InternalApi\nAlso I think we should consider @ExperimentalApi and ExperimentalSpi.  This allows you to stage new code without the super strong commitment.\n. Yeah I think you put them on the class and then IF you want to make an exemption, you put that into the method.\nThe typical ones will be constructors.  By making them @internal you allow them to be expanded over time without breaking API.  The builders are how people should construct them and hence we can default values there etc... This is now in place. Fair enough I guess.  I just figured that the other tests of the checks in general covered it.  For example there is no test that \"mutations\" get covered and subscription is just another ObjectType say.\nI have  this in place\n\nDo you need more access?. Oooh nice one. No its not spec - other than directives are in the spec to allow customisation by an engine.\nThe use of a \"data fetcher factory\" therefore allows you to look at the environment (from IDL from or from whatever takes your fancy) and allows you to switch in new DataFetchers rather than pure static wiring.\nI have the use case in mind of using IDL directives to allow Schema specifiers to \"specify\" what they want perhaps by class name fieldX : String @dataFetcher(dataFetcher : \"com.company.SecurityEnforcingDataFecter\")\n. This could go into 4.x but its an extension of the IDL work that comes in 3.x. Interesting that Byron as proposed what we have done (nearly once we get schema gen to transfer the node def.  which I meant to do but didnt)\n\n...A simpler and more general solution would be to refer to the entire AST node associated with each definition when built with buildASTSchema. That would still allow access to directives for tooling (type.astNode.directives) but would also allow access to the rest of the AST . More than happy with the removal of the \"smooshed\" definition. Yup - recently added\n\nSee : https://github.com/graphql-java/graphql-java/issues/377\nIts not released yet but 3.0 is coming soon-ish. See : https://github.com/graphql-java/graphql-java/blob/master/src/test/groovy/graphql/schema/DataFetcherSelectionTest.groovy\nThis use the new IDL support to \"print the current field selection including sub felds\" and that could be used to send it on to a proxy. It was not possible before to call FieldCollector via API.  And then there was no IDL print support in 2.4 either to allow you to reverse engineer a parsed Document back into text format.\nThese have been added in 3.0 plus a bunch of other goodies\nThe future readme has more info\nhttps://github.com/graphql-java/graphql-java/blob/master/src/test/groovy/graphql/schema/DataFetcherSelectionTest.groovy. I am not sure about this one.\nImagine a larger team, you put together a \"framework\" of runtime fetchers etc..\nThen you also create a series of graphql end points with different schemas.\nYou combine them at runtime.  So sometimes for a given schema endpoint you MAY not have a field for a fetcher.  \nIts not precise but no harm is done.\nIf we enforce all fetchers are used, then loosely coupled schema def -> runtime wiring is no longer possible. I think we should close this issue.  I dont think we should make this change.\nMy reasoning is again to allow a loose coupling between runtime wiring and schema.  I should be able to join together a IDL type specification to a RuntimeWiring that is larger in data fetchers than there is fields.\nI agree it can allow things to slip under the covers (eg I though I was using DF X but I have no field for it) BUT it benefits are that you can mix together more complicated schemas -> wirings where sometimes not all data fetchers get used.\nI advocate strongly that we dont do this.  Its overly precise and its costs very little in effect (eg a DF that is not used) but prevents a mix and match strategy when building your schemas + runtime wiring. java.util.Optional would indeed do it\nbut we would have to change the current behaviour from \nT argValue = environment.getArgument(\"arg\")\n\nto\nOptional argValue = environment.getArgument(\"arg\")\nThis would break all existing code.  Its a tricky one  . Implemented via PR #452 . BTW we can split this PR into 2 - the ability to specifynull as a literal value and the \"absence of null\" at runtime.\nThe first has some value just in being able to do literal specifications\nThe absence of null is valuable for the mutation reasons. When I started this PR I first had the idea of a special sentinal value eg: GraphQLNullValue.NULL\nBut while explicit, its really Java unnatural.  Its easier in javaScript since they have 'undefined' and 'null' values for this use case (sort of).\nI was thinking about it from the consumers point of view and thats the DataFetcher\n        Object get(DataFetchingEnvironment environment) {\n               Map<String,Object> args = environment.getArguments()\n               Map<String,Object> argObject = arg.get(\"ComplexThing\");\n\n         }\n\nThe complex object is going to be a Map and hence trying to work out if \"bar\" is present or not can be done via argObject.contains(\"subFIeld\")\n if (argObject.contains(\"subField\") {\n      updateSubField(argObject.get(\"subField\"))\n\nThe proposed code would then be more like\n Object subValue  = argObject.get(\"subField\");\n if (! GraphQLNullValue.NULL.equals(subValue))\n      updateWithSubField(subValue)\n\nIt just feels a lot less expected.  Its precise but its less natural.\nEither way the change is a behaviour breaking change since existing code cant know that GraphQLNullValue.NULL is possible or that null handling has changed.. Have a look at : https://github.com/facebook/graphql/blob/master/spec/Section%203%20--%20Type%20System.md\nAnd the Input Coercion part of it : \n\nFor each field of the input object type, if the original value has an entry with the same name, and the value at that entry is a literal value or a variable which was provided a runtime value, an entry is added to the result with the name of the field.\n\nThe value of that entry in the result is the outcome of input coercing the original entry value according to the input coercion rules of the type declared by the input field.\nFollowing are examples of Input Object coercion for the type:\ninput ExampleInputObject {\n  a: String\n  b: Int!\n}\nOriginal Value            Variables Coerced Value\n{ a: \"abc\", b: 123 }   {null}           { a: \"abc\", b: 123 }\n{ a: 123, b: \"123\" }     {null}         { a: \"123\", b: 123 }\n{ a: \"abc\" }             {null}         Error: Missing required field {b}\n{ a: \"abc\", b: null }    {null}         Error: {b} must be non-null.\n{ a: null, b: 1 }            {null}         { a: null, b: 1 }\n{ b: $var }          { var: 123 }   { b: 123 }\n{ b: $var }          {}                 Error: Missing required field {b}.\n{ b: $var }          { var: null }  Error: {b} must be non-null.\n{ a: $var, b: 1 }    { var: null }  { a: null, b: 1 }\n{ a: $var, b: 1 }    {}                 { b: 1 }\n\nNote: there is a semantic difference between the input value explicitly declaring an input field's value as the value {null} vs having not declared the input field at all.\n\nSo I think for 4.0 it would be right thing to do to move towards \"spec\" and use the absence of the field in the map to indicate that absence and presence in the map (with possible null value) to indicate present with some value (which maybe null or not)\nUsing a sentinel GraphqlNullValue is a mistake I think.  Saving this change for 4.0 say because of the breaking runtime behavior\n. BTW - there is minor runtime breaking behaviour in adding 'null literal' support\nTechnically foo(arg : null) will today be parsed as a enum and hence we when add the null keyword support that will no longer work./\nI think this is really minor since it would require some one to be accepting a enum and the word null being one of the enum values.  I think we can ignore that as being bad. Damn I have buggered this branch right up. I am going to throw it away and start again...with a TDD approach.\nAnd I have the right PR this time. And now I see that tests have already been added....  missed that sorry.\nAnyway I am starting a new branch either way to make sure I am 3.0 clean. Yeah I asked for this in another PR.  Thanks a lot. Ahhh nice catch.  Hmmm have to look into this.. The new more strict Scalar code will help with this but what about anyone writing their own Scalar implementation.\nI think we should do belts and braces.\nWe should fix the main Scalar implementations AND check for null after co-ercion. In this case you can get away without making a lot of calls.\nSome graphql \"graphs\" force a lot of calls and hence require sophisticated techniques such as DataLoader to alleivite this.  \nBut in your example here you can make your code MUCH more efficient and its nothing to do with graphql and everything to do with SQL\n```\nList allAccounts = accountRepository.findAll();\n        return allAccounts.stream().map(a -> {\n                List respondents = respondentRepository.findAll();\n            List<Membership> memberships = membershipRepository.findByAccountId(a.getId());\n\n```\nThe problem is you are doing n+1 SQL calls.  For every account do an SQL to get all respondents\n(over and over again - thats really wasteful) and then membership information.\nI think you need to revist your \"database design.\nYou want to use SQL joins and get accounts joined to membership and respondants.  Let SQL to all the heavy lifting for you in a lot less calls (maybe even 1)\nI dont know the ins and out of your database design but SQL joins are what you want here to reduce the dreaded N+1 performance problems.\nAnd in this case its not graphql induced.\nWhere graphql can get hairy is graphs all the way down\neg\nquery socialNetwork {\n    name\n    friends {\n       name \n       friends {\n         name\n      }\n }\n\nThe above is find a person and their friends and their friends friends.  This is hairy.. In terms of pagination in graphql, this is your responsibility as a schema designer.\nThe list fields you give back can contain \"pagination\" arguments and pagination \"info\"\nThe Relay specification has pagination built in : https://facebook.github.io/relay/docs/graphql-connections.html\nThis also outlines some ways to do pagination : http://graphql.org/learn/pagination/\nThe point is pagination is not a graphql engine thing - its the schema designers repsonsibility. Also have a look at idea behind DataLoader : https://github.com/facebook/dataloader\nIt allows for combining common look ups into less calls (if it suits your app)\nThere is a java implementation : https://github.com/engagingspaces/vertx-dataloader\nI havent used the above one however. I will link you to our documentation on mutations\nhttp://graphql-java.readthedocs.io/en/latest/execution.html#mutations\nIn short you need to write a DataFetcher that implements your desired mutation. So this clearly compiles on the Travis build, otherwise we would not have released.\nJVM 1.8.0_31\n\nWe have had trouble at my company with generics and early versions of Java 1.8.  I suggest updating your javac. Currently there is no way to inspect a Java enum as an input to an IDL\nvalues.\nThe current code simple takes the IDL enum and makes the anme and value the\nsame thing.\nWe could have a EnumFactory construct that would give make a call to get\nvalues for a named enum and it would return object values\n. Yes I meant an EnumFactory at the RuntimeWiring sense.\n. Are we happy to merge this?. Actually I added one more test case for the one you specifically mentioned\nThat is when the input var contains more fields than defined.  It will now throw an exception for this. Fair enough lets do it.  Its easy enough.  Have to do it on schema gen and de compile. If we do this I think we should use exception class hierarchy as instructions.\nIf you accidentally throw NullPointerException then I doubt you meant it.\nIf you throw a well known StopQueryExecutionException there is no doubt say on what do in the framework. Hey this is done yeah... via the graphql.execution.AbortExecutionException no?. I had  a quick look into this.  With the use of CompletableFuture its kinda tricky.\nThe AsyncES code tends to fire of N futures (per field) and wait for them all the complete but handle any exception from that in aggregate.\nWhile this \"independent\" execution, you can have 1 field / code path stop execution via say an AbortExecutionException but you can easily stop all the other futures that are nominally running at the same time.\n@kaqqao - do you want the other fields in your partial result?  Perhaps is it enough to ask whether any one (or more) future has been completed and grab their results but otherwise skip anything that is still running??. This is now in place yeah?. and the answer is yes we should.  PR in place. Added some extra checks around field uniqueness to this PR as well as directive uniqueness and arg uniqueness. So the spec says that if null is present and there are no errors then that is the result of the query\nSo graphql JSON encoder code is responsible for setting it up to encode nulls if it wants to follow spec. Because the graphql-java library BY design does not want to get into the game of build JSON serialisation strategies\nWould we would need one for Jackson / GSON / JSONP / Java 9 / SimpleJson ..... http://facebook.github.io/graphql/#sec-Type-System\n\nAll types within a GraphQL schema must have unique names. No two provided types may have the same name. No provided type may have a name which conflicts with any built in types (including Scalar and Introspection types).. I took this PR and added the \"parameter pattern\" to implement it\n\nsee: https://github.com/graphql-java/graphql-java/pull/493\nClosing this PR\n. Clever.  I havent see that before for cloning \"builder\" based objects.  That cools!. Closing and re-implenting via https://github.com/graphql-java/graphql-java/pull/552. I havent looked that code implementation yet but I think we SHOULD break the API.\nIt will put is inline with the reference implementation which gives back a Promise aka a CompleteableFuture\nI have a PR for that to show it - but its not a true asynch ACTUAL implementation but rather just breaking API shape. This is the PR in question\nhttps://github.com/graphql-java/graphql-java/pull/380\nI think strongly that we should have a Promise based return value before we add an actual asynch execution strategy. Having this code allow me to better examine our introspection code and make sure it works well with tools such as graphiql.\nSo it's also handy for testing a bit more end to end.. Since it was only a nitpick I would rather get this in an do a 2nd PR to fix up the nitpick. yup that seems to be missing the extra field statement\n(which is why I like IDL for defining Schema as an aside). This is in place on master. @bsideup - where would you put the transform() method\non DataFetchingEvironment or the DataFetchingEvironmentImpl?\nI thought about this and it logically belongs on the interface BUT the concrete builder is on the DataFetchingEvironmentImpl class.\nWhere would you put the transform so its meaningful?\nI kind of did the equivalent via this\nDataFetchingEnvironment singleEnv = DataFetchingEnvironmentImpl.newDataFetchingEnvironment(environment)\n                    .source(source)\n                    .build();. I guess we could put it on DataFetchingEnvironmentImpl but that would require casting first which is weird\n DataFetchingEnvironment env\n DataFetchingEnvironment newEnv = ((DataFetchingEnvironmentImpl) env).transform( bld -> bld.source(newSource))\n\nif we put it on the interface then the builder (from the impl) will become part of the Interface\n```\n@PublicApi\npublic interface DataFetchingEnvironment {\npublic static DataFetchingEnvironmentImpl.Builder newBuilder() {\n    ...\n}\n\n```\nThats also weird.\nI guess I could make Builder part of the interface itself. resolvers are called DateFetchers in graphl-java\nSee http://graphql-java.readthedocs.io/en/latest/schema.html for examples\n@dataFetcher is not inherently supported by the base graphql-java engine.\nYou can however write a WiringFactory that would interpret that and create data fetchers based directive.  The WiringFactory is passed the \"field definition\" which includes directives.\nAgain see that example for a custom WiringFactory. ```\nWiringFactory dynamicWiringFactory = new WiringFactory() {\n            @Override\n            public boolean providesTypeResolver(TypeDefinitionRegistry registry, InterfaceTypeDefinition definition) {\n                return getDirective(definition,\"specialMarker\") != null;\n            }\n        @Override\n        public boolean providesTypeResolver(TypeDefinitionRegistry registry, UnionTypeDefinition definition) {\n            return getDirective(definition, \"specialMarker\") != null;\n        }\n\n        @Override\n        public TypeResolver getTypeResolver(TypeDefinitionRegistry registry, InterfaceTypeDefinition definition) {\n            Directive directive = getDirective(definition, \"specialMarker\");\n            return createTypeResolver(definition, directive);\n        }\n\n        @Override\n        public TypeResolver getTypeResolver(TypeDefinitionRegistry registry, UnionTypeDefinition definition) {\n            Directive directive  = getDirective(definition,\"specialMarker\");\n            return createTypeResolver(definition,directive);\n        }\n\n        @Override\n        public boolean providesDataFetcher(TypeDefinitionRegistry registry, FieldDefinition definition) {\n            return getDirective(definition,\"dataFetcher\") != null;\n        }\n\n        @Override\n        public DataFetcher getDataFetcher(TypeDefinitionRegistry registry, FieldDefinition definition) {\n            Directive directive = getDirective(definition, \"dataFetcher\");\n            return createDataFetcher(definition,directive);\n        }\n    };\n    return RuntimeWiring.newRuntimeWiring()\n            .wiringFactory(dynamicWiringFactory).build();\n\n```\nThis is a sample example wiring factory.  It looks for a special directive say and adjusts behaviour on that\nYou can then do this say (this is an example)\n     private Directive getDirective(FieldDefinition fieldDefintion, String type) {\n    return fieldDefintion.getDirectives().stream().filter(d -> d.getName().equals(type)).findFirst().get();\n}\n\nand then\n     private DataFetcher createDataFetcher(FieldDefinition definition, Directive directive) throws ClassNotFoundException, IllegalAccessException, InstantiationException {\n    Optional<String> dataFetcherClass = directive.getArguments().stream().filter(argument -> argument.getName().equals(\"dataFetcherClass\")).map(arg -> ((StringValue) arg.getValue()).getValue()).findFirst();\n    if (dataFetcherClass.isPresent()) {\n        Class<DataFetcher> dfClass = (Class<DataFetcher>) Class.forName(dataFetcherClass.get());\n        return dfClass.newInstance();\n    }\n    return new PropertyDataFetcher(definition.getName());\n}\n\nThis of course is just example code\n. Done. Thanks for reporting this problem.\nA complete PR https://github.com/graphql-java/graphql-java/pull/470 is in place to add this as well as Ast support etc... Closing as duplicate of https://github.com/graphql-java/graphql-java/issues/468. The class is not really designed to be JSON instantiated.\nIt has a builder and is designed to be called more \"deliberately\".  The \"context\" and \"root\" object can never be set via a JSON object say\nThis would be nicer\n    ExecutionInput executionInput = ExecutionInput.newExecutionInput()\n            .query(requestString)\n            .operationName(operationName)\n            .context(context)\n            .root(context)\n            .variables(arguments)\n            .build();\n\nI will agree that the names of the methods should follow spec naming.\n    ExecutionInput executionInput = ExecutionInput.newExecutionInput()\n            .requestString(requestString)\n            .operationName(operationName)\n            .context(context)\n            .root(context) // This we are doing do be backwards compatible\n            .arguments(arguments)\n            .build();\n\nI would suggest you create a JSON oriented class that can be instantiated automatically that then feeds into actual builder\n. The naming has been changed to align with spec.  Its still not designed to be JSON instatiated directly. So one of the big aspects of this refactor is changing the static builder method to new Builder\n FieldCollectorParameters collectorParameters = newParameters(executionContext.getGraphQLSchema(),operationRootType)\nFieldCollectorParameters collectorParameters = new FieldCollectorParameters.Builder()\n\nThe static method pattern is used everywhere and deliberately.\nI am hesitant to accept this PR in this format since static method approach is where the code base is heading\nThere are some great little bits in this PR say around the execute setup but with all the new Builder code I dont think we should accept this.\n. Yes this is correct.  There is a PR in the works for this : https://github.com/graphql-java/graphql-java/pull/499\nThanks for reporting\nI am closing this as a duplicate of #498 . I tried to fix this up as a maintainer but I cant push upstream to the originating git\nMy git fu is not super strong\nI have created https://github.com/graphql-java/graphql-java/pull/524 which is this with the conflcts resolved. Actually looking back at it..its not a breaking change.  the ExecutionInput is new to this release and additive and has not yet been released.\nSo I changed requestString to query and arguments to variables in line with the spec.\nSince its not been released there is no break.. Sorry that other one is an accident.  Not sure how to delete #506 ... OK renamed it to getFieldDefinition. Now has a getByName() map  method. Ok I renamed the method, removed the TypeDefinition part.\nI didnt create a Directives (plural) since there already was one.  I know packages could work.  Instead I created a NodesUtil helper. To help with this issue can you run the same same query on the reference js served graphql to check its return values\n. http://facebook.github.io/graphql/#sec-List\nThe spec says about Lists\n\nList\nLists represent sequences of values in GraphQL. A List type is a type modifier: it wraps another type instance in the ofType field, which defines the type of each item in the list.\nFields\nkind must return __TypeKind.LIST.\nofType: Any type.\nAll other fields must return null.\n\nIt might be missing the ofType field (perhaps although others do too) but the other fields are following sec I think. Thanks for reporting.  A quick examination indicates you are right and we will look into this.. Custom \"injected\" data handlers are a great idea.\nAnother way to attack this problem is have the wiring happen at the Graphql builder level\nGraphQL.newGraphQL(schema).executionStrategy(x).errorHandler(customErrorHandler)\nThis would not allow a error handler per strategy say\nOr as you say when you instatiate the ExecutionStrategy you pass in the error handler. I can confirm this is a problem.\n```\nclass Issue526 extends Specification {\nenum Episode {\n    NEWHOPE, EMPIRE, JEDI\n}\n\nclass Droid {\n    List<Episode> appearsIn = [Episode.NEWHOPE, Episode.EMPIRE]\n\n    List<Episode> getAppearsIn() {\n        return appearsIn\n    }\n}\n\ndef \"526 list of enums comes back ok\"() {\n\n    given:\n\n    def spec = \"\"\"\n        enum Episode {\n            NEWHOPE,                    \uf700\n            EMPIRE,\n            JEDI\n        }\n\n        type Droid {\n            id: String!,\n            name: String,\n            appearsIn: [Episode],\n            primaryFunction: String,\n        }\n\n        type Query {\n            droid :  Droid\n        }\n    \"\"\"\n\n    def schema = TestUtil.schema(spec, newRuntimeWiring()\n            .type(newTypeWiring(\"Query\").dataFetcher(\"droid\", new DataFetcher() {\n        @Override\n        Object get(DataFetchingEnvironment environment) {\n            return new Droid()\n        }\n    })))\n\n    def graphQL = GraphQL.newGraphQL(schema).build()\n    def query = \"\"\"\n    {\n        droid {\n            appearsIn\n        }\n    }\"\"\"\n    def executionInput = newExecutionInput().query(query).build()\n\n    when:\n\n    def executionResult = graphQL.execute(executionInput)\n\n    then:\n\n    executionResult != null\n\n}\n\n}\n```\nreturns errors and null values in the epideo list\n0 = {graphql.SerializationError@3050} \"ExceptionWhileDataFetching{path=/droid/appearsIn[0]exception=graphql.schema.CoercingSerializeException: Invalid input for Enum 'Episode'. Unknown value 'NEWHOPE'}\"\n1 = {graphql.SerializationError@3051} \"ExceptionWhileDataFetching{path=/droid/appearsIn[1]exception=graphql.schema.CoercingSerializeException: Invalid input for Enum 'Episode'. Unknown value 'EMPIRE'}\"\nI will look closer as to why. When I used  a single enum value it also fails with null and a SerializationError\nIt because enum.equals(\"somename\") are never true. OK so its this code that causes the problem\nprivate Object getNameByValue(Object value) {\n        for (GraphQLEnumValueDefinition valueDefinition : valueDefinitionMap.values()) {\n            Object definitionValue = valueDefinition.getValue();\n            if (value.equals(definitionValue)) {\n                return valueDefinition.getName();\n            }\n        }\n        throw new CoercingSerializeException(\"Invalid input for Enum '\" + name + \"'. Unknown value '\" + value + \"'\");\n    }\nIt looking to do pure object equality.    So if the GraphEnum definition has the exact Java class types then it will work.\nSo an Java Enum --> Java Enum compare works\nBut a Java Enum --> Java String wont work\nSo given a Java enum like\nenum Episode {\n        NEWHOPE, EMPIRE, JEDI\n    }\nthen it wont match the enum type as generatored by the SchemaGenerator\nI can see two solutions\nRuntimeWiring has a graphql.schema.idl.TypeRuntimeWiring#getEnumValuesProvider that can provide actual enum values given a name\n```\npublic interface EnumValuesProvider {\n/**\n * @param name an Enum value\n * @return not null\n */\nObject getValue(String name);\n\n}\n```\nBut this is very precise and most people will trip on it.\nI think the coercion on Enums should better understand Java Enums and hence IF the object is a Java enum it can do a enum.name() check to String.value of say\nI will raised a PR with this solution\n. With the schema type system enum values can ONLY be names aka the name and value will always be the same\n```\nenumTypeDefinition : ENUM name directives? '{' enumValueDefinition+ '}';\nenumValueDefinition : enumValue directives?;\nenumValue : name ;\n```. Ahh we have worked on the same problem - \nhttps://github.com/graphql-java/graphql-java/pull/529\nI guess that wasnt a surprise since you reported the problem.\nI wanted to combine 2 problems in one - better composition and more info to the handler than we give today using the \"parameters object\" pattern\n. This has been rewritten in 4.x and is not longer the case that I can see. I think this will satisfy the principle of least suprise (when using the Schema Generator)\na java enum like\njava\n        enum Episode {\n            NEWHOPE,\n            EMPIRE, \n            JEDI\n        }\nand a graphql type of\ngraphql\n            enum Episode {\n                NEWHOPE,                    \n                EMPIRE,\n                JEDI\n            }\nshould match\n. The problem with using say https://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/schema/idl/NaturalEnumValuesProvider.java  is that it doesnt satisfy the principle of least suprise\nAs a user of graphql I have a typed defined as an enum and then I pass back a Java object thats an enum of exactly the same shape and it does work.\nI need to wire in NaturalEnumProviders for every enum I used.  And I might not have total control over all the objects and classes that are used (say in a team situation).  Assume I have 15 different enums say. I need to wire in 15 different enum providers\n. A thought - if we do decide that you have to provide \"enum providers\" (and I dont think we should) but if we do then we should enforce them at runtime wiring stage.  eg if there is a enum type then there MUST be an enum value provider. Yes we know about this issue -  There current master branch has a new set of parameters passed in\n/**\n     * This is called to ask if this factory can provide a data fetcher for the definition\n     *\n     * @param environment the wiring environment\n     *\n     * @return true if the factory can give out a data fetcher\n     */\n    default boolean providesDataFetcher(FieldWiringEnvironment environment) {\n        return false;\n    }\nand\n```\n    public class FieldWiringEnvironment extends WiringEnvironment {\nprivate final FieldDefinition fieldDefinition;\nprivate final TypeDefinition parentType;\n\nFieldWiringEnvironment(TypeDefinitionRegistry registry, TypeDefinition parentType, FieldDefinition fieldDefinition) {\n    super(registry);\n    this.fieldDefinition = fieldDefinition;\n    this.parentType = parentType;\n}\n\npublic FieldDefinition getFieldDefinition() {\n    return fieldDefinition;\n}\n\npublic TypeDefinition getParentType() {\n    return parentType;\n}\n\n}\n```\nThis gives you the parent type to allow for better decisions. @tklovett - we have the WiringFactory if you want to provide the same fetcher always to a specific type.  Its less visible (in a code sense) than the \"manual wiring\" but works the same\nJust respond to providesDataFetcher to all fields of a certain type\nBut as I type this I can see you have a point. > I am not sure about the WiringFactory method:\nThe reason I put this in is that previously if not one answered YES to providing a data fetcher then PropertyDataFetcher was used.\nI tried to replace that by saying you MUST wire in a default type of data fetcher and then providing a default implementation that used PropertyDataFetcher anyway.\nSo we need a place to provide the \"global\" proeprty fetcher.  This could be on RuntimeWiring (not per type though) or as I chose in the WiringFactory\nSee https://github.com/graphql-java/graphql-java/issues/536 for more background from other people\nI am happy to make the \"global\" data fetcher on RuntimeWiring rather than WiringFactory.  In either case it will default to PropertyDataFetcher. Actually it cant be global on RuntimeWiring since the getDefaultDF requires the \"field\" to be fetched to be named as input\nHence it needs to the FieldWiringEnvironment input to make a proper decision.\nAnd thats what WiringFactory does. This is fixed in 4.x which is due end of Aug. This is a duplicate of https://github.com/graphql-java/graphql-java/issues/538 and is indeed fixed on master. We have decided to close this PR.   The concern\n\nThe downside is that there is no explicit contract in ExecutorServiceExecutionStrategy to only use ExecutorService#submit(Callable). If one of the other #submit(Runnable[...]) methods were to be used, this proposed strategy would be silently broken.\n\nis valid but not reason enough to accept this more complicated code.\nWe wont be making new ways to submit fields in the ExecutorServiceExecutionStrategy.  They are always Callables since fields return values. \nOk I accept your use case.  Not sure how many people would ever do it but perhaps banks and financial type companies might\nI ran up a PR here : https://github.com/graphql-java/graphql-java/pull/562\nLet me know if you think you can implement your code in terms of that.  . @emrul - there is some opposition in accepting this PR into the system.  That is building a more complex library for the sake of a small user case.\nThat said I personally have recently come across a user case.  Public and Private APIs.\nImagine a graphql gateway that has more and less fields on it depending on whether the caller is a private in company caller versus a public out of company API user?\nThat said I am not sure its Introspection but rather a separate schema in general.. This is what I think we should do :\n1) have a switch to turn off Introspection (not replace it nor allow it to lie - just be on and off)\n2) expect people to build separate schemas for their class of users\n3) don't build replaceable introspection\nI have been thinking about what it would take to have a Schema A and transform it into Schema B with some differences (added fields and types / removed fields and types)\nits like you need a SchemaTransformer\nthat \u201cwalks\u201d the schema and calls back to code to add / remove fields and types\nthat way you can have a \u201copen\u201d schema and then \u201ctransform\u201d it into the more closed one say\nand keep 2 copies in memory\nthat way the Introspection will work for each\nif you \u201clie\u201d in Introspection you still have to enforce field access at query time via data fetchers\nbecause Introspection says there is no \u201csecretFoo\u201d field but the runtime will validate it and accept it\nnow you need to make the dataFetcher blow up some how\nthats kinda security by obscurity - not be design\n. @emrul - can you have a look at https://github.com/graphql-java/graphql-java/pull/641 and see if it satisfies your use case.\nIt prevents both introspection, query validation and data execution (should you some how get past validation)\nI think this will do what you want.\nYou would implement a GraphqlFieldVisibility implementation that controlled what fields are visible during the request based on your users. I am going to close this issue as the capability to change field visibility including to Introspection is now in master and will come with 4.0. I would like to know more about your user case \"private introspection\" fields.\nThe introspection system in graphql is is emant for developers to be able to know what structure is in place\nLike in RDBMS Tables.   SQL tables dont give you a restricted view of the tables columns based on who you are.  If you  have access to read - you can read the whole database schema.\nI figure graphql is much like that.  if you can make the Introspection query hit the graphql server then you can know all fields.  \nWhen you run the query you might not be able to see all data that could be represented by those fields but I figure you should be able to see those fields.\n(That said my analogy runs a little thin because in SQL databases you can create views on tables and restrict read access to only those views...but I digress)\nSo as I said I am trying to work out your \"requirements\" from a business use case more.\nAs for accepting this PR (if we indeed did because I am leaning towards having an open schema only) but if we did then I think that rather than going into the N places to make surgery on where we go direct to the hard coded Introspection types, we would need a provider of sorts\neg\n  class IntrospectionTypeProvider {\n\n }\n\nIts job would be to provide the __types and so on and perhaps do the \"if top level query\" detection\nThis would then be wired in via extensions to Graphql.Builder\nGraphql.newSchema(schema).introspectionTypeProvider(new CustomIntrospectionTypeProvider()).build\nand the passed down to the layers of code.\nThat way we could ship with the default behviour and and allows new behaviour to be wired in via standard SPI interfaces\nBut like I said I am not sure we want to offer \"quantum\" schema introspection so if you could expand on your reasons for that it would be great to better understand.\n. Closing this because https://github.com/graphql-java/graphql-java/pull/641 does it better. the graphql schema and type system is self referential eg a cyclic graph.  \ngraphql by its very specification has a \"introspection\" system that allows the schema to be ..well instropected and documented\nThis is how tools like graphiql work.  They fire off introspection queries to the schema and it reports what it looks like\nhttp://graphql.org/learn/introspection/\nhttps://github.com/graphql/graphiql\nThere are also static tools for generating documentation from a schema as well.  I think you might want to check those out\n. for example : https://www.npmjs.com/package/graphql-docs\nhttps://github.com/2fd/graphdoc. Close this because https://github.com/graphql-java/graphql-java/pull/641 does it better. We are planning a 4.0.0 probably over the next 6 weeks or so. Closing since its fixed in the next version. and then looking at the code closer - it seems PropertyDataFetcher does exactly this\nObject source = environment.getSource();\n        if (source == null) return null;\n        if (source instanceof Map) {\n            return (T) ((Map<?, ?>) source).get(propertyName);\n        }\n        return (T) getPropertyViaGetter(source, environment.getFieldType());\n. I took the SchemGen portion of this PR and applied it to master.  The SchemaPrinter code needs to be reimplemented and more extensively tested. I think abandon this PR and start a new one with the SchemaPrinter directives fixes separate.\nYou need to test them more since that was part of the problem with combining 2 changes\nI am going to close this and await a new PR\nThanks for contributing to the project.  We do appreciate the support. We are aiming for an end of August release.\nWe may create a 4.x-alphaN in the meantime if the release runs over. Fixed. By all means we could improve the javadoc.\nHowever the standard Scalar types are meant to be singleton instances and are not designed to be extended at all.\nScalars.GraphQLString is the one and only instance of the String scalar say.  Same for all the others. Scalars are meant to be the \"end\" of the logical tree in graphql queries\nSo the built in String / Int / ID / Long and so on are meant to defined as primitive values that are accepted in a standard format and output in a standard way.\nThis is the role of the Coercing code to decide how that standard way is implemented\nFrom\nhttp://graphql.org/learn/schema/#scalar-types\n\nIn most GraphQL service implementations, there is also a way to specify custom scalar types. For example, we could define a Date type:\nscalar Date\nThen it's up to our implementation to define how that type should be serialized, deserialized, and validated. For example, you could specify that the Date type should always be serialized into an integer timestamp, and your client should know to expect that format for any date fields.\n\nSo if there were designed to be re-useable it would suggest they are flexible in their accepted formats... which they are not. (not really)\nThe spec prescribes behaviours for the standard scalars\nhttp://facebook.github.io/graphql/#sec-Scalars\nUsing singletons is way for the library to ensure that the behaviour stays according to spec.\nbut as you say we could improve the documentation for those writing their own custom scalars\n. The Scalar code was revisited in 3.0 because it was incorrect according to spec\nYou will need to upgrade to get that fix\nparseValue will be Java objects as passed in via the variables mpa on the query. This is missing on more than fields.  All of the graphql runtime types have \"definitions\" that needs to be transferred.\nIf I recall that \"definitions\" were missing so I made another PR to add that and then forgot to circle  back and make SchemaGen put them in place. @martijnwalraven - you might want to pass that tip onto the Sangria team since they also use DateTimeFormatter.ISO_OFFSET_DATE_TIME.  I looked at their code for inspiration. Ok moved to DateTimeFormatter.ISO_INSTANT. Nice catch.  Working on a PR now. I will fix this along with #581. See https://github.com/graphql-java/graphql-java/pull/591\n. Just to help us reproduce and test, can you please give an example query\nIt helps with unit tests and reproduction  later. Definitely fixed in the too be released 4.x branch. Since we closed previous issue I am going to close this one as well (to keep things neat). Thanks. thenApply / thenAccept are the forms where you ONLY get the successful value.  The exception will be thrown when you to CF.get()\nhandle / whenComplete are the forms that area BiFunction/BiConsumer that are given the success value OR the throwable both at the same time\nThe equate to the same thing in practice but the error path is now made visible. Can you please send a reproduction query so we can look at it in more detail.\nPretty sure that missing as trailing } has a unit test hence the need for a more specific query. Ok I have run this on master (4.x) and I do get an exception.  I do get an error but it does not blow up.\nWhat version of graphql are you on?\nThe error could be improved for this.  Its currently\n{\n  \"errors\": [\n    {\n      \"sourceLocations\": []\n    }\n  ],\n}\nwhich is rubbish since it lost the error message. \nSee #606 for that fix.\n. I am going to close this issue because it currently does not NPE on master (4.x)\n. Can you please send in a reproduction query and schema so we can more easily fix this. I have the offending code\n```\n    public static DataFetchingFieldSelectionSet newCollector(ExecutionContext executionContext, GraphQLType fieldType, List fields) {\n        if (fieldType instanceof GraphQLObjectType) {\n            return new DataFetchingFieldSelectionSetImpl(executionContext, (GraphQLObjectType) fieldType, fields);\n        } else {\n            // we can only collect fields on object types.  Scalars, Interfaces, Unions etc... cant be done.\n            // we will be called back once they are resolved however\n            return NOOP;\n        }\n    }\n```\nThe problem is we are only handle ObjectTypes but we are not unwrapping List / Non null ness from the type\n. Now done via another PR. Sorry we dont publish javadoc currently.  Its present in source but no online\nHow to use doc can be found here : http://graphql-java.readthedocs.io/en/stable/\n. Thanks for reporting this.  Any chance you might want to put together a PR to help fix this :). Thanks. I have been in discussion with Apollo regarding instrumentation and have also looked into whats involved.\nThey are proposing a new standard where the engine gives back standardized tracing information\nhttps://github.com/apollographql/apollo-tracing\nThe new graphql 4.x (master) has support for this.  \nSee graphql.execution.instrumentation.tracing.TracingInstrumentation\nThere is no current Optics agent for java that I know that reports in the older protobuf msg format. \n. Answered. Closing this issue as its the wrong way to approach the problem. Thanks for reporting. Fixed on master. This has been fixed in 4.x aka master.  It now adds the \"additional types\" into the schema. turns out its the other way around - if you take a data object (null or not) then the data is considered present. EDIT : Actually no - since the outside code sets up the context it can also setup enough context into a custom FieldVisibility implementation to work out whats needed.  Example updated to show this.\nI have just realised this is missing a key bit of context.  There is no way to get the \"context\" object\non the call to filter a field and hence there is no way to make a smart decision based on anything else but name\nWe need to pass the \"context\" object into them so they can access their user info say or whatever.\n. > @bbakerman Just to double-check if I get it right. The visibility isn't meant to be dynamic (as in: the same schema with the same visibility strategy used for everyone and dynamically deciding who gets to see what on the fly), right? You're supposed to create a schema per group/role/user with different visibilities instead (and it's a cheap operation as all the same references are reused)?\nGoing further, I reckon it is done to ensure schema validity, as if it was dynamically deciding (vs the schema build time), it could easily produce an invalid schema?\n@kaqqao \nActually no - you can do it either way.  You can build a schema per visibility object.  Or you can have it dynamic.\nIf you make your schema invalid because of whacky field exclusion, be it on your head.\nThis will dynamically filter fields when asked.  So it can be as dynamic or static as you choose.. This PR inspired me to look further into graphql errors and this led to\nhttps://github.com/graphql-java/graphql-java/pull/650\nIt combines the idea in this PR  (extension via DataFetchers exceptions) and a lot more.\nI think it supersedes this PR. But thanks for this PR to seed the changes. The spec defined fields are\nmessage : String\nlocations : [ { line : Int, column : Int } ]\npath : [String or Int ]\nso\n\"errors\": [\n{\n  \"message\": \"Name for character with ID 1002 could not be fetched.\",\n  \"locations\": [ { \"line\": 6, \"column\": 7 } ],\n  \"path\": [ \"hero\", \"heroFriends\", 1, \"name\" ]\n}\n\n],\nWe are a long way off from that when a JSON serializer is put in place. I have done some more digging on this by comparing Jackson and GSON and how they serilaize\nTurns out for this code\n    private ExecutionResult createER() {\n    List<GraphQLError> errors = new ArrayList<>();\n\n    errors.add(new ExceptionWhileDataFetching(mkPath(), new RuntimeException(\"Bang\"), mkLocation(666, 999)));\n    errors.add(new ValidationError(ValidationErrorType.UnknownType, mkLocations(), \"Test ValidationError\"));\n\n    return new ExecutionResultImpl(null, errors);\n}\n\nprivate List<SourceLocation> mkLocations() {\n    return stream(new SourceLocation[]{mkLocation(666, 999), mkLocation(333, 0)}).collect(toList());\n}\n\nprivate SourceLocation mkLocation(int line, int column) {\n    return new SourceLocation(line, column);\n}\n\nprivate ExecutionPath mkPath() {\n    return ExecutionPath.rootPath().segment(\"a\").segment(0).segment(\"b\").segment(\"c\").segment(4);\n}\n\nThat Jackson works as expected :\n{\n  \"data\": null,\n  \"errors\": [\n    {\n      \"path\": [\n        \"a\",\n        0,\n        \"b\",\n        \"c\",\n        4\n      ],\n      \"exception\": {\n        \"cause\": null,\n        \"stackTrace\": [\n          {\n            \"methodName\": \"createER\",\n            \"fileName\": \"ExecutionResultTesting.java\",\n            \"lineNumber\": 59,\n            \"className\": \"example.http.ExecutionResultTesting\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"testJackson\",\n            \"fileName\": \"ExecutionResultTesting.java\",\n            \"lineNumber\": 47,\n            \"className\": \"example.http.ExecutionResultTesting\",\n            \"nativeMethod\": false\n          },\n          ...\n        ],\n        \"message\": \"Bang\",\n        \"localizedMessage\": \"Bang\",\n        \"suppressed\": []\n      },\n      \"message\": \"Exception while fetching data (/a[0]/b/c[4]) : Bang\",\n      \"locations\": [\n        {\n          \"line\": 666,\n          \"column\": 999\n        }\n      ],\n      \"errorType\": \"DataFetchingException\"\n    },\n    {\n      \"validationErrorType\": \"UnknownType\",\n      \"description\": \"Test ValidationError\",\n      \"message\": \"Validation error of type UnknownType: Test ValidationError\",\n      \"locations\": [\n        {\n          \"line\": 666,\n          \"column\": 999\n        },\n        {\n          \"line\": 333,\n          \"column\": 0\n        }\n      ],\n      \"errorType\": \"ValidationError\"\n    }\n  ],\n  \"extensions\": null\n}\nBut GSON does not.  GSON only uses fields and never public getters on POJOs - boo!!\n{\n  \"data\": null,\n  \"errors\": [\n    {\n      \"path\": {\n        \"parent\": {\n          \"parent\": {\n            \"parent\": {\n              \"parent\": {\n                \"parent\": {\n                  \"parent\": null,\n                  \"segment\": null,\n                  \"pathList\": []\n                },\n                \"segment\": {\n                  \"value\": \"a\"\n                },\n                \"pathList\": [\n                  \"a\"\n                ]\n              },\n              \"segment\": {\n                \"value\": 0\n              },\n              \"pathList\": [\n                \"a\",\n                0\n              ]\n            },\n            \"segment\": {\n              \"value\": \"b\"\n            },\n            \"pathList\": [\n              \"a\",\n              0,\n              \"b\"\n            ]\n          },\n          \"segment\": {\n            \"value\": \"c\"\n          },\n          \"pathList\": [\n            \"a\",\n            0,\n            \"b\",\n            \"c\"\n          ]\n        },\n        \"segment\": {\n          \"value\": 4\n        },\n        \"pathList\": [\n          \"a\",\n          0,\n          \"b\",\n          \"c\",\n          4\n        ]\n      },\n      \"exception\": {\n        \"detailMessage\": \"Bang\",\n        \"stackTrace\": [],\n        \"suppressedExceptions\": []\n      },\n      \"sourceLocation\": {\n        \"line\": 666,\n        \"column\": 999\n      }\n    },\n    {\n      \"msg\": \"Validation error of type UnknownType: Test ValidationError\",\n      \"validationErrorType\": \"UnknownType\",\n      \"sourceLocations\": [\n        {\n          \"line\": 666,\n          \"column\": 999\n        },\n        {\n          \"line\": 333,\n          \"column\": 0\n        }\n      ],\n      \"description\": \"Test ValidationError\"\n    }\n  ]\n}\nYou would need custom serializers to make GSON work as is.  Jackson just works.. BTW @andimarek - re This would also solve this PR: #647 . Custom data can be added after toSpecification.\nIt might not because thatb PR is asking for  a way to \"transfer\" custom data from an exception in a data fetcher into the actual ErrorWhileDataFetching class.\nThat is make it have user defined values but surface them up into a number of errors. More testing has revealed some problems\n public class NonNullableFieldWasNullException extends RuntimeException implements GraphQLError {\n\n    private final ExecutionTypeInfo typeInfo;\n     private final ExecutionPath path;\n\nThis wont serialize in neither Jackson or GSON.  Both fail because the graphql types (in ExecutionTypeInfo I think)  are circular somehow and it both get a stack overflow exception.\nThe NonNullableFieldWasNullException as is a problematic error to report. I have been looking more closely at GraphqlError and I am wondering the value of ErrorType getErrorType();\n public enum ErrorType {\nInvalidSyntax,\nValidationError,\nDataFetchingException,\nMutationNotSupported\n\n}\nits not spec - but it does classify errors - but only kinda. So while to get proper toSpecification errors you need to call toSpec on the ExecutionResult, some of these field naming changes just mean that without that its a \"smidge\" closer to working.\nBetter to be 75% correct than to be 5% correct say.  It is not 100% correct and cant be under GSON native say but it can be more correct than it otherwise would be.\nFor those that want 100% correct - they have toSpecification. Looking further into this  - this is a really neat PR - the traversal code WILL prove useful in the future and the combination of Instrumentation as a way to inject behaviour into a graphql execution is cool!. Yes it can. \"\" in java is considered non null which is why I think this example passed basic validation.\nIn order to do full business rule validation you need to do this in the DataFetcher for that input.\n```\nDataFetcher inputDF = environment -> {\n     String id = environment.getArgument(\"id\");\n     if (! isValid(id)) {   // your logic here\n       throw new ValidationException(\"No happy with this input\");\n     }\n    return lookUpObject(id);\n}\n```\nAny runtime exception thrown inside a DataFetcher will be captured as an graphql error and added to the ExecutionResult error list. See http://graphql-java.readthedocs.io/en/v4/execution.html#exceptions-while-fetching-data. I dont tihnk this is a problem in the graphql-java library.  It does NO JSON interpretation on input and output.\nWhat framework and graphql wrapper library are you using?  . Can you please report that problem again that project then.  This is not a graphql-java problem.\nif it turns out to be a graphql-java problem can you re-raised a new ticket with more detail on exactly what graphql-java (the base library) is doing wrong.. PR up. I have had a look at this more and its tricky one to fix (easily) because of the internal structure of the  BatchExecutionStrategy\nthe root cause is that the BacthedES expects the return value to always be a Iterable but what we need up is producing a Iterable that is a list with a CF inside it\nWe wrap that list in a CF in the code but its a CF pointing to a List. \nThese objects get passed into as handled as actual objects and not CFS\n      handleResult ...\n        List<Object> values = result;\n        List<FetchedValue> retVal = new ArrayList<>();\n        for (int i = 0; i < parentResults.size(); i++) {\n            Object value = unboxPossibleOptional(values.get(i));\n            retVal.add(new FetchedValue(parentResults.get(i), value));\n        }\n        return retVal;\n\neg the object placed into FetchedValue is in fact treated as completed - when in fact it is not completed yet.\nLater those fetched results are sent to handlePrimitive and so on a they get treated as coerced objects etc...\nI think the FetchedValue idea needs to be come a  FetchedValue of CF promises and not objects\n. also the mutation of the parent structure makes this super tough\n private void handlePrimitives(List<FetchedValue> fetchedValues, String fieldName,\n                              GraphQLType type) {\n    for (FetchedValue value : fetchedValues) {\n        Object coercedValue = coerce(type, value.getValue());\n        //6.6.1 http://facebook.github.io/graphql/#sec-Field-entries\n        if (coercedValue instanceof Double && ((Double) coercedValue).isNaN()) {\n            coercedValue = null;\n        }\n        value.getParentResult().putOrAdd(fieldName, coercedValue);\n    }\n }\n\nThis is pushing state up into the parent which also assumes the value is resolved.  Hmmmm. I take it back its easy to fix.  As I described the problem it told me the answer\nList> needs to become CF\nAnd CF.allOf() allows this\n    CompletableFuture[] cfs = results.toArray(new CompletableFuture[results.size()]);\n    return CompletableFuture.allOf(cfs)\n            .thenApply(v -> results.stream()\n                    .map(CompletableFuture::join)\n                    .collect(Collectors.toList()));\n\n. > Should BatchedExecutionStrategy delegate more of the resolution to the parent class so it picks up changes like Optional unboxing?\nyes it should.  Thanks for reporting... PRs are also welcome ;). I can confirm this is a bug.  Its caused because the Tracing support assumes that BatchExecutionStrategy fills out the ExecutionTypeInfo correctly\n        ExecutionTypeInfo typeInfo = dataFetchingEnvironment.getFieldTypeInfo();\n\n        Map<String, Object> fetchMap = new LinkedHashMap<>();\n        fetchMap.put(\"path\", typeInfo.getPath().toList());\n        fetchMap.put(\"parentType\", typeInfo.getParentTypeInfo().toAst());\n        fetchMap.put(\"returnType\", typeInfo.toAst());\n        fetchMap.put(\"fieldName\", typeInfo.getFieldDefinition().getName());\n\nbut BatchExecutionStrategy uses it weird ways of not really knowing what field / type hierarchy is in place at one time.\nWe could change TracingSupport because I think the information is available elsewhere but tis really annoying that BatchedExecutionStrategy does not fill out the right ExecutionTypeInfo hierarchy correctly.\nI think we need to do #675 also to fix this once and for all. https://github.com/graphql-java/graphql-java/pull/679 will allow arrays returned and tweaks the error messages a little better. I have updated https://github.com/graphql-java/graphql-java/pull/679 with the contents of this PR and its extra test\nI think this one can be closed as the other one contains it (in practice) plus some more code. I took a quick look into this one.  The problem is that the rules on child --> parent type nullablity are not being followed\nThe problem code is\n        resolveField(executionContext, newParameters, fieldName, curNode)\n            .whenComplete((childNodes, exception) -> {\n                if (exception != null) {\n                    overallResult.completeExceptionally(exception);\n                    return;\n                }\n                queueOfNodes.addAll(childNodes);\n                executeImpl(executionContext, newParameters, root, finalCurNode, queueOfNodes, finalCurFieldNames, overallResult);\n            });\n\nIt sees the exception (which is the wrong exception as well graphql.execution.NonNullableFieldValidator should be used)\nWe need a way to encode the type information into each place here and bubble up the parent -> child rules as discussed in http://facebook.github.io/graphql/#sec-Errors-and-Non-Nullability\nBecause of the way BatchedES pushes state into a shared tree it kinda challenging. Or perhaps again I dont grok how BatchedES works. I thought it would not be complicated but my ANTLR / Regex fu is not that great it seems.\nI am having trouble coming up with the syntax needed to allow ANY characters except \"\"\" but still allow \\\"\"\" to be in place.\nThe new spec allows \"\"\" quotes to be in inline strings as well as comments.  Previously I only looked at \"\"\" comments which is easier\n```\nStringValue:  TripleQuotes TripleQuoteCharacters TripleQuotes | '\"' StringCharacters '\"';\nfragment StringCharacters : ((~([\"\\\\n\\r\\u2028\\u2029])|EscapedChar));\nfragment TripleQuoteCharacters : EscapedTripleQuotes| [A-Za-z] ;\nfragment TripleQuotes : '\"\"\"';\nfragment EscapedTripleQuotes : '\\\"\"\"';\n```\nIf we have a ANTLR expert around that would help a lot :). I asked some ANTLR fu questions on StackOverflow and it seems to be paying results\nhttps://stackoverflow.com/questions/46133654/antlr-grammar-for-triple-quoted-string\nI will try to get this into a branch. The reference PRs from upstream graphql-js and spec are\nhttps://github.com/graphql/graphql-js/pull/926\nhttps://github.com/graphql/graphql-js/pull/927/files. This is now on spec master and the format decided. This is quasi related to https://github.com/graphql-java/graphql-java/issues/162. Now via instrumentation. It looks like you are using one of the graphql-java based frameworks for your code?\nCan you outline which one.  ?\nI think your problem is more how you tell that framework about our custom scalar (which looks ok at a glance)\nI think you will want to raise an issue with the framework project and not graphql-java itself since this project is about the base engine. @bobdi98 - the schema parser you are using is likely NOT the one in the graphql-java base library but rather one in another library - say the graphql-java-spring-boot one\nHence this issue is closed because we cant reproduce it using native graphql-java.\nIf you can write a iunit test demonstrating this then all the better. Thanks for this. This you for submitting this PR.  The project appreciates it.  It looks like 3 of us decide to fix this problem in very similar ways.\nhttps://github.com/graphql-java/graphql-java/pull/695\nhttps://github.com/graphql-java/graphql-java/pull/696\nhttps://github.com/graphql-java/graphql-java/pull/694\nI have merged 695 and hence we dont need this extra one.  \nWe do appreciate the PR however. Ok so your original PR fixed this @andimarek but I think there is some refactor value in this one as well reagarding Async and using it commonly in a few places. This is now on master.  Thanks for reporting this bug. I wrote a quick unit test on this\n```\n    def \"#699 union type in schema\"() {\n        given:\n        def wiring = RuntimeWiring.newRuntimeWiring()\n                .type(newTypeWiring(\"FooBar\").typeResolver(new TypeResolver() {\n            @Override\n            GraphQLObjectType getType(TypeResolutionEnvironment env) {\n                return env.getSchema().getType(\"Foo\");\n            }\n        })).build()\n        def schema = TestUtil.schema(\"\"\"\n            type Query {\n                fooBar: Foo\n            }\n        union FooBar = Foo | Bar\n\n        type Bar {\n            bar: String\n        }\n\n        type Foo {\n            foo: String\n        }\n    \"\"\", wiring)\n\n    def queryStr = \"\"\"\n        query {\n            fooBar {\n                ... on Foo {\n                    foo\n                }\n            }\n        }\n        \"\"\"\n\n    def calculator = new FieldComplexityCalculator() {\n        @Override\n        int calculate(FieldComplexityEnvironment environment, int childComplexity) {\n            return 10\n        }\n    }\n    MaxQueryComplexityInstrumentation queryComplexityInstrumentation = new MaxQueryComplexityInstrumentation(5, calculator)\n\n    def graphQL = GraphQL.newGraphQL(schema).instrumentation(queryComplexityInstrumentation).build()\n\n    def result = graphQL.execute(queryStr)\n\n    expect:\n    result.errors.size() == 1\n\n}\n\n```\nIt works as expected in this simple case\n@joesankey - can you outline more examples of why this isnt working for you please\n. I am going to close this for now and wait for more details to be added. Bugger didnt start from fresh master. Seems maven central now has it. a list if not a descent in field terms surely?\n type MyQuery\n      list : [String]\n      deep : [MyQuery]\n}\n\nand\n query {\n     list\n }\n\nwhen we encounter the field list its depth 1 - its not how many items are in the list say.  Its how many fields deep the query is\nif we had a query like\n query {\n    deep {\n        deep {\n            list\n        }\n   }\n }\n\nIn that case the field tree is 4 levels deep. includeScalars was there to avoid round tripping errors.\nIf I have a schema Foo and I print it, I should be able to ingest it again and get Schema Foo.\nSo if we had a graphql-java --> graphql-java roundtrip - you would want to omit BigDecimal but with replay-compiler you would not want that.  Competing aims here.   Hmmm. I have taken this PR and made #711 -\nI couldnt seem to make back updates to the original PR hence this one. The follow on PR for this is now merged so closing this one. test added. GraphqlList is not designed to be a singleton component aka like most \"code components\" in Spring.  Its a wrapper class for indicate that a graphql Type X is non null.\nIf you want a factory of types then I suggest you use Spring factories to create your types rather than Autowiring. I am going to close this issue because graphql-java is working as designed and you can work around this in Spring. >but it breaks completely the immutability of the schema objects.\nNo it doesnt - I wrap the map in unmodifiableMap() in every case\n       this.metadata = metadata == null ? emptyMap() : unmodifiableMap(metadata);\n\nThe problem is \"viral mutability\" can't be solved in Java.  That is an object in a immutable map maybe itself be mutable.  But that is a well known fact of Java land and hence impractical to solve.\nBut the main GrapqlType object itself is still immutable. I take your point.  I am not sure Map will do - better than none but maybe not that great.\nThe XXX Definition classes are not immutable BTW - in fact the parser relies on that to build them up as they parsed.  So the classes today are not immutable per se and hence hard to copy.\nAlso replace type reference calls on a field that is not volatile so its not thread safe to copy and technically may never be seen of the object was published across threads but the replaceTypeReference() was called later.  Thats a fix we should definitely do.\n. One other use case that I can come up with is using field meta data to feed into a complexity calculation.\nThat is for field X I can specify some metadata that helps me calculate field complexity.  I cant do that if I cant associate meta data or code with the field.\nFor example one can imagine associated helper code with a field to that might take query data as input and the meta data code does the calculation.\nOr just an more complex object than String/Int which we know to be immutable.\nLook I agree that Immutability is important but if some one puts metadata in the \"immutable map\" and changes it on the fly then its their funeral.  We can protect against them adding more data later bit not mutating the data they have.\nI stronly think its ok to have nominally mutable data associated inside immutable maps.\nIts always better to be useful than correct!. Closing this. I also echo the idea of that we NOT add Guava as a dependency.  Its very heavy weight dependency and we want to be as light as possible.\nThe code that does this is protected.  You can override it an a custom ExecutionStrategy say\nprotected Object unboxPossibleOptional(Object result) {\n        if (result instanceof Optional) {\n            Optional optional = (Optional) result;\n            if (optional.isPresent()) {\n                result = optional.get();\n            } else {\n                result = null;\n            }\n        }\n        return result;\n    }\nThat is the current code. You could use\nclass GuavaExecutionStrategy extends AsyncExecutionStrategy {\n        @Override\n        protected Object unboxPossibleOptional(Object result) {\n            if (result instanceof Option) {\n                return ((Option) result).get();\n            }\n            return super.unboxPossibleOptional(result);\n        }\n    }\n. I suspect (but dont know) that is was deliberate in the original graphql.\nThe spec mentions objects and objects fields as being something that can have deprecation.\nPerhaps they felt that input objects cant as easily be deprecated since its more a \"required\" input.\nIf you look at http://facebook.github.io/graphql/#sec-The-__Field-Type and contrast it to http://facebook.github.io/graphql/#sec-The-__InputValue-Type you will notice one allows deprecation and one does not.\nSo even introspection says that its not a thing\nThat said I can't see a spec statement forbidding deprecation on input fields so one could make an argument it can be allowed.\nMore color can be found here : https://github.com/facebook/graphql/issues/197 and here https://github.com/facebook/graphql/issues/235\n. Great idea!. You can use graphql.execution.instrumentation.Instrumentation#instrumentDataFetcher to instrument every DataFetcher in the system.\nYou can replace at runtime the DataFetcher that gets used.\nHow are you building your schema?  Per request or singleton?  Building the schema per request is quasi expensive but the schema is immutable at a build time.\nInstrumentation allows you to substitute in a new DF given the current one defined on the schema.\nPerhaps we need a \"DataFetcherFactory\" that can be put on a schema type and hence allow an indirection into the typically \"static\" schema.\n. OK I started to look into this problem.\nFirst off it seems to be doing the right thing MOSTLY.  That is a variable $input will not be validated early since the query validation can only know about co-ercing and validating AST literals.\nSee http://facebook.github.io/graphql/October2016/#sec-Validation.Variables and how it does not talk about validating variable \"values\" but only literals.\nSo its correct that it returns no errors.\nOk that leads us to execution and how to co-erce input values.\ngraphql.execution.ValuesResolver#coerceValue is the method that does this.  The code of interest is here\n    } else if (graphQLType instanceof GraphQLInputObjectType && value instanceof Map) {\n        //noinspection unchecked\n        return coerceValueForInputObjectType(variableDefinition, (GraphQLInputObjectType) graphQLType, (Map<String, Object>) value);\n    } else if (graphQLType instanceof GraphQLInputObjectType) {\n        return value;\n    } else {\n\nSo it will take \"InputObject\" types and Maps and co-erce them.  The spec says as much\nhttp://facebook.github.io/graphql/October2016/#sec-Input-Objects\n\nInput Coercion\nThe value for an input object should be an input object literal or an unordered map, otherwise an error should be thrown. This unordered map should not contain any entries with names not defined by a field of this input object type, otherwise an error should be thrown.\n\nSo this is where graphql-java differs.  It does NOT throw an exception on a non map but it just returns the value as is.  \nThis is wrong I think, certainly according to spec.  The problem with any object is what strategy do you use for pulling part and object?  JavaBean getters?  Field access?  Now all of a sudden you need a \"input object co-ercer\" so it can be object specific say??\nI think we should throw an exception as per spec if the input object is NOT a map.\n@andimarek  thoughts on this?. It looks like the original code followed spec and then this commit was made\nhttps://github.com/graphql-java/graphql-java/commit/1414bc0701677e0d0e1a89b311f9b8d2e64ef33f\n\nProblem: passing input object as a resolved class doesn't work  ValueResolver makes an assumption that an object passed through is always going to be a map.  However, when using graphql-java with graphql-java-annotations and graphql-java-servlet (GraphQLVariables), the inputs passed through are already resolved.  Solution: this patch allows to pass such objects through the resolver unmodified, without throwing an exception.\n\nSo I think this is a sensible compromise.  That is if the inside can understand the object then all is good.\nI think in drews case he was not expecting it to make it passed validation (which it always would have) so its not quite the same thing.\nSo the real question here is - does graphql-java want to follow spec or do they want to allow a more loose construct in the objects that enter data fetchers as arguments.\nI think it should do the latter.  Its easy in graphql-js to say EVERYTHING must be a map,  because everything is!  But in java (and other languages) we have stronger types and hence more object concerns.. Just on the idea of graphql error versus a runtime exception, the spec says\n\nOtherwise, if value cannot be coerced according to the input coercion rules of variableType, throw a query error.\n\neg it says you should throw an error.\nThe ruby example above does not throw an exception but rather adds error messages.  \nI can see an argument for doing it that way since the literal validation results in an error in the result list but variable map validation does not.\n. We discussed this in the maintainers room and have decided to follow spec.  5.0 will revert the previous hack that allow any object to come in as GraphQLInputObjectType input variable.\nIt will not throw an exception as per the spec (not a graphql error).\nThe linked PR now has that fix. Yeah I realise we can also parse a Document into a TypeRegistry and hence a schema proper.\nSo I will make this a tweak to SchemaPrinter to accept both Map introspectionResult and Document and hence allow you to print introspections that much easier. > This is somehow overlapping with AstPrinter, isn't it?\nIt is yes.  I thought about this.  But I would rather keep the printing of schemas (direct or reconstructed from introspection in one place.  But AstPrinter muddies that but so be it.  Ast is Document -> a IDL form.   Whereas SchemaPrinter is similar but the canonical place to print a schema. The code in question is\n private Object getFieldValue(Object object) {\n    try {\n        return object.getClass().getField(fieldName).get(object);\n    } catch (NoSuchFieldException e) {\n        return null;\n    } catch (IllegalAccessException e) {\n        throw new RuntimeException(e);\n    }\n\n}\nI am torn as to whether to fix this or not.  I take your point that if you wire in a FieldDataFetcher(\"expectedField\") then its hard to debug if you make spelling mistakes say\nConversely there are valid cases where you have a diverse range of objects being presented to the data fetcher and \"expectedField\" is not there.  graphql says that when you ask for field X and its not present then you should return null.\nThat is just like a map lookup.  If you do map.get(\"expectedField\") then it wont blow up but return null.  Very much javascript semantics (where graphql originated)\nYou could create your own data fetcher to give you the strict semantics you want.  There is not a lot of code here.  Or we could make it  have 2 modes a \"strict mode\" and a normal mode.\nI am leaning towards leaving it as it and recommending you create your own strict field fetcher.\nThoughts @andimarek ?. I wrote a unit test for this on master\n```\n    def \"#743 missing variables\"() {\n        when:\n        def schema = TestUtil.schema(\"\"\"\n            type Query {\n                version : Int\n            }\n        \"\"\")\n    def graphQL = GraphQL.newGraphQL(schema).build()\n\n    def executionInput = ExecutionInput.newExecutionInput()\n            .query('''\n                query NPEDueToMissingVariable($isTrue: Boolean!) {\n                    version @include(if: $isTrue)\n                }   \n                ''')\n            .variables([:])\n            .build()\n\n    graphQL.execute(executionInput)\n\n    then:\n\n    thrown(NonNullableValueCoercedAsNullException)\n}\n\n```\nWe have improved the code around variable co-ercion to better follow spec. Note however it will still throw an exception because isTrue is defined as being a required input and yet its not present.\nAs such it will now throw graphql.execution.NonNullableValueCoercedAsNullException  which is more deliberate than a NPE but still an exception\nSee http://facebook.github.io/graphql/October2016/#sec-Coercing-Variable-Values\n. This is working as expected in 5.0. > is this a direct adaption of the graphql-js implementation\nNo its not.  Its was developed indepedently pretty much. I think we want this change.  However I am still a little confused because the examples are not 100% clear.\nThe reference implementation has :\nhttps://github.com/graphql/graphql-js/blob/master/src/type/schema.js#L286\nhttps://github.com/graphql/graphql-js/blob/master/src/utilities/typeComparators.js#L57\nCan we put valid examples in place to ensure we are encountering what we should because the invalid examples are throwing me. I updated this to be graphql spec compliant as we discussed in the gitter room.. @joesankey - you have a couple of options.  You can hold onto the DataLoaderRegistry and unload keys but better yet throw it all away per request.\nYou can create a per request DataLoaderDispatcherInstrumentation and a per request Graphql object.\nCreating a new GraphQL object per request is super  cheap.  The new master code has a transform object for making this even easier.\n GraphQL perrequestGraphQL = previousGraphql.transform( builder  -> builder.setInstrumentation(...));\n\nCreating the schema (especially if you use IDL) is more expensive and essentially static.  So I would keep the schema as a static variable (or injected IoC component) and recreate your graphql object each request including data loader support\n. @szantogab - your dont have to use BatchedExecutionStrategy - in fact I actively recommend against it since its not 100% graphql spec compliant (its ok but not 100%)\nSee https://medium.com/@bradbaker/big-movements-in-the-graphql-java-world-67629fd45508 for an example of using data fetcher to gather N requests into one.\nThe key behind data fetcher is that if you ask for key K1 and later K2 and K3 and so on, it holds requests until a suitable time and presents K1,K2,K3 to a batch loading function.\nThey way you load V1,V2,V3 in one go and not 3.  It also caches the previous results (options to turn that off) and hence if you ever ask for K1 again it immediately can give you a past result.\nThis has some example code here -\nhttps://github.com/graphql-java/graphql-java/blob/master/src/test/groovy/example/http/HttpMain.java#L166\nAlso\nhttps://github.com/graphql-java/java-dataloader. With Asyncrhonous strategies and DataLoader there really isnt any need for the older BatchedExecutionStrategy.\nIts is not 100% graphql compliant (for example null values for non null fields does not work) and its a very early attempt at batching.\nFacebook proved batching can work via dataloader and java-dataloader is a faithful port of that proven pattern.\nIn short there is no advantage to BatchedExecutionStrategy and I recommend you dont use it. Thanks for reporting this with such detail.  I think you have found a problem in our implementation\nI have forked your repo and am working on it currently to look into the problem\nYour query is\nquery { \n    shops { \n          id \n          name \n          departments { \n              id \n              name \n              products { \n                   id \n                   name \n              } \n          } \n     } \n}\n\nEarly analysis says that the problem maybe in graphql.execution.ExecutionStrategy#completeValueForList.   This is the code that completes a list of values, in this case a list of \"shops\"\nThe implementation is to run completeValue for each item in the list.  However in practice this runs the execution engine down a level per list item.  This in turns cause the dispatcher to dispatch per list item and not for the whole list.\nThis is my early theory by the way.  I havent fully confirmed this.\nWhat I expect to happen is this\n\nengine encounters a list of shops\nfor each shop it creates a promise to resolve that shop item\nat the end of the 'shops' field then dispatchAll() is called to make good on those promises\nthis would cause department loads for the shop departsments\n\nI will look into this more.  Once again thank you for reporting in such detail.\n. I have a request from you @essh - In order to fix this issue I am going to need test case data.\nCan we please use the code in your example repo as the basis for that test case.  It will save  alot of work since you have done the heavy lifting in reproduction on this.. OK I had a deeper look at this.  First off lets explain the data\n```\n                shops: [\n                        [id         : \"shop-1\", name: \"Shop 1\",\n                         departments: [[id: \"department-1\", name: \"Department 1\", products: [[id: \"product-1\", name: \"Product 1\"]]],\n                                       [id: \"department-2\", name: \"Department 2\", products: [[id: \"product-2\", name: \"Product 2\"]]],\n                                       [id: \"department-3\", name: \"Department 3\", products: [[id: \"product-3\", name: \"Product 3\"]]]\n                         ]],\n                        [id         : \"shop-2\", name: \"Shop 2\",\n                         departments: [[id: \"department-4\", name: \"Department 4\", products: [[id: \"product-4\", name: \"Product 4\"]]],\n                                       [id: \"department-5\", name: \"Department 5\", products: [[id: \"product-5\", name: \"Product 5\"]]],\n                                       [id: \"department-6\", name: \"Department 6\", products: [[id: \"product-6\", name: \"Product 6\"]]]\n                         ]],\n                        [id         : \"shop-3\", name: \"Shop 3\",\n                         departments: [[id: \"department-7\", name: \"Department 7\", products: [[id: \"product-7\", name: \"Product 7\"]]],\n                                       [id: \"department-8\", name: \"Department 8\", products: [[id: \"product-8\", name: \"Product 8\"]]],\n                                       [id: \"department-9\", name: \"Department 9\", products: [[id: \"product-9\", name: \"Product 9\"]]]]\n                        ]]\n```\nThis is the underlying data in the shop /department / product database, using the query above.\nOne thing to note is that its perfectly spread.  That is shop 1 has unique departments with unique products as does shop2 and shop3.  So there is no caching available.\n@essh - that is one thing to note - that is in the real world one would expect some overlap and hence caching would kick in and no data fetches would be made for items previously fetched.  So the data is quite pathological in this case.\nSo above we get 3 batch calls for departments (one per shop) and 9 batch calls for products (one per department)\nThe reason for this is the graphql-java list handling.  When it encounters a list (say of shops) it iterates each item and calls completeValue for each which calls executionStrategy.execute() and resets the whole call stack down one level.\nSo the DataLoaderRegistry.dispatchAll() is being called when you go down to that level and fetch+resolve 1 or more fields.  \nSo above the list of shops, it descends on shop1 and tries to resolve id/name and departments but because it eagerly calls execute again it means dispatch is called and hence the batch fires.\nIt would have to do a breadth first approach to lists to avoid this I think.\nI am still investigating how we can fix this without fundamentally rearranging the execution order.\n. I have a fix and it gets the performance back on par with BatchedExecutionStrategy (but with more correctness as a graphql query that is). @aruberto  - Can you post a unit test / code showing this please. I can reproduce this bug via\n```\n    def \"#763 handles union types\"() {\n        given:\n        def schema = TestUtil.schema(\"\"\"\n            type Query{\n                someObject: SomeObject\n            }\n            type SomeObject {\n                someUnionType: SomeUnionType\n            }\n        union SomeUnionType = TypeX | TypeY\n\n        type TypeX {\n            field1 : String\n        }\n\n        type TypeY {\n            field2 : String\n        }\n    \"\"\")\n    def visitor = Mock(QueryVisitor)\n    def query = createQuery(\"\"\"\n        {\n        someObject {\n            someUnionType {\n                __typename\n                ... on TypeX {\n                    field1\n                }\n                ... on TypeY {\n                    field2\n                }\n            }\n        }\n    }\n        \"\"\")\n    QueryTraversal queryTraversal = createQueryTraversal(query, schema)\n    when:\n    queryTraversal.\"$visitFn\"(visitor)\n\n    then:\n    1 * visitor.visitField({ QueryVisitorEnvironment it -> it.field.name == \"someObject\" && it.fieldDefinition.type.name == \"SomeObject\" && it.parentType.name == \"Query\" })\n    1 * visitor.visitField({ QueryVisitorEnvironment it -> it.field.name == \"someUnionType\" && it.fieldDefinition.type.name == \"SomeUnionType\" && it.parentType.name == \"SomeObject\" })\n    1 * visitor.visitField({ QueryVisitorEnvironment it -> it.field.name == \"__typename\" && it.fieldDefinition.type.wrappedType.name == \"GraphQLString\"})\n\n    where:\n    order       | visitFn\n    'postOrder' | 'visitPostOrder'\n    'preOrder'  | 'visitPreOrder'\n\n}\n\n```\nas a Test inside QueryTraversalTest\nI made this PR which currently fails\nhttps://github.com/graphql-java/graphql-java/pull/765. Decided to merge it since its really minor stuff that passes the build. v4?  . @ind1go - If we allowed ErrorType into Map  toSpec() then ipso facto it would not meet spec.\nWe introduced it for those who want to follow spec strongly on execution result and errors.  For example stack traces may come with certain errors but some people dont want that (and others do)\nSince you are in charge of JSON serialisation, simply pull apart the list of errors yourself, create what ever map of them suits you with what ever data you want and then serialize that.. If you want a JSON Scalar then this looks pretty good for the \"literals\" that might come into the system.\nJSON is essentially a Map like scalar.  One thing to consider with Map like Scalars is that the breaking the symmetry of graphql query --> results.\nFor example a query\n{\n   hero {\n        name\n        power\n   }\n}\n\nwill produce a response like\n {\n    \"hero\" : {\n          \"name\" : r2d2\",\n           \"power\" : \"beeping, whistling,  saving\"\n     }\n }\n\nNote the symmetry - the response has the same shape as the response.  The leaf nodes (aka Scalars\" have 1 value which map the leaf nodes of the query.\nWith a Map like Scalar you have a leaf node query field but NOT a leaf value in the response.  Imagine power is a Map like scalar as you have imlemented.\n {\n    \"hero\" : {\n          \"name\" : r2d2\",\n           \"power\" : {\n                      \"key1\" : \"beeping\",\n                      \"key2\" : \"whistling\",\n                      \"key3\" : \"saving\"\n            }\n     }\n }\n\nThis is not to say that this is against spec but it does break the symmetry.  If you are happy with that then great.  \nI think the reason graphql does not define a Map like scalar is that it wants you to \"describe\" all the addressable fields.  In the above you have no way of knowing (as a consumer) what the keys of the Map like scalar might be.  Again this might be ok but the query itself is not specifying them.\nOne thing I dont know is how well upstream graphql client libraries can handle your Map like scalar.  Will something like Relay or Appollo JS clients be able to intrinsically understand your map like Scalar?  I am not sure.  I guess its not worse than any other scalar but most scalars have a single value say and this one does not.. I am going to close this as an issue in the code BTW. See https://github.com/graphql-java/graphql-java-extended-scalars for a JSON scalar.. @corydolphin - what is a Method Reference?  (also out of curiosity?). Yeah the trick with graphql is that you are mapping an opaque object to a\nnamed \"field\" at runtime not at code time\nSo there is no way to do a method reference that I know of since you dont\nknow the target object until the data fetcher runs.\nSo PropertyFetcher uses a reflective approach which by default is \"field\nname\" --> POJO getter name.\nSo a field \"name\" maps to a JavaBean getName() and so on.\nA method reference wont be possible to \"hold\" and apply to any opaque\nobject in java (that I know of - love to be shown how say)\nOn 23 October 2017 at 16:53, Cory Dolphin notifications@github.com wrote:\n\nIt allows a nice shorthand for referring to a method to e.g fulfill a\nfunctional interface.\nMy suggestion is that rather than have an implicit, reflection-based\ngetter (which is slow, and would fail at runtime if it could not be found),\nto instead use a method reference to the getter for the property.\nhttps://docs.oracle.com/javase/tutorial/java/javaOO/methodreferences.html\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/772#issuecomment-338554514,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSaDpiZOODB3MQwFbIUzyOLWOFkabks5svCm_gaJpZM4P2uj8\n.\n. Yeah I think you are right\n\nI have raised\nhttps://github.com/graphql-java/graphql-java/pull/797\nOn 24 October 2017 at 15:38, Cory Dolphin notifications@github.com wrote:\n\nWhat I'm suggesting is that instead of having it be \"automagic\",\ndevelopers are simply required to set the data fetcher as a method\nreference, and the api could be made easier to use. I.E. in our usage, we\nhave a wrapper, and thus our datafetchers for property-getters are just\ne.g. ObjectName::getThing\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/772#issuecomment-338871324,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSeSlTUtub-P3rBUtTdMFN_Q4BDtaks5svWnhgaJpZM4P2uj8\n.\n. Nope its not possible.  You're in charge of your own code.  \n\nYou wire together the execution strategies yourself and hence you need to wire in your custom handler at construction time.\nWhat is preventing you from using the following?\n newGraphql(schema).queryExecutionStrategy(\n        new AsyncExecutionStrategy(new MyCustomExceptionHandler())\n).build();\n\n. We wont be making a fix here unless a better reason can be articulated. I would take it up with the graphql-java-servlet and graphql-java-tools projects to be honest.\nA final immutable design is what we are after. The graphql spec mandates that input objects that come in via variables MUST be maps.\nhttp://facebook.github.io/graphql/October2016/#sec-Input-Objects\n\nThe value for an input object should be an input object literal or an unordered map, otherwise an error should be thrown. \n\nRecently graphql-java was changed (in 5.0) so that it enforces this spec behavior.\nSo we do not support the idea of having POJO classes as inputs.\nHowever your map of maps can be turned into a POJO via something like Jackson say if you are desperate to have a POJO inside your data fetcher.\nThat would involve a Map objs --> JSON --> POJO which is inefficient but allows what you want.\nWhether you use IDL or object type definitions the rules are exactly the same in this regard. Yes that is correct.  We will have to update the docs\n. > could that change have some performance impacts when you have a large result (= a lot of DataFetchers)?\nNo not any more than what we have today.  setAccessible has virtually no cost and all the cost is already in the reflective look up.\nThis is the approach take by most JSON parsers etc.. that is get direct access to the underlying fields.\nSince there will be a double lookup, then any one who wants to squeeze the absolute best performance can make their getters public as they were required to before.\nThis will just work more often for those who expect an object to be examined for values.\n. Thanks very much for this  PR. Actually we can do that later no problem. My reading of the graphql-js has this\nconst errors = isValidJSValue(value, varType);\n      if (errors.length) {\n        const message = errors ? '\\n' + errors.join('\\n') : '';\n        throw new GraphQLError(\n          `Variable \"$${varName}\" got invalid value ` +\n          `${JSON.stringify(value)}.${message}`,\n          [ varDefNode ]\n        );\n      }\nthat is it throws during execution if the type is invalid.\nThat said I am reading the code - not running it (yet).\nI am sympathetic to it being a validation error or just an \"graphql error\" however.  \nSo you offer of a PR is welcome.   \nBut its still not 100% clear that we should or should NOT throw during invalid InputObjectType values.\n. OK I concur - it catches a thrown exception and maps it to an error in the list\nI rewrote that test to ensure its about InputObjects\n```\nvar GQL = require('graphql');\nconst InputArgsType = new GQL.GraphQLInputObjectType({\n    name: \"InputType\",\n    fields: {\n        field1: {\n            type: GQL.GraphQLString,\n        },\n        field2: {\n            type: GQL.GraphQLString,\n        }\n    }\n});\nvar schema = new GQL.GraphQLSchema({\nquery: new GQL.GraphQLObjectType({\n    name: 'RootQueryType',\n    fields: {\n        hello: {\n            type: GQL.GraphQLString,\n            args: {inputObj: {type: InputArgsType}},\n            resolve() {\n                return 'world';\n            }\n        }\n    }\n})\n\n});\nvar query = 'query namedQuery($var: InputType!) { hello(inputObj: $var) }';\nvar variables = {\"var\": \"not-a-number\"};\nGQL.graphql(schema, query, null, null, variables).then(result => {\n    console.log(result);\n});\n```\nand it gets\n```\n{ errors: \n   [ { GraphQLError: Variable \"$var\" got invalid value \"not-a-number\".\n     Expected \"InputType\", found not an object.\n         at getVariableValues (/Users/bbaker/src/personal/node_gql/node_modules/graphql/execution/values.js:97:15)\n         at buildExecutionContext (/Users/bbaker/src/personal/node_gql/node_modules/graphql/execution/execute.js:207:54)\n         at executeImpl (/Users/bbaker/src/personal/node_gql/node_modules/graphql/execution/execute.js:121:15)\n         at execute (/Users/bbaker/src/personal/node_gql/node_modules/graphql/execution/execute.js:110:229)\n         at /Users/bbaker/src/personal/node_gql/node_modules/graphql/graphql.js:75:34\n         at graphqlImpl (/Users/bbaker/src/personal/node_gql/node_modules/graphql/graphql.js:59:10)\n         at Object.graphql (/Users/bbaker/src/personal/node_gql/node_modules/graphql/graphql.js:48:227)\n         at Object. (/Users/bbaker/src/personal/node_gql/test.js:35:5)\n         at Module._compile (module.js:570:32)\n         at Object.Module._extensions..js (module.js:579:10)\n       message: 'Variable \"$var\" got invalid value \"not-a-number\".\\nExpected \"InputType\", found not an object.',\n       locations: [Object],\n       path: undefined } ] }\n```\nThe code that does it is\ntry {\n    context = buildExecutionContext(schema, document, rootValue, contextValue, variableValues, operationName, fieldResolver);\n  } catch (error) {\n    return Promise.resolve({ errors: [error] });\n  }. We will reconsider this in light of this. Now present on master.  . Thank you. thanks. I want to get this merged first before the DataLoader fixes (its semi incorporates it) plus more. We would consider it but would need more detail on how this would be placed inside graphql-java\nThat library as is has NO edges - eg no HTTP / JSON just the core engine.  So for example HTTP headers and URLs and so on meaning nothing to the core graphql-java library.\nSo how do you see the support being implemented?\nWe have tracing support for the Apollo proposed tracing spec via graphql.execution.instrumentation.tracing.TracingSupport as an example already.  Its uses\nthe spec \"extensions\" map to place tracing data of the \"fields\" and fetchers\n. Closing for now as we are not likely to do this.  It can be done via a custom instrumentation. OK got it - up that seems a bit wrong.  The other parts of the code use a  graphql.schema.idl.EnumValuesProvider as an indirection.\nThis part does not.\nThat said the spec has been pretty specific about what values can be defaulted in what way and hence we need to double check that.. Your dont specify the database you are using so I will assume a relational one (with ordering)\nIn order to paginate any database you need some sort of ordering.\nSo lets assume you have a table of SALES ordered by sales date\nTo get the first three items you need a LIMIT\nselect * from SALES  order by SALES.ORDER_DATE limit 3\n\nOk that gets 3 out at a time.  You simply then reflect that in the Relay pageInfo that you use.\nRelay has the concept of cursors which is an encoded (typcially base64) string that contains instructions of the server.  The client says \"get 3 records after this cursor\"\nYou can encode the ordering key (sales.order-date above) into this.\nSo the query becomes\nselect * from SALES  where SALES.ORDER_DATE > cursorDecodedDate order by SALES.ORDER_DATE limit 3\n\nYou need to encode  / decode the ordering key into the \"cursor\" and sql query\nTo know if there is \"nextPage\" or not simply select +1 on the desired limit.  So select4 if you want 3 records.  If you get 4 there is more.  If you get 3 or less then there is no more.\n. The SimpleListConnection is pagination of an in memory list as you say.  Not that useful in production code.\nSince pagination is very application specific, you often need build your own Connection implementation.  For example deciding on cursors is very application specific.\nRecently I was playing with putting a graphql interface of an existing REST API which has page=N&size=Y type pagination.\nI ended up with\nhttps://github.com/bbakerman/graphql-java-examples/blob/master/src/main/java/com/graphql/example/proxy/relay/ForwardOnlyFixedPagedDataSet.java\nhttps://github.com/bbakerman/graphql-java-examples/tree/master/src/main/java/com/graphql/example/proxy/relay\nYour PR seems ok.  I left a specific comment on it there.. I am going to close this as more a question than a bug.  Thanks for the question however. Done. The graphql-js reference implementation has\n````\nfunction shouldIncludeNode(\n  exeContext: ExecutionContext,\n  node: FragmentSpreadNode | FieldNode | InlineFragmentNode,\n): boolean {\n  const skip = getDirectiveValues(\n    GraphQLSkipDirective,\n    node,\n    exeContext.variableValues\n  );\n  if (skip && skip.if === true) {\n    return false;\n  }\nconst include = getDirectiveValues(\n    GraphQLIncludeDirective,\n    node,\n    exeContext.variableValues\n  );\n  if (include && include.if === false) {\n    return false;\n  }\n  return true;\n}\n```\nI say this only so I can double check we have the right logic according to both spec and reference implementation. Thanks for making this PR. This is an example test that might pass with this mechanism\n    GraphQL graphQL = newGraphQL(starWarsSchema).build()\n\n    def query = '''\n        query A {\n            hero {\n                name\n            }\n        }\n\n        query B {\n            human(id:\"1000\") {\n                name\n            }\n        }    \n    '''\n    ExecutionInput input = newExecutionInput().operationNames([\"A\",\"B\"]).query(query).build()\n\n    def er = graphQL.execute(input)\n\n    then:\n    er.errors.size() == 0\n    er.data[\"A\"] == [hero: [name: \"R2-D2\"]]\n    er.data[\"B\"] == [human: [name: \"Luke\"]]\n\n. I spoke to the lead of Sangria about there implementation and a couple of thigns stood out\nFirst off the combined batching and @export as a featue.  \nWhen they have say 3 operations. A, B,C they applied a dependency resolution process to decide the order.  \nif they got a cyclic dep thet refuse the whole operation.\nOtherwise thet worked out that it sould be B,C,A or A,C,B based on @exported variables\nThey streams the results out the other side. \nThis allows for an order of say B,C,A and B can finish first as an execution result, then C and then A.\nThis allows you to send back B as results, and then C and then A.  In order words the story then comments then likes say??. > We definitely have use cases for performing multiple operations in a single request.\n@alexgenco - can you expand your use cases.  \nAs for thoughts on this the real challenge is the \"protocol\" for returning results.  Should they be combined?  Should they feed into each other via \"variables\" and hence need dependency resolution?\nShould the results be \"streamed\" much like subscription such that a client gets operation A, then B then C?\nShould they just assume the top ones are mutations and the last is a query?\nReally its much of the same concerns I had on https://github.com/facebook/graphql/issues/375.   I originally proposed this RFC but have not chased it up hard to try to get it in the spec as its a slow process.  I am not sure that there will be a \"spec\" compliant \"protocol\" to be honest\nThis is the blocking design challenge to me.\n. BTW this is not ready yet - there is more work to be done around Instrumentation but I wanted to show some early working code. Closing this for now. I am going to see yes it works with mutations because it captures what ever output fields have @export(as:\"foo\") on them.\nBut thats a great test to add. @guy120494 - yup it works with mutations as expected.  I added a test for that case. Closing as failed experiement. I think we am happy to accept this but can you explain your comment\n\nThis breaks the Engine UI. Eg:\n\nWhat engine UI... Apollo?  Something else??  \nCan we please have more background on this PR.. Thanks for this.  Your are correct. The spec says differently \ud83d\udc4d \nhttps://github.com/apollographql/apollo-tracing\n\nThe startOffset of parsing, validation, or a resolver call is in nanoseconds, relative to the request start.\n\nthat is 'a resolver call is in nanoseconds, relative to the request start.'\nSo which is it?\nI am happy to accept this this way as long as the spec gets updated as well.. We would be happy to accept these changes.  What I would do is invent a GraphqlFieldVisibilityEnvironment class (with builder) that contains the variables and change the API to include these.\nThis would be a breaking change but we can role it out in 7.0 say\nAlso be aware - is the execution context always available?? I am not sure in all cases. See the PR for the reasons for closing this issue and also the workaround to do what you want. Thanks for this PR.\nWow it really became viral as to where the field visibility env needs to go.\nThis is a fairly big breaking change and hence needs to go into a major version \nWe will have a deep look at this and see if we cant find a way to reduce the viral signature change required. Thanks for your efforts on this PR.  You have done an extensive job.\nHowever the viral \"change ALL the places\" approach has been nagging at me.  Its just to much change I think.\nGraphqlFieldVisibility is meant to be schema specific, that is attached to schema.  And hence your challenge of getting \"query state\" into the document visitors and so on.\nHowever there is another way to have a schema that is \"query\" specific without all these code gymnastics.\nJust transform it before use into the GraphQl object.\nLets assume your context object is the \"user permissions\" and hence field visibility is based on that\n GraphqlFieldVisibility fieldVisisibility = new UserPermsFieldVisisbility(getCurrentUser());\n\n  GraphqlSchema staticSchema = getStaticSchema()\n\n GraphqlSchema perQuerySchema = staticSchema.transform(builder -> \n       builder.fieldVisibility(fieldVisisibility));\n\n GraphQL graphql = GraphQl.newGraphQL(perQueryschema).build():\n\n // do queries now\n\nThe above can have a static built once GraphqlSchema but then you transform it just before you start a query.  This transform is a shallow clone operation and super cheap.\nThe new UserPermsFieldVisisbility(getCurrentUser()) would be the code that creates your per user / per request field visibility implementation.  It can do whatever logic your would have done with the \"context object\"\n . I am going to close this PR.  As stated above there is too much unintended change to get the context to the field visibility call plus I have outlined a way to achieve the same outcome.\n\nWe do really appreciate the effort you have put into this PR.  Its quality but its not the change we want to have in the code base.. Its not a crazy idea.  The reference JS implementation has no names but then it doesnt have interfaces in JS to inherit from.. Looking into this (and quickly implemented it) - it breaks Introspection\n\nList\nLists represent sequences of values in GraphQL. A List type is a type modifier: it wraps another type instance in the ofType field, which defines the type of each item in the list.\nFields\nkind must return __TypeKind.LIST.\nofType: Any type.\nAll other fields must return null.\nNon-Null\nGraphQL types are nullable. The value null is a valid response for field type.\nA Non\u2010null type is a type modifier: it wraps another type instance in the ofType field. Non\u2010null types do not allow null as a response, and indicate required inputs for arguments and input object fields.\nkind must return __TypeKind.NON_NULL.\nofType: Any type except Non\u2010null.\nAll other fields must return null.\n\nThis will cause the name to be listof_foo which is wrong (and the test catch).\nWe could fix that up...but the more I think of it - the more I like to keep it as it is. Another option would be to make the error collection available vis the data fetcher environment and have the DF contribute to the list perhaps?\nWe also have to think about the \"path\" of the errors.  The spec says there should be ONLY one error per path.  Will this break spec?. @andimarek  - are you still unhappy about the new return type.  I think its the only sensible way to pass back both data and errors.. Thanks for much for doing this PR.  For Chinese readers it helps spread the knowledge.\nI do worry that this will quickly get out of date, since the .po keys are text from the source document.  I guess that is how .po files work (I have not worked with them in anger) and so be it.\nWe will be aggressively adding new documentation as the project progresses.\nI worry that this will atrophy but some documentation is better than none.. Aliases are a syntatic sugar that allows you to rename a field in the results.\nSo you will get a map result with b1 and 'b2` in the result.\nHow a field name (+aliases) gets applied to a source object is the job of the data fetcher.\nOut of the box you get a Java data fetcher that takes the field name and \"JavaBean\" style tries to find data for that field or its the source is a map does a map read.\nHowever you can write your own DataFetcher that decides on an  object access strategy that respects aliases say.\nYou need to decide a strategy that makes sense for you. \nThere are challenges with using aliases, namely in fallback. If you try to read the \"b1\" value should it be null of its not found or should it fall back to the underlying field name \"bar\"??\nThat question cant be easily answered I think in a generic sense.  So having a specific \"AliasRespectingDataFetcher\" might make sense but its local to how you want to run your code and not generic for all.. Closing this as its more a question than a bug. A call has been made that this is not spec compliant.  We take spec compliance very seriously so lets re-open this and investigate whether in fact its wrong. After reading the spec link it does NOT say that aliases are to be used to look up underlying values.\nIt says that aliases are to be used as the outgoing property names on results (which is to be the field name by default and the alias to allow unique views on the field).\nLooking into the graphql-js reference implementation it has the following default resolver\n/**\n * If a resolve function is not given, then a default resolve behavior is used\n * which takes the property of the source object of the same name as the field\n * and returns it as the result, or if it's a function, returns the result\n * of calling that function while passing along args and context value.\n */\nexport const defaultFieldResolver: GraphQLFieldResolver<any, *> = function(\n  source,\n  args,\n  contextValue,\n  info,\n) {\n  // ensure source is a value for which property access is acceptable.\n  if (typeof source === 'object' || typeof source === 'function') {\n    const property = source[info.fieldName];\n    if (typeof property === 'function') {\n      return source[info.fieldName](args, contextValue, info);\n    }\n    return property;\n  }\n};\nIt ONLY looks up by field name - never by alias\nI am going to close this issue again.  We do have a PR open at the moment on this but I am also inclined not to support it as its not specified behaviour\ncc: @swaters-atlassian . Wow this is one the best presented PRs I have ever seen!\nThanks for this. Thank you for this PR. I dont have a problem with breaking out the DF runtime wiring from the schema definition.\nSo the more interesting challenge is how you put it back together.\nShould IDL wiring vs Object Schema wiring get unified back into one RuntimeWiring subsystem.\nBecause a Object Schema == an IDL schema when the runtime DFs are missing . I have looked further into this and we have structural problems in the ExecutionStrategy that means that we dont descend in perfect sets of layers\nSo given your tree\n```\n  1\n/   \\\n\n2    3\n  / \\   / \\\n4  5 6  7\n```\nThe code does this per field\nCompletableFuture<ExecutionResult> result = fetchField(executionContext, parameters)\n                .thenCompose((fetchedValue) ->\n                        completeField(executionContext, parameters, fetchedValue));\nThat is fetch the field (which can involve the dataloader) and complete the field which can cause the engine to descend and restart itself recursively.\nThere for the order can be as you observed.  As it gets to node 2 it descends its list because it calls dispatch for that inner recursive call.\nI think we would need to rewrite the ExecutionStrategy so that fetched all fields first in a level and then called resolve.  But even then it would need to know about lists and object types since they cause the engine to descend for those fields.\nHmmmm. We have greatly improved the data loader performance by \"tracking\" the levels encountered and dispatching the DL when we know we have have \"dispatched\" all the outstanding field fetchers including ones for lists.\nWe have tests that have shown it reduces it greatly.\nI am going to close this issue as the  9.0 release is imminent. Whoops - jumped the gun - this didnt make it into 9.0.  Sorry. See https://github.com/graphql-java/graphql-java/pull/990. The base graphql-java library does not deal with HTTP or error codes and so on.  Its purely the engine of executing graphql queries.\nThat example uses graphql-java-servlet which is another library.\nPerhaps @kaqqao might be able to help here as he was the author of that tutorial.\n. Thanks for reporting - yes to be useful beyond just breaking changes, we should consider additions.  \nOff hand I thought it reported them as INFO but if not it could be another category. See https://github.com/graphql-java/graphql-java/pull/847 - which addsa public (versus private) getter\nBy the way you could use delegation in your \"everywhere fetcher\"\n DataFetcher specialOne = env -> {\n       String fieldName = env.getField().getName();\n       if (isSpecialField(fieldName) {\n            return viaSepcialAccess(fieldName);\n       }\n       return new PropertyDataFetcher(fieldName).get(env);\n }\n\nCreating a new java object inline in this method goes on the stack and is super cheap as to be almost the same as  a method call. Its now has a public getter. Once again another excellent  PR... thanks very much. @guy120494 - We dont offer composed GraphqlFieldVisibility today nor plan to.\nI think you need to compose on the \"inside\" of the GraphqlFieldVisibility interface.  Its your conditions that decide what should or should not be included.  I would invent a composed set of conditions of your own choice and merge them together to provide a unified GraphqlFieldVisibility collection of allowed fields\n. Instrumentation does not return a list of fields that need merging\nImagine 2 field visibilities A and B on the fields\nname,age, secretIdentity\n\nA call to A returns [name,secretyIdentity]\nA call to B returns [age]\nSo thats the field list then?  union  of the list / intersection \nIts simpler if you decide that set of rules.\nAs for instrumentation, we provide multiple implementations that dont need to be conflict resolved. Re-reading the spec more closely I can confirm this is a bug. Now fixed. Thanks for this... and yes I agree the optional is not as clean. Please read http://graphql-java.readthedocs.io/en/v6/execution.html and the section Exceptions while fetching data\nIt outlines how you can change the errors you see namely via     DataFetcherExceptionHandler\nYou seem to be getting errors from https://github.com/graphql-java/graphql-java-servlet which is not this library.  I suspect that library is masking your errors not the base graphql-java library\nYou can extend the servlet and override the method that filters exceptions to allow more to be shown to the client.\n. Regarding the second comment, the \"extend\" keyword is only applicable to object types.\nThere is no \"extend\" for input type\ntypeExtensionDefinition : EXTEND objectTypeDefinition;\n\nobjectTypeDefinition : TYPE name implementsInterfaces? directives? '{' fieldDefinition+ '}';\n\nRegarding the first comment let me have more of a think about how one might handle \"reduced\" input types.   It strikes me as a little weird because you are restricting something that the client might have already INPUT and not something that they are restricted from seeing.\nCan you explain more about why a non admin can not submit a \"userNames\" field.  Is it because the code that acts on \"usersNames\" is unaware of the \"application roles\"?. Thanks for the detailed reply.  It does help inform how we make fixes to the library.\nI can \"buy\" your argument about consistency between Introspection and calls and in fact that is why we added \"field visibility\" to the library in the first place.. Thanks for reporting this.. > Is there a way of getting schoolId from within the data fetcher for Student (without specifying it as a parameter)?\nNo - arguments to fields are declared in the schema so a top level like\n type Query {\n     school(schoolId : ID) : School\n }\n\nThat top level query type has a school field and the data fetcher behind that gets the schoolId as an agument\nHave a look in here at the section \"DataFecthers\" : http://graphql-java.readthedocs.io/en/v6/execution.html\nThe execution context is typically per request.  But I can say for sure since I havent used graphql-spring-boot\nThe execution context can be a place to put security tokens and so on that you need to get data in your fetchers\n\nI assume I can create my own implementation of the DataFetchingEnvironment that returns a GraphQLContext wrapper or something, but I wanted to be sure:\n\nYes you can - see that link\n. Closing this as its not a bug. We have failing tests Don\nSchemaPrinterTest\nSchemaDiffTest\n. @mrdon2 - I am confused here about exactly how to repduce this problem.\nI can see the graphql.introspection.IntrospectionResultToSchema given back a graphql language element, name a list of  List that have default values.\nAnd I can see the AST printer correctly printing them as\ntype QueryType {\n   hero(\n   #comment about episode\n   episode: Episode\n   foo: String = \"bar\"\n   ): Character @deprecated(reason: \"killed off character\")\n }\nIs it some where else that defaults are not encoded correctly?\n. Is it compound graphql values perhaps?. I have found the source of the problem.  It was because the default value printing in a couple of places assumed string and not the AST type proper\nThere is now a PR for this.. Thanks you for this detailed issue.\n\nIs this the reference specification used for the graphql-java implementation?\n\nThe graphql-java project aims to follow the graphql spec as much as possible.  It was originally a port from the graphql-js reference implementation and we often use graphql-js behaviour as a \"tie breaker\" in expected behavior.\nAt first glance your Rn expectations look right however we will write them up in test form and investigate them.  The Scalars.GraphqlString and Scalars.GraphqlBoolean are responsible for co-ercing values and are likely to be the place to fix potentially.\nGiven that they are only fixed on graphql-js master 10 days ago then its likely they same bugs are in the graphql-java port.\nOnce again thanks for reporting in such detail.  A Pull Request with groovy spock tests outline expectations would be a great way to report such things in the future.\n. Looking further into this it is indeed the Scalar.XXX.parseValue method that is the source of the action.\nThe graphql spec says\nhttp://facebook.github.io/graphql/October2016/#sec-String\n\nString\nInput Coercion\nWhen expected as an input type, only valid UTF\u20108 string input values are accepted. All other input values must raise a query error indicating an incorrect type.\n\nSo reading that the input object to a Scalar.GraphqlString should only be a valid UTF-8 string.  \nHowever the graphql-js (reference implementation) has the following as its implementation\n function coerceString(value: mixed): ?string {\n   if (Array.isArray(value)) {\n     throw new TypeError(\n        `String cannot represent an array value: [${String(value)}]`,\n      );\n  }\n  return String(value);\n}\n\nSo it will take any object value (other than a list) and use JavaScript co-ercion to make it a String.  so number input, boolean input and so on.\nThe graphql-java is also currently very liberal \nreturn input.toString();\n\nSo the dilema we now have is that the spec says one thing but the reference implementation does another.\nSo out there in graphql production land, a number variable input to a String scalar type will succeed but the spec says it shouldnt.  This expectation versus specification is what I am struggling with here.\n. One thing to remember about graphql is that the total set of possible objects MUST be able to be expressed in schema (even with type resolvers)\nThat is for an interface / union of type IFoo you need to be able to have concrete types for all possible variables.  So exactly how dynamic do you need yuor types.\nI dont think its possible to write a response to your question in a simple issue.  You are asking...how do I build a graphql thing\"  Its too broad\nI think you should start with http://graphql-java.readthedocs.io/en/v6/ and https://www.howtographql.com/graphql-java/0-introduction/ and get a handle on building the app in general.\n. I am closing this issue as its not a problem with the software - rather its a general call for help . Schemas in graphql (by spec) are static.  if you contact a graphql server (say on /graphql) then it should report the same schema and the complete schema.  The point is that you can discover what's on offer.\nYou can offer and UBER schema (all possibilities) and then restrict what types some one can see via FieldVisibility.\nI think you might be on the wrong track in thinking that a schema is completely dynamic.  Imagine a relational database schema that was different every time you asked?  How can you write a program based on that?\nIt would help if you expanded aspects you want to make dynamic. I am closing this issue because it not clear what is being asked or that there is a software issue. Sorry but its not going to happen.  The whole point of async support we put into graphql 4 was to have a JDK 8 compliant system without extra dependencies (including Guava).\nI am sorry that you have a environment blacklist on CompletableFuture (that seems crazy to me on a JDK 8 based system) but we have embraced CompletableFuture to represent our \"promises\".\nCF is viral in most places in graphql-java and cannot be easily replaced. The reason is I think that you are  not naming the operation as a mutation.\nSee http://graphql.org/learn/queries/#mutations\nYou need to put it something like\nString query=\"mutation X {Create(name:\\\"shrikant123\\\"){name}}\". You need to define a mutation type at the top of your schema.\nhttps://github.com/thangbqvng/graphql-demo/blob/master/resource/schema.graphqls\nLooks ok\nHowever this is not pure graphql-java code re: import graphql.schema.GraphQLSchema;   This is some other library.  . GraphQLQueryResolver is not a part of graphql-java per se-- but some other library built on top of graphql-java.\nDo you know what library this comes from??   Its probably graphql-servlet project\nhttps://github.com/graphql-java/graphql-java-servlet/blob/master/src/main/java/graphql/servlet/GraphQLQueryProvider.java\nAsk them for help I think\n  . Since DataLoader instances typically \"cache\" values, you should only use them in a per request basis generally.\nAre you sure you want to share data loader instances across requests.  Its seems fraught.\nThe readme here explains more : https://github.com/graphql-java/java-dataloader\nIf you are intent on this approach, I would derive a new DataLoaderRegistry class that knows how to get the per session DL for itself.\n  . Already in place. This is in the code base. Fixed via https://github.com/graphql-java/graphql-java/pull/898. PR accepted (and tweaked). I decide that the changes where small enough and the wins high enough to make the changes directly myself on another PR\nhttps://github.com/graphql-java/graphql-java/pull/898\nSo this code is in effect now on master. @gkesler - this is pretty much the changes I asked of you made from your branch\nSee #897 for the original PR\n. Related to issue #896 . Sure got for it.  Please submit a PR\nI personally didnt even know OptionalLong et al existed.  . We have as a project goal of keeping the library as dependency free as possible\nSo yes we will choose to duplicate code at the expense of adding new dependencies.\nThat is what things like commons-xxx or guava say are not a dependency.\nSo far it has served us really well.. Investigations reveal that empty types are allowed\nhttps://github.com/graphql/graphql-js/blob/master/src/language/tests/schema-kitchen-sink.graphql#L15-L29\nand the RFC for the type spec updates is here\nhttps://github.com/facebook/graphql/pull/90/files\nnamely\n ObjectTypeDefinition : Description? type Name ImplementsInterfaces? Directives[Const]? FieldsDefinition?\n\nthat is fields are optional. Do you think your new TreeTraversal code could be applied to BatchedExecutionStrategy?\nThat code is pre me and is a bit of a mind bender in trying to understand?. The contribution model is to make a fork (as you have done) into another repo and then make a PR (like this) over to this main repo.\nThis is very much the GitHub contribution model.\nThis is the right way . The work break down on this is\n\nAdd the new TypeExtensions into the .g4 antlr file\nAdd the corresponding AST POJOs into graphql.lang\nAdd support into the AstPrinter for printing these new element\nAdd support into the SchemaParser for interpretting these elements\nAdd support into graphql.schema.idl.SchemaTypeChecker to check the invariants of the new type extensions (such as dual defined fields etc...)\nAdd support in SchemaGenerator for smoooshing all the type extensions together\nAdd GraphqlDirective support to all the runtime object types such as graphql.schema.GraphQLInputObjectType - where directives come from the AST directives\nUnit test it as much as sensible\nIntegration test it end to end from SDL text to type system. \nAssad to you to mate!. Are you building your GraphQLObjectType fields by hand or by schema file or some other mechanism.\n\nBasically a GraphQLFieldDefinition contains the data fetcher factory to use when getting a value from that field\nBy hand you use the GraphQLFieldDefinition builder\nIf you are using Schema generation then a WiringFactory allows to it be specified\nSee graphql.schema.idl.WiringFactory#getDataFetcherFactory\nif you are using annotation magic from some other library build on top of graphql-java then I dont know how they allow you to do it.. When used with a GraphQLFieldDefinition it is simply and indirection for getDataFetcher.\nThat is instead of  getting the data fetcher directly, it calls a factory and hence you can swap in implementations between calls if you need it.\nor you could it to use Spring ApplicationContext to get the fully wired bean that is the data fetcher say.  Think of it how BeanFactories work in Spring... but for data fetchers\nThe basic ones have a data fetcher factory that delegates immediately to the standard Field / PropertyDataFetchers. \n        public GraphQLFieldDefinition build() {\n        if (dataFetcherFactory == null) {\n            if (isField) {\n                dataFetcherFactory = DataFetcherFactories.useDataFetcher(new FieldDataFetcher<>(name));\n            } else {\n                dataFetcherFactory = DataFetcherFactories.useDataFetcher(new PropertyDataFetcher<>(name));\n            }\n        }\n        return new GraphQLFieldDefinition(name, description, type, dataFetcherFactory, arguments, deprecationReason, directives, definition);\n    }\n\n. I am going to close this issue because its not a bug and I think its been explained. I cant see your graphql query not can I see your variables you pass in.\nSo I am sorry without that I cant help you. Can you please write a unit test that shows this bug in action.  A rough guess says it should work\nI unit test would help me debug this a lot. Ahh I found your problem by writing this unit test\n```\n    def \"test enum list as args\"() {\n        def spec = '''\n            type Query {\n                countries(regions: [Region!]): [Country!]\n            }\n        enum Region {\n          EUROPE\n          ASIA\n        }\n\n        type Country {\n          code: String!\n          name: String!\n          regions: [Region!]\n        }\n    '''\n\n    def countriesFetcher = new DataFetcher() {\n        @Override\n        Object get(DataFetchingEnvironment env) {\n            assert env.getArgument('regions') != null\n            return null\n        }\n    }\n    def schema = TestUtil.schema(spec, [Query: [countries: countriesFetcher]])\n    def graphQL = GraphQL.newGraphQL(schema).build()\n\n    when:\n    def query = '''\n            query getCountries($regions: [Region!]) {\n                countries(regions: $regions) {\n                  code\n                  name\n                  regions\n                }\n            }\n        '''\n    def result = graphQL.execute(ExecutionInput.newExecutionInput()\n            .query(query)\n            .variables([regions: ['EUROPE', 'ASIA']])\n    )\n\n    then:\n\n    result.errors.isEmpty()\n\n}\n\n```\nWhich works.  Your problem is that your have specified the Regions argument and Regions variable definition differently originally\n countries(regions: [Region!])\n ....\nquery getCountries($regions: [Region]!) {\n\nthat is [Region!]   does not equal [Region]!\nthe first is a list of non null enums and the second is a non null list of (possibly null) enums\nThats the problem here.\nI will look to see what we can do in the error message to make it more apparent\n     . Hmm I need to look deeper\nAlso do you know about : https://github.com/donbeave/graphql-java-datetime\n. Also I would need a copy of your ScalarCode to judge. The parseLiteral is used during execution to create the variables map and to tur Argument values (which are AST) into argument values\nprotected CompletableFuture<Object> fetchField(ExecutionContext executionContext, ExecutionStrategyParameters parameters) {\n   ...\n        Map<String, Object> argumentValues = valuesResolver.getArgumentValues(fieldVisibility,\n    ....\nSee graphql.execution.ValuesResolver#getArgumentValues(graphql.schema.visibility.GraphqlFieldVisibility, java.util.List<graphql.schema.GraphQLArgument>, java.util.List<graphql.language.Argument>, java.util.Map<java.lang.String,java.lang.Object>)\n. Ok so I took your code and wrote a unit test for it (in Groovy which is what we use to test graphql-java)\n```\n    def \"test912\"() {\n        GraphQLScalarType GraphQLTimestamp = new GraphQLScalarType(\"Timestamp\", \"Timestamp\", new Coercing() {\n            @Override\n            public Object serialize(Object input) {\n                return input;\n            }\n        @Override\n        public Object parseValue(Object input) {\n            GregorianCalendar calendar = new GregorianCalendar();\n            BigInteger value = new BigInteger(String.valueOf(input))\n            calendar.setTimeInMillis(value.multiply(new BigInteger(\"1000\")).longValue());\n            return calendar;\n        }\n\n        @Override\n        public Object parseLiteral(Object input) {\n            if (input == null) {\n                return null\n            }\n            GregorianCalendar calendar = new GregorianCalendar();\n            calendar.setTimeInMillis(((IntValue) input).getValue().multiply(new BigInteger(\"1000\")).longValue());\n\n            return calendar;\n        }\n    })\n\n    def spec = \"\"\"\n            type Query {\n                field1 (arg : Timestamp) : Timestamp\n                field2 (arg : Timestamp) : Timestamp\n            }\n\n            scalar Timestamp\n\n    \"\"\"\n    def argEchoDataFetcher = new DataFetcher() {\n        @Override\n        Object get(DataFetchingEnvironment environment) {\n            return environment.getArgument(\"arg\")\n        }\n    }\n    def schema = TestUtil\n            .schema(spec, RuntimeWiring.newRuntimeWiring()\n            .scalar(GraphQLTimestamp)\n            .type(\n            newTypeWiring(\"Query\")\n                    .dataFetcher(\"field1\", argEchoDataFetcher)\n                    .dataFetcher(\"field2\", argEchoDataFetcher)\n    ).build())\n\n    def graphQL = GraphQL.newGraphQL(schema).build()\n\n    def bDay = 666\n\n    when:\n    def query = '''\n        query OpName( $var1 : Timestamp) {\n            field1(arg : $var1)\n            field2(arg : 1) \n        }\n    '''\n    def result = graphQL.execute(newExecutionInput().query(query).variables(var1: bDay))\n\n    then:\n    result != null\n    (result.data['field1'] as GregorianCalendar).toInstant().toEpochMilli() == 666000\n    (result.data['field2'] as GregorianCalendar).toInstant().toEpochMilli() == 1000\n\n```\nIt works as expected.  However I did need to tweak your Corecing function a little\nBasically you used IntValue.getValue in the parseValue method.  This is not right.  The objects that come into parseValue are from the variables map and are not AST literals.\nThat is what parseLiteral handles\nNotice in the query\n query OpName( $var1 : Timestamp) {\n            field1(arg : $var1)\n            field2(arg : 1) \n        }\n\nWe have 1 field whose argument from from the variable map (field1) and one that is an AST literal (field2)\nBoth get to the data fetcher as expected. I am going to close this issue because the system is working as expeceted if the Coercing is written correctly.\nI did  find a bug while doding this : https://github.com/graphql-java/graphql-java/issues/916\nwhich explains if null workaround in the parseLiteral above (when used with Schema generation).. Yes - we dont currently hold SDL directives into the runtime system - but we are adding support for it and hence can add support to print directives\nThanks for reporting...we will get onto it\n. Work breakdown \n\nwe start with printing directives from GraphqlObjectType / GraphqlFieldDefinition\nwe add the other types once we have directives on them. Thanks for reporting this issue\n\nI wrote this unit test to try and reproduce it.\n```\nclass Issue921 extends Specification {\ndef \"can run introspection on a default value enum schema\"() {\n    def spec = '''\n        type Thread {\n            id: ID!\n            title: String!\n            content: String!\n        }\n\n        enum ThreadSort {\n            NEWEST_FIRST\n            OLDEST_FIRST\n            MOST_COMMENTS_FIRST\n        }\n\n        type Query {\n            allThreads(sort: ThreadSort = NEWEST_FIRST) : [Thread!]!\n        }\n        '''\n\n    def qLSchema = TestUtil.schema(spec)\n    def graphql = GraphQL.newGraphQL(qLSchema).build()\n\n    when:\n    def result = graphql.execute('''\n            {\n              __schema {\n                queryType {\n                  fields {\n                    args {\n                      defaultValue\n                    }\n                  }\n                }\n              }\n            }   \n        ''')\n\n    then:\n    result.errors.isEmpty()\n\n    def json = JsonOutput.toJson(result.toSpecification())\n\n    json == '{\"data\":{\"__schema\":{\"queryType\":{\"fields\":[{\"args\":[{\"defaultValue\":\"NEWEST_FIRST\"}]}]}}}}'\n}\n\n}\n```\nBut it works as expected.\nCan you please check the assumptions here.\nThis was on latest master - can you confirm what version of graphql-java you are running please\nI created this PR to demonstrate the bug report ...where it works\nhttps://github.com/graphql-java/graphql-java/pull/926. Thanks for your efforts on this.  I have turned the unit test into a full fix PR. So this is not complete yet because Schema printing is not in place.  But I need the other PR #923 in place first and then add the extra types. Thanks for this.  . I had a look into this via this unit test\n```\n    def badScalar = new GraphQLScalarType(\"BadScalar\", \"BadToTheBone\", new Coercing() {\n        @Override\n        Object serialize(Object dataFetcherResult) {\n            return null\n        }\n    @Override\n    Object parseValue(Object input) {\n        throw new CoercingParseValueException(\"BadToTheBone\")\n    }\n\n    @Override\n    Object parseLiteral(Object input) {\n        return 1;\n    }\n})\n\ndef \"scalar_coercion_reporting\"() {\n    def runtimeWiring = RuntimeWiring.newRuntimeWiring().scalar(badScalar).type(\n            TypeRuntimeWiring.newTypeWiring(\"Query\").dataFetcher(\"field\", new StaticDataFetcher(\"hello\")).build())\n            .build()\n    def schema = TestUtil.schema('''\n        scalar BadScalar\n\n        type Query {\n            field(arg : BadScalar) : String\n        }\n    ''', runtimeWiring\n    )\n\n    def graphQL = GraphQL.newGraphQL(schema).build()\n\n    def executionResult = graphQL.execute(ExecutionInput.newExecutionInput().query('''\n        query X($var : BadScalar) {\n            field(arg : $var) \n        }\n    '''\n    ).variables([var: 'x']).build())\n\n    expect:\n    !executionResult.errors.isEmpty()\n\n}\n\n```\nIt ends up with the following error in the result\ngraphql.schema.CoercingParseValueException: Variable 'var' has an invalid value. BadToTheBone\nThe contract on scalar Coercing is that parseValue is to return CoercingParseValueException not a general RuntimeException.  We could make that more clear say.\n/**\n * Called to resolve a input from a query variable into a Java object acceptable for the scalar type.\n *\n * @param input is never null\n *\n * @return never null\n *\n * @throws graphql.schema.CoercingParseValueException if value input can't be parsed\n */\nI parseValue(Object input);\n\nThe parseValue method is meant to be resilient on its inputs and it should catch runtime exceptions say and translate them into CoercingParseValueException \nThe parseLiteral is even more strict.  It needs to return no exceptions.\n/**\n * Called to convert an query input AST node into a Java object acceptable for the scalar type.  The input\n * object will be an instance of {@link graphql.language.Value}.\n *\n * @param input is never null\n *\n * @return A null value indicates that the literal is not valid. See {@link graphql.validation.ValidationUtil#isValidLiteralValue}\n */\nI parseLiteral(Object input);\n\nIt indicates invalid literals via returning null (not exceptions).  This is because the parse will handle the AST literals mostly in shape, but a Timestamp scalar that takes a StringValue AST literal MUST not throw exceptions on parseLiteral.\nRather than add new ways for runtime exceptions to be handled out of the Coercing I think I would rather update the JavaDoc about the contract involved. Thoughts @andimarek  / @kaqqao ?. Oh and one other thing\n    try {\n        coercedVariables = valuesResolver.coerceArgumentValues(graphQLSchema, variableDefinitions, inputVariables);\n    } catch (RuntimeException rte) {\n        if (rte instanceof GraphQLError) {\n            return completedFuture(new ExecutionResultImpl((GraphQLError) rte));\n        }\n        throw rte;\n    }\n\nif the runtime exception is a GraphqlError, it will be transformed into the result.. CoercingParseValueException is a graphl error and hence will turn up in the errors response.  But a runtime exception that is not will buble to the top.. I have updated the documentation and javadoc.  This issue is working as at runtime however. Are you sure you are using pure graphql-java and not some other graphql-java based library that wraps graphql-java?  \nBecause none of the code above even exists in graphql-java as described, eg the .file(\"schema.graphqls\")) and so on are not from our code base\nis it perhaps https://github.com/graphql-java/graphql-java-tools ??\n. See #944  . yes this makes sense -  we have it on RuntimeWiring via a getScalars() method but yes the WiringFactory should allow it.  \nPlease make a PR if you can. See #944. OK PR feedback in - also added AST printing. cc: @kaqqao  - thoughts. No longer needed. See #944. How are you resolving the Timestamp scalar type?\nTimestamp is not a native scalar type in graphql-java (but there are libraries for it)\n. I suspect you are getting parse errors under the covers. Check out the values in executionContext.getVariables() before its passed into the resolver code.\nThat contains the variables as defined by the outside query.  Check you have the input you expect.\ngraphql.execution.ValuesResolver#coerceValueForScalar is really the only place where it calls parseValue(). Ahh I got it now - yes you cant just invent argument names in graphql.\nFrom your example query above the argument to the user field is called \"username\".  It cannot be called 'user' or 'myUser' because the schema is a well defined thing.  fields and arguments MUST be called by the name\nI wrote a quick unit test to show this\n```\nclass Issue938 extends Specification {\npublic static GraphQLScalarType GraphQLTimestamp = new GraphQLScalarType(\"Timestamp\", \"Timestamp\", new Coercing() {\n    @Override\n    Object serialize(Object input) {\n        return input\n    }\n\n    @Override\n    Object parseValue(Object input) {\n        GregorianCalendar calendar = new GregorianCalendar()\n        BigInteger value = new BigInteger(String.valueOf(input))\n        calendar.setTimeInMillis(value.multiply(new BigInteger(\"1000\")).longValue())\n        return calendar\n    }\n\n    @Override\n    Object parseLiteral(Object input) {\n        if (input == null) {\n            return null\n        }\n        GregorianCalendar calendar = new GregorianCalendar()\n        calendar.setTimeInMillis(((IntValue) input).getValue().multiply(new BigInteger(\"1000\")).longValue())\n\n        return calendar\n    }\n})\n\nclass UserImpl {\n    int id\n    String username\n    String email\n}\n\n\ndef \"938 custom scalar and variables\"() {\n\n    def schemaSDL = '''\n\n        type User {\n            id : Int\n            username : String \n            email : String\n        }\n\n        type Query {\n            User(username : String!) : User\n        } \n    '''\n    def userDataFetcher = new DataFetcher() {\n        @Override\n        Object get(DataFetchingEnvironment env) {\n            def username = env.getArgument(\"username\")\n            return new UserImpl(id: 1, username: username, email: username + '@gmail.com')\n        }\n    }\n    def runtimeWiring = RuntimeWiring.newRuntimeWiring()\n            .scalar(GraphQLTimestamp)\n            .type(\n            TypeRuntimeWiring.newTypeWiring(\"Query\")\n                    .dataFetcher(\"User\", userDataFetcher)\n                    .build())\n            .build()\n    def schema = TestUtil.schema(schemaSDL, runtimeWiring)\n    def graphql = GraphQL.newGraphQL(schema).build();\n\n    when:\n    def input = ExecutionInput.newExecutionInput()\n            .query('''\n                    query myTwoBestFriends($friendOne: String!, $friendTwo: String!) {\n                        friendOne: User(username: $friendOne) {\n                             id\n                             username\n                             email\n                        }\n                        friendTwo: User(username: $friendTwo) {\n                             id\n                             username\n                             email\n                        }\n                    }\n                    ''')\n            .variables([\"friendOne\": \"joeyt\", \"friendTwo\": \"rossg\"])\n            .build()\n    def executionResult = graphql.execute(input)\n\n    then:\n    executionResult.errors.isEmpty()\n    executionResult.data == [friendOne:\n                                     [id: 1, username: 'joeyt', email: 'joeyt@gmail.com'],\n                             friendTwo:\n                                     [id: 1, username: 'rossg', email: 'rossg@gmail.com']\n    ]\n\n\n}\n\n```\nAll works as expected.  But the query arguments MUST be called 'username'.  \nIn fact working on this I found a NullPointerException bug in the new error reporting which I will fix.\nHence the PR associated with this issue.  However over all the system is working as expected regarding variables and so on as mentioned above. See https://github.com/graphql-java/graphql-java/pull/954 for the bug I found. Ok looking into this perhaps the biggest surface error will be graphql.ExceptionWhileDataFetching\nIt is declared as\npublic class ExceptionWhileDataFetching implements GraphQLError {\n  private final String message;\n  private final List<Object> path;\n  private final Throwable exception;\n  private final List<SourceLocation> locations;\n private final Map<String, Object> extensions;\n\nThat is is explicitly has a an exception member and Jackson / GSon will reflect that if you call toJson() in it\nBut there a number of other errors that are in fact exceptions\nThings like public class MissingRootTypeException extends GraphQLException implements GraphQLError { and so on\nThey extend GraphQLException (runtime type) and implement GraphQLError so they can be placed as is inside the error collection.\nThis is typical where we throw an exception on an exceptional path and just add it to the error collection higher up.\nIf we took the exceptions out, we would have to translate them to errors at catch point into a more generic GraphQLError\nThe more I look into this the more I think the .toSpecification() is they way to go at the end of the run.  \nA twist on that is that perhaps we put \"instructions\" into the graphql setup that says to \"convert to spec\" errors on the way out autmatically (instead of requring them to do it before they serialise)\neg\nnewExecutionInput().query(\"{ foo }\").convertErrorsToSpecification().build();\n\nWhich means the ExecutionResult would inherently be spec compliant and no exceptions\nThoughts @andimarek / @kaqqao ?\n. The more I looked into this (and build some generic code solutions which turn GrapqlErrorsWithExeptions -> NoExceptionGrapqlErrors) the less I think we have anything to do\nThe \"make errors to spec\" already exists.  Such that you can just call .toSpecification() on the result and your done.\nHow in an calling library like graphql-java-servlet they will need to do some work to expose that switch but really it's there responsibility not the main library.\n. Ok I have updated it to have a new CoercingParseLiteralException - you convinced me on the symettry argument to have a new exception. Yup better words\nOn 1 Mar. 2018 01:44, \"Andreas Marek\" notifications@github.com wrote:\n\n@andimarek approved this pull request.\ngreat work.\njust one small comment.\n\nIn docs/mapping.rst\nhttps://github.com/graphql-java/graphql-java/pull/944#discussion_r171265126\n:\n\n\nString matchArg = env.getArgument(\"match\");\n+\nList productInfo = getMatchingProducts(matchArg);\n+\nList productCostInfo = getProductCosts(productInfo);\n+\nList productTaxInfo = getProductTax(productInfo);\n+\nreturn mapDataTogether(productInfo, productCostInfo, productTaxInfo);\n}\n};\n+\n+So looking at the code above we have 3 types of information that need to be combined in a way such that a graphql query above can get access to\n+the fields id, name, cost, tax\n+\n+We have two ways to create this mapping.  One is via using an un type safe List<Map> structure and one by creating a type safe List<ProductDTO> class that\n\n\nmaybe not type safe rather than \"un\"?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/944#pullrequestreview-100086598,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSQGpoheZe-OIKIhFrTP7jnW_4-y2ks5tZWZFgaJpZM4SSg9Q\n.\n. My first thought is that this again highlights that the graphql type system and the data fetching code needs to be split apart.  eg like your exploratory PR earlier.\n\nBut now is not the time for that.\nIs the driver here the circular reference between a \"GraphqlFieldDefinition\" being in a Schema and needing that schema in order to give it to the DFF as an input.\nBecause another way to do that is call initSchema(schemObj) on all the field (or all the types) and then they can all access it.\nSo my only problem with this change is that today the data fetcher factory COULD (and I say could) choose to be really lazy and switch implementations based on runtime variables (such as feature flags say) so that between calls you could change implementation.\nBut perhaps that is best handled inside the data fetcher itself.  graphql.schema.DataFetchingEnvironment gives you the GraphqlFieldDefinition anyway so you can know who you are fetching on behalf of.\nOne challenge some people have is the DI injection problem.  That is the GraphqlSchema might be build once before the DI is wired up (lets assume Spring say).  But they need access to the DI context (aka Spring context) to get access to code managers that actually do the fetching work.\nDoes this change (or the other PR) make that worse? Hmmmm...\nBetween the two implementations I prefer this one.  That is the semantics are \"during schema building you will be called to generate a data fetcher... its fixed after that\".\n. Sorry this repo is the base graphql-java engine.  You will probably want to raise it here\nhttps://github.com/graphql-java/graphql-java-servlet. Interfaces in the type system are \"implemented\" by object types.\nSo I would imagine it looks like this\n@GraphQLInterface\nclass SomeInterface {\n     ....\n}\n@GraphQLObject(implements = { SomeInterface.class }\nclass SomeObjectType {\n   ..\nor something like that\nThis is annotation equivalent of SDL like\n```\ninterface SomeInterface {\n ...\n}\ntype SomeObjecType implements SomeInterface {\n}\n```\nnotice how its the object type that says what is implemented.  This is the only way that makes sense to me...  an interface cant dictate who implements it - only an object type can choose to have that shape.\n. > If the only field of a query is an interface, does the schema suppose know \nUm I am not sure of the question.  Can you please be more precise, perhaps in SDL shorthand to illustrate your point. I think this is a bug in your annotations library.\nIn native graphql-java SDL, we add the additional types (not referenced from the operations but defined in the schema)\n```\n        Set additionalTypes = buildAdditionalTypes(buildCtx);\n    return schemaBuilder.build(additionalTypes);\n\n...\n         /\n     * We build the query / mutation / subscription path as a tree of referenced types\n     * but then we build the rest of the types specified and put them in as additional types\n     \n     * @param buildCtx the context we need to work out what we are doing\n     \n     * @return the additional types not referenced from the top level operations\n     */\n    private Set buildAdditionalTypes(BuildContext buildCtx) {\n        Set additionalTypes = new HashSet<>();\n        TypeDefinitionRegistry typeRegistry = buildCtx.getTypeRegistry();\n        typeRegistry.types().values().forEach(typeDefinition -> {\n            TypeName typeName = new TypeName(typeDefinition.getName());\n            if (typeDefinition instanceof InputObjectTypeDefinition) {\n                if (buildCtx.hasInputType(typeDefinition) == null) {\n                    additionalTypes.add(buildInputType(buildCtx, typeName));\n                }\n            } else {\n                if (buildCtx.hasOutputType(typeDefinition) == null) {\n                    additionalTypes.add(buildOutputType(buildCtx, typeName));\n                }\n            }\n        });\n        return additionalTypes;\n    }\n```\nI am guessing that the annotations library forms a tree from \"root types\" down wards say.  I dont think you can safely do this.\n. Ahh your right - this seems to have been lost in a refactor.\nIt is intended as a way to allow say \"reference queries\" to be turned into say full queries but it seems to have gotten lost in the wash.\nI will make this change.... Now in place. Yup its a super hot topic.  I am not sure it belongs in the base graphql-java engine library but rather in a higher level library that uses graphql-java.\nWatch this space.  I know of 2 efforts in Atlassian that are looking closely at this in Java and who knows what else might come from Apollo . I currently don't have access to a computer as I am on vacation...but I\nthink you are missing something... I recall a JSON to to schema\nthing...perhaps it was printing only\nThe trick is how do you offer data fetching behaviour from introspection?\nOn Thu., 26 Apr. 2018, 09:46 You Jia, notifications@github.com wrote:\n\n@bbakerman https://github.com/bbakerman I'm investigating on\nimplementing schema stitching with graphql-java, and one major thing that\nseems to be missing is the ability to build a GraphQLSchema object from\nan introspection query result which is in JSON. This would correspond to\nthe buildClientSchema function in the reference graphql-js implementation.\nI saw the SchemaParser class, but it only parses schemas written in the\nGraphQL schema language. Am I missing anything here?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/952#issuecomment-384766930,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSfJMgAtp7YmpgZutkXzcwQSC38btks5tsiP9gaJpZM4SalKX\n.\n. @kaqqao / @apottere / @andimarek  - thoughts?. Thanks for reporting.  PR is now up. I will go out in 8.0 which we hope to release by the end of this month. Can you post the offending query to give us more reproduce info. Thats the point of toSpecification() - it only sends the attributes that are \"to specification\" and not the others.\n\nThe errorType is a graphql-java attribute that was invented by the library.  I can see that it would be useful to have even in a specification world. PR up to fix this problem. @sp00m - the @Batched annotation should also be deprecated.  They all serve the purposes of the BatchedExecutionStrategy which should be removed at some stage. See #1243. So one of the challenges with this code is errors while fetching.\nLook at the BANG example in the test.  That exception is handled BUT by default is placed into the executionContext.getErrors() list.\nThis is examined only on the way out not at each level of execution results as the tree is processed.\nIts going to be tricky to associate the \"fetching errors\" with the specific @defer continuation code I think... Hmmmm. Added support for errors because we KNOW that its executed in encountered order. The graphql specification mandates this in a way\nhttps://github.com/facebook/graphql/blob/master/spec/Section%203%20--%20Type%20System.md\nThat is there is one document defined and it handles queries and schema definition.\nDo you have a specific problem or just that you can put queries in schema docs but nothing happens. Care to leave a more complete code example, perhaps a unit test of sorts to explain the code more. OK I have followed your feedback.  Its now List is called queryPath and is also in the message. Sorry but the example is actually in Java 8.  Its meant to be indicative of how you would wire a data fetcher into the runtime wiring.\nWe keep all of the documentation snippets in the code base as Java code for exactly that reason\nIts not a tutorial per se.  There are other sections in the documentation that talk about how to write a data fetcher.  \nOnce you combine a data fetchers together you have your runtime wiring.\nHave a look at the next section\nhttp://graphql-java.readthedocs.io/en/v7/execution.html\nIt hows how to write a DataFetcher.\n. The challenges seem to be around the returning of [listTypes] that then recursively call the ExecutionStrategy again once per list.\nThe expectation from some people is that query be executed in a breath first away and to hold any DataLoads until all fields in the level are dispatched.\nOne user has reported:\n\nMy data structure is like this: P -> [D] -> [A] -> H.\nArrays of A objects work well, they are loaded using one batched request for all D objects at once.\nBut when loading H objects DataLoader is dispatched separately for arrays of A objects \"belonging\" to one D object at a time.\nSo for example let's say I have 100 D objects and each has 10 A objects. ...with AsyncExecutionStrategy 100 requests are sent.. Code attack notes:\n\nThe existing graphql.execution.instrumentation.dataloader.DataLoaderPerformanceTest should be used for this.\nIt already has a schema of lists of lists\n``` graphql\nschema {\n    query: Query\n}\ntype Query {\n    shops: [Shop]!\n}\ntype Shop {\n    id: ID!\n    name: String!\n    departments: [Department]!\n}\ntype Department {\n    id: ID!\n    name: String!\n    products: [Product]!\n}\ntype Product {\n    id: ID!\n    name: String!\n}\n```\nWe should be able to use this code base and tests to see what more efficient strategies we can come up with\nGiven the query\n``` graphql\n            query { \n                shops { \n                    id name \n                    departments { \n                        id name \n                        products { \n                            id name \n                        } \n                    } \n                } \n            }\n```\nIt has a data set that looks like\ngroovy\n    def expectedData = [\n            shops: [\n                    [id         : \"shop-1\", name: \"Shop 1\",\n                     departments: [[id: \"department-1\", name: \"Department 1\", products: [[id: \"product-1\", name: \"Product 1\"]]],\n                                   [id: \"department-2\", name: \"Department 2\", products: [[id: \"product-2\", name: \"Product 2\"]]],\n                                   [id: \"department-3\", name: \"Department 3\", products: [[id: \"product-3\", name: \"Product 3\"]]]\n                     ]],\n                    [id         : \"shop-2\", name: \"Shop 2\",\n                     departments: [[id: \"department-4\", name: \"Department 4\", products: [[id: \"product-4\", name: \"Product 4\"]]],\n                                   [id: \"department-5\", name: \"Department 5\", products: [[id: \"product-5\", name: \"Product 5\"]]],\n                                   [id: \"department-6\", name: \"Department 6\", products: [[id: \"product-6\", name: \"Product 6\"]]]\n                     ]],\n                    [id         : \"shop-3\", name: \"Shop 3\",\n                     departments: [[id: \"department-7\", name: \"Department 7\", products: [[id: \"product-7\", name: \"Product 7\"]]],\n                                   [id: \"department-8\", name: \"Department 8\", products: [[id: \"product-8\", name: \"Product 8\"]]],\n                                   [id: \"department-9\", name: \"Department 9\", products: [[id: \"product-9\", name: \"Product 9\"]]]]\n                    ]]\n    ]\nWithout data loader at all we get a niave\n    BatchCompareDataFetchers.departmentsForShopsBatchLoaderCounter.get() == 3\n    BatchCompareDataFetchers.productsForDepartmentsBatchLoaderCounter.get() == 9\n\nwith data loader today we get\n    BatchCompareDataFetchers.departmentsForShopsBatchLoaderCounter.get() == 1\n    BatchCompareDataFetchers.productsForDepartmentsBatchLoaderCounter.get() == 3\n\nIs it possible to get productsForDepartmentsBatchLoaderCounter down to 1??\nOne of the things about the above example is that is only 1 set of list fields.  So imagine if we had 2 shop based fields and 2 department based fields.  This would change the runtime dynamic a bit I think. Yup\nOn Thu., 6 Sep. 2018, 09:00 Andreas Marek, notifications@github.com wrote:\n\n@bbakerman https://github.com/bbakerman can this be closed?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/979#issuecomment-418908597,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSRHRmEhKr7JcTnfL07G0EgpwQdcaks5uYFeJgaJpZM4Sui3w\n.\n. So the subscription model says the first field of the initial request is result Publisher\n\nThen each time that Publisher emits an event it is mapped over the rest of the original query and turned into ExecutionResults.\nSo you challenge regarding transactions is not in the graphql-java code but rather in your code that provides the original publisher.\nnote also that applying 1 transactions across a reactive stream is not really idiomatic.  It is meant to be one or more \"events\" that happen later.\nIf you truly need 1 transaction, then I suggest you don't use subscriptions. I think you may be leaking your JPA implementation concerns in the graphql arena.\nHave you read http://graphql-java.readthedocs.io/en/v7/subscriptions.html\nThe 1st field gives back a publisher of Foo objects.\ngraphql\n      stockQuotes(stockCode:\\\"IBM') {\\n\" +\n        \"            dateTime\\n\" +\n        \"            stockCode\\n\" +\n        \"            stockPrice\\n\" +\n        \"            stockPriceChange\\n\" +\n        \"        }\\n\" +\nSo the publisher that comes from the example stockQuotes field will have the rest of the fields applied over it.\nSo each time you publish an object it will have the query inner body applied\nSo in your code that that is backed by the Publisher put all your JPA concerns and have that object then be mapped over like any other object.\nif you have lazy objects that feed the Pubisher, then put the code that tranforms them into graphql ready objects BEFORE you publish the actual event.  \nFlux.from(publishers.getUserChangedPublisher(id).map(lazyUser -> makeFulluserHereBeforePublishing(lazyUser))\n\n. Again I feel that \"acks for messages sent\" should be in a wrapping publisher + subscriber outside the graphql query layer and in the sending layer of your code.\nI am still not convinced that we need to have the ability to extend the execution strategy here. I checked the code and I cant see how this can be the case\nI then wrote a small unit test and proved it.\nWhat version are you running etc..and do you have a stack trace\n```\n    def \"empty list\"() {\n        def testList = []\n        def listConnection = new SimpleListConnection(testList)\n    expect:\n    listConnection != null\n\n}\n\n```. Unless we can see evidence otherwise I am going to close this issue. Sounds like a good idea but a lot of work.  TCKs are notoriously hard to write and maintain.\nWe would of course accept PRs that helped get this in place.  . @exbe - We are looking at integrating the graphql-cats into graphql-java\nThis is not yet a proven way to get CTK ability however it might prove out and hence we can wire in other ExecutionStragtergies.\nI have  avery early PR almost ready.  Its not finished - its just parsing not execution. Yeah before the spec went public, it was , based.  It still is (because , is whitespace) but this is more idiomatic.\nA test would be excellent to ensure we don't regress\n. Coming in 9.0. @andimarek  - I split the logic contained in the instrumentation class out into its own graphql.execution.instrumentation.dataloader.FieldLevelTrackingApproach class\nThis will allow us to include Sam Bs Braid code as another approach.  We can then continue to test with both say and work out which is the better one.  We might then retain one or the other or maybe both.. @wakeboarder3780 - do you have a reference where other graphql servers are adding this?. Can you please outline the bug further.  As in how to reproduce it. \nYou have given us the fix but not the exact problem and how to reproduce it.. Thanks for the reproductive test...we will look into it\nOn Fri., 6 Apr. 2018, 16:04 david-tamjidi, notifications@github.com wrote:\n\nApplying the simple fix from the first comment will stop the exception\nfrom being thrown improving performance greatly for the non-async case\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/992#issuecomment-379378459,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSePK3bRUs2pHFFlMLFE3BfU4wbDUks5tl9h4gaJpZM4S5WZt\n.\n. Today you must wire this into your data fetcher code by hand\n\n DataFetcher df = environment -> {\n     SecurityContext ctx = environment.getContext():\n     if (ctx.hasRole(\"manager\",ctx.getCurrentUser() {\n          return callDownStreamData(environment)\n     } else {\n          return null\n    }\n }\n\nYou need to set up the \"security context\" outside when you start the graphql execution and pass it in via the \"context\"\nWe are working on a directives based approach right now that might make this easier to declare\nSee #1001 \n. Since this is not a bug I am going to close this issue. Thanks for this. This makes sense.  Please submit a PR where the current print methods have peers that supply a Writer say.\nThe can use UncheckedIOException say so we don't have to change the signature\nI am a little suprised on what exceptions you get\nthey use\n         StringWriter sw = new StringWriter();\n         PrintWriter out = new PrintWriter(sw);\n\nso its all in memory so its not IOExceptions that are happening here today. use the \"context\" object that is set up on the ExecutionInput.\n InventedContext ctx = InventedContext.newCtx().setJwt(jwtTokenFromCookie()).build();\n ExecutionInput.newExecutionInput().query(queryText).context(ctx).build\n\nPut that in place before you start executing.\nGraphQLQueryResolver comes from some other library other than graphql-java so you might have to ask there for more specific help or try gitter. I am going to close this issue because graphql-java does not deal with HTTP on purpose and instead this is an issue for another library. This is an excellent bug report.  Well done.  if only more bugs reports where as detailed as this.\nHowever.. its not a bug.  Its working as designed.\nThe root object is specified when you set up the execution input.\nExecutionInput executionInput = ExecutionInput.newExecutionInput()\n            .query(query)\n            .root(new StarttingObjectOfYourChoice())\n            .build();\n\nThe root can be set to be any value per query hence it being tied to ExecutionInput\nThe root object is used to seed the query process.  By default its null as you noticed.\nThen as you descend down the query tree, the source object is the object returned by the parent field.  For the 1st level (the root query level) it is the same as root object but after that it changes but the root never does.\n. @andimarek  - I am attracted to the simplicity of this versus our more complicated \"level / list tracking\"\nI have run this in the debugger and I can see how it works.  It waits for the original operation fields to be run-dispatched and then calls dl.dispatch() on each of the defined data loaders.\nIt gathers these together into a combined construct - currently called DispatchedBatchLoader (but I want to change this) that tracks the number of outstanding calls which \"captures\" the CF promises\nThe fact that this is as efficient as the other code we have is also a plus.  Its simpler and just as performant.  It's actually more like the Node.js \"tick\" queue to be honest, that is a queue of things to be done.\nMy thoughts are to refactor the 2 approaches into inner \"DispatchingStrategies\".\nThat is we retain DataLoaderDispatcherInstrumentation but we have a way to switch \"strategies\" such that it runs \"approach AndiBrad\" or the \"sam B approach\".  \nThat way we can keep the same API shell (there are things that DataLoaderDispatcherInstrumentation does that are missing like turn itself off when the ExecutionStrategy is not the one expect.  Its also doesn't do DL stats etc..\nThoughts?\n. One thing that has just occurred to me is that @defer support is probably broken with DataLoader\nThat is who is calling dispatch in the inner deferred code?  No one I don't think\nThis makes it no worse but we should fix this.. @sleberrigaud - pull the original dataloader-multilevel-dispatch back onto this branch.\nI have refactored it so that is has a graphql.execution.instrumentation.dataloader.FieldLevelTrackingApproach as a way to split out the logic\nWe can then add your own implementation as another approach and we can invent a way to switch between them for now.  This might not be the final way we deliver this however. #990 contains this code in a better named way.  We are likely to pick this approach and hence I am closing this PR. If you are not happy by all means re-submit in the better form. Yup I did a quick test of this and it is indeed broken because dispatch is not called for the deferred fields. This is now fixed. Thanks very much for this PR.  \nI would love to see this take further and cache more than just booleans but the other accessors as well.\nThat said caching is tricky.   I property fetcher for the property \"foo\" just says given and object Bar how do I read the foo field.  \nWe have to make sure that any caching is aware that an object presented to the  property fetcher might be different each time.\nHmmm  I need to consider this a little longer..\n. I had a look into this more.  I think if we are going to cache for performance we want to do that for all methods of class -> property name not just boolean ones.\nSo I created another PR #1013 \nI thank you for this PR but am going to close it and run with the other one. yup your right. The main contributors are currently both on extended vacation...we will get\nback to you in a few weeks\nOn Fri., 13 Apr. 2018, 11:45 escitalopram, notifications@github.com wrote:\n\nAs currently implemented (at least as of 7.0), it is possible to put\ndirectives on type definitions as well as on field definitions. This is\nreally handy for placing hints for DataFetchers into the schema file and it\nworks flawlessly.\nI would also like to pass on this extra information to the client.\nHowever, it seems that as per spec, these directives are not exposed in the\nintrospection feature.\nI wonder what the position of the development team would be on extending\nthe introspection code to support that, despite it being not specified by\nFacebook. I'm currently considering to code it myself and contribute it.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/1017, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSRYPiCz2YKDdbW-Vm1b8i0d4E76Oks5toMgRgaJpZM4TTrFF\n.\n. So introspection shows the schema types and it could show directives (non spec)\n\nBut what are the user cases that graphql clients can do knowing that a back end type as a @foo directive on it.\nThey cant know what foo does to the schema def.  Its already too late since the directives are applied in behaviour terms.\nSo I am trying to get insight in what a client could do if it KNEW that a @foo was on field X?\nAlso note - there are changes coming in 9.0 that allows you to wire in behaviour in once place to ALL directives on all fields say.. OK I can see your use case better.  IN some ways you need \"extra metadata\" to be carried with a type and see \"directives\" as a way to provide that.\nI am not adverse to a PR that added Introspection metadata to the types.\nThe trick would be to \"distunguish\" it from \"standard\" meta data in some way via naming say.  I consumer should be able to \"know\" that they are getting non standard introspection and hence distunguish it from the \"standard / any graphql server implementation\" type data. I have re-opened this - its a valid feature request. Soon?  No - not soon.  Not never.. but its not actively planned yet. I am not seeing this behaviour for extensions.\nI have written a new test that shows it working (see #1037 )\nCan you expand on this problem more or perhaps do a unit test that demonstrates it happening.\ngraphql.ExceptionWhileDataFetching#ExceptionWhileDataFetching is the class in question that transfers exceptions that are GraphqlErrors. I am going to close this because I believe its working as expected. If the DataFetchers are multi threaded then it will be asych other wise\nit's single threaded\nWe have avoided opinionated multi threading because it makes for bad\nlibrary design....however you can make you DataFetchers use threads...\nOn Tue., 17 Apr. 2018, 12:00 dgruntz, notifications@github.com wrote:\n\nI have just executed the following query:\nquery {\n  p1: getProduct(productId: 1) {\n    id\n  }\n  p2: getProduct(productId: 2) {\n    id\n  }\n}\nHowever, the two queries were executed sequentially by the same thread.\nShould such queries not be executed concurrently? I have printed entry and\nexit in my method (and added a Thread.sleep(10000) in the implementing\nmethod):\n\n\ngetProductById(1) 17:54:14 Thread[qtp331122245-17,5,main]\n<< getProductById 17:54:24 Thread[qtp331122245-17,5,main]\ngetProductById(2) 17:54:24 Thread[qtp331122245-17,5,main]\n<< getProductById 17:54:34 Thread[qtp331122245-17,5,main]\n\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/1019, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSUxPyv03TuMuL83ggvGegAuHIzciks5tphGUgaJpZM4TYmYW\n.\n. Thanks for this.  I am going to close this only because it is not actively going to be merged into master.\n\nOnce again thanks for the contribution. Thanks for this.. Can you explain more about accidental override rules in Kotlin?    I am not\nfamiliar with the language restorations and how we are not playing ball\ncorrectly\nOn Sat., 21 Apr. 2018, 17:50 Andres Diaz, notifications@github.com wrote:\n\nWhen i try to create a custom exception that implements GraphQLError cause\nan Accidental Override in the getMessage error in Kotlin\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/1022, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSWKJcHLZa_GCoCIR31jQyuqWmpxMks5tq6msgaJpZM4TeoYM\n.\n. I am not sure how we can solve this.  The graphql spec says that graphql errors MUST have a \"message\" attribute.  Hence GraphqlError having a getMessage method and hence JSON conversion just working.\n\nIts very convinenting to have exceptions implement GraphqlError to they dont have to be translated manually.\nI am not sure how to work around this for Kotlin??. I have asked colleagues at Atlassian about this problem.\nThe consensus was that this is a challenge even in native Kotlin\n```\ninterface GraphQLError {\n    fun getMessage(): String\n}\nclass FeatureFlagFetchException(s: String?) : RuntimeException(s), GraphQLError\n```\nTheir suggestion as a work around was to declare a .java file that represents the custom exception\n. Could you please supply a unit test that initially fails and then works with your fix applied. We are actively make new changes around directives in SDL schema.\nI want to merge this AFTER these are in place.\nThanks for your contribution. actually this is a great pre-req.  I will merge it first. We have actively tried to reduce the dependecies in graphql java so Apache or GSON /Jackson are a no go.  \nWe could build out a fuller implementation if needed but it would be in this library, no new deps\nThanks for this. Are you really going to put this in 9.0   Its marked as such. graphql-java itself does not HTTP and is not a complete engine like say Tomcat + Spring etc....\nYou wire in data fetchers and they get data from some where.\nYou can put HttpClient calls behind these data fetchers and act as an API gateway to those REST services under one logical schema.\nYou might want to look at other libraries to give you a complete HTTP engine + JSON + logging + metrics etc... eg spring boot or dropwizard + the graphql-java library\nSay https://github.com/graphql-java/graphql-spring-boot perhaps. graphql-java is a library that sets up the graphql query to follow the spec and handles all the interpretation.\nThe data fetchers are the thing you write yourself.  They are the places you get data from.  That might be a database call, a REST call or indeed another graphql downstream call.\nThat code is entirely up to you.  graphql-java has no network code that gets your our to another server say.\nSo your diagram above is entirely possible (we do exactly that in some services at Atlassian where I work) but you must code the data fetchers and do any \"mapping between\" what the downstream source gives you and what you want to send back in terms of your \"gateway\" schema.\nIf they are the same, then there is no mapping... If you want to present a modified view, then yeah tyou need some mapping code as well of results... along with data fetchers to get downstream data\n. So specifcally - yes you will need a http client in \"api proxy\" to talk to the back end systems.\nYou dont need a specific graphql http client... Its just not the complicated in my opnion.  Lots of people think they MUST need a dedicated client.  But its so simple just hand code it using Apache Http client and be done. I am going to close this issue as its a question and not a bug. Yeah I am receptive to this.  We have some Apollo support for tracing already in graphql-java via graphql.execution.instrumentation.tracing.TracingInstrumentation\nI think this caching control would need to be done via an Instrumentation so that consumers would opt into the behaviour by \"adding the instrumentation\" into the mix.\nWe would love to see a PR on how this might work.\nThe request format is intereting\n\"extensions\": {\n  \"cacheControl\": {\n    \"version\": 1,\n    \"noCache\": true\n  }\n}\nhow does a client specify that?  where?   in the variables map??  There are no \"extensions\" input that I know of??\n. This is very viable - and the more that the Apollo spec / engine gains ground the more we need it.\nWe have \"extensions\" on the execution result today so one could could your own.\nHowever we dont allow each individual data fetcher to \"add\" their own extension paths today.  We only allow it AFTER the query is done which is not powerful\nEven SDL annotated cache control mechanisms would still need data fetcher result extensions.\nI am thinking off hand there but I think DataFetcherResult would be the place for a DF to \"return extension\" data some how.  This could then be combined into the extensions map towards the end.\n. A flux is a reactive stream of results.  The list of Groups above can come down some time in the future, technically sporadically and not as a complete list as once.\nA CompletionStage> is a promise to give a complete list of groups some time in the future.  Once the result does arrive, it must be there as a complete unit.\nSo reactive streams (such as Flux) and CompletionStages share some similarities but they differ in the way results turn up.\nIf you have a reactive backend of data, you MUST fully read that Flux (reactive stream) before you can consider the CompletionStage done.\ngraphql-java is \"async\" not fully reactive.\nWhat I would do is create your own helper that \"creates a uncompleted CompleteableFuture\" and has code that that observes Flux until it signals it is done.  You buffer up the groups in this case and then publish the List on the CompletableFuture.\nIn really rough psudeo code it might\n```\nCompleteableFuture cf = new  CompleteableFuture();\nFlux flux = groupServer.get(ids)\n    List buffer = new List()\nflux.subscribe(new Subscription() {\n   onObject(group) {\n        buffer.add(group)\n   }\nonEnd() {\n        cf.complete(buffer);\n   }  \n}\nreturn cf;\n```\nThis is really rough code.  Off hand I dont recall how Flux is observed and projectreactor javadoc is down right now as I type.\nBasically you \"observer all the values in the Flux\" and buffer then up.  When it finishes you can \"complete\" the CF with the buffered list\nhttps://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html#complete-T-\nRemember also there can be exceptions and you need to complete the CF exceptionally\ncf.completeExceptionally(someException). Yup thats looks right. Looked into the code - not a problem but the new test confirms it. The parser doesn't need to hook into validation.  Its job is to built an AST tree that is syntactically correct and allow that to be validated and then executed.\n\nBy parser do you mean AST node traversal?  \nYou say natively validate variables.  What does native mean?   There is a prejudicial implication there that its currently \"non native\"  but I dont know what you mean by native?\nWe have fairly extensive validation in place (as define by the graphql spec).  So I am wondering what the exact problem definition is that we need to fix by new code designs?\n. I am not convinced we need to change the parser code to implement query validation.\nWe already have a post parse validation step that takes the AST and variables map and check preconditions to ensure it is valid.  \nThis code was based on the reference JS implementation and the spec.  We have gone through several iterations of it over the last 2 years to get it as correct as possible.\nAnd while nothing is perfect, it has served us really well.  So I am hesitant to \"change the parsing\" and move the same validation rules into that, since it really already is in place.. > My expectations is that validation should happen regardless of input method (inline vs variables).\nDoes this make sense?\nI will agree with this btw.  That validation should happen regardless input method.  Its just that I think this is best done after the parsing had happened and in the validation phase. \nIf we are missing validation code, then by all means lets improve that.  But not via a new parser but by traversing the parsed tree with a set of rules.. We sort of have this today.\ngiven this query\n```\n            {\n                human {\n                    name\n                    appearsIn\n                    friends(separationCount : 2) {\n                        name\n                        appearsIn\n                        friends(separationCount : 5) {\n                            name\n                            appearsIn\n                        } \n                    }\n                    ...FriendsAndFriendsFragment\n                }\n            }\n        fragment FriendsAndFriendsFragment on Character {\n            friends {\n                name \n                friends {\n                    name\n                }\n            }\n        }\n\n``\nand starting from thehuman` top level field it will build a map of fields like this\nselectionSetFields = {LinkedHashMap@2293}  size = 8\n 0 = {LinkedHashMap$Entry@2424} \"name\" -> \" size = 1\"\n 1 = {LinkedHashMap$Entry@2425} \"appearsIn\" -> \" size = 1\"\n 2 = {LinkedHashMap$Entry@2426} \"friends\" -> \" size = 2\"\n 3 = {LinkedHashMap$Entry@2427} \"friends/name\" -> \" size = 2\"\n 4 = {LinkedHashMap$Entry@2428} \"friends/appearsIn\" -> \" size = 1\"\n 5 = {LinkedHashMap$Entry@2429} \"friends/friends\" -> \" size = 2\"\n 6 = {LinkedHashMap$Entry@2430} \"friends/friends/name\" -> \" size = 2\"\n 7 = {LinkedHashMap$Entry@2431} \"friends/friends/appearsIn\" -> \" size = 1\"\n(taken from memory dump in IDEA)\nInstead of a object hierarchy like the one you linked to, we use a '/' separated naming hierarchy\ngraphql.schema.DataFetchingFieldSelectionSet#get will give this this map which is defined as Map<String, List<Field>>\nIs there something missing you need that this does not do?. @soneymathew  - The DataFetchingFieldSelectionSet already does what you are asking for, that is is collapses fragments and so on into fields and graphql types and currently shows the hirearchy via x/y/z based names.\nI wrote a unit test for your query above.  The DataSelectionSet.get() gives me a map like\nfieldsMap = {LinkedHashMap@2249}  size = 14\n 0 = {LinkedHashMap$Entry@2326} \"nodes\" -> \" size = 1\"\n 1 = {LinkedHashMap$Entry@2327} \"nodes/key\" -> \" size = 1\"\n 2 = {LinkedHashMap$Entry@2328} \"nodes/summary\" -> \" size = 1\"\n 3 = {LinkedHashMap$Entry@2329} \"nodes/status\" -> \" size = 1\"\n 4 = {LinkedHashMap$Entry@2330} \"nodes/status/name\" -> \" size = 1\"\n 5 = {LinkedHashMap$Entry@2331} \"nodes/stuff\" -> \" size = 1\"\n 6 = {LinkedHashMap$Entry@2332} \"nodes/stuff/name\" -> \" size = 1\"\n 7 = {LinkedHashMap$Entry@2333} \"edges\" -> \" size = 1\"\n 8 = {LinkedHashMap$Entry@2334} \"edges/cursor\" -> \" size = 1\"\n 9 = {LinkedHashMap$Entry@2335} \"edges/node\" -> \" size = 1\"\n 10 = {LinkedHashMap$Entry@2336} \"edges/node/description\" -> \" size = 1\"\n 11 = {LinkedHashMap$Entry@2337} \"edges/node/status\" -> \" size = 1\"\n 12 = {LinkedHashMap$Entry@2338} \"edges/node/status/name\" -> \" size = 1\"\n 13 = {LinkedHashMap$Entry@2339} \"totalCount\" -> \" size = 1\"\nand the getDefinitions() gives me\nfieldDefs = {LinkedHashMap@2250}  size = 14\n 0 = {LinkedHashMap$Entry@2270} \"nodes\" -> \"GraphQLFieldDefinition{name='nodes', type=graphql.schema.GraphQLList@1d470d0, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@4febb875, description='null', deprecationReason='null', definition=FieldDefinition{name='nodes', type=ListType{type=TypeName{name='Thing'}}, inputValueDefinitions=[], directives=[]}}\"\n 1 = {LinkedHashMap$Entry@2271} \"nodes/key\" -> \"GraphQLFieldDefinition{name='key', type=GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$3@25e2a451}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@1698ee84, description='null', deprecationReason='null', definition=FieldDefinition{name='key', type=TypeName{name='String'}, inputValueDefinitions=[], directives=[]}}\"\n 2 = {LinkedHashMap$Entry@2272} \"nodes/summary\" -> \"GraphQLFieldDefinition{name='summary', type=GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$3@25e2a451}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@10c626be, description='null', deprecationReason='null', definition=FieldDefinition{name='summary', type=TypeName{name='String'}, inputValueDefinitions=[], directives=[]}}\"\n 3 = {LinkedHashMap$Entry@2273} \"nodes/status\" -> \"GraphQLFieldDefinition{name='status', type=GraphQLObjectType{name='Status', description='null', fieldDefinitionsByName=[name], interfaces=[]}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@2fc0cc3, description='null', deprecationReason='null', definition=FieldDefinition{name='status', type=TypeName{name='Status'}, inputValueDefinitions=[], directives=[]}}\"\n 4 = {LinkedHashMap$Entry@2274} \"nodes/status/name\" -> \"GraphQLFieldDefinition{name='name', type=GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$3@25e2a451}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@328cf0e1, description='null', deprecationReason='null', definition=FieldDefinition{name='name', type=TypeName{name='String'}, inputValueDefinitions=[], directives=[]}}\"\n 5 = {LinkedHashMap$Entry@2275} \"nodes/stuff\" -> \"GraphQLFieldDefinition{name='stuff', type=GraphQLObjectType{name='Stuff', description='null', fieldDefinitionsByName=[name], interfaces=[]}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@63b1d4fa, description='null', deprecationReason='null', definition=FieldDefinition{name='stuff', type=TypeName{name='Stuff'}, inputValueDefinitions=[], directives=[]}}\"\n 6 = {LinkedHashMap$Entry@2276} \"nodes/stuff/name\" -> \"GraphQLFieldDefinition{name='name', type=GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$3@25e2a451}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@42e3ede4, description='null', deprecationReason='null', definition=FieldDefinition{name='name', type=TypeName{name='String'}, inputValueDefinitions=[], directives=[]}}\"\n 7 = {LinkedHashMap$Entry@2277} \"edges\" -> \"GraphQLFieldDefinition{name='edges', type=graphql.schema.GraphQLList@24d09c1, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@201b6b6f, description='null', deprecationReason='null', definition=FieldDefinition{name='edges', type=ListType{type=TypeName{name='ThingEdge'}}, inputValueDefinitions=[], directives=[]}}\"\n 8 = {LinkedHashMap$Entry@2278} \"edges/cursor\" -> \"GraphQLFieldDefinition{name='cursor', type=GraphQLNonNull{wrappedType=GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$3@25e2a451}}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@75459c75, description='null', deprecationReason='null', definition=FieldDefinition{name='cursor', type=NonNullType{type=TypeName{name='String'}}, inputValueDefinitions=[], directives=[]}}\"\n 9 = {LinkedHashMap$Entry@2279} \"edges/node\" -> \"GraphQLFieldDefinition{name='node', type=GraphQLObjectType{name='Thing', description='null', fieldDefinitionsByName=[id, key, summary, description, status, stuff], interfaces=[GraphQLInterfaceType{name='Node', description='null', fieldDefinitionsByName=[id], typeResolver=graphql.schema.idl.MockedWiringFactory$1@183e8023}]}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@45efc20d, description='null', deprecationReason='null', definition=FieldDefinition{name='node', type=TypeName{name='Thing'}, inputValueDefinitions=[], directives=[]}}\"\n 10 = {LinkedHashMap$Entry@2280} \"edges/node/description\" -> \"GraphQLFieldDefinition{name='description', type=GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$3@25e2a451}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@3e5499cc, description='null', deprecationReason='null', definition=FieldDefinition{name='description', type=TypeName{name='String'}, inputValueDefinitions=[], directives=[]}}\"\n 11 = {LinkedHashMap$Entry@2281} \"edges/node/status\" -> \"GraphQLFieldDefinition{name='status', type=GraphQLObjectType{name='Status', description='null', fieldDefinitionsByName=[name], interfaces=[]}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@2fc0cc3, description='null', deprecationReason='null', definition=FieldDefinition{name='status', type=TypeName{name='Status'}, inputValueDefinitions=[], directives=[]}}\"\n 12 = {LinkedHashMap$Entry@2282} \"edges/node/status/name\" -> \"GraphQLFieldDefinition{name='name', type=GraphQLScalarType{name='String', description='Built-in String', coercing=graphql.Scalars$3@25e2a451}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@328cf0e1, description='null', deprecationReason='null', definition=FieldDefinition{name='name', type=TypeName{name='String'}, inputValueDefinitions=[], directives=[]}}\"\n 13 = {LinkedHashMap$Entry@2283} \"totalCount\" -> \"GraphQLFieldDefinition{name='totalCount', type=GraphQLNonNull{wrappedType=GraphQLScalarType{name='Int', description='Built-in Int', coercing=graphql.Scalars$1@67ab1c47}}, arguments=[], dataFetcherFactory=graphql.schema.DataFetcherFactories$$Lambda$2/1839337592@b78a709, description='null', deprecationReason='null', definition=FieldDefinition{name='totalCount', type=NonNullType{type=TypeName{name='Int'}}, inputValueDefinitions=[], directives=[]}}\"\nSo to your original question, you done have the navigate the actual AST nodes as you have above.  The DataSelectionSet does that for you. What we dont have today is a List/ Tree view of the above.  We flatten all the names into x/y/z form.\nSo you can ask if dataFetchingFieldSelectionSet.contains('node.*) but you cant right now ask it for the fields under node.*\nWe could try to improve this but today without the amount of code above you could get that.. I was thinking something like this (psudeo java)\n```\nclass SelectedFieldAndType {\n     String fieldName\n     GraphqlType fieldType\n     List subSelection()\n}\nList selectedFields = dataFetchingFieldSelectionSet.getSelectionFor(\"node\")\n```\nMaybe this would help build a tree structure of subselected fields and their types.. This is a unit test written in Groovy (via Spock)\n```\n    static class Polygon {\n        private List>> coordinates\n    Polygon(List<List<List<Double>>> coordinates) {\n        this.coordinates = coordinates\n    }\n\n    List<List<List<Double>>> getCoordinates() {\n        return coordinates\n    }\n}\n\ndef \"list of list of list of double\"() {\n    def spec = '''\n        type Query {\n            coordinates : [[[Float]]]\n        }\n    '''\n\n    GraphQLSchema schema = TestUtil.schema(spec)\n    GraphQL graphQL = GraphQL.newGraphQL(schema).build()\n\n    when:\n\n    def root = new Polygon([[[1.0,2.0,3.0],[10.1,20.2,30.3]]])\n    ExecutionInput input = ExecutionInput.newExecutionInput().root(root).query(\n    '''\n        {\n            coordinates\n        }    \n    ''').build()\n\n    ExecutionResult executionResult = graphQL.execute(input)\n\n    then:\n    executionResult.data == [\n            coordinates : [[[1.0,2.0,3.0],[10.1,20.2,30.3]]]\n    ]\n\n}\n\n```\nIt shows a field with [[[Float]]] which is a list of list of list of Float in graphql terms.\nThe Polygon java object is set in as the root of the query in this case and that graphql type is mapped by pojo method name to the getCoordinates method.. I have used graphql SDL to define the schema as its the most flexible. Thanks for reporting.  I will look at the PR and comment there.\nFor the record there was a LOT of angst about defaulting null values in the new spec.  A lot!. I always took \"alias\" to be a renaming technique, not how you should get to the underlying data.\nThat is I have a field called  name BUT the client making the query wants to call it aliasedName on this query.  So its very much driven by the client making the query, not the server providing the schema.\nin graphql now we have the @fetch aliasing that allows the server (not the client) to indicate that property name should be used\ntype Query {\n    name : String @fetch(from:\"anotherProperty\")\n}\n\nMy other problem with this PR is that is handles maps but not POJO methods.  It should be consistent on all access strateegies\nIn short I dont think we should do this.  aliasing is a client side thing to get the same property I think\n. Thanks. Thanks fo this fix.  This is one of the most professional PRs I have reviewed.\n. Sorry I merged your other PR and now it has conflicts. The tricky part here is that Introspection is an open ended query.  It can be just `__typename`` right up to the default complicated Introspection query.\n```\nquery IntrospectionQuery {\n    __schema {\n      queryType { name }\n      mutationType { name }\n      subscriptionType { name }\n      types {\n        ...FullType\n      }\n      directives {\n        name\n        description\n        locations\n        args {\n          ...InputValue\n        }\n      }\n    }\n  }\nfragment FullType on __Type {\n    kind\n    name\n    description\n    fields(includeDeprecated: true) {\n      name\n      description\n      args {\n        ...InputValue\n      }\n      type {\n        ...TypeRef\n      }\n      isDeprecated\n      deprecationReason\n    }\n    inputFields {\n      ...InputValue\n    }\n    interfaces {\n      ...TypeRef\n    }\n    enumValues(includeDeprecated: true) {\n      name\n      description\n      isDeprecated\n      deprecationReason\n    }\n    possibleTypes {\n      ...TypeRef\n    }\n  }\nfragment InputValue on __InputValue {\n    name\n    description\n    type { ...TypeRef }\n    defaultValue\n  }\nfragment TypeRef on __Type {\n    kind\n    name\n    ofType {\n      kind\n      name\n      ofType {\n        kind\n        name\n        ofType {\n          kind\n          name\n        }\n      }\n    }\n  }\n```\nSo how would the library make a sensible decision on whether its an introspection query or not?  The presence of __xxx`` say?  This would allow people to whack__typename` in their expensive queries to subvert your depth checking.\nThis is a tricky problem and at first glance I cant think of an easy way to know its Introspection of not.\nHmmmm...\n. Yes it could however there is NO one canonical Introspection query.  A client is free to make them up.\nSo it would need to be a hueristic to \"guess\" if the max depth should be allowed or not.. Right so basically you have written a heuristic that checks if a query looks Introspection like.\nThis is likely to work but it CANT be guaranteed to work for all queries because the introspection queries are NOT fixed.  Its is however a pretty good heuristic.\nIn short I think this works for you but I struggle to immediately see how we can make it generic for all users.\nThat said it makes sense that one would want to not depth check valid introspection queries yet do it on the other queries.\nI am in a bit of a bind on how to solve this challenge. You need to use ExecutionInput to specify it\n```\n        HashMap variablesMap = new HashMap<>();\n        variablesMap.put(\"var1\",\"value1\");\n    ExecutionInput executionInput = ExecutionInput.newExecutionInput()\n            .query('{ yourquery { name } }')\n            .variables(variablesMap)\n            .context(new SomeContextObject())\n            .root(new SomeRootThing())\n            .build();\n\n```\nThe roor is fixed for the life of the query.  It also is the seed for the environment.getSource()\nEach object returned then becomes the new environment.getSource() as you descend the query.\nThe context is also an object of your choosing.  Its a helper for you in every data fetcher for \"context\". generally a data fetcher wont access the root but rather its a way to \"seed\" the object tree.\nSo assuming you have a query like\n {\n   user(id : 123) {   # at this point you have a fetcher that returns a User object\n       name\n       group {  # at this point the User object is the source and your looking for groups in the DF\n          name\n          test {  # at this point the group object is the source and you are looking for a Test object in the DF\n              id\n          }\n   }\n}\n      . Actually from the new and soon to be official spec we have this requirement.\n\n\nAn Object type must define one or more fields.\n\nSo while I agree it would be nicer for the document to \"parse\" and get validation errors later, be aware that type MyType {} is invalid and wont be allowed later.\nWhat is not clear in the spec is whether you are allowed to have an empty type and then \"extend type\" it so it does have fields.\n. Yeah as linked to above you can do exactly what you want with graphql-java via PreparsedDocumentProvider\nSome people in the wild are trying an even more aggressive technique on the client and server where they have a protocol for dispatching a query via a hash. \nThe client creates a #hash of the query text and sends it up.  If the server has seen it, then it gets that query from its cache and executes it. So 1 HTTP request and very little layload on the way up.\nIf the server hasnt seen it, it responds with a 3xx and the client sends the full query.  The server then saves that query and the calculated hash.\nThis requires complete co-origination between the client and server and is custom.  Its not defined in spec.  But it does save a lot of bandwidth depending on usage and frequency.\nTo do the above you would need to build the client/server behaviours yourself.. NaN is not a valid float and the spec (and reference graphql-js implementation) require valid floats.\nThe error message could be improved I agree but it is invalid. here is the grapqhl-js reference implementation\nfunction coerceFloat(value: mixed): ?number {\n  if (value === '') {\n    throw new TypeError(\n      'Float cannot represent non numeric value: (empty string)',\n    );\n  }\n  const num = Number(value);\n  if (num === num) {\n    return num;\n  }\n  throw new TypeError(\n    'Float cannot represent non numeric value: ' + String(value),\n  );\n}\nfor the record\n. @tinnou - we would be for you to ressurect this I think. Done. I am guess you would like the PreparsedDocumentEntry to be serialisable.  Its the inner Document that is the challenge.  Its the AST tree of a parsed query (built via ANTLR)\nCan you give us a pseudo code example of how your are expecting to jcache the objects in your graphql.execution.preparsed.PreparsedDocumentProvider\n. The errors and Nodes are now Serialisable . Yes they should nominally behave the same and you are using them right (for queries and mutations say).  \nFeel free to create a unit test showing this problem and perhaps even a PR to fix it.\nWe will look at this issue when we get a chance otherwise.. No - it does not make sense. \nDirective wiring allows you to gather say \"20 fields\" and wire them all in one go.  But the API requires you to build 20 fields by hand so you can just put the data fetchers (and hence the behaviour) at the time you build the field.. I think you would be better to invent a post processing step in graphql-java-annotations much like what we do in the SDL directive wiring.\nTo explain I will tell you how we build SDL\n\nStep 1 - parse the SDL in type definitions (and validate as much as we can)\nStep 2a - create the GraphqlType tree from those definitions including default / wired data fetchers\nStep 2b - after the field and containing GraphqlType is built, call out to the DirectiveWiring to mutate it into any form it likes (this is a kinda of post processing\nStep 3 - Complete Schema is now built\n\nYou seem to be asking for defaulting mechanism (field -> object type  -> schema) looking for directives / metadata.  This is going to be hard before you have built the complete schema but then circular trees are always tricky like that.\nI still feel like the interface graphql.schema.idl.SchemaDirectiveWiring is not the right  way for graphql-java-annotations to tweak the built tree.  The directives used are in SDL graphql.language.Directive form when used in the schema generator\nYou could for example synthesise runtime 'graphql.schema.GraphQLDirective` objects when running the graphql-java-annotations processing and then later walk the tree and change the behaviours based on them say.  I am guessing you are transferring \"java annotations\" into graphql directives so you can store metadata about a type??\nCan you give me a more concrete example of Java class -> Graphql type and how you want to process them?\n. > My dilemma is where to declare the \"toUpperCase\" directive? The problem is not how to generate a GraphQLDirective from annotation, but where to declare this annotation. \nJust create a GraphQLDirective instance and put it on the type at type creation time.  Thats not the hard part.  The hard part is later adding behaviour or mutating types.\n\nI guess that any solution is not going to be very clean, because I do not have the schema while creating the type.\n\nI think you will want to do a \"post schema\" creation step where you take all the directives declared and run them through a process where you mix in behaviors.  For example your toUpperCase directive will need to change the data fetcher if the field its on.\nThis post step is exactly what happens in the SDL creation steps.  We \"mutate\" the types and fields after they are built with the directive wiring and that can add/remove fields and add / remove data fetcher behaviour\n. > But directives definitions should be declared on the schema, as far as I understand, and not over specific fields/types.\nTrue but outside of SDL they just don't make as much sense.  I personally would not try to invent a holder of valid places for directives in a runtime only type system.\n\nSo if some field or type is decorated with a directive which is not defined on the root level of the schema which contains the object, an error shoud occur (I think this is a reasonable behaviour).\n\nI would not do that but that is up to you.  You will need to invent a new \"valid directive locations holder sub system\" because I don't think we would put such a thing into graphql-java itself.  We MAY but my initial inclination is to not add it.\nFor a start its NOT in the reference implementation (which we take inspiration from although we go beyond it at times) and it just doesn't seem add value to people who create a runtime type system by hand.\nI can see how with your @annotation based system you need more constraints on directives but I am not sure it should go into the base graphql-java library\nImagine you had this in the graphql-java-annotations\n```\npublic @interface DirectiveLocation {\nString[] locations();\n\nString name();\n\n}\npublic @interface DirectiveLocations {\n    DirectiveLocation[] value();\n}\n@DirectiveLocations({\n        @DirectiveLocation(name = \"objectAndFieldDirective\", locations = {\"OBJECT\", \"FIELD_DEFINITION\"}),\n        @DirectiveLocation(name = \"objectOnlyDirective\", locations = {\"OBJECT\"}),\n})\npublic static class SomeRegistryClass {\n}\n```\nThis would allow people to indicate what directive names are allowed where.\nThen later in your annotation processing, you would discover any @DirectiveLocations and create a list of all the value places.  You would then check them against the built graphql runtime objects BEFORE you build out the schema (this is the post processing step I mention above)\nIf the locations are valid, you would allow the schema to be built otherwise throw exceptions.\nps.  You can use enums etc.. instead of strings.  I just did that to type less.\n@andimarek - what are your thoughts on the idea of having a directive definition constructs attached to the runtime schema?\n. > Using your library, someone might create a project which only creates some GraphQLTypes. Another project will create different GraphQLTypes. Than, in a third project, we would merge these types into a schema.\nTrue that is a use case I suppose.  We are not really catering for it today - we would expect that directive oriented people would use SDL and \"combine\" their multiple types at runtime and have a single validation phase.\nBut I can see that it would be the case if you exposed prebuilt Runtime types in a  library.\n. Check out https://graphql.org/learn/queries/#fragments\nAlso post the offending query perhaps if you want more help. Closing this issue since no follow up was made.  Feel free to re-open it if more details are avaiable. Can you better describe your data dependencies.  I can see in your trivial example that that is +1 to a numebr and then do it again.\nBut this is hard for me to get meaningful discussion on.\nDo you have a situation where in order to create a FooBar object you first need to fetch the Foo and then once you have that you need to fetch the Bar for that Foo?\nCant you just do that in your batch loader (pseudo java code)\nBatcherLoad<String,FooBar> batchloader = keys  -> {\n    return CompletableFuture.supplyAsync(() ->  getAllFoos(keys))\n      .thenApply( foos -> getAllBarsForTheseFoosAndTurnThemIntoFooBars(foos))\n}\n??\nThere is no way today to chain data loader calls since they are \"batched\" together as a batch loader function call.  . @arlampin - can you outline some pseudo code on how you chain the calls together to be efficient?\nThe challenge I can see is around when to dispatch the second load of <Bar> load calls. There really is no clean way to dispatch the calls for \"maximum efficiency\".  The graphql engine tracks \"fields\" and their completion as to when to call dispatch.\nBut you have introduced a new layer.\nIF you are caching there is still benefit so I would call dispatch direct inside that code..\neg\n```\nDataLoader, Bar> barIdLoader = ...;\nDataLoader, Bar> fooBarLoader = new DataLoader<>(keys -> {\n  CompletableFuture, ID>> query = backend.asyncGetFooBarMap(keys);\n  query.thenCompose(map -> {\n    List> barIds = new ArrayList<>(map.values());\n    CompleteableFuture<?> cf = barIdLoader.loadMany(barIds).thenApply(bars -> {\n        Map, Bar> barIndex = bars.stream().collect(toMap(Bar::getId, Function.identity()));\n        return keys.stream().map(map::get).map(barIndex::get).collect(toList());\n    });\n    barIdLoader.dispatch()\n    return cf;\n  });\n});\n```\n. Yeah JS has the nextTick() which is really the JS runtime saying... \"I have run out of code to run.  Run all the promises now\" etc..  Java doesn't have this.  Of course is its a proper pre-emptive runtime so you avoid this : \n\n. I have taken the test code and put it into #1083 . The build is failing with\n\nA problem occurred evaluating root project 'graphql-java'.\ngit hash could not be determined\n\nI am not sure what they means however.  Can you re-pull master onto this branch so as to perhaps fix this.\nI did this on other branches and it seem to work.  Like I said I am not sure what this is??. Thanks for that.  I am creating a PR of this test and then start to investigate this bug.\nWe had another report of something similar in Atlassian where I work as well. Ok looking into this I found a few problems.\nThere is a typo where this is done (fieldAndType1 twice)\n        if (!sameType(fieldAndType1.parentType, fieldAndType1.parentType) &&\n            fieldAndType1.parentType instanceof GraphQLObjectType &&\n            fieldAndType2.parentType instanceof GraphQLObjectType) {\n        return null;\n    }\n\n. There is also some non null / list type handling missing as well according to the spec.  The PR has this in place\nThanks @samkline for the initial unit test - that helped bootstrap this work a lot. graphql.validation.rules.KnownDirectives is only used to validate queries and not SDL documents.  \nI am confused here as to who is running that code.  That is an IDEA plugin is some how running graphql-java code or not?\nThat plugin \"js-graphql-intellij-plugin\" is written in what?  Java-Script at a guess or is it actually graphql-java\nThe enforcement of directive locations is not done by the \"query rules\" but rather by graphql.schema.idl.SchemaGeneratorDirectiveHelper and other classes in that package\nCan you please explain more about how this \"problem\" presents itself (as in what code is running.  I can visually see that IDEA plugin thinks its wrong and that it is getting it wrong)\n. >  However, if the developer were to execute the document from the above shown screenshot against a graphql-java endpoint\nThe thing is its not really a sensible thing to submit a SDL document against a graphql server.  A server endpoint is the \"realisation\" of the schema whereas a SDL document is the original description of a schema.  Its the egg before the chicken if you will.\nI can see your challenge here because you are trying to get \"validation\" from the library on whether a particular SDL text it valid or not.\nYou best bet for that would be to use \ngraphql.schema.idl.SchemaParser#parse(java.io.Reader) and \ngraphql.schema.idl.SchemaGenerator#makeExecutableSchema(graphql.schema.idl.SchemaGenerator.Options, graphql.schema.idl.TypeDefinitionRegistry, graphql.schema.idl.RuntimeWiring) and catch SchemaProblems and map the errors it might contain to locations in the document.\nIf you looks at the code you will see that there is a LOT of code involved in validating that a schema follows all the rules.\nWe have tried to implement as many as we can but we havent designed it to be consumed programmatically - that is interpetted by an editor etc.. it will be interesting to see if you can do that\n . Let us know if we need to tweak the errors that come out of parse / wire so that you can report the errors in terms of text / line numbers.  \n. Wow - just when you think your codes ok ;)\n```\n\nTask :compileJava \n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/Assert.java:20: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public static  T assertNeverCalled() {\n                        ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/Assert.java:24: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public static  T assertShouldNeverHappen(String format, Object... args) {\n                        ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/Assert.java:28: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public static  T assertShouldNeverHappen() {\n                        ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLArgument.java:78: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLFieldDefinition.java:72: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLList.java:39: warning: [MissingOverride] getWrappedType implements method in GraphQLModifiedType; expected @Override\n    public GraphQLType getWrappedType() {\n                       ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public GraphQLType getWrappedType() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLNonNull.java:38: warning: [MissingOverride] getWrappedType implements method in GraphQLModifiedType; expected @Override\n    public GraphQLType getWrappedType() {\n                       ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public GraphQLType getWrappedType() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLObjectType.java:83: warning: [MissingOverride] getFieldDefinition implements method in GraphQLFieldsContainer; expected @Override\n    public GraphQLFieldDefinition getFieldDefinition(String name) {\n                                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public GraphQLFieldDefinition getFieldDefinition(String name) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLObjectType.java:87: warning: [MissingOverride] getFieldDefinitions implements method in GraphQLFieldsContainer; expected @Override\n    public List getFieldDefinitions() {\n                                        ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getFieldDefinitions() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLObjectType.java:106: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLTypeReference.java:32: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/InputValueDefinition.java:44: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/InputValueDefinition.java:64: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/AbstractNode.java:25: warning: [MissingOverride] getComments implements method in Node; expected @Override\n    public List getComments() {\n                         ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getComments() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/Type.java:9: warning: [MissingOverride] deepCopy implements method in Node; expected @Override\n    T deepCopy();\n      ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override T deepCopy();'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/Value.java:9: warning: [MissingOverride] deepCopy implements method in Node; expected @Override\n    T deepCopy();\n      ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override T deepCopy();'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/Directive.java:40: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/Argument.java:20: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/DirectiveDefinition.java:26: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/Definition.java:9: warning: [MissingOverride] deepCopy implements method in Node; expected @Override\n    T deepCopy();\n      ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override T deepCopy();'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/DirectiveLocation.java:25: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/EnumTypeDefinition.java:33: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/TypeDefinition.java:20: warning: [MissingOverride] deepCopy implements method in Definition; expected @Override\n    T deepCopy();\n      ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override T deepCopy();'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/EnumValue.java:18: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/EnumValueDefinition.java:24: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/EnumValueDefinition.java:36: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/Field.java:67: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/Field.java:91: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/Field.java:99: warning: [MissingOverride] getSelectionSet implements method in SelectionSetContainer; expected @Override\n    public SelectionSet getSelectionSet() {\n                        ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public SelectionSet getSelectionSet() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/FieldDefinition.java:40: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/FieldDefinition.java:56: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/FragmentDefinition.java:41: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/FragmentDefinition.java:57: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/FragmentDefinition.java:65: warning: [MissingOverride] getSelectionSet implements method in SelectionSetContainer; expected @Override\n    public SelectionSet getSelectionSet() {\n                        ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public SelectionSet getSelectionSet() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/FragmentSpread.java:27: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/FragmentSpread.java:35: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/InlineFragment.java:62: warning: [MissingOverride] getSelectionSet implements method in SelectionSetContainer; expected @Override\n    public SelectionSet getSelectionSet() {\n                        ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public SelectionSet getSelectionSet() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/InputObjectTypeDefinition.java:26: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/InterfaceTypeDefinition.java:30: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/ObjectField.java:20: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/ObjectTypeDefinition.java:32: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/OperationDefinition.java:89: warning: [MissingOverride] getSelectionSet implements method in SelectionSetContainer; expected @Override\n    public SelectionSet getSelectionSet() {\n                        ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public SelectionSet getSelectionSet() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/OperationTypeDefinition.java:37: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/ScalarTypeDefinition.java:24: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/UnionTypeDefinition.java:26: warning: [MissingOverride] getDirectives implements method in DirectivesContainer; expected @Override\n    public List getDirectives() {\n                           ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/VariableDefinition.java:38: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/VariableReference.java:18: warning: [MissingOverride] getName implements method in NamedNode; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLScalarType.java:61: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLEnumType.java:142: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLInterfaceType.java:71: warning: [MissingOverride] getFieldDefinition implements method in GraphQLFieldsContainer; expected @Override\n    public GraphQLFieldDefinition getFieldDefinition(String name) {\n                                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public GraphQLFieldDefinition getFieldDefinition(String name) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLInterfaceType.java:76: warning: [MissingOverride] getFieldDefinitions implements method in GraphQLFieldsContainer; expected @Override\n    public List getFieldDefinitions() {\n                                        ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getFieldDefinitions() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLInterfaceType.java:80: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/TypeResolutionEnvironment.java:40: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getObject() {\n                 ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/TypeResolutionEnvironment.java:73: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getContext() {\n                 ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLInputObjectField.java:66: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLInputObjectType.java:63: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/DataFetchingEnvironment.java:30: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n     T getSource();\n          ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/DataFetchingEnvironment.java:54: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n     T getArgument(String name);\n          ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/DataFetchingEnvironment.java:66: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n     T getContext();\n          ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/DataFetchingEnvironment.java:75: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n     T getRoot();\n          ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/ExecutionTypeInfo.java:134: warning: [JdkObsolete] Stack is a nonstandard class that predates the Java Collections Framework; prefer ArrayDeque. Note that the Stack methods push/pop/peek correspond to the Deque methods addFirst/removeFirst/peekFirst.\n        Stack decoration = new Stack<>();\n                                        ^\n    (see http://errorprone.info/bugpattern/JdkObsolete)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/DataFetchingFieldSelectionSet.java:42: warning: [MissingOverride] get implements method in Supplier; expected @Override\n    Map> get();\n                             ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override Map> get();'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/ExecutionContext.java:98: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getRoot() {\n                 ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/Async.java:28: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n                .whenComplete((noUsed, exception) -> {\n                             ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean to remove this line?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/Async.java:80: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n        cf.whenComplete((cfResult, exception) -> {\n                       ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean 'cf = cf.whenComplete((cfResult, exception) -> {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/Async.java:125: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n        source.whenComplete((o, throwable) -> {\n                           ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean 'source = source.whenComplete((o, throwable) -> {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/ExecutionStrategy.java:203: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n        executionResultFuture.whenComplete(fieldCtx::onCompleted);\n                                          ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean 'executionResultFuture = executionResultFuture.whenComplete(fieldCtx::onCompleted);'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/ExecutionStrategy.java:364: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n        executionResultFuture.whenComplete(ctxCompleteField::onCompleted);\n                                          ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean 'executionResultFuture = executionResultFuture.whenComplete(ctxCompleteField::onCompleted);'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/ExecutionStrategy.java:516: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n        resultsFuture.whenComplete((results, exception) -> {\n                                  ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean 'resultsFuture = resultsFuture.whenComplete((results, exception) -> {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/ExecutionStrategy.java:529: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n        overallResult.whenComplete(completeListCtx::onCompleted);\n                                  ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean 'overallResult = overallResult.whenComplete(completeListCtx::onCompleted);'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/defer/DeferSupport.java:43: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n        future.whenComplete((executionResult, exception) -> {\n                           ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean 'future = future.whenComplete((executionResult, exception) -> {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/ExecutionPath.java:62: warning: [ReferenceEquality] Comparison using reference equality instead of value equality\n        if(this == ROOT_PATH) {\n                ^\n    (see http://errorprone.info/bugpattern/ReferenceEquality)\n  Did you mean 'if(this.equals(ROOT_PATH)) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/ExecutionPath.java:183: warning: [ReferenceEquality] Comparison using reference equality instead of value equality\n        if (parent == ROOT_PATH) {\n                   ^\n    (see http://errorprone.info/bugpattern/ReferenceEquality)\n  Did you mean 'if (Objects.equals(parent, ROOT_PATH)) {' or 'if (parent.equals(ROOT_PATH)) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/ExecutionResult.java:18: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n     T getData();\n          ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationExecutionParameters.java:59: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getContext() {\n                 ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationExecutionParameters.java:67: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getInstrumentationState() {\n                                              ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationValidationParameters.java:27: warning: [MissingOverride] withNewState overrides method in InstrumentationExecutionParameters; expected @Override\n    public InstrumentationValidationParameters withNewState(InstrumentationState instrumentationState) {\n                                               ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public InstrumentationValidationParameters withNewState(InstrumentationState instrumentationState) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationExecuteOperationParameters.java:38: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getInstrumentationState() {\n                                              ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationExecutionStrategyParameters.java:45: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getInstrumentationState() {\n                                              ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationDeferredFieldParameters.java:32: warning: [MissingOverride] withNewState overrides method in InstrumentationFieldParameters; expected @Override\n    public InstrumentationDeferredFieldParameters withNewState(InstrumentationState instrumentationState) {\n                                                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public InstrumentationDeferredFieldParameters withNewState(InstrumentationState instrumentationState) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationFieldParameters.java:54: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getInstrumentationState() {\n                                              ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationFieldFetchParameters.java:36: warning: [MissingOverride] withNewState overrides method in InstrumentationFieldParameters; expected @Override\n    public InstrumentationFieldFetchParameters withNewState(InstrumentationState instrumentationState) {\n                                               ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public InstrumentationFieldFetchParameters withNewState(InstrumentationState instrumentationState) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/execution/instrumentation/parameters/InstrumentationFieldCompleteParameters.java:66: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getInstrumentationState() {\n                                              ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLEnumValueDefinition.java:58: warning: [MissingOverride] getName implements method in GraphQLType; expected @Override\n    public String getName() {\n                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public String getName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLEnumValueDefinition.java:78: warning: [MissingOverride] getDirectives implements method in GraphQLDirectiveContainer; expected @Override\n    public List getDirectives() {\n                                  ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getDirectives() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLEnumValueDefinition.java:82: warning: [MissingOverride] getDirectivesByName implements method in GraphQLDirectiveContainer; expected @Override\n    public Map getDirectivesByName() {\n                                         ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public Map getDirectivesByName() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/schema/GraphQLEnumValueDefinition.java:86: warning: [MissingOverride] getDirective implements method in GraphQLDirectiveContainer; expected @Override\n    public GraphQLDirective getDirective(String directiveName) {\n                            ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public GraphQLDirective getDirective(String directiveName) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/GraphQL.java:559: warning: [FutureReturnValueIgnored] Return value of methods returning Future must be checked. Ignoring returned Futures suppresses exceptions thrown from the code that completes the Future.\n        future.whenComplete((result, throwable) -> {\n                           ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n  Did you mean 'future = future.whenComplete((result, throwable) -> {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/NodeTraverser.java:48: warning: [MissingOverride] enter implements method in TraverserVisitor; expected @Override\n            public TraversalControl enter(TraverserContext context) {\n                                    ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public TraversalControl enter(TraverserContext context) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/NodeTraverser.java:53: warning: [MissingOverride] leave implements method in TraverserVisitor; expected @Override\n            public TraversalControl leave(TraverserContext context) {\n                                    ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public TraversalControl leave(TraverserContext context) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/NodeTraverser.java:61: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public static  T oneVisitWithResult(Node node, NodeVisitor nodeVisitor) {\n                        ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/util/TraverserState.java:35: warning: [MissingOverride] pushAll implements method in TraverserState; expected @Override\n        public void pushAll(TraverserContext o, Function<? super U, ? extends List> getChildren) {\n                    ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public void pushAll(TraverserContext o, Function<? super U, ? extends List> getChildren) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/util/TraverserState.java:48: warning: [MissingOverride] pushAll implements method in TraverserState; expected @Override\n        public void pushAll(TraverserContext o, Function<? super U, ? extends List> getChildren) {\n                    ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public void pushAll(TraverserContext o, Function<? super U, ? extends List> getChildren) {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/ExecutionResultImpl.java:55: warning: [TypeParameterUnusedInFormals] Declaring a type parameter that is only used in the return type is a misuse of generics: operations on the type parameter are unchecked, it hides unsafe casts at invocations of the method, and it interacts badly with method overload resolution.\n    public  T getData() {\n                 ^\n    (see http://errorprone.info/bugpattern/TypeParameterUnusedInFormals)\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/ObjectTypeExtensionDefinition.java:19: warning: [MissingOverride] deepCopy overrides method in ObjectTypeDefinition; expected @Override\n    public ObjectTypeExtensionDefinition deepCopy() {\n                                         ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public ObjectTypeExtensionDefinition deepCopy() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/EnumTypeExtensionDefinition.java:18: warning: [MissingOverride] deepCopy overrides method in EnumTypeDefinition; expected @Override\n    public EnumTypeExtensionDefinition deepCopy() {\n                                       ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public EnumTypeExtensionDefinition deepCopy() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/UnionTypeExtensionDefinition.java:14: warning: [MissingOverride] deepCopy overrides method in UnionTypeDefinition; expected @Override\n    public UnionTypeExtensionDefinition deepCopy() {\n                                        ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public UnionTypeExtensionDefinition deepCopy() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/ScalarTypeExtensionDefinition.java:15: warning: [MissingOverride] deepCopy overrides method in ScalarTypeDefinition; expected @Override\n    public ScalarTypeExtensionDefinition deepCopy() {\n                                         ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public ScalarTypeExtensionDefinition deepCopy() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/language/InterfaceTypeExtensionDefinition.java:15: warning: [MissingOverride] deepCopy overrides method in InterfaceTypeDefinition; expected @Override\n    public InterfaceTypeExtensionDefinition deepCopy() {\n                                            ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public InterfaceTypeExtensionDefinition deepCopy() {'?\n/Users/bbaker/src/graphql/graphql-java/src/main/java/graphql/ExceptionWhileDataFetching.java:71: warning: [MissingOverride] getPath implements method in GraphQLError; expected @Override\n    public List getPath() {\n                        ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public List getPath() {'?\nNote: Some input files use unchecked or unsafe operations.\n```. I am happy to accept this PR - if the error prone output is too onerous we can always disable it . Its interesting that IDEA does not ship with @Overrride checks enabled. if you do submit a PR with fix ups can you please attack one problem per PR.  eg all the overrrides versus all the futures ones etc...\n\nThis will make PR review so much easier. I turned on error prone from IDEA and a large portion of the errors are @Override warnings\nHence #1096  : https://github.com/graphql-java/graphql-java/pull/1096/files. I made a bunch of these changes in prep if we ran this.\nThese have been merged to master.  I think you should rebase to see that final output now. Closing as we wont have it run day to day = we will however use it periodically to check the code. @oeil - as far as I can tell, we do support Relay Modern - last time I checked the server side implementation hadn't changed shape when they brought out Relay Modern.\nBut I haven't watched it super closely so if you can list whats different (on the server) then we would consider implementing it. I looked into this.  Our Relay helpers for connections and so on work with Relay Modern.\nI am going to close this issue. > should we deprecate the constructor?\nHmmm.  I would prefer the other one...so maybe... but its stylistic more than functional.  I just wanted one consistent style within the main code base. Actually I moved the isLeaf and isInput methods out of SchemaUtil and then its NO longer used by any code\nIts @Internal and hence we can kill it\nI will do that in another PR. We have looked into this issue and we now know what is causing it.\nWe missed the fact that mutations will be default using the AsyncSerialExecutionStrategy and that the dispatch calls for that are not being made at the right time (as they are in serial).\nWe haven't yet worked out the best way to fix this but are working on it.\nThanks for reporting it.. The initial fix here is to disable data loader batching on mutations.  This will ensure that they queries work even if they are not as efficient as they can be.\nThe secondary and more proper fix involves working out how we can \"transfer\" from the spec required AsyncSerialExecutionStrategy to the non serial AsyncExecutionStrategy and keep the field reference counting correct.\nThe PR merged above is the first fix to get it work.  More will follow later. Can  I ask what version of graphql-java you are on and perhaps to utilise a reproduce unit test\nI created this quick unit test to try and reproduce and it could not\n```\n    def \"#1100 - interfaces can be generated\"() {\n        def spec = '''\n            interface A {\n              interfaceField : String\n            }\n        type T1 implements A {\n            interfaceField : String\n            f1: T2\n        }\n        type T2 {\n            f1: T3 \n        }\n        type T3 {\n            f1: T1 #recursion - points to a T1\n        }\n\n        type Query {\n            f : T1\n        }\n    '''\n\n    def schema = schema(spec, TestUtil.mockRuntimeWiring)\n\n    expect:\n    schema != null\n}\n\n```\nCan you please try to reproduce this further. The class graphql.schema.idl.SchemaTypeChecker is meant to pre-validate that type structure is valid by the way and hence we later make some assumptions about things being ok to cast...\nI say this as way of explaining the code - I am sure they could be bugs. Thanks. Since there is no reply I am going to close this issue for now. The trick here is the esoteric argument about \"what is a boolean input type\"\nBoolean.parseBoolean is a java idiomatic way to get a Boolean value.  And yes it takes Strings.\nThe reference graphql-js (which we tend to go to when the spec is in question) uses JavaScript Boolean parsing\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Boolean\n\nThe value passed as the first parameter is converted to a boolean value, if necessary. If the value is omitted or is 0, -0, null, false, NaN, undefined, or the empty string (\"\"), the object has an initial value of false. All other values, including any object or the string \"false\", create an object with an initial value of true.\n\nSo they accept strings / numbers and in fact any object with an idiomatic JavaScript approach.\nSo I dont think the current approach is incorrect.\nBut if you could explain more about the impact you are seeing and the inputs you think are incorrect we can discuss it. I am inclined to leave the behaviour as it is.  That is a value for input to a boolean uses idiomatic Java boolean-ness just like the JS reference implementation uses idiomatic JS boolean-ess.\n@andimarek  - thoughts?. Thanks for the detailed bug.  We will investigate this.  . I have a fix for this bug.  We will target a 9.x stable release . I suspect that this issue is for the graphql-java-annotations project and not the graphql-java base library.\nThere are no @GraphQLField and @GraphQLPrettify annotations in graphql-java. Can you explain more why please.\nI think I can guess at it but can you outline your use case better please. I think I would rather go with option 2 and leave @defer on by default.\nI understand your use case but I think those who DONT want it should be able to build out their schema by \"clearing the directives\"and then adding back the ones they want\nin other type places we use this code pattern\n```\n     public Builder withDirectives(GraphQLDirective... directives) {\n            for (GraphQLDirective directive : directives) {\n                withDirective(directive);\n            }\n            return this;\n        }\n    public Builder withDirective(GraphQLDirective directive) {\n        assertNotNull(directive, \"directive can't be null\");\n        directives.put(directive.getName(), directive);\n        return this;\n    }\n\n    public Builder withDirective(GraphQLDirective.Builder builder) {\n        return withDirective(builder.build());\n    }\n\n    /**\n     * This is used to clear all the directives in the builder so far.\n     *\n     * @return the builder\n     */\n    public Builder clearDirectives() {\n        directives.clear();\n        return this;\n    }\n\n```\nWhere we provide a clearXXX method, from which you can then build up the list of xxx things again.  I think we should repeat that . Ahh I made another PR in the mean time - pretty much this change with some deprecations etc..\nI also based it off the 9.x branch so it can be stable\nSee #1145 \n. Closing this since its now made via the #1145 - thanks fo this PR though. @tinnou - I am guessing we would want this on the stable branch as well as master right?. We have considered this.  The challenge is not semver but that you MUST maintain a stable branch and a master branch to do true semver.\nWe have not had the resources to maintain multiples branches so we created releases that contain breaking changes and bug fixes.\nHowever we are considering adopting a stable branch and hence we would in a better position to do semver as people know it. We are maintaining a stable branch now. This is working as like this by design (which might not be your expectation)\nThe challenge for DataLoader and graphql-java is knowing when is the most optimal time to dispatch calls to the data loaders.  It does this by tracking fields and KNOWING when the execution strategy has reach the most exhaustive end of the available field values.\nIt can ONLY do this if you use AsyncExecutionStrategy which is the default.\nIt turns of data loader optimisation for all other execution strategies since it cant KNOW when to do an efficient batch and if it didnt it could \"hang\" the query.\nI suggest you dont use ExecutorServiceExecutionStrategy - rather if you want to make your calls async on different threads then use a DataFetcher pattern that submits it to a CompleteableFuture pool\nDataFetcher df = environement -> {\n       return CompleteableFuture.supplyAsync( codeToGetData)\n}\n\nThis has the same async multi threaded behaviour as ExecutorServiceExecutionStrategy but it can be efficient in data loader terms.  You can also use your own executor pool with CompleteableFuture.supplyAsync so you have full control\n@andimarek - I think we should possibly deprecate ExecutorServiceExecutionStrategy and remove it at a later time.\n. We have some doco on http://graphql-java.readthedocs.io/en/latest/batching.html\nI will extend it to explicitly talk about other Execution Strategies. See #1173. Take a look at graphql.execution.DataFetcherResult  It allows you to return a data result (which can be a value or null) and also errors at the same time.  You return it from your data fetcher\nYou can then write a little bit of helper code to turn exceptions into graphql errors.\nAlso there is a ExecutionResult#toSpecification that will remove all extra attributes from graphql errors such as stack traces.. Seems fair - this would be a breaking change on those that call the overloaded method but its cleaner. See #1145 . The idea of a \"type + id\" is a very much a realy thing where its need for the node(id : $someId) pattern so I think we will leave this under the relay name space. > I've tried using a scalar that takes an object as input. \nI am not sure what that means.  in graphql only \"fields\" take arguments.  A scalar is a type (both input and output type) and represents an indivisable value.\nI suspect you are \"misusing the Scalar implementation\"\nCan you give more concrete examples.  graphql-java should be doing all the execution and parsing for you. Yeah you have your terminology and type systems wrong.\n```\nquery testOk {\n  field(arg: {test: \"ok\"} )\n}\ntype Query {\n    field(arg: Test): String\n}\ninput Test {\n     test : String \n}\n```\nYou should not use a scalar here but an input type.  This is the way we describe compound object values for field arguments\nScalars are leaf nodes that have a defined value set.   You have a compound \"object\" here not a scalar\nhttps://graphql.org/learn/schema/#scalar-types. We would not accept a JSON scalar type in graphql-java.  You can however write one and exposes it as a library say based on graphql-java.\nThe idea of making the variables map part of the \"Coercing\" callback is just wrong.  A Scalar is meant to be an atomic type - that is cant be broken down further.\nSo you can have a JSON scalar type say but its does not reach into the variables map to grab part of itsself like you have done.  Eg your have\nquery A($value: String!) { \n    query(parameter: {key: $value}) { \n           result \n     }\n}\nwhere the $value is actually a string but you want your JSON scalar to reach into the variables map to get a small part of it.  That is mix AST with variables.  Graphql is not meant to be used like that.\nA more proper example would be\nquery A($value: JsonScalar) { \n    query(parameter: $value) { \n           result \n     }\n}\nNotice here we have your JsonScalar and it is passed to the field as a parameter.  But as a whole variable - not as part AST and part variable.  Mixing the two is NOT how graphql should work.\n. I write a really simple groovy test showing this\n```\n    def \"map like scalar\"() {\n    def mapScalar = GraphQLScalarType.newScalar().name(\"MapScalar\").coercing(new Coercing() {\n        @Override\n        Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n            return dataFetcherResult\n        }\n\n        @Override\n        Object parseValue(Object input) throws CoercingParseValueException {\n            return input\n        }\n\n        @Override\n        Object parseLiteral(Object input) throws CoercingParseLiteralException {\n            return input\n        }\n    }).build()\n\n    def spec = '''\n        scalar MapScalar\n\n        type Query {\n            query(parameter : MapScalar) : Result\n        }\n\n        type Result {\n            result : MapScalar\n        }\n    '''\n\n    def dataFetcher = new DataFetcher() {\n        @Override\n        Object get(DataFetchingEnvironment environment) {\n            def argument = environment.getArgument(\"parameter\")\n            return argument\n        }\n    }\n\n    def runtimeWiring = newRuntimeWiring().type(newTypeWiring(\"Query\")\n            .dataFetcher(\"query\", dataFetcher)\n    )\n            .scalar(mapScalar)\n            .build()\n\n    def schema = TestUtil.schema(spec, runtimeWiring)\n\n    def graphql = GraphQL.newGraphQL(schema).build()\n\n    def query = '''\n        query A { \n            query(parameter: {result : \"value\"}) { \n                result\n            }\n        }'''\n\n     // use variables\n     query = '''\n        query A($value: MapScalar) {\n            query(parameter: $value) {\n                result\n            }\n        }'''\n    def executionInput = ExecutionInput.newExecutionInput().variables([value: [result: \"value\"]]).query(query).build()\n\n    when:\n    def er = graphql.execute(executionInput)\n    then:\n    er.errors.isEmpty()\n    println(er.data)\n}\n\n```. This shows a Java Map scalar but it could be a JSON one where you call Jackson or GSON to parse/serialise JSON say. Ok I looked further into this and the spec says nothing about whether the Scalar.parseLiteral method should take a variables map (allowing you to mix AST and variables)\nHowever looking at graphql-js (the reference implementation) I see the following definition\nparseLiteral: GraphQLScalarLiteralParser<*>;\nexport type GraphQLScalarLiteralParser<TInternal> = (\n  valueNode: ValueNode,\n  variables: ?ObjMap<mixed>,\n) => ?TInternal;\n\nSo it in fact it has a variables object defined as argument\nHOWEVER there is some validation code that never gives in the variables map and there are NOT built in scalars that use variables.\nSo it seems you CAN reach in and mix AST with variable references kinda sort of but the spec has nothing to see on it\n. Yeah trying to decide what do do here.  The spec is absent on variables being available and what I am calling partial AST eg `field(argument : { objectKey : $variableReference })\nThe JavaScript implementation seems to have it based on reading the code.  \nThere is 2 calls to parseLiteral - one for validation (we ask that a value be created so we can  let them say if its ok or not  (currently no variables yet since they havent been translated)\nThe JS implementation does\n```\n // Scalars determine if a literal value is valid via parseLiteral() which\n  // may throw or return an invalid value to indicate failure.\n  try {\n    const parseResult = type.parseLiteral(node, undefined / variables /);\n    if (isInvalid(parseResult)) {\n      context.reportError(\n        new GraphQLError(\n          badValueMessage(inspect(locationType), print(node)),\n          node,\n        ),\n      );\n    }\n  } catch (error) {\n    // Ensure a reference to the original error is maintained.\n    context.reportError(\n```\nSo no variables being passed here\nAnd then there is the call to get values for arguments during execution, which is when variables are available\nIn JS its\nif (isScalarType(type)) {\n    // Scalars fulfill parsing a literal value via parseLiteral().\n    // Invalid values represent a failure to parse correctly, in which case\n    // no value is returned.\n    let result;\n    try {\n      result = type.parseLiteral(valueNode, variables);\n    } catch (_error) {\n      return; // Invalid: intentionally return no value.\n    }\nWe could have a default method so we don't break ALL Scalars\ndefault Object parseLiteral(Object input, Map<String,Object> variables) {\n       return this.parseLiteral(input)\n}\n\n@andimarek ?  Thoughts?  This is a tricky one\n. I have asked on the spec site as well\nhttps://github.com/facebook/graphql/issues/495. This is now in place. Yup we stayed on java 6 for a very long time but maybe a year ago we decide to move to Java 8.\nWe wont be adding any support for older JDKS sorry.\nVersion | Release\u00a0date | End of Public Updates\n-- | -- | --\nJava SE 6 | December\u00a02006 | April 2013\nJava SE 7 | July 2011 | April 2015\nJava SE 8 (LTS) | March 2014 | January 2019 (commercial)\u00a0December\u00a02020 (non-commercial)\n. I think I know the roughly the problem around the builder keeping the old additional types but can you make up an more concrete example to use as a unit test so we fix exactly the problem. See #1145 . I am torn by this issue of datetime support in graphql-java\nOn the one hand its is NOT defined by the graphql spec and hence not a fundamental scalar\nOn the other hand people clearly want it (in graphql-java and graphql-js) because a date/datetime is a pretty fundamental scalar value.\nI really dont know if we should accept a datetime scalar in the base implementation since there are a number of alternatives.\nThoughts @andimarek ?  @kaqqao ?  @tinnou ?\n. This is a tricky one.  The data fetcher that runs on the subEntities is meant to be able to get all the \"objects\" that can then be used in later fields.\nLets say your SubEntity looks like this\n   type SubEntity {\n          name : String\n          address : Address\n     }\n\nI am assuming that the sub entity object is \"lazy\" and that you might not have the \"address\" object on it until you make a call in the \"address\" field say.\nbut graphql-java doesnt allow you to take the original object and mutate it with a new one that has the address filled out say.  The \"environment.getSource()\" is immutable.. It sounds like you are using another lib built on graphql-java (perhaps graphql-java-tools maybe??) and hence they introduce their own layers of code..  So i will talk in pure graphql-java terms\nI think you need to look ahead in your parent resolver.  If it needs to do work by filtering or getting extra data early then you have no choice.\nTake a look at graphql.schema.DataFetchingEnvironment#getSelectionSet which gives you the \"selection set\" of fields under the covers.  It allows you to know up front what will be asked for later.\nThe challenge here is seperation of concerns where we often want the data fetcher for SubEntity to not know about child fetchers.  But sometimes you have to.\nIf you are filtering in the subEntities, you really have no choice but to look ahead and get a List<SubEntityObj> that has been filtered.  That data fetcher is going to have to know about the things it filters on.. Thanks for reporting.. What is the other other graphql implementation that gives that error.\nOn the PR i makde the case that this is NOT covered by graphql specfication. @andimarek - this one is a classic fix that should be sent to the stable  branch.  However GitHub does us no favours here because it was started from master and hence a merge to 9.x is a merge of master.\nThis is challenge we have in trying to \"cheaply\" maintain a stable branch. I am not sure this follows graphql spec.  The spec has a set of rules on variable definitions\neg 5.8.x sections in http://facebook.github.io/graphql/June2018/#sec-Validation.Variables\nThe talk a lot about the use of variable definitions in the query.  eg\nquery takesBoolean($atOtherHomes: Boolean) {\n  dog {\n    isHousetrained(atOtherHomes: $atOtherHomes)\n  }\n}\nBut no where can I see that is mandates the entries in the runtime variables map MUST be used.  Note the difference.  It says that $varDef entries MUST be referenced but it does not mention the runtime variables map.\nI think its not correct to say that you supplied a runtime variable and thats an error if its not $variable referenced. eg\nDons reported issue is #1139  and he is saying that another (as yet unspecified) implementation is checking this\nLooking at graphql-js I cant see any reference to checking the runtime input variables map.\nHence I think this is NOT a correct implementation.  Whats the \"hurt\" @mrdon-atlassian if some one sends a { notUsedVar : \"x\" } up in the variables map but its not defined in the query??  Its chaff to the wind surely?\nThoughts @andimarek @kaqqao @tinnou ?\n. relates to #1135 . See #1127. Have  a a look at graphql.schema.idl.UnExecutableSchemaGenerator\nIt is an internal class (and hence may change) but shows you how to have a No op runtime wiring.\nNow it technically not possible to get an EXACT list of the graphql object types because it is ONLY during the execution of a query that interfaces / unions can be turned into an actual object type.\nWe would like to know more about what you want to achieve in this \"AST  -> graphql object types\" traversal.  This will help us give you a better answer. We don't have a code construct to traverse the schema per se because its not something that graphql-java does at runtime (as opposed to say query traversal).  I think you may want to write your own.\nRemember that the type system is circular so you have to remember what you have seen.\nI am going to close this since I dont think we should add more code to graphql-java for this since its yet more cost to maintain but not commonly asked for.  We can revist that decision of course. Can you explain more about how it failed?\nEnums are meant to be a constrained list of string like values eg\nenum Episode {\n  NEWHOPE\n  EMPIRE\n  JEDI\n}\nWe can map them to Java Enums under the covers and hence get ordinal support say.\nYou example above should be the strings \"1\" and \"2\" and \"3\" say. Closing this since I havent heard anything more back. A PR would help address this issue. @brockgibson  - can you explain in more detail your code, perhaps attach some psudeo code showing the problem or  a unit test demonstrating it.. Ahh are you using AsyncDataFetcher with a call to DataLoader?\nif you are - invert the relationship.  Stop using AsyncDataFetcher but rather in the DataLoader batch function you can make that an async call.\nYou are right that the chain of Async calls confuses things (or worse never returns) and you are not gaining any more concurrency by having async calls over async calls.. We will look into this.  The current code does PUT in types that are not directly referenced by other types but perhaps there is a edge case bug.\n. I wrote the following test on the 9.x stable branch\n```\n        def spec = \"\"\"\n            schema {\n                query: Query\n            }\n        type Query {\n            allLinks(filter: LinkFilter, skip: Int = 0, first: Int = 0): [Link]\n        }\n\n        type Link {\n            id: ID!\n            url: String!\n            description: String\n            postedBy: Employee\n        }\n\n        interface Employee {\n            id: ID!\n            name: String!\n        }\n\n        type User implements Employee {\n            id: ID!\n            name: String!\n            email: String\n            password: String\n        }\n\n        input LinkFilter {\n            description_contains: String\n            url_contains: String\n        }\n    \"\"\"\n\n    def schema = schema(spec, TestUtil.mockRuntimeWiring)\n\n    expect:\n    schema != null\n    GraphQLObjectType userType = schema.getType(\"User\") as GraphQLObjectType\n    userType != null\n\n    userType.getInterfaces().get(0).getName() == \"Employee\"\n\n```\nand it passes as expected.   It was part of graphql.schema.idl.SchemaGeneratorTest\nIt detects the extra \"User\" type that is not directly referenced by other types and adds it correctly as an additional type.\nCan you confirm what graphql-java version you are working on.  I think this has been working like this for a while since we already have a test for this exact scenario\ndef \"builds additional types not referenced from schema top level\"()\nCan you please confirm since I amp tempted to close this issue as working as expected\n. Sorry for the delay in getting back to you.  A few of us have been away with work.\nA quick glance shows this to be a very complete PR and the code looks interesting.\nI will look at it in more details and give you my thoughts on it. \nOnce again thank you for this PR.\nI havent fully got my head around the LazyList consumption but I will outline what I understand so far.\nThe results now support a LazyList which is really a callback for a list of results.  The consumer of that lazyList will be called back\none at a time as they are available until the \"boolean true\" is sent and then all results will be sent.  I am right here?\nThere is also a CompletionCancellationRegistry of callbacks but I could not see where anything was wired into that to get a calback.  I am\nnot clear on how this is intended to be used.\nSquinting at it I feel like its a home grown \"reactive stream\" (http://www.reactive-streams.org/), where a LazyList is really a org.reactivestreams.Publisher \nand the callback actions are like the org.reactivestreams.Subscriber of those results.\nReactive streams allow you to have a list of results that are not all in memory at the one time and allows the consumer (the subscriber) to\nsay how many they want and also allows for a complete drain by having them ask for MAX results via org.reactivestreams.Subscription#request\nAm I off the mark here in these thoughts?\nIf we were to have such a capability in graphql-java then I would model it using a more industry standard set of interfaces such\nas reactive streams so it can be more familar to programmers.\nIn fact we modelled graphql subscriptions subscription { field { subfield1 }} by using reactive streams and hence you get a stream\nof results based on the top level fields.\nThe graphql specification (as it stands in 2018) makes assumptions that all results can be sent at the one time and that errors are all availave\nwhich pulls the  implementation away from a \"lazy\" approach.  For example it mandates that IF a child field is null (but its type is non nullable)\nthen the parent field MUSt become nullable.  This is near impossible to do in a lazy list manner I suggest since you have already\nleaked out parent results before the child completed (I think)\nWe have thought about having a reactive streams interface for graphql-java however one of the challenges of it (as you have discovered)\nis the viral nature of how it changes the execution strategy implementation, right out to the type of results you get and how errors\nare represented.\nSome other people have created a execution strategy that uses reactive streams (https://github.com/bsideup/graphql-java-reactive/blob/master/core/src/main/java/com/github/bsideup/graphql/reactive/ReactiveExecutionStrategy.java) but they did so in isolation (eg copied most of Execution Strategy)\nbecause its near impossible to have a \"composeable\" ExecutionStrategy based on CompleteableFutures (todays code) that can be composed\ninto a version that wants to have lazy streams of data (your example)\nSo to summarize I think in order to have lazy results in graphql-java I would see it implemented as follows\n\nas a reative stream shape\nas a seperate execution strategy\n. The fact that you can change the argument map at all when it has some arguments is a BUG.\n\nWe try to use immutability where we can and this would be a classic place for this.\nIf anything I am tempted to close the loophole we have.  \nif you want to have mutable arguments, then I suggest you use your own \"context\" object that contains a mutable map.  Your data fetchers would use that say.  You can have what ever extra name remapping you like from that.. In short answer to the question - can it be changed - and we say no.\nThere is now a PR to make this immutable and firm up the contract.\n. http://facebook.github.io/graphql/draft/#sec-Validation.Directives\n```\nDirectives Are Unique Per Location\nFormal Specification\nFor every location in the document for which Directives can apply:\nLet directives be the set of Directives which apply to location.\nFor each directive in directives:\nLet directiveName be the name of directive.\nLet namedDirectives be the set of all Directives named directiveName in directives.\nnamedDirectives must be a set of one.\nExplanatory Text\nDirectives are used to describe some metadata or behavioral change on the definition they apply to. When more than one directive of the same name is used, the expected metadata or behavior becomes ambiguous, therefore only one of each directive is allowed per location.\nFor example, the following query will not pass validation because @skip has been used twice for the same field:\nquery ($foo: Boolean = true, $bar: Boolean = false) {\n  field @skip(if: $foo) @skip(if: $bar)\n}\n```\nIts pretty clear they should be unique per location.  Thats why we did it. Remember that each data loader is by default a cache\nSo it should probably be the following\n`\n@Bean\n    Instrumentation dataloaderInstrumentation() {\n            return new DataLoaderDispatcherInstrumentation(\n                  ()->new DataLoaderRegistry().register(\"characters\", new CharactersDataLoader())\n            );\n    }. I am tempted but I am going to say no.\nI appreciate that is a nice short cut however the reason I am against it are as follows\n\nit adds to the already large surface area of DataFetchingEnvironment\nit hides the other functionality that is in DataSelectionSet\nit breaks the encapsulation of duties, where two classes do the same thing (via proxy calls)\n\nI am tempted to make it easier but I dont think its enough code value in other regards. > If we deprecate ExecutorServiceExecutionStrategy, how could we handle two API queries parallel?\nThe new versions of Graphql use CompletableFuture results and they combine them.\nSo imagine we have two data fetchers (psudeo code in lambda syntax)\nDataFetcher firstCall = env -> CompleteableFuture.supplyAsync(() -> serviceLayer.makeCall1(env));\n\nDataFetcher secondCall = env -> CompletableFuture.supplyAsync(() -> serviceLayer.makeCall2(env));\n\nEach of these fetches is now and async call and CompletableFuture will delegate them to a standard ForkJoin scheduler in Java.   You can use your own scheduler if you want.  They WILL happen in parallel and be combined by graphql java\nIn essence we no longer need the old ExecutorServiceExecutionStrategy which did the same thing but was invented in Java before CompletableFuture\n   . Rather we will do a PR per upstream stable fix. This is not a known problem.  if you can get a test reproduction that would be perfect\nPerhaps @andimarek  we should just log and not throw exception??. I think @kdlan is onto the right approach here. Rather than trying to use a small scoped synchronized call, I think we have to make the sync on the state object.  That is the common view that is being examined in order to decide if we want to dispatch or not\nAlso remember we have to do it on read and write (not just write). I took this branch and made some changes I was not able to push it back to the originating repo.\nSo I made my own branch and created a new PR at #1191 \nI think it's a more targeted fix than  this one.  Its more in line with what @kdlan  has suggested. Closed this one as its covered in  #1191. done. Sounds like a good idea to have more useful error messages. done. Even if he has misconfigured his schema but putting an GraphqlObjectType  in play we still need to double check that graphql-java does indeed allow circular Input objects, which in java are only possible via a TypeRef style indirection layer (unlike JS)\nSee https://github.com/facebook/graphql/issues/189 and https://github.com/graphql/graphql-js/pull/1359\nI think we should double check that you can in fact do the following in graphql-java\n input Something {\n       name : String\n       otherThing : Something\n }\n\n. Ok I have double check that GraphqlTypeReferences can be used with input object types and yes they can.  I proved it with the above self referential type.\nI suspect the original report has a mix of output object types in his input objects types which is not allowed in graphql. Sounds fair enough to be honest. Made a PR for this.  Thanks for reporting this with code references and making it so easy to fix.. Ahh I didn't see that you had made a PR.  Sorry about the duplicate work.  I will go with mine since it has a test as well for regression reasons.\nThanks once again for the PR though. See #1189\n. Sorry this project is for the base graphql library.  You will want to ask in https://github.com/graphql-java/graphql-java-servlet. So nominally the spec of graphql outlines that the returned results MUST be held in memory before being released.  One reason is that of parent null ness.  If a non null child field turned out to be null then the previous parent result (according to the spec) should be made null (and that applies all the way back up the tree).\nThis would be impossible in a streamed version.  However one could imagine that a streaming consumer would be happy to relax this aspect.\nThere are some extensions in graphql that allows partial results, although technically not pure streaming.\nThere is a @defer directive you can use in queries\nhttps://graphql-java.readthedocs.io/en/latest/defer.html\nquery {\n   post {\n       postText\n       comments @defer {\n           commentText\n       }\n       reviews @defer {\n           reviewText {\n       }\n}\nThis will send back the postText first (complete not streamed) and then the comments down next and then the reviews.\nThis allows you to progressively get the most important results first and then other ones.  Again its not streaming but its trying to allow partial and early results\nThere is also a PR up from someone in the community that wants to do quasi streamed lists.\nhttps://github.com/graphql-java/graphql-java/pull/1157\nIts a form of sending partial results and nominally could be streamed.   But you can read me concerns on that PR.\nSo in summary, graphql-java does not allow stream of results, namely to be spec compliant and partly because we haven't built it like that.\nIt would be possible to write your own StreamingExecutionStrategy say if you really wanted to and preserve much of the query parsing and API.  But it would be its own implementation.\n. This issue got me thinking some more on this.  And I put up a PR as a early proof of concept\nI am not sure we want to include this but its shows that it is possible.\nThis PR has no tests, is not battle test and so on.  But it proves some aspects of the idea.\nOne the challenges of this is being a consumer and trying to get portions of this and understand them incrementally.. https://github.com/graphql-java/graphql-java/pull/1204. Can you please give a more concrete example of the type of fetchers you are doing that require multiple data loaders.\nPsudeo java code is ok\nThe data loader instrumentation code watches fields fetches not data loader calls.  So off hand I would expect that given fieldX if its data fetcher called 2 data loaders it would not care that 2 calls are made\nOr are you chaining them?? where the results of dataloader A feeds into a new dataloader B?\n. Thanks for outlining more in detail.\nOne of the challenges we have today in Java is knowing when to dispatch the data loaders.  Today we track fields and levels and dispatch once we have exhausted all fields.\nHowever with chained data loaders, we will kick it off but we will not know when to dispatch again since we don't see the chaining in place\nThis is not a problem in JavaScript because they have a tick loop and it fires when node.js has not more work to do.  Hence they hooked data loader into it\nYou could manually call dataLoaderRegistry.dispatch() inside chained calls but the it would be TOO eager I think.\n. You can chain data loaders BUT you cant do it with ULTIMATE efficiency\ngraphql-java tracks fields and hence how many dataLoader.dispatch() calls it needs to make\nif it does it too much then it will not be as efficient as it could be - if it does it too little the threads will block on promise that will never finished\nYou could do this\nDataFetcher df  = env -> {\n        CompletableFuture cf = firstDataLoader.load(env.getArgument(\"id\")):\n       cf.thenApply( resultFromFirst -> secondDataLoader.load(resultFromFirst.otherId();\n           // important step next\n          secondDataLoader.dispatch();\n));\nThe graphql field tracking will cause the first data loader to dispatch() while the second needs manual calling since graphql did not know that a chain CF was in play\nThis might mean you dispatch some other fields too early and hence less optimally\nIts not optimal but it is possible.\n    . Yikes... That seems bad... We will look ASAP\n\nOn Wed., 5 Sep. 2018, 04:44 vojtechmasa, notifications@github.com wrote:\n\nAny query containing __typename introspection field throws the following\nexception:\njava.lang.IllegalStateException: introspection field __typename doesn't have a fields container\nat graphql.analysis.QueryVisitorFieldEnvironmentImpl.getFieldsContainer(QueryVisitorFieldEnvironmentImpl.java:76) ~[graphql-java-10.0.jar!/:na]\nat graphql.analysis.MaxQueryComplexityInstrumentation.convertEnv(MaxQueryComplexityInstrumentation.java:111) ~[graphql-java-10.0.jar!/:na]\nat graphql.analysis.MaxQueryComplexityInstrumentation.calculateComplexity(MaxQueryComplexityInstrumentation.java:99) ~[graphql-java-10.0.jar!/:na]\nat graphql.analysis.MaxQueryComplexityInstrumentation.access$000(MaxQueryComplexityInstrumentation.java:22) ~[graphql-java-10.0.jar!/:na]\nat graphql.analysis.MaxQueryComplexityInstrumentation$1.visitField(MaxQueryComplexityInstrumentation.java:65) ~[graphql-java-10.0.jar!/:na]\nat graphql.analysis.QueryTraversal$NodeVisitorImpl.visitField(QueryTraversal.java:271) ~[graphql-java-10.0.jar!/:na]\nat graphql.language.Field.accept(Field.java:165) ~[graphql-java-10.0.jar!/:na]\nat graphql.language.NodeTraverser$1.leave(NodeTraverser.java:72) ~[graphql-java-10.0.jar!/:na]\nat graphql.util.Traverser.traverse(Traverser.java:83) ~[graphql-java-10.0.jar!/:na]\nat graphql.language.NodeTraverser.doTraverse(NodeTraverser.java:151) ~[graphql-java-10.0.jar!/:na]\nat graphql.language.NodeTraverser.depthFirst(NodeTraverser.java:76) ~[graphql-java-10.0.jar!/:na]\nat graphql.analysis.QueryTraversal.visitImpl(QueryTraversal.java:178) ~[graphql-java-10.0.jar!/:na]\nat graphql.analysis.QueryTraversal.visitPostOrder(QueryTraversal.java:96) ~[graphql-java-10.0.jar!/:na]\nat graphql.analysis.MaxQueryComplexityInstrumentation.lambda$beginValidation$1(MaxQueryComplexityInstrumentation.java:58) ~[graphql-java-10.0.jar!/:na]\nat graphql.execution.instrumentation.SimpleInstrumentationContext.onCompleted(SimpleInstrumentationContext.java:37) ~[graphql-java-10.0.jar!/:na]\nat graphql.execution.instrumentation.ChainedInstrumentation$ChainedInstrumentationContext.lambda$onCompleted$1(ChainedInstrumentation.java:237) ~[graphql-java-10.0.jar!/:na]\nat java.base/java.util.ArrayList.forEach(ArrayList.java:1378) ~[na:na]\nat java.base/java.util.Collections$UnmodifiableCollection.forEach(Collections.java:1081) ~[na:na]\nat graphql.execution.instrumentation.ChainedInstrumentation$ChainedInstrumentationContext.onCompleted(ChainedInstrumentation.java:237) ~[graphql-java-10.0.jar!/:na]\nat graphql.GraphQL.validate(GraphQL.java:541) ~[graphql-java-10.0.jar!/:na]\nat graphql.GraphQL.parseAndValidate(GraphQL.java:509) ~[graphql-java-10.0.jar!/:na]\nat graphql.GraphQL.lambda$parseValidateAndExecute$3(GraphQL.java:490) ~[graphql-java-10.0.jar!/:na]\nat graphql.execution.preparsed.NoOpPreparsedDocumentProvider.get(NoOpPreparsedDocumentProvider.java:11) ~[graphql-java-10.0.jar!/:na]\nat graphql.GraphQL.parseValidateAndExecute(GraphQL.java:486) ~[graphql-java-10.0.jar!/:na]\nat graphql.GraphQL.executeAsync(GraphQL.java:470) ~[graphql-java-10.0.jar!/:na]\nat graphql.GraphQL.execute(GraphQL.java:401) ~[graphql-java-10.0.jar!/:na]\nat graphql.GraphQL.execute(GraphQL.java:371) ~[graphql-java-10.0.jar!/:na]\nSpecifically, my query looks similarly like {payment(id: 152)\n{specificSymbol __typename}}.\nThis query works without problem in version 9.3.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/1200, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSSfGBCfQV4BgTfCOHKX5k9xv44u-ks5uXsn6gaJpZM4WZiPr\n.\n. Yup replicated it via unit test - will look into why this is happening.  Expect a 10.1 soon enough I think. @andimarek  - you added new code as part of your query traversal refactor\n\n@Override\n    public GraphQLFieldsContainer getFieldsContainer() {\n        if (isTypeNameIntrospectionField()) {\n            throw new IllegalStateException(\"introspection field __typename doesn't have a fields container\");\n        }\n        return unmodifiedParentType;\n    }\nWhich is explcitly asserting that _typename can be used during query traversal?  Not sure why??\n. ```\n            boolean isTypeNameIntrospectionField = fieldDefinition == Introspection.TypeNameMetaFieldDef;\n            GraphQLFieldsContainer fieldsContainer = !isTypeNameIntrospectionField ? (GraphQLFieldsContainer) unwrapAll(parentEnv.getOutputType()) : null;\n            Map argumentValues = valuesResolver.getArgumentValues(schema.getFieldVisibility(), fieldDefinition.getArguments(), field.getArguments(), variables);\n            QueryVisitorFieldEnvironment environment = new QueryVisitorFieldEnvironmentImpl(isTypeNameIntrospectionField,\n                    field,\n                    fieldDefinition,\n                    parentEnv.getOutputType(),\n                    fieldsContainer,\n                    parentEnv.getEnvironment(),\n                    argumentValues,\n                    parentEnv.getSelectionSetContainer());\n```. You can create your own directives not by hand by using DSL directives and Directive wiring\nWe wrote a document on this but it seems to have missed in the page tree.  We are fixing that now.\nSo to address this issue right now, here is the document repeat in this issue\nAdding Behaviour\nSchema Definition Language (SDL) allows you to define your graphql types in a declarative manner without using code. However you still need to wire in all the logic that backs those types and their fields.\nSchema directives allow you to do this. You can place directives on SDL elements and then write the backing logic once and have it apply in many places.\nThis idea of \u201cwriting it once\u201d is the key concept here. There is only code place where logic needs to be written and it is then applied to all the places in the SDL that have a named directive.\nThis is a more powerful model than wiring in 10-100s of data fetchers like you might with the conventional runtime wiring.\nFor example imagine you have a type like the following\ntype Employee\n    id : ID\n    name : String!\n    startDate : String!\n    salary : Float\n}\nPublishing salary information to every one who can see this employee\u2019s name might not be want you want. Rather you want some sort of access control to be in place such that if your role is that of a manager, you can see salaries, otherwise you get no data back.\nDirectives can help you declare this more easily. Our declaration above would become something like the following:\n```\ndirective @auth(role : String!) on FIELD_DEFINITION\ntype Employee\n    id : ID\n    name : String!\n    startDate : String!\n    salary : Float @auth(role : \"manager\")\n}\n```\nSo we have said that only people who have the role manager are authorised to see this field. We can now use this directive on ANY field that needs manager role authorisation.\n```\ndirective @auth(role : String!) on FIELD_DEFINITION\ntype Employee\n    id : ID\n    name : String!\n    startDate : String!\n    salary : Float @auth(role : \"manager\")\n}\ntype Department {\n    id : ID\n    name : String\n    yearlyOperatingBudget : Float @auth(role : \"manager\")\n    monthlyMarketingBudget : Float @auth(role : \"manager\")\n}\n```\nWe now need to wire in the code that can handle any field with this @auth directive. We use graphql.schema.idl.SchemaDirectiveWiring to do this.\n```\nclass AuthorisationDirective implements SchemaDirectiveWiring {\n@Override\npublic GraphQLFieldDefinition onField(SchemaDirectiveWiringEnvironment<GraphQLFieldDefinition> schemaDirectiveWiringEnv) {\n    String targetAuthRole = (String) schemaDirectiveWiringEnv.getDirective().getArgument(\"role\").getValue();\n\n    GraphQLFieldDefinition field = schemaDirectiveWiringEnv.getElement();\n    //\n    // build a data fetcher that first checks authorisation roles before then calling the original data fetcher\n    //\n    DataFetcher originalDataFetcher = field.getDataFetcher();\n    DataFetcher authDataFetcher = new DataFetcher() {\n        @Override\n        public Object get(DataFetchingEnvironment dataFetchingEnvironment) {\n            Map<String, Object> contextMap = dataFetchingEnvironment.getContext();\n            AuthorisationCtx authContext = (AuthorisationCtx) contextMap.get(\"authContext\");\n\n            if (authContext.hasRole(targetAuthRole)) {\n                return originalDataFetcher.get(dataFetchingEnvironment);\n            } else {\n                return null;\n            }\n        }\n    };\n    //\n    // now change the field definition to have the new authorising data fetcher\n    return field.transform(builder -> builder.dataFetcher(authDataFetcher));\n}\n\n}\n//\n// we wire this into the runtime by directive name\n//\nRuntimeWiring.newRuntimeWiring()\n        .directive(\"auth\", new AuthorisationDirective())\n        .build();\n```\nThis has modified the GraphQLFieldDefinition so that its original data fetcher will ONLY be called if the current authorisation context has the manager role. Exactly what mechanisms you use for authorisation is up to you. You could use Spring Security for example say, graphql-java doesnt really care.\nYou would provide this authorisation checker into the execution \u201ccontext\u201d object of the graphql input so it can then be accessed later in the DataFetchingEnvironment.\n```\nAuthorisationCtx authCtx = AuthorisationCtx.obtain();\nExecutionInput executionInput = ExecutionInput.newExecutionInput()\n        .query(query)\n        .context(authCtx)\n        .build();\n```\nDeclaring Directives\nIn order to use a directive in SDL, the graphql specification requires that you MUST declare its shape before using it. Our @auth directive example above needs to be declared like so before use.\n```\nThis is a directive declaration\ndirective @auth(role : String!) on FIELD_DEFINITION\ntype Employee\n    id : ID\n# and this is a usage of that declared directive\nsalary : Float @auth(role : \"manager\")\n\n}\n```\nThe one exception to this is the @deprecated directive which is implicitly declared for you as follows :\ndirective @deprecated(  reason: String = \"No longer supported\") on FIELD_DEFINITION | ENUM_VALUE\nThe valid SDL directive locations are as follows :\nSCHEMA,\nSCALAR,\nOBJECT,\nFIELD_DEFINITION,\nARGUMENT_DEFINITION,\nINTERFACE,\nUNION,\nENUM,\nENUM_VALUE,\nINPUT_OBJECT,\nINPUT_FIELD_DEFINITION\nDirectives are commonly applied to fields definitions but as you can see there are a number of places they can be applied.\nAnother Example - Date Formatting\nDate formatting is a cross cutting concern that we should only have to write once and apply it in many areas.\nThe following demonstrates an example schema directive that can apply date formatting to fields that are LocaleDate objects.\nWhats great in this example is that it adds an extra format argument to each field that it is applied to. So the clients can opt into what ever date formatting you provide per request.\n```\ndirective @dateFormat on FIELD_DEFINITION\ntype Query {\n    dateField : String @dateFormat\n}\n```\nThen our runtime code could be :\n```\npublic static class DateFormatting implements SchemaDirectiveWiring {\n    @Override\n    public GraphQLFieldDefinition onField(SchemaDirectiveWiringEnvironment environment) {\n        GraphQLFieldDefinition field = environment.getElement();\n        //\n        // DataFetcherFactories.wrapDataFetcher is a helper to wrap data fetchers so that CompletionStage is handled correctly\n        // along with POJOs\n        //\n        DataFetcher dataFetcher = DataFetcherFactories.wrapDataFetcher(field.getDataFetcher(), ((dataFetchingEnvironment, value) -> {\n            DateTimeFormatter dateTimeFormatter = buildFormatter(dataFetchingEnvironment.getArgument(\"format\"));\n            if (value instanceof LocalDateTime) {\n                return dateTimeFormatter.format((LocalDateTime) value);\n            }\n            return value;\n        }));\n    //\n    // This will extend the field by adding a new \"format\" argument to it for the date formatting\n    // which allows clients to opt into that as well as wrapping the base data fetcher so it\n    // performs the formatting over top of the base values.\n    //\n    return field.transform(builder -> builder\n            .argument(GraphQLArgument\n                    .newArgument()\n                    .name(\"format\")\n                    .type(Scalars.GraphQLString)\n                    .defaultValue(\"dd-MM-YYYY\")\n            )\n            .dataFetcher(dataFetcher)\n    );\n}\n\nprivate DateTimeFormatter buildFormatter(String format) {\n    String dtFormat = format != null ? format : \"dd-MM-YYYY\";\n    return DateTimeFormatter.ofPattern(dtFormat);\n}\n\n}\nstatic GraphQLSchema buildSchema() {\nString sdlSpec = \"\" +\n        \"type Query {\\n\" +\n        \"    dateField : String @dateFormat \\n\" +\n        \"}\";\n\nTypeDefinitionRegistry registry = new SchemaParser().parse(sdlSpec);\n\nRuntimeWiring runtimeWiring = RuntimeWiring.newRuntimeWiring()\n        .directive(\"dateFormat\", new DateFormatting())\n        .build();\n\nreturn new SchemaGenerator().makeExecutableSchema(registry, runtimeWiring);\n\n}\npublic static void main(String[] args) {\n    GraphQLSchema schema = buildSchema();\n    GraphQL graphql = GraphQL.newGraphQL(schema).build();\nMap<String, Object> root = new HashMap<>();\nroot.put(\"dateField\", LocalDateTime.of(1969, 10, 8, 0, 0));\n\nString query = \"\" +\n        \"query {\\n\" +\n        \"    default : dateField \\n\" +\n        \"    usa : dateField(format : \\\"MM-dd-YYYY\\\") \\n\" +\n        \"}\";\n\nExecutionInput executionInput = ExecutionInput.newExecutionInput()\n        .root(root)\n        .query(query)\n        .build();\n\nExecutionResult executionResult = graphql.execute(executionInput);\nMap<String, Object> data = executionResult.getData();\n\n// data['default'] == '08-10-1969'\n// data['usa'] == '10-08-1969'\n\n}\n```\nNotice the SDL definition did not have a format argument yet once the directive wiring is applied, it is added to the field definition and hence clients can begin to use it.\nPlease note that graphql-java does not ship with this implementation. It is merely provided here as an example of what you could add yourself.\nChaining Behaviour\nThe directives are applied in the order they are encountered. For example imagine directives that changed the case of a field value.\n```\ndirective @uppercase on FIELD_DEFINITION\ndirective @lowercase on FIELD_DEFINITION\ndirective @mixedcase on FIELD_DEFINITION\ndirective @reversed on FIELD_DEFINITION\ntype Query {\n    lowerCaseValue : String @uppercase\n    upperCaseValue : String @lowercase\n    mixedCaseValue : String @mixedcase\n#\n# directives are applied in order hence this will be lower, then upper, then mixed then reversed\n#\nallTogetherNow : String @lowercase @uppercase @mixedcase @reversed\n\n}\n```\nWhen the above was executed each directive would be applied one on top of the other. Each directive implementation should be careful to preserve the previous data fetcher to retain behaviour (unless of course you mean to throw it away). Fixed : https://graphql-java.readthedocs.io/en/latest/sdldirectives.html. https://github.com/graphql-java/graphql-java/pull/1205 this identical PR was merged.  Closing this one.\nThanks for the PR. Thanks for that PR. >  Does this mean type collection/reference replacement isn't even supposed to work on directives, or are they sort of \"second class citizens\" on purpose?\nIt's not on purpose but the directives were definitely built out later in the project lifecycle.\nI can see now how it needs to be a GraphqlType in order to be visited by Traverser code.\n@andimarek - what are you thoughts on this.\nGraphQLDirective can be made a GraphQLType in the same way that GraphQLFieldDefinition is a type and yet is not really a type in the true sense.\n. @gipeshka  - I changed the title of this issue to better reflect the idea behind this.  I also wanted to explore some thoughts on your ideas and also further ideas on validating and transforming graphql data. One of the capabilities missing in graphql-java (and perhaps graphql spec itself) is the ability\nto perform deeper validation of input.\nA greater validation system would ideally have the following aspects\n\nThe ability to run before the execution of the query fields happens\nThe ability for SDL directives to be specified indicating extensible validation\nThe ability for a pluggable \"aspect\" code to be created that interprets those directives and injects runtime behaviour\nIt should not require a Instrumentation to be added in order to get this happening (or if it does it should be automatic)\n\nThere is design challenge about where these validation hooks should live.\nFor example imagine SDL like the following\n```\ntype Query {\n    searchPages(criteria : SearchCriteria!, first : Int, after : String, last : Int, before : String) : Results\n    searchComments(criteria : SearchCriteria!, first : Int, after : String, last : Int, before : String) : Results\n}\ninput SearchCriteria {\n    complexFilter : String\n    simpleFilter : String\n    orderBy : String\n}\n```\nNow imagine that \n the SearchCriteria.complexFilter field has a certain SQL like syntax, that the SearchCriteria.simpleFilter has a different syntax\n the SearchCriteria.orderByfield is a comma seperated list of columns.\n* you can have acomplexFilteror asimpleFilterbut not both and you MUST have one of the other\n* thatfirst / afterarguments must be specified OR thelast / after` fields must be specified but not both (relay style)\nWhere would the validation hooks live for such a system?\nToday the only code hook place is the DataFetcher attached to the field.  But this is run ONLY during field execution\nand not before in a query validation stage.\nThe SearchCriteria input type validation rules are common across all fields that use it (in this case) and hence\nits validation could be hooked to it versus the fields that might use it.\nThe field arguments around first/after or last/before would belong to the field.  But is it a DataFetchingException that indicates this or could it be a pre field validation? This concern is more about the \"name\" of the error that results in the output.  Is it a validation error or is it a execution error?  I think its the former\n. So imagine we try to start using directives to enforce some of these validations.  I have thrown in some more example types\nAlso please dont concentrate on the syntax of the directives.  They are illustrative only not proposed synaxt\nin any way\n```\ntype Query {\nsearchPages(criteria : SearchCrieria!, first : Int, after : String, last : Int, before : String) \n    : Results @Validator(className:\"com.package.RelayParamValidation\")\n\nsearchComments(criteria : SearchCrieria!, first : Int, after : String, last : Int, before : String) \n    : Results @Validator(className:\"com.package.RelayParamValidation\")\n\n}\ntype Mutation {\nwalkIntoABar( visitor : BarVisitor) : BarDetails\n\npartyWalksIntoABar( visitors : [BarVisitor]) : BarDetails\n\n}\ninput SearchCriteria {\n    complexFilter : String\n    simpleFilter : String\n    orderBy : String\n}\ninput BarVisitor {\nage : Int  @Max(value : 18)\n\ndollarsInWallet : Float @Min(value : 1)\n\nwearingShoes  : Boolean @AssertTrue\n\n}\n```\nToday we have a interface called graphql.schema.idl.SchemaDirectiveWiring that is called back on every directivesas it \nis encountered.  So we have the SDL hooks to know about directives.\nHowever where such a SchemaDirectiveWiring would put the code behind the directive is the real question I mention\nabove.\nLets consider BarVisitor fo the moment.  One can assume that ANY time a BarVisitor is input to the system it should\nfollow these validation directives.  But what about lists.  Would be handle this implicitly that all members\nof the list are to be validated.  I am guessing yes.\nIf I do this query \n```\n   query {\n      oldGuy: walksIntoABar(visitor : {age : 25, dollarsInWallet : 100.0, wearingShoes : true})\n  teenager : walksIntoABar(visitor : {age : 14, dollarsInWallet : 0.0, wearingShoes : true})\n\n}\n```\nThen does the whole query fail or does the oldGuy field (that is valid) complete as expected.  \nOr is this a choice an implementation choose to make some how?\n. One good question is where to  put the code for input validation.  If we copied the previous pattern we would attach it to each field of the Input object like we do on GraphqlFieldDefinitions.\nBut this is insufficient.  For example a field like mutation { someObject(String input) has only a scalar type so putting code on the input object itself is no good.\nLooking at the examples above we have\n\nvalidation associated with a specific query / mutation field\nvalidiation associated with specific input object fields  regardless of query field\nvalidation potentially associated with the input object itself (for all its fields say)\n\nSo it seems we need a registry that can take a named \"node\" and associate a validation bit of code with it.  Those nodes could be \"query fields (and hence their arguments)\" , \"input object fields\" or \"input objects\" as a whole.\nThis starts to beg the question of having a SchemaExecutionRegistry that contains validation (by field/type name) and potentially later the \"data fetchers\" we have today again associated by field name.\nThis SchemaExecutionRegistry  is probably a peer top the GraphqlSchema or at least a top level object inside the schema (since today you get the schema to get data fetchers).. What are you thoughts on validation as opposed value transformation\neg in your issue you mention\ninput ConsumerData {\n    name: String @length(min: 1, max: 20)\n}\n\nHow would you expect that interaction to happen?\nWhen we did the directives work on output types via graphql.schema.idl.SchemaDirectiveWiring then we had \"code attached\" to the fields via the DataFetchers.\nI personally see how we would need another \"code place\" to be able to wiring in \"behaviour\" to  input types, both for validation and changing values\nI could see your DataTransformer interface being more like\n```\ninterface InputFieldBehaviour {\n     void validate(InputFieldValidationEnvironment envYouNeedToValidateIn);\n  default Object transformValue(Object startingValue) {\n      return startingValue;\n }\n\n```\nWhat this means for \"graphql.execution.instrumentation.fieldvalidation.FieldValidationInstrumentation\" though is interesting.. Yeah I dont mind what you have outlined above althought I still feel more explicit named methods is better.  That is a bit of code that intercepts input objects can do both validation and transformation via well named methods rather than just a method called \"apply\".  \nThe other thing that is nagging me on \"directives on input types\" scalar arguments to fields.  Imagine we have this\n```\ntype Query {\n     searchStories(containsText : String @length(min: 1, max: 20)) : [Story]\n}\ntype Mutation {\n      makeComment( ID : storyID, commentText : String @length(min: 5, max: 20) @uppercase) : Story\n}\n```\nThe validation / transformations here are not on an GraphQLInputObjectField but rather on an argument to a GraphQLFieldDefinition.  So which object holds the \"code\" here.   It could be the graphql.schema.GraphQLArgument that the GraphQLFieldDefinition contains.\nBut equally it could be the GraphQLFieldDefinition itself since it has access to all its arguments.  \nWhat we are missing today of course (as your PR tries to address) is the \"code hooks\" where these validations / transformations would take place.  I don't think it should be left to the data fetchers since this is both too late and too complex (breaks single responsibility - data fetchers already do too much)\nHmmmm.  Food for thought\n. We will be attacking this problem using the new code registry via\nhttps://github.com/graphql-java/graphql-java/pull/1321. Thanks for this.  This will be a powerful capability over time.  Out directive journey is really just beginning and hence we need to make them more first class.  \nThis is great PR.  Once you have the test I want to merge it.\n\ud83d\udc4d \ud83d\udcaf . yeah that seems wrong.  Looks like place holder text in the code that did not get replaced.. OK I think the problem you have is that scalars are created as singletons by your code and wired into the SDL.\nI wrote the following groovy test \n```\n        def spec = '''\n            scalar MyMap\n    type Query {\n        something(id: String!): MyMap\n    }\n    '''\n\n    def mapCoercing = new Coercing<Object,Object>() {\n        @Override\n        Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n            return null\n        }\n\n        @Override\n        Object parseValue(Object input) throws CoercingParseValueException {\n            return null\n        }\n\n        @Override\n        Object parseLiteral(Object input) throws CoercingParseLiteralException {\n            return null\n        }\n    }\n\n    def runtimeWiring = RuntimeWiring.newRuntimeWiring().scalar(new GraphQLScalarType(\"MyMap\", \"The description in code\", mapCoercing)).build()\n    def graphQL = GraphQL.newGraphQL(TestUtil.schema(spec,runtimeWiring)).build()\n    when:\n    def executionResult = graphQL.execute(IntrospectionQuery.INTROSPECTION_QUERY)\n    then:\n    executionResult.data != null\n    println JsonOutput.prettyPrint(JsonOutput.toJson(executionResult.data))\n\n```\nand its produced\n{\n                \"kind\": \"SCALAR\",\n                \"name\": \"MyMap\",\n                \"description\": \"The description in code\",\n                \"fields\": null,\n                \"inputFields\": null,\n                \"interfaces\": null,\n                \"enumValues\": null,\n                \"possibleTypes\": null\n            },\nThe description comes from the GraphqlScalar implementation.  I suspect this is something  in your code base\nI searched out code base for \"desc\" as a string and can't find it so I dont think its graphql-java. Hmmm I think this should be fixed @andimarek - the whole idea of a type reference is re-use and indirection.\nI will see what we can do to fix this. I suspect this might be fixed on master.  I tried this repoduction from the above and it works without error\n```\n    def \"the same reference can be used multiple times\"() {\n        when:\n        GraphQLTypeReference ref = new GraphQLTypeReference(\"String\");\n        def inputObject = GraphQLInputObjectType.newInputObject()\n                .name(\"ObjInput\")\n                .field(GraphQLInputObjectField.newInputObjectField()\n                .name(\"value\")\n                .type(ref)) //Will get replaced, as expected\n                .field(GraphQLInputObjectField.newInputObjectField()\n                .name(\"value2\")\n                .type(ref)) //Will not get replaced the 2nd time it's used\n                .build()\n    GraphQLSchema schema = GraphQLSchema.newSchema()\n            .query(GraphQLObjectType.newObject()\n            .name(\"Query\")\n            .field(GraphQLFieldDefinition.newFieldDefinition()\n            .name(\"test\")\n            .type(Scalars.GraphQLString)\n            .dataFetcher({ env -> \"test\" })\n            .argument(GraphQLArgument.newArgument()\n            .name(\"in\")\n            .type(inputObject))\n    )).build()\n\n    then:\n    schema != null\n\n```\nIt gets replaced as expected.  Is there another case where this might be different.??\nI will contribute this test as future protection against regression (since we have done it once apparently). I am going to close this as we have proof its working as expected. @kaqqao provided a test that proves this is still not working in all cases. graphql-java does not deal with JSON at all.  You need to use another library like Jackson or GSON to turn the data into a JSON representation.\nExecutionResult executionResult = graphql.execute(...);\n   ObjectMapper jacksonMapper = new ObjectMapper();\n   jackonMapper.writeValue(new File(\"target/data.json\"), executionResult);\nThis is done on purpose so that consumers are free to produce JSON as they see fit AND also graphql could also be used to server other wire protocols like YAML or XML if you chose.\n. graphql does not do \"pass through JSON\" per say\nso in your code here\n // remote HTTP response json data like : {person: {name: \"\", age: 20}}\n return JsonObject.mapTo(data);\n\nwhat is the data element.  If its a java Map, then leave it as one since graphql-java understands maps can treat them as first class data elements.  It does not understand JsonObject what ever that is.. If you need pageInfo data in your returned data then you MUST have it in the query and you MUST have it in your underlying schema.\nquery { \n    contact { id,name } \n    pageInfo { total }\n }\n\nin graphql, the data you get back is ALWAYS described by the query. I am guessing it is failing on the expected \"batch\" calls and not the expected data?\nI would expect that test to pass on the number of batch calls for optimal efficienciency . Thanks for reporting this.\nCould you help us out and make a PR here please. @kaqqao - this will help any efforts in regard to https://github.com/graphql-java/graphql-java/issues/1211 - eg better input validation.. Ahh sorry about the comments - didnt see the WIP bit. This is not longer needed and has been re-implemented via #395 .     { \n         contact { \n             id,name \n         }   \n    }\nIn SDL your original query probably matched a a schema like\n```\n    type Query {\n          contact : Contact\n     }\ntype Contact {\n      id : ID\n      name : String\n }\n\n```\nSo to have a query like\n{ \n       contact { \n           fields { \n                id,name \n            } \n        } \n     }\nYou would need a schema like\n```\n    type Query {\n          contact : Contact\n     }\n type Contact {\n     fields : Fields\n }\n\ntype Fields {\n      id : ID\n      name: String\n }\n\n```\nExtra levels are extra types in the schema\n. Closing this issue. @tinnou \nYou can supply the dataloaderRegistry now via  a supplier\nDataLoaderDispatcherInstrumentation dispatcherInstrumentation\n        = new DataLoaderDispatcherInstrumentation(() -> new DataLoaderRegistry(...));\nThis will be called per request.\n. I have created https://github.com/graphql-java/graphql-java/issues/1254 to capture the improvement in the lifecycle to dataloaders. The challenge is that for most people DataLoaders should be per request, but for some it does not matter so its not possible to  have a one strategy fits all.  I agree we can do a better job of documenting this. The challenge you are facing with the builder is one of re-use versus composition.  This is a challenge to all builder pattern\nOur builders (as much as we can) have the pattern where the internal members are private but there are a series of public \"setters\" to \"build\" out an object (in this case the schema).  \nNow you are wanting to re-use that state, re-read it (via the public accessors on fields) and then call the builder again to set the state back in.  This is not how our builders are intended to be used.  They are builders, not accessors + builders.\nWe use a xxx.transform( ....) pattern to take a built object and transform it into another one like it.  I suggest you look at that as a way to turn a Foo into a Foo-delta. Thanks for this PR.  We appreviate you taking the time to write it up.\nAs it is written today its a bit too opinonated in its tone as general purpose documentation.\nBut we will take it as the basis for a rewrite and re-use your examples to help explain the lifecycle of data loaders that are request bound.\n. Sorry but this is a design goal of the graphql specification.  graphql has a design goal which is that in order to retrieve a data element, you need to ask for that data element.\nContrast this to say REST where you ask for a resource BUT not which data elements.  And hence the size and shape of the response is a server concern and not a strict contract.\n\nMy only other option would be to define this particular query as just returning JSON, which eliminates all the other advantages of using GraphQL to begin with.\n\nThis is the point.  Graphql is not arbitary JSON blobs but rather JSON responses that represent the query.\n. Also dataFetchingEnvironment.getArguments.put(\"foo\", \"bar\") is no an allowed function\nWe use a copy of the arguments and give that to you.  Pretty standard immutable stuff.\nif you Must have a mutable store then create your own context object that allows that\nfor example\n```\n       Object  get(DataFetcherEnvironment dfe) {\n       MyContext myContext = dfe.getContext();\n\n       myContext.put(\"foo\",\"bar\")\n       ....\n\n```\nYou can then read it later\n. As for global context, thats what the ExecutionInput context is for\nSee\nhttps://github.com/graphql-java/graphql-java-http-example/blob/master/src/main/java/com/graphql/example/http/HttpMain.java#L108. Have a look at ExecutionInput and the \"context\" parameter.\nThis gets passed down on the call and is available in ALL DataFetchingEnvironments\nhttps://github.com/graphql-java/graphql-java-http-example/blob/master/src/main/java/com/graphql/example/http/HttpMain.java#L108. All this can be done.\nI suggest you first read the documentation\nhttps://graphql-java.readthedocs.io/en/latest/\nand perhaps look at a sample app\nhttps://github.com/graphql-java/graphql-java-http-example\nThe code behind a data fetcher is the dynamic bit of graphql. Again have a look at the code in https://github.com/graphql-java/graphql-java-http-example\nIt has all you need. I think the name \"Node\" is wrong.  Just doesnt sit nice.  Node invokes the AST nodes to me.\nAll the \"types\" have GraphqlXXX so I would continue that.\nNaming is hard but\n\nGraphqlSchemaItem\nGraphqlItem\nGraphqlComponent\nGraphqlElement\nGraphqlUnit\n. The method\n\nTraversalControl accept(TraverserContext<GraphQLType> context, GraphQLTypeVisitor visitor);\nis problematic in naming terms.  That is we could change it to be \nTraversalControl accept(TraverserContext<? extends GraphQlSchemaElement > context, GraphQLTypeVisitor visitor);\nbut the visitor is named GraphQLTypeVisitor and that can be changed without making a major breaking change to that SPI\nSo we want to make that change??\n. If you could then that would be great\nOn Sat., 27 Oct. 2018, 19:28 pete-proton, notifications@github.com wrote:\n\nthank you! do I need to reformat still? sorry for the late reply\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/1252#issuecomment-433602060,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSdSYzgKMxcT3DI3gvh7-jxA6PAL1ks5upBk4gaJpZM4XCmAd\n.\n. Your right - it doers not consider default methods on interfaces.  No good reason.  I guess we forgot they can have bodies (it was Java 6.0 code for a long time)\n\nThey do search upwards in the class hierarchy however\n```\n    private Method findPubliclyAccessibleMethod(Class root, String methodName) throws NoSuchMethodException {\n        Class currentClass = root;\n        while (currentClass != null) {\n            String key = mkKey(currentClass, propertyName);\n            Method method = METHOD_CACHE.get(key);\n            if (method != null) {\n                return method;\n            }\n            if (Modifier.isPublic(currentClass.getModifiers())) {\n                method = currentClass.getMethod(methodName);\n                if (Modifier.isPublic(method.getModifiers())) {\n                    METHOD_CACHE.putIfAbsent(key, method);\n                    return method;\n                }\n            }\n            currentClass = currentClass.getSuperclass();\n        }\n        return root.getMethod(methodName);\n    }\n```\n. @mrdon-atlassian \nI set out to fix this but found that it already works\nI created some TDD tests as the basis to start addressing this issue and they pass!\nhttps://github.com/graphql-java/graphql-java/pull/1264\nCan you give me some more examples where default methods on interfaces won't be found?\n. @sleberrigaud - no need for a new issue.  But reproduction steps please.\nA PR of just a test showing it would be great.  We have extensive sets of \"test classes\" already.  Make some new ones say and some new tests howing how you expect it to work.\nWe can work on the actual code to support it say. There was no fix - only more tests.  Anyway I will close this. @tinnou - a DataLoader is also a cache by default SO IF you really want to share data between requests, you could use a new cache implementation (its pluggable) such that it put the data in a shared place (memcache / redis etc..) and hence the key -> value could be shared across requests if need be.\nBut if we create DataLoaders per request, then a dispatch on them ONLY affects this request and not other ones.  Thats what we want to achieve and I think this is better API to show that.\nBefore out API encouraged the sharing of DataLoaders instances and thats not a great thing in practice.. I was able to replicate 100% of the time without the change as per @tinnou original test. > What do you think of such a solution? Is it viable? Do you see any issues of using DataLoader with \"enhanced keys\"?\nI have seen people do this already so its not unknown.  \nOne problem that might arise is that DataLoader are also caches.  The keys passed in are used to cache the data and hence if you have seen that key before, it can returned a cached value.  So for example if somewhere in the graphql tree of results you have already seen a result, a cache hit can return it without invoking the batch loader\nThe key used above is probably not a very good key for caching reasons.  Of course if you are NOT using caching then that does not apply so much\nAlso not that the new 2.1.1 version of data loader supports \"context\" objects on load calls.\nSo\n    dataLoader.load(key, someContextObjectHere)\nSo this may allow you to pass in context objects such as DataFetchingEnvironment say and hence access them into the batch loader.  There is a new BatchLoaderWithContext interface for this\nhttps://github.com/graphql-java/java-dataloader/blob/master/src/main/java/org/dataloader/BatchLoaderWithContext.java\n. You have outlined some pretty good examples and I am not 100% sure just yet how to respond\nLet me talk to my colleagues about what you have presented and let me get back to you. @doxavore - the documentation suggests using BatchLoader functions - but they are not deprecated.  \nThe come from the java-dataloader library which is howe we think people should do batching, that also follows spec.\nEach DataLoader has a \"batch loader function\" like this\n```\nBatchLoader userBatchLoader = new BatchLoader() {\n            @Override\n            public CompletionStage> load(List userIds) {\n                return CompletableFuture.supplyAsync(() -> {\n                    return userManager.loadUsersById(userIds);\n                });\n            }\n        };\n       DataLoader userLoader = DataLoader.newDataLoader(userBatchLoader);\n```\nIt gives you all the batched ids in one call.  You can then use that to put it into SQL say.\nCan you outline your use case more clearly about how you dont think you can achieve your aims using DataLoader (+their associated BatchLoader function)\n. @sp00m \nI had a go at trying to implement the example above using DataLoader\nThe code is in Groovy in Spock unit testing format\nhttps://gist.github.com/bbakerman/2304079e0c87fb198fc348cdb26edf2b\nThe \"keys\" here when we call dataLoader.load(key) are in fact the blogId + textToSearchFor.  The reason for this is that is the unique dimension being searched for. \nSo given data\n```\n    def blogData = [\n            new Blog(id: 1, name: \"Java\", purpose: \"Java stuff\"),\n            new Blog(id: 2, name: \"Reactive\", purpose: \"Rx stuff\")\n    ]\ndef articleData = [\n        new Article(id: 101, blogId: 1, title: \"Changes in the LTR policy of the JDK\"),\n        new Article(id: 102, blogId: 1, title: \"CPU impact of the JVM Memory Model\"),\n\n        new Article(id: 200, blogId: 2, title: \"So you want to use less CPU\"),\n        new Article(id: 201, blogId: 2, title: \"Why reactive systems use less CPU\")\n]\n\n```\nand a query of\nquery {\n          blogs {\n            id\n            name\n            articlesWithCPUInTitle: articles(whereTitleContains: \"CPU\") {\n                blogId\n                title\n            }\n            articlesWithReactiveInTitle: articles(whereTitleContains: \"reactive\") {\n                blogId\n                title\n            }\n          }\n        }\nit returns a result of\n[blogs:\n   [[id:1, name:Java, \n              articlesWithCPUInTitle:[[blogId:1, title:CPU impact of the JVM Memory Model]], \n              articlesWithReactiveInTitle:[]], \n   [id:2, name:Reactive, \n               articlesWithCPUInTitle:[[blogId:2, title:So you want to use less CPU], [blogId:2, title:Why reactive systems use less CPU]], \n                articlesWithReactiveInTitle:[[blogId:2, title:Why reactive systems use less CPU]]]]]\nThis only calls the BatchLoader function once for all blog instances (2) and for each sub field (2 x 2). ps.  I didnt use Foo/Bar but \"CPU / Reactive\" as search terms. I agree this could be made into a tutorial or documentation example. Hang on why did this show everything??. Bad merge??. Looking into it - it is not a graphql-java engine thing.\nIt consists of standard types + the ability to take say MultiPart message objects as input to a scalar \"File\".\nI feel like this is a extended-scalars thing or best left to a code layer that deals with HTTP. No... a fragment can be defined for any type.\nHave  a look at http://graphql.org/learn/. fragment comparisonFields on Character {\n  name\n  appearsIn\n  friends {\n    name\n  }\n}\nIn this example friends is a list AND a compund object type. Bad idea. The reason it does not assert is that the builder (that you used) now uses a map internally and will cause fields to be keyed by name\npublic Builder field(GraphQLFieldDefinition fieldDefinition) {\n            assertNotNull(fieldDefinition, \"fieldDefinition can't be null\");\n            this.fields.put(fieldDefinition.getName(), fieldDefinition);\n            return this;\n        }\nBy the time the constructor runs there is no duplicate.  It has the last field definition.  However in the past we didnt have builders and you could call the constructor directly and hence get it wrong.\nThere is no regression here.  The code is just improved. But thanks for reporting it. > Improved? It ignores a duplicate definition!\nNo it doesnt - its a builder... and it set the value of GraphqlFieldDefintiion into a map based on its name.\nThe reason it allows this (rather than asserting that it already has one) is the transform pattern.\nThis allows you to take an GraphqlObjectType  and transform it into another.  And you might \"replace\" a field that is already defined and in fact that is the most common transformation.\nThe no duplicate fields invariant holds.  There is even old coder in the GraphqlObjectType that doubles checks for duplicate fields.\nSo while you may supplied multiple field definitions under the same name during the \"builder\" phase there is no way to get that situation once you call .build()\n. We could improve the java doc on this I agree. See #1269\n. We need all those attributes in ExectionInfo because as we form the execution tree we need the parent previous values. \nSo really the question is one of easy of use versus duplication.\nIf someone is writing a data fetcher I posit that its easier to write\nDataFetcher df =  environment -> {\n     String cId =  environment.getArgument(\"customerID\")\n     int pgCount =  environment.getArgument(\"pageCount\")\n     return customerService.getCustomer(cID,pgCount);\n}\n\nthen it is to write\nDataFetcher df =  environment -> {\n    String cId =  environment.getExecutionInfo().getArgument(\"customerID\")\n     int pgCount =  environment.getExecutionInfo().getArgument(\"pageCount\")\n     return customerService.getCustomer(cID,pgCount);\n}\n\nI think the arguments should DEFINITELY be duplicated on the DataFetcherEnvironment.  I can see a lesser argument for GraphqlFieldDefinition and I would be happy for Field to drop down into ExecutionInfo only  \n. In your SDL you need to define custom scalars.  Datetime and Cursor are not scalars provided by graphql-java\nYou would need to declare the in SDL AND provide an implementation\n```\nscalar Datetime\ntype SomeType {\n   created : Datetime\n}\n```\nThis is not a bug in graphql-java per se.\nHow are you creating your schema?. Have a look at https://github.com/graphql-java/graphql-java-extended-scalars which has an implemented DateTime scalar\nAlso read the documentation on schemas here about how you wire in that implementation\nhttps://www.graphql-java.com/documentation/v10/schema/. I just wrote a quick unit test on this issue but could not reproduce\n```\npackage graphql\nimport groovy.json.JsonOutput\nimport spock.lang.Specification\nclass Issue1280 extends Specification {\ndef \"reproduce 1280\"() {\n    def spec = '''\n        input Default {\n            value1: Int = 0\n        }\n\n        type Query {\n            field(arg : Default) : String\n        }\n    '''\n\n    def graphQL = TestUtil.graphQL(spec).build()\n\n    when:\n    def executionResult = graphQL.execute('''\n        {\n        __schema {\n            types {\n              kind\n              name\n              inputFields {\n                name\n                defaultValue\n              }\n            }\n          }\n        }\n        ''')\n    then:\n    executionResult.errors.isEmpty()\n    println JsonOutput.prettyPrint(JsonOutput.toJson(executionResult.data))\n}\n\n}\n```\nthis has no errors and the data is as follows\n{\n    \"__schema\": {\n        \"types\": [\n            {\n                \"kind\": \"ENUM\",\n                \"name\": \"__TypeKind\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"OBJECT\",\n                \"name\": \"__Field\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"OBJECT\",\n                \"name\": \"Query\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"OBJECT\",\n                \"name\": \"__Schema\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"OBJECT\",\n                \"name\": \"__Type\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"OBJECT\",\n                \"name\": \"__EnumValue\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"ENUM\",\n                \"name\": \"__DirectiveLocation\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"SCALAR\",\n                \"name\": \"String\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"INPUT_OBJECT\",\n                \"name\": \"Default\",\n                \"inputFields\": [\n                    {\n                        \"name\": \"value1\",\n                        \"defaultValue\": \"0\"\n                    }\n                ]\n            },\n            {\n                \"kind\": \"SCALAR\",\n                \"name\": \"Int\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"OBJECT\",\n                \"name\": \"__InputValue\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"SCALAR\",\n                \"name\": \"Boolean\",\n                \"inputFields\": null\n            },\n            {\n                \"kind\": \"OBJECT\",\n                \"name\": \"__Directive\",\n                \"inputFields\": null\n            }\n        ]\n    }\n}\nSo it would appear to be working at first glance.  Can you outline more reproduction steps please\nThe message \"Expected type 'Int' but was 'IntValue'.\" comes mostly like the from the GraphqlInt scalar  for the record which would seem to indicate the Introspection code getting things wrong on default values.\nBut this seems to be working based on my unit test. I am going to close this for now.  If you find more reproduction steps please re-open it. Of hand without doing any deep investigation I do recall us tightening the fields in fragments being of different types.   Its possible what is intended for interfaces should not apply to unions.\nBut as I said I have not looked into this in detail.\nLet us look at the spec and also the reference implementation.\nThanks for reporting this. Have a look at https://facebook.github.io/graphql/June2018/#sec-Field-Selection-Merging\n\nExplanatory Text\nIf multiple field selections with the same response names are encountered during execution, the field and arguments to execute and the resulting value should be unambiguous. Therefore any two field selections which might both be encountered for the same object are only valid if they are equivalent.\nDuring execution, the simultaneous execution of fields with the same response name is accomplished by MergeSelectionSets() and CollectFields().\nFor simple hand\u2010written GraphQL, this rule is obviously a clear developer error, however nested fragments can make this difficult to detect manually.\n\nI suspect that this is part of the answer here\nLooking at this reference implementation is pretty much has this tests (which @andimarek  ported way back in 2015 originally). Actually thinking more about this.  Rather than logging what if you want to do some other action\nIt could be a Function<Boolean,ComplexityInfo that returns true if the abort exception should be throw say.\nThe use of a function would allow people do do other things like log or call statsd or react in some other manner.\nThe ComplexityInfo here is a builder built object that contains the complexity count.  Passing just int means we cant add more \"parameters\" at  a later time so we prefer wrapper objects with builders. Actually thinking more about this.  Rather than logging what if you want to do some other action\nIt could be a Function<Boolean,ComplexityInfo that returns true if the abort exception should be throw say.\nThe use of a function would allow people do do other things like log or call statsd or react in some other manner.\nThe ComplexityInfo here is a builder built object that contains the complexity count.  Passing just int means we cant add more \"parameters\" at  a later time so we prefer wrapper objects with builders. Actually thinking more about this.  Rather than logging what if you want to do some other action\nIt could be a Function<Boolean,ComplexityInfo that returns true if the abort exception should be throw say.\nThe use of a function would allow people do do other things like log or call statsd or react in some other manner.\nThe ComplexityInfo here is a builder built object that contains the complexity count.  Passing just int means we cant add more \"parameters\" at  a later time so we prefer wrapper objects with builders. Actually thinking more about this.  Rather than logging what if you want to do some other action\nIt could be a Function<Boolean,ComplexityInfo that returns true if the abort exception should be throw say.\nThe use of a function would allow people do do other things like log or call statsd or react in some other manner.\nThe ComplexityInfo here is a builder built object that contains the complexity count.  Passing just int means we cant add more \"parameters\" at  a later time so we prefer wrapper objects with builders. Actually thinking more about this.  Rather than logging what if you want to do some other action\nIt could be a Function<Boolean,ComplexityInfo that returns true if the abort exception should be throw say.\nThe use of a function would allow people do do other things like log or call statsd or react in some other manner.\nThe ComplexityInfo here is a builder built object that contains the complexity count.  Passing just int means we cant add more \"parameters\" at  a later time so we prefer wrapper objects with builders. Actually thinking more about this.  Rather than logging what if you want to do some other action\nIt could be a Function<Boolean,ComplexityInfo that returns true if the abort exception should be throw say.\nThe use of a function would allow people do do other things like log or call statsd or react in some other manner.\nThe ComplexityInfo here is a builder built object that contains the complexity count.  Passing just int means we cant add more \"parameters\" at  a later time so we prefer wrapper objects with builders. If we did go with this case, GraphqlList should also have this approach.\nThere is one idea that GraphqlNonNull and GraphqList should not be GraphqlTypes since they really dont have names.  The reference graphql-js uses this approach.\nWe should preserve the same \"Introspection\" semantics as graphql-js does say.\nSee https://github.com/graphql-java/graphql-java/issues/1251\nI don't think consuming code should rely on type name to identify the type.  Rather it should call the GraphqlTypeUtil methods to unwrap things which is more precise\nMy reasoning is this.\ntype                         name\n   [[FooBar!]!]            FooBar\n   [FooBar!]                FooBar\n   [FooBar]                 FooBar\n   [FooBar]!                FooBar\n   FooBar!                   FooBar\n   FooBar                    FooBar\nAll the types above are unique types but they would have the same name and IF some one uses the name to differentiate the types - then they are not really differentiating at all.\nBut if they use\nGraphqlTypeUtil.unwrapAll(type1).getName().equals(GraphqlTypeUtil.unwrapAll(type2).getName())\nthen its more clear that what they are comparing. PropertyDataFetcher is the default fetcher if no other is specified over it.\nIt will try to get field values (using the field name as the property name) first by public getter method, next by setAcceissible access on methods and then public field and finally by setAccessible field.\nThis means is just works out of the box at the expense of deeply following Javabeans specs on getters.  We took inspiration from GSON in this regard (which does something similar)\nBut if you dont like it then you can use your own property fetchers that implement the rules you would like to see.\nWe currently dont have a global mechanism to change the behaviour of PropertyFetcher. >  I really think that people expect private class members to not be accessible by graphql by default.\nWe have two choices\n 1. by open by default but make it possible to be closed\n 2. be closed by default but make it possible to be open\nWe have chose the first one.  There are pros and cons on what approach any library should take.\nWe do have a data fetcher factory mechanism for wiring in default fetchers however.\nHave a look at graphql.schema.idl.WiringFactory and its parent class graphql.schema.idl.RuntimeWiring about how you can use them to inject a default fetcher\ngraphql.schema.idl.WiringFactory#getDefaultDataFetcher. I am going to close this issue as its now possible to make the property fetcher only get public fields. Yes I think so\nOn Tue., 30 Oct. 2018, 19:09 Andreas Marek, notifications@github.com\nwrote:\n\n@bbakerman https://github.com/bbakerman we should backport that to 9.x\nI think. What do u think?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/1286#issuecomment-434207822,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSUDkQWWbxhBCiSE2HKu_pG-cY8ykks5uqAktgaJpZM4X7Rz2\n.\n. @LarsKrogJensen  - any chance you can give is a unit test / SDL schema so we can try to reproduce.\n\nI am unsure how you are using GraphQLTypeReference and hence how this is blowing up.\nnominally the schema type references SHOULD be all removed on schema creation time via graphql.schema.SchemaUtil#replaceTypeReferences but perhaps they are not.\nAny chance you can gives us a test reproduction helper. Hmnmm I think this behaviour should be fixed.  I will do it in terms of the other issue (because its a better desciption of the problem).\nBut the behaviour of re-using type refs is not wrong. Thanks for the PR. @andimarek - there is an integration test inside graphql.execution.DirectivesResolverTest. > Gave this a bit more thought, and I think there should be a method that returns a map of parsed directives for any directive container. This is because one might need to get directives from a different field than the first (if DataFetchingEnvironment#getFields contains multiple fields) or from a fragment or fragment definition.\n\nI can do it if you agree on the approach.\n\n@kaqqao - what shape do you see for this?  as in what is the key?  The Field node?  Should be not just combine them??\nDo you need the AST nodes per set of directives?\n```\n{\n    books(author: \"John Doe\") @cache(enabled = true) {\n        isbn\n        title\n    }\n   also : ...FragX\n}\nfragment FragX {\n   books @burnAfterReading {\n     title\n   }\n}\n```. @kaqqao - yes I think you are right.  We do need this and not what I have here.\nIf you are happy to then can you please make a PR, unwind the directives support we have there (directives of the top level field) and put in your idea.\nThe name graphql.Directives is already taken.  \nMy suggestion would be something like EncounterDirectives say.\nI would then see the DataFetchingEnvironemnt have a EncounterDirectives getEncounteredDirectrives method that is your access to the dfirectives on the ASDt nodes for that field.\nWew would also need to capture these into ExecutionStepIngo so one can look up as the parent directives.. please keep the DirectivesResolver code but change it to cater for the new collection of directives.\nAlso please add tests for this new scenario. I might back this change out since its 1/2 complete as is - not invaluable but not what we want as API know that I think more on it.. This has now been reverted via https://github.com/graphql-java/graphql-java/pull/1329\n@kaqqao - if you want to have a go at implenting it again (starting with the original code as  a base) then please do so.. We would be interesting in what you might be thinking.\nI guess some of our design principles we use on graphql-java are as follows.  So the closer to them that this might be the better it would be to get accepted\n\n\nWe prefer closer to zero dependencies.  Dont bring in guava, apache-commons, spring-xxx, y or z however much some StringUtils method might be useful.  Less dependencies makes graphql-java more applicable to everyone\n\n\nWe prefer staying out of the HTTP stack.  We are the low level engine of running graphql queries.  Other concerns such as JSON and HTTP are handled better by other layers\n\n\nWe prefer simple code to clever code.  It should be readable with well named methods.  Clever nested streams and lambas are not our thing\n\n\nWe prefer general to specific.  So the code should be generally applicable to use cases, not highly specific to just some use cases, even if it takes more setup.\n\n\nBased on what I read above it might be quite exciting to have a \"type registry\" system that defaults to multiple participants (as long as it can still work ok for the general case of \"read sdl, build type registry, wire schema\" like it does today\nSo please consider a PR to show what you are thinking.  we often use strawman PRs that are not tested or even compile as a mechanism to show your working.\n. I wrote this quick reproduction test (spock+groovy) but could not find a problem\n```\n        def spec = '''\n            directive @src(publisherRealm: String, name: String, version: String) on INTERFACE | OBJECT | INPUT_OBJECT | ENUM | SCALAR | FIELD_DEFINITION | UNION\n        type Foo @src(publisherRealm : \"x\", name : \"y\", version : \"Foo\") {\n            foo : String\n        }\n\n        type Bar @src(publisherRealm : \"x\", name : \"y\", version : \"Bar\") {\n            bar : String\n        }\n\n        union UnionType @src(publisherRealm : \"x\", name : \"y\", version : \"U\") =  Foo | Bar\n\n        type Query {\n            f1 : UnionType @src(publisherRealm : \"x\", name : \"y\", version : \"v\") \n        }\n    '''\n\n    def registry = parse(spec)\n    def errors = []\n\n    when:\n    new SchemaTypeDirectivesChecker(registry, RuntimeWiring.newRuntimeWiring().build()).checkTypeDirectives(errors)\n\n    then:\n    errors.size() == 0\n\n    when:\n    def schema = TestUtil.schema(spec)\n    then:\n    noExceptionThrown()\n\n```\nThis was on master (not on a released version so perhaps its been fixed since)\nAny chance you can create a production unit test on the version your are using?. graphql.schema.idl.SchemaTypeDirectivesCheckerTest has test case for unions and others for the record. Any news on this??. Any more news on this issue?\nJust doing my periodic review of open issues and wanted top ping this one. The website repo is here : https://github.com/graphql-java/graphql-java-page\nThis directory has the latest (unrelesed) doco https://github.com/graphql-java/graphql-java-page/tree/master/content/documentation/master\n. java.lang.NoClassDefFoundError are typically caused by an earlier exception where the class gets poisoned and cant be loaded for some reason.\nWithout more exceptions and information its impossible to tell you what is going on.\n. Sorry but we cant really help you write a java program via issues on the graphql-java project.  Its just too wide a field to say \"how do I write a Java program\"\nI recommend you get yourself a copy of a great IDE like Intellij IDEA or Eclipse and read a bunch of beginner tutorials.\n. I am not sure how graphql-java-tools works and hence how it allows you to insert your instrumentations not how it reacts to \"abort query\" exception that MaxQueryComplexityInstrumentation throws.\nIt sounds like the abstractions over graphql-java are not helping you in this case.. I am going to close this as it seems a graphql-java-tools issue. The data fetcher is the place where code to get values for individual fields should be placed.\nHowever if you have transactions / resources that need to span multiple fields (or the whole query) then your should look at using a custom graphql.execution.instrumentation.Instrumentation that knows the boundaries of your resources.\nThe graphql.execution.instrumentation.Instrumentation will be called back progressively as each stage (and field) is processed.. I am going to close this -  you are free to wrap your data fetchers via Instrumentation and we are unlikelt to create specific release lifecycle methods in the core library. Sorry I think you have the wrong project.  graphql-java is the base library that does query execution.\nI think you want the https://github.com/graphql-java-kickstart/graphql-java-servlet project. added new annotation as suggested. I agree with you that a stable introspection system is a win.  I have started some PRs to try and address this.\nThe graphql spec says nothing about a stable order when a type is asked for its fields (althought query results must be stable) and graphql-js itself just uses Object js map behavior which is also not stable.\nHowever in terms of debuggability and predictability a stable order is important.  Out SchemaPrinter already does name sorting for stability reasons.  I think the graphql types themselves should give out elements in a stable manner\n. The next version will have stable sort order of fields and types. We have not support for JWT since we are not a application server at all.  We have no support for HTTP / JSON / Authentication etc...\nThis is graphql engine on java and we believe its better that consumers use their application infra of choice.\n. Closing this as answer. I merged this into the other sorting PR since the test changes are co-depedent. @kaqqao - let me give you the 2 minute explanation and Andi can give you the long winded version since its his baby.\nThe thought is to create a  \"next gen\" execution engine that is truly async by design as opposed to todays which was created \"sync\" and then evolved into a CF based one.\nThe other goal is to allow it to be designed to easily allow \"batching\" by default and hence not need a \"batchES\" or \"not batch ES\"\nThis work came out of some explorations in a \"reactive\" execution strategy that then turned into a CompletableFuture based one so it can run on Java native without a hard dependency on say rxjava or reactor libs.\nWe think this will \"co-exist\" with the existing ES modules for some time.\nWe also need to re-think \"Instrumentation\" and so on since this has a completely different execution shape than the old \"depth first\" field at a  time pattern.. @exbe - this is not yet callable - the code exists but is not wired in from the top.  So you can use it today from public API - only on tests so far.\nBut yes later we will come up with a mechanism to \"use this next gen\" engines. 13 for this one\nOn Tue., 11 Dec. 2018, 18:13 Andreas Marek, notifications@github.com\nwrote:\n\n@bbakerman https://github.com/bbakerman can we move that to 13.0 or do\nu want that in 12.0?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/1321#issuecomment-446096512,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABlbSenFWfCPNAcSYiObA3-aZ_6AWS4Rks5u31sIgaJpZM4YoZOx\n.\n. So the previous behavior was a result of a bug most likely.  \n\noops.Query is not a valid set of characters for a named element, which is defined as\nNAME: [_A-Za-z][_0-9A-Za-z]*;\n\nSo it is correctly saying its invalid syntax.\nWe could accept ANY name and then validate but this would lead to silly situations with meaningful characters and open us up parsing bugs.\nI understand your point about how its not easy to work out whats wrong but it is correct.\nBuilding loose parsers and then guarding yourself on all the conditions is not a task we would want  take on.\n. Every field in graphql has a data fetcher - but default that is a PropertyDataFetcher that is a \"field name -> POJO getter \" look up.\nHowever you can wire in as many data fetchers as you like\nFor example here is a hand built object type (from the graphql java introspection class)\npublic static final GraphQLObjectType __InputValue = newObject()\n            .name(\"__InputValue\")\n            .field(newFieldDefinition()\n                    .name(\"name\")\n                    .type(nonNull(GraphQLString)))\n            .field(newFieldDefinition()\n                    .name(\"description\")\n                    .type(GraphQLString))\n            .field(newFieldDefinition()\n                    .name(\"type\")\n                    .type(nonNull(typeRef(\"__Type\"))))\n            .field(newFieldDefinition()\n                    .name(\"defaultValue\")\n                    .type(GraphQLString)\n                    .dataFetcher(environment -> {\n                        if (environment.getSource() instanceof GraphQLArgument) {\n                            GraphQLArgument inputField = environment.getSource();\n                            return inputField.getDefaultValue() != null ? print(inputField.getDefaultValue(), inputField.getType()) : null;\n                        } else if (environment.getSource() instanceof GraphQLInputObjectField) {\n                            GraphQLInputObjectField inputField = environment.getSource();\n                            return inputField.getDefaultValue() != null ? print(inputField.getDefaultValue(), inputField.getType()) : null;\n                        }\n                        return null;\n                    }))\n            .build();\nNotice how some of the fields have no data fetcher named?  This means they rely on POJO field fetching and hence the name fields comes from looking up the source object for a getName method.\nHowever the defaultValue field has a specific data fetcher since it has more logic on it.  It takes the parent \"source\" object and applies some logic to it to derive a meaningful value\nThe example above is hand build objects.\nYou can also use SDL and RuntimeWiring rather than hand built objects\nSee \nhttps://www.graphql-java.com/documentation/v11/data-fetching/\nhttps://www.graphql-java.com/documentation/v11/schema/. query ProductQuery {\n    products(match : \"Paper*\")\n    {\n        id, name, cost\n     }\n}\n\nHow does my fetcher know that it should not be fetching the tax info?\n\nIn this case your business logic fetcher should be behind the products field\nIf you want to optimise the fetch such that you build a POJO or map where it does NOT get the tax field then you need the data fetcher to \"look ahead\" at the \"selection set\" of sub fields.  It would there have to know what possible sub fields it can handle and hence only get id, name, cost and not tax\nTypically you would not a POJO but rather a Map of results which PropertyDataFetcher can pull part\nSee graphql.schema.DataFetchingEnvironment#getSelectionSet for API support in looking ahead to the selection set of sub fields.\nhowever OFTEN what happens is that you do indeed build a POJO that contains tax from the backend BUT since the query never asked for that field it is loaded (say from the database) but never used.  Sometimes code is like that.  Optimising to ONLY get certain fields might not be worth it depending on execution complexity.\n. The other thing to consider is that the graphql engine maps ONLY those fields \"asked for in the query\" to property gets.  So in your example above no one asked for the tax field and hence even if it was present in a POJO or Map structure - it would never be returned in that graphql query.  The order of execution is\nproducts(match : \"Paper*\")   # <--- this is the main business logic fetch returning POJO/Map\n    {\n        id,          # <- property fetch - pojo.getId() or dataMap.get('id')\n        name,   # <- property fetch - pojo.getName() or dataMap.get('name')\n        cost      # <- property fetch - pojo.getCost() or dataMap.get('cost')\n     }. Small breaking change but technically one. This is now fixed in 12.0. Thanks. You can already do most of this in graphql-java today.\nImagine you have a type system like this\n```\n            input PersonInput {\n                firstName : String\n                lastName : String = \"defaultedLastName\" \n            }\n        type Mutation {\n            updatePerson(lastName : String, firstName : String, personInput : PersonInput) : String\n        }\n\n```\nWhen the data fetcher for updatePerson it is given a DataFetchingEnvironment.  You can today ask 2 questions\n boolean containsArg = dfe.containsArgument(\"firstName\")\n Object firstNameValue = dfe.getArgument(\"firstName\")\n\nIf a field argument is NOT specified then there will be NO entries in the map for that key.\nI agree that DataFetchingEnvironment should have a getArgumentOpt to returns an Optional to better codify this in one call.\nBut in the mean time you can do that yourself.\nYou can then decide in your data fetcher how to \"apply\" arguments to the underlying data storage. eg if the lastName is missing then dont make  a call to set it.. Not this also works on complex input types eg PersonInput above\nif firstName is not set into the structure, then the resultant runtime map object that represents \"personInput\" argument will be missing.\nThe following update the graphql spec covers this\nhttps://github.com/facebook/graphql/pull/418/files. I am pretty happy with this approach.  However without the ability track up the inheritance node tree then I would not offer the getFirstApplicableDirective method.  \nBut if we later improve it - then we have the code structure to \"add it in\" which is great.\nSo I would aim to get this API in place with tests without the first applicable and we can work towards making that possible progressively.\nAlso note - the above query is confusing a little - because while the inline fragment and the actual fragment are both valid - only one will apply at runtime - so which one takes precedence (and is closest) is an interesting question\nI am worried about using Field as a key in the map.  I dont think its suitable with Document rewriting.\nWe have been working on a bunch of \"document rewriting\" capability and this involves \"making new nodes\" when doing this.. I tell a lie about Field stability - as long as the collectors run just before execution - then we wont allow query rewriting - it would only be just after parse that we allow query rewriting\nSo the Field key problem is not a problem  (still not a great key since its by identity but we dont have a choice really). See #1393 \nThe new QueryTraverser changes now allows the \"parent nodes\" that lead to a field to be accessed.  Hence working out the closest directive from a field is much easier to do.\nPlease comment on the API shape please @kaqqao especially around the DataFetcherEnv extension. PropertyDataFetcher does indeed use reflection but be careful in thinking that reflection is always slow.\nReflection in Java has gotten progressively faster over the years and also there is a method cache in PropertyDataFetcher such that once it has discovered a class / method to field it does not do it again.\nOnly a profiler will tell you what is happening but 40,000 items of anything is a lot to process in any computer system.  Its a lot of memory in one go and a lot of processing.  I would strongly suggest looking at some sort of paging in your system.\nThe fact that you are using DTO pattern probably means you have a object mapping framework like Jackson / Gson in play.  This takes a lot of processing at times.   At a guess this might explain why the Map approach is faster since it wont be doing as much work.\nBut as Andi says above, a profiler is really thew way to go to get insight on what is taking so long.. As a quick start to look at relative timings, I created the following dirty test program\nhttps://gist.github.com/bbakerman/855e9f2b76ce3642efebfd655e29efcd\nIt creates 40,000 friends to a hero using the starwars schema with no inner friends\n{ hero { name friends { name friends { name } } } }\nIt as a rudimentary warm up and then some timings\n```\ngraphql produced 40000 objects in 870 ms\nJackson write 40000 objects in 115 ms\n```\nDone on \nModel Name: MacBook Pro\n  Model Identifier: MacBookPro15,1\n  Processor Name:   Intel Core i7\n  Processor Speed:  2.2 GHz\n  Number of Processors: 1\n  Total Number of Cores:    6\n  L2 Cache (per Core):  256 KB\n  L3 Cache: 9 MB\n  Memory:   32 GB\nI will have a look via profiler to see more detailed information. \nAlso check out https://github.com/graphql-java/graphql-java-extended-scalars\n. See #1386 for a fix. > Can this live side-by-side with execution strategies? It seems like those operate at a lower level, i.e. coordinating the resolution of fields within an operation.\nYes it can\n\nDo the instrumentation hooks still make sense with this approach? I think they will basically fire off as if a separate request was made for each operation name, but I'm not sure.\n\nThat is problematic - I had no easy way to solve this in a previous PR that tried this.  Instrumentation today thinks it begins and ends a query - but we would need a \"UberInstrumentation\" that can sit over multiple operations at once\n\nIs this to spec? It's kind of vague when it comes to executing multiple operations.\n\nIts not vague - its not allowed.   :(. > I don't think adding acceptBackRef is worth it: just adding a new public TraversalControl backRef(TraverserContext context) to GraphQLTypeVisitor should be enough.\nOK I have added that. @cmonty \n\nWe do use ExecutionContext and call addError when an exception is thrown.\n\nCome 12.0 this will be removed and we will ask you to return a DataFetcherResult wrapper object from your data fetchers\nThis exists today and it can contain data (or null) and errors (or empty list) and the graphql engine will put the errors in the result for you today.\nhttps://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/execution/DataFetcherResult.java\nSo if you move to that system before adopting 12.0 then you will continue to work as expected. This is now in place on master.\nWe allow \"empty types\" for all types, objects, enums, interfaces, unions and input types. The lack of JavaDoc stands out for me.  How would some be an adaptor and what responsibilities do they have?  I know you know - will all people?. Yes - graphql-java itself has not runtime dependency on jackson at all.. > Why is FieldDirectivesInfo a position? because of the distance?\nOld naming.... > I think the public API is pretty friendly.\n\nI'm only slightly concerned about the inability to tell field and fragment directives apart. I don't have a use-case in mind, just a general feeling that a directive on an ancestor field (that has its own semantics) vs a directive on a fragment (that has no semantics of its own) should perhaps be distinguishable. Would tracking the directive location (DirectiveLocation) next to the distance be a good idea?\nMind you, I didn't look into the code deep enough to know if that's a hassle to do or not.\n\n@kaqqao  - you can do what you want via List<QueryDirectivesInfo> getAllDirectives();\nThis will give you all the directives that lead to a field and its location and its distance.  Its \"field\" oriented, that is all the directives that lead to that field (including all unmerged fields)\nSo you could just list.filter(info -> (nfo.getDirectiveLocation() == X).collecr(_) them into their constituent parts.\n. This will not make the next release and needs to be revisited a bit more. Have a read of https://www.graphql-java.com/documentation/v11/data-mapping/\nIn essence on input you will get map objects and on output you can use maps or plain old java objects OR have your own custom data fetcher for a field. > yes, I think we should make defer support disabled by default or make it possible to enable it. @bbakerman thoughts?\nThe reason we have @defer on by default was to make it as widely available as possible.\nAs @tbroyer pointed out you need to remove iot from the list of standard directives.   We could add a  helper  method to the builder like builder.removeDirective(\"directiveName\") to help.\n. @defer is not longer on by default in master (which will be released in 13.0 at some stage). There are 2 hard things in computing.\n\nNaming things\nCache invalidation\nand off by one errors\n\nIf you are using data loader as a cache and you update the backing object, then just like any caching system you must invalidate the cache entry by key.\nThere is a method for this : org.dataloader.DataLoader#clear and one for all keys org.dataloader.DataLoader#clearAll.  \nYou can disable caching in DataLoader via org.dataloader.DataLoaderOptions#setCachingEnabled\n. > I'm wondering though, shouldn't this cleanup be performed by the library automatically when executing GraphQL Subscription\nNo because only the specific implementation can know its own caching policies.. > Happened because I was creating GraphQL queries/mutations with GraphQLTypeReferences. Is that something I shouldn't have been doing in the first place?\nThis is the correct thing to be doing..  type references are replaced with ACTUAL references when the schema is built.\nWe had a bug that was recently fixed in master where type references to the same place did not get replaced properly.  \nhttps://github.com/graphql-java/graphql-java/pull/1386\nI suspect this might be your problem.\nI had a quick look at https://github.com/quinscape/domainql/blob/bug-noresolve/src/test/java/de/quinscape/domainql/DomainQLExecutionTest.java#L980 but I cant undeerstand the logic enough to see if its indeed the mentioned problem.\n. Its your batch loading code that is returning the map given the set of keys\npublic interface MappedBatchLoader<K, V> {\n     CompletionStage<Map<K, V>> load(Set<K> keys);\n }\n\nSo if you want empty list values - then put them in in that loader\nThe problem with a default value is that DataLoaderOptions has not concept of the type V that dataloader returns.  I mean we could cast it I guess.\nAlso this issue would be better over in the https://github.com/graphql-java/java-dataloader/issues project\nI made https://github.com/graphql-java/java-dataloader/issues/40 for this. I am going to close this issue here and follow up in the dataloader project. graphql-java has support for triple quotes including the \"indentation removal\" since about 23/1/2018\nSee graphql.parser.StringValueParsing#parseTripleQuotedString\nHave you see behavior that doesnt follow spec?  If so please let us know. We do have support for descriptions specifically.  Every AST type node can have them\neg\n fieldDefinition : description? name argumentsDefinition? ':' type directives?;\n\nIts defined as a single or triple quoted string\nAt schema build time these get transfered into the \"description\" string of the type element, eg GraphqlFieldDefinitiion or GraphqlObjectType etc..\nThis should work.\nThat said I cant see if we have explicit unit tests for description elements versus comments so I m ikght add some\n. I wrote this test (not in a PR yet) that seems to confirm it in Introspection results\n```\nclass TestTripleQuotedCommentSupport extends Specification {\ndef \"1405 - triple quote support in Introspection\"() {\n    def sdl = '''\n\n\"\"\"\nA simple GraphQL schema which is well described.\nAnd has multiple lines of description\n\"\"\"\ntype Query {\n  \"\"\"\n  Translates a string from a given language into a different language.\n  \"\"\"\n  translate(\n    \"The original language that text is provided in.\"\n    fromLanguage: Language\n\"The translated language to be returned.\"\ntoLanguage: Language\n\n\"The text to be translated.\"\ntext: String\n\n): String\n}\n\"\"\"\nThe set of languages supported by translate.\n\"\"\"\nenum Language {\n  \"English\"\n  EN\n\"French\"\n  FR\n\"Chinese\"\n  CH\n}\n'''\n    def graphQL = TestUtil.graphQL(sdl).build()\n\n    when:\n    def er = graphQL.execute(IntrospectionQuery.INTROSPECTION_QUERY)\n    then:\n    er.errors.isEmpty()\n    def introspection = er.data\n    def types = introspection[\"__schema\"][\"types\"]\n\n    def queryType = typeKindNamed(types, \"OBJECT\", \"Query\")\n    queryType[\"description\"] == \"\"\"A simple GraphQL schema which is well described.\\nAnd has multiple lines of description\"\"\"\n\n    def translateField = named(queryType[\"fields\"], \"translate\")\n    translateField[\"description\"] == \" Translates a string from a given language into a different language.\\n \"\n\n    def languageEnum = typeKindNamed(types, \"ENUM\", \"Language\")\n    languageEnum[\"description\"] == \"The set of languages supported by `translate`.\"\n}\n\ndef typeKindNamed(types, String kind, String named) {\n    types.find { it -> it[\"name\"] == named && it[\"kind\"] == kind.toUpperCase() }\n}\n\ndef named(list, String named) {\n    list.find { it -> it[\"name\"] == named }\n}\n\n}\n```\nThe TestUtil code there calls the SDL generator under the covers. See https://github.com/graphql-java/graphql-java/pull/1421\n. You cant do this.  Even if the field ordering was \"garunteed\" (which it is not and wont be).. there is no way from a data field for a field to gain access to the value of another field.\nAlso you have invented new \"syntax\" here of allowing access ($hello.name) into graphql which would just fail.   A field can have an alias but it MUST be a field.\nThis idea has ALL sorts of \"variable scoping\" challenges eg\n```\n{\n     person {\n         name\n         friends {\n             name\n             person {\n                  name\n                  $person.name   # which scope??\n```\nIn short I can see how you can do this AND we would not change graphql to allow a data fetcher to get previous results. This is not needed. You will want to ask in the https://github.com/graphql-java-kickstart/graphql-java-tools project.\nInputMismatchException usually means you are missing a token (eg opening and closing braces)\nBut how graphql-tools is combining files I have no insight on... hence ask there. > This is a breaking change, because we change the default behaviour, right?\n\nWe need to document it more clearly if that is the case.\n\nIt is if you consider it along the lines of \"if you wanted that shitty behaviour from before\" its a breaking change.\nBut if you consider it from \"it now does what would be reasonable expected\" then its not breaking.\nI guess its just a marker on changes.  There is plenty more breaking stuff in 12.x to be.     private static final Logger log = LoggerFactory.getLogger(GraphQL.class);\nJust turn off logging for graphql.GraphQL in your logging config. There is no way to override the standard Scalars.  The whole point of standard scalars is standard naming and behavior\nYou want \"date time\" behavior but you don't want a \"DateTime\" scalar?  I think you are doing it wrong.\nFor example I am sure you have a mix of real \"String\" fields and \"DataTime String\" fields so how would you know which was which?  Who would a caller know other than by field naming convention?  eg thisIsADateTime : String is the only way to know that its not a String but a\"DataTime String\"?\nI urge you to consider using https://github.com/graphql-java/graphql-java-extended-scalars and custom scalars.. You cant override the standard scalars and I dont think we would ever allow it.\nDataFetchers per field are the \"code callback\" that are injectable.  They are the standard way to change result objects.\nIf the higher level objects you return cant be made into Strings easily then you need to so that it in the top level data fetcher OR put a data fetcher onto your String fields and have them create the String object from the appropriate place\n```\n     query {\n            topLevel {                      # data fetcher gets specialField into String shape\n                    specialField           # or a specific data fetcher here that knows how to get it in to String shape\n```\nHave a look at graphql.schema.idl.WiringFactory that will allow you to KNOW what fields you are retriveving and hence put special data fetchers in place. I am going to close this issue because we will not allow scalar co-ercing overrides. Any news on this issue and its reproduction?. I am going to close this due to inactivity. Yeah - fair enough.  \nWe could change this in the ExecutionResult object.\nOf course the JSON production might not respect that but the Java API could try to follow the guidance. I think this PR has to go further and move the getter methods in the interface and implementation\nI think Jackson JSON production say will use that order (I might be wrong but I think it will off hand).  So for every one who just sends the  ExecutionResult directly back without calling toSpecification() then they will get this guidance of errors first. Thanks for reporting this.  The printing of directive definitions was completely missed in the SchemaPrinter. Thanks for reporting this.  We will look into it.. I was able to reproduce this bug\nIn groovy format like this\n```\n    def \"1438 - slash-n is incorrectly parsed\"() {\n        given:\n        def input = '''\n            mutation{fld(arg: \"\"\"L1\\nL 2\\nL 3\"\"\"){innerField}}\n        '''\n        when:\n        Document document = new Parser().parseDocument(input)\n        Field firstField = (document.definitions[0] as OperationDefinition).selectionSet.selections[0] as Field\n        def argumentValue = firstField.getArguments().get(0).getValue()\n    then:\n    argumentValue instanceof StringValue\n    def value = ((StringValue) argumentValue).value\n    value == 'L1\\nl 2\\nL 3'\n}\n\n``\nIt does seem to be something to do with \\n pairing of some sort because the string '''L1\\nl 2\\nL3 actually works as expected.\nAnyway I will try to get to the bottom of what is happening here.. Hmm it looks like the code problem is in graphql.parser.StringValueParsing#removeIndentation\nand how it tries to follow the graphqlspec on how to indent multiline triple quoted strings\nhttps://github.com/facebook/graphql/pull/327/files#diff-fe406b08746616e2f5f00909488cce66R758\nWe will need to review this code . Thanks for reporting this\nThis has been fixed and now follows the graphql spec on triple quote indenting more thoroughly. Thanks for this. We will not be fixing this in the base graphql-java.  \nThis use case (internet submitted schemas) deserves it own custom \"sensibility check code\" to be done by your application.\nWe make an assumption that the schemas provided are graphql schemas and may have a few problems.  \nWe don't optimise for detection of  binary data.  If we did, it would be code we would have to maintain over time and it would not be used by 95% of all library consumers.\nI urge you to develop your own \"sanity code\" before you submit it to the schema parser.. Interesting .. I know why this is happening.  The graphql Document is inclusive of \"query\" aspects and \"sdl type definition\" aspects\nhttps://facebook.github.io/graphql/June2018/#sec-Appendix-Grammar-Summary.Document\nSo the SchemaParser is parsing all of the Document but then only collects the known \"SDL\" types\nSo the underlying document parser is correct - however we can argue that SchemaParser should only accept \"SDL related\" elements\n. This is now fixed on master.\nIt with report an error if non SDL elements are present. The GraphQL object is nominally global however its really cheap to create one. Its the GraphqlSchema that can be expensive because of SDL parsing and so on\nSo you can very cheaply create a new Graphql via transform, which is a copy method\nGraphQL perRequestGraphqlObject = graphQL.transform(builder -> builder.instrumentation(..));\nYou can do this per request where you respect some debugging flags.. What does it do?  You can put it in a query field but then what happens?\nWe would need a much better explanation to consider it.  We would also like to see other possible implementations (for interoperability of clients - eg a web client could have the same behavior on graphql-java as it could on some other engine say)\nI am guessing its something like that which is described in https://blog.apollographql.com/new-features-in-graphql-batch-defer-stream-live-and-subscribe-7585d0c28b07. We dont have i18n messages in graphql - which is a pity to be honest. I think your first port of call here should be the kickstart project\nhttps://github.com/graphql-java-kickstart/graphql-java-tools\nThis is the project for the underlying graphql-java engine.  There might be some funky interplay here between Kotlin/java-tools and the defaulting of AST values.\nLooking at the stack trace, this is actually a Introspection call happening.\nI am not sure how javatools maps items(queryParams: QueryParams, env: DataFetchingEnvironment) into actual Java beans.  graphql-java base only ever works with maps and not Java types\nI suspect the problem is in there some how but I cant be sure not can I easily reproduce\nI would raise this bug over in java-tools.\n. CopyOnWriteArrayList is pretty efficient list. The GraphQL spec says that mutations WILL ALWAYS be serial.  So why allow people to wire in anything BUT a serial implementation?\nI guess it makes it more configureable than today but you have no way of knowing that they are following spec or not.  \nMaybe its a case of \"dont shoot yourself\" by wiring in a asynch mutation execution strategy. do you really want Spotify as a dependency.  I thought graphql-java was trying to be as lightweight as possible. Yet more constructors is an anti pattern I know.  I think GraphQL needs a builder\n  GraphQL graphQL = GraphQL.builder(schema).\n      .strategy(x)\n      .instrumentation(y)\n      .build()\n\nThat way the API can be evolved more easily without breaking existing client or adding yet more overloaded methods / constructors\n          . I think may of the classes in the package should be package private and hence not API.\nThis will allow better evolution of the implementation without breaking people.  For example I dont think any consumers should be able to create this class.  Its really an implementation class. The other variables in this class should be final.  The setters are an anti pattern.\n. #263 outlines this.  Immutability for the win. InstrumentationContext allows for callback that are site specific and not casting of Object is needed.  eg  the parse call back gets the parsed document. Having Document passed back and String requestString, String operationName, Object context, Map arguments is a contentious design\nOn the one hand this allows you to SPY on every thing as it happens and that could be great for better instrumentation.\nOn the other hand it means the parameters are no API and cant easily be changed.\nI think we either do NONE or have a Builder of InstrumentationParseParameters so we can add extra parameters in the future.  In fact as I type... this is what I think it should be.\nOr.... we have a Map<String,Object> arangement which is not at all type safe but infinitely extendable.  Its quasi secret information and might change at any time.\nThoughts?. Same thougths here - Should document be API?. There are no code hygeine rules for the project so I let IDEA do its full import behaviour of .* imports.  This is what we use here in Atlassian and I am a fan of it.. Having Document as API is the most contentious parameter in my book. I think the cod should have a Builder of GraphQL objects so it can be extended more easily over time.\nGraphQL.newGraph()\n  .schema(mySchema)\n  .executionStategy(s1)\n  .mutationStrategy(ms)\n  .build();\n\nI have a PR in that adds an  \"Instrumentation SPI\" and this is YET another example adding extra aspects to the GrapQL object. I know this is not related but inline assignment and null checking is super handy. Smidge more efficient and IDEA inspections (which I trust mostly) says to do it. \nBroken window theory in code and all.... So much more natural\n   Obj o = notNull(input,\"please\"). Good catch. Yeah I am updating that now. By default its looks the other builders and uses SimpleStrategy for execution.  You can then use your own via builder methods. Ok now have updated the readme as well to give examples...plus made it the examples compile time safe.. This way the readme will stay correct with the minimum effort of cut and paste. Done. Done!. Just to test that is not \"unlimited\" but rather not exceeded during the depth.  WQe have a case when its < 0 then its unlimited. Yeah the library does not have a good way for a consumer to \"inject\" a strategy in for handling errors. . So this is an outright API breaking change.  The previous calls expected to get the original \"context object\"\n\nSo from a SemVer point of view we cant make this change inside a minor version.\nEven if we made a Major SemVer change I wont not do it this way.  If we wanted to expose ExecutionContext then we would just add it as another attribute and hence its a non breaking change. Now I am not sure we should actually expose ExecutionContext as API.\nReducing the API surface area is good for long term project health.\n@mrcirillo - what do you want from ExecutionContext inside your data fetchers?\nIt currently has\n     private final GraphQLSchema graphQLSchema;\nprivate final ExecutionId executionId;\nprivate final ExecutionStrategy queryStrategy;\nprivate final ExecutionStrategy mutationStrategy;\nprivate final Map<String, FragmentDefinition> fragmentsByName;\nprivate final OperationDefinition operationDefinition;\nprivate final Map<String, Object> variables;\nprivate final Object root;\nprivate final List<GraphQLError> errors = new CopyOnWriteArrayList<GraphQLError>();\n\nwhich bits do you need?\nI am not convinced that ExecutionContext is what DataFetchers need.  Convince me?\n(We could invent a new API interface to contain what you need based on a convincing argument). I am wary of using the ExecutionContext directly in that it exposes \"execution\" internals directly to the most needed of API areas.\nI would rather we invented a SelectionSet / Fragments interface that we can give out that info and not more so that the \"scope\" of API is reduced.\nBy limiting the scope of API we can refactor the project better of time.\nBy allowing carte blanche access to ExecutionContext as it is, we create more API and lock the project into having to support it \nCan we please try to make a set of interfaces that represent what you want (even if under the covers it gets it form the executioncontext etc..). https://facebook.github.io/graphql/#sec-Names\nNice!. the fact is that because you changed the ExecutionStrategy above and hence this a breaking SPI change for people who extend execution strategy.\nHence the carefully crafted \"default\" here is backwards compatible but the whole PR is not\nSo I would remove the 1.8 requirement (which may come but you dont need to be dependent on it). Again technically a breaking changes for people who extend ExecutionEnvironment\nBut maybe we need to.\nThat or we  move the \"parameter objects\" with builders so we can \"optional\" add new parameters more easily without breaking SPI.. The parameters pattern is simply taking N current parameters and moving them into an object with a builder so it takes only 1 parameters\neg:\nresolveField(Field field, GraphQLInterfaceType graphQLInterfaceType,\n                                         Object value, Map<String, Object> argumentValues, GraphQLSchema schema)\n\nbecomes\nresolveField(ResolveFieldParameters parameters)\n\nthis is useful because you are able to \"add\" new parameters to the builder while preserving backwards compatibility.  This is more useful for \"API /  SPI\" of course\nThe following is for \"constructors\" from Effective Java\nhttp://www.informit.com/articles/article.aspx?p=1216151&seqNum=2\nBut it would be for methods as well\nNote this is not really your problem in terms of this PR.  But because you needed to add yet more parameters you exasperated the existing problem.\nA parameters object would also be a breaking change, although we might be able to do it via overloading and deprecation. This is an example linked from the README.  Dont do this one please. The these out for uber clarity. We already broke this SPI in 3.0 with the earlier \"parameters\" change.  You dont need to to this.. I thought about calling it \"Resolvers\" but decided against it because DataFetchers are not known as Resolvers and hence it doesnt ring true for graphql-java. I think this will be ok but let me add a test to ensure its ok to do. OK added and extra test to confirm.  Circular dependencies are ok and handled ok.\neg  \ntype Author {  \n    post : [Post]\n}\n\nand in another file\n type Post {\n   author : Author;\n}\n\nThe code only cares at this stage for top level types\nReferences to types are resolved later in the SchemaGenerator. This method was never used and hence i removed it for code health. sure - funny thing is its a direct port of the JS implementation.  So its \"reference mess\" ;)\nI agree its messy. done. done. done. done. done. Which import rules you want to run in this library.\nI personally find \"import all\" better but your tooling is not doing that clearly.. Notice how visitedFragments is NEVER used.  Thats why I took it out of the public method signature. I can make this public again but I figured 3.x and breaking changes and its unlikely to break ANYONE really. To use FieldCollector in a DataFetcher, I need the ExecutionContext.  . I have taken this out now as being API and made a new wrapper of the bits we need. Consider adding\njava.lang.annotation.Documented\n@Documented. Consider @Documented. In 4.0 we should remove deprecations.. done. done. done. yes it is missing that.  We can do that in another PR.  \nhttps://github.com/graphql-java/graphql-java/issues/414. Have  a look at the other errors.  They try to include a linecol() of the offending definition. eg\n```\npublic class MissingInterfaceTypeError extends BaseError {\npublic MissingInterfaceTypeError(String typeOfType, TypeDefinition typeDefinition, TypeName typeName) {\n    super(typeDefinition, format(\"The %s type '%s' is not present when resolving type '%s' %s\",\n            typeOfType, typeName.getName(), typeDefinition.getName(), lineCol(typeDefinition)));\n}\n\n}\n```. if you make this \n    public static  T assertNeverCalled()\nthen you can do this at call site\n{\n     return assertShouldNeverBecalled()\n   }. I am wary of trimming here.  I think we should use a isBlank() approach.  \nFor example in markdown they might have used 4 spaces in the description and now we have just trimed them away\nHow about:\n    String commentLine = comments.get(i).getContent()\n    if (isBlank(commentLine) {\n           ....\n\nand isBlank has the semantics if say : https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/StringUtils.html#isBlank-java.lang.CharSequence-\n. If we say we dont trim (and I dont think we should) then we should have a description that has preceding and trailing whitespace\neg:\n#      \\t\\rdescription 4     \\t\\r. eg: the equivalent of \\t\\r in source text. Lambdas and Groovy dont mix as well as one would hope :(. Rock and roll.  I was thinking the library needed this versus the myriad of execute(....) overlaods it has now. should this default to emptyMap?. We should add JavaDoc here for consistency AND this is also a key difference to getSource()\n\n\n[ ] Add JavaDoc. I like root being available because it is likely to contain global instructions.  eg credentials etc... for data fetchers on how to act versus the current object in scope. nice one. I have added these extra tests.  Is that what you are after @andimarek ?. unit tests added. @andimarek - has this gone out in API yet?  I cant remember\n\nif it hasnt then there is no need to preserve API.  \nIf it has can we make this a WiringParameters type interface\ninterface WiringParameters {\n        TypeDefinitionRegistry registry()\n        TypeDefinition parentType()\n         FieldDefinition definition()\n   }\nThat way later when we want another parameter we can extend  it onto the interface and no one gets broken!\nSince this is a SPI its ever more important. So are you saying that we we remove the old methods and introduce the new ones with parameters objects then?\nI think thats what you are saying. Can we call this toSpecification() please. with Javadoc. Nice work!. we do but there is an edge case according to the spec.\nif its POST BUT there is a query string parameter called query, you should take that instead\nIts kinda confusing.  Perhaps we could drop this slavish following of the spec for example purposes. Since I want to be able to .join() in a variety of places I think we should leave this as CompleteableFuture. ConcurrentHashMap is a better choice than synchronizedMap. Mostly pondering here.\nI wonder if we should make the complete value list truly async.  Should it join back as one result at this point?\nIs there any disadvantage is leaving it purely async for many items in a list?  Is there any expectation that is this point you have resolved the value so it can be sent onto future calls?. we dont do * imports.  Full imports please. The Instrumentation is not called back here and hence is lost\n        fetchCtx.onEnd(resolvedValue);\n\n\n[ ] Add in intrumentation call\n. This comment is an aside to this PR btw.  \n\n@andimarek \nThere is a lot of repeated code in here from the base ExecutionStrategy.  Perhaps we should make a ExecutionStrategyHelper and use composition instead of inheritance to allow better reuse??\nHard problem I know. fyi - there are a few PRS in the pipe that will make this code break.  But thats often always the case. Are we trying to say that the first things to be resolved (grand) is likely to be the last thing to be completed (50ms) and hence it come back in the right order.?. Just trying to work out what the tests really proves. @andimarek - the spec says:\n\nThe\n\nresponse map may also contain an entry with key extensions. This entry, if set, must have a map as its value. This entry is reserved for implementors to extend the protocol however they see fit, and hence there are no additional restrictions on its contents.\nSo since graphql-java (the implementor) does not use it then I would remove it until some one comes up with a good use case for it.\nAnd perhaps we should have  a ExecutionResultBuilder so that it ExecutionResult can be immutable more easily. @bsideup - if you could do that it would be really helpful. Is there no common type here ?  GraphqlType perhaps?\nI guess GraphQLEnumValueDefinition et all stop that. Wow thats a lot of new tests.  Good work!. Can we make the signature \n    protected ExecutionResult completeValueForEnum(GraphQLEnumType enumType, ExecutionContext \n context, ExecutionStrategyParameters parameters, Object result) {\nThat way its sympathetic to the other methods that have ExecutionContext \n context, ExecutionStrategyParameters parameters as parameters\nIn fact you could argue for consistency they should be the 1st two parameters (since this is a breaking change). Where would you put it? On the DFEImpl instead?  \nI can imagine DataFetchers that wrap other data fetchers might want to use this to \"tweak\" the environment before calling the wrapped DF.\nBut its just sugar on `Builder.newDataFetchingEvironment(currentEv).build() so I can remove it if you want.  I am not wedded to it in this case\n. IN fact here is one from the graphql base code\n````\npublic class UnbatchedDataFetcher implements BatchedDataFetcher {\nprivate final DataFetcher delegate;\n\npublic UnbatchedDataFetcher(DataFetcher delegate) {\n    this.delegate = delegate;\n}\n\n\n@Override\npublic Object get(DataFetchingEnvironment environment) {\n    List<Object> sources = environment.getSource();\n    List<Object> results = new ArrayList<>();\n    for (Object source : sources) {\n\n        DataFetchingEnvironment singleEnv = environment\n                .transform(builder -> builder.source(source));\n        results.add(delegate.get(singleEnv));\n    }\n    return results;\n}\n\n}\n````. FYI I have removed it. There were some copy and pasta errors in the messages.  I fixed them and put the offending object in 'quotes'\n. Another place that needs the path. I would rather see a new PR with the GraphQL class refactorings say then all the new Builder() changes. This has always bugged me that we have a builder but we dont use it completely. Can we call this getDocument please\nnit: no need for public modifier on private class. This is defintely more consistent. Is this the version that comes from a gradle4 approved \"starter\" and not a hand crafted response?\nI just want to make sure this is \"blessed\" gradlew generated code. I left it in to allow easier migration BUT I think we should break it\nthat is implementors of ExecutionStrategy are required to produce promises\nWe can keep the outer ones in place as \"sugar\" for people who just want a ExecutionResult direct. see above. removed. changed. Yup - good catch. done. I can see your point regarding logging.  For those that want highly tailored logging, having libraries do logging is painful.\nBut the opposite is true.  For those how just want it to function out of the box, then sprinkling logging helps them\nI think a different PR should consider the logging aspects of the library. This puts OSGi manifest instructions in place for those that use OSGi based systems\nIn this case the jar gets\n```\n\nviewmf build/libs/graphql-java-2017-06-29T10-48-10.jar\nManifest-Version: 1.0\nBnd-LastModified: 1498697292000\nBundle-ManifestVersion: 2\nBundle-Name: graphql-java\nBundle-SymbolicName: com.graphql-java\nBundle-Version: 2017.0.0.06-29T10-48-10\nCreated-By: 1.8.0_71 (Oracle Corporation)\nExport-Package:\n    graphql\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql.execution\n            graphql.execution.instrumentation\n            graphql.language\n            graphql.schema\n    graphql.execution\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.execution.instrumentation\n            graphql.language\n            graphql.schema\n    graphql.execution.batched\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.execution\n            graphql.schema\n    graphql.execution.instrumentation\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.execution.instrumentation.parameters\n            graphql.language\n            graphql.validation\n    graphql.execution.instrumentation.parameters\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.execution\n            graphql.language\n            graphql.schema\n    graphql.introspection\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.language\n            graphql.schema\n    graphql.language\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.schema\n    graphql.parser\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.language\n            graphql.parser.antlr\n    graphql.parser.antlr\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            org.antlr.v4.runtime\n            org.antlr.v4.runtime.atn\n            org.antlr.v4.runtime.dfa\n            org.antlr.v4.runtime.tree\n    graphql.relay\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql.schema\n    graphql.schema\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.execution\n            graphql.introspection\n            graphql.language\n    graphql.schema.idl\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.language\n            graphql.schema\n            graphql.schema.idl.errors\n    graphql.schema.idl.errors\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.language\n    graphql.schema.validation\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.schema\n    graphql.validation\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql\n            graphql.language\n            graphql.schema\n    graphql.validation.rules\n        version=\"2017.0.0.06-29T10-48-10\"\n        uses:=\n            graphql.language\n            graphql.schema\n            graphql.validation\nImport-Package:\n    graphql\n        version=\"[2017.0,2018)\"\n    graphql.execution\n        version=\"[2017.0,2018)\"\n    graphql.execution.instrumentation\n        version=\"[2017.0,2018)\"\n    graphql.execution.instrumentation.parameters\n        version=\"[2017.0,2018)\"\n    graphql.introspection\n        version=\"[2017.0,2018)\"\n    graphql.language\n        version=\"[2017.0,2018)\"\n    graphql.parser\n        version=\"[2017.0,2018)\"\n    graphql.parser.antlr\n        version=\"[2017.0,2018)\"\n    graphql.schema\n        version=\"[2017.0,2018)\"\n    graphql.schema.idl.errors\n        version=\"[2017.0,2018)\"\n    graphql.schema.validation\n        version=\"[2017.0,2018)\"\n    graphql.validation\n        version=\"[2017.0,2018)\"\n    graphql.validation.rules\n        version=\"[2017.0,2018)\"\n    org.antlr.v4.runtime\n        version=\"[4.5,5)\"\n    org.antlr.v4.runtime.atn\n        version=\"[4.5,5)\"\n    org.antlr.v4.runtime.dfa\n        version=\"[4.5,5)\"\n    org.antlr.v4.runtime.misc\n        version=\"[4.5,5)\"\n    org.antlr.v4.runtime.tree\n        version=\"[4.5,5)\"\n    org.slf4j\n        version=\"[1.7,2)\"\nRequire-Capability:\n    osgi.ee\n        filter:=\"(&(osgi.ee=JavaSE)(version=1.8))\"\nTool: Bnd-3.2.0.201605172007\n```\n\nps. that viewmf tool is a homegrown tool - not a public tool. In a split world, the data fetching environment is not available any more at this stage. This could be the general basis for a future \"async\" version that is breath first like the reference implementation. its in groovy test package. sure - its in groovy test package not main API. removed. done and renamed. This is painfully missing in Java :(\nThe ability to wait for a Collection support should be present. Notice here how we have a materialised ExecutionResult and then we wrap into a completed Future\nso that to the outside it looks like asynch promise?\nI am not sure of the value here.  It allows thenApply style composition but it nots async all the way down.\nThat said I guess it allows other strategies to be more or less asynch and hence the signature is in the right shape.\nActually as I type this, it makes me see how this is useful. The join will throw the NonNull exceptions and so here.\n. One decision we need to make is whether to use CompletionStage or CompletableFuture (or a mix of both)\nStandard Java best practice says use the interface CompletionStage.  Except you can never get the value of a CompletionStage and so you have all these .toCompleteableFuture() calls\nSince this code base is all about materialising values (eventually) perhaps we should use CompletableFuture?\n. We will want a specific NonNullNull field test in the equivalence tests say. This is one contentious aspect of this PR.\nThe most basic way to execute a query (just the string) was deprecated.\n50 of our tests are now invalid.  It tells me that we need a simple bit of sugar to allow an easy way to get going and then have the ExecutionInput as the way to do it in a more complex way.. groovy and java closures are not so sweet :(. There is already a graphql.ExceptionWhileDataFetching exception.  I dont think we need another one one with such a similar name\nIt could be refactored to take an error message say.\nor create a new BatchedDataFetcherException since this error is BatchedExecutionStrategy specific\n. I understand your concern here.  That is you want to get specific logic in place inside the \"Callables\" that get run.\nBut can you do all this via having your own custom ExecutorService?\nHere its calls  callableWrapper.wrapCallable(fieldResolverCallable);\nwhy can you do that INSIDE a custom executor service you wire in?\n customExecutorService.submit(fieldResolverCallable)\n\nThe result would be the same no?. nit - the project uses expand all imports. the contains here is going to be object equality since they dont have hashCode / equals methods. We MUST have the Map call here \nif (source instanceof Map) {\n   return (T) ((Map<?, ?>) source).get(propertyName);\n\n}\nPlease put this back. Do we have tests for Boolean and boolean fields already (I dont have code in front of me)\nIf not can we add them\nAlso doesnt beanUtils handle \n boolean getBooleanMethod\n Boolean getBooleanMethod\n boolean isBooleanMethod\n Boolean isBooleanMethod\n\nCan we add tests for those please\n. Bah - some how I have changed my IDEA settings :(. I ran this code locally and it NPEs when the definition is null\nxxxx.getDefinition().getDirectives()\n\n. The tests should cover this. Yeah the test coverage here is not wide enough.  It does not cover the 7 different types of objects. Make sure graphql.NonNullHandlingTest works as well.  Currently we are using graphql.execution.NonNullableFieldWasNullException as a way to jump out of a flow but adjust behaviour.\nBy going full async the order of field evaluation is now changed since evaluating A -> B -C can now be in any order\n. We have to agree on a JavaDoc set of settings\neg: lines between @params or not.\nYou and I are flip flopping here.\nI argue for lines after each section but... lets make a decision and document it into the project README. IDEA tells me that a lot of this code is repeated from AsyncExecutionStrategy - can we create a static OR a AsyncExecutionStrategyHelper common helper that an be used ot contain the common code\nSame below on error handling. Again IDEA says this is repeated code.  Can it go into a common place.  Even into ExecutionStrategy perhaps as a protected method for this code. Check out the testing library awaitability\ntestCompile 'org.awaitility:awaitility:2.0.0'\nhttps://github.com/awaitility/awaitility\nexamples where I used it\nhttps://github.com/graphql-java/java-dataloader/blob/master/src/test/java/org/dataloader/DataLoaderTest.java#L87. awaitability makes this much cleaner. We need to explain to people that DataFetchers can returns CFs and that they will be chained ok.\nThat needs to go on DataFetcher and in the general documentation.\nI think the doco should have a \"aasyncrhnous support in graphql\" section (but not in this PR). I think this should accept a CompletionStage at this specific point.\nWhile the JDK only has 1 implementation, people can write their own.\nhttp://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletionStage.html#toCompletableFuture--\nThe toCompletableFuture is provided as a interop to allow 2 different CompletionStages to interop.\nThis would be a tiny minor thing to be honest since the work around is for them to call toCompletableFuture() themselves in the DF.\n. I think we need to fix Instrumentation up.  \nhttps://github.com/graphql-java/graphql-java/issues/601\nWe would use .whenComplete((result,throwable) -> ....) to do this.\nThis does not have to go in this PR. Do we have a test some where that tests how a mutation switches back to query strategy once the first level is resolved?\nThis will be more important with async if we get it wrong. Can we get some JavaDoc on this please. This will change with the other PR to collapses these methods. Not true.  While the internal current code only checks objects, if you want to write \"field selection capture code\" then you need to be able to capture Interface objects.\nWithout this we cant capture all the fields in a selection as show by the tests\n. right its because we want selection sets on Interfaces as well.  Otherwise anything that is described by an Interface will not be seen by the DataFetchingFieldSelectionSetImpl and FieldCollector\n. Actually the other PR might include much of this.  . @andimarek - graphql.schema.DataFetcherSelectionTest\nThe queries used are of an interface type (eg Character) and as they are executed, the interface type needs to be examined for \"fields\". This pattern is interesting and a little hard to grok at first.  But if you want A -> B ->C I guess you have to. OK - its just that you have it defaulting to null via \nexecutionResult completedValue = future.getNow(null);\nPerhaps we need an assert then\n. done. done. Now this is quasi controversial.  Its a test dependency to prove that one could use a batch loading strategy inside graphql via Instrumentation. This guy can be deleted in a future commit. This makes it easier to create Instrumentation instances because you only have to override the methods you want. common test code. This is interesting in that its quasi testing another library, that is the java-dataloader. \nBut it really demonstrates that the lower level graphql-java library is able to compose in behaviours via Instrumentation.\nThe alternative to this whole PR would be to have people have custom derived execution strategies where as this allows composition over inheritance.  Any ExecutionStrategy can be used and the behaviour can be inserted via Instrumentation.\n. These numbers are startling.  In  a naive world where you need to make a HTTP call to get \"character\" data you would end up with 15 HTTP calls.\nHere we have at most 5 calls and if you have a HTTP API that accepts multiple 'character ids' then we only make 3 calls to it.\n. refactored this common set up code into TestUtil. Can we please out the parallelStream() call.  It does not offer much benefit and causes a stream to possibly cross threads.\nMany server environments are sensitive to arbitrary code just running on ForkJoin.commonPool()\nIn this case you are likely to have < 10 messages.  There is no benefit given the possible problems. can we put '' quotes around the variable bits.\n\"argument 'bar' with value 'IntValue{value=12345678910}' is not a valid 'Int'\"\n. I say this because our system inside Atlassian hate this kind of thing.  New threads means out code in not in control.\nSee: https://dzone.com/articles/think-twice-using-java-8\n. Rather than have 2 classes (that get used in a specific place versus the underlying ValidationUtil why not\nhave ValidationUtil collect error messages and if no calling code gets them via getErrorMessage() then so be it\nOne less class to maintain.\nThoughts @andimarek ?. Ahh must have missed this doco update.  I think this is on master so I am unsure why this comes up as a diff. removed. This should not be possible if validation catches the unknown field (which we have tests for) but belts and braces. np. sure. JavaDoc weirdness here I think. Maybe use where: data driven tests and input a series of different depths.... just to be sure . fix. I am guessing you are going to fix this up.  I think you should. JavaDoc. JavaDoc. Javadoc is wrong here:  talks of max Depth\ncopy pasta?. Previously the operation node extraction happened inside ExecutionContextBuilder.build()\nI have pulled this out because I want to refactor more in a later PR to allow \"business rule validation of variable input\" and hence we need the operation (and variable defs) before we build the execution context.\nSome of the attributes changed because they were only passed to allow this parsing.  By moving it here we dont need to pass them on any more.  For example Document.  Its only used for the getOperation say.. This has been moved up and out into Execution.  See above\nBoth are @Internal code so its safe. Got rid of the isValid since its does nothing and am looking to replace it with a call back system in a future PR. Since we keep repeating this code, perhaps we should move it into Introspection as a utility function one day. The test from the other PR. One advantage is for consumers in THEIR testing since they can more easily mock an interface than a value class.\nAlso in this case I had helper methods (mkError) and that is nicer behind an interface I think\nI think we should err towards interfaces in general. will do. Ahh you are right. A quick test reveals\n```\n        def query = '''\n        query VarTest($stringVar : String, $intVar : Int, $inputDataVar : InputData, $idVar : ID, $fmt1Var : String) {\n            field1(inputData : $inputDataVar, id : $idVar) {\n                ...fragOnField \n                ... on Information {  informationString (fmt1 : \"inlineValue\") }\n            }\n        }\n    fragment fragOnField on Information {\n        informationString(fmt1 : $fmt1Var)\n    }\n    '''\n\n```\nhas 2 fields called logically \\field1\\informationString both with different values.  Hmmm\nOne way would be for the map to be Map> where we have mostly 1 item but there can be N.\nAnother though is that is becomes just a > and you have to iterate thought them yourself.  They all have path attached inside them so they can be address more meaningfully than just \"field name\"\nWhat other thoughts do you have on how we can address this design challenge.\n. Thinking about it more - why not do both?\nThats what I did. Mostly moved this up in the file so its near where it gets called and tweaked the DF fetching to use the Async code. The following is moved upwards near it call site. A list but with extra info. Yup - full  validation gives\nValidation error of type FieldsConflict: alias2: they have differing arguments. The use of AbortExecutionException is our special exception type.\nThat is if your Instrumentation / DataFetcher throws this, then it instructs us to do a partial result (if you have entered execution proper that is)\nI did another commit that adds the DF support\nSo it becomes a special \"signal\" to stop execution once it has begun.\nCompletableFuture.anyOf(futures) is no good since it waits for any one of the outstanding work to be done.  Whereas we want immediate return I think. Ok I get your point better.   I will have another go at it using CFs and understanding the exceptions inside the CFs.\nAs for the case of a  DataFetcher returning a CF which completed exceptionally with a AbortExecutionException this would not be possible (in AsyncExecutionStrategy) since its not shortcutting anything.  We would not known until it completes that we should shortcut execution and hence we would wait for .join() and it would be all to late\nNot sure CFs with Intrumentation makes that much sense.  For things like \"timing and logging\" you want it to happen at the time we start and actively complete once the inner CF completes.  A CF inside a CF is too hard to co-ordinate I think\n. Ok looking into this more, I cant see how we can do it for AsyncSerialES (because it does them one at a time and hence can short circuit) but I cant see how you can do it for AsyncES\nIts code is basically\n        for (String fieldName : fieldNames) {\n            List<Field> currentField = fields.get(fieldName);\n            CompletableFuture<ExecutionResult> future = resolveField(executionContext, newParameters);\n            futures.add(future);\n        }\n\nand then \nAsync.each(futures).whenComplete(handleResults(executionContext, fieldNames, overallResult));\n\nSo you have fired off N fields at one time and then you wait for them all the complete.\nBut partial result with shortcircuiting is the opposite of that.  You need the call to  resolveField(executionContext, newParameters) to be able to tell you that it wants to shortcircuit.\nExceptions are that short circuit.  You could invent some dual type that is Either<CF<ExeutionResult>,ShortCircuitInfo> but really that's what exception is in Java\nI dont think you can \"interupt\" execution (while capturing a paertial result) without using exceptions. Ahh yes - good call - will do. done. Great point - on it. done. done. Can you please fix up * imports to be how they were before . For other reviewers.  This is the change.  That is the contraint type is unwrapped from non null whereas before it was not.  I had  a hard time picking this since the (albeit better) renaming hit the change. Technically this interface is invalid.  The spec says that an interface MUST have 1 or more fields\nhttp://facebook.github.io/graphql/October2016/#sec-Interface-type-validation. updated. Sorry I am old  and learnt to type  on mechanical typewriters and Mrs Cleary taught us that double spaces after a period are how you do it.  Its burnt into my muscle memory. ;). small refactor the make the methods more clear. allows backwards compat. never used according to idea. This was used in at least 2 spots (again according to IDEA) so I moved it into a common place with better common logic and type handling. Can you please make this ConcurrentHashMap.\nI know that parse and validation are on the one thread and concurrent but for consistency can you please make it so. good call. allows the schema to be tweaked before being used in this request. so we now pass it down to methods. Allows the execution context to be tweaked before execution via Instrumentation\nVariables is one area I am thinking this would be used for. to be consistent with other objects. In principle I like aspects of this PR but we cant accept it as it as is because its using a the ForkJoinPool without the ability for some one to specify another ExecutorService.\nWhen ever code uses Threading then the ability to control the underlying ExecutorService is super important.\nManaging threadlocals and security managers and so on can be important some some people (it very much is at Atlassian where I work) and hence you need a way to inject  your own ExecutorService into the mix.\nFor example notice how graphql.execution.ExecutorServiceExecutionStrategy takes an executor service say.  This is done for that reason.\nMake this code require an ExecutorService, default it to ForkJoinPool.defaultPool() and have the static methods also take an ExecutorService.. Please reinstate the original documentation.  We want to show it more from first principles and how one might write their own async data fetcher\nFeel free to add a futher section that might say something like\nThere is a helpful shortcur in graphql-java to create asynchronous data fetchers. \nUse ``graphql.schema.AsynchronousDataFetcher.async(DataFetcher<T>)`` to wrap a \n``DataFetcher``  as such .....\n\n. Sorry to be a pain but please make this final.\nHave a constructor that takes a wrappedDF and another that takes a wrappedDF and a ExecutorService.\nUse defaulting from 1 --> 2\nThen have statics for both say\npublic static <T> AsynchronousDataFetcher<T> async(DataFetcher<T> wrappedDataFetcher) {\n    return new AsynchronousDataFetcher<>(wrappedDataFetcher);\n}\n\npublic static <T> AsynchronousDataFetcher<T> asyncWithExecutor(DataFetcher<T> wrappedDataFetcher, Executor executor) {\n    return new AsynchronousDataFetcher<>(wrappedDataFetcher, executor);\n}\n\nThis way the class is final and immutable but we have two ways of making it\nOr make it return a new AsynchronousDataFetcher via the inner method\n  AsynchronousDataFetcher adf = async(env  -> ...).usingExecutor(myExecutor)\n\nwhere usingExecutor gives out a new AsynchronousDataFetcher copy. Can we please put back the extended error message here.  We have had some trouble with this in the past (whereby people think they can pass any Java object but the spec says you cant...)\nSay\n \"Variables for input objects must be an instance of a Map according to the graphql specification.\"  . My problem here is that its correct but perhaps too terse.\n\nThe system is yelling \"I want a Int\" but its not giving any clues into what you gave. (say an Boolean accidently)\nPerhaps something like\nthrow new CoercingSerializeException(\"Expected type 'Int' but received a '\" + mkActual(input) \"'.\");\n\nString mkActual(Object input) {\n        if (input == null) {\n              return \"null\";\n        } else {\n              return input.getClass().getSimpleName();\n       }\n  }\nYes it leaks the Java idiom but it will tell you more when the bug reports starting coming in.\nDev A :  It says it wants an Int\nDev B:  And what did you give it?\nDev A: Umm...oh it says Boolean\nDev B: well there you go.  Fix that!. can we make this 6.0 please. 6.0 here as well. Sorry once again but I think input here can be null and hence a NPE is waiting to happen.\nHave a mkType() function and if its null return \"null\" otherwise this error message. Can we please copy these values into variables during contruction.\nThe reason is that certain JSON serialisers such as GSON do a terrible job on errors and if we have them as member variables (with the right names) then it works better.\nIts a simple thing to work around JSON cock ups. javadoc nitpick \n@return errors encountered when fetching data.  This will be non null but possibly empty.. I think this might be the right place.  That is there was a result fetched.  It will be unwrapped from a CompletableFuture and so on.\n\nThis is an unwrapping of that value (with error handling)\n.     if (result != null && result instanceof DataFetcherResult) {\nThis can be just\n if (result instanceof DataFetcherResult) {\n\nsince null can never be a DataFetcherResult. Can we please move this logic into its own protected method and keep this method more simple\nresult = unboxPossibleDataFetcherResult(result,parameters)\n\nI think we will want to unbox the DataFetcherResult.getData as an optional via\n  unboxPossibleOptional\n\nThis can go in that method.\nThis covers people returning\nOptional<SomeObject>\nOptional<DataFetcherResult<SomeObject>\n<DataFetcherResult<Optional<SomeObject>>\nOptional<DataFetcherResult<Optional<SomeObject>>\n\nI know this is contrived by we want to just work right and Optional does not work with graphql. Have a look for examples in the test code of TestUtils.  It has a bunch of parse helpers etc... to do all this for you.. \"\"\" triple quotes in Groovy will rock your socks off for this kind of test. Can we be defnesive here.  If it has no SourceLocation it will go bang because of the stupid Java 8 Optional.of\nCan we use ofNullable() please.  I know it should be non null but..... Can we put some more javadoc on WHY you might use this.  For example if you have a down stream gql system and you want to reflect errors or to add extra errors to a somewhat successful fetch. Can we get some tests around when the downstream error path is empty and so on and hence the current path is used as is.\nAlso should we detect if the path is exactly the same and use it instead.  eg\nImagine you are running on [hero,friends] and you get a DFResult with an error with [hero,friends] as the path. \nis it \"[hero,friends,hero,friends]\" or is it just the same path??. es is Spanish not english.  You want 'en'. groovy where: rocks!. This can be Collections.singletonList or Arrays.asList(). yes but its sugar to make all the \"deepCopy callers\" look nicer.\nRemember I did this in like 35 odd classes\neg instead of\nmemberVariable == null ? null : memberVariable.deepCopy()\n\nits\n   deepCopy(memberVariable, Value:deepCopy)\nwith casting we can make this smaller - might give that a go. sure - just that it was in 30 places before - all derived from this class.  So I made the orther places simplier via inheritance.  We can use static compostion if you like. fixed - moved to NodeUtil. So if the Builders for GraphqlObjectType are external - why is this one (and others internal?)  Did you just not get around to it and plan to make it external?\nI think it should be one way or the others but not a mix. Naming is hard - Logic doesnt quite ring true for me - XXXWiring, XXXRuntime?\n. I think you need to put together \"strawman\" examples of how you see the DataFetchers and Schema getting wired together.\nIs there a GraphqlSchemaBuilder that wires DFs and DatafetcherFactories to Fields?  By name, by direct field object?\nShould this be merged some how with the current RuntimeWiring idea which is really this already?. Another better way to do this is \nif (operationName == null || operationName.isEmpty(). I am going to accept this PR (because the old code is wrong) but if you could make another one then that would be great. Its probably ok but I would do both.  Pretty sure null if the alias is missing but beltcs and braces. If you want to use $ in a groovy multi line string, then just use ''' quotes instead.  No need for quoting the \\$. I clean up and merged `beginExecutionStrategy` and `beginFields` into one step.  There are the same thing.\n\nThe beginFields was a mistake in retrospect. . This pattern of onDispatched with a CF passed in and then cf.whenComplete() with a value is everywhere. beginDataFetchDispatch was a badly named step in retrospect.  It is called when the query operation is started hence the new name which is less confusing. This was always called at the same time as beginExecutionStrategy so I merged them.. Now with 2 call backs - One on dispatch and one on complete. This has to go. Can we please remove the commentary from the JavaDoc.  Later someone reading it won't care that it was once not performant.  They only want to know what it does.\nI dont mind commentary in code bases (I love comments) but not in the JavaDoc.\nSo it would be become something more like\nThis method returns the {@link GraphQLObjectType}s that implement the given interface type.\n\n. Again can we remove the commentary from the JavaDoc.  Its should be how to use it not its code journey.\nAlso can we please fill out the javadoc descriptions for parameters and return type.  It will generate a warning otherwise.\n. This I don't mind as commentary because its the why on a deprecated method. . I dont like the circular dependency we have here.  That is  schema.getAllTypesAsList() is dependent on coming in via SchemaUtil and SchemaUtil now depends on graphql schema having done that.\nCan we please leave is as it was, since this is now a deprecated method and not used in the performant code base. Can we have another test that demonstrates that GraphqlSchema has the same map behind it.\nThis would be in another test class.\nI know its not quite unit testing but it does ensure that a capability of GraphqlSchema has a regression test on it should we reimplement SchemaUtil and its use. One problem I have here is the mpa Map<GraphQLOutputType, List<GraphQLObjectType>>\nGraphQLOutputType has no .equals / hashCode method and hence this object equality.  Its building on sand.\nThere is a whole other design challenge as to why graphql types dont have equals methods which we can address in this PR.\nBut I would rather use Map<String, List<GraphQLObjectType>> and fix that up inside GraphqlSchema method that wraps this.  Its one more map look up but its direct and has well known hashmap semantics.\nHmmm... its maybe a moot point because all graphql types MUST be unique by name and hence tend to have singleton object types.... Hmmmm\n@andimarek  - thoughts?. Yeah it seems like the spec grammar as written is weird or wrong\nI think the intention is for\ntype Foo implements Bar & Baz & Buz\n\nnot the weird combos this would allow - but do I follow spec or commons sense?. good catch. Will make it default. ok. this is needed more for IDEA and its \"run ANLTR rule\" support but it does no harm. New naming in the .g4 generates new entry points.  But I think the name change is a little better. IDEA needs this to be able to use the \"Run Rule\" plugin that helps you run the grammar interactively.  Without this you can do that.  It does not work out the transitive dependency\nHowever at actual generation time, it works out the transitive dependency ok.\nSo its harmless but really helps in development that you can run the rule interactively in IDEA.\nCheck it out.  Its a cool IDEA feature\n\n. ok'\n. ok. yes it would. Turns out its 1/2 java 8 and 1/2 groovy - that is the lamba is groovy and the stream is Java 8\nThe trick is remmebering all the extensions\nhttp://docs.groovy-lang.org/latest/html/groovy-jdk/java/util/List.html. Ok - so that is in the other PR to be honest #935 \nhttps://github.com/graphql-java/graphql-java/pull/935/files#diff-f7a2f15780b23ce3535e874aefd70ec2L30\nI need #935 in place first and then this schema gen extensions.  I extended the 2nd branch from the former branch to allow progression.  But if your happy with this on this branch - you get 2 for one\n. I am happy to change this to be consistent, that is throw a CoercingParseValueException for parseLiteral.\nThat way is way more consistent. No - its a lambda changing the outside variable.  So it has to be final or effectively final.\nUsing AtomicRef allows you to bend this rule.  That is I can call the lambda and allow it to have side effects.\nIdeally the code would have been structure so that its free of side effects  (calling all the way down) but it wasn't and I judged a complete refactor as too much.. So whats intresting about this PR is that its giving off a non spec compliant ReactiveStream\nhttps://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.2/README.md#specification\nThat is the rx stream you get does not follow all the capabilities a true stream should have .  This is a great read on that\nhttps://medium.com/@olehdokuka/mastering-own-reactive-streams-implementation-part-1-publisher-e8eaf928a78c\nYou would need to have Rxjava / reactor.io to get a truly 100% reactive Publisher.  We get that in subscriptionsbecause we delegate to some one else to give is the Publisher\nBut.... here is the thing.  The shape is perfect for sending a stream of results later.\nThat is the onNext() callback shape and the subscribe() call is perfect.\nThe subscribe() call is when the down stream subscriber has connected to the publisher.\nThis is the perfect time to start the running of the deferred calls.  If the caller has the Publisher then it must be ready to get further results.  As soon as they call subscribe we can start executing the queue of deferred fields.\nAs each one finishes, we send it down the pipe as a series of onNext calls.\nThis is why the Publisher shae is so great even though its not a 100% reactive generic implementation.\nSo the subscription object we give them is empty.  We wont have any back pressure on the deferred fields say (they cant ask for 2 and then ask for 2 more etc..)\nWe could invent a way for some to SPI plugin an actual Publisher say - but I am unconvinced yet that its needed.  I mean how many deferred fields will you have?  10s, 100s or 10,000?  Its the low number not a high number where you need back pressure\n. key with the deferredCalls queue is that it executes in \"encountered order\".  So we KNOW that any inner calls that might cause deferred fields will be simply added to the queue while executing the parent path.\nso\n  parent {\n       child1 @defer {\n               x\n               childChild1 @defer {\n                   ...\n               childChild2 @ defer {\n                    ...\n               }\n      child2 @defer {\n              ....\n\nwill result in a queue of [child1, child2, childChild1, childChild2 ] and the latter grand children will only be added when the call to child1 is made and they go to the end of the queue.. just to help while debugging. Path is tracked by the traversal context and these little factory methods make errors that add the path. Collapsed this back into AbstractRule since it was 1 method only. Well the spec says that once it boils down to an error it must be List\nSo I went straight to that since this is internal code. This come almost word for word from graphql-js. done. done. To make this threadsafe - invent a new type that encapsulates level + count and make that have read / write locks.. Clearly the printfs need to go at some stage!. The above is the possible contentious change. \nIt comes about because a argument can have a \"possible default value\" and an actual value AND in 2 different contexts.\nWhen we have a query like\nquery {\n    field (arg : \"123\", arg2 :$var)\n\nthen the argument values ONLY ever come from the AST literal or variables map.\nBut in DSL directives, we have an actual static value and NO variables map.\ntype Query {\n    field : String @directive(withArg : \"argValue\")\n}\n\nThe above can also have a default from a possible directive definition elsewhere is SDL.\nI chose to have it this way after debating naming and so on.  Previously a made getDefaultValue() hold the actual value but this is semantically wrong.  I can see now that it was wrong.\nSo I created the getValue() method but know its never called in \"query context\".   It could have been called \"getDirectValue()\" or some such but I couldnt make up a name that made it any clearer so I opted for the most straight forward name. A future change could make DirectiveLocation be its own top level class but thats really API breaking. by default its off.  This allows people who used @directives before to continue to work. I would not call this DispatchedBatchLoader - its too confusing\nThis tracks a \"dispatched data loader call\" so perhaps DataLoaderCall / DataLoaderDispatchCall or just DispatchCall. These methods should go in the FpKit as generic list twizzlers. Again the name DispatchedBatchLoaders is loaded (to excuse the pun)\nSince this rolls up  a series of calls and waits for them all perhaps the names\nCombinedCalls or CombinedDataLoaderCalls or OutstandingCalls. I cant decide if I love the bum syntax (\u203f\u02e0\u203f) or hate it.\n CompletableFutureKit.allOf(futures).whenComplete((ignored, ignored2) -> run.run());\n\nThat will pass IDEA warnings just as well\n.     dispatchDepth > 0 ? dataLoader.dispatch() : completedFuture(emptyList())\nYou dont need this.  dataLoader.dispatch() does nothing and returns an empty list if there is nothing to do\nSo just\n   return new DispatchedBatchLoader<>(key, dispatchDepth,dataLoader.dispatch()); .     this(depth,emptyList()). key is never used. Thanks - will change it to Class.getName(). fixed. why does this dissapear??  . JavaDoc - all the really important interfaces should have JavaDoc. I disagree.  I don't think the mental cost is worth the benefit. . will do!  updating now\n\n. Looking into this..... ok will do.  Not this will break people who have used directives already and \"hand\" rolled behaviour.\nWe will also need exceptions for @deprecated which can be considered an implicit directive. Good pick up.  Will add a unit test for merging since clearly this code has not been run. why take this away? Its Public API!. This concat, stream / flatmap has 7 lines an of code and the procedural one above has 6 and is way easier to understand.\nWhy change it other then just preferring it this way?. Can we please change the default from IntStream.UNKNOWN_SOURCE_NAME (which equals the string \"\") and change it to null.\nMy reasoning is for non SDL documents.  Today a graphql query will get errors without this value and with this PR it will say \"\"\nMost Object -> JSON conversions will leave out null columns, so null will mean the JSON output doesn't change for client queries.\nIts a change of least impact this way to existing clients. please default to null. Yeah my point is not at the parser level but within the SourceLocation object.\nThe SourceLocation is sent back in the error objects.  Today there is no sourceName attribute.  Your PR adds one.\nSo the JSON today will be\n errors : {\n    message : \"x y z\",\n    locations : [\n        {  line : 10, column : 9  }\n   ],\n }\n\nwith your change a bad client query (as opposed to SDL) will send back\n errors : {\n    message : \"x y z\",\n    locations : [\n        { sourceName : \"<unknown>\", line : 10, column : 9  }\n   ],\n }\n\nBut the client knows the source - the query it just sent.\nCan we default it to NULL IF the source name is the magic constant\neg\nString sourceName = startToken.getTokenSource().getSourceName();\nif (IntStream.UNKNOWN_SOURCE_NAME.equals(sourceName)) {\n   sourceName = null;\n}\n return new SourceLocation(startToken.getLine(), startToken.getCharPositionInLine() + 1, sourceName);\n\n. Remember the same grammar and parser is used for both queries and SDL definitions. Maybe put a builder on QueryVisitorFieldEnvironment.  It will allow it to evolve more easily over time.. JavaDoc??. Put a Builder on this and make the constructor private.  This allows for better API evolution over time. JavaDoc??. Add a builder. Add a Builder. Another way to do this in Java 8 is just use default methods on the interface.\nI am still 50/50 on whether this is a good idea.\nI do like your naming here.  Better than NoopFoo. * import???. Should you talk about order here?? pre order etc...??. will do\n. I dont think there is any need.  We only want to know if its a CF so we can do the mapping function later.  If its Optional / DataFetcherResult then it will be handled by the execution strategy code later.\nThis is very much about composing a DF to it can call back a mapping function with the original DF environment and the returned value\n            def newFetcher = wrapDataFetcher(field.getDataFetcher(), { dfEnv, value ->\n                def directiveName = directiveEnv.directive.name\n                if (directiveName == \"uppercase\") {\n                    return String.valueOf(value).toUpperCase()\n                } else if (directiveName == \"lowercase\") {\n                    return String.valueOf(value).toLowerCase()\n                } else if (directiveName == \"mixedcase\") {\n                    return toMixedCase(String.valueOf(value))\n                } else if (directiveName == \"reverse\") {\n                    return String.valueOf(value).reverse()\n                }\n            })\n\n. will do. Yeah I mostly agree however in this unit test I KNOW that the CF is already completed.  By design I know its finished and not async\n. Point taken though. I do.  see def \"will trace down into each directive callback\"() {\nIt asserts that each call back has a certain shape and that they are called at all.\nIt exercises all the known callbacks. I think generally the graphql-java should use builders on PublicAPI elements because without it the constructor becomes public API and over loading is your only way to construct things\nIn this case I would do QueryTraversal.newQueryTraversal() and have an internal builder of them. Without a builder the constructor is public SPI. Did you want this commented out???  I would remove it. Naming is hard \nbut GraphQLInstanceException is not grabbing me.\nThe Instance bit doesn't sit right with me'  \nSo I agree design sentiment but its the name that is throwing me.\nSuggestions:\n\nGraphQLExecutionException\nGraphQLRuntimeException\n\nAlso looking at the bullet points below it seems we do have 2 classes of \"runtime /execution\" exceptions\nOne class that deal with the \"schema - building+validating\" and one class that deals with the \"execution\" of a query (after validation / parse)\nSo should we split them into say\n\nGraphqlSchemaException\nGraphqlExecutionException\n\nThoughts @andimarek . I like the naming here :). This one feels like a GraphqlInstanceException no???. This is where I would like to have the \"schema exceptions\" instead - for this class of exception around building and validating schema. Or just collapse it out by removing the GraphQLRuntimeException\n```\n                                                 GraphQLException\n                                                 +\n                                                 |\n              +-------------------------------------------------------------------------------------------------------+\n              |                                  |                                     |                              |\n              |                                  |                                     |                              |\n              v                                  v                                     v                              v\n  GraphQLQueryException                 GraphQLExecutionException       GraphQLExecutionException            AssertInternalException\n```\nEither way is fine by me.  Thoughts @andimarek ?. This ones weird because there is a long standing need to abort the \"query\" before execution (like these complexity cases) and an unsatisfied need to let a data fetcher abort the query which we don't have today but would like\nSo as it stands today the hierarchy is right..but I am thinking into the future on whether we want to reserve this name for an as yet unused feature. We chose to have the toSpecification to allow you to build a result that perfectly follows the spec. fair enough. I would move this out into its own top level class.  These files are already large enough.. Oooh nice code. For the record I dont think you need to declare these as paremters to the method.  Groovy seems happy to just take them as implicit variables by name\nNow whether this is \"better groovy\" I dont know but the other tests that use a where: construct dont do this. Would you agree its tricky? ;). ta\n. JavaDoc on key types would be needed. I find this one a real stretch in terms of saying this is \"better\"...There are 2 conditions -scalar and enum and there is some unwrapping to be done.\nIf I look at this code is an indirection that is low value.\nThat said the others have more value. Java Doc and @Internal of @PublicApi  would be needed. In theory - perhaps\nbut in practice, given a graphql type it can only be 1 of 6 different types (enum, scalar, object, input, interface and union) or the wrappers like (list, null, type reference)\nSo in order to blow the stack given a single graphql type, then you would need megabytes of wrapping\neg [![![![![![![![![![![![![![SomeTypeHere]]]]]]]]]]]\nGiven a simple graphql type there is no infinite tree.\nNow if you include graphql.schema.GraphQLFieldDefinition (which does not derive from GraphqlType) then yes you can have a large tree.\nMy point is that not ALL uses case of recursion are problematic.  And in this case where we have a single GraphqlType, not at all.. There is enough visitor code here that it deserves its own file.\nPerhaps not one class per visitor so I would create a package protected holder of these classes called say \"TypeVisitors\" that contained these classes. please put these at the top of the file.  Bit more idiomatic. Simple JavaDoc please.\nThis probably deserves to be @PublicApi eventually (as a help to write a visitor). Naming is hard but I would call this (and the others) GraphqlTypeVisitor\nMy reasoning is that we have runtime types and AST types and its already confusing\nSo we have GraphqlType / GraphqlObjectType and so on to help with that\nHence I visitor of GraphqlType thigns should have the GraphqlTypeVisitor naming.  Same with the stubb and so on. Also naming as mentioned above GraphqlTypeVisitorStub. This is written by the gradlew wrapper task itself.  I just accepted what it wrote.  I never typed this. will do\n. will fix\n. good catch. protected. I really think you should always have { open and closing braces.. Checkout https://github.com/graphql-java/graphql-java/blob/master/src/test/groovy/graphql/TestUtil.groovy for a testing helper that does parsing and schema generation in tests.  Mostly for future reference. good catch. I would move ALL date parsing into the helper below. Since this is an @Internal class, kill the old constructor and make an hard assumption that ExecutionInput is ALWAYS non null.  No need for the Optional. nit: schema != null would be a better assertion I think.  Reads a little nicer . getChildrenWithName or just getChildren is a better namer I think.  You know its a List from the return type. Only if you use this constructor directly.  If you use the builders then it works as it always did\nI am happy to target only master if you like. This is bad.  I think I need to get rid of this.  I created this PR directly from git hub, not from the command line.\nI think we will want to remove this. This is not needed for this PR technically.  But I need it for another so bear with me.\nIt allows side ways movements of paths\nhero/name --> hero/id\n\n. Do a detection. \nif (e instanceof RuntimeException) {\n     throw (RuntimeException) e;\n} else {\n   throw new RuntimeException(e)\n}. Java doc please on this and how graphql will generally react. JavaDoc please. As much as Optional is a better pattern, its mixing styles on this class.  We already use null via getArgument() (because it predates Java 8) so I think we should stay consistent to the other methods in this interface. Can we make put this into a DirectivesUtil helper class so its simpler to read and easier to test\nMap<String, Map<String, Object>> directiveArgumentValues = DirectivesUtil.readDirectiveValues(field)\n\nSee graphql.DirectivesUtil. Not sure about this change.  Some one else wanted this in for Netbeans something something.  Did you mean for this to be changed??. This sets it to oldValue + value and not just value like it did before. I might want to change this to prevent broken API for those who called create direct. need to kill this method.  Not used. fix this. yes - it should always be a new DLR - this pattern is to try and encourage that. right - we always have a  DLR in play. yes we always have one in play. sure. I did the extra new DLR here JUST in case some one created it by hand because it was a public method. fixed. But since this is already a breaking change - I am going to clean this up by removing the old public constructor.\nOur code should be the only constructor of these things. good one\n. I incorrectly added these extra cases.  They are no longer valid. Rather then have a convenience method here - why not just make the callers user GraphQLTypeUtil.unwrapNonNull() say.\nIf you want to keep this method then I would call it getUnwrappedNonNullType \n. JavaDoc?. This is internal.  Should it be?  Since we now expect people to twizzle types themselves??. Actually thinking more about this.  Rather than logging what if you want to do some other action\nIt could be a Function<Boolean,ComplexityInfo that returns true if the abort exception should be throw say.\nThe use of a function would allow people do do other things like log or call statsd or react in some other manner.\nThe ComplexityInfo here is a builder built object that contains the complexity count.  Passing just int means we cant add more \"parameters\" at  a later time so we prefer wrapper objects with builders. That JavaDoc is strange.  I would rather words than leet.  \nCreates a new instrumentation  that tracks query depth. Can we have some JavaDoc on the semantic of the function.  That is IF it returns true the query will be aborted. I think this should be a Map<String,graphql.schema.GraphQLDirective>\n\nThat is a field has a map of named graphql.schema.GraphQLDirective objects.  From that you can get the arguments and the values to this arguments.\nWe have other code somewhere (off hand) that helps create that. This was stopping the command line version from building ebacuse of JavaDoc errors.  Clearly our builds dont run the same profile of JavaDoc as I do.  Not sure why. Broken windows fix. fixed. There is some groovy bugs where streams dont work on Java 11 - I am not 100% sure of the reasoning but re-writiing makes it work. complains as a bad method name. Should this be a default method or a marker interface that some one implements?  I like this because subclassing is easier. What should the default be?  include ALL fields by default or exclude trivial fields byy default?. Decided to keep current behavior for completeness and allow people to opt into less information if they choose.  So default is that trivial fields ARE included by default. I think we retain null-ness (for consistency) OR we start to make the move progressively\nBecause there are MANY MANY places that return null in the code base. Maybe some things around method naming and comments.  You posted some stuff on EAC once about that which I quite liked. This can be simply be\n public class PropertyDataFetcher<T> implements TrivialDataFetcher<T> . Just moved the comment in a bit. yes it is - we could get rid of it I guess but we do this in other places. This will need to be removed at some stage right?. whats with the `//` bit - is it in or out?. personally I dont think these messages on asserts add value.  If it DID blow up - it was would obvious that this line is offending.  There is no insight to be ahd I think.\n\nAnyway not a huge problem but I would just do assertNotNull(someField). public API??\nI guess it is by proxy. nice catch. javadoc??. andi-reactor code! ;)\n. javadoc eventually. javadoc on purpose eventually. private scope and final??. Common seems like a kitchen sink class.  Is there not another home or a  better named class maybe.\n. We have FpKit already for some of the methods.  I would move them there eventually. Why the execution2 path.  Why not called leave it in graphql.execution and rename the class.\nis this intended to be the packahe on going.  graphql.xxx2 smells to me. private final??. if we want a side line package for good reasons - then I like graphql.executionng as in next generation rather than 2. should this not be in graphql.execution like its created object??. Do we need all these Tuples classes.  They seem unused at present?. fixed. fixed. Yeah thats a bloody good idea.  It would make it more readable!. I still think ExecutionStepInfoFactory should be a singleton that takes the per request things (execitionCOntext et al) as parameters. do you want this commented out code??. JavaDoc on its reason for being. make it abstract and they will have to!. again make it abstract eventually to enforce this precondition. I love this pattern.  :). What about a newXXX version of this\npublic static ExecutionStepInfo.Builder newExecutionStepInfo(ExecutionStepInfo existing) {\n        return new Builder(existing);\n    }\njust for completeness??  We do this in other places I think. final\n. still stand by this comment\n. getChildOrNull might ber a better name. remove this when you are done. > make the class public. It is marked as Internal, so everybody can choose.\nBut it does a specific job.  That is a visitor that finds all the \"code\" spots and transfers them to the code registry\nIn a later version when we stop people putting the \"code in the types\" then this class can die OR at least become a checker (that you HAVE a type resolver for each type).  Again a job that is internal and not for every one.\n. as for naming this code - sure - what about CodeRegistryVisitor - since this is what it does.  Visits types to find \"code\" in them and build the code registry. Yes - but one breaking change per release.\nThis released we break the ability to \"read\" a fetcher from a field.  The next release we remove the ability to \"set\" a fetcher onto a field.  \nI have deprecation in place and hence we can do that in MAJOR version + 2. I do \n codeRegistry.typeResolverIfAbsent(node, typeResolver);\n\nThis will put a type resolve against that type UNLESS it was previously seat directly by other code (eg direct put). TODO ^. TODO ^\nI think you put in a supplier of the Map. better assertion message - eg state the precondition better or have no message. not sure on the CHILD_ smurfing\nThe thing that represents \"arguments\" could be called arguments. This one does not seem to be finished.\nIs this a BUG?. Yeah - defintely common method if this is needed\n@Override\npublic NullValue withNewChildren(NodeChildrenContainer newChildren) {\n       return NodeChildrenContainer.assertNotEmpty(newChildren);\n}\n\n. bad Javadoc - its going to lead to warnings and set of my OCD on having a clean command line compile / build. Objects.equals() ??. I think the indices here are wrong.\n def leafB = midA.selectionSet.children[1] as Field\n\nhere and below. indices are wrong I think. Hmmm this got missed some how in a merge.  Its been renamed but not here :(. This does the argument conversions\n(Named like ValuesResolver). This version is used ONLY during IF directive handling where the schema is not available.   . After we have a value resolved - we convert it. Removed. Most of these changes are in fact moving away from the deprecated graphqlSchema.getFieldVisibility(). Almost deserves it is on Collector based puirely on how much boilerplate.  Perhaps its own method\nzippers.stream().collect(Collectors.groupingBy(thisGrouping(executionResultZipper -> executionResultZipper.getBreadcrumbList().size()));\n. Yeah I reckon create its own helper method. I would do static import in all the places to reduce the boiler plate\n@Override\n    public NodeChildrenContainer getNamedChildren() {\n        return newNodeChildrenContainer()\n                .child(CHILD_VALUE, value)\n                .build();\n    }. I woukld still love to see JavaDoc at the top to outline the class.   . JavaDoc. Should all this transformation code be in graphql.language or one down in say graphql.language.transformation ?\nI think the latter. is this not done???. and hence not tested??. I would create a helper method for these checks\n@Override\n    public FloatValue withNewChildren(NodeChildrenContainer newChildren) {\n        NodeChildrenContainer.assertEmpty(newChildren);\n        return this;\n    }. Are you have one.  Do it on FLoatValue. JavaDoc. JavaDoc?\nMaybe a seperate PR for the JavaDoc say. what is this crazy syntax?? I didnt know you could do this! :). Naming\nAll our builders tend to be newFoo not newBuilder.\nThis should be newAnalysis or newFetchedValueAnalysis (I would go with the former). Also since its complex - what about a transform(Consumer<Builder> consumer) method?. updated. fixed. fixed. Naming : Can we call this \"EncounteredDirectives\" eg past tense - that is on this data fetcher we have \"encountered\" the following directives.. FYI - we put the @Internal on the whole class and hence reserve it completely as an internal implementation detail. Eventually this needs JavaDoc and also the name cchange mentioned above to getEncounteredDirectives ;). @Internal goes on the whole class. Hmmm - can Field be a good key?  It has not equals / hasCode.  This collects all fields in the Document.\nBut later when we match them up we need to do it by Field instance.\nBut Field objects can be \"rewritten\" and I think this is going to do \"identity\" matching.  And we may have changed a field by execution time\nHmmm - I think this is a non starter in terms of being able to find all directives \"eagerly\" before document execution.\nI think we are going to have to collect them from a DataFetcher as is.\nIn the tests can we prove that we can have repeated field names in lower levels are still work as expected\n. cc: @andimarek ^. done. I am a fan of static imports for readability. why use null boolean as a flag.  Surely a boolean is true of false??. whats up with this class??   A static class with a field with public access???  Not great API. This is the worse outcome I think - that is the result is thrown away.  \nThis is the biggest design blocker as discussed on https://github.com/graphql-java/graphql-java/issues/806. fixed. Actually we have 6 - instrumentExecutionInput, DocumentAndVariables, Schema, ExecutionContext, DataFetcher, and ExecutionResult. fixed. nice one. fyi - to others - we have our own asserts to reduce dependencies.. Perhaps put the or else in the parameters.  More useable\nFpKit.findfirst(list, x -> isGood(x), otherwiseThis)\nCould be a supplier to make it lazy\nFpKit.findfirst(list, x -> isGood(x), () -> otherwiseThis)\n. or just return the optional and make the caller handle it.\nObject x = findFirst(list, this::isGood).orElse(null)\nThat is better to be honest. This will blow up if the look up fails.  Is it likely to?  Should it be catered for?\nDo we need a test for this?. Should it assert if not found?. What about an Add case in the mix?  Just in case delete some how shifts thing??. done. Why not use graphql.schema.GraphQLFieldsContainer as the type and not the more generic ObjectType.\nThis is what this class is for, type safe access to the fields. ignore me - its resolved as an object type. Good thinking!. Sometimes I wonder if default methods on interfaces is not a better way to do this.  eg some vistor extends TraverserVisitor but its all implemented like the above.  So you only need 1 interface type and not the interface and stub. idea suggested this change. IDEA suggested change - no yellow lines!. Grammar is off here.  Did you mean Furthermore?\n. not a bad idea - for this fix up I wont but will consider it for the future. Typically we would do with the \"transform\"\nHave a look for \"transform(Consumer builderFunction)\" examples\nit allows things like\nnewEnv = env.transform( builder -> builder.parentType(null));\nSee https://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/GraphQL.java#L209 say. Our builders dont use a \"with\" prefix.  Just make it \"Builder parentType(..)\" to be consistent with the other builders in the code base. Static imports read better with builders. Maybe name this \"addComparator\" so the call site is \"builder.addComparator()\" and hence a smidge more readable. There are  a LOT of tests here which is great.\nPerhaps its time for a new test - eg SchemaPrinterComparatorsTest . Thinds that we want to be true public API we annotate for @PublicApI.  See other class for examples. This would be public API. Annotate with PublicAPI. Since it comes directly of the DataFetcherEnv then I think it makes sense to only give out an interface.\nThat way we can hide all the builders and so on and not make them API. { hello } is now considered as 0 based not 1's based. Ahh I did not know the spec says that - I guess we need to add one,\nOnes based index are weird right?? It goes against 50 years of computing theory! ;)\n. on it\n. no - its default is true. you did that. now made it non null as an arg declaration. ",
    "mudlee": "Hi. @bbakerman may I ask how would you solve this with timeout? If I fork the ExecutorServiceExecutionStrategy or the AbstractAsyncExecutionStrategy, and extend the CompletableFutures with a orTimeout(1,TimeUnit.SECONDS), that stops the future after 1 sec, but it does not propagate the TimeoutException up, so it won't be aCancellationException, and it won't appear in the errors field in the response. Instead, it will be an InternalServerException (with using spring).\nAny (more specific) idea, how to handle it correctly?. ",
    "kaqqao": "Why not simply complete the future exceptionally after a timeout? No need to touch the execution strategy or anything. The default AsyncExecutionStrategy will do the job just fine.\nIn your fetcher, you can just do loader.load(key).orTimeout(1, TimeUnit.SECONDS) (API available since Java 9). Or do the same in the BatchLoader itself. That is if you're using DataLoader, but nothing changes significantly if you're not. You'd just get a CompletableFuture by submitting to an Executor or something (e.g. CompletableFuture.supplyAsync(...)).\nThat way, you get a future completed with TimeoutException, and the normal error handling kicks in.\nJust tried a fetcher like this (I don't have Java 9 at the moment, hence no orTimeout):\njava\nCompletableFuture<String> cf = new CompletableFuture<>();\ncf.completeExceptionally(new TimeoutException());\nreturn cf;\nAnd I got the timeout error in the result, as I'd expect. \nThere's a whole another question on actually interrupting the underlying thread (and not only cancelling the future), but that is its own can of worms.. I believe you shouldn't even need the friendId in this situation... In your profile DataFetcher, you have access to the entire source object via DataFetchingEnvironment#getSource (which would be the friend in your case), so you don't specifically need to pass the ID.\nDoes that help?\n. Ha, with the way I worded the example, you're right! I now realize just how terrible job I've done trying to explain my problem. In my attempts to simplify the explanation of the situation I'm facing, I completely butchered the example. Sorry for that. I've made at attempt at fixing it. It's still somewhat vague, but I really hope it does a better job than the previous version.\n. Well, think of Relay global ID required by the Node spec. An ID is in the User return object, but it's no longer prefixed. The prefix was used only to satisfy Relay Node query, and to know what object type is being queried for. Perhaps the received ID was created using GraphQL-Java's own Relay#toGlobalId method.\nSo the result would contain ID \"1234\" but not e.g. \"objectType:1234\".\n(Edited the title and the description to contain this info as well)\n. Actual Class might be the same, but not the Type, thus GraphQL types might differ. This can potentially be worked around if you know all your Java types ahead of time, but that is not always the case either (e.g. if you're working on a library and not project code).\nAs for the TypedUser class, that's exactly what I tried doing, but the TypedUser class has to be generated dynamically, at runtime, as the lib I'm working on has to work with types unknown ahead of time. This is both very limiting (as it requires default constructor to always exist, can't deal with collections reasonably etc) and needlessly complicated and expensive. That's why I'm proposing to simply forward most of the info from DataFetchingEnvironment to the TypeResolver.\n. I've just tried removing the dependency on our forked version of graphql-java in out project and realized it's more painful than expected as TypeResolver doesn't even give access to the schema. And since TypeResolvers are instantiated before the schema is even built, it means there's no way to even provide the schema through constructor... which either means mutability/synchronization issues with adding the schema later or manually maintaining a schema-like registry of GraphQL types. And both are rather awful :(\nI really hope the next release will bring some resolution.. I elaborated in #205. In short, yes, I believe solving this one may solve or at least alleviate #205 as well.. Yup, what JS examples do is just set the entire request object as the root context. You can do the exact same thing. Then your fetcher can get the file from the request body. Nothing for the spec implementation itself to do.. I implemented TypeReferencereplacement for InputTypes on my local env, but couldn't figure out a good way to check for circularity...\nI guess I should make a proper fork and push what I have so far so that someone else could join/comment.\n. @aschrijver\nHello ex-Backabase colleague (it's Bojan)!\nI'm also heavily investing in this project (working on a to-be-open-sourced library that I intend to use in production soon), and am currently working on fixing some of the issues I identified and impact my work, but I'm not able to continually help with maintenance.\nFor this reason, I'm planning to look into Sangria (Scala GraphQL implementation) as an alternative, as it's very active and still JVM.\n. We're currently using our own forked version of graphql-java where we added the support for circular input types (issue #172). I'm planning to polish that code and make a PR (currently on vacation, so it will be a couple weeks more before I can do it). This is currently our most important one.\nAlso, schema printer (issue #126) would be a treat.\n. @aschrijver What I do in these cases is use my own classes that extend the ones from the  graphql.schema package. Because my project maps Java to GraphQL dynamically, I store the class information with the types. Can also be used to store complexity information with the field definitions and such.\nI like the proposed approach better, it is harmless and allows one to stay within the library even in more exotic cases. The fact the reference implementation doesn't have a feature shouldn't\u200b really stop other implementations from innovating, right? Sangria has various features that the reference doesn't. Absinthe too.. - About #34 \n\nbecause TypeReferences are not always replaced with the real object .. \u2014@andimarek\n\nThis means that in the current code, TypeReferences are only searched for and replaced in the output object fields, so simply adding the interface like in #34 isn't enough, as it would still leave TypeReferences used as arguments or in input object definitions unreplaced. I.e. it doesn't always replaces them, but only in some expected locations.\nMy PR takes care of this, and makes sure they are properly replaced regardless of where they are used.\n- I can (and will) surely add some tests showing it's impossible to mix the two and that the above is true, but not really sure what you meant by demonstrating that nothing breaks... All the current tests are passing...\n. I was having trouble understanding how the current tests are organized and how they actually work... didn't have much success to be honest. I have a vague idea where to put tests for this, but could use some pointers.\n. Right now, no implementation checks for non-broken recursion. I was asking in the chat about how to implement this and gave some ideas.\nI was thinking about adding a check if the reference points to a GraphQLInputType, but since ClassCastException will already be raised if the reference points to the wrong type, I figured an additional check wouldn't add much as it can't be thrown earlier (as type reference at the time it is used, usually points to a type not created yet) nor give a more meaningful exception (ClassCastException is pretty much the correct exception you should get).\n. @brimworks Wooow, the past commits were completely unrelated and I did not intend to add them to this PR! Will fix immediately! Only the first commit was intentional. Sorry for the confusion!\nRegarding the tests, I can add them, but I need some help as to where to put the check for non-null circular references. I was thinking it should be somewhere at the end, once the schema has been already built. What do you think?\nI also absolutely don't mind you taking it over if you'd like to.\nAnd, as to why I need extra context for TypeResolver, I'll provide the rationale in a separate PR for #122. But in short, because of generic type erasure, having the resulting object alone is often not enough to resolve its GraphQL type, as multiple generic types can be mapped to multiple GraphQL types (and if you introduce Java8's type-use annotations that influence the mapping, it gets even more complex) and having extra context can help with disambiguation.. Ok, I reverted to the initial state, with just the first commit.\nNot sure if I should also re-apply the commits that were adding support for TypeReferences as possible types in GraphQLUnionType and as interface types in GraphQLObjectType. I think at least the latter is a rather important feature, as certain legal recursive types are still impossible to create without it. The former is not as important, but highly desirable as it eliminates the need to handle yet another special case.\nI just don't like the way I implemented it. I'll try coming up with something better over the weekend.. I definitely agree on the approaches you suggested.\nJust to clarify why I said I didn't like my own impl for TypeReferences as possible types in GraphQLUnionType and as interface types in GraphQLObjectType.\nGraphQLObjectType holds its interfaces in a List<GraphQLInterfaceType> interfaces, and since TypeReference is a concrete class on the same level as GraphQLInterfaceType there's no way to make one inherit the other. This would mean an extra List<TypeReferences> unresolvedInterfaces would have to be introduced, which complicates List<GraphQLInterfaceType> getInterfaces() as it couldn't return both the resolved and unresolved interfaces.\nMy impl introduced 2 extra methods List<TypeReference> getUnresolvedInterfaces() and List<GraphQLOutputType> getAllInterfaces() to deal with this, and that's what I found iffy.\nAt some point I was thinking of making TypeReference an interface which would have one generic impl that would replace the current class, and additional impls that subclass GraphQLInterfaceType, GraphQLObjectType (and whatever other class might need to be replaced by a reference while maintaining their exact type). But my brain started looping endlessly before I got anywhere with this thought \ud83d\ude1e . @brimworks Wouldn't it make GraphQLObjectType.getInterfaces() kind of dangerous? I mean, inconspicuous looking code like this:\njava\nGraphQLObjectType type = newObject()\n            .withInterface(anInterface)\n            .withInterface(aReference)\n            .build();\ntype.getInterfaces();\nwould actually break with a ClassCastException without an obvious reason.. @brimworks \nI think I understood why replaceTypeReferences is not defined on an interface. It would require the method to be public instead of package-private, breaking the immutability \ud83d\ude1e, which I think is a big deal, so I decided to leave it as is. Maybe it could go to an abstract class instead... not sure how desirable that would be.\nI've now pushed the changes I had on my branch, including ubiquitous support for references. The important detail I found out is that order in which types are discovered is important for correct replacement of references, leading to rather surprising behaviors e.g. if the query/mutation type only uses references, and the real types are provided in the dictionary, they'll never get correctly replaced. For this reason, I changed SchemaUtil.collectTypesForXX to always update references.\nRegarding the talk above, I went with the approach of creating dedicated private types for references to Object types, Interface types etc. Seems to maintain type-safety nicely without requiring special case handling, but still feels somewhat iffy.\nOn the topic of schema validation, I added something more-or-less similar to query validation, alas simpler. It still feels like an overkill, to be honest \ud83d\ude2f  It currently only checks for infinitely recursive input types, as expected.\nI also added some tests, but I feel I am misunderstanding a lot when it comes to test organization in the project (and it sure does not help that I'm not exactly good with Groovy or know anything about Spock).\nAll in all, I'm not particularly happy with my code, especially the tests, so please feel 100% welcome to change anything and everything you don't like. I'll be OK with you even completely throwing it away in lieu of your own implementation. Just do pay attention to the changes in SchemaUtil.collectTypesForXX, they're easy to overlook and are IMHO important.. It was one of my motivations behind #122, yes. The solution I proposed there is to allow TypeResolver access to the schema, so that it can get to the GraphQLType by name or other means.. It was me who accidentally pushed unrelated stuff. Reverted the wrong commits in the meantime, and added basic tests and validation. Also expanded the support for references, which can now be used as possible types in unions and as interfaces on object types.\nI took the approach of creating dedicated private types to represent references to different real types (instead of using the single GraphQLTypeReference in all scenarios) in order to preserve type safety.\nI also enhanced the type collection logic to always replace references so that order in which types were discovered doesn't influence the result. This avoids a surprising behavior where references don't get replaced just because they were discovered before the actual type.. I'm almost done implementing static complexity analysis in graphql-spqr, similar to what Sangria and Absinthe have. Implemented an AST walker, that basically does what FieldCollector does, but for the entire tree (not just one level) and accumulates the scores for the encountererd nodes, taking the worst outcome in case of conditional fragments.\nBoth the function retrieveing the complexity expressions and the expression evaluator and replacable.\nWhatever ends up in graphql-java itself, I'd argue it's of utmost importance to make it extensible/customizable, so that different behaviors can be plugged in easily. Then projects and libraries can provide concrete implementations and/or extensions.. Just in case someone cares, my implementation is ready. It's in this package, the main class being ComplexityAnalyzer. It is completely implemented using the existing API (instrumentations being the critical part).\nFunctionally, it replicates Sangria's approach, It uses JavaScript expressions for the dynamic formulas (so no dependency on any expression language), but this is easily customizable, so other languages (SpEL, OGNL, JUEL etc), calculation methods or sources of info (think of a DB with live performance analytics) are pluggable.. I believe Sangria also calculates the maximum possible depth (in case there are conditional parts) before even executing the query. This seems to be a decent approach.. Yup, I somehow forgot the ExecutionStrategy is a part of SPI. I removed the need for Java 8 as it indeed makes no sense.\nCan you maybe help me out a bit more on how you'd tackle the changes to ExecutionStrategy? Should I leave them as they are or would you like a different approach? Perhaps breaking SPI is needed now, but can be done in a more future-proof way.... Bah, the useful part of the conversation is now getting buried under the hidden \"outdated\" reviews. But I guess you'll see it anyway.\nI reimplemented the changes to the ExecutionStrategy to be backwards compatible and am now seeking opinion on how to tackle the changes to TypeResolver.. I'm confused by \n\nthe proposed implementation already returns a Future as per spec\n\nWhere in the spec has Future been mentioned? Or do you mean the graphql-java impl?\nEither case, seems to me like this reactive strategy would serve wonderfully as a backbone for implementing subscriptions in graphql-java.. I don't think there's a hard decision yet, and that the current implementation is only a proposal. I might be totally wrong, thought.\nEither case, having these alternatives proposals is very important/good as it may influence how subscriptions can/will be implemented. And there won't be a better time to discuss that than now.. I must say I love the simplicity of this implementation.. @andimarek The only issue with adding default to the new TypeResolver method and deprecating the current is that it forces implementors to still implement the deprecated one:\n```java\npublic interface TypeResolver {\ndefault GraphQLObjectType getType(TypeResolutionEnvironment env) { //backward compatible :)\n    return getType(env.getObject());\n}\n\n@Deprecated\nGraphQLObjectType getType(Object object); //still forces implementation :(\n\n}\n```\nNot sure I got you on the last bit, do you mean you'd like me to add the TypeDecider interface I've described (can change name if you wish) in addition to default or you think default is enough?. OK, I'll rework this one then after #353 is merged. Do drop a line if you an opinion ondefault/TypeDecider` thing.. @andimarek @bbakerman Here's a suggestion mixing the approaches mentioned so far:\n```java\npublic interface TypeResolver {\nGraphQLObjectType getType(Object object);\n\ndefault GraphQLObjectType getType(TypeResolutionEnvironment env) {\n    return getType(env.getObject());\n}\n\n}\npublic interface AdvancedTypeResolver extends TypeResolver { //could maybe use a better name\n@Override\nGraphQLObjectType getType(TypeResolutionEnvironment env);\n\n@Override\ndefault GraphQLObjectType getType(Object object) {\n    //Could instead delegate to the method above, but I think an exception is better as library code never actually calls this method\n    throw new UnsupportedOperationException(\"AdvancedTypeResolver does not support simple type resolution\");\n}\n\n}\n``\nWhile a bit convoluted, this solves the conundrum rather effectively.\nAll existingTypeResolvers will keep working as usual and the new code can choose to useAdvancedTypeResolverinstead, implementing only the new method. Library code will only ever call the new method in all cases (already true in this PR). None of the builders that acceptTypeResolveror any other code need to change, unlike in my originalTypeDecider` approach.\nDidn't want to push it like this before I hear your comments.. @andimarek It is confusing, I agree. I added it to remove the need for any other changes. If I remove it, I have 2 options:\n\nDo instanceof check inside resolveType:\njava\ntypeResolver instanceof AdvancedTypeResolver ? ((AdvancedTypeResolver) typeResolver).getType(env) : typeResolver.getType(env.getObject);\nMake GraphQLInterfaceType  and GraphQLUnionType always wrap the given TypeResolver into AdvancedTypeResolver (the same approach I took for my TypeDecider idea)\n\nDo you think one of these is the way to go?\n. Awesome! Do you need me to do anything at this point?. It's not a bad approach, because input and output types are fundamentally different and calling them the same is needlessly convoluted. Output can contain interfaces, unions and potentially endless recursion. Inputs can have none of those. So it stands to reason you need to make distinct types for input and output, and distinct types should have distinct names. It is a common practice to have something like otherdetails and otherdetails_input.. Why not close the issue? Nothing left to be said.... Ah, perfect, this has actually been solved already! Thanks for the explanations @bbakerman and @apottere !\nAnd this issue is basically just a duplicate of #303  so I'll close it.. Actually, when I think about it better, maybe you wanted to keep it open until the decision on FieldCollector and the query proxying use-case from above.\nThinking of FieldCollector, perhaps it can be refactored a little to have methods that allow collecting based on fragment definitions only (when directives had already been processed) so that it can be used from within DataFetcher?. @bbakerman I was having similar ideas to what you ended up doing in your PR. I was thinking of refactoring FieldCollector in way that would allow it to be created (\"initialized\") with the variables, and passed to DataFetchingEnvironement, which would then be able to use it without having to pass variables again. It could even hide FieldCollector internally, just exposing the field collection methods itself. Not sure if this is smart, was just thinking aloud.\n. Just a small nitpick: the naming (async vs asynch) is a bit hectic, and could use standardization.. TL;DR I suggest you do away with  GraphQLTypeReference class instead\nMy original implementation was akin to this one, but there were specific reasons I went the way I did:\n\nbetter type-safety: can't accidentally mix up references to object/interface/input types\nwhen references and real types are stored separately, calling objectType.getInterfaces() or unionType.getTypes() before the schema has been built would either:\ngive incomplete information (return only real types), which is a very nasty hidden gotcha\nhave to expose objectType.getUnresolvedInterfaces() and leave it to the client to consolidate the two (which IMHO is an ugly, but functional, API)\nexpose an additional method that returns everything as List<TypeOrReference> that can be safely used while the schema is being built (again, IMHO ugly but functional)\n\n\n\nInstead, I opted to keep type safety (getInterfaces keeps returning interfaces, no instanceof checks, builder.withInterface() can't be accidentally given a reference to an object or input type), and consistency (all registered interfaces are indeed returned, no gotchas) by introducing the special implementations (which are both interfaces and references) returned by factory methods.\nWhatever path you choose to take, I'd strongly advise not to give incomplete view of registered interfaces (or possible object types for unions) to the client during building as this is a surprising behavior (could cause hard-to-notice bugs in existing client code). It is much better to force the client to consolidate the references and real types themselves than not to be able to do this at all and have inconsistent view. Maybe expose an additional method that returns everything as List<TypeOrReference> that can be safely used while the schema is being built?\nI'd even go as far as to suggest a completely opposite route: remove GraphQLTypeReference class altogether and enforce type safety everywhere in the same (or similar) vein I did for object interfaces. Maybe have one class with factory methods for all reference types instead of one factory method per class. I'd have done something like this in my original PR but couldn't for compatibility reasons. I'd argue this approach has all the merits: consistent view, type safety, no duplicated withInterface methods, and simple API (no two ways to create a reference).\nOr perhaps, do exactly as already mentioned: make GraphQLInterfaceType an interface, with 2 implementations. I can't fully think this one through, but sounds as if it would have similar benefits.. This was exactly my approach at some point as well. It is correct (in the sense it always gives correct information), so I'm ultimately fine with it.\nI went the other route mainly because I'm not a fan of instanceof checks.\nJust out of curiosity I must ask: if these problems stem from the fact the reference API wasn't originally intended to be used the way it is being used now, have you considered redesigning the whole thing i.e. making all problematic types like GraphQLInterfaceType interfaces with 2 implementations, as you mentioned above?. Commented on #377 about the idea I had for FieldCollector. Basically, I was thinking it could be created once per execution (with all variables and fragment set) and passed into every DatafetchingEnvironment. Maybe even completely hidden from the user and only exposed via new methods on DatafetchingEnvironment.. I'm quite sure this is the same bug as https://github.com/graphql-java/graphql-java/issues/367\nThe fix has been merged already, so it will work in the next release (and in the nightlies), and the usual new TypeReference(...) can now be used everywhere (i.e. GraphQLObjectType.reference is no longer needed).\nDo note the next release is a breaking one.. This isn't valid. You have to return the exact type from TypeResolver, not a reference. It is hard to do because you may not have the types built at this time, forcing you to keep your own type registry. This is one of the reasons the TypeResolver interface has been overhauled in 3.0. It now gives access to the schema, so the exact type can be acquired by name.\nI suggest you ask on Gitter if there will be any 2.x maintenance releases.. @andimarek Even though I find this approach more cumbersome to use (requires checking for this special value in addition to checking for nulls), I think it is the correct approach. It's very explicit and unambiguous, and that is IMHO the most important metric for a low-level library.. @andimarek I don't think I'm getting you about foo vs foo(bar: null). foo here is a query name and bar an optional argument, right? In that case, won't one result in an empty argument map, and the other in a map with key bar and value null?. While the missing key vs the current key-with-null is indeed a subtle change, I don't think it's likely to cause any damage. Currently the key is always present so there's really no reason anyone would be checking for its presence (the part that is changing), and args.get(missingKey) returns null anyway.. This was exactly my point in the previous message. Unless the code does arguments.contains(\"key\"), it will be fine. And there's currently no reason to ever check contains as it is always true... So the change is highly unlikely to cause any damage.. I was thinking along the same lines: have a known exception type that is explicitly handled, allowing instant interruption of further resolution, with the result built so far still reachable.\n@andimarek mentioned he already had something in mind, so maybe he has a different perspective.\nThe current implementation allows for instant interruption, but at the expense of the partial result. Conversely, an exception in a fetcher, retains the partial result but doesn't interrupt further resolution (beyond its own branch).\nBtw, I added an example to the issue, to better clarify the intent.. Originally, my scenario was like that: all the current and future fields get cancelled when an instrumentation throws, but the current result is still returned. But, I no longer have a concrete case for it... so I'm certainly on board with whatever you guys think makes sense here.. Neither the version you're using (2.3.0) nor the current stable (3.0) support the null keyword, and unquoted stings are normally enum values in GraphQL, so this why you're getting the error.\nThe current master does support null, so apart from waiting for the next stable release (aimed for the end of August, I believe), you could use a nightly build from https://bintray.com/andimarek/graphql-java/graphql-java or build master yourself.\nDo note that null itself is a rather recent addition to the GraphQL specification.. The code seems fine, so if you're sure the design is sound, it's all good.\nI have some doubts myself... I'm having issues understanding the implications of replacing thenApply/thenAccept with handle/whenComplete. Does it mean the exceptional completion was previously not triggering the instrumentation context callback when it should have? In this new impl. it seems safe, thus the new design seems better...\nBut if I misunderstood this, and the difference is just 1 vs 2 finisher methods, I must say I prefer having 2 with clear purpose, rather than one with mixed purpose. But I don't have strong opinions there.. @bbakerman  Just to double-check if I get it right. The visibility isn't meant to be dynamic (as in: the same schema with the same visibility strategy used for everyone and dynamically deciding who gets to see what on the fly), right? You're supposed to create a schema per group/role/user with different visibilities instead (and it's a cheap operation as all the same references are reused)?\nGoing further, I reckon it is done to ensure schema validity, as if it was dynamically deciding (vs the schema build time), it could easily produce an invalid schema?. @breathermachine As far as I know, you can not use GraphQLFieldVisibility like that. But I reckon you could achieve something similar using an instrumentation with customized beginField (that would perhaps throw an AbortExecutionException). Didn't try this myself, mind you.\nThat said, it's a general security guideline (neither Java nor GraphQL specific) not to give different error messages for not found and found but not accessible as that gives the potential attacker better insight into your system. Still, this is not always applicable, so make whatever your system requires.\nEDIT: Hmm, what would happen if a custom GraphQLFieldVisibility would throw an exception instead of returning false?. Once the object is created it is immutable (thanks to the final unmodifiable map)... Seems pretty safe.... @andimarek Yup, you're of course right... No good ideas how this can be designed more safely.... On the previous idea from @aschrijver , we could make a custom structure which would allow registering only immutable and/or cloneable types, similar to what annotation parameters in Java allow (plus the cloneable stuff).\nSo the API could be something like:\njava\nmetadata(String key, String metadataValue);\nmetadata(String key, Class<?> metadataValue);\nmetadata(String key, <primitives or wrappers>);\nmetadata(String key, Cloneable metadataValue); //return a clone when retrieving\nmetadata(String key, <Collections of the above>); //turned immutable on save\nThis looks like quite an overhead, but it addresses a number of concerns.... All good in my eyes. I'd merge it.. I like both and both the feature and the implementation. But also think the implementations for all directives supported out of the box should be kept together.. If the proper mechanism is already in place, I'm definitely for documenting it clearly instead of adding more on top.\nAm I understanding this clearly: CoercingParseValueException will not by itself end up in the response, but a custom subtype that is also a GraphQLError should be thrown to achieve that?. Ah, yes. Please do put a note for the time being, and I'll start rewriting it as soon as I can. It is true that it is outdated and must be substantially changed.. Sorry I never replied! Somehow missed it :(\nEither way, I totally agree. I think it's both important and useful to keep the exception available in the result, and to give an easy serialization option. And graph-java already does both...\nThe only mildly confusing thing is that some GraphQLErrors contain an exception while some are an exception, and would maybe prefer if there was a single approach (e.g. if all GraphQLErrors wrapped an exception and exposed it via getCause or something), but that's a different topic probably.. There's an issue tracking the exact same request in the spec: https://github.com/facebook/graphql/issues/300\nThere were also some discussions on how to distinguish the introspectable meta vs the current private meta.. The problem with implementing stuff while the spec is still under discussion is that it may easily end up conflicting with the spec in the future... And then unpleasant breaking changes become inevitable.\nAlso it is very much not safe to simply expose the directives blindly. They're often used to control access and visibility, and exposing that is game over.\nThe way I can imagine this working is having either separate directives for public meta, or having a way to control directive visibility. And such a mechanism is what the spec might end up including.. Hm, something broke on the introspection query. I guess the assertion doesn't expect a new directive or something simple like that.. Taken care of by the last commit. All good!. Just an idea: maybe add a boolean supportsDataLoader() method to the execution strategy, so that 3rd party strategies can declare themselves compatible?. This is what I can come up with:\n\nOnly supply readily usable examples in a separate repo, not actual deployed artifacts. This is similar to how Gson project handles this. The extras are maintained by the Gson team, but only as examples. You have to copy the code you need into your project. This could be an initial solution, and if it doesn't prevent people from asking, it could be easily turned into one of the below approaches.\nAdd it to graphql-java itself. I think this option only makes sense if it includes nothing but scalars for Java built-in types (like java.time.*). Adding more extras (apart from scalars) or library-specific scalars that drag in extra dependencies into the main project does not sound appealing. Of course, the extra dependencies could be kept as optional.\nHave extras or helpers as a separate project (as already suggested). I wouldn't call it scalars as it immediately means any future expansion in scope would mean yet another separate project. This is annoying as it requires not only the maintenance of a separate project, but also a version compatibility matrix or a clever versioning scheme (e.g. does extras v1.2 work with graphql-java 10.0?)... But is appealing because it enables adding often-demanded features without bloating the core library. I'd go for this if the support for JodaTime and other 3rd party libraries is seen as desirable, or if future expansions in scope are to be allowed for.\n\nOne interesting point that I encountered while solving this same problem in SPQR: how do you name the scalars that represent the same thing but in a different way? E.g. if java.time.LocalDate is a scalar called LocalDate, what is org.joda.time.LocalDate called? You can't call it JodaLocalDate as it reveals internal details of no use to the client (they're exactly the same thing from the client's perspective). Can't call it LocalDate as you can't provide conflicting types, even though it's unlikely both would be in use at the same time. All you can do is merge them into one scalar, but then the dependency to JodaTime is no longer optional.\nThere's an additional pain point here: Java also defines time types in java.sql.* and those extend java.util.Date but in an entirely incompatible way... So do you keep those as separate scalars? What if an instance of java.sql.Date is passed where a scalar representing java.util.Date is expected? Have to duplicate the logic... or merge it again into an unpleasant mess.\nSo I'd say, either stay way from this whole thing and simply give some examples, or limit the provided features to the bare minimum (java.time.* only). Or really, really plan this out thoroughly before going in...\nIn any case, I'm happy to help with anything you need.. I've updated the previous comment substantially, so if you're reading this from an email, please see the updated version on the web. Sorry for that.... My understanding of the spec is in line with @bbakerman 's: all the variables defined on the operation must have a usage, but that means they must all be referred to in the operation. Doesn't sound like it means all the entries provided in the variable map must be used...\nBtw, for the given example:\ngraphql\n{\n    \"operationName\": \"SpaceIDQuerysaa\",\n    \"query\":\n        \"query SpaceIDQuerysaa($spaceKey: String) {\n            space(key: $spaceKey) {\n                id\n                __typename\n             }\n        }\",\n    \"variables\": {\n        \"keyddd\": \"ISO\"\n    }\n}\nunless the key argument is nullable, this is still an exception, right?. One thing that's been requested a few times and still seems difficult to do is getting the conditional selections. To use the classic example:\ngraphql\n{\n    hero(episode: $ep) {\n        name\n        ... on Droid {\n            primaryFunction\n        }\n        ... on Human {\n            height\n        }\n    }\n}\nThere's no easy way to find out that primaryFunction and height have been conditionally selected.\nNot sure if you want to tackle this or not, but I figured it's worth a mention.. I now realize that GraphQLDirective isn't even a part of the GraphQLType hierarchy, so it's never traversed... Does this mean type collection/reference replacement isn't even supposed to work on directives, or are they sort of \"second class citizens\" on purpose?. Added the additional directives as roots for type reference resolution traversal which I was missing the first time and the tests for #1208 and general directive reachability during the traversal.\nI think it's now ready, but I'm happy to add/change anything if needed.. Yes, I think it's ready. I've added the tests, indeed.. Ignore. I managed to choose a reserved keyword on as the argument name.. Seems like this is rather expected side-effect of #1084. Not sure if anything can be done, nor if anything should be done... But it does cause a rather insidious regression that insta-bit me \ud83d\ude29. This is still broken, the test was just checking the wrong thing. No exceptions get thrown, but the resulting schema is invalid, as a GraphQLTypeReference remains unresolved.\nAs mentioned, this is a side-effect of #1084, because the traverser keeps track of the replaced references, and once an instance of GraphQLTypeReference is marked as resolved, the same instance will never be handled again. Which results in an invalid schema. Not sure how to approach this, but it's way too insidious to leave it as it is (you end having a broken schema without ever realizing it). At least an exception that tells the user what is happening is needed...\nI currently have some ugly workaround where I create a new reference each time. But it sure took a while to realize what was happening.. No worries, they're still legit comments :). Terribly sorry for the trouble, but I didn't get a chance to finish this \ud83d\ude29\nI can take care of it when I'm back from vacation, but that's 3 weeks from now.... @dnebing I think you misunderstood @andimarek . The core objects and builders are not innately thread-safe, nor should they be. Still, there's nothing stopping you from passing them around multiple threads, but if you do - it's up to you to ensure the safety and visibility of updates.\nAs for the servlet, it's a whole different crew maintaining that. So it's really not up to @andimarek or @bbakerman whether it's implemented safely. Although, I presume it is. But again, the core library neither does nor should care about such specifics.\nRegarding your use-case, I think it's a legit improvement request that SPQR gives you a hook into the build process beyond what it already does, perhaps by expanding the GraphQLSchemaProcessor interface. So please open an issue on that project and I'll take a look at it.. Gave this a bit more thought, and I think there should be a method that returns a map of parsed directives for any directive container. This is because one might need to get directives from a different field than the first (if DataFetchingEnvironment#getFields contains multiple fields) or from a fragment or fragment definition.\nI can do it if you agree on the approach.. @bbakerman The way I have it right now is that I return a new object (called Directives in my case) that is a glorified Map<Introspection.DirectiveLocation, Map<String, List<GraphQLDirective>>. \nI.e. it is a map of directives by name by location. The reason there's a List is because the same directive (same name) could appear multiple times but with potentially different argument values. So the directives for both books fields in your example are merged inside the inner Map<String, List<GraphQLDirective>> (under DirectiveLocation.FIELD), they're not keyed by the AST node.\nSimilarly to how only the current fields' directives are available, so are only the current fragments' directives (where a current fragment is a fragment to which a current field belongs).\nE.g. for a complex query such as:\n```graphql\nfragment Details on Book @timeout(afterMillis: 25) {\n    title\n    review @timeout(afterMillis: 5)\" +\n}\nquery Books @timeout(afterMillis: 30) {\n    books(searchString: \"monkey\") {\n        id\n        ...Details @timeout(afterMillis: 20)\n        ...on Book @timeout(afterMillis: 15) {\n            review @timeout(afterMillis: 10)\n        }\n    }\n}\n```\nThe resulting map for the review field would be:\njs\n{\n  \"FIELD\": {\n    \"timeout\": [ {\"afterMillis\": 5}, {\"afterMillis\": 10} ]\n  },\n  \"MUTATION\": {},\n  \"INLINE_FRAGMENT\": {\n    \"timeout\": [ {\"afterMillis\": 15} ]\n  },\n  \"FRAGMENT_DEFINITION\": {\n    \"timeout\": [ {\"afterMillis\": 25} ]\n  },\n  \"FRAGMENT_SPREAD\": {\n    \"timeout\": [ {\"afterMillis\": 20} ]\n  },\n  \"QUERY\": {\n    \"timeout\": [ {\"afterMillis\": 30} ]\n  }\n}\nFor the id field, there would be nothing under INLINE_FRAGMENT , FRAGMENT_DEFINITION or FRAGMENT_SPREAD as that field belongs to no fragments. Also nothing under FIELD as it doesn't have its own directives either. It would only have the QUERY directive.\nNot sure if that's the way it should be, that's just the way I have it now...\nI then have some convenience methods on this new Directives class for getting a single directive or the whole list per name per location.\nI don't really have a formed opinion yet on what should be in the library and how it should look... but I'm guessing in the background a structure keyed by the AST node will be necessary, while in the client-visible part it could be for the current context only, similar to the thing laid out above.\nThis is of course if such a feature is desired in the first place, as it's rather complicated \ud83d\ude1f. I added a comprehensive example and more rationale to the previous message, so if you're reading this from an email, please make sure to see the updated version of it.. Any chance you give a summary of the these changes? I'm curious to know what's coming and it's a bit difficult to follow without knowing the goal/motivation behind the changes. How is the new default execution strategy different form the current etc...\nAlso, does this mean the now deprecated BatchedExecutionStrategy is getting rehabilitated?. Thanks, @bbakerman! Sounds like a deep incision indeed \ud83d\ude2e I'll definitely have to look into it in detail. Don't want to just end up with the world suddenly changing under my feet.. Didn't add any tests as it's kind of a trivial thing, but will do if you want.. > Now that every Node is immutable you can't change a query anymore at any point. If you have some use cases which requires changing the query after it was create, please comment here. \nPerhaps I'm too late, but I'm aware of users that allow queries for objects without a subselection, by modifying the query on the fly to include all the direct fields in such cases. This was done via an instrumentation.\nIs this use case still possible?. Ah, just seen #1345 which caters exactly to this use-case :). Well, it is certainly possible to collect the directives per DataFetcher, that was my initial implementation (still present in SPQR). In that case I don't have to use Field as the key. The approach taken here though avoids multiple traversals... I could also use IdentityHashMap to make it obvious how the keys are being used. What do you think?. Oh, regarding the first applicable directive, it was intentionally not taking parent fields into account as each field has its own semantics, so I feel it would be asking for trouble to assume what applies to a field applies to its descendants. Where as a fragment has no semantics, it's just a container, so its directives wouldn't do anything if they didn't apply to the fields contained therein.\nI could be terribly wrong on the field hierarchy semantics though... I can't come up with any use-case where a directive wouldn't apply to a descendant field. It's just a feeling and the fact the directives for any field can already be acquired via FieldDirectives easily enough (see my comment above on FieldDirectives being public).. A completely different approach I was mulling over was to include the fragments into the ExecutionStepInfo. That way a fetcher could easily traverse upwards and find the applicable fragments. Then, there would be no need for EncounteredDirectives as the user would be able to reach all the directives already and decide what applies.. I think the public API is pretty friendly.\nI'm only slightly concerned about the inability to tell field and fragment directives apart. I don't have a use-case in mind, just a general feeling that a directive on an ancestor field (that has its own semantics) vs a directive on a fragment (that has no semantics of its own) should perhaps be distinguishable. Would tracking the directive location (DirectiveLocation) next to the distance be a good idea?\nMind you, I didn't look into the code deep enough to know if that's a hassle to do or not.. Since there already is a concept of a merged field, maybe MergedFieldDirectives is sensible? As it really does represent only the direcives applicable to a specific merged field.\nJust thinking aloud..... @bbakerman Ah, right! Missed that. Thanks!\nI think the API is finally solid (took 3 iterations \ud83d\ude01).. Why not go for the same approach done for DataLoaderRegistry, so that an instance can be registered via ExecutionInput instead of having to manually piggy-back it through the context?. Made a quick PR #1422 in case you like that idea.. Not sure I got your 2nd suggestion... But anything that allows easier non-breaking modifications sounds like a good idea.. Agreed, and removed. I've reimplemented the changes to the ExecutionStrategy in the way you suggested and made overloads and deprecations for backward-compatibility. Please see when you get a chance what you think of this version.\nNotes:\n- I've only introduced the ...Parameters classes where I needed them for this change, not everywhere where they should arguably go. Tell me If you want me refactor more places.\n- I made the ...Parameters constructors private to avoid implementors relying on them and ending up in this same situation. I wanted them package private so that they can be used internally, but BatchedExecutionStrategy is in a different package so there wasn't much point.\n- I added Javadoc to the @Deprecated methods only to link to the new options, but since this is not a full Javadoc, a lot of warnings are generated during the build. Would you rather have the incomplete docs removed or maybe provide the text you'd like in the Javadoc, or would you like me to add my own?\nNow, the question comes back to the TypeResolver: do I re-introduce the Java 8 dependent default for backwards compatibility, or do I implement it in a different way?\nOne idea I have is to introduce a new interface, say TypeDecider, that would provide the new functionality: GraphQLObjectType getType(TypeResolutionEnvironment env), and then change the builders that accept TypeResolvers in a fashion similar to this:\n```\n//wrap the given TypeResolver in a simple TypeDecider that just delegates to it\npublic Builder typeResolver(TypeResolver typeResolver) {\n    this.typeDecider = new SimpleTypeDecider(typeResolver);\n    return this;\n }\n//add new method that accepts TypeDecider directly\npublic Builder typeDecider(TypeDecider typeDecider) {\n    this.typeDecider = typeDecider;\n    return this;\n }\n```\nWith both approaches, backwards-compatibility would be, I think, complete.\nUPDATE: I've already implemented the TypeDecider approach, so if you like that option I can push it for review.. assertNotNull(interfaces, \"unresolvedInterfaces can't be null\");\nThis is a leftover from the first implementation, should be deleted. This constructor seems only ever used in the constructor above... Should it be removed?. Shouldn't this be AsyncSerialExecutionStrategy?. Haven't rechecked, but isn't it because selection sets on interfaces are also of interest?. AsyncSerial again?. Doesn't #593 take care of this?. Trying to understand this part. It says \"implements keyword, maybe & and 1 or more type names or ... this recursively again?\". Does it mean \"X implements & A & B\" is legal? How about \"X implements A implements B\"?. It seems identical to the reference implementation, and that's the least surprising possibility, so I'd call it correct.. Should I maybe use a specific (internal) kind of exception here that can be unpacked by the error handler later?\nOr perhaps sneaky-throw the original?. The anon class keeps a reference to the outer instance, which is irrelevant here but I figured it might become relevant as the code gets refactored in the future. This is the only reason I removed the anon class.. GraphQLArgument had previously only been found on a GraphQLFieldDefinition which itself could only been found on a GraphQLObjectType which is regular type. As a result, a type reference in an argument would only be possible within a hierarchy of another type. Now, a GraphQLArgument can be found directly on a directive which is not a real type. As a result, a type reference on an argument can be found outside of a hierarchy of a real type, thus it will not be in the schema's type map. And for those to be replaced correctly, directives need to be added as roots. This may result in a duplicated traversal in some cases (if the type of the directive argument is complex and has a reference inside, and does end up in the type map), but outside of a small performance hit, it has no negative consequences.\nI guess it would also be possible for GraphQLTypeCollectingVisitor to also keep track of all top-level references in a separate collection. I'm personally OK with my current approach, but am open to changing it if you wish.. * Directives with same names but different arguments - As far as I know, this is not allowed (same unique-name policy as with types). There might already be such a validation in place.\n Directives accepting complex types with further types and directives - Yes, I believe this is legit and is covered.\n Type traversal vs directive type traversal - I don't think there should be anything special about types under directives.\nThe edge cases I was referring to are mostly about type reference replacement. E.g. if a directive refers to a type found elsewhere in the schema, the reference must be replaced correctly. And vice versa, if another schema element referes to a type first defined on a directive it should work as usual. I tried to cover this in the tests.\nFor what it's worth, I've been using my fork for a few days now in rather complex scenarios (directives with complex types with references to other complex types with further directives) and it's behaving exactly as I'd expect.. But what I think is worth pointing out is that I don't change any rules in this PR. Everything doable with my changes is also doable without them. You can already add directives to anything, assign arguments of complex types, add further directives to those arguments etc.\nAll that the change does is make directives reachable by the traverser and, using that, make sure the reference replacement and type collection work in a consistent manner across schema elements.. Do you think it would maybe be better to create a new type to represent this or are you ok with Map<String, Map<String, Object>>?. The difference between this and getArgument(argumentName) is that in this case even the directiveName might be wrong, before we even check the argumentName. But I get your point., it does look weird.. I saved this into a variable to avoid doing an instanceof twice and to avoid needless repackaging of an Iterable into a Collection by FpKit#toCollection.  But since this is not exactly a method where tiny performance differences matter much, you may want to simply always call FpKit#toCollection and skip the double check.. FieldDirectives are intentionally not internal, just the constructor. This is to enable the user to look up directives for fields other than the current (either ancestors through the ExecutionStepInfo or descendants via the SelectionSet).. ",
    "maquessime": "Sorry for the formatting change, It's reverted now, was not wanted of course.\nI could revert  the \"refactor\" commit too for the data fetchers, sorry, it's just a habit to refactor before adding something new.\nThe only change could have been nameAndFieldName method and tests.\n. @danielkwinsor I think we can live with \n.name(\"foo\")\n.dataFetcher(new FieldDataFetcher(\"bar\")\nI close the pull request.\n. ",
    "pt-achang": "Closing this in favor of https://github.com/andimarek/graphql-java/pull/87. This PR is based off the wrong branch and contains extraneous commits.\n. From the Andi:\n\nThanks for this PR and thanks for your effort.\nAbout supporting Java 1.6 in general: I'm thinking about it now for some time I don't really now yet, if we should do this. Because even Java 7 is EOL, and I would rather to prefer to switch to Java 8 in the near future.\nBut of course there are still projects out there which use Java 1.6 (or even older).\nI created a entry in the mailing-list to gather some feedback: https://groups.google.com/forum/#!topic/graphql-java/iCCN2T1RgyI\n. Thanks!\n. \n",
    "corydolphin": "@andimarek I'd love to re-open this conversation if you are interested.\nI think it would help the project to bump the source version to Java 8. This would allow us to remove the reflection based PropertyBasedDataFetcher, and instead simply use Java's native Method references. \nE.G. PropertyDataFetcher(\"booleanFieldWithGet\") could simply be replaced with Object::booleanFieldWithGet. . @dminkovsky @GrigoryPtashko We can achieve what I desired without needing the library to use src/target of Java 8. Apologies for my confusion! . @bbakerman would it be OK to expose a way for an ExecutionStrategy to simply deal with the exception handling?\n. https://github.com/graphql-java/graphql-java/pull/391 should've fixed this. Updated handling. It seems like the rule-processing should abort once it hits an error. Otherwise, as in this case, the other rules have to handle i.e. null/not-found fragments. . Updated:\n\nI separated the renaming to a separate PR https://github.com/graphql-java/graphql-java/pull/748\nI have updated the description's schema to match the test's.\n\nAs for the content of the change, I actually think that the way https://github.com/graphql/graphql-js/blob/master/src/utilities/typeComparators.js#L57 implements it is clearer (and was my initial though), but I tried to match the fall-through negative case style. Logically to me, nullability is one of the highest order bits, so it should logically be the first check.. Out of curiosity, why would you want to use the PropertyDataFetcher instead of a Method Reference?. It allows a nice shorthand for referring to a method to e.g fulfill a functional interface. \nMy suggestion is that rather than have an implicit, reflection-based getter (which is slow, and would fail at runtime if it could not be found), to instead use a method reference to the getter for the property. \nhttps://docs.oracle.com/javase/tutorial/java/javaOO/methodreferences.html\n. What I'm suggesting is that instead of having it be \"automagic\", developers are simply required to set the data fetcher as a method reference, and the api could be made easier to use. I.E. in our usage, we have a wrapper, and thus our datafetchers for property-getters are just e.g. ObjectName::getThing. Done! Apologies for the churn, my editor automatically updated the imports. . Good catch. I was trying to reduce noise, sorry for the confusion. . Bbakerman's comment was in reference to a previous revision of the change. \nThe \"Problem\" is as stated in the description. The schema I provided there, and the test case here fails without the associated change to ObjectsImplementInterfaces. Why not use a SimpleImmutableEntry as a stdlib included Pair/Tuple implementation for the key?. ",
    "GrigoryPtashko": "@corydolphin @andimarek Guys, what are the plans for moving to sourceCompatibility to 1.8? We are using Java 7 in production and don't plan to move to 8. I work in the biggest russian touroperator. We've got a very high loaded system and a very very big codebase. And just started to use graphql. It is simply impossible to move to Java 8 and the moment. I'll be very sad if the whole graphql-java project switch to Java 8 :(. +1\n. +1\nI also think that \"Executing operation ...\" should be at the debug level.\n. @andimarek so it means that after 2.4.0 I will not be able to use the library on java 7?\nI use graphql and all our production is running on java 7. There's no way to switch to java 8 in the near future.. @andimarek Sorry to hear that..\nBy no means I want to be offensive but IMHO most of the devs I see now do not actually work on production code of big businesses. I agree about java 6. But the preference of the java 8 over the java 7 is just a race for shiny syntactic sugar which actually does not earn money. In most cases it's like a new toy for a developer. I work in a billion dollars business and I do not see requirements that push me to switch to java 8.. @andimarek @bbakerman @dminkovsky \nPeople, please, don't turn away from me :) How do you think if after all the\nversion of the graphql-java library can be continued with the java 7 support?\nI mean if this is possible at all I can maintain some kind of backward\ncompatibility branch with a little help at the beginning.\nI'll explain my motivation:\n\nI'm watching this lib and this repo for almost a year now. I'm not a new person\n   I'm just silent because there's a lot of work on my full time job. But..\nAs a full time developer I work in a company with a very mature codebase\n   written totally on java 7 and in runtime we also use java 7. Unfortunately,\n   we totally do not have plans to transfer to java 8 since the infrastructure\n   is really large, tested and ... working. I think you can understand it.\n   But nevertheless I've implemented a graphql backend for our data storage and\n   as I continue I find more and more applications of this backend. I mean so far I\n   had only the read only schemas, I've tested them in production, people\n   started using them. And now I'm going to start writing the write schemas so\n   my API will be used for creating and editing objects in our data storage.\n   I also use Relay on the front end. And as you may know there are some huge\n   changes coming in the new Relay part of which I personally wait for.\n   What I'm saying is that I'm really-really interested in having the\n   graphql-java lib evolving for the java 7.\nI also got a side-project where I use graphql-java but with java 8. I've\n   implemented subscriptions in it and in the spring-graphql-common projects.\n\nI mean that I understand internals and I make use of the lib everyday and\nas I go forward I use it more and more in production.\nWhat do you say?\n. @ieugen I understand what you are saying but switching to java 8 is not a solution at all. The codebase is more than 15 years old. We have 30K to 40K database requests per second on the 24x7 basis. We have lots of code like database replication written on java + redis instead of native db replication and so on and so forth. I actually don't want to discuss about how it is right or wrong to stay on a concrete version of some platform.\nI guess nobody is interested in this so I'll try to make this java 7 compatibility by myself.. @andimarek no problem :) I understand everything. I already have a fork and I think I'll try to make a backport after the PR with subscriptions is merged (this one https://github.com/graphql-java/graphql-java/pull/358).. ",
    "hanmu": "ok~thank you for your replay.\n. @andimarek  in the  danielkwinsor's example.we use the QL below to query for a recursive data :\nString queryString = \n        \"{\"\n        + \"  testObj {\"\n        + \"    recursionLevel\"\n        + \"    recursive {\"\n        + \"      recursionLevel\"\n        + \"    recursive {\"\n        + \"      recursionLevel\"\n        + \"    recursive {\"\n        + \"      recursionLevel\"\n        + \"    recursive {\"\n        + \"      recursionLevel\"\n        + \"    }\"\n        + \"    }\"\n        + \"    }\"\n        + \"    }\"\n        + \"  }\"\n        + \"}\";\nMy question is  if recursionLevel is a dynamic value, how can i write the QL to request for a full recursive data?\n. ",
    "markphilpot": "I will pick up the torch on this one.\n. If @fredrik-hultin doesn't mind, I'll break this up into a few PRs.  I'll give @fredrik-hultin a few days to check back since this PR was started back in February.\n. I can also take the lead if the context has been swapped out =) Let me know.\nOn Mon, Sep 5, 2016 at 4:46 AM, Fredrik Hultin notifications@github.com\nwrote:\n\nSorry guys, lost this for a while. Let me get a chance to have a look at\nthis soon again... I'll get back to you soon if this is still interesting?\n\u2014\nYou are receiving this because you were assigned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/pull/91#issuecomment-244727826,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAC0b-gIXE45jeYPmVLXTx-mPDURHZkEks5qnAESgaJpZM4Hixp7\n.\n. I agree with @yrashk -- let's merge this and open an Issue to track adding a test case for it.\n. Closing this since we merged the fix here.\n. Thanks! This makes sense to separate.\n. Thanks for the PR!  Let me know if the comments make sense.\n. \u043f\u043e\u0436\u0430\u043b\u0443\u0439\u0441\u0442\u0430\n. Spec Reference: http://facebook.github.io/graphql/#sec-String-Value\n. Thanks!\n. Thanks!\n. Github recently allowed sites to be run out of a docs directory on master rather than a gh-pages branch which makes the build pipeline much easier.  I'll take this one on.\n. So some options:\n\nthe github page contains:\nA) The latest javadocs\nB) The javadocs for the last release\nC) Javadocs for all previous releases including latest\nFor whatever reason I rarely use javadocs so I'm not sure what's most useful for everyone. I'm also making the assumption that the main README.md continues to be the focus for documentation rather than trying to set up a jekyll site.\nIf we go A) then I'll just use the new convention of the docs folder.  For B) or C) I'll use the gh-pages branch (makes it cleaner for on going development)\n. C) Isn't that bad. I wasn't going to try to do a travis auto commit for the latest so it will just be a manual periodic thing (I'll manage that for now).  Let me get a PR together and see what you think.\n. Check out the project page and let me know what you think :: http://graphql-java.github.io/graphql-java/\nObviously its bare since I didn't want to commit to moving the real documentation over... so essentially just a proxy for the javadocs only.\n. Try it now and see if that checks all the boxes.\n. Sounds good!\n. Poked the build.  This is the same query I used for introspection so I'm glad it's a part of the project now.  Assuming the build goes through I'll merge it.\n. Click on \"Details\" for the travis check\n\nClick the \"Redo\" button in the upper right of the summary box (it's not a great UI)\n\n\n. A service I use on my other projects is https://coveralls.io/ \n. Makes sense.  Thanks for the PR!\n. I'll work to incorporate that this week.\n. Can you just not have a catch block for NoSuchMethodException?\n. java\nif(isBooleanProperty){\n   try {\n      return getPropertyViaGetterUsingPrefix(object, outputType, \"get\");\n   } catch (NoSuchMethodException e1) {\n      // Empty\n   }\n}\nreturn getPropertyViaFieldAccess(object, outputType);\n. Is it worth adding generics in this PR?  It might make more sense in this context:\njava\npublic interface DataFetcher<T> {\n   T get(DataFetchingEnvironment env);\n}\n. While I like the explicit nature of no defaults I think PropertyDataFetcher is the one to go with.  It makes schema building even more verbose than it is however if there is no default.\n. +1\n. I personally use objects for the type safety, but I can understand a Map might be a new user's first choice.  In that light, would vote for being explicit with no default since we are breaking out Map and Property functionality from Field\n. ",
    "fredrik-hultin": "Sorry guys, lost this for a while. Let me get a chance to have a look at this soon again... I'll get back to you soon if this is still interesting?\n. ",
    "Underzenith85": "Oops, meant to merge this back into my own master for now.\n. ",
    "kirpi4ik": "Good question, it is definitely something wrong. We had to debug graphQL code to realize that our custom execution strategy was not used for mutations(no exceptions, no log).\nCreating hardcoded new instance of SimpleExecutionStrategy inside Execution is weird, more than that our custom execution strategy is already extending SimpleExecutionStrategy.\nSo if mutation really need to use different strategy at least it must be passed as parameter to GraphQL and not being hardcoded in the Execution.\n. ",
    "mattwigway": "Thanks @tuukka!\n. ",
    "tuukka": "I have now removed the unnecessary comment and amended the commit.\n. ",
    "exbe": "Is there any test code, which can help to reproduce this issue? I can't recall any issues with jackson.. @bbakerman I've added html report in the description. Of course it also generates other formats and can be integrated with travis ci.. I think we should take it and ready to merge.. But I would prefer to keep \"actual\" message, it is a burden to deal from raw exception without a hint.. It should be okay to use 'ExceptionWhileDataFetching.getException()'  in most situations instead getMessage() for your case. It should return untouched exception with your original message.\n. @gando999 yes, 'getErrorType ()' is a better way. Another solution would be to introduce fair localization for all strings.\nI am closing this PR for now. Feel free to re-open it anytime.. Closing this one, sine #315 has been merged already. These classes are generated by ANTLR and appear under build/generated-src/antlr/main/graphql/parser/antlr/...\nRun gradle clean build to get them.. Hi @bbakerman any updates on this one?. @andimarek I am aware of few places, where runtime type check can be replaced with visitor today. So this PR is a base for me.. @andimarek Thank you for your time!\nThe suggested change might look intimidating, but positive gain will overweight emotions. You can believe me here, I was relatively recently exposed to double-dispatch/visitor and it took me some time to get used to it.  The good thing though, it is easier for a client to traverse complex structures like AST. It also gives very good API, which would help contributors today and in the future. And... it will reduce the cost of maintaining the library code :)  \nHere is an example: KnownDirectives.hasInvalidLocation()\nUsing visitor, I can re-write this code as follows:\n```java\n private boolean hasInvalidLocation(GraphQLDirective directive, Node ancestor) {\n        return ancestor.accept(new LocationVisitor(directive),true);\n}\nstatic class LocationVisitor  extends NodeVisitorStub {\n    final GraphQLDirective directive;\nLocationVisitor(GraphQLDirective directive) {\n    this.directive = directive;\n}\n\nprivate boolean has(DirectiveLocation thing) {\n    return directive.validLocations().contains(thing);\n}\n\n@Override\npublic Boolean visitField(Field node, Boolean data) {\n    return !(has(DirectiveLocation.FIELD) || directive.isOnField());\n}\n\n@Override\npublic Boolean visitFragmentSpread(FragmentSpread node, Boolean data) {\n    return !(has(DirectiveLocation.FRAGMENT_SPREAD) || directive.isOnFragment());\n}\n\n@Override\npublic Boolean visitFragmentDefinition(FragmentDefinition node, Boolean data) {\n    return !(has(DirectiveLocation.FRAGMENT_DEFINITION) || directive.isOnFragment());\n}\n\n@Override\npublic Boolean visitInlineFragment(InlineFragment node, Boolean data) {\n    return (!has(DirectiveLocation.INLINE_FRAGMENT) || directive.isOnFragment());\n}\n\n@Override\npublic Boolean visitOperationDefinition(OperationDefinition node, Boolean data) {\n    return Operation.QUERY.equals(node.getOperation()) ?\n            !(has(DirectiveLocation.QUERY) || directive.isOnOperation()) :\n            !(has(DirectiveLocation.MUTATION) || directive.isOnOperation());\n}\n\n}\n}\n``` \nWhich gives me following benefits:\n type is known at compile-time, IDE will help me to autocomplete methods. \n static code-analysis and other tools works better with known type\n next time new type is introduced, I need just override a method from stub if I plan to use it\n if type is deleted or deprecated, it is easier to find all places this type was used\n readability is better - code is collocated with actual type and data. I have to carefully read conditions in large if-else statements\n visitor can be reused\n paves the way for further refactoring and simplification\n performance gain*\nSurely instanceof check is fast, but it still faster without reflection (type is known, no need to resolve an actual type and perform casting, no second explicit cast). \nSo far search detects 60 places, where instanceof is used. I assume some of these checks are called multiple times per request.\nThere is no need to trust words, we can run tests to measure impact.\n . @andimarek I have to experience api before I form my own opinion \ud83d\ude04  You guys already ahead in design.  My needs are also modest: to be able provide custom behavior based on runtime type without reflection and traverse AST. As long as it is not required to write too much of boilerplate I will be good.\nI believe fine-grained control over traversal would be beneficial in complex cases like efficient validation or orchestration. \nTo sum up: let's take as is and polish details later (through testing, feedback etc). . @bbakerman if someone decide to tackle this, which approach you would recommend to take?\n. 1.  Do we need tests for legacy behavior? \n2. Is it a valid case or dead code?. Actually, I run some experiments using poor-man tool like System.nanoTime().\nThese 100 lines performs worse than run-time type check and deviation is significant per 1000000000 executions. \nI blame NodeVisitor, it restricts me to use TraverserContext, which I am instantiating per every run.\nObject creation + overhead to set result overweight other benefits of using visitor here.  \nSo I went ahead and make a generic node visitor to check hypothesis what performance-wise visitor would take same execution cost. It looks okay at glance, but we can also run real benchmark. \nI think we can take tests from this PR and change node traversal. It should not introduce operational overhead for simple traversals like mine.\nWDYT? . @bbakerman I updated PR to include tests only.\nAlso, this implementation might be changed anyway, depends on  resolution for https://github.com/graphql-java/graphql-java/issues/1041. I can use arguments to narrow result. It is possible to use any valid type. \nquery HeroNameAndFriends {\n  hero(episode: \"JEDI\") {\n    name\n    friends {\n      name\n    }\n  }\n}\nExisting validation works fine, since input is a part of AST.\nHowever, if I use variables like in the following\nquery HeroNameAndFriends($episode: Episode) {\n  hero(episode: $episode) {\n    name\n    friends {\n      name\n    }\n  }\n}\nwith {\n  \"episode\": \"JEDI\"\n}, what is the expectation? \nVariables are not part of AST, only few validation rules are getting invoked (like NoUnusedVariables).  VariableReference is the only type, which appears in AST for variables and this makes sense, since variables are passed down through another codepath which bypasses validation. As in result, it is not getting validated against type system in any way.\nThe library responds differently for semantically same arguments values, where the only difference is the way one use it (inline vs variables).\nThis is critical for mutations:\nmutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) {\n  createReview(episode: $ep, review: $review) {\n    stars\n    commentary\n  }\n} \nwith {\n  \"ep\": \"JEDI\",\n  \"review\": {\n    \"stars\": \"XXXXX\",\n    \"commentary\": false\n  }\n}\nwould call data fetcher with bogus data.  If I change this query to provide inline input, it would raise validation errors.\nMy expectations is that validation should happen regardless of input method (inline vs variables).\nDoes this make sense? \n. @bbakerman Build failure is coming from gradle function (here), but it seems execution of the git command itself was ok. I think it has something to do with gradle thread... not sure.\nI will try to re-base/re-sync with latest master and see what happens.\nFrom travis log.\ncurrent git hash:\ngit rev-parse --short HEAD\ndf45cb3\nThank you for review, I will follow up with comments.\n. @bbakerman I feel confused with usage of @PublicAPI/@Internal. Is there guide anywhere besides javadoc? Basically I would love to wait few release before switching it to public. Probably we could od same thing for NodeVisitorStub/NodeVisitor - they are @Internal, but I believe they should be @Public as well.\nLet me ping you about test cases on gitter. I might need to clarify some use cases.. PS close-reopen PR helps to \"fix\" build failure on travis CI. @bbakerman @andimarek I think I responded to all comments.\nPlease take a look. @bbakerman @andimarek do you see anything else, which I should change in a scope of this PR?\nPlease let me know.. @bbakerman @andimarek any updates on this one?. @andimarek no worries, take your time :). @andimarek please check. @andimarek Are you looking for an example, explanation or something else? \nUpdated:  I think it make sense to add similar special cases for breadthFirst too as a legitimate api.\n. nice catch :). I have to play with it, but so far looks good... let me try to run it.\n Great job @kaqqao!. @andimarek just to quick-confirmation -- if I wanna flip between classic and brand new execution, I must be using execution2 for later, isn't it?. very nice thing :) looking forward to see numbers. hm.. it seems this function was just moved around..... hi @bbakerman \nWhy not to use java.util.concurrent.CopyOnWriteArrayList instead? \nNo effort would be required to maintain and test manual thread synchronization.. @andimarek  this would severely cripple visitor pattern implementation, isn't it? Every implementation of Node.accept() would be required to perform reflection to figure out actual runtime type of input in order to properly dispatch next call. It cancels benefits from double-dispatch and unnecessarily complicates everything for a client code.\nAlso for the convenience, one can subclass NodeVisitorStub and use methods like visitValue(), visitSelection(), visitTypeDefinition()  in his or her concrete visitor. Stub gives other conveniences as well, another one is default implementation for all NodeVisitor's methods - it reduces boilerplate code.. @andimarek you are right, yes. Accept knows which method to call on visitor. I've got biased towards method overloading :) \nI guess were are examples, where it make sense to express some-kind of grouping. \nPersonally I would keep it simple and use 'visit' for root visitor. . If we expect T of a certain type, would it be better to define upper bound as T extends Node?\nBy the way, I see visitor+traverser context as a specialized mechanism to traverse AST rather than general-purpose visitor.  \n. Could you share your thoughts about making getResult/setResult/getInitialData of an object type?. will it be enough? My guess propertyName should be used in the cache.. Unwrapping is using recursion, which is based on a fixed stack. \nLarge and deep graphs have a chance to overflow stack. VERY large graphql type system will overflow it for sure. \nRecursion is also application-dependent at runtime. If this lib will be called after web server, IoC framework, other application layers .... this all eats up stack leaving less and less room. Not to mention hypothetical cycles in graphql type system...\nAnother hypothetical  case is there application developer would run graphql in a thread with custom (and small) execution stack. \nTraverser is free from all above issues. It relies on a true stack, which would grow in size if needed and tracks visited types as it goes.\n. TypeTraverser is similar to NodeTraverser. Shall I update both?\nI consider NodeTraverser/TypeTraverser as @Internal for now.. @andimarek This method was part of older recursive reference resolution algorithm.\nThis PR uses getChildren() to unwrap actual type and replaceType(GraphQLInputType type) to set it.\nI am not sure if anyone else is using it (e.g. clients), so I have marked it as @deprecated.\nIdeally, if it is not part of some use case, this can be removed in future versions.\nIf I miss some use case, I would be happy to learn about it and add support.. > My point is that not ALL uses case of recursion are problematic.\nAgree on 100%. Do you think that traverser gives too much of overhead?  \nThis case might be trivial, but it is still type traversal. Traverser looks good enough to cover this case too. Would you prefer to have custom algorithm here instead? . It is getting tested via TypeTraverserTest :) Is it good enough?. For convince, which is based on assumption that in most cases developers won't need to visit marker interface very often (even stub doesn't care). \nNot a big deal -  I can move default implementation under GraphQLTypeVisitorStub. \nWhat is your preference @bbakerman and @andimarek? . I see what you are proposing, but not sure I have good enough picture about possible use and edge cases.\nDo we allow directives with same names and different arguments?\nCan I have a directive, which accepts a complex type which has yet another directive and another type? \nWill it matter to distinguish type traversal from traversal of a type under directive(s)?\nPlease bear with my questions, I will try to catch up with directives and clear my vision.\nSo far most simplest solution is probably the best strategy :) \n. Suggesting to move nextId, vertices, verticesById, edges to the top as per java conventions - 6.2 Placement. \nLine #238 is very unexpected place for key properties which defines this class as a graph. \nTo maintain readability for edges, I would suggest to move anonymous set  into inner utility class and just initialize the variable. \n. > Basic DAG  (dependency graph) implementation\nDo you see this implementation as a data structure or a type?\nIt feels that client is expected to know DAG internal implementation to effectively use it. For example client needs to know which id to which node was assigned to avoid unnecessary duplication. \nDo you plan to add node/edge removal?\n. > It wasn't my intent to create a generic purpose implementation of DependencyGraph.\nI've got my answers. \nThanks for explaining intent behind id correlation. BTW, are you ok if I throw in some test cases (edge/node duplication etc) and play with it?. ",
    "trevor-morris": "I've seen a similar issue, though for me I only saw the problem when the input object was passed as a variable. When it was passed as a literal (as in the example above), only the fields actually present in the literal seemed to be set in the map. The relevant code seems to be in ValuesResolver where there are two methods, one for converting a literal to a map, the other for converting a variable to a map.\nHere's the one for converting a literal:\n``` java\n    private Object coerceValueAstForInputObject(GraphQLInputObjectType type, ObjectValue inputValue, Map variables) {\n        Map result = new LinkedHashMap();\n    for (ObjectField objectField : inputValue.getObjectFields()) {\n        GraphQLInputObjectField inputObjectField = type.getField(objectField.getName());\n        // illegal field ... no corresponding key in the schema\n        if (inputObjectField == null) continue;\n        Object fieldValue = coerceValueAst(inputObjectField.getType(), objectField.getValue(), variables);\n        if (fieldValue == null) {\n            fieldValue = inputObjectField.getDefaultValue();\n        }\n        result.put(objectField.getName(), fieldValue);\n    }\n    return result;\n}\n\n```\nNote how only the fields present in the inputValue (representing the literal) get transferred to the map. However this is the method used for converting a variable to a map\n``` java\n    private Object coerceValueForInputObjectField(GraphQLInputObjectType inputObjectType, Map input) {\n        Map result = new LinkedHashMap();\n        for (GraphQLInputObjectField inputField : inputObjectType.getFields()) {\n            Object value = coerceValue(inputField.getType(), input.get(inputField.getName()));\n            result.put(inputField.getName(), value == null ? inputField.getDefaultValue() : value);\n    }\n    return result;\n}\n\n```\nNote how all fields in the input object type are copied, regardless of whether they are actually present in the input. So, for example, if the input map contained just \"firstName\" = \"X\" and the input type had fields \"firstName\" and \"lastName\" you'd end up with a map containing \"firstName\"=\"X\" and \"lastName\"=null\nIf I'm understanding this code correctly then the fix is trivial - just skip \"inputField\" if input.containsKey(inputField.getName()) returns false.\nI am puzzled, though, that lelong71 is seeing this problem with object literals, as I only see it with input variables (e.g. if the mutation looks like updateNameMutation(input: $input), rather than updateNameMutation(input: { firstName: \"New value\" })). Maybe I'm misunderstanding the original issue?\n. Interesting; this is somewhat related to #106 \nI think that the handling of input objects is inconsistent at the moment. An argument which is an input object can be given a value either via an object literal or a variable value. In either case the value may be incomplete - that is it may omit fields present in the input object type. At the moment I believe the following is true:\nIf given via an object literal then any fields missing in the literal are omitted from the argument value. But default values are not applied for the missing field and I suspect that if one of the missing fields is \"non null\" then that won't get detected either (that's just a guess, based on looking at the code).\nIf given via a variable value then any fields missing in the variable value are still set in the argument value - either to null, or to the default value, if present. Omitting a non null field is also correctly detected.\nI think these two problems are mirror images of each other. In one case (literal -> argument value) we only copy the fields actually present in the input, which means we (correctly) don't copy missing fields but also forget to apply default fields and non null checks for those missing fields. In the other case (variable value -> argument value) we copy all the fields, whether or not they're in the input. That means we correctly apply default values and non null checks, even for missing fields, but we incorrectly set the value of any nullable, non defaulted missing fields to null in the argument value.\nI have a pull request in with what I think is a fix for #106; if I get chance in the next day or so I'll alter it to try and fix this issue, #152, as well.\nOne thing I was unsure about; if the variable value explicitly sets a field to null should the default value apply? (Note: literals can't contain \"null\"). At first I thought not. But reading the GraphQL spec it sounds like items with a default values should be thought of as \"non null\" so I believe that the default should apply even in this case. So, for example, if you have an input object type with a nullable string field \"x\" which has default value \"DefaultX\" then specifying a variable using JSON like { \"x\": null } should result in \"x\" having the value \"DefaultX\".\n. I'm closing this request in favor of #156, which fixed another problem as well\n. I've pushed a new version that should have got rid of the conflicts (force push, I rebased on the latest master)\n. ",
    "shankarRaman": "So when I create a new server side schema, does the \"schema.json\" get automatically generated (which I am not seeing) or I need to do something?\n. Ok thanks.\n. ",
    "kiotoze": "It would be nice to get this feature working. ",
    "dalenavi": "By the spec, 'before' or 'after' should be a cursor type, an opaque node ID, a string. Not an array index.\nTo enable forward pagination, two arguments are required.\n * first takes an integer.\n * after takes the cursor type as described in the cursor field section.\nForward pagination arguments\nAn \u201cEdge Type\u201d must contain a field called cursor. This field must return a type that serializes as a String\n...\nWhatever type this field returns will be referred to as the cursor type in the rest of this spec.\nCursor type\nLet afterEdge be the edge in edges whose cursor is equal to the after argument.\n  If afterEdge exists:\n    Remove all elements of edges before and including afterEdge.\nPagination algorithm\n. I think I'm off track with the above references...\nI had the impression the spec suggested using a node id as the cursor.\nMaybe using the array offset as cursor is also a valid cursor type.\nI see now the array index cursor is still encoded as an opaque node id...\nDoesn't really change the question though.\nIf a client is requesting some List resource using Relay pagination,\nand the underlying List changes between calls,\nthen this situation could occur.\nWhat possible way to prevent it? Can't cache the list-as-it-was-when-first-requested indefinitely.\n. ",
    "dev-rkoshlyak": "look like include did not work as well:(\n. workaround: \nLook like if i need to use directive, I have to use add argument to field \"if\" on which i want to use directive .argument(newArgument().name(\"if\").type(GraphQLBoolean).build())\n. ",
    "Globegitter": "Yep we are running into this as well now and neither field @include(if: false) nor field @skip(if: false) does work but @dev-rkoshlyak workaround seems to do the trick for now.\n. Oh sweet. Also as an example of how the go library is handling it: https://github.com/graphql-go/graphql#origin-and-current-direction\nPlus in the PRs they specifically tracks the graphql-js version. Graphql for python handles it similarly. \n. @andimarek Yeah that is understandable. There is one community project though that tries to help with that: https://github.com/graphql-cats/graphql-cats. ",
    "alexkrebiehl": "Please try out the fix and let me know what you think.  This also fixed an issue with fragments not being resolved.\nThe issue was that each GraphQLObjectType that had a field that referenced another GraphQLObjectType was pointing to a different instance of that model type.  For example, x.y's reference to y was pointing to a different instance of y than z.y's reference to y.  Only one instance of y would have its type references resolved.  Unless you were pointing to that instance, you wouldn't see the updated model.\nThe problem was fixed by making sure each GraphQLObjectType reference was pointing to the same instance of GraphQLObjectType from the typeMap. \n. I'll look at making a test case for this.\nAs far as reference vs deep equality, I don't think it will help here (at least in my use case).  I'm using graphql-java-annotations and building the schema at runtime, so nodes being created don't know about other nodes that were already created. \nSince we actually alter the object when resolving type references, we either need to make sure everything is pointing to the same instance of that object, or we have to resolve type references for all of the duplicates.\nI don't think this will help #85 very much, since they are generating types on the fly.  However, this fix did solve my problems with fragment spreads.  Did you still have the fragment issue after the fix in this PR?\n. ",
    "ceronman": "I can confirm that after applying this PR, the issue described in #193 disappeared completely.\n. I have tried this with the last version of graphql-java and graphiql worked just fine. It think this issue can be closed. Thanks!\n. After discussing this with @yrashk from graphql-java-annotations, he mentioned that this might be a duplicate of #118. I have tried pull request #123 and the patch indeed fixed my issue. I hope it could get merged soon.\n. ",
    "DomKM": "I am also running into this issue. @kaqqao's suggestion that the DataFetchingEnvironment be made available to TypeResolver would solve it perfectly. This is also the approach that Apollo's graphql-tools uses for their type resolver signature.\n. ",
    "sazzer": "Turns out I'm just an idiot, and I wasn't correctly putting the response data into a \"data\" object. Doing that and it all works. :)\n. The problem is in PropertyDataFetcher.getPropertyViaGetter(). Updating it to support both isX and getX fields looks simple enough, so I might have a go if I get enough spare time.\n. If you have both an isXxx and a getXxx method for the same name but with\ndifferent return types, you're not a valid Java bean according to the spec.\nIt's acceptable to have both but they should reflect the same field and\ntherefore have the same value.\nIf the PropertyDataFetcher is to be used purely for beans this means this\nis a non issue. If it's to be used for any arbitrary class then your right\nit causes problems...\nOn Sun, 8 May 2016, 22:06 danielkwinsor, notifications@github.com wrote:\n\nI like PropertyDataFetcher the way it is, but alternative behavior can be\nsubclassed. The reason I like it as is: consider isClass and getClass. Or\nconsider isAnything and getAnything where the return types are different,\nor what is not expected. This could be worse than getting null values.\nWith that said, I've already subclassed these fetchers in my own code and\nsuggest the same here.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/130#issuecomment-217746128\n. Fixing this is probably as simple as changing the method to read: (Note I wrote this here and haven't tested it)\n\njava\n    private Object getNameByValue(Object value) {\n        Object valueToUse = value;\n        if (value instanceof Enum) {\n            valueToUse = ((Enum)value).name();\n        }\n        for (GraphQLEnumValueDefinition valueDefinition : valueDefinitionMap.values()) {\n            if (valueToUse.equals(valueDefinition.getValue())) return valueDefinition.getName();\n        }\n        return null;\n    }\n. Ah - Somehow I'd missed that there was a version of GraphQLEnumType that\ntakes an Object as the value. I've been using just the single-param\nversion. I'll give that a go and see what happens :)\nOn Wed, 11 May 2016 at 21:33 danielkwinsor notifications@github.com wrote:\n\nCan you please show your GraphQLEnumValueDefinitions? From my reading of\nthe code, the definition has a value of type Object, so you can insert\nPlanets.EARTH as value. When your DF returns Planets.EARTH that should\n.equal().\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/137#issuecomment-218581362\n. I've just tried it with the method that you've mentioned, and it turns out that it works fine. Sorry about that :(\n. \n",
    "zhbrass": "I modified the gist by @dminkovsky to use pre-Java 8 features. Feel free to use.\nhttps://gist.github.com/zhbrass/1fd7fbabad852a323740682065708b1b \n. ",
    "RusticFlare": "(Because I still had to go looking for this)\nYou can print by using the SchemaPrinter class.\njava\nSchemaPrinter schemaPrinter = new SchemaPrinter();\nschemaPrinter.print(schema);. @bbakerman Thanks for the feedback \ud83d\udc4d I'll get on it. @bbakerman I've added the ability to set the Executor you use with the method AsynchronousDataFetcher.executeIn(Executor). \nUsed like this:\njava\nGraphQLFieldDefinition.newFieldDefinition()\n        .dataFetcher(async(fooDataFetcher).executeIn(somePool))\n        // ... rest of field definition. @bbakerman I've gone with your first suggestion and added another static: asyncWithExecutor \ud83d\ude42 . @bbakerman Thanks for being patient with me \ud83e\udd47  . Thank you \ud83d\udc4d . Sorry for being picky but there's a double space after the full stop \ud83d\ude0a . Sure, no worries \ud83d\udc4d . I'm not sure I understand?\nThis method exists to take a List of (input/payload) fields and add the clientMutationId field. But the given List may be immutable, so we need to copy its elements to a new List that lets us add the clientMutationId field.. ",
    "ayhanap": "I also had problem with Boolean property accessors generated with Lombok and IDEA. The convention suggests is prefix for primitive boolean getters, so I think supporting get prefix for Boolean getters should bring no harm.\nAggree @sazzer for classes having both isXxxand getXxx. Even that is the case supplied a pull request #164 prioritizing is over get prefix for Boolean properties.\n. Thanks for review @markphilpot The current flow to find property data is as follows\n1. Try accessor methods. If the property is boolean use is getter methods instead of get.\n2. If no method exists then .. If the property is boolean, try get accessor method also.\n3. If no method exists then .. Get property data with field access.\nBefore this PR the current flow was 1 then 3, without 2.\nSo the code in your inline comments does not fulfill the requirements. Therefore I suggest you to check working code and let me know if this makes sense.\n. @dminkovsky Looks simpler and more explanatory indeed. \n. Updated the PR with @dminkovsky's cleaner suggestion.\n. Sorry missed that. Fixed that.\n. I think searching for method names containing fielddefinition names could lead to some unexpected results.\nAll I can think is to search for a method name as exact field definition name. So that way you can define field definitions on your getter method name. And the example scenario I mentioned is as follows.\nnewFieldDefinition()\n            .name(\"shouldUpdateAccount\") // instead of using updateAccount\n            .description(\"Should Update Account Details\")\n            .type(GraphQLString)\n            .build()\nAnd a POJO like this\npublic class Account{\n    boolean updateAccount;\n    public shouldUpdateAccount(){\n        return this.uppdateAccount;\n    }\n}\nWhat do you think @aschrijver. \n. Agree, those other requirements need more discussion and evaluation. Keeping in mind that this class is responsible of most of the data fetching, it should be fast and simple.\n. Right, just removed the unnecessary catch block for NoSuchMethodException\n. ",
    "arlampin": "Sure. Created #151 that fixes the issue.\n. #151 was merged, closing\n. @dminkovsky any update on this?. Could this be merged? Currently graphql-java doesn't realistically support directives, as you would need to add all arguments from all directives to all fields where you would like to use those directives.. @bbakerman there's already an open PR that fixes this. That's another issue, I was talking about BatchedExecutionStrategy.handleList(), not overall BatchedDataFetcher return type.. I updated PR to use the exact same logic as regular ExecutionStrategy, which supports arrays (and also primitive arrays after #681 has been merged). Are there any plans for improving DataLoader batching regarding this issue? We are currently using BatchedExecutionStrategy because it handles this case properly, but would like to switch to async DataLoaders.\nI wonder if BatchedExecutionStrategy itself contains something that could be reused for this?\n. I take it this made it to 9.0 after all?. We have a similar situation (I think). We have a DataLoader DataLoader<ID<Foo>, Bar>, which is implemented by fetching a Map<ID<Foo>, ID<Bar>> from backend, then loading each individual Bar by its ID. The backend basically returns a Foo ->Bar map.\nFor various reasons, we can't return the full Bar instance in the initial query, but have to load them separately. Since we already have a DataLoader to fetch Bar instances by their ID, I though I could use that to .loadMany the IDs.\nIn our case, a large number of requested Bar instances are already loaded from backend within the same GraphQL query, so by re-using the same ID loader we save lots of backend queries due to DataLoader cache.\n. @bbakerman sure. Something like this.\n```\nDataLoader, Bar> barIdLoader = ...;\nDataLoader, Bar> fooBarLoader = new DataLoader<>(keys -> {\n  CompletableFuture, ID>> query = backend.asyncGetFooBarMap(keys);\n  query.thenCompose(map -> {\n    List> barIds = new ArrayList<>(map.values());\n    return barIdLoader.loadMany(barIds).thenApply(bars -> {\n        Map, Bar> barIndex = bars.stream().collect(toMap(Bar::getId, Function.identity()));\n        return keys.stream().map(map::get).map(barIndex::get).collect(toList());\n    });\n  });\n});\n```\nYeah, I'm not sure if there's any clean solution to automatically dispatch the call.... Yeah, thanks, that's what I thought. We are now doing the dispatch thing and it works well enough.. Thanks, I tested with the latest development snapshot and it seems to work \ud83d\udc4d . Something to do with #1216 maybe?. OffsetDateTime was just a single example, there are plenty of other use cases where one might want to overwrite serialization without creating a distinct scalar. Object.toString()'s method contract doesn't require it to return particularly usable output, it's meant as development and debugging aid.\nThis isn't limited to GraphQL String type either. For example, we have a class ID<T> mapping to GraphQL ID type in the schema. toString returns e.g. Project:123 for debugging purposes, but in GraphQL output that value is base64 encoded using custom DataFetcher.\n. This is not always safe, as estimateSize() can return Long.MAX_VALUE in certain cases. Since values are anyway copied to a new list few lines below this, you could just check that one after copying.. ",
    "Jimexist": "I think you just need to implement DataFetcher and then get the File or FileInputStream from the context/environment. There is very little to be done this library.\n. Really appreciate this repo and everyone's contribution to it. I'm also a bit concerned about the low maintainance mode - maybe there is a way to allow people/community to contribute more actively?\n. thanks!\n. it... sort of. i was seeing failure for parsing unicode. in fact there was no implementation yet so i went on to add minimal test for non-unicode cases. would be happy to do another pr for unicode support though.\n. @bbakerman been busy recently, thanks for taking over. \bthe client is seeing this (our set up is jersey and dropwizard based, and this stack trace is printed on log and client gets 400 as configured).. ideally this can be solved using java 8's Base64 class but i guess the back-compat dependency requirement forbids that. this is arguably a bug in javax.xml.bind.DatatypeConverterImpl.guessLength presuming that a char must fit into a byte - which is not the case in unicode. i think at least the excetion thrown out should not be array index out of bound which is misleading. @andimarek yes i think so. @bbakerman i agree with you but i would go ahead and make my PR smaller - maybe your idea is better implemented in another PR.. @bbakerman ok thanks!. @dminkovsky did you mean the relay as an idea or the relay implementations in this repo?\n\nas an idea i could appreciate relay's approach to consolidate and decide on some standard (but not necessarily the only) way of implementing object identification (Node) and relationships (Connection) - the point is that for a sophisticated enough application there is going to be one, and relay just happens to be a good standard people could follow and they've already got better documentation than I personally could come up with so I would stick to that\nas an implementation I would argue that this package is preliminary. Relay should've been a utility class rather than a new-able one, and the connection class support is lacking.\n\nFor 2. I can volunteer to contribute. I wouldn't call one's usage of relay incorrectly considering that it is just an idea and a proposed implementation - there is no absolute standard that one must follow.. @dminkovsky i did find the type resolving of Node requiring a bit more efforts - especially when the individual types depend on the Node interface while the latter depend on individual types as well - this circular dependency requires more efforts (I am using Guice). But other than that - I am using Pojos in data fetcher's return value and then rely on getters to fill the fields on GraphQLTypes. ... missed one point, I am also using Jackson's data mapper to do convertion between Pojo's and Map<String, Object> - can't really go beyond that because Java is relatively lacking the support for type magics.. regarding @Internal i think putting internal in package name is a good practice. @dminkovsky I tried but failed to find a concrete example of replaying my issues - i'll come up with a better test case should i encounter my original problem again. Sorry for the mistake - and please feel free to close this PR.. i think it is confusing that execution could at the same time throw GraphQlError and return GraphQlError. is there an ETA for this? at least can bump the version in master so that many stream APIs and lambdas can be put in.. @bbakerman done . @andimarek sorry about the format - it is fixed now. @andimarek @jplock this is fixed now. @andimarek the fact that it is named with Util makes it useful in many other occasions, and making it stateless (i.e. static utility functions only) will make it easier to reason about thread safety, etc. And i think it is just a matter of convention that utility functions are static and they operate solely on the inputs, not the containing object's state.. @andimarek separation of PRs makes sense - so I created this https://github.com/graphql-java/graphql-java/pull/364. i don't have a strong argument against mock-ability - so feel free to close this if you believe this is unnecessary.. @bmsantos @andimarek \nI agree that\n\ud83d\udc4d:\n- static functions are great for static importing\n- static functions are easier to reason since they are meant to be stateless, and pure\n\ud83d\udc4e:\n- some times static importing makes code less readable\n- static classes are bad for mocking\nMy opinion is that:\n- personally I am not a big fan of big util class, and I don't think it is good practice to name any class with xxxUtil (no offense intended), since it gets big pretty quickly and stuff gets dumped into it carelessly. it is generally a good idea in terms of maintainability to tear it apart into specific named classes e.g. (GraphQlTypeCollector or TypeReferenceResolver) and have them made mockable with interface + impl. class\n- that said, one should not over-do it because there is a price to pay for abstraction (i.e. flexibility), and dependency chain gets pretty long pretty quickly (and soon there's need for Guice or Spring). for simple static utility functions, i think it is fair to trade mock-ability (i.e. flexibility) with simplicity - You'll just have to test the utility function and also accept the fact that it has a single behavior and baked into whatever class that uses it. i could create a PR and let's see what's changed? @andimarek @bbakerman . https://github.com/graphql-java/graphql-java/pull/383. @bbakerman good point, reverted src/test/groovy/graphql/GarfieldSchema.java and src/test/groovy/readme/ReadmeExamples.java. @bbakerman do you think it's worth the effort to address the dup code and extract them into a utility function?. ok that's a fair point. i'll close this issue.. Sorry for the lack of explanation here. Indeed in the situation you mentiond here it didn't matter. But in cases the map is converted using jackson the key being absent is different than null value. One of the cases will trigger an unknown field exception.. You are right for this specific line change i should've put into a separate pull request that fixes similar things. Will be more careful next time.. will do - and i'll update this PR soon. thanks for the comment.. might be a good thing to assert that it is either 0 (unlimited) or positive?. why not just instanceOf Number?. not in this package - but it is always good to be cautious before deleting a public class. having said that, it is fair enough to delete it in a breaking release.. ok. ok. ",
    "0x6e6562": "@andimarek Not sure how helpful it is to suggest something from a different platform, but in the Absinthe GraphQL server library, you can get a handle on Elixir equivalent of a Java ServletRequest - they call it %Plug.Upload{} in the standard library, but the abstraction would be isomorphic in Java:\nelixir\nmutation do\n  field :upload_file, :string do\n    arg :payload, non_null(:upload)\n    arg :metadata, :upload\n    resolve fn args, _ ->\n      args.payload # this is a `%Plug.Upload{}` struct.\n      {:ok, \"success\"}\n    end\n  end\nend\nAs previous posters have said, it is possible to craft this from the library as is, so strictly speaking this is not necessary. But it would be nice from a documentation perspective.. @andimarek I would gladly raise a PR to help other people with this issue, but for various different reasons, I decided to abandon file uploads via graphql-java, so I didn't put the time in to figure out how to wire this into a programmatic field definition. I just made the point about the upload support because I had used it on a different project (using a different graphql server package).. ",
    "loganvolkers": "If someone is looking to implement this, here is a proposed spec that uses multipart upload: https://github.com/jaydenseric/graphql-multipart-request-spec. If someone is looking to implement this, here is a proposed spec that uses multipart upload: https://github.com/jaydenseric/graphql-multipart-request-spec. If someone is looking to implement this, here is a proposed spec that uses multipart upload: https://github.com/jaydenseric/graphql-multipart-request-spec. I found this reference for GraphQL js for inspiration: https://github.com/taion/graphql-type-json/blob/master/src/index.js. So we copied the approach from GraphQL.js.\n\nHopefully this helps other people implement custom scalars\nOr the GraphQL.java maintainers tell us this is the wrong approach.\n\njava\n    static JsonNode valueToJson(Value v) {\n        if (v instanceof BooleanValue) {\n            return JsonNodeFactory.instance.booleanNode(BooleanValue.class.cast(v).isValue());\n        } else if (v instanceof EnumValue) {\n            return JsonNodeFactory.instance.textNode(EnumValue.class.cast(v).getName());\n        } else if (v instanceof FloatValue) {\n            return JsonNodeFactory.instance.numberNode(FloatValue.class.cast(v).getValue());\n        } else if (v instanceof IntValue) {\n            return JsonNodeFactory.instance.numberNode(IntValue.class.cast(v).getValue());\n        } else if (v instanceof NullValue) {\n            return JsonNodeFactory.instance.nullNode();\n        } else if (v instanceof StringValue) {\n            return JsonNodeFactory.instance.textNode(StringValue.class.cast(v).getValue());\n        } else if (v instanceof ArrayValue) {\n            final ArrayNode result = JsonNodeFactory.instance.arrayNode();\n            for (final Value v2 : ArrayValue.class.cast(v).getValues()) {\n                result.add(valueToJson(v2));\n            }\n            return result;\n        } else if (v instanceof ObjectValue) {\n            final ObjectNode result = JsonNodeFactory.instance.objectNode();\n            for (final ObjectField f : ObjectValue.class.cast(v).getObjectFields()) {\n                result.set(f.getName(), valueToJson(f.getValue()));\n            }\n            return result;\n        } else {\n            throw new IllegalStateException(String.format(\"Unsupported value type: %s\", v.getClass()));\n        }\n    }. Great concerns @bbakerman. The following is a list of tools that I have used that support a JSON Scalar over the past year (note that Graphql java and graphql-java-tools compatibility was confirmed today with the above code)\n\nApollo Client\ngraphql-tools\ngraphql-js\ngraphql-java\ngraphql-java-tools\ngraphiql\ngraph.cool. Hey Brad thanks for taking a look and getting back to me quickly.\n\nThe document that I linked you in hindsight isn't necessarily the best because it focuses more on the web frameworks of the world. In reality though, OpenTracing has instrumentation for many types of IO operations: JDBC, Mongo, RPC, \nThe way that I see this implemented is like this:\n 1. The instrumentation would need some way of accessing a parent Span.  In order to create an OpenTracingInstrumentation instance you'd likely need to provide a Supplier<Span> and Supplier<Tracer> (or Provider) to access the global Tracer and the parent Span from the upstream web framework or other context.\n 2. Create a child Span for the entire GraphQL request.\n 3. Create a child Span for each resolver\nI'm definitely not an expert on OpenTracing, but I do know that it seems to have some excellent open source momentum as a replacement to Zipkin.\nFor inspiration here are a couple things that may be of use:\n - Jaxrs implementation\n - https://github.com/opentracing-contrib\n - https://github.com/openzipkin/brave\n - http://zipkin.io/pages/existing_instrumentations.html. ",
    "iancw": "I've expanded the provided example for a bit more context.  When I put a variable named uuid_0 in the arguments map, I still get ValidationError: Validation error of type UndefinedVariable: Undefined variable uuid_0 during validation.  I also attempted $uuid_0 with same result.\nWhen I provide the values statically, the framework automatically puts them into the arguments map.  For example, this works.\nquery  {\n    account(uuid:\"88888888-4444-4444-4444-121212121212\") {\n        ...\n    }\n}\nAnd uuid shows up as a key in the arguments map.  It looks like the Graphql grammar the parser is based on understands variables, but there is no grammar for specifying the values of said variables.  They appear instead to be passed as part of a JSON request alongside the GraphQL query by react / express-graphql and graphql-ruby in a extra-graphql capacity (as described above).\nI see no mechanism to set them in graphql-java currently.  I could easily write a wrapper in my service to parse JSON response and stick the variable definitions somewhere.  There doesn't appear to be a place though.  If I'm corrected, I'll happily submit a PR to the README that documents how to do this.\n. So I just found your TODO MVC example, and see that you do in fact use variables as described above (https://github.com/graphql-java/todomvc-relay-java/blob/master/src/main/java/todomvc/GraphQLController.java#L33-L34). And also it seems to be working fine for me now.  Maybe I just needed to clean & rebuild or something. Working on a PR to update README as promised. \n. I submitted a PR to README to document how variables are supported.   Not sure when / if that will merge, so I'm just closing this issue. I have my graphql-Java server working with relay following advice from @danielkwinsor.  Thanks!\n. ",
    "devtomk": "Are variables really supported? Maybe I am missing something, but the following code always results in an error \"Validation error of type UndefinedVariable: Undefined variable personId\"\nString query = \"query { person(id: $personId) { id, name } }\";\nMap<String, Object> variables = new HashMap<>();\nvariables.put(\"personId\", \"42\");\n\nExecutionInput input = ExecutionInput.newExecutionInput().\n    query(query).\n    variables(variables).\n    build();\nExecutionResult result = graphQL.execute(input);\n\nThe following works without problems:\nString query = \"query { person(id: \\\"42\\\") { id, name } }\";\nExecutionInput input = ExecutionInput.newExecutionInput().\n    query(query).\n    build();\nExecutionResult result = graphQL.execute(input);\n\nI am using graphql-java 4.0 \n. ",
    "SebastianWjertzoch": "I have the exact same problem with version 4.1.. We both use the ExecutionInput. So type declaration is not part of the query.\nLike this\nString query = \"query { person(id: $personId) { id, name } }\";\nMap variables = new HashMap<>();\nvariables.put(\"personId\", \"42\");\nExecutionInput input = ExecutionInput.newExecutionInput().\n    query(query).\n    variables(variables).\n    build();\nExecutionResult result = graphQL.execute(input);. Ok. So i have to build an special query for every kind of request. I was confused because this: \nquery { person(id: \\\"42\\\") { id, name } }\nworks fine without special queries.. ",
    "camuthig": "@dminkovsky it looks like this merge didn't make it's way into 2.2 either. \nIs there a plan to get conflicts resolved and merge this in the near future? Seems like it would cover most all of the requirements for implementing the new functionality (if maybe not schema language, I'm uncertain about that) in the recently merged GraphQL Null RFC. \n. ",
    "crazytoucan": "I am quite excited for this PR, as this will get us closer to out-of-the-box correctness with latest versions of GraphiQL. Is there anything blocking this merge?. ",
    "emrul": "I had the need for storing metadata on fields.  I did it by extending graphql.language.FieldDefinition with additional properties and passing that in to my builders.\nIn my data fetchers I can call environment.parentType.getFieldDefinition.getDefinition and check if its an instance of my subclass - if it is I can access the metadata to customise how my DataFetcher behaves.\nThe metadata I'm storing should never go to the client so I don't have to worry about serialising it.. Hi, I just tried your PR and unless I've made a mistake I think its failing.\nI believe it is because SchemaUtil() has a reference to Introspection.__Schema in the method collectTypes()\nIf I use the default it is fine but if I wire my own in and issue an Introspection query I get \nValidation error of type InvalidFragmentType: Fragment FullType cannot be spread here as objects of type GraphQLObjectType{name='__Type', description='null', fieldDefinitionsByName={kind=graphql.schema.GraphQLFieldDefinition@386cac77, name=graphql.schema.GraphQLFieldDefinition@7f61d90a, description=graphql.schema.GraphQLFieldDefinition@50e0e4d8, fields=graphql.schema.GraphQLFieldDefinition@2f04c3d1, interfaces=graphql.schema.GraphQLFieldDefinition@72d6cd52, possibleTypes=graphql.schema.GraphQLFieldDefinition@30ee38b, enumValues=graphql.schema.GraphQLFieldDefinition@549f0116, inputFields=graphql.schema.GraphQLFieldDefinition@5d0c5a1f, ofType=graphql.schema.GraphQLFieldDefinition@1974a0b1}, interfaces=[]} can never be of type GraphQLObjectType{name='__Type', description='null', fieldDefinitionsByName={kind=graphql.schema.GraphQLFieldDefinition@6d120aaf, name=graphql.schema.GraphQLFieldDefinition@412921aa, description=graphql.schema.GraphQLFieldDefinition@7e4a4732, fields=graphql.schema.GraphQLFieldDefinition@42871162, interfaces=graphql.schema.GraphQLFieldDefinition@3f3d3cef, possibleTypes=graphql.schema.GraphQLFieldDefinition@37916ed3, enumValues=graphql.schema.GraphQLFieldDefinition@1bcedcc4, inputFields=graphql.schema.GraphQLFieldDefinition@6138c2de, ofType=graphql.schema.GraphQLFieldDefinition@37345052}, interfaces=[]}. I made a PR along your original suggestion of having an IntrospectionTypeProvider - the only real differences are:\n\nSchemaUtil.allTypes() references the schema provided by the TypeProvider\nInstead of configuring the GraphQL instance I configure the GraphQLSchema.  I write Kotlin but I've made a Java example:\n\n`\n    GraphQLSchema schema = GraphQLSchema\n            .newSchema()\n            .query(...)\n            .mutation(...)\n            .introspectionTypeProvider(MyIntrospectionProvider.INSTANCE)\n            .build(...);\n\n`\nThis works, I suspect because of the change to SchemaUtil()\nI'll be very happy to use the naming conventions in your PR, I also have no issue with configuring the introspection provider at the GraphQL level but I suspect we'll need to find a way to still push this down into the GraphQLSchema instance so that it can pass it on to SchemaUtil()\nThoughts and pointers much appreciated!. @bbakerman this has been quiet for a couple of weeks - do you have any idea on whether you'll be able to correct your PR or accept mine?. @bbakerman I'm a little confused - who and where is this opposition coming from? I received no comments on my PR or in this issue other than from yourself.\nI'm also not sure I understand the complexity argument.  The current code base has a static class (SchemaUtil) that makes a direct reference to a static singleton inside one of its methods.  It could be argued that unless the developer were intentionally trying to make it impossible for this code to be extended there are more flexible code constructs that would otherwise be more appropriate.  Even if you had 2 separate GraphQL instances in a JVM they would currently share the same reference to IntrospectionSchema.\nMy proposed patch (I would guess) changes less than 100 lines and refactors the code I mentioned above so it becomes extensible and we no longer have a totally inflexible reference to a static singleton.  Now library users can extend and override behaviour if they need to.\nI'm not sure how, given some of the other PRs and library features there are in GraphQL-Java and the intent of this particular PR to do a small bit of clean up, that this one should get picked up as contributing to a 'more complex library for the sake of a small user case'.  I'm also slightly taken aback that this has seemingly happened in the shadows somewhere while this issue has been left dormant and I've had no clue - that questions the level of transparency that this project is striving for.\nI appreciate the use case you reference.  Its not the same as ours and maybe when you have a finite number of possibilities it is simpler to have separate schema.  However, I would point out that if my suggested approach was taken then you could meet the public / private company API requirement without much effort other than writing a filter at Introspection schema level - far easier to manage than a separate API.\nI have a meeting with the rest of the team on our current project this afternoon.  We'll discuss the project feedback there and decide on how to proceed.. Thanks for the explanation @andimarek.  I understand your situation.  We're of course open to the idea that not all our patches are things that other people would want.  I would still ask you to consider whether such tight coupling in this instance is a good idea in what should be a library for other developers to be able to use and extend.\nWe will most likely maintain our work in a separate fork and we'll try to track this projects releases as closely as possible.\nPlease feel free to close this issue & associated PR.. Guys, I think we're set with maintaining our fork as the approach forward so your choices here really won't impact us.  We are discussing whether we can spend time to publicly release our work (mainly about providing more enterprise-y features) after project has launched.\nThat said, I don't know who's usecase @bbakerman is targeting but it certainly would not be something we could use.  I also would point out that DataFetchers would need to do security checking even if you kept n schemas in memory (unless you had separate DataFetchers for each schema..  at which point the question is what benefit are you getting?)\nProviding a switch to switch introspection off is something that might be useful for some, but it sounds like it will create a LOT more headache to actually make that a useable approach.  It also sounds like it will involve more complexity than what I suggested.  And you will still need to refactor that tightly coupled relationship between SchemaUtil and Introspection classes.\nIt is also not 'security by obscurity' to design a system that hides inaccessible fields as long as it also prevents access to those fields - you as library designers can't make sure users do the right thing.\nOverall I would suggest against this - unless I'm mis understanding some use case I'm not sure how the alternative proposal provides any useable benefit.. @andimarek I think you might have not read my related comment on the PR I provided: https://github.com/graphql-java/graphql-java/pull/557#issuecomment-313707486 \"We initially thought about building multiple GraphQL schemas but the project anticipates that access should be controlled at group level and having a large number of instances of GraphQL schemas for each permutation just isn't feasible.\"\nEssentially it was one of our early thoughts/plans but it just wasn't viable.  I fully agree, if we had a well-defined split between, say, public and private users, we could work with your suggestion.  But instead we have a group hierarchy and certain groups are permitted access to certain fields (and sub-fields).\nIn our current setup, with the patch we have applied it works very well: the DataFetchers are calling out to an ACL check to make sure users are authorised to request the particular fields they're asking for.  If a user tries to query something that they don't have access to we return an error that looks like the field just doesn't exist.  Now, returning a 'field doesn't exist' error while the Introspection schema says it does wouldn't make any sense - so we applied the same ACL checks on introspection queries.\nUpon reflection, this probably isn't something most users of this framework would have to do - we just needed it because our customers are rather particular about this sort of thing.. I've made some changes against the latest master.  It isn't ideal but at least allows me to override the data fetchers for Introspection queries.\nFeedback welcome, if there is an alternative way of achieving this I'll happily switch to it.. The project I'm working on has quite stringent security requirements: we use SSL client certificates, each user is bound to a database role.\nYou allude to the business requirement when you mention SQL views - but views aren't the only way in SQL.  MS SQL Server, Postgres and Oracle all support 'column level' security.  In this case a role can be restricted from even knowing about the entire schema.  For a write up on how this is done in Postgres see here: https://www.depesz.com/2009/01/31/waiting-for-84-column-level-privileges/\nThe reason for this exists at all in the SQL world is to prevent information leakage.    We want to pass through the column level controls from our SQL database onwards into GraphQL\nSay we have an object with about 50 fields - one group of users who can see all of them, and another group who can see just under half.  The group of users who can see the reduced set must not know about the existence of the other fields.  This bit is key: field names convey the potential existence of certain data and we don't want certain groups of user even knowing about them.\nWe initially thought about building multiple GraphQL schemas but the project anticipates that access should be controlled at group level and having a large number of instances of GraphQL schemas for each permutation just isn't feasible.\nThe smartest thing to do seems to be to filter the schema when its requested based on what the user can actually see.  I don't see anywhere in the GraphQL spec that says we should return the entire schema, especially when in our case it will mean most user groups will see and interact with only 20-30% of it.  Sangria has a SchemaFilter that can achieve similar, it's also very easy to do with GraphQL JS.\nI hope you'll agree on the business case, if so I can refactor my PR so that we do it via an IntrospectionTypeProvider on the builder.  What do you think?\n. I'd been off our project for a while but am now back on it and I have to say, on initial glance this work looks really, really great.  I think we can get behind this and kick-away our custom fork - thank you @bbakerman & @andimarek !. ",
    "fibbers": "After debugging this a bit futher, I now see when the error is thrown.\nSome debugging notes about the variables when evaluating VariableTypesMatchRule.checkVariable:\n\n this results in the error:\n\nvariableReference: VariableReference{name='orderBy'}\nvariableDefinition: VariableDefinition{name='orderBy', type=NonNullType{type=ListType{type=TypeName{name='UserOrdering'}}}, defaultValue=null}\nvariableType: GraphQLNonNull{wrappedType=graphql.schema.GraphQLList@259b9b2e}\n  wrappedType: graphql.schema.GraphQLList@259b9b2e\n    wrappedType: graphql.schema.GraphQLInputObjectType@259b9b2e\n      name: \u201cUserOrdering\u201d\ninputType: graphql.schema.GraphQLList@37d2f318\n  wrappedType: graphql.schema.GraphQLInputObjectType@37d2f318\n    name: \u201cUserOrdering\u201d\n\n\nthis results in a succesful response:\n\nvariableReference: VariableReference{name='orderBy'}\nvariableDefinition: VariableDefinition{name='orderBy', type=NonNullType{type=ListType{type=TypeName{name='UserOrdering'}}}, defaultValue=null}\nvariableType: GraphQLNonNull{wrappedType=graphql.schema.GraphQLList@5cb3019a}\n  wrappedType: graphql.schema.GraphQLList@5cb3019a\n    wrappedType: graphql.schema.GraphQLInputObjectType@5cb3019a\n      name: \u201cUserOrdering\u201d\ninputType: graphql.schema.GraphQLList@5cb3019a\n  wrappedType: graphql.schema.GraphQLInputObjectType@5cb3019a\n    name: \u201cUserOrdering\u201d\n\n\n\nNow, let's find out why variableType.wrappedType sometimes refers to a different object than inputType (which causes VariablesTypesMatcher to error).\n. I'm using Play Framework as my server. Seeing that this error is almost consistently reproducable (sometimes all goes well though and only after trying a few times on Dev mode*), I'm thinking maybe something weird is going on related to classloaders. Just a hunch though :-)\n* when sending a query, each time dev-mode seems to restart and reload classes, which is why I'm thinking it is classloader related. I haven't seen a succesful attempt on production, though.\n. You pointed me in the right direction @TomerSabags, thanks!\nI already created my schema as a Singleton instance to prevent re-creating the schema on each query. However, my schema had multiple connections pointing to the same type, but using a different db-query (e.g. a User-connection from a Department-type, or a User-connection from a Project-type). Each User-connection accepts the same arguments, such as UserOrdering. This meant that if I had 3 User-connections in my schema, I also created 3 instances to handle the UserOrdering argument.\nAfter caching and reusing the GraphQLInputObjectType for this UserOrdering argument when constructing the schema, the == checks now succeed and thus, sending enum-arguments as variables works!. ",
    "iatzmon": "I'm having the same problem using Apollo as my client\n. ",
    "TomerSabags": "I had the same issue and managed to solve it, you might have the same problem - \nwhen creating the schema I used a method for creating each enum - so each time (for every query) this enum was created again and that's why the \"==\" check failed.\nTo solve it I created a map (while initializing the schema generator class) of every enum type in my schema and I defined the schema enums directly from this map, in that way the queries are all using exactly the same enum instance and the \"==\" check passes.\nHopefully this helps\n. ",
    "brimworks": "I'm willing to help with the change related to supporting TypeReferences as input types, but it appears that this PR also contains changes to add extra context information to the TypeResolver interface (which requires Java 1.8).\n...I think @dminkovsky was hoping that the TypeReference as input change would include unit tests, and I think @IamCornholio was hoping that a schema validation check would be added to detect when a circular input type is declared as \"non null\" (and thus it would be impossible to provide such an input that would be valid).\n@kaqqao, if you don't think you address the above two items, I can extract out the TypeReference parts of this pull request and address the above two items as a separate pull request from me, but I don't want to rudely undermine your pull request. Please let me know your plan by Monday, otherwise I'll just open a separate PR that addresses these issues.\nThanks,\n-Brian. > Not sure if I should also re-apply the commits that were adding support for TypeReferences as possible types in GraphQLUnionType and as interface types in GraphQLObjectType.\nYes, I think we need to do that. For implementation, perhaps a minor refactor can be performed, although I'd love to get @dminkovsky's opinion. Specifically, if we introduce this interface:\njava\npublic interface ResolveTypeReferences {\n    public void resolveTypeReferences(SchemaUtil util, Map<String, GraphQLType> typeMap);\n}\n...then SchemaUtils gets this change:\njava\n    void replaceTypeReferences(GraphQLSchema schema) {\n        Map<String, GraphQLType> typeMap = allTypes(schema, schema.getDictionary());\n        for (GraphQLType type : typeMap.values()) {\n            if (type instanceof ResolveTypeReferences) {\n                ((ResolveTypeReferences)type).resolveTypeReferences(this, typeMap);\n            }\n        }\n    }\n...and then modify the existing (and new places) where replaceTypeReferences is defined so they all implement the ResolveTypeReferences interface.\n...this way the logic for resolving the type references can be pushed down into the individual types.\nFor \"bonus points\", the SchemaUtil.resolveTypeReference and SchemaUtil.resolveTypeReferences methods could be turned into generic methods so we can avoid all this type casting:\n```java\n     T resolveTypeReference(T type, Map typeMap) {\n        if (type instanceof GraphQLTypeReference || typeMap.containsKey(type.getName())) {\n            GraphQLType resolvedType = typeMap.get(type.getName());\n            if (resolvedType == null) {\n                throw new GraphQLException(\"type \" + type.getName() + \" not found in schema\");\n            }\n            return (T)resolvedType;\n        }\n        if (type instanceof ResolveTypeReferences) {\n            ((ResolveTypeReferences) type).replaceTypeReferences(this, typeMap);\n        }\n        return type;\n    }\n<T extends GraphQLType> List<T> resolveTypeReferences(List<T> types, Map<String, GraphQLType> typeMap) {\n    List<T> resolvedTypes = new ArrayList<T>();\n    for (T type : types) {\n        resolvedTypes.add((T)resolveTypeReference(type, typeMap));\n    }\n    return resolvedTypes;\n}\n\n```\n. > I need some help as to where to put the check for non-null circular references. I was thinking it should be somewhere at the end, once the schema has been already built. What do you think?\nIt seems the GraphQLSchema  constructor is the logical place to do this check. For implementation, I'd do what graphql.validation.Validator does for graphql.language.Document. Specifically, it defines a generic \"visitor\" interface (graphql.validation.AbstractRule) that various rules implement, and if a rule is \"broken\", then a ValidationError is thrown. However, given that there is only one check being performed, perhaps this is overkill. Maybe @dminkovsky or @IamCornholio have a better suggestion.. Yes, I see exactly what you mean @kaqqao ! \nPerhaps changing the List<GraphQLInterfaceType> to be a List<GraphQLType>. The GraphQLObjectType.getInterfaces() is already making a copy of the list, so might as well make a copy and cast to GraphQLInterfaceType at the same time. By keeping the API the same as it is now (only adding a public Builder withInterfaces(GraphQLTypeReference...) method to the builder, and a singular version too), then we keep things \"type safe\".\n...similar thing with the GraphQLUnionType.. ...if it has not been resolved, then you are correct. We could implement getInterfaces() so it throws an UnresolvedTypeException (or something like that) so users of that interface understand that getInterfaces() can only be called after resolving the types.. Great work @kaqqao ! I'd love to see this change get merged in.\nThanks!\n-Brian. I don't think the changes should break anything, and they fix much needed functionality, so I'd love to see the changes get merged in.\nWith that said, if it is important to have \"pure\" code, then I think all the schema types should essentially hold \"type references\". To get a concrete type you would pass in a map of type names into concrete types.\nHowever, the above suggestion would break the API, so it would require us to wait for a major version update.. Thanks @dminkovsky for the green light. I'll be working on this and posting a PR (hopefully by the end of this week).\nThanks,\n-Brian\n. Not to familiar with Spock, but I'm adding tests to ParserTest.groovy and it seems pretty straight forward. So far I've added to the ANTLR grammar the new syntax, then modified GraphqlAntlrToLanguage.java to generate the new \"language\" nodes of the AST. I can push my work in progress if you want to start the review process early.\n. I quickly skimmed that issue, but it was unclear to me what format the printer prints in. I'm ASSUMING it iterates over the AST and pretty prints the original input in GraphQL syntax. If that is the case, then all these new AST symbols I'm adding will have a direct impact on the pretty printer (since there will be a host of new symbols to handle).\nUnfortunately, the work I'm doing currently doesn't require such a pretty printer, but I do see value in it. So, I probably won't have time to contribute to that effort in the near future.\n. This was easier than I thought... so I've posted this pull request: https://github.com/graphql-java/graphql-java/pull/243\nFeedback is welcomed.\n. I realized today that I forgot to add the 'schema', 'extend', and 'directive' type declarations, so the latest commit adds support for those.\n. Thanks for reviewing this!. I'm waiting for feedback from @dminkovsky . I've got a code generator that uses this feature that I'd like to release, but it currently depends on my fork. I was hoping to get this merged and released so I don't have to depend on a fork.\nThanks,\n-Brian. BTW @dminkovsky here is the code generator I wrote that uses this code:\nhttps://github.com/Distelli/graphql-apigen\nThanks,\n-Brian. Thanks for the encouragement! I wish the best for you and your family in 2017.\nThe idea for this \"schema first\" development is partially from this JS project:\nhttps://github.com/apollostack/graphql-tools\nIn fact my example uses the same Author/Posts example ;).. The BatchedExecutionStrategy seems to work fine, but I'll admit that I haven't done a ton of testing with it.\nI'm not currently think of turning this into a product, but if you have ideas toward that end, I would be interested :).\nThanks,\n-Brian. graphql-java supports parsing GraphQL schema language. So far I know of two projects that use this:\nhttps://github.com/Distelli/graphql-apigen\n...which generates interfaces and wiring code that allow you to simply implement the interfaces and wire-up a GraphQL object that you can query/mutate with.\nhttps://github.com/Cox-Automotive/graphql-java-tools\n...which appears to adapt existing objects so they conform to a GraphQL schema (at least that is what I grasp from a casual reading of the README).. Ya, that throw new RuntimeException() code should never be hit now that you have added it to the grammar... I was thinking about adding that to the grammar, but I like to keep my PRs focused.\nThanks!\n-Brian. It looks like this is a feature of the GraphQL spec:\nhttp://graphql.org/learn/schema/\n\"The fields on an input object type can themselves refer to input object types, but you can't mix input and output types in your schema.\"\n...so I guess that answers it :).. Thanks! I'll close my PR and this request.. Looks like this is already done here: https://github.com/graphql-java/graphql-java/pull/204. Thanks for the heads up @dminkovsky, I have commented on this pull request:\nhttps://github.com/graphql-java/graphql-java/pull/204\n...basically it looks like two changes are getting bundled into one PR and still no tests and no schema validation (is schema validation important to you?).\nIf that PR isn't moving along by Monday, then I'll open a separate PR that addresses the issues (and bundles only a single change).\nThanks,\n-Brian. defaultValue may be null... I wasn't sure if there was a precedence on what to do here (add null to the list?).\nNote that I did have to add a null check to AstComparator.isEqual().\n. implements is a keyword, otherwise I would use that name :).\n. This looked like a harmless bug, so I took the liberty to fix it.\n. This was a helpful message when I was debugging... but it does make me wonder if the grammar should be handling the mutation and query keywords. Now that 'name' is a rule rather than a token, we should be able to use the mutation and query keywords in the grammar.\n. These changes should probably be reverted from the pull request.. Personally, I'm using this library with Java 1.8, but I'm not sure that requiring Java 1.8 will be acceptable to the maintainer of this project.. Can we separate out this change regarding extension of the TypeResolver interface? That conflates the original goal: resolving TypeReferences.... I'm also curious about why you need all this extra context information when you implement your TypeResolver.. ",
    "pcarrier": "For: query throws { error(message:\"hello\") } with:\nrootQueryBuilder.field(newFieldDefinition()\n  .argument(newArgument()\n    .name(\"message\")\n    .type(Scalars.GraphQLString)\n    .build())\n  .type(Void)\n  .dataFetcher(env -> {\n    final String message = env.getArgument(\"message\").toString();\n    if (message == null) {\n      throw new GraphQLException();\n    } else {\n      throw new GraphQLException(message);\n    }\n  })\n  .build())\nI get:\n{\n  \"data\": {\n    \"error\": null\n  },\n  \"errors\": [\n    {\n      \"exception\": {\n        \"cause\": null,\n        \"stackTrace\": [\n          {\n            \"methodName\": \"lambda$queryType$19\",\n            \"fileName\": \"OpticsSchema.java\",\n            \"lineNumber\": 776,\n            \"className\": \"apollo.optics.graphql.OpticsSchema\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"resolveField\",\n            \"fileName\": \"ExecutionStrategy.java\",\n            \"lineNumber\": 40,\n            \"className\": \"graphql.execution.ExecutionStrategy\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"execute\",\n            \"fileName\": \"ExecStrategy.java\",\n            \"lineNumber\": 35,\n            \"className\": \"apollo.optics.graphql.exec.ExecStrategy\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"executeOperation\",\n            \"fileName\": \"Execution.java\",\n            \"lineNumber\": 60,\n            \"className\": \"graphql.execution.Execution\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"execute\",\n            \"fileName\": \"Execution.java\",\n            \"lineNumber\": 33,\n            \"className\": \"graphql.execution.Execution\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"execute\",\n            \"fileName\": \"GraphQL.java\",\n            \"lineNumber\": 78,\n            \"className\": \"graphql.GraphQL\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"lambda$null$1\",\n            \"fileName\": \"GraphQLHandler.java\",\n            \"lineNumber\": 57,\n            \"className\": \"apollo.optics.graphql.GraphQLHandler\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"lambda$op$7\",\n            \"fileName\": \"Blocking.java\",\n            \"lineNumber\": 231,\n            \"className\": \"ratpack.exec.Blocking\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"lambda$get$0\",\n            \"fileName\": \"Blocking.java\",\n            \"lineNumber\": 70,\n            \"className\": \"ratpack.exec.Blocking$1\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"intercept\",\n            \"fileName\": \"Blocking.java\",\n            \"lineNumber\": 244,\n            \"className\": \"ratpack.exec.Blocking\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"access$000\",\n            \"fileName\": \"Blocking.java\",\n            \"lineNumber\": 35,\n            \"className\": \"ratpack.exec.Blocking\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"get\",\n            \"fileName\": \"Blocking.java\",\n            \"lineNumber\": 68,\n            \"className\": \"ratpack.exec.Blocking$1\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"get\",\n            \"fileName\": \"Blocking.java\",\n            \"lineNumber\": 61,\n            \"className\": \"ratpack.exec.Blocking$1\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"run\",\n            \"fileName\": \"CompletableFuture.java\",\n            \"lineNumber\": 1590,\n            \"className\": \"java.util.concurrent.CompletableFuture$AsyncSupply\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"runWorker\",\n            \"fileName\": \"ThreadPoolExecutor.java\",\n            \"lineNumber\": 1142,\n            \"className\": \"java.util.concurrent.ThreadPoolExecutor\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"run\",\n            \"fileName\": \"ThreadPoolExecutor.java\",\n            \"lineNumber\": 617,\n            \"className\": \"java.util.concurrent.ThreadPoolExecutor$Worker\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"lambda$newThread$0\",\n            \"fileName\": \"DefaultExecController.java\",\n            \"lineNumber\": 136,\n            \"className\": \"ratpack.exec.internal.DefaultExecController$ExecControllerBindingThreadFactory\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"run\",\n            \"fileName\": \"DefaultThreadFactory.java\",\n            \"lineNumber\": 144,\n            \"className\": \"io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator\",\n            \"nativeMethod\": false\n          },\n          {\n            \"methodName\": \"run\",\n            \"fileName\": \"Thread.java\",\n            \"lineNumber\": 745,\n            \"className\": \"java.lang.Thread\",\n            \"nativeMethod\": false\n          }\n        ],\n        \"message\": \"hello\",\n        \"localizedMessage\": \"hello\",\n        \"suppressed\": []\n      },\n      \"message\": \"Exception while fetching data: graphql.GraphQLException: hello\",\n      \"locations\": null,\n      \"errorType\": \"DataFetchingException\"\n    }\n  ]\n}\n. I guess my point is that it'd be nice to add errors to the env that don't necessarily even have an exception, that have an errorType other than DataFetchingException, and it does look indeed like the message has a prefix I can't control.\n. Nevermind, bad repro\n. No, review is fine, thanks :)\n. @leebyron any thoughts on this?\n. @bbakerman yes this is a screenshot of https://www.apollographql.com/engine/\nThe background is that I work on the Apollo Engine team (sorry, I'm not used to using its full name as we just launched but will be more careful).\nThe Engine backend, a GraphQL endpoint itself, is written with graphql-java and as of today, it runs behind engineproxy. As a result it is now instrumenting itself :).\nThis is the first time we have our visualizations for a GraphQL server and we find problems with the trace format implementation in graphql-java that might have gone unnoticed by its developers.\nThe problem that you can see in the screenshot is that the fields are reported as belonging to StringToString! instead of StringToString. As a result that latter type appears empty.. Confirmed to fix the Apollo Engine UI:\n\n. My code might be wrong. I believe my change makes startOffset refer to the start of the field's execution (startFieldFetch) as opposed to its end (now), which is perfectly in line with the spec?\nWhat would you suggest the spec should say instead of what it currently does?. Confirmed to fix the Apollo Engine UI:\n\n. ",
    "dllx": "In our HTTP endpoint getting application/json GrapQL requests and providing the JSON responses, we are extracting the Exceptions (incl. DataFetchingExceptions) from the errors in the ExecutionResult obtained from GraphQL.execute. Depending on the exceptions' causes, we populate the \"errors\" part in the JSON response, inventing some additional fields to the error structure.\nTo some degree, this works, but we'd like to better associate an error with a certain mutation in the request (if there are multiple mutations). So maybe this can be considered here.\n. Thank you, that would be great. No, I don't have a patch for that ready, sorry.. Unfortunately, I have very few time looking into this. In my Ceylon implementation of a GraphQL engine (https://github.com/dlkw/ceylon-graphql, see code at https://github.com/dlkw/ceylon-graphql/blob/master/source/de/dlkw/graphql/exp/Schema.ceylon#L664) I have split the completeValues function and used an input flag to signal \"this happens in a non null field\" and a special return value to signal the error the non-null case.\nMaybe this is transferrable to this project and you can take some inspiration from there.. Yes, I was wondering about the same. I posed a question on stackoverflow to find out more on it, please see http://stackoverflow.com/questions/41238205/graphql-mutation-operation-in-single-transaction.\nAs the spec says nothing about the side-effects of resolving a top level mutation field, the server could probably implement the execution/modification of such a field as some sort of no-op if a previous executed top level field had an error.. Which leads to the fact that with the current state of graphql-java, this could be implemented by the data fetchers keeping track of the success state in the context Object and react on that accordingly.\nThat would be a bit awkward as many occurences would have to be adapted, so I still think it would be cleaner when implemented at a more central spot, i.e., the graphql-java library.. I'm not (yet) convinced that keeping track of the path is necessary for error handling and null propagation on non-nullable fields.\nI have a vague idea, but don't know if it will work out. Unfortunately, I'm rather time constrained, but will have another look when possible.. Line 1 should not be a syntax error, it is allowed according to the spec.\nLines 2, 4, 6, 8 are syntax errors because argument lists, when given, must contain at least one argument.\nLine 3 is a syntax error: directives must come after the field name\nLine 5 is allowed according to the spec (no syntax error)\nLine 7 (and 8) should be a syntax error, no directives allowed after the top level selection set.\nI did not check, but if your observations are correct, then the reactions in cases 1, 7, and 8 of graphql-java are wrong.. Yeah, I was wrong above for Line 1. It is not allowed according to the spec. It would be allowed if the operation type (query/mutation) was added, like\ngraphql\nquery @skipme{hello}\nRegarding\ngraphql\ngraphQL.execute(\"{hello}@skipme\")\nWhat is normative on this? Is it the spec? Then the grammar is buggy if it accepts it. If the grammar is normative, then the spec is buggy. But for this corner case, it is probably not important, as only the implementation defines the directives' semantics anyway.. We are also using the context (Object) to store some information that we need in several data fetchers all around the response hierarchy. That works fine, I don't see how you could not put info about the executing user (authentication info) there.\nIf you use some authentication/authorization framework like Shiro, you can use that to get the Subject, but (in the case of Shiro), the Subject is bound to the thread local storage. Parallel execution strategies won't work, then.. There's a little bit more in the \"best practices\" at http://graphql.org/learn/serving-over-http/, but as you say, not about HTTP status code.. ",
    "lpellegr": ":100: : I am facing the same issue. It would be really convenient to be able to define an error formatting strategy (e.g. I would like to exclude the stacktrace in my case).\n. ",
    "lulzmachine": "@dminkovsky thanks! I was looking for something similar. I won't want risk exposing internals by showing a stacktrace. Your code worked fine except for one thing:\nHad to change\n    if (!locations.isEmpty()) {\ninto\n    if (locations != null && !locations.isEmpty()) {\nOr I'd get NPEs while serializing (in my case a dataFetcher threw an IllegalArgumentException), and \"location\" was null. Okay. Thanks for the input! It's been very helpful! Closing the issue now, I hope that's okay. ",
    "yeyuexia": "That's my code to custom exception. use Json to operate json format. you can do more thing in  errorHandle and toJson\n```\n    private Throwable errorHandle(GraphQLError error) {\n        if (error.getErrorType() == ErrorType.DataFetchingException) {\n            return ((ExceptionWhileDataFetching) error).getException();\n        } else {\n            return new CustomException();\n        }\n    }\nprivate Json toJson(Throwable throwable) {\n    final Json json = Json.read(json(throwable));\n    json.delAt(\"stackTrace\");\n    json.delAt(\"localizedMessage\");\n    json.delAt(\"suppressed\");\n    return json;\n}\n\nprivate List<Json> customError(ExecutionResult executionResult) {\n    return executionResult.getErrors()\n        .stream()\n        .map(this::errorHandle)\n        .map(this::toJson)\n        .collect(Collectors.toList());\n}\n\n```\n. ",
    "santoshunific": "Getting below exception:\n{\n    \"errors\": [\n        {\n            \"exception\": {\n                \"cause\": {\n                    \"cause\": {\n                        \"cause\": null,\n                        \"stackTrace\": [\n                            {\n                                \"methodName\": \"handleErrorResponse\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 1638,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeOneRequest\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 1303,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeHelper\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 1055,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"doExecute\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 743,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeWithTimer\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 717,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 699,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"access$500\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 667,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 649,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 513,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"doInvoke\",\n                                \"fileName\": \"AmazonDynamoDBClient.java\",\n                                \"lineNumber\": 2186,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"AmazonDynamoDBClient.java\",\n                                \"lineNumber\": 2162,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeQuery\",\n                                \"fileName\": \"AmazonDynamoDBClient.java\",\n                                \"lineNumber\": 1589,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"query\",\n                                \"fileName\": \"AmazonDynamoDBClient.java\",\n                                \"lineNumber\": 1565,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"count\",\n                                \"fileName\": \"DynamoDBMapper.java\",\n                                \"lineNumber\": 1562,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapper\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"count\",\n                                \"fileName\": \"AbstractDynamoDBMapper.java\",\n                                \"lineNumber\": 289,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.datamodeling.AbstractDynamoDBMapper\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"count\",\n                                \"fileName\": \"FailedBatchThrowingDynamoDBMapper.java\",\n                                \"lineNumber\": 307,\n                                \"className\": \"com.unific.aws.dynamodb.FailedBatchThrowingDynamoDBMapper\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"countOfEmailSentBetweenPeriod\",\n                                \"fileName\": \"DynamoDBOutboundEmailRepository.java\",\n                                \"lineNumber\": 67,\n                                \"className\": \"com.unific.repositories.DynamoDBOutboundEmailRepository\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"getEmailsLeft\",\n                                \"fileName\": \"PlanService.java\",\n                                \"lineNumber\": 166,\n                                \"className\": \"com.unific.graphql.services.PlanService\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke0\",\n                                \"fileName\": \"NativeMethodAccessorImpl.java\",\n                                \"lineNumber\": -2,\n                                \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                                \"nativeMethod\": true\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"NativeMethodAccessorImpl.java\",\n                                \"lineNumber\": 62,\n                                \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"DelegatingMethodAccessorImpl.java\",\n                                \"lineNumber\": 43,\n                                \"className\": \"sun.reflect.DelegatingMethodAccessorImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"Method.java\",\n                                \"lineNumber\": 498,\n                                \"className\": \"java.lang.reflect.Method\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"SingletonMethodInvoker.java\",\n                                \"lineNumber\": 21,\n                                \"className\": \"io.leangen.graphql.metadata.execution.SingletonMethodInvoker\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"resolve\",\n                                \"fileName\": \"Resolver.java\",\n                                \"lineNumber\": 89,\n                                \"className\": \"io.leangen.graphql.metadata.Resolver\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"OperationExecutor.java\",\n                                \"lineNumber\": 93,\n                                \"className\": \"io.leangen.graphql.execution.OperationExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"OperationExecutor.java\",\n                                \"lineNumber\": 59,\n                                \"className\": \"io.leangen.graphql.execution.OperationExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"resolveField\",\n                                \"fileName\": \"ExecutionStrategy.java\",\n                                \"lineNumber\": 99,\n                                \"className\": \"graphql.execution.ExecutionStrategy\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"SimpleExecutionStrategy.java\",\n                                \"lineNumber\": 19,\n                                \"className\": \"graphql.execution.SimpleExecutionStrategy\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeOperation\",\n                                \"fileName\": \"Execution.java\",\n                                \"lineNumber\": 106,\n                                \"className\": \"graphql.execution.Execution\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"Execution.java\",\n                                \"lineNumber\": 49,\n                                \"className\": \"graphql.execution.Execution\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQL.java\",\n                                \"lineNumber\": 222,\n                                \"className\": \"graphql.GraphQL\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQL.java\",\n                                \"lineNumber\": 187,\n                                \"className\": \"graphql.GraphQL\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQL.java\",\n                                \"lineNumber\": 179,\n                                \"className\": \"graphql.GraphQL\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQL.java\",\n                                \"lineNumber\": 175,\n                                \"className\": \"graphql.GraphQL\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQLExecutor.java\",\n                                \"lineNumber\": 47,\n                                \"className\": \"com.unific.graphql.GraphQLExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQLExecutor.java\",\n                                \"lineNumber\": 27,\n                                \"className\": \"com.unific.graphql.GraphQLExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"processQuery\",\n                                \"fileName\": \"GraphQLQueryHandler.java\",\n                                \"lineNumber\": 34,\n                                \"className\": \"com.unific.graphql.handlers.GraphQLQueryHandler\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"processQueryBasedOnContentType\",\n                                \"fileName\": \"GraphQLController.java\",\n                                \"lineNumber\": 155,\n                                \"className\": \"com.unific.graphql.GraphQLController\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"handle\",\n                                \"fileName\": \"GraphQLController.java\",\n                                \"lineNumber\": 112,\n                                \"className\": \"com.unific.graphql.GraphQLController\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke0\",\n                                \"fileName\": \"NativeMethodAccessorImpl.java\",\n                                \"lineNumber\": -2,\n                                \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                                \"nativeMethod\": true\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"NativeMethodAccessorImpl.java\",\n                                \"lineNumber\": 62,\n                                \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"DelegatingMethodAccessorImpl.java\",\n                                \"lineNumber\": 43,\n                                \"className\": \"sun.reflect.DelegatingMethodAccessorImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"Method.java\",\n                                \"lineNumber\": 498,\n                                \"className\": \"java.lang.reflect.Method\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"handleRequest\",\n                                \"fileName\": \"EventHandlerLoader.java\",\n                                \"lineNumber\": 259,\n                                \"className\": \"lambdainternal.EventHandlerLoader$PojoMethodRequestHandler\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"handleRequest\",\n                                \"fileName\": \"EventHandlerLoader.java\",\n                                \"lineNumber\": 178,\n                                \"className\": \"lambdainternal.EventHandlerLoader$PojoHandlerAsStreamHandler\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"call\",\n                                \"fileName\": \"EventHandlerLoader.java\",\n                                \"lineNumber\": 888,\n                                \"className\": \"lambdainternal.EventHandlerLoader$2\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"startRuntime\",\n                                \"fileName\": \"AWSLambda.java\",\n                                \"lineNumber\": 281,\n                                \"className\": \"lambdainternal.AWSLambda\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"\",\n                                \"fileName\": \"AWSLambda.java\",\n                                \"lineNumber\": 64,\n                                \"className\": \"lambdainternal.AWSLambda\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"forName0\",\n                                \"fileName\": \"Class.java\",\n                                \"lineNumber\": -2,\n                                \"className\": \"java.lang.Class\",\n                                \"nativeMethod\": true\n                            },\n                            {\n                                \"methodName\": \"forName\",\n                                \"fileName\": \"Class.java\",\n                                \"lineNumber\": 348,\n                                \"className\": \"java.lang.Class\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"main\",\n                                \"fileName\": \"LambdaRTEntry.java\",\n                                \"lineNumber\": 94,\n                                \"className\": \"lambdainternal.LambdaRTEntry\",\n                                \"nativeMethod\": false\n                            }\n                        ],\n                        \"requestId\": \"EL0S3EH2THOBCIIRQ8P5OI4EN7VV4KQNSO5AEMVJF66Q9ASUAAJG\",\n                        \"errorCode\": \"ValidationException\",\n                        \"errorType\": \"Client\",\n                        \"errorMessage\": \"Query key condition not supported\",\n                        \"statusCode\": 400,\n                        \"serviceName\": \"AmazonDynamoDBv2\",\n                        \"httpHeaders\": {\n                            \"Connection\": \"keep-alive\",\n                            \"Content-Length\": \"104\",\n                            \"Content-Type\": \"application/x-amz-json-1.0\",\n                            \"Date\": \"Mon, 25 Sep 2017 11:56:58 GMT\",\n                            \"Server\": \"Server\",\n                            \"x-amz-crc32\": \"1080857196\",\n                            \"x-amzn-RequestId\": \"EL0S3EH2THOBCIIRQ8P5OI4EN7VV4KQNSO5AEMVJF66Q9ASUAAJG\"\n                        },\n                        \"rawResponse\": \"eyJfX3R5cGUiOiJjb20uYW1hem9uLmNvcmFsLnZhbGlkYXRlI1ZhbGlkYXRpb25FeGNlcHRpb24iLCJtZXNzYWdlIjoiUXVlcnkga2V5IGNvbmRpdGlvbiBub3Qgc3VwcG9ydGVkIn0=\",\n                        \"message\": \"Query key condition not supported (Service: AmazonDynamoDBv2; Status Code: 400; Error Code: ValidationException; Request ID: EL0S3EH2THOBCIIRQ8P5OI4EN7VV4KQNSO5AEMVJF66Q9ASUAAJG)\",\n                        \"rawResponseContent\": \"{\\\"__type\\\":\\\"com.amazon.coral.validate#ValidationException\\\",\\\"message\\\":\\\"Query key condition not supported\\\"}\",\n                        \"retryable\": true,\n                        \"localizedMessage\": \"Query key condition not supported (Service: AmazonDynamoDBv2; Status Code: 400; Error Code: ValidationException; Request ID: EL0S3EH2THOBCIIRQ8P5OI4EN7VV4KQNSO5AEMVJF66Q9ASUAAJG)\",\n                        \"suppressed\": []\n                    },\n                    \"stackTrace\": [\n                        {\n                            \"methodName\": \"invoke0\",\n                            \"fileName\": \"NativeMethodAccessorImpl.java\",\n                            \"lineNumber\": -2,\n                            \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                            \"nativeMethod\": true\n                        },\n                        {\n                            \"methodName\": \"invoke\",\n                            \"fileName\": \"NativeMethodAccessorImpl.java\",\n                            \"lineNumber\": 62,\n                            \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"invoke\",\n                            \"fileName\": \"DelegatingMethodAccessorImpl.java\",\n                            \"lineNumber\": 43,\n                            \"className\": \"sun.reflect.DelegatingMethodAccessorImpl\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"invoke\",\n                            \"fileName\": \"Method.java\",\n                            \"lineNumber\": 498,\n                            \"className\": \"java.lang.reflect.Method\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"SingletonMethodInvoker.java\",\n                            \"lineNumber\": 21,\n                            \"className\": \"io.leangen.graphql.metadata.execution.SingletonMethodInvoker\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"resolve\",\n                            \"fileName\": \"Resolver.java\",\n                            \"lineNumber\": 89,\n                            \"className\": \"io.leangen.graphql.metadata.Resolver\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"OperationExecutor.java\",\n                            \"lineNumber\": 93,\n                            \"className\": \"io.leangen.graphql.execution.OperationExecutor\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"OperationExecutor.java\",\n                            \"lineNumber\": 59,\n                            \"className\": \"io.leangen.graphql.execution.OperationExecutor\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"resolveField\",\n                            \"fileName\": \"ExecutionStrategy.java\",\n                            \"lineNumber\": 99,\n                            \"className\": \"graphql.execution.ExecutionStrategy\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"SimpleExecutionStrategy.java\",\n                            \"lineNumber\": 19,\n                            \"className\": \"graphql.execution.SimpleExecutionStrategy\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"executeOperation\",\n                            \"fileName\": \"Execution.java\",\n                            \"lineNumber\": 106,\n                            \"className\": \"graphql.execution.Execution\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"Execution.java\",\n                            \"lineNumber\": 49,\n                            \"className\": \"graphql.execution.Execution\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"GraphQL.java\",\n                            \"lineNumber\": 222,\n                            \"className\": \"graphql.GraphQL\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"GraphQL.java\",\n                            \"lineNumber\": 187,\n                            \"className\": \"graphql.GraphQL\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"GraphQL.java\",\n                            \"lineNumber\": 179,\n                            \"className\": \"graphql.GraphQL\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"GraphQL.java\",\n                            \"lineNumber\": 175,\n                            \"className\": \"graphql.GraphQL\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"GraphQLExecutor.java\",\n                            \"lineNumber\": 47,\n                            \"className\": \"com.unific.graphql.GraphQLExecutor\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"execute\",\n                            \"fileName\": \"GraphQLExecutor.java\",\n                            \"lineNumber\": 27,\n                            \"className\": \"com.unific.graphql.GraphQLExecutor\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"processQuery\",\n                            \"fileName\": \"GraphQLQueryHandler.java\",\n                            \"lineNumber\": 34,\n                            \"className\": \"com.unific.graphql.handlers.GraphQLQueryHandler\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"processQueryBasedOnContentType\",\n                            \"fileName\": \"GraphQLController.java\",\n                            \"lineNumber\": 155,\n                            \"className\": \"com.unific.graphql.GraphQLController\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"handle\",\n                            \"fileName\": \"GraphQLController.java\",\n                            \"lineNumber\": 112,\n                            \"className\": \"com.unific.graphql.GraphQLController\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"invoke0\",\n                            \"fileName\": \"NativeMethodAccessorImpl.java\",\n                            \"lineNumber\": -2,\n                            \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                            \"nativeMethod\": true\n                        },\n                        {\n                            \"methodName\": \"invoke\",\n                            \"fileName\": \"NativeMethodAccessorImpl.java\",\n                            \"lineNumber\": 62,\n                            \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"invoke\",\n                            \"fileName\": \"DelegatingMethodAccessorImpl.java\",\n                            \"lineNumber\": 43,\n                            \"className\": \"sun.reflect.DelegatingMethodAccessorImpl\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"invoke\",\n                            \"fileName\": \"Method.java\",\n                            \"lineNumber\": 498,\n                            \"className\": \"java.lang.reflect.Method\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"handleRequest\",\n                            \"fileName\": \"EventHandlerLoader.java\",\n                            \"lineNumber\": 259,\n                            \"className\": \"lambdainternal.EventHandlerLoader$PojoMethodRequestHandler\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"handleRequest\",\n                            \"fileName\": \"EventHandlerLoader.java\",\n                            \"lineNumber\": 178,\n                            \"className\": \"lambdainternal.EventHandlerLoader$PojoHandlerAsStreamHandler\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"call\",\n                            \"fileName\": \"EventHandlerLoader.java\",\n                            \"lineNumber\": 888,\n                            \"className\": \"lambdainternal.EventHandlerLoader$2\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"startRuntime\",\n                            \"fileName\": \"AWSLambda.java\",\n                            \"lineNumber\": 281,\n                            \"className\": \"lambdainternal.AWSLambda\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"\",\n                            \"fileName\": \"AWSLambda.java\",\n                            \"lineNumber\": 64,\n                            \"className\": \"lambdainternal.AWSLambda\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"forName0\",\n                            \"fileName\": \"Class.java\",\n                            \"lineNumber\": -2,\n                            \"className\": \"java.lang.Class\",\n                            \"nativeMethod\": true\n                        },\n                        {\n                            \"methodName\": \"forName\",\n                            \"fileName\": \"Class.java\",\n                            \"lineNumber\": 348,\n                            \"className\": \"java.lang.Class\",\n                            \"nativeMethod\": false\n                        },\n                        {\n                            \"methodName\": \"main\",\n                            \"fileName\": \"LambdaRTEntry.java\",\n                            \"lineNumber\": 94,\n                            \"className\": \"lambdainternal.LambdaRTEntry\",\n                            \"nativeMethod\": false\n                        }\n                    ],\n                    \"targetException\": {\n                        \"cause\": null,\n                        \"stackTrace\": [\n                            {\n                                \"methodName\": \"handleErrorResponse\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 1638,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeOneRequest\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 1303,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeHelper\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 1055,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"doExecute\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 743,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeWithTimer\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 717,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 699,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"access$500\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 667,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 649,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"AmazonHttpClient.java\",\n                                \"lineNumber\": 513,\n                                \"className\": \"com.amazonaws.http.AmazonHttpClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"doInvoke\",\n                                \"fileName\": \"AmazonDynamoDBClient.java\",\n                                \"lineNumber\": 2186,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"AmazonDynamoDBClient.java\",\n                                \"lineNumber\": 2162,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeQuery\",\n                                \"fileName\": \"AmazonDynamoDBClient.java\",\n                                \"lineNumber\": 1589,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"query\",\n                                \"fileName\": \"AmazonDynamoDBClient.java\",\n                                \"lineNumber\": 1565,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"count\",\n                                \"fileName\": \"DynamoDBMapper.java\",\n                                \"lineNumber\": 1562,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapper\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"count\",\n                                \"fileName\": \"AbstractDynamoDBMapper.java\",\n                                \"lineNumber\": 289,\n                                \"className\": \"com.amazonaws.services.dynamodbv2.datamodeling.AbstractDynamoDBMapper\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"count\",\n                                \"fileName\": \"FailedBatchThrowingDynamoDBMapper.java\",\n                                \"lineNumber\": 307,\n                                \"className\": \"com.unific.aws.dynamodb.FailedBatchThrowingDynamoDBMapper\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"countOfEmailSentBetweenPeriod\",\n                                \"fileName\": \"DynamoDBOutboundEmailRepository.java\",\n                                \"lineNumber\": 67,\n                                \"className\": \"com.unific.repositories.DynamoDBOutboundEmailRepository\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"getEmailsLeft\",\n                                \"fileName\": \"PlanService.java\",\n                                \"lineNumber\": 166,\n                                \"className\": \"com.unific.graphql.services.PlanService\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke0\",\n                                \"fileName\": \"NativeMethodAccessorImpl.java\",\n                                \"lineNumber\": -2,\n                                \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                                \"nativeMethod\": true\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"NativeMethodAccessorImpl.java\",\n                                \"lineNumber\": 62,\n                                \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"DelegatingMethodAccessorImpl.java\",\n                                \"lineNumber\": 43,\n                                \"className\": \"sun.reflect.DelegatingMethodAccessorImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"Method.java\",\n                                \"lineNumber\": 498,\n                                \"className\": \"java.lang.reflect.Method\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"SingletonMethodInvoker.java\",\n                                \"lineNumber\": 21,\n                                \"className\": \"io.leangen.graphql.metadata.execution.SingletonMethodInvoker\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"resolve\",\n                                \"fileName\": \"Resolver.java\",\n                                \"lineNumber\": 89,\n                                \"className\": \"io.leangen.graphql.metadata.Resolver\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"OperationExecutor.java\",\n                                \"lineNumber\": 93,\n                                \"className\": \"io.leangen.graphql.execution.OperationExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"OperationExecutor.java\",\n                                \"lineNumber\": 59,\n                                \"className\": \"io.leangen.graphql.execution.OperationExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"resolveField\",\n                                \"fileName\": \"ExecutionStrategy.java\",\n                                \"lineNumber\": 99,\n                                \"className\": \"graphql.execution.ExecutionStrategy\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"SimpleExecutionStrategy.java\",\n                                \"lineNumber\": 19,\n                                \"className\": \"graphql.execution.SimpleExecutionStrategy\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"executeOperation\",\n                                \"fileName\": \"Execution.java\",\n                                \"lineNumber\": 106,\n                                \"className\": \"graphql.execution.Execution\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"Execution.java\",\n                                \"lineNumber\": 49,\n                                \"className\": \"graphql.execution.Execution\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQL.java\",\n                                \"lineNumber\": 222,\n                                \"className\": \"graphql.GraphQL\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQL.java\",\n                                \"lineNumber\": 187,\n                                \"className\": \"graphql.GraphQL\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQL.java\",\n                                \"lineNumber\": 179,\n                                \"className\": \"graphql.GraphQL\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQL.java\",\n                                \"lineNumber\": 175,\n                                \"className\": \"graphql.GraphQL\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQLExecutor.java\",\n                                \"lineNumber\": 47,\n                                \"className\": \"com.unific.graphql.GraphQLExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"execute\",\n                                \"fileName\": \"GraphQLExecutor.java\",\n                                \"lineNumber\": 27,\n                                \"className\": \"com.unific.graphql.GraphQLExecutor\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"processQuery\",\n                                \"fileName\": \"GraphQLQueryHandler.java\",\n                                \"lineNumber\": 34,\n                                \"className\": \"com.unific.graphql.handlers.GraphQLQueryHandler\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"processQueryBasedOnContentType\",\n                                \"fileName\": \"GraphQLController.java\",\n                                \"lineNumber\": 155,\n                                \"className\": \"com.unific.graphql.GraphQLController\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"handle\",\n                                \"fileName\": \"GraphQLController.java\",\n                                \"lineNumber\": 112,\n                                \"className\": \"com.unific.graphql.GraphQLController\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke0\",\n                                \"fileName\": \"NativeMethodAccessorImpl.java\",\n                                \"lineNumber\": -2,\n                                \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                                \"nativeMethod\": true\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"NativeMethodAccessorImpl.java\",\n                                \"lineNumber\": 62,\n                                \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"DelegatingMethodAccessorImpl.java\",\n                                \"lineNumber\": 43,\n                                \"className\": \"sun.reflect.DelegatingMethodAccessorImpl\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"invoke\",\n                                \"fileName\": \"Method.java\",\n                                \"lineNumber\": 498,\n                                \"className\": \"java.lang.reflect.Method\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"handleRequest\",\n                                \"fileName\": \"EventHandlerLoader.java\",\n                                \"lineNumber\": 259,\n                                \"className\": \"lambdainternal.EventHandlerLoader$PojoMethodRequestHandler\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"handleRequest\",\n                                \"fileName\": \"EventHandlerLoader.java\",\n                                \"lineNumber\": 178,\n                                \"className\": \"lambdainternal.EventHandlerLoader$PojoHandlerAsStreamHandler\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"call\",\n                                \"fileName\": \"EventHandlerLoader.java\",\n                                \"lineNumber\": 888,\n                                \"className\": \"lambdainternal.EventHandlerLoader$2\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"startRuntime\",\n                                \"fileName\": \"AWSLambda.java\",\n                                \"lineNumber\": 281,\n                                \"className\": \"lambdainternal.AWSLambda\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"\",\n                                \"fileName\": \"AWSLambda.java\",\n                                \"lineNumber\": 64,\n                                \"className\": \"lambdainternal.AWSLambda\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"forName0\",\n                                \"fileName\": \"Class.java\",\n                                \"lineNumber\": -2,\n                                \"className\": \"java.lang.Class\",\n                                \"nativeMethod\": true\n                            },\n                            {\n                                \"methodName\": \"forName\",\n                                \"fileName\": \"Class.java\",\n                                \"lineNumber\": 348,\n                                \"className\": \"java.lang.Class\",\n                                \"nativeMethod\": false\n                            },\n                            {\n                                \"methodName\": \"main\",\n                                \"fileName\": \"LambdaRTEntry.java\",\n                                \"lineNumber\": 94,\n                                \"className\": \"lambdainternal.LambdaRTEntry\",\n                                \"nativeMethod\": false\n                            }\n                        ],\n                        \"requestId\": \"EL0S3EH2THOBCIIRQ8P5OI4EN7VV4KQNSO5AEMVJF66Q9ASUAAJG\",\n                        \"errorCode\": \"ValidationException\",\n                        \"errorType\": \"Client\",\n                        \"errorMessage\": \"Query key condition not supported\",\n                        \"statusCode\": 400,\n                        \"serviceName\": \"AmazonDynamoDBv2\",\n                        \"httpHeaders\": {\n                            \"Connection\": \"keep-alive\",\n                            \"Content-Length\": \"104\",\n                            \"Content-Type\": \"application/x-amz-json-1.0\",\n                            \"Date\": \"Mon, 25 Sep 2017 11:56:58 GMT\",\n                            \"Server\": \"Server\",\n                            \"x-amz-crc32\": \"1080857196\",\n                            \"x-amzn-RequestId\": \"EL0S3EH2THOBCIIRQ8P5OI4EN7VV4KQNSO5AEMVJF66Q9ASUAAJG\"\n                        },\n                        \"rawResponse\": \"eyJfX3R5cGUiOiJjb20uYW1hem9uLmNvcmFsLnZhbGlkYXRlI1ZhbGlkYXRpb25FeGNlcHRpb24iLCJtZXNzYWdlIjoiUXVlcnkga2V5IGNvbmRpdGlvbiBub3Qgc3VwcG9ydGVkIn0=\",\n                        \"message\": \"Query key condition not supported (Service: AmazonDynamoDBv2; Status Code: 400; Error Code: ValidationException; Request ID: EL0S3EH2THOBCIIRQ8P5OI4EN7VV4KQNSO5AEMVJF66Q9ASUAAJG)\",\n                        \"rawResponseContent\": \"{\\\"__type\\\":\\\"com.amazon.coral.validate#ValidationException\\\",\\\"message\\\":\\\"Query key condition not supported\\\"}\",\n                        \"retryable\": true,\n                        \"localizedMessage\": \"Query key condition not supported (Service: AmazonDynamoDBv2; Status Code: 400; Error Code: ValidationException; Request ID: EL0S3EH2THOBCIIRQ8P5OI4EN7VV4KQNSO5AEMVJF66Q9ASUAAJG)\",\n                        \"suppressed\": []\n                    },\n                    \"message\": null,\n                    \"localizedMessage\": null,\n                    \"suppressed\": []\n                },\n                \"stackTrace\": [\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"OperationExecutor.java\",\n                        \"lineNumber\": 64,\n                        \"className\": \"io.leangen.graphql.execution.OperationExecutor\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"resolveField\",\n                        \"fileName\": \"ExecutionStrategy.java\",\n                        \"lineNumber\": 99,\n                        \"className\": \"graphql.execution.ExecutionStrategy\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"SimpleExecutionStrategy.java\",\n                        \"lineNumber\": 19,\n                        \"className\": \"graphql.execution.SimpleExecutionStrategy\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"executeOperation\",\n                        \"fileName\": \"Execution.java\",\n                        \"lineNumber\": 106,\n                        \"className\": \"graphql.execution.Execution\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"Execution.java\",\n                        \"lineNumber\": 49,\n                        \"className\": \"graphql.execution.Execution\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"GraphQL.java\",\n                        \"lineNumber\": 222,\n                        \"className\": \"graphql.GraphQL\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"GraphQL.java\",\n                        \"lineNumber\": 187,\n                        \"className\": \"graphql.GraphQL\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"GraphQL.java\",\n                        \"lineNumber\": 179,\n                        \"className\": \"graphql.GraphQL\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"GraphQL.java\",\n                        \"lineNumber\": 175,\n                        \"className\": \"graphql.GraphQL\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"GraphQLExecutor.java\",\n                        \"lineNumber\": 47,\n                        \"className\": \"com.unific.graphql.GraphQLExecutor\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"execute\",\n                        \"fileName\": \"GraphQLExecutor.java\",\n                        \"lineNumber\": 27,\n                        \"className\": \"com.unific.graphql.GraphQLExecutor\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"processQuery\",\n                        \"fileName\": \"GraphQLQueryHandler.java\",\n                        \"lineNumber\": 34,\n                        \"className\": \"com.unific.graphql.handlers.GraphQLQueryHandler\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"processQueryBasedOnContentType\",\n                        \"fileName\": \"GraphQLController.java\",\n                        \"lineNumber\": 155,\n                        \"className\": \"com.unific.graphql.GraphQLController\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"handle\",\n                        \"fileName\": \"GraphQLController.java\",\n                        \"lineNumber\": 112,\n                        \"className\": \"com.unific.graphql.GraphQLController\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"invoke0\",\n                        \"fileName\": \"NativeMethodAccessorImpl.java\",\n                        \"lineNumber\": -2,\n                        \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                        \"nativeMethod\": true\n                    },\n                    {\n                        \"methodName\": \"invoke\",\n                        \"fileName\": \"NativeMethodAccessorImpl.java\",\n                        \"lineNumber\": 62,\n                        \"className\": \"sun.reflect.NativeMethodAccessorImpl\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"invoke\",\n                        \"fileName\": \"DelegatingMethodAccessorImpl.java\",\n                        \"lineNumber\": 43,\n                        \"className\": \"sun.reflect.DelegatingMethodAccessorImpl\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"invoke\",\n                        \"fileName\": \"Method.java\",\n                        \"lineNumber\": 498,\n                        \"className\": \"java.lang.reflect.Method\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"handleRequest\",\n                        \"fileName\": \"EventHandlerLoader.java\",\n                        \"lineNumber\": 259,\n                        \"className\": \"lambdainternal.EventHandlerLoader$PojoMethodRequestHandler\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"handleRequest\",\n                        \"fileName\": \"EventHandlerLoader.java\",\n                        \"lineNumber\": 178,\n                        \"className\": \"lambdainternal.EventHandlerLoader$PojoHandlerAsStreamHandler\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"call\",\n                        \"fileName\": \"EventHandlerLoader.java\",\n                        \"lineNumber\": 888,\n                        \"className\": \"lambdainternal.EventHandlerLoader$2\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"startRuntime\",\n                        \"fileName\": \"AWSLambda.java\",\n                        \"lineNumber\": 281,\n                        \"className\": \"lambdainternal.AWSLambda\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"\",\n                        \"fileName\": \"AWSLambda.java\",\n                        \"lineNumber\": 64,\n                        \"className\": \"lambdainternal.AWSLambda\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"forName0\",\n                        \"fileName\": \"Class.java\",\n                        \"lineNumber\": -2,\n                        \"className\": \"java.lang.Class\",\n                        \"nativeMethod\": true\n                    },\n                    {\n                        \"methodName\": \"forName\",\n                        \"fileName\": \"Class.java\",\n                        \"lineNumber\": 348,\n                        \"className\": \"java.lang.Class\",\n                        \"nativeMethod\": false\n                    },\n                    {\n                        \"methodName\": \"main\",\n                        \"fileName\": \"LambdaRTEntry.java\",\n                        \"lineNumber\": 94,\n                        \"className\": \"lambdainternal.LambdaRTEntry\",\n                        \"nativeMethod\": false\n                    }\n                ],\n                \"message\": \"Operation resolution exception\",\n                \"localizedMessage\": \"Operation resolution exception\",\n                \"suppressed\": []\n            },\n            \"message\": \"Exception while fetching data: Operation resolution exception\",\n            \"locations\": null,\n            \"errorType\": \"DataFetchingException\"\n        }\n    ],\n    \"extensions\": null\n}. ",
    "piotrblasiak": "That\u00b4s great, but any way to remove the stack trace from other, like ValidationErrors as well?. Never mind. Seems like toSpecification() takes care of that.. Looks like it indeed is the same problem as #538. Will wait until it hits a stable build, thanks!. Thanks for the reply.\nYou are right that reactive streams and transactions are not compatible so I would either have to do the transaction in the initial publisher or in the last consumer.\nSo why do I even need a transaction? It is because let\u00b4s say I subscribe to changes to a User. The User has lazy-initialized JPA fields like friends() that only gets fetched when the field is called. So then I have a few choices to make this work with graphql:\n1) Fetch all available data on all entities I subscribe to every time there is a change (not possible, as there can be friends of friends etc and the graphql subscription query should not have to be limited to n levels).\n2) Fetching all the needed fields in the first publisher, but this would require me to pass down graphql logic or something to the first publisher so that it knows what to fetch. Not really intuitive.\n3) Emit the ID of the user and fetch & resolve it in the graphql execution strategy where all the fields are being accessed and we can do it within a transaction which is all that is needed for the lazy loading to work.\nI did make it work with option 3 by doing the following:\n```\nprivate CompletableFuture executeSubscriptionEvent(final ExecutionContext executionContext, final ExecutionStrategyParameters parameters, final Object eventPayload) {\n        if (eventPayload instanceof Callable) {\n            return new Callable<CompletableFuture<ExecutionResult>>(){\n\n                @Transactional(readOnly = true)\n                @Override\n                public CompletableFuture<ExecutionResult> call() throws Exception {\n\n                    return executeSubscriptionEventImpl(executionContext, parameters, ((Callable) eventPayload).call());\n                }\n            }.call(); \n    }\n\n    return executeSubscriptionEventImpl(executionContext, parameters, eventPayload);\n}\n\n```\nAnd instead of returning the User entity in the datafetcher publisher I return a Callable that has the JPA fetching included:\n.type(\"Subscriptions\", typeWiring -> typeWiring\n .dataFetcher(\"userChanged\", environment -> {\n  final String id = environment.getArgument(\"id\");\n  return Flux.from(publishers.getUserChangedPublisher(id))\n  .map(entityUpdatedNotification -> (Callable)() -> userService.getUser(id));\n }))\nDoes this make sense to you?. Your suggestion is my option (2) - but that would instead require me to leak graphql into the component that does the publishing :) I am actually quite happy leaking JPA etc into graphql instead as that is much closer to \"the surface\". And now that I am getting more into this I realise even more that I must have my own SubscriptionExecutionStrategy because I also want to ack notifications etc after they have been written to the websocket etc. Not sure if this is also something you could take into consideration for graphql-java, but worth noting that there might be more people that want to do this so might warrant a change down the line.. Ok, you\u00b4re right - I tried it with a fresh project and then I saw the dependency in the tree, so must be some conflict in my project. Sorry for wasting your time.. Ok, thanks for adding the change to PropertyDataFetcher - but by making the default that it will fetch private fields and no way of changing the default for the whole thing this opens up for some nasty bugs.\nI am using class-level access control annotations on my domain objects, which I think is quite common. If I forget to create an explicit getter or have a getter with parameters then the PropertyDataFetcher will simply bypass the access control check without me noticing it. I really think that people expect private class members to not be accessible by graphql by default.\nI know GSON does this as well, but I think in that case it\u00b4s also quite nasty and even if some people like it there is probably a large number of people that don\u00b4t expect this to be the default.\nI would greatly appreciate it if you could turn it off by default by providing some data fetcher factory or something.\n. ",
    "gdrte": "The above link is broken. Here is the correct one\nhttps://graphql-java.readthedocs.io/en/latest/execution.html. ",
    "gtod": "Ahh, and only now I see #212 addresses this, closing.\n. ",
    "TKffTK": "I mean just that, missed totally from documentation, my bad. I will close this as unneeded request :)\n. ",
    "dpisarenko": "\nSet up the GraphiQL server. \n\nCan you tell, where I can learn, how to do it?. Thanks for your answer.\n\nI would look for a Docker image, if you use docker. \n\nSomething like this ?. You can ignore my last question. I tried it out and it seems to work. Many thanks!. @dminkovsky There is an cross-site scripting (XSS) problem, when I try to run this locally. I've described the problem on StackOverflow -- you are welcome to answer it and get 200 StackOverflow points of reputation (bounty).. @dminkovsky It probably is CORS. I already configure it in my Java application, but there are probably errors. I've updated my SO question so that now it includes code fragments that show, how exactly I configure CORS.. ",
    "commonsguy": "My guess is that compile 'org.antlr:antlr4-runtime:4.5.1' is not the problem. If I had to guess, the antlr plugin is the culprit, either just from applying it or from the antlr \"org.antlr:antlr4:4.5.1\" line in the dependencies.\nI haven't used ANTLR in about a decade, so I haven't played with the antlr Gradle plugin and do not know what to do to suppress that portion of the POM.\n. ",
    "foragerr": "@IamCornholio You found and tied together an SO question, a gradle forum post and a github issue; I bow to your google fu!\nYou should post your pom customization snippet as an answer on SO.\n. I submitted a PR for gradle antlr plugin. https://github.com/gradle/gradle/pull/763\n. ",
    "liaofangcai": "I found it. thanks\n. Has been resolved, thank you very much\uff01\uff01\uff01\n. ",
    "leebyron": "Sorry for not seeing this before. I've been closing out old issues on the graphql branch.\nThis PR unfortunately introduced a bug into graphql-java where previously the behavior was correct. \n4. in a number form should be a parsing error. See https://github.com/graphql/graphql-js/blob/master/src/language/tests/lexer-test.js#L570-L582 for examples of test cases which are expected to produce parse errors.\n@okorz001 is correct about the difference between (list) and (list, opt). http://facebook.github.io/graphql/October2016/#sec-Grammar-Notation explains the meaning of these and illustrates that (list) means one or more of that token. ",
    "danielFesenmeyer": "This is a really nice feature :) Are there any plans when this will be released?. ",
    "industrialist": "Hi Team,\nNice project! I'm keen to understand where this has ended up as I'm interested in extending our existing graphQL schema to a new Spring-based microservice we're adding to our project. I'm just a little unclear as to where things are up to with this. Let me know if I'm being a noob?\nCheers. Thank you!. ",
    "wabrit": "Hi @dminkovsky - many thanks for fixing this; much appreciated.\nAlan. ",
    "AntwaneB": "You're welcome! :) Thanks for your work.. Hum, fixed by reading the spec.... http://graphql.org/learn/schema/#object-types-and-fields\nInt! to make it non-null...\nSorry. ",
    "jleskovar": "@dminkovsky my thinking is that they would just not even be called. I realise my use case is probably quite rare, as I can't have any logging at all, neither at runtime or compile time. I have uploaded a fork (https://github.com/jleskovar/graphql-java) of graphql-java 2.2.0 at coordinates com.github.jleskovar:graphql-java:2.2.0-no-slf4j that completely removes slf4j from the classpath, just for my own usage. . Closing, as I have a workaround for now.. ",
    "smarques84": "Thank you @dminkovsky , this fixed my issue! . ",
    "fderose": "I don't know why StarWarsIntrospectionTests is failing in CI. With the f41a062 commit, it runs locally for me.. ",
    "jplock": "@dminkovsky when 2.4.0 is tagged, would it be possible to update https://github.com/graphql-java/graphql-java-servlet as well?. Nope, it wasn't updated for 2.3.0 yet either, but that would be appreciated.  :). Just curious, but how does this related to https://github.com/graphql-java/graphql-java-tools or are they both doing basically the same thing (schema file -> GraphQLSchema)?. This could be replaced with StandardCharsets.UTF_8. ",
    "vojtechmasa": "Do you have ETA to resolve this issue? Thank you.. @andimarek @bbakerman Wow! That's great news! Thanks a lot guys! I know you said that it might change in the future, but do you think it should be mentioned in documentation? I guess people would need to be interested how to add description for their types / fields.. Looks great. Thank you!. ",
    "JeffQuandt": "When is this PR going to be merged into a release? Specifically, the Generics capability included in this change set. For example, the readme shows creating a DataFetcher using a generic. However, the 2.3.0 release has the non-Generic version.. ",
    "aamura": "I had the same problem than Jeff, README made me happy because I thought that Generic was included in the version but 2.3.0 release doesn't include it.. ",
    "crazyfrozenpenguin": "@dminkovsky, I have just browsed through the code but will soon test it.\nOne feature that it would be great to have would be the concept of DataFetcher dependencies when executing in parallel.\nA DataFetcher can depend on other DataFetchers or, a DataFetcher could unlock other DataFetchers.\n. ",
    "bmsantos": "What's the reason for Java 6? The only release with public updates is Java 8:\nhttp://www.oracle.com/technetwork/java/eol-135779.html. @dminkovsky and @andimarek, if you really want to keep offering support for 1.6, then yes, I don't think that there's any other option other than extract async code into its own jar - maybe graphql-java-async?. Breaking this on its own jar might actually be a much better approach since async related releases/updates will be easier to do.\nLet me know if you need any help on this.. I'm trying to get some free cycles to put out a small version of a project that exercises graphql with Vert.x. This will help me (and maybe others) to quickly exercise and test the async move to a jar. I'll try to put a first sample by the end of this weekend.. @dminkovsky, just published a simple Vert.x project that uses the current implementation of graphql-java-async. You can find it here.\nI'll be using it to exercise:\n\ngraphql-java-async\n@brimworks GraphQL Schema ApiGen\n@aschrijver implementation of Facebook's DataLoader for Vert.x\n. @dminkovsky, I can have a stab into extracting the async related code into its own graphql-java-async lib if that's alright with you.\n\nLet me know what you think.. Sounds good. If you want to rebase, that will be great. Otherwise I can always rebase it myself.\nThanks. Thanks, will get to it ASAP.. @dminkovsky, I've created the graphql-java-async project here. In addition, a PR has been placed against your fork of graphql-java async branch.\nLet me know if you find any issues and/or have any questions.. One reason that crossed my mind is that with this one can start having Apollo style of persisted queries where queries can be identified by ID (see here). If you have a large schema or just wish to provide many different queries, then one might want to store them in a fast clustered cache such as Couchbase.. I asked this same question in #283. The given reason, \"because many companies are still using it\", although acceptable, it is not very convincing. Such companies can always create a new micro/service in the front of their current service(s) and use Java 8 instead (just don't deploy in the same system). After all, this is exactly one of the main reasons why GraphQL shines - it can provide the same as well as reshape consumed data.. Is anyone tackling this task or is it still waiting for other considerations?\nWhat's the strategy being considered?\nShould #336 happen first? Or should it happen in simultaneous, meaning, move project to Gradle multi-project, keep current in java 6 and create a new one in java 8 and start moving parts into sub-modules in java 8 section.\nThoughts?. You should be able to also use GraphQLAsync in something like (not tested):\n```\npublic class Resource {\n    @Inject\n    private GraphQLAsync graphQL;\n\n    @GET\n    public void asyncGet(@Suspended final AsyncResponse asyncResponse) {\n        graphQL.executeAsync(\"write query here\")\n               .thenApply((result) -> asyncResponse.resume(result));\n    }\n}\n\n```\nYou can see a fully working example in Vert.x here.\nGrpahQL and GraphQLAsync can be shared and there's no need to continuously recreate them. . I might be wrong here, but I'm under the impression that this breaks the GraphQL specification.\nI don't think GraphQL is supposed to continuously emit values on a single query. If RxJava is to be used, then the query should probably return rx.Single. Not sure if this is of any advantage since the proposed implementation already returns a Future as per spec.\nI might be wrong here, but it seems that GraphQL future way of handling \"reactivity\" will be through the use of \"subscriptions\" (although not in the spec yet).\n. That said, maybe there's some space for a new \"Reactive\" spec definition. I'm actually interested in a way to do something similar but through an EventBus. In other words, client makes query to GraphQL endpoint and in turn, GraphQL submits queries to backend services that will respond directly to the client. Its more like a \"fragment\" to a query than a \"subscription\" to mutations.. @kaqqao, you are right, it does`t. But what I meant was that it seems that one of the goals in the java async implementation is to have it as close to the JS reference implementation as possible.\nAnd that's what was done in #242\n. @bsideup, all true. I would rather have an interface based on RxJava, even if just rx.Single is returned in order to be closer to a Future behavior. I've used the current proposal for GraphQLAsync in Vert.x (simple example here) and one of the issues that I had is that not all Futures are created equal in Java. Vert.x, like Akka or Guava, has its own Futures implementation and the use of Java's CompletatbleFuture/CompletionStage will for the most part require some sort of translation from any of these other libraries.\nIn nowadays I pretty much convert everything async (rest calls, circuit breakers, etc) into an rx.Observable just because if makes development so much easier and \"functional\".\nUnfortunately, that was not the path chosen by the GraphQL team but maybe there's space for improvement in this area. I mean, it might be an option to create a generic GraphQLAsync that can use different executors. Something like:\njava\ngraphql = new GraphQLAsync<ExecutorType, OutType>(schema, new ExecutorType());\nOutType result = graphql.executeAsync(\"query\");\nLike this one could use an RxJavaExecutor, a CompletableFutureExecutor, or whatever.. I like that it is static so that the methods can be statically imported, making code much cleaner and leaner and simple to parse by the human eye.\nTesting a static method can be problematic but shouldn't be the main reason to discard \"static\" methods altogether.. @bbakerman, normally \"async\" is preferred mainly due to pronunciation: https://english.stackexchange.com/questions/39743/abbreviation-of-asynchronous\n . ",
    "Cafeinoman": "Is there a plan a plan / date to release this? It would be really helpful on an actual project.... ",
    "bsideup": "Hey @dminkovsky, any updates on the status of this PR?. Why not add it to the context?  I use this approach (  nested contexts ) in my Reactive GraphQL - works great :). @bmsantos \nReactive vs. Futures is a very popular topic, especially in JS world (async/await vs. RxJS)\nAn advantage over futures is that it can optionally produce changes to the initial result. In fact, CompletableFutures are supported in graphql-java-reactive:\nhttps://github.com/bsideup/graphql-java-reactive/blob/master/core/src/test/java/com/github/bsideup/graphql/reactive/AdaptersTest.java#L23\nReactive programming usually supersedes futures, because while Reactive Publisher is 0..n, CompletableFuture is 0..1. It means that if you use CompletableFutures/static values everywhere the resulting changeset will always contain at most 1 element without producing any changes.\nBut I like the flexibility of Reactive-aware executor under the hood so that when I want to produce changes I'll not refactor my code.. @bmsantos \nI'm all in for \"async first\" version of graphql-java!\nIn graphql-java-reactive I decided to support reactive Publisher and CompletitionStage by default, but there is adapt method to override:\nhttps://github.com/bsideup/graphql-java-reactive/blob/master/core/src/test/java/com/github/bsideup/graphql/reactive/AdaptersTest.java#L45\nThis way data fetchers are able to return any type they want and the adapting is centralized and reused across all data fetchers :). I can confirm that this PR fixed my issue with missing types.\nCould you target it for 3.x as a hotfix? Otherwise, a big part of IDL is broken :)\nThanks!. Hi,\nYes, my case IS dynamic discovery :) \nI have a pluggable system with many extensions to the single GraphQL endpoint. Thanks! Do you plan to simplify this API somehow? . ok :) Will do. Hey @ieugen,\nYes, you case sounds valid for the change as well :)\nI sent a PR with proposed change, could you please take a look at it and say if it works for you?\nhttps://github.com/graphql-java/graphql-java/pull/478\nYou can even try it yourself thanks to JitPack:\nhttps://jitpack.io/#bsideup/graphql-java/476-parent_type_ref_in_datafetcher-SNAPSHOT. Hey @andimarek,\nDo you have some other review notes about this PR? :). @bbakerman could you please provide .transform() method? (see https://github.com/graphql-java/graphql-java/pull/479 for the ref). please expose value; it can be usable for other things like change tracking (my case). Java test because of transform() lambda. Groovy (until 3.0) doesn't work properly with lambdas and functional interfaces.. Well.... I know that it's possible ( I'm an official Groovy Committer after all :D ), yet I found it very ugly. But if you still want me to do that then no problem, I can change :). sure, will change :). done :). Do you want me to do that in this PR or you will take over?. @bbakerman @andimarek pushed the change with a single object as an argument. ",
    "timtebeek": "Spring Boot support should not be too difficult to add I suppose; I've done so for graphql-jpa here: https://github.com/timtebeek/graphql-jpa-spring-boot-starter/tree/master/src/main/java/com/github/timtebeek/graphql/jpa\nThat's a different project that uses graphql-java to deduce a schema from jpa, but that just means graphql-java would need even less to setup.\n. @dminkovsky As discussed on gitter here's a list of projects that could be related:\n- https://github.com/oembedler/graphql-spring-boot\n- https://github.com/oembedler/spring-graphql-common\nAnd to a lesser extend:\n- https://github.com/jcrygier/graphql-jpa\n- https://github.com/timtebeek/graphql-jpa-spring-boot-starter. ",
    "herojan": "@dminkovsky Ah, I wasn't looking for a solution to a problem I was having, I already have support for this in my own project. I was making this issue to discuss whether or not this feature should be added to graphql-java. Actually adding it isn't hard.\nI had seen that Spring project before but I didn't know it does this. It looks like they based their implementation on Sangria's too, since the documentation structure and headings are the same. The expression language is quite nice.\nThe idea was to add this to GraphQLFieldDefinition and its Builder class, in the same way as the dataFetcher is added. I modified the example above for it to be a bit clearer.\nI do believe it would make sense here because it is a simple pre-execution analysis similar to the validation rules, and because no graphql interface could ever be exposed without supporting this kind of thing. . ",
    "ieugen": "FYI, Github v4 api is GraphQL based and it's interesting to see how they enforce limits [1]. \nThey have a node limit and a rate limit: \n\nClients must supply a first or last argument on any connection.\n  Values of first and last must be within 1-100.\n  Individual calls cannot request more than 11,250 total nodes.\n\n[1] https://developer.github.com/v4/guides/resource-limitations/. Hi everyone,\nI often here the same  argument about still using Java 6 when it comes to libraries and while it is a valid argument in some cases it is not valid in all.\nDoes someone have real usage numbers of the companies that use graphql on Java 6? If not, the argument  to stick to Java 6 might be just guessing. \nAnother argument for switching is that Linux distributions provide Java 8 as default install. For example Debian will be released soon with Java 8, but it is available in backports for current stable.\nGraphQL is not used like this on clients so Android compatibility is not an issue here. \nI also believe using Completable Futures and Optional are big wins!\nDisclosure: I'm considering using GraphQL in a production project with vertx.. @GrigoryPtashko \nI believe version 2.x will be a \"maintenance\" branch and will support Java 7, while version 3.x will use Java 8. Backporting takes some time and effort but it is possbile, especially with the IDE support. From what I saw, graphql-java has very little outside depnendencies so that should make things easier.\nThat being said: \nJava 7 does not have security support since April 2015 [1] . That should be an incentive to upgrade unlesss the company you work for has bought subscriptions for Java or does not care about security. \nI believe there are solutions to switching you infrastructure to Java 8. It's hard to give good solutions without knowledge about your infrastructure and deployment processes but migrating to a micro-service architecture is one good way of doing it. \nDocker could be used for that and you could package the Java version you need. You could also keep multiple Java versions on the same system. \nI strongly encourage your company to consider a migration strategy for their technologies or at least a containerization solution so you can isolate old services and gain the ability to migrate the other systems. \nI can help if you are interested. Feel free to ping me if you wish to talk about it. \n[1] https://java.com/en/download/faq/java_7.xml. Can't wait for this to get merged. Any idea on when it is going to happen? I am really interested iusing graphql with schema generation. So far, there is graphql-apigen but I believe having this functionality in the core project (or community) makes more sense. \nHow can we help out? Let me know and I might find some time to work on this project.\n[1] https://github.com/Distelli/graphql-apigen. I second this. This will make using Dependency injection frameworks a lot more easily. You could let the framework build the components and then wire them into graphql. \nThink about CDI/ Spring / Guice building the data fetchers and then the runtime injecting them by name/type in the proper place.  \nThis can also allow AOP by means of adding directives that force some behaviors in a declarative way.\nI believe this is quite an useful feature. Code generating libraries like graphql-apigee can benefit as well. . @vtahlani https://gist.github.com/ieugen/12e2ccf078c6d07032cc4a26d6dc53ac this might help. . @acidbluebriggs : Sorry for re-opening, but maybe a git flow approach is better suited to having a stable version and a development version. . @bbakerman : You have a good point. Come to think of it, we might end up in the situation with multiple enpoints. \nHow about logging the unused data fetchers for starters?\n. @andimarek : java.util.Optional could do that, no ?  . As they say: If you wish to make an omelet... release version 4 :).. Thanks @bbakerman, I think exposing good models and making the queries fit that model is a good way of achieving good performance. Also graphql maps very good to CQRS and Event Sourcing so I imagine that we can use projections that fit the response we need to send to the end user. But that takes a lot of effort to design properly and it will happen in time. \nSome other tricks I found is that for example, all big players that expose an API do automatic paging of results. Github pages to 30 by default with a maximum of 100 items per page [1] . Amazon AWS does something similar. \nCome to think of it, it is unreasonable not to do some form of pagination automatically. This will limit the number of results fetched and consequently the number of calls to the database that cascade.\nBuilding projections is a more advanced topic but can yield real benefits. \np.s. I managed to reduce the time it took the query to ~6s by tweeking the code and making the calls to the users in the User Data fetcher. Still n+1 trips to the database, but it works faster. Don't know why right now but it is enough for us to adopt graphql internally.  \n[1] https://developer.github.com/v3/#pagination\n. I also have a use case where it would be great to have the name of the type when resolving Data fetchers. \nI have added a gist to help explain the issue [1]. \nIn the schema,  I declare a data fetcher like this:\ntype MutateQuestionnaire {\nstart(id: Long!, token: String!): Questionnaire @dataFetcher(name: \"mutateQuestionnaireStart\")\nAnd I'm using a Spring based wiring factory to lookup a bean with the name mutateQuestionnaireStart and bind it to the field. \nHaving the name of the type MutateQuestionnaire will allow me to implement a sort of auto resolution process where I can declare something like:\nstart(id: Long!, token: String!): Questionnaire @dataFetcher(strategy: \"autowired\")\nAnd then I can lookup for beans with the name computed from the type name and field name: mutateQuestionnaire_start .\nIs this similar to your usage case @bsideup? \n[1] https://gist.github.com/ieugen/12e2ccf078c6d07032cc4a26d6dc53ac. Code looks good to me.. Looks like it made it. V8 was just released https://github.com/graphql-java/graphql-java/commits/v8 . You should also check out Rejoiner. https://github.com/google/rejoiner .\nIt takes GRPC services and generates qraphql api. Uses graphql-java . Have not tested it yet. Please share feedback if you do. \nRegards. Congrats @tinnou :). See graphql java servlet or graphql java spring boot projects from this organization.. My feedback after some time:\nI've considered implementing this back-end but out of time I'm going to try out join-monste . It does all of this on top of nodejs. \nI do believe using Jooq is a better than Calcite because of the maturity of Jooq. \nhttps://join-monster.readthedocs.io/en/latest/\nhttps://github.com/acarl005/join-monster. Look at graphql-servlet and graphql spring boot. This library does not know HTTP. . ",
    "kreed-rmn": "@dminkovsky That'll work! Thanks!. ",
    "darrinps": "Didn't help. Looks like it can't find anything other than class for GraphQL. No methods at all associated with it from what I am seeing. . Thanks.\nWill it be long before that is released? I may wait if it's just a few days or so.\nAlso, do you know if there is an example of how to hit an endpoint? I see it set up for Star Wars for example, but don't see how to set the execute of the Graph object to hit a specific endpoint. So, if I am running that Star Wars instance at localhost://8080 is there an example somewhere of how to configure the execute to hit that point?\n. That works fine by the way. Changes it to:\nGraphQLSchema schema = GraphQLSchema.newSchema()\n                .query(queryType)\n                .build();. ",
    "rayngwf": "This unit test checks the exact reported issue. Thanks.\nTo make unit test for default value more complete, we should include testing with other value types as well, including list and enum etc.. ",
    "ersimont": "I'm hesitant because I don't have a build setup for this project, and I also don't use Gradle. I assume it's just bumping the version number in build.gradle, and that's it?  If so, I could make the PR, but it would probably be faster for a project member to do it themselves than to verify that I did it correctly.... ",
    "huixiaohuang": "Sorry for my misdescribing. For parseDocument(), consider this infomation flow: String input -> Document document. So can we do a parseQueryString() for the information flow that is from Document document -> String input?  \nIn this case, we can do some operations between queries & fragments, such as appending a fragment into a query in runtime. Apperantly we can do this appending operation with a Document instance which is parsed from the String query. However, how can we get the updated String query from its updated Document instance? This is my problem.. Yes! Gorgeous! Thank you.. ",
    "shendepu": "No, I did not find walkaround.\nI think it can also add selectionSet then it will work. Field and InlineFragment has it.\n???? iPhone\n? 2017?1?18??22:59?Dmitry Minkovsky notifications@github.com<mailto:notifications@github.com> ???\nYes, you are correct, I believe this is a defect: you would need to have\navailable the FragmentDefinition referenced by the FragmentSpread to know\nwhat fields the fragment spread is spreading. But in\nDataFetchingEnvironment, nothing has a reference to that fragment. I\nbelieve adding the ExecutionContext to the DataFetching environment has\nbeen suggested elsewhere. We should go ahead and do something like that.\nHowever, FragmentSpread is an AST node that describes the AST. In this\ncase, it's a fragment spread and it has no children. Directly having a\nreference to its FragmentDefinition is not appropriate for an AST class, I\nthink, since its focus is to model a language node as it appeared in the\ndocument.\nThank you for reporting this! Did you find a workaround?\nOn Wed, Jan 18, 2017 at 2:15 AM, Jimmy Shen notifications@github.com<mailto:notifications@github.com>\nwrote:\n\nDataFetchingEnvironment.fields has information selected fields.\nBut when I run below query, I can't find a way to know the field\nselectionSet at emplPositionClasses field. Because it is explicit defined\nfragment, so it is the instance of selection in emplPositionClasses\nselectionSet is FragmentSpread. and there is no methods to get selectionSet\non FragmentSpread.\nFor the other two type of selection, Field and InlineFragment, there are\nmethods to get selectionSet, so inline fragment has no issue.\nthe field emplPositionClasses type is EmplPositionClassConnection\nquery {\nmantle {\nemplPositionClasses {\n...EmplPositionClassesFragment\n}\n}\n}\nfragment EmplPositionClassesFragment on EmplPositionClassConnection {\nedges {\nnode {\nid\nemplPositionClassId\ntitle\ndescription\n}\n}\n}\nSo is it reasonable to also add getSelectionSet() method on class\nFragmentSpread?\n-\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/303, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AANWZePrW1abBlaorCEmjTu7FQy8B8d_ks5rTbwlgaJpZM4LmjVJ\n.\n\n\n-\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/graphql-java/graphql-java/issues/303#issuecomment-273497647, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AEhipWBjumUR_EqdJzLiBD8thgLmkuq-ks5rTiiugaJpZM4LmjVJ.\n. I only find latest java with graphql-java-2017-01-15T22-16-50.jar. It seems #301 not in there yet. So I will need to wait the latest build to give a try.. ",
    "mrcirillo": "From stepping through the code I can see that the actual ExecutionContext is never passed to DataFetchingEnvironment (or the new DataFetchingEnvironmentImpl) as the context parameter (line 31 of ExecutionStrategy). Instead executionContext.getRoot() is passed as that param. Is this intentional? Changing it to pass the ExecutionContext would give us access to fragment definitions. . I've already done it :) I'll make a PR soon.. Could you post the request body that your browser is sending?. > Convince me?\nSpecifically, I need access to the fragment definitions so I can inspect which fields will be resolved. Without the definitions I can only look at a FragmentSpread object, which doesn't tell me much.\nFor me, inspecting these queries is important because I have a schema that is built at runtime by inspecting my database ORM. Associations between my domain objects are lazily loaded, so a deep graph could cause many recursive queries to the db. If I can inspect fragment definitions then I can eagerly join these associations when the query is received and avoid N+1 problems. However these definitions are only available to the ExecutionContext.\n\nNeeds to not break API\n\nRight. I got ahead of myself. I think a way to fix it and not expose the ExecutionContext would be to pass fragmentsByName or a List<SelectionSet> that has no FragmentSpread objects as selections. The former is probably easiest.. ",
    "scf37": "I expected error about missing arguments. \nDoes nullable type of field argument imply default value of null?. ",
    "tklovett": "The spec does explicitly allow for additional user- or implementation-specific fields:\n\nGraphQL servers may provide additional entries to error as they choose to produce more helpful or machine\u2010readable errors, however future versions of the spec may describe additional entries to errors.. Here's a basic implementation that fixes the issue and seems to work end-to-end. The deprecation state was reflected in the schema introspection. \n\njava\n        for (Directive directive : fieldDef.getDirectives()) {\n            if (directive.getName().equals(\"deprecated\")) {\n                for (Argument argument : directive.getArguments()) {\n                    if (argument.getName().equals(\"reason\")) {\n                        final StringValue value = (StringValue) argument.getValue();\n                        builder.deprecate(value.getValue());\n                    }\n                }\n            }\n        }\nIts not the most elegant solution though :). @bbakerman No problem -- I was expecting y'all wouldn't want the new Foo.Builder() changes included. I can revert those and open a new PR.\nFor discussions sake, why is the newFoo() pattern preferred? I personally prefer the direct constructor call because:\n- It removes a level of indirection, where the indirection doesn't encapsulate any ignorable details.\n- When using the constructor directly, I know what type is being instantiated and what modifications are done to it.\n- From reading the static method call, I don't know\n  1. where the method is defined\n  2. what intermediate (Builder) type is being created, or\n  3. what, if any, modifications are done to the Builder before being returned. \n- Calling the constructor directly removes a bit of extra method boilerplate\n- Methods like newParameters don't actually return a FooParameters object, they return a FooParameters.Builder which is a bit misleading.\nOf course IDE tooling eases these concerns so its not a big deal.\nAgain, I'm just interested in the discussion here. I'll absolutely revert those changes before opening a new PR.. Awesome! Thanks\nOn Jun 15, 2017 5:46 PM, \"bbakerman\" notifications@github.com wrote:\n\nClosed #505 https://github.com/graphql-java/graphql-java/issues/505.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/505#event-1125986423,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABIrwSuq-FBRncoLxDjk3ReAObCTa1fHks5sEbRagaJpZM4N7qDO\n.\n. @bbakerman My inclination would be to allow injecting a different error handler per strategy, just in case its needed. Though I can't think of a legit use case for it.. Thanks\n1. No worries -- I'm happy to close this and use your implementation. Thanks for working on that!. This looks great and definitely addresses what I brought up in #523, thanks!. If I'm reading this correctly, this only allows one to specify a \"global\" default data fetcher for all fields. It would also be nice to be able to specify a default data fetcher at the type level.\n\nFor example, we want to use an io.vavr.Either<Error, Success> as the Java backing of a union ErrorOrSuccess = Error | Success for handling common user errors (e.g. \"That username is already taken!\"\nSince the DataFetcher<Either<Error, Success>> doesn't return an Object with properties, the default PropertyDataFetcher does not work for pulling scalar fields out of the object. We've created an \"EitherPropertyDataFetcher\" which 1) maps the Either to the Left or the Right projection and b) delegates to a PropertyDataFetcher to fetch the property from the Left or the Right projection.\nBut this means that we have we have to register the EitherPropertyDataFetcher as the .dataFetcher(...) for every field on the type:\n```\n    private TypeRuntimeWiring.Builder ErrorOrSuccess() {\n        return TypeRuntimeWiring.newTypeWiring(\"ErrorOrSuccess\")\n                .typeResolver(new EitherTypeResolver(\"Error\", \"Success\"));\n    }\nprivate TypeRuntimeWiring.Builder Error() {\n    return TypeRuntimeWiring.newTypeWiring(\"Error\")\n            .dataFetcher(\"message\", EitherPropertyDataFetcher.forProperty(\"message\"))\n            .dataFetcher(\"successful\", EitherPropertyDataFetcher.forProperty(\"successful\"));\n}\n\nprivate TypeRuntimeWiring.Builder Success() {\n    return TypeRuntimeWiring.newTypeWiring(\"Success\")\n            .dataFetcher(\"id\", EitherPropertyDataFetcher.forProperty(\"id\"))\n            .dataFetcher(\"successful\", EitherPropertyDataFetcher.forProperty(\"successful\"));\n}\n\n```\nIdeally, we would be able to register one DataFetcher to be used for every property. e.g.:\nprivate TypeRuntimeWiring.Builder Error() {\n        return TypeRuntimeWiring.newTypeWiring(\"Error\")\n                .fieldDataFetcher(new EitherPropertyDataFetcher());\n    }. A similar low-level exception is thrown when decoding an invalid cursor string on this line:\nString string = new String(getDecoder().decode(cursor), StandardCharsets.UTF_8);\njava.lang.IllegalArgumentException: Illegal base64 character 2d\n    at java.util.Base64$Decoder.decode0(Base64.java:714)\n    at java.util.Base64$Decoder.decode(Base64.java:526)\n    at java.util.Base64$Decoder.decode(Base64.java:549)\n    at graphql.relay.SimpleListConnection.getOffsetFromCursor(SimpleListConnection.java:112)\n    at graphql.relay.SimpleListConnection.get(SimpleListConnection.java:46)\n    at com.foo.BarDataFetcher.get(BarDataFetcher.java:35). Here is an example query (with names obscured) that causes the NPE in NoFragmentCycles.java:67. There may be a simpler case (maybe with less nesting) that reproduces. This example comes from our production schema.\n```\nquery ValidationNoFragmentCyclesNPE {\n  foo {\n    bar {\n      ...definedFragment\n    }\n  }\n}\nfragment definedFragment on Bar {\n  baz {\n    bang {\n      bip {\n        ...undefinedFragment\n      }\n    }\n  }\n}\n```\nHere's the affected graphql-java code:\n```\nprivate void detectCycleRecursive(String fragmentName, String initialName, List spreadPath) {\n    List fragmentSpreads = this.fragmentSpreads.get(fragmentName);\nouter:  // EDIT: should this be here?\nfor (FragmentSpread fragmentSpread : fragmentSpreads) { // EDIT: fragmentSpreads is null here, causing the NPE\n...\n\n```. Would you like me to revert this change entirely and keep the method signature the same?\nOr I can change it to\npublic static Builder newParameters() {\n    return new Builder();\n}\nwith the assertions moved to public FieldCollectorParameters build() {...}, as they are in this PR.. Sure, I'll bring this back in my amended commit.. My interpretation of the pattern was that ExecutionStrategyParameters had access to the constructors of Builder, while outside classes do not. Given that, ExecutionStrategyParameters#transform(Consumer) could call the constructor directly instead of via an additional layer of indirection (the static accessor of the constructor). There were no external callers of ExecutionStrategyParameters#newParameters(ExecutionStrategyParameters), so it was safe to delete.\nWhat's the reason for using this method?. This @Internal API change (and corresponding changes in Execution and ExecutionTest) is new in this amended commit and was not previously reviewed.. These can be inlined if you like, but will then cause merge conflicts with #508 . Removed in f66494b. This is fixed in 0b85a3b. > public abstract class ExecutionStrategy {\nthis super(); call doesn't need to be here. this will be a breaking change to 3rd-party implementations of ExecutionStrategy which don't override handleDataFetchingException but depend on it to add errors to the ExecutionContext. Can we call SimpleDataFetcherExceptionHandler#accept(DataFetcherExceptionHandlerParameters) here?. In my opinion, end users should be responsible for defining the data fetching exception logging. If a client wants simple log-everything behavior, they can easily:\n```\nSimpleDataFetcherExceptionHandlerWithLogging extends SimpleDataFetcherExceptionHandler {\n@Override\npublic void accept(DataFetcherExceptionHandlerParameters params) {\n    super(params)\n    log.warn(...)\n\n```\nIn our API, we have some commonly thrown exceptions (e.g. expired auth) which we don't want to be logged as warnings. Otherwise, we will send tons of non-actionable events through our logging and alerting infrastructure. To implement my own selective logging logic, I had to disable logging on the entire ExecutionStrategy class -- which means I may miss important warnings from it in the future.. > in parallel\nShould this be \"in series\"?\nAlso occurs on the no-args constructor below.. That would certainly work with the current implementation of ExecutorServiceExecutionStrategy. The downside is that there is no explicit contract in ExecutorServiceExecutionStrategy to only use ExecutorService#submit(Callable). If one of the other #submit(Runnable[...]) methods were to be used, this proposed strategy would be silently broken.\nEssentially, this strategy relies on end users having up-to-date knowledge of the internals of the ExecutorServiceExecutionStrategy, which isn't ideal.\n```\n    public class WrappingThreadPoolExecutor extends ThreadPoolExecutor {\n    private CallableWrapper wrapper;\n\n    public WrappingThreadPoolExecutor(CallableWrapper wrapper) {\n        super(\n                0,\n                100,\n                60L, TimeUnit.SECONDS,\n                new SynchronousQueue<>(true)\n        );\n\n        this.wrapper = wrapper;\n    }\n\n    @Override\n    public <T> Future<T> submit(Callable<T> task) {\n        return super.submit(wrapper.wrapCallable(task));\n    }\n}\n\n```\nIf this strategy is to be used, it would be better if ExecutorServiceExecutionStrategy were injected with some CallableOnlyExecutorService which wraps an ExecutorService to provide that contract.. For an example -- it may be reasonable for the ExecutorServiceExecutionStrategy implementation to switch to using ExectorService#invokeAll(Collection<? extends Callable<T>>) instead of \"manually\" using #submit(Callable) and Future#get() for each field.. ",
    "mattesja": "Ok, using the doc from https://github.com/graphql-java/graphql-java/tree/v2.3.0 helped.\nThanks!. I just want to preparse the queries on system startup and keep them in memory.\nI don't think, that a persistent storage of parsed query Documents has a big benefit on performance.. ",
    "gando999": "Sure, I was just found that although I could override toString() on my exception (raised during data fetching), I still did not want to deal with the 'Exception while fetching data' string being appended to the message I raised the exception with. Is there another known way to recover my original message without resorting to string parsing? (I am still new to GraphQL so I am probably missing something) . Ok, its not part of the GraphQLError interface but I guess I can use the getErrorType() to perform an explicit cast. Just felt a bit awkward.. Yep - no worries - thanks for looking. ",
    "deruf": "Please don't accept this yet, I found a problem and have some additional validation to add.. ",
    "karthicks": "Hi, @dminkovsky ,\nJust got a chance to digest the change and comments in #283, and noticed a few differences, some of which may be minor:\n\nYour change, as it stands, requires a force upgrade to Java 8. However, one of your follow-up comments notes that it'd be a separate project, so that distinction is probably moot.\nThere's a dependency on spotify's completable futures library, which my change doesn't require.\nThe async version of GraphQL described here only works with the AsyncExecutionStrategy, whereas the version in your change accepts any kind of ExecutionStrategy, which to me looks more flexible. Does your GraphQLAsync class work with a non-AsyncExecutionStrategy?\nI made a concerted effort to handle the exceptional cases in every CompletableFuture, and surface the error in the ExecutionContext. Your change may have neglected to handle a few error cases, if I'm not mistaken.\nWith your change, the AsyncExecutionStrategy can be run in either serial or parallel mode. In my case, it's always parallel, which probably means that it can't be used as a mutation strategy. On a related note, I was able to get the parallel mode working without having to define a new (user-provided?) interface such as CompletableFutureFactory.\nThe version of AsyncExecutionStrategy here tries to reuse as much of the code in it's super class, viz., ExecutionStrategy, as humanly possible. In your change, I noticed that you're not really using the super class' execute method at all.\n\nI'll keep looking at your change, but I think I nailed down the key differences. All in all, this change is a tad simpler (smaller?). And, it is something that we plan to deploy to production.\n-Karthick. @dminkovsky ,\nThanks for the update. Please take your time - there's no rush. By the way, I just added a way to get a parallel and serial flavor  of the asynchronous strategy, for the query and mutation paths, respectively.\n-Karthick. ",
    "stikkos": "Neat, non-intrusive solution. There is an issue with exception propagation to the ExecutionFuture resulting in a loss of ExceptionWhileDataFetching exceptions though. ",
    "delki8": "Sounds good @dminkovsky, I'm a testing entusiast and GraphQL newbie, hope we can help each other.. ",
    "guy120494": "yes. well, Im not a java expert (yed :P ) but I think it is.\nlets say that getSource suppose to return Integer.\nString s = env.getSource(); - compiles but we get ClassCastException\nString s  =env.getSource(Integer.class) - doesnt compile. that's true, and I think that this is better than nothing, because its sometimes can prevent confusion.\nWorst case scenario, it does no harm. What would happened if execustionResult returns null when error is empty?\nIs there any convention in JSON libraries what happens? I know that in GSON it ignores the null values (unless specific asked not to). changed names and added Javadoc to toSpecification(). can this PR be merged? or do I need to fix anything else?. @andimarek but all JSON libraries respect the \"transient\" keyword, don't they?\nSo we don't restrict ourselves to a specific library. I was going through the code (unfortunately I didn't see any documentation of connection in readdocs) I stumbled across SimpleListConnection.\nThis class assumes that you fetched all the data before it starts building the connection object, so there is no connection in the DB level (I deduced that from the part where it uses the \"after\" and \"first\" arguments). Also, this class creates the cursors, so the datafetcher has no idea of the orders of the cursors, and hence cant use the \"after\" and \"before\" argument, and it cant know whether this is the last/first page.\nIs this class meant to be used? or we have to implement our connectionBuilder class? if so, don't you think it is better to have a dedicated datafetcher for it? (one that can create a cursor per entity, and can be asked if there are any pages left)\nIn the annotations project, we try to solve this in this PR. What do you think?. Does it work also with mutations? A field of the result of a mutation can be exported as a variable to a query?. Sounds fair, but what is the difference between that and an instrumentation? you could say the exact same thing on instrumentation, but yet there is ChainedInstrumentation.. It is not quite what I want, because I want to know the implementations of the interface when building the schema (that are specified by @GraphQLInterface(possibleTypes={..}))\nI guess that's the difference between programmatically building the schema and building the schema with SDL. Well, I just to stay with what I have now  . I'm one of the maintainers of the annotations project. I want to add support for interfaces (What we have now is not enough in my opinion). For that I want to add a new annotation @GraphQLInterface that can be put on interfaces. The problem is: how do I know which classes implement the interface?\nI was thinking that we could have an option to specify which classes implement the interface(@GraphQLInterface(possibleTypes={A.class, B.class}), but on second thought I don't think it is a good idea, because that way we cannot have other classes implement this interface(like if we import the interface from external jar, we cannot implement it). Do you have any idea how can we do that? \nP.s, I noticed that if we have the interface in the schema, then the schema doesnt recognize the implementations of it, unless they are explicitly specified in the schema\nExmaple:\nLets say that under Query I have only the interface Animal. The interface has 2 implementation: Dog and Cat. When I build the schema it doesn't recognize the Dog and Cat classes, but if under Query I have Animal, Cat,Dog then the schema recognizes that Cat and Dog implement Animal. You are right, it does make more sense, I will try that.\nAbout my other question: If the only field of a query is an interface, does the schema suppose know what objects implement it (even though they are not explicitly specified as fields in any place of the schema)?. Lets say I have this schema:\n```\ninterface SomeInterface {\n age:Int\n}\ntype SomeObjecType implements SomeInterface {\nname:String\n}\ntype Query {\nfield:SomeInterface\n}\nSo the only field in my schema (under Query) is the interface.\nWhen I try to query my server I can't do\nquery {\n        field{\n               ... on SomeObjectType{name}\n              }\n}\nbecause the schema doesnt know `SomeObjectType`.\nBut if I have:\ntype Query {\nfield:SomeInterface\nobject:SomeObjectType\n}\n``\nI can run the query above, because the schema knowsSomeObjectTypeand it knows it implementsSomeInterface`\nIs that suppose to be like that? or is a bug in the annotations? if so, I have no idea how to fix that. Well, I use extension in my work, so I prefer to leave it as it is.\nAlso, I think it is better not to delete it and maybe do a //TODO.\nAbout the immutable, it is better to do it immutable after graphql-java supports extension, that way people that do use extensions (like me) don't need to make another instance.\nBut even if you think I'm wrong, I think it's for another PR, don't you?. On second thought, In my work we construct our own object to be sent as a response, so we don't use this getExtensions() method.\nNevertheless, make a PR that supports extensions is better than delete this method and maybe forget about it later in the future.\nBut again, I think this discussion belongs to another PR, because this is not the topic about this PR as i see it. If you want me to remove this method an accept this PR, I would be happy to do so. ",
    "Nickersoft": "Thanks @dminkovsky! Didn't realize there'd be such a difference.. ",
    "aschober": "Thinking on this more, it appears that the expected path is to JSON serialize the entire ExecutionResultImpl object which includes data and error objects as opposed to accessing the fields independently.. ",
    "raderio": "@bbakerman is this documented somewhere?. No documentation?. @andimarek can I help with publishing milestones to maven? What I need to do?. https://github.com/graphql-java/graphql-java/releases/tag/v4.0. At least you can provide a full application sample about DataFetcher and TypeResolver.\nFor example it is not clear to me \n```\nDataFetcher fooDataFetcher = environment -> {\n        // environment.getSource() is the value of the surrounding\n        // object. In this case described by objectType\n        Foo value = perhapsFromDatabase(); // Perhaps getting from a DB or whatever\n        return value;\n}\nGraphQLObjectType objectType = newObject()\n        .name(\"ObjectType\")\n        .field(newFieldDefinition()\n                .name(\"foo\")\n                .type(GraphQLString)\n                .dataFetcher(fooDataFetcher))\n        .build();\n```\nwhy type is GraphQLString, it should be Foo?. But is it planned?. https://github.com/graphql-java/graphql-java/issues/335. > When executing an operation, you can optionally provide a context. If you put the uploaded binary (or entire HttpRequest object) there, you can get a hold of it from DataFetcher. https://github.com/facebook/graphql/issues/349#issuecomment-326064720. Thanks.. May be is it possible to achieve by adding a wrapper class like Undefined<T>, it is something like Optional<T>, so it or has value(nullable or non nullable value) or is not defined\nUndefined<String> or Undefined<Optional<String>>\nin Kotlin Undefined<String?>. Cool, thanks.\n\nI agree that DataFetchingEnvironment should have a getArgumentOpt to returns an Optional to better codify this in one call.\n\n+1. ",
    "apottere": "I think this line is really the problem: https://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/execution/ExecutionContextBuilder.java#L50\nIf you have more than one operation in your query, it forces you to pick one to run.  Isn't that a huge breach of the spec?. Sorry, my mistake - it looks like that is the correct behavior.  The query in the original comment isn't actually valid.\n@vijethpatil if you want to get multiple query results in the same request, you can use something like this instead:\nquery {\n  q1: company {\n    ...\n  }\n  q2: company {\n    ...\n  }\n}. Note that this is only when using the 1-arg constructor for GraphQLSchema or passing null as the mutation type in the 3-arg constructor.  If you pass an \"empty\" mutation object type, the exception goes away and a GraphQL error is returned to the caller:\n{\"errors\":[{\"validationErrorType\":\"FieldUndefined\",\"message\":\"Validation error of type FieldUndefined: Field echo is undefined\",\"errorType\":\"ValidationError\",\"locations\":[{\"line\":1,\"column\":12}]}]}. This throws a NullPointerException:\n```java\npublic static void main(String[] args) {\n    GraphQLObjectType query = GraphQLObjectType.newObject().name(\"Query\").build();\n    GraphQLSchema schema = new GraphQLSchema(query);\nnew GraphQL(schema).execute(\"mutation { doesNotExist }\");\n\n}\n```\nAs does this:\n```java\npublic static void main(String[] args) {\n    GraphQLObjectType query = GraphQLObjectType.newObject().name(\"Query\").build();\n    GraphQLSchema schema = new GraphQLSchema(query, null, Stream.of(query).collect(Collectors.toSet()));\nnew GraphQL(schema).execute(\"mutation { doesNotExist }\");\n\n}\n```\nThis does not:\n```java\npublic static void main(String[] args) {\n    GraphQLObjectType query = GraphQLObjectType.newObject().name(\"Query\").build();\n    GraphQLObjectType mutation = GraphQLObjectType.newObject().name(\"Mutation\").build();\n    GraphQLSchema schema = new GraphQLSchema(query, mutation, Stream.of(query, mutation).collect(Collectors.toSet()));\nnew GraphQL(schema).execute(\"mutation { doesNotExist }\");\n\n}\n``. Yeah, fragment definitions are available on theDataFetchingEnvironmentnow.. Oh, missed your last observation.  I'm all for adding theExecutionContextto theDataFetchingEnvironment, but there was a comment on the last PR that tried to fix a similar issue about not expanding the API surface by exposing theExecutionContext, so that's why I didn't in my PR.. @jplock they are really similar, but graphql-java-tools goes one step further and dynamically creates your data fetchers for you and infers type/field names.  As it stands, this is still a much less opinionated approach.  I still have to look at it a little more, but it's possible I can wrap this in graphql-java-tools so there's less duplicated logic.. That being said, @dh94 you might be interested in https://github.com/graphql-java/graphql-java-tools. Do you want to renameDataFetchParameters,FieldFetchParameters, andFieldParameters` while you're at it?. Do we actually want to expose root here?  I can check how it's done in the reference impl, but it seems odd.. ",
    "vijethpatil": "Thanks @apottere @dminkovsky for clarification. Makes sense to pick the first one if the query(operation) to run isn't specified based on the spec.. ",
    "kobbikobb": "Thank you!. ",
    "vaant": "@andimarek edits from maintainers should be allowed.  As far as graphql#267, I would say this is a partial implementation.  From my reading, there isn't anything that would preclude this as an initial implementation for the Subscription system but the corresponding Events system is entirely ignored.  I suppose this limits usefulness, at least in regards to the RFC, but does provide a very simple way for users to set and manage their own SubscriptionType.. ",
    "yinan-liu": "found a way to do the same.. ",
    "heruan": "@yinan-liu Can you please show how you added totalCount? I'm also interested on this and I can't find a way.. ",
    "greenled": "@yinan-liu please could you talk about the way you found?. ",
    "opshubdata": "Ah. This error occurred while building schema of nested objects not for list type.  Let me remove unnecessary fields from this example,\n```\nfinal GraphQLObjectType attributesObjectType = GraphQLObjectType.newObject().name(\"attributes1\")\n                .field(newFieldDefinition().type(GraphQLString).name(\"key\").build())\n                .field(newFieldDefinition().type(GraphQLString).name(\"value\").build()).build();\n    final GraphQLObjectType systemObjectType = GraphQLObjectType.newObject().name(\"systems\")\n            .field(newFieldDefinition().name(\"attributes1\").type(attributesObjectType).build())\n            .build();\n\n    final GraphQLInputObjectType attributeInputObjectType = GraphQLInputObjectType.newInputObject()\n            .name(\"attributes1\")\n            .field(GraphQLInputObjectField.newInputObjectField().type(GraphQLString).name(\"key\").build())\n            .field(GraphQLInputObjectField.newInputObjectField().type(GraphQLString).name(\"value\").build()).build();\n\n    final GraphQLFieldDefinition systemWithArgs = newFieldDefinition().name(\"systems\").type(systemObjectType)\n            .dataFetcher(new SystemDataFetcher())\n            .argument(GraphQLArgument.newArgument().name(\"attributes1\").type(attributeInputObjectType).build()).build();\n\n    final GraphQLObjectType queryType = GraphQLObjectType.newObject().name(\"query\").field(systemWithArgs).build();\n    final GraphQLObjectType mutation = GraphQLObjectType.newObject().name(\"mutation\").field(systemWithArgs)\n            .build();\n\n    final GraphQLSchema schema = GraphQLSchema.newSchema().query(queryType).mutation(mutation).build();\n\n    String query = \"mutation{systems(attributes1:{key:\\\"1\\\",value:\\\"2\\\"}){attributes1:{key,value}}}\";\n\n```\nSo here, we are using GraphQLInputObjectType object for argument type. But the error is still same.\nLet us know if you need any other details or if we are making any mistake to build schema.. Great!!.\nThanks a lot for saving our time and suggesting best solution.. ",
    "danielocampo2": "@andimarek but does this limitation applies to any object in your schema? If we have 2 different queries with a parameter, say, \"userID\" then that means that we can't use that same parameter name even if it represents exactly the same data for both queries?\nThanks!. ",
    "ronaldborman": "Sure, no problem. See pull request #375 . ",
    "Priyank780": "It means Graphql doesn't support same schema for read/write operation for this type of nested object schema? Should I use different name for reading and writing operation (bad solution basically)?. ",
    "stevehu": "@bbakerman @andimarek When do you think 3.0.0 will be released? As this is an added on feature, it is possible to release it with 2.5.0? Thanks.. ",
    "jauco": "I'm now fairly sure this is a bug:\n\nGraphQLUnionType line 39 contains a method for resolving type references.\nIn the method a check is performed if the type is a type reference, this check will always fail because the type is an object type\nAnd of course you cannot add a type reference because the builder or constructor won't allow you to\n. I made a fix in jauco/graphql-java@85453f8483b74238bc303f0112776acca8be82e5 I'm not sure if this is the best solution, and I don't know how to run gradle unittests so I'm not submitting a PR right now.\n\nBut if you think this is a good approach I will.. thanks!. If that works, it seems like it's indeed a nicer solution than this PR. We're going to check it out!. ",
    "dh94": "looks really cool - awesome work!\ninspiration came from graphql-tools right?\ni think this will be a huge step up for this repository!\ngreat job!!. @apottere  i saw that repo,  but this seems more clean. I'm not sure this is a good thing,\ni think it's nice to have the api decoupled from the implementation completely,\nand with adding this directive you tightly couple them together.. hyphen are not allowed in graphql, see GraphQL naming rules.\nthe pull request you referred to wasn't merged to graphql-js and is closed - so graphql-js doesn't support it.\ni would recommend you look at How to handle Hyphens in GraphQL\n. i'll take a crack at it. @andimarek changed message as requested \ud83d\udc83 . @andimarek @bbakerman  sure thing, should i create a new pull request for this?. @andimarek  @bbakerman  created https://github.com/graphql-java/graphql-java/pull/437. I think maybe the name RuntimeWiring could be a bit misleading, why not call it ResolversMap like in graphql-tools?. I see that you add an error if the type already exists in the current registry,\nso if I'm not mistaken when circular dependencies are introduced an error will be thrown here.\nmaybe we can take the same approach as in graphql-tools to avoid it? http://dev.apollodata.com/tools/graphql-tools/generate-schema.html#modularizing. ",
    "ZeusInTexas": "Forget about it, I just found the perfect way of doing it. I simply forgot to wrap the type with the \"GraphQLList\" type in the query definition.. ",
    "cliedeman": "React router solves this problem nicely by having links to docs of the previous versions right at the top of the readme.. ",
    "kaseyreed": "The current work-around is to ensure the last merged type registry contains the schema definition.. ",
    "vtahlani": "Do you have example for using dataFetcher directive. Below is my IDL schema\n```\nschema {\n    query: QueryType\n}\ntype QueryType {\n    getUser: User@dataFetcher(dataFetcher : \"new com.test.data.User()\")\n}\ninterface User {\n    userId: ID\n    , UserName: String\n    , Friends: [User]\n}\n```\nSchema get loaded successfully but looks like dataFetch not working.\nCan we write custom function as part of dataResolver, the way we can do it with graphql-js? Can we call javaScript functions?. I have aleady gone through this link, here runtime wiring function is\nmissing definition for getDirective and createTypeResolver functions, do\nyou have complete example with run time wiring?\nWhat would you recommend graphql-js or graphql-java?\nOn 14 Jun 2017 04:27, \"bbakerman\" notifications@github.com wrote:\nresolvers are called DateFetchers in graphl-java\nSee http://graphql-java.readthedocs.io/en/latest/schema.html for examples\n@datafetcher is not inherently supported by the base graphql-java engine.\nYou can however write a WiringFactory that would interpret that and create\ndata fetchers based directive. The WiringFactory is passed the \"field\ndefinition\" which includes directives.\nAgain see that example for a custom WiringFactory\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/497#issuecomment-308272169,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AMtxyP-_2ibcOSVjdgogT4k45VaTGPeeks5sDxPrgaJpZM4N4fH3\n.\n. ",
    "acidbluebriggs": "I've already been writing my own, in Kotlin. I can't upgrade from 2.3\nbecause the breaking changes, in 2.4. :-( what happened to semver? ugh!!!!\n;-) Plus, I can't wait as we've run into a total showstopper without it.\nSo, this will require 3.0, eh? Oh well. Thanks for the info. Didn't know if\nthis had been done somewhere else.\nOn Wed, May 10, 2017 at 8:21 PM bbakerman notifications@github.com wrote:\n\nYup - recently added\nSee : #377 https://github.com/graphql-java/graphql-java/issues/377\nIts not released yet but 3.0 is coming soon-ish\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/422#issuecomment-300648088,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAYJk5tLnOz4pzhj___OFQuZb01psWpNks5r4lSAgaJpZM4NWvZ6\n.\n. Hah, I've had to resort to manual parsing of the original query, getting\nthe selection sets and location of the \"sub query\" from the DFE, a custom\nclient to pass the document to the DFE, and all that to find and parse out\nall the fragments that go with the query. Heh. I'm going to like to see\n3.0. Thanks for the info.\nOn Wed, May 10, 2017 at 8:30 PM bbakerman notifications@github.com wrote:\nIt was not possible before to call FieldCollector via API. And then there\nwas no IDL print support in 2.4 either to allow you to reverse engineer a\nparsed Document back into text format.\nThese have been added in 3.0 plus a bunch of other goodies\nThe future readme has more info\nhttps://github.com/graphql-java/graphql-java/blob/master/src/test/groovy/graphql/schema/DataFetcherSelectionTest.groovy\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/422#issuecomment-300649386,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAYJk8subXpL3SGXIokQtuQHKGaj3Jg8ks5r4laygaJpZM4NWvZ6\n.\n. Sorry, one last question... and you can close this... how stable is master?. \n",
    "benmccann": "I've updated README.next.md as requested\nIs there any reason that file lives in src/test/groovy/readme/ instead of the root directory with the other README?. ",
    "ajmalsha": "I need mutation query like this .\nmutation{\n  Author(id:2,name:\"ajmal\",posts:[{id:1,title:\"hello\"}]){\n    id\n  }\n}\ncan you help me?. ```\nSchemaParser schemaParser = new SchemaParser();\nSchemaGenerator schemaGenerator = new SchemaGenerator();\nthis part is not working for me. can you please help me?\nerror like :- SchemaGenerator cannot be resolved to a type \n```\n. @andimarek  i know that i'm asking about if i need to add any dependency to do this? \nI think your maven repository is not updated . and i found some missing file in that. that why i'm facing this issue .. Thanks . ",
    "emmulator": "Ok, I do have a newer version as the default on my system, I'll have to figure out why that build is picking up the older version.  Sorry to trouble you. :). Yes, JAVA_HOME was set to an older version that my company is still on.  Changing that to the newer version fixed everything.  Sorry again and thanks for the quick response! . ",
    "david-tamjidi": "Any idea if this will make it into 7.0? :). Here is a sample query which is triggering the error:\n```\nquery {\n    someObject {\n       someUnionType {\n          ___typename\n          ... on TypeX {\n           field1\n         }\n          ... on TypeY {\n           field2\n         }\n     }\n  }\n}\n```\nThe \"__typename\" field is the one throwing the ClasscastException.. Here is a hacky but simple fix to highlight the error:\n`private void visitImpl(QueryVisitor visitor, SelectionSet selectionSet, GraphQLCompositeType type, QueryVisitorEnvironment parent, boolean preOrder) {\n    for (Selection selection : selectionSet.getSelections()) {\n        if (selection instanceof Field) {\n                GraphQLFieldDefinition fieldDefinition;\n                if(((Field) selection).getName().equals(TypeNameMetaFieldDef.getName())) {\n                    fieldDefinition = TypeNameMetaFieldDef;\n                } else {\n                    GraphQLFieldsContainer fieldsContainer = (GraphQLFieldsContainer) type;\n                    fieldDefinition = getFieldDef(fieldsContainer, (Field) selection);\n                }\n            visitField(visitor, (Field) selection, fieldDefinition, type, parent, preOrder);\n        } else if (selection instanceof InlineFragment) {\n            visitInlineFragment(visitor, (InlineFragment) selection, type, parent, preOrder);\n        } else if (selection instanceof FragmentSpread) {\n            visitFragmentSpread(visitor, (FragmentSpread) selection, parent, preOrder);\n        }\n    }\n}`\n\n. Please see the attached unit test case as it will help highlight the problem\n<------------------------->\nimport java.util.Map;\nimport org.junit.Before;\nimport org.junit.Test;\nimport graphql.ExecutionInput;\nimport graphql.ExecutionResult;\nimport graphql.GraphQL;\nimport graphql.execution.AsyncSerialExecutionStrategy;\nimport graphql.schema.GraphQLObjectType;\nimport graphql.schema.GraphQLSchema;\nimport static org.junit.Assert.assertEquals;\nimport static graphql.Scalars.GraphQLInt;\nimport static graphql.Scalars.GraphQLString;\nimport static graphql.schema.GraphQLFieldDefinition.newFieldDefinition;\nimport static graphql.schema.GraphQLObjectType.newObject;\npublic class TestExceptions {\nprivate GraphQL fGraphQL;\n\n@Before\npublic void setup() {\n    GraphQLObjectType queryType = newObject().name(\"QueryType\")\n            .field(newFieldDefinition().name(\"FIELDS\").dataFetcher((env) -> env).type(newObject().name(\"FieldsType\")\n                    .field(newFieldDefinition().name(\"FIELD_STRING\").type(GraphQLString)\n                            .dataFetcher((env) -> \"TEST\"))\n                    .field(newFieldDefinition().name(\"FIELD_INT\").type(GraphQLInt).dataFetcher((env) -> 1))))\n            .build();\n\n    GraphQLSchema schema = new GraphQLSchema(queryType);\n    fGraphQL = GraphQL.newGraphQL(schema).queryExecutionStrategy(new AsyncSerialExecutionStrategy()).build();\n}\n\n@SuppressWarnings(\"unchecked\")\n@Test\npublic void simpleQuery() {\n    // The idea here is to put a breakpoint on line 75 inside the catch block of eachSequentiallyImpl() of\n    // Async.java\n    // to see that the exception gets thrown each time or add a print statement temporarily inside the catch block\n    // to print out each time the exception gets thrown\n    ExecutionResult result = fGraphQL\n            .execute(ExecutionInput.newExecutionInput().query(\"query { FIELDS { FIELD_STRING, FIELD_INT } }\"));\n    assertEquals(\"Errors wasnt null: \" + result.getErrors(), result.getErrors().size());\n    Map<String, Object> data = result.getData();\n    assertEquals(\"TEST\", ((Map<String, Object>) data.get(\"FIELDS\")).get(\"FIELD_STRING\"));\n    assertEquals(1, ((Map<String, Object>) data.get(\"FIELDS\")).get(\"FIELD_INT\"));\n}\n\n}\n<------------------------->. Applying the simple fix from the first comment will stop the exception from being thrown improving performance greatly for the non-async case. ",
    "jameskleeh": "Right, so my question is how would I get the value of that header?. @andimarek That is exactly what I was looking for. Thanks!. @bbakerman Thanks for the response. Given the scalars are not used by this library itself and instead are for usage by users, it doesn't make much sense to me why they would be designed in a way that isn't extensible. That was just a side note however and I didn't intend to distract from the main reason for creating this issue.\nIf you perhaps describe the way the methods in Coercing are used, I would be happy to submit a PR for the javadoc. @bbakerman Thanks for the javadoc update.\nRe: https://github.com/graphql-java/graphql-java/pull/585/files#diff-dc68e8d611d1400df42325428aee3043R44\nWill the input to parseValue be an instance of graphql.language.Value?. Also in regards to the specification for Scalars, currently (2.4.0) they throw an exception, and do not raise a query error per what the spec says. \n\"If the integer input value represents a value less than -231 or greater than or equal to 231, a query error should be raised.\"\nIs there any way to raise a query error with a custom scalar type in version 2.4 ?. @bbakerman Can you explain how the Scalars raise query errors in 3.0 ? As far as I can see, exceptions are still thrown instead of a query error being raised.\nhttps://github.com/graphql-java/graphql-java/blob/v3.0.0/src/main/java/graphql/Scalars.java#L79\nThanks!. @bbakerman Sure thing! I'll put something together. @bbakerman PR submitted. Also just FYI. I'm writing an automatic schema generator for GORM (Grails Object Relational Mapper https://gorm.grails.org) using this library. https://github.com/grails/gorm-graphql. @andimarek Thanks! Done. The main goal of this change was to leave ValidationUtil alone as much as possible to keep the logic intact.. @bbakerman The changes around the error messages and removal of parallelStream is complete. @bbakerman Thanks for merging!. @bbakerman No problem - I'll remove the usages. @bbakerman I think a separate class is better because the whole context is surrounding a single argument. You would have to set the argument inside the validation util before doing validation and then clean it up afterwards. It couples validation to arguments and would make for less clean code. Just my 2c.. ",
    "tkvw": "Why didn't you implement a custom serialization \ntype for this? @see: https://github.com/google/gson/blob/master/UserGuide.md#TOC-Custom-Serialization-and-Deserialization. Nice, thanks for the changes (I checked them and they look fine by me), closing this PR.  . ",
    "SeenaLibin": "Hi,\nBut the same code worked fine in version 2.1.0. ",
    "bowenliang123": "@andimarek All right. I am considering staying version 2.4.0 for further use. Thanks for your detailed reply.. ",
    "omaraya11": "Sure .. anytime . ",
    "LarsKrogJensen": "I would argue that a cache is out of scope of this project, as you said even a simple LRU cache is tricky. There are many quality open source caching solutions out there, looking especially at caffeine. With only a few lines of code you, as a user, have a quality cache in place\nWhats more is that to achieve high cache hit ratio it is recommended that field arguments are passed in as variables instead of directly in the query.\nUpdated the doc to include usage.. Updated the execution documentation on how to use it.\n. FWIW, I few months I played with porting graphql-java over to kotlin (https://github.com/LarsKrogJensen/graphql-kotlin) just for the fun of it and learning. Kotlin is such a beautiful language. One of the features that I really wanted to implement was async data fetchers all the way without any usage a threads or thread pools. \nI went with CompletionStage, which I regret - it didn't provide any real value as one of the comments above also concluded.\nOne change that I also made was to make DataFetcher interface return a CompletionStage, and that was maybe not the best choice as:\n- Most fields are simple leafs and don't require async, they should just return values.\n- It did not play well with subscription types. To support subscriptions executions I had to add additional PublisherFetcher. (There is a simple SubscriptionExecutionStrategy implementation)\nWhat I really would like is the datafetcher to return a union type (not available i java or kotlin yet) of\nObject | CompletableFuture | Publisher (reactive stuff). This would on the other hand make the execution strategy more complicated as it would have to examine the value and select different value completion strategies.\n. Nice, but the solution ignores a potential alias field. Should I open a new issue?. @andimarek  Sorry for being unclear, but you are correct - I upgraded a project from graphql-java 10 to 11.\nProject is currently using java 11.. Sure, will try to create a reproducer.. Thanx for the hint, will try that.\nSpent a few hours on trying to create a simple reproducer, but failed so far. I'll continue.. #1216 might indeed be related, unsure how yet.. Can confirm this issue is the same a #1216. Now that I know what is causing it I can work around it, closing as duplicate. Thanks for the responses, I should have look harder for known issues.  :(. Check. It can if the document provider for what ever reason returns null. We could either let it throw a NPE or wrap it into a more descriptive exception.\nThe lambda will always return a non-null result though.. Converted lambda to function, will look into if I can target this function with test.. ",
    "AndiMiko": "funny, I came here one hour after you to request the exact same thing!\nActually, I thought I found a way to achieve this with a custom wiring factory that contains the RunTimeWiring and checks whether one exists. Like this:\n```\npublic class CustomWiringFactory implements WiringFactory{\n    private RuntimeWiring wiring;\n    public AnnotationAwareWiringFactory(RuntimeWiring wiring) {\n        this.wiring = wiring;\n    }\n    @Override\n    public boolean providesDataFetcher(TypeDefinitionRegistry registry, FieldDefinition definition)\n    {\n        return true;\n    }\n@Override\npublic DataFetcher getDataFetcher(TypeDefinitionRegistry registry, FieldDefinition definition) {\n    DataFetcher existingFetcher = wiring.getDataFetcherForType(parentType.getName()).get(definition.getName());\n    if (existingFetcher != null) {\n        return existingFetcher;\n    }\n    return new CustomDataFetcher();\n}\n\n}\n```\nBut the problem is, that getDataFetcher is only passed the FieldDefinition and as far as I can see there is no possibility here to know which type it does belong to.\nIsn't this a general Problem here? The power of a custom WiringFactory is not very impactful if you get a field without any information to which type it does actually belong to.\n. I solved the first issue on the current version by adding a custom DataFetcher whenever none is present. Not perfect, but works for now.\nprivate RuntimeWiring.Builder makeDefaultWirings(RuntimeWiring.Builder wiring,\n                                                     TypeDefinitionRegistry compiledSchema)\n    {\n        for (String typeName : compiledSchema.types().keySet()) {\n            Map<String, DataFetcher> dataFetchers = wiring.build().getDataFetcherForType(typeName);\n            TypeDefinition type = compiledSchema.types().get(typeName);\n            if (type instanceof ObjectTypeDefinition) {\n                for (FieldDefinition fieldDefinition : ((ObjectTypeDefinition) type)\n                        .getFieldDefinitions()) {\n                    dataFetchers.computeIfAbsent(fieldDefinition.getName(),\n                                                 AnnotationAwarePropertyDataFetcher::new);\n                }\n            }\n        }\n        return wiring;\n    }\n. I would call it DefaultDataFetcher, last resort sound kind of strange :). Will add tests later. I had problems compiling the current master cause of some antlr dependencys missing. I think it was in graphql.parser package. Do you have a hint what I was missing? (not at my desk right now). should be ready now. @andimarek @bbakerman . @andimarek is something wrong? . There is already a change on the current master to change this interface (and support more stuff). You are not overwritting the ExecutionStrategy anymore, but instead implement a DataFetcherExceptionHandler\n```\n/*\n * This is called when an exception is thrown during {@link graphql.schema.DataFetcher#get(DataFetchingEnvironment)} execution\n /\npublic interface DataFetcherExceptionHandler extends Consumer {\n/**\n * When an exception during a call to a {@link DataFetcher} then this handler\n * is called back to shape the error that should be placed in the list of errors\n * via {@link ExecutionContext#addError(GraphQLError)}\n *\n * @param handlerParameters the parameters to this callback\n */\n@Override\nvoid accept(DataFetcherExceptionHandlerParameters handlerParameters);\n\n}\n```\nWith DataFetcherExceptionHandlerParameters having following fields.\n```\npublic class DataFetcherExceptionHandlerParameters {\nprivate final ExecutionContext executionContext;\nprivate final DataFetchingEnvironment dataFetchingEnvironment;\nprivate final Field field;\nprivate final GraphQLFieldDefinition fieldDefinition;\nprivate final Map<String, Object> argumentValues;\nprivate final ExecutionPath path;\nprivate final Exception exception;\n\n```\n. ExceptionWhileDataFetching is not a throwable/exception. DataFetchingException shouldn't be specific to BatchedExecutionStrategy, I see more usecases for it.. ",
    "filipncs": "Any plans to do a minor 3.0.x release with this fix? The commit that fixed this (https://github.com/graphql-java/graphql-java/commit/9addb0219831a39c9ffc3cc96ab445c4e15b700f) applies cleanly to v3.0.0 with only a couple of adjustments.\nI'd gladly supply a PR with a clean modification to v3.0.0 that fixes the issue and includes a test.\nIn general it would be nice to have an idea of what the current roadmap looks like, e.g. if it would make more sense to hold out for 4.0.0. And the GraphQLError is turned into an actual compliant response here: https://github.com/graphql/graphql-js/blob/master/src/error/formatError.js#L15\n/**\n * Given a GraphQLError, format it according to the rules described by the\n * Response Format, Errors section of the GraphQL Specification.\n */\nexport function formatError(error: GraphQLError): GraphQLFormattedError {\n  invariant(error, 'Received null or undefined error.');\n  return {\n    message: error.message,\n    locations: error.locations,\n    path: error.path\n  };\n}. And here is a near-minimal node example, using graphql-js, that exercises the behaviour of the reference implementation:\n```\nvar GQL = require('graphql');\nvar schema = new GQL.GraphQLSchema({\n    query: new GQL.GraphQLObjectType({\n        name: 'RootQueryType',\n        fields: {\n            hello: {\n                type: GQL.GraphQLString,\n                args: {number: {type: GQL.GraphQLInt}},\n                resolve() {\n                    return 'world';\n                }\n            }\n        }\n    })\n});\nvar query = 'query namedQuery($var: Int!) { hello(number: $var) }';\nvar variables = {\"var\": \"not-a-number\"};\nGQL.graphql(schema, query, null, null, variables).then(result => {\n    console.log(result);\n});\n```\nPrinted result:\n{ errors:\n   [ { GraphQLError: Variable \"$var\" got invalid value \"not-a-number\".\nExpected type \"Int\", found \"not-a-number\": Int cannot represent non 32-bit signed integer value: not-a-number\n    at getVariableValues (/private/tmp/example/node_modules/graphql/execution/values.js:97:15)\n    at buildExecutionContext (/private/tmp/example/node_modules/graphql/execution/execute.js:207:54)\n    at executeImpl (/private/tmp/example/node_modules/graphql/execution/execute.js:121:15)\n    at execute (/private/tmp/example/node_modules/graphql/execution/execute.js:110:229)\n    at /private/tmp/example/node_modules/graphql/graphql.js:75:34\n    at Promise (<anonymous>)\n    at graphqlImpl (/private/tmp/example/node_modules/graphql/graphql.js:59:10)\n    at Object.graphql (/private/tmp/example/node_modules/graphql/graphql.js:48:227)\n    at Object.<anonymous> (/private/tmp/example/index.js:21:5)\n    at Module._compile (module.js:624:30)\n       message: 'Variable \"$var\" got invalid value \"not-a-number\".\\nExpected type \"Int\", found \"not-a-number\": Int cannot represent non 32-bit signed integer value: not-a-number',\n       locations: [Array],\n       path: undefined } ] }\nI.e. the GraphQLError is caught long before it reaches the calling code, and is added to the errors array (that can then be formatted for a serialized response with the above mentioned formatError method).\nTo sum up: The reference implementation does not let GraphQLErrors bubble out to calling code. It includes them in the errors array.. Even just the operationName would be quite helpful.. I added a commit to the PR that performs the necessary change. Doesn't seem to obviously break anything else.. ",
    "abassouk": "I have implemented a reactive version of ExecutionStrategy that works with RxJava 2, and on the happy path it works beautifully. If your DataFetcher is returning any of the Rx reactive streams, a Publisher, Futures/CompletableFutures or even a CompletionStage, it works as expected. Parallelism is up to the DataFetcher and the reactive stream object it returns - if the reactive object is on different scheduler then it's going to be fetched async.\nThis hasn't needed any changes to the ExecutionStrategy so far, and the only problem left at the moment is merging errors from async and non-async sources.. ",
    "backjo": "Yep - will do!. ",
    "thecaddy": "Perfect!  This is great.  Any idea on when you think these features will ship?. ",
    "donbeave": "Hi @andimarek \nThank you, understand.\nI just created PR: https://github.com/graphql-java/awesome-graphql-java/pull/6\nBest regards,\nAlexey Zhokhov.. ",
    "jdorleans": "@donbeave It'd be nice to have your lib not depending on spring, but rather a raw date/time support. Have you consider doing this? . No worries, I can add them back. I just followed the other files format which seems to be aligned with java standards better.. ",
    "rhmoller": "Hi, what can I do to move this forward? \nIt is currently blocking us from upgrading to 3.0. which is fine as long as the framework only creates one instance of each type.\nalternatively I can map the collection of types to a collection of type names and check that instead?. ",
    "huangd0ng": "@andimarek I saw your comments and I'll submit a patch after work. We are using this library in production and feel good. Thanks for your work!. @bbakerman  @andimarek  i'm sorry that there're too much work to do recently and I haven't made changes according to your reviews. I saw @bbakerman submitted changes based on this. Shall we abandon this PR?. We are doing something like that. We build services based on Spring Cloud which provides restful api and use graphql for client queries. I built a library like feign using annotations to define how to fetch data from backends and create data loaders automatically. To answer your question, we use restful api between services and connect them in the graphql gateway. At client side, we use apollo client.. Maybe you are looking for something like GraphQL schema stitching  https://dev-blog.apollodata.com/graphql-schema-stitching-8af23354ac37  ?. ",
    "imrikoch1212": "Do you know if it will contain any breaking changes from the current release?. ",
    "soudmaijer": "Hi, really looking forward to the 4.0 release. Would love to start using the AsyncExecutionStrategy.\nWould be nice if you could publish some milestones to a maven repository that last a bit longer than a day (bintray) ;-)\nThanks for the great work so far!!! . could you also backport this to 4.1.x? It breaks graphiql completely now running the introspection query.. ",
    "mikeparisstuff": "Thanks for the fix :). Awesome this looks exactly like the issue.. I believe I've stumbled upon this issue as well and as an aside would also love to see the validation system become more pluggable in the future.\nGiven how the spec (http://facebook.github.io/graphql/October2016/#sec-String-Value) defines a string value I would think the implementation should validate that things that are being used as strings are indeed strings. I would expect the query in the snippet below to fail at validation time because I am trying to use a variable of type ID! for an argument of type String!.\nCurious what paths forward there are to fix this.\nHere is a snippet that isolates the issue.\n```java\nimport graphql.ExecutionResult;\nimport graphql.GraphQL;\nimport graphql.schema.GraphQLSchema;\nimport graphql.schema.StaticDataFetcher;\nimport graphql.schema.idl.RuntimeWiring;\nimport graphql.schema.idl.SchemaGenerator;\nimport graphql.schema.idl.SchemaParser;\nimport graphql.schema.idl.TypeDefinitionRegistry;\nimport java.util.HashMap;\nimport static graphql.schema.idl.RuntimeWiring.newRuntimeWiring;\npublic class HelloWorld {\npublic static void main(String[] args) {\n    String schema = \"schema { query: Query } \\n\" + \"type Query{ hello(str: String!): String }\";\n\n    SchemaParser schemaParser = new SchemaParser();\n    TypeDefinitionRegistry typeDefinitionRegistry = schemaParser.parse(schema);\n\n    RuntimeWiring runtimeWiring = newRuntimeWiring()\n            .type(\"Query\", builder -> builder.dataFetcher(\"hello\", new StaticDataFetcher(\"world\")))\n            .build();\n\n    SchemaGenerator schemaGenerator = new SchemaGenerator();\n    GraphQLSchema graphQLSchema = schemaGenerator.makeExecutableSchema(typeDefinitionRegistry, runtimeWiring);\n\n    GraphQL build = GraphQL.newGraphQL(graphQLSchema).build();\n    ExecutionResult executionResult = build.execute(\n            \"query Get($str: ID!) { hello(str: $str) }\",\n            \"Get\",\n            null,\n            new HashMap<String, Object>() {{ put(\"str\", 1); }}\n    );\n    // This throws the error: Exception in thread \"main\" graphql.AssertException: wrappedType can't be null\n}\n\n}\n```. \ud83d\udc4d . ",
    "martijnwalraven": "Great to see this moving so fast! One point of feedback is that you may want to use Instant.now() instead of ZonedDateTime.now(), and DateTimeFormatter.ISO_INSTANT instead of DateTimeFormatter.ISO_OFFSET_DATE_TIME for startTime and endTime.. @bbakerman: Great! The Scala code has also been changed.. ",
    "yarinvak": "https://github.com/graphql-java/graphql-java/pull/434 the closed pull request discussing this issue. Is it going to be implemented soon?. I think that this feature could be very helpful. Exposing metadata on the schema can be very useful - for example, if we wish to create a separate service which validates queries sent to a graphql service, and we wish to restrict inputs. With directives, we will be able to expose the input validation restrictions through the graphql schema (and the service will be able to be updated with the validation restrictions by sending an introspection query to the graphql service).\nI don't see any reason to not expose directives in the introspection query as the schema is pretty much public and the goal of the introspection query is to provide a way to understand and query the schema. Directives are inherentic part of the schema and I don't see any reason why to not expose it.\nIf I would like to PR this issue, it could be accepted by you? Or do you have any suggestion how to expose a service metadata without extending the introspection?. I see a little problem that maybe you can give me some solution for.\nLets say I want to build a GraphQLType for the Query type. I can supply this type with 'GraphQLDirective's. I guess these are the directives that are decorating the type itself, like as if I build a GraphQLField with directives.\nBut the directives definitions should be supplied to the GraphQLSchema, so if the schema does not contain a directive definition, it should not work on the Query type or on some field.\nBut while building the Query type, or any graphql type, I do not know which directives are declared in the schema. So i might be using directives on some type or field which are not declared in the schema and it will still work.\nTo be more detailed: in graphql-java-annotations we allow building graphqltypes out of annotated classes and fields. And if i wish to add some directive wiring functionality, i will never know what directives are declared in the schema because its not in my scope. \nWhat do you think is the right usage in this case? \n. For example, lets say I have the type Person.\nIn graphql-java-annotations, I would create a class Person:\njava\npublic class Person{\n@GraphQLField\nString name;\n@GraphQLField\nPerson[] friends;\n}\nIt will be generated into a corresponding GraphQLType of Person, when I'll call GraphQLAnnotations.object(Person.class).\nLet's say I wish to add GraphQLDirective support over one of the Person's fields.\nSo I will annotate it like that:\njava\n@GraphQLField\n@GraphQLDirective(\"toUpperCase\")\nString name;\nMy dilemma is where to declare the \"toUpperCase\" directive? The problem is not how to generate a GraphQLDirective from annotation, but where to declare this annotation. Because in SDL we declare the directive definition on the schema itself, but here I have only the Person, and I don't think the Person class is the right place to put the directive definition on.\nI guess that any solution is not going to be very clean, because I do not have the schema while creating the type.\nI would suggest that GraphQL-Java will validate that if a type or a field in the schema contains directives, they are also declared/defined on the schema, so a situation where field is decorated with an unsupported directive would not be happening.\n. But directives definitions should be declared on the schema, as far as I understand, and not over specific fields/types.\nSo if some field or type is decorated with a directive which is not defined on the root level of the schema which contains the object, an error shoud occur (I think this is a reasonable behaviour).\nMy suggestion is that you add a validation in the schema building (in code first) which checks whether a specific object contains directives which are not declared in the schema.\nI can pr this but I would like to understand if this logic is reasonable and accepted. I see what you did here and I did implement something like that for the meantime.\nBut let's talk about graphql-java.\nUsing your library, someone might create a project which only creates some GraphQLTypes. Another project will create different GraphQLTypes. Than, in a third project, we would merge these types into a schema. \nNow, if in the first project we decorated the types with a directive named \"uppercase\" with some valid locations/valid arguments, and in the second project we decorated with a directive named \"uppercase\" too but with other valid locations, we created a conflict. There is not a single point of truth (which in my opinion should be the directives which are declared on the schema itself).\nAnd more than that, in the current implementation we can add directives to fields and types without adding them to the schema, and they won't be exposed on the introspection query.\nA validation on the schema.build() which validates that every directive which is being used in a type/field/etc is also declared on the schema, and that there are no multiple directives with the same name, may solve that. . ",
    "justinsb": "Thanks - removed that comment and just amended the commit (as the change is so small)\n. Similar to #586 . ",
    "yspotts": "sure. Here is a simple one that causes the issue:\n```\n{\n      summary \n       }\n}\n```\nIt has a missing open brace\nLooking at the code, it seems pretty clear the exception comes from graphql.Parser line 46. Indeed, there is no root cause to that exception. . Running version 3.0.0. ",
    "BattleBeaver": "cool, thank you, @bbakerman!. ",
    "tylerhjones": "ah ok, thank you. ",
    "realityforge": "It should be noted that this cherry picks a commit from https://github.com/graphql-java/graphql-java/pull/600 originally submitted by @michaelplavnik . ",
    "breathermachine": "Hello, I'm new to GraphQL and I'm trying to use this functionality to perform per-field authorization. Is there a way to customize the error message?\nInstead of \"Validation error of type FieldUndefined: Field 'name' in type 'Organization' is undefined @ 'employees/homePosition/organization/name'\", I would like to error to be something like:\n\"Validation error of type FieldAccessError: Field 'name' in type 'Organization' is not accessible given current credentials\"\nThank you!. @kaqqao Thank you for your response. Actually what I wanted to do was to return a 403 while revealing as little information to the outside as possible. However, graphql is returning the same error message for fields not supported by the schema, and blocked fields. I would like to have it distinguish the two cases so I can send the appropriate HTTP code (404 for the first case and 403 for the second).\n. ",
    "zhewang2": "Return DataFetcherResult type should be good.\nTake a look at DataFetcherResult class and return it as the final type of result with errors.\npublic DataFetcherResult(T data, List<GraphQLError> errors) {\n    this.data = data;\n    this.errors = Collections.unmodifiableList((List)Assert.assertNotNull(errors));\n}\n\n. ",
    "martin-g": "The GraphiQL example is not the same as the failing one.\nIn the failing one you have a backslash followed by a new line character. In the GraphiQL there is no new line. The error message comes from Jackson and says that there is a problem with code=10, i.e. LF, not the backslash.. ",
    "MartinX3": "Thanks for your fast response.\nThere is a new line character. Github killed the new line after the \\  .\nI look, if I can reformat this issue code block.. I'm using this one for spring boot:\ngraphql-spring-boot-starter. I made a mistake\nI used \"\" in the application.properties.... ",
    "drewolson": "This looks like the right fix. I'm unsure of how to test these in-progress fixes via maven.\nAlso, I agree that this should be released as 4.0.1 if you're willing to do it.. \u2764\ufe0f . I'm working on a PR now. If nothing else, I should at least be able to provide a failing test. Will update this issue once I've got it.. I wrote a failing test in my fork here. The problem is this line. The fact that the selectionSet is null is causing the null pointer exception.\nI'll poke around and see if I can find a solution but I'm guessing you may know the fix faster than I do.. @andimarek The point is that the selectionSet is null but it should not be. The null selectionSet for interfaces is blowing up when it calls this line (as far as I can tell). I can try to create an example app that fails, if that helps.. Here's the simplest example I could come up with that explodes.\nhttps://github.com/drewolson/graphql_npe_example/blob/b1c6d0cca5791062b80c323cf39e864fd6d76429/src/test/java/NpeExampleTest.java. @andimarek my apologies, it appears that interface was a red herring. The actual cause of my NPE is the introspection field __typename. I've updated my example to demonstrate the problem. I hope this helps! Thanks for your responsiveness.. Thanks! Any chance in getting this on a 4.2 release? This bug completely breaks GraphiQL when using instrumentation. . Yes, will do.\nOn Sat, Sep 2, 2017 at 8:45 AM Andreas Marek notifications@github.com\nwrote:\n\nmaybe .. we haven't planned it yet.\nBut you could you please test it before we release it?\nAfter the PR is merged you just have to use the latest dev build:\nhttp://graphql-java.readthedocs.io/en/v4/getting_started.html#using-the-latest-development-build\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-java/graphql-java/issues/669#issuecomment-326744892,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAAN0KP5nqVF86Bl1JHANc9NO9ithFLsks5seVvjgaJpZM4PHofP\n.\n. I have confirmed that this fix works for me, thanks!. I have confirmed this is fixed for me on master. It would be really great to get this into a 4.1.x or a 4.2 release along with the introspection fixes. Thanks!. Great, thanks!. @bbakerman I disagree with the conclusion here. I strongly believe that coercion should throw an error if an unexpected (non-coercible) value is found in the provided variables.\n\nThe primary reason for this is that, as a user of GraphQL, I should be able to have the expectation that all the arguments to my fields will be type-checked against the provided GraphQL schema. This is, of course, one of the primary benefits of using GraphQL in the first place. If I want to provide my users the ability to use variables (I do) and graphql-java chooses to not validate the values within the variables, this means that I must assume that any argument to my data fetchers may be invalid at the time the data fetcher is invoked. To me, this removes a primary benefit of using GraphQL -- the idea that the domain logic in my application can assume valid input and that this is guaranteed by the GraphQL implementation.\nAll other major implementations behave in the way my test was expecting. Here is an example of the same issue in the graphql-ruby library. It correctly (in my opinion) fails with invalid input values provided via variables (both in simple and more complex cases). I'd be happy to also build examples in elixir and javascript.\nPerhaps I'm misunderstanding your proposed solution and, if so, I apologize. I think it is vitally important that a data fetcher can trust both the structure and type of values that are provided as arguments, regardless of passing these values as literals or variables.. Here's the specific section of the spec I believe this behavior is at conflict with: http://facebook.github.io/graphql/October2016/#sec-Coercing-Variable-Values\nThe line that is most relevant to this discussion is:\n\nOtherwise, if value cannot be coerced according to the input coercion rules of variableType, throw a query error.\n\nIf the goal is to allow other libraries the ability to turn a set of resolved variables into a POJO, that's fine, but it should happen after the raw variables are coerced into a Map. In my application, I do this manually using Jackson with something like objectMapper.convertValue(env.getArgument(\"input\"), MyClass.class) in my data fetcher.. @bbakerman I think you're right that throwing an error would also be in the spirit of the spec. It might be slightly more inconvenient for implementers but I think it's definitely usable.\nHere's the line that convinced me that some kind of error (thrown or added to errors) is correct:\n\nIf a query error is encountered during input coercion of variable values, then the operation fails \nwithout execution. [1]\n\nI think the without execution phrasing is very relevant to this discussion.\nThanks for the conversation so far, looking forward to how you decide to handle it.\n[1] - From: http://facebook.github.io/graphql/October2016/#sec-Coercing-Variable-Values. @bbakerman @andimarek I've updated the error messages to be more descriptive. Let me know what you think.. @bbakerman I've updated the PR to handle null types when displaying type names.. @andimarek / @bbakerman any thoughts on this? I'd like to get this merged before a release as it fixes several issues with my previously merged PR.. Thanks for this, I'm a huge fan of this change! Looking forward to getting it merged. Much appreciated @bbakerman.. I worry that this error is too \"internally\" focused. While this may feel like a special case, isn't this just the same as above? If we could say \"Expected type 'Map' but received a 'String'.\" is that good enough?. Yep, will do.. ",
    "vincentDAO": "I also got same issue when using BatchedExecutionStrategy and DataFetcher> together. . Great! We're waiting to upgrade our app to 4.2.. OK, thanks. \nI will follow  #675.. hi bbakerman,\nAs I know you fixed this issue in #677 already.\nI downloaded v4.2 but it doesn't include the fix. \nI saw you changed some lines from 85-90 in #677 https://github.com/bbakerman/graphql-java/blob/f6aacbc2a08abaf3b6fe7c1749e1f1422c3ddf34/src/main/java/graphql/execution/batched/BatchedExecutionStrategy.java\nBut  the change isn't in v4.2 https://github.com/graphql-java/graphql-java/blob/v4.2/src/main/java/graphql/execution/batched/BatchedExecutionStrategy.java\nCould you help to check?\n. Thanks for you quick reply.\n. I think this is a bug.\nIt should duplicate with https://github.com/graphql-java/graphql-java/issues/672. ",
    "jexp": "Great news, tanks a lot!. I didn't mean triple quoted strings (which was my original Issue back then). \nBut using triple quoted strings instead of comments for documentation (in the draft spec):\nhttps://facebook.github.io/graphql/draft/#sec-Descriptions. ",
    "rsmkrishna": "Hi \nThanks, for the quick reply. Can you help me with any proper documentation on \"How to implement Customscalar type\". As you said above one i refered to Graphql-datetime example from git.\nThanks in advance.. @andimarek , Thanks for your reply. \nyes I am refering above said link. I am trying to add one of the java scalar type file(GraphQLDate.java) in my local poc project. and i am getting below error \n'Caused by: graphql.GraphQLException: type Date not found in schema'\nThe only document i found greatful is \"graphql-java.pdf\". I am referring that. where i found one line \n\".scalar(CustomScalar)\" at page 11. But i don't find any class related to instance \"CustomScalar\".\nhttps://media.readthedocs.org/pdf/graphql-java/latest/graphql-java.pdf\nPlease guide to create and register a custom scalar type in graphql-java.. Here is the detail Error footpath.\nError starting Tomcat context. Exception: org.springframework.beans.factory.UnsatisfiedDependencyException. Message: Error creating bean with name 'graphQLServletRegistrationBean' defined in class path resource [com/oembedler/moon/graphql/boot/GraphQLWebAutoConfiguration.class]: Unsatisfied dependency expressed through method 'graphQLServletRegistrationBean' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'graphQLServlet' defined in class path resource [com/oembedler/moon/graphql/boot/GraphQLWebAutoConfiguration.class]: Unsatisfied dependency expressed through method 'graphQLServlet' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'graphQLSchemaProvider' defined in class path resource [com/oembedler/moon/graphql/boot/GraphQLWebAutoConfiguration.class]: Unsatisfied dependency expressed through method 'graphQLSchemaProvider' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'getGraphqlSchemaByType' defined in class path resource [com/scb/s2b/journey/configuration/JourneyQueryParser.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [graphql.schema.GraphQLSchema]: Factory method 'getGraphqlSchemaByType' threw exception; nested exception is graphql.GraphQLException: type Date not found in schema. Please guide with the correct approach for above scenario. . ",
    "bobdi98": "Why is this issue closed? I have the exact same problem as this. Is there a solution for this already?. @rsmkrishna @andimarek  any conclusion on this issue? This is in fact a graphql issue because, the error stack shows that the error comes out SchemaUtil.java (line 217)\nHere is the snippet of code - \n        if (resolvedType == null) {\n            throw new GraphQLException(\"type \" + type.getName() + \" not found in schema\");\n        }\n\nScalar type is added to SchemaParser (.scalars(localdateTime)).\nNot sure, why it says \"not found in schema\"\n. ",
    "zjchen82": "@bbakerman Understood that the depth is not related to the number of items in the list. \nThe example with depth 4 is actually 2 by using graphql-java 4.1. The depth is 4 if the type in the example change to \ntype MyQuery\n      list : [String]\n      deep : MyQuery\n}\n@andimarek Noted with thanks. \n. ",
    "henryqdineen": "I'm also open to alternate ideas. I also wonder what the use case is for includeScalars() in SchemaPrinter since the reference implementation doesn't have a similar option.. So maybe the ignoring should be done during ingesting the schema?. Looks good. Thanks so much.. Thanks guys. I just updated some of the tests so these cases are covered. Sorry I didn't get too creative with the tests. . Thanks again! Will this be in 8.0?. ",
    "LeeWong": "I got  an response on the gitter graph-java chat channel to confirm that graphql-java works well with the relay modern.. ",
    "rj254": "Thanks! . ",
    "jhaber": "It seems like the choice to include statistics must be made globally (or least per-GraphQL instance), do you think it would make sense to allow this choice at per-execution granularity? For example, we normally don't want to return statistics because it bloats the response, but for debugging we want people to be able to opt-in to seeing the statistics (we're also considering including statistics by default if the query is coming from GraphiQL, etc.).\nIf you agree this is useful, maybe it should be an option on ExecutionInput similar to DataLoaderRegistry?\nEDIT: Opened issue #1451 for this. Sounds good to me, thanks for the suggestion. ",
    "chrisregnier": "Definitely only creating the schema once. \nFor more clarity into what I'm doing, I've setup my system to look for any methods annotated with GQLResolver and match the methods to the schema field requests. This is really nice for pulling in Query and Mutation resolvers into the same location, along with supporting fields that might not be directly on the models, as you can see in the example below. The declaring class can then also be used for storing a bunch of cache related objects as well. \nschema: \ntype User {\n  lname: String\n  fname: String\n  fullname(reverse: Boolean): String\n}\ntype Query {\n  currentUser: User\n  users(filter: String): [User]\n}\n```java\npublic class User {\n  public String fname;\n  public String lname;\n}\n@QueryScope\npublic class UserResolver {\n  @Inject private UserDAO userDAO;\n  private LRUCache userCache;\n@GQLResolver(type=\"Query\", field=\"currentUser\")\n  public User currentUser(@GQLContext DataFetchingEnvironment env) {\n      return ((ReqContext)env.context).currentUser;\n  }\n@GQLResolver(type=\"Query\", field=\"users\")\n  public Set findUsers(@GQLParam(\"filter\") String filter) {\n      // also do stuff with cache here\n      return userDAO.findUsersWhere(filter);\n  }\n@GQLResolver(type=\"User\", field=\"fullname\")\n  public String getFullName(@GQLParam(\"reverse\") boolean reverse, @GQLSource User user) {\n    return (reverse)? String.join(\", \", user.lname, user.fname) : String.join(\" \", user.fname, user.lname);\n  }\n}\n```\nIn the example above I've got I've added a @QueryScope, which means the UserResolver class will be instantiated once for each query. This is easy to do cause this can be done outside of the query. But I was looking into creating some other scopes that would instantiate the declaring class for every time it's requested (ie each User would get a new scope).  \nSo I'll take a look a deeper look at Instrumentation cause I think that might be enough to do what I want. No need for a DataFetcherFactory for now, but thanks!\n. ",
    "buptliuhs": "I agree with you on your point by the example of map lookup. However, just imagine a database query using SQL, it will throw an error when some unknown fields in the query, and that's why I think having a strict mode of FieldDataFetcher by default is better. I'm using graphql-annotation btw (which means I did not spell the wrong words). I feel that it might be more suitable to implement the strict mode FieldDataFetcher in that according to your recommendation.\nThanks!. ",
    "szantogab": "Good question, furthermore, I still don't get it how the data loader can be used with JPA. Like when a user has many posts, and the client wants to retrieve all the users, and their posts, how can it be batched efficiently in two queries? (We obviously need to query the users, and then somehow get the IDs of each user's posts, and then load it with dataloader? Makes no sense.)\nAnyone to explain? :). @joesankey thanks, do you have any examples? I've yet to find any.. @bbakerman Thanks for your reply. I think I got the whole dataloader concept, but I still have a problem with it:\nLet's assume we have a set of users, and each user can have multiple posts. How can we efficiently query all the users and their posts while using a relational database?\nHere's how the query would look like:\n```\nquery {\n    users {\n        id\n        posts {\n            id\n            title\n        }\n    }\n}\n```\nPlease correct me where my solution is incorrect:\n\nQuery all the users from the db\nWith dataloader, we prime all the users with their IDs in the userDataLoader.\nIn the user.posts data fetcher, we use a userPostLoader and load a given user's id, to get back its posts.\n\nThis should result in a db query that fetches all the users, and another query that fetches all of the users posts at once.\nBut it doesn't, because unfortunately DataLoaderDispatcherInstrumentation calls dispatchAll() too early, when there is only one userId has been loaded to userPostLoader. So I have exactly n+1 queries going to the database this way.\nWhere am I going wrong here?. @bbakerman Any info on when this will be merged?. Any info on when will this be merged?. @mogaleaf Can you tell me please, how you have managed to create a DataLoaderRegistry per request with spring-boot-graphql plugin?\nThanks!. ",
    "joesankey": "@szantogab you need to use BatchedExecutionStrategy, which will parse the graph and resolve types in batches for you.. @bbakerman interesting, now that we have the Asynchronous strategy, what is the advantage of BatchedExecutionStrategy?. ",
    "essh": "Sure, I'm fine with that.. Thanks for this work. I\u2019ve had a chance to test it out now and it is much better than before but still not quite as efficient as the BatchedExecutionStrategy. The previous comment on this issue also raised this point with an example and the test cases added with the fix also seem to indicate it\u2019s not quite on the exact same level yet.\nAny thoughts on what could possibly be done on top of this work to further improve batching performance as you move deeper into the query?. ",
    "aruberto": "Hey @bbakerman \nI was trying out the changes in the pull request but still running into issues once I am past first level. \nI'll see if I can create a working example of issue later but a similiar schema to what I am working with would be:\n```\ntype Company {\n  id: Int!\n  name: String!\n}\ntype Person {\n  id: Int!\n  name: String!\n  company: Company!\n}\ntype Product {\n  id: Int!\n  name: String!\n  suppliedBy: Person!\n}\ntype QueryType {\n  products: [Product!]!\n}\n```\nI have 2 sets of BatchLoaders and DataLoaders hooked up for fetching people and companies by their ids. When I query:\nquery Products {\n  products {\n    id\n    name\n    suppliedBy {\n      id\n      name\n      company {\n        id\n        name\n      }\n    }\n  }\n}\nThe product.suppliedBy is correctly calling the person BatchLoader with all the person ids found across all products. However the suppliedBy.company is calling the company BatchLoader multiple times with a single key each time.\n. @bbakerman I've created an example project - https://github.com/aruberto/graphql-java-dataloader-issue\nWith graphql-java 5.0, running main method produces 100 lines each of PERSON BATCH LOADER STARTING WITH 1 KEYS! and COMPANY BATCH LOADER STARTING WITH 1 KEYS!\nWith graphql-java built from https://github.com/bbakerman/graphql-java/tree/760-dataloader-performance-with-lists, the person batch loader is only called once and the app prints PERSON BATCH LOADER STARTING WITH 100 KEYS! but afterwards it calls company batch loader 100 times and prints 100 COMPANY BATCH LOADER STARTING WITH 1 KEYS!. ",
    "vojtechhabarta": "I have the same problem.\nCurrently I am using BatchedExecutionStrategy and I wanted to switch to AsyncExecutionStrategy but it is much slower in my case and for larger data (where BatchedExecutionStrategy finishes its job in 30 seconds) AsyncExecutionStrategy fails after few minutes with OutOfMemoryError.\nMy data structure is like this: P -> [D] -> [A] -> H.\nArrays of A objects work well, they are loaded using one batched request for all D objects at once.\nBut when loading H objects DataLoader is dispatched separately for arrays of A objects \"belonging\" to one D object at a time.\nSo for example let's say I have 100 D objects and each has 10 A objects. With BatchedExecutionStrategy only one request for 1000 A objects is sent to backend but with AsyncExecutionStrategy 100 requests are sent.\n(using graphql-java 7.0). I have the same problem.\nCurrently I am using BatchedExecutionStrategy and I wanted to switch to AsyncExecutionStrategy but it is much slower in my case and for larger data (where BatchedExecutionStrategy finishes its job in 30 seconds) AsyncExecutionStrategy fails after few minutes with OutOfMemoryError.\nI described my use case here https://github.com/graphql-java/graphql-java/issues/760#issuecomment-372826395 since I overlooked this issue.. ",
    "ind1go": "Well... to be exact it would still meet spec! \ud83d\ude04  At the bottom of section 7.2.2:\n\nGraphQL servers may provide additional entries to error as they choose to produce more helpful or machine\u2010readable errors, however future versions of the spec may describe additional entries to errors.\n\nI agree that there is a need to follow spec strongly and toSpecification() has definitely been an excellent improvement. I guess there are two parts that you want to meet in the spec - one is that the permitted elements are in the right order (if necessary - the top-level elements must meet a precise ordering, for example) and also have the right names. toSpecification() does a great job of these, and if I were adding my own fields I wouldn't want to have to re-write this logic, rather defer to the framework.\nMy suggestion is that it might be possible to delegate to the provided toSpecification() and then build on top of it for this type of customisation, perhaps with some kind of handler for the ExecutionResult. It would mean that all the specced fields are exactly right, but then there would be freedom for those machine-readable fields. At the moment, ExecutionResultImpl.toSpecification() defers straight to GraphQLError.toSpecification() and then on to GraphqlErrorHelper.toSpecification(), with no opportunity to intervene.. Thanks for merging. So long as you're happy! \ud83d\udc4d . Looking through the history of SchemaPrinter, it looks like this might be fixed in v5.0 and later through #709 - I'm in the Dark Ages on 4.2! \ud83d\ude06 Will get back once I've tried that and likely close this issue.. Yep, as suspected! Sorry for the noise.. If you needed something to make you feel this was worthwhile, we're today puzzling over a problem that this should fix - a huge (valid) response that fills the heap, but where much of it could be streamed out earlier.. Probably just wants to be start or startPhase or something if now generic.. ",
    "lorines": "@loganvolkers how did you implement the serializer in Java? I am trying to implement JSON scalar, but my query is returning an empty object instead of a JSON object.. ",
    "ryber": "@loganvolkers or @lorines also wondering how the Coercing works in this case for the serializer\nIf you return the JSON from Jackson as a string then, indeed you get JSON but it's jammed inside of a string\n{\"data\":{\"body\":\"[]\"}}\nHowever if you try and return a Map version of the json then you get a parsing error. I'd really prefer to return the JSON as JSON and not as a string\n. For anyone who finds this. Returning a Jackson JsonNode works:\n```java\n         private ObjectMapper om = new ObjectMapper();\n    @Override\n    public Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n        try {\n            return om.valueToTree(dataFetcherResult);\n        } catch (Exception e) {\n            throw new CoercingSerializeException(e);\n        }\n    }\n\n```\n. > Sorry but this is a design goal of the graphql specification. graphql has a design goal which is that in order to retrieve a data element, you need to ask for that data element.\nThere is no reason the specification can't allow for that in this case by allowing me to say \"this fragment, recursively, up to a depth of x\" or allow the implementation to define x. It's a huge flaw IMO. Not supporting these kinds of data structures well doesn't mean they don't exist or that GraphQL can't be a great platform to support them. . ",
    "ejdzipi": "As i am using graphql-java-servlet and graphql-java-tools, i need to provide my own ExecutionStrategyProvider and so on, which produce a lot of classes which are identical to default graphql-java classes just to change one exception handler.. ",
    "SignalDancer": "@bbakerman  if that's true, then, this example in the documentation is outdated correct? There's no way to get a ReviewInput or Episode object back (without using the inefficient workaround you describe), only a further LinkedHashMap? Or am I misunderstanding? (copy pasta from read the docs execution section, which has this, but of course, as mentioned above, no example on how to get it back as an Episode or Review object)\nprivate DataFetcher mutationDataFetcher() {\n    return new DataFetcher() {\n        @Override\n        public Review get(DataFetchingEnvironment environment) {\n            Episode episode = environment.getArgument(\"episode\");\n            ReviewInput review = environment.getArgument(\"review\");\n        // make a call to your store to mutate your database\n        Review updatedReview = reviewStore().update(episode, review);\n\n        // this returns a new view of the data\n        return updatedReview;\n    }\n};\n\n}\n. ",
    "bernardzzz": "Is it possible you forgot to define scalar CustomeScalar in your schemaDefinition.graphql\uff1f. ",
    "tyroprogrammer": "added scalar CustomeScalar in the schemaDefinition.graphql and it started working. Thanks!. ",
    "randing89": "OK closing this issue because it has been supported by looking at the code. However, the docs are not mentioning that. . Yep. the reference implementation is following the spec where skip only short-circuit when it is defined and equals to true. Our original implementation will return as long as skip is defined which will fail the case where skip=false include=false. ",
    "alexgenco": "Just wanted to bump this thread. Any reason not to revive this? We definitely have use cases for performing multiple operations in a single request.. > can you expand your use cases.\nWe don't have an immediate use case for just executing multiple operations, except if it would make it easier for us to hack together an ad-hoc way to chain mutations with variables (something like the @export proposal). Also, we don't need to stream downstream responses, we would be ok with just waiting for all operations to finish to respond.\nBascially, we have designed our API in favor of small, composable mutations and queries, but clients are hesitant to eat the cost of 2-3 HTTP requests to get what they want.\nHere's an example use case with actual mutations from our API:\n```graphql\nmutation Tokenize(input: TokenizeCreditCardInput!) {\n  tokenizeCreditCard(input: $input) {\n    paymentMethod {\n      id @export(as: \"singleUseId\")\n    }\n  }\n}\nmutation Vault {\n  vaultPaymentMethod(input: { paymentMethodId: $singleUseId }) {\n    paymentMethod {\n      id @export(as: \"vaultedId\")\n    }\n  }\n}\nmutation Charge {\n  chargePaymentMethod(input: { paymentMethodId: $vaultedId }) {\n    transaction {\n      status\n    }\n  }\n}\n```\nBasically, you tokenize a credit card (exchange raw details for a single-use token), then use that single-use token to permanently store the payment method in the merchant's vault, then use the vaulted payment method ID to charge the payment method.\nWe support a large number of payment method types (credit card, apple pay, google pay, etc.), and would prefer to not have to create a mutation for each of tokenize, vault, and charge for each payment method in order to limit the surface area of our API.. Will there be a point release for this soon? We upgraded to 10.0 recently and would prefer to roll forward than backward.. I should also mention my team has their eyes on https://github.com/facebook/graphql/issues/375, and another goal of this change is to move us toward supporting that feature if it ever makes it to spec.. I also just found this https://github.com/graphql-java/graphql-java/pull/808. Seems like you might already have some thoughts on this @bbakerman \ud83d\ude09 . I'm going to close this for now, as there seem to be too many unknowns around multiple operations right now.\nPer my comment here https://github.com/facebook/graphql/issues/377#issuecomment-452916601, I think we should decouple variable export from multiple operation support if possible. I'm working on another PR to spike out variable export within a single operation, and hopefully I'll get that up in the next few days.. Yeah I punted on figuring out what to do here, opting for the user to configure how the results should be accumulated (maybe with some common ones available in the lib, such as nesting data under the operation name).. ",
    "gkesler": "@bbakerman @andimarek \nLike RFCs and this PR.\nWhat do you think about implementing [multiple] query execution using formal [dependency graph]\n(https://en.wikipedia.org/wiki/Dependency_graph)?\nIt will provide you with a formal and universal way of executing a query by walking it in the natural order and calculating transitive closure?\nIt will also decouple you from all kinds of dependencies: relationship dependencies between objects, cross-dependencies between queries. Further more, I am also very much interested in submitting an RFC to make query criteria a first class citizen in the language and therefore it'll also require another kind of dependencies, more specifically reverse relationship dependencies from the child to its parent. Additionally it will allow cascaded mutations operations where a write request could be split automatically on the sequence of requests to write parents and children.\nWDYT?. thanks @bbakerman \nI plan to submit more in this area, pretty much what was listed in the README top paragraph.\nThere are many places with suboptimal calculations.\nPlus I'd like to introduce \n- Visitor pattern to GraphQLType and AST Node trees. \n- Tree traversal based on push-down automata - significantly simplifies execution strategies, especially those that use breadth-first ordering. Plus both depth-first and breadth-first traversals will share most of the traversal code.\n- type checking based on double dispatch mechanism that reduces of completely eliminates the need to use reflection (instanceof) - also improves performance + guards against new definitions in AST and GraphQLType hierarchies.\nDo you have any objections?\nAlso, do you want me to put commits into separate branches into this repo? . yes, I would like to refactor all current execution strategies using this mechanism.\nBatchExecutionlStrategy is the one that I'd like to refactor most of all\nBecause of its pure state, I had to implement for my project my own BatchExecutionStrategy, leveraging only resolveField method from its superclass.. plus there are a few recursive algorithms in schema and validator packages of unnecessary complexity that need to be refactored. @andimarek \nI have modified the files as you've requested.\nPlease review & merge. @andimarek \nDo you want me to address last issues with Assert.assertNotNull vs. Objects.requireNotNull ?. @amarek any ETA when this PR will be merged?. K, thanks, no rush. @andimarek \nIn this PR I had provided only 1 use of the traverser.\nI intend to simplify/optimize overly complicated in my mind execution strategies  with this traverser. Special concern I have with regards to BatchedExecutionStrategy that uses breadth-first traverse. With this mechanism I expect all execution strategies to perform better, look very similar and hence easier to maintain.\nPlus the same mechanism could be/should be applied to the type system. There are tons on similar recursive + direct dispatch in schema types that also could be optimized.\nI will send you more PRs after this one is merged.. \ud83d\udc4d . @andimarek thanks for the input.\nI'll try to simplify it.\nAny particular suggestions?\nWould more comments help?. understood, will do my best. @andimarek could you please take a look and merge this PR if acceptable?. @andimarek \nThank you for the thorough code review.\n\ngraphql.util.Traverser is a general purpose utility class responsible for all kinds of traversals in an arbitrary defined tree. In order to improve code reuse and performance it is using push-down automata instead of call stack recursion. With push-down style of traversal the difference between depth-first traversal and breadth-first traversal is only in the type of queue used to keep traversal state.\ndepth-first traversal keeps the traversal state in a LIFO structure known as stack, where the insertion [of children nodes] happen at the head and this way they become immediately available for the next traversal iteration\nbreadth-first traversal keeps the traversal state in a FIFO structure known as queue, where the insertion [of children nodes] happen at the tail and this way they become available after all currently queued nodes are traversed\n\nVisitor pattern allows to improve code reuse even further by separating the traversal code from the code that needs to be executed while the algorithm riches a node to process (said visits a node). The generic graphql.util.TraverserVisitor defines callback methods corresponding certain traversal events/states:\n   * enter method is called when the Traverser algorithm visits a node for the first time, before enqueuing the children. This allows to implement pre-order type of traversal\n   * leave method is called after the Traverser has processed all children of a particular node. This allows to implement post-order type of traversal. \n\nNote that even in case of breadth-first traversal leave method is called after processing all immediate children of the particular node. In case of depth-first traversal leave method is called after processing the entire sub-graph of the particular node.\n\n\nonBackRef is called when the Traverser algorithm reaches a node that had been already visited. In such case the traversal does not go again to the children, so there will be no infinite loop caused by the cycle in the graph.\nonMapKey is a special kind of a callback to notify the Visitor that the current element is actually a Map.Entry key and that the very next enter or onBackRef call will be the value of that key. This is very useful when the children of a node are not stored in an indexed array or collection, but in an associative array or map instead. \n\n\nWhile provisioned, the basic implementations of graphql.util.TraverserStack and graphql.util.TraverserQueue don't deal with maps, so in order to support maps one needs to subclass either of those classes to enqueue Map.Entry objects.\n\nAnyways, I have created a little refreshing presentation on graph traversal. Hope you can find it useful.\n\nYou are absolutely right, one can store temporary variables while processing a node in the TraverserContext.vars space and completely get rid of contextStack. The only reason I've introduced contextStack is performance - obtaining a value from  the local stack is slightly faster than obtaining a value from the variables map in the TraverserContext. Let's give it a shot, I am updating this PR to get rid of this contextStack.\n\n\nMore over, in case we need to perform parallel processing, local stack won't work. That's why generic variables storage is a part of TraverserContext.\n\n\n\nThey are actually different. In the base class the TraverserVisitor and NodeVisitor parameter is the same and it is passed around through Node's accept method. In the QueryTraversal case the NodeVistor's parameter is the TraverserContext and the enter and leave implementations make sure that the current TraverserContext is passed into NodeVisitor's methods.\n\n\nThere is a performance difference between single dispatch\n\n\njava\nif (context.thisNode() instanceof Field) {\n   // do something with Field\n} else if (context.thisNode() instanceof Selection) {\n   // do something with Selection\n}\nand double dispatch techniques\n```java\nclass Field extends Node {\n   public Object accept (Object data, Visitor visitor) {\n      // do something with the Field\n      return visitor.visitField(this, data);\n   }\n}\nclass InlineFragment extends Node {\n   public Object accept (Object data, Visitor visitor) {\n      // do something with InlineFragment\n      return visitor.visitInlineFragment(this, data);\n   }\n}\nclass SelectionSet extends Node {...}\ncontext.thisNode().accept(data, visitor);\n```\nThe fundamental difference between these two techniques is that the binding to a code that needs to be executed for a particular Node type in case of single dispatch happens after slow, reflection-based instanceof type check and type cast, whereas in the second case that binding happens at the compile time, in accept method implementation.\n\nGood idea! I got rid of QueryTraversalNotifier!. @andimarek \nthanks again for the review.\n\nI understand completely your position and obviously we'll be contributing more stuff to the project.\nCurrently we've encountered a number of performance issues, one of them was fixed in my very first PR, some other would ideally require this PR to be merged. We'll make the fixes based on the current state of the affair.\nI would like to ask you to elaborate a little more on what makes you uncomfortable with the push-down traversal? Maybe I can try to make it even simpler? \nWe've been using this project for our Java based graphql server and we plan on to continue using it at the enterprise scale, that's why we are very cautious about its performance characteristics. Our integration is primarily based on the BatchedExecutionStrategy which didn't do all the job for us and therefore we needed to subclass it. Subclassing also did not work well because most of the methods in it are private so we had to implement our own BatchedExecutionStrategy reusing only (via reflection) resolveField method. Anyways, by submitting this PR we just wanted to bring the state of this project closer to what we need and this way eliminate the need of the fork.\nAnyways, we would like to have good cooperative relations with you, guys. We'd like to offer to you our help in any areas of this project. Please feel free to drop me a line at greg_kesler@intuit.com.. The bottom line is we would like to have double dispatch with Visitor pattern enabled on the class hierarchies that are used in the tree structures, i.e. on AST nodes and GraphQLType sub-classes.\nIn our project we perform transformations of GraphQL AST into other kind of AST and we had to fork and introduce Visitor pattern on the AST types.\nMigration to the push-down automata while desired - I have an extensive background in building compilers where this traversal techniques is used heavily - it is not urgent. . @andimarek @bbakerman \nThank you very much for your consideration. Hope we could address remaining comments and move forward.. thank you @andimarek. I am good with all changes.. Totally agree. Let's take it the way it is now and polish it later.. @andimarek just merged with latest and greatest from master.\nPlease, take a look.. Unfortunately, I am a dinosaur using NetBeans.\nWill try to get better at not touching files next time :). sure, sorry about that. that's my IDE template. yes. yes. sure, will do. yes. yes. yes, there is. \nVisitor can control the Traverser if it returns some special values:\n- TraverserMarkers.QUIT causes the Traverser to stop the main loop and return. Useful in the scenarios where you need to fihnd something in the tree/graph and stop searching.\n- TraverserMarkers.ABORT causes the Traverser not to visit subtree if visiting the root returns this value. Useful in the scenarios where you want to traverse subtrees conditionally, for instance in the QueryTraversal. For possible subclassing.\nFor instance, it is very easy to create PreOrder, PostOrder or BreadthFirst iterators using this mechanism. One only need to call traverseOne as iterator's advance method and use external loop while condition as iterator's method to check if there are more elements to traverse.\nI did not want to put this in this class for the reasons not to abuse its purpose. When iterators are required, one cold either put them right in  this class or subclass it just for the purpose of adding that behavior.. In my opinion, this runtime check adds complexity to this algorithm (additional O(N), where N is the number of Nodes in the tree).\nAny particular reason why sub-typing with compile time binding is not used?. This is partially my fault:)\ngetChildren() returns List.\nInstead of new ArrayDeque<>(getChildren(...)).descendingIterator() I think it would be more efficient to do getChildren().listIterator(size()) and wrap it into an Iterator that goes in the reverse direction. I'll submit PR for this . why not to subclass here SimpleTraverserContext to avoid code duplication?. This seems to me to be too heavy for a simple double dispatch routine.\nIdeally accept method is declared this way:\njava\n<U> U accept (U data, NodeVisitor<U> visitor);\nwhere Visitor's methods should look like\njava\ninterface NodeVisitor<U> {\n   U visit (Field node, U data);\n}\nIn order to be able to reuse NodeVisitor in the Traverser's case we could do one of the following:\n1. declare methods TraverserContext.getControl() and TraverserContext.setControl() to communicate TraversalControl values between Visitor and Traverser.\n2. define runtime exceptions AbortTraversalException and StopTraversalException and throw them from Visitor instead of returning TraversalControl values. . I had a similar comment on the NodeTraverser.\nWhen a Visitor is used by a Traverser, it is most likely the argument to the Visitor will be TraverserContext. Therefore in my opinion it would be cleaner and, actually, more efficient to return from the Visitor a TraverserContext. Visitor can set on the Traverser a result as well a TraverserControl value. If we do this, Visitor's definition would look like:\njava\ninterface NodeVisitor<T> {\n   T visitField (Field node, T data);\n   ...\n}\nAnd this will allow to simplify simple double dispatch case, where I there is no need to traverse a tree, ,but perform an action based on the node runtime type.. Let's make this an explicit property of the TraverserContext in order to tell the Visitor the current traversal direction: down vs up ... or pre-order vs. post-order. Perhaps code organization like\njava\nswitch (context.getVar(LeaveOrEnter.class)) {\n   case LEAVE:\n      return TraversalControl.CONTINUE;\n   case ENTER:\n      // do the stuff\n}\nwill be more readable.\nWDYT?. separating callback Consumers into preOrder and postOrder Consumer in my mind made the code a little more readable, in a sense that there were no redundant check like this if (!preOrder).\nAdditionally, there is redundant code above the line 181 that is executed twice. Is that intentional?. I vote for 2 inline classes and get rid of the extra check for the queue type. In the original version this was a side effect of currentContext.isVisited() call.\nThe reason was to avoid redundant lookup with the same key. With this version this redundancy happens when isVisited calls visited.contans() and here when addVisited calls visited.add().\n. any particular reason why visited set is declared as LinkedHashSet?\nDeclaration like this could create false-positive results for nodes that implement equals and hashCode methods.\nCycle detection should prevent visiting exactly same node again, not the node that equals to it, cause that could be an absolutely legitimate subtree.. why not to put this assert into the default case? it would help to avoid lookup in the CONTINUE_OR_QUIT list.. again, I think having switch here would help to avoid unnecessary comparisons.. in case the loop was broken due to visitor.leave method requested to QUIT, the currentContext will contain the result of the previous visitor.backRef or visitor.enter calls. Is that intentional? and why?. additionally, in case visitor.backRef decides to continue the traversal, cycle variable will be set to true and when the traversal loop is ended either normally or prematurely, but not because of another cyclic reference, the last value of cycle=true will be reported as the result of the traversal. Is that intentional? and why?. I tink I understand the intent, please, correct me if I am wrong. You want to report with the result if a traversal has encountered a cycle or not. \nI am thinking about the use case. What the client is expected to do with it?\nIf, let's say, the client needs to simply report that a cycle was encountered, then, perhaps, it needs to know what node has cyclic reference(s). \nAdditionally, if there are many cycles detected, then perhaps, all of them need to be reported.\nwdyt?. Vertex.id is its correlation ID. When Vertices leave the graph for external resolution in the DependencyIterator.next(), it is expected they will be correlated with DependencyIterator.close(..). At that time the vertices to correlate could be the same ones produced in the .next call or completely different, for instance, their clones or just lookup keys. In the second key correlation happens using Vertex.id value;\n\nIt feels that client is expected to know DAG internal implementation\n\nThe client needs to know the DAG concept and the API in order to use it effectively, doesn't it?\n\nDo you plan to add node/edge removal?\n\nnot at the moment.\nThis is just a POC.\nIt wasn't my intent to create a generic purpose implementation of DependencyGraph.. go ahead. ",
    "guidorota": "The changes to rename IDL in SDL in the documentation were made in this commit.\nShould we close this issue or do you think there's more that we can rename without introducing a breaking change?. We can start reporting them at INFO level for now, and change it later if we find that it's not suitable.. This is now fixed. @LarsKrogJensen thanks for reporting, and let us know if you have other problems.\nGuido. Yes, good point. I'll change it to 6.. @bbakerman do you think a null check is enough, or should we check if the string is empty too?. ",
    "RyGuyOlson": "This is exciting! Do you know when this might be pulled in?\nSeparately, is there any coordination from any query libraries to leverage this new addition to the specification? From what I read Sangria is the only library atm that supports this functionality for batching: http://sangria-graphql.org/learn/#batch-executor. ",
    "mrdon2": "PR at  #824. The way the PR works, the spec should be ok as it uses the same spec-checking code path as normal errors. PR has been merged. Ok, I think all issues should be addressed.. Ok, I think I have all comments addressed.  Also, good lord this PR UI is confusing.. All changes should be implemented.  . Fixed in https://github.com/graphql-java/graphql-java/pull/862. Tests are fixed. No, this happens with basic strings.  If the default value is a string, it is included in the introspection query result as defaultValue=\"\\\"foo\\\"\".  However, the IntrospectionResultToSchema class doesn't evaluate the \\\"foo\\\" value as a JSON value (and therefore set it to foo), but keeps the quotes.  Then, when the schema is turned into an introspection query response, the backslashes are encoded, so what you get is defaultValue=\"\\\\\\\\\"foo\\\\\\\\\"\". I know java tests aren't what this project uses, but I wanted to get something out and show how it works before trying to figure out how the groovy test stuff works.. Wasn't sure if this should be better integrated into the if/else section below or there was value in keeping it all separate from a readability standpoint. Could also be an interface; just thought this way it'd be more user-friendly.. The path should be relative to the data fetcher location, so it is up to the fetcher how it creates that path.  . fixed. I did move it over to fetchField, which seems to work well.. fixed. fixed. fixed. fixed. fixed. I didn't see one and besides, it hardcodes some data that is useful for my tests. done. made unmodifiable. not that I could find. made unmodifiable. ",
    "labilezhu": "Ok, I have fixed it.. To help anyone to make the zh_cn translate easy, and keep updated.  I commit my OmegaT 3.6.0 (An open source CAT tool for translation) project to graphql-java-i18n-zh_cn  :\nIt helps anyone to translate PO files. Any one want to translating graphql-java documents into Chinese can use this OmegaT project.\nThis will save your time for catch up the continuous updated English doucment. Because OmegaT can remember the translated result by sentence, and reuse it when the source English document updated.. Ok, I have fixed it.. ",
    "Type1J": "This might cause an efficiency problem, but not supporting aliasing means that this implementation does not conform to even the earliest GraphQL spec: http://facebook.github.io/graphql/July2015/#sec-Field-Alias. @bbakerman That's the output, not the input. It's to let upstream servers or the client know per field caching information usually specified statically in the schema.. ",
    "samogot": "Even if you rewrite ExecutionStrategy such way, this will work only for first layer. After recursion call you won't be able to know if you are in recursive call and don't need to dispatch, or it is last recursion branch of a layer an you need run dispatch now\nI had an idea to rewrite DataLoaderDispatcherInstrumentation to do something like reference counting of future recursive calls, and run dispatch only once in end CompleteFields. But I gave this idea up, because Instrumentation do not have all data that I need (ExecutionContext) and because this is very error-prone strategy and needs a lot of testing. ",
    "DavidFlorin": "Ok, thank you. I will put this issue on graphql-java-servlet. ",
    "nlevy": "hi @andimarek , thanks for the quick response.\nThe use case is as follows:\nWe are using some generic base persistence entity for several graphql types, it looks something like:\n```\npublic @Data class BaseEntity implements Cloneable, Serializable {\n@Column(name = \"OBJECT_ID\", nullable = false, updatable = false)\nprivate Long id;\n\n@Column(name = (\"DATA\"), nullable = false)\nprivate JsonObject data;\n\n// additional fields and methods omitted\n}\n```\nThe data field contains a json object, which matches the graphql schema, for the sake of example, lets say it has two fields, name and value.\nNow, if I want to make a query with the a selection set like this {data {name value}} we have a problem - the default property data fetcher is able to get data using the getter, but when it attempts to get name or value from within - the source is the jsonObject, so you need to use data.get(prpertyName) to get it, and not a regular getter method.\nI know there are other ways around this problem, like using the propertyDataFetcher on the entity level and some custom jsonObjectFetcher for the inner fields, we try to use the same fetcher anywhere (for some other reasons).\nThis is one use case we've encountered, In my mind since this is the default data fetcher, it might be useful on some cases to be able to extend it with only small tweaks instead of writing a completely new one.\nBTW - does adding a protected getPropertyName() sound better to you? does the trick for us as well . ",
    "JangChulwoon": "First, Sorry I am not good Eng  :(  \nI used GraphQLException  when I handle Exception.   \nFor example ...  \ntry {\n            throw new Exception(\"Exception !! \");\n        }catch (Exception e){\n            throw new GraphQLException(e.getMessage());\n        }\n\nrequest  \n\n```\n{\n   a  { \n     ...  there is not problem query ..\n   }\n   b  { \n     ...  there is problem query ..\n   }\n}\n```\n\nresult \n\n\"data\": {\n    \"a\":  data bla bla  ~~ ,\n    \"b\": null\n  },\n \"errors\": [\n    {\n      \"message\": \"Exception while fetching data (/b) : Exception ??\",\n      \"path\": [\n        \"b\"\n      ],\n      \"exception\": {\n        \"cause\": null,\n        \"stackTrace\": [\n          {  // ..... \nMost can be processed by GraphQLException.\nBut , If validate and parse step operate exception, I couldn't handle Exception. \n\nSuch as case\n\n```\n{\n  \"data\": null,\n  \"errors\": [\n    {\n      \"message\": \"Validation error of type FieldUndefined: Field 'WrongQuery' in type 'QueryName' is undefined\",\n      \"locations\": [\n        {\n          \"line\": 8,\n          \"column\": 3\n        }\n    ....\n```\nBecause GraphQL-java works in the following order.\nParse and validate -> A query and B query     -> combine result   -> return \n\nIt may be a little different ... \n\nIf parse and validate step  operate exception, It returns exception immediately without processing querys.\nSo, We can't handle Exception in parse or validate step. \nWe can only handle exceptions in queries. \n. Oh.  Thank you for teaching me ! \nI will change the code as you advised me  ! \n. ",
    "hfye": "I encountered the same problem and have spent whole day on it.\nplease share if you have any solution!. I finally found out that the issue was caused by graphql-java-servlet. Its default error handler filtered out the errors.. ",
    "fnovoa10": "Hey @hfye, I solved my problem using the following post, I hope it works for you.\nhttps://picodotdev.github.io/blog-bitix/2017/11/devolver-mensajes-de-error-descriptivos-en-graphql/\nRegads.. ",
    "Mark-K": "Part 2\nI tried separating the \"admin\" user fields into a separate IDL\nNormal User Schema\nschema {\n    query : Query\n}\ntype Query {\n    search ( input : SearchInput ! ) : [ SearchResult ! ]\n}\ninput SearchInput {\n    startId : Int !\n    endId : Int !\n}\ntype SearchResult {\n    id : Int !\n    title : String !\n    content : String !\n}\nAdmin User extended schema\nextend input SearchInput {\n    userNames : [ String ! ]\n}\nextend type SearchResult {\n    userName : String !\n}\nJava code fragment\nTypeDefinitionRegistry registry = new TypeDefinitionRegistry();\n        SchemaParser parser = new SchemaParser();\n        String resource = \"user.graphql\";\n        URL schemaUrl = this.getClass().getClassLoader().getResource(resource);\n        try (Reader in = new InputStreamReader(schemaUrl.openStream(), StandardCharsets.UTF_8)) {\n            registry.merge(parser.parse(in));\n        } catch (IOException | RuntimeException ex) {\n            LOG.catching(ex);\n            return null;\n        }\n        boolean isAdmin = (null != account) && account.hasRole(\"admin\");\n        if (isAdmin) {\n            String adminResource = \"admin.graphql\";\n            schemaUrl = this.getClass().getClassLoader().getResource(adminResource);\n            try (Reader in = new InputStreamReader(schemaUrl.openStream(), StandardCharsets.UTF_8)) {\n                registry.merge(parser.parse(in));\n            } catch (IOException | RuntimeException ex) {\n                LOG.catching(ex); // stops here\n                return null;\n            }\n        }\nWhen the admin.graphql schema is parsed the following error occurs:\ngraphql.schema.idl.errors.SchemaProblem: errors=[InvalidSyntaxError{ message=Invalid Syntax ,locations=[SourceLocation{line=1, column=7}]}]\nRemoving extend from the extend input in the admin.graphql file causes the following error:\ngraphql.schema.idl.errors.SchemaProblem: errors=['SearchInput' type [@1:1] tried to redefine existing 'SearchInput' type [@7:1]]\nStill looking for a solution.... Good Morning BBakerman,\nThank you for your response!\nIn answer to your question, the application code is aware of the user's roles and for a non-admin user arbitrarily replaces the userNames list (ignores the input value) with a list containing only the logged in user's userName.\nHaving the userNames field in the input schema for a non-admin user implies that the non-Admin user is permitted to search for any other user's data which is not the case.  Being able to remove the field from the non-admin's view of the schema removes that \"ambiguity\" and seeming security hole.\nFor me it's actually more of a how to deal with QA Team/Documentation Team/Customer issue than a programming issue.  The question is \"why is it there if I can't use it?\"  I can document it to death; but, the question will remain and will keep coming back like an unwelcome zombie.\nIf you should decide to include the functionality of making the visibility of input fields controllable by the application, my personal preference on how hidden input fields are handled would be for an InputMapDefinesTooManyFieldsException to be thrown.  This exception is already thrown when a field that does not exist in the schema (an undefined field) is found in the input variables.  The idea is that if the field is hidden, it does not exist as far as the client is concerned.  When validating the variables map, passing the request for an input type's fields through the schema's getFieldVisibilty().getFieldDefinition() mechanism may work assuming that the schema instance can be obtained at that point and a method accepting a GraphQLInputFieldsContainer can also be implemented.  Looking at the code, it wasn't apparent that the schema was obtainable where the decision to throw InputMapDefinesTooManyFieldsException is made.\nHowever, that said and being new to GraphQL, I'm not sure what the accepted approach is when dealing with what a user is permitted to do and how that should be presented in the schema.  The application should obviously not allow a user to make unauthorized requests or include unauthorized fields in input data.\nBut shouldn't that information be reflected in the schema that the user can see?\nSo, if you were to say:\n\nthe accepted practice is to add a validation rule and reject requests containing unwanted fields\nthe application should silently ignore such things.\n\neither would be perfectly acceptable and doable.\nMy background in web development has been to only show users what they are allowed to operate on.  Even though the web app may have many functions available, the current user may only see in the interface the subset of functions they have been granted permission to use.  That may or may not be how GraphQL interprets the idea of user permissions and visible schema.\nI am in the process of separating the business logic from the web interface of several web apps by collecting the BL out of the web apps and facing it with GraphQL.  The initial version due to multiple user authentication sources was too complex, too many URL endpoints (one for each unique user type), schema files and redundancy.  The user authentication requirement was changed to a single source so the complex \"mess\" is being merged and reduced which is leading to situations where merging the schema makes api visible to users that don't have permission to actually use it.. Thank you for looking into this very difficult and potentially contentious issue.\nI will look into how to do the pull request and making groovy spock tests for reporting future issues.  Thank you for the suggestion.\nMy thinking is that when the input data is JSON, the Map received as Input should have already been parsed by the JSON library's (such as Jackson) string to Map parser and converted into the Java type as specified in the input data and JSON value conversion rules.  So in the case of correct value syntax, there should be no need for value coercion.\nFor example:\nJSON: \n{ \"s\": \"s\", \"b\": true, \"n\": 123 }\nshould be parsed into\nJava Map\n{ \"s\": String(\"s\"), \"b\": Boolean.TRUE, \"n\": Integer(123) }\nAs a result, the graphql-java library could require that the values of built-in scalars in the Input Map be the type specified by the schema, since the built-in scalars are basically the same as those defined by the JSON format.  Though there may need to be some leniency with numeric type conversions such as up casting (Int -> Long) when necessary.\nThis would mean that the code that prepares the variable map must do \"the right thing\".\nBut that might not be current practice or not always reasonable, so making \"strict\" a requirement could break existing code and/or make parsing other data formats much more difficult. (i.e. web form data, Properties...)\nMy suggestion, would be (if the code will be modified) if it is feasible to make strict and lenient input validation selectable (with the default being lenient perhaps so as not to break anyone's hard work).  When explicitly set to \"strict\", values in the input map must be the type specified by the schema without coercion.  The \"lenient\" selection would provide the current (best effort to make sense out of the input) behavior.\nThis could be implemented in any of several different ways, for example:\n- an added boolean flag that changes the behavior of the existing validator\n- making input validation modular in the sense that a developer could select between a \"StrictInputValidator\" module, the \"DefaultInputValidator\" module or even implement a \"UserDefinedInputValidator\"\n- define pluggable \"pre-validation\" that executes just before field validation occurs\n. Michael,\nThanks for weighing in on this issue.  You are reporting on a slightly different area than what I originally reported.  My issue is with how the values of input variables are parsed (actually coerced) and validated.  You are having a problem with how the query string itself is validated.  This might deserve its own independent issue. But, having said that I have also seen (been surprised by) this behavior too.\nOops! Sent type X in the query when type Y was required. Hahaha...\nInstead of an exception, an error with a more meaningful message would allow a client developer to understand/find/fix the mistake faster.\nInput variable definition parsing needs to take the following issues into account (at a minimum).\n- variable name mismatch: query ( $star: String! ) { hello ( str: $str ) }\n- variable Type mismatch:\n  - query ( $str: String ) { hello( str: $str ) }\n  - query ( $str: OtherThing ) { hello(str: $str ) }\n  - query ( $str: OhterThing! ) { hello(str: $str ) }\nIn most cases the library responds correctly; but, in some cases an exception gets thrown.\nThe AssertionException is troublesome because it propagates all the way back to the application.  If not handled by the application, no response is produced and the application unexpectedly terminates.\nWhen the application is responding to client input, unexpected termination is not a very polite way to say you messed up.\nExample 1 [OK]:\nThe parameter name is misspelled in the query input variable definition.  An error message describing the problem is returned to the client.  Basically variable str wasn't found but did find an unused variable star in the input variables.\nRequest: query Get($star: String!) { hello(str: $str) }\n Output: {\"errors\":[{\"message\":\"Validation error of type UndefinedVariable: Undefined variable str\",\"locations\":[{\"line\":1,\"column\":40}]},{\"message\":\"Validation error of type UnusedVariable: Unused variable star\",\"locations\":[{\"line\":1,\"column\":11}]}]}\nExample2 [OK]:\nThe query is okay but the variable name in the variables map is misspelled.  An error message is returned which when translated says that variable str was not found in the variables map.\nRequest: query Get($str: String!) { hello(str: $str) }\nVariables: new HashMap() {{ put(\"star\", 1); }}\n Output: {\"errors\":[{\"message\":\"Variable 'str' has coerced Null value for NonNull type 'String!'\"}]}\nExample3 [OK]:\nThe input variable definition makes the str variable optional where as the schema says that its required.  In this case as well, an error is returned to the client.\nRequest: query Get($str: String) { hello(str: $str) }\n Output: {\"errors\":[{\"message\":\"Validation error of type VariableTypeMismatch: Variable type doesn't match\",\"locations\":[{\"line\":1,\"column\":38}]}]}\nIn most cases the graphql library's response is correct.\nFor Schema:\nschema { query: Query }\ntype Query { hello ( str: String!) : String }\ninput MyInput { str: String ! }\nHowever, the library response is different depending on the input query string when the input variable type definition differs from the type specified by the schema.  Testing results below show that Boolean returns an error message.  But, 'Int!' throws an exception and 'Int' returns an error message with graphql claiming that 'Int' is an unknown type.  Looking at the results below, when the input variable is a required String, an assertion exception will occur when other built-in scalar types Int, Long, ID (types other than Boolean) are specified.\nI believe that I have also experienced the assertion exception when the required input type is user defined and a different user defined input type was specified in the input variable definition but have no evidence and didn't reproduce that case this time so maybe I am wrong and it was actually an error message instead.\nTest Results:\nQuery: query Get( $str : String ) { hello (str: $str) }\nResponse: {\"errors\":[{\"message\":\"Validation error of type VariableTypeMismatch: Variable type doesn't match\",\"locations\":[{\"line\":1,\"column\":38}]}]}\nQuery: query Get( $str : Boolean! ) { hello (str: $str) }\nResponse: {\"errors\":[{\"message\":\"Validation error of type VariableTypeMismatch: Variable type doesn't match\",\"locations\":[{\"line\":1,\"column\":40}]}]}\nQuery: query Get($str: Boolean) { hello(str: $str) }\nResponse: {\"errors\":[{\"message\":\"Validation error of type VariableTypeMismatch: Variable type doesn't match\",\"locations\":[{\"line\":1,\"column\":39}]}]}\nQuery: query Get( $str : Int! ) { hello (str: $str) }\nResponse: graphql.AssertException: wrappedType can't be null\nQuery: query Get($str: Int) { hello(str: $str) }\nResponse: {\"errors\":[{\"message\":\"Validation error of type UnknownType: Unknown type Int\",\"locations\":[{\"line\":1,\"column\":17}]}]}\nQuery: query Get($str: MyInput) { hello(str: $str) }\nResponse: {\"errors\":[{\"message\":\"Validation error of type VariableTypeMismatch: Variable type doesn't match\",\"locations\":[{\"line\":1,\"column\":39}]}]}\nQuery: query Get($str: MyInput!) { hello(str: $str) }\nResponse: {\"errors\":[{\"message\":\"Validation error of type VariableTypeMismatch: Variable type doesn't match\",\"locations\":[{\"line\":1,\"column\":40}]}]}\nHere is a copy of the stack trace if that is helpful.  It was produced by graphql-java-6.0.jar \nat graphql.Assert.assertNotNull(Assert.java:10)\n    at graphql.schema.GraphQLNonNull.<init>(GraphQLNonNull.java:34)\n    at graphql.execution.TypeFromAST.getTypeFromAST(TypeFromAST.java:22)\n    at graphql.validation.TraversalContext.enterImpl(TraversalContext.java:141)\n    at graphql.validation.TraversalContext.enter(TraversalContext.java:78)\n    at graphql.validation.RulesVisitor.enter(RulesVisitor.java:58)\n    at graphql.validation.LanguageTraversal.traverseImpl(LanguageTraversal.java:33)\n    at graphql.validation.LanguageTraversal.traverseImpl(LanguageTraversal.java:36)\n    at graphql.validation.LanguageTraversal.traverseImpl(LanguageTraversal.java:36)\n    at graphql.validation.LanguageTraversal.traverse(LanguageTraversal.java:28)\n    at graphql.validation.Validator.validateDocument(Validator.java:40)\n    at graphql.GraphQL.validate(GraphQL.java:531)\n    at graphql.GraphQL.parseAndValidate(GraphQL.java:501)\n    at graphql.GraphQL.lambda$parseValidateAndExecute$2(GraphQL.java:482)\n    at graphql.execution.preparsed.NoOpPreparsedDocumentProvider.get(NoOpPreparsedDocumentProvider.java:11)\n    at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)\n    at graphql.GraphQL.executeAsync(GraphQL.java:463)\n    at graphql.GraphQL.execute(GraphQL.java:394)\n    at graphql.GraphQL.execute(GraphQL.java:353). ",
    "thangbqvng": "Thanks for your help, I will try to fix it.. ",
    "Edholm": "Does this also fix the issue of when an input argument is null for non-nullable types? Now I get a NonNullableValueCoercedAsNullException and InternalServerError when I would expect a validation error instead\nExample that works as expected:\nmutation {\n  createItem(item: {nonNullableType:null}) {\n    ...itemFields\n    __typename\n  }\n}\nExample that does not:\nmutation CreateItem($item: CreateItemInput!) {\n  createItem(item: $item) {\n    ...itemFields\n    __typename\n  }\n}\nwhere the arguments look like this:\n{\n  \"item\": {\n    \"nonNullableType\": null,\n  }\n}. ",
    "gfsilva92": "Ok, I'm clarified! Thanks.. ",
    "sryara": "@gfsilva92 @tinnou Can you guys please provide an example for the above use case? I am also struggling to achieve query only fields from database that are specified in request ? Any small example will be a big help. Thanks.. ",
    "mogaleaf": "Having one DataLoaderRegistry and Dataloader per request is exactly what I was trying to do.\nMy problem comes in fact from the spring boot graphql plugin that I'm using and by default it comes with one singleton Instrumentation/DataloaderRegistry and doesn't create a new Instrumentation/DataLoaderRegistry for each request.\nAfter customizing this behaviour I can now create one DataloaderRegistry and Dataloader per request and it works fine.\nI'm closing this issue.\nThanks for your help.. @szantogab I have extended the SimpleGraphQLServlet and override the protected Instrumentation getInstrumentation() method.\nThis method is called at each request so you can create a new Instrumentation at each request.\nIn GraphQlServlet you have \nprivate GraphQL newGraphQL(GraphQLSchema schema) {\n        ExecutionStrategyProvider executionStrategyProvider = getExecutionStrategyProvider();\n        return GraphQL.newGraphQL(schema)\n            .queryExecutionStrategy(executionStrategyProvider.getQueryExecutionStrategy())\n            .mutationExecutionStrategy(executionStrategyProvider.getMutationExecutionStrategy())\n            .subscriptionExecutionStrategy(executionStrategyProvider.getSubscriptionExecutionStrategy())\n            .instrumentation(getInstrumentation())\n            .preparsedDocumentProvider(getPreparsedDocumentProvider())\n            .build();\n    }. ",
    "nickbabcock": "Looks like CI is failing for unrelated reasons. ",
    "babadofar": "I'm building the GraphQLObjectType  by hand, not using IDL schemas. \nNo annotation magic, just plain simple code.  So what I'm curious about is how to use Data Fetcher Factory with GraphQLFieldDefinition . ",
    "alexcibotari": "Hello @bbakerman , I have updated description with variables. I'm not familiar with your code, but if you help me I can write several Unit Tests.\nI would like to create schema exactly as in description and execute a query in order to check what I will receive in Java.. ",
    "joshstrange": "@bbakerman I have seen that but we use unix timestamps everywhere and I don't see support for that in that library.\nHere is my code\n````\npublic static GraphQLScalarType GraphQLTimestamp = new GraphQLScalarType(\"Timestamp\", \"Timestamp\", new Coercing() {\n    @Override\n    public Object serialize(Object input) {\n        return input;\n    }\n@Override\npublic Object parseValue(Object input) {\n    GregorianCalendar calendar = new GregorianCalendar();\n    calendar.setTimeInMillis(((IntValue)input).getValue().multiply(new BigInteger(\"1000\")).longValue());\n    return calendar;\n}\n\n@Override\npublic Object parseLiteral(Object input) {\n    GregorianCalendar calendar = new GregorianCalendar();\n    calendar.setTimeInMillis(((IntValue)input).getValue().multiply(new BigInteger(\"1000\")).longValue());\n\n    return calendar;\n}\n\n});\n````. @bbakerman Thank you for your input! Where can I look for said parse errors (or where can I put my breakpoint to check)?\nTimestamp is a Scalar type that I defined:\n````\npublic static GraphQLScalarType GraphQLTimestamp = new GraphQLScalarType(\"Timestamp\", \"Timestamp\", new Coercing() {\n        @Override\n        public Object serialize(Object input) {\n            return input;\n        }\n    @Override\n    public Object parseValue(Object input) {\n        GregorianCalendar calendar = new GregorianCalendar();\n        BigInteger value = new BigInteger(String.valueOf(input));\n        calendar.setTimeInMillis(value.multiply(new BigInteger(\"1000\")).longValue());\n        return calendar;\n    }\n\n    @Override\n    public Object parseLiteral(Object input) {\n        if (input == null) {\n            return null;\n        }\n        GregorianCalendar calendar = new GregorianCalendar();\n        calendar.setTimeInMillis(((IntValue) input).getValue().multiply(new BigInteger(\"1000\")).longValue());\n\n        return calendar;\n    }\n});\n\n````\nAlso I can see it getting correctly set in the coercedValues HashMap and it's in the executionContext.getVariables() it just never makes it into the DataFetchingEnvironment, or more importantly it's lost after this line:\n````\n        Map argumentValues = valuesResolver.getArgumentValues(fieldVisibility, fieldDef.getArguments(), field.getArguments(), executionContext.getVariables());\n````\nin ExecutionStrategy.fetchField(). @bbakerman Interesting, I'm finding that variables never work for me unless they share the exact same name as the field for which they are a variable for. I think this is my actual issue as I can get variables working for a timestamp (my custom scalar) if I name it \"created\" and use graphql to search for a record created at a specific time (useless in practice but proves my point they work). Same with for example searching for a user by username. If I name the variable \"username\" it all works, if I name it \"user1\" or \"myUser\" then it stops working. \nI could almost accept this as a limitation but it breaks down if I have a query like the following:\nquery myTwoBestFriends($friendOne: String!, $friendTwo: String!) {\n    friendOne: User(username: $friendOne) {\n         id\n         username\n         email\n    }\n    friendTwo: User(username: $friendTwo) {\n         id\n         username\n         email\n    }\n}\nPassing up variables:\n{\n    \"friendOne\": \"joeyt\",\n    \"friendTwo\": \"rossg\"\n}\nI believe the source of my problems is coming from the ValuesResolver.getArgumentValues() function which receives my valid variables but since they don't match field names it throws them away.. Thank you @bbakerman! You have been extremely helpful in answering all my questions and I'd like to thank you for the time and effort you put into this library, it's a godsend!\nEDIT/PS: Also I see you work at Atlasssian so that you for your work on the tools I use daily!. ",
    "mjagus": "Hi @bbakerman and thank you for your time on this. I reproduced the problem on both 6.0 and 7.0 version of graphql-java, but I'm also using graphql-java-tools, graphql-servlet and I'm executing queries via GraphiQL UI, so the source of problem may actually be in a different library. I will take a look at your test and get back to you within this week with a more detailed test case.. I did some digging and it seems that SchemaParser of graphql-java-tools creates GraphQLEnumValueDefinitions with enum objects as their values whereas SchemaGenerator of graphql-java simply creates them with String values. At least that's what happens in unit test environment.\nDuring execution of an introspection query and when using graphql-java-tools, GraphQLEnumType::getNameByValue method will never find a proper match because an equals check happens between String and Enum object.\nI have created PR for your PR to better demonstrate the test case: bbakerman/graphql-java#2 . The test should now fail with CoercingSerializeException as expected. I have used NaturalEnumValuesProvider to simulate behaviour of graphql-java-tools.\n. Wouldn't it be better to call name() instead? toString() may be overriden by owner of the enum class whereas name() is final.. ",
    "ellebrecht": "Glad to contribute, thanks for your great library.. ",
    "sp00m": "@bbakerman Oops good catch, I'm indeed using graphql-java-tools, I did not notice it has another way of initializing all this, my bad!. @andimarek, BatchedExecutionStrategy has been deprecated, but the @Batched annotation hasn't, and its JavaDoc still reads:\n\nThis annotation must be used in conjunction with BatchedExecutionStrategy.\n\nI've been using @Batched quite heavily, as it allows avoiding the select n+1 issue. Do you have any documentation on how to replace BatchedExecutionStrategy? The deprecation notice states:\n\nBatchedExecutionStrategy has been deprecated in favour of AsyncExecutionStrategy and DataLoaderDispatcherInstrumentation.\n\nCan one of these understand the @Batched annotation kind of the same way BatchedExecutionStrategy could? Or should the @Batched annotation have been deprecated as well? If so, how to avoid the select n+1 issue?\nEDIT: looks like I'm not the only one wondering about this deprecation: https://github.com/graphql-java/graphql-java-tools/issues/58#issuecomment-415358754.. Thanks for your answer, I get your point about caching, but I'm not too sure it's an issue in the way I've been trying to use BatchLoaders.\nSay with the example of Blog 1..n Article 1..n Comment, correct me if I'm wrong, but I think the original idea of BatchLoaders is to have three of them in this case:\n\none BlogBatchLoader, called by Article#blog\none ArticleBatchLoader, called by both Blog#articles and Comment#Article\none CommentBatchLoader, called by Article#comments\n\nIn such an implementation, I can see how the key I proposed could be an issue, especially for the ArticleBatchLoader as it can be called by both Blog#articles and Comment#article.\nThe way I've tried to use BatchLoaders though, isn't \"one by entity\" but rather \"one by source-target relation\", so you would have:\n\none for Blog#articles\none for Article#blog\none for Article#comments\none for Comment#article\n\nIn this case, I don't see caching as an issue (but actually a great addition), as I can't find a case where calling Comment#article twice with the same Comment source should give a different result (note that I'm talking about per-query cache). What do you think? Or did I misunderstood anything?\n\nI saw this BatchLoaderWithContext indeed, but to be honest, I'm not too sure how this could work. For example with the following query:\nquery {\n  blogs {\n    articlesWithFooInTitle: articles(whereTitleContains: \"foo\") {\n      title\n    }\n    articlesWithBarInTitle: articles(whereTitleContains: \"bar\") {\n      title\n    }\n  }\n}\nHow would you make the underlying ArticleBatchLoaderWithContexts trigger only the two following queries (pseudo code):\n\nselect from article where blog in (:theSourceBlogs) and title like 'foo'\nselect from article where blog in (:theSourceBlogs) and title like 'bar'\n\n?\nThanks for your time!. Well actually, the best would be to know how one would implement the resolution of such a schema with BatchLoaderWithContexts (not the proper implementation of course, but a high overview of the architecture would be great): https://github.com/sp00m/graphql-gom/blob/master/src/test/resources/graphql/gom/example/example.graphql, especially the Article#comments(containing: String): [Comment!]! part.. Really appreciate this, thanks for your time \ud83e\udd47 . That's brilliant, many thanks for your time again!\nSo we've basically ended up with the same approach if I understand correctly: having a custom type for the BatchLoader keys, that holds both the source id and the arguments (which is basically what I've implemented in graphql-gom).\n\nThe reason for this is that is the unique dimension being searched for.\n\nNice wording, that's basically it yeah. Caching will still operate for an identical \"sourceId+ searchText\" pair, which does make sense with this schema.\nThanks again, I just wanted to make sure this was the correct approach. Feel free to close this ticket, unless you have things to add?\n\ud83d\ude4f . PS: I'm pretty sure other devs could be interested by this snippet of yours BTW. Maybe it deserves a link in graphql-java's docs?. ",
    "rmcloughlin": "Also on this page:  http://graphql-java.readthedocs.io/en/v7/getting_started.html. ",
    "martin-walsh": "I should also state that my issues are arising through usage of graphql-java-servlet project & that my assumed use case is rendering errors to json with Jackson.  If you feel the fix is more appropriate in that project given the lack of dependency upon jackson, please close this issue and I will open an issue within graphql-java-servlet instead. Ok, thanks, I'll dig further & see what can be done downstream. ",
    "varun-mach": "I am not able to test  my application as I get a 404 error for any request sent on /graphql.. ",
    "jiayou50": "@bbakerman I'm investigating on implementing schema stitching with graphql-java, and one major thing that seems to be missing is the ability to build a GraphQLSchema object from an introspection query result which is in JSON. This would correspond to the buildClientSchema function in the reference graphql-js implementation. \nI saw the SchemaParser class, but it only parses schemas written in the GraphQL schema language. Am I missing anything here?. ",
    "mrdon-atlassian": "We (Atlassian) built a schema stitching library called graphql-braid: https://bitbucket.org/atlassian/graphql-braid/src. PR https://github.com/graphql-java/graphql-java/pull/1142. Actually, I read the error wrong.  I tested this more on github and you are correct - the impl doesn't care about either vars not used or vars not defined.  Gonna reject the pr.. This was more for making the tests easier and minimizing impact.  It may be useful to validate just a document outside its execution context?. ",
    "benneq": "@mrdon-atlassian Is there any working example for your library?\nThe examples on your git README.md rely on non-existing classes ( HttpGraphQLRemoteRetriever )\nAnd use lot's of code that's not compatible with version 0.11.0 , 0.11.1, 0.11.2, 0.12.0.\nThe GraphQLRemoteSchemaSource need some kind of Supplier<Reader> schemaProvider. In the examples of your README.md there's nothing like that.\nI couldn't yet figure out how to use this... :(. ",
    "elenigen": "You are my hero ... so when will it be available this 8.0 release? . ",
    "haizz": "@bbakerman https://gist.github.com/haizz/5df2091859253a04523979db03a25d1e. Thanks! Yeah, I actually did put clearAll call in the Subscriber of Publisher<ExecutionResult>:\nkotlin\ndataLoaderRegistry.dataLoaders.forEach { dl ->\n    dl.clearAll()\n}\nI'm wondering though, shouldn't this cleanup be performed by the library automatically when executing GraphQL Subscriptions?. ",
    "patteblanche": "I am seeing that the errorType is not part of the specification: http://facebook.github.io/graphql/October2016/#sec-Errors\nThen, maybe the errorType could be added to extensions?  It is confusing to have a field in GraphQLError that is ignored when serialized to json.. Ok, got it.\nI would add that it is confusing to have members of GraphQLError interface that do not get serialized in the response.\nThanks for your fast response.\n. ",
    "treycordova": "Under Type Validation, point 5:\n5. An object type must be a super-set of all interfaces it implements:\n      i. The object type must include a field of the same name for every field defined in an interface.\n          a. The object field must be of a type which is equal to or a sub-type of the interface field (covariant).\n              a. An object field type is a valid sub-type if it is equal to (the same type as) the interface field type.\n              b. An object field type is a valid sub-type if it is an Object type and the interface field type is either an Interface type or a Union type and the object field type is a possible type of the interface field type.\n              c. An object field type is a valid sub-type if it is a List type and the interface field type is also a List type and the list-item type of the object field type is a valid sub-type of the list-item type of the interface field type.\n              d. An object field type is a valid sub-type if it is a Non-Null variant of a valid sub-type of the interface field type.\n\u2014 https://github.com/facebook/graphql/blob/master/spec/Section%203%20--%20Type%20System.md\nSpecifically:\n\nAn object field type is a valid sub-type if it is an Object type and the interface field type is either an Interface type or a Union type and the object field type is a possible type of the interface field type.\n\nI think that's in support of polymorphic types for queries, at least. I could be reading it incorrectly, of course.\nMoreover, I'm running a version of the schema mentioned here through graphql and graphql-tools (for quick API mocks) and it parses and handles queries without error.. ",
    "escitalopram": "Thank you. There's no further problem; I'm just trying to understand the codebase better.. I'm using a GraphQL server which dynamically extracts its type definitions from a CMS (in order to be able to read from and write to it). I put directives on fields, that inform the data fetchers how to access the data in the actual CMS.\nThe data the CMS provides for its types are quite comprehensive, e.g. it would also contain labels to use for the UI of the client application, which I would like to be able to pass on to the GraphQL client, so that I only need to maintain my types in the CMS and everything down to the GraphQL client application doesn't need to be touched when CMS types are added/changed.\nMy client already has to use introspection to list the types and fields, and it would seem bad design to me, if I had to use an additional mechanism (and query) to obtain the rest of the (CMS-)type information, when directives are already there.. Ok, thank you. Due to our project planning here, I guess it will take at least a month until I can come up with an actual pull request.. ",
    "domarmstrong": "Yes I'll put something together, havn't had time today. I'm resolving the paths now using DataFetchingEnvironment.getFields() to get the Fields/SelectionSets directly. So closing as no issue for me now.. ",
    "cmorgner": "Ok, I just found GraphQLTypeReference and I think my feature request can be disregarded.. :). ",
    "WolfgangFahl": "Please do not close this issue - my request was specifically for a groovy free and simpler example. . ",
    "ebenoist": "Is this issue the reason why I'm seeing N+1 calls on a secondary batch join?\nI have two batch loaders, one for listings and one for releases. \n```JAVA\npublic static  CompletableFuture asFuture(Callable<? extends T> callable,\n      Executor executor) {\n    CompletableFuture future = new CompletableFuture<>();\n    executor.execute(() -> {\n      try {\n        future.complete(callable.call());\n      } catch (Throwable t) {\n        future.completeExceptionally(t);\n      }\n    });\nreturn future;\n\n}\nBatchLoader batchListingsLoader = ids -> asFuture(\n      ServletScopes.transferRequest(() -> core.getListings(ids).getListingsList()),\n      MoreExecutors.directExecutor());\nBatchLoader batchReleasesLoader = ids -> asFuture(\n      ServletScopes.transferRequest(() -> lp.getReleases(ids).getReleasesList()),\n      MoreExecutors.directExecutor());\npublic DataLoaderRegistry get() {\n    DataLoaderRegistry registry = new DataLoaderRegistry();\nregistry.register(\"listings\", new DataLoader<>(batchListingsLoader));\nregistry.register(\"releases\", new DataLoader<>(batchReleasesLoader));\n\nreturn registry;\n\n}\n```\nAnd when given my query:\n{\n  user(input: { token: \"token\"}) {\n    feed {\n      listing {\n        title\n        release {\n          title\n        }\n      }\n    }\n  }\n}\nThis results in listings being loaded in bulk correctly, but releases are loaded one at a time, but the load count and batch load count increase on every call.\n```\n// LISTING CALLS\nStatistics{loadCount=24, loadErrorCount=0, batchLoadCount=0, batchLoadExceptionCount=0, cacheHitCount=0}\nMar 20, 2018 12:21:37 PM com.reverb.rql.clients.APIClient lambda$requestURL$0\nINFO: REQUEST - url: https://api.reverb.com/api/listings?ids=10958215,10958031,10958027,10958028,10957866,10957526,10957501,10957368,10957323,10957301,10957187,10957125,10957086,10957054,10956732,10956707,10956675,10956629,10956555,10956515,10956496,10956465,10956449,10956437 code: HTTP/1.1 200 OK duration: 94\n// RELEASE CALLS\nStatistics{loadCount=0, loadErrorCount=0, batchLoadCount=0, batchLoadExceptionCount=0, cacheHitCount=0}\nMar 20, 2018 12:21:37 PM com.reverb.rql.clients.APIClient lambda$requestURL$0\nINFO: REQUEST - url: https://lp-api.reverb.com/releases/?ids=c9cce85e-a98d-470d-bad6-a2eb3204cc4d code: HTTP/1.1 200 OK duration: 238\nStatistics{loadCount=1, loadErrorCount=0, batchLoadCount=1, batchLoadExceptionCount=0, cacheHitCount=0}\nMar 20, 2018 12:21:38 PM com.reverb.rql.clients.APIClient lambda$requestURL$0\nINFO: REQUEST - url: https://lp-api.reverb.com/releases/?ids=b9e4f1bf-3269-41e2-a4e0-f5f442b5378d code: HTTP/1.1 200 OK duration: 127\nStatistics{loadCount=2, loadErrorCount=0, batchLoadCount=2, batchLoadExceptionCount=0, cacheHitCount=0}\nMar 20, 2018 12:21:38 PM com.reverb.rql.clients.APIClient lambda$requestURL$0\nINFO: REQUEST - url: https://lp-api.reverb.com/releases/?ids=9d6df3b9-880d-4659-8fcf-f5a6cf615249 code: HTTP/1.1 200 OK duration: 43\nStatistics{loadCount=3, loadErrorCount=0, batchLoadCount=3, batchLoadExceptionCount=0, cacheHitCount=0}\n```. ",
    "siderakis": "What about passing an object in the Context, so that each node that uses a DataLoader (and any async node, since it's children may use a DataLoader) can signal (in a thread-safe way) that it and all of it's children nodes are done queuing up DataLoader requests. When the root gets the signal that all nodes ready then it dispatches. This cycle repeats until no async requests are pending. \nI know the idea is pretty hand-wavey at this point, I need to look closer at the current implementation to get more specific. Just looking for early feedback.. The plugin is currently showing 100 Warning. I'd be happy to go through and add start fixing issues and suppressing warning in a follow up PR.. Nice progress :-) !\n```\n\nTask :compileJava\n/Users/siderakis/graphql/graphql-java/src/main/java/graphql/execution/ExecutionTypeInfo.java:140: warning: [JdkObsolete] Stack is a nonstandard class that predates the Java Collections Framework; prefer ArrayDeque. Note that the Stack methods push/pop/peek correspond to the Deque methods addFirst/removeFirst/peekFirst.\n        Stack decoration = new Stack<>();\n                                        ^\n    (see http://errorprone.info/bugpattern/JdkObsolete)\n/Users/siderakis/graphql/graphql-java/build/generated-src/antlr/main/graphql/parser/antlr/GraphqlParser.java:4927: warning: [MissingOverride] sempred overrides method in Recognizer; expected @Override\n        public boolean sempred(RuleContext _localctx, int ruleIndex, int predIndex) {\n                       ^\n    (see http://errorprone.info/bugpattern/MissingOverride)\n  Did you mean '@Override public boolean sempred(RuleContext _localctx, int ruleIndex, int predIndex) {'?\n/Users/siderakis/graphql/graphql-java/src/main/java/graphql/TypeMismatchError.java:43: warning: [DoubleBraceInitialization] Prefer collection factory methods or builders to the double-brace initialization pattern.\n        private static final Map, Introspection.TypeKind> registry = new HashMap, Introspection.TypeKind>() {{\n                                                                                                  ^\n    (see http://errorprone.info/bugpattern/DoubleBraceInitialization)\n  Did you mean 'private static final ImmutableMap, Introspection.TypeKind> registry = ImmutableMap., Introspection.TypeKind>builder().put('?\n/Users/siderakis/graphql/graphql-java/src/main/java/graphql/schema/idl/ArgValueOfAllowedTypeChecker.java:118: warning: [OrphanedFormatString] String literal contains format specifiers, but is not passed to a format method\n                .orElseThrow(() -> new AssertException(\"Directive unknown argument type '%s'. This should have been validated before.\"));\n                                                       ^\n    (see http://errorprone.info/bugpattern/OrphanedFormatString)\n/Users/siderakis/graphql/graphql-java/src/main/java/graphql/schema/idl/TypeInfo.java:29: warning: [JdkObsolete] Stack is a nonstandard class that predates the Java Collections Framework; prefer ArrayDeque. Note that the Stack methods push/pop/peek correspond to the Deque methods addFirst/removeFirst/peekFirst.\n    private final Stack> decoration = new Stack<>();\n                                               ^\n    (see http://errorprone.info/bugpattern/JdkObsolete)\n/Users/siderakis/graphql/graphql-java/src/main/java/graphql/schema/idl/TypeInfo.java:83: warning: [JdkObsolete] Stack is a nonstandard class that predates the Java Collections Framework; prefer ArrayDeque. Note that the Stack methods push/pop/peek correspond to the Deque methods addFirst/removeFirst/peekFirst.\n        Stack> wrappingStack = new Stack<>();\n                                        ^\n    (see http://errorprone.info/bugpattern/JdkObsolete)\n/Users/siderakis/graphql/graphql-java/src/main/java/graphql/execution/ExecutorServiceExecutionStrategy.java:71: warning: [FutureReturnValueIgnored] Method returns a nested type, java.util.concurrent.Future>\n            futures.put(fieldName, executorService.submit(resolveField));\n                       ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n/Users/siderakis/graphql/graphql-java/src/main/java/graphql/execution/ExecutorServiceExecutionStrategy.java:71: warning: [FutureReturnValueIgnored] Method returns a nested type, java.util.concurrent.Future>\n            futures.put(fieldName, executorService.submit(resolveField));\n                                                         ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\n/Users/siderakis/graphql/graphql-java/src/main/java/graphql/execution/ExecutorServiceExecutionStrategy.java:82: warning: [FutureReturnValueIgnored] Method returns a nested type, java.util.concurrent.Future>\n                    executionResult = futures.get(fieldName).get().join();\n                                                 ^\n    (see http://errorprone.info/bugpattern/FutureReturnValueIgnored)\nNote: Some input files use unchecked or unsafe operations.\nNote: Recompile with -Xlint:unchecked for details.\n9 warnings\n\n```. ",
    "arcuri82": "as I had to spend some time to understand how to write my own custom GraphQLScalarType for java.time.ZonedDateTime, it would have been great if such scalar was already available. Anyway, currently using (adapted from here and here):\n```\nclass MyDateTimeScalar : GraphQLScalarType(\"MyDateTime\", \"DataTime scalar\", MyDateTimeScalarCoercing())\nprivate class MyDateTimeScalarCoercing : Coercing {\noverride fun serialize(input: Any): String {\n    if (input is ZonedDateTime) {\n        return input.format(DateTimeFormatter.ISO_ZONED_DATE_TIME)\n    }\n\n    val result = convertString(input)\n            ?: throw CoercingSerializeException(\"Invalid value '$input' for ZonedDateTime\")\n\n    return result.format(DateTimeFormatter.ISO_ZONED_DATE_TIME)\n}\n\noverride fun parseValue(input: Any): ZonedDateTime {\n\n    return convertString(input)\n            ?: throw CoercingParseValueException(\"Invalid value '$input' for ZonedDateTime\")\n}\n\noverride fun parseLiteral(input: Any): ZonedDateTime? {\n\n    if (input !is StringValue){\n        return null\n    }\n\n    return convertString(input.value)\n}\n\nprivate fun convertString(input: Any): ZonedDateTime? {\n\n    if (input is String) {\n        return try {\n            ZonedDateTime.parse(input)\n        } catch (e: DateTimeParseException) {\n            null\n        }\n    }\n\n    return null\n}\n\n}\n```\n. ",
    "TuomasKiviaho": "The use case would be a JAX-RS MessageBodyWriter<GraphQLSchema>  implementation where the throwing of IOException still has it's merit.\n``` java\n@Override\npublic void writeTo(GraphQLSchema graphQLSchema, Class<?> type, Type genericType,\n    Annotation[] annotations, MediaType mediaType,\n    MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream)\n    throws IOException, WebApplicationException\n{\n    SchemaPrinter schemaPrinter = new SchemaPrinter();\n    Map<String, String> parameters = mediaType.getParameters();\n    String charset = parameters.get(MediaType.CHARSET_PARAMETER);\n    try (Writer writer = charset == null\n        ? new OutputStreamWriter(entityStream, StandardCharsets.UTF_8)\n        : new OutputStreamWriter(entityStream, charset);)\n    {\n        schemaPrinter.print(graphQLSchema, writer);\n    }\n}\n\n}\n```. ",
    "rhino88": "Ah that makes perfect sense! Thank you for the timely reply.\nPerhaps this should be incorporated into the docs somewhere here: http://graphql-java.readthedocs.io/en/latest/execution.html#queries\n. ",
    "sleberrigaud": "I've updated with the basic code comments. If you guys are happy with this, I can as @bbakerman suggests implement as a different strategy within DataLoaderDispatcherInstrumentation . @bbakerman I'm wondering if the default method here was hiding the real root cause for us. I've had another issue yesterday with the same effect and it turned out to be because one of the super class was not visible.\nIn my case, I had a package-private abstract class with default methods, and different implementations and the method on the abstract class was not found by GraphQL Java.\nMaybe I should open a specific issue about that one?. Trying to reproduce via a test in PropertyDataFetcherTest and can't see to be able to. Wondering if the code to support default interface methods fixed things... \ud83e\udd37\u200d\u2642\ufe0f . I would make this an interface, keep the public API surface minimal.. Assuming data can be null? Is there an annotation used by the project to mark such nullable parameters?. If the goal is to make the object immutable, you should return a defensive copy of the list here.. Looks like you don't need to keep a reference to the relativeError, doesn't seem to be used anywhere but in the constructor.. Maybe extract methods to clarify the operations here.... If you want immutability, make a defensive copy.. private final as well?. > it is meant to be directly instantiated and not to be implemented\nWhy? By doing so IMHO you're constraining the usage of the API, for no apparent reason. I do understand the need to provide a default implementation, but to only have one is limiting the framework capabilities.\nLet's say for example (this might be a dumb example), one want to internationalize error messages and would want to lazy (and batch) load i18n messages based on error keys. By having an interface for DataFetcherResult they could implement it easily in a way that works for them. Clearly the implementation doesn't offer the same flexibility.\nJuts my 2c.. Naming is hard... and I prefer DataLoaderDispathCall... good call.. Probably, I just copied those across here for the example... since I had them otherwise in the Braid lib.. \ud83d\udc4d . The one thing I like about it is that it conveys clearly that we don't care about parameters in that particular case. But I agree it's kinda hacky... hopefully unnamed params are coming to a future Java release.... ",
    "rrva": "Also opened https://github.com/graphql-java/graphql-java/issues/1012 for the other performance area that could be improved in PropertyDataFetcher. I guess graphql-java-tools uses reflectasm to make this better, but since graphql-java-tools lags behind in compatbility with dataloaders etc, I would prefer to only depend on graphql-java (and graphql-java-tools seems to have other performance issues...). @bbakerman Thanks for fixing this! . Tried graphql-java from this PR and my benchmark project at https://github.com/rrva/hello-dataloader/commit/ed800010b5351c6ccc8eefd4a7563015a77a2cdd\nMuch better response time behavior.\nDid a quick profile to show what is left, but I am happy as is.\n\n. Maybe base the cache key on something else than clazz.getCanonicalName() which seems to be slow due to being a native method?\nhttps://bugs.openjdk.java.net/browse/JDK-5058117\nconsider if getName() is sufficient, since it seems to be cached.. javadoc fails on using -> in a comment, change it to to . also, getCanonicalName seems to return null for anonymous inner classes:\n```java\npackage foo;\npublic class Foo {\ninterface Bar {\n    void baz();\n}\n\npublic static void main(String[] args) {\n    System.out.println(\"class name:\"+Foo.class.getName());\n\n    Bar b = new Bar() {\n        @Override\n        public void baz() { }\n    };\n\n    System.out.println(\"anon inner class name: \"+ b.getClass().getName());\n    System.out.println(\"anon inner class canonicalName: \"+b.getClass().getCanonicalName());\n}\n\n}\n```. ",
    "vagostep": "@bbakerman In Kotlin, the class Throwable has a member called \"message\". Kotlin automaticaly create a setter and getter with this name (getMessage and setMessage). So, this method cause the accidental override with the abstract method in the interface GraphQLError getMessage() when i extends of Throwable and implements GraphQLError. \nHere was the same problem notify by another user: https://stackoverflow.com/questions/48698699/accidental-override-the-following-declarations-have-the-same-jvm-signature-wh. @bbakerman Great. It would not have even occurred to me to use Java-Kotlin interoperability in this case. I will implement it. ",
    "Arcnor": "For anybody else stumbling upon this problem, the related Kotlin issue is https://youtrack.jetbrains.com/issue/KT-6653 (I also opened a ticket with the GraphQL specific problem that got closed as duplicated of the first https://youtrack.jetbrains.com/issue/KT-24822). ",
    "mrcasablr": "@bbakerman Thank you! Yes, we will need a engine for sure. My question was more of if graphql-java can fetch data from a graphql source (a microservice).  For example - \n\nIn the above picture, microservice 4 runs a graphql-java server on spring-boot so does api-proxy. I was wondering if the api-proxy graphql-java can talk to a graphql microservice built on graphql-java or we need a graphql java client on the api-proxy?  . ",
    "varunkumar": "My understanding is that the client doesn't need to specify anything in the request. Client can just use information like maxAge to manage its cache. Tools like Apollo engine can also use this information to manage its cache.. ",
    "FutureElement": "thanks very much. how about like this\n```@Override\npublic CompletionStage> load(List keys) {\n    Flux flux = groupService.getGroupsByProjectIds(keys);\n    return flux.collectList().toFuture();\n}. ok, thanks. ",
    "soneymathew": "@andimarek I think this experience is a good reference to implement this one\nhttps://www.npmjs.com/package/graphql-fields. @bbakerman  currently I am working around by doing the below. I think if it is exposed as a convenience method that will take care of internal stuff like applying the @include or @skip directive and just let me focus on the fields that are requested could greatly simplify the below approach for me.\nI am thinking an api that facilitates something like. \nMap<String, List<Field>> fields = dataFetchingEnvironment\n  .getSelectionSet()\n  .justGetMeFieldsStartingFromTheNode_I_Am_In()\nCurrently how I do this is as below\n```\n    private List getFieldNames(DataFetchingEnvironment env) {\n        Collection> values = env.getSelectionSet().get().values();\n        return extractFieldsFromNodesAndEdges(values, env);\n}\n\n/*\n* We want to extract supported fields only from within nodes and edges.node in the Connection type\n* We will replace this approach with solution of https://github.com/graphql-java/graphql-java/issues/1043\n* when it is released\n* Here we have to consider fields, inline fragments and fragment spreads as the possibilities for field selections\n* */\nprivate List<String> extractFieldsFromNodesAndEdges(Collection<List<graphql.language.Field>> values, DataFetchingEnvironment env) {\n    return values.stream().flatMap(field -> {\n        String name = field.get(0).getName();\n        SelectionSet selectionSet = field.get(0).getSelectionSet();\n        if (selectionSet != null) {\n            List<Selection> selections = selectionSet.getSelections();\n            if (name.equalsIgnoreCase(\"nodes\")) {\n                return getFields(selections, env).stream();\n            } else if (name.equalsIgnoreCase(\"edges\")) {\n                return getFieldsFromEdgeNode(selections, env).stream();\n            }\n        }\n        return (new ArrayList<String>()).stream();\n    }).collect(toList());\n}\n\nprivate List<String> getFieldsFromEdgeNode(List<Selection> selections, DataFetchingEnvironment env) {\n    return selections.stream().flatMap(selection -> {\n        if (selection instanceof graphql.language.Field) {\n            Field graphQLfield = ((graphql.language.Field) selection);\n            String fieldName = graphQLfield.getName();\n            if (fieldName.equalsIgnoreCase(\"node\")) {\n                return getFields(graphQLfield.getSelectionSet().getSelections(), env).stream();\n            }\n        } else if (selection instanceof InlineFragment) {\n            InlineFragment inlineFragment = (InlineFragment) selection;\n            String fieldType = inlineFragment.getTypeCondition().getName();\n            if (fieldType.equalsIgnoreCase(\"ThingEdge\")) {\n                return getFieldsFromEdgeNode(inlineFragment.getSelectionSet().getSelections(), env).stream();\n            }\n        } else if (selection instanceof FragmentSpread) {\n            FragmentSpread fragmentSpread = (FragmentSpread) selection;\n            FragmentDefinition fragmentDefinition = env.getFragmentsByName().get(fragmentSpread.getName());\n            return getFieldsFromEdgeNode(fragmentDefinition.getSelectionSet().getSelections(), env).stream();\n        }\n\n        return (new ArrayList<String>()).stream();\n    }).collect(toList());\n}\n\n\nprivate List<String> getFields(List<Selection> values, DataFetchingEnvironment env) {\n    return values.stream()\n            .flatMap(field -> {\n                if (field instanceof graphql.language.Field) {\n                    graphql.language.Field field1 = (graphql.language.Field) field;\n                    return Arrays.asList(field1.getName()).stream();\n                } else if (field instanceof InlineFragment) {\n                    InlineFragment inlineFragment = (InlineFragment) field;\n                    String fieldType = inlineFragment.getTypeCondition().getName();\n                    if (fieldType.equalsIgnoreCase(\"Thing\")) {\n                        return getFields(inlineFragment.getSelectionSet().getSelections(), env).stream();\n                    }\n                } else if (field instanceof FragmentSpread) {\n                    FragmentSpread fragmentSpread = (FragmentSpread) field;\n                    FragmentDefinition fragmentDefinition = env.getFragmentsByName().get(fragmentSpread.getName());\n                    return getFields(fragmentDefinition.getSelectionSet().getSelections(), env).stream();\n                }\n                return (new ArrayList<String>()).stream();\n            })\n            .filter(myService::isFieldNameSupported)\n            .collect(toList());\n}\n\n```. ",
    "swaters-atlassian": "Interestingly, the existing PropertyDataFetcher does actually handle aliases properly in POJOs which is to some degree why I chose to fix things in this particular way.  The reason it works for POJOs is that the lookup is by the getter of the propertyName on the object which will work regardless of the alias.  It fails in the alias case where a map is supplied because in order to support cases like returning the same property twice with different formats it makes a certain amount of sense to key the map by the alias rather than the propertyName so both can exist.  However, to resolve that requires querying the map by the alias and not the propertyName if an alias exists.\nIf there is a different place other than the DataFetcher where we should be resolving aliases then help me out.  I can see a couple alternatives for our use case:\n1. The source map is built up with only propertNames as keys and aliased properties (and their associated arguments) are mapped in and resolved somewhere higher up in the chain after fetching.\n2. We write our own DataFetcher and attempt to patch it in as the default resolver for our needs. ",
    "jimkyndemeyer": "Updated as requested with a null sourceName when it's unknown.\nI also verified that the spec is still met given that only line and column is included in the response here:\nhttps://github.com/graphql-java/graphql-java/blob/ce06266d82878686d35d9b20c3ab22245cb2f38d/src/main/java/graphql/GraphqlErrorHelper.java#L37-L42. A bit more context:\n- I'm the core developer for https://github.com/jimkyndemeyer/js-graphql-intellij-plugin which is written in Java\n- For the 2.0 release, graphql-java will be used to provide the validation rules and schema tools for GraphQL editing. Previously the Facebook graphql-js reference implementation was used by the plugin via a Node.js process.\nIt's a bit of a complication that both SDL and executable GraphQL exists within the same language and file type, so I had the same concerns that you raise.\nAs it stands, I'm ignoring the \"executable graphql\" validation rule in the GraphQL code editor as the developer is not attempting to execute. However, if the developer were to execute the document from the above shown screenshot against a graphql-java endpoint, it would return not only the expected \"executable\" error, but also include \"Directive not allowed here\" errors, which is misleading given that the locations are valid. I'm not decided either way, only that it's potentially misleading.\nAs for the plugin, the schema validation that you mention could also trigger errors in the code editor given that the plugin builds a schema. So If you prefer not to update the KnownDirectives rule, I could work around it by ignoring directive location errors reported inside type definitions.. Thanks, makes sense.\nI'm currently using UnExecutableSchemaGenerator.makeUnExecutableSchema which appears to run a lot of the schema validation.\nI'll make sure to separate the \"executable/runtime\" validation from the schema validation. I have all the info I need from the plugin parse tree to differentiate between them inside the plugin.. I second disabling this by default.\nThe directive locations and arguments on the built-in @defer directive conflicts with the Relay Modern directive: https://github.com/facebook/relay/blob/76fef685f70a5aa09cd180ce0f2ef6b6d3f4f7e8/packages/relay-test-utils/testschema.graphql#L11-L14\nAn alternative solution would be to let any user schema declared directives take precedence or replace the built-in ones. Right now declaring a Relay defer directive appends it to the end of a linked hash set. The validation always looks up the built-in version as a consequence.. Thanks for working on this.\nIt looks like tempDirectiveDefs is never used to update the registry further down in the merge method:\njava\n        // ok commit to the merge\n        this.types.putAll(tempTypes);\n        this.scalarTypes.putAll(tempScalarTypes);\n        this.directiveDefinitions.putAll(tempDirectiveDefs); // <- this statement appears to be missing. This assertion throws based on the following SDL:\ngraphql\ndirective @test(include: Boolean!) on FIELD\nWhereas the following passes:\ngraphql\ndirective @test(include: Boolean! = false) on FIELD\nBoth definitions are valid according to the grammar. Can you elaborate on the thinking behind adding this assertion?\n. Thanks for the feedback.\nThis looks a bit weird, but it's based on the behaviour that the previously used CharStreams.fromString uses internally: \nhttps://github.com/antlr/antlr4/blob/8005cfd090d709856a42d78547aec75a4a7bdbc1/runtime/Java/src/org/antlr/v4/runtime/CharStreams.java#L211-L213\nAs far as I can tell, this PR shouldn't change the behaviour of any existing use cases.\nThe current sourceName without this PR appears to be set to \"<unknown>\":\nhttps://github.com/antlr/antlr4/blob/8005cfd090d709856a42d78547aec75a4a7bdbc1/runtime/Java/src/org/antlr/v4/runtime/IntStream.java#L36. Ah, makes sense.\nDidn't get that from your first comment. I was focusing on the parser instantiation code.\nI'll update the PR.. ",
    "themanojshukla": "But, we could have something to White-List those queries which are exclusively specified by the users (could be list of allowed queries). \nCan't we have some regex to identify the valid IntrospectionQuery format.? . I got a workaround for this, but I want your guidance over my approach.\nI've tokenized the introspection query, and created a simple array of token of type String.\nHere is what I found as possible && unique tokens..\nString[] validTokens = {\n \"\", \"query\", \"IntrospectionQuery\", \"schema\", \"queryType\", \"name\",  \"mutationType\", \"subscriptionType\",\n \"types\", \"FullType\", \"directives\", \"description\", \"locations\", \"args\", \"InputValue\", \"fragment\", \"on\", \"Type\",\n \"kind\", \"fields\", \"includeDeprecated\", \"true\", \"type\", \"TypeRef\", \"isDeprecated\", \"deprecationReason\",\n \"inputFields\", \"interfaces\", \"enumValues\", \"possibleTypes\", \"defaultValue\", \"ofType\"\n};\n\nNow, I will tokenize each request (only unique tokens, no duplicates) and now can match if the current query contains only IntrospectionTokens or not.\nIf it contains only IntrospectionTokens I would by pass it from the depth checker, but if any token in current query is out of this allowed strings, I would make it pass through the depth checker as normal process.\nNow, in future, if anything new comes into the valid IntrospectionQuery, I would just add that new token to the list of validTokens. And all would be as fine as it were.\nI've not seen any kind of prevention in any implementation of GraphQL specs. Following/modifying this approach we can make it available as @PublicApi  or configurable to Back-end Developers.\nI tried this on my local project, It works perfectly fine. Need your thoughts on this.!!\n. Can we configure/modify/change the default introspection query written in GraphiQL tool? If yes, we can have a mechanism to avoid the above problem. \nAs far as I'm aware, the very first introspection query is made by THAT GraphiQL interface WHICH IS connected to our GraphQL server (what we add as dependency in our server project), so the Introspection Query Stored in GraphiQL is always hit whenever somebody opens /graphiql endpoint. \nIf anyhow, we can configure THAT stored query, then we can easily allow those Introspections which we created/configured and have agreed that it (fully or partially) is sufficient to explore whole (or required) schema with documentation. Doing so, we can bypass the depth checking for our CUSTOM Introspection and all other queries will have to pass through the depth checker (if depth limit is enabled).\n . Thanks @andimarek for the link, and @bbakerman for detailed description. Thank you so much. That meets my concern, so closing this request.!!. Thanks for the detailed information !!. ",
    "alamothe": "Awesome! \ud83d\udc4d \nOne question: is there any situation where naked GraphQLException will be thrown after this fix? \nIs the expectation that execute should always return a result with errors as a part of it? Or do the clients still need to be on a lookout for GraphQLException?. ",
    "tipok": "@bbakerman in my case this is totally fine, i'm just using the parser here and failing during validation is totally fine. I've interpreted the spec this way:\nIf it's true of type boolean in JSON it's correct but if it's \"true\" of type string  in JSON it should fail because of type mismatch.\nWhy i did so:\nThe difference here between input and output in the spec. For output conversion is fine if no information is lost (this is really non specific), but for input the types have to match.\nThe JS Boolean(x) and Boolean.parseBoolean(x) in Java are really different in their behaviour.\nIn JS Boolean(\"false\") will always return true because the string isn't empty, but in Java Boolean.parseBoolean(\"false\") will be always false.\nNow to our test:\nWe do have a mutation:\nGraphLQ:\ngraphql\nmutation UpdateObject($b: Bool!, $s: String!) {\n  update(b: $b, s: $s) {\n    id\n    b\n    s\n  }\n}\nVariables:\nJSON\n{\n    \"b\": \"hello\",\n    \"s\": \"hello again\"\n}\nThe result is an update which is interpreted as:\nJSON\n{\n    \"b\": false,\n    \"s\": \"hello again\"\n}\n. ",
    "mateusz-bajorek": "Ping!\nLooking at https://mvnrepository.com/artifact/com.graphql-java/graphql-java - it seams like you are still publishing the nightlies over to mvn central. The normal releases are there (i.e. 11.0 etc.) but development builds as well (2019.01...). It would be good if you could publish those to a snapshot repository rather than release one.\nWhat do you think?. Sure, here is my reasoning:\n- there is noise in the maven repository page, you need to scroll around 7 screens down to find the actual latest release (I always tend to look at maven repo page first, before the github releases)\n- you can push dev builds to a snapshot maven repository and it only requires the devs who want to use them to include reference to the snapshots repo like described here https://maven.apache.org/guides/mini/guide-multiple-repositories.html \nThat way: people who want to use those builds still have no issue in doing so, and it's clear they are not full releases. I think this is the industry standard to follow such process.. ",
    "johnarne": "Same here, doing manual dispatch. Seems like the JS implementation would handle this use case without manual dispatching, since dispatching would happen at next tick? But yeah, I see no good way of figuring out when dispatching is needed. Feel free to close this issue, thanks for the clarifications.. ",
    "benmosher": "Does all this still hold true? \nI ask because I just chained a few data loaders with v11 / DataLoader v2.2.1 and it works. But maybe by luck and not design?. Update: seems like it can still hang with chained loaders and I was just lucking out with the dispatch order until today.. Actually, I think my pattern is no longer really needed, in light of the MappedBatchLoaderWithContext. Up to you if you want to address but I think I will be in good shape if I convert my batch loaders to use context from the BatchLoaderEnvironment.\nCheers!. ",
    "k15a": "Ahh, now I got it. Thank you very much.. ",
    "samkline": "Failing unit test, taken from example 111 in the spec: https://github.com/samkline/graphql-java/commit/9d3a10c27b1ca65542e4baa84af32a62965d3523. Thanks for getting a patch up so quicly @bbakerman !. ",
    "oeil": "thanks @bbakerman for your reply, I actually have not given a try yet - reading the documentation page of graphql-java and relay (http://graphql-java.readthedocs.io/en/latest/relay.html) there is a note saying it only supports \"Relay Classic\" not \"Relay Modern\". \nThis note is probably out-dated... (hopefully)\nI'll try to give it a shot in coming weeks if I can find some time for. Thanks. ",
    "zcourts": "I will create a reproducer this weekend. I've tested and had the same behaviour on both 8.0 and 9.0. That's good to hear! I actually did a quick prototype before I flew (conference for the week). The implementation is beyond rough, but is functional.\nCopy and pasted the impl here https://gist.github.com/zcourts/2a2dc316310b7344794ddef64c6ca690#file-binarytreetyperegistry-java-L226\nLine 226 linked is the biggest atrocity of the impl.\nIt demonstrates the point though and does work. \nIt's obviously a copy and paste of the current type registry modified just for this. Yup, I'll put one together. I'm at a conference this week so may be tight on time but back home weekend so I will do it then.. Got back yesterday haven't had time yet, will send reproducer this week. No problem. Thanks for following up. \nI didn't get the time but asked one of my colleagues and they ruled out graphql-java as the source. They're convinced it's something we're doing. We extend a lot of graphql-java classes and override behaviour for example:\njava\n    return new SchemaParser() {\n      @Override\n      public TypeDefinitionRegistry buildRegistry(Document document) {\n         //here we add the `src` directive on the fly so that later (due to schema stitching see issue 1293) we can tell which app a definition originally came from\n      }\nMy colleague's convinced that we've messed something up here but I'm not sure how that's even possible as the only thing we do is:\njava\nif (definition instanceof UnionTypeDefinition) {\n    definition = ((UnionTypeDefinition) definition).transform(b -> b.directive(dir));\n}\nwhere dir is a Directive created simply with var dir = new Directive(...).\nFor now I'd say close this until we can reproduce it with a test case, tracing the source of unions isn't detrimental for us since the individual types in the union will have src on them.. We can also help with an implementation as we've already got work planned to implement our own as part of our Q1 roadmap. You can reach me at courtney dot robinson at hypi dot io or twitter.com/zcourts. ",
    "EnilPajic": "Thank you very much for bug fix, I appreciate it! \nSuggestion: maaaybe, for performance, StringBuilder#new(int) should be used when creating StringBuilder instance, and very good estimation is the stringValue parameter's size: StringBuilder sb = new StringBuilder(stringValue.size());\nI'll close the issue now.. ",
    "kentago": "Yes Will tryck to move this accordingly. Created in annotations instead... Closing this... . ",
    "kclaes": "Confirmed fixed in 2018-07-04T08-09-58-795c232\n(I searched the issues before creating this one, but I think I couldn't find anything because there's no Issue reflecting this problem, only a PR (?) )\nAny timeframe for a release that contains this fix?. @bbakerman It's not lazy per se -- it makes use of a resolver: GraphQLResolver<SubEntity>, that implements the getters for properties that aren't available when fetching the SubEntities for an Entity in GraphQLResolver<Entity>.\nThink of address being in a different database or service. GraphQL allows us to neatly separate the call to that database in the SubEntity Resolver, and only when we need it.\nNow, when I want to filter on the collection of SubEntities in the GraphQLResolver, this resolver for address hasn't been invoked yet.\nIt's not a lazy issue (the object I return isn't a proxy that would fetch the property like it would in a typical ORM), it's a resolver issue.\nDo you have any suggestions on how to tackle this?. ",
    "freben": "If I remove the exclamation mark (componentInfoLocationUrl: String), it works.. Confirmed working. That's great, thanks! Talk about quick turnaround.. ",
    "ehudon": "This change is already covered in https://github.com/graphql-java/graphql-java/pull/1109. Duplicated of https://github.com/graphql-java/graphql-java/pull/1117. Sorry about that.. ",
    "brockgibson": "Thank you @bbakerman, very helpful information.\nWe are moving towards using the AsyncExecutionStrategy and supplying an ExecutorService in the supplyAsync method as you mention above. In the meantime, it might help to call out in the graphql-java docs some of the information above.\nWe've had issues in the past with getting the ThreadPool setup correctly with the ExecutorServiceExecutionStrategy as well such that it didn't hang and didn't underutilize threads. So deprecating seems reasonable from our viewpoint.\nThanks again!. Thanks @bbakerman. I am indeed using the AsyncDataFetcher.\nAs a little background, my team was previously using the ExecutorServiceExecutionStrategy to parallelize execution of resolvers. We have since been migrating to AsyncExecutionStrategy. As an approach to enabling \"backwards compatibility\" with regard to fetcher behavior, I looked into creating an Instrumentation that instrumented DataFetchers by wrapping them in AsyncDataFetchers, which caused the issue described above.\nWe will instead be doing as you mention above to not combine the two.. ",
    "marceloverdijk": "I always thought that Graphql was also recommending opaque id (not necessary \"type + id\" though).\nBut reading the spec again I cannot find it, even the examples use readable (simple numeric) id's.. so yes better to keep it in the relay name space.. @bbakerman if you like the idea I can make a PR.. OK no problem. Using environment.getSelectionSet().contains(..) is not that long.\n. Thx for feedback and fair point regarding function. I will have a look this week.. @bbakerman I've updated the PR accordingly to your feedback. \nLet me know if you require any other changes or would like to see more tests.. @bbakerman I've updated the javadoc and merged in master to resolve conflicts.\nLet me know if you have any other feedback.. Thanks for merging!. I've updated the javadoc.. The function - and its return meaning - is documented on class level, similar as is done in e.g. SimpleFieldValidation. I can move/copy it to the constructor param if you want. Let me know.. ",
    "sfriberg": "Hi,\nHere is a small example of what I was trying to do.\nBasically the variable is used as part of the input json object.\nhttps://github.com/sfriberg/graphqlScalar\nThanks,\nStaffan. The use case here is a basically a where clause similar to graphcool/prisma, so encoding this by hand would be tedious. So the best solution here would be to autogenerate this for each call. As a first iteration tried to basically have a generic object instead (parse JSON through scalar). Is it possible to have a generic object as input type?. Would it be possible to have the scalar call contain the variable list/map?\nWhich seems to be roughly what is done here,  https://github.com/taion/graphql-type-json.. Hi @bbakerman \nSorry for pinging you. Just wanted to understand if supporting something like   taion/graphql-type-json would be acceptable in graphql-java?\nDid a quick prototype and supporting the regular primitives at least as part of the final scalar parsing is rather non-intrusive as the variable map is available there. Could be done with a default method taking the variable map so it is backwards compatible.\nThe first call scalar parsing that happens as part of verification seems to require a bit more work as the variables weren't part of that call chain (still need to read the code a bit more to understand the flow).\nThanks,\nStaffan. Hi Brad,\nThank you for taking the time to dive into this and your detailed answer. Much appreciated!\nWill simply provide the full object as a parameter.\nI will let you decide if you want to pursue providing the variable map or not to parseLiteral. Feel free to close this as Will-Not-Fix if you don't, or keep it open for tracking if you do.\nThanks,\nStaffan. ",
    "semaphore3000": "Yes, this would be awesome.\nFor the moment I\u00b4m misusing the Context-Object to pass fields from grandparents to grandchildren.. ",
    "michaelschlies": "A title prefixed with WIP may help prevent accidental merges too!. ",
    "rpmcdougall": "I must also mention that I drew some inspiration from https://github.com/donbeave/graphql-java-datetime. So I owe some credit to the authors of that library for some of the implementation I've done.. I suppose another alternative approach (which I am unsure of) is to be opinionated on which implementations of date/datetime etc. are implemented if the consensus is that it would be accepted to add additional dependencies(I didn't think about this immediately when I started working on this PR). For example, only supporting java.util.Date or the joda implementation. I'm not sure this would be a sane approach, but just a thought. I think this more or less gives more credit to the examples into helpers approach in my opinion since there are so many different date/time dependencies one could use as already has been stated.. Would we maybe want to come to a consensus on what a good example module for Date/DateTime etc might look like here and then close this PR and open a feature request issue to discuss what all might make good candidates for an examples/extras project?. Going to close this since there hasn't been much activity on it. Thanks for the earlier discussion everyone.. I totally understand, I'll keep an eye out for any other issues I can attempt to tackle!. ",
    "Salrandin": "Hi, thanks for the advice so far.\nFor our project we are currently leveraging https://github.com/graphql-java/graphql-java-tools.\nThis requires us to make pojos for every type in our schema and also data resolvers.\nWe are creating expanding on our current schema with a few hundred new attributes and creating these pojos and resolvers by hand is cumbersome and seems backwards.  We are trying to use java poet code generation to create these class shells and also use it to make sure our java classes are in sync with our schema as eventually several teams will be touching this code.\nSo in short we would like to do some schema introspection during build time to populate all the necessrary java classes.  We can do this with recursion but wanted to see if its possible to leverage Graphql-java code to do this instead.. ",
    "albertlockett2": "The graphql-java code that causes this runs something like this:\nSchemaGenerator schemaGenerator = new SchemaGenerator();\n// content from above is in schema.gql\nReader schemaFile = this.loadSchema(\"schema.gql\");\nGraphQLSchema schema = schemaGenerator.makeExecutableSchema(typeRegistry, wiring);\nAs far as I can tell, doesn't really matter what's in the runtime wiring. https://github.com/albertlockett2/graphql-java-bug-example I created an example project that causes this exception. Can just mvn test\nHere's the source from the test:\n```java\nimport graphql.TypeResolutionEnvironment;\nimport graphql.schema.GraphQLObjectType;\nimport graphql.schema.GraphQLSchema;\nimport graphql.schema.idl.RuntimeWiring;\nimport graphql.schema.idl.SchemaGenerator;\nimport graphql.schema.idl.SchemaParser;\nimport graphql.schema.idl.TypeDefinitionRegistry;\nimport java.io.File;\nimport junit.framework.Test;\nimport junit.framework.TestCase;\nimport junit.framework.TestSuite;\npublic class AppTest extends TestCase {\npublic AppTest(String testName) {\n    super(testName);\n  }\npublic static Test suite() {\n    return new TestSuite(AppTest.class);\n  }\npublic GraphQLObjectType resolveType(TypeResolutionEnvironment env) {\n    return (GraphQLObjectType) env.getSchema().getType(\"MyImplementingType\"); \n  }\npublic void testApp() {\nTypeDefinitionRegistry types = new SchemaParser().parse(new File(\"src/test/resources/schema.gql\"));\nRuntimeWiring wiring = RuntimeWiring.newRuntimeWiring()\n  .type(\"Query\", typeWiring -> typeWiring.dataFetcher(\"hello\", env -> \"Hello, world\"))\n  .type(\"MyInterface\", typeWiring -> typeWiring.typeResolver(this::resolveType))\n  .build();\n\nGraphQLSchema schema = new SchemaGenerator().makeExecutableSchema(types, wiring);\nSystem.out.println(\"Hello, world!\");\nassertTrue(true);\n\n}\n}\n```\nDoes:\n````\n\nT E S T S\nRunning ca.albertlockett.AppTest\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.261 sec <<< FAILURE!\ntestApp(ca.albertlockett.AppTest)  Time elapsed: 0.252 sec  <<< ERROR!\njava.lang.ClassCastException: graphql.schema.GraphQLTypeReference cannot be cast to graphql.schema.GraphQLInterfaceType\n    at graphql.schema.idl.SchemaGenerator.lambda$buildObjectTypeInterfaces$7(SchemaGenerator.java:381)\n    at java.util.ArrayList.forEach(ArrayList.java:1255)\n    at graphql.schema.idl.SchemaGenerator.buildObjectTypeInterfaces(SchemaGenerator.java:380)\n    at graphql.schema.idl.SchemaGenerator.buildObjectType(SchemaGenerator.java:373)\n    at graphql.schema.idl.SchemaGenerator.buildOutputType(SchemaGenerator.java:296)\n    at graphql.schema.idl.SchemaGenerator.buildField(SchemaGenerator.java:544)\n    at graphql.schema.idl.SchemaGenerator.lambda$buildObjectType$4(SchemaGenerator.java:362)\n    at java.util.ArrayList.forEach(ArrayList.java:1255)\n    at graphql.schema.idl.SchemaGenerator.buildObjectType(SchemaGenerator.java:361)\n    at graphql.schema.idl.SchemaGenerator.buildOutputType(SchemaGenerator.java:296)\n    at graphql.schema.idl.SchemaGenerator.buildField(SchemaGenerator.java:544)\n    at graphql.schema.idl.SchemaGenerator.lambda$buildInterfaceType$10(SchemaGenerator.java:411)\n    at java.util.ArrayList.forEach(ArrayList.java:1255)\n    at graphql.schema.idl.SchemaGenerator.buildInterfaceType(SchemaGenerator.java:410)\n    at graphql.schema.idl.SchemaGenerator.buildOutputType(SchemaGenerator.java:298)\n    at graphql.schema.idl.SchemaGenerator.lambda$buildAdditionalTypes$3(SchemaGenerator.java:261)\n    at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608)\n    at graphql.schema.idl.SchemaGenerator.buildAdditionalTypes(SchemaGenerator.java:253)\n    at graphql.schema.idl.SchemaGenerator.makeExecutableSchemaImpl(SchemaGenerator.java:230)\n    at graphql.schema.idl.SchemaGenerator.makeExecutableSchema(SchemaGenerator.java:176)\n    at ca.albertlockett.AppTest.testApp(AppTest.java:39)\n```. ",
    "josh00007777": "Thanks for looking into it. I have tested in latest branch and It is working as expected. Thanks again.. Ok, Thanks for explaining. I am closing the issue.. ",
    "Me1kaa": "https://github.com/graphql-java/graphql-java/pull/1156. duplicate of https://github.com/graphql-java/graphql-java/pull/1113. duplicate https://github.com/graphql-java/graphql-java/pull/1113. Okay, thank you. Then I'll just recreate context in my PageableDataFetcher and put it into my fetchers chain.\nFor immutability you can use defensive coping in DataFetchingEnvironmentImpl:\n``` java\npublic class DataFetchingEnvironmentImpl implements DataFetchingEnvironment {\n//other code\n    @Override\n    public Map getArguments() {\n        return new LinkedHashMap<>(arguments);\n    }\n@Override\npublic List<Field> getFields() {\n    return new ArrayList<>(fields);\n}\n\n@Override\npublic Map<String, FragmentDefinition> getFragmentsByName() {\n    return new LinkedHashMap<>(fragmentsByName);\n}\n\n}\nor wrapping to unmodifiableMap in ValuesResolver java\npublic class ValuesResolver {\n//other code\n    public Map getArgumentValues(GraphqlFieldVisibility fieldVisibility, List argumentTypes, List arguments, Map variables) {\n        if (argumentTypes.isEmpty()) {\n            return Collections.emptyMap();\n        }\n    Map<String, Object> result = new LinkedHashMap<>();\n    Map<String, Argument> argumentMap = argumentMap(arguments);\n    for (GraphQLArgument fieldArgument : argumentTypes) {\n        String argName = fieldArgument.getName();\n        Argument argument = argumentMap.get(argName);\n        Object value;\n        if (argument != null) {\n            value = coerceValueAst(fieldVisibility, fieldArgument.getType(), argument.getValue(), variables);\n        } else {\n            value = fieldArgument.getDefaultValue();\n        }\n        // only put an arg into the result IF they specified a variable at all or\n        // the default value ended up being something non null\n        if (argumentMap.containsKey(argName) || value != null) {\n            result.put(argName, value);\n        }\n    }\n    return Collections.unmodifiableMap(result);\n}\n\n}\n```\nI don't know the architecture of library well enough yet, so can only give suggestions.\n Solution up to you =). And thank you for answer!. Yeah, sorry. Haven't found that in docs. Anyways, thank you!. @andimarek exactly, that's it. I close the issue.. There is a valuable feature because current deferred has a problem with matching paths. So, is any forecasts of that feature? We want to use it, and here is the question: wait for this PR will be merged or use this branch or maybe do the fork? Do the tests is the main problem with that branch(maybe the community can help)?  And Merry Xmas!. By now, I just downloaded rep. Checkout to that branch and merged it with v11.0 and uploaded it to my company's rep(so after all tests was excellent). That's an easy solution, but I hope that will be merged soon. \n@michaelshiel, so, if you're really in need - do the same.. ",
    "mahkoh": "This PR is based on the last release and therefore has conflicts.\nI've encountered the need for lazy lists in production and have already implemented much simpler support for lazy lists via a custom execution strategy. Such a toy implementation is, however, incompatible with deferred results and probably other features. Therefore I'd like to upstream support for lazy lists if possible.\nI'm also not sure if this implementation does not break any other features that I'm not aware of. In particular, since the code that implements lazy lists is almost completely orthogonal to the existing code, the existing tests do not test the combination of this new feature and the existing features. I've added a test that tests deferred fields in combination with lazy lists.. To summarize what users have to do to use this feature:\n\nAdd a custom Jackson serializer for LazyList objects\nAdd a custom Jackson serializer for ExecutionResult objects\nReturn a LazyList object from the DataFetcher\n\nEverything else is handled transparently.. I haven't written any documentation yet and I'd probably have to write more tests that test the interaction between this and other features (though I don't know which features are most likely to interact badly with lazy completion.)\nBut before I do this: Could you tell me if you're interested in merging support for lazy completion?. ",
    "hanbingjiao": "@bbakerman If we deprecate ExecutorServiceExecutionStrategy, how could we handle two API queries parallel?\nSuch as the following the request:\nquery QueryType($id1: String!, $id2: String!) {\n a1: getData(id: $id1) {\n    resultCode\n    data {\n      abc\n    }\n  }\n  a2: getData(id: $id2) {\n    resultCode\n    data {\n      abc\n    }\n  }\n}. ",
    "spadmanaban16": "Any updates? For the same reason, am also using the deprecated ExecutorServiceExecutionStrategy.. ",
    "kdlan": "I have got following Exception . It not happens everytime even I change the loop times from 100 to 10000\n```\ngraphql.execution.instrumentation.dataloader.Issue1178DataLoaderDispatchTest > shouldn't dispatch twice in multithreaded env STANDARD_ERROR\n    [pool-1-thread-2] ERROR graphql.GraphQL - Execution 'c81f6f8a-f7bc-4041-8a12-4edaddfc1b42' threw exception when executing : query : '\n                    query {\n                        getTodos { __typename id\n                            related { id __typename\n                                related { id __typename\n                                    related2 { id __typename\n                                        related2 { id __typename\n                                            related { id __typename }\n                                        }\n                                    }\n                                }\n                            }\n                            related2 { id __typename\n                                related2 { id __typename\n                                    related { id __typename\n                                        related { id __typename\n                                            related2 { id __typename\n                                                related2 { id __typename\n                                                    related { id __typename }\n                                                    related2 { id __typename\n                                                        related2 { id __typename\n                                                            related { id __typename }\n                                                        }\n                                                    }\n                                                }\n                                                related { id __typename }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }'. variables '{}'\n    java.util.concurrent.CompletionException: graphql.AssertException: Internal error: should never happen: level 6 already dispatched\n        at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)\n        at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)\n        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:769)\n        at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)\n        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)\n        at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)\n        at graphql.execution.Async.lambda$each$0(Async.java:38)\n        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)\n        at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)\n        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)\n        at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)\n        at org.dataloader.DataLoader.lambda$dispatchQueueBatch$3(DataLoader.java:335)\n        at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)\n        at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)\n        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)\n        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1595)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n    Caused by: graphql.AssertException: Internal error: should never happen: level 6 already dispatched\n        at graphql.Assert.assertShouldNeverHappen(Assert.java:26)\n        at graphql.execution.instrumentation.dataloader.FieldLevelTrackingApproach$CallStack.dispatchIfNotDispatchedBefore(FieldLevelTrackingApproach.java:101)\n        at graphql.execution.instrumentation.dataloader.FieldLevelTrackingApproach.dispatchIfNeeded(FieldLevelTrackingApproach.java:235)\n        at graphql.execution.instrumentation.dataloader.FieldLevelTrackingApproach.handleOnFieldValuesInfo(FieldLevelTrackingApproach.java:177)\n        at graphql.execution.instrumentation.dataloader.FieldLevelTrackingApproach.access$000(FieldLevelTrackingApproach.java:32)\n        at graphql.execution.instrumentation.dataloader.FieldLevelTrackingApproach$1.onFieldValuesInfo(FieldLevelTrackingApproach.java:154)\n        at graphql.execution.AsyncExecutionStrategy.lambda$execute$1(AsyncExecutionStrategy.java:83)\n        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)\n        ... 16 more\ngraphql.execution.instrumentation.dataloader.Issue1178DataLoaderDispatchTest > shouldn't dispatch twice in multithreaded env FAILED\n    graphql.AssertException\n1 test completed, 1 failed\n```. I add some logging on method for debug, following is the output\n[pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - despatch needed, level: 3\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - dispatchIfNotDispatchedBefore, level:3\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[0]/related2/related2/id\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[0]/related/related/id\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[0]/related2/related2/__typename\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[0]/related/related/__typename\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[0]/related2/related2/related\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[0]/related/related/related2\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[0]/related2\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[0]/related\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[1]/related2/related2/id\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[1]/related/related/id\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[1]/related2/related2/__typename\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[1]/related/related/__typename\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[1]/related/related/related2\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[1]/related2/related2/related\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[1]/related\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[1]/related2\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[2]/related/related/id\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[2]/related2/related2/id\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[2]/related/related/__typename\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[2]/related2/related2/__typename\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[2]/related/related/related2\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[2]/related2/related2/related\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[2]/related2\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[2]/related\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[3]/related2/related2/id\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[3]/related/related/id\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[3]/related/related/__typename\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[3]/related2/related2/__typename\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[3]/related/related/related2\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[3]/related2/related2/related\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[3]/related2\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[3]/related\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedFetchCount, level:4, count:3\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseHappenedStrategyCalls, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[4]/related2/related2/id\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[4]/related/related/id\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[4]/related2/related2/__typename\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[4]/related/related/__typename\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[4]/related2/related2/related\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginFieldFetch.onDispatched, path /getTodos[4]/related/related/related2\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseFetchCount, level:4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[4]/related\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - beginExecutionStrategy.onFieldValuesInfo, path /getTodos[4]/related2\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - increaseExpectedStrategyCalls, level:4, count:1\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - despatch needed, level: 4\n    [pool-1-thread-2] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - dispatchIfNotDispatchedBefore, level:4\n    [pool-1-thread-4] INFO graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation - despatch needed, level: 4. Synchronized on dispatchIfNeeded could not avoid race condition.\njava\n     private void handleOnFieldValuesInfo(List<FieldValueInfo> fieldValueInfoList, CallStack callStack, int \ncurLevel) {\n        callStack.increaseHappenedOnFieldValueCalls(curLevel);\n        int expectedStrategyCalls = 0;\n        for (FieldValueInfo fieldValueInfo : fieldValueInfoList) {\n            if (fieldValueInfo.getCompleteValueType() == FieldValueInfo.CompleteValueType.OBJECT) {\n                expectedStrategyCalls++;\n            } else if (fieldValueInfo.getCompleteValueType() == FieldValueInfo.CompleteValueType.LIST) {\n                expectedStrategyCalls += getCountForList(fieldValueInfo);\n            }\n        }\n        callStack.increaseExpectedStrategyCalls(curLevel + 1, expectedStrategyCalls);\n        dispatchIfNeeded(callStack, curLevel + 1);\n    }\nFor example if only lock on dispatchIfNeeded. When 2 thread enter handleOnFieldValuesInfo,  the second thread call increaseHappenedOnFieldValueCalls and increaseExpectedStrategyCalls  just before first one reach the dispatchIfNeeded. Now the first thread will call dispatchIfNotDispatchedBefore and second will call dispatchIfNotDispatchedBefore again.\nWe should add synchronization on the whole callstack state change and check.\n```java\n    private void handleOnFieldValuesInfo(List fieldValueInfoList, CallStack callStack, int curLevel) {\n        synchronized (callStack) {\n            callStack.increaseHappenedOnFieldValueCalls(curLevel);\n            int expectedStrategyCalls = 0;\n            for (FieldValueInfo fieldValueInfo : fieldValueInfoList) {\n                if (fieldValueInfo.getCompleteValueType() == FieldValueInfo.CompleteValueType.OBJECT) {\n                    expectedStrategyCalls++;\n                } else if (fieldValueInfo.getCompleteValueType() == FieldValueInfo.CompleteValueType.LIST) {\n                    expectedStrategyCalls += getCountForList(fieldValueInfo);\n                }\n            }\n            callStack.increaseExpectedStrategyCalls(curLevel + 1, expectedStrategyCalls);\n            dispatchIfNeeded(callStack, curLevel + 1);\n        }\n    }\npublic InstrumentationContext<Object> beginFieldFetch(InstrumentationFieldFetchParameters parameters) {\n    CallStack callStack = parameters.getInstrumentationState();\n    ExecutionPath path = parameters.getEnvironment().getFieldTypeInfo().getPath();\n    int level = path.getLevel();\n    return new InstrumentationContext<Object>() {\n\n        @Override\n        public void onDispatched(CompletableFuture result) {\n            synchronized (callStack) {\n                callStack.increaseFetchCount(level);\n                dispatchIfNeeded(callStack, level);\n            }\n        }\n\n        @Override\n        public void onCompleted(Object result, Throwable t) {\n        }\n    };\n}\n\n```. Or maybe we can remove the Assertion, just debug logging it and return. query directive may implement by Instrumentation\npublic class DirectiveInstrumentation extends SimpleInstrumentation {\n    @Override\n    public DataFetcher<?> instrumentDataFetcher(DataFetcher<?> dataFetcher,\n            InstrumentationFieldFetchParameters parameters) {\n        List<Directive> list = parameters.getEnvironment().getField().getDirectives();\n        if (!list.isEmpty()) {\n            return new DirectiveDataFetcher(dataFetcher);\n        }\n        return super.instrumentDataFetcher(dataFetcher, parameters);\n    }\n}\nand define a new DirectiveDataFetcher to implement your UPPERCASING implmenttion.\nI just found it is  a possible way to implements it and can not give a example now. ",
    "larrybud": "I am doing something along these lines with Jooq. \nI define a mapping between GraphQL types/interfaces and SQL columns or expressions. Joins are supported. This mapping is executed against the selection set, and the one-to-one relationship traversals are flattened out into a single SQL query. Since the selection set is used to extract the columns to query, only the requested fields are retrieved. The query result data is then 'un-flattened' and returned to the GraphQL layer. \nIt also supports the relay connection model with filtering and paging done in the DB. Quite a lot of work, really, and still in development. \nI had not heard of Calcite. . The basic idea is to extract a tree of selections from DataFetchingEnvironment, intersect that with a hierarchial mapping from GraphQL labels to fields, and combine it with a base query. \nI am using JOOQ, Postgres and Kotlin. The uppercase fields below are JOOQ generated classes and fields. In the example code below I will use the Star Wars schema, but I will add the Planet object in order to demonstrate one-to-ones, and a Hobby object to demonstrate 'embedded' types. \n```graphql\nthis is not the entire schema; see the link above\ntype Planet {\n  id: ID!\n  name: String\n}\ntype Hobby {\n  name: String\n  rank: Int\n}\ntype Human implements Character {\n  # existing fields go here...\n  # make homePlanet a reference to Planet\n  homePlanet: Planet\n  hobby: Hobby\n}\n```\nImagine that you had the following schema:\n```sql\ncreate table planet as (\n  id                serial            primary key,\n  name              text\n);\ncreate type character_type as enum { 'Droid', 'Human' };\ncreate table character as (\n  id               serial             primary key,\n  type             character_type     not null,\n  name             text               not null,\n  secret_backstory text\n);\ncreate table droid as (\n  id               integer            primary key references character,\n  primary_function text\n);\ncreate table human as (\n  id               integer            primary key references character,\n  home_planet      integer            references planet,\n  -- these fields will be extracted into an embedded GraphQL type\n  hobby_name       text,\n  hobby_rank       integer\n);\n```\nNow I create bindings from GraphQL labels to fields. If you are not familiar with Kotlin, this may look a little strange, but it is really just a type-safe builder that constructs a tree. Again, the all-caps symbols are JOOQ generated tables and fields. \n```kotlin\nval planetBindings = objectBindings(PLANET) {\n    \"id\"..PLANET.ID\n    \"name\"..PLANET.NAME\n}\nval characterBindings = objectBindings(\n    CHARACTER\n        .leftJoin(DROID).using(CHARACTER.ID)\n        .leftJoin(HUMAN).using(CHARACTER.ID)\n        .leftJoin(PLANET).on(HUMAN.HOME_PLANET.eq(PLANET.ID))\n) {\n  // .always means that the field will always be fetched, even if it is not asked for\n  \"id\".always..CHARACTER.ID\n  // type is not a field in the GraphQL interface, but is needed for type resolution downstream\n  \"type\".always..CHARACTER.TYPE\n\"name\"..CHARACTER.NAME\n  \"secretBackstory\"..CHARACTER.SECRET_BACKSTORY\n// droid fields\n  \"primaryFunction\"..DROID.PRIMARY_FUNCTION\n// human fields\n// this is a one-to-one association\n  \"homePlanet\"..planetBindings {\n      // join condition\n      \"id\"..HUMAN.PLANET\n  }\n  // this is an embedded/composite field\n  \"hobby\" {\n    \"name\"..HUMAN.HOBBY_NAME\n    \"rank\"..HUMAN.HOBBY_RANK\n  }\n}\n```\nThe bindings are used to create 'fetchers', which are invoked by the wiring. \nThis:\ngraphql\nquery {\n    allCharacters {\n        id\n        name\n        ... on Human {\n            homePlanet {\n                name\n            }\n            hobby {\n                rank\n            }\n        }\n    }\n}\nwill produce something like:\nsql\nselect c.id as \"id\",\n       c.type as \"type\",\n       c.name as \"name\",\n       h.hobby_rank as \"hobby.rank\",\n       p.name as \"homePlanet.name\"\nfrom character as c left join\n     droid as d on c.id = d.id left join\n     human as h on c.id = h.id left join\n     (select id, name from planet) as p on h.home_planet = p.id\nI am counting on Postgres join elimination. This means that a left join will be 'dropped' if it can't possibly affect the query outcome. So if I select no fields from DROID I will not incur the cost of joining against it (N.B. only true if the join is on a unique key). \nFields in the query are aliased using the full graphql label path, e.g. hobby.name. After query execution, the result record(s) are transformed into trees (maps of maps, which graphql-java handles) by splitting on the periods. \nOne-to-ones are handled specially. If only the join field is requested, e.g. homePlanet.id, then no extra join is performed; HUMAN.PLANET is sufficient. If other planet fields are requested, then planetBindings is invoked with the relevant sub-selections, and the resulting query is joined against as a table. \nOne-to-manys are not supported in bindings, quite intentionally. These are handled by explicit data fetchers in the wiring. \nThe fields in the bindings do not have to be simple table fields, but can be any SQL expression. For example, if the GraphQL Character.name field was stored in the droid and human tables rather than in character, you could define the name mapping as a case statement:\nkotlin\n\"name\"..choose(CHARACTER.TYPE)\n    .`when`(CharacterType.DROID, DROID.NAME)\n    .otherwise(HUMAN.NAME)\nObviously, the devil's in the details, and it takes a fair amount of code to fit all the pieces together. All of this was done for my employer, so I can't post the code without permission, but I'm sure they'd let me do so, if anyone's interested. Priorities shifted while I was working on this. so it's rough, and not well-tested. \nThere's also a filtering and sorting aspect at the GraphQL layer that gets mapped to the bindings. One can, for example, do order-bys with arbitrary SQL expressions. Finally, there's paging using the Relay connection model, which was probably more work than all of the above. Let me know if you'd like details on any of that. . ",
    "patrox": "@larrybud Can you please share more details about how you actually did it ? As it exactly matches my case - I would like to use graphql in order to provide a general interface for the client to fetch data which might be located in more than one table - so a join between them is needed, but on the other hand, there are cases when the requested fields will come from just a single table, so I would like to avoid joining it with another table as it's not needed.\nI assume I will have to implement DataFetcher for each part of data which will come from a separate table, but if a customer requests data which comes from different DB tables, is it possible to generate a single sql query which will join both tables and will fetch the data in one go ? As I would like to avoid getting it in separate calls.. Thanks @larrybud for a very comprehensive description - I'm still digesting it ! :)\nThe join elimination seems to be quite promising.. ",
    "tsroka": "@andimarek while working on nadel, i needed to traverse AST using NodeTraverser and got NPE. Will fix formatting,. > nice ... see my comments about naming\nRenamed as per your comments and added #toString. This function does not look very useful. Is that a convention in gql-java to accept builders?. maybe annotate with ThreadSafe? Or add comment that it is thread safe?. just wondering if it would be easier to understand the api if the method name would be something like .defaultContext in this case, as for me it would be hard to understand which one should be used: context with object or context with builder (without looking at the docs). just a small thing to consider, given the number of the constructor args, maybe it will be more manageable to pass builder instance here and use it instead (assign fields from builder fields directly) . AFAIK any other instrumentation methods cannot change state. instrumentDocumentAndVariables feels inconsistent with the rest of Instrumentation interface. Should it not be a separate interface with Transformation in its name?. I would say,  return Collections.unmodifiableMap here, since this class is supposed to be immutable?. Awesome, that will make Nadel code much nicer. wow, that wasn't intended to go into the PR. good catch. I am not sure. If you put wrong query (e.g. with fragment with wrong type) you will get weird NPE that will not tell you what's going on.. fixed. fixed. Are we going to extract this method as well somewhere else? Also one thing that is missing in QueryVisitor that we need in Nadel is being able to visit FragmentDefinition (needed so that we can change type condition on the fragment). ",
    "tschuettel": "Thx for merging. Any idea when this will be released?. ",
    "tbo-axelor": "i want to add reference field like \npublic GraphQLInputObjectType getGraphqlInputType(EntityType<?> entityType) {\n        GraphQLInputObjectType.Builder inputType = GraphQLInputObjectType.newInputObject().name(entityType.getName().toLowerCase());\n        inputType.field(GraphQLInputObjectField.newInputObjectField().name(\"testList\").type(GraphQLTypeReference.typeRef(\"Address\"))).build();\n        return inputType.build();\n    }\nbut it give error like \njava.lang.ClassCastException: graphql.schema.GraphQLObjectType cannot be cast to graphql.schema.GraphQLInputType\nso how to done referencetype in GraphqlInputType ??. ",
    "AndreasVoellmy": "Great! Can you post a link to your PR?. ",
    "Togrias": "Hi,\nThanks for your reply. A common (?) use-case would be when the graphql schema does not match the database schema. A single object can require data from multiple tables to be fetched. \nOne example is a many-to-many relationship. A \"USER\" reads many \"BOOKS\". A \"BOOK\" has many \"READERS\". Right now, if we want to use dataloaders, the results of one dataloader must feed into another dataloader. We must include the intermediary associative table \"USERS_BOOKS\" as a GraphQLObjectType, which may not be desirable.\nideally we can do this (pardon my kotlin):\nval userBooks = userBooksLoader.load(x).await()\nval books = userBooks.map { booksLoader.load(it.books).await() }\nAnother example is a relational database where one table represents a \"main\" object and there are many other tables which are subclasses of that table, there is a table for \"PERSON\" that has name and id, but stores information on other tables like \"USER_WITH_OCCUPATION\" and \"USER_WITH_HEALTHCARE_INFORMATION\". Sometimes we don't want to expose the subclasses as fragments.\nval user = usersLoader.load(x).await()\nval userWithOccupation = userWithOccupationLoader.load(user.occupation).await()\nval userWithAllTheInformation = new UserWithAllTheInformation(user, userWithOccupation, ...)\nAnd a third example is as you mentioned if a dataloader needs to chain from the results of another.\nI think we just need to wrap the load function:\nin DataLoader:\nsuspend fun asyncLoad(id: K, callback: {with onAwait() and onComplete() callbacks}) {\n//wrap the original CompletableFuture with a CompletableDeferred (if kotlin) / CompletableFuture (if java) that has the aforementioned callbacks.\n}\nclass WrappedCompletable(original: CompletableDeferred, callbacks) {\n  suspend fun await() {\n    onAwait()\n    return original.await().also { onCompleted() }\n  }\n}\nThen pass the callbacks to the instrumentation to count the number of delayed fields.\nA side benefit is that execution can be performed asynchronously instead of level by level.. Thank you for your reply.\nI'm using graphql-java on a Kotlin project. Turns out that it's not too difficult in Kotlin to implement a node.js-style nextTick() function to queue dispatches. Kotlin has its own async framework.\nThen I just have to re-write AsyncExecutionStrategy and DataLoader to use Kotlin's async framework rather than the Java standard CompletableFuture framework. The resulting dataloader would function just as intuitively as the node.js version.\nI guess my solution is more relevant for people who use Kotlin. Not sure how many of us are here.. I saw that you reopened this issue and thought to chime in.\nIf the desired eventual outcome is to implement the node.js functionality, I would suggest a centralised dispatcher. It makes sense to make DataLoaderDispatchInstrumentation a first-class entity rather than an optional one.\n\nDeprecate using CompletableFuture static methods like CompletableFuture.supplyAsync() in DataFetchers.\nMove the above methods into DataFetchingEnvironment. Eg. DataFetchingEnvironment.supplyAsync().\nThe new methods spawn an extension of CompletableFuture that holds a reference to the Instrumentation. methods such as whenComplete() would also notify the centralised Instrumentation.\nThe ExecutionStrategy would also have to use the centralised dispatcher to execute asynchronous operations.\nThe DataLoaderDispatchInstrumentation instance is now able to monitor all asynchronous operations and implement process.nextTick().\n\nI'm using a similar solution but with Kotlin's coroutine framework. I'm not very familiar with Java so please forgive me for mistakes.. ",
    "guy-klebanov": "Hey all,\nIs there any solution in Java (graphql) for chained DataLoaders ?\nAnyone done it and can share (don't want to reinvent the wheel) ?\nThanks Guy.. ",
    "helfer": "I have exactly the same problem: I'm fetching a set of objects, and then need to check permissions for each of these objects via a separate call to another service. I can't do that efficiently with the current data loaders. As you said, I could hack something together that would kind of work, but it isn't nearly as efficient, adds quite a bit of complexity and requires a deeper understanding of how queries are resolved in GraphQL, and how graphql-java orchestrates the loaders. I don't feel comfortable going down that route given that many different teams at my company will be contributing to the GraphQL schema, and I can't expect everyone to go through the trouble of wiring up data fetchers and dispatching them manually. Ideally, whether or not batching is done should only need to be known at the resolver (data fetcher) level. If batching is desired, implement a batched data fetcher. If batching is not desired, implement a normal data fetcher.\nSo, how hard would it be to implement something along the lines of Sangria's DeferredResolver, i.e.  DeferredDataFetcher? I think that's a much better abstraction than having to add a second concept of loaders, having to construct them for every query, passing them through the context and then calling them in the resolver.\nDeferred data fetchers could have a method called getBatch, whose signature could be just like get of a normal data fetcher, except that it would take a list of DataFetchingEnvironment. To provide extra convenience for the common use-case where only the source is needed (eg. fetching a list of related objects by their id), a function could be provided to extract the sources from the BatchDataFetchingEnvironment.\nIf the resolver is inherently batched, all the problems of figuring out when to dispatch and whether to dispatch manually go away, because inside the resolver everything is batched, so firing off a second batch async request is as simple as chaining the promise.\nI'm not familiar with the internals of graphql-java's execution engine, but I assume that since it's already aware of levels there is a place in the code where the executor is aware of all the fields at a given level, and could batch together all calls to a given resolver (aka data fetcher) if the field has a DeferredDataFetcher.. ",
    "sujivisva": "Hi,\nThanks a lot for your reply.\nWhatever you have explained is a directive which needs to be declared in the SDL and needs to be applied on the respective fields. I understand the authorization concept.\nBut in my case, I just want to declare the directive and implementation in a programmatic way and leave the choice of where to apply the directives, to the client who makes the query call. \n\"So I just need QUERY DIRECTIVES\"\nFor an example as I mentioned in my original question, UPPERCASING of fields can be done using custom directive. Client can decide on where to apply the UPPERCASING directives. \nAnd also, I am using GraphQL SPQR framework for schema-less approach in which I have found a way to hook GraphQLDirective objects to the GraphQLSchemaGenerator class. It doesn't support adding directives via RuntimeWiring like you mentioned.\nRuntimeWiring runtimeWiring = RuntimeWiring.newRuntimeWiring()\n            .directive(\"dateFormat\", new DateFormatting())\n            .build();\nAnd moreover, I found bit confused of GraphQLDirective class. Could you please let me know what is the purpose of this class? I am able to define a custom directive using this class like below.\nGraphQLDirective upperCaseDirective = GraphQLDirective.newDirective()\n.name(\"uppercase\")\n.description(\"Directs the executor to uppercase this field\")\n.validLocations(FRAGMENT_SPREAD, INLINE_FRAGMENT, FIELD)\n.build();\nBut I am unable to find a way to hook the implementation logic to this GraphQLDirective object. I tried my best to explore the graphql-java framework to find out where exactly, the implementation for @include & @skip directives are hooked but I couldn't. I have seen those directives are just declared in graphql.schema.GraphQLDirective.Directives class\npublic static final GraphQLDirective IncludeDirective = GraphQLDirective.newDirective().......\npublic static final GraphQLDirective SkipDirective = GraphQLDirective.newDirective().......\nBut I couldn't find where exactly the logic for include & skip directives are implemented. So this is my actual question. If I DECLARE a custom directive using GraphQLDirective class, how can I DEFINE the same (Add IMPLEMENTATION to the custom directive object)?\n. ",
    "gipeshka": "@sujivisva regarding your question on skip and include directives, apparently they are implemented in ConditionalNodes and are used in QueryTraversal, see eg line 224 with shouldInclude. I think validation should throw some standard exception to be handled somewhere up.\nI see your point regarding the validation and transformation directives. Not sure what is InputFieldValidationEnvironment here. I think it makes sense to provide a generic InputFieldBehaviour with two descendants to represent directive behaviour with ValidationInputFieldBehaviour and TransformationInputFieldBehaviour like \n```\ninterface InputFieldBehaviour {\n    Object apply(Object value);\n}\nabstract class ValidationInputFieldBehaviour implements InputFieldBehaviour {\n    /*\n     * @throws GraphQLDirectiveValidationException in case data is invalid\n     /\n    abstract protected void validate(Object value);\nObject apply(Object value) {\n    validate(value);\n    return value;\n}\n\n}\nabstract class TransformationInputFieldBehaviour implements InputFieldBehaviour {\n    abstract protected Object transform(Object value);\nObject apply(Object value) {\n    return transform(value);\n}\n\n}\n```\nWiring seems valid to me using SchemaDirectiveWiring since it is still wiring of behaviour to directives, it is still applied when building the schema. When one understands the approach with SchemaDirectiveWiring it looks quite easy to apply it again for directives, wdyt?. ",
    "AnkitaBasu": "@bbakerman  i have used the above example in a Spring boot application which uses the graphql starter\n    <dependency>\n        <groupId>com.graphql-java</groupId>\n        <artifactId>graphql-java</artifactId>\n        <version>11.0</version>\n    </dependency>\n    <dependency>\n        <groupId>com.graphql-java</groupId>\n        <artifactId>graphql-java-tools</artifactId>\n        <version>5.2.3</version>\n    </dependency>\n    <dependency>\n        <groupId>com.graphql-java</groupId>\n        <artifactId>graphql-java-servlet</artifactId>\n        <version>6.1.2</version>\n    </dependency>\n    <dependency>\n        <groupId>com.graphql-java</groupId>\n        <artifactId>graphql-spring-boot-starter</artifactId>\n        <version>5.0.2</version>\n    </dependency>\n    <dependency>\n        <groupId>com.graphql-java</groupId>\n        <artifactId>graphiql-spring-boot-starter</artifactId>\n        <version>5.0.2</version>\n    </dependency>\n\nHowever the directive is not getting applied to the fields, i tried to put it in debug mode and noticed that the control never goes to the Directive class. How do i register it? is it expected to register it self automatically in spring boot ?\nAlso below is how i used it in .graphqls file\ndirective @auth(role : String!) on FIELD_DEFINITION\nschema {\n query: Query\n}\ntype Query {\n allBooks: [Book]\n book(id: String): Book\n}\ntype Book {\n  isn: String @auth(role : \"manager\")\n  title: String\n  publisher: String\n  publishedDate: String\n}\nThanks. ",
    "mstachniuk": "Your right. I missed that in my codebase. Fortunately, the description in GraphQLScalarType can be null.\nThanks for the explanation!. ",
    "lyuanx": "Hi,\nYou don't understand what I mean.\nI mean that graphql.execute(....) return data is not null if DataFetcher return java bean\ngraphql.execute(...) return data is null if DataFetcher return json data\n(java bean and json data has the same datastruct)\n!!! now I wanna DataFetcher reutrn json data but does't work\ncan you resolve it, thank you very much. Thank you, I fix it . ",
    "michaelshiel": "I'm wondering what the status of this branch is? It's very important for my project (and seems to work well). Would you like help cleaning/documenting to get it merged? Just point me in the right direction \ud83d\udc4d . ",
    "ashu-walmart": "Thanks for the response @andimarek. I will create a test case for this and see if I can reproduce the error. In the application I am working on, the batched data loader seems to have inconsistencies in batching requests for the top level aliased fields. The test in my application has 3 top level fields but only two get batched together in the first dispatch and the third one is a seperate dispatch.. https://gist.github.com/ashu-walmart/8f8c40b6fdd649d03db95b5b5cb78437. Here is the failing test case I created. Is the test and expectation correct?. @bbakerman Yes the test is failing on expectedBatchedKeys assertion.. As far as I can tell. https://github.com/graphql-java/graphql-java/blob/master/src/main/java/graphql/execution/instrumentation/dataloader/FieldLevelTrackingApproach.java#L163 is the issue where fieldFetchCount is incremented before dispatch for level 1.. I cant build locally without this change because there is a space in my local path. I have tried all I can with quotes and such but if there is a better Gradle alternative available to this, I am happy to learn.. ",
    "osi": "aye will do\n-- \n(peter.royal|osi)@pobox.com - http://fotap.org/~osi\n\nOn Sep 21, 2018, at 7:40 PM, Andreas Marek notifications@github.com wrote:\nthanks @osi,\ncan you create a PR for that? That would be really create. Thanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Nothing is required. It's been implemented at https://github.com/graphql-java-kickstart/graphql-java-servlet/pull/102 .. the payload transformation happens before entering the execution engine.. \n",
    "mattes3": "Oh, I just found the answer: https://github.com/graphql-java/graphql-java-http-example/blob/master/src/main/java/com/graphql/example/http/StarWarsWiring.java\nThe DataLoader registry is in the Context object which allows keeping the DataLoaders per-request.. I will write something in the docs and send you a PR.. PR #1241 is ready.. OK, great! Curious how you'll change the tone (because English is my second language). Keep me posted when it's in the docs.. ",
    "dnebing": "While it is exposed by SPQR, I think it exposes a core issue of the GraphQL builders themselves.\nThe builder design pattern allows you to pass the builder around so that other pieces can contribute.  It is only once the final \"build/create/generate\" step is done that things are finalized.\nWith the GraphQLSchema.Builder class, that is not the case.  With types, you can pass the builder around and add types in.  But not so with the queues, mutations and subscriptions.\nOpening them up by making them public is the least-invasive way of supporting passing the builder around so multiple components can contribute.  Perhaps a better approach would be to enhance to include addQuery(), addMutation(), addSubscription() so the builder would support contribution from multiple providers...\nIs that something you'd be open to?  I'd be happy to add that if that would be acceptable.... The additionalType() is exactly the kind of change I was talking about though.  The current builder half-supports being able to later submit additional data to be used in the build; I get why you want to exclude the accessor + builder pattern, so how about going all in and allow for other add() kind of methods?. With graphql-java-servlet, you don't care about thread safety?  That sounds kind of concerning...\nI would have guessed that since you have graphql-java-servlet as well as its OsgiGraphQLHttpServlet, that you would have the ability to support many threads as well as many class loaders.... ",
    "senzzzi": "@bbakerman that did the trick, thanks a lot for help! This was not an issue at all.. ",
    "sra-013": "According to my understanding, if I want to fetch data based on the current user credentials, I'll have to use the getContext() method of the DataFetchingEnvironment. However, I am unable to figure out how to actually call the method and initialize the context.  . \"Some people use a dependency framework that injects context into data fetchers automatically and hence don\u2019t need to use this.\" I am using Spring so according to the above statement, I would not have to inject context explicitly. How do I go about it in that case?. Thanks!. Thanks!\nSo, currently I am following the current piece of documentation because that is what suits best to my needs:\nhttps://www.graphql-java.com/documentation/v11/data-mapping/\nI want data from multiple sources to be unified. I have created separate getters for each field inside the 'get()' method. Now I do understand that the dataFetchingEnvironment variable holds details on the fields to be fetched and that each field is mapped to its POJO getter. \nMy doubt is that after coming inside the get() method, how does my fetcher look at getters that I have created for my fields.\nSo, for example, let's take the case given in the above link and let's say that I want only the cost info and not the tax info so my query looks something like (but I still have the taxinfo mapping of course):\nquery ProductQuery {\n        products(match : \"Paper*\")\n        {\n            id, name, cost\n        }\n    }\nHow does my fetcher know that it should not be fetching the tax info?. ",
    "pete-proton": "raised this small one 2 weeks ago - just one reply, which seemed to me like the PR was not looked at thoroughly. could you tell me if there is anything needs to be done from you PoV? \nTBH feel a little discouraged raising further PR's due to this one left in limbo. . thank you! do I need to reformat still? sorry for the late reply. sure, sorry took a while, but finally created https://github.com/graphql-java/graphql-java/pull/1323. thanks for the quick response. this is to replace\nvaluesByParent.get(env.getParentEnvironment()).add(value);\noldValue is the accumulator, which is an analogue of the List. \nbefore\nlist.add(value)\nafter\noldValue + value\ndoes this make sense?. ",
    "doxavore": "To be clear, the v10 documentation for batching suggests using the deprecated BatchLoader, and as of today, we're not aware of a way to get the WHERE id in (1, 2, 4) functionality using non-deprecated features? I haven't seen anything else to suggest how one might do this without custom List<Long>-style loaders that won't respect the cache.. ",
    "mcbain": "I cannot get it running. What should the schema look like?\ntype Mutation {\n  singleUpload(file: Upload!): Boolean!\n}\nWhat is Upload supposed to be? I tried already input, scalar, none worked.\nhttps://github.com/jaydenseric/graphql-multipart-request-spec\ncurl localhost:8080/graphql   -F operations='{ \"query\": \"mutation ($file: Upload!) { singleUpload(file: $file)  }\", \"variables\": { \"file\": nulmap='{ \"0\": [\"variables.file\"] }'   -F 0=@pom.xml. figured it out \n```\n @Bean\n  GraphQLScalarType upload() {\n    return graphql.servlet.ApolloScalars.Upload;\n  }\n```. ",
    "fforw": "Improved? It ignores a duplicate definition!\nJust check if that key is already present in your map. \nWhat reason could there be to ignore such fundamental issues in a schema definition?. Did I miss the documentation of this behavior? If not it seems that is something that should be documented clearly.. I tested the branch with the current grade build from master and the bug does not longer occur, so I guess it's fixed by #1386 . ",
    "xenoterracide": "I believe it was generated by introspection via Postgraphile.. it may be of interest.... apollo-android generates java classes, but when it looks at the schema, it only generates the one you need for you query, maybe there could be an import like/ish this.... also I tried doing this (and Instant), with the extended types available at runtime... but it's still saying I need to implement the class (note, I modified types too)\nscalar DateTime. Exception in thread \"Apollo Dispatcher\" java.lang.IllegalArgumentException: Can't map GraphQL type: Datetime to: class java.lang.Object. Did you forget to add custom type adapter?\n    at com.apollographql.apollo.response.ScalarTypeAdapters.adapterFor(ScalarTypeAdapters.java:29)\n    at com.apollographql.apollo.internal.json.InputFieldJsonWriter.writeCustom(InputFieldJsonWriter.java:83)\nhmmm.... \n```\n    GraphQLSchema schema( @Value( \"classpath:schema.graphqls\" ) Reader schema ) {\n        TypeDefinitionRegistry typeDefs = new SchemaParser().parse( schema );\n        RuntimeWiring wiring\n                = RuntimeWiring.newRuntimeWiring()\n                .scalar( new DateTimeScalar() )\n                .build();\n        return new SchemaGenerator().makeExecutableSchema( typeDefs, wiring );\n    }\n````\nso that isn't enough?. note, I don't see that the documentation for either clearly explain how to add a value from the extended library, which is presumably different/simpler. Note the exception I mentioned above, doesn't happen until runtime.... oh nvm, that exception is coming from apollo, still that documentation could be clearer... I presume this is the actual right way to do it.\nGraphQLSchema schema( @Value( \"classpath:schema.graphqls\" ) Reader schema ) {\n        TypeDefinitionRegistry typeDefs = new SchemaParser().parse( schema );\n        RuntimeWiring wiring\n                = RuntimeWiring.newRuntimeWiring()\n                .scalar( ExtendedScalars.newAliasedScalar( \"Datetime\" )\n                        .aliasedScalar( ExtendedScalars.DateTime ).build() )\n                .build();\n        return new SchemaGenerator().makeExecutableSchema( typeDefs, wiring );\n    }. ",
    "timbonicus": "Thanks @bbakerman, your explanation makes a lot of sense. I was upgrading from graphql-java v9 to v11 and this behavior changed. I'll switch to using GraphTypeUtil.unwrapAll instead!. ",
    "Maclaon": "sorry, my mistake, i posted wrong place for my issue, it should be on graphql-spqr. ",
    "dupski": "Cool cheers. I shall sort out a PR :). ",
    "khteh": "How can I debug this? I am new to java. I tried using jdb and it just exited without any stack trace:\n C:\\Projects\\Java\\GraphQL\\HelloWorld>jdb target\\HelloWorld-1.0.jar\nInitializing jdb ...\n\ntrace\nCommand 'trace' is not valid until the VM is started with the 'run' command\nrun\nrun target\\HelloWorld-1.0.jar\nSet uncaught java.lang.Throwable\nSet deferred uncaught java.lang.Throwable\nVM Started: Error: Could not find or load main class target\\HelloWorld-1.0.jar\nCaused by: java.lang.ClassNotFoundException: target\\HelloWorld-1.0.jar\n\nThe application exited. I use Sprint Tool Suite 4 and this is what I see at the console window:\nSLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\nSLF4J: Defaulting to no-operation (NOP) logger implementation\nSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n{hello=Hello World!!!}. ",
    "abazlinton": "Sorry I don't think I've described this issue very well. I'll close this for now. Thanks for your time :). ",
    "xtaixe": "Hi @andimarek \nAs discussed with @bbakerman that PR doesn't work for all our cases. If the Document is cached or provided by the preparsedDocumentProvider the instrumentation won\u2019t be called, but we still need to convert the variables in that case\u2026  As @bbakerman pointed out thought, that instrumentation can't be done after the document caching because if you rewrote the document you would need to validate again.  So caching and document rewriting is opposed (while caching and variable rewriting is not).\nSo if we still needed to go the instrumentation route, we would still need an instrumentation just for the variables/execution input as I had in my PR (#1354)\nThat said, I also discussed with @bbakerman that the work in #1336 might be enough for us to do what we need with a bit of extra work on our side to get the info we need for the conversions, so we'll see how things go once we do the upgrade to version 12 (which presents some challenges due to the immutability changes I think). ",
    "mrubin": "@andimarek Thank you for the suggestion. This approach (wiring up a specific DataFetcher for each field of User and AdminViewOfUser) is slower than the Map approach.. not nearly as bad as the DTO approach without the specific data fetchers, but about 3x slower than Map.\nFor ~40,000 of the above objects, I would be creating roughly 400,000 DataFetchingEnvironmentImpl (with the specific data-fetcher approach). Or would a DataFetchingEnvironmentImpl be created per field even with the reflection approach?\nAm I reading this correctly - a PropertyDataFetcher is created for each field (that's in the schema) if we haven't wired up one of our own? If so, how can it be faster to look up the field name in a Map for each field than to just return the field directly? I can see why you would say that a specific data fetcher should be faster than a Map. But that doesn't seem to be the case in practice... @bbakerman Thanks for the response.\n\nThe fact that you are using DTO pattern probably means you have a object mapping framework like Jackson / Gson in play. This takes a lot of processing at times. At a guess this might explain why the Map approach is faster since it wont be doing as much work.\n\nAs noted in the original post:\n\nit takes 1-2 seconds to generate the list in the data fetcher and return it to graphql, and then it takes graphql almost 2 minutes to process that list and return the final result.\n\nOnce the DTOs are generated and returned to graphql, there should be no further (object mapping) processing required. Yet it takes a significant amount of time to extract the fields. The Map approach is significantly faster. PropertyDataFetcher approach is 1-2 minutes, whereas Map is more like 3 sec. However, generating Maps by hand for complex DTOs is not desirable.\nWe tried the specific data fetchers approach, expecting it to be on par or even faster than Map, but it is 3-4x slower than Map. Again, this is once the DTOs are already generated and handed off to graphql. Not sure why (without profiling).. We\u2019re going to try to create a standalone example so that we can profile it. . This issue does not reproduce on Java (unless you find a collection that has an O(n) size()), but it reproduces easily on Scala, which is what we use for our graphql server.\nJava's Collections appear to have an O(1) size() (see this post), even though the documentation for LinkedList says, \"All of the operations perform as could be expected for a doubly-linked list.\" What's expected of a linked list is O(n) complexity to determine length :)\nSomething in graphql-java (see below profile and code screenshot) is calling size() repeatedly. When given a collection with an O(1) size(), this is imperceivable. However, when given a collection with an O(n) size() - like a Scala collection we happened to be using - this results in a great deal of overhead for 40,000 elements (size() called on a linked list of 40,000 entries for every field in the schema?). Once we were able to identify this issue, we can address it in a number of ways - switch to a collection with an O(1) size(), copy the data into an ArrayList prior to handing it off to graphql-java, etc. With one of these workarounds, the specific data fetcher approach is indeed equivalent to (or imperceptibly faster than) the Map approach (where we followed the examples and happened to use a Java collection, not a Scala one, to hand the list of Maps off to graphql-java) and allows us to continue to use our DTOs.\nThank you for the help!\n\n. ",
    "Jyothigorripudi154": "schema {\n    query: Query\n}\ntype Query{\n    data:MapEntry\n}\ntype MapEntry {\n  key: String\n  value: UserModel\n}\ntype UserModel{\n  id:Id\n  name:String\n}. like the above i written .graphql file.\n but from my service i get the result like\n\"response\": {\n        \"data\": {\n            \"1\": {\n                \"id\": \"1\",\n                \"name\": \"jyothi\",\n            },\n            \"2\": {\n                \"id\": \"2\",\n                \"name\": \"kalyani\",\n            },\n            \"3\": {\n                \"id\": \"3\",\n                \"name\": \"jammu\",\n            }\n          }\n}\nplease can anyone help me out.\n. Thanks in advance\n. ",
    "mlick": "This is my demo:\n```\nimport com.google.common.collect.Collections2;\nimport graphql.GraphQL;\nimport graphql.schema.DataFetcher;\nimport graphql.schema.GraphQLSchema;\nimport graphql.schema.idl.RuntimeWiring;\nimport graphql.schema.idl.SchemaGenerator;\nimport graphql.schema.idl.SchemaParser;\nimport graphql.schema.idl.TypeDefinitionRegistry;\nimport java.util.*;\nimport java.util.stream.Collectors;\nimport static graphql.schema.idl.TypeRuntimeWiring.newTypeWiring;\n/\n * @author mlick\n * @date 2018/12/25 15:10\n /\npublic class TestMoreData {\nprivate GraphQL graphQL;\n\nprivate static final int MAXSIZE = 10_000;\nprivate static List<User> userList = new ArrayList<>(MAXSIZE);\n\nstatic {\n    for (int i = 0; i < MAXSIZE; i++) {\n        userList.add(new User(i, \"id\" + i, \"name\" + i));\n    }\n}\n\nprivate DataFetcher dataFetcher = environment -> {\n    Map<String, Object> params = environment.getArguments();\n    Collection<User> fuserList = new ArrayList<>(userList);\n    String order = Optional.ofNullable((String) params.get(\"filter\")).orElse(\"-1\");\n\n    long startTime = System.currentTimeMillis();\n    //TODO  java 8  => time is short\n    fuserList = fuserList.stream().filter(b -> b.userId.contains(order)).collect(Collectors.toList());\n    // guava => time is long\n    // fuserList = Collections2.filter(fuserList, input -> input.userId.contains(order));\n    System.out.println(\"parse collection time=>\" + (System.currentTimeMillis() - startTime));\n\n    return fuserList;\n};\n\nprivate RuntimeWiring buildWiring() {\n    return RuntimeWiring.newRuntimeWiring()\n            .type(newTypeWiring(\"Query\")\n                    .dataFetcher(\"user\", dataFetcher).build())\n            .build();\n}\n\nprivate GraphQLSchema buildSchema(String sdl) {\n    TypeDefinitionRegistry typeRegistry = new SchemaParser().parse(sdl);\n    RuntimeWiring runtimeWiring = buildWiring();\n    SchemaGenerator schemaGenerator = new SchemaGenerator();\n    return schemaGenerator.makeExecutableSchema(typeRegistry, runtimeWiring);\n}\n\nprivate void init() {\n    if (graphQL != null) {\n        return;\n    }\n    String schemaSDL = \"schema {query: Query}type Query {user(limit: Int, offset: Int, filter: String): [User]}type User {userId:  String \\n name:  String}\";\n    GraphQLSchema graphQLSchema = buildSchema(schemaSDL);\n    this.graphQL = GraphQL.newGraphQL(graphQLSchema).build();\n}\n\n\nprivate Map<String, Object> getUserList(String query) {\n    init();\n    return graphQL.execute(query).toSpecification();\n}\n\npublic static void main(String[] args) {\n    TestMoreData td = new TestMoreData();\n    long startTime = System.currentTimeMillis();\n    Map<String, Object> m = td.getUserList(\"{user{name}}\");\n    System.out.println(\"graphql parse execute 1 time==>\" + (System.currentTimeMillis() - startTime) + \"ms\");\n    // System.out.println(m);\n\n    for (int i = 2; i < 10; i++) {\n        startTime = System.currentTimeMillis();\n        m = td.getUserList(\"{user(filter:\\\"\" + i + \"\\\"){userId,name}}\");\n        System.out.println(\"graphql parse execute \" + i + \" time==>\" + (System.currentTimeMillis() - startTime) + \"ms\");\n        // System.out.println(m);\n    }\n}\n\npublic static class User {\n    Integer id;\n    String userId;\n    String name;\n\n    public User() {\n    }\n\n    public User(Integer id, String userId, String name) {\n        this.id = id;\n        this.userId = userId;\n        this.name = name;\n    }\n}\n\n}\n```\nTest results:\nguava  filter\nparse collection time=>4\ngraphql parse execute 1 time==>745ms\nparse collection time=>0\ngraphql parse execute 2 time==>1020ms\nparse collection time=>0\ngraphql parse execute 3 time==>528ms\nparse collection time=>0\ngraphql parse execute 4 time==>431ms\nparse collection time=>0\ngraphql parse execute 5 time==>454ms\nparse collection time=>0\ngraphql parse execute 6 time==>411ms\nparse collection time=>0\ngraphql parse execute 7 time==>428ms\nparse collection time=>0\ngraphql parse execute 8 time==>405ms\nparse collection time=>0\ngraphql parse execute 9 time==>430ms\njava filter\nparse collection time=>4\ngraphql parse execute 1 time==>727ms\nparse collection time=>2\ngraphql parse execute 2 time==>487ms\nparse collection time=>1\ngraphql parse execute 3 time==>235ms\nparse collection time=>0\ngraphql parse execute 4 time==>169ms\nparse collection time=>1\ngraphql parse execute 5 time==>141ms\nparse collection time=>1\ngraphql parse execute 6 time==>166ms\nparse collection time=>1\ngraphql parse execute 7 time==>130ms\nparse collection time=>0\ngraphql parse execute 8 time==>131ms\nparse collection time=>0\ngraphql parse execute 9 time==>123ms\n. But my running time in version 6.0 is normal, please run my demo under the corresponding version to see the effect, thank you.. ",
    "dimdimych": "The specification does not allow it\nhttps://facebook.github.io/graphql/June2018/#Name. ",
    "cmonty": "@bbakerman We currently use the ExecutionContext to pass authorization data to DataFetchers. Is there an alternative implementation for passing this type of per execution context to DataFetchers after this is released?. @andimarek Ah, you're correct. We use env.getContext() to pass authorization data, which is the Object you described. Sorry for the confusion!\nWe do use ExecutionContext and call addError when an exception is thrown. . Awesome, thanks for the information!. ",
    "mlvandijk": "Thank you for merging so quickly! Any idea when this will be released? We'd like to update our GraphQL dependencies :). Thanks @andimarek @bbakerman - good to know. I think we get them from a graphql-java-kickstarter dependency then; will check there. :). ",
    "hartig": "Hi, I am one of the authors of the research paper and I also supervised the student who created the prototype implementation.\nIt is correct that the algorithm makes the assumption that it has access to the data returned by every resolver/DataFetcher. I can see that this is an issue in implementations.\nI have developed (conceptually) an idea on how the extend the algorithm to get rid of this issue. Now, I am looking for a student to help me implementing and evaluating this idea.. I have followed up via email. . ",
    "mjstewart": "Thanks very much for the feedback, I will push the changes in the next few days. Updated PR to incorporate feedback. Extracted out into its own test class.\nA few extra tests included to cover new transform method and ensure equals and hashCode are implemented correctly since this type is used as the key for hashmap registry lookups.. Reverted SchemaPrinterTest back to original master version. All new comparator tests are in SchemaPrinterComparatorsTest. ",
    "tbroyer": "FYI, I currently disable @defer support using this snippet:\n```java\n private static GraphQLSchema removeDeferSupport(GraphQLSchema schema) {\n   return GraphQLSchema.newSchema(schema)\n       .clearDirectives()\n       .additionalDirectives(without(schema.getDirectives(), Directives.DeferDirective))\n       .build();\n }\nprivate static  Set without(Collection collection, T withoutValue) {\n   return collection.stream().filter(d -> d != withoutValue).collect(toSet());\n }\nand this causes an error to be returned early (at validation time):json\n{\n  \"errors\": [\n    {\n      \"message\": \"Validation error of type UnknownDirective: Unknown directive defer @ 'echo'\",\n      \"locations\": [\n        {\n          \"line\": 1,\n          \"column\": 27\n        }\n      ]\n    }\n  ]\n}\n```\nBetter than nothing :wink: . ",
    "thilinaucsc": "how does this happen in java?\n. ",
    "lkorth": "I'm following up on graphql-java-kickstart/graphql-java-tools#169, testing with graphql-java 11.0 and graphql-java-tools 5.4.1 when I switch from comments to single or triple quoted strings in the schema I lose all descriptions in introspection queries. I haven't had time to write a failing test for this yet, but I'll try to find some time to dig into where it's getting lost.. ",
    "qzucas": "in version 11.0\n the OperationTypeDefinition's code is:\nprivate final Type type;\n@Internal\nprotected OperationTypeDefinition(String name, Type type, SourceLocation sourceLocation, List<Comment> comments) {\n    super(sourceLocation, comments);\n    this.name = name;\n    this.type = type;\n}\n\npublic Type getType() {\n        return type;\n    }\nbut in version 2019-01-22T01-01-11-41d67d7, the code is \nprivate final TypeName typeName;\npublic static final String CHILD_TYPE_NAME = \"typeName\";\n\n@Internal\nprotected OperationTypeDefinition(String name, TypeName typeName, SourceLocation sourceLocation, List<Comment> comments, IgnoredChars ignoredChars) {\n    super(sourceLocation, comments, ignoredChars);\n    this.name = name;\n    this.typeName = typeName;\n}\n\npublic TypeName getTypeName() {\n    return typeName;\n}\n\nin version 2019-01-22T01-01-11-41d67d7\ni don't find where use this OperationTypeDefinition.getType(). @andimarek thanks for your reply.\nI know the version is unreleased. It's normally that the daily version goes wrong. But I want to use the new function of new version about directives in my project.\nWhen will be the version 12.0  released?  I look forward to that this problem will be solved soon and 12.0 will be released.\nthank you. @andimarek thank you very much. I have used version 12.0 and very well.. ",
    "thorntonrp": "I created issue https://github.com/graphql-java/graphql-java/issues/1439 which describes how the development build versions are creating confusion about release versions.. ",
    "chih-chen": "@bbakerman Thanks for point out this solution, I really forgot about it. . ",
    "willtrking": "@tinnou I'll be able to do that this weekend. Should note that I am on version 11.0, not master. Before i try to reproduce, I will see if I still see the issue on master.\n. ",
    "Sparow199": "I think that the modifications should stay at toSpecification() scope. It's only useful when we consume our GraphQL API with visual tools like GraphiQL, Altair et GraphQL Playground. In my tests, these tools works only when i call toSpecification() method. If you are in the case of juste parsing the JSON result, the order of field have no sense. \n. ",
    "jschwartz73": "Thank you!. ",
    "jadedevin13": "I understand. It's in apollo server's roadpmap. \n\n@stream is similar to @defer, except that processing can continue right away, and the streamed part of the result can begin sending right away.\n\nClosing this for now.. ",
    "jeffbrown": "I have removed this change.  At the time that I submitted the PR, that example wouldn't run with the latest code.  I see now the impl has been changed to be consistent with the docs.\n. ",
    "denvned": "It would be more convenient if it returned CompletableFuture here.. ",
    "fkorotkov": "Yeah. I just ran './gradlew wrapper --Gradle-version=4.0' to generate changes in that particular commit. \ud83d\ude05. ",
    "tdraier": "Good question .. honestly, I took the configuration from graphql-java-annotations and graphql-java-servlet which is working well. Usually you should choose between the 2 plugins - both actually extend the manifest and the jar with in a different way. But in our case osgi plugin is enough, and it's more clear to use only one. I will remove the bnd plugin. Thank you !\n. Actually, that's exactly what I get with the osgi plugin only, without biz.aQute.bnd.builder (only in my case the version of bnd tool differs when I include biz.aQute.bnd.builder,  it's Bnd-3.1.0.201512181341). So including it or not does not change anything, better keep osgi plugin only.. ",
    "JWGmeligMeyling": "This optimisation is already present within PropertyUtils itself. See how the added test passes fine: https://github.com/graphql-java/graphql-java/pull/569/commits/f9eb924e7f36e929ba7299b4d9214b6c7fe3edff . The point is that Boolean isBooleanMethod should not work, because by convention you either have boolean isBooleanMethod or Boolean getBooleanMethod. These two cases were covered in the existing testcase: https://github.com/athenagroup/graphql-java/blob/fa6eefae0fcecb6bfc991d275884bd7d0a065cf3/src/test/groovy/graphql/DataFetcherTest.groovy#L102-L118  . ",
    "utwyko": "Indeed, good catch! Should be fixed now.. ",
    "translatorzepp": "We just picked a random error that implemented GraphQLError here, but I'm happy to add a generic error to test on instead.. ",
    "felipe-gdr": "do we need that empty string at the end?. can the resulting message end up having a -1,-1 location if currentToken result in a null value?. Should we mention, on the Javadocs of printAstCompact, that comments will be suppressed?. ",
    "mmorel-35": "Hello what do you think about creating an enum with a pair of values including a function that would return the right value?\nIf what you return is already an enum, just creating a findByName function.\nSwitch case can create mess. ",
    "johnliucn925": "I would move this into putHintsInExtensionsMap and return it like:\n```java\n   private Map<> putHintsInExtensionsMap(Map extensions) {\n        Map<> currentExtensions = new LinkedHashMap<>(extensions)\n         List> recordedHints = map(hints, Hint::toMap);\n         Map cacheControl = new LinkedHashMap<>();\n        cacheControl.put(\"version\", 1);\n        cacheControl.put(\"hints\", recordedHints);\n     currentExtensions.put(\"cacheControl\", cacheControl);\n    return currentExtensions;\n}\n\n```. "
}