{
    "sgrif": "Issues in the language that need to be resolved or worked around:\n- [ ] Overlapping impls of marker traits. Want to be able to define a generic impl of SelectableColumn for the various join sources, for any type that is a selectable column of either the left or right side. Invalid today since there would be overlap in the case that the left and right are the same, but this doesn't matter because there are no methods for ambiguity anway.\n- [x] ~~Orphan impls of tuples. For Queriable to work with associations, we need to be able to implement it for a tuple with no types that we control. If we cannot resolve this in the language, it looks like it's possible to work around it by adding an unused type parameter that we can pass in w/ something we explicitly control.~~\n  - This has not been resolved in the language, but as of https://github.com/sgrif/yaqb/commit/555993efd7f130b4e7643daa90abf08781550926 I believe we have an acceptable workaround.\n. I need to revisit this soon. Most things which are unchecked are going to be 0.2 or later, not 0.1. If anyone wants to help me out and make a new issue moving things over, I would :heart: you forever\n. Just glancing over this here's the status of unchecked items at the time of writing:\n- determining that FK constraints are violated will be 0.2 or later (probably 0.2, I really like that idea).\n- proper representation of aggregate rules is not possible in the language right now. It requires https://github.com/rust-lang/rust/issues/29864 or specialization with lattice impls. This will be top of the priority list once it's possible, and is a blocker for 1.0 (if the language doesn't support this in time, the plan is to remove tracking of aggregate rules entirely)\n- associations are 0.3, maybe not going to be a thing at all. I'm not sure there's value in actually having APIs in the ORM for this vs just saying the join you want, and than doing .group_by(|r| r.0) (group_by would have to come from iter_utils of course). I'm open to hearing use cases for supporting this in the library itself.\n- JSON and other indexed query operators are unknown at this point, as I don't even know what support for those types should look like. The index operator will almost certainly require specialization, as I'll need to do something like impl<T> AsExpression<T> for Expression<SqlType=Anything>\n- IS NULL I'll add tomorrow\n- \"CODEGEN: type safe api for arbitrary SQL\" -- so in the past I had this idea where we can establish a database connection at compile time, stick the sql fragment behind SELECT * FROM table WHERE, which basically would let us type check it. But honestly, we have ended up with a really fucking expressive query builder. I don't think we need this. I'm open to feedback.\n. This can also potentially lead to memory unsafety if the table is declared with the right columns, but in a different order than they exist in the schema, causing the wrong types to be applied and potentially breaking some invariant of the output.\n. Fixed by https://github.com/sgrif/yaqb/commit/4ebd0c17aa1f37bcf8ea6fd69df83468a53efb18\n. @aturon @nikomatsakis Was thinking about this recently, and thought you might be interested as it would have been helped by the lattice rule, but could be aided by other additions to the type system as well. Basically we have an impl that looks like this for every size tuple:\nrust\nimpl<T, U> Expression for (T, U) where\n    T: Expression + NonAggregate,\n    U: Expression + NonAggregate,\n{\n    // ...\n}\nWhat we need is to write something along the lines of:\nrust\nimpl<T, U> Expression for (T, U) where\n    T: Expression + !NonAggregate,\n    U: Expression + !NonAggregate,\n{\n    // ...\n}\nWith the lattice rule we could have added an Aggregate trait, and then had an impl for T: Expression + Aggregate + NonAggregate with a body that would force it to fail to compile if it was ever used. Ultimately though, what we really need here is either negative reasoning, or mutual exclusion.\nThe main goal (in case there's another solution that I'm missing) is to make sure that we do not have an impl for T: Aggregate, U: NonAggregate.\n. Also I know you had asked me to keep you in the loop when I find some concrete examples to point you guys at. Is there a preferred form of communication besides just pinging you on issues like this?\n. I think it's because I have a wildcard dependency on libc and they pushed a breaking change recently. I'll push up a fix shortly.\n. Also sorry for the delay, I wasn't watching issues on this repo and didn't actually expect one to be opened!\n. @mfpiccolo Fixed, sorry again for the delay. If you're actually trying to use this, let me know if I can help at all. I'm getting to the point where I should write up a usage guide and some docs, and having someone less familiar w/ the internals would be helpful for that.\n. >   Also, did you release pq-sys 0.2.0 to crates.io without pushing the commit to github? I am guessing that you just locked the libc version there as well.\nYes on both. Just pushed.\n\nIs this project going to be like AREL or will it also have the higher abstraction of an ActiveRecord-like ORM as well?\n\nIt's intended to be somewhere in between. Ultimately this is meant to be your persistence layer, but it's trending somewhere closer to the data mapper pattern. There's a lot of features that Active Record has that I don't think belong on the model layer, or are better handled by the database.\nI've been porting crates.io to use this as something to give some amount of focus to get to 0.1. You can see where it's been heading here (note: there's a lot of noise and mess on that branch as well, I'm going to scrap 100% of that code if I ever do actually open a PR to port them over. This is just so I have a real world app to play with).\nOff the top of my head WRT to changes from Active Record, the following come to mind:\n- No thread local connection. If you're going to do stuff involving a database, you'll be taking &Connection as an argument\n- Associations are non invasive. You won't have user.posts. If you want a user and all of its posts, then you'll get back a (User, Vec<Post>)\n- Timestamps are just database triggers.\n- The structs you use for updates and inserts can be (and almost certainly will be for insert) different types from the model you get back from select. So you tend to end up with create(conn: &Connection, new_user: &NewUser) -> Result<User, DbError>\n- No model layer validations. Data integrity validations will be handled by the database (with some interface to display those to the UI if absolutely needed, such as unique indexes failing). Validating form input should get handled by the client or controller layers\n- It's enforced that you use everything you select\n\nI would definitely be interested in helping out with the documentation or development.\n\nWanna shoot me an email and we can coordinate further? It's on my github profile.\n. I've updated the title of this to where I think this should go based on recent developments. Ultimately Expression and SelectableExpression are redundant, and Expression::SqlType is basically meaningless.\nWhat I'm currently imagining is the resulting trait being\nrust\npub trait Expression<Source> {\n    type SqlType;\n}\nOne thing that's stood out to me lately is that the only case where SelectableExpression and Expression differ is when the source is the right side of the left outer joins, which makes the type nullable.\nIt is entirely possible that this indicates a fundamental flaw either in how we handle nulls, or how we vary the sql type for joins. I am open to any ideas/opinions about that, or this change in general.\n. A combination of #709, #764 and the nullable change described in #764 fully resolve this.. This is a hole in the docs. If you're not going to use the return value, you should use insert_returning_count (which I'm open to other names for as well). insert is only intended to be used when you need the created record (either for ids, timestamps, or the result of some default value)\n. Leaving this open since there's an actionable problem \n. Fixed by https://github.com/sgrif/yaqb/commit/58b73cbd7903de44d63a7ce45cb53ed2e5750885\n. Definitely a construct to ensure users are up to date. My most basic vision is basically similar to Rails, with time-stamped files that end up being SQL files. I'm unsure as of yet whether it makes sense to provide a minimal Rust DSL for common cases. The main thing for me is that any API we do provide there is immutable, as we have a huge issue in Rails with old migrations changing inadvertently. \nSo I'm thinking we'll probably start with time-stamped SQL files and build on top of that if we feel it's needed. In all scenarios, I want to be able to switch arbitrarily between SQL files and Rust files, with the timestamp and naming convention being the thing that ties them together. \n. One note is that my plan for timestamps. For those unfamiliar, in Rails we generally have two semi-magic columns called created_at and updated_at, which get automatically updated by Active Record when any persistence action takes place. I don't like having them handled by the ORM, and it leads to a lot of issues (and doesn't really fit with the design path this has been taking).\ncreated_at is actually really easy, as it should never change, and just having it default to NOW() in the database is all it takes. updated_at can be trivially done with a trigger, and we can actually re-use the same function for all the triggers. So we'll probably end up automatically performing this when we set up a database for the first time:\nsql\nCREATE FUNCTION diesel_set_updated_at() RETURNS trigger AS $$\nBEGIN\n    IF (NEW.updated_at IS NOT DISTINCT FROM OLD.updated_at) THEN\n        NEW.updated_at := current_timestamp;\n    END IF;\n    RETURN NEW;\nEND\n$$ LANGUAGE plpgsql;\nThen for each table with timestamps, you can do:\nsql\nCREATE TRIGGER my_table_set_updated_at BEFORE UPDATE\nON my_table FOR EACH ROW EXECUTE PROCEDURE set_updated_at();\nHowever, part of why I think a Rust DSL might make sense is that we can have add_timestamps_to(table) be an easy shorthand for adding both created_at and updated_at to a table with the proper defaults, and setting that trigger.\n. This has been resolved by https://github.com/sgrif/diesel/pull/79 and b062ff1. At this time, SQL files are the only supported type of migration. Some of the plumbing for other forms is in place, however. I may revisit the possibility of a Rust DSL in the future. However, at the moment the only especially compelling benefit they would provide is being able to give you down for free. While there is value in that, the value gain going from no tooling to what will ship in 0.4 is much greater, so I'm taking the 80/20 solution for now.\n. The needs of our own test suite after adding SQLite has pretty much sold me on the need for some kind of Rust support. I don't know that I want a full rails style DSL, but there's no way to represent id INTEGER PRIMARY KEY AUTOINCREMENT/id SERIAL PRIMARY KEY in a platform agnostic way, and I don't want to maintain two sets of migrations in our test suite just for that.\nI still need to think it through further, but I'm thinking we can at least support files that look like this:\n``` rust\n// timestamp_migration_name.rs\nfn up(&Conn) -> QueryResult<()> {\n    // do stuff\n}\nfn down(&Conn) -> QueryResult<()> {\n    // Do the opposite stuff\n}\n```\nI'm still unsure if it's worth doing a rails style \"change\" method, where you get down for free, but I'm interested in exploring at least being able to write migrations manually in Rust. I want to continue to support the SQL file version, even though those could universally be represented in Rust using Connection#execute (there's something to be said for editor assistance and syntax highlighting).\nI'm going to spend some more time thinking about this after we finish 0.5, and probably open an issue once I've had time to collect my thoughts.\n/cc @mfpiccolo @mcasper @samphippen \n. Yes. We've DSLized a little bit in our actual tests, though the migrations are still raw SQL. I ended up not even putting what came out of it in the main diesel crate, as it was so far away from being suitable for general use. It's actually going to be a lot more complicated to make this work for real\n. #27 added this\n. @mikeastock Excellent! I'm happy to help however I can. Feel free to ping with any specifics. I'm trying to get the bare minimum getting started stuff out the door tonight. \n. Documentation can always be improved, but I believe we have the minimum acceptable level of documentation for all modules. I think we're good to go for 0.1.\nPRs to improve documentation, no matter how minor, are always welcome.\n. We shouldn't implement From<i32> for them, we should stop relying on it. I think the easiest thing to do is add fn times(self, x: i32) -> Self; to the trait, and use that instead of the * operator.\n. \"Diesel\" came to mind as an idea tonight.\n. Fixed by https://github.com/sgrif/diesel/commit/c8127d408f759faa056503014cd00e92479215e0. Diesel has stuck in my head as something easy to remember, and not already too overloaded in the tech space. \n. Whoops!\n. :heart:\n. I actually have been referencing yaqb::result::Result as DbResult, and have been thinking about exporting that with that name. \n. The goal is not not overload prelude, but I've been referencing yaqb::result::Result when I use that name. \n. I like the idea, but I'm not sure how we'd do it, since the only thing I can think of to test it is to add a compile-fail test, but that only works on nightly anyway\n. Yeah, you wouldn't want to make the columns Nullable, as it'll just end up trying to insert NULL into the column. Right now there's no good way to handle a field that you want to optionally update with a struct. I actually can't think of an easy way to do this with plain assignments, either. This is a valid use case though. I might be able to do something with the type system to have it know to skip the update if the column is not nullable, but this hole would still exist if you wanted to optionally update a nullable column.\nThis popped into my head as a possible solution. Thoughts?\n``` rust\n[changeset_for(users)]\npub struct UserChanges {\n    id: i32,\n    #[optional_update]\n    first_name: Option,\n    #[optional_update]\n    last_name: Option,\n    #[optional_update]\n    email: Option,\n}\n```\nCould also specify it at the struct level.\n``` rust\n[changeset_for(users, behavior_when_none=\"skip\")]\npub struct UserChanges {\n    // ...\n}\n```\nIn the short term, I would just do 3 queries to work around this.\n. So I think this is what the impl needs to look like regardless of codegen. I think I'll need to add some impls for Box<Changeset> to make this work, but it's already object safe so that should be fine.\n``` rust\nimpl AsChangeset for UserChanges {\n    type Changeset = Vec>>;\nfn as_changeset(self) -> Changeset {\n    let changes = Vec::new();\n    // push any fields we always update\n    if let Some(first_name) = self.first_name {\n        changes.push(Box::new(users::first_name.eq(first_name)))\n    }\n    // repeat for each field\n    changes\n}\n\n}\n```\nI don't think there's a way to do this without boxing, and also using a Vec or the code will just get horrendous. I think it's fine to write impl<U: Changeset<Target=T>, T> Changeset for Vec<T>, and impl<U: Changeset<Target=T>, T> Changeset for Box<T>\n. I've pushed up the required impls. Can you try manually implementing AsChangeset on your struct and tell me if that works? If so we just need to make an annotation to standardize it.\n. Your return type should be Self::Changeset from as_changeset\n. And you'll need changes to be mutable\n. Whoops, I need to add some ?Sized to things. I will fix when I'm back at a computer. \n. Just pushed an update. This compiles, and should work as a workaround (it's what I'll have the annotation generate)\n``` rust\nimpl AsChangeset for UserChanges {\n    type Changeset = Vec>>;\nfn as_changeset(self) -> Self::Changeset {\n    let mut changes: Vec<Box<Changeset<Target=users::table>>> = Vec::new();\n\n    if let Some(first_name) = self.first_name {\n        changes.push(Box::new(\n            users::first_name.eq(first_name).as_changeset()\n        ))\n    }\n\n    if let Some(last_name) = self.last_name {\n        changes.push(Box::new(\n            users::last_name.eq(last_name).as_changeset()\n        ))\n    }\n\n    if let Some(email) = self.email {\n        changes.push(Box::new(\n            users::email.eq(email).as_changeset()\n        ))\n    }\n\n    changes\n}\n\n}\n``\n. I think we're seeing https://github.com/rust-lang/rust/issues/28894 strike again. The _actual_ issue is thatAsQueryis not implemented for&UpdateStatement<...>. It is implemented forUpdateStatement<...>. Hopefully #29 will make this less confusing.\n. @bwo Yeah, I'm going to basically give the ability to choose between the current behavior and that behavior. I don't want to stop supporting puttingNULLin an update, though.\n. I'm going to change the behavior ofchangeset_forto treatNoneas skip by default in 0.3. The more I think about it, the more clear it becomes that assigning null is not the majority case. You can still set null by manually doingset(column.eq(None))`.\nI will likely introduce an additional type in the future to represent wanting to assign null (which when deserializing from JSON will require the key being present, and the value being null)\n. First pass at correcting this for those interested: #47 \n. FWIW it sounds like you don't actually need to use AsChangeset there, you can just call set((foo.eq(self.foo), bar.eq(self.bar)), etc directly, which might be slightly less verbose in your use case.\n. Yeah, I'll probably add an option for the behavior you want at some point. We just need to be careful to make sure the API is sufficiently clear what the difference is, and make sure its a wide enough use case to justify being in the core library, as we don't want to end up with 18-billion options (e.g. after this I wouldn't be surprised for someone to have a struct where they want one Option to have the new behavior, and another use the old, etc)\n. Yeah, I've considered that in the past as well. There's a similar gap for inserts, where there's no way to insert NULL into a column which is nullable, but also has a default which is not NULL (a very niche case). My worry is that having another type to represent this would potentially just make actually using the struct painful. Then again, since the last time I really thought about that option, we've moved much towards having structs whose only purpose is to represent changes for the database, and not be used much in app code beyond that, so it might be worth investigating.\nFor just this case though, I think I'm fine with something like changeset_for(users, treat_none_as_null = \"true\").\n. @Drakulix I've added the option in 59a25e8bbd04d2c88475768004d067f2b5eda7db\n. It looks like you're using nightly, not syntex. You need to specify a few things in Cargo.toml. https://github.com/sgrif/yaqb/tree/master/yaqb_codegen#using-on-nightly\n. (Sorry, the instability should settle a bit on Monday when I release 0.1)\n. I think once we add these methods, it'll also be fine to have first do limit(1) automatically.\n. @mfpiccolo You just described exactly what I want (Although I'm still unsure if run_all is a good name)\n. also I'm leaning towards insert(&new_user).into(&users::table).run(&conn) over what's listed in the posts.\n. It'll likely just be delete(existing_user).execute(&conn). If there's a primary key, we know what table to use from codegen.\n. Would it though?\nrust\nupdate(users.filter(id.eq(1))).set(user_changes)\ndelete(users.filter(id.eq(1))\ninsert_into(users).values(new_user)\nvs\nrust\nupdate(users.filter(id.eq(1))).set(user_changes)\ndelete(users.filter(id.eq(1))\ninsert(new_user).into(users)\nthere's also the third option (not mutually exclusive)\nrust\nnew_user.insert_into(users)\n. I do want to end up supporting update(record) and delete(record) as sugar for filtering on the PK though, so there's merit to insert.into. It also reads more naturally.\n. I've updated my post to be less specific about the timeline for supporting other databases. It definitely makes sense to do pre-1.0 if possible, as it's unlikely to be something I can add without some amount of breaking API changes. However, I don't want to commit to any specific timeline.\nI'm going to close this, as I've take the only actionable response to this I can.\nAs a side-note, since I haven't documented this anywhere, when we support MySQL, we'll still be following Postgres' semantics for a \"correct query\". So mixing aggregate and non-aggregate expressions will fail to compile, as will comparing a string with an integer (AKA please dump my database), etc. \n. Definitely reasonable to support. Not going to assign it a milestone just yet, but if anyone wants to tackle it, feel free. Shouldn't be hard to implement, just need to make sure that union, intersect, and except can be called multiple times, but the other query DSL methods cannot be called after one of these methods.\n. There's some random scattered thoughts with regards to contributing here. https://github.com/diesel-rs/diesel/issues/120\nI'd avoid having the types returned by these methods implement any of the DSLs, really, and instead require a fully built query. We want to avoid things like enums if possible, as they carry runtime information that can't always be inlined, and can't be reasoned about at the type level.\nGo ahead and rely on AsQuery, we can add marker traits if needed to filter out the problem cases.\nKeep in mind that anything adding support for something like this would need to be thoroughly tested.\n. Gave this a little thought. It actually should be extremely straightforward, just needs a lot of tests.\n``` rust\ntrait UnionDsl>: AsQuery {\n    type Output = Query;\nfn union(self, other: Other) -> Self::Output;\n\n}\nimpl UnionDsl for T where\n    T: AsQuery,\n    U: AsQuery,\n{\n    type Output = UnionQuery;\nfn union(self, other: U) -> Self::Output {\n    UnionQuery::new(self.as_query(), other.as_query())\n}\n\n}\npub struct UnionQuery {\n    left: T,\n    right: U,\n}\nimpl QueryFragment for UnionQuery where\n    // you know the drill\n{\n    // impls...\n}\nimpl Query for UnionQuery where\n    T: Query,\n    U: Query,\n{\n    type SqlType = T::SqlType;\n}\n```\nNote: We may want to drop the constraints on UnionDsl and instead just have them on the impl of Query for the resulting UnionQuery, as it can actually be frustratingly difficult to satisfy that those constraints hold.\n. And while I'd have UnionQuery and friends implement UnionDsl, IntersectDsl and ExceptDsl, they shouldn't implement any others. They need to take fully constructed queries and can't be modified afterwards. Also, for ease of review, please submit each of those as a separate PR.\n. The example using main is probably fine. I think many of our examples could change to use try!, or change their assertion to compare against Ok though\n. I don't think we need to teach users how to handle error cases, but if we can avoid unwrap without actually making the example less clear, I'd like to. \n. I think that there are still a few places left but I can't confirm at the moment. Feel free to let me know if that's the case\n. Thanks!\nOn Thu, May 12, 2016 at 7:31 AM Taylor Jones notifications@github.com\nwrote:\n\nAh, I see what you're talking about.\nUpon doing a global project search for /// assert_eq!(, I've found that\ncases that use .unwrap() in the assert are all using Ok([statement]) now.\nIs this the desired beahvior?\nAnyways, I'm closing this PR and recommending that #34\nhttps://github.com/diesel-rs/diesel/issues/34 be closed if everything\nis as it should be. Sorry for the misunderstanding!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/34#issuecomment-218731294\n. We wouldn't be able to query this out, as there would be no lifetime for us to deserialize &'a str to. You must own the data. \n. We should improve the error message here though\n. You're right, that's a valid use case. (Just for the record, this was the code which I wrote to get my head straight)\n\n``` rust\nuse std::borrow::{Cow, ToOwned};\nimpl<'a, T: ?Sized, ST> ToSql for Cow<'a, T> where\n    ST: NativeSqlType,\n    T: 'a + ToOwned + ToSql,\n    T::Owned: ToSql,\n{\n    fn to_sql(&self, out: &mut W) -> Result> {\n        match self {\n            &Cow::Borrowed(ref t) => t.to_sql(out),\n            &Cow::Owned(ref t) => t.to_sql(out),\n        }\n    }\n}\nimpl<'a, T: ?Sized, ST> FromSql for Cow<'a, T> where\n    ST: NativeSqlType,\n    T: 'a + ToOwned,\n    T::Owned: FromSql,\n{\n    fn from_sql(bytes: Option<&[u8]>) -> Result> {\n        T::Owned::from_sql(bytes).map(Cow::Owned)\n    }\n}\n``\n. I also need to properly support generic lifetimes for the other codegen as well, at the moment they just take advantage of the fact that you can have an unused lifetime name in an impl, and just putimpl<'a>on them universally.\n. Yes, that code compiles. Because for any lifetime'a, returning a'staticwill satisfy it.\n. Are youuseung the table from the other module? I don't see it in your code. Can you post the full code?\n. Deriving should be enough. Have you followed the instructions at https://github.com/sgrif/diesel/blob/master/diesel_codegen/README.md#using-on-nightly? This looks like you're probably just missing thedefault-features = false, features = [\"nightly\"]on codegen\n. I should probably make it more clear in the README,table!must be called, we don't derive it for you. As for the first set of errors, try updating to the latest nightly, or use Syntex + stable\n. The problem is that the type of your struct can very much not be one-to-one with the types of the table. I am planning on eventually addingload_table_from_schema!(table_name)andload_schema!, which will use a database connection at compile time to get this information from the database.\n. The added test is failing. You need to add this as a re-export inexpression::dsl. This also could use an integration test, and a changelog entry.\n. To test nightly only features, you need to docargo test --no-default-features --features unstableindiesel_test. Or just runbin/testfrom the root directory. I should put this in aCONTRIBUTING.md` now that I think about it.\n. Thanks!\n. This is likely not going to happen until we get closer to 1.0. I have said in the past that I want to support other databases eventually. My gut was to close this, as there's not anything immediately actionable. However, as you've presented a reasonable use case that isn't \"I prefer MySQL\", I'm accepting this feature for 1.0.\n. Yup, supporting 1 means supporting N\n. So I've started to give this some serious thought. @tafia has started some of the work on this in #72. Here's a rough overview of what has to change, in order of easiest to hardest, along with what I think might be possible solutions, but I'm not yet sure.\nJust as a note, while I haven't decided if I will support MySQL in the long term, I do want whatever changes we make here to make it possible to theoretically support MySQL, as that will help ensure that we can truly support N adapters and not just 2. In an ideal world, this is done in a way that additional adapters can be added as third party crates.\nI'm writing this up to help clarify my thoughts, get some eyes on it to see if I'm missing anything, and give a roadmap for anyone who wants to take on a piece of this. I would prefer that we solve the harder bits (or at least have a strong indication that we have a solution that will work) before we bother with the easier pieces.\n- Connection needs to become generic. Should be trivial, but need to audit the public API for anything that doesn't translate.\n- Cursor somehow needs to become generic.\n  - This one is a pain in the ass, and I wish we didn't have to do it. Any way that we end up doing this will basically mean that users who want to point at this as a return type will have to put connection specific information in their signatures.\n  - This will eventually just be replaced by impl trait in whatever form it eventually lands, as I want the return type here to be impl Iterator<Item=T>. The current direction that's heading seems like it'll be useable for our needs (basically anything that doesn't require us to state the concrete type higher than the function level, as that would end up requiring HKTs to work here).\n    - I don't expect that feature to be in stable pre-1.0, so I expect that we'll just have to bite the bullet here, and bump to 2.0 at some point to change to impl trait.\n- Many of the types we support right now are specific to PG.\n  - The easy answer is to move everything that isn't also supported by Sqlite to a separate diesel-postgres crate, or under a config flag.\n    - I am comfortable treating Sqlite as the \"lowest common denominator\" for SQL implementations and leaving those in the main crate. To my knowledge there is no type that is supported by sqlite (without extensions) that isn't supported by all backends. \n    - There is definitely value in leaving these types non-backend specific. The vast majority of schemas are dominated by strings, integers, dates, and their variants. We want crates to be able to add functionality around those without caring about backend when possible\n  - We should change the constraint on Connection to be trait Connection where {all std lib primitives and all fundamental sql types}: ToSql<Type, Self>.\n    - We should also constrain that an impl is required for the nullable versions of all of those. If we ever see Higher Ranked Types, what we should write instead is for <ST: NativeSqlType, T: ToSql<ST, Self>> Nullable<T>: ToSql<ST, Self>\n    - An unresolved question here is whether or not we should also require implementations of optional 3rd party crates that we've deemed important enough to support in the core adapter (e.g. chrono). I'm leaning towards no, since those won't be in the core crate when compiled w/ no features, which is what crates abstracting over us would depend on.\n  - Array is an unfortunate loss here, as it's the only other type that is generic besides Nullable, and might be painful to abstract over without coupling to the backend (Oracle and SQLServer also support arrays).\n    - As far as I can tell, there is no other generic type in PG or any other backend that is unbounded. Range is the closest, but even it's restricted to a known subset.\n    - I'd like to resolve the question of \"is there any unbounded generic type supported by any backend other than array?\"\n  - JSON is an additional unfortunate loss. 2 of the 3 cases I'm looking at (MySQL and PG) have a JSON data type, and it would be nice to eventually write impl<T: serde::Deserialize> FromSql<Backend, JSON> for T where String: FromSql<Backend, JSON>, since that would not be backend dependent. I'm not sure we can ever do that though, since with these API changes that impl could access backend specific code. We might need some sort of MappedFromSql trait.\n- ToSql, FromSql, Expression, and Query need to become generic over the backend, as do any traits generic over them.\n  - This is going to include things like AsExpression, AsQuery, Queryable, FromSqlRow, and likely more.\n  - Are we sure that Expression and Query need to be generic? Query does if Expression does to be sure, but are there any fundamental SQL statements that change based on the back end?\n    - As I wrote that, Bound becomes the obvious case.\n  - Again, this shouldn't be too hard, but I'd like to canvas our existing users to see how often any of these traits show up in their code for internal abstractions they've built.\n- NativeSqlType is coupled to PG\n  - oid and array_oid are the trouble cases here.\n  - The best solution that comes to mind is to have it be NativeSqlType<Backend>, giving Backend an associated Metadata type, and having a metadata function that returns that struct.\n    - We should try to eliminate the new function if we go this route\n    - Is the compiler smart enough to eliminate some copying if I only use one field of the returned struct, and the function impl is just a struct literal?\n      - Is this still true if it's going through a trait object?\n      - Does it even matter? Is our worst case for a performance hit a few extra i32 copies? We should benchmark regardless\n- Note for the last 2 points: This is making it clear to me that I want the \"backend\" type to be different from the connection. So we would have Connection<Backend> where i32: ToSql<Integer, Backend>, ... and we'd have impl Connection<PG> for PgConnection. This is because there's a lot of structs that will need to become generic over the backend which need to remain 0-size, and I'd like to avoid using PhantomData any more than we are, as it tends to be an indication that you're doing something which cannot be made object safe.\n- Our handling of bind params is fundamentally at odds with SQLite's API.\n  - Just to clarify:\n    - PG's API takes a query, an array of oids, an array of char*s (for the data), an array of lengths, and an array of booleans indicating whether it's text or binary\n      - As such, our push_bind_param function takes a type and an Option<Vec<u8>>. We can calculate the lengths ourselves, we get the oid from the type, and we always pass binary.\n    - MySQL is similar. They take an array of MYSQL_BIND structs, which consists of an enum for the type, a void * for the data, and a length. Whether the data is binary or text is dictated by the type. Text data still fits into our Vec<u8> fine.\n    - SQLite instead has several functions that you call, based on the type of the bind param. These functions in general take a statement pointer, the index of the bind param, the data itself which is usually by value and a specific type, not a pointer, and a length in places where it makes sense.\n      - What's important to note here is that the requirement of a statement pointer means that we can't actually call these functions in the place where we currently call to_sql.\n      - Our code related to constructing bind params currently does not know or care about the index.\n      - SQLite is unique in that it has no IO protocol that you can use (which is sorta the point), so we are bound to its C API.\n  - This is by far the hardest one to solve\n  - One potential solution (I think I prefer the one proposed later) would basically be to create a BoxToSql<Backend> trait, take the type on construction, and return that. This would mean ToSql falls to dynamic dispatch. This is potentially a catastrophic perf hit.\n  - This is potentially awful, but there's actually no reason we can't just continue to use our current API. We can read a Vec<u8> back into an i32. We lose all guarantees of type safety at that layer of abstraction, but we should in theory be guaranteed that we're fine by the layer above. Since we have a very small subset of types that we need to worry about, we can just match on a type identifier to determine what to do. If we see performance hits in the read, we can even do some unsafe casts from Vec<u8> -> &u8 -> *const u8 -> *const i32 and dereference it if we really need to.\n    - This seriously sounds so horribly dirty, but the more I think about it the more it could actually work, and is starting to be my favored option as it doesn't require significant changes to the API for other adapters, and won't cause a performance hit for them either.\n    - This is all dependent on the fact that SQLite has a known set of types that we have to deal with. As far as I can tell, no extensions add types which affect the C API, particularly in the handling of bind parameters. We need to confirm that this is true, otherwise we need to provide an API that crates can hook into.\n- A scorched earth solution if we truly can't find a type safe solution that abstracts over multiple backends is to just take the traits or structs that need to change, and just put them under #[cfg(feature = \"postgresql\")]. This would mean we don't have to find an actually generic API for different backends, but would be incredibly harmful to the ability for third party crates to provide additional abstractions, and would mean that Diesel would never be able to be used with more than one type of database in the same application.\n. @mfpiccolo @samphippen @mcasper It's long, and pretty technical, but I'd like to get thoughts on the above. Also if any of you are interested in helping tackle some of this, have at it.\n@tenderlove, @rafaelfranca, @senny, @metaskills -- I know none of you are involved in this project or Rust, but I think you guys would be able to provide some valuable insight as well. I'm happy to clarify our API and how these problems relate to it in ways that don't require knowledge of the language if you'd like.\n@metaskills: In addition, I'd be interested to hear if you think this will be enough for SQL Server. I've more or less looked at this from a high level WRT MySQL as the third case, but knowing that it can handle another DB is a good indication that we will in fact be generic after this.\nAfter writing this up, I think I've got my thoughts organized enough that I can see a reasonable path to implementing this. From what I can tell, the proposed solutions will also put us in a place for others to write additional database adapters without having to have them in the primary crate. We can essentially put this to the test by having postgres and sqlite live in separate crates. @e-oz, you've expressed interest in having MySQL support in the past. It'd be great if you were interested in working on that as a third party crate, as well.\n. @matthewd If you don't mind, you might have some thoughts too\n. @iqualfragile That's essentially the scorched earth option at the end, but it doesn't work terribly well if you want to have traits people can depend on regardless of backend. Ideally our core types (in the rust sense not the SQL sense, e.g. what comes out of the expression module) don't change based on your backend.\nBut yes, not having to be properly generic over the backend would reduce coding complexity, and I'm open to it as a last resort. I'm confident after writing up these thoughts that we can properly become generic though. Bind params are the hardest part and I think we have some good options.\n. > it probably won't make a huge difference. When dealing with databases, you have to compare this stuff to the performance of I/O.\nI agree. That said, it'd still be nice to have benchmarks to back up the fact that we haven't caused any regressions in cases like finding a single record by primary key, where our query builder has the largest hit. Additionally, being able to show that our query builder is effectively 0 cost is a nice bullet point. That said, yeah I don't think the metadata case will be nearly as big of a hit as changing to_sql to dynamic dispatch would be.\n. This is true. However, I think leaning on the type safety provided by our current query builder is fine here. Based on where sqlite has caused issues in Active Record, I believe we should be safe.\n. > Meaning loss as in they will need to be supported in an external crate?\nLoss as in they will need to be adapter specific (which likely means being in another crate)\n\nbut it might be prudent to be sure of this before deciding if it is worth it to support SQLite with this route.\n\nIf our type system doesn't cover any potential problems, it's an issue regardless of if we're supporting SQLite or not.\n. Moving the timeframe on this forward to 0.5, as it's our most immediately actionable feature. I expect to have this finished this weekend.\n. @placrosse I'm interested in making sure that it's possible to add additional adapters that aren't part of the main diesel crate. If you're interested in trying to add TDS support as a third party crate once we finish the SQLite stuff, let me know -- I'd be interested in working with you on it.\n. We still have a little bit more work to do, but I've merged our SQLite support branch into master. We'll be releasing 0.5 with this feature later this week.\n. I do not like the idea of generating a table from Queriable, as it implies too heavily that a struct has to be one to one with a database table, and puts too much schema information in the struct itself. I'd prefer a macro which generates the table! call for you based on the database schema at compile time.\n. Forgot to reference this from the other PR. First pass at this is https://github.com/sgrif/diesel/pull/49 -- There will be an additional macro which loads table names from schema and calls that one automatically.\n. Note: I don't think this needs to be a compiler plugin. We just need a DebugQueryBuilder that doesn't need a database connection, and have the macro expand to:\nlet mut query_builder = DebugQueryBuilder::new();\n$query.to_sql(&mut query_builder).unwrap();\nprintln!(\"{}\", &query_builder.sql);\n. This will likely be much easier once we implement the Identifiable trait that we're looking to add to support associations as part of 0.6\n. And just so it's clear, if we do this right, we should be able to have anything which implements serde::ser::Serialize implement AsExpression<Json> via ToSql<Json>\n. Yes, you can fairly easily add support for any types that you want within\nyour application. I'm on my phone but will give examples later\n\nRather than wait for the absurd feature\n\nUnsure what that is supposed to mean\nOn Tue, May 10, 2016, 5:02 PM archer884 notifications@github.com wrote:\n\nSo, I was just trying to use Jsonb in a table and I had kind of\nassumed--until I ran into this error--that diesel would give the json to me\nas a string and I could deserialize it myself. No dice. Instead, I get a\ncompilation error. Rather than wait for the absurd feature (querying jsonb\nwith diesel, I guess?), what about just letting diesel give me the data\ninstead of exploding? :)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/44#issuecomment-218290337\n. Oh. I didn't realize this was a comment on an existing issue. XD\n. So basically what you'd need to do is:\n\n``` rust\nstruct JsonB;\nimpl HasSqlType for Pg {\n    // ...\n}\nimpl FromSql for String {\n    // ...\n}\nexpression_impls!(JsonB -> String);\n```\nUnsure what the binary rep of jsonb is so you might need to do some digging there\n. Hey folks -- today's my first day back from holiday vacation. I'm getting caught up on issues now. I've gone ahead and added this feature to the 0.10 timeline, as there's clearly a lot of demand for it. \nhttps://github.com/diesel-rs/diesel_full_text_search was mostly just a proof of concept to demonstrate some of the basics of how to add support for additional extensions outside of Diesel. It \"conveniently\" tackled some types which didn't require ToSql/FromSql implementations. I'd like to see a plugin crate done to ensure we have appropriate APIs in place, but I'm fine with adding this to Diesel proper for now and exploring that space at a later date.\nI'll leave implementation specific comments on #561.. In theory we shouldn't be ignoring the result of delete statements. It's technically fine, since we're asserting it was successful one line down, but I don't know if encouraging not checking results is better than encouraging unwrapping. At least this results in a compiler warning.\n. Looks good other than that comment. Can you squash the commits?\n. This will need a changelog entry.\n. Pushed up a fix for the mentioned issue. This just needs docs and a changelog entry, and it's good to go.\n. Please squash these down to a single commit. Good to merge after that.\n. Up to you on the docs\nOn Sun, Dec 6, 2015, 12:39 PM Mike Piccolo notifications@github.com wrote:\n\nSquashed. There is only the issue of what to do with the docs for the\nDebugQueryBuilder struct.\ni.e.\n- Should it be #[doc(hidden)]\n- No docs\n- Docs for contributors only\nOther than that this is ready to go.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/46#issuecomment-162335814.\n. Review? @mfpiccolo \n. This issue still exists for doctests.\n. There's still a lot of cases in our integration suite that #52 missed, too.\n. @mfpiccolo Review?\n. @mikeastock @mcasper Would you guys mind trying pointing at this branch and poking it, too? I want to get 0.3 out tonight, and this is probably a bit fragile, would like to see if it breaks in any obvious ways for you guys\n. I don't know what you're talking about. I'm not a machine, I swear. \n\n. I don't know how to travis... /headdesk\n. :metal:\n. I've updated with docs, and an additional infer_schema! macro, which queries for all table names at compile time, and calls infer_table_from_schema! for each one.\n. Yes, I would at minimum like to have all the code from the readme put in an executable example, with some other examples added as well.\n. You'll need to use two different structs for that use case. (Which makes sense if you think about it, you don't want to have to deal with options for reads, when you know the field is always present)\n. (I might eventually be able to support reading a non-nullable field into an option, but at the moment coherence prevents it)\n. Oh, whoops!\n. ^----- That commit probably also makes save_changes way more useful for your use case as well\n. Close. I'd like to have each of the pieces in their own function, and probably link to these from the README\n. Busted! I only support tuples of an arbitrarily large size, as it takes longer to compile when I increase it. Right now we go to 16 IIRC, I'll bump it to 26\n. This is fixed in the next release. You'll need to add features = [\"large-tables\"] to your Cargo.toml, as this change increases our compile time by a ton, and I don't think common usage requires > 16.\n. Unfortunately since we're working with tuples here, I can't just use an arbitrary number in the macro. (The short version is self.19 is a valid expression, but self.(19-1) is not.)\n\nSo I have to put some boilerplate in to make this work, which means I end up picking some arbitrary number. 26 was what my editor macro to add more impls worked up to.\n. You can double it again with the \"huge-tables\" feature\n. This is due to https://github.com/rust-lang/rust/pull/29850 breaking some of our dependencies.\n. I like to call this \"PHP style CI\"\n. This needs a compile-fail test, currently the constraints on the arguments look too loose. \n. I've fixed the issue with Vec<T>, but there's a separate issue here when #[changeset_for] is used on a struct with a single field which is not yet fixed. See #66.\n. Review? @mfpiccolo @samphippen @mcasper @mikeastock \n. @mfpiccolo Do you have a primary key other than id on that table?\n. PSA to those who tried this branch -- delete and recreate your database, there's some schema changes that won't work otherwise.\n. Forgot to mention it in the commit, but this was fixed by cf5613391b2b33ff31d120682e4c4ec487fe9b32\n. Can you mark all of these as #[doc(hidden)], please?\n. Also, can you bump this date https://github.com/sgrif/diesel/blob/master/.travis.yml#L6 to the latest nightly?\n. Yup, this appears to be correct. We can add a type alias as Queriable to ease migration. Feel free to open a PR renaming.\n. Thanks for the PR. There's some failing tests, but I think I can handle getting them passing. I think it's still a bit premature to try and genericise these interfaces, but this all seems pretty reasonable at first glance. This is a pretty hefty PR, so it'll take me a day or two to get through it.\n. Hey just wanted to update why I haven't given this much attention lately. I've started to give more thought to sqlite 3 support, and there's a couple of hard problems that need to be solved.\n- Our NativeSqlType API only makes sense for PG, but there's not an obvious other place to put it.\n- The way we handle bind parameters during query construction works fine for PG and MySQL's API, but is fundamentally opposed to SQLite's.\nBoth of these lead me to believe that we very well might end up simply having the traits themselves have different APIs based on a cfg flag. If that is the route that we end up going down, I'm not sure that it actually makes sense to promote some of these to traits (though it might be worth it any way)\nIn any case, I'm hesitant to do some of the easier changes until we figure out the harder ones.\n. Note: I wrote up some very long thoughts on this issue overall in https://github.com/sgrif/diesel/issues/39#issuecomment-172110839\n. @tafia Thanks for starting the work on this, but there's a lot of feedback that still needs to be addressed, and we're now at the point where this change is actually needed. I'm going to close in favor of #128.\n. The answer to both your questions is that SQL is not Rust, and this is ultimately the translation layer between them. As a user, you can think of a row as a tuple, and there's only options, never null. I don't have that luxury in the implementation layer.\nWe could change Vec to slice there, but there's not really any reason to do so. Vec::new doesn't have a cost associated with it.\nThe naming of DbResult is because it is wrapping a PG struct called PQResult. Again, since this is an internal facing struct, not a user facing struct, I'd prefer to represent what it is for the implementation.\n. Yes, it's appropriate to fix typos. It's generally appreciated to batch up grammar changes into a single PR if you find more than one.\n. @mfpiccolo @samphippen @mcasper Review?\n. You can cargo install it\nOn Fri, Jan 8, 2016, 12:04 AM Mike Piccolo notifications@github.com wrote:\n\nCode looks good to me. What are the steps for running the commands from a\nproject directory?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/79#issuecomment-169913073.\n. All integer types are supported for use where appropriate. Unfortunately, the error messages can sometimes be unhelpful due to https://github.com/rust-lang/rust/issues/28894. The trait that it's failing to find is probably AsExpression<types::Integer>. What's allowed here is based on the type of id. It seems likely that your column is of type Integer or Serial, which are both 32 bit signed integers. You can't write 32bit_column.eq(1i64). For BigInteger, you can use 64 bit integers as well. However keep in mind that this type is also signed, and you can only use i64 not u64. PostgreSQL does not have an unsigned integer type.\n\nIf my assumptions about your app are incorrect, let me know and I'll re-open.\n. I don't like the ability for this to leak. Without a case that can't work in the function form, I'm hesitant to add that.\n. @crackofdusk, @mathroc, @tohou: You've only touched documentation, so no action is required from you on this, and I've removed you from the checklist.\n@mcasper, @mfpiccolo, @palango: I am in favor of this licensing change, but as contributors I cannot make this change unless you all agree. \n@mikeastock: Looks like the only code change you've made is changing some variable names, so legally I don't think we need any action (I'm not a lawyer), but confirmation that you're fine would still be welcome.\n. Thank you for the quick replies, everyone\n. cargo install diesel_cli && diesel migration run in before_script should make sure that they exist at compile time. You can also do diesel::migrations::run_pending_migrations from build.rs.\n. review? @cmr\nDid I miss anything?\n. In addition to just flat out fixing this problem, I'd also like to decouple the table name from the struct name, and allow a #[table_name=\"foo\"] annotation.\n. Yeah, it literally is .to_lowercase + s right now. We can make it\nslightly better, but I don't want to try and handle actual pluralization\nfor every word\nOn Mon, Jan 11, 2016, 5:46 PM Matt Casper notifications@github.com wrote:\n\nThe decoupling would probably help a lot, as it looks like it has trouble\nwith any edge case pluralization as well\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/86#issuecomment-170744905.\n. Also I didn't mention it earlier, but also keep in mind that I've left associations out of the public API of the released crate, as I'm not happy with the current design and it may change further (it also likely requires the lattice rule coming w/ specialization to implement properly)\n. So I've been starting to think more heavily about this, and specifically how to avoid duplicating a lot of information when dealing with non-standard tables and primary keys. An interesting thing about the #[table_name] annotation is that I can't actually access it from annotations on other items (which makes sense, especially when considering the associated struct might be coming from another crate).\n\nJust spitballing some thoughts here. Scoping to belongs_to only to simplify. We might be able to work this into assuming the other side implements a trait, rather than how we operate today. If we do #[belongs_to(bar)] Struct Foo;, then the code that'll get generated is:\n``` rust\nimpl ::diesel::BelongingToDsl for Foo {\n    type Output = ::diesel::helper_types::FindBy<\n        foos::table,\n        foos::bar_id,\n        i32,\n    >;\nfn belonging_to(model: &Bar) -> Self::Output {\n    foos::table.filter(foos::bar_id.eq(model.id.clone()))\n}\n\n}\nimpl ::diesel::JoinTo for foos::table {\n    fn join_sql(&self, out: &mut ::diesel::query_builder::QueryBuilder)\n        -> ::diesel::query_builder::BuildQueryResult\n    {\n        try!(bars::table.from_clause(out));\n        out.push_sql(\" ON \");\n        foos::bar_id.eq(bars::table.primary_key()).to_sql(out)\n    }\n}\n```\nSo I guess really all we need is something like\n``` rust\ntrait Identifiable {\n    type Table: Table;\n    type Pk: AsExpression;\nfn table() -> Self::Table;\nfn primary_key(&self) -> Self::Pk;\n\n}\n```\nNow the question is where do we actually generate this. Are we fine with just requiring a #derive(Identifiable) on the other side? I could just tack it onto something common like Queriable, but that would imply that you don't have models which aren't associated with a single row of a single table.\nIt's worth noting that all of this is focusing around the idea that these structs will represent a single row on a single table. While that's counter to the design of the framework overall, I think that more or less has to be a given when we start talking about associations (unless we want to explore the idea that you'd have a single struct to represent both sides, but I don't think that'll work well with one-to-many, and would inhibit code re-use).\nIt's also worth noting that we never actually use the argument to belongs_to, other than to generate the foreign key and infer the struct name.\nWith all of this in mind, I'm thinking that we should change the API to #[belongs_to(User)], with the ability to specify the foreign key: #[belongs_to(User, foreign_key=\"author_id\")]. With this change, the generated code would become:\n``` rust\nimpl ::diesel::BelongingToDsl for Foo {\n    type Output = ::diesel::helper_types::FindBy<\n        foos::table,\n        foos::bar_id,\n        i32,\n    >;\nfn belonging_to(model: &Bar) -> Self::Output {\n    foos::table.filter(foos::bar_id.eq(<Bar as Identifiable>::primary_key(model)))\n}\n\n}\nimpl ::diesel::JoinTo<::Table> for foos::table {\n    fn join_sql(&self, out: &mut ::diesel::query_builder::QueryBuilder)\n        -> ::diesel::query_builder::BuildQueryResult\n    {\n        try!(::table().from_clause(out));\n        out.push_sql(\" ON \");\n        foos::bar_id.eq(::table().primary_key()).to_sql(out)\n    }\n}\n```\nThis does mean that you can't have an association using a primary key other than that of the table. I think that's fine, as the point is that we're equating with a single row, and I've never seen a good use case for changing the primary key of an association in Rails.\nThis will be a little bit more murky when it comes to has_many, as that means the API becomes the slightly awkward #[has_many(Post)] or #[has_many(Post, foreign_key=\"post_id\")]. It's worth noting that has_many as it is today is effectively worthless (other than enabling joining).\nAt some point it will also be the thing that makes you able to get Vec<(User, Vec<Post>)> out of a query, but I'm not sure that needs to care about the struct as much as it is a property of how you're performing the join. I was writing some examples of what I mean but as I wrote them I realized there's some flaws involving how it gets mixed with select. I'd have to implement to figure that out. But what I'm getting at is that unlike belongs_to, which does deal with a specific struct, has_many doesn't necessarily need to know about it, and in fact it is more about the table, implying that #[has_many(posts)] is in fact the right thing to do.\nPerhaps at the heart of this is figuring out exactly what associations are meant to do. I do like Post::belonging_to(user) as a helpful piece of sugar over the common posts.filter(user_id.eq(user.id)) (I also just realized that could totally be posts::belonging_to(user) since the Post struct has nothing to do with belonging_to, but I'm struggling to come up with any cases where we need to involve structs.\nIf that's the case, maybe we need to separate out the relationships between tables from the relationships between structs. The biggest problem there is that we no longer have a place for you to actually annotate a table. I need to spike some more on what I want to be able to do with has_many to figure out the right place to solve this...\n. @mcasper @mfpiccolo review?\n. No problem. I'm not planning on releasing another version until either #88 or #89 are resolved, so let me know if you're able to point at git for everything\n. Moving this to 1.0 as while it's important for launch, it's not immediately a problem\n. The basic idea of how the lookup works hasn't changed, but we do provide the ability to have that result in types from places other than diesel::types. I think this is sufficient until I see a use case showing otherwise.. @mfpiccolo @mikeastock @samphippen @mcasper Would like to get some discussion going on this.\n. I'm moving this to 0.6, as SQLite support is more immediately actionable.\n. The first pass was released in 0.7, but I'm leaving this open as I think there's still more work to be done.\n. Fixed upstream\n. Unsure if this is too much, but I think I'd also like to have something like diesel_manage_updated_at(table_name), because I can never remember the trigger syntax.\n. We can handle that via DEFAULT NOW()\n. I guess it should just be BEFORE UPDATE if we assume updated_at has a default.\n. There's currently no Rust DSL, though we may add one in the future as use cases arise. I'm fine with creating this as part of the migrations code, as long as it has a sufficiently specific name.\nThe actual code for creating these should probably live on the Connection, so we can easily adapt it for SQLite once #152 is merged.\n. We shouldn't do any sort of magic around this, the user should set the trigger themselves. We just need to provide the function for them.\n. Sure. If you want to open a PR with what you have, I can do the legwork on finishing it up, too.\n. Also I think the only tests that we need for this are an entry in https://github.com/sgrif/diesel/blob/master/diesel_tests/tests/types_roundtrip.rs#L76\nIt is a shame that we need this in diesel proper -- I really wish that we could make diesel-chrono be a separate crate. \n. Yeah, that's the main benefit of doing it in crate is not needing to newtype it. \n. The only remaining type for this is chrono::NaiveDate. A close to working implementation was done in https://github.com/sgrif/diesel/commit/c0b0fb8c50908c5d9ca2cbf8853059e1cbb6b6d1 but it was ultimately reverted as I treated 0 as the start of the Julian era, when PG treats it as the start of the PG epoch. Anyone interested should feel free to adapt that code, with tests similar to what have been added to the other date/time types w/ concrete values added for NaiveDate to prove that it's correct.\n106 has been added as a separate tracking issue for figuring out how we should handle timezone aware types.\n. Fixed by #114, #101, and #94 \n. > Shouldn\u2019t this read \u201cTimestamps are represented in Postgres as a 64 bit signed integer\u201d? If so, should this be in a separate PR?\nYes to both.\n\nAs converting from DateTime to Date (for example) is easy, should there be impls like impl ToSql for NaiveDateTime, or should mappings between types be strict?\n\nI'd prefer to be strict -- as you said, it's easy to convert from DateTime to Date if that's what you need. I prefer to avoid any implicit loss of precision.\n. This is a great start, thanks for working on it.\n. I cleaned up the code, squashed the commits, and merged in https://github.com/sgrif/diesel/commit/9d879552f348c2747c527bf49c4b92f0b548672f. Feel free to take a swing at dates/times as well (Julian day conversion, yayyyyyy)\n. Right, and so we can do an impl of ToSql for all the various non naive types to timestamptz, with only an impl of FromSql for DateTime<UTC>.\n. (I need to read through the docs more thoroughly on that front, too)\n. Let's just kill the alias, this is a mechanical change for migrating\n. This needs a CHANGELOG entry.\n. Good to merge. Needs rebase.\n. Ok so I've started looking into this a little bit, and my first pass worked similarly to Rails, where I calculated the statement name from the hash of the SQL string. I actually started to wonder if this was even worth it, as to my knowledge PG will perform query planner caching automatically regardless.\nHowever, I've come to realize that due to how our query builder works, we can do much better than that. As long as an AST contains no SqlLiteral nodes (in which case we should not prepare the statement), TypeId::of<QueryType>() is a sufficient stand-in for a hashing function. (As an aside, if we wrote #[derive(Hash)] for every Expression, any AST which does not contain SqlLiteral would result in the same hash if we hashed the query rather than the resulting SQL string).\nWe can also determine whether an AST contains a SqlLiteral node as a compile time constant. As such, an implementation should do the following:\n- Change our AST builder to be 2-pass, once for constructing the query, once for collecting the bind params.\n  - This means QueryFragment/Query/Expression change to roughly the following (Note: The error types might change or be able to be removed from to_sql)\nrust\npub trait QueryFragment {\n    fn is_preparable() -> bool;\n    fn to_sql(&self, out: &mut QueryBuilder) -> BuildQueryResult;\n    fn collect_bind_params(&self, out: &mut BindParamCollector) -> BuildQueryResult;\n}\n- Change connection to operate on PQprepare and PQexecPrepared when is_preparable() returns true\n- Cache prepared statements in a BTreeMap<u64, CString> where the key is the type id, and the value is the statement name. This can be in an LRU cache that wraps the same type if we deem it appropriate\n  - I'm unsure if we actually need to do LRU caching here. Would like to see some numbers on what we can expect a server to handle in terms of number of concurrently prepared statements\nWhile to_sql will continue to incur the same costs that it does today, is_preparable and collect_bind_params should be absurdly optimizable, where is_preparable should compile to a literal, and collect_bind_params should eliminate the call for all nodes that aren't Bound, leaving only the to_sql calls inline.\n. This might not actually work for our case, since TypeId::of<T> requires that T: 'static. Now the only type for which that doesn't hold true is Bound<T, U> where U might not be 'static. Ironically, that's the only case where we don't want the ID to change, but presumably if we did remove the 'static bound fromTypeId::of, then &'a i32 and &'b i32 would have different types. We actually want Bound to have the same type for ID here for any U, so that Bound<VarChar, String> was the same as Bound<VarChar, &str>. That said, if we just have one additional prepared statement for users.filter(name.eq(\"Sean\")) and users.filter(name.eq(\"Sean\".to_string())), it's not the end of the world. We should explore this further.\nAt the end of the day, if we do end up having to compute the hash of the SQL string, that's fine too. I'd still like to change our query builder to be 2 pass, as that will potentially be helpful for SQLite support, and will make this optimization easier in the future.\n. Did I really forget to close this? This was done by #279 and #280. > The reliance on Syntex scares me\nI wouldn't call it reliance. Every single thing that we use syntax extensions for is completely reasonable to write by hand (which I often do when I don't want to use syntex, or can't use codegen).\n. Putting this on the 0.7 milestone. I've been working on this for a few days now. Still need to audit a few more cases, but I'm fairly certain that every single one of our syntax extensions (with the exception of infer_schema! and infer_table_from_schema!) can be handled with a normal macro.\nThe overall plan is to add macros for each of our custom derive cases (all of our annotations are basically custom derive. The ones that aren't explicitly a #[derive] annotation are because they need arguments.) I'm thinking I'd like to structure the macros so that they are compatible with the custom-derive crate, but I see no reason to enforce using that crate.\nI think it makes sense to keep the syntax extension form, but simply have them call the macro from the main Diesel crate. Aside from the \"this eventually becomes stable\" argument, we can also provide much better error messages from a procedural macro. For example, if Insertable is derived on a tuple struct, all fields must be annotated with the name of the column. We simply can't communicate that effectively from a normal macro.\nI plan on opening a PR moving #[insertable_into] over to a normal macro this weekend, and I think we should declare this as a blocker for 1.0.\n. These have been implemented wherever possible.\n. @mfpiccolo Feel free to add yourself to this list if you're interested.\n. See https://github.com/sgrif/diesel/commit/c26d299da9b4b3e71b545c74dbc95ae13b2bbb98\n. This looks good, thanks. Can you rebase this into a single commit?\n. Thank you for the excellent work you've been doing lately. Please keep it up!\n. @mcasper Ugh.... Right, stable... I think it's probably fine to move the modules being tested into lib.in.rs (I say this quite begrudgingly).\n. Or at the very least let's just make a module that is structs_with_codegen_for_testing_foo be a module.\n. I don't like having a general annotations module, as that changes from having schema be a generic dumping ground to having annotations be a generic dumping ground. Can we at least make these be one module per test if we think that inlining them into the tests themselves is too painful?\n. It also just makes it clear where they are used, instead of ending up in some generic dumping ground for every edge case. I just don't want to end up with https://github.com/rails/rails/blob/master/activerecord/test/models/post.rb\n. The only downside to inlining them into the tests is that the modules that the tests are in need to go through syntex on stable (which means no line numbers on compiler errors). Given that this is development only, and most of us (all of us?) who work on the framework use nightly for day-to-day dev, this is probably fine.\n. I've raised questions on the specialization RFC related to this. I think the real answer under specialization might involve adding a NotNull trait and IsNullable trait (redundant with Nullable<T>, maybe potentially replacing it with T: NativeSqlType + IsNullable), and having the following:\n``` rust\nimpl Expression for Eq where\n    T: Expression,\n    U: Expression,\n    T::SqlType: NotNull,\n{\n    type SqlType = Bool;\nfn to_sql(...) { ... }\n\n}\nimpl Expression for Eq where\n    T: Expression,\n    U: Expression,\n    T::SqlType: IsNullable,\n{\n    type SqlType = Nullable;\nfn to_sql(...) { // identical to previous }\n\n}\nimpl Expression for Eq where\n    T: Expression,\n    U: Expression,\n    T::SqlType: IsNullable + NotNull,\n{\n    type SqlType = ();\nfn to_sql(...) { unreachable!(\"No type should impl NotNull and IsNullable\"); }\n\n}\n``\n. As I think through this, I'm becoming more confident that this problem is scoped entirely too booleans coming from infix predicates. While technically you can run into the same problem withSELECT 1 + NULL, we don't actually implementAddforNullable. So another way to put this is that the problem only applies in cases where we have an _unbounded_ constraint on the input types. At first glance, that appears to only apply to infix predicates which return a boolean (andIsNull/IsNotNull`, but this doesn't apply to those for obvious reasons).\nGiven the idea of \"truthy\"/\"falsey\" in other languages, I think that treating NULL as false is a reasonably comfortable conversion. This would not remove the idea of a Nullable<Bool>, which you could certainly still have as a column. It would only affect cases that we at present cannot correctly handles, which is nullable_expression.eq(other_nullable_expression).\nAs a side note, if we ignore other backends, this problem is not solved by just mapping Eq to IS DISTINCT FROM in PG. IS DISTINCT FROM is not treated as an operator, so we cannot do things like x IS DISTINCT FROM ANY(some_array). The problem also applies to cases like > and <.\nI'm starting to become amicable to this over a solution which changes the type to Nullable<Bool>, as unless we suddenly decide to allow T to be comparable to Nullable<T>, which we currently prevent by design, any case involving NULL would bubble up through AND in painful ways. For example x.eq(y).and(nullable_x.eq(nullable_y)) would not compile, as both sides would need to be Nullable.\nOther cases where this does apply in SQL are essentially functions, and operators like +, which do have bounded input. We don't currently have elegant handling of multiple types for functions, but for operators like +, it's completely possible with our types as set up today to have Nullable<Integer> + Nullable<Integer> return Nullable<Integer>. What is not possible today is to have Integer + Nullable<Integer> (looking through the commit history, I'm not sure I fully understand why I wrote Rhs as an associated type, and not a type parameter. Presumably it's due to wanting to use AsExpression, and the inability to say impl<Rhs> ::std::ops::Add<Rhs> where { there is exactly one type for which \"AsExpression\" is implemented on Rhs, and ::diesel::ops::Add exists } but I need to confirm.\n. Interesting point from IRC: We could actually handle Eq similarly to Add, where we have a EqResult trait of some kind with a known output. This would require adding brute force impls for every native type, but we can remove a lot of that pain with macros, similarly to how we handle Add for numeric types, and Queriable/AsExpression for primitive types. This would also enable us to add equality comparisons that we don't support today like varchar.eq(text). We'd still have the same x.eq(y).and(nullable_x.eq(nullable_y)), but we might be able to figure out some way to implement impl<T: Expression<SqlType=Bool>> AsExpression<Nullable<Bool>> for T that doesn't overlap with our existing impl<T: Expression> AsExpression<T::SqlType> for T\n. I've decided to pull the trigger on treating NULL as false in this particular case during deserialization. I'm reasonably sure that this can only manifest itself with booleans, and I'm comfortable with that coercion for that type in particular as it essentially mimics it's behavior in boolean contexts in SQL outside of a select clause.\nWe should continue to keep an eye on this and make sure it cannot manifest itself for any types other than bool.\nI believe we might be able to fix this with specialization by specializing SelectableExpression rather than Expression. Something like this:\nrust\nimpl<T, U, QS, ST> SelectableExpression<QS, Bool> for Eq<T, U> where\n    ST: NotNull,\n    T: SelectableExpression<QS, ST>,\n    U: SelectableExpression<QS, ST>,\n{\n}\nrust\nimpl<T, U, QS, ST> SelectableExpression<QS, Nullable<Bool>> for Eq<T, U> where\n    ST: NotNull,\n    T: SelectableExpression<QS, Nullable<ST>>,\n    U: SelectableExpression<QS, Nullable<ST>>,\n{\n}\n. Fixed by https://github.com/sgrif/diesel/pull/107\n. Any implementation which tackles this should likely handle https://github.com/sgrif/diesel/blob/c26d299da9b4b3e71b545c74dbc95ae13b2bbb98/diesel/src/expression/date_and_time.rs#L23 as well.\n. FYI the build is failing with the new dotenv release so let's fix this quickly\n. Can you squash your commits and rebase so the build goes green?\n. Thanks. As a note, I'd appreciate someone taking the changes here further and removing the .unwrap calls since we have a decent way to handle these at the top level. I'm not huge on the exit(1) in map_err calls, but it's better than what we have now\n. A lot of folks on twitter recommended gitter, and it looks like the best option ATM. I've set up a public room here. If you're a committer to the project, you've been added to a private room as well.\n. Importing diesel::prelude::* won't import select, insert, update, and delete. Those examples should all still be diesel::update\n. Already added.\n. Good point. I think it definitely makes sense for it to run migrations as a \"I just cloned this app and want to get up and running\" case. I'm not sure if it should just run pending migrations in general though, or if it should only run migrations if the __diesel_schema_migrations table didn't already exist. I'm open to arguments either way.\n. Yup, that's my thoughts as well. I've updated the original issue to include that as a prerequisite.\n. Review? @mfpiccolo @mcasper \n. Review? @mfpiccolo @mcasper \n. Review? @mfpiccolo @mcasper \n. # Type Constraints\nDue to the nature of what we're doing, we often have data structures that need to constrain their types in several different ways. Let's take Eq<T, U> as an example.\nEq<T, U> as a data structure can reasonably exist for any values of T and U. Therefore, the actual struct definition of T and U should not have any constraints on the struct definition itself, or its inherent impl.\nEq<T, U> is only a valid expression if T and U are the same SQL type. Therefore, in the impl Expression, we should constrain that T: Expression, U: Expression<SqlType=T::SqlType>. This should be loosened as needed based on the various usages of the expression. Traits like AsExpression should never appear on the struct itself. If we want to have a DSL which takes U: AsExpression<T::SqlType>, those sorts of constraints should appear on the DSL itself (the GlobalExpressionMethods#eq method in this case)\nConstraints required for conversion to SQL should appear on the impl for QueryFragment. The impl for QueryFragment should not care about type safety, as that has been handled at higher levels. Eq<T, U> would likely only have the constraints that T: QueryFragment and U: QueryFragment.\nAny type that implements Expression should likely implement NonAggregate and SelectableExpression, based on the implementations of its members. See the body of the infix_predicate! macro for common examples.\n. # Some Style Guidelines\nOne of the biggest lessons I've learned from maintaining Rails is that git history is really important, particularly the ability to get context on a line of code quickly via git blame. As such, much of the code is styled in such a way that lines are unlikely to change in order to support unrelated changes. Here's a few points that have come out of it. Note that these are guidelines, not hard rules. Use your best judgement.\nIf a function, struct, trait, or any other definition spans more than one line, the { goes on its own line.\nExample:\n``` rust\n// GOOD\nfn foo(some_args: OmgVerboseTypeName, more_args: OmgVerboseTypeTwo)\n    -> OurReturnType\n{\n    // ...\n}\n// BAD\nfn foo(some_args: OmgVerboseTypeName, more_args: OmgVerboseTypeTwo)\n    -> OurReturnType {\n    // ...\n}\n// ALSO BAD\nfn foo(some_args: OmgVerboseTypeName, more_args: OmgVerboseTypeTwo)\n    -> OurReturnType {\n        // ...\n    }\n```\nThe reasoning for this is simple: While I hate the curly brace being on its own line, I hate having part of the function signature being at the same indentation level as the function body (I need an easily identifiable visual separator), and we need the indentation level of the function body to be independent of the struct definition.\nDo not token align. Just don't.\nIt rarely actually improves readability. The next line should start 4 spaces deeper than the previous, at the same indentation level, or 4 spaces shallower. Not 7 because it lets a : line up, as we'll have to re-align everything as soon as we add a longer key.\nAlways use trailing commas for multiline groupings\nExample:\n``` rust\n// GOOD\nlet ints = [\n    1,\n    2,\n    3,\n]\n// BAD\nlet ints = [\n    1,\n    2,\n    3\n]\n```\nKeep lines under ~80 characters\nYou don't need to break it up when it's 81. My rough guideline is \"does this fit in my terminal pane\", which for me ends up being 1 vertical vim split out of 2 on a 15-inch macbook, and 1 vertical vim split out of 3 on a cinema display. This comes out to roughly 80ish characters, but there's no hard character limit. Documentation should have a hard wrap at 80 characters.\nPrefer where clauses to the compact form basically always\nType constraints have a tendency to change more frequently than anything else. This will probably settle down a bit as we approach 1.0, but when a single constraint changes, I don't want to cause churn on the entire signature every time. My general rule of thumb is that you should use a where clause if there is more than one type parameter (even if all but one are unconstrained), or if the type parameter has more than one bound.\nBreak things into multi-line when it gets close to being required, not after\nIf a function signature is pushing it, it's reasonably likely something will change that pushes it over the \nedge. Move to a where clause or multiline signature sooner rather than later.\nState what you mean in where clauses\nFor example, if we still had Expression: QueryFragment, and we had\nrust\nimpl<T, U> QueryFragment for Bound<T, U> where\n    T: NativeSqlType,\n    U: ToSql<T>,\n{\n    // ...\n}\nthen your constraint for Expression should show that you're trying to satisfy the constraints for QueryFragment, not just repeating them outright.\n``` rust\n// GOOD\nimpl Expression for Bound where\n    T: NativeSqlType,\n    Bound: QueryFragment,\n{\n    type SqlType = T;\n}\n// BAD\nimpl Expression for Bound where\n    T: NativeSqlType,\n    U: ToSql\n{\n    type SqlType = T;\n}\n```\nHere's what a long function signature should be structured like\nrust\nfn really_long_function_name_omg_we_used_half_our_char_limit<T, U, V>(\n    arg1: Type1,\n    arg2: Type2,\n) -> ReturnType where\n    T: Something,\n    U: Something,\n{\n    // body\n}\nIf you find existing code that doesn't already adhere to these guidelines, don't change it simply to adhere to them\nIf we start changing code for style reasons only, it completely defeats the purpose of trying to avoid git churn in the first place. Do change code that doesn't adhere to these guidelines if you're already changing that line for other reasons.\n. # Common Abbreviations\nST: Sql Type. Basically always has the NativeSqlType constraint\nDB: Database. Basically always has the Backend constraint.\nQS: Query Source. Usually doesn't have a constraint, but sometimes will have QuerySource attached\nPK: Primary Key\nLhs: Left Hand Side\nRhs: Right Hand Side\nConn: Connection\nGenerally, we prefer to give our types meaningful names. Lhs and Rhs vs T and U for a binary expression, for example.\n. Our query builder (high level sense, not constructing sql sense) is Expression and AsExpression. QueryFragment is our AST.\nThere's a lot of overlap between these types. In a traditional OO language I would separate them more. Rust's type system means we don't have to, but I want to draw that distinction.\n. It looks like pg_config.exe isn't on your PATH. How did you install postgres on your machine? Can you make sure that executable is on your path and try again?\n. Can you give the output of where pg_config.exe and also the output of pg_config --libdir?\n. I've set up appveyor to confirm I didn't have anything funky setup locally. The only step required to get it to build was SET PATH=%PATH%;C:\\Program Files\\PostgreSQL\\9.4\\bin (note: Make sure you run cargo clean after setting that if it wasn't set before). I'm going to close this issue, as the library does appear to build on Windows just fine.\nI'm happy to help you figure out the issue with your setup though, feel free to continue to comment.\n. Review? @mfpiccolo @mcasper \n. Review? @mfpiccolo @mcasper \n. Ok the tests should be passing on this now. Other than potentially fixing this so Changeset doesn't need to be generic over the backend, this is good to go. I can always do that change later, as well.\nI've broken out most of the code that was pre-requisite for this and committed it separately, so this change should actually be pretty boring for the most part. It's worth noting that the main benefit here is that we're no longer using trait objects for the SQL type, though being able to fail to compile if you try to do an array comparison on sqlite is pretty nice, too.\nI think this is ready for a final review. @mcasper @mfpiccolo?\n. Yeah, travis is just wigging out in general. It's not related to these changes.\n. Review? @mfpiccolo @mcasper \n. This looks reasonable overall. I was hoping to improve our test coverage of the CLI before working on this. I'll take a closer look tomorrow\n. Yeah, go for it. We'll need to revisit some of this when we start making diesel_cli backend agnostic, but that shouldn't block it getting merged.\n. Review? @mcasper @mfpiccolo \n. @mfpiccolo @mcasper Can I get a quick review on this?\n. We can probably use default impl/partial impl to make it easier to add new AST passes. We have a lot of AST nodes that are composed of exactly 1 or 2 elements, we can add a BinaryQueryFragment trait and do something like:\nrust\ndefault impl<DB, T> QueryFragment<DB> for T where\n    DB: Backend,\n    T: BinaryQueryFragment<DB>,\n{\n    fn is_safe_to_cache_prepared(&self) -> bool {\n        self.left().is_safe_to_cache_prepared() &&\n            self.right().is_safe_to_cache_prepared()\n    }\n}\nRight now I'm having to manually add these for a ton of nodes, and it's quite painful\n. We should see if we can remove the need to ever specify QueryId as a constraint by adding a blanket impl for all T, maybe with the constraint of T: QueryFragment<Debug> or something. If I could, I would make QueryId a supertrait of QueryFragment but that would mean that I have to specify the query id type when it is boxed, which we don't want to do.\nBut right now if a type forgets to implement it, the error message is really hard to track down. It's similar to if QueryFragment wasn't implemented, but that's much less likely.\n. I'd like to have https://github.com/diesel-rs/diesel/blob/d120a230e80afd14f06f5498a884353eb45be2a5/diesel/src/migrations/connection.rs#L23 just be for<'a> &'a str: ToSql<VarChar, T::Backend>, and use an ad-hoc insert in that file. However, that's going to fail because ColumnInsertValue requires that DB: SupportsDefaultKeyword or DB == Sqlite. With specialization we can make the SQLite impl a blanket impl, and then specialize it for DB: SupportsDefaultKeyword.. Review? @mfpiccolo @mcasper \n. Given that you explicitly need to call a method to execute the query, I'm not super concerned with the case of \"I executed SELECT * FROM users, but then decided I don't want the results\". We've already paid the bigger costs of round tripping to the database.\n. Fixed by #142\n. Review? @mcasper @mfpiccolo @samphippen \n. Everything here has been done except #184. The semicolons definitely aren't doing anything\n. Review? @mfpiccolo @mcasper \n. Oh there's a compile-fail test that I need to fix. I won't merge until I do.\n. @mfpiccolo <3 -- Tess and I are at a movie but feel free to push that commit up to this branch\n. The README on master documents the code on master. You can find the older versions on the tag for that version. The latest released is at https://github.com/sgrif/diesel/tree/v0.4.1\n. We usually try to keep master correct for the upcoming release, as it's\ndifficult as maintainers to keep track of all of the things that we would\nneed to change when we actually make the release. I understand your\nfrustration, but usually these sorts of cases are rare and minor. The\ndifficulty of avoiding it as a maintainer would be more difficult. If you'd\nlike to put a note in the readme, with a link to the latest released\nversion, I would accept that PR.\nOn Tue, Jan 26, 2016 at 6:38 PM, Victor Brekenfeld <notifications@github.com\n\nwrote:\nI would argue, that master then should also track master in the README:\ndiesel_codegen = { git = \"https://github.com/sgrif/diesel\" }\nThis way is confusing and unintuitive, although understandable, as the\nobvious example is broken.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/138#issuecomment-175294245.\n\n\nThanks,\nSean Griffin\n. Can you pick one style of map(collect) and use it consistently? This looks fine otherwise\n. Also you shouldn't need to manually use Iterator. It's in prelude. \n. I think the most \"correct\" thing to do here is to ignore files that are ignored by VCS, but that feels a bit like overkill. I'm fine with just making sure up.sql and down.sql are there. We should also make sure that we better communicate our errors instead of just panicing\n. Fixed by #141\n. This looks fine. I'm going to hold off on merging until we get a bit closer to release, as I'd just like to think about it a bit more to be 100% sure this is the right thing to do here.\n. This will need a changelog entry (go ahead and change the entry about Iterator since that's still unreleased)\n. This PR also needs to ensure that errors returned by FromSql, or FromSqlRow do not result in a panic!, but instead result in an Err being returned for the query. We should have a test to verify this (probably something abusing the NativeSqlType node, as actually causing one of these errors should basically be impossible using the query DSL)\n. I rebased and finished this PR manually.\n. I fixed it as part of the rebase.\n. Wow, thanks for the thorough and well done PR.\n. This is missing a changelog entry. I'll add it.\n. Today our output looks like this:\n\nWe should be able to assume that errors will only occur because of a bad connection, or an error running a specific migration. It's clear in the output when a connection error occurred (though the output could be better here), and when an error occurs running a migration, it immediately follows the migration version. I'm not sure that there's much else we can do here.. Is there any use case for just drop on its own? Should we just have this be diesel database reset?\n. Just to clarify, my reasoning here is that we definitely want reset as a command either way, and I'd rather not expose drop on its own without a specific reason, as it's just one more thing to maintain and/or change if we ever decide to do something like https://github.com/rails/rails/pull/22967\n. I'm fine with this, as long as we don't require .env to be set.\n. review? @mfpiccolo @mcasper \n. Review? @mcasper @mfpiccolo \n. I'm going to pull this off the 1.0 milestone. I don't see any way for this to happen in the immediate future. The ecosystem isn't there yet. From my point of view there are two main requirements here:\n\nDoesn't require the use of a global logger.\nDoing something as simple as \"log crate1 to stdout, crate2 to a file\" or \"temporarily disable logging for a single crate\" should not be difficult.\nIt would be impossible to test our implementation of logging if a global logger is required.\nHas a reasonably simple \"getting started\" story. e.g. \"I just want to log to STDOUT or a file and don't care about anything else\" shouldn't require much more than connection.set_logger(Logger::new(stdout()))\nHappy to see more complex configuration available, but this is a thing that people will see pretty early on. It needs to be possible without stalling getting started.\n\nThe two options today seem to be log and slog. log fails the first requirement (the Log trait is present, but impossible to interact with from outside the crate). slog fails the second (Printing to stdout requires 4 lines and 3 different crates. Most of the examples in their docs that I encountered don't compile, a lot of bit-rot over there it seems). Arguably log fails the second requirement as well.\nI'll be interested to see what happens with https://github.com/SergioBenitez/Rocket/issues/21, as I assume they have similar concerns to mine.. Profiling execution time is definitely an interesting case that I haven't considered much. I need to give that one some thought. (The general answer to your question is, yes having us provide our own ad-hoc logging system with shims for log and slog is probably the most likely path forward at this point). The main problem with that implementation is that I made the mistake of encouraging code written as &PgConnection, not C: Connection<Backend = Pg>, meaning this will likely need to be part of Connection itself.. I also doubt this could ever be (efficiently) implemented outside of Diesel, since any outside implementation would have to force the query builder to run when we would normally skip it because it's in the prepared statement cache and looked up by QueryId.. @weiznich If your crate doesn't ever pass a connection to a dependency... Maybe? I don't think it's a viable option at this point even beyond the \"People take PgConnection and not T: Connection<Backend = Pg>\" piece these days. Until associated types are considered for disjointness, this would break a lot of generic code (e.g. the recent issue with batch insert not working for pooled SQLite connections). Switch the order of the columns on your model. It's trying to load the ID\ncolumn into name and vice versa. This is a separate issue I'd like to\nimprove.\nOn Fri, Mar 18, 2016, 6:25 PM Jakob Gillich notifications@github.com\nwrote:\n\nYes, please. Here is one that drives me crazy:\nsrc/models/artist.rs:17:61: 17:66 error: the trait diesel::types::FromSqlRow<diesel::types::Integer, diesel::pg::backend::Pg> is not implemented for the type collections::string::String [E0277]\nsrc/models/artist.rs:17         match artists::table.filter(artists::name.eq(name)).first(conn) {\n^~~~~\nsrc/models/artist.rs:17:61: 17:66 help: run rustc --explain E0277 to see a detailed explanation\nsrc/models/artist.rs:17:61: 17:66 help: the following implementations were found:\nsrc/models/artist.rs:17:61: 17:66 help:   >\nsrc/models/artist.rs:17:61: 17:66 help:   >\nModel:\n[derive(Queryable)]\npub struct Artist {\n    pub name: String,\n    pub id: i32\n}\nI looked at the tests and the code looks alright. But I'm also just\ngetting started with Diesel, so maybe I got something fundamentally wrong..\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/151#issuecomment-198341740\n. For now, yes. We use indexed access instead of named access for performance\nreasons. I want to remove the ordered requirement without impacting that.\n\nOn Fri, Mar 18, 2016, 6:30 PM Jakob Gillich notifications@github.com\nwrote:\n\nOh wow, the order matters? I had no idea haha, thanks!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/151#issuecomment-198344641\n. Yes. It doesn't give us the diagnostics we'd need in most cases, and https://github.com/rust-lang/rust/issues/28894 and https://github.com/rust-lang/rust/issues/33094 generally cause our error message to never show up anyway. So I discussed this with some folks at the all hands this year, and rustc_on_unimplemented has gotten a lot more functionality since the last time we looked at it. It still won't solve all our problematic cases, but I think it may be enough to help us in a few of them. I'm going to try to look into this further to give the compiler folks more feedback on where it could help, and where we still need better hooks.\n\nThis is something I'd like to make a major focus in 2019, hopefully looking into using a lint to help cases that we can't fix with other compiler hooks. A lot has changed since the last activity on this issue, so I'd like to renew the call for \"please give us your bad error messages\". If you can provide a small, single file script to reproduce the problem (e.g. something we'd be able to add as a compile test to Diesel), that would be much appreciated.. Review? @mfpiccolo @mcasper @samphippen \n. Fixed by #172 (more or less)\n. Fixed by #172 (more or less)\n. Fixed by b25be2f\n. Fixed by #166\n. Fixed by #171\n. Fixed by #175.\n. Excellent question. I've not tried installing SQLite support on my Windows laptop, so I'm not sure how to qualify it for that, but the way I'd describe it for postgres is \"Having installed PG from the links on their website, and made sure C:\\Program Files\\PostgreSQL\\{version}\\bin is on the %PATH%\" (The second half being non-obvious, but unfortunately required).\n. Thanks. I'll probably merge #152 around lunch tomorrow once I have time to address stuff in the morning (I'm in UTC-7 if you want to get specific). I'll try to get Appveyor set up in the morning, too if you want to tackle getting SQLite working for that (they don't offer SQLite as a \"service\" and I'm not sure how well things like chocolatey work on that service)\n. Hah, no pressure. <3\n. The CLI tests fail against SQLite due to some contention over file locks (/cc @mcasper), but other than that everything is still fine on Windows.\n. Our integration tests shouldn't need to be single threaded. ;)\n. Given that diesel setup does stuff that has nothing to do with the database, are we sure that moving the namespace is the right thing to do?\n. Does it make sense to split out diesel setup from diesel database setup? I suppose diesel setup in that case would be diesel database setup + mkdir migrations?\n. On cursory review this looks pretty reasonable, but I'm a bit fried tonight and the diff is rendering rather silly for me. I'll take a more in depth look tomorrow. Thanks for tackling this so quickly.\n. I'm about to head to bed but assuming all the comments I left previously\nhave been addressed this is fine.\nOn Sun, Jan 31, 2016, 9:16 PM Matt Casper notifications@github.com wrote:\n\nAlright, I think everything has been resolved. Final review @sgrif\nhttps://github.com/sgrif @mfpiccolo https://github.com/mfpiccolo ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/161#issuecomment-177754499.\n. I need committers who aren't on Pacific time. :P\n\nOn Sun, Jan 31, 2016, 9:17 PM Sean Griffin sean@seantheprogrammer.com\nwrote:\n\nI'm about to head to bed but assuming all the comments I left previously\nhave been addressed this is fine.\nOn Sun, Jan 31, 2016, 9:16 PM Matt Casper notifications@github.com\nwrote:\n\nAlright, I think everything has been resolved. Final review @sgrif\nhttps://github.com/sgrif @mfpiccolo https://github.com/mfpiccolo ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/161#issuecomment-177754499.\n. This is the main focus of 1.1. It's done.. Review? @mcasper @mfpiccolo @samphippen \n. So there's a couple of things here.\n- I don't want to merge this until we merge #161.\n  - After we merge that, this command should be diesel database seed not diesel seed\n  - diesel database setup should call this automatically.\n- The tests are failing with this change, as the current setup doesn't like migrations/seeds.sql. This should probably go somewhere other than the migrations directory, but I'm not sure where.\n\n\nI'm unsure how I feel about this feature. Can you give some details on what the use case for this is? Is there a reason we need this to be separate from migrations? It's also pretty easy for apps to just add a bin/seed.rs which does this. The only additional work required would be establishing the database connection, and passing this string to execute.\n@mfpiccolo @mcasper What are your thoughts?\n. > Dont think, that seeds.sql is the best way to make the bootstrap\n\nThis is \"first\" iteration, just not to start conversation about new feature without some \"working\" solution.\n\nI think if we are going to have that conversation, we should identify the problem we're trying to solve. I don't think that \"Rails does it that way\" is a good enough reason.\nDon't get me wrong, it's a useful tool in Rails. But we're working with a clean slate and I'd prefer to avoid extraneous features if we can avoid it. All I'm looking for is a concrete use case that is sufficiently painful without us providing this functionality out of the box.\n. I've given this a bit more thought, and am going to go ahead and close this. It's already easy enough to add bin/seeds.rs to your application without any additions to Diesel.\n. Review? @samphippen @mcasper @mfpiccolo \n. @mcasper @mfpiccolo ping\n. Oh also, somehow nightly on PG passes even though the failure is at compile time not runtime. Because... yeah... reasons...\n. I'd prefer to avoid using apt-get for this if we can. Trusty should ship\nwith 3.8 by default.\nOn Mon, Feb 1, 2016 at 11:24 AM Cameron Alexander notifications@github.com\nwrote:\n\nActually, scratch that. I was able to get the build to pass by manually\ninstalling the work around and setting the distro to precise instead of\ntrusty\nhttps://github.com/SoftwareWarlock/diesel/blob/diesel-sqlite-support/.travis.yml#L2\n.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/167#issuecomment-178109947.\n. It's definitely compatible with 3.8. If you look at the failure message\nappearing on Travis, it's due to sqlite3_errstr not being found, which\nmeans it's an ancient 3.7 version. Also note that the problem isn't that\ncodegen is failing to compile, but that Diesel as a dependency of codegen\nis failing\n\nOn Mon, Feb 1, 2016 at 12:37 PM Cameron Alexander notifications@github.com\nwrote:\n\nJust did a sanity check, and the version really is 3.8, so maybe the\ncodegen is compatible with 3.7.15, but not 3.7.9 nor 3.8?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/167#issuecomment-178145252.\n. ...And I just realized what the problem is.\n\nOn Mon, Feb 1, 2016 at 12:38 PM Sean Griffin sean@seantheprogrammer.com\nwrote:\n\nIt's definitely compatible with 3.8. If you look at the failure message\nappearing on Travis, it's due to sqlite3_errstr not being found, which\nmeans it's an ancient 3.7 version. Also note that the problem isn't that\ncodegen is failing to compile, but that Diesel as a dependency of codegen\nis failing\nOn Mon, Feb 1, 2016 at 12:37 PM Cameron Alexander \nnotifications@github.com wrote:\n\nJust did a sanity check, and the version really is 3.8, so maybe the\ncodegen is compatible with 3.7.15, but not 3.7.9 nor 3.8?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/167#issuecomment-178145252.\n. Wait, never mind, I don't actually know what the problem is. I thought it\nmight have something to do with\nhttps://github.com/sgrif/diesel/blob/master/diesel_codegen/Cargo.toml#L20,\nbut we override that in the cargo config to use the local path, and there's\nno reason that the error it'd cause would be related to an old version of\nSQLite.\n\n\nOn Mon, Feb 1, 2016 at 12:39 PM Sean Griffin sean@seantheprogrammer.com\nwrote:\n\n...And I just realized what the problem is.\nOn Mon, Feb 1, 2016 at 12:38 PM Sean Griffin sean@seantheprogrammer.com\nwrote:\n\nIt's definitely compatible with 3.8. If you look at the failure message\nappearing on Travis, it's due to sqlite3_errstr not being found, which\nmeans it's an ancient 3.7 version. Also note that the problem isn't that\ncodegen is failing to compile, but that Diesel as a dependency of codegen\nis failing\nOn Mon, Feb 1, 2016 at 12:37 PM Cameron Alexander \nnotifications@github.com wrote:\n\nJust did a sanity check, and the version really is 3.8, so maybe the\ncodegen is compatible with 3.7.15, but not 3.7.9 nor 3.8?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/167#issuecomment-178145252.\n. Fixed by a9117a3\n. Yeah, that's fine for now.\n. This is literally just a shim for like 4 weeks\n. Closing in favor of a9117a3. \n. Review? @mfpiccolo @mcasper \n. Only in tests for now. It might eventually turn into something that becomes more general.\n. Review? @mcasper @mfpiccolo \n. I have no clue. We'll do whatever makes the most sense as specific needs come up. :)\n. @mcasper Was this fixed by #189 ?\n. Review? @mcasper @mfpiccolo \n. Well I guess that leaves it to @mcasper \n. Er @mfpiccolo rather\n. /cc @mcasper \n. Strange it wasn't doing that for me.\n\n\n\nOn Tue, Feb 2, 2016, 11:48 PM Matt Casper notifications@github.com wrote:\n\n@sgrif https://github.com/sgrif It already does\n$ diesel setup\nCreated migrations/ directory at: /Users/mattcasper/code/home/test/migrations\nCreating database: my_db\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/177#issuecomment-179046227.\n. I'm a bit confused why we added the timestamp stuff to CLI. What I was imagining here is that we'd automatically create this function at the same point that we create the __diesel_schema_migrations table (which I need to better generalize to \"general metadata management\" before we can merge this), and then there was a SQL function you could call with a table name for no reason other than that I can never remember the trigger syntax. If we can't do the second half, I think we should just drop that and just provide this trigger automatically with no other behavior.\n. I think diesel_manage_updated_at is fine.\n. Just a heads up, this looks like it still has a good bit of work left to do. At this point I'm calling the cutoff point for 0.5 features. This can make it into 0.6 once it's updated.\n. This is perfect. One last comment. This also needs a changelog entry, and docs.\n. @robertmaloney SystemTime is unstable. You need to write your test against PgTimestamp\n. This was implemented by https://github.com/diesel-rs/diesel/commit/a7373087d7c18f7b594435def83697098511a249. Review? @samphippen @mfpiccolo @mcasper \n. Also @derekprior @tessgriffin @steveklabnik will likely have feedback on this. Please rip it to shreds. <3 \n. I've addressed the feedback given so far. Can anyone take another look?\n. Thanks everyone. I've addressed the last round of feedback in the implemented version. https://github.com/sgrif/diesel.rs-website/blob/master/source/views/guides/getting-started.html.slim\n. Permalink: https://github.com/sgrif/diesel/blob/b1a215b/diesel_cli/src/main.rs#L289\n. Yeah, I think so. I had envisioned broader support than #887 added, but I don't see any way to do that since we have to do string parsing with these types.. /cc @Eijebong . Upon further investigation, SQLite appears to have no visible difference in behavior between numeric and double precision floats. If anybody knows this to be incorrect, please let me know.\n. Review? @mcasper @mfpiccolo \n. The tests for this fail to compile.\n. Can you break out the stuff that moved into database.rs without changing in a separate commit to make it easier to review?\n. One comment. Please squash before merging.\n. Connections are very much only intended to be used on a single thread. This isn't just true of Diesel, but DBs in general. We do implement Send. I'm unsure why the Sync constraint exists on r2d2, but it shouldn't have it. You'll probably need to wrap it in a Mutex to make it happy. :\\ \n\nThe reasoning for using Rc instead of Arc there is covered in the commit that added it\n. @mfpiccolo @mcasper Review?\n. Yes, I need to re-use that ensure_sqlite_ok function somewhere.\n. Bumping to the 0.7 milestone. SQLite has extremely simple semantics, and we should at least be able to implement it for at least that backend. PG might get bumped to 0.8.\nI don't think we can abstract over this in a database agnostic way. Instead we will provide backend specific APIs. SQLite will probably be insert(&new_record).into(table).on_conflict(replace)\n. SQLite provides 5 options for alternate behaviors. REPLACE, ROLLBACK, ABORT, FAIL, and IGNORE. We won't provide support for INSERT OR ROLLBACK, as our handling of transactions is based on lexical scope and we can't properly handle this case.\n. Is this a blocker for your application? I can definitely get it done for 0.8\n. Tentative release date for 0.8 is the 28th (if enough little things like this get completed I might release sooner though)\n. It will be in the next release. 0.8 was featureless as we needed to get macros 1.1 support out. . I'm going to release 0.9 today. Unfortunately, I wasn't able to complete this in time despite my best efforts. PG's upsert is an extremely complex feature, and it's just going to take some more time for me to implement proper support with an API that is up to our standards. I can't push back the 0.9 release any longer, as I am going on vacation on Tuesday and I want to release with enough time to fix any issues that may occur. So I will move this to the 0.10 release, which is slated for the end of January.. @seamusabshere No, just a few spikes which I'm going to throw the code away from.. That's the main thing I'm trying to decide on. I need to spike on it a bit more to decide for sure. I think it'll probably be something like the examples below. Feel free to take a swing at it if you'd like, but I suspect that implementing this properly will require a pretty thorough knowledge of our internals. I'm skipping all of the modifiers on the conflict target for now. I'm also unsure if I want to handle multiple on conflict clauses to start, but I've included it below.\n```rust\n// In addition to the examples that I say must fail to compile, all of this must fail to compile if used with a backend other than PG.\n// single record ON CONFLICT DO NOTHING\ninsert(&new_user.on_conflict_do_nothing()).into(users)\n// multi-record ON CONFLICT DO NOTHING\ninsert(&vec![user1, user2].on_conflict_do_nothing()).into(users)\n// Need to ensure that this does not compile\ninsert(&vec![user1.on_conflict_do_nothing()]).into(users)\n// everything below should also work with vecs, should also fail to compile if the conflict handler is on a record inside the vec\n// single record single handler by constraint name\ninsert(&new_user.on_conflict(on_constraint(\"users_pkey\"), do_update().set(any_valid_as_changeset)).into(users)\n// should fail to compile\ninsert(&new_user.on_conflict(on_constraint(\"users_pkey\"), do_update().set(posts::title.eq(\"foo\"))).into(users)\n// single record single handler with where clause\ninsert(&new_user.on_conflict(on_constraint(\"users_pkey\"), do_update().set(any_valid_as_changeset).filter(any_valid_predicate)).into(users)\n// should fail to compile\ninsert(&new_user.on_conflict(on_constraint(\"users_pkey\"), do_update().set(any_valid_as_changeset).filter(non_bool_expr)).into(users)\n// should fail to compile\ninsert(&new_user.on_conflict(on_constraint(\"users_pkey\"), do_update().set(any_valid_as_changeset).filter(posts::title.eq(\"hi\"))).into(users)\n// single record single handler by single column\ninsert(&new_user.on_conflict(id, do_update().set(any_valid_as_changeset)).into(users)\n// single record single handler by multiple columns\ninsert(&new_user.on_conflict((project_id, email), do_update().set(any_valid_as_changeset)).into(users)\n// single record single handler by arbitrary expr\ninsert(&new_user.on_conflict(lower(email), do_update().set(any_valid_as_changeset)).into(users)\n// should fail to compile\ninsert(&new_user.on_conflict(posts::id, do_update().set(any_valid_as_changeset)).into(users)\n// single record multiple handlers\ninsert(&new_user.on_conflict(any_valid_args).on_conflict(any_valid_args)).into(users)\n// ON CONFLICT DO NOTHING with conflict_target\ninsert(&new_user.on_conflict(id, do_nothing()))\n```\nI think that's everything, though I might have forgotten a few cases.. Depending on how important actual atomicity is, the easiest workaround would just be to do a SELECT query on the fields that could conflict, filter the vector, and then an update. You could also write a stored procedure and use sql_function!. I am going to do on_conflict_do_nothing before the rest though, I might be able to finish just that piece of it soon.. Yes, I agree. The hard part is mostly just making sure that incorrect uses fail to compile.. The plan is to have ON CONFLICT DO NOTHING as part of 0.11.. Removing from the milestone since ON CONFLICT DO NOTHING is all we are planning on doing for upsert in 0.11. The rest will probably be in 0.12. ON CONFLICT DO NOTHING is implemented by #712. It's a Rust bug, not a Diesel one. It sometimes does weird recursive trait lookups when the type at the bottom of it is a type error.. Yeah, maybe give &(*score_chunk).on_conflict_do_nothing() a try or even &OnConflictExtension::on_conflict_do_nothing(score_chunk). I'll add an explicit test for when the type is &[T] and not Vec<T>. Nope, I need to add a : ?Sized constraint on the trait I think.. I'll release a 0.11.1 with #723 once it's green.. #793 implements this with two main exceptions:\n\nON CONFLICT DO UPDATE with expression indices\nON CONFLICT DO UPDATE with a where clause on the update\n\nThese are both things that we will eventually support, but at the moment they are not prioritized. If you need one of those two features, please let me know.. Last time I'd checked rustfmt, it still didn't support a few options that we'd need to use it. The big one that stands out immediately is moving the where to the next line. Generally our style is chosen to reduce git churn as much as possible, as I rely on git blame pretty heavily for context. The where change would mean the line with the second predicate would have to change if I want to delete the first.\nStill, I'll fiddle with it a bit and see if it's at a reasonable place for us to use. I'm willing to make some concessions if it means being able to use this in place of a style guide.\n. Just so I'm clear, when you say \"the current style\", you mean the style proposed by this PR?\n. Looks like there is no option for the placement of where. Unfortunately, this would be just too much churn without it. :( https://github.com/rust-lang-nursery/rustfmt/issues/815\n. In theory it should be possible, yes. However our API isn't really designed for that use case.\n. Also worth noting that all of the documentation examples you've added fails to run. That will need to be addressed as well before this can be merged. We have a script to help you run all of the test suites locally at bin/test, usually good to double check it before pushing.\n. Sorry for the delay in responding to this. I've been on hiatus for a few weeks. I'll take another look at this soon -- just wanted to let you know I haven't forgotten\n. There's a lot of style nitpicks as well, but I can just fix those manually. Will take another look today or tomorrow when I can go a bit more in depth.\n. Heading out of town, but I'll take a look when I have a chance.\nOn Tue, Apr 5, 2016, 4:14 PM Georg Semmler notifications@github.com wrote:\n\nHopefully all style nitpicks are fixed. If not please leave a comment.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/199#issuecomment-206004807\n. It's unclear to me why any code in the migrations module should need to be changed for this feature. It seems like this change needs to:\n- Generate a struct with the up and down string, along with the version\n- Implement the Migration trait\n- Generate a constant with all the instances of this struct\n- Generate a single function to which runs from that constant\n. Can we do some pub exports or make the module public instead of moving so\nmuch code around?\n\nOn Thu, Apr 14, 2016, 6:32 AM Georg Semmler notifications@github.com\nwrote:\n\nMost changes in the migration module are needed to reuse the code in\ncodegen (migration::migrations is not public). Furthermore I add a function\nto run migrations from a Iterator instead of running them from a directory.\nThe codegen part does more or less what you describe.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/199#issuecomment-209915472\n. Thank you. I will review/merge soon.\n. Thank you for working on this. I've gone ahead with a separate implementation, though this PR was used as a reference. I'll make sure you're credited for the feature in the next release announcement.\n. What is the diesel_test_helpers code shared with? It's only used by the tests you added?\n. What do you mean by share code? What is it being shared with?\n. You don't need to move it to another crate for that, take a look at cargo's test suite for example.\n. https://github.com/rust-lang/cargo/blob/master/Cargo.toml#L57-L58 no black magic involved\n. This needs an entry in types_roundtrip.rs\n. Look at some of the other examples in that file. It's pretty straightforward\n\nOn Thu, Feb 11, 2016, 1:30 AM Andrew Ryan Lazarus notifications@github.com\nwrote:\n\nHmmm. How do I types_roundtrip.rs?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/202#issuecomment-182761608.\n. Shouldn't need to newtype it, look at how we handle NaiveDate and NaiveTime. The last argument to that macro can be a function to create the type.\n. I'm taking a few days off, I'll review when I'm back\n\nOn Wed, Feb 24, 2016, 12:10 AM Andrew Ryan Lazarus notifications@github.com\nwrote:\n\nThoughts?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/202#issuecomment-188111514.\n. @nerdrew Are you still interested in working on this? There's a few more comments that need to be addressed before this can be merged.\n. Diesel is probably using a different version of the UUID crate than your code.\n. Build should be green if you rebase, as well\n. No problem.\n. I've released version 0.5.1 to address this. You can install with cargo install diesel_cli --no-default-features --features postgres now.\n. Can you give some steps to reproduce? Do you have write access to that directory? (Also does that directory exist?)\n. When I run the test suite against a file backed database with RUST_TEST_THREADS=1, the tests pass.\n. https://gist.github.com/sgrif/1495ed44ac1d83cf2381, then set DATABASE_URL to something like foo.sqlite3 and run the tests.\n. I was able to replicate the error by attempting to run tests with a file in the Application Support directory.\n. It appears that SQLite doesn't like paths with a space in them.\n. No, foo.db is the valid way, not ./foo.db. It looks like dotenv on Rust doesn't handle any type of quoting or escaping. If you're using that, make sure that the DATABASE_URL line is set to:\n\nDATABASE_URL=/Users/zamith/Library/Application Support/ActionAlly/action_ally.db\nand not\nDATABASE_URL=\"/Users/zamith/Library/Application Support/ActionAlly/action_ally.db\"\nor\nDATABASE_URL=/Users/zamith/Library/Application\\ Support/ActionAlly/action_ally.db\nBased on your original post, I'm guessing that you have double quotes in your .env file.\n. Also, doing ./foo.db seems to work for me just fine. Not sure what's up with that.\n. I'm opening an issue there now. No worries, glad we got it resolved.\n. You are correct, we are missing support for group_by (and more generally, we are also missing the ability to select multiple aggregate expressions even if it's valid. Ref #3). This is something I'd like to add support for in the future. We haven't gotten to it yet, as the features that we're targeting for 1.0 are features that are likely to require breaking changes to our existing API (0.6 will bring a reworking of associations, and is currently planned to be the last release before 1.0).\nFor the most part, your workaround appears to be the way to go about doing this in the short term. The sql function will never infer the type, and will always need it to be specified. Text isn't correct here though, BigInteger is.\nIn the short term, I think it's fine for us to add a group_by function (not public API, as it will change when we properly support it) that takes a column. Because .filter(sql(\"TRUE GROUP BY ...\")) is silly and you shouldn't have to do that.\n. @barosl I've pushed up 6df20de which adds a group_by method. This is not part of the public API, and has only the most basic of tests for it. This method will almost certainly have breaking changes when we properly support the group by clause publicly, but I wanted to make sure you had a reasonable workaround. With this, your workaround can become:\nrust\ndonate::table.select((donate::name, sql::<BigInteger>(\"sum(amount) AS sum\")))\n             .group_by(donate::name)\n             .order(sql::<BigInteger>(\"sum\").desc())\n             .load(&*db).unwrap();\nwhich is a little more sane. I'm not going to ship a new version for this change, as it doesn't affect the public API. That means you'll have to point at git for now, but next time I have a bug fix to use as an excuse I'll ship 0.5.2 which will include that change.\nThis \"fix\" does not close this issue, nor does it constitute proper group by support, it's simply a crappy workaround that is slightly less crapy than filter(sql(\"TRUE GROUP BY ...\"))\n. Note for anybody reading this because they're looking for issues to work on:\nBefore we can add proper support for group by, we almost certainly need to resolve #3.\n. > because although it's a bit silly as you said, there seems to be no other \"better\" workarounds out there\nI just pushed a better workaround. :P Still not great, but less silly at least.\n\nand Text happens to be SqlOrd. Is my assumption correct?\n\nSqlOrd actually is only for functions like max. .order doesn't care about the type that you pass it. My comment about the type was for your select clause, not your order clause.\n. > Oh, I thought the added group_by was for internal use because you said it was not part of the public API. By \"public API\" did you mean the method was #[doc(hidden)]?\nCorrect\n\nI guess, even though .order doesn't care about types particularly, using BigInteger in there too is \"correct\"\n\nAlso correct\n. Oh yay, we're failing on nightly for obscure reasons again! >_>\nYeah, as @mcasper mentioned, try switching to an older nightly. Assuming you're using multirust, run\nrust\nmultirust update nightly-2016-02-09\nmultirust default nightly-2016-02-09\nI'll get us working on the latest nightly soon.\n. Looks like this was caused by https://github.com/rust-lang/rust/pull/31487. I'll push up a fix as soon as I can (we need to synchronize dependencies for syntex versions), but I won't be doing a release for this change.\nI've updated the website to include a note about this. Thank you for bringing it to our attention, @defyrlt \n. :shipit: \n. Woo tests!\n:shipit: \n. Should we mention somewhere that you can do diesel SUBCOMMAND --help for more information?\n. Can you update this to point at git for dotenv?\n. Or just point your cargo file at git?\n. Just point it at this repo.\nOn Fri, Feb 19, 2016, 7:21 PM nokaa notifications@github.com wrote:\n\n@sgrif https://github.com/sgrif I attempted to do that, but I was\nunsure what url to use for diesel_codegen.\nhttps://github.com/sgrif/diesel/diesel_codegen and\nhttps://github.com/sgrif/diesel/tree/master/diesel_codegen both failed to\nclone.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/218#issuecomment-186497041.\n. I don't think we need to add that overhead here, as this is usually just meant to be the \"locally run smoke test\". When dealing with stable failures, just running the integration test suite is almost always enough.\n. Can you squash these commits?\n. You need to call table! directly for SQLite at the moment.\n. You would always use types::Timestamp in the table macro. data_types::PgTimestamp is something that can be deserialized from a column of that type.\n. Been out of the country and still getting caught up. Haven't had a chance\nto re-review yet. Will do today.\n\nOn Sun, Mar 27, 2016, 3:29 PM Georg Semmler notifications@github.com\nwrote:\n\nIs there anything preventing this from being merged, except of time?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/226#issuecomment-202148159\n. There were a lot of style changes that needed to be fixed, but I've gone ahead and updated manually. Normally I'd squash it into the previous commits to avoid git churn, but they were numerous enough to warrant keeping them separate. Please make an effort to avoid these sorts of changes in the future, we take git churn pretty seriously.\n. Sorry for taking so long to reply here. I've looked through your code, and nothing looks immediately wrong to me. Is it possible to replicate this issue with less code? Sorry for the troubles that you've been having. Improving our error messages for cases like this is definitely on the radar.\n. @jimmycuadra Were you able to pare this down at all? I tried to build your example, but there's conflicts with quasi (presumably due to serde versions not being updated for the latest nightly or something). If you can just pull out the diesel code into something I can use to reproduce, that'd be helpful. But I can't build your entire app.\n. Thanks for the update. Let me know if there's anything else I can do to help.\n. Thanks, I'll try to fix this today.\n\nOn Thu, Mar 31, 2016, 1:40 AM Jimmy Cuadra notifications@github.com wrote:\n\nI got a chance to look at this again and was able to reproduce the error\nwithout so much set up and unrelated code. Take a look here:\nhttps://github.com/jimmycuadra/diesel_error\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/227#issuecomment-203800916\n. I should have spotted this originally. The issue is that insert(new_access_token) should be insert(&new_access_token). If you make that change, the code behaves as expected. (It still doesn't compile because FromSql<diesel::types::BigInt> isn't implemented for num::bigint::BigInt, but that field should be an i64 anyway because a big integer in PG is just 64 bits, not infinite).\n\nThat said, there's no reason you would be expected to figure out the problem in your code from the error message given. We either need to improve the error message here, or just have this case work. I've opened a new issue for that in #249.\nThanks for the report, sorry I didn't spot the error initially.\n. No problem. The result ended up being a big win for our error messages.\n. > Why is this not the case?\nShort version is that with SQLite, there's no cost to an additional connection. That said, I don't have a terribly strong opinion one way or another. If you want to open a PR for this with an argument laying out why implementing Send is beneficial over just establishing a new connection as you need it, I'd be open to it.\n. > Does diesel automatically escape variables to prevent SQL injection attacks?\nYes.\n\nEither way, it would be helpful to discuss what measures are taken by diesel \n\nI'm not sure we should go too in depth here. Protection from SQL injection attacks is pretty much an assumed feature of any ORM.\n\nwhat measures should be taken by the user to prevent SQL injection attacks.\n\nNone\n. Going to close this issue. Please do comment if you still think that there is something actionable to be done here.\n. Again, I think that escaping identifiers and strings (or using prepared statements, which is what we do) would be assumed of all ORMs, but feel free to open a PR and we can discuss the specific changes you'd like to make to the docs.\n. Yes, there's a function for writing raw SQL (though its use is discouraged as you lose the vast majority of the safety benefits the query builder provides). http://sgrif.github.io/diesel/diesel/expression/dsl/fn.sql.html\nThis query written using the query builder is basically one-to-one with the equivalent SQL.\n``` rust\nuse diesel::prelude::;\nuse diesel::expression::{sql, count};\nuse hosts::dsl::;\nhosts.select(id, hostname, created_at, updated_at)\n    .left_outer_join(logs::table)\n    .filter(logs::app_id.eq(whatever))\n    .group_by((hostname, id))\n    .order(count(logs::app_id).asc())\n    .limit(1)\n```\n. No, this is a major limitation at the moment. We need specialization to do\nthis safely. There's an issue open for this but I'm on my phone and can't\nfind a link at the moment\nOn Fri, Mar 18, 2016, 11:22 AM Andrew Ryan Lazarus notifications@github.com\nwrote:\n\nFollow up question: is it possible to have multiple joins? I see a test\nfor a join through, but what about cases where there isn't a through?\nWhat I want:\nlogs::table.select((logs::id, users::id, hosts::id))\n    .inner_join(hosts::table)\n    .inner_join(users::table)\n    .limit(1)\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/231#issuecomment-198218919\n. This isn't something I would want to put in the main Diesel crate, but it was designed to make it easy to add support for extensions like this. Here's an example crate which adds support for PG full text search. https://github.com/sgrif/diesel_full_text_search/blob/master/src/lib.rs\n. This needs compile fail tests for all of the following:\n- update(users).set(changes).returning(posts::title) needs to fail (columns from other tables, or more specifically, violating SelectableExpression)\n- update(users).set(changes).returning(count(id)) needs to fail (cannot have aggregate expressions in a returning clause)\n- Attempting to run a query using an explicit call to returning on SQLite.\n. @mcasper @mfpiccolo Review?\n\n@mcasper When finished, this feature should cover the use case we discussed.\n. Whoops, sorry about that. Publishing now\n. Should be good now\n. Can you open a new issue and provide the full error?\n. :+1:\n. Travis uses an ancient version of SQLite and you have to go through contortions to get it to work (see our travis.yml's history). However, the \"update SQLite\" issue on the travis package whitelist repo was recently closed, so they may have fixed it.\n. > What exactly would I have to install?\nAny version of libsqlite that is more recent than 2012\n. Sorry, I've been away on travel. I'll make sure this gets dealt with as quickly as possible.\n. Side note, that I don't have a better place to document. I'm thinking we should start reaching out to Serde and other prominent crates to loosen their syntex versions when possible (even if it means writing code differently to work on other versions). The shared dependency on Syntex is effectively forcing us (and others like dotenv, which hasn't actually had a code change associated with a syntex bump in ages) to churn immediately when any part of libsyntax changes, even if we aren't affected by it (e.g. our nightly tests still pass).\n. I disagree, we do need to explicitly bump the version with each release. These changes are breaking code for someone, just not us as we're not relying on it. The problem is that there's urgency to do so with each release, since as soon as serde makes a hard version bump (and not a range), every other project is going to get a ton of issues opened. Sometimes this will be unavoidable (we actually had to make code changes going from 0.27.0 to 0.28.0), but I think it can be less than it is now.\n. I also need to finish my work on making it more pleasant to use diesel on stable without syntex, but that still doesn't solve the problem unless we want to actually remove it as an option\n. I've published v0.5.4 of diesel_codegen with the updated dependencies\n. @erickt No, we recently dropped aster and quasi as dependencies, as they made the issue worse. The more transitive dependencies on syntex, the worse it is. We no longer have anything transitive, but everybody effectively has it as a transitive dependency through serde.\n. Right. That's basically the use case for syntex. ;)\n. Should this be >= 0.28.0, < 0.31.0?\n. Cool. Was about to push the same, but if you can update this I'd like to see a green CI run. I've updated dotenv master\n. Review? @mfpiccolo @mcasper \n. This seems like a bug in Rust, but we should be able to work around it.\n. Fixed in 4771cb6b624ae4fbff42ed6115034b831591125c\n. Review? @mfpiccolo @mcasper \n/cc @jimmycuadra\n. @weiznich Is this ready to go?\n. Thank you for working on this!\n. Hm. Looks like I broke the website when setting up the docs subdomain... Let me see what I can do. \n. I've fixed the DNS records. It might take up to an hour for the record to propagate. \n. Review? @mfpiccolo @mcasper \n. Review? @mfpiccolo @mcasper \n. Review? @mcasper @mfpiccolo \n. Review? @mcasper @mfpiccolo \n/cc @LordPython\n. Ping @mcasper @mfpiccolo I would like to roll a release soon with this PR in it.\n. Review? @mfpiccolo @mcasper \n. Two issues here. The first is that table! is generating all_columns = (id) instead of all_columns = (id,). This is the actual bug. However, I think it probably makes sense for us to generate a queryable impl for T as well as (T,) when a struct has only one field. That's a separate addition.\n. Review? @mcasper @mfpiccolo \n. Build will fail as master still needs a syntex update.\n. This has been fixed in master, and 0.6.0 is being released with the new constraint.\n. Sorry, I missed this!\n. Review? @mcasper @mfpiccolo @samphippen \n. Any objections to merging this?\n. Review? @mcasper @mfpiccolo @samphippen \n. Probably every historical major/minor version, but not patch versions\nOn Thu, Apr 14, 2016, 10:16 PM Matt Casper notifications@github.com wrote:\n\nDo we want docs.diesel.rs/ to support every historical version\nof diesel, or just the most recent (major?) release? Just the past couple\nreleases?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/issues/268#issuecomment-210278132\n. We're meant to doc with all features enabled, but I believe I forgot to add uuid. Might be worth adding an all feature so there's a more local place to update this as new features are added.\n. Review? @samphippen @mcasper @mfpiccolo \n. This is because defining relationships is not a stable/supported feature. It's a work in progress that is likely to change significantly. I'm hoping to have this feature finished for the next release. #89 is the tracking issue for this feature.\n. Review? @mfpiccolo @mcasper @samphippen \n\nI'd like to roll a release with this fix ASAP\n. This breaks the build. We need this to be pretty extensively tested before we can review it further. In addition to tests that demonstrate logging works at all, we should have tests making sure that backend specific features can be used with the logging connection, and compile-fail tests to show that features for a different backend can't be used (e.g. if this is wrapping a SqliteConnection, we need to ensure that you can't use PG specific features)\n. > Queries using parts that are only available with a specific backend?\nYes. For example, DebugConnection<SqliteConnection> should not be able to use Any for example, while DebugConnection<PgConnection> should.\n\nThe former should work with the current implementation, as it passing everything down to the specific backend in the end\n\nCool. Need tests for it though, and most importantly we need tests that trying to pass a query containing an Any or similar to DebugConnection<SqliteConnection> fails to compile.\n\nI think there are only tests needed to check the functionality\n\nYes we should test the functionality. ;)\n\nAre there are some tests for PgConnection/SqliteConnection?\n\nIt's not so much about testing the connection as it is about testing the behavior of the entire system. That is what our integration tests are for. We prefer to be fairly exhaustive in our testing.\n. I'm in the middle of moving to another country for the next few weeks. I'm\npretty unavailable, but I'll see if anyone else in the core team has\ncomments.\nOn Sat, May 7, 2016, 3:42 PM Georg Semmler notifications@github.com wrote:\n\nAny comments on this?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/272#issuecomment-217667570\n. Probably going to include this in 0.8, will re-review soon once 0.7 ships\n. I'm going to go ahead and close this, as it would need quite a bit of work to bring up to date. I really wanted to have logging be a separated concern from everything else, but I don't think that's feasible as we've encouraged people to write &PgConnection and not C: Connection<Backend=Pg>(_: &C). So ultimately this solution will probably need to have a set_logger method on connection. It'll also need to integrate with prepared statement caching, since we generally don't actually generate the SQL string anymore.. > I think somebody forgot\n\nHeh. I appreciate politely avoiding calling out my dumb mistake. \ud83d\ude49 \ud83d\ude48 \ud83d\ude4a \n. Interestingly, I think the effects of this would be relatively minor. The version of Diesel that codegen uses wouldn't affect the code that it generates. Really the only thing that CLI and Codegen are affected by from Diesel is the Connection, which didn't have any changes to it in 0.6. Either way, we should point at the latest version because it's silly not to.\n. Nice catch. Thanks!\n. Also usually you shouldn't bump crate versions in PRs. We will bump when actually releasing.\n. Bytea should be working fine in 0.6.1.\nTo answer your more general question, there's no way to ignore them, but you can call the table! macro directly for those tables, and then call infer_table_from_schema! for the rest of the tables, instead of infer_schema!\n. Closing this as there's nothing actionable. If this didn't sufficiently answer your question, feel free to ping me here or in gitter (and if Bytea isn't working in 0.6.1 that is definitely a bug)\n. Were you ever able to confirm that at least Bytea was working correctly for you?\n. :+1: Yeah, need to add support for those types (will likely be a separate crate actually). Still unresolved questions, but if you're interested in working on it let me know and I'd be happy to help. Tracking issue: https://github.com/diesel-rs/diesel/issues/44 \n. Review? @mcasper @mfpiccolo @samphippen \n. Review? @diesel-rs/core\n. @samphippen @mfpiccolo @mcasper I have no clue if that last comment pinged\n. It looks like github pages aren't redirected, so any links written before I set up the docs.diesel.rs domain will die. I don't think there's anything we can do to fix this.\n. Review? @samphippen @mcasper @mfpiccolo \n. I don't think so. The only important cases are the ones that return the literal false. The tests there were more to drive implementation than enforce anything specific. Perhaps I need to change the implementation to make this more clear, but all the \"fiddly\" cases are basically saying \"I'm safe to cache if all of my components are safe to cache\"\n. Review? @mfpiccolo @mcasper @samphippen \n. Digging into it now.\n. So the reason that it's compiling as a dylib is because it needs to be for nightly. I'm looking into if there's a way for me to conditionally set plugin = true for Cargo.toml or if we need to split this into an entirely separate crate.\nSince you're able to build by making sure libpq.dll is on the path, go ahead and keep doing that. If you're only using stable, you can remove the diesel_codegen line from dependencies, as it's only needed in [build-dependencies].\n. I think I've got a fix upstream. Confirming that it doesn't break nightly usage.\n. This has been fixed. Your app should compile fine if you point diesel_codegen at git = \"https://github.com/diesel-rs/diesel.git\". For use with stable, you will also need to change syntex to 0.31.0 and point dotenv_codegen at git as well.\n. For completeness, these are the changes I made to get a working build without libpq.dll on the path for my machine (which is Windows). pg_config.exe does still need to be on the path.\n``` patch\ndiff --git a/Cargo.toml b/Cargo.toml\nindex 6661653..d779718 100644\n--- a/Cargo.toml\n+++ b/Cargo.toml\n@@ -5,13 +5,13 @@ authors = [\"Sean Griffin sean@seantheprogrammer.com\"]\n build = \"build.rs\"\n[build-dependencies]\n-syntex = { version = \"0.26.0\", optional = true }\n-diesel_codegen = { version = \"0.5.0\", default-features = false, features = [\"postgres\"] }\n-dotenv_codegen = { version = \"0.8.0\",  optional = true }\n+syntex = { version = \"0.31.0\", optional = true }\n+diesel_codegen = { git = \"https://github.com/diesel-rs/diesel.git\", default-features = false, features = [\"postgres\"] }\n+dotenv_codegen = { git = \"https://github.com/slapresta/rust-dotenv.git\",  optional = true }\n[dependencies]\n diesel = \"0.5.0\"\n-diesel_codegen = { version = \"0.5.0\", default-features = false, features = [\"postgres\"] }\n+diesel_codegen = { git = \"https://github.com/diesel-rs/diesel.git\", default-features = false, features = [\"postgres\"] }\n dotenv = \"0.8.0\"\n dotenv_macros = { version = \"0.8.0\", optional = true }\n``\n. Review? @diesel-rs/core \n. Yeah, definitely. Since we still have the string keys in some cases though, it'd probably be best to split out two different caches, and perform the lookup based on which variant we have. Since that's a bit of a larger change, I wanted to keep it as a separate PR (if we do it at all -- I'm not sure the benefits are worth it)\n. Also to clarify, this only affects PG not the text type in general. SQLite handles nul bytes fine. \n. This is now documented on [theTexttype](http://docs.diesel.rs/diesel/types/struct.Text.html). It may be worth documenting elsewhere, but this issue seems resolved for the time being.. There actually is something I'd like to address here. That error message isn't as helpful as it could be. It should be something along the lines ofToSql is not implemented for String. (Unsure if we can actually make that happen in this context though)\n. Do you have PG installed? If so, you need to make sure thatpg_configis on the path, or thatlibpqis in/usr/local/includeor some other path that ld can see. If you don't want PG support, then runcargo install diesel_cli --no-default-features --features sqlite`\nFor SQLite, do you have pkg-config installed? Does sqlite3 show up in pkg-config --list-all?\n. Closing as there's nothing actionable here. I'm happy to help you get your system set up properly, but this is likely a configuration problem. If there is a bug, it's either in pq-sys or libsqlite3-sys\n. I'm sometimes in #rust, but the best way to reach me is in our gitter room. Link is in the README\n. Explored this a bit. Tests mostly passed. Only place I had to make a change outside of Diesel's code was here, as VarChar can no longer be referenced as a struct. The type argument was never actually used though, so it was trivial to eliminate and replace with PhantomData instead.\nI also dug into how this might affect us on the supported backends. SQLite we already know for sure won't be affected, as there is on varchar or text type, only the text affinity. For PG, things are kinda similar. We already know that they're treated the same under the hood. In the public API, it's a similar story. The varchar type (oid 1043) basically is never used. All functions or operators work with the text type (oid 25) instead.\n```\n[local] sean@sean=# select count(*) from pg_operator where oprleft = 1043;\n count\n\n 0\n\n[local] sean@sean=# select count(*) from pg_operator where oprleft = 25;\n count\n\n22\n\n[local] sean@sean=# select count(*) from pg_proc where 1043 = any(proallargtypes);\n count\n\n 0\n\n[local] sean@sean=# select count(*) from pg_proc where 25 = any(proallargtypes);\n count\n\n41\n\n```\nThis works because there's a cast defined between the two types.\n[local] sean@sean=# select * from pg_cast where castsource = 1043 and casttarget = 25;\n castsource | casttarget | castfunc | castcontext | castmethod\n------------+------------+----------+-------------+------------\n       1043 |         25 |        0 | i           | b\nThe wrinkle here is that the same is not true for varchar[] and text[]. This doesn't affect the most common cases, like insert/update. It does however affect all functions and operators. If the type of a column is varchar[] on the db side, doing filter(column.eq(vec![\"1\"])) would result in ERROR:  42883: operator does not exist: character varying[] = text[].\nWe could maybe work around that by doing some sort of internal nonsense that only affects arrays. While this might be an annoying gotcha, I think it's relatively low cost to just have the situation be \"if you're using a text array, use text[] not varchar[]\". The gains elsewhere are worth it.\n. Review? @diesel-rs/core \n. LoadDsl feels like a really weird place to document it, since this affects\nall traits not that one. It is a likely place people are to encounter the\nproblem, though\nOn Sat, Apr 30, 2016 at 5:00 AM gregcline notifications@github.com wrote:\n\nMaybe it could go in the LoadDSL trait documentation here:\nhttp://docs.diesel.rs/diesel/prelude/trait.LoadDsl.html\nI know I ended up there looking for my different options for executing\nqueries, and it seems that this trick depends on decoupling the actual\nexecution call from building the query.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/290#issuecomment-215955128\n. I'm going to do the same thing that I did in #1343 to LoadDsl and friends which makes this trick obsolete.. > It looks to me like both errors are choking on a &std::vec::Vecstd::string::String where I would expect to see std::vec::Vecstd::string::String\n\nIt takes a reference because the place where we construct the values is in a method that takes &self on the AST, not self, so each field needs to be borrowed. We actually implement the various traits on &'insert YourStruct not YourStruct directly. This used to be because the structure of the code demanded it. That's no longer the case, but we still borrow the data simply because there's no reason for us to own it, and it's nice to be able to pass in a slice rather than a vector. That said, maybe it's worth re-considering that use case...\nNone of this is relevant to the actual bug, just wanted to answer the question.\n. Couldn't replicate with our test suite's schema. Noticed that our array column is NOT NULL, I think that's the culprit.\n. Currently we don't support arrays containing null or multidimensional arrays. As you mentioned, neither of these changes are necessarily enforced on the backend side, and we're not sure what the best solution is there.\n. The officially supported nightly version for 0.5.4 was nightly-2016-03-11. Please update to 0.6.1 to use with nightly-2016-04-09 or later (syntex 0.31.0)\n. I need to update diesel_demo now that it's dependencies are updated... Will report back when it's done\n. diesel_demo should be up to date.\n. The getting started guide on diesel.rs should be up to date.\n. Let me know if you have any more issues. :)\n. Review? @diesel-rs/core \nDocs will be a separate PR, as we need to document the existing behavior as well.\n. Right now the correct type to use is NaiveDateTime, as we don't treat timestamp and timestamptz as separate types yet.\n. I've opened https://github.com/diesel-rs/diesel/issues/295 to address this\n. Yes that is the plan\nOn Wed, May 4, 2016, 1:49 PM Adam Perry notifications@github.com wrote:\n\nWhat about supporting timestamp with time zone columns for PG? There\nwould be a clear (in my mind) mapping:\n- NaiveDateTime -> timestamp / timestamp without time zone\n- DateTime -> timestamptz / timestamp with time zone\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/295#issuecomment-216963531\n. We don't have any support for upsert at the moment, but this is something I'd like to add in the future. See https://github.com/diesel-rs/diesel/issues/196. I'm going to bump this to the 0.7 milestone, as SQLite in particular should be extremely easy to support for this case. I'll see if I can add it today.\n. No problem. SQLite also supports specifying that upsert should occur in the table's schema. Worst case, you could always specify the ON CONFLICT clause for the primary key (or whatever index it is that you're wanting this behavior on). Diesel generally doesn't have opinions about how you structure your schema (with exception of things that we just don't handle yet, like composite primary keys)\n. Review? @diesel-rs/core \n\n/cc @llogiq\n. @llogiq :heart: !!! Let me know if there's anything else you're missing. \n. Yes you are right we should attempt to explore that in 0.7 or 0.8\nOn Wed, May 11, 2016, 10:16 AM iqualfragile notifications@github.com\nwrote:\n\nmaybe support for composite primary keys? I guess that would mean some\nchanges, not sure if the api would change though.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/298#issuecomment-218472736\n. Everything in this issue has been resolved. group_by is going to wait for 2.0. Logging has been removed from the milestone (we can add it backwards compatibly I think, though it'll require a default impl of the set_logger method on Connection which panics). Joins have been sufficiently reformed.. Also...\nRight now the plan is to have 0.7 be the last release before 1.0\n\nYeah, that worked out well... >>\n. We really need to make concat_idents! useful. XD\n. Thanks! :heart:\n. I think I'm going to rework the definition to allow pasting the struct def into the macro. We should test that _all variants are handled.\n- [x] Struct with pub\n- [x] Struct without pub\n- [x] Named fields with no annotations\n- [x] Named fields with one or more #[column_name(name)]\n- [x] Named fields with ignored attributes\n- [x] Named fields with both #[column_name(name)] and ignored attributes\n- [x] Named fields with pub and any of the above\n- [ ] Tuple fields with one or more #[column_name(name)]\n- [ ] Tuple fields with both #[column_name(name)] and ignored attributes\n- [ ] Tuple fields with pub and any of the above\n- [ ] Named or tuple fields which are optional with any of the above\n. This is what the \"bottom\" of the macro will probably look like for Insertable:\n``` rust\n    (\n        table_name = $table_name:ident,\n        struct_ty = $struct_ty:ty,\n        lifetimes = ($($lifetime:tt),),\n        values_ty = $values_ty:ty,\n        self_to_columns = $self_to_columns:pat,\n        columns = ($($column_name:ident, $column_kind:ident),+),\n    ) => { parse_as_item! {\n        impl<$($lifetime,) 'insert, DB> ::diesel::persistable::Insertable<$table_name::table, DB>\n            for &'insert $struct_ty where\n                DB: ::diesel::backend::Backend,\n                $values_ty: ::diesel::persistable::InsertValues,\n        {\n            type Values = $values_ty;\n        fn values(self) -> Self::Values {\n            use ::diesel::expression::{AsExpression, Expression};\n            use ::diesel::persistable::ColumnInsertValue;\n            let $self_to_columns = *self;\n            ($(\n                column_insert_expr!($table_name::$column_name, $column_name, $column_kind)\n            ,)+)\n        }\n    }\n}};\n\n```\nThen it's just a matter of parsing all the various struct definitions into it. A messy and incomplete example for tuple structs:\nrust\n    (\n        ($table_name:ident)\n        $(pub)* struct $struct_name:ident <$($lifetime:tt),+> ($(\n            #[column_name($column_name:ident)]\n            pub $field_type:ty,\n        )+);\n    ) => {\n        Insertable! {\n            table_name = $table_name,\n            struct_ty = $struct_name<$($lifetime),+>,\n            lifetimes = ($($lifetime),+),\n            values_ty = ($(\n                ::diesel::persistable::ColumnInsertValue<\n                    $table_name::$column_name,\n                    ::diesel::expression::bound::Bound<\n                        <$table_name::$column_name as ::diesel::expression::Expression>::SqlType,\n                        &'insert $field_type,\n                    >,\n                >\n            ,)+),\n            self_to_columns = $struct_name($(ref $column_name),+),\n            columns = ($($column_name, regular),+),\n        }\n    };\nGoing to scrap most of the code from the stream this morning, as we need to fundamentally approach the macro differently, since the expression needs to focus on pattern matching not on field access. And I need to approach it from a parsing point of view as well. Will swing at this a bit more during tomorrows stream unless someone else wants to take over it.\n. This is addressed by #303 \n. Review? @diesel-rs/core \n. Doesn't look like there are any compile test errors?\n. Yeah, make sure you're using the same version in .travis.yml. I'll bump it soon as there are breaking changes coming in libsyntax tomorrow. LGTM\n. Review? @diesel-rs/core \n/cc @aturon @nikomatsakis Seeing some cases of this sort of thing out in the wild is likely relevant to the lang team.\n. The build failures are because the code assumes https://github.com/rust-lang/rust/issues/31776. I need to address that, but the changes are minor and shouldn't need to affect review.\n. Nice catch. The fix is pretty easy, just change Serial to Integer\n. Thanks!\n. Sounds good. After Macros 1.1 I'm going to finish composite primary keys and roll a release, we can merge after that\n. Want to rebase so we can merge?. Can you add the lint feature to the integration test lines in bin/test, too? (Maybe hold off for a few on rebasing I'm about to push up something that changes that file for MySQL). Review? @diesel-rs/core \n/cc @dikaiosune\n. @CryZe That was fixed by #312 \n. You can pass a string literal, or compile time macro that generates a string literal (like dotenv! if you're using the rust-dotenv crate, or env! from the standard library).\n\nThe way in complier time is a little not friendly..\n\nThat's the tradeoff of a compiled language. We can't just evaluate arbitrary Rust code.\n. @mcasper We should probably improve the check if SQLite isn't present, since we won't have that branch as a catch-all.\n@deadalusai Your issue is that you're not giving a valid PG URL. It should start with postgres:// or postgresql://\n. Review? @mcasper \n. If CLI is compiled without PG support, everything should be passed unconditionally to SQLite.\n. Ah you're right. We used to have an alternate version of that function, but it looks like it was lost. Fixed.\n. Can you bump the date in .travis.yml and all the READMEs?\n. Yes, the codegen readme is the one I'm referring to.\n\nThe change was introduced for rust-1.7.0 so I guess it breaks for versions earlier than that. Is that worth mentioning?\n\nThis only affects nightly and we don't work on nightlies from over a month ago anyway.\n. Most backends provide some sort of a schema dump tool, which I think is the main path forward for something like that. I could see us potentially hooking into that with Diesel setup\n. Going to close this, since it's not immediately actionable. I'm happy to consider a feature for this if an issue were to be opened with a concrete proposal on what the API for this would look like, and exactly what it would do.. It gets pub rexported\n. @robertmaloney Are you still interested in working on this?. \ud83d\udd1c\u2122\nI'm currently in the process of moving and haven't had much time to work on things. 0.7 is almost ready to go, though. I'll see if I can roll a patch version with only the nightly change when I'm at my computer though. \n. You can also use an older nightly for the time being\nOn Tue, May 3, 2016, 1:15 PM Julian Laubstein notifications@github.com\nwrote:\n\nStill won't compile\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/317#issuecomment-216617721\n. Can you add a compile fail test to assert that .returning must take a selectable expression?\n. I don't think any of these cases really need to be changed. We can't use try! for the most part in the main functions, what we're more looking for is anywhere that we're doing assert_eq!(foo, bar.unwrap()) where we could instead make a change like assert_eq!(Ok(foo), bar). I'm not sure if there are any of those cases left or not.\n. Do you also have libpq installed?\n. I do want to see if we can improve this scenario, as it's a common stumbling point. Can you tell me what the output of pg_config --libdir is when the symlink isn't there? We may need to ask pg_config for the specific file to link against or something.\n. @fuyingfuying In https://github.com/diesel-rs/diesel/issues/321#issuecomment-218053859 you said it was... Anyway that looks like the root of the problem here, and the message given is definitely the correct solution. I'll see if I can improve the error message in pq-sys when pg_config isn't installed\n. Can you try pointing at master? This should have been resolved by https://github.com/diesel-rs/diesel/commit/ccad1510c197d73dbfd474c9f9a82d470055e486, which will be released later this week.\n. Sorry! I've been moving to another country for the last 2 weeks so I\nhaven't had time to finish the release.  \ud83d\ude14\n\nOn Wed, May 11, 2016, 12:32 PM iqualfragile notifications@github.com\nwrote:\n\ndamn, second fixed bug in diesel i run in today.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/322#issuecomment-218514844\n. Yeah, that's likely the direction we'll continue with -- just means that\nwe'll be chasing edge cases for a while\n\nOn Wed, May 11, 2016, 12:35 PM iqualfragile notifications@github.com\nwrote:\n\nbtw on the embracing sqlite philosophy of untyped sql: i really really\ndon't think thats a good idea, i would just handle it as if the type\ndefinitions would be definitive, just like postgress does. there is not\nreally a good usecase for storing different types into the same collumn\nanyways.\njust fail with a good error message if someone put stupid values into the\ndb.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/322#issuecomment-218515820\n. Unsure how much control we have here, but I'd like the error message to either be:\n\n`NaiveDateTime: AsExpression<types::Date>` is not satisfied\nor\n`NaiveDateTime: ToSql<types::Date, Pg>` is not satisfied\nThose are only marginally more clear, but at least they mention the fact that the column is of type date. Ideally we could give an even better message, explicitly calling out the mistake, but I don't believe we have the ability to do that at the moment.\n. This is another instance of https://github.com/rust-lang/rust/issues/28894 biting us. It's picking up on the impl<T: Expression> AsExpression<T::SqlType> for T blanket impl, and complaining about Expression missing even though the underlying problem is the missing AsExpression impl. I'm trying to see if there's a way for me to move this around to circumvent the problem, but this might just need to be fixed upstream.\n. Review? @diesel-rs/core @diesel-rs/contributors \nI recommend looking at each commit individually\n. Ah yes I need to add docs before this is merged\nOn Wed, May 11, 2016, 5:30 PM Pascal Hertleif notifications@github.com\nwrote:\n\nThe first 3 commits LGTM, that last one I have to re-read in the morning\n\ud83d\ude04\nDo you want to maybe add some more documentation to the Queryable macro?\nThe docs for Insertable\nhttps://github.com/diesel-rs/diesel/blob/e471837eb65e46cea5cb340dfcaa4ebd2f083854/diesel/src/macros/insertable.rs\nare quite extensive and mention how the macro can be used with the\ncustom_derive crate, for example.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/324#issuecomment-218596169\n. Thanks! :heart:\n. The problem is that you have a nullable field but you are attempting to load it into a type which does not handle it. Rust does not have a concept of null, so you need to have the type reflect this. You either need to change post_id to have the type Option<Uuid>, or you need to change your schema so that the column is NOT NULL\n. Review? @diesel-rs/contributors @diesel-rs/core \n. Yeah, it's rather annoying that the order has to be this way, but unfortunately it does. \n. I want to rethink the overall structure of the update module before merging this, but I figured you might have some feedback anyway @diesel-rs/contributors \n. Updated and ready for review @diesel-rs/contributors \n. Ah yes, I thought I had done that on the first pass. I will make it so.\n. Hm... Travis doesn't seem to want to run this branch anymore.\n. Tests passed locally. YOLO merging.\n. You should be able to work around this temporarily by cloning the repo down and pointing at the path instead of at git.\n. Caused by https://github.com/diesel-rs/diesel/commit/f90217f80320e922323d9906dd1028e94eb1c954\n. I'll see if I can come up with reliable steps to reproduce, as I've seen this locally intermittently but I'm not sure what caused it. In the short term you can just revert the commit I referenced in the previous comment to work around\n. Haven't had a ton of time to look into it yet\n. I fixed it by deleting diesel_codegen.. This is correct. You cannot deserialize a column of type Nullable<Integer> into an i32. You'll either need to use an Option<i32> on the Rust side, or change the field to be NOT NULL on the SQL side.\n. We don't really have support for embedded structs at the moment. When you're querying against two tables, you'd get back a (Post, User) instead of embedding the parent record inside of the child. If you really want to embed a struct, you'll need to implement FromSqlRow for your User struct manually. It'd look something like this:\n\n``` rust\nuse diesel::prelude::*;\nuse diesel::backend::Backend;\nuse diesel::types::{FromSqlRow + HasSqlType};\nuse diesel::row::Row;\nuse std::error::Error;\nimpl FromSqlRow for User where\n    DB: Backend + HasSqlType,\n    User: Queryable,\n    >::Row: FromSqlRow,\n{\n    fn build_from_row>(row: &mut T) -> Result> {\n        let row = try!(<>::Row as FromSqlRow>::build_from_row(row));\n        Ok(User::build(row))\n    }\n}\n```\nNote: Haven't tried that exact code, that's just from memory of what it'd roughly look like.\nWe don't support the JSON type yet, but it's on the radar for something we'd like to support. https://github.com/diesel-rs/diesel/issues/44 is the tracking issue, and I've mentioned how you could use it today in your app if needed in the comments there.\n. Dup of #317 #313\nFixed by #312 \nWe will be releasing 0.7 soon, please be patient. In the mean time I recommend using the version of nightly specified in the .travis.yml file on v0.6.1\n. This is the expected behavior. Otherwise we have no clue what you mean when you say matches.inner_join(teams). You can use the .on method to specify an explicit on clause.. For anyone running into this in the future, this is caused by having postgres 9.5 installed, but pointed at  a data directory for 9.4 (likely because you haven't run pg_upgrade yet)\n. There is a \"way\" to do this right now, by supplying a migration directory manually. I'm not sure that maintaining schemas on multiple backends in the same code base is a common enough use case to warrant any support beyond that.\n. Closing as I don't see this being a feature that we pursue any time soon.. At the moment we don't support having columns on structs called id that isn't the primary key\n. r2d2-diesel is using the latest released version, while your code is using the version from git. You can manually override it with .cargo/config, or clone down r2d2-diesel locally and point it at git. \n. Yes, by default the number of columns is capped at 16. You can increase it by adding features = [\"large-tables\"] to Travis.yml. The amount is lower by default to improve compile time. \n. Sorry I meant Cargo.toml\nOn Sat, May 21, 2016, 2:53 PM fuying notifications@github.com wrote:\n\n@sgrif https://github.com/sgrif\nWhere is the file \"Travis.yml\" placed?? How can I find it.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/340#issuecomment-220794418\n. No problem. If you need more help in the future, consider asking in the gitter room instead of opening an issue. \n. It's linked in the README. gitter.im/diesel-rs/diesel\n\nOn Sat, May 21, 2016, 3:23 PM fuying notifications@github.com wrote:\n\n@sgrif https://github.com/sgrif Where can i find the gitter room.\nPlease give me an URL. Thanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/340#issuecomment-220795790\n. What part of them is out of date? They're updated automatically when the build passes\n. Yeah, they track master at the moment. The plan is to have the docs.diesel.rs URL track the latest release once we're post 1.0\n. Yeah, for now there's no way to have columns with the same name as keywords in Rust. I'm planning on having some renaming convention in the future, but haven't decided on what it should be. The underscore proposal sounds reasonable.\n. Try rebasing on master and running on beta. So I'm going to close this as a duplicate of #162. At this point, everything needed for absolute minimum \"support\" for PG enums is there. We even have a test case for this in Diesel itself.\n\nI'm aware that this requires more code than people would like right now (this is true of implementing new types in general, not just enums). #162 is the tracking issue for that, and is going to be the main focus of 1.1.\nIdeally you'll just need to provide an impl of ToSql, FromSql, and HasSqlType (I originally wanted to have the rest of the traits come from blanket impls, which requires changes in the language, and is why there hasn't been much movement on this. At this point I'm thinking we'll just provide some derives for the other traits).\nAt this point, I do not want to provide any special support for PG enums (e.g. infer_enums!(), diesel print-enums, or #[derive(PgEnum)]). Such a feature would have to have some very strong opinions on the mapping, that I don't want to have in Diesel. That said, there's no reason that one of those features couldn't be supplied by another crate. I'm happy to help someone with the initial implementation of such a crate, but I wouldn't want it under the diesel org.\nTL;DR: Custom types in general are \"supported\". It's going to get more ergonomic in 1.1. We aren't going to provide special handling for PG enums.. Not at the moment, but using diesel print-schema works\nOn Sat, Dec 16, 2017, 3:11 PM Josh Leverette notifications@github.com\nwrote:\n\nI don't necessarily agree with the decision, but I appreciate the way\nyou're approaching the situation. I personally think enums are important\nenough to be a special case, but as long as it is possible to support\nthem in Diesel, that's good enough for me. As you said, an outside crate\ncould be developed to provide an opinionated solution to this issue that\ncould act as a way to reduce boilerplate for those who are interested.\nLooking at the example code you linked to, it seems pretty reasonable to\nme. My only real question at this point: is using infer_schema! is\npossible with a database that has custom types in some/all of the tables?\nI've been busy with other projects for awhile now, but from what I recall,\ninfer_schema! might have actually generated code which could not compile\nin such cases, and I don't remember finding a way to inject the custom\ntypes into the namespace that infer_schema! created.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/343#issuecomment-352215549,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK3CVhaMcOvmOk96IWmiPhbmxc-mqks5tBD_6gaJpZM4IlWGG\n.\n. Does SQLite give something reasonable back if you read the field as something other than text? I would prefer to avoid date parsing if we can\n. I don't mean that we should cast it in the SQL, I mean that the deseriailzation function we call can be anything, SQLite doesn't care. If you call read_double, it'll give back what it thinks that should be.\n. r2d2-diesel uses diesel = \">= 0.5.0, < 0.7.0\"\n. There is no branch, it was a single cherry picked commit\n\nOn Mon, May 30, 2016, 4:54 AM Anthony Ramine notifications@github.com\nwrote:\n\nOk, you just forgot to push the branch then?\nhttps://github.com/diesel-rs/diesel/blob/master/diesel/Cargo.toml#L3\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/345#issuecomment-222445528,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ABdWKwgZjiQBAgOqICOx4XUkKOBc7wJcks5qGqXEgaJpZM4IoOXh\n.\n. Because 0.6.2 was a minor patch on 0.6.1 done long after master had changes\nthat I didn't want to release\n\nOn Mon, May 30, 2016, 6:02 AM Anthony Ramine notifications@github.com\nwrote:\n\nThat doesn't explain why master isn't 0.6.2. Could you make master the\n0.6.2 version as expected?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/345#issuecomment-222458682,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ABdWK3qAK6MIyevzyHqxaUL9Ygfq0e53ks5qGrXOgaJpZM4IoOXh\n.\n. Connections aren't object safe, and basically never will be able to with Rust as it is today. You'll have to write your functions as fn foo<T: Connection>(conn: &T)\n. They're simply i32 fields, treated like any other field. We don't take indexes into account.\n. Closing as a duplicate of #162.. Diesel doesn't have any control over how file paths are parsed. They're handled either by the Rust file APIs, or by SQLite. \n. No worries. I will take a look at it as soon as I can. I am in Europe right\nnow for work so it will probably be mid next week.\n\nOn Fri, Jul 8, 2016 at 6:14 PM Rasmus Kaj notifications@github.com wrote:\n\nI tried moving the added code into to pg submodule, as @sgrif\nhttps://github.com/sgrif suggested 25 days ago. It turns out a bit\nharder than I anticipated. As far as I understand, the problem is that the\npostfix_expression! macro don't allow me to specify a backend\nimplementation, as the infix_predicate! macro does.\nAny help fixing this would be much appreciated.\nPS. Sorry for being away for so long.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/351#issuecomment-231416980, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/ABdWK80cjlbw25ml67fuYneptTLhDNekks5qToSUgaJpZM4Iy11U\n.\n. LGTM. Can you add a changelog entry and squash? Thanks for working on this.\n. Hah I'm glad you mentioned something, as I noticed an issue with your structure. This should not get re-exported from expression, this should go in diesel::expression::expression_methods, which is already glob-reexported in prelude (sorry, I know this is nitpicky but we end up with a lot of these modules so I want it to be consistent)\n. Moving the actual code into another module nested under\nexpression_methods, similarly to the other 5 or so modules in there.\n\nOn Sun, Aug 7, 2016, 7:57 AM Rasmus Kaj notifications@github.com wrote:\n\nOk. Are you talking about just the \"use\" structure, or moving the actual\ncode into expression_methods.rs?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/351#issuecomment-238078408, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK8_1WkRap8aGpAG6tdC_ljSSNfNpks5qdcg8gaJpZM4Iy11U\n.\n. Review? @diesel-rs/contributors \n. Yes, PK means PrimaryKey. I'm fine with changing the code base to use the longer form everywhere (as a separate commit)\n. That's a good idea. I have some random thoughts (with a section for abbreviations) written down in https://github.com/diesel-rs/diesel/issues/120 but I haven't organized them into a coherent document yet. PK wasn't documented there but I've just added it.\n. This is fixed in 0.7\n. Hey sorry for the delay in responding. You need to enable the chrono feature to deal with dates. PG date will map to chrono::NaiveDate. bytea maps to Vec<u8>, but you may need to point at master if you're using the infer_schema! macro.\n. It would probably make sense for CLI to expose a reasonable public API there. /cc @mcasper\n. That would certainly be the easiest to implement, but I'd rather just have a more static API akin to libgit2 vs git. I'm fine with improving the readability of these. I like @killercup's suggestion of using dashes instead of underscores. I'd like to continue to keep the rules of \"what is the version\" simple (and right now that rule is anything before the first underscore)\n. Option 4: Fix the linear growth in compile time that is linked to number of trait implementations in Rust itself and then I can implement this to be as large as people ask and turned on by default. (Easy, right? :trollface:)\n. For the record, I will accept a really-huge-tables feature.\n. Agreed that we should include more information about the error when possible. I need to think through the API though, as I'm not sure I want to make QueryResult generic over the backend.\n. I guess rather than try to implement an exhaustive enum that is backend specific, a more useful API would be to identify the \"common\" errors that are likely to be handled programmatically, and abstract over them.\n. Anyone have opinions on\n\nrust\nenum Error {\n    DatabaseError(Box<DatabaseErrorInformation>),\n    UniqueConstraintViolation(Box<DatabaseErrorInformation>),\n    ForeignKeyViolation(Box<DatabaseErrorInformation>),\n    InvalidTransactionState(Box<DatabaseErrorInformation>),\n    // Rest of error variants, which is not related to the database specifically\n}\nvs.\n``` rust\nenum Error {\n    DatabaseError(DatabaseErrorKind, Box),\n    // Rest of error variants, which is not related to the database specifically\n}\nenum DatabaseErrorKind {\n    UniqueConstraintViolation,\n    ForeignKeyViolation,\n    InvalidTransactionState,\n    #[doc(hidden)]\n    __Unknown, // Match against _ instead, more variants may be added in the future\n}\n```\nvs.\n``` rust\nenum Error {\n    DatabaseError(DatabaseErrorKind, Box),\n    // Rest of error variants, which is not related to the database specifically\n}\nenum DatabaseErrorKind {\n    ConstraintViolation(ConstraintKind),\n    InvalidTransactionState,\n    #[doc(hidden)]\n    __Unknown, // Match against _ instead, more variants may be added in the future\n}\nenum ConstraintKind {\n    Integrity,\n    Restrict,\n    NotNull,\n    ForeignKey,\n    Unique,\n    Check,\n    Exclusion,\n}\n```\nSo the difference between matching: UniqueConstraintViolation(error), DatabaseError(UniqueConstraintViolation, error), or DatabaseError(ConstraintViolation(Unique), error). The first one is definitely more concise, but the second one feels better structured internally. The third one is quite verbose (especially when you include the additional imports), but it is the most flexible in that it would allow users to for example handle any constraint violation without caring what kind.\n/cc @diesel-rs/contributors \n. I'm starting to lean more towards 2 actually. This isn't meant to be an exhaustive list of all the possible errors, but to aid the common cases that are recovered from programatically. If we need exhaustiveness, I would probably want to expose a method with the raw error code instead. I do like separating the kind out into its own enum though to make it easy to handle \"the query failed\"\n. > ```\n\n//? Is there a way to easily know which field(s) the constraint failed for?\n\n```\n\nYou can get the table name and the constraint name on PG, but it won't tell you the column separately or anything like that (makes sense, it could be a composite index). On SQLite there is no way to get the specific constraint that failed.\nEDIT: Also you can't pattern match on those specifics (other than with a guard). I really wanted to try to make that happen, but there's no way without adding a lifetime to the error enum, since it'd need to be an &'a str, and it'd be ugly to pattern match on anyway since the variant would have to contain the result, etc. Only way around either one is to use a String, and you can't pattern match that.\n. r? @diesel-rs/contributors \n. The setup seems like it would be pretty trivial. We call the relevant libpq functions and pass in a result pointer here manually. I'm not sure how we actually verify that the result was cleared though\n. As far as I know there is no way to determine if memory has been freed or not.\n. I'm leaning towards having a proper type to represent the error case anyway, which would own the PGResult pointer and implement drop, which should more or less eliminate this case (we likely have the same leak for SQLite but I haven't checked yet)\n. r? @diesel-rs/contributors \n. I'm not sure I like passing the foreign key around like this. The goal of the API was to abstract away how two tables are joined together. This is missing tests for the added behavior, both behavioral and compile-fail. In particular, it seems like the resulting type is wrong. users.inner_joins(posts).inner_joins(comments) would return (User, (Post, Comment)) not (User, Post, Comment) if I'm reading this correctly?\nIn general I've been moving away from multiple joins as a solution for associations anyway, as once you've introduced more than one join into the mix, it's often significantly better to run two queries, as the amount of duplicate data sent over the wire is significantly reduced.\n. As far as I'm aware there is no data type in SQLite that maps to UUID?\n. We also support it because SQLite does have a ton of built-in functions for dealing with dates. Yes, it represents them as strings, but that's ultimately an implementation detail, not something relevant to whether the type exists or not. Importantly, there is a canonical way to represent a date in SQLite. \nThat is not the true of UUIDs. We could store the raw bytes, or we could store the text representation. It's not obvious which we should choose, and we would be incompatible with existing databases when we choose one or the other.\nUltimately when there's a clear representation of a type and semantically it exists for a given backend, we support it even if there's some mismatch. For example, even PG's datetime type supports a different range of dates than chrono. Given that SQLite is fully dynamically typed, if we really wanted to only support what strictly could be represented, the only type that we could support for SQLite is Vec<u8>. We do have to draw the line somewhere though, and this is where we've chosen to draw it for the time being.. PG does not allow queries which conditionally change their return type.. r? @diesel-rs/contributors \n. r? @diesel-rs/contributors \n. Thank you for the report. Because keeping up with nightly perpetually causes a lot of churn, our policy is currently that we will support nightlies on the dates that Rust releases. This means that the next nightly we will support will be on July 7th (because I am at a conference, it may not get updated until a few days after that date, but that will be the date we target). Thanks for your patience and understanding.\n. Thank you for the report. Because keeping up with nightly perpetually causes a lot of churn, our policy is currently that we will support nightlies on the dates that Rust releases. This means that the next nightly we will support will be on July 7th (because I am at a conference, it may not get updated until a few days after that date, but that will be the date we target). Thanks for your patience and understanding.\n. Thank you for the report. Because keeping up with nightly perpetually causes a lot of churn, our policy is currently that we will support nightlies on the dates that Rust releases. This means that the next nightly we will support will be on July 7th (because I am at a conference, it may not get updated until a few days after that date, but that will be the date we target). Thanks for your patience and understanding.\n. Ah this looks like a breaking change in a minor update actually. We may need to lock down the version further. /cc @erickt did something break in a semver incompatible way? I've gotten 3 reports about this.\n. Yes that's where it should be. Specifying 0.31.0 is basically 0.31.*\n. Ok just wanted to make sure since the issue mentioned syntex_syntax (I'm out of the country ATM so I haven't had a ton of time). And yeah we'll update nightlies on the 7th (and likely ship 0.7.0 on that date). We'll update syntex and friends on that date as well. Thanks for looking into it @dtolnay \n. Yes, I will document it when I handle the next update (which will likely actually be on the 11th or 12th when I get home, but will target the nightly from the 7th assuming Rust ships today)\n. /cc @mcasper I think we should give a command to generate at runtime since users won't have access to the files in build.rs\n. Thanks. I manually merged this in https://github.com/diesel-rs/diesel/commit/17326dd26ab4a57862784b4c4d2dfffb0325b4a7. There were some style issues that needed to be addressed which I did by amending your commit to avoid git churn. As such Github won't automatically pick up on me merging it, but it has been accepted. Thank you for working on this.\n. I'm fine with this until we add better support for nonstandard primary keys. Can you add a test for this and a changelog entry?\n. Well one argument for adding a test: I have no clue if we need to make an equivalent change for SQLite or not.\n. Yes, I would prefer if a minimal test case could be added for this as\nyou've described. I'll write the patch to fix this for SQLite as well.\nOn Wed, Jul 13, 2016 at 6:43 AM Ant\u00f3nio Cascalheira \nnotifications@github.com wrote:\n\nSeems like SQLite also supports views and also fetches them in the same\nway, alongside with normal tables: Stack Overflow\nhttp://stackoverflow.com/questions/82875/how-to-list-the-tables-in-an-sqlite-database-file-that-was-opened-with-attach.\nI don't use SQLite but next week i can do a new pull request with the\nSQLite fix.\nAs it currently is, diesel crashes if we have a view (views are just\nqueries, not tables and as such have no primary keys) so the current tests\nwould already be what we need to test this situation. If you still want me\nto add something to the tests just for the sake of it, i will just add the\nSQL to create a view and check if it wasn't fetched (If it was, it would\ncrash diesel anyway when using infer_schema!).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/374#issuecomment-232320544, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/ABdWK4Jd9lURFxZeS8MOfG-aOhgCHgSRks5qVMFTgaJpZM4JE-eA\n.\n. I think just a test for load_table_names that creates a view should be sufficient.\n. I don't think that is something which makes a ton of sense for Diesel to do, as there's no direct equivalent in SQL. I wouldn't do this with LIKE either, since as you've pointed out, escaping special characters can be a pain. I'd probably do something like this (I'm assuming you're using PG, not sure if there's a direct equivalent on SQLite):\n\n``` rust\nsql_function!(left, left_t, (Text, Integer) -> Text);\n.filter(left(some_expr, str.len()).eq(str))\n```\nAnd if you really want to do some_expr.starts_with(str), you could do something like:\n``` rust\nuse diesel::expression::helper_types::*;\ntrait MyExpressionMethods: Expression + Sized {\n    fn starts_with(self, needle: String) -> Eq>, AsExprOf> {\n        left(self, needle.len()).eq(needle)\n    }\n}\nimpl MyExpressionMethods for T where\n    T: Expression + Sized,\n{}\n```\n(Yeah the type signature is a bit gnarly there, but it's a pain to hide that return type right now)\nAnyway I think this makes a ton of sense to do as a small third party crate, but it's above the level where I want Diesel to live right now, as it's meant to stay pretty close to SQL. I may re-evaluate that in the future as more common patterns come about, but until we get a lot of other things figured out with regards to documentation and discoverability I'd like to keep the surface area of the API small.\n. Yes, it'd be good to have some example apps for both backends (probably after 0.7 releases :soon: :tm:)\n. You'll need to manually do a second query. We don't expose that function, as its value cannot actually be relied on in all contexts. You can approximate its behavior by doing something like your_table.order(id.desc()).first(), which makes the caveats of sqlite3_last_insert_rowid more explicit and apparent.. Thank you for the pull request. I've just pushed https://github.com/diesel-rs/diesel/commit/4267ca42437b4ef76e4ace49a9a1ecd080243bee which was already done when you opened this (but was blocked waiting on a release of dotenv). \n. So I can definitely add #[allow(missing_docs)] to the generated module (we already add #[allow] for anything that is a default warning), but it's worth noting that changing #[allow(missing_docs)] to #![allow(missing_docs)] would allow it for the entire schema module, which is probably what you want.\nI'm hesitant to make this change because it can very quickly expand to pretty much any lint out there.\n. The latest released version of Diesel uses nightly-05-09, I will be releasing a new version soon. https://github.com/diesel-rs/diesel/blob/v0.6.2/.travis.yml\n. Can you give the full code that you're trying to write? Is posts an integer column?\n. http://docs.diesel.rs/diesel/prelude/trait.BoxedDsl.html will help you dynamically build the query. As for parsing the string, that's not something Diesel can help with. \n. Review? @diesel-rs/contributors \n. Review? @diesel-rs/contributors \n. Yup, I will have a fix for those shortly. Opened https://github.com/diesel-rs/diesel/issues/520 to track just in case. > I'm especially wondering whether the \"insert/update is empty\" state can be more cleverly encoded in the type system.\nHaving column_names return an option seems like a reasonable place to do that, since that's the place that we're doing something which can panic. I'm not sure if that would be too implicit though, with the structure that we have. If column names returned something rather than operating on the query builder, I'd feel better about it but we'd need const fn to do that efficiently.\nFor now I think this is fine. However, I don't like having an additional on QueryFragment. Let's just have to_sql on InsertStatement and InsertQuery do nothing if InsertValues#is_empty returns true. One other option would be to do something like Err(AbortQuery), but have the connection handle it.\n. An empty query should be valid IIRC, but we can always just have the connection do nothing if the query builder constructs an empty string.\n\n(What are your reasons for not wanting an is_empty method, by the way?)\n\nIt only affects this one case (and I guess potentially update). Don't need to pollute the entire AST with it. Especially since we can just see if the query builder constructs an empty string.\n\nLet me know what you want to do.\n\nFor now let's just have it construct an empty query, and then check in the connection for an empty string if needed. We can always change to the abort idea later on if we feel like there's a good use case.\n. get_result and get_results will need to handle it as well.\n. Review? @diesel-rs/contributors \n. Review? @diesel-rs/contributors \n. Have at it!\n. Review? @diesel-rs/contributors \n. > Though it's not a breaking change to change to IntoIter, right?\nGiven this changes a feature that hasn't been released yet, it's definitely not a breaking change. ;)\n\nAlso, that tuple macro is crazy but still getting crazier.\n\nYeah, I hesitated to make this change for that reason. Everything we add to that macro has a non-trivial hit to compile times. This one appears to be less bad since it has only 2 constraints.\n. Closing as it turns out custom-derive is completely broken and we're just going to remove it from the docs now that Macros 1.1 is a thing.\n. I believe this is intentional to improve readability on tablets\n. Thanks for the issue! This pretty much falls naturally out of the current design once we add composite PK support in general, which is something I'm working on.\n. Worth noting that in the async case I'd also like load and get_results to return some sort of stream instead of Future<Vec<T>>, as it frees me up to do cursory things (granted, even just a future is fine). This of course will require re-implementing the postgresql adapter to not rely on libpq (which I'm already working on for other reasons, not sure if I've spoken about it outside of the podcast). It also will not be possible with sqlite.\n. That's a possibility as well, but it's untrue to how I'll actually have access to the data, which is in batches. If we're doing true async IO I also will not have the length ahead of time, so it'd have to be an actual iterator not Vec>, at which point why not just do a true stream?\n. Stream<T> is to Vec<T> as Future<T> is to Result<T, _> (or I guess Option<T> in this case)\n. Sorry that I didn't reply -- I had an unexpected baby. Yes, that is the correct link to the podcast.. No.. So... I've fully implemented a PoC for this twice now. I'm going to close this for the time being. \nThis is not a statement that async I/O will never happen, but it is a statement that it is not currently on the roadmap, and I do not consider this to be actionable at this time. Neither tokio nor futures have stable APIs at the moment (tokio in particular is supposedly going to have a major overhaul at some point).\nAt absolute minimum, we need to wait for things to settle down there. However, there are problems that need to be solved in those APIs as well. I found that in order to get to an API that I was happy with, I had to resort to some pretty nasty hacks which had a lot of gotchas and I'm not comfortable shipping. It seemed that ownership hits you way harder here as well. It's virtually impossible to have anything that isn't 'static. This might seem obvious or NBD, but consider for a moment that you basically never actually own the connection. Everything takes &connection (or more likely a PooledConnection<'a, T>).\nWith the state of things as they are today, we would also need to re-implement connection pooling to make this work. This is on top of what would already be an enormous amount of work. This is not just \"make it async\". When we switch to tokio, we can no longer use the client libraries provided to us by the database creators. We need to learn the wire protocol that database uses, and implement it at the TCP level. \nFinally, I hear a lot of people saying that the lack of async support is the big blocker for them using Diesel, but I'm not buying it. PostgreSQL is the only backend likely to get an async driver any time soon (I do not know the MySQL wire protocol, and it is mostly undocumented). The tokio-postgres crate, which people would likely be using instead if async was really the blocker for them, has had 300 downloads in the past 3 months. I'm not saying that async isn't a thing worth doing, but I think people are perhaps overstating how important it is to them.\nAnyway with all that said, I'm going to close this issue. Open issues in this repo should represent something that is actionable, and that you could reasonably open a pull request to fix. I do not consider this to be actionable with the state of async in Rust today. I will keep my eye on that situation, and if that changes, I will open a new issue for this. But you should not expect async Diesel in the near future. . I want to re-iterate: I am not trying to say that \"async isn't a big deal\". I am trying to say it is not currently a priority, and it is not feasible for us to attempt to accomplish it at this point in time.\n\npeople who view async as a blocker are not using sync-Rust instead. They are simply not using Rust.\n\nWhile you're probably right, and it may not have been a great stat to bring up, I'm not sure I agree with \"if I can't use Diesel I'm just not going to use Rust\" being the norm in this case. \nI'm also not trying to use the stats for tokio-postgres to infer the popularity of async, I'm using to to give some number to the only async alternative available for the backend that we are most likely to support. Presumably there are a decent number of people who want all of:\n\nRust\nPostgreSQL\nAsync I/O\n\nThis is what those people would be using.\nBut again, I'm probably calling too much attention to what was by far the smallest part of my reasoning for closing this (which I should also mention was discussed with the rest of the core team). This is mostly about it not being something we can do right now, which is why I wanted to close this issue. If circumstances change and async-diesel becomes feasible in the future, we'll open a new issue. But I want to avoid keeping issues open which cannot reasonably be closed with a pull request (this would of course be a very large pull request). @gfortaine Right now it's more of an issue of time than desire.. Can you do the same to the SQLite connection?\n. No the change log is kept up to date. This doesn't need a change log entry though as it's invisible to users. \n. Review? @diesel-rs/contributors \n. 0.7.1 doesn't support timestamptz. It will be in 0.8\n. Can you please paste your full console output as well as the command you were trying to run?\n. Nightly Rust shouldn't be required. What version are you using? (The output of rustc --version would help)\n. Can you try with 1.9.0 or 1.10.0?\n. (I can confirm that it does not compile with 1.8.0, but I do not know the minimum version it compiles with. My guess would be 1.9.0)\n. You need to either install sqlite3 on your system or install with --no-default-features --features \"postgres\"\n. -lsqlite failing is most likely an issue with your setup. Make sure that libsqlite3.so is either in a directory on your LIBRARY_PATH, in the directory specified by SQLITE3_LIB_DIR, or properly being discovered by pkg-config\n. No problem. Glad I could help. The next release will have a more helpful error if you try to install it on an unsupported version of rustc. :)\n. Review? @diesel-rs/contributors \n. Going to move beta to allowed failures for now since this looks like a bug in rustc\n. diesel::insert(&NewRun { ... }).into(runs::table).execute(&connection) will insert a new run. The fact that there is a foreign key will not have any impact on the flow (other than providing potential error conditions). Your test_name column should probably be NOT NULL or your field should be Option<String> though.\n. > the fact that this is handled automagically makes diesel even more appealing\nNot sure what you mean? We're literally not handling anything here. And yes your question about the process is correct.\n. I actually can't reproduce this either with the supported nightly or the latest nightly. Your given example compiles fine for me on both. I did notice that the output you've pasted isn't using the code from crates.io, it's using files on your local machine (Compiling diesel_codegen v0.7.0 (file:////diesel_codegen)). Do you have a .cargo/config which is overriding it? Either way I also notice that the version it states is out of date. The latest version in 0.7.1 so either pointing at the released version from crates.io or updating your local copy should fix this issue for you.\n. Ah, actually I can see exactly what the problem is. You're using diesel_codegen_syntex 0.7.1 which will be generating code for the macro provided by diesel 0.7.1 but the version of diesel being used is 0.7.0 (unfortunately I can't prevent this, restricting the version of diesel in Cargo.toml would just cause it to use two copies of diesel, not force you to update the version used in your app). But basically some of your dependencies are missing https://github.com/diesel-rs/diesel/commit/ccd2a75ee1bdc1195272e22b1b8abccbe5c7ba74\n. Review? @diesel-rs/contributors \n. So the main question that comes to mind with this feature is what the behavior should be when inside of a nested transaction. I guess the simplest answer would be to not support specifying the isolation level when starting the transaction, and instead just add support for SET TRANSACTION instead.\n. Seems like advisory locks can just be done with sql_function!. I'll try to get SET TRANSACTION support in the next release\n. Taking this off the milestone. It's a relatively minor feature to add, but it's not super critical at the moment, as we don't offer a ton over execute(\"SET TRANSACTION WHATEVER\"), and I'm trying to get the 0.9 release wrapped up soon. Review? @diesel-rs/contributors \n. You mean documentation for the SQL type itself? Yeah I'll update that PR adding those docs after I merge this.\n. Do we need to update each of the children to point to the workspace as well?\n. Yeah it gets built with different features. Shame those don't get cached. I'm less concerned with the time of CI and more withbin/test. Maybe we can reorder those so the SQLite tests all happen together and then the PG tests?\n. This sounds like it's worth opening a bug with compiletest over?\n. Or just removing compiletest from the workspace\n. It looks like cargo has improved its caching without workspaces, so there's not as much specific benefit from doing this anymore.. @killercup asked me to take a second look at this.\nSuper unscientific single run ofrm -rf **/target && time bin/test`:\nWith PR:\n5:31\nWithout PR:\n6:43\nSeems good! I will fix the test failures manually. Merged in 9cb56fec2fd7fbf644798b2cc6423b92cb5603a7. TL;DR: Not sure if this is a bug in Diesel or rustc but we should see if we can fix it on our end, and there's a pretty straightforward way to do that. The rest of this comment are technical details on the issue which you may or may not find interesting.\nPossibly boring technical details about the issue\nSo this actually has little to do with syntex, this bug can be reproduced with nightly and rustc plugins as well. I'm really not sure if this is a bug in rustc, Diesel, or neither. The issue comes from the code that we're generating. When building an AST everything takes a span which is basically a byte offset into a file. For code generation from derive, the span is pretty much always the span of the derive attribute itself, which in this case is byte 0. The code we'll be generating for that struct is:\n``` rust\nimpl<__ST, __DB> Queryable<__ST, __DB> for T where\n    __DB: Backend + HasSqlType<__ST>,\n    ((),): FromSqlRow<__ST, __DB>,\n{\n    type Row = ((),);\nfn build(row: Self::Row) -> Self {\n    T {\n        _dummy: row.0,\n    }\n}\n\n}\n```\n(Yes ((),) looks kind of silly but for this struct that is the tuple of the types of all fields on the struct). The issue comes from the row.0 part. When we try to construct that we're giving it that same span with the 0 byte offset. However, the compiler is trying to build a new span which starts at the dot and ends at the 0. It appears to be assuming that we are giving it a span which starts and ends at the 0. So it's subtracting 1 from the start, but in this case the start is 0 so it underflows.\nI suspect that the assumptions the compiler is making about the span are incorrect. But that doesn't matter, as we can't demonstrate this as an issue through any public APIs and this is a private, internal API for rustc.\nInterestingly, this code differs from what we would generate using our stable macro, which would be:\n``` rust\nimpl<__ST, __DB> Queryable for T where\n    __DB: Backend + HasSqlType<__ST>,\n    ((),): FromSqlRow<__ST, __DB>,\n{\n    type Row = ((),);\nfn build(row: Self::Row) -> Self {\n    let (_dummy,) = row;\n    T {\n        _dummy: _dummy,\n    }\n}\n\n}\n```\nI've been changing all of our syntex/nightly macros to be implemented purely in terms of the stable macro form in order to get access to $crate. I thought I had already done that for Queryable but it looks like I missed it. Making that change should work around this issue.\n. I've submitted a fix upstream either way. https://github.com/rust-lang/rust/pull/35990\n. This is a Rust issue not a diesel issue. https://github.com/rust-lang/rust/issues/36081. Review? @diesel-rs/contributors \n. (I added docs before merging)\n. Review? @diesel-rs/contributors \n/cc @mcasper \n. Using an in memory database is certainly supported, but you not be able to use infer_schema! with an in memory database (as there's no persistent schema to infer from). You will need to either use the table! macro directly, or compile against an on disk database for schema inference purposes.\n. You can run migrations against the database after establishing the connection using the run_pending_migrations function. That function requires the migrations to be on disk in the appropriate location. If you want to avoid that constraint, use the embed_migrations! macro. I've just noticed that the documentation is a bit lacking for embed_migrations! (which I will fix later today) but you use it like so:\n``` rust\nembed_migrations!();\nfn establish_connection() -> Result {\n    let connection = try!(SqliteConnection::establish(\":memory:\"));\n    try!(embedded_migrations::run(&connection).unwrap();\n    Ok(connection)\n}\n```\n. I'm definitely against something like CSV for this. \n. Closing this since I don't think there's anything actionable right now.\nIf we were to do this, I think it should be a thin wrapper around the dumping tools that various databases provide. I'm happy to consider the feature, but we need a new issue with a more concrete proposal on what the API would look like, and what specifically it would do. I'd be fine with the proposal focusing on one backend as an example, we can figure out how to make that work with the tools for other backends from there.. I think this issue has been addressed as much as it can be.\nWe now have QueryableByName for use with sql_query, since order specifics are painful when writing the query by hand. I've tried to make the fact that Queryable cares about order as clear on this as I can be in the documentation. The only other thing we can do for this a lint, which is covered in #573.. Can we call the feature deprecated_time instead of time?\n. I'm certainly open to alternative suggestions. But you hit the nail on the head, time as a feature name sounds too authoritative for something in the rust-lang-deprecated org.\n. Sorry for the delay. Can you add a changelog entry, squash and rebase? Thank you for working on this!. Sorry, I've been short on time. I will make sure the guides are up to date this weekend. \n. @Emilgardis I know you disagree with our nightly support policy but please don't start commenting on every issue complaining about it. \n. My bad I thought you were someone who had opened another issue. :+1:\n. So I'm not entirely opposed to this feature, and would like to hear what @diesel-rs/core have to say on it. However I'm against it personally. I think it adds unnecessary complexity for a simple problem. The only use case where this is necessary are to have column names which are the same as keywords in Rust. This is a relatively limited set, and I think we can avoid the complexity simply by having a defined convention in those cases (e.g. type -> ty). This solution also has the benefit of being something we can do automatically in codegen.\n. Ok so I've put some more thought into this. I like the idea but I don't like the API. It's not clear to immediately which side is the rust name and which side is the SQL name. as doesn't imply thats the aliasing which is occurring either. \n. I still don't like rename as the API. It's unclear to me which side is being renamed.\n. So we discussed this feature a bit more internally. The consensus was that there's not really a strong motivation for this feature in terms of general renaming of columns. Without a stronger motivation, we want to avoid introducing new features like this.\nWhat we do need to address are the table/column names that cannot be represented in Rust because they overlap with keywords. (type being the most obviously common one). What we'd like to do in order to solve that problem is take the same approach that bindgen took, and put an underscore at the end of the name if it conflicts with a Rust keyword. This approach is simple, consistent, and easy to document.. Forgot to mention -- part of the reason for not wanting to introduce this as an API in the table! macro for now is that any code which does successfully compile but doesn't have the name you want can always be renamed in Rust by pub use foo as bar. We don't currently support tuple types in PG. They're not currently on the list of types that are high priority to support. \n. Clearing out old issues....\nThis is basically just \"we don't support PG tuples\". I think support for this will probably need to come from another crate. I don't think we can make this ergonomic without variadic generics. If nothing else, the PG type (int4, int4) will map to PgTuple<i32, i32> not (i32, i32) if we ever support it in Diesel.\nClosing, as this is not immediately actionable.. @ElijahCaine We do work on beta as well if you use syntex. Beta allows the same things that stable does. If you want to use #![feature] attributes (opting into an unstable feature), you have to use nightly. We switched to the six week tracking cycle because keeping up with every breaking change in nightly was a huge maintenance burden and was taking up enough time that it was preventing feature development.\nStable Rust is always an option on syntex, but we point to nightly because it's a bit simpler.\nA lot of the discussion around this is moot now that the procedural macros 1.1 RFC has been accepted. That RFC was specifically designed to be something easy to stabilize, and will likely end up being the only thing we target once it becomes stable (which we're hoping is by the end of the year)\n. > What is your decision on this PR?\nI appreciate the work on this, and will merge it when the time is appropriate. I'm in the process of migrating our nightly story to macros 1.1. I'm not planning on releasing sooner than we would have otherwise. Since macros 1.1 have landed, the entire discussion around our nightly version support is now moot, and I'll be moving nightly off of allowed failures in the next release.\n. The type is called Integer on SQLite\n. You say the database was set up by diesel setup -- but that doesn't create any tables. Can you provide steps to reproduce? What you've described should not be possible without user migrations\n. So ultimately there are two cases where you need to implement traits around this. The first is when you have a custom type in Rust that is represented by an existing database type, and the second is when you are adding support for a new database type that isn't already supported. This PR doesn't address the second case (which ultimately will need to care about the exact bytes sent over the wire, and thus needs more traits).\nFor the first case, ultimately the only two traits that you need to implement are AsExpression<OtherDbType> and FromSqlRow<OtherDbType, Backend>. So comparing the code with/without this PR:\nWithout PR\n```rust\nimpl FromSqlRow for Color {\n    fn build_from_row>(row: &mut R) -> Result> {\n        match i16::build_from_row(row)? {\n            1 => Ok(Color::Red),\n            2 => Ok(Color::Green),\n            3 => Ok(Color::Blue),\n            v => format!(\"Unknown value {} for Color found\", v).into(),\n        }\n    }\n}\nimpl<'a> AsExpression> for &'a Color {\n    type Expression = AsExprOf>;\nfn as_expression(self) -> Self::Expression {\n    AsExpression::<Nullable<SmallInt>>::as_expression(*self as i16)\n}\n\n}\n```\nWith PR\n```rust\nimpl CustomSqlType for Color {\n    type DataBaseType = SmallInt;\n    type RawType = i16;\nfn to_database_type(&self) -> i16 {\n    *self as i16\n}\n\nfn from_database_type(v: &i16) -> Result<Self, Box<Error + Send + Sync>> {\n    match *v {\n        1 => Ok(Color::Red),\n        2 => Ok(Color::Green),\n        3 => Ok(Color::Blue),\n        v => format!(\"Unknown value {} for Color found\", v).into(),\n    }\n}\n\n}\n// Add all needed implements for diesel\nCustomSqlType!(Color);\n```\nI think we can definitely improve the ergonomics of the before code. FromSqlRow could use a better name. The signature of build_from_row could be simplified with some type aliases. The AsExpression impl could be impl AsExpression<SmallInt> for Color. I'm open to all of those, but I don't think we need to introduce a new trait that effectively mirrors the existing one. Especially when it involves macros. For code likely to be introduced by users (not libraries), I'd prefer to keep as much of it out of codegen and in Rust as we can, so that understanding Rust is enough to understand what it's doing. Most importantly, these are the error messages I get if the impls are missing:\n#[derive(Queryable)] with missing FromSqlRow\nerror[E0277]: the trait bound `Color: diesel::types::FromSqlRow<diesel::types::SmallInt, _>` is not satisfied\n  --> src/main.rs:64:11\n   |\n64 |     users.load::<User>(&connection).unwrap();\n   |           ^^^^ the trait `diesel::types::FromSqlRow<diesel::types::SmallInt, _>` is not implemented for `Color`\n   |\n#[derive(Insertable)] without AsExpression:\nerror[E0277]: the trait bound `Color: diesel::Expression` is not satisfied\n  --> src/main.rs:54:1\n   |\n54 | #[derive(Insertable)]\n   | ^^^^^^^^^^^^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `Color`\n   |\n   = note: required because of the requirements on the impl of `diesel::Expression` for `&'insert Color`\n   = note: required because of the requirements on the impl of `diesel::expression::AsExpression<diesel::types::Nullable<diesel::types::SmallInt>>` for `&'insert Color`\nThe second one could definitely be improved, and I wish it mentioned the actual bound it's looking for more prominently, which I've been pushing on the Rust team to do. But both error messages provide the exact trait impl that needs to be written.\nAs such, I think this is ultimately a documentation problem. We should better document how to do this in a prominent location, and we should improve the ergonomics where we can. But I don't think this PR improves the situation at the end of the day.. There's a blanket impl for Option that violates coherence without specialization. It is present with features = \"unstable\" though.. You can implement AsExpression in a way that doesn't require a ToSql impl, and you can implement FromSqlRow in a way that doesn't require a FromSql impl, as in my example above.. Works fine for me. https://gist.github.com/sgrif/299a94c7fa818801d2604ba97972c6a9. https://github.com/diesel-rs/diesel/issues/438\n. Since Macros 1.1 has landed, and is on a fast path to stabilization, I think the right call here is to just remove all mentions of custom-derive from the docs instead.\n. Looks like nightly got moved out of allowed failures is the only problem. \n. You should be able to just create the view in a transaction and it'll be fine. \n. r? @diesel-rs/contributors \n. Probably worth mentioning that the value of attisdropped on the entry with the wrong name is 'f'\n. @iamsebastian Is there a reason you're unable to use infer_schema! for that?\n. No, what I mean is that I'm curious why you need to print out the schema instead of inferring it.\n. infer_table_from_schema! would work for that as well. Just to expand on that, I do want to provide a function that verifies that the schema matches what is expected at runtime. You'll need to use master if you're using 1.15 beta. The guide will be updated tomorrow.. r? @diesel-rs/contributors \n. No I need to rebase and then add changeset options to the list of attributes for Syntex to strip\n. r? @diesel-rs/contributors \n. Ok so a fatal error is actually the only kind of error... So the docs just straight up appear to be lying. For posterity, the error that causes this issue is a query with more than 34434 bind parameters.\n. My assumptions here were wrong. Macros 1.1 took up a lot of time, but this will be in the next release.\n. sql isn't intended to work with bind parameters. For any case where bind parameters are likely to appear (e.g. anywhere that isn't special syntax for an additional clause or type of query), some combination of sql_function!, infix_expression!, postfix_expression! and prefix_expression! should be sufficient. If you give more details about what you're trying to do in gitter, I can help further.. Gah the insertable commit got pulled in here and I can't make it go away\n. Yeah, you're correct. You'll need to box it before the branch, but you won't need to box it again in each branch. Once it's boxed it stays boxed forever.\n. Merging when CI is green again since this has been extracted from a reviewed PR\n. Review? @diesel-rs/contributors \n. Review? @diesel-rs/contributors \n. Once the macros 1.1 port is finished we won't be affected by any breakage in nightly, so it'll be fine.\n. Review? @diesel-rs/contributors \n. Review? @diesel-rs/contributors \n. Travis is refusing to re-run but I believe I've fixed the failures\n. I prefer the tests broken, thanks. Closing\n. Tests should finally be green. @diesel-rs/contributors review?\n. Review? @diesel-rs/contributors \n. Fixed those failures, but now seeing a really cryptic message from Cargo about path overrides doing things incorrectly. We've also got the rustc-macro -> proc-macro rename landing tonight so I'm going to wait until tomorrow to figure this out\n. And there's more dead code to remove\n. Can you submit the API change as a separate PR without re-implementing it? That will make it much easier to review.\n. I'm wanting to release today, so in order to make sure things move quickly I'm going to go ahead and take over here and make the changes I'd like to see (and split up the PR into smaller commits). I'll make sure you're credited on the commits that go in.\n. Relevant code pulled into #471 and #472.\n. @killercup Got time for a review?\n. @killercup Review?\n. Review? @killercup \n. Uh I guess I did this in the wrong order but I merged after squashing\n. Oh I forgot to push is why\n. Review? @killercup \n. Running it locally a few times should show failures yes\nOn Wed, Oct 12, 2016, 1:07 AM Cyryl P\u0142otnicki notifications@github.com\nwrote:\n\nHi ! Is it easy to detect flakyness locally, e.g. would just rerunning the\nsuite couple of times locally give you intermittent failures ?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/475#issuecomment-253120216,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK4RW2pwMzVPuV4SS4Ham-0L_lw7xks5qzGslgaJpZM4KS8mR\n.\n. Review? @diesel-rs/contributors \n. Yeah, I'll address the docs after I add chrono support. I'm not super worried about adding specific tests for &str (we don't have explicit tests for &[u8] vs Vec<u8> either)\n. @weiznich As mentioned, I'd prefer an implementation that looked something like https://github.com/diesel-rs/diesel/pull/385#issuecomment-236690138. The query would still succeed from the user's point of view, as we'd handle the error in the connection itself. See the discussion on the linked thread.\n. Going to tackle this tomorrow. Review? @diesel-rs/contributors \n. Failure is from compile-fail, will fix before merging but not likely relevant. \n. I'll try to look at it today.\n. I finally have a working implementation of Identifiable that allows non-references. It was much more difficult to figure out than I expected. We really need ATCs. :. This should be up to date and working now. Merging once CI is green. @Drakulix If you could give this another go when you have a chance that would be awesome. I'm going to get #[derive(Identifiable)] working with composite PKs soon, and then test out the rest of the features with composite PKs. Your Identifiable impl should look like:\n\n```rust\nimpl HasTable for UserHasApp\n    type Table = user_has_app::table;\nfn table() -> Self::Table {\n    user_has_app::table\n}\n\n}\nimpl<'a> Identifiable for &'a UserHasApp {\n    type Id = (&'a Uuid, &'a Uuid);\nfn id(self) -> Self::Id {\n    (&self.app_id, &self.user_id)\n}\n\n}\n``. No, this isn't possible at the moment. #429 goes in that direction, but we're not sure if it's the direction we will take.\n. The examples assume the use of PostgreSQL. However that error looks like the schema is incorrect, where a field that should beNOT NULLis nullable.\n. I _think_ this is a bug in the latest nightly, but I will investigate further.\n. I'm hoping to get this fixed upstream.\n. Is it safe to assume that the location ofsqlite3.dllis on your path?\n. I don't control thelibsqlite3-sysproject, so you'll have to open an issue with them. The only step that you listed that I can potentially do anything about is the renaminglibpq.libwhich seems odd to me, and I've never had to do on Windows.\n. Closing this issue, as any changes to make this easier will happen to https://github.com/sgrif/pq-sys, not Diesel. I will also be releasing a new PG driver early next year which will not depend on libpq, and should make this easier.. @martinth Would love to get that info as a PR to some part of our documentation (not entirely sure where the right place would be). There are no plans at this time. Diesel is designed to allow for third party adapters to be written out of tree though. Feel free to drop by our gitter room if you are interested in pursuing that.\n. Review? @diesel-rs/contributors \n. This was merged.\n.0.8.0is equivalent to^0.8.0which will resolve to0.8.1.\n. We don't currently support the geometric types\n. We don't currently support the geometric types. Would love to see someone write a third party crate for this.. Swap the order ofextern crate diesel;andextern crate diesel_codegen. I've opened https://github.com/diesel-rs/diesel/issues/495 which has the root cause to discuss what we can do to make this workaround unnecessary. \n. Review? @diesel-rs/contributors \n. Seeing ICEs on the latest nightlies so I'm holding off on merging this for now. https://github.com/rust-lang/rust/issues/35900#issuecomment-261091872\n. Rust master should be fixed. Will check again tomorrow\n. Review? @diesel-rs/contributors \n. I don't have a list, no. I usually add a FIXME comment if something is significantly worse off without a feature. \n. Oh good, nightlies are building again. This is fixed by https://github.com/diesel-rs/diesel/pull/493. I'll try to release tonight.\n. As a workaround in the short term you can use an older nightly.\n. All rust nightlies which have this issue are actually completely broken for procedural macros. It's all fixed on master, so we'll release tomorrow or the day after depending on when the nightly was rolled\n. 2016-11-06\n. Runcargo clean` and recompile. Nightlies don't ship unless they work on all platforms. I use mac to develop primarily, and windows periodically.\n. 0.8.2 has been released with a fix. https://github.com/diesel-rs/diesel/issues/44. Duplicate of #496. 0.8.2 has been released with a fix. You can also see how we're handling this in crates.io -- https://github.com/rust-lang/crates.io/blob/4082d4e49c0e24a4883f301cc299360d4b828aaf/src/dependency.rs#L162-L184 https://github.com/rust-lang/crates.io/blob/4082d4e49c0e24a4883f301cc299360d4b828aaf/src/dependency.rs#L54-L65. Closing for the same reasons as https://github.com/diesel-rs/diesel/issues/343#issuecomment-352206453. Separate commits during code review. I will often request a squash after everything looks good. Thanks for working on this. I have to go make dinner, but I will finish reviewing tomorrow. @killercup feel free to merge if you think it's good to go\nOn Mon, Dec 5, 2016 at 5:37 AM Pascal Hertleif notifications@github.com\nwrote:\n\n@killercup approved this pull request.\nGreat! I'm fine with merging this as-is, but also left a few more inline\ncomments with really tiny stuff.\n@sgrif https://github.com/sgrif wanted to review this as well. I don't\nknow if he finished dinner already, though. Apparently, there was a huge\namount of cheese involved, so I don't want to rush him ;)\n\nIn diesel_codegen/src/schema_inference.rs\nhttps://github.com/diesel-rs/diesel/pull/504#pullrequestreview-11349379:\n\n\nlet connection = establish_connection(database_\n\n\nurl).unwrap();\n-    let data = get_table_data(&connection, table_name).unwrap();\n-    let primary_keys = get_primary_keys(&connection, table_name).unwrap()\n+    let connection = establish_connection(&database_url).unwrap();\n+    let data = get_table_data(&connection, &table_name).unwrap();\n+    let primary_keys = get_primary_keys(&connection, &table_name).unwrap()\nJust for a fun exercise: I'm pretty sure the &s you added here are no\nlonger necessary \u2013 the bindings are already references. (Deref coercion\nallows rustc to accept &&&foo where &foo was wanted.)\n\nIn diesel_codegen/src/embed_migrations.rs\nhttps://github.com/diesel-rs/diesel/pull/504#pullrequestreview-11349379:\n\n@@ -15,7 +15,7 @@ pub fn derive_embed_migrations(input: syn::MacroInput) -> quote::Tokens {\n     }\n\n let options = get_options_from_input(&input.attrs, bug);\n\n\nlet migrations_path_opt = options.map(|o| get_option(&o, \"migrations_path\", bug));\nlet migrations_path_opt = options.as_ref().map(|o| get_option(&o, \"migrations_path\", bug));\n\nNice. I think you can just give it o instead of &o here (same as other\ncomment).\n\nIn diesel_codegen/src/ast_builder.rs\nhttps://github.com/diesel-rs/diesel/pull/504#pullrequestreview-11349379:\n\n@@ -11,6 +11,6 @@ pub fn ty_path(path: Path) -> Ty {\n pub fn path_ident(ident: Ident) -> Path {\n     Path {\n         global: false,\n-        segments: vec![PathSegment::ident(ident)],\n+        segments: vec![PathSegment::from(ident)],\n     }\n\nFYI this whole function can be replaced with ident.into()\nIn diesel_codegen/src/schema_inference.rs\nhttps://github.com/diesel-rs/diesel/pull/504#pullrequestreview-11349379:\n\n@@ -62,7 +62,7 @@ fn column_def_tokens(\n     let path_segments = column_type.path\n         .into_iter()\n         .map(syn::Ident::new)\n-        .map(syn::PathSegment::ident)\n+        .map(syn::PathSegment::from)\n\nI added a bunch of From impls to syn a while back. I don't think we need\nthe .map(syn::Ident::new) here anymore.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/504#pullrequestreview-11349379,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK0kN4kOiW0-cCs-il-1lNycE0PyTks5rE-ldgaJpZM4LBGAM\n.\n. I think the reason it's unused is that this branch was made before we had lifetimes there, but the file merged fine, so the \"usage\" is using the wrong syntax and therefore not actually being used.. Thanks!. Review? @diesel-rs/contributors Not sure what's up with Cargo & SSL on CI, but the failure is unrelated. Review? @diesel-rs/contributors . This was :+1:'d in gitter. Review? @diesel-rs/contributors . Script gone rogue. Reopening. Review? @diesel-rs/contributors . > I'm not quite sure why you needed to explicitly state for<'a> &'a Parent::Id: Borrow for that, but okay. :)\n\nIt's because the lifetime of Parent is unnamed, but I change that in the final commit in this series.. @killercup Last one. <3. > IIRC in the ATC RFC they were asking for concrete use cases (I haven't followed that discussion). Do you have a vision for how ATCs can make this API and the type signatures involved nicer?\nWith ATCs we would be able to remove pretty much every place that we are implementing traits for &'a T but not T. (Which is this trait, and every trait touched by this PR). Since we could just get the ID for a given lifetime at that point, life would be much easier.. Looks like I forgot to add NOT IN when I added IN. If you're on PG I'd recommend using .ne(any(array)). I'll add NOT IN for SQLite in the next version though.. Review? @diesel-rs/contributors . Review? @diesel-rs/contributors . Ugh.... Fiiiiiiiine. I cave.. I will try to tackle this for the release after the next, which I will work on after I get back from holiday vacation. So late January. Probably. No, Postgres is a better place to start. SQLite is fundamentally different.. MySQL support has been fully implemented, and will be released with Diesel 0.11.. Review? @diesel-rs/contributors . Review? @diesel-rs/contributors . CI failure is due to what appears to be a bug in the latest nightly. There was a bug in Rust nightlies on that date. Please update to a later nightly.. You may also need to run cargo clean afterwards. Review? @diesel-rs/contributors . Review? @diesel-rs/contributors . This was implemented by #617 and we didn't like the code. Variadics will eventually make this pointless anyway.. This is because CockroachDB doesn't support stored procedures. We can probably add a skip-timestamp-helpers feature or something and just not generate those functions.. Review? @diesel-rs/contributors  . Review? @diesel-rs/contributors . Review? @diesel-rs/contributors . Review? @diesel-rs/contributors . @killercup Do you have any thoughts on this approach vs the alternative mentioned? The reason I bring it up is because the alternative would give a decent opt-in for MySQL if you actually needed to compile with multiple databases, whereas this approach is pretty much PG only as I'm not comfortable loading DBs other than the one connected by default. It might be strange to support other DBs on MySQL but not on PG, but then again there would be no reason to need it on PG with custom schema support. Unfortunately, if we want to be able to use macros 1.1, we can only take string literals as arguments.. > What makes MySQL special here?\nIt uses the term \"schema\" and \"database\" interchangeably. If you query information_schema.tables (which is ANSI standard by the way) on MySQL, tables from databases other than the one you're connected to would appear, and the database name appears where the schema name appears in PG.. > Can you do ($database_url:expr, $schema:indent) and expand to #[options(database_url=strigify!($schema))] so users can only supply something that can become a module name?\nNo, this is the same reason we had to add the \"env:ENV_VAR\" magic string form. Macros can't appear in this position.. It'd just be one infer_schema! call per schema name. Updated. The CI failures are because syntex is trying to compile the PG specific module, even if we're using the SQLite feature. I'm just going to move it out of the set of modules evaluated by syntex and restrict that test to nightly only since we're quite close to removing syntex entirely.. Review? @diesel-rs/contributors . Should be green now. Looks like doctests for macros aren't running on the latest nightly. Can you squash your commits and mention why this change is needed inside the commit message?. We may add support for multiple tables in the future, but for the time being the best way to handle this is going to be to implement Insertable by hand. \nExample implementation:\n```rust\nstruct SomeForm {\n    field1: String,\n    field2: String,\n}\nimpl<'a> Insertable for &'a SomeForm {\n    type Values = <(Eq, Eq) as Insertable>::Values;\nfn values(&self) -> Self::Values {\n    (table1::field1.eq(&self.field1), table2::field2.eq(&self.field2)).values()\n}\n\n}\n```\nI think you're right that AsChangeset could use a type parameter instead of an associated type, but at this point we can't make a breaking change there. You could probably use a macro + tuples for this case instead. Identifiable would never be used with more than one table, since its point is literally \"this struct represents a single row on a single table\", and one of its items is \"what table is this associated with?. I'm going to merge as-is because I'm going to release a point version and having working links would be nice. If you could follow up with another PR to fix the usage of absolute URLs that would be awesome though.. This code will look fairly ugly if it's generic, but this is roughly what you'd want:\nrust\nimpl<T> ListData<T> where\n    T: Table,\n{\n    pub fn set_page<'a, DB>(params: &Map, max_items: i64, source: BoxedSelectStatement<'a, T::SqlType, T, DB>) -> BoxedSelectStatement<'a, T::SqlType, T, DB> where\n        DB: Backend + HasSqlType<T::SqlType>,\n    {\n        // your code\n    }\n}\nYou may need to disambiguate T::SqlType by writing <T as AsQuery>::SqlType. . I think that allow on the entire generated module is fine. Agreed that all generated code must always be warning free. . Also thanks for fixing this. :). aliased and with are only for CTEs, not your usage. The short version is that you will need to use the sql function until #3 is fixed. \nI do want to expand on the aliases thing though. We don't have any mechanism for arbitrary aliases in SQL, as it's not necessary. I am on my phone on roaming internet so apologies if the code is poorly formatted or has typos. For example, you could do:\nlet max_ordering = max(ordering);\nelems.select(max_ordering)\n    .group_by(tpe)\n    .order(max_ordering)\nWhich will generate the SQL \nSELECT MAX(ordering) FROM elems GROUP BY type ORDER BY MAX(ordering)\nYou may say \"but that's less efficient!\". It's not, though. If you look at the query plan it's identical to the aliased form. Query planners are smart. . The error message is telling you that you are using the wrong integer types. Integer is the equivalent to i32. If you want to use i64 in Rust, you should use BigInt instead. SQL does not have unsigned integers which is why you cannot use u32. We don't currently support the inet type. You can find a list of all types that we currently have implemented in the core crate at http://docs.diesel.rs/diesel/types/index.html and http://docs.diesel.rs/diesel/pg/types/sql_types/index.html. Support for using infer_schema! with types added by third party crates is tracked by #88.. Hm... I feel like this used to work in the past. It definitely is meant to work (with or without a default being present, which we currently don't/can't verify). This has gotten pretty stale. Feel free to re-open if you still want to work on this. BTW https://github.com/SergioBenitez/Rocket/blob/24805bbf16d25a21d6a926c86035ac905524c71c/scripts/test.sh#L80-L84 I super promise everything is fine now. Macros 1.1 fixed everything.. > I'd be interested in having my application at start up run the migrations as well, are there any code samples for that.\nWe provide the run_pending_migrations function which you can use to run your migrations at app startup. I don't think there have been any best practices established yet. Certainly at minimum calling that function from main is a pretty reasonable practice.\nWe also have the embed_migrations! macro which puts the migration SQL in your binary to remove the need to have them on disk (and is much worse documented than I thought... The way you use the generated code from that macro is embedded_migrations::run(&conn) for the record.) Unsure if we want to consider using that macro a best practice or not for typical server deployments. \nInterested in other people's thoughts/stories around this.. infer_schema! is entirely evaluated at compile time. There is no distinction between \"production\" and \"not production\" for those purposes. It's fine to run your migrations in main if you're using infer_schema!. The migrations will have to have been run on the compilation host prior to compilation (which can include running migrations from build.rs).. I'm clearing out old issues, and I'm going to close this as there's not much discussion still happening here.\nTo add a final datapoint:\ndiesel print-schema is now the recommended way to use Diesel. infer_schema! is still around, and it's useful for development when you're just getting started, and your schema churns a lot, but diesel print-schema! significantly simplifies deployment since you no longer need a database running to compile/deploy the application.\nThe way we run migrations on crates.io is literally by having our \"run\" task be diesel migration run && start-server. We don't have the lower function built in yet. I'd certainly accept a pull request that adds one. We provide the sql_function! macro as well which would allow you to just define the function locally like so:\n```rust\nsql_function!(lower, lower_t, (a: types::VarChar) -> types::VarChar);\ntry!(table1::table.filter(lower(table1::name).like(query)).load::(&conn));\n```. > NOT READY FOR MERGE\nOk merging. :trollface:.  >  At the moment, some serde features do require a codegen plugin, but that will go away when Macros 1.1 lands.\nThe master branch is for 0.10, which will launch no earlier than the release of Rust 1.15 which will stabilize Macros 1.1, so that's not a concern.. > looks like it can also work with SQLite's JSON type.\nLet's not worry about that type for now (or any type that is an extension to any backend).. I think we should support FromSql for String and Vec<u8>, but not ToSql. It's definitely reasonable to want to send JSON from the database unchanged to a client, and skip the deserialize/serialize step. For ToSql though, we only want to support types that we are reasonably sure are valid JSON.. When I originally wrote #44, I had envisioned that we would have our own enum which was basically a copy of the \"json value\" enum that both rustc-seriailze and serde provide. However, that was over a year ago, and a lot has changed. I'm fine with just targeting serde.\nI also envisioned (and would still like to somehow have) an impl that was roughly:\nrust\nimpl<T: serde::Deserialize> FromSql<types::Jsonb> for T\nBut that will likely never be possible within Rust's coherence rules until we figure out some method of permitting overlap.\nCan we see if we can avoid having JSON be treated as a separate type from JSONB internally? I get a result from select * from pg_cast inner join pg_type a on a.typname='json' and a.oid=castsource inner join pg_type b on b.typname='jsonb' and b.oid=casttarget; so I think we can. It will simplify operators and functions if we can treat them as the same type internally. So just doing pub type Json = JsonB should suffice.\nOverall this code seems fine for the parts that it has tried to accomplish so far.. > Also, I'm not sure how to implement them. But I'd be happy to accept suggestions!\nThis can be a separate PR, but the implementation of array comparison operators is probably a good place to start. Relevant code is here and here. Thank you for working on this! I'm excited to hear you guys are experimenting with Diesel. Let me know if there's anything else I can do to help.. > Is there a story for implementing these traits correctly from outside diesel itself?\nNot at the moment. We should probably make those macros public (with a #[doc(hidden)] or a note that they are likely to have their APIs change pre-1.0, and decide if there's a better API post-1.0. Ideally I'd like to provide more blanket impls in Diesel itself and make those macros obsolete, but that at minimum would require specialization, and likely even that wouldn't be enough without the lattice rule.\nAnyway it needs further exploration and discussion. I'm fine with making those macros public for the time being if you'd like to open a PR.. @dtsu No, HasSqlType<T> is considered local if T is local. https://github.com/diesel-rs/diesel_full_text_search/blob/master/src/lib.rs#L8-L27. Closing as a duplicate of #162. See https://github.com/diesel-rs/diesel/issues/343#issuecomment-352206453 for some thoughts on this.. Also I should expand on this a little bit since this issue is slightly different. Specifically for the case of \"implementing support for a Rust type that is not crate local, for a SQL type which is crate local\" (an example of this is implementing support for HashMap<String, Option<String>> for an Hstore type). Currently the only thing we implement for types in Diesel that you cannot write from outside of Diesel is impl AsExpression<Nullable<Hstore>> for HashMap. Right now the concrete affect of that is that you cannot have an Insertable impl where one of the columns is Nullable<Hstore>. That's going to get fixed (probably in 1.1). The only other place that's visible is that you can't do nullable_column.eq(map), you'll have to do nullable_column.eq(Some(map)) instead. If that last bit is the only visible difference between types in Diesel, and types outside of Diesel, I think that's acceptable.. > Were you also envisioning this diff fixing all of those items missing documentation as well?\nDefinitely don't submit one PR fixing all of the documented items. One PR per file is about the right size. We can't accept a PR that adds #![deny(missing_docs)] until after the documented items are fixed.. Y'all need to review my open PRs so I can close this. ;P. I think using CURRENT_TIMESTAMP here. I'd prefer to avoid specializing this per-backend if possible. The constraints around transactions and lack of subsecond precision are acceptable for migrations.\nAlso I like your sense of humor with the title. :). I'm fine with that. . Sorry I haven't been following this super closely, but what was the issue with CURRENT_TIMESTAMP? It is ANSII standard and should work on all backends.. Ah, I see. Carry on then. :). I think we could change a bit less code if we use a single name like diesel_codegen_options instead.. I honestly don't have that strong an opinion. Can you changes which are formatting-only? I will merge after that. It's not that I disagree with the changes, just that we prefer to avoid git-churn as much as possible.. I'm not sure there's much else that's going to happen on this in the near future. infer_schema! and diesel print-schema should be excluding views (if that's not the case, please open an issue). Creating a table! declaration for a view is fully supported. table! requires a primary key, but you can safely just pick any column and call that your \"primary key\". Probably a marker trait like HasDefault for making Option<T> invalid and eventually some trait to represent if a given set of columns is a superset of the columns with no default. Nullable would go out of the picture for inserts since a nullable column is technically default null if not otherwise given. . We just need to implement the derives that are behind a cfg flag to give a\nmore specific error when called.\nOn Tue, Jan 10, 2017, 9:20 AM Pascal Hertleif notifications@github.com\nwrote:\n\nIs there a nice way to do this? All I can think of is something like\n[cfg(not(any(feature = \"sqlite\", feature = \"postgres\")))]mod hello_you_need_enable_one_of_the_backend_adapters_as_cargo_feature_thank_you;\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/570#issuecomment-271586781,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK7DlGUF5trvNMvzuL7fY_4ylZzuxks5rQ5OLgaJpZM4LejmM\n.\n. This was fixed a while back when compile_error! was stabilized.. It looks like EarlyLintPass does run early enough to catch these cases.. Additional case we should lint for: References on Insertable structs for types other than str and [T]. Error message is super unhelpful in that case. I'm going to stick this on the milestone. I think this would be a great thing to have done for 1.0. Right now I don't think that'll be possible, but if we have some more people come in to help with documentation I should have some more bandwidth to work on this.. This isn't happening in time for 1.0.. Thanks!. Not sure if there's still a question that needs answering here, but the structs prefixed with Pg are always representations of how PG sends something over the wire, not structs intended for use in application code. Using chrono or SystemTime is the proper way to do this.. Looks like there's nothing actionable left here. If you're still having trouble, I recommend trying Diesel 0.10 with Rust 1.15 stable.. You need to unwrap the result or handle the possible error.. This is probably a question to ask on the r2d2 repo, but it looks like you can set a connection customizer in the pool's configuration. http://sfackler.github.io/r2d2/doc/v0.7.1/r2d2/config/struct.Builder.html#method.connection_customizer. Duplicate of #196 . > Is there a way to avoid this and write it in a way such that I don't have to change the query when adding new columns to filter?\n\nWell if you want to select a subset of the fields in the table, you'll need a custom select clause. So not really. \n\nI could get the original to work if there is a way to splat/unpack a tuple into columns. Is there a function for this in postgresql?\n\nI don't think so, but I'm also not sure I fully understand the goal of doing that.\n\nStill the SQL injection issue..\n\nThe solution there is to use the query builder instead of a SQL string. Unless I'm missing something, your query is (other than the select clause) identical to:\nsql\nSELECT\n    ts_rank(\n        to_tsvector('english', filters.name) ||\n        to_tsvector('english', filters.description) ||\n        to_tsvector('english', array_to_string(filters.tags, ' '))\n    , plainto_tsquery('{}'), 32) AS score,\n    id,\n    user_id,\n    created_at,\n    updated_at,\n    name,\n    description,\n    code,\n    params,\n    tags\nFROM filters\nWHERE score > 0\nORDER BY score DESC\nIf that's the case, it's also identical to:\nSELECT\n    id,\n    user_id,\n    created_at,\n    updated_at,\n    name,\n    description,\n    code,\n    params,\n    tags\nFROM filters\nWHERE ts_rank(\n        to_tsvector('english', filters.name) ||\n        to_tsvector('english', filters.description) ||\n        to_tsvector('english', array_to_string(filters.tags, ' '))\n    , plainto_tsquery('{}'), 32) > 0\nORDER BY ts_rank(\n        to_tsvector('english', filters.name) ||\n        to_tsvector('english', filters.description) ||\n        to_tsvector('english', array_to_string(filters.tags, ' '))\n    , plainto_tsquery('{}'), 32) DESC\nWhich can be written in the query builder as:\n```\nsql_function!(array_to_string, array_to_string_t, (a: Array, b: Text) -> Text);\nsql_function!(ts_rank, ts_rank_t, (a: TsVector, b: TsQuery, c: Integer) -> Float);\nlet search = ts_rank(\n    to_tsvector(\"english\", filters::name).concat(\n    to_tsvector(\"english\", filters::description)).concat(\n    to_tsvector(\"english\", array_to_string(filters::tags, \" \"))),\n    plainto_tsquery(your_variable), 32).aliased(\"search\");\nfilters.with(query).with(search)\n  .filter(search.gt(0))\n  .order(search.desc())\n  .select(your_columns_here)\n```\nThis exact use case is actually in the documentation here. Looks like this has been resolved. You can also do this by adding the PG directory to your PATH, there's an executable in the PG install directory which does this for you as well.. Certainly for the cases covered by that pseudocode this seems completely reasonable to add. So I don't think I want to add support for \"treat domain type as its base type\". That check constraint you've provided means that the range of values that can be serialized differ from those of the base type. In this case you can create struct MyType;, and implement a bunch of traits example from our test suite. This is a bit verbose right now, it's going to be a focus of 1.1. #162 is the tracking issue for that.\nTypes that aren't in diesel::types can be used in table! by doing:\n```rust\ntable! {\n    use diesel::types::;\n    use my_types::;\nfoo {\n        id -> Integer,\n        bar -> MyType,\n    }\n}\n```. I'm assuming the CI failures have nothing to do with your changes but I need to fix them before I merge. Can you rebase to trigger a new build?. This should have been fixed in 0.9. Can you provide a script to reproduce?. Just to clarify on why it is important that this is an error case, while inserting an empty vector is not:\nWhen you insert 0 rows, we always know exactly how to replicate the behavior that would have otherwise occurred (execute returns Ok(0), get_results returns Ok(Vec::new()), and get_result returns Err(NotFound)). That is not the case with a changeset with no changes.\nIn the absolute simplest case we'd need to do the equivalent SELECT statement to figure out what to return, but even that is insufficient. We'd also need to vary our behavior based on whether the changeset given was attempting to use upsert. Even with all of that, the triggers executed could potentially change the outcome as well.. This is a (very) long term goal. I think this is more likely to end up being a lint than a hard error, as actually representing this in the type system is likely impossible unless we have some form of anonymous struct/record. . This is no longer a goal of the project. Properly supporting this would require not just know about the type and default of the column, but also any triggers that could fire. If we were truly to support this we would also need to care about constraints as well.\nUltimately the revised goal of the project is to prevent all errors on select statements at compile time, and many classes of errors on insert/update, but not all.. If we're able to do a version range that supports both without much additional work that would be preferable. /cc @alexcrichton it looks like there's also no way for us to opt just the one crate out of being in the workspace? What's the best option here since binaries are supposed to check in their Cargo.lock?. I'm going to remove the Cargo.lock from the tree as well, since crates.io will never use it by the look of things.. Can you provide the error message you received? Was the file actually present at the path you pointed to?. Nightlies later than nightly-2017-01-19 or so are busted. You can point diesel_codegen master to work around the problem. https://github.com/rust-lang/rust/issues/39347. Can you give an example of the .env file that was failing so I can make sure we give an error message than handles that case? Was the .env file itself invalid?. http://docs.diesel.rs/diesel/expression/expression_methods/global_expression_methods/trait.ExpressionMethods.html#method.eq\nThe docs have a search function, that method is the first result when searching for eq. The method for IS NOT NULL is called is_not_null, and is documented here (again, found by typing is_not_null into the search bar). Yes, writing a guide on this is the second one on the list that I give for people who reach out to help with the docs.. The main reason those macros are in the main Diesel crate is to provide access to $crate, and avoid hard coding ::diesel.. You can rename an extern crate, and you also do not have to import it at the root of your project. . Hm. I did like having the macros in the main crate since it made it possible to unit test a lot of the codegen stuff (especially weird combinations of things that need to be enumerated) without relying on actual codegen, but I should reconsider that. I can't reopen this PR so you'll need to open a new one.. Yup. Thanks!. Looks like we need an annotation on UpdateStatement and friends. Feel free to open a PR. I'll fix the doctests before merging, just need an extern crate in the setup file. LGTM pending CI. > Do you want to add more to this to include a test that actually connects to a MySQL server?\nAll of our existing tests do that. They now fail on the unimplemented!() call that is the result of begin_test_transaction(). @Eijebong You can't join to more than two tables in a single query, but having multiple associations on a single model is definitely supported. This is a bug.. Ah, I see what's going on now. The issue isn't that there are multiple associations, it's that this is a self-referential association.. If by \"Will it be possible in the future\" you mean \"is this a thing that I think is reasonable to do and want to support eventually?\", then the answer is yes. If you mean \"is this a thing you are actively working on and have a concrete timeline for?\" then the answer is no. As I was writing that I realized this is literally just an if statement in codegen. I'm 99% certain the only problem with it is the invocations of select_column_workaround!. This should be trivial to support.. Going to close this for now, as I think the need for this is going to end up going away one way or another. If we continue to only implement for sizes up to 4 (which seems to be all we need, really), I think the code is much more accessible without the macros. I'm going to remove the comment for now. Thanks for working on this, and sorry it got caught in the confusion.. > but I have not tested the code locally or have enough knowledge of MySQL to really be sure.\nWell it seems to at least get to calls to query_all and execute_returning_count before blowing up now, so I think we're on the right track.. I think the specific source of this error is likely the dsl module.\n```rust\nmod $table_name {\n    pub struct table;\nmod columns {\n    // ...\n}\n\nmod dsl {\n    pub use super::table as $table_name;\n    pub use super::columns::*;\n}\n\n}\n```\nIn theory we could just skip generating the dsl module if there's a column with the same name as the table. That is potentially even more confusing than an error though. If nothing else, giving a more helpful error message is certainly the easiest thing to do here.. > Which seems fine since right now DEI is only implemented for String\nActually, it's also implemented for PgErrorInformation, which is the main reason this trait exists in the first place. Still I think you're right that it's fine to require Sync here. The original implementation of PgErrorInformation was not Sync, but that changed in 7e378c48, where I specifically mention that the unsafe impl Sync is fine. I've double checked that there's no issue sending a *mut PGresult to another thread or sharing it, so this seems fine.. .order((replied.desc(), updated.desc())). You can find the docs for .order here. Whoops, I didn't think 0.10.1 affected the core crate. I will release now.\n. > Let's hope we can deal with MySQl on a higher level of abstraction from now on ;)\nOther than adding some ToSql/FromSql impls, yeah the rest of the interaction should be through the query builder.. Can you add a CHANGELOG entry?. You need to add #[derive(Identifiable)] to Like, which will also require adding #[primary_key(user_id, post_id)]. Yes, that looks fine to me.. Can you add a changelog entry as well?. Merged as 9bb2430. Going to merge this as the follow up is more in need of code review than this is.. I rebased poorly. https://github.com/diesel-rs/diesel/commit/e0272a4398444666ea7a62b2cf1e6a98003fd17e was the commit this added.. https://en.wikipedia.org/wiki/Information_schema\nThis code should work with minimal changes for everyone except Oracle, DB2, and SQLite.. Not quite yet. Still need to get the test suite fully passing locally, and a bit more cleanup. Soon though.. According to that error message, you're missing impl<'a> AsExpression<Nullable<Text>> for &'a UserId. I expanded on this in https://github.com/diesel-rs/diesel/pull/429#issuecomment-278367893. Feel free to comment here, open a new issue, or ping in gitter if this hasn't been sufficiently answered.. Thanks @dnagir for making me aware of this issue.. Rerunning. Will make it deterministic in a separate PR.. Thanks @dnagir for making me aware of this issue.. Unless I'm misreading the source, libmysqlclient will always install signal(SIGPIPE, SIG_IGN), and the CLIENT_IGNORE_SIGPIPE flag doesn't appear anywhere in the codebase other than in the definition.. Going to git log -SCLIENT_IGNORE_SIGPIPE. This will take a while.. This setting appears to be completely useless and broken since https://github.com/mysql/mysql-server/commit/ebd24626ca38e7fa1e3da2acdcf88540be70fabe (or earlier, but that was the last time it was referenced in libmysqlclient). MySQL will always clobber any handlers installed for SIGPIPE, and we can do nothing about it other than writing a direct wire protocol implementation. I mean... Now that I think about it, it makes complete sense. Of course you wouldn't define \"should we set this signal handler\" as a connection option. It's a global thing. They should still update the docs and remove the define though.. Also they should probably not clobber global signal handlers. Just saying. Agreed. I'll add it to the todo list.. Yes, this has been fixed on master. It's a serious enough bug to warrant a new release. I will cherry-pick it and release a bugfix release with it.. I've released v0.10.1 which includes a fix for this issue. For posterity, this was fixed by https://github.com/diesel-rs/diesel/commit/e0272a4398444666ea7a62b2cf1e6a98003fd17e. We don't currently support representing a join to the same two tables in different ways. Ultimately the plan for this is to allow giving a table an explicit alias, which you can reference separately. This gets into one of the fundamental impedence mismatches we have where you specify a join between to tables by annotating a random struct, not the table itself (because the table is likely not part of your code).\nUltimately this is something that is not slated for 1.0, and very low on the priority list. What is on the priority list for 1.0 is to provide a better untyped raw SQL escape hatch for the \"we don't support this\" cases, so the answer to how to do this with Diesel will likely point you towards that API when added.\n\nAlso, sometimes there are other constraints than column equality in the join condition.\n\nYes, ultimately I want the join_to! macro to be more robust. Conditions other than equality aren't likely to be supported by the associations abstraction though.\nWhile I do think this is something to support this eventually, since it's far past 1.0 and I don't have a concrete API in mind yet, I'm closing this as non-actionable.. For the time being, yes -- only one of the two joins can be represented by the query builder. You need to specify the SQL type of the query when using the sql function.. User is not a SQL type. You probably want users::SqlType. Good idea. I'll do that as a future improvement.. You'll need to box either the order or the whole query. See the examples in the docs here and here. #657 fixes item 1. Timestamp helpers can wait for now.. As long as there's a reasonable use case for recovering from the introduced error kind, and it's sufficiently generic, sure. Somewhat humorously, this bug was unlikely to ever cause a segfault. As long as the allocator is laying things out as compactly as possible, there will always be allocated memory in the address after the end of the vector by the time the overrun could occur.. I left the table! definitions local for documentation purposes. Reflex. Did not mean to open.. Oh man I wish I'd realized this was going to be number 666. I would have made it a PR that enabled MySQL on CI or something.. Lol I don't think the joke is worth that much work. ;). I cleaned this up manually and merged in e160921c1a1d4e62e1aae480ae405d918fe6bc22. All green. This also required https://github.com/sgrif/mysqlclient-sys/commit/3b1daa0f3a8f41fd685f470a3f2db7ca57857862. Can you be more specific? Can you give the output of diesel --version? Are you running against Postgres? Can you give the full error message you receive (and possibly run with RUST_BACKTRACE=1? Are the steps that you followed approximated by the following shell commands?\ncargo install diesel_cli\ndiesel setup\ndiesel migration generate create_posts\necho \"CREATE TABLE posts (...)\" > migrations/xxx_create_posts/up.sql\necho \"DROP TABLE posts;\" > migrations/xxx_create_posts/down.sql\ndiesel migration run\ndiesel migration redo. The guide does say to run diesel migration run.\n\nWe can apply our new migration with diesel migration run. It's a good idea to make sure that down.sql is correct. You can do a quick sanity check by doing diesel migration redo, which will revert and reapply the latest migration.\n\nStill, you shouldn't get an error from omitting diesel migration run. I'll see if I can reproduce.. I was able to reproduce the issue at least. It shouldn't error in this case. I'll open a separate issue to track.. The issue occurs because MAX(col) returns NULL if the table is empty. The SqlType of Max<T> is T::SqlType in Diesel 0.10. https://docs.rs/diesel/0.10.1/diesel/expression/dsl/struct.Max.html Semantically we should probably just change the return type of this (along with min, avg, etc) to all return T::SqlType::IntoNullable.. I wouldn't quite call this easy for newcomers, but it is at least fairly isolated.. > Still a complicated piece of diesel\nYeah, when you're using TypeId as a key in a hashmap as only one possible code path, it's pretty much always going to be complex. XD. You're certain that column is the issue? Nothing looks out of place to me. The only thing that jumps out to me that could be the issue is a mismatch between chrono versions. Are you using Chrono 0.2.x and Diesel 0.10.x?. (Also this isn't related to your bug, but, you probably shouldn't use floats for currency. precio_en_centavos as an integer would be the standard way to do it \ud83d\ude09). I attempted to reproduce your issue and was unable to do so. The code that I used to try to reproduce is at https://gist.github.com/sgrif/6a1a7af32274b19f43cad5c83131e811. This code compiled successfully. Can you please provide additional information that I can use to reproduce, preferably in the same form as that gist?. You have multiple structs called Cuadro. The failure here is because Cuadro is referring to the struct here, which does not implement Queryable, not the one here which does.. Right. The next step is to have this drop the clone assumption and return a RefMut instead.. There's not really any way to make this easier or more ergonomic. In order to make infer_schema! work on stable via macros 1.1, we can only take string literals as arguments. Once we get Macros 1.1 for bang macros or macros 2.0, we will be able to go back to taking any arbitrary input that you want to give us, including one that is based on configuration files.\nWe have special handling for environment variables because it's a common pattern that is easy for us to support without forcing additional opinions on the application. For us to support some sort of configuration file today, we'd have to enforce a specific opinion about how configuration files should work for your application, which is not something I want to do in an ORM.\nAs an aside, is there a specific reason that using .env as a \"configuration file lite\" is something you don't want to do? Until we have another way to implement infer_schema! on stable which allows us to take arbitrary macro input, there's not much else we can do here. The only other option is to not use infer_schema! at all. We provide diesel print-schema which gives you the table! calls directly (though you'll end up needing to give that the database URL as well either through an environment variable or an argument). To clarify, I want to continue to have the generated type be Array<Timestamptz>, but make sure that deserializing to Vec<Option<NaiveDateTime>> deserializes successfully. Even though considering it to be Array<Timestamptz> is technically incorrect, as it could in theory have a null in there, I want to provide some flexibility here. There is no way to represent whether the elements of an array can or cannot be null in postgres.. This was fixed by #694.. I'd like to postpone these for the time being. I think there are two steps I'd like to take as separate PRs before we take this step:\n\nMove the tests for the bang macro to instead use the #[derive] (and presumably move them to the diesel_codegen crate)\nRemove the struct parsing code from diesel and only leave the entry point that codegen uses.\n\nThat would make our job of reviewing significantly easier, help point out gaps in our test coverage, and make me more comfortable with this step.. This has been proposed before. It's still blocked on https://github.com/rust-lang-nursery/rustfmt/issues/815.. Agreed. There are a few more kinks being worked out, but I think we're going to move forward with the default configuration soon.. I do. I'll amend when I merge. :). @killercup re-review?. Can you provide additional information, such as the version of Diesel CLI you were using, the version of Rust you were using, and whether DATABASE_URL was pointing at a Postgres, SQLite, or MySQL database?. If you can give a list of steps I could follow to reproduce that would be helpful. I agree that it's probably something fishy with your setup. Maybe try compiling a program that links diesel without using the CLI?\nIt could also be the loading of one of the c libraries. Do you still see a segfault if you do cargo install diesel_cli --no-default-features --features postges? Do you see it if you run an application linked against pq-sys?. This is fixed on master. It's not a big issue.. Please hold off on opening more of these until we've dealt with the others. . https://github.com/diesel-rs/diesel/pull/692#issuecomment-298238188. I am able to reproduce the issue.. I've identified the issue and am working on a solution. The issue only occurs when no schema name is specified on the table. As a workaround, you can write infer_table_from_schema!(\"dotenv:DATABASE_URL\", \"public.stuffs\"). I still need to look into the issue you were seeing on 0.10.1, as that should have been fixed. The issue with the primary key lookup was only an issue on master, not the released version (and we would have shipped with that bug in place had you not stumbled onto it). Blame points to 58b59e93, so I'm guessing it was just an oversight. I should have pressed for a compile-fail test.. Rolled up into #709.. Rolled up into #709. Duplicate of #376 . > By the way, do you think it'd make sense to actually add tests to document/assert the expected, broken behavior?\nAn example broken case is users::table.left_outer_join(posts::table).select(users::id + posts::id). I'm not sure that it's worth adding a case to the repo for it.. Just need to bump the PG version for the travis failure. Upsert is very new.. > short of adding quickcheck for this\nThis PR includes tests which use quickcheck for this. :) https://github.com/diesel-rs/diesel/pull/713/files#diff-0d44c4b35c16133e20e082de4f8fc12cR114. I think we should special case this in the migrations code. It should still be an error (but one where the CLI gives a reasonable message). Diesel should never generate an empty query outside of migrations. It shouldn't panic, but it should be an error. . So there's two parts to this. The first is that we're panicking when PGRES_EMPTY_QUERY because we don't have an error message. I agree that we need to avoid this. However, receiving an empty query is pretty much always an error case. Empty migrations are the only way to trigger it through the public API. If it were to happen in any other case, it'd be a bug in Diesel. So I think we should add\nrust\nPGRES_EMPTY_QUERY => {\n    let error_message = \"Received an empty query\".to_string();\n    Err(Error::DatabaseError(DatabaseErrorKind::__Unknown, Box::new(error_message)))\n}\nAdditionally, I think we should add an EmptyMigration variant to MigrationError, and give a slightly more specific error message like \"Attempted to run an empty migration.\". Eventually I want to revamp how we handle errors there, and the message can eventually be improved to something like \"Attempted to apply migration 348975234957_name, but up.sql was empty.\", but that's out of scope for now.. Still need to add this to travis.. Can we do the sorting in the actual queries that we execute instead?. Not that I'm aware of, but I'll keep an eye out.. lol. A good place to ask questions is in gitter. There's a link in the README. There's not a way to set a column to its default right now, but it's something we're exploring.. File descriptors and sockets are fine across threads. They're not fine across forks.. I suspect we need to move https://github.com/diesel-rs/diesel/blob/2d6f6b73eb126e5716fc66d152c29b778b568450/diesel/src/mysql/connection/raw.rs#L98-L102 to https://github.com/diesel-rs/diesel/blob/2d6f6b73eb126e5716fc66d152c29b778b568450/diesel/src/mysql/connection/raw.rs#L82. Testing will be a bit of a pain. I will explore it further tomorrow.. See http://docs.diesel.rs/diesel/associations/index.html. Yes, if something is #[doc(hidden)], you aren't supposed to use them, and they're not meant to be public API. Often times we have to make things public from the Rust point of view (either marked as pub or #[macro_export]) because we are using that type/macro inside of a macro which is public API. If something is marked as #[doc(hidden)], that is our way of indicating that you aren't meant to use it. If there's a specific macro that you think should be public API, please let me know.. Can you rebase onto master? I've fixed the build there (releasing 0.11.1 broke it lol). Rebase for CI?. It's fixed.. https://github.com/diesel-rs/diesel/issues/736#issuecomment-280870233. When you say \"diesel\" do you mean diesel_cli? If so, you should install it with cargo install diesel_cli --no-default-features --features sqlite. If you're referring to the diesel crate itself, it doesn't rely on postgres unless you have features = [\"postgres\"] in your Cargo.toml.. Sorry, I don't fully understand what you mean. Do you still need help, or did that comment resolve the issue for you?. Yes, we will be revamping the getting started guide so that it has a SQLite and MySQL specific page. I'll mention it once we do that.. Diesel CLI 0.11 requires that you have libclang and lvm installed. You can find more details here\n(This has also caused a ton of issues and I'll be reverting it later tonight or some time tomorrow if you don't feel like installing those). Once the build is green I'm going to backport this to 0.11.x and release a new version.. Can you add a PG specific test which verifies that all the error fields are correct as well?. I don't know what we need to do to make it show up as a status check, but it's definitely running. https://ci.appveyor.com/project/sgrif/diesel/build/1.0.95. Can you add tests and a changelog entry?. No, just add an ## Unreleased header if there isn't one already.. (This won't go into 0.11.3, it's a feature not a bugfix).. Can you run cargo clean and then paste the output of cargo install --verbose?. Also make sure you cargo update. Hm. That assertion is coming from somewhere other than Diesel. Can you run again with RUST_BACKTRACE=1?. What version of Rust are you running against? (rustc -vV). Assuming the answer is stable 1.15.1, I found the assertion. Very unsure what it means though... Can you give the output of diesel print-schema perhaps?. I grepped the Rust source for assert!(!p.is_null. It's https://github.com/rust-lang/rust/blob/cfebdeaaccee40e060708d6b60c4abbe9edf72bb/src/libproc_macro/lib.rs#L156-L159 (which had no error message in 1.15.1).\nI'd maybe give it a try on nightly. I'm unsure if this is an issue on our end or Rust's.. I suppose so. I wish I could reproduce the issue locally. :. This issue is serious enough to warrant a release. Connection is intentionally not object safe. You can't store a Box<Connection>.. > It'll definitely require a lot of work to redo a lot of guide documentation\nIronically the guide is 100% unaffected by this change. We never call .select or .order in the guide (and even if we did it would probably be with 1 argument since that's the most common case). Yeah, @PlasmaPower that sums up my concerns with that crate pretty nicely.. I did link to an explanation on that too Your explanation is much shorter though. :wink:. @blakepettersson If you want to order something dynamically, you need to either box the order clause, or box the query. The latter is more common. The same is true for varying select clauses (though keep in mind that the select clause for each branch has to have the same SQL type).\nThis PR has nothing to do with either of the uses that you mentioned.. This is unlikely to go forward until we at least know which direction the variadic generics RFC goes.. My response to the PR description without having read the code:\n\nI was unsure if it made sense to introduce diesel::data_types::Money\n\nYes, it does. I would call it Cents though, not Money. > especially since I don't believe any other backend (mysql, sqlite) have a specific MONEY type. Basically, I am unclear on the intended structure and relation of \"generic\" types and backend-specific types...\nBasically we put it in a backend specific module, and pub re-export it from the generic module. I have not decided what we'll do when there's a namespace collision there. > There is currently no implementation of various ops (Add, Mul, etc.); it seems this can be sensibly be implemented here, but was unsure if it should be implemented for PgMoney or some types::Money\nDoesn't need to be handled by this PR.. > Also, is there a rustfmt setting/style used in this project? I use default rustfmt & autofmt in vim, which ended up creating a bunch of formatting-noise edits (not included here).\nNo, rustfmt doesn't have settings for a few things that we really want (mainly having where on the line above the first predicate). We take git churn really seriously and right now the settings we could make with rustfmt would have too much churn. We do want to add one though. I appreciate you making sure that you excluded the formatting-noise changes. . I'm fine with having it be called PgMoney and then aliasing it as Cents, since that's the most common case. I don't want PgCents though -- Usually that prefix is \"this is a type that is the raw representation sent over the wire, not one that you should use\". Cents is a type that we want to encourage people to use. (Literally the main reason for wanting to support this type is so when people ask about what to do with their DECIMAL(10, 2) columns I can stop adding \"but also you should be using an integer as cents for monetary data\" to the end of my answer). Cents is not universally correct, but it is correct for the majority of currencies. I think it's fine to have the alternative PgMoney spelling as well for users who are working with currencies that are not cents.. Can you add a CHANGELOG entry?. Is there a reason you used a third party crate rather than implementing it for IpAddr from the standard library?. Should we add steps 1 and 2 as well? Looks fine to me otherwise modulo licensing issues.. > For potential symmetry with future fns like do_update which might have params? (I think it's fine.)\nYes. Can you run cargo rustc -- -Ztrace-macros and paste the last few lines before the error?. What about without --bin main? Alternatively, can you replace the infer_schema! call with the output of diesel print-schema?. Hm. Well I'm not sure why the error message you're seeing complains about ')', but the issue is that we don't yet support unsigned types. If you change the type of Student.RiskFactor to be a plain float (or use the output of diesel print-schema instead of infer_schema! and manually remove the unsigned), does that resolve your problem? (Also go home MySQL, you're drunk. Unsigned floats are not a thing.). > If you specify ZEROFILL for a numeric column, MySQL automatically adds the UNSIGNED attribute to the column.\nMaybe that?. If nothing else we should be giving a specific and helpful error message here.. http://docs.diesel.rs/diesel/types/index.html is the list of the supported types across all backends. You can also see the types Mysql specifically supports so far by looking at the list of HasSqlType impls here. We can probably just add type Char = VarChar, they should be effectively the same from Diesel's point of view.. If you could actually give a list of the types that you need which aren't supported, that would be extremely useful information for feature prioritization. > I'm sure it would be nice in the future to support all the types the respective databases do at some point.\nThat's roughly the plan (though types that have more involved capabilities such as geometry types will likely live in third party crates). If you want to install without mysql support, run cargo install diesel_cli --no-default-features --features postgres. We're working on revamping it to deal with the fact that there are more backends today than there used to be. It's a long process.. @dessalines Did you actually read the replies?. @killercup Do you mind deleting either .env.sample or .env.example and then merging this?. Yeah, the diff noise got a bit amplified since I decided to switch the parameters everywhere, but it would have been misleading to leave them in the old order in every impl. This was merged I just forgot to push before deleting the branch. We could probably make + work, but I'm not sure how I feel about having it not map to + in SQL.. We could probably make + work, but I'm not sure how I feel about having it not map to + in SQL.. Fixed by #770. I didn't notice that this was opened against 0.11.x instead of master. In the future please make sure you open all pull requests against master.. No, I'll cherry pick it at some point later. With the possible exception of limit, none of those fields are relevant to Diesel. You're certainly able to use Diesel to query information_schema in a similar fashion that we do internally, but the internals of diesel_codegen and diesel_infer_schema are not part of our public API and shouldn't be used directly.. You can get the result of last_insert_rowid in your application using no_arg_sql_function! and select. We may eventually try to implement get_result for inserts on SQLite, but last_insert_rowid has a ton of caveats and gotchas that we've opted to avoid for the time being. table.order(id.desc()).first(&conn) inside of a transaction makes the tradeoffs much more apparent.. No, you're doing nothing wrong. We don't fully support group by yet. See #210 and #3 . The process that I go through for adding a new impl is basically just pub struct NewConnection; impl Connection for NewConnection {} and then let the compiler tell me what to do next (placing unimplemented!() in the bodies of every method definition). Once that's done, I run the test suite and let the failures from unimplemented!() calls tell me where to go from there.\nI'm happy to provide whatever support I can for this, but I would want this to be a third party crate, not a pull request to Diesel itself.. > As an out-of-tree effort, how would I go about running the test suite against my implementation?\nThat is an excellent question that I wish I had an answer to. Short term I'd just pull down the repository, and add your crate as an optional dependency, and test locally that way.\nOne thing I forgot to mention is that if you do write a full adapter, you'll want it to work with Diesel CLI and Diesel Codegen. I'm fine with adding the minimal code required to add a cassandra variant to this enum and the equivalents from other crates, where the match arms basically just call out to your crate for functionality.. I guess the long term answer is that you'll be the first out of tree adapter, so we'll figure something out. Once the crate gets a bit farther along we'll probably add whatever code we need to the test suite, but not run that branch on Travis (or at least put it as an allowed failure). Agreed that checked is the only reasonable option for dealing with currency. However, I think we should panic rather than return an option. If you take the combined wealth of the world and convert it to various currencies, the only one which doesn't fit in i64::MAX is the Zimbabwe Dollar which hasn't existed since 2009. (I'm not terribly concerned about the Zimbabwe Dollar even historically, since the value of 1USD to 1ZWD in 2009 would overflow, it's unlikely to be stored in this data type).\nThe least valuable which exists today is the Costa Rica Colon, which using the highest estimate I could find for the combined wealth of the planet ($260 trillion USD) would be 1.458418e+17 CRC, an order of magnitude less than i64::MAX.. Actually I lied, since this is cents, it would be 1.458418e+19 which would overflow. Still, I think it's fine to say that you need to operate on the inner value manually if you want to work with amounts which approach the combined wealth of the earth in extremely weak currencies.. Fine with me if you want to merge when Travis is green, @killercup. @killercup What are you imagining your syntax would look like for infer_schema!?. Updated, needs a re-review.. Test failures seem related.. Haven't had time for code review lately, we'll get to it. . Hey, thanks for the PR. 0.7 requires bindgen generating at compile time rather than using the bundled bindings, right? That caused huge issues for us and we abandoned that approach for MySQL and PG.\n\nI haven't really looked into what it would entail, but is there any interest in using rusqlite for diesel's SQLite backend\n\nI'm not opposed to it, but IIRC your API is based off of the rust-postgres crate, correct? That makes it pretty fundamentally incompatible for us unfortunately.. Oh hey it looks like you ran into all the same pains. XD https://github.com/jgallagher/rusqlite/pull/247. Excellent! I will merge once CI is green. Thanks for following up!!!! <3. It's been a while since I've gone into it in depth but I remember the biggest issues being Statement having a lifetime parameter attached to it, and bind parameters requiring dynamic dispatch (which basically required boxing). https://github.com/diesel-rs/diesel/commit/8996f28b might have some insights, as it's the commit where I switched to libpq for postgres. > I don't think having ToSql return a Result is going to work here\nLol ok past Sean, whatever you say... (I love reading old commits). > Do you solve this by having statements and rows hang on to Rc'd connections?\nSQLite is the only adapter where we even have to worry about that, and yeah it holds onto an Rc<Connection>. The iterator (our version of Rows more or less) takes a &mut Statement, since it actually has a known, scoped lifetime.\n\nother than an internal cache keyed by the query string.\n\nYeah, that would be the standard way to do it. Ironically, the fact that we don't have to use the query string for our cache is one of our big wins, that's actually visible performance-wise on SQLite. https://github.com/diesel-rs/diesel/blob/master/diesel/src/connection/statement_cache.rs#L99-L105\n\nYou want to be able to say \"bind this value of a statically-known type to parameter with index N\n\nThe index is less relevant (again, SQLite is a bit special here, it's the only backend where the API even cares about the index), but yeah our ToSql and FromSql are generic over the type. We work with tuples rather than slices when we have more than 1 parameter (we're looking at maybe going to hlists, but there's open RFCs that are relevant to that whole discussion #747). We should be preferring SSL connections already, but I agree that we should add the ability to specify ?sslmode=require in the URL, similar to PG.. Yes, I will add support for that as well. Not sure if I have an open issue for this or not, but it also generates incorrect code for custom schemas.. Yeah, I'm thinking of maybe generating with different commands and hosting them at multiple subdomains so that would do the \"contributor docs\" one. We'd still want a feature flag for \"plugin docs\" though since that'd mostly be removing #[doc(hidden)]s. psql -c 'select version();' will give you the version. Are you able to run the migrations from the examples directory in our source tree? (e.g. cd examples/postgres/getting_started_step_1 && diesel migration run). I don't know that we have any control over this. Presumably it's something on Github's end that is causing this to occur? @arthurnn do you know who the right person to ping about this is?. Lol I figure we'll add that to the docs once #650 is resolved. I actually would prefer not to explicitly document this for the time being, since it's such a niche case and I try to avoid encouraging the sql function that exists today in our documentation (since it's a pretty shitty API). It helps if I mark the tests as #[test], too. >_>. This would allow for an incorrect representation of the data being sent, which is why we do not implement this for DateTime<Local> or DateTime<FixedOffset>. The data is sent as UTC (at least we try to ensure it is). If you've overridden the session time zone setting to be something other than UTC, you can take it as NaiveDateTime and convert it manually, but it's up to you to ensure that the time zone has actually been set to that of the client. . Hm. Perhaps I misread the PR the first time. It looks like you're doing a proper conversion. Still, I would prefer to force that conversion to be explicit in the users of Diesel, since allowing this to happen automatically makes it unclear whether we're interpreting the date being sent back as Local, or if a conversion occurred. . Yeah, we can do whatever we want with the domains they're just hosted on DNSimple.. Will look into the CI failure if it continues.. Are you compiling on the host itself, or from your development machine? Can you confirm that the versions of libpq are the same?. Are you compiling on the host or target? (I don't think that should cause a segfault, but good to rule out). Also do you know whether the connection actually successfully established or not? Can you check if user_seen was going to return an Ok or Err had it not segfaulted? It seems like the most likely cause is that we're not handling some error condition properly.. Can you try statically linking libpq? (export PQ_LIB_STATIC = 1 and then cargo clean should do it). Thanks. You've given me information to reproduce, so I will try to look into it (to be honest though I don't have any ideas). The only thing I can think to try is to compile on your host machine.. Closing as this issue has been stale for a while, and there's still nothing actionable we can do. If this issue is still occurring or you can provide additional information, let me know and I'll reopen.. I think for now sql_query is the best bet for something like this. Support for this is roughly the same as supporting selecting from a subselect, which will come at some point in the future.. Yes. We install with all supported backends by default, you need to specify --no-default-features --features whatever,backends to disable certain ones. Once compile_error! is stable we'll probably switch to no backends by default.. We probably just need to bump Diesel CLI to use 0.9.0. Yes, the issue should be fixed on master (I don't think we've rolled a release that included it yet). This appears to be a bug in Rust, not Diesel.. I can confirm that this issue is still present. Given this struct:\nrust\nstruct Foo {\n    #[column_name(barId)]\n    bar_id: i32,\n}\nThere is no way to define #[belongs_to(Bar)]. If you don't specify the foreign key, or explicitly specify foreign_key = \"bar_id\", the macro (surprisingly) does not error, but generates no code. If you specify foreign_key = \"barId\", the macro will complain that field doesn't exist.\nWe need to change the derive to:\n\nNot assume the field name and column name are the same\nDecide whether foreign_key = specifies the field name or column name (probably field name IMO). @ggrochow Sorry that this never got reviewed. Are you still interested in working on this? This change looks fine, it'll just need a changelog entry (and a rebase). You can accomplish this by adding libsqlite3 to your Cargo.toml directly with the features you'd like. We can implement FromSql<MediumInt> for i32, but not ToSql. It'd be similar to the situation with Timestamptz where we allow things like DateTime<Local> in ToSql but not FromSql. I think the situation for MediumInt would be significantly more painful however, since there would be no type which would implement both ToSql and FromSql for it.. The only type left is mediumint which we aren't going to support. Closing this.. You can specify the timeout in the connection URL. https://www.postgresql.org/docs/9.4/static/libpq-connect.html#LIBPQ-CONNSTRING. > isn't documented much\n\nIt's documented at http://docs.diesel.rs/diesel/associations/index.html\n\n(Do you have to treat the participating structs different afterwards?)\n\nNo\n\nis not tested anywhere in the repo\n\nyes it is\n\nhas special annotation syntax \n\nThis is the same as all other derives\n\nHasn't been significantly touched in a while\n\nUnsure why this is something that you have a problem with?\n\nIs there an alternative?\n\nNot using it. All #[has_many] does right now is enable parent_table.inner_join(child_table). If you always join in the reverse direction, or use belonging_to and grouped_by, you don't need it.. Yeah that's completely fine with me. Your error message is good.. I mentioned it in gitter, but your issue is that you're passing the wrong type to get_results. It should be the type you want to deserialize to. We already know the SQL type from the query itself.. I'd be fine with losing precision from avg and friends specifically, but I don't see any way to make that happen without allowing loss of precision for all cases which is not something I'd be willing to accept.. The ISO standard is that any operation on a null value returns null. I'm fine with adding ops for nullable values (preferably as a single blanket impl if possible). Can you run cargo update?. Sorry I did not reply to this in April, this was during my parental leave when I wasn't around much. There's not enough information here to reproduce, so I'm going to close this. If you are able to reproduce this issue on Diesel 0.99 or later, please open a new issue.. It's coming from the glob import on diesel::types::*. diesel::types::ops is not internal, it's public API. we just need a more scoped import.. I don't think you're running into this issue. Diesel doesn't have any types or modules called builder.. I'm a bit torn on what to do here. It's really unfortunate that SQLite requires the type name to be exactly INTEGER in this case. As @Eijebong mentioned, our inference on SQLite is really more just trying to deduce intent, as types are just suggestions more than anything in SQLite. Ultimately I'd prefer not to special case this, as the use cases for SQLite trend towards not needing 64 bit PKs, and you can override manually in the cases where it matters. Ultimately though I think keeping our inference rules simple and consistent here takes priority.. The repo homepage is sgrif/diesel.rs-website. Once all open doc PRs today are merged, we will be able to add #![deny(missing_docs)] to the repo. #1407 (hopefully) addresses the \"I don't know where to find things\" issue (please comment on that PR with your feedback though). I've reviewed every single piece of documentation in the library over the past few weeks to make sure it's up to date (I likely missed a module somewhere, please open an issue if you find anything that is out of date or poorly documented). I'm hoping to publish ~10 more guides before the end of the year.\nI realize not everything is documented as perfectly as it could be. If you have any concrete places where the documentation could be improved (even if it's just \"I couldn't find/figure out X, here's where I looked\") please open an issue.\nHowever, I think we have sufficiently resolved the issue of \"our docs generally suck\" enough to close this.. As you mentioned, the nullable method is intended for this purpose.. You can declare any function you'd like with the sql_function! macro. http://docs.diesel.rs/diesel/macro.sql_function.html. For non-core modules like these, Diesel is designed to be extended by third party crates. I don't think this makes much sense to be in Diesel proper. Functions can be implemented with the sql_function! macro (http://docs.diesel.rs/diesel/macro.sql_function.html). For a proof of concept of how to implement custom operators/types, please see https://github.com/diesel-rs/diesel_full_text_search. You claim that it is Diesel which is slow, but give nothing to use as a baseline for comparison. Writes are much slower than reads in any RBDMS, including PG. I doubt you're seeing anything other than the performance of PG itself. Can you provide more specific details about why you think it is Diesel that is causing the slowdown here?. I've definitely warmed to the idea of marking a field as ignorable for update/insert (to skip a field for update, you can always use my hilarious, hacky workaround for now. I'm not sure I see the use case for skipping something on Queryable though. If you want to populate other data after loading, it seems like it'd make more sense to have another struct that is struct Foo { data_from_database: DbModel, other_data: whatever }. It's not blocked on that PR. It just hasn't been a priority. As I mentioned in https://github.com/diesel-rs/diesel/issues/860#issuecomment-300280659 though, if/when this lands, it'll be for AsChangeset and Insertable, not Queryable.. Can we use the URL crate here instead?. > This simple pull request (which greatly expands subset of connection strings that will now be parsed correctly) has brought every nitpicker out of the woodwork complaining how it is not perfect\nPlease be polite. There is no need to be offended at one additional person reviewing the code. I've been traveling since I left my previous comment, and haven't had a chance to look at the problem more in depth.. > we need to determine exactly what the grammar for Postgres and MySQL connection strings are\nOk let's try to lay this out as explicitly as possible then. A valid connection string that we accept for MySQL or PostgreSQL is a subset of URLs which meet the following requirements:\n\nThe scheme MUST be one of the expected schemes for the adapter (postgres:// or postgresql:// for PG, mysql:// for MySQL).\nThe path MUST have exactly 0 or 1 segments\nThe fragment MUST NOT be present\nThe query MUST either not be present, or be represented as application/x-www-form-urlencoded, where all keys given are additional options expected by that backend\n\nThis means that the definition of how to extract the database name should authoritatively be:\n\nParse the URL\nValidate the scheme\nIf the path length is greater than one, error\nIf the path length is zero, return the default database as determined by the scheme\nOtherwise, return the result of percent_decoding the single path segment\n\n\nI submit that the database C driver code is the final authority.\n\nSince this applies to drivers other than libpq (and even our PG driver won't use libpq forever), I'd prefer to keep our specification separate. That said, I suspect that they will align more often than not.\n\nNote that using URL crate will not solve the problem of being unable to use question mark character in the name of MySQL databases.\n\nWe should be respecting percent encoded question-marks. That is a separate bug, which should have a separate issue opened.\n\nThe full connection spec needs to be met.\n\nNo, we can fix one issue at a time, and open issues for each bug as they come in. My main concern is implementing our own pseudo-url-parser when there's already a crate out there for this.\n\nI tried it and found the URL crate is unable to parse the postgres percent encoded unix domain socket format (postgresql://%2Fvar%2Flib%2Fpostgresql/dbname)\n\nAs best I can tell, that's a bug in the URL crate. Based on the URL spec, that host should be valid since postgresql is not a \"special\" host, meaning that the host should be parsed as an opaque host string, which does not percent decode its input. I'd open an issue against the URL crate. As a workaround, you can use the host query param instead.. I'm going to go ahead and close this. Nobody on the team wants to deal with the rudeness on this PR, and it has merge conflicts that will require additional work from someone. If anyone wants to take this over and work on this without the attitude, feel free as there are still bugs to be addressed.. I'm pretty sure there are other tools that output database schema in graphviz. This really seems out of scope for Diesel though.. LGTM modulo style nits. I'm surprised that this causes issues with incremental compilation specifically. One unfortunate property of infer_schema! is that Rust doesn't know that database changes should trigger a rebuild. Usually that's not a problem, since some code should have changed to trigger a rebuild. I would have expected that incremental compilation was more or less never caching infer_schema! since it's using a procedural macro.\nCan you provide a full set of steps that I can follow to reproduce this issue, where following those steps with incremental compilation turned on causes things to incorrectly compile, but following them with incremental compilation disabled does not? There's not enough information to reproduce/identify the issue here.. Modifying a migration does not change your database. It is expected that you always create a new migration or roll back the migration before modifying it. Everything else you've mentioned falls into what I mentioned above. Cargo doesn't know that your database changed if you had no code changes. It has nothing to do with incremental compilation.\n\nWhy doesn't Diesel work without these NOT NULL statements?\n\nAre you trying to load data into a field that isn't an Option? That would be a mismatch, as the type could contain null. I can't really answer that generally, as Diesel doesn't \"require NOT NULL everywhere\", but we do enforce type safety.\n\nWhy is a completely empty database file created at compilation, if I don't create it by running the diesel command?\n\nSQLite creates the database file if it doesn't exist when you establish a connection. This is regardless of Diesel.\n\nHow can I put the migrations directory into my db directory?\n\nRun diesel --help to see the list of options. The option you need is --migration-directory, though it doesn't work everywhere. There's an open issue for it. You may be interested in embed_migrations! as well.\nI'm going to close this as I don't see any actionable issue here . Yes, percent encoding is 100% the correct thing for us to be doing. I actually assumed the URL crate was already decoding where needed for us. It sounds like that's not the case. Either way, having explicit tests to make sure that this is handled seems valuable.. Also IIRC we've had issues opened before from people unclear that percent encoding was an option. We should try to call it out more loudly in the docs.. This is a reasonable feature, but I'm unsure what I'd like the public API for it to be. If nothing else, #[derive(Insertable)] with no columns should fail to compile, as we're breaking our guarantees about runtime errors.. In general I'd rather not chase the latest versions on these unless we have a specific reason to update, or there's been a Rust release.. Either way this PR more or less coincided with a Rust release, so it's fine. This is basically just a slightly confusing case that only applies when you have exactly 1 column. #[derive(Queryable)] wants all the fields as a tuple, since the overwhelmingly common case is to have more than one field. .select(time) creates a query with the type Timestamp, but your struct is expecting a query of type (Timestamp,). You can do .select((time,)) to get the desired result. It's less than ideal in this case, but I don't think there's a ton of value in special casing the single column queryable case as it's so rare.. Not dumb at all. It's an unfortunately confusing case and I'm always happy to help.. Follow up PR will bring back the errors we want. Ping for review -- AppVeyor failure is unrelated. > I also fear that having joins build up from Join/JoinOn/InternalJoinStuff will make it harder to debug.\nI agree. The goal is to have Join be the canonical thing you target if you need to care about more than one table (in particular, Join<T, excluded, Cross> is a thing I want to target to fix the issue with excluded being allowed in wrong places). I think we mostly have that with this PR, but overlapping marker impls will make it much easier to be sure that's the only impl you need to care about.. Can you ensure that there is only one version of uuid in your Cargo.lock? Diesel 0.12.0 doesn't support UUID 0.5.0 which is likely your problem. https://github.com/diesel-rs/diesel/blob/v0.12.0/diesel/Cargo.toml#L25. Remove the use uuid::Uuid; lines from your table! invocations. That should fix your problem.. Can you give some more context on what you're trying to accomplish? It is not a goal of Diesel to make it easy to write code that is generic over the backend. Even if we provided this function, any place that a query is executed would have to sufficiently prove that the query is valid on all possible backends, which is extremely verbose to write. . It's not impossible, but it's not a use case that we design for. Using Diesel with multiple backends generically can often be quite painful, which is why we usually write separate functions per backend in places like CLI.. I've published 0.12.1 which locks the chrono version. SaveChangesDsl (along with AsChangeset, IntoUpdateTarget, and Identifiable) is implemented on a reference to your struct, not the struct itself. References always implement Copy. If save_changes isn't present, you're probably missing either #[derive(AsChangeset)] or #[derive(Identifiable)]. This needs a compile fail test to assert that using it with SQLite fails.. Yeah this is in preparation for logging. It's slower than the no-op but it should get optimized away if it ever mattered. Either way I'm looking at refactoring QueryFragment to use more traditional AST visitors, which will eliminate the problem.. It's a breaking change, but one that would only affect third party connection adapters, and I'm not aware of any that exist at the moment. I intend for these traits to be public API, but while we're still 0.x I don't think changes to the query builder traits warrant mentions in the changelog or anything.. The solution I've been using in crates.io is to set the connection pool size to 1, but I agree that it'd be nice to make it easier. I do not want to implement Sync on connections, as they are explicitly not thread safe and several of them rely on being guaranteed to not be concurrently used across threads. We'd need a mutex for sure.. I'm about to merge #898 so make sure you rebase and retest before merging. Turned out to not be needed. Some is for use with Rust types. now corresponds to the SQL CURRENT_TIMESTAMP expression. Combining the two doesn't make sense. You probably want now.nullable(). Don't want to reference unstable syntax in the docs, but hypothetically does let where_clause = box if  {... look less weird to you?. Unfortunately, since syn always panics when something fails, there's nothing we can do to improve error messages as a result of giving invalid syntax. I've asked them to look into returning a result in the past (https://github.com/dtolnay/syn/issues/7), but they are uninterested in doing so. I'd open an issue over there if you want to see movement on that front. I'm open to new issues if there's any specific places we can improve the error messages, but I think this can probably be closed at this point.. I'd rather not introduce the log crate or warnings for this. We need to properly return an error here.. > We need to properly return an error here.\nWe cannot accept a PR that simply has TODO: Better error handling. Going to close this, as it's been sitting around for a while. Feel free to re-submit if you're still interested in working on this. However for this to be accepted we'd need to present this error case to the user. Silently treating it as an empty result set is not an acceptable solution.. Reopened against master in #933 . Thanks.. Looking at the generated code from cargo rustc -- -Zunstable-options --pretty=expanded, I can safely say this is not a bug in Diesel. You should open a bug on the Rust language with this reproduction script: https://is.gd/hhcC15. We do add a __Nonexhaustive variant to make sure we can add new ones in the future. https://github.com/diesel-rs/diesel/blob/master/diesel/src/result.rs#L24. I've spent most of the day working on this, and after coming at it from 3 different angles -- I don't think this is a good change.\nBasically the benefits of using error-chain here are:\n\nOur variants that take Box<Error + Send> go into a more general \"chain\" \nBacktrace tracking\n\nThat comes at several costs though:\n\nSignificantly more boilerplate\nContrary to the goals of this PR, I found that the amount of code I had to write to use error-chain was more than the boilerplate it seeks to remove.\nI think we there is a fundamental mismatch between what our errors look like, and what error-chain is designed for. It seems to be best suited for places where you are just trying to glob errors from a bunch of different libraries into 1 enum. We are instead trying to classify our errors based on where they came from. We cannot be more specific than Box<Error> for most variants, since we need to be extensible.\nErrors become painful to construct.\nMost things from chain_error are unusable if an error is already boxed. I don't want FromSql to care that it's getting wrapped in a DeserializationError or ToSql to care that it's getting wrapped in a  SerializationError.\nWe could work around that by adding type Error to those traits, but I don't think that's a net win.\nWe could also work around it by creating a SerializationError type separately, but that type would basically have 1 variant, and now we're just making it hard to access the \"real\" error.\n\n\nPattern matching is way more painful.\nIf nothing else, the fact that it requires importing a type called Error into scope is a problem.\nMore weight is given to our least common errors\nThe variants that were most improved by this were InvalidCString, DeserializationError, SerializationError, and QueryBuilder error. None of those are error types that users will commonly encounter, and if they do they're likely unrecoverable. By far the most common are NotFound, and DatabaseError. For those two types it is very important that we retain ergonomic pattern matching.\n\nUltimately I don't think either of the benefits get us very much. As I mentioned, the places where the \"chain\" is useful are places that are uncommon, and we could achieve the same thing by implementing std::Error::cause (which we should do and I will follow up with a PR for that).\nI think we're also over-estimating the value of the backtrace. Ultimately for our users, the only valuable piece of the backtrace will be where the query was executed. They can easily get that by using error-chain for their application error, which I expect many people do. Having a backtrace that points to where in our deserialization code an error occurred is only useful for the developers of Diesel. This is why Rails, for example, removes all lines that point to library code from exception backtraces by default.\nSo given all of that, I'm going to close this in favor of just implementing Error::cause.. Even though this is on the milestone, it's worth noting that we don't consider this a blocker. After some internal discussion we all agree that we would be able to continue to support the existing functions in the public API (even if deprecated) with whatever we end up with. Since this didn't happen for 0.99, and I don't want to introduce any new deprecations in 1.0, I'm going to move this off the milestone. This will have to wait for at least 1.1 (and be implemented by deprecating the existing API). In theory we could allow this, but it would be more true to the associations API for this to go through the crates table, since that is the primary key both foreign keys are referencing. So this is at least partially a duplicate of the issues for adding through associations, but I'm going to leave this open since this is specific to declaring possible joins.. This was fixed by 5cd4c0c2. As you've mentioned here, this solution can't work, as the OID needs to be found at runtime not compile time. We cannot assume the OID is stable in any way for types that are not core to PG. Querying at startup is one possibility, but I'd prefer something that is lazily done when constructing the query that requires that type. They can't be handled in a static map, since you can connect to more than one database.\nI think that problem needs to be solved first, as a standalone pull request that handles only that problem.. The idea of having a static vs dynamic enum is interesting, but I don't think it pans out to the ToSql case. Ultimately I think the way to go about this is as follows:\n\nAdd a MetadataLookup type to TypeMetadata (set to () for all cases)\nChange the signature of ToSql to take some struct that wraps W instead of W directly (this type implements Write where W: Write. This type would also be generic over DB and have a field of type DB\nChange the signature of HasSqlType::metadata to take a reference to DB::TypeMetadata\nIntroduce an actual metadata lookup type for PG, which wraps a reference to PgConnection (this will almost 100% require doing a mem::transmute to have a &'static PgConnection, which is unfortunate, but until we get ATCs I don't see anyway around that without adding lifetimes to Pg or to TypeMetadata which are places I really don't want to add a lifetime parameter). Also for the record, I'm less concerned about the caching aspect of it, and more concerned about the API. An initial implementation could make the request every time and that's fine. It's easy to add caching later.. I'd prefer to avoid exposing the entire connection object to ToSql, especially since until now it's been entirely concerned about the backend and not the actual underlying connection. Part of that layout is so that we can provide some amount of encapsulation.. > Nice. Let's hope that's enough new internal traits for a while, though ;)\n\nDarn that ruins my plans for a followup PR adding InternalLoadDslInternals. I'd prefer to keep ne, not_like, not_between, etc in cases where there is an explicit operator, since that's what people will be looking for. I even want to keep ne_any even though it's literally not(eq_any, since I think most people think of NOT IN as a single operator and not as NOT(IN(...))\nWhile not(foo.like(bar)) may generate the same query plan as foo.not_like(bar), they are not equivalent in terms of ease of discoverability or matching peoples expectations.. > we need to remember to update diesel_full_text_search though.\nAlready have -- waiting to merge this to push so I can point it at git instead of a path dependency. No, becuase QueryFragment<DB>: QueryFragment<Debug> means that QueryFragment<Debug>: QueryFragment<Debug> which is cyclic. Fixed by #1051 . It's probably worth adding some simple doctests to demonstrate its usage. Our associations API is documented here. If you want to get all of the schools which have a bank account, just join between the two tables. . It's a bit of a quirky interaction between those two features, but yeah it's by design. I don't think that specifically passing an upsert with do_nothing to insert should change the return type of get_result, as that's a really non-local change. You should call .optional here if you want a QueryResult<Option<User>> as per the docs. Unfortunately, this isn't going to happen in the near future. If we can add this backwards compatibly once generic associated types land, we will revisit it then. Right now though, I'm clearing out any issues that require breaking changes or new language features, as they're not actionable at this point in time.. Should this wait until after #1080 ?. Sorry that was Ruby. Let's keep the feature focused. The use case we want to support here is renames, we don't need to complicate things by adding a bunch of other information that Diesel does not care about (and likely never will).\nI'm more in favor of using attributes for this, but want to make sure the naming makes it very clear what is the Rust side and what is the SQL side.\nrust\ntable! {\n    users {\n        id -> Integer,\n        #[database_name=\"username\"]\n        name -> Text\n    }\n}\nI'd also like to see a concrete proposal for the conventional renames for Rust keywords.. I'd rather not establish a convention for column names containing only numbers (or any other column which is not valid as an unquoted identifier in SQL). Why should we special case numbers but not spaces? Or other characters that aren't valid identifiers? We would have to conventionally handle any arbitrary sequence of characters. infer_schema! does not need to handle absolutely every possible edge case, as long as we provide the tools for users to make it work on their own. Providing renames does that.\nThat said, the issue with Rust keywords (notably type) is incredibly common, and a frequent source of friction that does warrant special casing.\n\nI have no idea how many of those are not valid identifiers in Rust\n\nHave you tried throwing infer_schema! at it? I'd be interested to hear how many of these cases you have. > There is no point in users doing it at all.\nI agree, which is why the overwhelming majority of the time, you won't see column names that aren't valid SQL identifiers.\nI don't see the value of adding a convention for breaking convention, especially one that's so uncommon.. I'm not claiming that they don't exist, I'm saying that they're not common enough to warrant any sort of convention for automatically renaming them, especially since columns that are invalid SQL identifiers are by definition breaking convention. The issue is already going to be exposed to the user when they have to figure out what we renamed their column to.\nAnyway we're not getting anywhere by debating that further. I think you've made your position very clear. What I'd like to move forward with for the time being is an annotation to allow renames (something like database_column_name sounds good I think), and then a separate PR that introduces the conventional column renames for Rust keywords. I'm not sold on column_ as a prefix, but we can discuss that in the PR.. @Measter It is possible, but I do not like that syntax. Which side is the rust side? Which is the SQL side? I'd strongly prefer something that uses an attribute (for consistency with Rust's syntax), and makes it clear in the name which side is which.. Agreed. Can you open a new issue for renaming table names?. Thanks for confirming. :heart:. \ud83d\udc4d on turning it into an issue template IMO. While I'm happy to provide assistance for anyone looking to implement this, it's not a type that I want to support in the main Diesel crate. Diesel's design is meant to allow for third party crates to add extension types such as this one. Feel free to comment on this issue with questions or discussion of implementation, but I'm going to close it as it's not a feature that I'd like to add to the main crate.. We already did that. We should have an impl for nullable columns.. This is semi-related to a feature we've discussed in the past, which is having a Rust DSL for migrations. If we do end up adding a secondary migration format, it'll almost certainly be that form and not JSON or YAML. At the moment this feature doesn't seem to add a lot of value. Database backends have tools for dumping their schema if you just want to generate a migration for an existing database. Being able to easily swap out backends is not a main goal of Diesel.. Reverting since this broke Appveyor.. This sounds like a bug in cargo or rustc. That function prints to stdout as you mentioned, which should be getting captured.. We don't support columns which have the same name as keywords in Rust (type being the most common case). You'll need to rename the column, or use the table! macro manually (you can generate it with diesel infer-schema) and omit that column.. This isn't a feature that we're currently looking to support. You could make this work using the sql function.. Added it to the changelog entry while rebasing.. Based on the value of the metadata table I mentioned previously. diesel update wouldn't modify this file. It would generate a new migration that has all of the changes between \"current metadata version entry\" and \"version of diesel_cli being run\". I'm not sure I understand what you're asking. We would set up a file that is \"here's how to migrate from version 1 to version 2\". If we read the table and see that the version is less than 2 (or the table doesn't exist), we will generate a migration with that file. We'd change the file that is generated for new projects to already have those changes in the initial migration.. Only for new projects. We cannot modify this file for existing projects.. @killercup I'm going to hold off on merging this until you've had a chance to review since you had some strong opinions about this change.. > The workflow cockroach will be to run diesel setup, and empty out the file, right?\nPretty much. I'm hesitant to actually call out a specific workflow for that case, since we don't \"officially\" support it. But yes, that is what I intend for those folks.. By default diesel_cli compiles with support for all supported backends. It looks like you don't have mysql installed on your machine. If you'd like to install with just support for one backend, you can do cargo install diesel_cli --no-default-features --features \"postgres\". Can you remove all the enum stuff from this PR? I'd like to focus only on the runtime lookup of OIDs for now. So this strays pretty far from what I'd laid out in https://github.com/diesel-rs/diesel/pull/940#issuecomment-307481087. There's a lot of other issues, the biggest of which being that it doesn't compile, and has no tests. I decided that it'd be less work to just finish up the branch I had for this rather than work on cleaning this PR up. Closing in favor of #996 . /cc @weiznich . We need to make this fail to compile. We don't support the PG tuple type (and even if we did, it wouldn't map to a Rust tuple).\nWe should probably figure out a way to have all of the expression methods omitted from tuples.. Also since you're probably looking for a workaround for what you're trying to do:\nrust\nuse diesel::expression::grouped::Grouped;\nlet query = diesel::delete(subs::table.filter(Grouped((user_id, show_id)).eq_any(\n        users::table.inner_join((subs::table).inner_join(shows::table))\n            .select((user_id, show_id))\n            .filter(id.eq(test_user_id).and(title.eq(test_title))))\n    ));\nGrouped is internal, and that code may stop working in the future, but that will at least give you what you need for now. The way that I'd probably want to write that is:\nrust\nlet target = subs::table\n    .filter(subs::user_id.eq(test_user_id))\n    .filter(exists(shows::table.filter(shows::title.eq(test_title).and(shows::id.eq(subs::show_id)))\nbut that will fail to compile at the moment (supporting subselects which reference the outer table is something we're looking to fix). FYI the workaround I gave you will no longer work in the next release. I'd do this instead (and this is probably just the best way to write the query regardless):\nrust\nlet shows_with_title = shows::table\n    .select(shows::id)\n    .filter(shows::title.eq(test_title));\nlet target = subs::table\n    .filter(subs::user_id.eq(test_user_id))\n    .filter(subs::show_id.eq_any(shows_with_title));\nlet query = diesel::delete(target);\nThe SQL will be:\nSQL\nDELETE FROM subs\n  WHERE subs.user_id = $1\n    AND subs.show_id IN (\n      SELECT shows.id FROM shows WHERE shows.title = $2\n    )\nwhich should be significantly more efficient than what you were trying to write originally. I think this is one of the bigger 1.0 blockers. I can figure this out if needed, but if there's someone with more experience in this space we would love a PR for this. @skade Are you using https://github.com/sgrif/heroku-buildpack-diesel ? If so just add a .diesel-version file to the root of your repo and the CLI build will be cached.. This isn't happening for 1.0. This will have the same caveats as varchar when it comes to arrays.\n\n\nOther than that this should be fine. The binary representation is identical to text.. No, this isn't something anybody on the team is actively working on -- We'll be publishing a new policy soon about what we're doing with the issue tracker, but we're moving towards issues open here either being on the team's roadmap or things that are good for new contributors. If you'd like to discuss implementing this feature, you can start a thread at https://discourse.diesel.rs. @Boscop Because the support we had was broken, and requires a more complete solution. We only accepted it in the first place because it was initially thought that a type alias would be sufficient. In general we don't support extensions in Diesel proper, since they can easily live in third party crates. Supporting this type is no different than supporting any other custom type as I've mentioned in https://github.com/diesel-rs/diesel/issues/1624#issuecomment-379541186. If you're interested in supporting a crate for this and have questions after taking a swing at it feel free to ask in Gitter. It does make sense, yes. So how do I get one of these. You can use sql_function! or no_arg_sql_function! for this. Generally we want to avoid exporting every possible function in SQL from Diesel, since it's trivial to declare the ones that you want. . Relevant for anyone outside the core team who may be interested in reviewing this: I'm planning on writing a guide around extending the query builder using this code as the final goal. I'm feeling pretty good about the level of abstraction in that code (maybe not specifically for pagination, but it felt like a good self-contained example. And there will always be use cases that need to drop down to this level). However, AstPass needs to be documented for that guide (and specifically reborrow feels off to me if it's part of our public API. Unfortunately there's no good place that reborrowing for the language is documented that I can link to). LAST_INSERT_ID has many gotchas that I'm not comfortable implicitly relying on. If you'd like to use LAST_INSERT_ID, you can very easily do so with the sql_function! macro.. LGTM. @agersant I think you're just running into a quirky (but intentional) edge case. #[derive(Queryable)] does not special case single-field structs. If you are manually calling select, you'll need to pass it a tuple (so .select((id,)). Is this an issue that occurs without a manual call to select?. I think that would be a strong candidate for something that should best live as a third party crate, not as part of Diesel itself. However, I'm happy to assist someone in implementing such a crate.. It shouldn't need to. The impls should all be able to look something like:\n```rust\npub struct UserId(pub i32);\nimpl ToSql for UserId\nwhere\n    i32: ToSql,\n{\n    fn to_sql(...) {\n        self.0.to_sql(...)\n    }\n}\n```. @Eijebong This isn't implementing a new SQL type. However, even if it were it could still be trivially delegated.\n```rust\npub struct MyIntegerType;\nimpl HasSqlType for DB\nwhere\n    DB: TypeMetadata + HasSqlType,\n{\n    fn metadata() -> DB::TypeMetadata {\n        >::metadata()\n    }\n}\n```. > I've only been using it for about an hour, and before this I hadn't actually tried sticking my newtypes into the DB via Diesel, so there are probably unknown unknowns\nLol I'd probably start with trying that out. ;). > Doesn't try to handle generics at all. I haven't encountered generics on newtypes so I didn't bother. They should be easy to add\nThis seems reasonable to me.. > It seems almost... too... easy...\nThat's the goal. ;). I've only given it a cursory look, but it looks fine at first glance. You're missing a lot of impls that are required to use the newtype in every context you could use String. Particularly, you'll need AsExpression impls for every combination of nullable/not and reference/not, along with FromSqlRow for nullable/not. You'll want a Queryable impl as well so they can query for the newtype directly. These are the impls that we have for our primitive types. You'll want to verify against an actual database. Anything else will only be testing your assumptions.. You'd need to create a custom domain type in PG to do what you're describing.. Closing as there's nothing actionable here. See https://github.com/diesel-rs/diesel/issues/595#issuecomment-352208313 for more thoughts, and #162 for the tracking issue on ergonomics here.. Looks like something went wrong with the rebase (or with Github), this is showing all of #996 as part of this PR's changed files.. r? @Eijebong . Unless I'm missing something, you're missing AsExpression impls.. That change is pretty much exactly what I want. There's really no need to overthink it (we should probably have a test that diesel setup followed by diesel migration run has no output lines with \"Running migration\") to make sure that a future change to the versioning doesn't break this). There are a lot of deeper issues here which warrant discussion, but the short answer is that yes I would accept a pull request which provides an option to globally disable prepared statement caching.. So just to address a few of the specific points here:\n\nThe first issue I have is that using named prepared statements causes PG to cache generic query plans. \n\nThis actually isn't true at all. Generally query planning occurs when the bind parameters are initially passed in. Postgres may decide to cache a generic plan, but it will only do so for queries which are frequently executed, and when the generic plan is determined to be roughly as efficient as the plan created with specific values. I'd be surprised if generic plans were being cached in the cases that you've described. Then again, you also sound like you've specifically isolated the issue so \u00af\\_(\u30c4)_/\u00af\n\nThe second problem is the change in #686 from using the single statement PQexecParams to PQprepare and PQexecPrepared breaks the ability to use an external connection pool like pgbouncer in \"transaction pooling\" mode.\n\nCan you elaborate on this for me? The only difference between using PQexecParams and what we're doing now is that one additional Sync message is sent between the Parse and Bind/Execute messages. The only way that could cause an issue is if the connection is returned to the pool in between those two round trips, which should not occur even in statement pooling mode. It certainly should not occur in transaction pooling mode, since the connection is held for the entire transaction.\nUnrelated to the problem you're describing there, I am generally interested in seeing if we can generate deterministic statement names so that they actually can be shared when using pg bouncer (this would require graceful re-preparing behavior since we can no longer guarantee that a statement being in our cache means that it's been prepared on the real connection). Since there isn't any activity on this issue, and there are no actionable items for us to take at this time, I'm going to close this issue.. This is the expected behavior. The module needs to be in scope. You generally shouldn't import stuff from dsl outside of functions. I agree that we need to make this more clear in the documentation. I'm not sure how we can improve the error message other than a lint. \n\nI find it confusing that diesel needs very tight hygienic control of the surrounding namespace or otherwise falls flat on its nose.\n\nI don't see any way that we could work around this, unless we enforce the exact location of the table module from the crate root, which isn't something I want to do.. Immediately found code which validates my concerns in crates.io. Approximately this:\n```rust\nuse schema::versions;\n[derive(Identifiable)] // <--- This requires schema::versions be in scope for the module\npub struct Version {\n    // ...\n}\nimpl Version {\n    //       v---- This variable name will always error if schema::versions is in scope for the module\n    fn max(versions: Vec) -> Self {\n        // This function does not do anything Diesel related\n    }\n}\n```\nIf we made this change, I'd probably end up fixing our test suite by either limiting the imports we do from schema or always importing them at the function level instead of the module level. The problem is, we have code that enforces that you do the import at the module level. With this change, you could no longer use a variable with the same name as the table anywhere in the file, even though it's often the most convenient variable name for a collection in functions which have nothing to do with Diesel.. Yeah so I think this is pretty much dead unless we're ok with this change as is. I explored if we could have all our derives which take the table name take a path instead, and it's basically impossible unless we change Rust to allow a path fragment to be followed by ::. We don't bump the patch versions of something when nothing has changed. We'll only do that for major/minor versions.. You aren't meant to ever reference these types correctly. You should use the types in http://docs.diesel.rs/diesel/helper_types/index.html. We should probably add helper types for InnerJoin and LeftOuterJoin. Can you amend the commit message to note that this is for group by not join?. Releasing now. Thanks.. Can you add a changelog entry?. Yeah so as @killercup mentioned, I don't think this is a feature that's appropriate for Diesel itself. I'm happy to help you get it set up as a third party crate though. I thought I had mentioned this before, but I can't find it on the issue tracker so it must have been in gitter or I just never mentioned it. Sorry if I haven't made this clear before now.\nIn general, I think this code should be broken up differently. I think a simpler starting point would be #[derive(PgEnum)], which you place on enums defined in your code. infer_enums! could be built on top of that pretty easily (though I'm not really sure that this needs a macro to infer it. The number of enum types in an application are going to be pretty small compared to the number of tables).. /cc @rubdos . The representation I get for SELECT '10000.16'::numeric is Positive { weight: 1, scale: 2, digits: [1, 0, 1600] }. The value we're sending is Positive { weight: 0, scale: 2, digits: [10000, 1600] }. The fix is relatively trivial. Just improving our test coverage and making sure this doesn't affect numbers after the decimal point as well. I'm not sure I see much value in doing this over specifying the schema in the table! call, and just glob-importing that module where needed. Can someone elaborate more on the use case?. /cc @rubdos . I've updated this to include the API we've discussed. debug_sql is now debug_query which returns a type that implements Display and Debug. The display implementation will be the SQL query with the binds as a comment. The Debug impl pretends it's a struct called Query, which contains the SQL and the binds as fields.\nI chose to keep it as a bare function instead of a method on the queries because the function is easier to discover in the docs.. I'll start using that style for future guides. I don't think it's worth the time to convert this one though.. I'll address the feedback on this as I move it to the website.. @corwinharrell WDYT?. I just realized this is on the main Diesel repo. Can you please open an issue on the website's repo? https://github.com/sgrif/diesel.rs-website. My concerns with this PR are the same as the last time it has been brought up. Has anything changed to address these?\n\nIt's harder to test\nWe can no longer test the behavior of the derived code inline, it has to go into the integration testing crate, which makes things harder to isolate and makes feedback cycles longer\nWe need to improve our test coverage\nThe last two PRs which did this both introduced regressions. I'm not comfortable accepting a complete rewrite of this code unless we improve our test coverage first\nWe lose a convenient place to document things\nFor some of the derives we can document options for the derive on that trait, but that is not the case here. It was nice to have this as a place we could link to in rustdoc that was isolated.\nCircular dependencies have complicated our build process\nThe fact that Diesel now needs diesel_codegen has significantly complicated the release process, and has made running bin/test recompile the same crate multiple times, slowing feedback cycles.\nIt's not in service of anything specific\nI'm not against having refactorings in general, but we're right in the middle of a push to 1.0. This doesn't feel like the right time to accept rewrites of this scope.. > As stated in the Gitter discussion, this code was originally written to experiment with joining a table multiple times.\n\nI'm not clear on how this makes that any easier? Joining to a table multiple times is something that will require more than just changes to internal code. We would need to introduce a public API for controlling table aliasing, which is currently out of scope for 1.0. Otherwise any time you reference a column from a table it would be ambiguous which instance of the table you're trying to reference.\n\nThe circular dependency is already introduced, so this should not affect this decision.\n\nIt is something I would like to eventually remove.\n\nIf diesel 1.0 is released with the current macro based approach this means those macros are part of the stable api. Therefore it will not be possible to remove them without releasing version 2.0 of diesel.\n\nThat is a good point. I think we need to discuss whether we want that to happen or not, and what we should do if not.. I understand. In general I don't think that's going to be a good solution. If you have two belongs_to with different foreign keys on the same table, then we don't know which one you meant when you say parent.inner_join(child). I think part of how we solve that is by separating join code from #[belongs_to], which would solve some of your use cases. It would also let you have self-referential associations as long as you aren't trying to write a join.\nI've actually been warming up to the idea of inferring joinable! from foreign keys. If we were to do that we'd need to warn when two constraints would conflict. One other benefit of doing that is infer_schema! and diesel_print_schema! could then also generate enable_multi_table_joins! for every combination of tables (the last part might not actually be desirable). @weiznich If it's ok with you, I'd like to defer this change until after 1.0. We're not planning on doing another release until 1.0, and I'd really like to avoid rewriting a major part of the framework in that release. I do think we can continue to improve the test coverage around codegen until then though. @weiznich I think we're good to start working on these (one at a time please don't flood us with review requests \ud83d\ude04 ). However, I'm going to close this PR since the entire thing basically needs to be rewritten and the discussion on this PR isn't relevant to the actual code being merged.. Note that the new PG driver will do URL parsing on our end when it ships, so we will eventually be able to have the behavior of all of these conform to the same thing. The behavior I'm trying to target is roughly \"the behavior of libpq, but following the URI standard whenever those two differ\". So basically:\n\nThe URL is treated as scheme://username:password@host/database_name\nscheme must be one of mysql, postgres, postgresql\nUsername will default to the username executing the current process if not specified\nAny available query params will be backend specific, but we will mostly only allow them for things like SSL behavior, which will follow the parameter names of libpq. I'd like us to test that these are actually generating the code we expect. We should execute the queries and expect to see some data back.. The only test I can see which executes a query involving a foreign_key option is the test for self referencing associations.. We need to provide some tests for this behavior, even if it's not testing the actual results of executing the query. I'd like to at least test that foreign_key is doing the right thing, and probably a test like:\n\nrust\nassert_eq!(\n    debug_sql(Foo::belonging_to(&bar)),\n    debug_sql(foos.filter(bar_id.eq(bar.id))),\n);. You can use connection.execute to set the pragma. https://sqlite.org/pragma.html#pragma_busy_timeout. Your names are backwards FYI. You're trying to go grandchild -> child -> parent. The code and error should be identical. Just your naming is wrong. What you're calling Parent should be called GrandChild. Changing the names wouldn't change the error.. Don't thank me yet. I have a lot more work to do to get rid of the fallout from that change.. I don't really have a strong feeling for or against forcing it, but we should make sure everything on the domain actually works with HTTPS first.. :+1: from me then. . I've been making it a point to ensure as little assumes protocol as possible. So if you're using https, you should stay in https. However, right now our SSL support is implemented by basically having Cloudflare do a giant MITM attack on us. Until we have \"proper\" SSL support (which is unlikely to happen until github pages supports it for custom domains), I don't think it makes much sense to force its usage.. Meaningful advice \"If you want to change the primary key of a row, you should do so with .set(table::id.eq(new_id)). AsChangeset never changes the primary key of a row.\". Can we add a test as well? Doesn't need to specify the error message beyond maybe \"is not supported\". > Should we add something to the changelog to explain what kind of relations will not get inferred.\nI think it should be documented, but the changelog is not the place to do it. Maybe in the docs for joinable! itself? (with links in the docs for infer_schema! and diesel print-schema). It's due to how we're doing whitelisting. I'm going to roll this into another PR which rewrites print-schema. I don't like real_name as the attribute name, but we can change that later LGTM (I do need to refactor the $doc stuff though. :). No, we do not currently support DO UPDATE ... WHERE. I think I should clarify what the intended role of Diesel's migrations are here. The term \"structural\" vs \"data\" migrations has been thrown around, which is fine. Diesel's migrations are really only meant for \"structural\" migrations. Things like UPDATE should only be getting run if it's in service of some structure change (e.g. denormalization) and can be reversed. If it's just \"oops all values in this column should be lowercased\", Diesel migrations are a poor tool.\nHowever, that distinction has little to do with the issue that seems to be at hand here, which is zero downtime deploys. For backwards compatible changes (adding tables or columns), there's not much to do here. You run your migrations, then you deploy code. For destructive changes, the process with Diesel is the same as anything else:\n\nDeploy code which works with both the new and old schema\nDeploy the schema change\nDeploy code which only works with the new schema\n\nHowever, it sounds like you're also asking about things like how to deploy migrations which would require a significant amount of down time. I think that is something which is out of scope for Diesel. There are existing tools (e.g. https://github.com/shopify/lhm) which handle this. Perhaps one will be written in Rust eventually, but I don't think the language that tools like that are written in is relevant here.. @juliusdelta Go ahead. I don't think it makes sense for Diesel to arbitrarily retry anything by default, but I'd be fine with adding a RetryTransaction error variant. If nothing else we should potentially change transaction to take a FnMut as a defensive measure so we can change this later.. Update on this: We didn't change the signature of transaction to take FnMut, so if we want to implement something that does retries, it will need to be a separate method.. @Diggsey It is completely valid to return false from has_broken. is_valid will prevent the broken connection from being reused.. @diesel-rs/core We need to make a decision on our policy for Rust versions. RFC #1105 does not explicitly state whether increasing the minimum required Rust version is considered a major breaking change or not. I think we need to explicitly decide whether we are allowed to increase our minimum required Rust version or not without a major version bump.\nMy vote is that yes, we should be allowed to increase our minimum supported Rust version in minor versions (but not patch versions). Updating to a new stable version should never be difficult. Future enhancements like specialization, overlapping marker traits, and generic associated types will make new features in Diesel possible, and we should be able to take advantage of that.. Fixed by #1714. To be clear, sql_function! should not need to be affected by this at all. This would only require an API which exposes sqlite3_create_function in some form. I suspect whatever we come up with will end up requiring an additional call to sql_function! to be used with the query builder.. We also need to consider safety here. Unlike other databases, a custom SQL function in SQLite is tied to the connection, not the database itself. This means that we should ideally enforce that custom SQL functions are always declared.\nProbably the best way we could do this by providing an API where you give us all your custom functions, and we give you a function that has the signature (SqliteConnection) -> YourCustomConnection. I don't know that we can reasonably do this though, since we've had 2 years of encouraging people to write functions like fn do_stuff(conn: &SqliteConnection) not fn do_stuff<C: Connection<Backend = Sqlite>>(conn: &C).\nI suspect the best we can do is set this up so people define all their SQL functions in one place, we give them a function that takes &mut SqliteConnection, and document \"hey if you want to use these, you better make sure you called this function on your connection\". There's no reason to use r2d2 with SQLite. \"Connections\" don't have any actual cost associated with them like they would for a database with a server.. Fixed by #1691 . Update: https://github.com/diesel-rs/diesel/commit/73778af0 was very much in service of this eventual feature. Any version of this that lands will require explicitly listing the columns. e.g. We will not support INSERT INTO table SELECT ... but we will support INSERT INTO table (col1, col2) SELECT ....\nI would love to see ideas on concrete API proposals for this. Right now the best I've got is:\nrust\ninsert_into(table1)\n    .from_select(\n        (col1, col2, col3),\n        table2.select(...).etc,\n    )\nI think we can do better though. In particular, I don't like the amount of rightward drift there. It reminds me very much of our old on_conflict function from 0.16, which we deprecated in 0.99 for the same ergonomic reasons. I think I'm going to go with this API:\ninsert_into(table1)\n    .from_select(table2.select(...))\n    .into_columns((col1, col2, col3))\nThe order is backwards from what you'd write in SQL, but it lets us default to table1::all_columns, and any method that allowed you to specify the columns doesn't make sense unless you know that you're inserting from a select statement.. So I prototyped this out, and found that the select statement generally was so long we had the same rightward drift problem. You can work around it by sticking stuff in locals, but then the variable is awkward to name and really \"you can work around this crappy API\" doesn't make it acceptable. @weiznich had a really good idea in the gitter room though. select_statement.insert_into(table).columns(col_list), which is even more backwards from the SQL, but definitely lets you insert line breaks where it's natural. TBH this is also pretty close to how I read these queries anyway, since the select statement is by far the most important part.\nI'm going to play around with it some more, but I think I want to go with that API. The main issue will be making it discoverable. It'll have to end up being a trait that's implemented on BoxedSelectStatement, SelectStatement, and Table rather than an inherent method on IncompleteInsertStatement. I suppose linking to it from the docs, and adding a section to the insert guide will probably be sufficient.. I ended up generalizing the API. The only API that is being explicitly added for this feature is the into_columns method, which only works for insert from select. Otherwise, passing a select statement to values will now \"just work\", and any query that can be written as insert_into(table).values(values) can instead be written as values.insert_into(table). This behavior should be mentioned in the docs for infer_schema!. I don't think we need to make a macro for this.. If nothing else, we should fix the behavior in diesel print-schema. I haven't been able to reproduce the issue. Since diesel print-schema is the recommended usage, which does support blacklisting, I don't think there's a major need to add it to infer_schema! which is mainly intended for use while prototyping. If someone can provide steps to reproduce a bug in the blacklisting behavior of diesel print-schema, please open a new issue with full steps to reproduce, including a migration file to set up the schema in question.. This has been raised before, and we decided to keep things as they are for reasons I laid out in https://github.com/diesel-rs/diesel/issues/852#issuecomment-315755841. If you need i64 keys, you can use table! or diesel print-schema and specify that the id column is of type BigInt there, but I don't think we should change the behavior of schema inference for the reasons I laid out in the previous comment.. I'm not sure what you're asking for? You can provide bind parameters to a query using the .bind. All queries are performed as prepared statements, regardless of backend.. Sorry I haven't had my coffee yet I thought this was an issue not a PR. >_>. Closing due to inactivity. Feel free to open a new PR if you're interested in continuing to work on this. For this to be merged, I'd like to see the URL crate used rather than manual parsing.. Feel free to open a PR. We should open a PR to the URL crate to fix the percent encoded case as well.. The main question isn't whether the connection is useable, but whether the statement itself is useable. I suspect we need to remove that statement from the cache if an error occurs here.. This no longer panics as of 1.0.0-rc1. I still have concerns about whether the statement cache is poisoned by this case or not. If anyone is able to create a repro script that shows a poisoned prepared statement from this, I would appreciate an issue report.. Could you rebase this onto #1122 instead of master? <3. To clarify, specifically I think we should be checking for the URL starting with mysql://, postgres:// or postgresql:// when those features are not enabled. I think we can safely assume that the user is not trying to connect to a SQLite database in that case.. Related: We should strip sqlite:// from the URL if it's present. I've had a couple people try that expecting it to work.. The reason the impl isn't there is that not all boxed queries are valid delete statements. If any clause is present other than the where clause, it would result in an error. However, now that we have filter on Update and DeleteStatement directly, I'd be fine with a separate BoxedDeleteStatement and BoxedUpdateStatement (or even just boxing the where clause on those by default -- there's not a huge drawback to doing so). I actually think boxing the where clauses by default would have been the right way to go. Unfortunately, we can't change that now that we're post-1.0. I'm definitely interested in having BoxedUpdateStatement and BoxedDeleteStatement though. The API surface on those is relatively small. I don't think we need to support upsert for boxed update statements (unless it's easy to add support). Boxed update statements should box the values as well as the where clause.\nI'm happy to mentor someone interested in working on this. It'll be a decent sized patch, but it's pretty straightforward once you understand the basics of our codebase, and BoxedSelectStatement is a perfect reference for this, as the implementation will be quite similar.. @ivanovaleksey I appreciate the offer, but this has already been mostly implemented (support for delete statements is merged, I have a branch with support for update statements that I need to clean up one last thing on before pushing up). Fixed by #1137. There's nothing else we can do here. chrono doesn't support dates with a day or month of 0. There is no non-error type we can return with chrono. You can either turn on the NO_ZERO_DATE SQL mode (in which case they will be converted to NULL, and you should ensure that the column is nullable to avoid errors), or you can load them into a type other than one from chrono which supports zero dates (the only such type I'm aware of is MYSQL_TIME. Or option C: Use PG. \ud83d\ude09 . The PG answer was a joke. :wink:. The only thing that is a hard requirement for Diesel is support for savepoints.. Yes. Technically we only require it if you call transaction while already inside a transaction, so if you never do that it should be fine. That said, Diesel may open a transaction for certain methods (AFAIK we don't do this for PG currently, and I don't know that we'd ever really have a reason to, but who knows).\nI guess the only other thing is modifying schema in a transaction. The reason that requirement exists is because we run migrations in a transaction. Again though, it's not a hard requirement, since using Diesel CLI to maintain your schema is not a requirement for using Diesel or the other features of Diesel CLI\nFWIW MySQL just implicitly commits the transaction if you try to modify schema. I hate that behavior with a burning passion, but it may work as a shorter term solution.. :+1: for using associated constants for those 3 cases. We don't have control over the error message, but we do call this out in the getting started guide. We should make that same call out in the docs for load. Tests pass locally for me as well. I'm going to try merging this and see what happens on master.. The reason this fails on CI but not locally is that this PR only changed NaiveDateTime, not NaiveDate. On my machine (and presumably yours), CAST('0000-0-0' AS DATE) returns NULL, so it's erroring before it gets to the deserialization code. On Travis it's using a different MySQL version which is parsing that string.. No, I fixed it in 347cd24. Diesel CLI and Infer Schema should also use this in the places they currently fail to compile when built with 0 features. . The table_name(foo) was really only a thing with impl_Identifiable! which is essentially deprecated. AFAIK there is nothing that takes table_name(foo) when using diesel_codegen, so I think this is the right fix.. group_by is not part of our public API. It has no expected behavior. https://github.com/diesel-rs/diesel/blob/ceed4c15b375746ed1b334e0d0ee3f8013ac09bf/diesel_tests/tests/group_by.rs#L5-L7. I'm actually wondering if we should just remove clippy from bin/test as it increases build times quite a bit. I don't think linting the tests extensively adds nearly as much value. If we removed it from bin/test I would say that we should not lint tests on CI either. Only lint the main code, which is what CI does currently.. Given that it's test code, I don't think that's a huge loss. I guess it's a question of whether people are running bin/test or bin/check more.. I was hoping to leave this for a new contributor, but thanks for fixing this. :). You're missing use diesel::NotFound. Thank you for the PR. However, this takes several steps that I'm not comfortable with right now. I would strongly prefer that Diesel does not know or care about the default values of columns for the time being (this is something that we could potentially revisit after 1.0, but it has major compatibility concerns that I don't want to commit to for 1.0 stability).\nI'd also want to see a more compelling justification for doing batch insert on SQLite in a single query. We already support batch insert by doing one query per row. While this would be a performance concern on other backends, it is not a concern for SQLite, as there is no round trip time.. You're comparing apples to oranges. One is atomic, the other is not. If you wrap your benchmark in a transaction, the performance is virtually identical between 100 separate queries and 1 query. https://github.com/diesel-rs/diesel/issues/1177. Tests were green, I had just forgotten to run rustfmt on it. Going to mark the failing test as #[should_panic], as its solution is the same as the other 2 mentioned in the PR description (the issue is that we're currently generating VALUES (('foo'), ('bar')) which is valid with most expressions, but invalid with DEFAULT.). @diesel-rs/contributors WDYT?. Should we skip generating the DSL module here too? (Otherwise that error message will still appear). ```rust\nlet case_1 = chat_id.eq(1).and(position.eq_any(vec![1, 2, 3]));\nlet case_2 = chat_id.eq(2).and(position.eq_any(vec![3, 4, 5]));\nlet case_3 = chat_id.eq(3).and(position.eq_any(vec![6, 7, 8]));\nmessages.filter(case_1.or(case_2).or(case_3))\n```. You'll need to box it in that case. http://docs.diesel.rs/diesel/expression/trait.BoxableExpression.html. IIRC I was just straight up incorrect in #912, and we just need a PR that updates the code to not conflict with the latest master. Adding this to the milestone. The solution is literally just rebasing an old PR. The longer we wait, the harder that will be.. IDK why @diesel-rs/reviewers isn't showing up in the list I can request code review from... Maybe I have to ping it to convince GH that it exists.\nAlso FYI, the stats on this are huge, but the PR is actually quite small. The vast majority of the changes are churn from changing all examples/tests to use the new API. A-ha! I figured it out. I actually think this might potentially improve the error messages, but I'll have to play with it more. Is there anything in particular you had in mind for a compile-fail test that isn't already covered by the existing tests?. Yup. If you'd like I can add you to the github group which gets pinged for code review. @ecasilla You can ask questions either in the public gitter or as comments on the PRs you're trying to review (feel free to ask questions after things have been closed/merged as well). @retep007 I've added you to the team -- You'll get pinged on future PRs, but feel free to review any of the open PRs in the mean time. There's quite a few open right now.. (Note: Everyone who's replied to this has been added shortly after replying, I'm only singling that person out because there happens to have been an extremely high volume of PRs opened in the past 24 hours and I assumed the were around right now). I should also mention -- If anyone tries to review a PR, and feels like they don't understand enough to properly review it, please ask questions on the PR. We don't mind explaining things that aren't clear, and hearing what needs more context before the PR is opened is extremely helpful.. Hey folks, just a heads up, I did some cleanup tonight. Anyone who hasn't commented on an issue in the past month will have been removed. If you'd like to be re-added, please comment again on this issue.. Can you confirm that you installed diesel_cli with PG support enabled? (Either by doing cargo install diesel_cli or cargo install diesel_cli --no-default-features --features \"postgres\"). It should work fine if compiled with both SQLite and PG support.. Unfortunately I'm unable to reproduce. Does your username or password contain any special characters?. Can you provide the output ofotool -L $(which diesel)or the equivalent command on your OS to show the shared libraries used in thedieselbinary?. Also just to confirm, you're seeing this error message when using *exactly* the URLpostgres://myuser:mypassword@localhost/mydb?. One other thing you could try is changing the scheme topostgresql` -- The short form was only recognized by libpq shipped with PG 9.2 and later (though if you're using an earlier version of libpq than that you'll likely have other issues).\nI suspect that you're loading some older versions of libpq (possibly system libraries), and need to set your LD_LIBRARY_PATH before running it. No problem. No. A struct with 2 fields will have the same in memory representation as passing the args separately (more or less). This looks great! This will be perfect to link to from the getting started guide as well. I'll leave this open for the rest of the team to leave feedback on if they have any, otherwise I'll deploy this to the website tomorrow.. CI says no. The rebase needs more work. The migrations module was moved out of Diesel and into another crate (which lives in diesel_migrations/migrations_internals). All these files should have been deleted, I'm not sure why they're still around on master. Hopefully CI fails (I'm really scared if it doesn't). I don't think this needs a changelog entry (it's a minor change in behavior, but not one that our users need to care about during migration). CI says \"run cargo fmt\". A lot of this is really out of date now that we're using rustfmt.. It seems like this is more of a problem of using a relative path for your database URL, rather than a bug in Diesel. We don't really have any behavior here other than passing what you give us unmodified to SQLite.. Does setting the global config accomplish the same thing? If not I think we should fix this in clap.. Can you add a few test cases?. The last commit is the sort of thing I had in mind, yes. However, those tests pass without your code changes. Based on some cursory testing, it looks like we should only need the .setting(AppSettings::PropagateGlobalValuesDown). However, that setting causes diesel --database-url=... database drop to work, but not diesel database --database-url=... drop. The addition of the database_url_from_cli function doesn't seem to affect it.. Can you add a note that we can remove that function once https://github.com/kbknapp/clap-rs/issues/978 is fixed?. You need to run rustfmt. Well that's not a valid query either way, but yes you are getting the general idea. Such a query is ambiguous in any case, as we don't know which instance of table_a you want to refer to. It's the same issue as self-referential joins. Please provide your full compiler output. I reduced your repro case to this minimal case:\n```rust\n[macro_use] extern crate diesel;\n[macro_use] extern crate diesel_codegen;\nuse diesel::prelude::*;\ntable! {\n    users {\n        id -> Int4,\n        username -> Varchar,\n    }\n}\ntable! {\n    categories {\n        id -> Int4,\n        username -> Varchar,\n    }\n}\n[derive(Identifiable)]\npub struct User {\n    pub id: i32,\n    pub username: String,\n}\n[derive(Identifiable, Associations)]\n[table_name = \"categories\"]\n[belongs_to(User, foreign_key = \"username\")]\npub struct Category {\n    pub id: i32,\n    pub username: String,\n}\nfn main() {\n    let user = User { id: 1, username: \"\".into() };\n    let cats = Category::belonging_to(&user);\n}\n```\nby switching to UFCS (<Category as BelongingToDsl<&User>>::belonging_to(&user)) we get a much clearer error message:\n``\nerror[E0277]: the trait bounddiesel::query_builder::SelectStatement: diesel::FilterDsl>is not satisfied\n  --> src/main.rs:36:16\n   |\n36 |     let cats = <Category as BelongingToDsl<&User>>::belonging_to(&user);\n   |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the traitdiesel::FilterDsl>is not implemented fordiesel::query_builder::SelectStatement|\n   = help: the following implementations were found:\n             <diesel::query_builder::SelectStatement<F, S, D, W, O, L, Of, G> as diesel::FilterDsl<Predicate>>\n   = note: required because of the requirements on the impl ofdiesel::FilterDsl>forcategories::table`\nerror[E0277]: the trait bound i32: diesel::Expression is not satisfied\n  --> src/main.rs:36:16\n   |\n36 |     let cats = >::belonging_to(&user);\n   |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::Expression is not implemented for i32\n   |\n   = note: required because of the requirements on the impl of diesel::Expression for &i32\n   = note: required because of the requirements on the impl of diesel::expression::AsExpression<diesel::types::Text> for &i32\n   = note: required because of the requirements on the impl of diesel::BelongingToDsl<&User> for Category\n```\nYou are attempting to use the field username as the foreign key, but the primary key of user is id which has the type Integer. You cannot compare an integer and text column.. Just to make sure this has up to date context:\nThe issue is limited only to columns called bool. The problem is in the code generated by #[derive(QueryId)], where there is an associated const with the type bool. The solution to this is to have a type alias somewhere known (it actually doesn't even have to be in Diesel, we can just put it in the generated code), and reference that instead of bool directly. Eventually the language will provide std::primitives::bool, and we can change to referencing that when it lands in stable.. This is a low priority bug, so I'm leaving it off the milestone. Happy to help a new contributor work on a patch though. :+1: Feel free to ask in Gitter if you have questions.. I'd rather avoid speculatively doing this for all types, as there's no reason you couldn't just have a column called char. The only reason that bool is causing an issue is that it appears in the signature of a trait. I believe we can fix that by just changing impl_query_id! to use ::std::bool instead of bool, and not touch codegen at all. Hm... Actually ::std::bool doesn't work. I wonder if there even is a way to reference bool with an absolute path. I've opened https://github.com/rust-lang/rust/issues/44865 to see if we can get a better way to do this. In the short term I think we should add this to the crate root:\n``rust\n// Referenced byimpl_query_id!to ensure we get the right type if users have\n// a column calledbool. This should be removed when the language lets us\n// referencebool` with an absolute path\n[doc(hidden)]\npub type RealBool = bool;\n```\nand change impl_query_id! to use $crate::RealBool instead of bool. We should also add tests for this. Simply adding a migration with a column that has the same name as each primitive should suffice. Your list is also missing str. I'm going to close this, as it's gotten out of date. I would still like to see the underlying issue fixed, but through the method I mentioned above rather than making these names reserved.. On second thought, I don't want to add this much code to optimize something which is not a bottleneck on a function that is likely being used by nobody.. Why? What's the downside?. The cost of an empty transaction is basically the cost of a ping. If you benchmark this change in isolation, you will see that there is a 2 microsecond difference (cost of doing nothing vs the cost of doing not nothing). However, if you were to execute SELECT 1 in there (something we do every time a connection is removed or checked into the connection pool), the performance is virtually identical. If there were a more meaningful difference here, I'd be fine with adding this, but I don't want to speculatively add code that does exactly what occurs otherwise unless there's a real gain.. Changing users to &*users will fix it.. By design, no. Queryable does not correspond to field names, it corresponds to the type. That said, this is on the list of things I'd like to lint for in https://github.com/diesel-rs/diesel/issues/573. I don't know enough about docker to help with your issue, but you can use diesel print-schema instead of infer_schema! to avoid needing a database at compile time.. So I like this, but I think it's a bit odd now that diesel_codegen doesn't require extern crate but diesel_proc_macro does. I think I'd also like to split up our bang macros by behavior, not by the fact that they're a macro. What I think I'd like to do is this:\nMove the infer_schema! and infer_table_from_schema! macro definitions into diesel_infer_schema. Move the derives for that into infer_schema_internals (note: diesel is explicitly left out of the name so it doesn't show up in searches). Then we also create a new diesel_embed_migrations crate (we can probably move this into its own repo TBH), and have it depend on a new embed_migrations_internals crate.\nThere's also a tradeoff here that the infer_schema! macro (and others) will no longer show up in the documentation for the main crate. We'll have to play with that to see what we think is best, but I don't think that should block this PR.\n@diesel-rs/core Anyone else have thoughts on this?. > I believe that some people might read this change as us taking a step back from promoting infer_schema! as the way to develop Diesel apps.\nI'm completely fine with people taking that interpretation. I think we're at the point where we can say that diesel print-schema is the canonical way to develop, and infer_schema! is more useful for prototyping and/or tests. I hadn't even thought of bundling the migrations module with the embed_migrations! macro, but I really like that idea now that I've seen it.. @weiznich Given that this PR is getting quite large, can you give an updated summary on everything that's changed?. As mentioned, this is not a bug in Diesel. Closing as there's nothing actionable for us to do.. Agreed that we should add a custom type to the test. r? @weiznich . #1520. This appears to have been caused by 38038f6b. It occurs for all reference types except str and slices. It's happening because after that commit we are attempting to use a value of type &'a &'b Value, which does not implement AsExpression.\nWe haven't implemented that in the past, as there's really no reason to take a reference other than for str and slice, since virtually every other type we support is Copy. That said, we should probably just allow double references here in general. I really wish we could do a blanket impl for this. I've opened a PR to fix this on master, but I won't be backporting it to 0.16 as there's very little reason to use &NaiveDateTime here instead of just NaiveDateTime.. These may not be used by SQLite, but they are used by the other backends as you can see from the build failures. . There's not really anything we can do here. debug_query shows the SQL of the query as it exists at that point (as if it were passed to execute). If we tried to mirror the behavior of get_results here, it would cause debug_query to stop working on all backends other than PG. You can append the returning clause yourself by calling .as_query or .returning(table::all_columns). My last comment described how to see the full query, depending on whether it is run with execute or get_results. This is definitely a blocker for 1.0. Hm... I get this when testing locally: Err(DatabaseError(__Unknown, \"terminating connection due to unexpected postmaster exit\")). You can easily test this with connection.execute(\"SELECT 1\").is_ok(). I don't think we need an explicit method for this.. I'm not interested in exposing this. The fact that we happen to use libpq is an implementation detail, and one that will change between minor versions. SQLite is the only backend likely to continue using the C library for the foreseeable future. Are you ever using that column on anything Diesel related? If not you can just delete the column from schema.rs.\nOtherwise you can create a struct Ltree; somewhere. Since this type comes from an extension, which we don't support in Diesel, I'm going to close this. Proper support for this type would be better handled by a third party crate. (See diesel_full_text_search for an example implementation of one). Yeah I think it's worth having us keep a diff file that can be easily re-applied in crates.io. Fixed in 8fb0429. I don't like this approach. I'd much rather we provide a single function called array which takes a tuple.. So I'd roughly take this approach:\n```rust\n// Not super stoked on this name\npub trait IntoSingleTypeExpressionList {\n    type Expression;\nfn into_single_type_expression_list(self) -> Self::Expression;\n\n}\n// This would go in types/impls/tuples.rs\nimpl<$($T,)+ ST> IntoSingleTypeExpressionList for ($($T,)+)\nwhere\n    $($T: AsExpression,)+\n{\n    type Output = ($(AsExprOf<$T, ST>,)+);\nfn into_single_type_expression_list(self) -> Self::Expression {\n    ($(self.$idx.into_sql::<ST>(),)+)\n}\n\n}\npub struct Array {\n    elements: T,\n    _marker: PhantomData,\n}\n// Order here is important, it's likely people will sometimes need to specify the sql type, but infer the actual argument being passed.\npub fn array(elements: T) -> Array\nwhere\n    T: IntoSingleTypeExpressionList,\n{\n    Array {\n        elements: elements.into_single_type_expression_list(),\n        _marker: PhantomData,\n    }\n}\nimpl Expression for Array\nwhere\n    T: Expression,\n{\n    type SqlType = types::Array;\n}\n```\nIt's worth noting that a single element array literal would look a little funky, as it'd be passed like: array((foo,)).. This needs some compile-fail tests as well, probably checking that: only usable with pg, expressions have to be the right type, expressions have to have the same type. Thank you for all your hard work, this is an excellent PR! <3. I manually rebased, and made additional changes. This was merged in 8fb0429. I'm also curious what the compile times are with this feature on. I think we can probably just update huge-tables to this number instead of adding a new feature. @nsrsr Objecting to the term \"insane\" in a feature name in favor of another word is a completely reasonable request. It very much falls under \"Using welcoming and inclusive language\" which we've laid out in this project's values very clearly.\nAttacking people for such ideas will not be tolerated. This is your only warning.. Hah I figured it'd add some module level docs too but that can always be done separately. Something vaguely along the lines of \"methods which are used to construct select statements. Methods in this module will generally map to the keyword for the corresponding clause in SQL, unless it conflicts with a Rust keyword (such as where). Methods in this module are generally focused at the query level. For expression level methods, see expression_methods and dsl\"\nI don't like the terms \"query level\" and \"expression level\", but I'm struggling to come up with a better term to differentiate them. Also saying that it's for select statements is slightly misleading since update and delete statements also implement FilterDsl, but I think it's fine to just refer to these as methods around select statements, since UpdateStatement and DeleteStatement are concrete types that I'm fine with people relying on, but SelectStatement is internal. I believe you are looking for replace_into (which was insert_or_replace in 0.16). You can call .optional(). We call this out in the documentation of every method that can return NotFound (which is basically just .get_result and .first. You could also use infer_table_from_schema! for the tables that you want to infer. Closing as there doesn't appear to be anything actionable here, but feel free to ask further questions here or in gitter.. So I think this goes the wrong direction for this feature. We should support this for all backends since they all use nearly identical syntax. I also don't think we should take a type here. All backends support the registration of additional collations, and the built-in collations available depend on the platform the server is running on. We could try to do schema inference on this, but I don't think it's a big enough win for the amount of work that would require. This is a pretty low risk method. So I think the implementation aught to look a bit more like this:\n```rust\npub struct Collate<'a, Expr> {\n    expr: Expr,\n    collation: Cow<'a, str>,\n}\nimpl QueryFragment for Collate<'a, Expr> {\n    fn walk_ast(&self, mut out: AstPass) -> QueryResult<()> {\n        self.expr.walk_ast(out.reborrow())?;\n        out.push_sql(\" COLLATE \");\n        out.push_sql(&collation);\n        Ok(())\n    }\n}\nimpl QueryFragment for Collate<'a, Expr> {\n    fn walk_ast(&self, mut out: AstPass) -> QueryResult<()> {\n        self.expr.walk_ast(out.reborrow())?;\n        out.push_sql(\" COLLATE \");\n        out.push_sql(&collation);\n        Ok(())\n    }\n}\nimpl QueryFragment for Collate<'a, Expr> {\n    fn walk_ast(&self, mut out: AstPass) -> QueryResult<()> {\n        self.expr.walk_ast(out.reborrow())?;\n        out.push_sql(\" COLLATE \\\"\");\n        out.push_sql(&collation);\n        out.push_sql(\"\\\"\");\n        Ok(())\n    }\n}\nimpl<'a, Expr::SqlType> Expression for Collate<'a, Expr> {\n    type SqlType = Expr::SqlType;\n}\nimpl<'a, Expr> QueryId for Collate<'a, Expr> {\n    type QueryId = ();\nconst HAS_STATIC_QUERY_ID: bool = false;\n\n}\npub trait TextExpressionMethods {\n    fn collate<'a, T>(self, collation: T) -> Grouped>\n    where\n        T: Into>,\n    {\n        Grouped::new(Collate::new(self, collation))\n    }\n}\n```. @gentoo90 Are you still interested in working on this?. Thanks for taking the time for the first attempt. We call this out explicitly in the getting started guide\n\n. We do not currently support allowing the same table to appear multiple times in a single query. This is a duplicate of the table aliasing feature. Yeah this seems like a duplicate of #860 to me.. This looks like it has more to do with how you compiled SQLite than Diesel. Am I missing something?. Sorry for not replying to this issue sooner. I didn't mean to ignore it, but we will likely not be able to address it until after 1.0.0. So if I'm reading this correctly, the only time this has a change in behavior is when the path starts with file:? (which means this is technically a breaking change for anyone who has a file starting with file: but I think we can safely ignore that). @euclio Are you still interested in finishing this?. The status appears to be that it has a failing build and needs a rebase. The test suite would need to pass before this can be further reviewed. I'd also like to see a more meaningful test -- The test provided passes without this change. I agree that the clippy failure seems unrelated, but it only occurs on this PR. I can't reproduce on master or locally. Never mind I see now it is affecting other PRs. You will need to use [replace] in your Cargo.toml, it's not enough to just change your diesel line if you are using r2d2 or other plugins.\nhttp://doc.crates.io/manifest.html#the-replace-section. Make sure you also point diesel_codegen and diesel_infer_schema at master. > what documentation fixes might help others avoid this particular pothole in the future?\nWe've been trying to document it a bit more in the relevant methods for the upcoming release. It appears in the docs for JoinDsl (where the methods you are calling come from), as well as joinable! (which had to be invoked for this to work at all).\nAdditionally on master, both infer_schema! and diesel print-schema will generate code which invokes this for every table in your schema, making this a non-issue for most people. 0.99 but yes. >  if you don't have a Cargo.toml and are in the root of the project you can tell you're in the root because the migrations directory exists.\nExcept the command you're complaining about is diesel setup, which is responsible for creating the migrations directory.\n\nIf you're not in the root you can't tell where the root is\n\nYou can always specify the directory with the MIGRATION_DIRECTORY environment variable, or the --migration-dir command line argument. Unless I'm mistaken, the only time we look for Cargo.toml is to decide where to create the migration directory if you haven't specified explicitly.\n\nI delete my development database and want to run migrations over again.\n\nYou probably just want diesel database setup in that case.. As I said, if you just want to create the database and not setup the whole project (which involves creating the migrations directory, generating default migrations, etc), you should run diesel database setup instead.\n\nand having that panic and spit out a confusing error message still doesn't feel ideal.\n\nI don't think it's common to use Diesel without cargo, so I doubt this is something many are likely to run into.. Appveyor is already too slow, but I do think it's worth adding an additional matrix entry for this on Travis. I would like to hear input from @killercup and @Eijebong on that though.. @simonhdickson Are you still interested in working on this? This needs to be rebased and added to CI before it can be merged.. Yes, I'd go ahead and add a manual matrix entry that only runs the CLI tests, and enables this feature (same way we do clippy/rustfmt). The comments that have been left on this PR need to be addressed.. Feel free to open a new PR, please leave the original author's commits in\ntact if you do\nOn Tue, May 1, 2018 at 9:36 AM Nick Babcock notifications@github.com\nwrote:\n\nApplying the diff\nhttps://github.com/diesel-rs/diesel/pull/1302#issuecomment-378414844 I\nposted earlier to this PR addresses the last outstanding comment (the\nenvironment var looks to be already taken care of). If desired, I can\nsimply open a new PR with applied diff to this PR.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1302#issuecomment-385701919,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWKwwMzpnyodCzYNEnQs2KqofbTKT_ks5tuIDsgaJpZM4QcWmU\n.\n. #1672 finished this. Making this change would mean that Option<T> no longer generates consistent SQL, which would break our prepared statement caching. Ultimately I don't think it's a bad thing for Diesel to be very close to SQL, which is what we always err towards. Note that we do support the PostgreSQL IS NOT DISTINCT FROM operator with .is_not_distinct_from, which has the semantics you want.. You need to set the DATABASE_URL environment variable, or create a .env file with that variable. . @bgeron You are coming dangerously close to trolling. Last warning. . > (It is not possible to implement this outside of diesel because of them DistinctOnDsl impl for SelectStatement)\n\nThat doesn't sound right. Assuming DistinctOnDsl comes from your crate, you should be able to implement it for any type. (Note: I'm not opposed to having this in Diesel). LGTM. Short answer to answer the question: No, I don't think there is a less boilerplate-ey way to do this in 0.16/0.99\nLonger answer for people looking to take a crack at this:\nUltimately the issue here comes from the fact that they are trying to have an unknown number of columns in their order clause. Unlike some other ORMs, Diesel has chosen to override the previous value for all query builder operations besides filter. (For example, .order(:foo).order(:bar) in Ruby on Rails will generate ORDER BY foo, bar).\nThe reasoning behind this is that it's unclear whether the order given last by the user should be considered more important or less important. Most members of the Rails team consider the behavior of order to be a mistake. The only reason filter is given special treatment here is that it is the only query builder method where we can combine its arguments in an associative fashion.\nWhile I don't want to discount this use case, it is definitely one that is less common, which is why it was de-prioritized in favor of the tuple-based API that is causing pain here. I don't have any ideas on what this API should look like. Perhaps it'd make sense to have an API that takes a Vec, and applies it in the manner that this PR is attempting to do (I would actually love to have a vec passed to order behave in exactly this fashion). I'm moving this to the 1.0 milestone. I'm pretty sure we can make passing a Vec to order_by \"just work\", but it requires changing the signature of the trait, which is technically a major breaking change under RFC #1105. Never mind, this will require a separate method... . No, it makes sense for unboxed queries as well.. I think I am going to restrict this to boxed queries, and go with the name .then_order_by (mostly because I can't come up with a good method name for \"like order_by but it takes a vec!\". I also think the API is more useable if we don't force the use of a vec for this. So the original code becomes:\nlet mut query = table.into_boxed();\n\nfor order in &order_by {\n    match *order {\n        \"title\" => query = query.then_order_by(column::title.asc()),\n        \"body\" => query = query.then_order_by(column::body.asc()),\n        \"published\" => query = query.then_order_by(column::published.asc()),\n        other => return Err(MyErr::InvalidParam(other.to_string()))\n    }\n}\n\nI'm open to alternative APIs if anyone has ideas.. Hey @nrc I know you can't say when things will be stable, but do you think it'll be long enough that we should bother dealing with this?. @weiznich FYI -- If you press y in Github it will convert the address bar to a \"canonical URL\" which will continue to work even after I merge your PRs. ;). Ironically this used to work, but was removed when insertable_into was changed to derive(Insertable_. This has come up enough times that it's worth pursuing (I don't like the idea of giving multiple arguments to table_name, I think this needs a more explicit API.) Happy to do the legwork of implementing if someone proposes an API that seems reasonable.\nSince this is not a feature that will require a breaking change, it is on hold until after 1.0.. I'm unable to reproduce with the latest release. Please open a new issue if you continue to have problems on 0.99.0. To make this even more fun, the docs.rs build for diesel_migrations failed. See #1311 for someone's example of how they are doing dynamic ordering. You can also use the sql function for this.. Yeah that was master. I've fixed it on that end.. Yes, I'm going to include some minor changes to this derive in 1.0. I'm not sure I see the need to add bors to this project at the moment. CI is not nearly enough of a bottleneck to cause issues, and we don't have nearly enough commit volume to need to worry about CI passing on a branch but failing on merge. We could just as easily fix that by making master require green CI before merging. . I'm still not fundamentally opposed to this, but I think we should go ahead and close this for the time being. Our CI is in a weird place right now where it's slow enough that I hesitate to add anything that will make it slower (see the backlog right now), but it's not so slow that waiting on CI before merging something is a major problem.\nI get that I've been a bit reckless at times with merging things I shouldn't have, but that doesn't result in any serious problems with the current state of the project (there's zero chance that a bad master for an hour results in nightly not getting published for example). I've been trying to be better about making sure CI is always green. Pretty much every case where something has passed CI but failed post-merge has been due to an update of clippy/rustfmt, and I don't think that warrants this kind of tooling.. Hopefully we can just make sure this sort of thing gets caught in code review next time.. TBH I would actually prefer to just #[allow(missing_docs)] in a lot of these places. Unfortunately, there's no way for me to say \"allow this module to have no module level doc-comment\" without also allowing all items in the module to omit documentation.. This was fixed by #1449. The compile test failures are mostly due to https://github.com/rust-lang/rust/issues/34260. We would have to go through major contortions to avoid the overflow here, and I really think this is a bug in rustc. For now I'm going to comment out the bad lines and push to get this fixed in Rust. (All places that the overflow happens should be failing with E0277 -- There are also failures due to us expecting E0599 which are legit and part of the logic behind this change). Just noise. I still want to do this at some point, but I'll revisit it at a later date.. Ideally we'd handle this and #408 at the same time.. I don't think that these methods would be significantly easier to use than using the query builder directly. Generally we try to keep Diesel very clear what underlying SQL is being performed. I think this would make a great candidate for a third party library, but I don't think it makes sense for Diesel at this time.. We've purposely excluded the revert method, because what it does is dependent on which migrations have or haven't been run, and we don't expose that information.\nDropping and recreating your database is not recommended for tests. Instead, you should run your tests in a transaction. We provide [begin_test_transaction] and [test_transaction] for this purpose.\n[test_transaction]: http://docs.diesel.rs/diesel/connection/trait.Connection.html#method.test_transaction. Thank you for providing code to reproduce the issue. I am looking at it now.. After pulling the generated code with cargo expand, and then compiling that to see what line is causing the issue, it appears this is caused because you have shadowed Result with your own type. You can work around this issue by replacing use errors::* with something that doesn't import Result, and changing the code which used that type to use errors::Result instead.. Thanks for the issue. It's unfortunate that Rust was not able to provide a better error message here. The reason that this occurs becomes more clear if you try to load target. The reason that this occurs is that we do not allow the same table to appear in a query more than once. The reason for this restriction is that it's ambiguous whether comments.parent is referencing the inner query or the outer one, unless the table is aliased. Unfortunately we don't have support for table aliasing at this time.\nYou can work around this by running your subselect as a separate query. (Since you're using SQLite, there's no round-trip time to worry about). Your code works if changed to the following:\nrust\nlet child = comments.select(parent).filter(parent.is_not_null()).load::<Option<i32>>()?;\nlet target = comments.filter(mode.eq(2)).filter(id.nullable().ne_any(child));. I forgot a changelog entry but I'll add one in the merge. We tend to leave \"embarrassingly simple\" things which are not critical open so that first time contributors have something easy to start with. I appreciate the PR though.. Shit I forgot to merge this before 1.0. This is happening because you are running infer_schema! on an empty database. You need to run your migrations with diesel migration run as the guide says. I've opened #1393 to fix the error when an empty database is used.. @bitemyapp Did you figure out all your issues related to Diesel? The float problem doesn't seem like it's Diesel related.. I'm not sure I understand what this has to do with chrono. If your column is REAL, that maps to f64 in Diesel.. Can you please provide the code that is causing your problems, along with the full compiler output? Otherwise I can't do more beyond guess at what you're trying to do, or what's going wrong.\nIf you want to use chrono::NaiveDateTime, you should call your type either DATETIME or TIMESTAMP.\nGlancing through our type mappings in SQLite, it looks like REAL maps to f32 not f64 in 1.0.0-beta1 (that seems like a bug to me). The type names that we map to diesel::types::Double in 1.0.0-beta1 are any types that contain the string \"DOUBLE\", \"DEC\", or \"NUM\"\nThe error message \"Expression is not implemented\" is almost always useless. If you look at the full error message, you will see a line that says \"required because of the requirements for AsExpression<SqlType> for RustType\". That line is the one you want to care about. SqlType is the type we're expecting, and it means that RustType can't be used for that SqlType (typically because it's an unsupported conversion, in the case of f64 in a Float column, or because a feature is missing, which is a common mistake with chrono types).. Also you can always see what types got inferred by using diesel print-schema. Ah, I see why we map REAL to f32. It's a 32-bit float in ANSI SQL. Also you said you were using that type because our documentation told you to do so. Can you point me to where that was? I can't find that type name mentioned anywhere in our documentation.. > for what should be an unsigned database id\nIf you'd like to submit a PR that makes IDs unsigned on all the backends we support, I'd be happy to make that change. However, as it stands right now, they are signed.\n\nAre you intentionally restricting it to ANSI rather than what SQLite can do?\n\nWe aren't restricting at all. infer_schema! maps between type names and Diesel's representation of types. We use the type name to figure out what you intended in ways that don't map to SQLite's storage classes. You can safely declare a table as some_col -> BigInt regardless of the type name. (You can use diesel print-schema to get what infer_schema! would have generated, and then edit it as you'd like).\n\nI didn't say I was using f64 because of the docs, I said I was trying to use Double in my model type because of the docs. I was in whack-a-mole mode.\n\nCan you be more specific about what you read that implied that you should do that? I'd like to improve the documentation to fix that error. The module for that type says (emphasis added):\n\nTypes which represent a native SQL data type, and the conversions between them and Rust primitives. The structs in this module are only used as markers to represent a SQL type, and shouldn't be used in your structs. See the documentation for each type to see the Rust types that can be used with a corresponding SQL type. Additional types can be added by other crates.\nThe last one appeared to be SQLite's somewhat unfortunate handling of dates requiring that I use Integer for the column type, meaning i32 for the model type.\n\nSQLite does not have any requirement that you use Integer to store dates. > I mean, you can also use TEXT or REAL too but that's not much of a choice.\nAgain, I'm not sure what you're getting at here. SQLite doesn't have a storage class for dates, but that doesn't affect our support for it.\n\nMy point is it's not a real date or timestamp column type.\n\nCan you explain to me what you're looking for from a \"real\" date or timestamp column type that isn't provided?. Just to be clear, you can call your column DOUBLE, DECIMAL, or NUMERIC to make infer_schema! infer it as diesel::types::Double, which maps to f64 on the Rust side. (Sorry, our type mappings on SQLite are not well documented at the moment. I'm trying to figure out the best place to document them).. I'm referring to your database schema. e.g. the CREATE TABLE definition.. > Your suggested column types don't neatly fit an i64.\nI thought we were talking about f64. If you want to use i64 (aka you want infer_schema! to infer your column to be diesel::types::BigInt) you should call your type BIGINT.\n\nNumeric can contain any of the five storage classes, so that isn't narrowly or clearly i64.\n\nI think you may be confused about how SQLite's storage works. SQLite is dynamically typed.  Any column can store a value of any type. \"Storage classes\" apply to values, not columns. Columns are given a \"type affinity\", which can sometimes affect which storage class is used, but only if that conversion is determined to be lossless. The only time storage classes are ever visible is if you are using CAST, and is generally irrelevant if using Diesel.\n\nDouble is f64, not i64\n\nI've never said Double is i64.\n\nDecimal falls under Numeric affinity and isn't a 64-bit whole number, but rather, a Decimal value for which you can specify precision.\n\nThe type affinity is virtually meaningless here. It only affects how storage occurs in cases where the conversion is lossless. You should never see any visible change in behavior due to type affinity of a column, and unless you are using CAST, you should never need to care about storage classes. SQLite has no concept of a decimal value for which you can specify precision (aka the decimal type in other backends). The highest precision you can store in SQLite as a numeric value is a 64 bit float. Anything else would need to be stored as a string.\n\nThe actual column type that maps unambiguously onto i64 in SQLite and is in common use for that purpose is Integer\n\nAs I've mentioned, infer_schema! will put more meaning on your type names than SQLite will. If you call a type SMALLINT, we will infer that to mean you want to work with i16, which is what that type means elsewhere. Same with INTEGER, and BIGINT. This is specific to infer_schema!, not Diesel as a whole. You can safely declare a table to have a column of type BigInt regardless of what you call your type.\nIf you prefer to avoid infer_schema!s behavior here, I recommend not using it, and using table! directly. You can use diesel print-schema to get the output that infer_schema! generates, and the edit it as you see fit.. This bit from the SQLite documentation may help clear things up:\n\nThe type affinity of a column is the recommended type for data stored in that column. The important idea here is that the type is recommended, not required. Any column can still store any type of data. It is just that some columns, given the choice, will prefer to use one storage class over another. The preferred storage class for a column is called its \"affinity\".\n\n. If you'd prefer to map to SQLite's type affinities, I recommend avoiding using infer_schema!, and using table! directly instead.. It looks like infer_schema! actually finishes fine, but the code it generates is allow_tables_to_appear_in_same_query!() which doesn't have a matcher for zero tokens. Yes, pointing to a file which doesn't exist would cause SQLite to create a new database at that location, which would be empty.. This was resolved.. Thank you for the pull request. I'm hesitant about exposing this, because most useful cases here should be given a corresponding variant in DatabaseErrorKind. If we do decide to go this route, what do you think about returning the SQLSTATE code, rather than a backend specific one?\nEither way, this won't be merged until after 1.0 has been released.. > I'm not sure what this distinction is.\nOne is an ANSI standard that is consistent across backends. I actually didn't even think about the fact that PG has no error codes besides SQL state codes. I was thrown off by the fact that this returns i64. This function can't return i64, SQLSTATE codes are 5 character strings. e.g. \"2BP01\"\nI also don't like the name code since other backends have \"error codes\" which are not SQLSTATE identifiers.\n\nI'd recommend merging it now while you can still change the DatabaseErrorInformation trait without affecting compatibility.\n\nThis pull request is fully backwards compatible.. > I can't find any evidence that SQLite implements this particular part of the standard\nIt's not part of the SQL standard, it is a separate ANSI standard (similar to information_schema). SQLite does not support it. MySQL does, and AFAIK SQL Server and Oracle do as well.\n\nIt adds a trait method. Implementors of DatabaseErrorInformation will not compile with this change without a change in the implementation.\n\nIt adds a trait method with a default implementation. Implementors don't need to care. It can cause minor breakage in downstream code if some code is calling x.code() where x implements a different trait which also has a method called code. However, this is considered a minor breaking change (aka semver backwards compatible) by RFC #1105. If you're still interested in working on this, feel free to open a new PR, but I'm going to go ahead and close this as it's not currently in a state that's close to being merged, and there has been no activity for several months. For this PR to be considered, it'd need to be based on the SQLSTATE standard rather than a backend specific code, and return an appropriate type. I'd also like to see some use cases that justify a generic error code as opposed to better handling of specific errors.. Shit I didn't even see that there was an open PR for this. Sorry :(. https://docs.rs/diesel_migrations/1.0.0-beta1/diesel_migrations/macro.embed_migrations.html. This has come up before, and I don't think this issue brings up anything new.\nI've said in the past that for us to consider Rust migrations, there would need to be a really compelling use case. So far the only real use case that's been raised is \"you can sometimes get down for free\", which isn't a huge win. Writing database agnostic code is an explicit non-goal of the project. This is doubly true for schema management.\nI have made sure that the code is structured so alternative migration forms can be added in the future, and we will continue to make that the case. Since this doesn't raise any new use cases that haven't been discussed, and there's nothing actionable here, I'm going to close this issue.\nSee #980, #336, #10, and gitter history for past discussions on this topic.. @theduke I agree with you that it is a reasonable use case. I just don't think it's one that fits into Diesel. I've architected our migration infrastructure to make it easy for third party crates to come in with new functionality (see the barrel feature for an example).. Oh whoops I didn't see that the link was still wrong. I guess we can call the file .keep.. It got removed since it showed up in the results of the regex I was using to find these.. I just realized I never mentioned a tuple like (user_id.eq(session.get(\"user_id\")), &post_form). > I just hope they find it ;)\nThis is the most prominent place I can put it, so they better. >_>. I was going to wait for the build but ok :P. No, I just generally wait all the time now after that time that I broke CI like 3 times in a day with PRs that \"definitely aren't doing anything that could break CI\". Note that your SQL doesn't map to the operator or types you've specified. || is the \"concatenate\" operator, and the equivalent Rust would likely be authors.eq(authors.concat(vec![\"Jane Doe\"])). At the moment we would not be able to support composite foreign keys here without making a breaking change to BelongsTo. At the moment we're not considering anything that would require a major version bump.. > I don't really feel qualified to write docs and I am not even sure if what I wrote is accurate.\nKeep in mind that we're always happy to answer questions. Typically this process is what results in better docs, since you know what you were looking for and/or confused by better than we can guess. :). @alatiera Are you still interested in finishing this?. No problem, that's why I pinged you. It looks like the outstanding issue is that your last commit didn't address https://github.com/diesel-rs/diesel/pull/1414#discussion_r157878831 :). @weiznich Feel free to take over this. Can you add a change log entry for this?. CI failure is legit. . I manually cancelled the CI build because I want master to run so we rebuild our docs. I will re-run once the docs have been rebuilt.. The CI failure is legit. Only thing missing is a CHANGELOG entry but I can add that.. > WATAAAAAAA\nGo drink some water mate. Even if we close this, the issue will forever have a link to this PR. in the future please do leave issues with that tag for potential new contributors. . @juliusdelta Are you still interested in finishing this?. There doesn't appear to be an obvious solution here unless we get some changes landed in the language. Attempting to implement Identifiable for tuples just causes Rust to blow up trying to recurse for no reason.. Can you please update your commit message to include a link to https://github.com/rust-lang/rust/pull/44890 as context? . Feel free to merge when CI is green. We recommend using diesel print-schema in the long run, but infer_schema! is still a very useful tool for prototyping when the schema file churns a lot.. > The more projects do fancy things at compile-time, the less freedom the Rust team will have to improve compile times, AFAICT.\nGiven that proc macros are capable of running any arbitrary code, the Rust team will always need to assume that proc macros do anything, including network or Disk IO. Whether our project takes advantage of those capabilities is irrelevant.\n\nI've personally never expected people to do things like that\n\nPerhaps seeing these use cases in the wild will change your expectations. You may also be interested in embed_migrations!, which would also prevent things like using MIRI for proc macros.. > If no one uses them in such dubious ways\nAgain, claiming that our project has any impact on that is ridiculous. It is impossible to know if anyone is using Rust in a certain way. You can say for sure that someone is using something, but unless you have access to everybody's closed source repositories, it is impossible to say that someone isn't using something.\n\nthat's not where that code should run in the first place\n\nFrankly, I'm not sure what gives you the right to decide where other people's code should or shouldn't be run. Thank you for the pull request, but I don't think we're interested in this feature at this point in time. For changes which cannot be represented in SQL, you should consider a one-off task rather than a Diesel migration.. I think I may expand on this with a second section in the future. I want to hammer home somewhere that \"Queryable is one-to-one with the queries you run (which doesn't always mean a table)\", and \"Insertable and AsChangeset are one-to-one with web forms, API endpoints, or whatever your user input source is\". I'm not sure if this guide is the right place to do it, but a second section that talks about when to use each, how to compose structs (especially for insert), etc probably makes sense.\nEither way, I think this first section is fine to review on its own.. Recommendations applied. I'm going to publish rather than merging to drafts.. You need to ensure that your payees module is in scope, with a line such as use schema::payees; (Assuming that you have your table! or infer_schema! declarations in a module called schema).\n. We mention this in a few other places (I think the associations docs mentions it?) we could probably put that same wording in the docs for Identifiable.. > given the amount of overlap you're going to have between the insertable and queryable versions for most models\nThis is what I like to call \"incidental duplication\" -- which is the term I use to refer to things that happen to be structurally similar right now, but change in the future for different reasons. The approach we've taken is very specifically designed to separate things that represent the results of queries from things that represent input from external sources. The desire to keep these separate comes from experience with hundreds of applications. You can see similar approaches in other modern frameworks like Phoenix.\nIf you really want to share these structs, Queryable composes with other structs that are Queryable. You could have a struct like this:\nrust\nstruct UserWithId {\n    id: i32,\n    user: User,\n}\nIt sounds like you've found the answers you're looking for, so I'm going to close this issue.. This was fixed in #1380 which was released in 1.0.0-rc1. We need to backport this to 0.99. In the mean time you can enable the Chrono feature to work around this. Can you a CHANGELOG entry?. \n. Yes, this is an issue in Rust not Diesel.. You should remove \\lib from your path. You cannot statically link libpq with msvc. You only need the bin directory on your path.. You can also just run pg_env.bat which does all the setup needed for you.. Feel free to open a pull request to https://github.com/diesel-rs/diesel/blob/master/guide_drafts/backend_installation.md with Windows steps that work for you. Unfortunately, I don't use Windows for development, so I'm not the best person to document how to link libpq on that platform.. @killercup @Eijebong I requested specific review from each of you to get your thoughts on whether we can consider this a minor breaking change or not under RFC 1150.. > There is no such thing as a \"minor breaking change\".\nI recommend you read RFC 1105. This is a very specific term defined quite clearly.. > Would you say this is a fix in Diesel's SQL-mapping-type-system to prevent possibly invalid code to when using MySQL?\nNo, it's just moving some coercions that libmysqlclient does for us into Diesel. This would allow us to remove the HasSqlType bound on Connection::query_by_index and use the same code for both by-index and by-name queries.\n\nCan you write code right now that breaks this?\n\nBasically if you're doing by-name queries, the types aren't going to be what you expect. It means that on MySQL you couldn't use the same struct for Queryable and QueryableByName if you're using anything that has unexpected types.\n\nI'm torn between seeing as a pre-emptive bug fix\n\nIt's less of a bug fix and more of a \"making something a lot easier\"\n\nThe latter would be quite unfortunate, not even a week after 1.0;\n\nYeah I'm just not going to make this change if we decide it requires a major version bump.\nSome quotes from the RFC to back up my reasoning here:\n\nSo, this RFC proposes that all major changes are breaking, but not all breaking changes are major.\nMinor changes should require at most minor amounts of work upon upgrade. For example, changes that may require occasional type annotations or use of UFCS to disambiguate are not automatically \"major\" changes. (But in such cases, one must evaluate how widespread these \"minor\" changes are).\n\nI think this very clearly falls into the minor change category, especially since it's fairly unlikely that there's any code actually breaking from this (at least there's nothing published on crates.io which would use this, of course we can't know what's in people's apps).\nOne other bit from the RFC which definitely applies here:\n\nThat means that any breakage in a minor release must be very \"shallow\": it must always be possible to locally fix the problem through some kind of disambiguation that could have been done in advance. > That particular change though, isn't such a change as per RFC 1105 AFAICT.\n\nSure. Like I said, this is going by the spirit not the letter. I don't suspect that there's any code out there that will break because of this, if there is it's very little work to fix, and could be written forwards compatibly -- the criteria for everything else listed as minor. It is definitely possible that there is code out there that could break from this, which is why I asked the rest of the core team to chime in on whether they agree that this is minor or not.\n\nAs for looking at the raw bytes, isn't that required if an end user wants to use spatial types?\n\nNope, every type that isn't supported in Diesel itself is transmitted as a string. The correct way to get the data for JSON, geometric types, enums, and anything else is <String as FromSql<types::Text, Mysql>>::from_sql(input)\n  . Never mind, geometry is not sent as text.. @diesel-rs/core I think I've made every argument I'm going to for this. I had some vague shower thoughts this morning about how this might let us get rid of HasSqlType for tuples, and that might allow us to support PG tuples as direct mappings to Rust tuples, but I haven't explored it enough to know if that's true or not.\nCan we get an official vote on whether this is an acceptable change for 1.1? I think we need to be unanimous here. If anybody is uncomfortable, we don't make the change.\n\n[x] @sgrif\n[ ] @killercup\n[ ] @Eijebong \n  . One last note: If we do make this change I think we should do a week long RC1 release for 1.1.0. I'm going to hold off on doing this for now. While I do still think that we could do this with reasonable expectation that no code will break, we should have a bigger win to justify it. However, the more time that passes, the higher risk this change would be, so I suspect we will need to hold off until either 2.0 or do it by introducing a Mysql2 backend if we ever decide we actually need this change.\n\nWith all that said, I think we should make RawValue an opaque representation for all backends in 2.0 (with a raw_bytes method on it that exposes &[u8] in all cases except SQLite) in order to future proof against changes we may want to make. (e.g. I do think there may be some value in giving the OID to the FromSql impl, but we can't make that change now). I actually don't know if we can fix this until disjointness based on associated types lands. We need to change this impl:\nimpl<Left, Right> SelectableExpression<\n            Join<Left, Right, Inner>,\n        > for $column_name where\n            $column_name: AppearsOnTable<Join<Left, Right, Inner>>,\n            Join<Left, Right, Inner>: AppearsInFromClause<$($table)::*, Count=Once>,\n        {\n        }\nto be these two impls:\n```\n    impl<Left, Right> SelectableExpression<\n        Join<Left, Right, Inner>,\n    > for $column_name where\n        $column_name: SelectableExpression<Left>,\n        Right: AppearsInFromClause<$($table)::*, Count=Never>,\n    {\n    }\n\n    impl<Left, Right> SelectableExpression<\n        Join<Left, Right, Inner>,\n    > for $column_name where\n        $column_name: SelectableExpression<Right>,\n        Left: AppearsInFromClause<$($table)::*, Count=Never>,\n    {\n    }\n\n```\nI need to think about this more to come up with a way to fix this today.. I'm going to leave this open for a day or two in case anybody has a better idea for the method name.. @jbcden FYI, we usually avoid the \"Request changes\" button unless the changes are substantial enough that you think a second review will be needed after the changes are addressed.. You can add libsqlite3-sys to your Cargo.toml and specify whatever features you want. See #829 and other times this has been brought up in the past.. This is ready for review regardless of the CI failures. I haven't had a chance to look into why this is failing on CI since READ ONLY and READ WRITE are not new. There might be order dependence in versions of PG older than what I tested on locally. I'm hoping that a rebase magically fixes the CI failures because I have no clue why READ ONLY and READ WRITE are somehow not working. Lol yup, that'd do it. Explains why it wasn't failing locally >_>. Hm, that's actually a problem since I don't think we can modify schema in a READ ONLY transaction. This was merged but I'm bad at rebasing.. Reverting (going to be a manual commit since there was rebasing involved). Actually I lied. This isn't implementation defined behavior. We're not relying on the internal representation of bool, we're relying on the behavior of casting a bool to u8. This is not an implementation detail, it is public API which cannot be changed without a major version bump. (If we were using mem::transmute that would be a different story). LGTM after the old macro is removed.. Also the tests for the old macro need to be ported over I think. > There are no tests for the old macro \ud83d\ude1f\nAwesome.... crates.io\nI don't have a high res or vector logo on me, I'll have to track one down.. I'm going to revisit this in the future, this will require some design work to add the appropriate section to the website, and I don't have the cash to pay a designer for this right now. > Is Queryable assuming the order of the struct fields matches the order of the database columns?\nNo. It is assuming it matches the order of the items in the select clause of the query being run. If you haven't specified a select clause, it will be all columns on the table, in the order they appear in the table! declaration. If you are using diesel print-schema or infer_schema!, then that will be the same as the order of your database columns.\n\nMy assumption had been that diesel was mapping the fields of the struct by name to the database columns. Are the docs saying that instead the struct field order is used to map to columns, such that in the example above database column \"a\" would map to struct field \"c\"?\n\nCorrect. If you are using diesel print-schema or diesel infer_schema, then the query examples::table would have the select clause (examples::id, examples::a, examples::b, examples::c), which would load into your struct with the value of examples::a in the field called c on your struct.. If you have any concrete places that you think it should be mentioned, feel free to open a PR. We mention in as many places as we can.. Rather than using feature = \"unstable\" for this (which IIRC is actually unused right now), can we change this to be #[cfg(diesel_unstable)]? Rayon does this and I think it's a really good idea. It requires that the outermost compilation unit (aka the actual application) build with RUSTFLAGS = --cfg diesel_unstable, which means you can't accidentally transitively depend on an unstable Diesel feature. This mirrors how relying on nightly works (if one of your deps needs nightly, you have to opt into nightly), and makes much more sense than cargo features (which are additive and you can rely on without knowing it). I was tired when I reviewed this. I retract my thing about not using the unstable feature. This is about unstable Rust not unstable features of the library.. You need to make sure that libpq.dll is on your %PATH%.. There's nothing wrong with discussing on the issue tracker, but as mentioned the action we can take is answering your question. Typically we close issues at that point, as more often than not people don't come back and say \"this fully answered my question, thanks\". I'm glad to hear that you got it sorted out.. Unfortunately, we can't really do this until we more generally separate \"data sources\" from \"tables\". The problem is that all tables in Diesel must have a primary key, and there's no way that we could infer that. Humans can just pick a random arbitrary column and call that the primary key (and many views actually do logically have one), but I don't want to do that in Diesel CLI. Yup, that's the work around. For the record, I closed this issue, because that specific feature is not something we can support. That said, I do want to support views in general, as a separate concept from table!/Table (basically just not having a primary key), and when we do that they will absolutely be inferred by diesel print-schema and infer_schema!. They could stand to be a lot more exhaustive. For starters, there are no tests for having more than one association, using tuple structs, cases where the foreign key field is named differently than the foreign key column.. In example one you have: let (start, end) = (range.start as i64, range.start as i64);\nYou meant range.end. You can use debug_query to show the generated SQL, which is identical other than the values of your bind parameters.. Forgot to mention in the commit message. The reason for the BatchInsert struct is that I'm not comfortable implementing QueryFragment for slice.. Thanks, but this exact approach has been opened before and rejected. I'd prefer to use an actual URL parser rather than rolling our own.. Can you add a CHANGELOG entry?. @killercup I want to land it incrementally, but I think we need to answer some higher level questions about the API. I also have some strong concerns with this implementation. I'm not convinced that there's any reason to duplicate the functionality of FromSqlRow and ToSql here.\nI don't like the API that's exposed in this PR. We should be able to figure out the number of arguments based on the type of the function given. I don't think we should be exposing anything like Context. We should deal with conversions on our end, and just give the user what they ask for.\nThere are also major memory safety issues in this implementation. At absolute minimum we need to be enforcing that both the function given and it's return type are 'static. I need to look more closely to see if there are any other issues in that regard.. @maghoff What's your plan here? Do you want to continue working on this? If so I think we should get you in touch with someone on the team to help implement the rest of this (and probably start by agreeing on an API to target before anything else). This was implemented in #1691. cc @alexcrichton I can't actually test this on beta/nightly due to the other regressions, but does this seem more reasonable to you? There's no chance of this breaking in the future, right?. Can you give some more context on why you need it, and why you think it's a good fit for Diesel to support this type? CString is meant for heavy interaction with C code, not databases. . > as well as avoiding any copies and conversions until the thing hits the Diesel or DB layer.\nThere's actually no copies involved in converting to an &str, and Diesel won't copy it until we need to in order to send to the DB. In terms of data coming from the DB, the same amount of copies will be required regardless of whether it's a CString or String.\nMy gut reaction is to close this. We don't generally add support for types which don't have a direct mapping to a SQL type for a given database. I suspect Vec<u8> is probably a more appropriate type here. You can pretty easily add support for this in your own app by using a wrapper struct, as well.\nThat said, given that this is a type in the standard library (e.g. there's zero chance of you opening a PR on the other side adding Diesel support), and this is more reasonable for us to support than most other types proposed, I'm going to leave this open for a few days to think about it and for others to give feedback.. >  I suspect Vec<u8> is probably a more appropriate type here.. Right now you'd need to convert to a &str first (which you can do for free and without copies) -- we should probably add ToSql and FromSql impls for Vec<u8> and &[u8] for text columns.. I actually take that back -- there's no reason for us to support types other than String or &str on text columns, and you do need to ensure that they're UTF-8 encoded. We are specifying the client encoding on both MySQL and PG, which means that the database is sending us data encoded as UTF-8, and expects any text data in that encoding. SQLite only supports UTF-8 for text columns to begin with. You should probably use a binary column if you actually want unspecified encodings.. Your database is going to need a client encoding regardless of how you\naccess it. Text columns have encodings, and wire protocols also have\nencodings. If you don't want them, you should use a different data type.\nThat's not a diesel thing, that's how databases work.\nOn Thu, Jan 18, 2018, 4:55 PM Soni L. notifications@github.com wrote:\n\nSo what I should do is forget Diesel and use raw SQL?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1495#issuecomment-358821677,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK77PWXJpECZF6j86dQsTPkX_vfhBks5tL9n8gaJpZM4RjXkS\n.\n. It's a connection level setting. Not something that can really be handled\nat a column level.\n\nOn Thu, Jan 18, 2018, 5:33 PM Soni L. notifications@github.com wrote:\n\nShouldn't you try to match wire protocol encoding with text column\nencoding to reduce conversions as much as possible?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1495#issuecomment-358828870,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWKwChnwsztjnQgnq2oEVgD07_x4i8ks5tL-LzgaJpZM4RjXkS\n.\n. I don't think save_changes() should behave any differently than updates everywhere else. You can configure this behavior with #[changeset_options(treat_none_as_null = \"true\")] on your struct.. I do see your point. However, I think that having updates always work consistently, and keeping save_changes easy to understand in terms of every other form of update is more valuable. I had actually considered deprecating save_changes for a while, since it's pointless on PG and is at a weird level of abstraction compared to the rest of the library.\n\nI disagree with your assertion that save_changes and update should require separate structs. Keep in mind that AsChangeset in general is meant to be on structs which are one-to-one with your input source (e.g. they would also have #[derive(Deserialize)]). Keeping that use case in mind, there's not a great way to differentiate from \"this was not included in the input\" vs \"this was explicitly assigned to null\" other than Some(None). Of course depending on your use case, that may not be what you want, hence why we have the option.\nI recommend reading through #26 for more context.. > So for edit requests I always deserialize into a FooEdit struct first, do the validation on that, then create a FooUpdate struct instance from that and then call update() with that.\nThis all sounds reasonable for validations at the moment. I suspect we will eventually end up with something that lives at a level close to serde that handles validations, where deserializing something that fails validation is considered a deserialization error.\n\nHow common is it to deserialize a request directly into the actual changeset struct?\n\nI think we need more applications built before we can answer that. The intent is for them to live very close together though even if they aren't the same struct (ideally they should be able to though). This is one of the main reasons that Queryable is typically a separate struct. The point about \"did this mean assign null or skip this field\" still stands regardless of whether you have an intermediate struct or not.\n\nAnd in those use cases, wouldn't that changeset struct usually be a separate struct (FooUpdate) than the model struct (Foo)\n\nI'm assuming by \"model struct\" you mean the thing that implements Queryable, and yes they are typically different. Actually reading the rest of that paragraph, yeah I better see where you're coming from (you expect this to be a thing on Queryable structs which you're seeing as more traditional \"models\" in the Python/Ruby ORM sense). TBH if anything that just reinforces my desire to deprecate the function more than anything else, but it also is a situation where #[treat_none_as_null] handles your use case very well.. > Hm, shouldn't model structs be both Queryable and Identifiable?\nIdentifiable means \"this struct has an identifier linking it to a single row in a database table. It is completely separate from Queryable which says \"I can be deserialized from a SQL query\", though Identifiable structs usually implement Queryable.\n\nAll its model structs are Queryable and Identifiable\n\nYup, and if all your structs are one-to-one with database tables, that's what it'll look like. We decouple those concepts by design. Same with AsChangeset. It definitely can be on the same struct as Queryable, but in my experience, the needs of your input for updates changes for different reasons than the structures you return on reads.\nIn Rust specifically for example, if you are building a web app, the id does not come from the same place as the rest of your input (it comes from the URL not the request body). I intend most usage to look like update(posts.find(params.get(\"id\"))).set(&post_form). Similarly with inserts, the parent ID usually comes from the session or auth token, not the form input. So I would expect most inserts to look like insert_into(posts).values((user_id.eq(session.get(\"user_id\")), &user_form)).\nYou don't have to follow these patterns, but they are separated for a reason.\n\nBtw, please don't deprecate save_changes()\n\nI'm not currently planning on it.. Good point. No we don't.. Fixed by #1499. Yeah, that sounds like a good idea to me. :). I've been meaning to generate an impl on the struct as well as a reference to the struct. Would that sufficiently handle your use case?. You can also change node::all_columns to node::all_columns() if you have node::dsl::* in scope.. You can revert a single migration with diesel migration revert. You can reset your whole schema with diesel database reset. You can run diesel --help for a full list of commands.. No, we don't have anything to log what SQL is run for a transaction. The SQL is BEGIN and COMMIT or ROLLBACK.. /cc @dtolnay mind taking a look at this?. After playing around with Diagnostic, I realize that I need to structure this to return errors, not panic.. I guess I'll restructure to not-panic separately... Yeah I'm fine with this change and backporting. \nwait for it.... It compiles in 9:30 >_<. > Are there any plans to keep track of Varchar length in the future?\nNope, we also don't currently plan on tracking any other constraints, defaults, indexes, etc.\n\nWould there be interest in a PR for this\n\nNot at this time. Thank you!. Can you expand on what you mean by \"execute multiple updates\"? Can you provide the SQL query you'd like to construct?. You just need to call execute on multiple update statements. e.g.\nrust\nupdate(posts).set(field.eq(\"1\")).filter(...).execute(&conn)?;\nupdate(posts).set(field.eq(\"2\")).filter(...).execute(&conn)?;. I haven't seen much real world usage that needs to execute multiple unrelated update statements in a single round trip. If you want to optimize for that benchmark, you can pass a SQL string to connection.batch_execute (this is how migrations are run).. Thanks, but this is the documented behavior of #[derive(Queryable)], and isn't something that will change any time soon. The type of a SQL query is represented as a tuple, which necessitates order dependence. Additionally, Queryable does not mean one-to-one with a row in a database table, meaning field names aren't particularly useful there.\nIf you don't want field order to be important, I recommend avoiding #[derive(Queryable)] and implementing the trait directly instead.. Release mode timings:\n\n16 columns\n9.87 secs\n32 columns\n20.56 secs\n64 columns\n82.36 secs\n128 columns\n\u00af\\_(\u30c4)_/\u00af probably forever. Note: Diesel itself has so little \"real\" code that release mode doesn't generally affect it. Only release mode for libs using Diesel.. /cc @dtolnay. Note: Build is going to be red until tomorrow. Nothing I can do about that, but this should be fine to review. https://github.com/rust-lang/rust/pull/47738 will be in tomorrow's nightly.. /cc @dtolnay you may find this one interesting too. Yeah, I'll get to those soon. :). For reference, I think the weird span behavior with the macro invocation might be a bug in rustc. If so, https://github.com/rust-lang/rust/issues/47988 is the issue.. For reference, I think the weird span behavior with __diesel_use_everything!() is due to a bug in rustc. https://github.com/rust-lang/rust/issues/47988 is the issue.. For reference, I think the weird span behavior with __diesel_use_everything!() here is due to a bug in rustc. https://github.com/rust-lang/rust/issues/47988 is the issue.. Can you rebase and run rustfmt so it's easier to see what's new in this PR?. Merging with red CI #yolo. Correct. Yeah, it's probably worth a compile test. compile test added. Oh crap I forgot a changelog entry. Fixed in 367c341. Datetime does not have a time xone. The appropriate type is NaiveDateTime. http://docs.diesel.rs/diesel/sql_types/struct.Timestamp.html\n\nYou'll need to call your type TIMESTAMP or DATETIME on the SQL end for infer_schema! to infer that you want to store that sort of data in this column.. infer_schema! and diesel print-schema use the same logic. I was referring to either one. ;). I don't think we would support duration support for SQLite.. We don't typically support types that don't have a direct database mapping to a SQL type. Even if we did, there's no obvious way to store it, and you wouldn't be able to do anything useful with it.. SQLite has no corresponding interval type to store it as. I'd expect now + Duration to work if we supported durations. It wouldn't.. You'll need to change the first parameter of BoxableExpression to Join<left::table, right::table, Inner>. > This matches the behaviour of normal subselect queries\nWhere? I don't see that impl. Sure.. Your first impl won't work. It'll fail when you try to execute a query containing a PunishmentTypebecause you did not implement QueryId or QueryFragment. The second version relies on API which is not public. foreign_derive is for use in Diesel only. You should put #[derive(AsExpression)] on PunishmentType directly.. I'd need to see more of your schema to answer that, but I'm recovering from a concussion and can't help you right now. Try asking in gitter. Oh also it looks like the problem is that you don't have a ToSql implementation. Above comment is correct. Either use i64 on the Rust side, or change the type to INTEGER on the SQL side.. Fixed by #1554. This is looking great, but the Table impls made me realize something -- You haven't implemented this for boxed select statements, and there is no way to safely do so (we can't know if a boxed select statement already has a FOR UPDATE clause or not). I think rather than .for_update().skip_locked(), we should go with the API .for_update_skip_locked(), which overrides the previous FOR UPDATE clause if there was one. This way we can reasonably implement it for boxed select statements.. Ughhhhhhhh.... \n\n. I need to spend some time thinking about this.. SQL vendors please stop adding features which are extremely complex and ever so slightly different in an incompatible way with nearly identical feature from other SQL vendor kthx. It's the weekend. I'll take a look on Monday. :). I never said which Monday :trollface: #perl6 (Sorry I've been a little swamped lately I have pinned this to my browser, and I super promise to review this week. I was about to do it right now but literally as I was writing this my wife said it's time to go). Let's go with the API you've proposed. My main concern with it is that it allows:\nfoo::table\n    .for_update()\n    .filter(stuff)\n    .skip_locked()\nwhich is nonsense, but I think that's OK. This still has unresolved feedback to be addressed though. Note: We can work around this by having the return type of .for_update be something like LockClauseBuilder, and making everything else be inherent methods on that type -- But unfortunately the way things are structured today we wouldn't be able to get away with just implementing AsQuery. We'd also need to implement every DSL trait since the blanket trait on tables won't apply there. It'd also require making the concrete type of <SelectStatement as ForUpdateDsl>::Output part of the public API which I don't want to do.. I'm not sure I see the benefit of having a separate locking method vs just .for_no_key_update and .for_share on the table itself. It would look like the API you've proposed.\n.for_update().skip_locked()\n.for_no_key_update().skip_locked()\nWRT specifying the table, I suspect we'd add something along the lines of .for_update_of(table). Granted, this is a large amount of methods -- Your API is somewhat along the lines of something I considered when I was thinking about this (but I was thinking something more along the lines of .locking().for_update().skip_locked.for_table(table), which has all sorts of problems). Ultimately the only thing gained by going with a separate builder style API in any form is that we would need one method to specify the table instead of 4, but I'm not sure that's a big enough win?. > It has the advantage of not cluttering the top-level DSL.\nThis really depends on what you consider the \"top level\" DSL. Your proposal clutters a different top level, which is much harder to document. Ultimately this is a documentation problem more than anything else. We could certainly choose not to document the methods from LockingDsl on QueryDsl if we choose to keep them separate.\n\nI also think having a bit of structure is preferable to just a flat namespace - do you disagree?\n\nI do not disagree, I just haven't seen an API that I think is preferable.\n\nIt's obvious from looking at the nested form what the skip_locked() modifier actually applies to, even if you are not already familiar with it: nested better matches the reality of how the query is executed, which is why it's a bit of a pain to pull those methods up onto the root QueryDsl.\n\nSure, this is the concern I raised in my original comment today. I think it's not an actual concern in practice however, since people are just going to write .skip_locked immediately after the line it applies to.. @diesel-rs/core Need some more opinions here. Brief look over looks fine. I don't like the amount of churn here. I'll try to make some time to give it a more thorough review in the morning.. @Diggsey it is time. I want to change how the trait structure is set up, but that doesn't need to block this PR I think.. Adding a non-defaulted method to a trait in the public API is a breaking change.. I'd like to hold off on this for now. If the motivating use case is nullable_column.eq_any(non_nullable_subselect), I think there's a better solution (possibly #1547, or possibly just adding a .nullable method on SelectStatement, need to look at it more closely). I think this is probably the least ergonomic solution though.. This needs a changelog entry. Probably T: Queryable<Selection::SqlType>, Selection: SelectableExpression<node::table>. Follow the compiler errors and ask more specific questions if you don't understand the constraints it claims aren't holding.. Tests are failing. You're missing AsExpression and FromSqlRow derives. It's being called, and it's failing. @joshleeb Since CI is still red, and there's still a bunch of debug code in there I'm assuming this is still WIP. I'm hoping to release 1.2 this week, so let me know what I can do to help get this done.. Your code has changed the errors that occur. You should look at the differences, if they seem reasonable, update the tests.. Please run rustfmt. Your doctest example is fine, but you're missing #[derive(AsExpression)]. I'd also like to see some tests (not doctests) showing that this can be used in Queryable and Insertable contexts.. > I looked into adding the Postgres geometric operators to diesel\nI really don't know that those belong in Diesel. I think they probably should be in a separate crate. TBH the only reason I didn't close this PR immediately is because these types are in ever PG installation, not an extension. Even with that, I'm still not sure that these types belong in Diesel itself vs a more full featured crate.\n\nThe operator structs are in the public API where anyone can shove any type into them?\n\nIt depends on the use case, but generally yes, we enforce type safety at the point of construction.\n\nThe SQL generated from raw use of operator structs may not be supported by the backend?\n\nNo. Anything that generates backend specific SQL should reflect that in it's QueryFragment impl.\n\nTraits are used to provide builder pattern dsl methods for valid combinations only?\n\nI don't know what this means.\n\nIf you use the .method style dsl then the generated SQL will be valid for the backend, i.e. no operator errors?\n\nWe're talking about backend specific features. It'll fail to compile on the wrong backend.\n\nI am leary to blindly create a trait like PgGeometricExpressionMethods that happens to work for all point -> point -> result operators, but then puts the next person who wants to add another geometric type such as circle into a bind because the trait bounds on my naive PgGeometricExpressionMethods were too loose.\n\nI agree. You shouldn't do that.\n\nA naive forward compatible design would be to just have a separate trait for each geometric operator that is generic over right and left hand side types, with impls for each possible type signature. I would use a script to brute force find valid type signatures for each operator.\n\nI wouldn't make it generic at all. I'd introduce one trait per type that you care about, as we've done for virtually every other type specific operator.. I'll need to think about it more and discuss with the rest of the core\nteam. :)\nOn Fri, Feb 23, 2018, 6:53 PM Yet Another Minion notifications@github.com\nwrote:\n\nHaving another crate for geometric operators is fine with us (what we are\ndoing already). Do you think that crate should be owned by diesel-rs just\nlike diesel_full_text_search or operated by a random third party?\nThe only reason I thought of upstreaming into diesel is like you said:\nbecause these types are in ever PG installation, not an extension.\nI brought up adding the operators because I noticed when writing tests\nthat the Eq operator is not valid for point type in Postgres, but diesel\nlets it compile anyway (fails at runtime with DatabaseError). The runtime\nerror when using schema::dsl::column_name.eq(PgPoint(3,4)) is what I was\nreferring to with:\nIf you use the .method style dsl then the generated SQL will be valid for\nthe backend, i.e. no operator errors?\nPlease let me know if there are any more changes, more tests, etc.. that\nyou would like me to make.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1566#issuecomment-368187648,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK-BclaBfU2GDRDOvnzzLRyQ4dTSvks5tX2uwgaJpZM4SLT_8\n.\n. @diesel-rs/core We never had much of a discussion about this PR, and I think we should -- and that we should do so in public.\n\nI have serious reservations around supporting geometric types in Diesel. Our policy has been that extensions live in third party crates, and while this isn't an extension to PG it certainly has the weight of one. My main reservation here is that any type we deserialize to should be richer than what we provide, e.g. chrono::NaiveDateTime vs PgTimestamp.\nEven if we were to provide a \"primitive\" type with no functionality like we have for others, we get into the question of whether we should support all the various operators for these types in Diesel or not. Again, I seriously hesitate to do that in Diesel. It really feels closer to diesel_full_text_search to me in spirit than something that should live in Diesel itself. I'm also concerned with our ability to maintain those operators, since I don't think anybody on the team is using PG's geometry types directly.. Sounds like there's consensus around this living as a third party crate. I've been thinking a lot about the config file lately, I'll open an issue.. Looking at the tests that had to change, I'm not comfortable with this. Strictly speaking it could be called a minor breaking change, but this seems likely to actually affect apps.. CI is failing.. Oh whoops! Sorry!\nOn Fri, Feb 23, 2018, 5:19 PM Katharina notifications@github.com wrote:\n\nYea, there is a problem with the code I don't know how to solve. I\nmessaged you on gitter about it\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1573#issuecomment-368176880,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK9hPJnh0r9DzpXAhM84gbtuHQMWWks5tX1WSgaJpZM4SPfcY\n.\n. There's still CI failures to be addressed. @spacekookie Looks like there's some minor cleanup left but this looks good overall. I think there's work to be done on the docs for the migration trait but I can do that after merging. Additionally, right now this constitutes a major breaking change. Anybody who is depending on the existence of diesel_migrations::Migration will break. We need to re-export anything moved into the core diesel crate from diesel_migrations publicly.. @spacekookie Sorry for the delay in replies (both on this and your other PR on the website which I still need to reply to). I've been fairly swamped at work and have been mostly away from this project. My understanding is that this is blocked on the PR bumping clippy. I'm not entirely sure why that is, since your CI failures look like what was fixed on master a while ago. Perhaps try rebasing?. I'm at a conference, but one of the other committers can take care of\nmerging. I'd like to see this squashed down.\n\nOn Mon, Apr 16, 2018 at 8:22 PM Katharina notifications@github.com wrote:\n\nPing @sgrif https://github.com/sgrif it builds now! \ud83c\udf89 \ud83d\ude04\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1573#issuecomment-381790395,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWKwQjRoJoyX2lLe8NTqaS5hQonqyCks5tpTW6gaJpZM4SPfcY\n.\n. Duplicate of #860.. > Have we ever written down/settled on a min Rust version policy?\n\nLast time we discussed it, I believe the consensus was \"it's fine to bump as long as there's a good reason\", and that \"makes something easier to implement\" is not a good reason if the thing can be implemented without bumping Rust. So basically any time it's required for a new feature or to fix a bug. We should probably document it somewhere (maybe in the top of the changelog?) I think it's worth also having the policy that patch versions never bump the minimum Rust version.. That's an irrelevant error, the version of clippy we use is tied to a specific nightly, and isn't expected to work with other versions.. I'd prefer not to drop support for older versions of UUID. We should just be able to remove the features = section, as the use_std/std feature is enabled by default.. Ugh. Well I guess let's open a PR that adds a backwards compatibility shim? Otherwise it's impossible for us to support both.. This is blocked on https://github.com/uuid-rs/uuid/pull/157. UUID 0.6.1 was released which does include the use_std feature, so this should be good to go. Can you re-add that feature usage? (I don't think we can specifically exclude 0.6.0 from the range, but I also don't think we need to). This impl is too broad. The failing compile-test is legit.. :-1: from me on this idea. It's too unclear what this does, and I don't think there's an easy way to make it obvious. I don't think it's obvious whether this ignores a database column, populates it on null, or changes the expected SQL type.. With the feature in general. I think this affects more things in non-obvious ways than #[serde(skip)] does.. This has been discussed at length (I think it's usually been in the context of \"I want Rust migrations\" rather than this, but in my eyes the only reason to have Rust migrations is for auto-revert).\nUltimately based on my experience maintaining Rails, I don't think that the value gained by getting revert for free outweighs the maintenance cost of having a Rust DSL for migrations. It's been a hotspot of bugs for Rails for the entirety of my involvement with that project, and the DSL still only handles a small subset of what is possible in SQL.\nThat said, I designed our migration API to allow for other forms of migrations to exist, and have set up plans for how third party crates would add new forms. Barrel is looking like it will be the first external migration system to do that integration. While I'm happy to help implement non-SQL migrations and have the small amount of code in Diesel required to integrate third party crates that do so, I do not think this feature makes sense for Diesel itself at this time.. > Is there any support to separate read and write queries over different connections?\nYes. This would work the same as any other database driver. Create users with read access vs read/write access, and establish the connection using those.\n\nIs there any method to inspect querybuilder-queries or handwritten queries at compile time to see if they are read or write?\n\nNo, there is not.. https://github.com/diesel-rs/diesel/issues/1583#issuecomment-370186178. Sorry, I left out some context from previous discussions about this.\nI don't think there's enough value in a rust-based migration DSL to justify the cost of maintenance. The only argument I've heard in favor of them (other than \"I just don't want to write SQL migrations\", which I don't find compelling) is that you're able to get down for free. I don't think that use case is compelling enough for such a feature to live within Diesel itself. I'm happy to help others implement it as a third party plugin.\nSystems like Django ORM in Python or Data Mapper in Ruby where the migrations are generated from a model don't make much sense for Diesel, since structs which implement Queryable are not assumed to be one-to-one with a database table.. Diesel doesn't assume or enforce that your structs are in anyway tied to table schema. If you wanted to write a library built around that for use with Diesel, I'd be happy to help with implementation questions.. Queryable represents the result of a SQL query, which may or may not represent the entirety of a single database table. Often they represent only a few columns of a table, values from multiple tables, or values which aren't representative of a single database column at all. Or to put it another way, table! declarations are what is one-to-one with your database schema in Diesel. We choose to generate those from your database schema, rather than generating your database schema from Rust declarations. You have to write one of those two, we chose the one which more precisely represents what you actually mean. #[table_name] is used by other traits, but not by Queryable\nOn Tue, Mar 6, 2018, 7:37 PM flip111 notifications@github.com wrote:\n\nI understood the Queryable/Insertable structs to be the value containing\n\"objects\" (the O in ORM). Can table! hold values? I mean the values that\ngo into and come from the database.\nIn the docs i see #[table_name = \"posts\"] i think this annotation does\ntie the struct below it to the posts table. Or is nothing\nassumed/enforced here? No check with the schema (table!)? If not, what is\nthe posts string used for?\nI'm just trying to understand this by the background of another (non-rust)\nORM i used to work with ...\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1590#issuecomment-371002552,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK0NmaCIrNlnhswcFiKRnEnWopcbeks5tb0fvgaJpZM4SfGeV\n.\n. I'm not interested in debating the meaning of the term ORM. Thanks for bringing up your concerns. :). > This issue would not be created if the diesel had all of this great stuff documented.\n\nYou did literally link to the documentation for it one comment ago. ;). See https://github.com/diesel-rs/diesel/blob/master/guide_drafts/backend_installation.md if you need more help.. git blame brings us to https://github.com/diesel-rs/diesel/commit/b7cad847919008f96cde90b74c311d7862ecb645 which gives context as to why it was hidden. That said, I don't know that it needs to be, and I'd be fine with a PR that un-hides it.. CI is red due to #1602. Assuming this is fine if that weren't a problem.. Yes, Macros 1.1 has been stable for well over a year. I think it was Rust 1.17? I know it was by far the biggest release of Rust. It's the reason Serde and Diesel work on stable.. > If so, would you mind, @sgrif, if I closed this PR and opened an issue for discussing this new sql_function macro?\nUp to you. It's your PR. ;). I'm so glad that panics in custom derives don't report as ICEs anymore. I don't understand how this trait differs from BelongsTo. . Diesel's master branch supports #[diesel(embed)] on #[derive(Insertable)]. It'll be easier to just redo this from scratch than to rebase. /cc @dtolnay @alexcrichton\nI don't know if there's any actionable feedback here for either of you, but I think this is an interaction that you should be aware happened. Enabling nightly support for Diesel 1.2 dramatically improves our error messages, and I was planning on actively encouraging people to enable that feature in development. But that apparently now makes us incompatible with Serde which really sucks. I'm not trying to say \"please fix hygiene in Serde now\" or anything, but if either of you have ideas on how I can work around this I'd really appreciate it. Docs should just look like normal rustdocs, not an additional argument in this case. I did spend some time looking at making this work with macros 1.1, and I'm actually not 100% sure that it's possible today, since we'd need to wrap the whole thing in a module, the only name we have for that module is the name of the function, and you can't have a type and module with the same name. We could potentially also change the API if you use the new syntax, but I'm not sure how I feel about that.. > If you mean having the docs above the macro call,\nI don't. I mean having them exactly where they would otherwise be.\n```\nsql_function! {\n    /// Here are some docs\n    #[sql_name = \"heres_an_anotation\"]\n    fn foo(bar: Integer) -> Text;\n}\nsql_function! {\n    #[sql_name = \"note_the_order_can_be_reversed\"]\n    /// Doc comments just get desugared to #[doc = \"...\"]\n    fn bar(baz: Integer) -> Text;\n}\n```. Copying my comments from the gitter convo (and pinging the power rangers):\nI can say with certainty that I intended to make that enum (and MigrationError) extensible, and it slipped through the cracks\n(I wouldn't turn it into a struct, but that's semantics)\n@diesel-rs/core I would like to get the rest of the core team's opinion here. I don't think there's anything we can do without a semver major version bump. I'm opposed to separating the version of diesel_migrations from the rest of the framework, and I'm also opposed to a semver-major bump on the whole shebang. That said, this enum should have been made extensible from the start. What do y'all think?. Yeah, a redesign was originally planned for 1.0 but we agreed that we could \\ deprecate the current API backwards compatibly. That does not apply to types. Yes. In your case that's probably a SqliteConnection. Please have a look at the readme of that crate (https://github.com/sgrif/mysqlclient-sys). If you are still having issues, please open an issue over there.. You might want to give a better motivating example since the one you gave will be 1 hour off from what you expect in most time zones for roughly half the year. :). Seems reasonable. Can you point me at the specific error code and provide a minimal query/code to trigger the error?. Calling the error SerializationFailure, as it does not appear to apply to any isolation levels other than SERIALIZABLE, and that is the documented text for this error in the SQLSTATE standard. I've cleaned up the test case and opened #1839 for the SERIALIZABLE half of this. I'm holding off on deadlocks for now, since that's much easier to demonstrate across multiple backends (maybe not SQLite >_>), but the SQLSTATE code for it is PG specific. You'll need to nest your columns to match the nesting of your structure. For example:\nsome_table\n    .select(((foo1, foo2), bar))\n    .first::<FooBar>(&conn). @diesel-rs/reviewers This needs a re-review. This needed some pretty substantial work.. diesel print-schema will happily output whatever database types you have, regardless of whether they're supported by Diesel or not. There are many extensions to PG which have support added outside of Diesel. You can change the table definition to Text if you want, but you'll run into the same problem that led to the removal of that alias in the first place (see https://github.com/diesel-rs/diesel/pull/1215). You'd need to fully implement it as a custom type, like this test. @Boscop https://github.com/diesel-rs/diesel/issues/1624#issuecomment-379541186. There's no reason that you'd need to do anything related to ExpressionMethods or expressions, just adding a Citext SQL type is sufficient. I wouldn't couple to any concrete types for ToSql/FromSql impls, just allow anything that impls for Text. Thank you for the report. However, making boxed queries Send would require a major breaking change, and isn't likely to happen right now. I suggest waiting until the query has been moved into your closure to box it, or just constructing the query entirely on that thread.. @diesel-rs/core I'd like us to come up with some action to address this, even if it's just documentation. @alexcrichton you may have thoughts on this as well? This problem will end up affecting futures eventually too I think, since y'all deprecate things in the same way. Yeah, unfortunately since #[deprecated] doesn't actually always warn, there's really no other way for folks to determine if they are depending on deprecated code or not. See http://docs.diesel.rs/diesel/macro.sql_function.html to use custom SQL functions.. This is almost certainly due to the use of two versions of uuid. I'm going to close this, as it seems resolved. Feel free to comment here, open a new issue, or ask for help in gitter if you continue to have problems.. Unresolved question: if generating schema fails, should we abort the transaction used to run the migrations? I'm leaning towards no, since we don't have hooks to do so, and we don't run migrations in a transaction on MySQL. @diesel-rs/core Do we have anything left to do on this?. @diesel-rs/core Unless anyone objects, I'm planning on cherry-picking this against v1.2.0 and releasing as 1.2.1 once it's approved. I've released 1.2.2 with a short term fix, and opened #1636 to come up with a better long term answer. Random note (I should probably open an issue for this), I think we need an explicit merge conflict flow, and probably also a CLI subcommand which regenerates the patch file. Another unresolved question which I will perhaps figure out by tinkering with this on crates.io -- Do we want to have the patch file not existing be an error? I think maybe yes if we expect to generate this from a Diesel subcommand.\nAt least for crates.io, where we have the modified schema already committed, and want to generate the patch file (vs the flow for new apps, where they'll have the unmodified schema committed, and then edit it), it was annoying to generate the patch file... So probably?. > I assume it's not possible to ever get import-types to be an empty string? Do you want to add some simple validation that the given string parses as Rust path?\nI'm personally fine with just generating invalid code if it's not a valid Rust path, mostly because I don't think we will ever generate a better error message. We'd probably just use syn for this, and it'll just give us \"could not parse all tokens\" for an error message which isn't exactly helpful.\nI'm not sure I understand the empty string question. ping @diesel-rs/reviewers  This has sat around for a bit. Thank you for the pull request, but we've rejected similar features in the past, as we're not interested in exposing the concrete implementations of our connections as part of our public API.. I'm not sure that it's possible for us to encode this (without a breaking change), but we definitely should be . Is there a reason this can't just call .nullable on the select clause?. Or return Nullable<Subselect<Self>>?. >  but for DefaultSelectClause this will require some sort of wrapper type.\nI don't think so. We should just reify the type when .nullable is called, similar to what we do when you box a query.. This is likely some sort of issue with your installation of whatever backends you're using. Unfortunately, with the information you've provided, there is no way that we could reproduce or provide additional help. Please feel free to comment here with more details if you still need help.. I disagree that this should be handled in Diesel. Transactions that do not explicitly commit will be rolled back when the connection is dropped. This is a problem specific to connection pooling, and should be handled there.. Fixed by #1672 . It's not currently possible. If you'd like to revive #1292 to add this feature, please feel free.. Definitely don't want to deprecate their current location, just want to re-export them in both.. None of our tests should have needed to change for this. > I found sql_name by searching through tickets, not through official documentation.\nsql_name is definitely documented in the documentation for the table! macro. http://docs.diesel.rs/diesel/macro.table.html\n\nThe serde documentation does a good job of enumerating attributes:\n\nDiesel has a much larger API surface than serde. They're able to compress their attributes into a handful of pages because they are all related to either Serialize and Deserialize. By contrast, Diesel has 10 derives, and we aren't even talking about a derive. For Diesel, I think it makes much more sense to document attributes on the trait being derived, or in this case, on the macro that's being used.\nWith all of that said, this was a poor interaction. The reason that this problem occurred is that we have an internal type called Identifier, which is the type of QuerySource::FromClause that we generate for your table. This is actually essentially duplicate of https://github.com/diesel-rs/diesel/issues/851.\nWhile we have 0 control over the error message in this case, we could probably avoid the error entirely by referencing Identifier through a qualified path, and avoiding importing it. We've paid less attention to importing types/traits here, since it's so uncommon to have a capitalized column. But we can definitely fix this specific case. . It's an ongoing project. You can always feel free to ask in gitter for help, that's often how we identify gaps in the documentation. Panics are not exceptions. You should not be catching them in general. There is no reason that normal usage would result in a database connection continuing to be open when a panic occurs, unless you are using connection pooling. I have laid this out in #1646.\nYour argument is like saying that Vec should have special behavior on panics because it can get left in an inconsistent state when using Mutex. Exception safety is the responsibility of the types that cause values to outlive an exception, not the types that have internal invariants.\nThis PR is making the exact same argument made there. Unless there is something new to bring to the discussion, continuing to go in circles is not productive. Additionally, continuing to re-open an issue after it's closed is not acceptable behavior.. Destructors being run is very different from general exception safety. The entire reason that Mutex poisons at all is that types in Rust are allowed to have invariants which get potentially violated in Rust. Of course, any type is required to ensure that destructors are always able to safely run (e.g. Vec has to make sure it doesn't try to Drop an element which is actually uninitialized memory, or free the wrong amount).\nEvery single one of our built-in connection types is !UnwindSafe. They should be assumed to be invalid if a panic has occurred, period. Transactions aside, we internally use other types which are not !UnwindSafe. Making these types UnwindSafe is not something I'm willing to commit to. I'm going to quote the docs for UnwindSafe to make the rest of my point:\n\nTypes such as &mut T and &RefCell are examples which are not unwind safe. The general idea is that any mutable state which can be shared across catch_unwind is not unwind safe by default. This is because it is very easy to witness a broken invariant outside of catch_unwind as the data is simply accessed as usual.\nTypes like &Mutex, however, are unwind safe because they implement poisoning by default. They still allow witnessing a broken invariant, but they already provide their own \"speed bumps\" to do so.\n\nConnection pooling is akin to Mutex here. It is the thing responsible for making a type potentially appear after a panic occurs. Similar to Mutex, it is that types responsibility to implement poisoning to ensure that no broken invariants can be witnessed if that occurs.. When a connection is dropped, the transaction is rolled back. This is the behavior of every database server out there.. > This API from the standard library has an identical contract to the transaction method:\nhttps://doc.rust-lang.org/std/cell/struct.RefCell.html#method.replace_with\n\nAs you can see, it unlocks the RefCell even in the event of a panic.\n\nI'm not sure what you mean by \"contract\". You're referring to undocumented behavior, which could incidentally change in the future. RefCell is !UnwindSafe. It should not be used across panic boundaries, period. Whether broken invariants happen to get observed in one case or another is completely irrelevant, and dangerous to assume.\nFor the same reason, Diesel's connections are !UnwindSafe, period. We use types which are not unwind safe. Changing how transactions behave does not make us UnwindSafe. You should not be using a diesel connection across panic boundaries.. :-1: from me. Semantically, Vec<u8> is not a type which represents json. Can you rebase please?. Nothing new. It's definitely a bug.. This feature has been requested in the past, and isn't something we're interested in adding to Diesel. We prefer the workflow of writing your migrations, and generating your schema from that.. This isn't possible until Diesel 2.0. We may eventually try to generalize \"data source\" as a supertrait of Table, which has no primary key (e.g. views), but tables should always have some form of primary key.. @Diggsey You can just tell Diesel some random column is the primary key. Nope, Mongo is not something we are planning on supporting. . > Multiple generic parameters\n\nWhere clause\n\nNeither of these are supported right now. They're both a PITA to parse. I have a followup branch which handles them.. We don't have any control over the error Rust generates here.. I agree with this comment by a core team member in Gitter. I think you should publish this as a separate crate and see how it goes.. This wouldn't solve your original problem, as the v4 feature would not be enabled since the versions don't match up.. I do not want to re-export every feature of every optional dependency we support. While I can appreciate the sentiment here, I don't think this approach makes sense in Diesel. For most applications, they will likely want to enable at least one feature on the other crates (usually serde). This requires syncing versions. There's really no way around it.. I don't want to add this to the travis matrix. We don't need to rerun the whole suite for this. See https://github.com/diesel-rs/diesel/pull/1302#issuecomment-358111591. A manual matrix addition which runs only the CLI tests w/ bundled enabled once, on stable is enough.. Worth noting that this can't be handled entirely at the connection pooling level, since any implementation of this would have to ensure all reads get directed to the primary when a transaction is open. That said, I do generally agree that this should get handled outside of Diesel.. I reverted the rustfmt bump. This is a reasonable feature request, but isn't likely to get added in the near future. I'd recommend using sql_query for this.. Glad to hear it. :smile:. I actually don't think this would be super hard to implement if someone were interested in tackling it (being able to select a single element of an array would be a good first step). I think this might make sense as an issue for @galuhsahid or @yamishi13 in a few weeks.. @weiznich We cannot safely implement Index for this due to its signature.. Thank you for the issue. Installing from git is not expected to work, as cargo does not provide the tools we would need to make it work. You can install the latest master version by cloning the repo locally, and running cargo install from the diesel_cli directory there.. I am able to confirm this issue.. It looks like the inability to install a local clone was due to a recent change in behavior w/ Cargo when installing a package in a workspace. I could not install on nightly (ac3c2288f 2018-04-18), but I could install on nightly (56733bc9f 2018-02-01). I would open an issue on https://github.com/rust-lang/cargo for that. In the mean time, applying this patch locally should help:\npatch\ndiff --git a/diesel_cli/Cargo.toml b/diesel_cli/Cargo.toml\nindex 2ebe774..c397a6d 100644\n--- a/diesel_cli/Cargo.toml\n+++ b/diesel_cli/Cargo.toml\n@@ -20,7 +20,7 @@ clap = \"2.27\"\n clippy = { optional = true, version = \"=0.0.195\" }\n diesel = { version = \"~1.2.0\", default-features = false }\n dotenv = \">=0.8, <0.11\"\n-infer_schema_internals = { version = \"~1.2.0\", features = [\"serde\"] }\n+infer_schema_internals = { version = \"~1.2.0\", path = \"../diesel_infer_schema/infer_schema_internals\", features = [\"serde\"] }\n migrations_internals = \"~1.2.0\"\n serde = { version = \"1.0.0\", features = [\"derive\"] }\n tempfile = \"3.0.0\". I'm heading out for the rest of the day. I do not think this is a bug in Diesel. If you have more issues, others can help you at https://gitter.im/diesel-rs/diesel. This has pretty much stalled so I'm going to close this. If someone wants to rebase this onto master and push it over the finish line, I think folks are still pretty interested in this general feature (there may need to be more discussion over whether this is the right way to handle it or not). I'm good with changing the terminology, but I'm not sure include is the right term to use, since it's actually saying \"exclude everything not in this list\". Perhaps only instead? I think I'd like to mention table in the option as well. . Can you add a CHANGELOG entry for this as well?. @dreid FYI I'm hoping to release 1.3 tonight, and I'd like to include this PR. If you're able to address the few remaining comments today that would be awesome.. A comment is a poor way to ensure something like that remains true. The tests will unconditionally fail if the fields are re-ordered.. The implementation is complete, this is now ready for full review. @weiznich did you have other concerns with this PR?. Thanks, but there's no SQL type which maps to a 128 bit integer. Numeric is neither an integer type, nor is it limited to 128 bits.. Possibly, but that would require:\n\nMoving away from the actual semantics of the database\nIntroducing a new SQL type, which does not actually exist\nChanging the behavior of sum (breaking change)\nDropping support for older versions of Rust\n\nIt's definitely possible for you to do this in a third party crate though, by introducing a new SQL type, and defining a new sum function with sql_function!.. Would this change serve your use case equally well?\n```patch\ndiff --git a/diesel_derives/src/associations.rs b/diesel_derives/src/associations.rs\nindex e2882fc..8adf70c 100644\n--- a/diesel_derives/src/associations.rs\n+++ b/diesel_derives/src/associations.rs\n@@ -46,7 +46,7 @@ fn derive_belongs_to(\n     let foreign_key_expr = if is_option_ty(&foreign_key_field.ty) {\n         quote!(self#foreign_key_access.as_ref())\n     } else {\n-        quote!(std::option::Option::Some(&self#foreign_key_access))\n+        quote!(std::option::Option::from(&self#foreign_key_access))\n     };\n Ok(quote! {\n\n``. We can useInto` instead.\nimpl<'a, R, T> Into<Option<&'a R>> for &'a HasOne<R, T>\nwhere\n    &'a T: Identifiable<Id = &'a R>,\n{\n    fn into(self) -> Option<&'a R> {\n        match *self {\n            HasOne::Id(ref id) => Some(id),\n            HasOne::Item(ref item) => Some(item.id()),\n        }\n    }\n}. Nope, since HasOne is local you are allowed to assume that !From holds. I think this is what we need then:\n```patch\ndiff --git a/diesel_derives/src/associations.rs b/diesel_derives/src/associations.rs\nindex e2882fc..8028afd 100644\n--- a/diesel_derives/src/associations.rs\n+++ b/diesel_derives/src/associations.rs\n@@ -46,7 +46,7 @@ fn derive_belongs_to(\n     let foreign_key_expr = if is_option_ty(&foreign_key_field.ty) {\n         quote!(self#foreign_key_access.as_ref())\n     } else {\n-        quote!(std::option::Option::Some(&self#foreign_key_access))\n+        quote!((&self#foreign_key_access).into())\n     };\n Ok(quote! {\n\n``. I'm a bit too tired to look at this more in depth. I suspect the trait you have in mind is correct in that case, but it should probably have a name other thanForeignKey. I'd like to look at it more in depth though.. Fun fact: This is from the release notes of 0.2.0, whenget_result` was first introduced.\n\nIn the future, get_result may also check that only a single row was affected.\n\n(We can't actually change the behavior now). I've addressed this in 1.3.0. However, the compiler is hitting an ICE, so there's either a bug in Rust itself or the fork that docs.rs is using. https://docs.rs/crate/diesel_infer_schema/1.3.0/builds/100665 Please open a bug for one of those projects.. Clone is not object safe. We can never make them cloneable. . I think we can just hook this into our normal \"implement this for all tuples\" system. I'm opening an alternate PR. Thanks, but this is a bug in Rust not a bug in Diesel. Please open an issue there. Probably yes. This was just a quick PR, feel free to take over and finish those things. @ivanovaleksey Yes, feel free to clone this branch, make your changes, and then open a new PR. Or just copy the code from here. @ivanovaleksey Were you still interested in working on this?. I'm with @Eijebong on this, I don't think yanking old versions of this crate is a good idea. . I'm not sure how that's helpful. The issue is people with existing 0.16 projects updating Diesel to 0.99 or 1.0 and leaving diesel_codegen there. It's not like they'd randomly decide to go to 0.17.. > So we just need to parse Cargo.toml/Cargo.lock? \ud83d\ude48\nTBH that actually sounds fairly reasonable. I'm not sure I understand your concern. Why would pulling the latest version and running migrations modify this file?. @Diggsey I think that's a good idea, but ultimately unrelated to this PR. :smile: This is just setting the convention that schema stuff should live in src/schema.rs and setting that by default for new projects. As usual, it's easy to opt out of this if it's problematic.. I don't think there was one on Github.. @weiznich You should have all the rights you need to create it. Are we unable to run cargo metadata in a build script?. The .unwraps worry me a bit. I don't want to risk breaking old builds with this. Can we make sure we just return and do nothing if something along the way errors?. Can you edit .travis.yml to run against this branch in your PR too please?. Ah right, we'll need to cherry pick the fix for that.. Yes to both. Thanks, but this isn't something I want to have Diesel care about or try to enforce right now. This is no different than other forms of constraints. You can just as easily have an arbitrary check constraint that we have no way of handling. Additionally, we have no way to try and enforce this at compile time. There's no type that represents a fixed length string in Rust.. I think that a crate which exposes this as public API is better rewritten from scratch. The current API is not something I'm comfortable publishing for external use. If nothing else, it will definitely have to live in a crate with a name other than \"_internals\". @weiznich It's continuing to use 1.3.0 from crates.io. @weiznich You can push this to the appveyor_nonsense branch to get an appveyor run, too. @Deedasmi The problem is that we end up giving the path to patch, which will replace the file not just truncate/append, so our old handle becomes invalid.. @weiznich Can you release this as 1.3.1?. Waiting on CI. This is a new feature in Diesel 1.3. Please install the latest version of Diesel by running cargo install diesel_cli --force.. I'm not sure that multiple print-schema sections is the way to go, but I think we need to support this somehow. Agreed that it would need to support separate filters per schema, and that could definitely lead to the conclusion that duplicating that section is the way to go. However, we could also allow filters to specify the schema in the table name. e.g. filter = { only-tables = [\"schema1.table1\", \"schema2.table1\"] }. I don't think we need import_types be schema specific. There's no harm in having the imports used by schema 2 in the tables from schema 1 99% of the time. I'm sure someone out there has a very specific case where this doesn't work, but... that's what patch_file is for.. You should also be able to send an anonymous record which gets coerced automatically (but this will transmit as ($1, $2) instead of a single bind parameter. See http://docs.diesel.rs/diesel/pg/types/sql_types/struct.Record.html for details.. This isn't really a bug in Diesel, but more a limitation of the language. To fix this we would need disjointness based on associated types, and probably specialization as well. Without those in the language, there's nothing we can do about this. The orphan rules exist for a reason. . @weiznich Has an idea about how to fix this.. @gdf8gdn8 Please do not check \"This issue can be reproduced on Rust's stable channel.\" if that is not the case.. Can we make this a separate test instead of changing the existing one?. Can you provide a minimal crate to reproduce the issue? Can you also provide the output of building with -Z external-macro-backtrace on a nightly compiler?. Is there a specific reason we need any of these changes?. I'd prefer not to arbitrarily churn code unless there's a specific reason, especially WRT things as unstable as syn and proc_macro2. If someone on the core team is reading and strongly disagrees, feel free to reopen.. @Eijebong disagrees. This is using 1.26.1. It's buggy AF. @killercup  https://github.com/diesel-rs/diesel/pull/1743/files#diff-354f30a63fb0907d4ad57269548329e3R49. Fixing this is going to require a major version bump :. 1.3.2 has been released with this change.. Quoting the docs for joinable!\n\nAllow two tables to be referenced in a join query without providing an explicit ON clause.\n\nThe only affect this macro has is decides what ON clause is used when you do left_table.inner_join(right_table). We can't have two implementations of that for the same two tables, the compiler doesn't know what you meant. You will need to provide the on clause explicitly.. @Diggsey The problem is that it's not just a change in behavior, it could cause code which was previously compiling to no longer compile. While I do think that it's incredibly unlikely that anyone is exhaustively matching this enum (there's no reason to do so unless you're implementing a connection), it's documented and part of our public API. Specifically this enum is structured to allow exhaustively matching, so I think it would be against the spirit of our commitment to semver if we can avoid it. (We can avoid it, see #1751). This isn't pub use. @diesel-rs/reviewers Between this and #1744, we have enough for a 1.3.2 release. Need some feedback here. . >  In my opionion this is at least something we should try to avoid\nIt was already MySQL specific, this just makes it explicit. The goal is to remove these in 2.0. They're #[doc(hidden)] for a reason. \n\nIt is technically a breaking change\n\nWe can go the route that isn't technically a breaking change if we want to, but I think that route is actually more likely to break code than this one. The only other alternative is to just leave this broken until Diesel 2.0.. @killercup @Eijebong Based on @weiznich's comments, I'd like to get consensus from the whole team on this.. > Can we maybe do a \"mini crater run\" with known production users?\nNot that I'm aware of. I very strongly feel that there's no way this impacts any production users though. There is literally no reason to ever care about the concrete value of this type, unless you are implementing your own connection. The only code this could/should break is someone implementing an alternate <Connection Backend = Mysql>\nThe only other possible change here that I can come up with is to change the implementation of ToSql for unsigned types to add an extra byte at the end. I think this is the most likely of the options to break real code (there's very little reason for someone to exhaustively match MysqlType, and even less reason to depend on the exact type of this associated type. However, we encourage people to rely on the behavior of ToSql impls).\nI'm not sure I entirely understand your second point, since structs can't have associated types.\nNow that everybody has commented, it sounds like we're all in agreement that the 4 choices we have are:\n\nThis\n\n1749\n\nThis change, but instead of changing the type of <Mysql as Backend>::BindCollector, we instead change the ToSql impl of Unsigned<T> to write an extra byte at the end (aka crazy hacks)\nRelease 2.0\n\nAnd that we are all feel uneasy about this option, but agree that it is the best of those 4 choices. Unless anyone specifically objects, I'll merge this tomorrow and release it as 1.3.2. After implementing this, I'm not sure it really makes sense to have this in Diesel. The use case feels very niche, and not something that I think is worth maintaining in our own codebase -- Especially since you can have this in your own code base:\nrust\nfn nowtz() -> AsExprOf<now, Timestamptz> {\n    now.into_sql()\n}. We're in the process of changing how we handle SSL. I believe I've fixed the issue, but we're waiting for a certificate to be re-issued. If you're still having problems in 24 hours, please open a new issue. HTTPS should be working again on the main site, there appears to be an issue getting it set up for the docs subdomain. I will be reaching out to folks to get this fixed, but it may take several days to resolve. I would recommend using docs.rs if you need HTTPS in the mean time, but it appears the build is broken over there as well... Unfortunately, the only option in the short term is to access our documentation over HTTP. I apologize for any inconvenience this causes. It appears this has been fixed. . It appears this has been fixed. . Looks like this error occurs when Diesel CLI looks for a config file (the default location is in the same place as Cargo.toml). Should we mention the specific version we run against?. I'm fine with pointing people to .travis.yml, my point was just that we should indicate that we're running a specific version that may not be the most recent stable (I don't plan on immediately updating when 1.27 comes out for example). CI failure looks legit. Nope\nOn Wed, Oct 17, 2018 at 4:36 PM Andrew Speed notifications@github.com\nwrote:\n\n\ud83d\udc4b Would anyone object to me working on this issue?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1762#issuecomment-430813228,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABdWK3rLqoa9L0oN2qXb0Bc6C6aGtPS3ks5ul7DPgaJpZM4Uq6Ca\n.\n. I don't think there's anything actionable that we can do at this point in time. Even the comment you've linked to says \"the lang team is looking into this but hasn't made a decision yet\". As far as I can tell there's no compiler that demonstrates a concrete problem here, nor is there any change we can currently make that would address this potential problem today.\n\nIn a few months, if Diesel is unable to compile with stable Rust (which would be a pretty shocking step for Rust to take), please open a new issue.. @Eijebong Any blockers on this?. I spent 10 minutes looking at this issue trying to come up with a pun related to Mass Effect.. Schema inference is doing the right thing. Your column is of type timestamp in your migration, not timestamptz or timestamp with time zone. Your issue in your code has nothing to do with this, you need to change now to now.nullable(). For the record, SMALLINT is not the same as TINYINT but there does appear to be a legitimate omission here. . @diesel-rs/reviewers This could still use review. I'd like feedback on this overall design before continuing further on this.. @mehcode Right now we need feedback on the design of the feature more than the implementation. :). Note that ON DUPLICATE KEY UPDATE is unsafe and can lead to major issues, especially if using replication. For this reason, Diesel doesn't support it and does not intend to. . You'll have to use http://docs.diesel.rs/diesel/fn.sql_query.html. The above comment is likely correct. It sounds like you edited a migration without re-running it, or your schema for some other reason does not match what you expect it to be.. https://github.com/rust-lang-nursery/rust-clippy/issues/2910. It's been fixed on master, you need to rebase. Diesel doesn't currently support .group_by, and for that reason we don't allow mixing aggregate/non-aggregate expressions. You can use the workaround above until we introduce support for group by. This is a known issue in Rust that is caused by #![feature(proc_macro)], there is nothing Diesel can do about it. . Actually I lied, this is because you don't need any of the #[table_name] attributes you've applied. Just delete them.. Thanks, but we don't accept errors that are specific to nightly versions of Rust. There's an ongoing discussion about this and it's not clear what the final direction will be, Diesel will not be acting on it until it's clear what we actually will need to do for stable.. I had mistook this for a different issue, this one does look like one that we can address. The fix may be included in 1.4, which will be released in the next week or two -- But that's only assuming https://github.com/rust-lang/rust/issues/52545 is fixed. If our docs still fail to build, I'll be reverting the fix before releasing 1.4.\nThis is a warning, not an error -- and one that you can easily silence, so it's not something we're going to cut a release over.. You can silence specifically this error with #![allow(proc_macro_derive_resolution_fallback)]. Unless you're writing a ton of custom derives, it's unlikely you'll be getting new instances of this warning.. https://github.com/diesel-rs/diesel/issues/1785#issuecomment-422577018. You should avoid relying on the concrete representation of PG's json types or Diesel specific implementations. Instead you should work in terms of serde_json::Value types, which are already supported, and then call that types ToSql/FromSql implementations.. I have no idea. We build our docs on stable.. You're using 0.16.0, which hasn't been supported for nearly a year. I'm not sure whether this is actually something we should change. It is the trait that maps to the load method, and the only reason you'd be looking at it instead of RunQueryDsl::load is if you are calling it from generic code.\nThat method should be called load, but this trait existed before we broke ExecuteDsl into multiple traits.. Please re-open if this is still an issue once it hits beta.. Actually, it's because the nightly that docs.rs uses is super old and has bugs that have since been fixed.. We don't expose anything that parses your SQL queries for you. You'll likely need to use something much lower level (e.g. libpq or libmysqlclient) which exposes specific details about its prepared statements. It seems like we just need to grab the connection before calling finalize. Based on some cursory googling, error code 1181 means that link.exe couldn't open a library (seems to be libpq.lib). It's likely because it's either not installed, not on your path, or compiled with a different version of MSVC. \nThis is an issue with your local configuration, not Diesel. https://github.com/sgrif/pq-sys has some additional information about how to tell the linker where to find your libraries. . Unfortunately, this is an error generated by Rust in general and not something we have any control over. Feel free to open an issue on the Rust repo if you think this is actionable for them.. (The problem is likely that you forgot an & in the call to values which we do try and call out will generally lead to more opaque than average error messages). The above comment is correct. https://docs.rs/r2d2/0.8.2/r2d2/struct.Builder.html#method.connection_customizer. Thanks to everyone in the Rust IRC for helping me find a solution to this that wasn't UB.. Please rebase onto master. Can you squash and rebase?. See http://diesel.rs/guides/extending-diesel/#custom-operators for examples of how to add new operators to Diesel. You defined my_like to exist on all types, and take any argument of the same type. It sounds like you want it to be only on decimal columns, and only take text arguments. You should write fn my_like<T: AsExpression<Text>> and impl<T: Expression<SqlType = Decimal>>. Feel free to open a PR. embed_migrations! is something that generates code at compile time, not an external tool that is run separately. Having that macro modify a file in your project as a side effect of being compiled would be extremely confusing. Not to mention that there's no guarantee that embed_migrations! will get compiled before src/schema.rs -- which would lead to a compiler error about code that doesn't exist.. > embed_migrations! is something that generates code at compile time, not an external tool that is run separately. Having that macro modify a file in your project as a side effect of being compiled would be extremely confusing.\nThis still applies to build.rs. Here's a much more definitive reason. :) https://github.com/rust-lang/blog.rust-lang.org/pull/264/files#diff-c12c29289690c7837a4a9280fc339f4aR109. #1807. You can assign &*self instead. I don't see any need to implement this for mutable references in general.. I'm fine with adding documentation to these classes for internal use, but I do not want to make them public. Your use case is better served by just using the URL crate.\nlet mut url = Url::parse(&string)?;\nurl.set_password(Some(\"[redacted]\"));. So -- this is an edge case that people definitely run into, but I think this is giving too much weight to it. What do you think about something shorter like \"#[derive(Queryable)] will always assume your fields are a tuple, even if there's only a single element.\" and maybe linking to an example? (Those words can be improved also). Needs a rebase or rebuild for green CI but looks good otherwise. Hm.. This seems more complicated than I had anticipated it being. I will poke at it more on Monday. Ok I see where the complexity comes from. I need to refactor how default select clauses are handled at some point, but this is more what I was thinking for the implementation:\n```patch\ndiff --git a/diesel/src/expression/nullable.rs b/diesel/src/expression/nullable.rs\nindex 2f30e51..5d38acb 100644\n--- a/diesel/src/expression/nullable.rs\n+++ b/diesel/src/expression/nullable.rs\n@@ -1,6 +1,7 @@\n use backend::Backend;\n use expression::;\n use query_builder::;\n+use query_source::Table;\n use result::QueryResult;\n use sql_types::IntoNullable;\n@@ -31,8 +32,14 @@ where\n     }\n }\n-/// Nullable can be used in where clauses everywhere, but can only be used in\n-/// select clauses for outer joins.\n+impl SelectableExpression for Nullable\n+where\n+    Self: AppearsOnTable,\n+    T: SelectableExpression,\n+    QS: Table,\n+{\n+}\n+\n impl AppearsOnTable for Nullable\n where\n     T: AppearsOnTable,\ndiff --git a/diesel/src/query_builder/select_clause.rs b/diesel/src/query_builder/select_clause.rs\nindex 08a714e..9f5046d 100644\n--- a/diesel/src/query_builder/select_clause.rs\n+++ b/diesel/src/query_builder/select_clause.rs\n@@ -1,5 +1,6 @@\n use backend::Backend;\n use expression::{Expression, SelectableExpression};\n+use expression::nullable::Nullable;\n use query_builder::*;\n use query_source::QuerySource;\n@@ -10,6 +11,9 @@ pub struct SelectClause(pub T);\npub trait SelectClauseExpression {\n     type SelectClauseSqlType;\n+    type Nullable;\n+\n+    fn nullable(self, source: &QS) -> Self::Nullable;\n }\nimpl SelectClauseExpression for SelectClause\n@@ -17,6 +21,11 @@ where\n     T: SelectableExpression,\n {\n     type SelectClauseSqlType = T::SqlType;\n+    type Nullable = SelectClause>;\n+\n+    fn nullable(self, _: &QS) -> Self::Nullable {\n+        SelectClause(Nullable::new(self.0))\n+    }\n }\nimpl SelectClauseExpression for DefaultSelectClause\n@@ -24,6 +33,11 @@ where\n     QS: QuerySource,\n {\n     type SelectClauseSqlType = ::SqlType;\n+    type Nullable =  as SelectClauseExpression>::Nullable;\n+\n+    fn nullable(self, source: &QS) -> Self::Nullable {\n+        SelectClause(source.default_selection()).nullable(source)\n+    }\n }\npub trait SelectClauseQueryFragment {\ndiff --git a/diesel/src/query_builder/select_statement/mod.rs b/diesel/src/query_builder/select_statement/mod.rs\nindex b14d05e..3214f76 100644\n--- a/diesel/src/query_builder/select_statement/mod.rs\n+++ b/diesel/src/query_builder/select_statement/mod.rs\n@@ -85,6 +85,25 @@ impl SelectStatement {\n     }\n }\n+impl SelectStatement\n+where\n+    S: SelectClauseExpression,\n+{\n+    pub fn nullable(self) -> SelectStatement {\n+        SelectStatement {\n+            select: self.select.nullable(&self.from),\n+            from: self.from,\n+            distinct: self.distinct,\n+            where_clause: self.where_clause,\n+            order: self.order,\n+            limit: self.limit,\n+            offset: self.offset,\n+            group_by: self.group_by,\n+            locking: self.locking,\n+        }\n+    }\n+}\n+\n impl SelectStatement {\n     pub fn simple(from: F) -> Self {\n         SelectStatement::new(\ndiff --git a/diesel_tests/tests/filter.rs b/diesel_tests/tests/filter.rs\nindex 55612e1..16f1a7a 100644\n--- a/diesel_tests/tests/filter.rs\n+++ b/diesel_tests/tests/filter.rs\n@@ -464,3 +464,87 @@ fn filter_subselect_with_pg_any() {\n         .load(&conn);\n     assert_eq!(Ok(vec![sean]), users_with_published_posts);\n }\n``. I think we might also want to make this a method onQueryDslso we can document it, and give it a doctest.. #44 tracks json operator support. I've attempted to reproduce your issue with the steps provided, and was unable to. As written, the code printsHello, world!. If I add a.unwrap` to your insert to view any runtime errors, I receive this error:\n\n\"column \\\"author\\\" is of type bit but expression is of type boolean\"\n\nA cursory googling shows that the error code you provided is a generic access error on Windows (e.g. their version of a segfault). There is no unsafe code involved in the serialization of booleans, so I suspect this is caused by a misconfiguration in your system, likely in the version of libpq.dll you are linking against.\nSince there appears to be no actionable bug in Diesel here, I'm going to close this issue. Feel free to continue to ask questions here, but I can't guarantee we will be able to help with specific configuration issues. I've found the problem and will have a fix shortly. We will release 1.3.3 with this fix once it has been merged\n. This is something we should support, but I'd like to see more discussion around what the API should be. We 100% need the lifetime declared in belongs_to, but I'm wondering if just belongs_to(\"Foo<'a>\") makes more sense. I think allowing elided lifetimes as the syntax makes perfect sense.. We will not be backporting this to 1.3. Merging with failing CI since this only affects docs (which we aren't building ATM). Thanks!. I'd like some more time to review this in depth, but at first glance I'm not sure how I feel about the approach taken to get around the lack of GATs. I really don't like that we've removed the ability to say <DB as Backend>::RawValue. We've generally tried to encourage folks to use that vs explicit types, as it makes their code less likely to break if the type changes in the future. This ends up breaking anybody using that form.\nThat said, this definitely may be the best/only approach, but I'd like some time to look at it more closely.. So it's clear to me that keeping &DB::RawValue around is possible, but not something we want to do in the long run. 2.0 seems like a reasonable time to change to backend::RawValue<DB> instead.(note: I do think including the module should be encouraged by example, similar to serialize::Input)\nThat said, this whole structure of RefFamily<'a> is incredibly opaque to me, and I think it's overly abstracted from what we're trying to do. The helper type should be a forwards compatibility shim for the eventual switch to GATs at most, not required to even understand what this is doing. I've opened #1976 as an alternative to that piece of this PR, which can be independently merged into master (and will hopefully make this a little smaller for review purposes if we go that direction). http://docs.diesel.rs/diesel/result/trait.OptionalExtension.html#tymethod.optional. Thank you for the feature request. We're currently in the process of a cleanup of the issue tracker, and aren't currently accepting feature requests (there will be an official policy written soon, but the TL;DR is that open issues should reflect something that is a bug or on our immediate roadmap).\nWe're happy to discuss feature requests, but the place to do so is discourse.diesel.rs, not the issue tracker.. > These changes are looking fine on themself, but adding those two impl will not allow a user to really use the enum as custom type, because it is missing the derive of FromSqlRow and AsExpression.\nYes, I tried to keep this focused on specifically the impls for the traits being documented, rather than discussion different levels of abstractions here. It seems like folks generally understand that you need #[derive(AsExpression, FromSqlRow)], but get hung up on how to implement these two traits.\n\nMaybe we should add such an example also to the guide as part of the Extending Diesel section?\n\nProbably a separate guide, but yes.. Last failure was due to rustfmt so I'm going to merge with pending CI after fixing. Thanks for the feature request. I can see why pulling this out of Diesel CLI might be useful for your use case. However, there's a big difference from both a design and maintenance point of view between something hacked together for internal use, vs something we're comfortable supporting as a stable API designed for public consumption.\nHopefully it's clear why providing a public API for this is a lot more work than \"just making this code public\".\nWhile multi-db support is possible with Diesel, it's not a primary goal of the project. For that reason, developing a feature like this simply isn't on the roadmap in the near future. That said, if the code in Diesel CLI today suits your need, and you feel it's acceptable to maintain as a public API, I'd encourage you to take it and release it as your own crate. Diesel might even end up depending on it.\nHowever, I don't see this feature getting implemented as a standalone library any time soon.. Thank you for the feature request. We're currently in the process of a cleanup of the issue tracker, and aren't currently accepting feature requests (there will be an official policy written soon, but the TL;DR is that open issues should reflect something that is a bug or on our immediate roadmap).\nWe're happy to discuss feature requests, but the place to do so is discourse.diesel.rs, not the issue tracker.. > there will be an official policy written soon\nThanks for your patience. . I'm actually going to re-open this, since I think implementing it will be fairly easy and would be a nice addition for 1.4. Go for it. @diesel-rs/core I'd like full consensus among the core team before this is merged. I've requested a review from each of you individually. . https://github.com/diesel-rs/diesel/blob/master/diesel_cli/Cargo.toml#L43. Thank you for the feature request. We're currently in the process of a cleanup of the issue tracker, and aren't currently accepting feature requests (there will be an official policy written soon, but the TL;DR is that open issues should reflect something that is a bug or on our immediate roadmap).\nWe're happy to discuss feature requests, but the place to do so is discourse.diesel.rs, not the issue tracker.. Barrel is a separate project, and is not maintained by Diesel. Please open an issue with that project instead.. I don't think this is worth it. Rust 2018 effectively removes this as an option, since extern crate statements are gone. While it's still technically possible, I don't think we should remove our ability to write use in derives for something that requires writing unidiomatic code to do. I didn't think this justified it, no. The path given is resolved relative to the CARGO_MANIFEST_DIR environment variable given to us by Cargo, which is the only available information we have. If you believe the value of that environment variable is incorrect in the presence of a workspace, that is a bug in Cargo, not Diesel.. This is entirely dependent on how your database works. For SQLite, yes. For other DBs you would need to write an extension for your database server which is outside of the scope of Diesel.. @joelgallant Honestly, we haven't done extensive testing on that. Given that all the databases we support are generally backwards compatible in their wire protocol, I believe we suspect virtually every version of PG and MySQL in use today. We do of course support features that are only available in newer versions of those libraries, and if you're using those features (which you would have to explicitly do), you will need to be on a version that supports it. AFAIK the only backend which we have a meaningful version requirement on is SQLite, because we use a function that's only present in newer versions. I honestly can't remember what function it is or what version it was added in, but I know we didn't work with the version of sqlite that shipped with macOS a few years ago.\nIf you want to do some more extensive testing to figure out what our version support is, I would certainly love to document that. It's valuable to do, but just not something we've prioritized.. Yeah, I'd prefer we not give ourselves a false sense of security here. Crates.io/cargo will not use this lockfile, and we shouldn't pretend it will.. They probably need to be updated. You need to use the type, or fully qualify it as you have everywhere else. Please do not use the issue tracker to ask for help in the future. It should only be used for reporting bugs. Our gitter channel or discourse are the correct places to ask for help.. Unfortunately, this isn't really something we have any control over. It's entirely dependent on your system setup and your linker, which Diesel doesn't interact with at all. It might be worth writing an RFC to add this sort of capability to rustc/cargo. I agree it'd be great to improve this, but it's just not possible today. Since there's nothing actionable here, I'm going to close this issue.. You will need to continue to use #[macro_use] for the time being.. We need to add a test for this.. You could do it as a unit test in this file, or in the CLI tests.. It looks like a lot of folks have already commented with ideas. Ultimately if the difference in performance is a println!, this is not something that is related to Diesel. Outside of \"looks like maybe a compiler bug\", there's not much insight I can offer you. However, Diesel does not interact with stdout in any way, so if the addition/removal of a println! is what changes your performance characteristics, Diesel is not the root cause.. There's a few deeper issues here. The history behind all of this is a bit scattered, so let me give some recap/context here.\nA very long time ago, Diesel had Varchar and Text as separate types. This was painful for a variety of reasons. While they are treated as separate types in PG (though varchar actually isn't anymore, if you explain any query that involves varchar, you'll see it's always unconditionally cast to text), PG has implicit coercions that make them mostly interchangeable.\nHowever, we can't really model those coercions easily in Diesel, due to a combination of limitations of Rust, and our architecture. There's no easy way for us to say impl<T: AsExpression<Text>> AsExpression<VarChar> for T. So this would lead to really funky things like being unable to write text_col.eq(varchar_col), having functions like lower only work with one type but not the other, and a ton of duplication in our own codebase.\nWe fixed this in #288 by just making varchar a type alias. This was a workaround, not a fix for the root problem. We've since encountered similar issues that cannot use this workaround. Numeric types are a major case where SQL coerces, but we cannot (it's much less common for this to be painful in practice though). Timestamp vs timestamptz is another case where the types coerce between each other, but do not have identical semantics, and our \"just use a type alias\" solution would not work.\nHowever, strings are special. This really does (mostly) work for pretty much all string types. These types all have identical representation (contrary to what some folks believe, using char, varchar, bpchar, etc have no benefit over using text. They're all just bytea under the hood). Additionally, all these types have the same set of Rust types that correspond to them. String and str.\nHowever, this has come back to bite us in a few ways. The first one we encountered was that these coercions do not apply to arrays. You cannot use text[] where a varchar[] is expected. This is why we warn in diesel print-schema and friends if we encounter a column of that type.\nThe second issue we encountered is that text always \"wins\" in these coercions. When PG encounters some_string_col = ''::text or ''::text = some_string_col, it will cast some_string_col to text, rather than the text to whatever type that column is. We first ran into this when we attempted to use this same type alias workaround to citext. When we sent a bind parameter as text, it would do a case sensitive comparison rather than an insensitive one. The case here is similar.\nWith all that said, I still don't really know how we can fix the \"root\" problem here. The best I've ever come up with is adding explicit casts for this, which at least gives us an out, but would still make splitting up the string types extremely painful.\nThat said, I do still believe that strings are \"special\", and I think we might be able to improve the situation here for specifically strings. You don't actually have to know the OID of the type you're transmitting in every case, you can also send 0, which means \"interpret this as an untyped string literal\". That might actually be exactly what we want for bind parameters sent for a string type. (Note: an implementation doing this will not be as simple as just changing the OID of Text to 0. There are still cases where we need the actual OID, particularly when sending it as part of an array or composite type). > Will diesel support #[diesel(embed)] on AsChangeset structs?\nYes. I just haven't gotten around to implementing it. IIRC the last time I worked on it, there was a weird interaction between treat_none_as_null = \"true\" and embed on an Option field that I wanted to think about. Feel free to open a PR for this, though.. See http://docs.diesel.rs/diesel/r2d2/type.PoolError.html. You're not the first person to have brought this up. Yellow isn't correct for folks outside of the US, either. It varies by country (though no country uses red as far as I know. :wink:). For a case like this, it seems like just using sql is the easiest solution if you want something lightweight. If you want something that's used in Diesel's query builder, you can certainly create a struct that represents this.\n```\n[derive(Debug, Copy, Clone, QueryId)]\npub struct Now6;\nimpl Expression for Now6 {\n    type SqlType = Timestamp;\n}\nimpl NonAggregate for Now6 {}\nimpl QueryFragment for Now6 {\n    fn walk_ast(&self, mut out: AstPass) -> QueryResult<()> {\n        out.push_sql(\"NOW(6)\");\n        Ok(())\n    }\n}\n``. The error you're getting from the compiler is correct. You're passing it the output stream as the first element of your tuple, which doesn't really make any sense. You haven't included the definition of yourAgentIdtype. Assuming it has anagent_idfield, your first usage ofoutshould beself.agent_id. You will also need to provideimpl ToSql for AgentIdif you haven't already done so.. This really isn't something we can prevent. Diesel as a project is a set of crates which evolve as a whole package.diesel_derivesrelies on internal, private APIs of Diesel, which may change or break freely between versions.diesel_derivesis not expected to work with a different version ofdiesel`. If you're pointing at master for one, you will need to point at master for the other. This isn't something we're able to automate for you.\nNote that your assertion of needing to clone manually is incorrect, you can use the replace or patch sections of Cargo.toml for this, which are well documented in Cargo's documentation.. Duplicate of #860. Composite foreign keys are not supported, but we should be ignoring them, not erroring out. . > Why 2.0? This isn't a breaking change.\nIt's not, but this represents a pretty major change to the \"normal\" way to use Diesel, so I think it makes sense to include it as a major part of 2.0.\n\nAny thoughts on how we want the macros?\n\nDerives should definitely not be a thing the user ever has to think about. They should for sure be exported with the trait in question. Almost all of those are already in prelude, any that aren't probably should be. This is especially important for derives that don't map to an individual trait, such as #[derive(SqlType)].\nAs for the bang macros, I think this should probably be considered on a case by case basis. schema.rs currently does not include any imports. However, that file is usually generated and we can certainly add them. Especially considering that the macros used there (table!, allow_types_to_appear_in_same_query!, joinable!, etc) are unlikely to appear elsewhere in a program (unless it's our test suite or a plugin). \nI'd be interested in seeing an audit of all our public bang macros, and seeing how many of them are likely to appear in non-generated files, how much we think they'll appear in app code vs plugin code, and where we might think to put them. \n\nThe more I think on it, the more I dislike a generic diesel::macros bucket.\n\nYeah, I think I agree with this. Glancing through the list of macros we export today (that I'm honestly not sure is complete because it's shorter than I remember), most of these have a vaguely clear place to put them. e.g. diesel_*_operator can be in diesel::expression (and those are probably only being used in library code). sql_function! is probably the only one that is worth putting in prelude I think. I'm not sure. I'd love to see some exploration here.\nThe only things I could see going into a macros bucket are the stuff called from schema.rs but we can probably call that schema if that ends up being the case.. Sorry XD. Fixed the doc links (apparently intra-rustdoc links don't work on type aliases) if someone wants to merge when CI is green.. Your explanation of the issue makes sense, but I do not think that pretending an embedded migration has a file path is the right solution. Can we try fixing this by handling the None case in impl Display for MigrationFileName?. I'd be interested in hearing more about the use case since any function that interacts with migrations should be calling this already. You don't need this function in order to do that. You can just call run_pending_migrations and it will do this for you. Yeah, let's just fix any_pending_migrations to either call this function or short circuit if the database isn't set up. I'm not sure I understand the use case of running our test suite in release mode. I guess I'm just not following the need to run Diesel's test suite outside of developing Diesel. We ask SQLite for this information, and SQLite is telling us that the column is nullable. I agree that it's going to auto increment the rowid even if you didn't ask it to do so when you try to give it null, but I'm not sure we want to special case this when SQLite is clearly retaining this information.\nsqlite> drop table data;\nsqlite> create table data (id integer primary key);\nsqlite> pragma table_info('data');\n0|id|integer|0||1\nsqlite> drop table data;\nsqlite> create table data (id integer primary key not null);\nsqlite> pragma table_info('data');\n0|id|integer|1||1. Making __diesel_for_each_tuple! public API seems reasonable to me. (Probably not exactly as it is right now). I had meant to name the derive ValidGrouping since the plan was to reduce churn... But I'm also starting to hate that name, so I think we should go with this for the derive, if we do go through with the plan laid out in Discourse we can have a poorly named derive to start, and then rename the derive when we decide on a final name.. Not sure if it's worth an issue since ultimately one of us needs to look into it, I'm not sure we will just accept a PR from someone saying they investigated and it's fine.\nI don't feel strongly about it though if you want to open an issue.. Can you provide a proposal with all the categories described in https://discourse.diesel.rs/t/diesel-2-0-what-goes-here/11?. Unfortunately, without steps to reproduce there's nothing we can do to help. If you're still having this problem, please open a new issue with information we can use to reproduce your problem. A small code sample that demonstrates the issue would be most helpful.. We could consider this for 2.0. BIT and BIT(1) could be inferred as Boolean instead of Binary. We'd need to continue to infer BIT(n) to be Binary for n > 1. > Is there any reason that Diesel returns an error when trying to apply an empty changeset?\nBecause there's no obviously correct thing to do here. We could generate some valid SQL that does nothing (e.g. SET id = table.id), but that would cause triggers to fire which may not be expected. Ok(0) isn't clearly the correct thing to do either, since that number is how many rows were matched, regardless of if the changes requested actually affected anything.\nEven if we wanted to return Ok(0) here, doing so would be rather challenging since the place this error is generated has to return Result<(), Box<std::error::Error>>, so handling this at the connection level would be extremely difficult.\nThe current behavior was introduced in https://github.com/diesel-rs/diesel/commit/579c6934 if you're interested in a little more context.. > Do you have any interest in folding in some of the work I've done?\nWe're not looking to add any new backends into the main project, but we're certainly happy to do what we can to support you if you'd like to develop it as a third party backend. Or are you asking for changes in the mysql backend to support TiDB?. For issues like that, a separate backend is likely a better solution. The backend can share a lot of code with the default MySQL backend, but these things tend to drift apart more over time for different reasons, and trying to keep the same connection for both can lead to a lot of issues (we're planning to create a separate mariadb backend for the same reason). So this problem is beyond left_join. It also happens for inner_join. We can fix this relatively easily for nested left_joins, but for mixed joins I don't see a way we can fix this without overlapping marker traits or disjointness on associated types, neither of which look likely to be stable soon.\nhttps://gist.github.com/sgrif/32710a5f01e1ba36e1ae3fcff2145765 is a compile test demonstrating all the problem cases. We can fix the foo.left_join(bar).left_join(baz) allowing non-nullable columns from bar by changing https://github.com/diesel-rs/diesel/blob/a0c1e297269d3c8c136d3f9d3691d220939f9a95/diesel/src/macros/mod.rs#L45 to be Self: SelectableExpression<Left>.\nHowever, we have the same problem with foo.left_join(bar).inner_join(baz), and I don't see a clear path to solving that case, even with a license to make breaking changes.. We actually might be able to fix this by replacing all of the SelectableExpression impls related to join to be concrete impls for every combination of tables in allow_tables_to_appear_in_same_query!, but I'm worried about the impact that will have on compile times. @aturon @nikomatsakis this is one of those cases I've talked to y'all about in the past, if either of you have some time I'd love to walk you through this issue for us in more detail. If nothing else, we should definitely fix the empty schema file issue.. What's the exit code you're getting?. That would depend on what shell you're using. Google \"{your shell} get exit code\". That is 0xC0000135 in hex, which is a missing DLL. You should have received a popup window telling you what's missing.. Let's just change the return type of the function to QueryResult<Vec<(...)>>. I think this match distracts from the example too much.\n. Why not this?\nrust\nfn users_with_name(connection: &Connection, target_name: &str)\n    -> QueryResult<Vec<(i32, String, Option<String>)>>\n{\n    use self::users::dsl::*;\n    users.filter(name.eq(target_name)).load(connection)\n        .map(|x| x.collect())\n}\n. You can :scissors: this.\n. This one too\n. Can we call this print_sql?\n. We can't test it. Let's have the definition of print_sql! be println!(\"{}\", &debug_sql!(args)), and have debug_sql! return a String. Then we can test debug_sql which is 99% of the behavior.\n. Also this needs docs\n. This needs docs\n. Annoyingly, this means pointing at git for diesel_codegen won't work. However, the compile-fail tests will blow up if I point this at git, as the linker will find two crates to satisfy the diesel dependency (the compile fail tests just look in the build dir for dependencies, they don't have anything fancy like cargo). Basically our options are:\n- Just accept this, and limit people to using the released version of codegen\n- Use sed on Travis to rewrite this line (downside is that running tests locally will blow up by default)\n- Rewrite compiletest_rs to use Cargo\n. I wonder if infer_table_from_schema is a better name here. load implies that we're doing SELECT * FROM to me.\n. This should just call first, shouldn't it?\n. Let's assume stable, not nightly.\n. Probably don't need quickcheck\n. Fixed in dba4399\n. Do you think it's even worth having this in the public API, over the two macros?\n. Needs the ## Unreleased header\n. This seems incorrect. You can sum a float, right?\n. I have one concern with that. If we assume it's always a number, we have a clearly defined way to determine what is and isn't a migration in this directory (for example, we shouldn't error when we see .gitkeep). We'd need to make sure we have a strict definition, as I do want to error in the case where something looks an awful lot like a migration, but is off somehow (down.sql being missing for example). Is ignoring files with a leading . enough here?\n. I think this falls under the same umbrella as https://github.com/sgrif/diesel/pull/64/files#r48106745 -- I think it'll be fine to ignore files starting with ., but beyond that we want to make sure it contains exactly what's expected.\n. If anything I'm actually thinking of moving the other branches down. I don't like having #[doc(hidden)] public functions in the main library, and really the only \"public\" use case I can see is running pending migrations as part of your build script.\n. No, that's what I mean. I'd rather move more of the logic into here and out of diesel proper.\n. These definitely shouldn't implement Expression, they can be used as bind params simply by implementing ToSql\n. You can see the not_null! macro that we use in the other FromSql implementations.\n. I'm unsure how I feel about these. Should we just be handling the timestamptz type separately, and leave timestamp as just mapping to/from NaiveDateTime?\n. I feel like this is wrong...\n. Still :scissors: XD\n. I think the None case is just unreachable!(), since NaiveTime cannot represent more than 24 hours as microseconds.\n. I think this is just unreachable!(\"Received negative time from PG (time should always be positive)\")\n. Actually let's just remove the conditional entirely.\n. Can we indent these similarly to the other lines (and move the rhs to a newline as well)? These will just get replaced once #97 is fixed\n. I almost want to write this as:\nrust\nname.split(\"_\").map(|word| vec![word[..1].to_uppercase(), word[1..].into()]).collect()\nBut I'm not sure if it's better or not.\n. collect is not needed here.\n. Are we able to inline these structs into the test functions? This file is starting to become a dumping ground.\n. If the only problem with doing that is errors about privacy, I'm fine with adding some no_privacy=true options that are internal only to codegen. I'd also prefer to duplicate these structs if they are only used in 2 tests.\n. I'm about to push up a fix for #97, and would like this to be updated to use it before I merge as I'm going to remove query_sql_params. The code for this will be:\nrust\nlet connection = connection();\nlet midnight = NaiveTime::from_hms(0, 0, 0);\nlet query = select(sql::<Time>(\"'00:00:00'\").eq(midnight));\nassert!(query.get_result::<bool>(&connection).unwrap());\nI'll ping you when it's up, probably 5-10 more minutes.\n. These will change to the following structure:\nrust\nlet connection = connection();\nlet midnight = NaiveTime::from_hms(0, 0, 0);\nlet midnight_from_sql = select(sql::<Time>(\"'00:00:00'::time\"))\n    .get_result(&connection);\nassert_eq!(Ok(midnight), midnight_from_sql);\n. Yes, query_sql_params will be gone in a moment. I'll have code up shortly, and you can look at some of the other tests for examples.\n. query_sql might get removed as well.\n. That's not what this means. It occurs during revert if we can't find the migration on disk that the database says we should revert\n. Does error require display?\n. While we may go this route in the future, to limit the scope of this PR, I'd prefer that we did not change this type, and instead had the various methods on Connection return Box<Iterator>\n. I don't think we should require Drop or Sized. I'm torn on requiring Send\n. This shouldn't be in the connection interface\n. This shouldn't be in the connection interface.\n. typo here, double period.\n. No, it allows the macros to continue working if they do extern crate diesel as foo. It's fairly standard practice when exporting macros.\nTechnically all that would break anyway since codegen can't do the same thing. We should probably have codegen do all the things it needs to figure out and then always just call macros from the main diesel crate.\n. And we do the fully qualified names in contexts where we can't assume that use is safe (which is basically everything except table!)\n. Pretty much just that we don't need to write a new function.\n. Even though we have one. XD\nSo not much other than that the new function is slightly shorter.\n. Yeah, it'd probably be better in this case but I don't think it's worth the\ngit churn to change it.\nOn Thu, Jan 21, 2016 at 2:37 PM Mike Piccolo notifications@github.com\nwrote:\n\nIn diesel/src/query_builder/delete_statement.rs\nhttps://github.com/sgrif/diesel/pull/122#discussion_r50468280:\n\n{\n     fn to_sql(&self, out: &mut QueryBuilder) -> BuildQueryResult {\n         out.push_context(Context::Delete);\n         out.push_sql(\"DELETE FROM \");\n         try!(self.0.from_clause(out));\n-        try!(self.0.where_clause(out));\n-        if let Some(clause) =  self.0.where_clause() {\n\nFair enough. I am not a big fan of Tuple Structs because it seems like\nnormal structs could make the code more readable than the implicit integer\nnames.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/122/files#r50468280.\n. I made this private on purpose. We should call into the more generic update_metadata_if_needed\n. Wait this is in migrations.rs. Did I not finish my metadata work? Shit maybe I shouldn't have deleted all my branches\n. Let's not unwrap here.\n. result.map(|r| r != 0)\n. Wait you're using execute... That returns the number of rows affected by a command, which should always be 0 here. I'm pretty sure this code needs some tests.\n. This shouldn't panic here\n. I don't think this function needs to be in diesel proper.\n. I don't think this function needs to be in diesel proper.\n. Right, but execute should not return the number of rows a query would return. At least I didn't think it did. SELECT EXISTS should work here, wouldn't it?\n. Short of adding exists to our query builder (which would be nice), you could do this:\n\nrust\nselect(sql::<Bool>(\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = '__diesel_schema_migrations'\"))\n    .get_result(&connection)\n. Ugh. Ok, can we at least do\nrust\nselect(sql::<Integer>(\"SELECT 1 FROM information_schema.tables WHERE table_name = '__diesel_schema_migrations'\"))\n    .get_results::<i32>()\n    .map(|res| res.size() != 0)\n. Actually it doesn't matter because this will just go away once I redo my metadata stuff because this just becomes get_metadata_version(&connection) == 0\n. This has the unfortunate side effect of causing save_changes::<User>(&connection) to turn into save_changes::<User, _>(&connection). I'll fix this before the 0.5 release\n. Just need to pull this up to a SaveChangesDsl<Conn: Connection> and impl that instead.\n. This was mentioned privately, but just so it's documented publicly:\nThe double underscores are because we inhabit the same namespace as user code, and I always put some underscores when we are able to cause namespace conflicts. I also prefer to put diesel in the name somewhere if it's ever user visible (in this case it isn't). Sam pointed out that DIESEL_DB would be just as good but we basically dropped it there because it's a non-issue.\n. Generally one per row\n. Things that are likely to change for the same reason can be grouped (.unwrap().collect() for example)\n. I'd rather not add a dependency for this. Let's just have this take a Vec instead of an iterator.\n. This style bothers me. Can you change it to\nrust\nfile_names(path).map(|files| {\n    files.contains(&\"down.sql\".into()) && files.contains(&\"up.sql\".into())\n}).unwrap_or(false)\n. Yes, please\n. Quite possibly nothing, as there's currently no case where we'll end up calling as_query() in the context of backend::Debug. However, I've been thinking about logging lately (see #150), and if we do end up using this for the eventual implementation, we'll want to generate the RETURNING clause there.\n. Gah. I thought I caught all of these. I unfortunately need to make this slightly less obvious and simple, and instead have it write to stderr. The most likely case where this Drop would fail is if it's being called as the result of stack unwinding from panic! elsewhere, which leads to nothing other than the unhelpful \"panicked while panicking. Aborting\". This needs to just write to stderr instead.\n. Yes. It ended up being entirely internal, so it made sense to just have this be a c_int on the struct rather than a usize, and skip the coercions later.\n. Do you think that any docs/comments we'd add would clarify more than the slice::from_raw_parts documentation?\n. I have no clue. I've adopted it as my standard name for \"variable which I would have named type if it weren't a keyword\"\n. I'm not sure this is required. This function is already SqliteQueryBuilder#push_identifier. I'm not sure what other information to convey other than that we're escaping identifiers for SQLite, which the method/class name already give.\n. As strange as this might seem, I actually want this code to stick out. This section is part of us shoehorning SQLite into our existing ToSql structure. While I don't think it needs to be fixed as part of 0.5, I do think that we need to fundamentally rethink this structure at some point in the future, and my hope is that having this stick out like it does will help to remind future us of that.\n. Glob importing the crate causes namespace conflicts, and it felt like the most appropriate name to use as a namespace.\n. The fact that this is in backticks makes me feel like this should be diesel database setup. Thoughts?\n. Indentation\n. This function name feels like it describes much less than the documentation does.\n. We're going to need to abstract this soon. Can we not mention postgres here?\n. The migration output should be swallowed, as is all stdout output during tests. I have no clue why it isn't. https://github.com/sgrif/diesel/issues/156\n. This line shouldn't change, unless we indicate that there's a .env file expected.\n. I think this needs to be more thorough or link to the dotenv docs.\n. database url is fine.\n. Also for SQLite this method is literally just \"delete a file\". Which I find kinda funny\n. You indented 2 levels, you should only indent 1.\n. Actually let's just be more vague. \"This will return an error if it is unable to drop the database.\"\n. I don't think drop_database should take a connection. The process of doing this will vary too much by backend.\n. The diff here rendered in a not terribly helpful way. The change was that I renamed our existing insert_with_defaults test to batch_insert_with_defaults, and set it to run on everything except SQLite. I then changed the insert_with_defaults test on both backends to operate on a single record instead of a batch.\n. I think it's too early to make that determination.\n. Maybe use https://doc.rust-lang.org/nightly/std/path/struct.Path.html#method.relative_from here?\n. Two questions:\n- Does this become significantly easier implementation-wise if we make the paths relative to the project root and not $CWD?\n- Do we actually care about it being relative to $CWD instead of project root?\n. Never mind, the definition of \"project root\" is too ambiguous.\n. Could this implementation be simplified to something like:\n``` rust\nlet mut result = PathBuf::new();\nwhile !target_path.starts_with(current_path) {\n    result.push(\"..\");\n    current_path = current_path.parent();\n}\nresult.join(target_path.relative_from(current_path))\n``\n. Ugh. Let's just copy paste the body of it as a bare function, with aFIXME: Remove when 1.7 is stable. I'm just tired of adding and removing underscores.\n. Serial is just an alias right now. If we ever turned it back into a proper type, it would be invalid on SQLite as it's the PG specific name for an auto incrementing integer.\n. This name is hilarious\n. It's probably not the most self-explanatory name if it doesn't appear next to themanageform. I'm actually not sure why these are Rust functions. Hopefully it'll become clear as I read on.\n. Do you think it needs to be said? \n. \"a dotenv file\"\n. Yes, I'm being \"that guy\"\n. Yes,diesel_clidepends directly ondotenv. Since it's a separate crate, there's no reason for it not to\n. It creates two files. However, I think thatup.sqlanddown.sql` can be collectively referred to as \"a migration\". 2 files != 2 migrations.\n. I opted to leave it out, as cargo outputs this for me:\nbe sure to add `/Users/sean/.multirust/toolchains/nightly/cargo/bin` to your PATH to be able to run the installed binaries\nI'm fine with calling it out if you think we should, though.\n. I'm open to suggestions on this one. codegen being a separate crate might be fairly alien to devs from other languages. I don't think I ever really cover what it does, and I don't have a great \"quick summary\" other than \"it generates code\". And I'm really not sure what details to give beyond that, actually\n. I could maybe say something like \"which gives us several useful class annotations, as well as the infer_schema! macro. We'll see both of those soon.\"\n. Good point. I picked run because that's the CLI command, but I like your description better (though we say revert instead of rollback)\n. Yes, they will be in separate panes on the website.\n. This code all runs when used on the code as of https://github.com/sgrif/diesel/pull/175 (which I'm still waiting for a review on. :P)\n. I don't have strong feelings about it, though apply feels weird to me. @mfpiccolo @mcasper do either of you have an opinion here?\n. Wait are you saying \"We can run our new migration\", or are you saying you think we should rename the CLI command diesel migration run?\n. It's in the database with published = false. Maybe I should expand on that more?\n. I guess I assumed that it was implied that \"drafts\" are still saved somewhere (and that the db is the only place that would be)\n. It's just a word for a post that isn't published (e.g. published is set to false in the database.) I set up the example this way to demonstrate that\na. Diesel doesn't fuck with your database defaults (we defaulted published to false in the migration)\nb. To give me a bullshit reason to demonstrate how update works.\nClearly this is too implicit, though.\n. Maybe I need to better call out the published.eq(true) section of https://github.com/sgrif/diesel/pull/181/files#diff-8c27d0d0b409c1de1867fdc9a128c72cR158 ?\n. FWIW I'm not trying to be confrontational or anything, just trying to identify where I need to improve things.\n. :runner: \n. Should this be .and_then(|e| e.first().map(Ok).unwrap_or(Err(Error::NotFound)))?\n. You can remove this lifetime.\n. You can remove this lifetime.\n. Ugh. See this sucks. I really liked being able to stick it into a HashSet like this. :\\\n. This should still return a HashSet regardless. This line should be .map(HashSet::from_iter)\n. Yes, this will go into those little terminal windows with the file name in the top bar\n. \n. \n. I just like leaving unbalanced parens to make programmers feel uncomfortable (for the rest of the day\n. Open to suggestions.\n. This is the most British suggestion ever.\n. We need to tell travis to run both of these, too. \n. We want TimestampExpressionMethods to be hidden. We don't want the fact that we're glob importing PG's expressions to be hidden.\n. I don't see any reason for us to add this alias. I prefer to use the generic name whenever possible (Serial actually does imply something different than Integer and will change to accommodate this in the future)\n. Ah, I see the problem. Our schema inference won't actually work just yet with this...\n. This is fine\n. This is incorrect. A nil UUID still has the appropriate 16 bytes, but they are all zero. None reaching this type is an error, not something the type should be handling.\n. Can you test for a specific value instead of a random one?\n. Can you test for a specific value instead of a random one?\n. The style of a lot of these tests bugged me. I just pushed some stuff up to master to demonstrate what I'd like the style of these tests to look like. Mainly I want the signal to noise ratio to be a bit better.\n. Sorry. :(\n. No, this function never returns. I just noticed it was being used in a strange way on some lines affected by this change, and modified the signature so it can be used with unwrap_or_else instead of map_err.unwrap\n. No, there's no code that is unreachable.\n. -> ! does not type check in these cases.\n. src/main.rs:175:71: 175:85 error: the trait `core::ops::FnOnce<(database_error::DatabaseError,)>` is not implemented for the type `fn(_) -> ! {handle_error}` [E0277]\n. The signature of this shouldn't change. We keep these boxed for a reason.\n. This shouldn't need to change.\n. Code shouldn't get constructed by string munging. Can you move this to a procedural macro that actually constructs an AST in codegen?\n. Again, code generation doesn't belong in the main Diesel crate, nor should we be writing to files. This should happen inside of codegen.\n. This method has a typo.\n. Please make sure the code adheres to the style guidelines\n. Is there a reason we can't use join from the standard library?\n. Same thing here. We shouldn't be creating code using string munging, this needs to go in codegen.\n. There's no reason that this needs to be in the main crate, we can stick this in the module generated for the users.\n. Is there a reason these tests can't go in the main integration test suite?\n. Two requests on this. First, can you put this in a .sql file and use include_str! here? Second, can we do this in a single query with batch_execute or whatever the function is called? The one on SimpleConnection\n. Does this need to be on connection given that it's PG specific right now? Should this at least have unimplemented!()?\n. No, this is fine.\n. While I know we can't test the exact value, can you test that this is setting the timestamp to a later time than before?\n. Does this differ in any meaningful way from sql::<ST>(\"query\").load::<U>(&connection)?\n. You can remove this config, we don't support any other backends.\n. You can just remove this module entirely.\n. We need to support using both PG and SQLite in the same code base. We should do the same thing that we do in CLI here.\n. Can you merge this with the line below? I dislike uninitialized variables.\n. Shouldn't this field just be bool?\n. BigInteger is the proper name for this type.\n. Double is the proper name for this type.\n. The style of this whole section is really wonky. Please add spaces around your braces, and avoid multiline predicates. If something is too long to fit on a line it should be moved to a function.\n. :scissors: \n. Should this just use the not_none! macro that all other FromSql impls use?\n. Do you think it makes sense to have these tests just make an assertion on the Err that comes out, rather than testing the panic with unwrap?\n. This is perfect. Thanks.\n. Sorry, my previous example should have been select(sql::<ST>(\"query\")).load::<U>(&connection).\n. Can you add a usage example?\n. Can you add a usage example?\n. This needs to check SelectableExpression, as well.\n. This needs to check SelectableExpression, as well. Or more likely check that InsertQuery<E, InsertStatement<T, U>>: Query, and add the SelectableExpression constraint there.\n. This removes a lot of type safety constraints. This needs to continue to verify that we're referencing an update target.\n. Change the type to Bool in your table! call\n. Good point.\n. Can you move this out of the main Diesel crate, at least? I prefer not to add code there if it's only needed for codegen or CLI.\n. This is interesting. I wonder if we can pull this into a crate...\n. :scissors: \n. Why change this?\n. Please ensure that your code matches the style guide (spaces before all your braces)\n. I don't like having the enum change to single variant in these cases. We should just have it be a type alias.\n. It's a bug in Rust that was fixed today. Will be in the nightly by tomorrow.\n. This needs to be a struct, not a type alias.\n. No. See my comment above.\n. This shouldn't be required, it's overloaded in .cargo/config\n. Why did this change?\n. Sorry this has taken so long to review, but 1.7 is stable now.\n. Ah, makes sense. Honestly, with this feature added, I'm thinking we might just be able to cut most of the existing \"runtime\" migration functionality, and move it into diesel_cli. Packaging the migrations in the binary feels more rust-like. That doesn't need to be part of this PR though, this is fine for now.\n. Actually, can you move the migrations that you added in this PR to a directory name other than migrations so this doesn't need to change?\n. For match arms it was.\n. Why did you change the format of these lines?\n. Please follow the style that was used before.\n. What was the purpose of this change? There are array types that don't end with []\n. Is there a reason this needed to change?\n. Seems like we could just do a separate query to get the primary key name? (Which is what we ultimately need). This would result in much less code changing to support it.\nrust\nfn primary_key_names(conn: &PgConnection, table_oid: u32) -> Vec<String> {\n    pg_index\n        .inner_join(pg_attribute)\n        .select(attname)\n        .filter(indisprimary.eq(true))\n        .filter(attrelid.eq(table_oid))\n        .load(&connection)\n}\n. I don't think this needs to be on the ColumnInformation struct. Ultimately we pass the primary key name independently of where that struct is used.\nTwo joins is high on the list, but it would be incredibly painful to use until some changes land in Rust or I figure out a workaround.\n. $table_name ($primary_key) (missing space)\n. Maybe put this into a struct?\n. Can we avoid using unwrap here?\n. Why the cast instead of the table_oid function that was there before? (I'd prefer to avoid literal SQL as it's unchecked by the compiler)\n. Format for this should be:\n``` rust\npub fn run_pending_migrations_from_iter(\n    conn: &Conn,\n    all_migrations: T,\n    output: &mut Write,\n) -> Result, RunMigrationsError> where\n    Conn: MigrationConnection,\n    T: Iterator>,\n{\n``\n. This needs a#[cfg(feature = \"uuid\")]. This module should be#![cfg(feature = \"uuid\")]. I'd prefer not to default to uuid. People can enable it explicitly if they want it.\n. Why move this?\n. Please don't reformat existing code that isn't being changed.\n. I don't think we should use thelogcrate here. It looks like it only works with a global logger, which isn't a route I'd like to go down. Since everything would be the same log level anyway, I don't see much reason to take anything other than aW: Write.\n. @mfpiccolo @mcasper Thoughts?\n. If we do go forward with using the log crate for this, I wonder if it would make sense for the other connections just to call those macros directly instead of a separate struct.\n.unwrap_oris coming fromOption, notResult. So we're saying \"if we have a where clause, make sure it's safe to prepare. If we don't have a where clause, it doesn't matter\"\n. Can you elaborate? To make this code uniform we'd need to implementQueryFragmentforOptionwhich I'm not sure is something we want to do for this one case.\n. Ah I thought we were in a different module. Yeah,where_clauseis absolutely at a different level of abstraction in this case. It's treated specially because it's the only case where the equivalent query builder method is append and not replace (e.g.filter(foo).filter(bar)is the same asfilter(foo.and(bar)), whileorder(foo).order(bar)is equivalent toorder(bar)`).\nThe fact that we're boxed makes things a little tricky. Actually making it uniform would require doing something like Box<QueryFragment<DB> + WhereAnd<Box<QueryFragment<DB> + WhereAnd<Box<QueryFragment<DB> ..., and infinitely recursive types like that are illegal. I'm not super happy with it, but don't have a great answer. It's a problem with this module as a whole though, not just this specific method.\n. I elaborated a bit on the reasoning in 5fe68e03\n. Can you just mention this in the commit message instead of a code comment? :smile:\n. This is not a TODO, Many<T> should never impl Copy.\n. You don't think it makes sense to impl these traits here?\n. I don't think the missing_copy_implementation needs to be explicitly allowed here, does it? \n. This type should probably implement these?\n. This type should probably implement these?\n. I don't think we need to explicitly allow missing_copy_implementations here.\n. This should probably implement Debug?\n. This should probably implement Debug?\n. This type would never implement Copy\n. Isn't this one missing Copy?\n. This type would never implement either one of these.\n. I don't think this needs to be explicitly allowed?\n. This type should probably implement these?\n. Copy shouldn't need to be explicitly allowed.\n. Copy shouldn't need to be explicitly allowed.\n. This should probably implement these?\n. Yup. Would normally restructure this code to not need it, but that's basically impossible with this type of macro.\n. What is MiB and friends here? Sizes? Where did they come from?\n. Seems good\n. What do you think about adding clippy to dev-dependencies instead, and changing this to cfg_attr(all(test, feature = \"unstable\")))\n. Lol what\n. I would imagine we'd want it whenever possible since it's a lint pass. I\ndon't feel terribly strongly about it though\nOn Tue, Apr 26, 2016, 2:36 AM Pascal Hertleif notifications@github.com\nwrote:\n\nIn diesel/src/lib.rs\nhttps://github.com/diesel-rs/diesel/pull/305#discussion_r61047346:\n\n#![cfg_attr(feature = \"unstable\", feature(specialization))]\n+#![cfg_attr(feature = \"dev\", allow(unstable_features))]\n+#![cfg_attr(feature = \"dev\", feature(plugin))]\n+#![cfg_attr(feature = \"dev\", plugin(clippy(conf_file=\"../clippy.toml\")))]\n\nI created a new feature so we can control if/when CI includes clippy. Do\nyou think we should just include it every time unstable is tested?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/305/files/9b4d3b77b7c5c046956b10be79757433abbec0b2#r61047346\n. Do you hold the opinions that the current names are better than what clippy wants, or is this just to avoid the API change?\n. By which I mean I don't feel strongly about this enum, and I'd be fine with changing the names for this one.\n. This is objectively a better name. It's worth noting that I named these local variables for parity with PG internally though, which is what this is based off of. https://github.com/postgres/postgres/blob/6928484bda454f9ab2456d385b2d317f18b6bf1a/src/backend/utils/adt/numeric.c#L822-L825\n\nI don't feel strongly about whether that matters or what this should be named, but I just wanted to mention it. We should go with whichever you think is best.\n. I wish Default had fn new() -> Self as an alias for Default. Since we can derive this, and the derived fn will be identical to our explicit new function. Since this struct is purely internal, I wonder if it's worth just deleting our new function entirely and changing the call site to use default. It reads slightly worse, but if we're adding the derive we may as well have less code as a result.\n. This version number makes me chuckle.\n. Can you make this #[doc(hidden)]? In the long run what we need is a better story for using types that aren't provided by diesel from infer_schema! (both for apps, but also for third party crates adding support for things like full text search). However, I'm not fully sure how that's going to be done yet, and I acknowledge that there's no way to work around this in the short term. I'm fine with adding this temporarily, but want to be able to remove it once we have a better story for other types besides \"use table! instead of infer_schema!\n. We shouldn't remove it anywhere except documentation. This line isn't displayed\n. Can you indent this once and add a trailing comma?\n. Hm. This shouldn't be necessary actually, there should be a blanket SelectableExpression impl on FilteredQuerySource\n. Maybe we can just add an order by clause instead? ;)\n. I'd like to see a more \"real\" test here. Maybe users.select(name).union(posts.select(title)).union(comments.select(text))?\n. What about unions on unions on unions on unions? :trollface: #UnionsForDays\n. Good point. I'll probably give the whole changelog a pass before the next release.\n. Can we move these up somewhere outside of the adapter specific modules so there's one clear place it occurs regardless of the backend as long as #[cfg(feature = \"chrono\")] is true?\n. I'd prefer to move this to a separate file\n. Can we put this trait in the pg module? I think we can implement this for sqlite as well by generating expr is not null, expr for nulls first and expr is null, expr for nulls last.\n. SqlOrd is just a marker trait for SQL types which have a defined order, meaning that max and min should be called. It shouldn't affect this feature. A trait for this is fine, but I'd prefer OrderingMethods or something similar that matches the naming convention of everything else here. (I know it's redundant with the module name, but these traits are exported in prelude so I prefer to have them use non-generic names. It's the same reason that everything in query_dsl has Dsl in the name.)\n. Should this be implemented for any T: Expression? It's completely valid to specify this without a defined order.\n. The more I think about it, the more I think that implementing this for SQLite is a bad idea. It should be moved into the appropriate submodule in pg though.\n. I'd prefer to avoid testing the generated SQL, and instead demonstrate the results in a data set.\n. No, that would expand to type Output = <Self as FindDsl<PK>>::Output, which would be infinitely recursive.\n. FindBy is just a helper for Filter<Source, Eq<Column, Value>> which was common enough to justify a slightly more concise alias.\n. This git churn irks me to no end, but there is no way to write this in a way that doesn't churn. I would have added a random semicolon on a separate line if it would have let me keep this comma. YES I AM THAT DRUNK WITH STYLE GUIDE POWER\n. Remove the T: Copy constraint and BAM CHURN\n. This was expanded because the relevant From impls that we were relying on are provided for Box<Error> and Box<Error+Send+Sync>, but not Box<Error+Send>. This seemed like the simplest path forward.\n. This impl would allow the following incorrect query to compile:\nrust\nusers.inner_join(posts).select(comments::text)\n. I double checked that I wasn't missing something, and I'm not. I've explored this change numerous times. We cannot write\n```\nimpl SelectableExpression> for column where\n    Other: Table,\n    table: JoinTo,\n{}\nimpl SelectableExpression> for column where\n    Other: Table + JoinTo,\n{}\n```\nbecause they overlap if Other == table. For your impl to be correct, you'd need to add a SelectableExpression constraint, which would be:\n``` rust\nimpl SelectableExpression> for column where\n    Left: JoinTo,\n    Right: Table,\n    column: SelectableExpression,\n{}\nimpl SelectableExpression> for column where\n    Left: JoinTo,\n    Right: Table,\n    column: SelectableExpression,\n{}\n```\nwhich again, overlaps if Left and Right are the same type, or if column: SelectableExpression<Left> + SelectableExpression<Right>. There's no way to properly resolve this in the language today without a more in depth rethink of this code.\n. No, that trait doesn't exist and it would not be possible to write it today.\n. as_str() returns an InternedString so it needs the additional deref to get to &str\n. (There is almost certainly a better way than this to go from ident to str)\n. Lol I love that the answer there is like \"alternatively, you can load your entire database into memory to work around this issue\"\n. Fair point. I think I'll lie about the place where the signature is Zip<IntoIter<'_, Vec<Post>>, IntoIter<'_, Vec<Vec<Comment>>>> though. :)\n. Can you add a blank line above this one?\n. All methods on traits are public. This is a breaking change.\n. It could probably be changed to\nrust\nfor (index, child) in self.into_iter().filter_map(|child| child.foreign_key().map(|k| (id_indices[k], child)) {\n    result[index].push(child)\n}\nbut I felt it was cleaner this way\nI can't turn the whole thing into a functional statement, as there's no method out there for this. The equivalent in Ruby would be something along the lines of group_by { |child| id_indices[foreign_key] }, but neither Rust nor itertools provide that method (itertools has a method with that name that does something extremely different)\n. I mean the keys aren't necessarily always small. String keys are a thing and the user can do literally anything here. That said, I'm open to using a different hasher if there's a good reason. I'm not sure anything can end up being a security risk here, the worst it could be is a DOS vector since collisions would mean slower execution.\n. Yes. I have to arbitrarily do Child: Clone to write it that way though, since even though it's an empty vector we still only have impl<T: Clone> Clone for Vec<T>\n. I think we can just remove feature = \"unstable\". Quickcheck still hides this behind a flag because they support older versions of Rust, but we don't.\n. If they only have SystemTime behind the unstable flag I would just always have it on.\n. Yes\n. Isn't the table name specified as #[table_name(posts)] on the struct?\n. This is the intended API, not something I want to change.\n. Wait what? That was not true before.\n. No. I'm inclined to just drop custom-derive from the documentation in this case. I'm not happy with this change to the API. This push was also before the macros 1.1 RFC which changes things a lot now that it's landed. Core team is discussing what we want to do.\n. The goal is to provide a single consistent API and for the macro to be useable with or without custom_derive\n. This shouldn't be required, we have a local override.\n. This needs to be bounded. Just 0.43.0 is fine.\n. This needs to be bounded.\n. Has this version been released? Do we need to point at git?\n. Where are you getting 0.7.3 from? The version numbers haven't changed.\n. The code just ended up flowing better handling it up here.\n. This line is way better w/ Macros 1.1 because the quoting library I'm using supports repeations so I can just impl ToTokens on Attr directly and do $($fields)* like I would in a normal macro\n. Also lifetimes are way less of a pain\n. What's with the :?\n. I'm curious if that means that there happens to be a : in the right spot or if the test isn't running. XD\n. This will probably clarify:\nrust\nlet x: Option<&ast::Attribute> = x;\nlet y: Option<Result<bool, ()>> = y.map(|a| extract_treat_none_as_null(cx, a));\nlet z: Result<bool, ()> = z.unwrap_or(Ok(false));\nlet w: bool = try!(z);\n. I'm not really sure there's any way to reasonably simplify it. It's an operation which can fail on a value which may not be present. We can't unwrap_or before the map because we'd have to synthesize an attribute from nowhere, and I don't think we'd want to do that anyway.\n. Ah I see what you mean. \n. Question mark would make it way less difficult to parse. XD\n. Dropping support for Syntex versions is definitely a breaking change. This would need to be in 0.8.0. However, pull requests shouldn't bump the version we'll do it when it's time to release.\n. Do you think we need this since we have the test on load_table_names?\n. Keeping them alphabetical\n. This function is just a straight copy paste from the old crate. I'd like to avoid having an inflector beyond the absolute simplest cases. It's been a major source of pain in Rails, as it's brittle, will never get everything right, and is impossible to change without breaking people's apps.\n. Also admit it you just want to have a function called to_pascal_case\n. I think it makes sense for syn to only provide the AST definitions and parsing, and having a separate crate for the AST builder. I definitely think that abstraction needs to exist. I'm not confident enough in the usage patterns that have emerged to really find the right abstractions yet though.\n. /cc @dtolnay It looks like this is an issue in quote. I can't actually use borrowed data here. Since you're always putting at addr-of in front of the value before iterating over it, it's effectively T where for<'a> &'a T: IntoIterator, which is only true for Vec. It looks like with a separator you are taking ownership of the value though. Worth always taking ownership of the iterator? Do you have a better suggestion?\n. Seems fine. Although since it needs to be assigned to a local variable anyway, the same could always be achieved by sticking a ref or & somewhere.\n. I think the use case for quasi quoting a vector and then using it again afterwards is significantly less than the reasoning behind println! taking a reference though.\n. I avoided that because of the additional rightward drift, and the need for a no-op _ arm.\n. Good point\n. Done and released. Thanks.\n. I tried that, but the compiler didn't figure out to that fn() -> ! can coerce to ,Fn() -> ExpectedType without this. \n. Yeah. cfg can't be used on arbitrary items yet and this code is gross with separate functions for each variant. \n. The _Dummy struct will never appear, it's eliminated entirely during macro expansion\n. No clue. It's probably not safe to rely on, but it was the simplest path forward at the time. This is maintaining the existing behavior.\n. This crate will never be published\n. Added like 6 more &s because I can\n. expect will use the Debug implementation of the error, not Display\n. It's the URL currently on the website. I'd expect that they will make old URLs continue to work.\n. I think it makes more sense here than in the library itself. (e.g. I agree, but I disagree that it should be in the error messages from codegen)\n. Can you expand on what you mean by stability and how we should elaborate on it?\n. Yes.\nFor the record, this is exactly why I am against any \"real\" pluralization logic. It is never going to be correct, and we can't \"fix\" it without breaking people's apps.\n. How about The inferred table name is considered public API and will never change in without a major version bump.\n. Oh whoops that wasn't supposed to get committed. I do that when I need to do -Ztrace-macros\n. Yeah, I'll probably submit a PR upstream.. I know! That's what https://github.com/diesel-rs/diesel/pull/494 was!. I should merge it. I have no idea why this commit made these lints start failing here.\n. T: Copy is basically me saying T is actually &'a T but I didn't want to write &'a T everywhere.. We have a bunch of intermittent failures from needing an order added, would definitely prefer in a separate PR. It affects most of our tests. Actually making me contemplate default ordering.. Derp. If you want to break them out into a separate PR, that's fine. I want to evaluate the issue a bit more before I would merge it though. Either way it should be left out of this PR. As a general rule of thumb we try to keep things small, focused, and easy to review. For example, #508, #509, and #510 could have reasonably been a single PR, but it helps the reviewer a ton to keep things more granular.. &x is preferred to x.as_str(). This still shouldn't need to affect the input type.. I could see the return types needing to change. Unclear on why the input type should have needed to change. There is no case where &Vec<MetaItem> wouldn't deref to &[MetaItem]. Yes, I think so. Interesting idea. We'd need to run it through a query builder, but we have the debug query builder for that. I'm going to do it as a future refactoring.. Yeah, that's why this works. Though the reason I added the default type parameter is because NoDefaultClause is a voldemort type from outside this crate, and we have some test code that references InsertStatement that needed to keep working (at least temporarily). I'll probably add a default for Op as well. I'm fine with explicitly putting NoReturningClause here.. Yeah, I will in a few once I'm done with this other branch. I would love to use Iterator::sum for this, but I don't see a good way to do it without first using Iterator::collect to put it into a Result<Vec<T>>. Yeah I'm just going to submit a PR to make sum work out of the box. Doesn't 'insert: $lifetime mean those lifetimes outlive 'insert not the other way around? A reference can't outlive its data!. Deref coercions don't apply to trait impls. I'm going to do a doc pass on the whole module before we ship. The .returning function is basically undiscoverable right now.. Then this bound should be total nonsense. 'insert should be the shortest lifetime in this list. I have observed that the compiler often doesn't care if I do $lifetime: 'insert or 'insert: $lifetime though.. Me not grammar. That's what I wrote originally, but I felt like it was clearer to just actually say 1=0. I think it originally was because this code was based on the general infix expression code where the members are called left and right. I agree I should come up with a better name for this context.. This is actually a view and doesn't have a primary key. But since we have to specify some primary key, for completeness's sake these three columns combined felt like they should act as a unique identifier. The _ character in a SQL LIKE expression is equivalent to . in a regular expression. \\\\_ is matching a literal _ character in the resulting string.. Added it to the docs. I don't think we need to specifically call out the error case there, as I don't think having a table with the same name as a schema is a common thing to do, especially for tables in public. If the error did occur I think it's pretty self-explanatory what happened.. That's what the link currently goes to?. Oh markdown is fun. I also had a link with the [insert] label in the release notes for 0.2.0, and that link is overriding this one.. Fixed on master. You're right on the syn side. libsyntax definitely doesn't have that impl though.. Yes, but I quite frequently end up adding fields to these things, so I've been consistently writing it like this (and never relying on the return value of the last delegating line) to make it easier to add more fields in the future with less diff noise. Nah, I've been using it in a few places when it feels better than try!.. And actually it's 70k binds. XD. Can you change this to avoid absolute URLs? This will eventually break when we start hosting past versions.. Same nit here on absolute links.. Same nit here on absolute links. Although this definitely makes me think we need a way to say \"root of the docs for the current version\" easily.. I usually get these by querying the pg_type table FWIW. Eventually I'd like to just load these dynamically, as they technically aren't supposed to be assumed stable (in practice they are though other than user defined types so it's very low priority and possibly not even possible with the rest of the project's goals). Do you think we should call this type JsonB and have #[doc(hidden)] pub type Jsonb = JsonB to make schema inference happy like we do for VarChar?. I wonder if we should add an everything feature so we use that here (which would also reduce churn in the travis scripts). I think you mean serde_json_value_from_sql here.. r#\"\"\"# is more characters. ;). You can just write Fn(&str, Box<Error>) here. Taking an error handler function seems unideomatic compared to returning an error.. I want to completely rewrite this at some point. I seriously doubt that this function should be operating on token streams at all. But for now I just wanted to get the minimum possible change for the user visible changes.. This function is expected to be able to handle strings containing multiple SQL statements.. Can this be phrased as a description of what the trait does, rather than a command?. How about \"The backend this connection represents\"?. utf8mb4. Because why would you have utf8 be the thing that adheres to the unicode standard?. It's the equivalent of the client encoding setting in PG as best I can tell. It's the encoding used for non-query-result data. Specifically I'm setting it here because it's the encoding used for all of the parameters to mysql_real_connect.. As mentioned in the comment above, this should never happen unless there was a linker error. I'll add a description though.. Ugh. You and your links.. The error code is useless as best I can tell ATM. The FIXME comment is to figure out what to actually do here.. \"/lol_no_schema/at_all\" is not a valid URL. We don't support connecting to unix sockets at the moment.. :+1:. Added a message. I'm leaving at as an actual assert and not just a debug assertion though since failing to successfully set this option could cause safety issues.. But you just said that you would link links. ;). I'm going to do it as a separate commit. I need to rebase something off this branch to open a PR. Second paragraph of the commit message is addressing that case. I don't want to go further than the naive approach until I better understand the case it's describing and can test it.. None means that the bind parameter is going to be populated with SQL NULL. We're not dealing with mysql_stmt_bind_result yet, just mysql_stmt_bind_param.\nSince the value of the buffer is None, self.is_nulls[i] will be 1, and self.lengths[i] will be 0. The value of buffer and buffer_length are both 0 since we initialized the struct with zeroed memory (I don't think any of that matters though as long as self.is_nulls[i] is non-zero). I think I may change the type of data to just be Vec<Vec<u8>> though, since we'll always want a buffer for the mysql_stmt_bind_result case. Since Vec::new doesn't allocate, it should be fine. (This will also make it easier to do an eventual refactoring that I'd like to do for RawBytesBindCollector where it puts everything in a flat Vec<u8> and then has a Vec<Option<usize>>)\nEither way I won't make that change until we're dealing with mysql_stmt_bind_result.. Ugh, fine.... Actually I like the code better with that change now. Yeah, boolean expressions in MySQL are transmitted as MYSQL_TYPE_TINY which corresponds to signed char. For codegen I will infer TINYINT(1) to mean bool, yes. I don't really want to define/care about the behavior of a > 1 byte type being used here, but I think your code is actually easier to read anyway. Hm interesting point. If nothing else, mysql_binds will always need to be in its own vec.. Type inference is doing that.. Errors is none if this is an input bind, some if it's an output bind. This method makes no sense in the context of an output bind. Honestly, I should probably just separate these into two structs. There's basically no shared code other than that one function to link up the pointers.. The only time we'd be in this branch where that wasn't true was a bug in the MySQL C library. Since there's no memory safety violation if that bug occurred (it'd probably just abort with OOM), I don't think we need to defend against it here.. Was true before this as well. This is needed because the call to reserve above is invalidating the previous pointer (Forgetting this line was the cause of the segfault I mentioned in gitter). set_len can never leak memory. It only affects whether destructors are run for the values in the vec. In this case, the values are u8 so it's meaningless. The amount of memory used is defined by capacity, which we don't touch. I don't want to use truncate or shrink_to_fit, because we'll likely just have to re-allocate on the next row. This code re-uses the buffer for each query run (deallocating after the last row is processed). Same answer. Not for this one. enum_field_types::MYSQL_TYPE_TINY => stuff() will run stuff if the value is equal to MYSQL_TYPE_TINY. MYSQL_TYPE_TINY => stuff() will run stuff for all possible values (and also fail to compile since we have #[deny(warnings)] and using a catch-all ident which matches an imported name in a pattern warns). The lifetime is the 'a referenced in the Self::Item type, which is the lifetime of the RawResult reference we are holding onto, which is the actual correct lifetime. The fields are fully disjoint, so we don't need any sort of streaming iterator abstraction here.. I personally think this way is easier to read, but I don't feel strongly. I should change the impls of SqliteRow and PgRow to use that form as well, so I'll do it in a separate commit.. Fine. :P. I'm going to explore this, but if I end up going that way it'll be a separate PR as this one is large enough as it is.. I'm assuming this is some sort of system specific thing? This should go in your global gitignore, not our project's.. This could also be written as for (i, (data, bind)) in self.data.iter_mut().zip(&mut self.mysql_binds).enumerate(). Thoughts on which is nicer?. Doesn't matter, I end up deleting this in the next commit.. This is literally the same code as the sqlite impl, but I don't think it's worth making a macro for 2 cases.. I'm going to pull out separate determine_column_type functions for MySQL and PG, as there's several cases I want to handle. This is required to turn things like int(11) into int for now.. I'm going to apply this pattern to the entire codebase soon. One env var is great for CI, terrible for local development.. We still need one to win if both are enabled. I can probably make the error message more generic and just have it be not(cfg(feature = \"sqlite\")) in the future.. I have to put something here. MySQL doesn't allow TEXT PKs (because reasons I guess?). 255 has always been the go-to size since the length fits in one byte. Are you suggesting we go up a power of two?. :+1:. Fun fact: By default, it won't even error in MySQL. It'll just silently truncate the data with no indication that anything is wrong.. (The (255) does nothing in SQLite and PG.). Since tests fail by panicking, that would be bad in any project (I'll bet cargo test sets panic=unwind even if the project is configured with panic=abort). If this were public API or if it were anywhere that we cared the slightest bit about performance I would do that.. Yeah, I'll test it more thoroughly after I refactor a bit more.. Will do on master. \u2702\ufe0f . What's this array actually doing? Are we sure we want to allow this? For example I named everything Mysql instead of MySQL to be ideomatic. I would assume we want the same to apply to other backends.. This still errors since we have deny(warnings) right?. Isn't this redundant with https://github.com/diesel-rs/diesel/pull/305/files#diff-7ab3c70a207718b2fce878a8f925a415R22?. Isn't this redundant with https://github.com/diesel-rs/diesel/pull/305/files#diff-7ab3c70a207718b2fce878a8f925a415R22?. Isn't this redundant with https://github.com/diesel-rs/diesel/pull/305/files#diff-7ab3c70a207718b2fce878a8f925a415R22?. What's the lint that led to the unwrap_or_else change? ptr::null_mut is a const fn so it probably shouldn't be complaining here.. Heh. I need to refactor this.. The computer is on fire. :). https://github.com/Manishearth/rust-clippy/issues/1527. We should probably enable this for the whole file. Now that I'm more familiar with the wire protocol, I know why libpq is giving us this as a c string. And it's really dumb.. We should probably enable this for the whole module.. Wait did clippy not break on this one?. I named this variable for parity with the pg code which is the \"documentation\" for this structure. I don't feel strongly on whether we need to keep it or not.. I think we can derive this.. Isn't this redundant with the line in lib.rs?. I think we can derive this. Isn't this redundant with the line in lib.rs?. Eh. We may as well just change that line to b\"string lit\". Also there's a typo in expected on that line, too. I don't think you meant to make this change.. Should we enable this for the whole file?. Spaces?. Should we stick this in a file that we can include! in all the crates?. If anyone were using PgDateTime, PgNumeric and friends or the interval DSL and wanted to test stuff involving it, yes. But I agree it doesn't warrant inclusion here.. Why add this? Nothing is going to compile with TestConnection = () anyway.. Can you please make more of an effort to not add random whitespace and empty lines in your pull requests?. Ah, I see. We should probably add MySQL then. Do we actually need the two lines above this one? NaN probably should be in backticks when it appears actually.. Does this need to be locked down to =0.0.114?. Not sure. Let's just try it and see what happens. I'd put it in the project root directory and call it make_crate_pedantic.rs. Though CLI should probably continue to allow things in release builds so that random lints added in future versions of Rust don't cause the binary to stop compiling.. Does Result::<String, Error>::is_some still read nicer to you?. . Yeah, I'm really not worried about the 40 byte overhead there. I do want to split the two caches into separate maps though since the TypeId can work with a phf which will reflect perf-wise. Probably, yes. (I actually don't mind third party connection adapters using this, I just don't want to commit to stability with its API). Yeah, probably because of the bounds. #[derive(Default)] will require adding it to every value of DB that we want as well (which is nonsense and not required, but rustc's derives are kinda dumb). Oh I thought you had made bin/test do clippy as well. I'll stick an allow on here, no point in adding an unused method.. macOS ships with libpq, but it does not ship with a postgres database. Most people will need to install postgres to get it running.. They'll also need to set MYSQL_UNIT_TEST_DATABASE_URL to a different database.. Not sure how I feel about recommending that they run as root. I think we should probably mention how to not run as root even if we continue to say root in the .env example. Something like:\n\nIf you didn't specify the MySQL user to be one with elevated permissions, you'll want to a command like mysql -c \"GRANT ALL ON \\diesel_%`. TO ''@'localhost';\" -uroot, or something similar for the user that you've specified.. In the closure we have a life mutable reference (which came from a refcell). Trying to get an additional reference would panic. I could pass a reference to the cache to the closure but this felt better.. :+1:. It's only 6 lines of code. I'd rather keep the normal Rust code which is easier to understand.. Actually this just reminded me that I wanted to addError::RollbackTransactionfor those times that you don't have an actual error but you want to rollback the transaction. I may as well do that now.. I can link to the line in the source code? There is no documentation on this. But we also have https://github.com/diesel-rs/diesel/blob/3d985d717b0caaad931464e8a658c1f73bc9a57e/diesel/src/pg/types/array.rs#L54-L56 ;). Would you like me to link to https://github.com/postgres/postgres/blob/82f8107b92c9104ec9d9465f3f6a4c6dab4c124a/src/backend/utils/adt/arrayfuncs.c#L1461 ?. It used to be, yeah. I don't know when it stopped being used.. Still true.. I think there's a more fundamental issue with how types likeOptionandResultare able to compose. Adding moretry_methods is a bandaid IMO. I think this is most apparent with deref coercions. If I have aStringand want to call a method that takes&strI just write&s. If I have anOptionand want to call a method that takes anOption<&str>I have to writes.as_ref().map(|x| &*x). Pattern matching also makes the issue quite apparent.. Yeah, it claims thatstatement` is dropped with a life reference. Which is wrong, borrowck should know is wrong (even without non-lexical lifetimes), and I think is probably a bug in rustc. FWIW this also compiles:\n\nrust\nlet x = StatementIterator::new(statement_use).collect();\nx\nBut clippy doesn't like that one.. Honestly, no real reason. #[derive()] feels more attached to the item, while #[allow] feels more attached to the block of code. . Actually it derefs the reference to the RefMut, and then the RefMut itself.\nx: &RefMut<T>\n*x: RefMut<T>\n**x: T\n&**x: &T. This line is displayed in the rendered documentation, and thus is the right level of indentation (There is a removed #). It won't render the trailing space >_>\nIt's a # and a .. Same answer.. I don't think it would ever make sense for this type to be used with Default?. Oh you're right, my mistake.. Oh you. I wonder if we can use cfg_if! here? If not, you'll need this to be all(feature=\"postgres\", not(feature=\"mysql\")) to avoid warnings.. \u2702\ufe0f . Probably worth doing use schema::posts::dsl::*; for this. Let's replace diesel_demo_step_x_mysql with self on all of the lines other than use diesel_demo_step_x_mysql::*. We shouldn't hard-code the travis user here. I'd leave the user off and see if CI complains. If it does, let's only set this if TRAVIS_RUST_VERSION is unset.. Yes, I keep a separate branch that I can just push to for when I need to debug CI things. On travis it's called \u0ca0_\u0ca0 but Windows doesn't like unicode.. Nice. Yes, the whole thing will need a lot of documentation if merged.. Yeah, this is the thing that should be called Cents. It looks like you're never using this struct. Can we just delete it?. MySQL accepts this as valid syntax (since it's part of the SQL standard), but it's ignored. The proper way to create a foreign key in MySQL is\nfk_id INTEGER NOT NULL,\nFOREIGN KEY (fk_id) REFERENCES fk_inits (id). setup already does this. We don't need to add a new command for it.. If there's something going on with our test suite that requires recreating the database every run, we absolutely need to fix that. This is not an acceptable solution.. The examples should be dropping and recreating their databases, since \"create a migration and run it\" is part of the example. The test suite however should not leave behind any state. I don't think that requiring a single command to be run to create the database before running the test suites is a major issue, and it means that most of the test suites do not need to assume that they are running as a user with elevated permissions.. The examples aren't meant to run against the same database as the test suite. We should probably change either CONTRIBUTING.md or the database used by the examples to not conflict.. Actually I'm not sure I fully understand the issue you ran into. We hard code the database for examples here. My point was that we just need to make sure that it doesn't conflict with the example URL given in the CONTRIBUTING document, but it already doesn't. Something else is wrong if the examples were running against your test database.. Ah sorry, I guess I missed that. I'm fine with adding another set of env vars, but let's have it fall back to the defaults set today if the env var is unset, since the number of environment variables required is getting quite large.. I figured I'd just lay out the docs now. It really only matters for full queries, not for little pieces like this.. We'll want to export this as both.. Can we change this to \"Cents (also aliased as PgMoney)\"?. Heh. I wouldn't have even thought to do this. Thanks. ;). The impl is trivial enough that I don't think this is necessary, as long as we have an entry in diesel_tests/tests/types_roundtrip.rs. Same here, we don't need this test.. We do need this one. :). The docs currently say: \"The associated type is usually the same as Expression::SqlType, but is used to indicate that a column is always nullable when it appears on the right side of a left outer join, even if it wasn't nullable to begin with.\". Is there more to say about nullability? (I'll be rewriting the docs when I remove the associated type). So I'm assuming I wrote this before you joined because we've not discussed this before. I'm curious on your thoughts though. I do write the types out explicitly in the struct definition because I think it's important to give them meaningful names. All of my usual principals say to use the full names, here, but this is what the code looks like.\n```rust\nimpl<\n    'a,\n    Select,\n    From,\n    Distinct,\n    Where,\n    Order,\n    Limit,\n    Offset,\n    Groupby,\n    DB,\n\nInternalBoxedDsl<'a, DB>\n    for SelectStatement<\n        Select,\n        From,\n        Distinct,\n        Where,\n        Order,\n        Limit,\n        Offset,\n        GroupBy,\n    > where\n        DB: Backend,\n        Select: QueryFragment + SelectableExpression + 'a,\n        Distinct: QueryFragment + 'a,\n        Where: Into + 'a>>>,\n        Order: QueryFragment + 'a,\n        Limit: QueryFragment + 'a,\n        Offset: QueryFragment + 'a,\n{\n    type Output = BoxedSelectStatement<'a, Select::SqlTypeForSelect, From, DB>;\n\nfn internal_into_boxed(self) -> Self::Output {\n    BoxedSelectStatement::new(\n        Box::new(self.select),\n        self.from,\n        Box::new(self.distinct),\n        self.where_clause.into(),\n        Box::new(self.order),\n        Box::new(self.limit),\n        Box::new(self.offset),\n    )\n}\n\n}\n``. Whoops, I didn't mean to add this here. I was trying to figure out whybin/testtwice no longer runs the second time with 0 recompilations and I think it's because crates are recompiled with/without clippy, but the doctest dependency ondiesel_codegenindieselbreaks everything (as usual. What else is new). Also this struct *really* makes me want associated types for structs. Even though that's a nonsense idea.. Also @nrc if you want a pathological case for rustfmt discussions, see the code 2 comments up..OfCourseYouWouldHave. Probably, but I want to document a real use case here. The doctest wouldn't add anything useful over the existing tests (other than ensuring the example works of course, but meh...). I'm open to suggestions. When it was just table name and optionally the primary key, the macro rules themselves were pretty self documenting. Agreed it's obscure now. Do you think there's another syntax which is more obvious? Or are you just saying we need to document the full syntax better?. Should we specify the message here?. I think we should specify \"including release mode\", since that's where this differs from the default.. Indentation is funky here..new_url.to_string(). Indentation is off. If it's not required why do we need it at all?. You're right. I should mention that Diesel provides diesel as well. And also the things that Diesel provides.. If this were every actually rendered, it'd be the third h1 on the page and my 8 years out of date SEO skills say that there should only be one h1 per page. No, because the line above is an assertion on<=.x <= y && x >= yimpliesx == y. It's technically more correct, but my reasoning was actually \"this is less typing than#[allow]\". That's an odd database url. ;). This makes the test significantly harder to read for me.. I'd rather we just create a table specifically for testing this.. If nothing else, this error message should more specifically state that the reason this is treated as an error is that the bigdecimal crate does not provide support forNaN, not that Diesel wishes to treat it as an error. This is the correct answer. And while breaking changes are allowed since we're still pre-1.0, I would like to keep this function as is. Most of these functions have thedo_thinganddo_thing_in_directory. This name is too generic for us to export. You shouldn't need to export it to use it from another module. . \u2702\ufe0f . Why the function name change?. Probably just due to module ordering. I'd just move the definitions here instead of the PG module and add another cfg attr. These should be specifying the backend, shouldn't they?.&& trueis a no-op in all cases. We are only assigning when the value isfalse(which is the only time the value could change). Because I wrote the first third of this, stashed it, wrote three other prototypes which all turned out to be dead ends, rewrote a sixth of this, remembered that I had a stashed partial impl of this version, and had merge conflicts because I switched styles in the second one. I'll fix it lol. What do you suggest? The only other options I could come up with are printing to stderr or panicking. The first is untenable, and I've become more hesitant towards the second. Ultimately in this particular case the worst that could happen is we skip prepared statement caching, which is why I went this path. Interested to hear your thoughts.. I've been shying away from adding those constraints earlier than needed unless there's a concrete case where it improves errors. I'm not sure that it would do so here.. Merge conflicts. merge conflicts.... Could refactor to a higher order function that takes afn(Project) -> WhatEverRunReturns` pretty easily I think. \u2702\ufe0f . \u2702\ufe0f . This seems like a weird condition to me. Why do we want to handle the case where the expected path exists but is a file/symlink rather than a directory? It seems like just checking whether it exists would be more clear.. \u2702\ufe0f . \u2702\ufe0f . Unsure how much it'd be inconsistent with the rest of the codebase, but lately I've been preferring this style:\nrust\npub fn if_exists(self) -> Self {\n    DropDatabaseStatement { if_exists: true, ..self }\n}. Lol good enough. \ud83d\udc4d . I think we can actually just do t.into() now.. Yes. I think we will need to stick #[inline(always)] on the impls for tuples and SelectStatement, as I believe that both of them are currently considered too expensive to inline and are extreme hot paths. I was planning on leaving that for a separate commit though. . I tend to leave these to note that I am intentionally doing nothing in the else case. If we think they add little value, we should probably remove them across the entire code base. Ironically I originally had that, and then started to go down a path where .bind appended the actual bind parameter SQL, and then decided that it was a bad API and scrapped it and forgot to add the docs back. I think it was stable in 1.16. I can change it here. I'm not generally super concerned about which stable version we support though (will want to come up with a concrete policy once we're 1.0). Yes, we should be panicking inside of codegen and never getting to the Rust macro. I feel like it should be possible to return IncompleteInsertStatement<DefaultValues, Insert> where DefaultValues implements Insertable for all tables rather than introducing a whole new query type for this. Wait seriously? MySQL doesn't support this? . The second sentence is misleading. I'd change it to: This will cause problems when using Diesel.. Once all of this is merged and stable functionality-wise, I think I will replace Succ with Once and MoreThanOnce just for the minor improvement in the error messages.. I'm not sure I understand the question here? This is basically just saying that both counts are either Never or Succ.. Because they're the same type. This is where we say a table contains itself exactly once. If we can get the changes we need to specialization, I'd have these two blanket impls instead:\n```rust\nimpl AppearsInFromClause for U {\n    type Count = Never;\n}\n// The table constraint is to make this impl disjoint from the impl we provide for Join\nimpl AppearsInFromClause for T {\n    type Count = Once;\n}\n``. Good point. Will fix.. I'm happy to put aThankYou` at the end if you think the current name is too rude. I don't know. I need to discuss w/ some folks. If nothing else, I don't think this doc comment is likely to get out of sync with the code.. Yeah, that was why I haven't opened an issue. I figured the answer would either be \"this is intentional\" or \"this is blocked on chalk\". :D. Yes. Apps should never need to call this. Period.\nI like it. It's forceful.. LoadQuery implies LoadDsl, but we need to explicitly mention it here in order to make this impl disjoint from the sqlite/mysql ones.. \u2702\ufe0f . Can you add a blank line in between each branch here?. Do we need to match on doc this early? If nothing else it seems like this could just be doc = $doc:tt -- but it seems like we could just not stick the doc = [] until we get to that point. Also not sure why we're collecting doc into a repeater, but I guess I'll find out.. This is specifically the table level documentation, right? Is it even possible to have more than one of these?. Can we make it clear in the name that this is table level documentation?. What is \"the next parsing step\"? What is the current parsing step? . Same thing here. What is \"the next parsing step\"? What did we just finish?. There are places that it is passed to a function which expects something which implements Write. I could manually add &mut *out to those places, but the goal of this version is to avoid churning lines which don't need to change.. > I don't see any advantage over passing those fields directly as arguments to to_sql.\nWell there's two main points (I explained some of this in the PR description, not sure if you read it). The big one is that less existing code will need to change this way. If we add a second parameter, we'll need to modify every definition and every use of it. The second reason I'm preferring this is that I don't want to have to modify all this code again when we realize we needed a third or a fourth parameter.\n\nCreating this wrapping struct needs ~100 lines boilerplate code\n\nLines of code is not a valuable metric to measure things against.. You're right, either one could work. I felt that this version was more flexible, and required less churn.. I'll take another look. Don't need ::types. This needs to be #[doc(hidden)]. I implemented this and compared the two versions. I decided that I did not like the enum form. Reasoning laid out in the commit message. https://github.com/diesel-rs/diesel/commit/2a84869c38b0d69bddf86021029e5c003c7e74f0. no and no English is about as consistent as PHP. > This would confuse me if I didn't know what it was doing.\nThat's semi-intentional. This is the method least likely to be used by plugins. I should perhaps call that out more explicitly. Given that \"bind parameter\" isn't a standard term in SQL, I don't want to document a method called push_bind_param assuming knowledge of what bind_param means. Do you have any suggestions on how we can improve this without relying on knowing what the method name means already?. I guess I mostly added that to give a definition to the push portion of the method name. I agree that the only reasonable place for it to be added is at the end. I like your suggestion. It's certainly the most common, but it's just a term that many ORMs use. It's not part of the standard.. Please avoid visual alignment.. How about write!(out, \"{}\", self). Do we need any of these besides bigdecimal?. Yes, deref coercions are used all over the place. We use assert_eq! in tests.. Can't use ..self here, as the type is changing.. I generally prefer to avoid code comments which can get out of sync with the code they're referencing. I explained the reasoning for this in the commit message, which is where I prefer to document these things. This function doesn't have any invariants which we could violate without rewriting the function.. Do you think it would be valuable to add a comment which points to Path::new from the standard library as a reference point?. I don't think this comment is adding any value.. I don't think this comment is adding any value.. Why do we need to do string conversion here? How about just BigDecimal::parse_bytes?. Since we are relying on specific bits being set here, can we use binary literals instead?. I usually group \"external uses\" separately from \"internal uses\". Hm... This feels off to me. I think I'd prefer this to be something like:\nrust\npub trait CanAppearInRange where\n    Pg: HasSqlType<Self::RangeType>,\n{\n    type RangeType;\n}\nThat way we can just call metadata on RangeType. Let's avoid using unwrap. Can we avoid abbreviations for this?. How about we add a debug_assert! here that the size matches. Formatting is a bit weird here.. We need the nullable impl too. Can you run this file through rustfmt when you're done? (Latest version default settings)\nI'm planning on doing it to the whole codebase soon, one less place that needs to churn.. I don't feel super strongly either way, I just find the binary version easier to read.. That's a good point.. This is not a relevant user-facing detail. No. This doesn't affect data storage, it affects transmission.. This isn't infer_schema!. Given that the latest stable rust ups the default recursion limit to 1024, this is probably not necessary.. From mappings should never fail. This should be TryFrom or just left to the FromSql implementation.. Can we change the assertion to make sure it doesn't contain Running migration instead?. This is incorrect. We support stable, beta, and nightly. There's an issue with our doctests failing the beta build at this moment, but that doesn't affect our support.. I think the note block calls more attention to it than necessary.. I'm not sure I understand what your first correction means? The point I was trying to make was that the macro is only present if you've enabled at least one backend (otherwise it's just the derives). I intentionally left out the use statements. You're right that we should specify which exact type these are though.. I think you meant to remove this line?. I don't think this will work for linux users, where mysql the binary is included in a separate package from libmysql the object we need to link against.. How do you feel about treating the output as an unnamed struct? So the output would be:\n{ query: \"SELECT * FROM users WHERE id = ?\", binds: [1] }\nAnd then we could theoretically work properly with pretty-printing as well. Probably not. I suspect this one just predates me writing doctests. \nI don't think there's any command we can give here which will work in a cross-platform way. Do you think we should we just focus on the Diesel CLI specific stuff and assume that folks can figure out whether they have something installed on their own? (Worst case, attempting to install diesel_cli will tell them). I was hoping to keep them semantically separate since if we go with slog we'll actually want to keep them separate in that structure. If we did want to do the json-ish thing, perhaps instead of a debug_sql function/macro, we should have a .debug() instance method which just returns a struct that implements std::fmt::Debug. That would give us the hook we need to deal with pretty-printing. Actually here's a thought -- what if DebugQuery implemented Display as you've described, and Debug with the anonymous struct form?. I'm going to merge #1051 first, and redo this on top of that, as a lot of the surrounding code has changed here.. Lol I must have hit dn on accident instead of dd where the last thing I searched for was sqlite::SqliteConnection. \u2702\ufe0f the . Can we avoid visual indent?. I'm not sure I understand where you want me to put that. Yeah this one has been commented out for a while lol. Since before sqlite support apparently lol. It's not doing anything PG specific.. It will also work for SQL Server, Oracle, Spanner, and any other database which correctly implements the information_schema ANSI standard.. /cc @cuviper It would be great if there were a way to do this without allocating.. If Rem<u16> returned u16 instead of BigUint I'd happily use that instead. It seems like all the scalar operations are just converting to the num type under the hood? For Rem specifically that should be unnecessary since the result will never be larger than the size of the scalar passed in, nor will it be affected by any digits other than the 1-2 least significant.. Only on slices, and that would require allocating an intermediate string. IIRC clippy warns but I will give it a shot. Could this be impl<T: ToSql<Timestamp, Mysql>> ToSql<Datetime, Mysql> for T?. :+1:. How about\n\ninfer_schema! now automatically renames columns that conflict with a Rust keyword by placing a _ at the end of the name. For example, a column called type will be referenced as type_ in Rust.\n\nI don't think we need to mention diesel print-schema separately since it's documented as behaving the same as infer_schema!. Would need to use writeln! as well since \\n doesn't work with raw strings (which this should do regardless). \u2702\ufe0f . How about just &[&str]?. new_name feels weird to me. How about we call it rust_name, and rename the name field to sql_name?. I'm going to run it on the whole codebase one of these days. Trying to reduce the churn in the short term. Lol I'll get rid of it. These commas shouldn't be required. Since this message is user-facing, can we provide some information about how to fix this? It should mention that features = [\"postgres\"], etc are required.. Is lossy the correct behavior here? If there's an invalid UTF-8 character, I think that should be considered an error condition.. I'm finding this test rather difficult to read. Rather than relying on the (implicit to this test) behavior of set_username and set_password doing percent encoding, can we just have a URL string which includes percent encoded/decoded characters?. This doesn't seem relevant to users of Queryable. Can we use the URL crate for this rather than doing our own parsing?. To make it clear what this run is.. Well we also need some env var that is different to make it a different matrix item than the normal nightly test runs.. :+1: will follow up with that once I'm done moving this code around. Everything else we've deprecated is tested through doctests, not integration tests.. Given that insert_or_replace is exactly analogous to insert, it made sense to do them at the same time. While working on it, I noticed that having it be INSERT OR REPLACE was unnecessary, and it could just be REPLACE which is compatible with MySQL.. This is what rustfmt decided to do.. Every test case needs to have a unique project name.. Can you use as_bytes here to be more explicit what we want?. Do we need this as_ref?. Can we use as_bytes here to be more explicit about what you want?. Do we need this as_ref?. Can we pull this out into a function?\nrust\nfn decode_into_cstring(s: &str) -> ConnectionResult<CString> {\n    let decoded = percent_decode(s.as_bytes)\n        .decode_utf8()\n        .map_err(|_| connection_url_error())?;\n    CString::new(decoded.as_bytes()).map_err(Into::into)\n}. Reading this from the perspective of a new user -- What is Child? What is Parent? Why does this say it takes two arguments, but the signature only takes one?. \"You can narrow the scope by calling filter\". some_table.find(some_struct.id). Relative URLs please. This will break on docs.rs. \"can return the inserted rows by calling .get_results instead of .execute\". Relative URLs please. This is missing a description and #Example header. We don't typically show this setup. Can we instead do 2 selects, one with limit and one without, to show the difference that way?. We don't typically show this setup. Can we instead do 2 selects, one with offset and one without, to show the difference that way?. This example misses the point of this API. While it may sometimes be used with a separate update struct, most usage of this would have #[derive(AsChangeset)] on the main struct. e.g: \n```rust\nlet mut spider = animals.filter(species.eq(\"spider\")\n    .first::(&connection)\n    .expect(\"Too scary to load\");\nspider.spieces = String::from(\"solifuge\");\nspider.legs = 10;\nspider = spider.save_changes(&connection).expect(\"Could not save changes\");\n``. I *really* want to hide it. Can we move this to a local variable?. Not that I'm aware of but if you know of one please do open a PR. Because instances of this type never exist, and more code = slower build times. Surprised this didn't trigger a missing copy implementations as well. Should this type implementCopy`?. How about this:\nrust\nlet file_name = self.migration.file_path()\n    .and_then(|file| file_path.file_name())\n    .and_then(|file| file.to_str());\nif let Some(name) = file_name {\n    f.write_str(name)?;\n}\nOk(()). I don't think you meant to delete this. Also this needs to fall back to printing the version if no file path is present. Embedded migrations return None for the file path. Yeah, it's produced by rustfmt because it's trying not to change the meaning of the string (which this PR does). I'll see if adding some backslashes makes it less weird. This needs to test diesel_proc_macro_internal as well doesn't it?. I'd still prefer to test this against all backends. Even if we're not generating anything that directly hits the database, we should still be sure that we're generating code that is valid for all backends. You can specify a version and a path. \u2702\ufe0f . Should we go ahead and change this to the currently used date?\n. This is testing serialization. The next test is testing deserialization.. Because noon is not midnight.. Chrono doesn't deal with julian days, but a float representing julian days is one of the documented valid date formats at https://sqlite.org/lang_datefunc.html. It's quite trivial to convert julian to gregorian, which is what this is doing.. The pointer is never null in any case here. This could probably use an ad-hoc insert more and be more clear, couldn't it?\nrust\ninsert_into(users::table)\n    .values(vec![\n        users::name.eq(\"Sean\"),\n        users::name.eq(\"Tess\"),\n        users::name.eq(\"Pascal\"),\n    ]). We don't need to render all this whitespace. These should all still be #[doc(hidden)]. I don't want to expose the internal structure of this module, just have it be public for documentation purposes.. nice. I dunno. She's pretty much like me.. I don't understand the need for this crate. Everything in here was previously part of the public API, and I don't see the reasoning for making it private. Why does this need to be separate from diesel_migrations?. These whitespace lines will all be rendered if you don't have # won't they?. I think you meant #! here?. Did you mean to leave this blank?. Do you think that this implies we're loading the data instead of returning a query that needs to be executed?. Do we need to restate this here? Is it stated in the docs for Identifiable? Do you think this line is confusing without seeing the use lines?. This trait doesn't actually load anything. Do you think this statement is misleading?. It looks like this is only valid after a specific set of expressions. Can we limit this to that set, and get a compile test that it fails for something that it shouldn't apply to (e.g. LIKE)?. This can just be types::Array. Why the tuple?. Can we import this?. Does this need to be public?. Or ::types::Array. Is there a reason for us to not import it?. Can we keep all the use statements at the top?. Should this be (Bound<T>, Bound<T>): ToSql<Range<ST>, Pg>?. Can we drop the HasSqlType<ST> if the other comment is addressed?. This includes the bundled feature by default. I'm fine with giving a flag for this, but I don't think it should be the default.. I bumped because crates.io did and this was the date they were using and rustup update nightly failed.. The error message is the same either way. Panicking is how proc macros communicate errors to the user.. \n. I guess having the message at the top is marginally better. Diesel CLI 0.99 is going to break when a new version of clap is released.... @juliusdelta What do you think about changing this pyramid to use and_then like my comment above?. This type should implement Copy. Yes. Or if you wanted to get really fancy:\n``rust\nimpl <'a> fmt::Display for MigrationName<'a> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let file_name = self.migration.file_path()\n            .and_then(|file| file_path.file_name())\n            .and_then(|file| file.to_str())\n            .map(|name| f.write_str(name))\n            .unwrap_or_else(|| f.write_str(self.migration.version))\n    }\n}. This type should still implementCopy. ;) (I'm still really surprised that themissing_copy_implementations` lint isn't triggering here). I'm going to do a pass on this module soon.. Rebasing is hard. Because Rust is super inconsistent about whether it runs lints or not, and suddenly this clippy lint (which should have always been failing) is now failing as a result of these unrelated changes.. Oh I wonder if the lint only triggers if the type has a clone impl. That would make sense.. I think that should be left to the documentation for the backend specific lookup types. I prefer not to put PG specifics here.. I would be linking to the page they are currently on.. I'd be linking to the page the user is currently on. There are plenty of examples in libstd where a module that basically only has one trait puts all its documentation in the module docs, and then has the trait documented as \"see the module docs\". I figured the same applies reasonably well to traits with only one method (in general the goal here being to have the docs render as high up the page as possible).\nTL;DR: Given that the trait only has one method, and the trait docs are written as though they were the docs for this method, I think this is fine. The only real alternative is moving the trait docs to this method, and linking to them in the trait docs, but the trait docs render higher up on the page.. Backticks aren't needed around \"SQL\". s/the diesel crate/Diesel. > you will only need #[macro_use] extern crate diesel; at the root of your project.. Do you think this comment is misleading? Should it say \"brings the user table into scope\"?. You don't need the manual anchors. ;). \"SQL\" doesn't need backticks. I found this sentence a bit hard to parse. What do you think about restructuring it like: \"Queryable is the trait you normally use with Diesel's query builder. If you're using sql_query, you will instead need to implement QueryableByName\". \"SQL\" doesn't need backticks. sql_query should be a link. It is a function not a method. I'd omit the parenthesis here.. This feels too vague to me. Do you think we should mention that the types are unverified after we explain what types we're not verifying (the next paragraph). These aren't mutually exclusive. You can override one or more fields while having the rest be picked from the table. Should we explain how this annotation affects the derived implementation?. Should #[diesel(embed)] be mentioned here as well?. It's probably worth mentioning the error someone would see if they have #[table_name] but forgot #[sql_type] on a field that isn't meant to map to a column, or if there was a type mismatch.. \"SQL\" doesn't need backticks.. Do you think we should put a dot in front of these to indicate that they're a method? Should these be links?. Do you think we should put a dot in front of this to indicate that it's a method?. Do you think this should focus more on the use case of Insertable? e.g. \"#[derive(Insertable)] is usually intended for cases where the struct is being built by some other method (for example, deserialized from an HTTP request). Typically you will not use Queryable and Insertable, as a web form for a new record wouldn't have fields such as id, created_at, or updated_at. If you are building the struct by hand in your Rust code, you can skip Insertable entirely, and use an ad-hoc insert (link to docs)\". s/track/trace. Should this focus on the use case that AsChangeset is designed for? (See the previous comment about insertable and web forms). Is this comment adding any value?. Can this just say \"we've covered all the derives\"?. This method isn't really meant to be used with select statements normally. .first is intended for that case. I don't think wanting to skip LIMIT 1 is common enough to warrant an example here.. I don't think we need to state \"sqlite and mysql don't support returning clauses\" every time we say \"RETURNING\" in our docs. Especially since trying to run this code on SQLite will give you \"Sqlite: SupportsReturningClause is not satisfied\". You'd still want LIMIT 1 there.. It only executes one query that modifies data (the second query is a select). A transaction is only really needed if you're executing two or more queries that modify things, which you'd like to have be atomic. If that were the case, you would need an outer transaction regardless of backend.. Originally I was going with \"might eat your fucking face if you take your eyes off it\". This is just moved from the other location. I wonder if we can set up a way to run our docs code through rustfmt.. This is just moved from its original location, and I also have a PR up that rewrites this example. This is a post 1.0 thing either way. I'll open an issue.. Never trust something with more than 2 eyes. Feel free to change the name, I'm just being lazy. I probably copied them over before I just decided to #[allow(missing_docs)]. Do you think that is sufficiently covered by the documentation for .on?. I think we can safely assume that is always present at this level. We can deprecate the macro in 1.1.. I think we need to #[doc(inline)] some stuff, that function should be exposed only in diesel_migrations. It looks like we do have #[doc(inline)], but that doesn't work for functions from other crates... Looks like we'll need to do some work there. I didn't think it was worth the churn since those lines aren't rendered.. This renders underneath a link to QueryBuilder.. This renders underneath a link to BindCollector. It doesn't render in a prominent enough location. I've been toying with the idea of deprecating Connection::establish and just having inherent methods for each class (would let us vary the signature too which would be nice). It's what's generated by sql_function!. It's just convention. All our docs are written assuming that line. All our macros and derives should work without it.. Yes. Static file servers typically render index.html if a directory is requested.. The docs for the types module shows links to backend specific types.. Should we link to on_conflict_do_nothing here?. Nit: It'd be more ideomatic to use users::id.eq(1) here (not that it matters too much for a compile-fail test. I've literally never split them into multiple lines. I have no idea where that started. What do you think about calling this child_table and parent_table, and then specifying that the child table is the one with the foreign key, and the parent table is the one with the primary key that the child table points to? (This is how the association docs lay it out). SQL should be capitalized.. You can always inspect the SQL of a query using debug_query. Do you think it'd make sense to show how this would be accomplished without joinable! instead of demonstrating in terms of generated SQL? e.g. mentioning that users.inner_join(posts) becomes equivalent to users.inner_join(posts.on(users::id.eq(posts::user_id)))?\n. I dont bother adding them for drafts. I have to do a ton of work on code blocks when I publish. Good catch. Good catch. I would love an idea for a better header to use here.. I originally had this as the third section (swapped with \"custom operators\"), since this is definitely \"lower level\" than custom operators are.\nHowever, this seemed like code an app is more likely to write. Operators are more likely to be handled by libraries (and that example might even belong in the \"supporting custom SQL types\" guide).\nAnyway, this order is roughly \"most likely to be done by apps to least likely\". If we swap this with \"custom operators\", the order becomes \"highest level to lowest level\". I like how you're always like \"why do relative instead of https only\" and then you paste a link to http :P. We do in section 3 which used to come before this >_<. Open an issue? ;). I agree. I'm going to merge without doing this so I can publish a guide referencing code here, but I will make sure to come back and do this after we ship 1.0. Advanced querying guide will. But then I can't do diesel print-schema > src/schema.rs. Given you added https support in the first place, yes. :P. Drunk Sean thought it was funny. ../diesel/ is redundant.\n  . Even though this line is hidden, can we avoid using conn.execute? This is trivial in the public API: diesel::delete(users).execute(&conn);. We try to avoid using unwrap in documentation. Recent doctests follow the convention below. Can you update this test to do the same?\n```rust\n#[macro_use] extern crate diesel;\ninclude!(\"doctest_setup.rs\");\n\nfn main() {\nrun_test().unwrap();\n}\n\nfn run_test() -> QueryResult<()> {\n// actual test goes here and uses ?\nOk(())\n}\n```\n. What do you think about naming this ArrayLiteral so it's clear what the distinction from types::Array is?. This should implement Clone and Copy.. The first sentence should be its own paragraph.. This doc comment mentions type inference more than anything else. Do you think this is likely to be used in contexts where the type can't be inferred enough to warrant this much attention?. Note: If #1391 is merged before this, this needs to get updated.. Can we have a #[doc(hidden)] reexport of this from somewhere public and make the module private?. There's no need to use fully qualified paths vs just useing the trait here. This macro doesn't get called from user code.. Can we be specific on at least one of these? (Also why are there so many?). Ughhhhh actually add none of those. Seriously Rust. Just fucking say \"f64: AsExpression<Integer> is not satisfied\" these errors are ridiculous.\n  . Oh right hence why we can use it in Diesel >_<. You don't need to go through the pg module for this. Just types::Array<T> is enough.. We prefer to stick to public API for new tests, and avoid using execute.. use self::number_arrays::dsl::*;. Can we just create this table in the test directly since it's only used once?. Good catch. That would mean Diesel would error every time you compile without all three backends. You should be able to declare how a backend supports a type, and then only have the code generated if that backend is enabled for Diesel.. This enum would be used when introducing a new SQL type, which shouldn't happen in user code. I agree that this one is technically a major breaking change. This one is strictly optional, we'll just end up allowing MYSQL_TYPE_STRING for decimal, which is probably fine.. The impl was always present it just came from a different place if PG was enabled.. Very marginally, but it would be significantly harder to do that here than it was in that case. I don't think existing code that does this is worth touching. . Not backwards compatibly, no. This isn't public API. We don't need to deprecate it.. Do we need any of these as_refs?. Can we use expect here? This is going to give a very poor error message if the model doesn't have a field with the right column name.. Why is this needed?. foreign_key_attr is never used again. Can we just do .map(|a| a.ty)?. Don't we already have a util function for getting the inner part of an option?. What is t? The type? Can we at least call it ty?. The changes to this function feel unrelated to the rest of this PR. Can we leave them out?. use self::numbers::dsl::*;. Can we use the public API for this? diesel::insert_into(numbers).values(&vec![n.eq(1), n.eq(2), n.eq(3)]). Can we use the public API for this? diesel::delete(numbers).filter(n.eq(1)). Can we use the public API for this? diesel::delete(numbers). If the test fails, or someone interrupts the test mid-run, this will break. We need to either change the CREATE TABLE line to be CREATE TABLE IF NOT EXISTS, or (preferably) do this DROP TABLE in a Drop impl. Sorry I just realized that all this code was moved from another part in the file. Can we leave this code where it was before? This just adds unnecessary git churn.. Can you confirm this test is actually run by travis?. This is maybe a nit, but I feel like in the interim we should pull this into a function so we don't actually have 40 lines of code copy-pasted like htis. Lol whoops. The Array type doesn't exist unless this feature is enabled.. This code was just moved unchanged.. Array is a PG specific type, why would we include it if you aren't using PG?. This is to work around bugs in Rust.. The Datetime type is a MySQL specific type, and is only present when the mysql feature is enabled.. Yeah, the replacement of types with sql_types probably touched enough lines for it to not be seen as a rename in git.. Our definition of public API is whether or not it appears on documentation. #[doc(hidden)] items can be freely changed without deprecation.. Can we improve this error message to say \"No field found that corresponds to the column post_id\". This is explained in both the commit message and PR description.. >  If we wanted to support anything that\n\nimplemented diesel::Connection, we would need to add the constraint\nC::TransactionManager: TransactionManager<Self>. However,\nTransactionManager has the bound that it's parameter be Connection,\nso we just recurse infinitely. Maybe on day the language will be smarter\nabout this. Until then, we just have to do this weird hack.. This trait would need to be generic over the backend for it to be used by more than just SQLite. If we think we will want to re-use this for other backends, we need to do that in this PR. We're a 1.0 library, so we can't change this later.. Why are we specifying OPEN_NOMUTEX here? It is not a flag set by sqlite3_open, and it seems unrelated to your change.. I'd prefer we hold off on making that change for the time being. We certainly can't just do it by default, but we can possibly expose an API for this in the future.. This reads more like a code comment than documentation. Can we say something like \"A re-export of r2d2::Error, which is only used by methods on r2d2::Pool\"?. I would change this to Added and reword it as\nAdded diesel::r2d2::PoolError as an alias for r2d2::Error. Previously this type was inaccessible due to diesel::r2d2::Error.. \u2702\ufe0f . It's never actually used. Only the type is. I didn't feel like using PhantomData for it since we actually have the value at the point of construction.. Need to otherwise access records in another file and this felt cleaner than .records().records. This is not a breaking change. There is no way to construct this type in public API other than by constructing it by passing a slice to values. All of that continues to work.. I guess technically? We can keep it around, it literally does nothing though. I guess I can leave this impl in place -- it's straight up impossible to construct this type though. The code you just pasted would continue to work, and is the intended way to do that.. Why do we need this trait? It's entirely redundant with FromSql. Do we need a separate trait for this? Can we use ToSql instead?. See the comment on the line above. That would require Tab: Default. Should this be optional? It's only used with the mysql and postgres features.. Can we change SqliteValue to operate on sqlite3_value_* functions, and construct it by calling sqlite3_column_value?. ToSql always just writes some bytes to a buffer. In the case of Sqlite, we then look at the SqliteType variant for each value, and figure out the right bind function to call based on that. We should be able to do pretty much the exact same thing here, but calling sqlite3_result_* instead.. > However, it might be that somebody more familiar with the Diesel code base could be able to make it work.\n\nYeah, this is a pretty hairy feature to take on for your first PR. Last nit. This should be #[cfg(feature = \"url\")].. There are a bunch of open issues for this, one of them being https://github.com/rust-lang/rust/issues/34260. I don't think it warrants a link, it's not getting fixed in the near future.. Yes, that was intentional. Even though it is on Insertable, it is designed primarily for use with select statements.. I'd rather not introduce unnecessary git churn.. Why do we need to make this public? Things should be using the column_name() method.. Why do we need to make this public? Things should be using the field_name() method.. I don't see any shorthand destructuring of the struct. That line can and should be using the method form.\n\nMaybe this should be moved to Attr as member funtcion?\n\nIt already is there as a method. That is my point.. Same answer.... We don't need this method. let #struct_name { #(#field_name: #column_name,)* } works in all cases. Alternatively, just skip destructuring entirely (which was mostly done to make the macro_rules! form easier), and use self.#field_name. We should never need a conditional on whether something is a tuple struct.. This function and infer_table_name were both copied over from the old codebase. I think I want to deprecate the inferred table name behavior (I want to hold off on that until everything is moved over though). Can you add an env var so we know what this is, like the other items?. This needs to actually run the tests not just compile. I'd prefer we have this function take *mut T and cast the function pointer rather than the other way around. The call to transmute is too likely to accidentally cause problems in the future.. > Hence, the sqlite3_column_value() interface is normally only useful within the implementation of application-defined SQL functions\nIsn't that exactly what we're doing? unprotected just means that there's no mutex around the value, but that literally just means that it needs to be !Sync (which it will be by default if it involves a pointer). Either this comment is wrong, the comment below is wrong, or SQLite's docs are wrong. Both the comment below and SQLite's docs claim that calling sqlite3_value_bytes can invalidate the pointer returned by sqlite3_value_blob. This is of course identical to the implementation in Diesel today, which means that this definitely isn't happening (or nobody is using binary on SQLite with Diesel... Or we're relying on UB).. Either way, something is lying. I'd like to either fix the comment here, or fix the implementation.. Migrations that came from a _in_directory function always have a file path.. This code doesn't currently work with generic structs, but good catch.. Our test suite fails without the full feature. . Let's not start this again lol. I stuck an if cfg! in there. Running it unconditionally requires additional synchronization that would have been more painful.. No, see the comment and code related to this which point at a rustc bug.. It's not unreachable.. @dtolnay any idea on whether this is a bug or something I actually need to handle? The problem comes from code that looks like this:\n```rust\nmacro_rules! gen_struct {\n    () => {\n        #[derive(QueryId)]\n        struct Foo;\n    }\n}\ngen_struct!();\n```\nwith hygiene turned on, the body of the derive can't see any of the uses that come from __diesel_use_everything!();. The point would be this:\n```\n[derive(Debug, AsExpression)]\n[cfg_attr(something, sql_type = \"SomeType\")]\nstruct Foo;\n```\nIf we error here, we force them to write\n```\n[derive(Debug)]\n[cfg_attr(something, derive(AsExpression))]\n[cfg_attr(something, sql_type = \"SomeType\")]\nstruct Foo;\n```\nAn example of this in Diesel is:\n#[derive(FromSqlRow, AsExpression)]\n    #[diesel(foreign_derive)]\n    #[cfg_attr(feature = \"mysql\", sql_type = \"::sql_types::Tinyint\")]\n    struct I8Proxy(i8);. Also it takes more code to error here than to generate no code. ;). Lol. where_clause is an exclusive reference to a member of item.generics. The line after this block ends creates a shared reference to item.generics. I believe this block can go away when NLL lands.. I agree. Blame @dtolnay. https://docs.rs/quote/0.4.2/quote/macro.quote_spanned.html\n\nThere should be no space before the => token.. (But maybe we should just ignore that because I agree it looks really wrong without a space). Thanks for the insight. <3. I'm assuming that if you derive this on a struct with no fields, you're likely trying to do INSERT DEFAULT VALUES. Otherwise I'm not sure what they're trying to accomplish.. Rather than duplicating bind param handling here, what do you think about structuring this differently so that it just holds the bind parameter?\n\n```\nstruct UncheckedBind {\n    query: Query,\n    value: Value,\n}\nimpl SqlLiteral {\n    pub fn bind(self, value: U) -> UncheckedBind\n    where\n        U: AsExpression,\n``. Adding this bound is a breaking change.. This needs to support more than justIntegerdoesn't it?. \u2702\ufe0f . This impl can probably just be generic over everything.. There wouldn't be a correspondingAsExpression` impl, so... :P \nThere's nothing to prevent you from putting Unsigned<Text> in your table declaration already. I'm surprised that this isn't failing due to #[deny(missing_docs)]. It needs docs.. Needs docs.. This should be pub(crate). Needs docs.. This impl is wrong. We should just derive it.. This should have Query: NonAggregate and Value: NonAggregate as bounds.. Can we prefer Self to explicitly stating the full type?. This should be Self: AppearsOnTable<QS>.. This should be Self: Expression.. What do you think about this instead? Local::from_utc_datetime(&naive_date_time). This can just be field.ty.clone(), can't it?. Nope.. No, we include them on integers because it's common to accidentally end up with the wrong type. That's less of a concer here.. This map_err uneccessary. . This map_err is unnecessary.. \u2702\ufe0f . Can you use the new intra-module link form that rustdoc provides?. Link to the docs?. Can we delete this comment? The commit message should have all the context needed.. Can this be written as Some(Host::Ipv6(host)) | Some(host) => Some(CString::new(host.to_string())?),. Can we not use the same variable twice in quote!?. No, it's fine to leave it using try! for now.. Why the temporary variable here? let (ref field_ty, ref field_access) should work fine.. None of the &s are needed.. Can we add .possible_values(&[\"sql\", \"barrel\"]) and .default_value(\"sql\")?. Arg names should be uppercase by convention.. This needs to be #[cfg]d.. All of this code should live in Barrel, not Diesel.. Can we pull this out into a function?. Can we just move the migration trait from diesel_migrations into diesel so this code can live in Barrel?. If this is an optional integer, why is the return type Option<&str>?. Do we actually need to split these? Rust doesn't mind if there's an unused lifetime in the generics.. This feels to implicit to me. Can we take Option<syn::Lifetime> instead?. lifetime.. This type should not be deriving FromSqlRow, nor should any other SQL types.. This should be in the mysql module, it's backend specific.. None of these should have QueryId implemented.. None of these should have Expression implemented.. This should be Unsigned<ST::QueryId>.. This should only be implemented for Unsigned<SmallInt>.. This should only be implemented for Unsigned<SmallInt>.. This should only be implemented for Unsigned<Integer>.. This should only be implemented for Unsigned<Integer>.. This should only be implemented for Unsigned<BigInt>.. This should only be implemented for Unsigned<BigInt>.. Also all of these implementations are backend specific, they should not be generic like this.. This should be MySQL specific.. It doesn't need to for backwards compatibility, but I think we should default it anyway. Less churn.. I'd rather we implement QueryFragment for the modifiers rather than duplicate this impl 3 times.. Do we need Modifier at the end of every type? I think just SkipLocked is fine.. Can we move this to ForUpdateClause::new?. MySQL 8 does support these modifiers, so we should allow them on that backend.. We've been very conservative about adding variants to this in the past. Can you provide some example use cases that need this variant?. I'd just enable it outright for the backend, and put a note in the docs about the supported versions.. We should mention that SKIP LOCKED is only on PG 9.5+ as well. It's worth noting that this is the only way to create a select statement that can fail at runtime in Diesel (other than network errors). I'm inclined to accept the variant, but I'd prefer that it be kept as a separate PR so we can keep the changes atomic, and to give that error a place to be discussed in isolation.. Just test is_err for now. Oh I see what you mean, it'd time out if it didn't fail immediately. Perhaps check that the error message contained an expected string?. I think you need to run rustfmt. ;). I don't think this line needed to change.. We can drop this impl. The only types which implement this already have a FOR UPDATE clause, which tables do not.. We can drop this impl, too. I was surprised that I had to keep &** here. I would have expected to be able to remove at least one *.. Why did this need to move?. Can we document what this actually does rather than just repeating the name of the type?. Can we provide more information than just repeating the type?. Can we provide more information than just repeating the function/argument names? Maybe at least a usage example?. How about \"Columns generated by table! now implement Default\". Are you planning on releasing before this is merged? I'm not comfortable putting a git dependency here.. Why barrels?. ?. What do you think about changing this to if let Some(migration) = ::barrel::diesel::migration_from(path)?. Why the commented lines?. We don't strictly speaking need it, but I like the symmetry of having both methods on both types. It makes it more clear to me what you can call on UncheckedBind by seeing it here. Otherwise I have to click through to the return type to see the methods on the other type. If we just have the same methods on both, those methods (and docs) apply in both places.. Why do we need these types?. Is this PG specific? COALESCE can have many signatures and is ANSI SQL.. I don't think the HasSqlType impl being generic is a problem. It doesn't enable anything on its own.. You should not specify the bundled feature here.. Did you mean to remove this?. I don't like this name, but I don't have a better suggestion.. Since this is owned, we don't need to defer grabbing the values. We can Just have this wrap Vec<T> where T = <U as Insertable<Tab>>::Values. This impl bothers me more than the rest of the duplication. I'd like to mull on it for a bit.. This is very much not the right approach. We cannot assume that 25.hours() means 1.day() + 1.hour(). chrono::Duration is lossy. We should not try to infer what they meant when they constructed it. We should convert the types with their direct translation:\nPgInterval {\n    microseconds: duration.num_microseconds().expect(\"Cannot convert a duration larger than 292471 years\"),\n    ..Default::default(),\n}. Can we follow the convention used for every other type in the name?. DurationProxy. Why do we need this field, then?. Yes good catch. Some generated code to assert order like this:\nlet users::updated_at = users::all_columns.4\nThat code gets a span which points at the field definition as its source location. No, this does not invoke any UB, nor does it change the representation in memory.. As I mentioned in the original PR, this impl doesn't enable anything by itself, and I don't think we need to make it more specific.. What's wrong with it?. On the one hand I don't like that we're silently losing precision rather than returning an error on overflow. On the other hand this only occurs for durations greater than thousands of years so I don't really care.. \"leap seconds\", \"daylight savings time\". The implementation doesn't overflow so maybe let's not mention this. This link will break on docs.rs. . I worded it this way because the message the user gets is literally \"Queryable<...> is not implemented\". Needed to pull out the PG specific functions to use them for testing.. No. https://github.com/diesel-rs/diesel/pull/1630/files/ae22270600aeddeb8b95e6b88f48060bd514ab9a#diff-15619a8ba441d58f7250a6aa4a4b5273R200 does.. I don't know how we could do that other than checking with which. But then we have the same problem. It is. You cannot specify both fields.. You can just #[cfg] out the one create_table statement.. This test is kinda funky -- There's no reason to write this code. You would 100% use tuple inserts for this today. Even if it were \"18 fields that came from user input, and 1 field that needed to be a Diesel expression\", you'd write .values((that_one_expression, insertable_struct)). However, I do think it's worth ensuring that #[derive(Insertable)] continues to work with non-ToSql types, hence why I didn't just change the test. This is also a regression test to make sure I don't just assume everything can coerce to nullable again.. I actually think there'd be more noise if I took a vec. I guess maybe it'd just be a .to_owned, but we are talking 3 lines vs 2.... Shouldn't this be timestamptz?. Same here. Should this be cfg'd?. They're going to change later for different reasons. I'd rather not risk breaking/changing the deprecated form.. I don't think that's correct. http://docs.diesel.rs/diesel/dsl/index.html https://github.com/diesel-rs/diesel/blob/master/diesel/src/lib.rs#L187-L191. Correct, you cannot inline documentation across crates.. I did. I'm planning to, just haven't gotten around to it. This has less to do with proc_macro2 and more to do with Rust. I agree that it's brittle and will break again in the future. That said, the only reason we do this at all is to work around a bug in Rust itself, and if this code breaks it just means that a handful of error cases point at the macro invocation instead.\nI couldn't find any way to directly construct a bad span, no.. Oh I didn't even notice that one. Yes, I'll open some bugs for them soon.. Yes, it landed in the same version as macros 1.1. We already use it elsewhere.. diesel setup will create a config file. I just forgot to change the project name in this test. It's a race condition, not an actual bug.. No, cfgs can only go on items, not expressions.. \u2702\ufe0f . This needs to be placed in the Unreleased section.. Yes. We generally allow overriding clauses later. This should be no different. I'm planning on a followup PR to allow overriding the rest of the lock clause as well. This would break any existing code that implements ForUpdateDsl.. Oh actually it should just not even be there. I had originally directly implemented Sub, etc on PgInterval but decided it was weird to have Add only be between two PgIntervals, but the other operators be query builder operations, so I opted to leave it out in favor of inteval.into_sql::<Interval>() + whatever. I'm not a fan of private constants have the same name as their string value and are only used once. This is more of a documentation thing.. > I'm concerned that this may be too limited an interface: I wished to store a list of previous revisions as part of the metadata for example, which means they've have to be double-encoded in the toml file.\nI had the same concern and thought about it for a good while. You absolutely do not need to store it double encoded. You're right that this function will return a TOML string for tables/arrays though, and you'll end up calling toml::from_str on the result. There's actually a benefit to doing that, since you can then turn the returned string into a type other than toml::Value etc.\n\nPerhaps this \"get\" method could use erased_serde to allow it to support structured data? That way I can specify the type when I access the metadata?\n\nI'd prefer not to couple to any single serialization framework here. Especially since that assumes that metadata is serialized in a file, which may not be true for Rust migrations, or migrations which decide to use magic comments, etc.. Why?. > What if barrel decides not to use TOML to store its metadata? Then I won't know how to deserialize an array without knowing where a migration came from?\nI was sort of assuming that if you're caring about specific metadata keys, you're also assuming a migration format, but you're right that isn't ideal. I'll need to think about this more. I was about to say we could have get_map and get_array as separate functions, but there's no type we can really return from get_array unless we have an enum. Perhaps we should just have a very naive enum representation of Value(String), Array(Vec<ThisEnum>), Map(HashMap<String, ThisEnum>). (This now is making some assumptions about how maps are represented but I think that's probably reasonable.) Either way I do need to give this more thought.\n\nSerde is the de facto standard for serialization, and diesel already has it as an optional dependency, so this doesn't seem overly risky.\n\nI'm not implying that there's another serialization framework to use instead, just that some types are difficult to represent with Serde, and I'd rather not push it here.\n\nFor embedding migrations, the internal format would not be exposed, we'd just pick any format which supports the whole of that object model (eg. RON).\n\nThis is less about embedded migrations, and more about cases where the metadata is entirely computed. . We haven't released a version that supports config files yet, so we don't need to support the whitelist/blacklist terms here. Only on the command line.. This signature won't be able to represent composite keys. Should this take self by value, and be implemented on a reference instead?. Should we just have Hash + Eq as bounds here?. Can we use Self here?. Should this implementation be more generic? e.g.\n```\nimpl ForeignKey for Option\nwhere\n    T: ForeignKey,\n    ST: IntoNullable,\n{\n    type KeyType = T::KeyType;\nfn key(&self) -> Option<&Self::KeyType> {\n    self.as_ref().map(T::key)\n}\n\n}\n``. I don't understand why we needSThere.. That would cause all generic functions to fail to compile if the sqlite feature is enabled (e.g. Diesel would no longer compile itself). This actually *is* the compile time error version of this. The function simply isn't generated, meaning attempting to provide an impl will fail to compile. The alternative would be to return a runtime error if you tried.. This is backwards isn't it? Shouldn't this beexcept-tables?. This is backwards, isn't it? Shouldn't this beonly-tables?. I think git is just confused.. Newline please :smile:. We don't need this.collect. Can we doserde = { version = \"1.0\", features = [\"derive\"] }instead?. Should this sayonly-tables`? TBH I wonder if we should just remove any \"default\" behavior (I think we have an issue open saying that the default is broken anyway). Can we give a specific error message for each one? I'd prefer something like this:\n``\nif matches.is_present(\"whitelist\") {\n    eprintln!(\"Thewhitelistoption has been deprecated and renamed toonly-tables`. \");\n}\nif matches.is_present(\"blacklist\") {\n    eprintln!(\"The blacklist option has been deprecated and renamed to only-tables. \");\n}\n``. Puts a nice label in the matrix so it's clear what this does. I think this line needs to remain unchanged.. TheSizedbound should be on the method, not the trait. Putting it here is technically a breaking change.. Why do we need this?. If we need this to be public API, then let's make it public API. Let's rename it toUpdateAndFetchResults, document it, and make it public.. This line should not be changed.. Can we give these more descriptive names? e.g.ChangesandOutput?. This seems unrelated, but :+1: if it doesn't bump our stable version. We don't need a space before the colon. Please avoid changes that are unrelated to your main PR. There's no reason to update clippy here.. What isfname? Can we avoid unnecessary abbreviations?. We still need a space after the colon. Sure -- Just didn't really feel like churning every call. Probably should have named itdummy_scopeor something since we've now changed it from const to mod to fn. I don't think TOML cares about whitespace does it? Can we have this indented normally?. We still need to keep this name around. We can't just make a major breaking change like this. Yes.#[doc(hidden)]. The changelog is a description, not a set of commit messages. It should use language like \"Tinyinthas been renamed toTinyInt\". This is a breaking change. Are we unable to support both versions?. This is a breaking change. Are we unable to support both versions?. Assuming that we're able to support0.1.32, yes.> 0.1, <= 0.3. Does this skip running unit tests?. Does this skip running unit tests?. Those are the integration tests. Are the tests insrcstill run (if there are any)?. Also I don't think we need to handle warnings for the 2018 edition just yet -- I'm pretty sure we actually want to fix this the other way, and remove the[[test]]section (not 100% sure yet, waiting until 2018 is in beta to figure it out). Ok sounds good. Can this comment more explicitly say \"Rust 1.30 addsimpl<'a, T> From<&'a Option> for Option<&'a T>\"?. This is much uglier than I had hoped XD (not that we can avoid it). This seems unrelated?. What's important here is that one is just a normal pointer, not a reference. Rust makes no guarantees about raw pointers. If aliasing here is UB then virtually every cast from reference to raw pointer is UB. What's important is that we never use the aliasing pointers in a way that actually violates aliasing rules. While both pointers exist at the same time, we never dereference more than one of them.. I don't think we want this change. It commits us to supportingOption<&'a T> -> Option<&'a U>for any type where&'a T: Into>, which isn't enabled by your PR to Rust. typo here, \"special casing\" is two words (surprised clippy didn't catch this). I've just been allowing this elsewhere to avoid the git churn, but I guess it's not too bad if it's only in two places.. Let's avoid using private API in new tests.sql_queryif we must, but this can just use the normal insert API. Can we just add anallowfor that instead?. Either way, this seems unrelated to your change, and should probably be done in a PR that bumps clippy, not here. Hm... I was more envisioningfn bytes(&self) -> &[u8]onPgValue, and then we'd just donot_none!(value.bytes()). Oh this is interesting. We could probably just stick a reference to the metadata lookup onPgValuebut I'm not sure I want to do that.. In these cases we don't care since we know it's not looking at the oid. We should probably encode this somehow though if we don't make arbitrary lookup possible here.. Actually no, we don't need to do any of that._oidabove is the right value.. I'd like all these fields to be private. The struct should not be destructurable. I'm not clear why this is needed. We allow.nullableon expressions which are already nullable, andNullableworks fine regardless of the SQL type forT. I'd rather be consistent and not have this bound.. Let's not delete whitespace :). I don't think we need this test if we have the doctest.. WDYT aboutSelectNullableDslinstead?. OIDs aren't fixed, which is why we have the dynamic lookup in the first place.. Removing thebash-completioncommand is a breaking change, and shouldn't be done in a 1.x version. We need to keep that command and print a deprecation warning.. Once https://github.com/rust-lang/rust/issues/48055 lands, we can just havedata: [u8]as the final field of the struct. Until then, we'll probably need to useNonNull<[u8]>. Not without removing the entire abstraction and special casing this one place :\\. No, the diff is just a bit confusing because theexpected a numbererror appeared twice before. Yes, since this is implemented in terms ofString. If this weren't generic, the constraint wouldn't be required.. I'm not sure I understand what you're saying. Do you mean that you expected this to be helpful for when you *want* to use the newtype on your struct, requiring only aFrom` impl instead of the relevant trait?\nThe goal of this feature is to let you write impls on newtypes for coherence purposes, but not have to use the newtype on your struct (since they tend to be painful to use). Keep in mind, a lot of this cases this is meant to enable are cases where the inner type isn't supported by Diesel (e.g. all the folks who want impl FromSql<Binary, Sqlite> for Uuid). I don't think the folks asking questions about it have generally ever been to this page in the first place. Yes, otherwise you have to specifically put the flag before any subcommand. I think showing the diff can be done as a future enhancement. . I do want to mention what file it's looking at here -- What do you think about --locked-schema?. It's just from back when Expression was a supertrait of NonAggregate. It's safe to remove.. Because we don't want U: NonAggregate as a bound.. This needs to be stuff::table. I'd just do ERROR unused here, and have fewer lines to change if the displayed path changes.. Or I guess it's st elsewhere in the file. There should be an empty line here.. I don't like the use of the word \"installed\" for this. What do you think of \"Note: This module requires enabling the r2d2 feature\". What do you think about migrations.sort_by_key(|a| a.path()) instead?. These sort of comments tend to get out of date with the code, and we prefer not to have them. Context like this is better kept in the commit message instead.. It's an interesting idea, but I think it needs work to be added (delimiters, indicating what it actually is, etc). There's a discussion to be had here, but either way that should be a separate PR, not part of this one.. This lifetime should be elided. Whoops this is the one I meant to leave in. We should discuss this more and see if there is a better option for this. I'm not sure I follow you. Those re-exports don't show up in docs at all. This is just moving the same implementation we've had over. For there to be a name collision you'd have to write a function declaration which uses the name of an argument as the type of another which seems odd enough to ignore IMO. I agree, but it also makes the generated code harder to read (which people do). It's possible, but would require more work than just s/this function/#fn_name. I'm actually not sure if it's even worth having these doc comments at all. The module they're being generated for is #[doc(hidden)] and if it wasn't, it's still only pub(crate) so this never gets rendered in docs. It's pretty much only there if you look at the expanded code. The generated code shouldn't have branches though. I guess it does have a lot of loops. I'm torn on how to word this, since not all capabilities of the old macro can be done with sql_function!.. I don't think we need this comment. Yeah, that's fine. This is only the compile tests. We don't officially support nightly, we just bump this periodically as needed to be able to run the compile tests (which require nightly). We should remove the gating on the uses of this feature as well (grep try_from). We don't need to document this since it's a point release. Ah I see. Can you update the FIXME comment to specify which Rust version we can use it?. ",
    "nikomatsakis": "@sgrif this seems good. The hard part I guess might be finding these examples later -- I'll try to keep a log. For what it's worth, this would probably be addressed by the semi-proposal for negative reasoning I advanced in this comment, which itself is just a variant on rust-lang/rfcs#1148. \n. ",
    "aturon": "@sgrif Thanks for the heads up! In general issue comments like this are fine -- perhaps you could have a meta-issue with links to various examples as they come up, just so there's ultimately one place to track?\n. ",
    "Pyriphlegethon": "This problem could possibly be solved by using a PhantomData marker similar to these two examples: ebfull/pcap and hyperium/hyper.\n. ",
    "weiznich": "When supporting multiple aggregate columns we should consider that there could be queries that mix aggregate and non-aggregate fields. See for example the following query:\nSQL\nSELECT a.id, count(b::id) FROM a LEFT JOIN b ON a.id = b.a_id GROUP BY a.id;. @jonnybrooks As far as I know there is no process in those operators made. Feel free to try to implement it. If you hit any problem just ask in out gitter room.. @JohnMH See #1561 for unsigned integers in MySQL. *~ are recovery files created by most editors. I think such files should be allowed/ignored. Furthermore there may be other examples(emacs uses #filename# for example).\nI see three possibilities here: \n1. maintain a list of \"allowed\" file endings\n2. simply check if there is a down.sql and a up.sql in the migrations dir\n3. remove all \"temporary\" files from the migrations dir\n. I've played a bit with making a custom Connection outside of diesel which does the logging on each command. I came up with the following interface/implementation:\n(I mainly write this because this won't make it into 1.0. So this don't get lost till one implement this feature)\n```rust\n[derive(Debug, Clone, Copy)]\npub enum TransactionState {\n    Start,\n    Commit,\n    Abort,\n}\npub trait Logger: Send + Default {\n    fn on_establish(&self, url: &str);\n    fn on_transaction(&self, state: TransactionState);\n    fn on_execute(&self, query: &str);\n    fn on_query(&self, source: &T)\n        where T: QueryFragment,\n              DB::QueryBuilder: Default;\n}\n[derive(Debug)]\npub struct LogConnection {\n    inner: C,\n    logger: L,\n}\nimpl SimpleConnection for LogConnection\n    where C: Connection,\n          L: Logger\n{\n    fn batch_execute(&self, query: &str) -> QueryResult<()> {\n        self.logger.on_execute(query);\n        self.inner.batch_execute(query)\n    }\n}\nimpl Connection for LogConnection\n    where C: Connection,\n          L: Logger,\n          ::QueryBuilder: Default\n{\n    type Backend = C::Backend;\n    type TransactionManager = LogTransactionManager;\nfn establish(database_url: &str) -> ConnectionResult<Self> {\n    let logger = L::default();\n    logger.on_establish(database_url);\n    C::establish(database_url).map(|inner| LogConnection { inner, logger })\n}\n\nfn execute(&self, query: &str) -> QueryResult<usize> {\n    self.logger.on_execute(query);\n    self.inner.execute(query)\n}\n\nfn query_by_index<T, U>(&self, source: T) -> QueryResult<Vec<U>>\n    where T: AsQuery,\n          T::Query: QueryFragment<Self::Backend> + QueryId,\n          Self::Backend: HasSqlType<T::SqlType>,\n          U: Queryable<T::SqlType, Self::Backend>\n{\n    self.logger.on_query(&source.clone().as_query());\n    self.inner.query_by_index(source)\n}\n\nfn query_by_name<T, U>(&self, source: &T) -> QueryResult<Vec<U>>\n    where T: QueryFragment<Self::Backend> + QueryId,\n          U: QueryableByName<Self::Backend>\n{\n    self.logger.on_query(source);\n    self.inner.query_by_name(source)\n}\n\nfn execute_returning_count<T>(&self, source: &T) -> QueryResult<usize>\n    where T: QueryFragment<Self::Backend> + QueryId\n{\n    self.logger.on_query(source);\n    self.inner.execute_returning_count(source)\n}\n\nfn transaction_manager(&self) -> &Self::TransactionManager {\n    // See the implementation of `std::path::Path::new`\n    unsafe {\n        &*(self.inner.transaction_manager() as *const C::TransactionManager as\n           *const LogTransactionManager<C::TransactionManager>)\n    }\n}\n\n}\n[derive(Debug)]\npub struct LogTransactionManager {\n    inner: T,\n}\nimpl TransactionManager> for LogTransactionManager\n    where C: Connection,\n          L: Logger,\n          ::QueryBuilder: Default\n{\n    fn begin_transaction(&self, conn: &LogConnection) -> QueryResult<()> {\n        conn.logger.on_transaction(TransactionState::Start);\n        self.inner.begin_transaction(&conn.inner)\n    }\nfn rollback_transaction(&self, conn: &LogConnection<C, L>) -> QueryResult<()> {\n    conn.logger.on_transaction(TransactionState::Abort);\n    self.inner.rollback_transaction(&conn.inner)\n}\n\nfn commit_transaction(&self, conn: &LogConnection<C, L>) -> QueryResult<()> {\n    conn.logger.on_transaction(TransactionState::Commit);\n    self.inner.commit_transaction(&conn.inner)\n}\n\nfn get_transaction_depth(&self) -> u32 {\n    self.inner.get_transaction_depth()\n}\n\n}\n```\nThis could nearly be implemented outside of diesel. \nThe following changes must by applied inside of diesel to make this fully working:\n Add a Clone-trait bound for AsQuery and fix all errors rustc is throwing at you\n Generalize this ExecuteDsl impl for all Connections with Connection::Backend = Sqlite (Not sure if this is possible outside of diesel, or how I must change that code). > The main problem with that implementation is that I made the mistake of encouraging code written as &PgConnection, not C: Connection<Backend = Pg>, meaning this will likely need to be part of Connection itself.\nThat's a bit unfortunate, but is it really required that logging works out of box for existing implementation?\n\nI also doubt this could ever be (efficiently) implemented outside of Diesel, since any outside implementation would have to force the query builder to run when we would normally skip it because it's in the prepared statement cache and looked up by QueryId.\n\nIn the interface that I've proposed above there is a Default bound on QueryBuilder. This means it is possible to construct a QueryBuilder and use it from there. (::diesel::debug_sql works from outside of diesel, so one could simply use this method there or call QueryFragment::to_sql() with a constructed QueryBuilder). @diesel-rs/core I would like to propose that we discuss this issue again in the context of diesel 2.0.\n\nThe main problem with that implementation is that I made the mistake of encouraging code written as &PgConnection, not C: Connection, meaning this will likely need to be part of Connection itself.\n\nCouldn't this be simply \"solved\" by doing type PgConnection = LogConnection<diesel::PgConnection, MyLogger>; in your crate root and then fixing the includes?. Thanks for the comments. I will rework this to use codegen instead.\n. I've updated the pull request according to your comments.\n. Is there anything preventing this from being merged, except of time?\n. Hopefully all style nitpicks are fixed. If not please leave a comment.\n. Most changes in the migration module are needed to reuse the code in codegen (migration::migrations is not public). Furthermore I add a function to run migrations from a Iterator instead of running them from a directory.\nThe codegen part does more or less what you describe.\n. I revisited and minimized the changes in the migration module.\n. Thanks for the comments. \nI've updated the pull request according to your comments.\n. Is there anything preventing this from being merged, except of time?\n. Thanks for the style fixes, but does the style guide not explicitly saying that brackets after multiline function definition needs to be  on the next line? Did I miss read something or should the guide being updated? Maybe someone should try to write a appropriate config for rustfmt?\n. Yes\n. I will fix the testbuild as soon as I have some spare time. I've manly opened this pull request to start talking about this. (Maybe I should  have mention this, when I've opened this request). Also this is missing a strategy to log the binded parameters.\nWhat do you exactly mean with backend specific features? Queries using parts that are only available with a specific backend? Or custom functions implemented on a specific backend. The former should work with the current implementation, as it passing everything down to the specific backend in the end. The later wont work in the current state. (Is this needed at some point?)\nRegarding to compile tests: There is already an doctest, testing the usage of PgConnection or SqliteConnection as inner connection. So if this one compiles I think there are only tests needed to check the functionality (Are there are some tests for PgConnection/SqliteConnection?)\n. I've updated the pull request to work with the newly introduced caching mechanisms. \nAlso I added some tests:\n- All tests in diesel_tests are run against the normal connection and the debug connection\n- I added 2 test to check if the logged query is right. To verify those results tests with the debugging connection cannot run in parallel, because in that case there might be also a log of a other test case in there. (If more tests are needed here, it should be fairly simple to add them) \n- pg_specific_expressions_cant_be_used_in_a_sqlite_query.rs also checks now against the debug_connection \nWhat`s left:\n- Add some way to log the query parameters\n- check the code style\n- maybe remove debug_sql and friends? They shouldn't be needed after this.\n. Any comments on this?\n. Take your time. There is no need to have this merged in the next few days.\n. Any news?\n. @nmrshll I think this belongs to the getting started guide on our homepage. Feel free to submit a PR there, that mentions that the postgres variant needs libpq and the mysql variant libmysqlclient. I would say that we cannot list the package names for all distros out there, therefore we should just say that you need those libraries.. Hopefully formatting is a bit better now. I've tried to remove most of the indentation related changes.\n. > I'm not sure I like passing the foreign key around like this. The goal of the API was to abstract away how two tables are joined together.\nIf we abstract away which foreign key is used to join two tables it's not possible to have multiple joins between tables. See #332. In a second step we could maybe try to abstract the key away for cases where there is only one possible join?\n\nThis is missing tests for the added behavior, both behavioral and compile-fail.\n\nThere is not that much added behaviour in this pull request: \n- [x] Joins over multiple tables -> There is already an test case\n- [ ] Ability to join tables multiple times with different foreign keys \n- [ ] additional optional parameters on belong_to and has_many annotations\n- [ ] compile-fail tests for selecting a column that is not part of the join\n\nIn particular, it seems like the resulting type is wrong. users.inner_joins(posts).inner_joins(comments) would return (User, (Post, Comment)) not (User, Post, Comment) if I'm reading this correctly?\n\nYes the returning type is (User, (Post, Comment)). I wouldn't call this wrong. I could (and maybe should) change this to (User, Post, Comment). But on the other hand having something like this: users.left_outer_join(posts).inner_join(comments) should maybe result into something like (User, Option<(Post, Comment)>) so the current variant matches this type as close as possible.\n\nIn general I've been moving away from multiple joins as a solution for associations anyway, as once you've introduced more than one join into the mix, it's often significantly better to run two queries, as the amount of duplicate data sent over the wire is significantly reduced.\n\nI currently try to implement the following query using diesel:\nsql\nselect t.*, o.*, u.*, v.*, w.* from tile_versions as t \n    inner join tiles as ts on t.tile_id = ts.id \n    inner join bounding_boxes as b on ts.bbox = b.id  \n    inner join geo_points as o on b.o = o.id\n    inner join geo_points as u on b.u = o.id\n    inner join geo_points as v on b.v = v.id\n    inner join geo_points as w on b.w = w.id\nwhere ts.geometry_id = 1 and t.version_id=1;\nIf I try to implement everything without any join something like this is the result\nsql\nselect t.*, o.*, u.*, v.*, w.* from tile_versions as t, \n    (select * from geo_points) as o,\n    (select * from geo_points) as u,\n    (select * from geo_points) as v,\n    (select * from geo_points) as w\nwhere t.version_id = 1 and \n    t.tile_id IN (select id from tiles where geometry_id = 1)\n    and o.id IN (select o from bounding_boxes where id in (select bbox from tiles where geometry_id =1))\n    and u.id IN (select u from bounding_boxes where id in (select bbox from tiles where geometry_id =1))\n    and v.id IN (select v from bounding_boxes where id in (select bbox from tiles where geometry_id =1))\n    and w.id IN (select w from bounding_boxes where id in (select bbox from tiles where geometry_id =1));\nPostgres Explain results for the query 1 in \"Nested Loop  (cost=3.54..11.12 rows=16 width=213) \" and for query 2 in \"Nested Loop Semi Join  (cost=6.31..87.46 rows=1 width=213).  A other solution would be to split of the selection of the bounding_box. The result would be a loop in my rust code iteration over every tile and than loading the corresponding box using 4 queries. Probably there are also cases where using separated queries will result in a poor performance. Because of that I'm thinking it should be possible to write such queries in diesel. Nobody say it must be easy, but it should be possible without relaying on plain sql and losing almost all type checking abilities of diesel.\n. As @sgrif explained this won't work in this way.\n. Our policy for including mappings between certain SQL types an rust types is like following:\n Either a rust type is able to represent all possible values of the matched SQL type and  also the SQL type could represent all values of the rust type\n Or the type is a fundamental type like boolean.\nThe first condition is not fulfilled because there at Text and also Binary values that are no valid uuid's (for example all shorter or longer values)\nIn my opinion also the second point is not fulfilled because uuid is not that fundamental like for example booleans. (If anyone from @diesel/core disagrees, pleas response here :wink:)\nGiven that (and given that it is quite easy to write a new type wrapper for this outside of diesel) I would say that impl should not be part of diesel itself.. In my opinion NaiveDate (and similar types) falls in the same category like booleans. They are fundamental in such a way that it is not possible to write larger application without using them. So not supporting the is not an option.\nOn the other hand it is possible to write large application without using uuid's, because for nearly all use cases using a 64 bit identifier should be enough. . The same is happening for eq_any in select.\n``` rust\n[test]\nfn select_in_empty_array() {\n    use schema::users::dsl::*;\n    let connection = connection();\n    let user_ids:Vec = Vec::new();\nlet actual_users: Vec<User> = users\n    .filter(id.eq_any(&user_ids))\n    .load::<User>(&connection)\n    .unwrap();\n\nlet expected_users: Vec<User> = vec![];\nassert_eq!(expected_users, actual_users);\n\n}\n```\nBacktrace:\nthread 'main' panicked at 'index out of bounds: the len is 0 but the index is 0', ../src/libcollections/vec.rs:1167\nstack backtrace:\n   1:     0x564915aef2bf - std::sys::backtrace::tracing::imp::write::h6528da8103c51ab9\n   2:     0x564915af39fb - std::panicking::default_hook::_$u7b$$u7b$closure$u7d$$u7d$::hbe741a5cc3c49508\n   3:     0x564915af367f - std::panicking::default_hook::he0146e6a74621cb4\n   4:     0x564915ae286e - std::panicking::rust_panic_with_hook::h983af77c1a2e581b\n   5:     0x564915af3c41 - std::panicking::begin_panic::he426e15a3766089a\n   6:     0x564915ae3dea - std::panicking::begin_panic_fmt::hdddb415186c241e7\n   7:     0x564915af3bde - rust_begin_unwind\n   8:     0x564915b297df - core::panicking::panic_fmt::hf4e16cb7f0d41a25\n   9:     0x564915b29952 - core::panicking::panic_bounds_check::h14f942e6ac026712\n  10:     0x5649158886af - _<collections..vec..Vec<T> as core..ops..Index<usize>>::index::h4863830f0426cb69\n                        at /buildslave/rust-buildbot/slave/nightly-dist-rustc-linux/build/obj/../src/libcollections/vec.rs:1167\n  11:     0x564915888206 - _<diesel..expression..array_comparison..Many<T> as diesel..query_builder..QueryFragment<DB>>::to_sql::h04ea5398a50d0208\n                        at /home/user/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/master/diesel/src/expression/array_comparison.rs:122\n  12:     0x56491594b58c - _<diesel..expression..array_comparison..In<T, U> as diesel..query_builder..QueryFragment<DB>>::to_sql::hb077a8a5ee258ebd\n                        at /home/user/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/master/diesel/src/expression/array_comparison.rs:52\n  13:     0x56491594b093 - _<diesel..expression..predicates..And<T, U> as diesel..query_builder..QueryFragment<DB>>::to_sql::h92cd07251e370466\n                        at /home/user/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/master/diesel/src/expression/predicates.rs:55\n  14:     0x56491594aef8 - _<diesel..query_builder..where_clause..WhereClause<Expr> as diesel..query_builder..QueryFragment<DB>>::to_sql::he2873b9c28d1257d\n                        at /home/user/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/master/diesel/src/query_builder/where_clause.rs:59\n  15:     0x564915949223 - _<diesel..query_builder..select_statement..SelectStatement<ST, S, F, D, W, O, L, Of, G> as diesel..query_builder..QueryFragment<DB>>::to_sql::h8f51b06912f2f50b\n                        at /home/user/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/master/diesel/src/query_builder/select_statement/mod.rs:160\n  16:     0x564915943b25 - diesel::pg::connection::PgConnection::prepare_query::h43506e9ca901658b\n                        at /home/user/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/master/diesel/src/pg/connection/mod.rs:149\n  17:     0x564915943268 - _<diesel..pg..connection..PgConnection as diesel..connection..Connection>::query_all::hacdd6d89b0f35ea9\n                        at /home/user/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/master/diesel/src/pg/connection/mod.rs:72\n  18:     0x564915943143 - _<T as diesel..query_dsl..load_dsl..LoadDsl<Conn>>::load::h27debfc27bb7977a\n                        at /home/user/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/master/diesel/src/query_dsl/load_dsl.rs:53\n. #519 fixes only empty insert statements.\nAs my second comment states, there is a similar issue with select in statements.\n(Side node: #480 fixed this)\n. I would like to look into this. Is there any specific reason why quick_error and not error_chain is used?\n. I'm not that familiar with quick_error, but I'm using error_chain in an other project. \nAs far as I understand error_chain wraps quick_error and adds some stuff on top of this. For example it let you easily link other error_chain generated errors into your chain. Also there is some code around the actual error-enum generated (Implementation of Display and std::error::Error). Furthermore the error-type contains an optional backtrace. Take a look at the documentation for more details.\nWhat are the next steps for this pull-request? Changing BuildQueryResult form Result<(), Box<Error+Send>> to something generated exact error and then fixing all compiler errors?\n. I've opened a pull-request to @killercup repo to implement the remaining point. \n. @mehcode @gfortaine Adding to that we probably also need something like existential types because otherwise we are not able to use async functions as part of traits. I'm not sure what's the time line for stabilisation there. . @mehcode From that standpoint: Maybe just implement it using the unstable nightly features and put it behind the already existing unstable feature flag?. @mehcode Would it possible to somehow summarize your current plan in our forum?\nMerging those 2018 edition PR's should be possible as soon as we've figured out what's up with our CI (again\u2026) and where to export our macros.. @sgrif unfortunately it seems to be not that simple.\nUsing the following code: \n```rust\n[derive(Clone, Copy)]\n[repr(i16)]\nenum Color {\n    Red = 1,\n    Green = 2,\n    Blue = 3,\n}\n// Use the type like every other type provided by diesel\ntable!{\n     users{\n         id -> Integer,\n         name -> Text,\n         hair_color -> Nullable,\n     }\n }\n[derive(Queryable, Debug, Clone)]\nstruct User {\n    name: String,\n    hair_color: Option,\n}\n[derive(Debug, Clone, Insertable)]\n[table_name = \"users\"]\nstruct NewUser<'a> {\n    name: &'a str,\n    hair_color: Option,\n}\nuse diesel::types::*;\nuse diesel::expression::AsExpression;\nuse diesel::expression::helper_types::AsExprOf;\nuse diesel::pg::Pg;\nuse diesel::row::Row;\nuse std::error::Error;\nimpl FromSqlRow for Color {\n    fn build_from_row>(row: &mut R) -> Result> {\n        match i16::build_from_row(row)? {\n            1 => Ok(Color::Red),\n            2 => Ok(Color::Green),\n            3 => Ok(Color::Blue),\n            v => panic!(\"Unknown value {} for Color found\", v),\n        }\n    }\n}\nimpl<'a> AsExpression> for &'a Color {\n    type Expression = AsExprOf>;\nfn as_expression(self) -> Self::Expression {\n    AsExpression::<Nullable<SmallInt>>::as_expression(*self as i16)\n}\n\n}\nfn test() {\n    use self::users::dsl::;\n    use diesel::;\nlet p = PgConnection::establish(\"\").unwrap();\n\nlet u = NewUser{\n    name: \"\",\n    hair_color: None,\n};\n\nlet u: User = insert(&u).into(users).get_result(p).unwrap();\n\n}\n```\nproduces the following error about missing implementations:\nerror: no method named `get_result` found for type `diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>>` in the current scope\n  --> src/lib.rs:76:42\n   |\n76 |     let u: User = insert(&u).into(users).get_result(p).unwrap();\n   |                                          ^^^^^^^^^^\n   |\n   = note: the method `get_result` exists but the following trait bounds were not satisfied: `diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>, diesel::query_builder::insert_statement::Insert, diesel::query_builder::returning_clause::ReturningClause<(users::columns::id, users::columns::name, users::columns::hair_color)>> : diesel::query_builder::QueryFragment<_>`, `&diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::AsQuery`, `_ : diesel::query_builder::QueryFragment<_>`, `&diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::Query`, `&diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::Query`, `diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::Query`, `diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::Query`, `&mut diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::AsQuery`, `_ : diesel::query_builder::QueryFragment<_>`, `_ : diesel::query_builder::QueryId`, `&mut diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::Query`, `&mut diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::Query`, `&mut diesel::query_builder::insert_statement::InsertStatement<users::table, &NewUser<'_>> : diesel::query_builder::Query\nIn an ideal world one would only have to implement ToSql and FromSql  for any custom type.. @sgrif Finally I've got a working implementation against diesel 0.10.\nThe following traits needs to be implemented: (Implementation omitted)\n```rust\nstruct MyCustomType;\nimpl ToSql for MyCustomType{}\nimpl ToSql, DB> for MyCustomType{}\nimpl FromSql for MyCustomType{}\nimpl FromSqlRow for MyCustomType{}\nimpl AsExpression for MyCustomType{}\nimpl<'a> AsExpression for &'a MyCustomType{}\nimpl<'a> AsExpression> for &'a MyCustomType{}\n```\nCompared to this 6 implementation the implementation of the CustomSqlType trait is rather short and easy. (I'm not saying we should go that specific way, but this needs to be improved in some way). @sgrif As shown above this won't work if you start to use the type with LoadDsl. (Maybe I'm missing something?). > This deserves a hint in the documentation (or a more prominent one, in case it's already documented)\nIt is already in the docs. For example here.\nDo you have any suggestion where we may add a more prominent hint?\n. @sgrif If we change the root location of the relative path used in this macro it is possible to implement this using macros 1.1. See #470 .\n. Travis is failing while building compilertest. Any idea why?\n. Using compiletest 0.2.3 didn't fix this.\n. I realized that this fixes the issue only partially. I will try to add tests and provide a better fix for this in the next few days.\n. I've updated the implementation to handle more cases. Also I realized that this could also fix #384.\nI'm not sure if I've implemented is_empty in all places where it is needed.\n. I think using a custom error for this would be problematic, because I think a user expect such queries to succeed. Furthermore with using an is_empty method we can save a call into the database, because we can reason about situations where the query would be illegal.\n. Any news on this? It's annoying and error prone to check in every place where you use eq_any or insert for an empty input.\n. @sgrif I've opened a pullrequst to @killercup repo which rebases and improves his pull request.. There is #429 open, which add support for adding custom type mapping. This could be used to map an enum to an integer.\n@sgrif stated in #483 he is not sure if he want to add support for this in diesel. I've extracted the corresponding code here so it could be used without landing this pull-request. (If needed I could also upload it to crates.io). @killercup I've updated the pull request. Now all planed features are implemented. Any idea why the Travis is failing?. @killercup I've implemented a other variant for the error handling. . All tests are passing on beta now. There are failures on nightly, but they are seaming unrelated to this pull request.\nIf there are no more issues regarding the code style I think this should be ready to be merged.. Thanks for opening the pull request. I'll try to have a look at it tomorrow. . @killercup I've reviewed and merged your changes (Thanks again). Also I added some small tweaks. I think this should be ready for merge now, if all tests are passing.. @killercup I've fixed the last failing test and rebased on master. All tests are passing now. I also addressed those small style nitpicks.\n. It's working without the need of having a box. Iterator itself implements IntoIterator, therefore it is sufficient to call .iter() on the array.\nSee the embedded_migration code for an example. (In special line 56). @killercup I'm able to reproduce this, as you assumed this related to dependency change. Building diesel with clap 2.19 will produce a fully working build, but building with 2.20 (the most current version) will produce a build that showed the described issue.. It seems like that this lock is ignored because diesel uses a cargo workspace and therefore a common lock file for all workspace members. The common lock file should be located in the workspace root.. Serde does something like this to prevent such issues. This should solve the $crate issue.\nI assume the first commit should be submitted as own pull request? It only moves the remaining modules from diesel_codegen_shared to diesel_codegen.. I opened a new pull request that only removes diesel_codegen_shared for now. (See #613 )\nAfter the new pull request was merged I could open followup pull requests to move the codegen from the macro implementation to diesel_codegen. \n(In my opinion the generation by syn/quote is much more readable and shorter as the current macro implementation). @AndrewSpeed Feel free to take it. If there is any problem just ask here or (preferable) in our gitter channel.. @killercup Rebase is done. Any news on this?. I played little bit with some rustfmt flags. The result is something like the following:\n```rust\nstruct A {\n    a: i32,\n    b: i32,\n}\ntrait Foo {}\ntrait Bar {}\ntrait Baz {}\nfn foo() -> ()\n    where T: Foo,\n        B: Baz,\n        W: Foo,\n        SomethingLonger: Foo + Baz + Bar,\n{\n    println!(\"\")\n}\nfn boom() -> ()\n    where T: Foo,\n{\n    println!(\"\")\n}\nfn many_args(\n    a: i32,\n    b: i32,\n    c: i32,\n    d: i32,\n    e: i32,\n    f: i32,\n    g: i32,\n    h: i32,\n    i: i32,\n    j: i32,\n    k: i32,\n    l: i32,\n    j: i32\n) -> i32\n    where T: Foo,\n        B: Bar\n{\n    println!(\"\")\n}\n```\nNotability to the current format:\n\nwhere is moved to the line of the first where bound. I don't think this is a problem because adding a new bound will only add a new line\nfunction argument list does not have a tailing comma. This is unfortunate, but there seems no option to change this\n\nThe following rustfmt.toml was used\n```toml\nwhere_trailing_comma=true\nwhere_pred_indent=\"Tabbed\"\nfn_return_indent=\"WithWhereClause\"\nfn_arg_indent=\"Tabbed\"\nfn_args_layout=\"Block\"\nstruct_trailing_comma=\"Always\"\nstruct_lit_trailing_comma=\"Always\"\nmatch_block_trailing_comma=true\nmatch_wildcard_trailing_comma=true\n```\n. > The where on a new line is very unfortunate to me. Why are its entries (from the second on) indented by two levels? At least they got a trailing comma in there. ;)\nThe entries an indented by two levels, because the config tells rustfmt to do so. Changing where_pred_indent to \"Inherit\" moves the bounds to the same level as the where clause.\nAbout the new line: At leas it does not introduce any additional lines into the diff of an patchset.\n\nFTR, here's how I'd format a complex closure in a nested method chain (similar but not identical to how you did it #692):\n\nThe best I've got out of rustfmt is the following: (Not quite the same :disappointed: )\nrust\n    let foobar_thingy_name: ImATypeName = syn::aster::from_generics(model.generics.clone())\n        .with_predicates(model.generics\n            .lifetimes\n            .iter()\n            .map(|l| {\n                syn::WherePredicate::RegionPredicate(syn::WhereRegionPredicate {\n                    lifetime: l.lifetime.clone(),\n                    bounds: vec![insert.lifetime.clone()],\n                })\n            }))\n        .build();\n\nAnd here are deeply nested types (also from #692):\n\nRustfmt fails to format this type definitions. They remain unchanged without any message. (Even if the formatting is clearly broken.)\n\nThis has been proposed before. It's still blocked on rust-lang-nursery/rustfmt#815.\n\n@sgrif If I understand correctly, the where keyword is only put on the same line as the return type to generate simpler diffs for patchsets? \nThe proposed variant does also not introduce any overhead to the generated diff, if the first bound is not removed. (But mostly in this cases you will also remove the corresponding type parameter and then also the function definition is changed.)\nI think introducing a semi-automated variant, that get thinks \"right\" (whatever this means in this context) in most cases will reduced the overhead introduced by the style discussion on each pull-request. I think I've sufficiently shown that getting the style right is quite hard (Or maybe I don't spend enough attention on such things?)\n(I do not suggest to introduce this now, but it should be some kind of goal for the next few releases.)\n. For me this looks like a bug inside of libpq, because if you look at the code we are passing a pointer to PQfinish that is guaranteed to be not null. Therefore it would be great to know what exact version of libpq is causing this. \nAdditional side node: We are running our tests on travis to, so this seems not to be the only condition to reproduce this.. Drop and therefore PQfinish is called in every case if RawConnection goes out of scope, independently if this is an error case, a success case or a panic (if rustc does not use panic=abort)\nSo for me this is an additional indicator that this may be an issue in libpq or a internal used library. To fill a bug report there we  need a reproducible test case for this. The first step there would be to get the exact version of libpq. . I've tried to dig a bit into this. The first thing that I've tried was to disable all unrelated tests, till only that one that triggers the bug is left. Turns out that there is no single test triggering this. At least photos::test::photo_create_get and s3::test::upload_unauthorized needs to be run to trigger this. If I run only on of them the segfault does not happen. \nSo next step was looking at the code of both tests. Turns out only photos::test::photo_create_get does something with a database, the s3 test does not create a database connection. For me that's a sign that the problem is not database related, but somewhere else. \nNext thing I've tried was to minimize the code in both test cases. For the photos test, only the setup needs to be run, for the s3 test everything needs to be run. After those changes the segfault only happens sometimes \ud83d\ude1f See the attached patch for the exact changes. If I try to strip down the photos test even more I begin to see OpenSSL related errors: \n\n OpenSSL error 1 \nBUG: rust-openssl lock 1 already unlocked, aborting\nAborted (core dumped)\n\n\n OpenSSL error 2 \nssl_ciph.c(403): OpenSSL internal error, assertion failed: ssl_mac_secret_size[SSL_MD_MD5_IDX] >= 0\nAborted (core dumped)\n\nNext stop was trying to get some backtraces to see what's exactly happen here. Turns out there are different backtraces for the same crash. All those have in common that the segfault happens inside of jemalloc during deallocation of something. One (the last one) of those backtraces does not show libpq or anything diesel related, so in my opinion this is clearly not diesel related at this point, the error must be somewhere else.\nSo blind guessing what is happening here: Both, libpq and rusoto seems to depend on openssl. Somehow someone get's openssl into some state that does something really strange (possibly corrupting the allocator??). Therefore the crashes that we observe are only the results of the actual error.\n\nBacktrace 1\n\n```\n#0  0x00005555569ea783 in je_arena_bitselm_get_mutable (chunk=0x7ffff1c00000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:710\n#1  je_arena_mapbitsp_get_mutable (chunk=0x7ffff1c00000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:788\n#2  je_arena_mapbitsp_get_const (chunk=0x7ffff1c00000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:795\n#3  je_arena_mapbits_get (chunk=0x7ffff1c00000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:809\n#4  arena_run_reg_dalloc (run=, ptr=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/arena.c:306\n#5  arena_dalloc_bin_locked_impl (tsdn=, arena=, chunk=, ptr=, bitselm=,\n    junked=) at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/arena.c:2963\n#6  0x0000555556a019b7 in je_tcache_bin_flush_small (tsd=, tcache=, tbin=0x7ffff22e42a8, binind=, rem=10)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/tcache.c:137\n#7  0x00005555569dff8c in je_tcache_dalloc_small (tsd=0x7ffff1c00000, tcache=, ptr=, binind=20, slow_path=false)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/tcache.h:419\n#8  je_arena_dalloc (tsdn=, ptr=, tcache=, slow_path=false)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:1441\n#9  je_idalloctm (is_metadata=false, slow_path=false, tsdn=, ptr=, tcache=)\n    at include/jemalloc/internal/jemalloc_internal.h:1170\n#10 je_iqalloc (tsd=, ptr=, tcache=, slow_path=)\n    at include/jemalloc/internal/jemalloc_internal.h:1187\n#11 ifree (tsd=, ptr=, tcache=, slow_path=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/jemalloc.c:1896\n#12 0x0000555556912645 in _$LT$diesel..pg..connection..raw..RawConnection$u20$as$u20$core..ops..drop..Drop$GT$::drop::h03caa4735911d86e (self=0x7ffff1c3c300)\n    at /root/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-1.3.3/src/pg/connection/raw.rs:101\n#13 0x000055555575dbfe in core::ptr::drop_in_place::h9acbcd85800b00a4 () at libcore/ptr.rs:194\n#14 0x0000555555756aa1 in core::ptr::drop_in_place::h04c2dc3962a5d1f7 () at libcore/ptr.rs:194\n#15 0x00005555557579fe in core::ptr::drop_in_place::h1e2f8d0938f10505 () at libcore/ptr.rs:194\n#16 0x000055555575e3be in core::ptr::drop_in_place::ha2e9101fbdea6a2a () at libcore/ptr.rs:194\n#17 0x000055555575923d in core::ptr::drop_in_place::h42cc81964b1f195e () at libcore/ptr.rs:194\n#18 0x00005555556b3b7c in _$LT$alloc..vec..Vec$LT$T$GT$$u20$as$u20$core..ops..drop..Drop$GT$::drop::hd46f22b389075231 (self=0x7ffff1cf8bb0)\n    at liballoc/vec.rs:2108\n#19 0x0000555555759a01 in core::ptr::drop_in_place::h4a35b8241e83c0ab () at libcore/ptr.rs:194\n#20 0x000055555575ff41 in core::ptr::drop_in_place::hc0444852ccad62a7 () at libcore/ptr.rs:194\n#21 0x000055555575e06e in core::ptr::drop_in_place::h9de0a46a68ac3b72 () at libcore/ptr.rs:194\n#22 0x000055555575fcd4 in core::ptr::drop_in_place::hbbff7e05e32b76eb () at libcore/ptr.rs:194\n#23 0x000055555575793e in core::ptr::drop_in_place::h1a968a0ac74f0681 () at libcore/ptr.rs:194\n#24 0x000055555575d024 in core::ptr::drop_in_place::h8f7222ad5e89af57 () at libcore/ptr.rs:194\n#25 0x00005555557bd539 in _$LT$alloc..sync..Arc$LT$T$GT$$GT$::drop_slow::he1a7f7be16948ef1 (self=0x7ffff21fcf78) at liballoc/sync.rs:535\n#26 0x00005555557bdb48 in _$LT$alloc..sync..Arc$LT$T$GT$$u20$as$u20$core..ops..drop..Drop$GT$::drop::h4bb6017166197e6e (self=0x7ffff21fcf78)\n    at liballoc/sync.rs:986\n#27 0x000055555575703e in core::ptr::drop_in_place::h0e05b11abafd7c66 () at libcore/ptr.rs:194\n#28 0x000055555575da1e in core::ptr::drop_in_place::h987a6d498314de68 () at libcore/ptr.rs:194\n#29 0x000055555566b333 in photothing_api::photos::test::setup::h51c6ea83ff6502ca () at src/photos.rs:89\n#30 0x000055555566b6a4 in photothing_api::photos::test::photo_create_get::h2a3c0f07075334d1 () at src/photos.rs:94\n#31 0x0000555555805022 in photothing_api::photos::test::photo_create_get::_$u7b$$u7b$closure$u7d$$u7d$::h4f2d22478459737e () at src/photos.rs:93\n#32 0x0000555555755dbe in core::ops::function::FnOnce::call_once::h72028cabb6f107ca () at libcore/ops/function.rs:238\n#33 0x000055555582ad4f in {{closure}} () at libtest/lib.rs:1468\n#34 call_once () at libcore/ops/function.rs:238\n#35 _$LT$F$u20$as$u20$alloc..boxed..FnBox$LT$A$GT$$GT$::call_box::he56a774394cbb882 () at liballoc/boxed.rs:661\n```\n\n\nBacktrace 2\n\n```\n#0  0x00005555569ea783 in je_arena_bitselm_get_mutable (chunk=0x7fffecc00000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:710\n#1  je_arena_mapbitsp_get_mutable (chunk=0x7fffecc00000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:788\n#2  je_arena_mapbitsp_get_const (chunk=0x7fffecc00000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:795\n#3  je_arena_mapbits_get (chunk=0x7fffecc00000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:809\n#4  arena_run_reg_dalloc (run=, ptr=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/arena.c:306\n#5  arena_dalloc_bin_locked_impl (tsdn=, arena=, chunk=, ptr=, bitselm=,\n    junked=) at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/arena.c:2963\n#6  0x0000555556a019b7 in je_tcache_bin_flush_small (tsd=, tcache=, tbin=0x7ffff22e4068, binind=, rem=100)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/tcache.c:137\n#7  0x00005555569dff8c in je_tcache_dalloc_small (tsd=0x7fffecc00000, tcache=, ptr=, binind=2, slow_path=false)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/tcache.h:419\n#8  je_arena_dalloc (tsdn=, ptr=, tcache=, slow_path=false)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:1441\n#9  je_idalloctm (is_metadata=false, slow_path=false, tsdn=, ptr=, tcache=)\n    at include/jemalloc/internal/jemalloc_internal.h:1170\n#10 je_iqalloc (tsd=, ptr=, tcache=, slow_path=)\n    at include/jemalloc/internal/jemalloc_internal.h:1187\n#11 ifree (tsd=, ptr=, tcache=, slow_path=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/jemalloc.c:1896\n#12 0x00007ffff77fe00d in CRYPTO_free () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#13 0x00007ffff78a599d in ASN1_primitive_free () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#14 0x00007ffff78a5d0f in ASN1_template_free () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#15 0x00007ffff78a5baa in ?? () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#16 0x00007ffff78a5d0f in ASN1_template_free () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#17 0x00007ffff78a5baa in ?? () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#18 0x00007ffff78a5d0f in ASN1_template_free () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#19 0x00007ffff78a5baa in ?? () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#20 0x00007ffff78a5c65 in ASN1_item_free () from /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n#21 0x00007ffff757bff3 in ?? () from /usr/lib/x86_64-linux-gnu/libpq.so.5\n#22 0x00007ffff7563756 in ?? () from /usr/lib/x86_64-linux-gnu/libpq.so.5\n#23 0x00007ffff7563837 in ?? () from /usr/lib/x86_64-linux-gnu/libpq.so.5\n#24 0x00007ffff75638d6 in PQfinish () from /usr/lib/x86_64-linux-gnu/libpq.so.5\n#25 0x0000555556912645 in _$LT$diesel..pg..connection..raw..RawConnection$u20$as$u20$core..ops..drop..Drop$GT$::drop::h03caa4735911d86e (self=0x7ffff1c3c240)\n    at /root/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-1.3.3/src/pg/connection/raw.rs:101\n#26 0x000055555575dbfe in core::ptr::drop_in_place::h9acbcd85800b00a4 () at libcore/ptr.rs:194\n#27 0x0000555555756aa1 in core::ptr::drop_in_place::h04c2dc3962a5d1f7 () at libcore/ptr.rs:194\n#28 0x00005555557579fe in core::ptr::drop_in_place::h1e2f8d0938f10505 () at libcore/ptr.rs:194\n#29 0x000055555575e3be in core::ptr::drop_in_place::ha2e9101fbdea6a2a () at libcore/ptr.rs:194\n#30 0x000055555575923d in core::ptr::drop_in_place::h42cc81964b1f195e () at libcore/ptr.rs:194\n#31 0x00005555556b3b7c in _$LT$alloc..vec..Vec$LT$T$GT$$u20$as$u20$core..ops..drop..Drop$GT$::drop::hd46f22b389075231 (self=0x7ffff1cf8bb0)\n    at liballoc/vec.rs:2108\n#32 0x0000555555759a01 in core::ptr::drop_in_place::h4a35b8241e83c0ab () at libcore/ptr.rs:194\n#33 0x000055555575ff41 in core::ptr::drop_in_place::hc0444852ccad62a7 () at libcore/ptr.rs:194\n#34 0x000055555575e06e in core::ptr::drop_in_place::h9de0a46a68ac3b72 () at libcore/ptr.rs:194\n#35 0x000055555575fcd4 in core::ptr::drop_in_place::hbbff7e05e32b76eb () at libcore/ptr.rs:194\n#36 0x000055555575793e in core::ptr::drop_in_place::h1a968a0ac74f0681 () at libcore/ptr.rs:194\n```\n\n\nBacktrace 3\n\n```\n#0  0x00005555569ea783 in je_arena_bitselm_get_mutable (chunk=0x7ffff1600000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:710\n#1  je_arena_mapbitsp_get_mutable (chunk=0x7ffff1600000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:788\n#2  je_arena_mapbitsp_get_const (chunk=0x7ffff1600000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:795\n#3  je_arena_mapbits_get (chunk=0x7ffff1600000, pageind=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/include/jemalloc/internal/arena.h:809\n#4  arena_run_reg_dalloc (run=, ptr=)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/arena.c:306\n#5  arena_dalloc_bin_locked_impl (tsdn=, arena=, chunk=, ptr=, bitselm=,\n    junked=) at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/arena.c:2963\n#6  0x0000555556a019b7 in je_tcache_bin_flush_small (tsd=, tcache=, tbin=0x7ffff22e42a8, binind=, rem=0)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/tcache.c:137\n#7  0x0000555556a02781 in tcache_destroy (tsd=0x7ffff21ff4f8, tcache=0x7ffff22e4000)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/tcache.c:371\n#8  0x0000555556a025a5 in je_tcache_cleanup (tsd=0x7ffff21ff4f8)\n    at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/tcache.c:410\n#9  0x0000555556a02efc in je_tsd_cleanup (arg=0x7ffff21ff4f8) at /rustc/8876906867b2db3c7177d69dd020c40d89177f86/src/liballoc_jemalloc/../jemalloc/src/tsd.c:82\n#10 0x00007ffff6f33f82 in __nptl_deallocate_tsd () at pthread_create.c:158\n#11 0x00007ffff6f34197 in start_thread (arg=0x7ffff21ff700) at pthread_create.c:325\n#12 0x00007ffff6a4b03d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\n```\n\ncc @sfackler as openssl maintainer (because of the rust-openssl error while minimizing), @matthewkmayer as rusoto maintainer (because the second required test depends heavily on rusoto). I've managed to write a \"simple\" program that reproduces this issue:\n```rust\n// diesel = {version = \"=1.3.3\", features = [\"postgres\", \"r2d2\"]}\nextern crate diesel;\n// reqwest = \"=0.9.5\"\nextern crate reqwest;\nuse std::thread;\nuse std::env;\nuse reqwest::Client;\nuse diesel::r2d2::;\nuse diesel::;\ntype PgPool = Pool>;\npub fn init_db_pool() -> PgPool {\n    let db = env::var(\"DATABASE_URL\").expect(\"missing database url\");\n    let manager = ConnectionManager::::new(db);\n    Pool::new(manager).expect(\"db pool\")\n}\nfn request() {\n        let url = \"https://google.com\";\n        let _res = Client::new().put(url)\n            .body(\"some content\")\n            .send()\n            .expect(\"request failed\");\n}\nfn main() {\n        for i in 0..10 {\n                println!(\"Try {:?}\", i);\n                let b = thread::spawn(|| {request()});\n                let a = thread::spawn(|| {let _ = init_db_pool();});\n                a.join();\n                b.join();\n        }\n}\n```\nRunning this code in the docker container provided above does the following for me:\n Dead lock\n Segfault with various stack traces\n(This does also happen on newer nightlies, so this does not depend on the rustc version)\n@matthewkmayer This means this is not a rusoto issue\n@seanmonstar Any idea on this (The second part is reqwest).. > haven't read much of the code, but it currently fails on CI for this case:\nerror: no rules expected the token `{`\n   --> src/macros/mod.rs:752:33\n    |\n748 |       table! {\n    |  _____- starting here...\n749 | |         use types::*;\n750 | |         use macros::tests::my_types::*;\n751 | |\n752 | |         table_with_custom_types {\n    | |                                 ^\n753 | |             id -> Integer,\n754 | |             my_type -> MyCustomType,\n755 | |         }\n756 | |     }\n    | |_____- ...ending here: in this macro invocation\nThis is caused by the second rewriting rule that is used to parse the #[doc] attribute and place the content to the back. A similar error would pop up if we use the same syntax for the columns. (From a short view seems like it is very hard or even impossible to provide the /// syntax with the current implementation of the table! macro)\nI'm a few weeks abroad, so I'm not able to work in this time on this. I will continue the development as soon as I returned. (Feel free to close the pull request in the mean time.). I've changed the syntax to that one proposed by @killercup and fixed the failing test cases. This should be now ready to be merged.. > Do you think you could add some compile-tests for valid and invalid syntax combinations? I'm not sure we have a comprehensive test suite for table!. It's a pretty complicated beast by now, and we should probably at least add tests for new features.\nI've tried to add a compile fail macro for invalid syntax, but compile-test complains error: 0 unexpected errors found, 1 expected errors not found. It seems like that compile-test does not recognize error that originates outside of the tested crate. \n. > Maybe you can add this one with one more case for the explicit error thing you introduced. We can always add more tests later. (I'd add \"compile-success\" tests as more doc tests.)\nFor example the following code should trigger the explicit error I've introduced:\nrust\ntable! {\n     some wrong syntax\n}\nRustc prints the following error:\nerror: environment variable `invalid table! syntax` not defined\n  --> src/lib.rs:59:1\n   |\n59 | / table!{\n60 | |     some wrong syntax\n61 | | }\n   | |_^\n   |\n   = note: this error originates in a macro outside of the current crate\nIf I add this table! call to your compile-fail-test without an error annotation this test will still pass :(\n(For the new syntax there should be at least 2 compile pass test. On doc test and one at the end of macros/mod.rs). > Okay, it seems compiletest is a bit fuzzy in what macro errors it finds or even looks for. This works for me:\n\n\none table! call per tests\nexactly one \"error-pattern\" matcher below\n\n\nThis did not work for me. (I've added the first two as test cases, but the second one will fail:()\n\nAlso, I just remembered something: You macro syntax allows all attributes, not just doc ones. Is this on purpose? Do we want that?\n\nThis could be quite handy, because so you can also add things like #[allow(missing_docs)] to the generated code. (Maybe this should also be documented?). > I'm not convinced we actually want that. It's not clear to the user where the attributes end up, and, more important, this macro should not be seen as something to generate Rust code (IMO), but as something that creates a mapping to \"the SQL side\".\nOn the other hand this macro generates Rust code internally. So there is a possibility that someone manages to set warnings in such a way that the generated code does not compile(For example #[deny(missing_docs)] before this pull request). \nThere are two ways to handle this:\n1. Allow to add those attributes to the generated code. Downside: Expose some underlying implementation details.\n2. If such a warning is triggered fix that warning in the generated code. Downside: To fix an eventually occurring issue some time is needed (Implement the \"fix\", open a pull request, wait for review, wait till a new version containing those change is published).\n(It should be no big problem to remove this, but I think this would be a quite helpful feature in some cases). What is the way forward with this pull request? How do we want to handle the failing compile-fail test? . @killercup ping\n. Restricting this to doc comments should only require some small change. I think I must change the $doc:meta variables to $doc:expr and modify the parser from #[$doc] to #[doc=$doc].\nI would like to hear @sgrif opinion about this.. @killercup Any news on the failing compile test?. > Other than that, I still don't like the \"environment variable invalid table! syntax not defined\" message, \nIf there is a better way to produce an error message there, I'm happy to change this. But it seems like as long as compile_error is not implemented/stable that there is no better solution to achieve this. Without this message the macro will recuse endless.\n\nit's weird how big this PR is for this simple change\n\nTo implement this change some bigger parts of the table!-macro parsing logic needed to be restructured. This results in the big diff :disappointed: \n(Compile tests are fixed now, so this should be ready to merge). @killercup I've updated the pull request to address @sgrif comments. \nAs far as I could tell it should be quite easy to plug something like #424 into the \"new\" parsing structure, but I've not tried it\u2026. Also I've found a small bug involving multi line doc comments on columns. This is fixed by the second commit.. @mikhail-krainik That was this thing. But be warned: I'm quite sure doing that is a bad idea\u2026. Maybe someone should rise concerns here about the none breaking extensibility of the ErrorKind field?. Example code. I've prototyped an solution for the runtime cacheing here. This allows to use the enum feature across different database instances.\nThe caching is implemented on connection layer, so it should work even if different instances are used in parallel.\nThe implementation is missing some error handling and the handling of enum array type combinations. So see it as something to start iterating over.. I've used a slightly different approach to get the type lookup working inside of ToSql. This reuses most of the already written code and does not change that many parts of the existing interface. Furthermore it does not require any hacks including mem::transmute or &'static references.. > I'd prefer to avoid exposing the entire connection object to ToSql, especially since until now it's been entirely concerned about the backend and not the actual underlying connection.\nAs far as I can understand we must expose the connection in some kind to ToSql, because otherwise we could not reason about dynamic sql types (We may need to query the database. To query the database we will need the connection.)\nFurthermore, we do not really expose the connection for all backend. We expose a type, that implements MetadataLookup in theory this could be anything. In practice in case of the Pg backend it is because of the restriction that we may need to query the database the actual connection object. For other back ends this must not be true.\nIf there is any better solution to this, I'm quite happy to change it. But as explained above, I think we need to expose the connection in some kind, because we need to execute queries in some cases.. @sgrif  I've updated the branch to do not expose PgConnection to ToSql. The macro is able to parse this, because we disallowed every attribute but  #[doc=\u2026].\nThere are some tests are failing. (diesel_cli::print_schema).. @greenpdx Your issue is slightly different than that one described here. You are trying to load a nullable sql type (Nullable<Timestamp>) into a not nullable rust type (NaiveDateTime). Diesel does not support such mappings to prevent errors. Instead try to change the rust type into Option<NaiveDateTime>.. @GopherJ That error message indicates that you trying to load a Timestamp into a string which is not supported. You need to enable the chrono feature and use chrono::NaiveDateTime for this.. Opened #995 for the runtime lookup part.. It would have been somewhat easier if for me to implement this, with a clearer perspective how to get this merged and clear points what exactly needs to be fixed (And why in a certain way;)).\nAnyhow, I'm happy to see some movement on this topic. . @kevinmichaelchen There is no good solution for this on sqlite and mysql. \nThere are several bad solutions:\n SELECT id from table ORDER BY id DESC LIMIT 1;\n Use LAST_INSERT_ID that has some issues as noted by Sean above\n Generate the id in your rust code\n Use postgresql and returning :wink:. As written above, I know about the alternatives. It simply seems to be inconsistent to have private types in the public interface.. How does one use those helper types when the query source is no raw table, but a join?\nSomething like this?\nrust\n Select<Filter<Join<self::groups::table,\n                               self::user_is_member_of_group::table,\n                               joins::Inner>,\n                        Eq<self::user_is_member_of_group::dsl::user_id,\n                              Bound<Integer, i32>>>,\n             Nullable<self::groups::dsl::id>>\nfor the following query\nrust\ngroups.inner_join(user_is_member_of_group)\n           .filter(group_user_id.eq(self.id))\n           .select(id.nullable())\nTable dsl:\n```rust\ntable! {\n    groups {\n        id -> Integer,\n        group_name -> Text,\n    }\n}\ntable! {\n    user_is_member_of_group (user_id, group_id) {\n        user_id -> Integer,\n        group_id -> Integer,\n    }\n}\n```. I've added a changelog entry.. > Yeah so as @killercup mentioned, I don't think this is a feature that's appropriate for Diesel itself. I'm happy to help you get it set up as a third party crate though. I thought I had mentioned this before, but I can't find it on the issue tracker so it must have been in gitter or I just never mentioned it. Sorry if I haven't made this clear before now.\nI remember only some discussion about mapping enums to primitive types like integers, but it is ok. Would it be possible to host this crate as part of the diesel-rs organization?\n\nIn general, I think this code should be broken up differently. I think a simpler starting point would be #[derive(PgEnum)], which you place on enums defined in your code. infer_enums! could be built on top of that pretty easily (though I'm not really sure that this needs a macro to infer it. The number of enum types in an application are going to be pretty small compared to the number of tables).\n\nGood point:+1: This will hide the implementation details fro the actual users. It should be quite easily possible to rewrite the current code to that approach.. As stated in the Gitter discussion, this code was originally written to experiment with joining a table multiple times. So it is no big deal to close this pull request.\n\nIt's harder to test\n        We can no longer test the behavior of the derived code inline, it has to go into the integration testing crate, which makes things harder to isolate and makes feedback cycles longer\n\nThere is already no test inline for this functionality(As stated below those tests are missing.) Furthermore, I think most likely those tests will also call #[derive(Associations)] or implement those traits manually.\n\nWe need to improve our test coverage\n        The last two PRs which did this both introduced regressions. I'm not comfortable accepting a complete rewrite of this code unless we improve our test coverage first\n\nAgreed. For this custom derive the following test cases are needed?\n\n[ ] Test simple join child.join(parent)\n[ ] Test reverse join parent.join(child)\n[x] Test self join table.join(table)\n[ ] Test join with custom foreign key name \n\n\nWe lose a convenient place to document things\n        For some of the derives we can document options for the derive on that trait, but that is not the case here. It was nice to have this as a place we could link to in rustdoc that was isolated.\n\nSerde documents the usage of the codegen options in a custom guide outside of rustdoc.\n\nCircular dependencies have complicated our build process\n        The fact that Diesel now needs diesel_codegen has significantly complicated the release process, and has made running bin/test recompile the same crate multiple times, slowing feedback cycles.\n\nThe circular dependency is already introduced, so this should not affect this decision. \n\nIt's not in service of anything specific\n        I'm not against having refactorings in general, but we're right in the middle of a push to 1.0. This doesn't feel like the right time to accept rewrites of this scope.\n\nIf diesel 1.0 is released with the current macro based approach this means those macros are part of the stable api. Therefore it will not be possible to remove them without releasing version 2.0 of diesel. \n. > I'm not clear on how this makes that any easier? Joining to a table multiple times is something that will require more than just changes to internal code. We would need to introduce a public API for controlling table aliasing, which is currently out of scope for 1.0. Otherwise any time you reference a column from a table it would be ambiguous which instance of the table you're trying to reference.\nI've played a bit with implementing this, but got no really useful solution. (At least I've reached a point where it was possible to have multiple #[belongs_to(XY)] annotations and where one could join two tables on different foreign keys, but only one (The aliasing was missing). On @killercup pointed out a much simpler solution for my initial problem, so I've stopped there.)\nWhile playing I needed to decide which traits needs to be implemented if there are multiple #[belongs_to(XY)] annotations for the same parent table to prevent conflicting implementations for JoinTo and BelongsTo. Filter those implementations was much easier on proc macro side, than in the original macro rules code, so I've ported things over. \nThis pull request contains only the cleaned part of porting the dervie, without any of the other experiments.. > If you have two belongs_to with different foreign keys on the same table, then we don't know which one you meant when you say parent.inner_join(child)\nMy idea for solving this problem was to let the argument of the join methods be something that implement some trait (call it JoinOnClause for example). In case of there is only one association between child and parent JoinOnClause would be implemented for parent and child. Otherwise there exist some \"default\" implementation for (parent, foreign_key) and (child, foreign_key) which would clearly state which key should be used. (It is quite simple to find out which traits should be implemented in proc macro derives, therefore those code)\n\nI've actually been warming up to the idea of inferring joinable! from foreign keys. If we were to do that we'd need to warn when two constraints would conflict. \n\nI've managed to go down this route some steps. I've created a trait ForeignKey that got implemented for every foreign key column and contained informations about the child and the parent table. The problem with this is that as soon as you start to add generic implementation of for example JoinTo based on this, it is impossible (I've found no way) to also add a generic implementation for the reversed implementation.. > Can rustdoc be used with proc-macro crates? I haven't tested this in a while.\nYes this seems to be possible.\n\n\nI think this does service Diesel developers, because one can argue it makes the code base easier to contribute to. I'm not sure which of the tow, proc-macros or macro_rules, are harder to write, but currently you need to concern yourself with both. This removes the need to deal with this macro_rules macro in this specific area.\n\nFor me it is much easier to read proc macro code than macro_rules code parsing struct definitions, because the proc macro code uses the same syntax as normal rust code and could be structured in more or less small functions.. > Circular dependencies have complicated our build process\n    The fact that Diesel now needs diesel_codegen has significantly complicated the release process, and has made running bin/test recompile the same crate multiple times, slowing feedback cycles.\nI think it should be possible to remove this circular dependency even if we transform all derives to proc macro implementations. The circular dependency exists because infer_schema! depends on diesel_infer_schema, that depends on diesel. So if we reorder some things it should work without the circular dependency.\nI propose the following change: \n\nRemove everything related to infer_schema! from diesel and diesel_codegen (Should be the infer_schema! macros and the derive_infer_schema custom derive)\n\n-> diesel_codegen does not depend on diesel itself anymore\n\nRename diesel_infer_schema to diesel_infer_schema_intern\nCreate a new crate diesel_infer_schema_codegen for the custom derive.\n\nOptionally apply what @dtolnay has proposed here:\n\n\nReexport the diesel_codegen macros from diesel. This eliminates the need to track two distinct crates to use diesel, and potentially unbreaks embed_migrations! (It is not possible to build diesel without the needed custom derive anymore)\n\n\nCreate a new crate diesel_infer_schema, that contains the infer_schema! wrapper macro and reexports the custom derive from diesel_infer_schema_codegen\n\n\n. Rebased to master and removed the JoinTo implementation.. I've rebased this again to pull in the new test cases. Everything seems to pass.\n@sgrif: Any decision on this yet?. @sgrif It's ok for me, I fully understand your concerns.\nAs mentioned before: changing this after the 1.0 release will be a breaking change, because:\na) It removes public macros from diesel (this could not be solved by hidding some items, because the macros must be public :disappointed: )\nb) If we go with the change proposed here it will alter the crate structure\nSo this means such a change cannot happen without releasing diesel 2.0.. > Also FYI, I have no problem releasing Diesel 2.0 the day general proc-macros become stable.\nPorting the custom derives only need macros 1.1.\n\nI don't care about the numbers in version numbers as long as the breakage for our users is manageable (say, less than 15min of work for a codebase that casually uses diesel).\n\nOne could use this argument also to justify to release version 0.17 before going to 1.0 (just saying). > I'd like us to test that these are actually generating the code we expect. We should execute the queries and expect to see some data back.\nThere are already tests doing this in diesel_test. So I'm not sure if we should add those tests on two location? \n\nI fear this will fail CI with must_use errors, though. Let's add insert some data and assert the results.\n\nThere is an #![allow(unused_must_use)] at the top of the file to prevent this errors.. >  I'd like to at least test that foreign_key is doing the right thing, and probably a test like:\nI've adjusted the diesel_codegen tests to check the generated sql\n\nThe only test I can see which executes a query involving a foreign_key option is the test for self referencing associations.\n\nI've added one test to diesel_tests for this scenario.. Any idea why the tests are failing? It builds fine for me locally using the same rust version (1.19.0). Seems like I missed this commit.\nI've tried to build this branch locally without rebasing it on master. With rebasing to master I was able to reproduce the \"problem\".. Also the docs for associations seems to be out of date.\nFor example they are talking about using #[belongs_to(table)] but not about using the joinable!() macro. (The first is not needed anymore, the second is required now\u2026). There is a type miss match between the returned SQL types and the return types of your function.\nIn detail your sql statement seems to return Date whereas the function is returning NaiveDateTime. Date could be converted to NaiveDate but not to NaiveDateTime. The corresponding sql type for the second is Timestamp. get_result will only load one row, so the return type must be (NaiveDateTime, i32) instead of Vec<(NaiveDateTime, i32)>. If you want to return all values use load or get_results instead.. > Does setting the global config accomplish the same thing? If not I think we should fix this in clap.\nThe documentation of global states explicitly the current behavior, so this seems to be desired or at least not fixable without changing larger parts of clap.\n\nNOTE: Global arguments, when matched, only exist in the command's matches that they were matched to. For example, if you defined a --flag global argument in the top most parent command, but the user supplied the arguments top cmd1 cmd2 --flag only cmd2's ArgMatches would return true if tested for ArgMatches::is_present(\"flag\").. There is also this issue on the clap repo, but setting this flag does not solve the problem\u2026\n\nEdit:\nSetting this flag allows to simplify the fix, as we need now only to perform the recursive lookup.\n. Something like the last commit?. >Based on some cursory testing, it looks like we should only need the .setting(AppSettings::PropagateGlobalValuesDown). However, that setting causes diesel --database-url=... database drop to work, but not diesel database --database-url=... drop. The addition of the database_url_from_cli function doesn't seem to affect it.\nExecuting target/debug/diesel migration run --migration-dir some/migrations/dir  --database-url /tmp/test.db fails for me without the database_url_from_cli function.\nAlso this function may fix the issue with diesel --database-url=.... >  However, those tests pass without your code changes.\nI've modified those tests to run without the DATABASE_URL environment variable. Now migration_run_runs_pending_migrations_custom_database_url_1 fails without the using database_url_from_cli. Fixed by #1304. @diesel-rs/core Any idea what is causing the appveyor failures?. I've hopefully fixed all now broken parts of the documentation and added a changelog entry. From my side this is ready to be reviewed and merged.. > @weiznich Given that this PR is getting quite large, can you give an updated summary on everything that's changed?\nBasically the following things are changed:\n\nRemove diesel_codegen\nRemove diesel::migrations\n\nRemove(Or better rename) the old diesel_infer_schema crate\n\n\nAdd diesel_derive, containing all custom derives (Queryable, QueryableByName, Identifiable, Insertable, AsChangeset and Associated)\n\nAdd diesel_infer_schema containing all infer_schema! related code\nAdd diesel_migrations containing all migration related code . @diesel-rs/core What is missing to get this merged?. Try setting MYSQLCLIENT_LIB_DIR to point to the directory where mysqlclient.dll is stored.. @shijunti19  That's certainly a configuration issue because it's working on our CI. See the CI setup for an example how to set those variables.. >1.  Diesel supports serde_json::Value attributes for DB's that support JSON columns. I'm using SQLite, so I'll have to serialize and deserialize to a TEXT column. Is there a way to use what Diesel has already implemented for JSON columns or will I need to write something from scratch?\n\nIt is generally possible to reuse type conversions that diesel already implements. For example if you want to map the values of an enum to integer values you could implement ToSql in the following way:\n```rust\nenum MyEnum {\n     A = 1,\n     B = 2,\n}\nimpl ToSql for MyEnum {\n    fn to_sql(&self, out: &mut ToSqlOutput) -> Result> {\n        match *self {\n            MyEnum::A => >::to_sql(&1, out),\n            MyEnum::B => >::to_sql(&2, out),\n        } \n    }\n}\n``\n(FromSql::from_sql` could be implemented in a similar way)\nUnfortunately it is not possible to implement this straightforward for serde_json::Value outside of diesel, because of the orphan rules preventing impl's for foreign types and foreign traits. This could by solved by using a local wrapper type. Furthermore all implements for serde_json::Value are mapping this type to a underlying database json type. For me it seems like a better solution to manually transform the serde_json::Value to a string first and then insert this string into sqlite.\n\n\nCan a custom type map to multiple SQL columns (trying to store a 4x4 matrix in SQLite)? If so, is there an example somewhere?\n\n\nI think this is currently not possible, but I may be wrong about it.. diesel::insert currently only supports inserting structs. The error message is indicting that in a really bad way. Rustc assumes one wants to use Into::into instead of IncompleteInsertStatement::into. \nOn diesels master-branch the story around insert changed drastically. The new insert_into method allows setting values directly and also improves the error message.. Try to add enable_multi_table_joins!(rooms, users); somewhere in your crate.. I think this may be a similar issue as #1201. > That doesn't sound right. Assuming DistinctOnDsl comes from your crate, you should be able to implement it for any type. (Note: I'm not opposed to having this in Diesel)\nThe problem is not that I cannot implement DistinctOnDsl for SelectStatement due to the orphan rule, but because I cannot access the fields of SelectStatement to construct the new version of SelectStatement. . Use serde_json::Value instead of that Json type. . This should be doable with our current implementation. We simply need to remove those calls to unwrap and replace them by something returning code with a meaningful error massage using compile_error!.\n(Probably this should be done after #1231 is merged). Tests are failing because master is broken again :disappointed: (Maybe I've some time to fix this today). Rustfmt says the formating is broken, otherwise this looks good :+1:. > We could just as easily fix that by making master require green CI before merging.\nThere was already a case where merging a pull request with green CI broke master. (Note the broken build for the merge commit, but the green build for the last commit in the pull request.)\nSuch situations are not prevented by requiring to have the CI green. \n. In theory this should be already be possible with the current code. \nTake a look at the docs of the Migration trait.\nAlso embed_migrations! already creates the code needed to embed the diesel-cli written migrations in the binary. What is missing is some kind of cli tool to actually print that code.. > Can you please update your commit message to include a link to rust-lang/rust#44890 as context?\nDone. Maybe we should include this in the diesel 1.0.0 release?. @anilanar You need to add an explicit select clause to your query to transform the return type into the right one.\nrust\nusers::table.select((users::id, (users::age,))).load::<UserWithId>(&conn);\nShould work. A other solution would be to manually implement Queryable. > @weiznich I think I might be confused: don't we already have something like it in the same file, a few lines down?\nMy mistake, I forgot that the sqlite type mapping does work in a other way than the postgres mapping.. @top1st Without saying what does not work nobody can and will help you.. @diesel-rs/contributors \nAs far as I remember the representation of rusts bool type is considered a internal implementation detail and may change at any time. So this pull request introduces at least implementation defined behavior. \nSee the most up to date comment I've found about this.\n. > Also the tests for the old macro need to be ported over I think\nThere are no tests for the old macro :worried: . Travis says this needs a rustfmt run. >  I'm not sure why you closed this issue when it hasn't been resolved \nThis issue was closed because diesels policy for open issues is the following:\n\nOpen issues in this repo should represent something that is actionable, and that you could reasonably open a pull request to fix.\n\nThis is clearly a issue with your current setup. We will happily help you there to figure these things out, but this discussion does not belong to the issue tracker. Use our gitter room for such questions.. There are already tests in diesel_derives. > I just saw your comment, how do you feel about --no-clippy?\n--no-clippy is also fine in my opinion\n\nI also wasn't sure if 1acc792 should be pulled into a separate PR or if it was ok to lump it into this one. Thoughts?\n\nI don't think this needs a separate pull request.. The problem is the following line:\nrust\n use schema::node::dsl::*;\nThis imports a type alias for node::table named node, which causes this error message. Changing node::all_columns into ::schema::node::all_columns should fix your problem.. I've failed to reproduce this. Which could you post a complete minimal reproducing example(including the Cargo.lock file) somewhere?. I was able to reproduce this.This is caused by a incompatible r2d2 version in your dependency tree. cargo update -p r2d2 fixed this for me.\n. What happens here if someone calls the following code:\nrust\nupdate(some::table).execute(conn)?;\nIt does just not work because SetNotCalled does not implement QueryFragment, right?\nIf so we may want to add a compile tests for that?. You will need to add a new type wrapper for the chrono::Duration type. Derive AsExpression and FromSqlRow for that type. After that you need to implement ToSql and FromSql for your new type in respect to BIGINTEGER. \nSee this testcase as an example for supporting custom rust types.. No you can't because you own neither chrono::Duration nor FromSql/ToSql. You need to add impl for AsExpression for &'a chrono::Duration similar to that ones in this file\n(I'm not sure if chrono::Duration will be accepted as a supported type for sqlite.). Please add informations about what compiler version you tried to use\n. A replace section will only work in a workspace as far as I know, so you need to add [workspace] to Cargo.toml.. Just add an line with [workspace] into your Cargo.toml and it should work. Alternatively you could try to use a [patch] section. (I've never tried this) . This commit introduced a bug into what queries are allowed as subqueries for eq_any\nAfter this change the following code compiles, but generates invalid sql:\n```rust\ntable!{\n    users{\n       id -> Integer,\n       name -> Text,\n    }\n}\ntable! {\n    posts {\n        id -> Integer,\n        user_id -> Integer,\n    }\n}\nfn test() {\n    let subquery = users::table.filter(users::id.eq(1));\n    let query = posts::table.filter(posts::user_id.eq_any(subquery));\n}\n```\nThis does only happen/work for normal select statements, not for boxed select statements. . > > This matches the behaviour of normal subselect queries\n\nWhere? I don't see that impl\n\nIt just works. It may also be related to the bug written below #1545 .\n(Adding the same impl for SelectStatement generates a conflicting implementation error with the existing impl for SelectStatement). @joelgallant Try looking into diesels own test suit for examples how to write unit tests.\nIt basically boils down to have a function to create connection somewhere and calling begin_test_transaction on that connection before returning it to the test case.. The following code works for me:\n```rust\n[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, FromSqlRow, AsExpression)]\n[sql_type = \"Integer\"]\npub enum PunishmentType {\n    /// The user is locked from adding to game queues.\n    Locked = 1,\n    /// The user can't speak but can read the chat.\n    Muted = 2,\n    /// The user is banned from the server.\n    Banned = 3,\n}\nimpl From for PunishmentType {\n    fn from(value: i32) -> PunishmentType {\n        match value {\n            0 => PunishmentType::Locked,\n            1 => PunishmentType::Muted,\n            _ => PunishmentType::Banned,\n        }\n    }\n}\nimpl FromSql for PunishmentType\nwhere\n    i32: FromSql,\n    DB: Backend,\n{\n    fn from_sql(value: Option<&::RawValue>) -> deserialize::Result {\n        >::from_sql(value).map(PunishmentType::from)\n    }\n}\nimpl ToSql for PunishmentType\nwhere\n    DB: Backend\n{\n    fn to_sql(&self, out: &mut serialize::Output) -> serialize::Result {\n        >::to_sql(&(*self as i32), out)\n    }\n}\n``. This should continue to target master. Only backports of bugfixes should target release branches. New features belonging into the master branch.. Given that it is easily possible to provide implementation for those types outside of diesel I also feel that this live in a 3rd-party-crate. If we see a big demand in supporting this type we could include the support at any future point of time easily from the third party crate. \nThe only downside I see in this approach is that things likeinfer-schema/print-schema` won't work out of the box for this custom type. (But this is a separate issue, for which we could provide a general solution)\n. > This has more duplication than I'd like, but this seems fine.\nAn alternative to prevent some duplication would be to unify field_ty and field_expr. I decided against this because both functions consists more or less only of parts (all quote_parse! calls) that needs to be handled separately. . @diesel-rs/core Adding this implementation is not considered as breaking change, right? (Asking because I needed to change the tests to compile). > Looking at the tests that had to change, I'm not comfortable with this. Strictly speaking it could be called a minor breaking change, but this seems likely to actually affect apps.\nI'm fine with not having this. I've found a other solution for my affected code, so feel free to close this.. I think this will be part of the diesel 1.2 release. . I think I heard somewhere something like soon (as in the next weeks), but take with some caution, because I'm not the one that decides to make a release.. > This needs explicit tests (as does the derive TBH), but other than that this looks fine.\nTo write this test we need to merge #1567 first.. @diesel-rs/reviewers Test is added, so this could be reviewed.. > I believe this was a breaking change\nAccording to RFC 1105 this is not considered as a breaking change that requires a major version bump. Specifically see [this section] (https://github.com/nox/rust-rfcs/blob/master/text/1105-api-evolution.md#minor-change-implementing-any-non-fundamental-trait).\n\nMaybe makes sense to call this out more clearly in the CHANGELOG?\n\nFeel free to open a PR adding a notice about this to the change log.. Do you see a problem with this feature in general, or with the naming?\nIn the second case we could do something similar to serde and use #[diesel(skip)].. @sgrif To point to a practical use of this, see this example from my wundergraph crate.\nIf there is any other way to do something similar that does not involve manually implementing Queryable I'm fine with using it.. So is there any other way to solve this without manually implementing Queryable on each struct needing this?. @mehcode This should be doable by using the methods provided by the Migration in diesel-migrations.. Our cli arguments are entirely handled by clap. Those crate generates help and bash completions for us. \ndiesel database drop is marked as hidden subcommand, therefore it is not shown in diesel database --help\nI'm not sure if that's the intended of clap or if we should report it as bug there.. As travis suggests, this does not \"fix\" the example but break it.\nProbably you did this change because it does not work using this variant in your own code? \nThe issue here is that there are actually two ways to access the table and column definition.\n1. use schema::my_table::dsl::*; and then access the table with my_table and the columns with the name of the column\n2. use schema::my_table; and then access the table with my_table::table and the columns with my_table::my_column\nThe first variant leads to shorter code, while the second variant is clearer to which table a certain column belongs to (useful for writing complicated queries affecting multiple tables)\nSo my guess is that you have a use schema::posts::dsl::*; somewhere in your code so that the code from the example doesn't work. The example code uses the second variant. This is a breaking change because it removes compatibility with the old num-trait version.. > Unless I missed it, this isn't used in our public API\nYes, your right :+1: \nI'm not sure what causes the ci error. Otherwise this look fine.. Seems like we crashing rustc. CI fails because of #1556, some new clippy warnings and some changed compile test output.. The difference to BelongsTo is that this must not be implemented for every relation, but only once for a wrapper type. See the linked commit from wundergraph for a specific example. (This feature is not for normal users of diesel, but rather for people wanting to abstract over certain features in diesel.). Using the embed_migrations! macro from diesel_migrations it is possible to store the sql migrations inside your application binary. If the backend is sqlite and the database does not exist a call to embedded_migrations::run will create a new database file.. This error message means that the environment variable DATABASE_URL is not set at compile time. See the documentation of env! for details.. @sgrif Github means this needs a rebase.. execute returns the number  of affected rows. \nFor mysql there is no way that an insertstatment returns the inserted row, this needs a distinct query.. Yes documentation is missing.\nSean added some check that we really add the documentation.. Diesel 1.3 was released some days ago containing this feature.. Workaround: Change \"large-tables\" into \"32-column-tables\" (Or just remove that feature because that's now the new default).\n@diesel-rs/core As far as I could see this happens because we deny warning in diesel and then drop a warning that we deprecated the large-table feature inside of diesel. So the build will fail. \nAdditionally the error message is really bad. It seems like cargo is hidding the real message because if I use a local diesel clone I get the following message:\nError message\n\n```\nerror[E0550]: multiple deprecated attributes\n   --> /home/weiznich/Dokumente/rust/diesel/diesel/src/lib.rs:1:1\n    |\n1   | / //! # Diesel\n2   | | //!\n3   | | //! Diesel is an ORM and query builder designed to reduce the boilerplate for database interactions.\n4   | | //! If this is your first time reading this documentation,\n...   |\n303 | |                                    select, sql_query, update};\n304 | | pub use result::Error::NotFound;\n    | |________________________________^\nerror: use of deprecated item 'expression::functions::helper_types::not': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/expression/functions/helper_types.rs:14:22\n   |\n14 | pub type Not = not;\n   |                      ^^^^^^^^^\n   |\nnote: lint level defined here\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/lib.rs:113:9\n   |\n113| #![deny(warnings, missing_debug_implementations, missing_copy_implementations, missing_docs)]\n   |         ^^^^^^^^\n   = note: #[deny(deprecated)] implied by #[deny(warnings)]\nerror: use of deprecated item 'query_builder::update_statement::UpdateStatement': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/query_builder/update_statement/mod.rs:23:44\n   |\n23 | pub type IncompleteUpdateStatement = UpdateStatement;\n   |                                            ^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types': The large-tables feature has been renamed to 32-column-tables\n --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:7:9\n  |\n7 | pub use sql_types::*;\n  |         ^^^^^^^^^\nerror: use of deprecated item 'deserialize::FromSql': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:10:9\n   |\n10 | pub use deserialize::{FromSql, FromSqlRow};\n   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'deserialize::FromSqlRow': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:10:9\n   |\n10 | pub use deserialize::{FromSql, FromSqlRow};\n   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'serialize::IsNull': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:13:9\n   |\n13 | pub use serialize::{IsNull, ToSql};\n   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'serialize::ToSql': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:13:9\n   |\n13 | pub use serialize::{IsNull, ToSql};\n   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Bool': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:16:17\n   |\n16 | pub type Bool = ::sql_types::Bool;\nerror: use of deprecated item 'sql_types::Tinyint': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:19:20\n   |\n19 | pub type Tinyint = ::sql_types::Tinyint;\n   |                    ^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::SmallInt': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:22:21\n   |\n22 | pub type SmallInt = ::sql_types::SmallInt;\n   |                     ^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Integer': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:25:20\n   |\n25 | pub type Integer = ::sql_types::Integer;\n   |                    ^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::BigInt': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:28:19\n   |\n28 | pub type BigInt = ::sql_types::BigInt;\n   |                   ^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Float': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:31:18\n   |\n31 | pub type Float = ::sql_types::Float;\n   |                  ^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Double': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:34:19\n   |\n34 | pub type Double = ::sql_types::Double;\n   |                   ^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Numeric': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:37:20\n   |\n37 | pub type Numeric = ::sql_types::Numeric;\n   |                    ^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Text': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:40:17\n   |\n40 | pub type Text = ::sql_types::Text;\n   |                 ^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Binary': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:43:19\n   |\n43 | pub type Binary = ::sql_types::Binary;\n   |                   ^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Date': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:46:17\n   |\n46 | pub type Date = ::sql_types::Date;\n   |                 ^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Interval': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:49:21\n   |\n49 | pub type Interval = ::sql_types::Interval;\n   |                     ^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Time': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:52:17\n   |\n52 | pub type Time = ::sql_types::Time;\n   |                 ^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Timestamp': The large-tables feature has been renamed to 32-column-tables\n  --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:55:22\n   |\n55 | pub type Timestamp = ::sql_types::Timestamp;\n   |                      ^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'sql_types::Nullable': The large-tables feature has been renamed to 32-column-tables\n   --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:106:25\n    |\n106 | pub type Nullable = ::sql_types::Nullable;\n    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'serialize::Output': The large-tables feature has been renamed to 32-column-tables\n   --> /home/weiznich/Dokumente/rust/diesel/diesel/src/types/mod.rs:109:35\n    |\n109 | pub type ToSqlOutput<'a, T, DB> = ::serialize::Output<'a, T, DB>;\n    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'expression::array_comparison::AsInExpression': The large-tables feature has been renamed to 32-column-tables\n   --> /home/weiznich/Dokumente/rust/diesel/diesel/src/expression_methods/global_expression_methods.rs:105:12\n    |\n105 |         T: AsInExpression,\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'expression::array_comparison::NotIn': The large-tables feature has been renamed to 32-column-tables\n   --> /home/weiznich/Dokumente/rust/diesel/diesel/src/expression_methods/global_expression_methods.rs:103:38\n    |\n103 |     fn ne_any(self, values: T) -> NotIn\n    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: use of deprecated item 'expression::array_comparison::NotIn': The large-tables feature has been renamed to 32-column-tables\n   --> /home/weiznich/Dokumente/rust/diesel/diesel/src/expression_methods/global_expression_methods.rs:107:9\n    |\n107 |         NotIn::new(self, values.as_in_expression())\n    |         ^^^^^^^^^^\nerror: use of deprecated item 'expression::Expression::SqlType': The large-tables feature has been renamed to 32-column-tables\n   --> /home/weiznich/Dokumente/rust/diesel/diesel/src/expression_methods/global_expression_methods.rs:105:27\n    |\n105 |         T: AsInExpression,\n    |                           ^^^^^^^^^^^^^\nerror: use of deprecated item 'expression::array_comparison::AsInExpression::InExpression': The large-tables feature has been renamed to 32-column-tables\n   --> /home/weiznich/Dokumente/rust/diesel/diesel/src/expression_methods/global_expression_methods.rs:103:50\n    |\n103 |     fn ne_any(self, values: T) -> NotIn\n    |                                                  ^^^^^^^^^^^^^^^\n\nerror: aborting due to 30 previous errors\nerror: Could not compile `diesel`.\nTo learn more, run the command again with --ver\n```\n\n. > Is there a reason this can't just call .nullable on the select clause? \nAdding a nullable method will require to return a new type. In case of SelectClause<T> this seems to be easy (SelectClause<Nullable<T>), but for DefaultSelectClause this will require some sort of wrapper type. If we add a wrapper type I think it is easier to just use this type everywhere.\n\nOr return Nullable<Subselect<Self>>?\n\nNullable<_> works only with Expression not with SelectableExperession  as far as I see. Also using Nullable<_> on the Subselect seems to be pretty similar to #1547 .. > Is there a reason this can't just call .nullable on the select clause?\nI've tried to do this and failed because of conflicting implementations of SelectableExpression or SelectClauseExpression.\nThings I've tried:\n Add a method fn nullable(self) -> SelectClause<Nullable<T>> on SelectClause<T>\n Change the nullable method on SelectStatement to use this method instead the wrapper type approach in this PR\n(At this point diesel compiles successfully)\n Tried to compile the test case from this PR and got a compilation error\nthe trait bound `diesel::query_builder::SelectStatement<filter::filter_subselect_with_nullable_column::home_worlds::table, diesel::query_builder::select_clause::SelectClause<diesel::expression::nullable::Nullable<filter::filter_subselect_with_nullable_column::home_worlds::columns::id>>>: diesel::expression::array_comparison::AsInExpression<diesel::sql_types::Nullable<diesel::sql_types::Integer>>` is not satisfied\n Looked up the implementation of AsInExpression for SelectStatement. It seems that the implementation does not apply because SelectStatement does not implement SelectQuery because of  SelectClause<Nullable<T>> does not implement SelectClauseExpression because Nullable<T> does not implement SelectableExpression<QS>.\n* Trying to implement SelectableExpression<QS> for Nullable<T> fails with multiple errors regarding conflicting implementations related to joins:\nerror[E0119]: conflicting implementations of trait `expression::SelectableExpression<query_source::joins::Join<_, _, _>>` for type `expression::nullable::Nullable<_>`\nerror[E0119]: conflicting implementations of trait `expression::SelectableExpression<query_source::joins::JoinOn<_, _>>` for type `expression::nullable::Nullable<_>`\nerror[E0119]: conflicting implementations of trait `expression::SelectableExpression<query_builder::select_statement::SelectStatement<_>>` for type `expression::nullable::Nullable<_>`\nAlso there is a comment in the Nullable source file indicating this is by design, so removing those impls is probably not a good idea.\n\nThe next thing I've tried is to implement SelectClauseExpression for SelectClause<Nullable<T>> but this gives a conflicting implementation error for the normal implementation.\n\n\nOr return Nullable<Subselect<Self>>?\n\nI'm not sure how this would actually help if we want to make the nullable step explicit. Otherwise we could simple go with something like #1547 but also for SelectStatement\n. @stahlstift It is not required to add this as a feature to diesel itself, because one could easily specify the bundled linking there using @spease method. (Adding a feature flag for this wouldn't make it easier\u2026)\nFor diesel-cli there is already #1302, which needs someone to fix the remaining review comments. . If you have specific examples in mind please open a PR to add them.. > So from what I am hearing, the only change that needs to be made is to update lib.rs to look like this?\n:+1: \n\nDoes it make sense to add new tests for these methods somewhere?\n\nMaybe change one or two tests to the newly added methods. Just in case somebody tries to remove them for whatever reason.. There is not much we can do about this. The table! macro is just a plain macro_rules macro that gives us no way to emit custom error messages.\nThe documentation of the table! macro already mentions #[sql_name=\"\u2026\"] so I'm quite unsure what else we could do to improve this. In my opinion the only improvement that could be done is to add more documentation on this. The questions is where and what. . In general it is totally possible to implement custom types outside of diesel. The test case you linked is basically the blue print for implementing such an type.\nIt is really hard to answer this question without any code to reproduce this. Please add the your current code and the current (exact) error to the issue. \nI will close this issue because it does not contain anything that actionable for us to fix in diesel. \nFeel free to update the issue with more informations. We will continue to answer this questions here. Or ask in our gitter channel. . In general your policy for the implementation of  FromSql / ToSql for certain types in diesel is something like the three following questions:\n\nIs this a commonly used type. (Yes because there is already support for Jsonb in diesel.\nCould we provide a FromSql and a ToSql implementation for that type. (In this case Yes)\nCould the conversion go somehow wrong because the sql type or the rust type could hold values that are not representable in the other type. (In this case the conversion from Vec<u8> to Jsonb could go wrong, because obviously not every arbitrary byte sequence is a json string)\n\nOnly if we could answer those three questions with:\n\nIt is a commonly used type\nWe could provide both conversions \nNothing could go wrong\n\nwe add support for those types. \nBecause the third question is not answered positively I do not think we want to add support for this conversion (Maybe the members of @diesel-rs/core have a different opinion here?)\n\nIs this the right thing to do? (i.e., Am I missing some other obvious\nalternative?)\n\nAs far as I understood your use case you want to load values into some struct that implements Deserialize or you want to store values from some struct that implements Serialize in a jsonb column, right? \nI see three alternatives here:\n\nWhy not use serde_json::from_value / serde_json::to_value for construction and destruction of the value loaded from/stored in the database?\nIf variant 1 is to noise because you have many such operations in your database, whats about adding support for a custom type (for diesel) to your application. Something like JsonValue<T> and then implement for FromSql and ToSql for this type for all T that implements Serialize / Deserialize. After that you could just use  JsonValue<MyJsonType> at every location that currently supports serde_json::Value.\nIf you have any performance concerns, you could implement FromSql / ToSql for each of your json types and use them directly.. Feel free to take it \ud83d\udc4d . It will require a breaking change because we need do separate Table in such a way that there is a supertrait of Table that contains the AllColumns associated type and the all_columns function. The Table trait would than contain only the PrimaryKey associated type and the primary_key function. It is a breaking change because this would break all code that currently implements Table.\n\n@sgrif Maybe we should introduce a diesel 2.0 tag to have a list of things we may want to fix in 2.0?. diesel_codegen is dead since 0.99. See the Changelog for details.. This is missing a rustfmt run otherwise it looks fine.. In my opinion this is something that should be handled at connection pooling level.\nSo implementing this would require to rewrite the current pooling architecture. There are other issues in the current pooling system so this is something on our backlog. I'm not sure when the rewrite takes place. (Maybe we should first collect some ideas what the new system should be able to handle.)\n. Just to write it somewhere:\nI think this should be done in a similar manner like the implementation of  numeric operations in diesel for various types. This means in detail that instead of providing a index method we should use the Index trait from the std-lib and then return a custom wrapper for codegen from there. (Just like for Add for example). Diesel codegen is dead since 0.99. See the changelog for details.. > I'm not sure I entirely understand the use case here. There certainly seems to be a more generic concept here than just foreign keys. It seems like this is trying to recreate Into.\nMy use case is basically to write a generic type HasOne that contains either a referenced id or the referenced item itself.\nrust\npub enum HasOne<R, T> {\n    Id(R),\n    Item(T),\n}\nI want to use this in my graphql resolver crate, that is build on top of diesel. (Graphql leads to quite nested structures.) For serialization to json/\u2026 it is easier to store the referenced values inline.\nBasically I want to be able to write something like\n```rust\n[derive(Queryable, Serialize)]\nstruct Post {\n    title: String,\n    content: Option,\n    user: HasOne,\n}\n```\nSo the next step is that I need some way to transform graphql \"queries\" into sql queries to load data from the database. My strategie here is to load data by different levels. Given a query that requests all posts with informations about the authors, this means to load all posts first (and populate the HasOne::Id variant). After that load all corresponding users (using the id form HasOne::Id to populate the HasOne::Item variant). To prevent N+1 queries I want to use the existing BelongsTo infrastructure in diesel. This means I need to find some way to implement BelongsTo. Manually implementing it would result in writing a lot of this implementations, so I look for some way to make the existing #[derive(Associations)] work with custom types. In the end it boils down to have some way describing how to handle a certain type in foreign key positions. Currently this is done entirely in diesel_derive by special casing Option.\n\nWould this change serve your use case equally well?\n\nUnfortunately not, because I'm not allowed to write an generic impl for Option<T>\nrust\nimpl<'a, R, T> From<&'a HasOne<R, T>> for Option<&'a R>\nwhere\n    &'a T: Identifiable<Id = &'a R>,\n{\n    fn from(m: &'a HasOne<R, T>) -> Self {\n        match *m {\n            HasOne::Id(ref id) => Some(id),\n            HasOne::Item(ref item) => Some(item.id()),\n        }\n    }\n}. That seems to work. (I didn't even try that because I assumed this would conflict with the default implementation for From). Wait, stop: Turns out this kind of solves only one part of the issue because we have no way to know the correct type for ForeignKey in BelongsTo. This type will change depending on the foreign key wrapper.... If I do not miss something this won't work because we need to change Self::ForeignKey depending on the actual type there.\nFor normal types T we want T. (And we get T)\nFor Option we want also T (And we get T).\nFor HasOne (and other similar types) we want T. (Currently we will get HasOne). No worries. There is no need to merge this in the next day. Better enjoy you vacation :wink:\nRegarding to the name: I'm generally bad in naming things so whenever there is a bad name in any of my PR just suggest a other on.. We are relaying on the dotenv crate for handling .env files. So this should probably be reported there.. This seems to be a regression in rustc.\nSee https://github.com/rust-lang/rust/issues/50825 for details.. Duplicate of #1700. diesel_codegen is dead since diesel 0.99. So do not use it!\nSee the changelog for details.. An other solution would be to publish a empty version as 0.17 or so that does print an error message saying not to use this crate anymore in compilation with recent diesel versions.. So what's about releasing diesel_codegen 0.17 that gives error messages not to use that crate?\nIf someone wants to use diesel 0.16 it is an intentional decision and that person will use diesel_codegen 0.16. If someone uses diesel_codegen by accident (or old guides) there is a message what's wrong. Old projects using diesel 0.16 will continue to work because going from 0.16 to 0.17 indicates a breaking change.. > The issue is people with existing 0.16 projects updating Diesel to 0.99 or 1.0 and leaving diesel_codegen there. \nI'm not sure if that's really the issue. (Let's just ask the next person with that problem :wink:)\n\nIt's not like they'd randomly decide to go to 0.17.\n\nIf they are updating diesel I assume they will also update diesel_codegen to the latest version. In that case will releasing a newer version emitting some error message point them into the right direction. \n\nIf there's a way to get the version of diesel used in a build script, we could add one which makes the compilation fail and release 0.16.whatever\n\nSo we just need to parse Cargo.toml/Cargo.lock? \ud83d\ude48 . Fixed by publishing 0.16.1 of diesel_codegen.. Was fixed by #1789. Using first with sql_query is not possible, because we could not know if the query already contains a limit clause.\nThe error message is quite bad, but there is not much we could do about this. (For some reason Rustc simply fails to see that LimitDsl is not implemented for some type.  ). Duplicate of #1700. @iamcharleschege Look at the original issue for a workaround.(just use a older nightly from before 15/5/18) Otherwise there is nothing we could do beside waiting for rustc to fix that issue. \nPlease remember: Nightly is there for especially this case. To move forward without fear to break someone's code, because there is time before the change reaches the stable release. \nThis means you should test once a while against nightly but you shouldn't depend on nightly for code that needs to compile at any time. For this usecase there is the stable release.. > You should have all the rights you need to create it.\nRight. (I totally forgot about that \ud83d\ude1f ) . > Any reason why you aren't you running this in a build.rs ?\nBecause I've found no way to get the working directory of a down stream crate from build.rs. CARGO_MANIFEST_DIR is set there to the directory where diesel_codegen lives.. > Are we unable to run cargo metadata in a build script?\nIt is possible to run cargo metadata in a build-script, but it is run in the diesel_codegen directory and therefore will result in the dependency list of diesel_codegen. Theoretically we could change the working directory, but I've found no way to get the directory of the downstream crate to run cargo metadata there. (Totally possible that I miss something). > Can you edit .travis.yml to run against this branch in your PR too please?\nI've added the branch to the .travis.yml but it seems like the test suite is broken on current stable + some dependency is broken on the old nightly.. I got finally a green CI on this. I've disabled the clippy CI entry because some dependency (pq-sys) does not support that old rustc version.\nIf there are no objectives I will try to release diesel_codegen as 0.16.1 tomorrow. Do this need a changelog entry? Or a distinct tag?. I vote against removing the infer_schema_internals crate because I plan eventually to provide a diesel print-schema like utility for wundergraph at some later point. It would be nice to reuse the existing code to load a schema from the database to write such an tool. So maybe it is possible to keep it as a separate crate?. I'm with @sgrif on this. A crate that exposes this functionality as public api should be written from scratch. I'm fine with temporally moving this inside of diesel-cli. As soon as someone starts working on that new crate those code could be used as starting point. It will not be more work to copy the code from diesel-cli instead of from infer_schema_internals.\n@xianghx Existing code using the old crate will just continue to work, so there is no problem. If we release a rewritten infer_schema crate at some point in time you could just update to the new crate.. Basically a duplicate of #1700 .\nWill be hopefully fixed with the next rustc nightly.. This sounds like you don't have the needed rights to read from the postgres information schema with your current user.. Is your temp directory writable for your current user? If not this seems more like a system configuration issue.. @Deedasmi Could you check if that solves the issue? (I've no windows machine \ud83d\ude09 ). @Deedasmi (or someone other with access to a windows machine) Could you try again? The old solution had some issues. (Hopefully now everything works fine.. It's a rustc bug, see #1700 #1701 #1705 #1711 #1729, #1730 , rust-lang/rust#50825 and rust-lang/rust#51042. > I know that Diesel supports defining custom enum types as well as Rust-side newtypes via diesel-derive-newtype. I am trying to understand whether Diesel supports user-defined newtypes and composite types on the Postgres side as well; the documentation is particularly sparse on this subject.\nSupporting composite types on Postgres side should work the same way like supporting custom enum types there. Documentation is sparse because nobody have written something about that yet. (Presumably because at most only a few people have tried that :wink:, so If you get it working, maybe write a short guide?)\nRegarding to the example code: (There are several small error in there pointed out by the compiler, I will not attempt to fix them here, just apply the compiler suggesting )\nIn general your are on the right track. Similar to you I've tried to do an insert and it seems like the serialization is wrong. For postgresql FromSql is basically something that constructs the binary representation of values passed to libpq, so one must figure out how this representation looks like. Unfortunately this seems to be similar good documented as the feature in diesel (a quick google search showed basically nothing \ud83d\ude1f ). From toying a bit around with the implementation I found out the following things:\n First you need to write the number of fields as Integer to the final representation\n Then you need to write the Oid of the type of the first field. \n* Then you need to write the length in byte of the following type(For BigDecimal this is not that easy because it has a variable length, for Uuid it is easy the size is 16)\n(It's quite late here, so I've stopped playing around further, and rather started to write this comment)\nUpdated implementation of ToSql\nrust\nimpl ToSql<DbEntry, Pg> for Entry {\n    fn to_sql<W: Write>(&self, out: &mut serialize::Output<W, Pg>) -> serialize::Result {\n        ToSql::<sql_types::Integer, Pg>::to_sql(&1, out)?;\n        ToSql::<sql_types::Oid, Pg>::to_sql(&1700, out)?;\n        ToSql::<sql_types::Integer, Pg>::to_sql(&/*Somehow figure out the size here*/, out)?;\n        ToSql::<sql_types::Decimal, Pg>::to_sql(&self.amount, out)?;\n        ToSql::<sql_types::Oid, Pg>::to_sql(&2950, out)?;\n        ToSql::<sql_types::Integer, Pg>::to_sql(&16, out)?;\n        ToSql::<sql_types::Uuid, Pg>::to_sql(&self.currency, out)?;\n        Ok(IsNull::No)\n    }\n}\nThe FromSql implementation should be similar.\n(I will close this issue because this is nothing actionable for diesel itself. Feel free to response here, or even better move to our Gitter channel.). Diesel basically passes the raw sql string without any change to the database, so this seems to be a restriction in postgresql itself or libpq. (So nothing diesel could do much about).\nFrom looking at the postgres operator overview it seems that there are only specific arguments are supported after is (and therefore no bind).\n(For future questions: Our Gitter room is a better place to ask questions :wink:). See #1702 for a fix. That looks strange. We have explicitly a test case testing u32::max_value().\nCould you provide the sql that you used to construct your table?. Short version: This wont work in that way.\nLong version:\nBoth columns on your user table have different SqlTypes. (In detail, id has the type Integer, name has the type Text). Each SqlType is compatible with certain rust types. (Again in detail Integer is compatible with i32, Text with &str and String.) Those types are a compile time thing, that means you cannot switch/match at runtime on them. \nNow you are trying to construct a function that accepts a type T that is compatible to the both SqlTypes. While in theroy such an type could exist, in pratice there is no such type provided by diesel.\n(To fix this function compiling you need to change param.as_expression() into <_ AsExpression<Text>>::as_expression(param) for the name filed and <_ AsExpression<Integer>>::as_expression(param) for the id field, but as written abvoe as soon as you throw in a i32 or a string into that function you will get a unfixable compiler error). > When will this fix be released?\nSee this comment for informations about the next release.\nAs workaround: Just add #![allow(unused_import)] to the module containing the macro call.. That sounds like you are using different versions of bigdecimal. Please doublecheck that your crate depends on the same version as diesel. (Cargo tree could be handy for this). Closed because this does not contain something actionable for the diesel team.\n(If this does not solve the issue, just continue asking here or even better in our gitter room). It's a rustc bug, see #1700 #1701 #1705 #1711 #1729 , #1730 , #1731, #1737 , rust-lang/rust#50825 and rust-lang/rust#51042. @mathroc The issue is fixed since the 8 of June.\n\nit might be interesting to keep one of these issue open until this is resolved. it would avoid people opening the same issue again and again .and give them an issue to subscribe to to be notified when this is resolved\n\nThe issue was closed because of several reasons:\n It is nothing that is actionable for the diesel team. Our policy is than only actionable issues should be open. All other issues are closed. (This does not mean we do not response to questions ask in closed issues, it just means that we categorize issues in a certain way)\n It is a bug in rustc so the bugreport does not belong to the diesel repo, but to the rustc repo. To have a issue to subscribe to people should go there because the issue will be fixed there.. We are working on fixing this. In the mean time use the HTTP version our just build the documentation locally. (Just do cargo doc in your crate and you will have your own copy of the api docs in target/doc/diesel.). Both are equivalent because diesel::prelude exports PgConnection if the as soon as the postgres feature is enabled.\nThat said it would be great to fix this inconsistency. If you (or somebody else) is interested to open a PR: The source for the web page is here\n. Duplicate of #1755. What about just adding a rust-toolchain file with the corresponding version?. > What about nightly then ?\nIt is possible to override the used toolchain using cargo +version ..., correct? \nOtherwise we could just use rustfmt from the nightly that we use for clippy.\n(Also given that clippy is deprecating the plugin in favour of the command line tool our need for nightly will be gone...). I think all builders now use the toolchain specified in rust-toolchain.toml. That makes clippy failing. (I'm not sure if the normal channel builder picking the right toolchain.)\nWhen I remember correctly it is possible to override that using cargo +toolchain command in place of cargo command where toolchain ist something like stable, beta, a stable version or a nightly version. So I think at least the CI command to execute the clippy check must be adjusted. . Done by #1924 . Using #[macro_use] extern crate diesel in your crate root continues to work on the 2018 edition, so there is no need to fix this now. \nOtherwise there is also the possibility to apply a patch file to the generated schema that allows you to automate such changes.\nIf someone is willing to work on this feel free to submit a PR, but I've currently other priorities than \"fixing\" something that's already working.. I think those last comments mix some different things. \n1. Those warnings issued on the latest release if a derive is used.\n2. Making diesel compatible with importing macros by use statements.\nThe first point is unrelated to this issue and already fixed on master. Master currently builds fine, but our ci fails because some dependency bumped its minimal supported rust version above ours. So if you don't need to support rust 1.27 or something you could just use master. \nThe second point is somewhat more complex. I think we all agree that this should be fixed, but it's unfortunately quite complex to do this. I've already a branch somewhere that works in principal. The issue is that rustdoc does not allow me to document those macros in a way I would like. I need to find some time to look into how we could workaround this.. @derekdreery There is already #1956. The only thing missing there is putting all macros exports in the right place.. That sounds like something is wrong with your mysql setup. (I would guess libmysqlclient is missing)\nSee the documentation of mysqlclient-sys (the crate we use for the mysql stuff) for details how to setup the environment.\nI close this issue because this is nothing actionable that could be fixed inside of diesel.\nFeel free to use our Gitter channel  for further questions or response to this issue.. > It's not missing. I installed it. The error happens when compiling diesel_cli\nThat error is clearly a linker error. This means: (ordered by likelihood)\n libmysqlclient is not installed \n libmysqlclient is not found by the linker. See the Readme from mysqlclient-sys for details how to tell the linker where to search\n* libmysqlclient is incompatible with your linker (32bit vs 64bit for example)\n. > Anyone know if this is intentional?\nYes this is intentional.\n\nWhat if someone just wants to use diesel with postgresql? Does everyone need all the dependencies?\n\nIt is possible to compile diesel cli to work only with postgesql using cargo install diesel_cli --no-default-features --features \"postgres\"\nUnfortunately there is no way for us to guess which database system should be enabled and which should not be enabled at build time.. I've tried to reproduce this locally using the provided schema and failed to reproduce this.\n$ diesel print-schema\ntable! {\n    comments (id) {\n        id -> Int8,\n        nid -> Int8,\n        uid -> Int4,\n        pid -> Int8,\n        at -> Nullable<Int4>,\n        likes -> Int4,\n        body -> Text,\n        created -> Timestamp,\n        changed -> Timestamp,\n    }\n}\ntable! {\n    node (id) {\n        id -> Int8,\n        uid -> Int4,\n    }\n}\ntable! {\n    users (id) {\n        id -> Int4,\n        name -> Varchar,\n        mail -> Varchar,\n    }\n}\njoinable!(comments -> node (nid));\njoinable!(node -> users (uid));\nallow_tables_to_appear_in_same_query!(\n    comments,\n    node,\n    users,\n);\n$ diesel --version\ndiesel 1.3.1\nClosed because this does not seem to be a issue.\n(Feel free to add more informations how to reproduce this, but without any idea how to reproduce this there is nothing we can do here.). See this test case for an example. For future questions please use our gitter channel . It is currently not possible. Maybe a later version of diesel may add support for this feature.\nI will close this issue now, because there is nothing actionable for the diesel team in here. \n(To implement this impl Trait on trait functions needs to be supported in rust). on_conflict is a postgresql specific method because it uses postgresql specific syntax. \nAs far as I'm aware of we do not support anything like this on mysql side. \n. There are 2 possible ways here:\n Fall back to raw sql\n Implement the according diesel dsl. This could also be done outside of diesel, but this is something we are also interested to have inside of diesel. Basically you need to implement a mysql version of the diesel postgres upsert implementation. . Could you open a PR for this? The code lives here. \n(Hint: the line needs to be let total = results.get(0).map(|(_, total)| total).unwrap_or(0);)\n. Short version: Because non of the derives given expect a attribute named #[table_name]. See the documentation of diesel_derives to see which attribute is where supported.\nLonger version: A struct implementing Queryable (by the derive) is not related to a specific table by design. It just represents the result of a query with a specific type signature. It's possible to use structs implementing Queryable for queries over multiple table or/and have multiple structs implementing Queryable for a single table. Basically such structs are not 1:1 with tables but more 1:1 with queries (therefore the name :wink:). For mysql it is basically the same. Just use #[mysql(typename = ...)]. For the SQL side simply see the mysql documentation.\n(Also: the only databases system that supports real custom types is postgresql). Then you only need the MyEnum part from that example. Simpley replace MyType with your own random SQL type (that is already supported in diesel).\nBasically you just need to implement FromSql and ToSql and derive AsExpression and FromSqlRow for your type. And don't forget the sql_type annotation.  . > Just use #[mysql(typename = ...)]\nMy mistake it is #[mysql = \"...\"]. You also need to derive SqlType\n(For representing a own type as already implemented type this is not needed.). Something like this: (basically the same as the example above)\n```rust\n[derive(AsExpression, SqlRow, Debug, Clone)]\n[sql_type = \"Text\"]\nenum MyEnum {\n   Foo,\n   Bar\n}\nimpl ToSql for MyEnum {\n    fn to_sql(&self, out: &mut Output) -> serialize::Result {\n        let t = match *self {\n            MyEnum::Foo => \"foo\",\n            MyEnum::Bar => \"bar\"\n        }\n        <&str as ToSql>::to_sql(t, out)\n    }\n}\nimpl FromSql for MyEnum {\n    fn from_sql(bytes: Option<&[u8]>) -> deserialize::Result {\n        match >::from_sql(bytes)? {\n            \"foo\" => Ok(MyEnum::Foo),\n            \"bar\" => Ok(MyEnum::Bar),\n            _ => Err(\"Unrecognized enum variant\".into()),\n        }\n    }\n}\n```\nFor defining own sql types: Just see the definition of types inside of diesel. @sergeysova Unfortunately not because rustdoc does not build our documentation we cannot do a release currently.. @qrilka https://github.com/rust-lang/rust/issues/54524. @r-arias Yes, our ci is failing on windows only. Unfortunately I have no access to a windows machine, so no way for me to track down that issue. Hopefully someone other from @diesel-rs/core (or someone other) with access to a windows machine could help here.\n(That said: That error looks quite strange, because it's only happening on windows and the code that causes this according to rustc has no conditional thing based on the OS \ud83d\ude1f. I also opened a issue on the rustc repo for this: https://github.com/rust-lang/rust/issues/55832 ). @r-arias Yes only sqlite causes problems.. @r-arias That's not a configuration issue of the environment, because it does not fail at the linking stage, but while compiling the rust code. In detail while trying to resolve some traits. Those traits do not depend on any os specific impls and work on all other platforms. (That's probably a bug in rustc but without windows I'm not able to dig further into this.). That would be possible, but how? The same database url is used for the build.rs file to run the migrations, so I do not see how running the migrations would be ok, but running infer_schema on the same url would fail afterwards. . @icefoxen For supporting the new macro import feature we need to change some internal macros. (The issue is basically that we call internally some macros from the exported ones. Because of the macro hygiene rules a user is not able to provide reference to those internal macros.) Till that is done continue to use #[macro_use].. @theduke That seems to be an issue with rustdoc. I've already reported that against rustc, see https://github.com/rust-lang/rust/issues/54524.\nUnfortunately I've no clue what exactly is causing this.. The ci needs to pass before any further review is meaningful.. Someone needs to fix the ci. (We will not merge a PR that breaks the ci :wink:)\n\nIs there any reason that these dependencies have an upper bound on version selection?\n\nWe need a upper bound there because otherwise those dependencies could break diesel if they break the functions that are used inside of diesel. Using only > some version would allow cargo to pull in a new possible incompatible major version.\n. As @sorccu pointed out this was already done by #1837.. > \nerror: cannot find macro table! in this scope\nerror: cannot find derive macro Queryable in this scope\n\nThis sounds like that the #[macro_use] annotation is missing on your extern crate diesel; import.\n(I closed this issue because there is nothing actionable for the diesel team here. Feel free to response here or use our gitter channel to ask future questions.). That ci error looks quite strange. I've played around a bit with the corresponding code:\n```rust\nfn _check(comment :Comment, posts: Post) {\n    _test(&comment, &[posts])\n}\npub fn _test<'a, T, P>(_t: &'a T, _p: &'a [P])\nwhere &'a P: diesel::associations::Identifiable,\n      T: HasTable + BelongsTo,\n      T::ForeignKeyColumn: ExpressionMethods,\n      Vec<_Id<&'a P>>: AsInExpression<::SqlType>,\n      ::Table: FilterDsl>>>,\n      T::ForeignKeyColumn: ExpressionMethods\n{\n    _test2(_t, _p)\n}\npub fn _test2<'a, C, P>(_c: &'a C, _p: &'a [P]) where C: BelongingToDsl<&'a Vec>\n{}\n```\ndoes compile but \n```rust\nfn _check(comment :Comment, posts: Post) {\n    _test2(&comment, &[posts])\n}\npub fn _test2<'a, C, P>(_c: &'a C, _p: &'a [P]) where C: BelongingToDsl<&'a Vec>\n{}\n```\ndoes not.\n@diesel-rs/contributors any ideas?\nOne solution is to \"just\" bump the minimum supported rust version, because on current stable it just works. For me this sounds like a compiler bug \ud83d\ude1f . @diesel-rs/core This requires bumping the minimal (official) supported rustc version to 1.27 because of the compiler bug described above.\nAlso I needed to bump the nightly used for compile tests and clippy because some dependency had a hard version requirement to an newer proc_marco2 version that the one that was working on the old nightly. On the bright side this improved the error messages of our custom derives significantly when using the unstable flag.. @sgrif ping. This meas that libpq is missing on your system (or that the linker cannot find it)\nThere is currently nothing that diesel can do about this, therefore I close this issue. Feel free to join our gitter channel for faster support.. You need to run rustfmt on the changed file to fix the ci otherwise this seems fine. :+1:. Looks fine, but CI continues to fail because of a unrelated issue. (We have already a fix for this but it is currently in review). . Rebasing the commit to the current master branch should fix the ci.. Duplicate of #1739.\n(Rustc uses the derive be in the error message, so this does not point to the actual unused important l. Rebasing the commit to the current master branch should fix the ci.. I don't know the exact representation of every postgres type in libpq. This would be a better question for the libpq/postgis folks.\nIn general serialisation should just be the reverse operation of deserialisation, so just create the same thing you get FromSql::from_sql.\nI close this issue because this is nothing actionable for diesel itself. (The representation is something that is defined by libpq/postgis). You need to use rustfmt from rust 1.26.1.. Could we move the clippy attribute to the affected function, so that we do not apply it to the whole module?. The first point in the getting started there mentions that we could not just reuse the github org, but have to create a new one there:\n\nYou need an Azure DevOps organization. If you don't have one, you can create one for free. If your team already has one, then make sure you're an administrator of the project you want to use.. I've started playing with this a bit. Got something working here, but it seems like I got not everything setup right in the ci, because \"some\" jobs fail :(\n. You are basically describing the current state :wink:\n(You are looking for diesel-migrations, especially embed_migrations!). As the docs metion you need to enable the \"serde_json\" feature to use the conversion form Jsonb to serde_json::Value.. If we change this I think we should just add support for all shells that are supported by clap. So that we have something like diesel generate-completions SHELL.. You need to use rustfmt from rust 1.26.1.\n. I'm not sure I understand why this is necessary. embedded_migrations::run(&db)?; internally checks already if any migration needs to run. . There is already an implementation of on_conflict().do_update() for postgresql here.\n\nWhat needs to be done:\n Move that module to diesel::upsert and add reeports at the current location (otherwise this is a breaking change). Also make this module only available if the sqlite or postgres feature is given.\n See what parts are available on both systems, all other parts should be moved back to the postgres specific module.\n Add a new trait SupportsOnConflictClause and implement it for Pg and Sqlite. (Similar to SupportsReturningClause here)\n For all QueryFragment<Pg> impl's left in the new diesel::upsert module, change them to be impl<DB> QueryFragment<DB> for \u2026 where DB: SupportsOnConflictClause\n* Look for upsert test that apply for both backends and enable them on sqlite. (For example this one)\nFeel free to open a PR early in that progress to get feedback there. Also ask in our gitter channel if you get stuck somewhere.. @sgrif Any news on this?. @rrichardson  Have you tried to just pass the whole list of values to the insert function?\nSomething like this:\n```rust\n::diesel::insert_into(table).values(&vec![\n    (column_a.eq(42), column_b.eq(\"foo\")),\n    (column_a.eq(42), column_b.eq(\"bar\")),\n    // more tuples\n]).execute(conn)?\n```\nThis should generate the following sql query:\nsql\nINSERT INTO table(column_a, column_b) VALUES (42, \"foo\"), (43, \"bar\");\n. > It seems like it is possible to use items from a mod defined inside of a constant by using the full path without self, but it seems not to be possible to create use statements for those things. Not sure if that should be reported as bug against rustc?\nOpened https://github.com/rust-lang/rust/issues/54525 about that.. > Rust 2018 effectively removes this as an option, since extern crate statements are gone. \na) Not everybody will update to Rust 2018, it is also possible to continue using the 2015 edition.\nb) It is also possible to rename the crate on in rust 2018 by changing the name in your Cargo.toml \nc) This broke some of our internal code. I can also fix this there, but again, this was a breaking change and if it's possible to avoid such a thing we should do that, because this will probably affect more users.\n\nI don't think we should remove our ability to write use in derives for something that requires writing unidiomatic code to do.\n\nIt's quite unfortunate that use statements are broken there, but I consider this a bug in rustc that should be fixed there.. What's wrong with sql_query(\"SELECT load_extension('libspatialite-2.so');\").execute(&connection)? as part of your startup sequence?. This is clearly a rustc issue (because it works on stable). Closed because this is nothing that could be fixed in diesel.\nSee https://github.com/rust-lang/rust/issues/54524 for the documentation issue.. @sgrif Needs rebase.. Closed by #1955 . I would vote for continue to use the short form because it is (in my opinion) easier to read.. As far as I can see from that minimal code snippet, the problem seems to be that you use the result only in the print statement. Therefore rustc could not infer the concrete type of total_results because I only knows that those type has to implement a bunch of traits, but multiple types could fulfil that. \nTherefore a explicit type annotation is needed here. (In the examples this is not the case because the assert_eq! explicitly puts a value (with a type) to compare in there.)\nTo make this work there are two solutions:\n Add a type annotation to the variable: let total_results: Result<Vec<i64>, _> = places::table.count().load(connection);\n Add the generic type parameter explicitly to the method call: let total_results = places::table.count().load::<i64>(connection);\n(Closed this issue because our issue tracker should only contain actionable open issues. Feel free to ask such questions in our gitter channel or our forum. CI says this needs a rustfmt (1.26.1) and clippy run.. > Not sure if I missed something on the contrib guide, but do I need to do something else to get approval and merge?\nYou don't missed something, it's just that nobody currently has time to review PR's \ud83d\ude48 \n(More reviewers would be great \u2026). That's more or less out of scope for diesel, because diesel depends on compile time on knowing what database is used and then generates the corresponding sql specific to that database. \nAlso it will prevent using unsupported sql features at compile time. (For example you could only use Unsigned<Integer> using the MySql backend. For all other connections/backends this results in a compiler error. Adding a generic connection type would result in one of the two following strategies:\n Support only a common subset of sql that is supported on all backends (if that even exists and if it's usefull)\n Possibility to generate sql that is invalid (We should not do that, in my opinion.)\n(Closed because this is nothing directly actionable for the diesel team. Use our discourse forum for feature requests.)\n. MariaDB is more or less supported through the MySql backend. \nIn the long term we want to add a distinct MariaDB backend that  shares most of it implementation with the existing MySql backend. \nIf anyone is willing working on this feel free to claim that issue or drop a message on gitter. \n(Changed the title of the issue to make more clear that we want to add a distinct backend.). Feel free to submit a PR to https://github.com/sgrif/diesel.rs-website extending the note section there to directly list which native dependencies are required for which backends. . @h-michael Yes azure pipeline could be ignored. It is just enabled but missing the corresponding pipeline file. (Just started to get #1889 working\u2026). @h-michael \nFor MacOS it seems like the wrong sqlite instalation is used\nFor the linux builds see the inline comments.. I've just noticed that the current implementation does not work for insert statements based on select statements. (See the tests in diesel_tests/tests/insert_from_select.rs. In such cases invalid sql is generated for sqlite. That needs to be fixed before we could merge this :(\nThis means that we need to have a specialized impl of queryable for insertstatements based on select statements for sqlite.. @h-michael These ones. If allow them for sqlite to, they will compile but generate invalid sql. The issue there is that sqlite cannot decide if the ON in INSERT INTO table(Column,List)  SELELCT Column, List FROM table ON CONFLICT DO NOTHING; is part of an on conflict clause or a join clause. \n\nTo avoid a parsing ambiguity, the SELECT statement should always contain a WHERE clause, even if that clause is simply \"WHERE true\", if the upsert-clause is present. Without the WHERE clause, the parser does not know if the token \"ON\" is part of a join constraint on the SELECT, or the beginning of the upsert-clause. \n\n(From the official documentation)\nIn my opinion there are two solutions to get this PR merged: \n\nSomehow add a default where clause like suggested by the sqlite docs for the sqlite insert statement with select statements and conflict clause\nMake those code not compiling for sqlite. (This will need a compile-fail test) and we try to fix that after merging this PR.\n\n(I must say that I've totally missed that case for too long, so sorry for that\u2026)\n. > I think query builder should not automatically insert query that the user unintended.\nInserting a additional WHERE true does not alter the query, but only works around a bug in sqlites query parser. (They even state that in their docs\u2026)\n\nBut I don't know diesel team policy.\nHow do you think about that?\n\nOur policy here is to prevent generating invalid sql as far as this is possible. In this case that's certainly possible. It should be just a matter of some additional traits that are implemented based on the type parameters of InsertStatement and then could be used to prevent generating sql in certain cases or modify the generated sql.\nThat said I would be fine if we use the second suggested solution.\ncc @diesel-rs/core To hear other opinions. > That is either parser bug or spec, we can't guarantee that it remains the same in the future version.\nIf that behavior changed, we should add version specific codes.\nSure we cannot guarantee that this won't change in a future sqlite version, but adding a WHERE true clause if no where clause is existing can never lead to a invalid query. Even if a future sqlite version fixes that, those query will remain valid and behave the same. . Changed Milestone to 2.0 because this needs a solution for the insert by select case. (2.0 is just a placeholder for the next release after 1.4). If you get this ready before this evening (UTC) I'm willing to think about adding it to 1.4, otherwise I won't block the release on this. (The release is already long overdue...). @h-michael We need a compile-fail test for this, not an test that this results in a runtime error.. There is true.into_sql::<Bool> that should work here.. @h-michael That's unfortunate, but there will be a release after 1.4. Just ping me if you need help somewhere.\nThanks for continue working on this.. The lock file was removed in 79af07cc0. If I understand that commit correctly readding it is useless because diesel_cli is part of a workspace, so the workspace lock file is used.. How would Value looks like in that case?\n(I've closed this issue because our issue tracker should only contain actionable bugs where someone is actively working on or where we are looking for help. For feature request use our forum). There was https://github.com/diesel-rs/diesel/pull/1762 to do this, but somehow this PR got stucked.. @diesel-rs/core I've got everything working beside of an trait overflow error on windows for sqlite. Does anyone has an idea what's happening there?. @diesel-rs/core I've found the problem. (Stupid mistake\u2026)\nI propose we merge this PR, disallow uuid 0.7 and then release diesel 1.4. > It looks like CI is failing due to unstable features being tested for the stable and beta versions, but I'm not sure what the cause of this is\nI think this is caused by the rust-toolchain file. I'm not sure what's the right way to solve this\u2026\n@diesel-rs/contributors Maybe we should not add a rust-toolchain file for a compiler version that is not supported any more by diesel? So maybe just bumping rustfmt to 1.30?. Seems like the build of diesel_tests is broken after this.\nAlso this needs a rustfmt run (rustfmt from rust 1.26.1). Thanks. Unfortunately not because we cannot publish new documentation because of a rustdoc issue. See https://github.com/rust-lang/rust/issues/54524 for details.. Uuid 0.7 get's never used because the last release of diesel has no support for uuid 0.7, only master supports the new version.. If uuid changed the name of that feature there is no way for diesel to support both versions. That means we cannot update uuid to a newer version without releasing diesel 2.0 because this would remove support for old versions of uuid.. > For what it's worth, use_std was deprecated in uuid 0.6.\nThis doesn't help us because we also support older versions of uuid.. @terry90 That's unfortunate but there is really no way to solve this without a major version bump (or uuid reverts that change\u2026). So nothing we could do about this, sorry.\n. Looked into this a bit further. It seems like we could workaround that issue with the std / no-std feature by just not depending on that feature. But this won't allow us to support uuid 0.7 because they changed some function that we use. So no way to do this update without a breaking change.\n. So I've opened a PR that could fix that. Unfortunately that requires an unstable cargo feature, so that's nothing we could merge directly (The required feature seems to be planned for rust 1.31).\n\nIf you have unstable crate as part of public API, it is already wrong to consider diesel stable. Being part of feature though, I don't see big problem to update in next patch version with mention of need to upgrade uuid, not a big deal\nI agree too, I think I'm not the only one to use Rocket and Diesel, which seems close to a full web framework like Rails with Activerecord, and this issue unfortunately makes the latest diesel incompatible with rocket. The moving parts in the Rust ecosystem - I think - should not be ignored.\n\nThat's unfortunate but but there is really nothing we could do about that (Removing uuid from diesel 1.0 is not possible any more \u2026). The only way would be to release diesel 2.0 as soon as possible, but I do not see that happening (because we would like to include some more things in such an release\u2026). Another \"solution\" would be to break our stability guarantee to make no breaking change, but I think we all agree that we generally do not want to do this (If we do that now, who draws the line when it's ok to do a breaking change and when it's not ok?).\nThat said both, rocket and uuid have not reached 1.0 yet. That means if you decided to use them you should except breaking things here. (To be clear: It is absolutely ok for them to do this changes, but don't expect a library that has declared some form of stable feature set to follow them.) \nFor using them as public dependency of a crate that already has reached 1.0 means that you must accept that there may be breaking changes that you cannot support any more. Also that's ok in my point of view (at least as long as the old version does not contain any security issues, which is not the case here).\nThere are several workarounds for this issue that neither depends on rocket, nor on diesel or uuid.\n It is possible to add support for own types to diesel. (See this test for an example). This could be used in combination with the new type pattern to add support for whatever uuid version you want outside of diesel.\n Basically the same is possible on the rocket side\nTherefore I do not see this as critical issue that needs to be solved now. . @julien1619 See #1915 :wink:. Sqlite does not support unsigned integers. That's \"just\" sqlites strange type system that accepts nearly everything as type name. Internally sqlite has only 5 types: Null, Integer, Real, Text and Blob. Each type name is mapped to one of the supported types. There are multiple rules for determining the resulting type from the given type name. In your case the following rule applies\n\nIf the declared type contains the string \"INT\" then it is assigned INTEGER affinity.\n\nto intergerunsigned, so just Integer is used as type.\nSee the sqlite documentation for more details.\nDiesel won't change the current behaviour because we try to represent the underlying database technical correctly.. Have you tried to pass that expression to order_by? (That may require to define some functions using sql_function! in this case.)\nI will close this issue because this is nothing actionable for the diesel team. Please use our gitter channel or our forum to ask questions.. Picked to #1889. Possible workarounds:\n\nChange the type of your column to Text if possible\nDefine your own SqlType that maps to Char(n). See this testcase for an example (Just replace that enum by string, also you probably want to use #[postgres(oid = \"18\", array_oid = \"1002\")] instead of #[postgres(type_name = \"char\")]).. > blocked by #1889 , i guess.\n\nYes I would like to merge #1889 before merging any bigger PR. (Also maybe releasing 1.4). Rust 1.31 stabilizes the needed feature, so merge this as soon as we bump our  minimal rustc version to 1.31.. > Makes me sad but \ud83d\udc4d at least we'll show it's not compatible\nWe can add support for uuid 0.7 as soon as cargo supports renaming crates(#1915) or we release diesel 2.0. As you noted that's not certain that this will return really a value, because there could be no value :wink:.\nTherefore diesel itself will not provide such a function.\nThat said it is possible to extend diesel in your crate to provide something that does exactly this:\n```rust\nstruct AssertNotNull(T, ::std::marker::PhantomData);\nfn unsafe_assert_not_null(t: T) -> AssertNotNull\nwhere T: Expression>,\n      ST: NotNull\n{\n    AssertNotNull(t, Default::default())\n}\nimpl Expression for AssertNotNull\nwhere T: Expression>,\n      ST: NotNull,\n{\n    type SqlType = ST;\n}\nimpl QueryFragment for AssertNotNull\nwhere T: QueryFragment,\n      DB: Backend\n{\nfn walk_ast(&self, pass: AstPass<DB>) -> Result<(), Error> {\n    self.0.walk_ast(pass)\n}\n\n}\n```\nThen just wrap the corresponding query into unsafe_assert_not_null(your_query).. Maybe the following:\nrust\ndiesel::select((&foo, &bar)).filter(exists(diesel::select(\n  projects::table\n    .filter(projects::id.eq(&project_id))\n    .filter(projects::user_id.eq(&user_id)),\n)));\n. Thanks :+1:. cc @dtolnay because potential breaking change in syn.. @dtolnay See this comment on the corresponding PR. I do not consider that as major breaking change that requires some action from your side. The ping was to just let you know that this issue exists :wink:. Fixed on master. @Eijebong Why would this bump our minimal syn version. This should use exact the same imports as before, it only prevents type collisions from the newly exported syn::Result type. (Technically this should not be a major breaking change if I understand RFC-1105 correctly). @Eijebong I do not see why it should not work with syn 0.15.21. As far as I understood the issue that is breaking diesel_derives is that syn 0.15.22 exports some type called Result<T> from it's main module. We are doing a wild card import of all items from that module, but assume that Result refers to the Result<T, E> type from the std lib.Therefore compilation will break with the new version. \nThe fix just explicitly imports the items that we actually use (so no \"wrong\" Result<T> type is pulled in scope) Those types should exist on previous syn versions, because we used them before.. So this seems fine modulo that clippy compiler error. That seems like we need to update clippy \u2026 (Will try to look into this this evening). That's the behaviour that we've currently implemented. It's documented for example here.\nThere is not much we can do about this, because we do not have all the necessary informations available at compile time (missing the column names in queryable, because on struct that implements queryable does not need to be coupled to exactly one table/set of colums, but could be used for all sets of columns with matching types.) and also not at runtime (fieldnames). \nI'm closing this issue because there is noting actionable here for the core team. Use [the gitter channel)(https://gitter.im/diesel-rs/diesel) or our forum for additional discussion.. @Mingun Simply because not each struct field needs to match a DB field. For example what's about queries selecting the result of some function?\n(Also looking up the name requires a additional roundtrip to the database)\nThat said: We may provide a lint to warn on mismatching fields, but someone needs to implement that.. @kevlarr I think adding a note to the guide that the field order matters is a good idea. Feel free to open a PR :wink:. @Mingun The problem here is that a struct that implements Queryable have not necessary to match a specific table, it just marks that struct as: \"It's possible to load data of the following types into this struct\"\n\nas far as I know, diesel at compilation looks at DB scheme. Therefore to me it is unclear why it is impossible to look at an order of fields in DB schemes, for each field in Rust structure to find its column number in the scheme and to use it instead of taking field ordinal from Rust structure. In preudocode:\n\nIt's impossible because that would require analysing the whole crate at compile time. The \"db scheme\" (table! macro calls) are living in a other place as the Queryable derives. Also a struct that derives   Queryable not necessary  needs to match a specific table (It's more like it should match a specific query, therefore the name). See the examples below for illustration. \n\nWe speak about problems of compliance of an order of fields in the Rust structure and in the DB table from where here functions?...\n\nNo we don't. We speak about deriving Queryable checking some fixed field order. (If you implement Queryable manually the problem does not exists because you specify the field order explicitly.)\nFor example the following things are also possible:\n```rust\ntable! {\n    users {\n        id -> Integer,\n        name -> Text,\n    }\n}\ntable!{\n    posts {\n        id -> Integer,\n        name -> Text,\n    }\n}\njoinable!(posts -> users (id));\n[derive(Queryable)]\nstruct User {\n    user_id: i32,\n    user_name: String,\n}\n[derive(Queryable)]\nstruct Post {\n    post_id: i32,\n    post_name: String\n}\n[derive(Queryable)]\nstruct UserWithPosts {\n    user: User,\n    post: Post,\n}\nusers::table.inner_join(posts::table).load::(&conn)?;\n//\nsql_function!(fn simple_hash(x: Text) -> Integer);\n[derive(Queryable)]\nstruct StrangeThing {\n    id: i32,\n    hash_of_name: i32,\n}\nusers::table.select((users::id, simple_hash(hash_of_name)).load::(&conn)?;\n```\nAll of this needs to be handled and that goes way beyond to simply checking that the struct field names matching the loaded column names.\nThat said if you think that's possible just open a PR :wink:. That really depends on what rqlite provides in terms of an api. Generally it is possible to add support for systems that supports some sane subset of sql.\nAdding support for rqlite needs at least a custom Connection implementation (if the used sql dialect matches sqlite) or a complete custom Backend implementation (if the sql dialect does not match that one from sqlite). Both can and should be done in a separate crate. \nI close this issue because this is nothing actionable for the diesel team. For questions and feature requests use our gitter channel or our forum.. Duplicate of #1787.\nAnd already fixed on master. Duplicate of #1609 . Seems like there is some impl missing.\nIn detail, the corresponding impl for OwnedBatchInsert is missing here.\nFixing this should be not hard:\n1. Change OwnedBatchInsert to be generic over the table, similar to BatchInsert\n2. Fix all compiler errors about a missing type paramater for OwnedBatchInsert. In most cases the table parameter is already there\n3. Add the missing impl for UndecoratedInsertRecord in src/query_builder/insert_statement/mod.rs\n4. Add a test case to diesel_tests\nAs a workaround: Pass the values list by reference.. Already merged and released as 1.4. Thanks for opening this PR, but there is already one PR open to fix that problem.\nDuplicate of #1923  . > Let me know if I can get the unit tests working, \nTry doing that what the error message suggests :wink:\nUnit test require that one of our backends is enabled, in this case the postgres backend because upsert is a postgres specific thing.\nSo running cargo test --features \"postgres\" should make the tests work. . @icefoxen If you rebase this in the next few days this will be part of the next release.. That warning is already fixed on master. Release is blocked on getting a review of a few open PR's.. Seems like this is a configuration error. \nThe \"requirement\" to reproduce this on stable is coming from a time where we got the same bug report about some known nightly breakage several times a day. . That's the expected behaviour for your code.\nThe problem is that you generate one id that you use for all elements of your vector. That results in that all insert statements have the same id, which results in the unique constraint violation.\nIf you move that generation inside of the the loop the code will work like you expect :wink:\nBTW: A better way to do this:\n```rust\n// \u2026\nlet conn: &PgConnection = &self.0.get().unwrap();\nlet new_persons = messages.list.iter()\n    .map(|msg| {\n        models::NewPerson {\n            id: Uuid::new_v4(),\n            name: &msg.name,\n            super_power: msg.super_power,\n            rich: msg.rich,\n        }\n    }).collect::>();\nlet items = diesel::insert_into(people)\n    .values(new_persons)\n    .get_results::(conn)\n    .map_err(|error| ServiceError::InternalServerError(format!(\"{:#?}\", error)))?;\nOk(items.pop().unwrap())\n````\n. @h-michael The problem is that the CI is currently broken because a dependency bumped it minimal supported rust version. This requires us to also bump our minimal supported version, which is done in this PR. Generally we have the policy to not merge any PR's where the CI is broken.\nThat said I totally understand your frustration to rebase your PR again, but I see no easy solution for this...\nAlso this should be the last rustfmt related change for a longer time :tada:. @icefoxen This needs another rebase. Because CI was not green.. I've manually rebased and merged this. 1.4 already contains this fix .. You need to enable the \"network-address\" feature.. Diesel 1.3 does not support ipnetwork 0.13. You need to use version 0.12. \nThe next diesel version will add support for 0.13.. You need to do exactly what the error message tells you to do: radacct::table.into_boxed<YourDBType>() where YourDBType is some concrete database type (Pg, Sqlite or Mysql).. Thanks :+1:. I think composite foreign keys are currently not supported (at least in combination with diesel print-schema).\nYou may be able to workaround this by setting diesel print-schema up in such a way that it ignores those tables. Than you need to write the table definitions by yourself. The associations api will probably not be usable to. Also it should not be possible to use the joinable! macro to simplify join statements, but it should be possible to write queries involving a join over both tables by using explicit on clauses.. In my opinion such a thing does not need to be in diesel core. Our general rule is to only provide ToSql/FromSql implementations for things that basically cannot fail. That's not the case here because those implementations will fail as soon as some other json than the expected in the column.\nThat said it's already not that hard to write the corresponding code to use a struct for a json field in your crate:\n```rust\n[derive(FromSqlRow, AsExpression, Debug, Serialize, Deserialize)]\n[sql_type = \"Jsonb\"]\npub struct Body {\n    pub text1: String,\n    pub text2: String,\n}\nimpl FromSql for Body {\n    fn from_sql(bytes: Option<&[u8]>) -> deserialize::Result {\n        let value = >::from_sql(bytes)?;\n        Ok(serde_json::from_value(value)?)\n    }\n}\nimpl ToSql for Body {\n    fn to_sql(&self, out: &mut Output) -> serialize::Result {\n        let value = serde_json::to_value(self)?;\n        >::to_sql(out)\n    }\n}\n```\nAlso note that this custom derive from that third party crate does use an internal api and may break at any time (cc @terry90)\nThe error message if the implementation above is missing is not great, but there is not much diesel could do here, because those errors are generated by rustc and we have no way to tell rustc point to this or that.\nI closing this issue because I see nothing actionable for diesel here.. It's always possible to do this as macro or third party derive if you think that's to much boilerplate code. . A simple macro doing this should just be\n```rust\nmacro_rules! impl_jsonb_boilerplate {\n    ($name: ident) => {\n        impl ::diesel::deserialize::FromSql<::diesel::sql_types::Jsonb, ::diesel::sql_types::Pg> for $name {\n             fn from_sql(bytes: Option<&[u8]>) -> diesel::deserialize::Result {\n                 let value = <::serde_json::Value as ::diesel::deserialize::FromSql<::diesel::sql_types::Jsonb, ::diesel::pg::Pg>>::from_sql(bytes)?;\n                 Ok(::serde_json::from_value(value)?)\n            }\n        }\n    impl ::diesel::serialize::ToSql<::diesel::sql_types::Jsonb, ::diesel::pg::Pg> for $name {\n         fn to_sql<W: ::std::io::Write>(&self, out: &mut ::diesel::serialize::Output<W, Pg>) -> ::diesel::serialize::Result {\n             let value = ::serde_json::to_value(self)?;\n            <::serde_json::Value as ::diesel::serialize::ToSql<::diesel::sql_types::Jsonb, ::diesel::pg::Pg>>::to_sql(out)\n         }\n    }\n}\n\n}\nimpl_jsonb_boilerplate!(Body);\n``. I think the failing nightly rust build is caused by https://github.com/rust-lang/rust/issues/57488. If there is a general way to ignore certain build results for azure pipelines that would be the best solution. Unfortunately I'm not aware of anything like this \ud83d\ude1f . So that's not working :(. Thanks :+1:. @diesel-rs/core I think we should discuss where we want to expose those macros exactly.\nThe following is just a mind dump:\n* I would expose all derives fromdiesel::derivesand maybe re-export the most important ones likeQueryablefromdiesel::prelude::`\n Basically the same thing for macros\nThinks to bikeshed: Maybe expose every macro just from diesel::macros and skip the distinction between macro_rule macros and derives?. Sure that's no breaking change, but I do not see that we get to a consense here before we released 1.4. The next planed version after that will be 2.0 :wink:. > Some bad news. Rust doesn't let you organize macro_rules macros. What that means is they all have to be at root. We could move out all the macros into a diesel-macros crate and then that should allow us to organize into modules via re-exports.\nAt least something like this seems ~work. Unfortunately I've found no way to hide the documentation output in the crate root, at least not in 5 minutes playing around with that. (Maybe that's not possible and we should just try to make it possible in rustdoc?) cc @sgrif  about that.\n```rust\nmod macros {\n    #[macro_export]\n    macro_rules! foo {\n        ($($tt:tt)*) => {}\n    }\n}\npub mod public_macro {\n    #[doc(inline)]\n    pub use super::foo;\n}\n```. @fbruetting This is planed for the next release, but it needs some work before it could be merged. Especially someone needs to figure out where exactly each macro should be exported (and make the documentation appear there).. Thanks :+1:\nClose #1601. That is already fixed in git-master. The next release should be done in the next few days. \nNote that directly using cargo install diesel_cli does not show threat this as errors. . diesel_codegen is deprecated since diesel 0.99 and should not be used anymore. See the Changelog for more details.. The first part of the issue is known an could be worked around by copying the example project out of the work space.\nThe second part is caused be a unsupported rustc version. The minimal supported version was bumped to 1.31 which supports that feature.. > The first part cannot be fixed since it's in the cargo-pulled config from diesel upstream:\nsh\n$ cp /path/to/diesel/git/clone/examples/examples/sqlite/getting_started_step_2 /somewhere/out/of/git/repo/ -r\n$ cd /somewhere/out/of/git/repo/\n$ cargo build\nworks fine for me.\nAlternatively change the root Cargo.toml in the cloned git repository to not contain diesel_tests as workspace member. \n(I will fix that as soon as I've some time)\n\nI don't get the second part, my rustc is 1.31.0.\n\nThere is certainly something wrong with your rustc setup and you are using a older cargo version, because that feature was stabilized in 1.31.. Seems to be resolved. \n. Oracle is no supported back end therefore it is not possible to connect to a oracle database using diesel. Also we do not have any plans to add support for this to diesel.\nThat said there is diesel-oci that implements such an back end outside of diesel. It does work but is not finished yet. Also it requires a nightly compiler and a patched diesel version. What is planed is to upstream those changes. \nClosed as Won't fix.. Thanks for reporting them :+1:\nWould you mind opening a PR fixing them?. From a short look over the code: It seems like the FromSql implementations could possibly fail if the range does not have the right format. Our general policy for FromSql implementations included in diesel core is that they should basically never fail. \nThat means adding the ToSql implementations and related stuff is fine, but adding FromSql is against that policy.\ncc @diesel-rs/core . > Seems like it's good to have precise Rust type to represent ranges with specific bounds. But I could remove some (redundant maybe) types like RangeInclusive and RangeToInclusive.\nHaving those is additional types is no problem in my opinion.\n\nIf I leave out FromSql these types cannot be Queryable, I guess?\n\nRight, not implementing FromSql implies that Queryable is not supported.. > I see these types as kind of validation. What is validation policy? Maybe FromSql-like impls (maybe for completely separate trait) should be added to another crate?\nThe policy contains 2 rules:\n\nIt's a commonly used type\nThe conversion cannot fail for all possible values of that type.\n\nThe second rule is not fulfilled because postgres range could contain values that are not valid for a specific Range* type in rust. (For example [0,1] for Range<i32>)\nI do not think that a FromSql like trait would be useable in this context without also extending the Connection trait.\n. I do not think that it is a good idea to migrate only parts of the code/examples to the 2018 edition. That should be done in one step. There is already some effort done by @mehcode on this.\nAlso I rechecked that the examples are building fine using the last stable(1.32.0) and last nightly( c1c3c4e95 2019-01-29) compiler. Therefore I see no reason to change this now. \n(The Cargo.toml files are part of the examples. They state that edition = \"2018\" is not set, therefore this code is fine.). > Does not compile with rustc 1.31.1.\nI cannot reproduce that with rustc 1.31.1. (It builds fine for me...)\nCan you provide detailed steps to reproduce this?. > \nWeird. Here's the code I'm using: https://github.com/stevensonmt/diesel_pg_demo\nAs I guessed before: That's not the example code :wink:. The problem there is that you've not copied the whole project, but only the lib.rs file. The example also includes a Cargo.toml file, **without edition =\"2018\"**. Your project sets that flag. (It's a bit unfortunately thatcargo new` by default now generates projects with edition 2018 enabled by default...)\nAnyway: I'm open to change those examples. But such a change should update all examples at once, not only a single one. Feel free to open a new PR for updating all projects in the example folder.. > I am happy to make edits and PRs for all the examples, but I'd like to know which of these three strategies is preferred.\nAs written above: I'm OK with a similar change like this one, as long as that updates all examples. (And given the proposed alternatives I would prefer this variant.). CI says you need to run rustfmt.. > Say, what's this waiting on?\n:point_up: \n. \ud83d\udc4d Thanks. cc @Thomspoon . I'm not sure what exactly are you expecting here. \nThe steps for reproducing this are quite sparse. (We will need to exact sql that has caused this)\nAs a blind guess: Maybe something is wrong with the hand written sql?. migrations_internals is (as the name suggests) not considered part of the public API, therefore that's not the right place to expose that function. \nThe public API resides in diesel_migration, therefore the \"stabilisation\" should happen there.\ncc @diesel-rs/contributors Do we want to expose such a functionality?. As a workaround you need to define your own BoxedQuery type alias with the right sql type.\nThis change \"fixes\" the minimal example:\n```diff\ndiff --git a/src/main.rs b/src/main.rs\nindex ff7d64d..19129e6 100644\n--- a/src/main.rs\n+++ b/src/main.rs\n@@ -14,6 +14,8 @@ mod krate {\n     use crate::version::Version;\n     use diesel::pg::Pg;\n     use diesel::prelude::*;\n+    use diesel::dsl::SqlTypeOf;\n+    use diesel::query_builder::BoxedSelectStatement;\n #[derive(Debug, Clone, Queryable, Identifiable, Associations, AsChangeset, QueryableByName)]\n #[table_name = \"crates\"]\n\n@@ -34,25 +36,32 @@ mod krate {\n         }\n     }\n\ntype BoxedVersionQuery<'a, Backend> =\nBoxedSelectStatement<'a, SqlTypeOf, versions::table, Backend>;\n+\n     pub trait CrateVersions {\nfn all_versions(&self) -> versions::BoxedQuery<'_, Pg>;\n\nfn all_versions(&self) -> BoxedVersionQuery<'_, Pg>;\n     }\nimpl CrateVersions for Crate {\n-        fn all_versions(&self) -> versions::BoxedQuery<', Pg> {\n-            Version::belonging_to(self).into_boxed()\n+        fn all_versions(&self) -> BoxedVersionQuery<', Pg> {\n+            Version::belonging_to(self)\n+                .select(super::version::ALL_COLUMNS)\n+                .into_boxed()\n     }\n }\nimpl CrateVersions for Vec {\n-        fn all_versions(&self) -> versions::BoxedQuery<', Pg> {\n+        fn all_versions(&self) -> BoxedVersionQuery<', Pg> {\n         self.as_slice().all_versions()\n     }\n }\nimpl CrateVersions for [Crate] {\n-        fn all_versions(&self) -> versions::BoxedQuery<', Pg> {\n-            Version::belonging_to(self).into_boxed()\n+        fn all_versions(&self) -> BoxedVersionQuery<', Pg> {\n+            Version::belonging_to(self)\n+                .select(super::version::ALL_COLUMNS)\n+                .into_boxed()\n     }\n }\n }\n@@ -70,7 +79,7 @@ mod version {\n     pub num: String,\n }\n\n\ntype AllColumns = (versions::id, versions::crate_id, versions::num);\n\n\npub type AllColumns = (versions::id, versions::crate_id, versions::num);\npub const ALL_COLUMNS: AllColumns = (versions::id, versions::crate_id, versions::num);\n``\n. @sgrif CI says this needs a rustfmt run.. So I've tried to implement that with the existing__diesel_for_each_tuple!` in diesel-oci. Basically it's not possible to do that because we cannot change the trait bounds here \ud83d\ude1e . That will require a custom connection/backend implementation. Our current policy about that is that we will not add a new backend to diesel itself because it is possible to do that outside of diesel (at least with some nightly features).\n\n\nThat said: It is currently not possible to change the code used to setup the migration table. That will change for diesel 2.0. See #1676 for a possible implementation.\nI'm closing this issue because there is nothing actionable for diesel here. The migration thing is already tracked with that PR. If you need any help with the custom backend implementation just ping someone on gitter or open a thread in our discourse forum.. CI says that there is coming a 0.10.1 dotenv version from somewhere that fails to build.. Seems like you've found the same bug that we've investigated a few hours before that report \ud83d\ude48 \nSo let me summarize shortly what we've already know:\n The problem here is that a left join always returns a nullable field, independently from the schema definition\n Diesel enforces that for single left joins. There it's not possible to select such a non nullable field. (To select that field you need to use column.nullable() instead)\n* There seems to be a bug as soon as more than one join is involved, then the not nullable field is also accepted.\nSo basically that code above should result in a compiler error but it doesen't. To workaround the runtime error: just call .nullable() on each column coming from the table of the left join. (In your case ac)\n. That sounds like your linker is missing libpq as native library somewhere. See our CI setup for a working example.\nI close this issue because this is nothing actionable for the diesel team.. Diesel does not try to hide differences between databases, therefore the like functions behave like the underlying implementation behaves. For postgresql there is also an ilike function exposed. The basic reason for that is that we don't try to hide the underlying sql. A user should be able to see which sql is generated by just looking at the dsl written query (at least whenever possible).\nI don't think we will chance that policy anytime soon therefore I close this issue.  For applications generic across different databases it is possible to abstract over that using some custom trait. That is also possible as third party crate, so maybe just publish it if you think there is some value for others there?. The field order of your AccessToken struct does not match the order of columns returned by your query. For queries without explicit select clause that's all columns in that order that is given by your table! definition.\nThe following definition of AccessToken fixes your problem.\n```rust\n[derive(Eq, PartialEq, Debug, Serialize, Deserialize, Queryable)]\npub struct AccessToken {\n    pub id: String,\n    pub client_id: String,\n    pub grant_type: String,\n    pub issued_at: NaiveDateTime,\n    pub scope: String,\n    pub expires_at: NaiveDateTime,\n    pub user_id: String,\n}\n```\nNote that this behaviour is explicitly documented for our Queryable derive.\n(Closed because that's nothing that is actionable by the diesel core team). I think the issue here is that you tell diesel to treat the barcode field as Int8/BigInt. \nTry something like the following:\n```rust\n[derive(SqlType)]\n[postgres(type_name = \"ean13\")]\npub struct Ean13;\ntable! {\n    use diesel::sql_types::*;\n    use super::Ean13;\nusers (id) {\n    id -> Int4,\n    name -> Text,\n    barcode -> Ean13,\n    balance -> Money,\n}\n\n}\n[derive(Debug, PartialEq, FromSqlRow, AsExpression)]\n[sql_type = \"Ean13\"]\npub struct Ean13Wrapper(pub i64);\nimpl ToSql for Ean13Wrapper {\n    fn to_sql(&self, out: &mut Output) -> serialize::Result {\n        Ok(IsNull::No)\n    }\n}\nimpl FromSql for Ean13Wrapper {\n    fn from_sql(bytes: Option<&[u8]>) -> deserialize::Result {\n        Ok(Ean13(8))\n    }\n}\n[derive(Queryable, Debug)]\npub struct User {\n    pub id: i32,\n    pub name: String,\n    pub barcode: Ean13Wrapper,\n    pub balance: diesel::data_types::PgMoney,\n}\n```\n. It would maybe be the better solution to implement Ord for Migration, but I was not able to do this.\nAs far as I understood it's not possible to:\n- Implement defaults for parent Traits functions\n- Implement Traits for generic types in other modules as they are defined\n. If I try to use a bool here the compiler is complaining that the trait diesel::types::FromSqlRow<diesel::types::Integer, diesel::sqlite::backend::Sqlite> is not implemented for the type bool\n. sql does not implement Query or AsQuery so I cannot call load on it as far as I understood.\n. select(...) will add a select statement  in front of the summited query. so this seems not to be a option here. One possibility would be to introduce a new pragma function, which adds pragma instead of select to the beginning of the query.\n. To move this out of the Diesel main crate I will need to expose raw_connection. This seems like a bad idea for me.\nThe alternative implementation of this would be to add a pragma function, that act like select but add Pragma instead (without any from part).\n. Should be possible, but why? This are only a few lines of code. And it's not easily extensible for new database implementations from outside the crate.\n. Because the compiler is telling me to do this. (Don't know where the other NotFound is coming from)\nsrc/schema_inference/mod.rs:93:13: 93:21 warning: pattern binding `NotFound` is named the same as one of the variants of the type `diesel::result::Error` [E0170]\nsrc/schema_inference/mod.rs:93         Err(NotFound) => {\n                                           ^~~~~~~~\nsrc/lib.rs:22:1: 22:23 note: in this expansion of include!\nsrc/schema_inference/mod.rs:93:13: 93:21 help: run `rustc --explain E0170` to see a detailed explanation\nsrc/schema_inference/mod.rs:93:13: 93:21 help: if you meant to match on a variant, consider making the path in the pattern qualified: `diesel::result::Error::NotFound`\nsrc/schema_inference/mod.rs:97:9: 97:15 error: unreachable pattern [E0001]\nsrc/schema_inference/mod.rs:97         Err(_) => {\n. Without this change the dummy migrations from diesel_test are used(They are added in this commit)\n. We don't even need this here. Tests are only build for postgres or sqlite, not for both at the same time.\n. I've changed the query to get the column informations. Resulting of this the type names changed a bit. One of this changes results in a rename of the array type names. They don't start with _ anymore, but they seems to end with [] now.\nCheck this query\nsql\nselect oid::regtype, typname from pg_type where typname like '\\_%';\n. Informations relating to primary keys living in pg_index, informations about datatypes in pg_types and column related stuff in pg_attributes.\nI couldn't get more than one join working, so I decided to rewrite the data type part of the query to use a cast, instead a join to get name of the data type. Unfortunately this results in this changes.\n. I considered first to implement this using 2 queries, but decided against it. My concerns with this solution are, that you will need to build the ColumnInformation struct by hand.\nIf you don't like the current implementation, I can change this back.\nMaybe the best solution would be to get this working with two joins.\n. Returning the primary keys independently would be a way, but then bigger changes on sqlite side would be required. I will look into this tomorrow.\n. I removed the raw sql, but inlined the table_oid query as subquery.\n. Fixed\n. this module is not public, so I can't use this trait in codegen\n. You should be able to filter the logging statement on crate basis. For example if someone uses env_logger as logging backend one could set RUST_LOG=diesel=debug to output all debugging statements from diesel with a log level of debug or higher. Also you could implement your own backend to filter on custom rules.\nIf you don't like this approach I will change this as suggested. I've choosen the log crate because it seems to be the standard for such things and seems to be greatly configurable form the users of this library. \n. Definitely there should be a compile_test for this. I did not expect that to happen.\nMaybe we could use JoinTo::JoinAllColumns to solve this. SelectableExpression<InnerJoinSource<Left, Right, FK>> should be implemented for each column there. Is there any \"Trait\" to check if a Tuple contains a certain type? If not, is it possible to write such thing?\n. > No, that trait doesn't exist and it would not be possible to write it today.\nUsing specialization this seems to be possible.  Currently there seems to be a problem with the resolution of associated types when using specialization. See the following minimal example. Because of this the explicit specialization from line 27 to line 37 and from line 66 to line 72 is needed. There are already rust-lang issues for this. \n. In theory yes.\nIn practice custom_derive removes every attribute from the item, so #[table_name(posts)] is not passed to the underlying macro.\nSecondly, the macro is passed the entire item, sans attributes. It is the derivation macro's job to parse the item correctly.\nDocumentation of custom_derive, below the example code.\n. The file defining  the custom_derive macro didn't change in the last 5 month according to the github history.\nAlso testing the code provided as documentation results in a compiler error. So this definitively needs to change.\nDo you have any better ideas?\n. This commit doesn't change anything for other methods to invoke this macro, it only fixes the usage with custom_derive. \nIt should also be possible to provide this outside of diesel, but I think it belongs into the main crate, because all other macros suggests the usage of custom_derive.\nObviously things will change as soon as macros 1.1 will become usable on stable, but up to this date custom_derive seems like the best method to provide support for stable.\n. Thanks, didn't know about this one.\n. It's used to hide the __diesel_schema_migrations from the inferring method. Maybe this should be done more explicitly with .filter(table_name.ne(\"__diesel_schema_migrations\")? Also the escaping of \"_\" should in theory happen inside of diesel.. diesel_codegen_syntex and diesel_codegen_shared are dead, as stated in #568. It is not possible to use a proc-macro lib as depenency without using the proc-macro version. Therefore the infer schema related code needs to live somewhere else. A new crate is in my opinion a clearer solution, as putting it into diesel itself.. I've implement the error managment in a other way to have all infer_schema related code in the corresponding crate. Otherwise the wrapping with the schema module would be done seperatly in codegen and cli. So everything is shared between codegen and cli. The only difference is what happens in case of an error. Codegen panics, cli will print a message and then tries to infer the other tables.. The problem with rustfmt is that it fails on formating the macros.\nRunning rustfmt on the output of quote::Token::as_str() will produce something like\nmod infer_users {\n    table ! { users ( id ) { id -> :: diesel :: types :: Int4 , username -> :: diesel :: types :: Varchar , password -> :: diesel :: types :: Varchar , access_level -> :: diesel :: types :: Int2 , } }\n}\n;\nIn my opinion this is far from optimal. (There seems to be a rustfmt issue) \nIf rustfmt would work on the generated code, running rustfmt would be the better solution. So I'm not realy sure how to handle this.. As stated in here this is not possible as long as the crate is not published to crates.io\n\nNote: using a local configuration to override paths will only work for crates that have been published to crates.io. You cannot use this feature to tell Cargo how to find local unpublished crates.. The problem here is that you cannot simply return a Vec<Result<Tokens, Box<Error>> because the generated code could be wrapped in another module if a custom schema is set. \nThe other solution would be to split this function into two:\n * One generating  Vec<Result<Tokens, Box<Error>>\n * One taking Vec<Tokens> and returning Tokens (basically wrapping everything if needed into a custom module for custom schemas). fixed\n. In theory this could work, but when I tried it it resulted in parsing ambiguous. . This is now working.. This is still valid (the part about macro_rules and use).\nBut now this is not the main cause for moving import to the import field. Now this is done because it is easier to distinguish between import, doc and the table body in this way. So I think this comment is not needed anymore here.. In this case you are right, we do not need to parse doc here (It's removed in my last changes).\n\nIn general:\nWe need to match those *_doc =[$($doc:expr)*] things in a repeater because:\n - There may be none\n - A comment may contain multiple lines:\nrust \n/// First line\n/// Second line\n   Rustc desugers this into:\n```rust\n[doc=r\"First line\"]\n[doc=r\"Second line\"]\n``\nTherefore we must match on multiple doc attributes\n. As far as I know there is no way to check if the macro expands the doc comments correctly. One could only run rustdoc on some example code and check this output manually.. It should not be needed to implementWriteexplicitly, because it should be available through the implementation ofDeref/DerefMutbelow.. ThePgTypeMetadata::Dynamic/PgTypeMetadata::Staticapproach does not require to change this for all backends. So this may be preferred? Or is this required for any future feature on other backends?. In my opinion this struct wraps two totally unrelated things. The only common point here is that both parts are passed toToSql::to_sql. I don't see any advantage over passing those fields directly as arguments toto_sql. \nCreating this wrapping struct needs ~100 lines boilerplate code for nothing (as far as I understand).. This could not implementDebugbecausePgConnectiondoes not implementDebug. As long as one ignores the error handling this version seems to be easier. \nAs soon as you add error handling you will need to touchHasSqlTypeagain, because the lookup will return anResult. ThereforeHasSqlType::metadatawill also return anResult. So each Implementation and each call ofHasSqlType::metadata` will be touched again.\nUsing the Dynamic/Static approach the lookup is done inside of ToSql (already returns Result) or inside of BindCollector::push_bound_value (already returns Result). So only an try! around those lookup calls will be needed. . Makes sense.\nAccording to the rust-api-guidelines only smart pointers should implement Deref/DerefMut. Furthermore ToSql only requires Write, so maybe we should drop the Deref implementations?. Clippy complains here because this calls a function even in the success case. Creating a String from a &'static str will allocate memory.\nA better solution would be to replace the ok_or call with ok_or_else and construct the error message string there.. I think we should rather implement Display for Migration instead of implementing the formating as custom function.. Is there any reason why this function needs #[doc(hidden)] twice?. Maybe include this struct definition with the derive into the rendered rustdoc?. I think this should be shown in rustdoc.. Are there any particular reasons why this should not implement Debug, Clone and Copy?. I think this change was not ment to be part of this pullrequest?. The formating of this string looks quite change. In particular the two closing parentheses. Is this produced by rustfmt? Otherwise I think this should be changed.. There is no impl for &String: From<&str>, so this needs some more explicit conversion.. This tests fails on CI. Do we really need this test twice? The same value is also tested by the next test.. Why are this two values not in the array above, but rather tested separated?. This pointer is never null in any case? Otherwise it may be better to add a additional check for this. I think it may be better to add the additional check for null here because in theory this could be null\u2026. Not really (It is only a artifact from testing\u2026). There is much more documentation wrong/incorrect/broken after this. I think it is more meaningful to first finish the actual implementation and fix all those documentation things afterwards.. We need a extra crate here because some parts of this are used inside of migrations_macros. Everything that was public before inside the migrations module remains public, because it is reexported through diesel_migrations. To prevent having the \"same\" method thrice we could do something like this:\n```rust\npub trait SqlExpressionMethods: Sized {\n    fn collate(self, collate: T) -> Collate where T: CollateKind {\n        Collate::new(self)\n    }\n}\npub trait CollateKind{}\npub mod collate {\n    pub struct Binary;\n    pub struct NoCase; \n    pub struct RTrim;\nimpl CollateKind for Binary {}\nimpl CollateKind for NoCase {}\nimpl CollateKinde for RTrim {}\n\n}\n```\n(This is only a suggestion to discuss this with @diesel-rs/contributors ). I think this should be a associated constant instead of a member function.\nrust\nconst COLLATION: &'static str;. If we use a associated constant, we do not need to store collation explicitly. So maybe use std::marker::PhantomData here?. It would be great to add some small documentation with an example to this function.. > From what I understand, Pathbuf::from indicates that you expect the MIGRATION_DIRECTORY value will always convert without fail. \nAs far as I understood the stdlib docs/code this conversion is guaranteed to succeed. If the user passes a nonsense path a PathBuf pointing to a non existing (the nonsense path) location is generated and the following operations executed by diesel will end with a error message indication a invalid/non existing path.\n\nWhy do we need to chain .or_else and then match on the subcommand (name?, not sure which value of the tuple 1 represents)?\n\nThe or_else is needed to workaround some architectural decisions/limitations in clap. A clap app consists of several subcommands (migration, setup, print-schema , \u2026 for diesel_cli). Each subcommand could also consists of several subcommands (list, run, \u2026 for diesel migration). Arguments are defined in a subcommand and are valid for the defined subcommand and all child subcommands.  ArgMatches contains all arguments passed to a certain subcommand. Arguments are stored in that ArgMatches to which they are passed, not in which they are defined. So if someone is calling diesel migration --migration_dir /some/dir list the migration_dir argument is stored in the ArgMatches of migration. It is also possible to call diesel migration list --migration_dir /some/dir where migration_dir is stored in the ArgMatches of list. (There is a global option that allows a argument globally, but that does not solve this problem here). Therefore we need to traverse the results for each subcommand. This is done by recursively calling this method on each subcommand. (See the clap docs for why the we access .1 on the tuple). Just add those table definitions here? . This example seems to be very similar to that one above, so do we really need both? (At least we could change this one to load all posts for multiple users?). We should mention here that a default/implicit on clause is used if JoinOnDsl::on is not called.. Same as for inner_join. We should mention here that calls to that macro are generated by infer_schema! and print-schema if the database relations exists in SQL (REFERENCES)\nAlso we should mention here the allow_tables_to_appear_in_same_query! macro that enables multi table joins.. Because this lives in diesel/src/pg I think we  do not need the #[cfg(feature = \"postgres\")] annotation.\n(Same for the empty main function for the not-pg case). I think this trait should also live in diesel/src/pg/expression/array.rs because it is Postgres specific. . I think adding adding the actual definitions here will make the example easier to understand because the all needed code is included in the actual example. (This is not needed everywhere, but because associations are quite complex I think the docs may be improved by adding them here.)\n. So better move this to pg/query_builder/query_fragment_impl.rs?. This is not that simple :wink: \nIf someone is using infer_schema! he needs to import diesel_infer_schema now.\nIf someone is using embed_migrations! he needs to import diesel_migrations now.. diesel_codegen not longer exists, it is \"renamed\" in diesel_derives.\nSo maybe \n\ndiesel_codegen exists no longer and must be removed as dependency. All custom derives are provides by diesel itself now.. Also mention infer_table_from_schema!?. Instead of panicing in error cases we should emit a compile_error! in place of the actual impl QueryableByName. This should result in better readable error messages.. Maybe transform the function call into a link to the actual function?. Maybe this should include a example case where dynamic lookup is appropriated? (Some sentence mentioning custom sql type definitions?). We should mention somewhere here that all types that implement FromSql also must also implement FromSqlRow (and link to FromSqlRow). I think transform one of the places FromSql into a link would improve the trait documentation. (Because if someone implements this he will go forth and back between the FromSql and FromSqlRow documentation). Should we mention the need of #[macro_use] here?. I think that we should not remove the generated code examples, because they show how one could implement this traits manually. Maybe we should move this to a special section in the end of this guide or even to a additional guide?. Maybe render a empty line between the struct definition and the actual code? . There should be a visible sign that this code only works with postgres.. I think a second example showing how to use get_result with a select query would be great. Maybe add this as first example and then add a caption like postgres specific use case, before the existing example.. Add a actual link to load?. What about other queries known to return only one item? For example filtering by the primary key?. I think this sentence should state on which part of the query on should be called.. Those changes are also part of the document Queryable pull request.. If we want to replace this macro with a custom derive in 1.1 we should hide the documentation about it, to \"remove\" the item from the public api.. Resolve this merge conflict :wink: . Why do we need mod where_clause twice?. As written above: If we want to replace this macro, we should not mention it in the documentation.. This empty line should be removed.. I think this example would be clearer if all entries are part of the insert statement above.. We should remove the unwrap statements and raw sql strings in the example code of:\n eq_any\n ne_any. Link to QueryBuilder. Link to BindCollector. Link to FromSql. Maybe we should override exactly this documentation in the implementation of each Connection. The example code block should end here. (Put ``` in this line)\n\nAlso as said in the gitter conversion. I think the example above would benefit from adding the actual table! calls. (I would add them in line 978 before the call to joinable!). table_with_foreighn_key -> table_with_foreign_key. in line -> the line. I would use a different formulation for this part of the documentation:\nFor joins that do not explicitly use on clauses via JoinOnDsl the following on clause is generated implicitly:\nsql\npost JOIN users ON posts.user_id = users.id. As noted above: This needs to be moved to line 992. I think this is missing a Box::new() or something.. As noted on gitter: This should have a language hint.. language hint. language hint. language hint. language hint. language hint. language hint. language hint. We should not mention diesel_derives here, because this derive is provided by diesel itself for all users outside of diesel.. Is there any reason why this doc test should be ignored?. The new derive adds this impl also for Postgres. Is this intended?. I case that \"postgres\" is not enabled the #[postgres] attribute is not checked. I think we should either check the attribute unconditionally or report an error if the attribute exists but \"postgres\" is not enabled.. Didn't we decide here that compile_error! messages are more readable?. Then we should at least check if the attribute would be valid, without generating the actual impl.. Couldn't we make trying to use this function produce a compiler error?\nFor example by adding a new trait IsRawDbConnection, implement it for PgConnection, SqliteConnection and MysqlConnection and than add  something like where Self: IsRawDbConnection to this function?. This should be written as Into::into \nI think there is a clippy lint for this, but it seems to have this overseen.. Technically this is public API, because a downstream crate could use this. Removing this macro will cause those (theoretical existing) crates to break.. We can move them to a separate pull request. These changes are unrealated to the actual porting, but include\n some cleanup (removing a unused function parameter)\n improved error handling, compile error and checking the syntax of the #[belongs_to()] attribute more deeply\nSo just open a follow up pullrequest containing this changes, as soon as we merged this one, or only put those changes into a separate commit?. Why is this import needed? We import all types from sql_types in line 5, so this should also include Timestamptz. This line references the types module which is now \"empty\". I think this should better point to sql_types now\n. Point to deserialize::Queryable?. Also point to the new locations?. All other impl in sql_types are unconditional to the enabled backends, so I think this should also be implemented in every case.. floats and option should be private, not public. The message is not 100% correct, the user should use the types inside the sql_types module instead the ones inside the types module. If I intentionally try to misinterpret the message I read something like: Instead of types::Integer use simply sql_types\". We reexport the whole sql_types module above so this should not be needed again?\n(Same for all other types here). The types in sql_types don't have this cfg's anymore, so maybe skip them here too?. Why rename this variable? The old name was better :wink: . Then maybe enable it also unconditionally?\n(It seems a bit strange that this type is only there if \"postgres\" is one of the enabled backend)\n. Git does not see this as a code-move (it is shown in the diff). Therefore we could make those two also modules private (they do not contain any public items, as far as I have seen). Why this constrain is required?\nThis code should work for any kind of backend as far as I see. Why does this use a underscore name?. Why is this impl needed?\nYou use records.iter() below. This is a breaking change, because this will break code that uses this as a trait bound. This is also a breaking change. It is not impossible, because I've a codebase where something like this exists:\nrust\ntrait MyOwnInsert<&'insert, T, Res, E> {\n    type Ret;\n    fn insert(&'insert self, conn: &SqliteConnection) -> QueryResult<Self::Ret>;\n}\nNow if I implement this trait for C where C: AsRef<[E]> I need (amongst other) the following trait bound:\n```rust\n InsertStatement<T, <&'insert [E] as Insertable<T>>::Values>: ExecuteDsl<SqliteConnection>,\n```\n(Note that this only uses code from our public API). Couldn't we just#[derive(Default)]?. Shouldn't this not better use>::Values?. The correct link is now: https://docs.rs/diesel_migrations/*/diesel_migrations/fn.run_pending_migrations.html\nIt would be great to fix that before merging . Maybe we should better use some self documenting type here instead ofOption?. I think those two implementations should be moved down to the actual structs needing them. Have you opened a issue for this? Then there should be a link here?. Just to clarify this: This links toInsertable::insert_intobut tells the user that this isSelectStatement::insert_into(Yes it is technical correct thatSelectStatementimplementsInsertablebut maybe this should be formulated in a other way). Why not just importinsertable::Insertable. Change this to something like--disable-clippyas Sean mentioned in the gitter channel.. This two lines should be removed.. Because otherwise the shorthand pattern for the destruction of the struct won't work. \n(In detail [this](https://github.com/diesel-rs/diesel/pull/1504/files#diff-cecdfd4f581eb6c37ace4cbea4fc8575R80) line would not be possible without making that thing public)\nMaybe this should be moved toAttras member funtcion?. Same reason as forcolumn_name. Do we really need the full feature here?\nAs far as I can see the default features should be sufficient for diesel.. Wouldn't \n```rust\nfield.ident.map(Identifier::Named).unwrap_or_else(|| Identifier::Unnamed(index.to_string().into())\n```\nbe a bit more idiomatic?.Identseems to beCopynow. Maybe return no reference than?. This causes failures in all but the first test for sqlite, because each test is executed in a new database.\nI would vote for simply callingembedded_migrations::run()unconditionally.. Is it possible for this cases to point directly totreat_none_as_null(\"true\")?. Maybe this should explicitly be replaced by a call tounreachable!(). Maybe we should use some other example here, becausesqlis meant to implement small missing query fragments not whole queries. So maybe just show something where a custom filter is set?. I'm not sure ifModifierneeds a default value set toNoModifierto prevent a breaking change.\n(From a quick look this seems to be no part of the public api.). There is a copy-past error in here. This trait is required forskip_lockednot forfor_update.. I've removed this bound.. Yes, [this PR](https://github.com/diesel-rs/diesel/pull/1513) fixed that problem. . It is possible to fix this locally by executingcargo update -p r2d2. Why? This line is required because of theparse_quote!below. We can change it tofield.ty.clone()but I do not see the point to do this.. Just put a#[derive(QueryId)]on the definition ofUncheckedBind. So it seems it is possible to use the same variable inquote!twice.\nInternallyquote!seems to useinto_iterso passing aVec<_>to quote will cause an error about a moved variable, but if we use a reference instead it works :wink:. Similar toUncheckedBindthis should be annotated with#[must_use=\"\u2026\"]. Shouldn't we be here also generic overT, because otherwiseRunQueryDslwill only be implemented forSqlLiteraland not for the generic case?\n(Same forSelectableExpression). Shouldn't this beimpl ToSql, Mysql> for u16?. Should this beimpl ToSql, Mysql> for u64?. I'm not sure if this is a good idea, because this will allow also things likeUnsignedto be valid in some contexts. (Note for @diesel-rs/reviewers). Here it seems like the impl foru32is missing?. Also: Is the impl foru32missing?. I think this condition should be replaced with a call todetermine_unsigned. Better useIntegerinstead ofInt4.. There should be an example here.\n. This does generate invalid sql, therefore the compilation fails.. It is already done [that way](https://github.com/diesel-rs/diesel/pull/1581/files#diff-6b84e53c349d8eac5892281f4b21cc4dR238) if I understand the comment correctly.. I think that should rather panic than return aErr, because this is clearly a programmer mistake. \n(We could even think about usingcompile_error!` if this typechecks correctly.). We should mention somewhere here that this feature needs the unstable feature and a nightly compiler.. Just to be sure. It's okay here to convert this to a signed integer? \nThis does not use some kind of undefined behavior in case of self > 128? \nI assume that the cast does not change the binary representation and only that matters when it is written to the database? (Because of that, maybe it would be clearer to do the writing directly here?)\n(This applies to all ToSql/FromSql impls below.). I think this impl is to broad. This makes Mysql: HasSqlType<Unsigend<Text>> a valid constrain. \n(So maybe better allow only a manual written subset of Unsigned types?). We could do something like that:\nimpl<'a, DB> Debug for BoxedWhereClause<'a, DB> where DB: Backend, DB::QueryBuilder: Default, {\n    fn fmt(&self, fmt: Formatter) -> io::Result<\u2026> {\n        fmt.debug_tuple(\"BoxedWhereClause\").field(if let Where(q) = self {debug_query(&q).to_string()} else {\"None\"}).finish()\n    }\n}\nBut I'm not sure what I should think about that idea\u2026. @sgrif I do not see this anywhere mentioned.. This means that the docs for Time and Timestamp are also broken, because they do the same. \nWhat is the preferred way to handle this? Just link explicitly to docs.rs?. This change seems to be unrelated to the other changes.. Is there a https:// missing?. This should be diesel::dsl::select and not ::dsl::select, because this is used as doc comment. Removing this is a breaking change. We won't do this.\n(Just leave that reexport in this place + add a deprecate notice to it). Why do we need to import select here? (Applies also for the other new imports in this file). Why do we need to import select here?. Why do we import select here and then use a qualified call to insert_into below.\n(In general I would vote for having more imports and better remove the qualified calls in our test suite. This means instead of doing select(something) \u2192 dsl::select(something) better do one use diesel::dsl::select on the top of the file. This applies for all changes in diesel_test and diesel_compile_test). Those files seems to be in the wrong place?\ndiesel_cli/tests/print_schema/print_schema_custom_types/print_schema_simple_without_docs/diesel.toml\nseems to be wrong. \nMaybe they belong to \ndiesel_cli/tests/print_schema/print_schema_simple_without_docs/diesel.toml?. This needs to be #[doc(hidden)]?. Maybe it makes sense to unify those trait implementation with the old ones? (They should be the same module the name of the struct). pub using items with #[doc(inline)] does not actually show the documentation in that place (Rustdoc will only render pub use super::count::*; here not the actual imported types.. Hmm, then this only works inside of an crate. (There was this PR for diesel_migrations). Maybe report this to rustfmt? . This is fixed now :wink:. I think doing this is quite risky, because this may break at a minor version bump of proc_macro2 \nMaybe there is some way to just construct a bad span itself? (This would at least make this code more robust against possible future changes of the debug output). Doesn't this need a #[aggregate] annotation?. If we change things here, we should also fix the sentence grammatically.\nI think \"Tables with no primary key, or a composite primary key containing more than 5 columns are not supported.\"\n. Then maybe generate some kind of error here? Maybe compile_error!?. > Should we just have Hash + Eq as bounds here?\nI've skipped the Hash + Eq bound here because not types deriving AsExpression are implementing Hash and Eq. \n\nI don't understand why we need ST here.\n\nBecause otherwise I got conflicting implementations:\n``\nerror[E0119]: conflicting implementations of traitassociations::belongs_to::ForeignKeyfor typepg::types::date_and_time::PgTimestamp:\n  --> /diesel/diesel/src/pg/types/date_and_time/mod.rs:17:74\n   |\n17 | #[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, FromSqlRow, AsExpression)]\n   |                                                                          ^^^^^^^^^^^^\n   |                                                                          |\n   |                                                                          first implementation here\n   |                                                                          conflicting implementation forpg::types::date_and_time::PgTimestamp`\nerror[E0119]: conflicting implementations of trait associations::belongs_to::ForeignKey for type std::string::String:\n  --> //diesel/diesel/src/type_impls/primitives.rs:64:26\n   |\n64 |     #[derive(FromSqlRow, AsExpression)]\n   |                          ^^^^^^^^^^^^\n   |                          |\n   |                          first implementation here\n   |                          conflicting implementation for std::string::String\n``\n. I think this test case should live indiesel_tests/tests/custom_types.rsbecause we link that file everywhere.. Because otherwise it is not possible to implement it outside of diesel. (Because otherwise it is private)\n. I do not really like to have those two mysql specific functions here. (On the other hand I see no better solution +row_metadatawas also only used by mysql). It does not change anything on the number of executed unit tests.\nHelp statement from cargo:\n\nwarning: An explicit [[test]] section is specified in Cargo.toml which currently\ndisables Cargo from automatically inferring other test targets.\nThis inference behavior will change in the Rust 2018 edition and the following\nfiles will be included as a test target:\n\n/home/weiznich/Dokumente/rust/diesel/diesel_derives/tests/helpers.rs\n/home/weiznich/Dokumente/rust/diesel/diesel_derives/tests/as_changeset.rs\n/home/weiznich/Dokumente/rust/diesel/diesel_derives/tests/associations.rs\n/home/weiznich/Dokumente/rust/diesel/diesel_derives/tests/queryable.rs\n/home/weiznich/Dokumente/rust/diesel/diesel_derives/tests/identifiable.rs\n/home/weiznich/Dokumente/rust/diesel/diesel_derives/tests/schema.rs\n/home/weiznich/Dokumente/rust/diesel/diesel_derives/tests/queryable_by_name.rs\n/home/weiznich/Dokumente/rust/diesel/diesel_derives/tests/insertable.rs\nThis is likely to break cargo build or cargo test as these files may not be\nready to be compiled as a test target today. You can future-proof yourself\nand disable this warning by adding autotests = false to your [package]\nsection. You may also move the files to a location where Cargo would not\nautomatically infer them to be a target, such as in subfolders.\nFor more information on this warning you can consult\nhttps://github.com/rust-lang/cargo/issues/5330\n\n\n(The same applies for diesel_derive). See the linked Cargo issue. Setting autotest = false is basically just the current behaviour. This only disables the detection of integration tests in tests/. For this this means that we have only on entry point into our integration tests as is it currently defined in our Cargo.toml \nI do not see any downside of doing this now, this will just silence the warnings by explicitly opting in to the current default behaviour.. Doesn't that comment mean in cleartext that this continues to be undefined behaviour because we have at one point in time 2 mutable pointers for a given memory location and the compiler assumes that there is on aliasing?\nOr is the argument here that we have one mutable pointer/reference to the outer type (RefMut) and one to the new inner type U  and that that are two different memory locations?\n. This doc test now fails because:\na) Name is now nullable\nb) The results change. This tests more combinations, than the doc test, in detail:\n\nTests boxed queries\nTests boxing nullable queries. What about making the shell variants just arguments?\nSomething like this:\n\n```rust\nSubCommand::with_name(\"completions\")\n    .about(\"Generate shell completion scripts for the diesel command.\")\n    .arg(Arg::with_name(\"SHELL\")\n        .index(1)\n        .required(true)\n        .possible_values(&Shell::variants())\n    .setting(AppSettings::SubcommandRequiredElseHelp);\n```\nThis would simplify the implementation and automatically support all shells that are added in a future version of clap.. I'm not sure if we really want to copy all the data from libpq. The current implementation just uses the provided buffer.\nWe should try if there is a way to continue doing this.. Could we provide something better here. Like this: postgres must be in the form postgres(type_name = \"\u2026\") or postgres(oid = \"\u2026\", array_oid = \"\u2026\")?. Unrelated sidenote:\nWe get frequently questions about basically this, so maybe we should highlight that in some way? (Maybe just make it bold?). I would vote for printing the actual diff here using something like difference.. Do we really want this to be a global flag?. I would vote for doing that in this PR because it is a quite small additional change.. In my opinion this last sentence sounds somewhat strange. (Could also be my non perfect English \ud83d\ude48 ). Why don't we derive this two impls too?. Several of the types that now derive NonAggregate had Self: Expression on their impls before. Not sure if that matters?. Don't know, just saw it here. \"Note that in order to use this module you need to enable the r2d2 feature on diesel.\" \nsounds better for me.. So as requested by @Thomspoon I've played a bit around with how to write such a struct. As Sean has written above, currently the probably easiest way is to use \u2028NonNull<[u8]> as field here.\nThis would result in the following code:\n```rust \nstruct PgValue {\n    raw_bytes: NonNull<[u8]>,\n    oid: u32\n}\nimpl PgValue {\n    unsafe fn new(value_ptr: *mut u8, byte_count: usize) -> Self {\n        let slice =  from_raw_parts_mut(value_ptr, byte_count);\n        Self {\n            raw_bytes: NonNull::new(slice).expect(\"cannot be null\"),\n        }\n    }\nfn as_bytes(&self) -> &[u8] {\n    unsafe { self.raw_bytes.as_ref() }\n}\n\nfn oid(&self) -> u32 {\n    self.oid\n}\n\n}\n```\nThe new function should be only called in PgResult::get. For constructing PgValue from a other PgValue from inside a from_sql a additional function should be added.. This should not be removed, but be replaced by a reexport.\nSomething like:\n```rust\n[deprecated(since = \"1.4.0\", note = \"Use diesel::upsert instead\")]\npub use upsert;\n```. Seems like this is missing some word between, maybe an \"and\"?. That's a backward incompatible breaking change, we cannot do this.\nI guess the best solution here is to remove Queryable as supertrait of OnConflictTarget and then just add a additional Queryable bound where needed. Has anyone from @diesel-rs/core a better idea?\n(That also should fix that error from the gitter channel.). This should test only insert_into(st); because otherwise this test would be redundant with that one below.. So the OnConflictTarget trait here says that it has Queryable<Pg> as supertrait. Changing that to be generic over DB without providing a default type for the generic type parameter is a breaking change. On way around this is to just remove the super trait (Queryable) there and then add it as additional constrain everywhere where the compiler tells you that it is missing. (As far as I see this should only be on this function). Sqlite does not support the default key word. Also returning clauses are not supported. So both traits should not be implemented because otherwise invalid sql will be generated.. Move postgres specific implementations back to the pg/upsert module and then re-export them here.. Move the trait bound to an explicit where clause.. Do not remove tests that are unrelated to the PR. Returning clauses are not supported on sqlite so do not remove that test.. Returning clauses are not supported on sqlite so do not remove that test.. Only remove this statement all other parts of the test should not be changed.. Returning clauses are not supported on sqlite so do not remove that test.. just go with pub(crate) mod on_constraint; and reexport that module from ::upsert::on_constraint. Use an explicit where clause for more than one (simple) constrain.. Maybe move those examples to a postgres specific section  (== below a headline/something indicating that this is only for postgres) of this doc comment?\nFor the cfg attr usage: This is also done in other places, so this is ok: https://github.com/diesel-rs/diesel/blob/2ce0e4ea0fda474459139042247512f0c8b254cf/diesel/src/query_builder/sql_query.rs#L62. We should do pub pg::on_constraint::*; to have the old module layout in place. Otherwise this would be a breaking change.. Unrelated (so not needed for this PR): We should replace this with a __diesel_for_each_tuple call. \n(This is more or less as side note for the core team). After looking at the code above I think this should be changed to contain a on_constrain clause, so verify that this extension is only supported on postgresql (Sorry for changing my mind so often\u2026). This should also have a #[doc(hidden)] attribute to prevent it from showing up in the docs. Also there is the enabled-by-default feature with-deprecated for enabling deprecated things. So as the name suggests this reexport should only be included if that feature is enabled. That means just add #[cfg(feature = \"with-deprecated\")] to it.. You should not change this branches.. Why do we return a i32 here?. This needs to be fixed.. If that module is postgres specific just move it to the postgres module and reexport it from here.. Also this should be fixed.. There should be an empty line between the \"title\" line and all other content.. Reorder the doc tests to indicate what's only working on postgres, and then hide/remove the cfg attribute.. I think we should provide some type def for that type :wink:\nrust\ntype RawValue<'a, DB> = <DB::RawValue as FamilyLt<'a>>::Out;\nThen use it as RawValue<'a, DB>.. The trait and the type below should be #[doc(hidden)] to remove them from our public api.. Just use the actual type here:\nsuggestion\n        fn from_sql<'a>(bytes: Option<&'a [u8]>) -> deserialize::Result<Self> {. Is there any reason why we don't use a slice here?\nBeside of that: Oid's should be u32 (http://docs.diesel.rs/diesel/pg/types/sql_types/struct.Oid.html)\nSo that `PgValue would look like this:\n```rust\npub struct PgValue<'a> {\n    bytes: &'a [u8],\n    oid: u32,\n}\npub struct PgValueProxy;\nimpl<'a> FamilyLt<'a> for PgValueProxy {\n    type Out = PgValue<'a>;\n}\n. Why this needs to be `RefFamily<PgValue>`? `PgValue` itself implements the necessary trait. (In your version, if the change above is applied, this should be `PgValueProxy`). Those should be moved to pg/mysql.. Because otherwise it would not be possible to explicitly set the toolchain like that. (Otherwise everything will be build with the toolchain specified in rust-toolchain). I see nothing in [`travis-cargo`'s code](https://github.com/huonw/travis-cargo/blob/master/travis_cargo.py#L5) that seems like it would do something that would prevent timeouts. There seems to be nothing that is looking like a retrying logic.. Good question. Maybe @sgrif Could answer this.\nThe only useful thing I've found is the upload doc thing used a few lines below.. This line is not requiredsuggestion\n. This misses libpq and mysqlclientsuggestion\n        sudo apt-get install curl libpq-dev libmysqlclient-dev &&\n. Use curl retry here?suggestion\n          sudo apt-get install curl &&\n.suggestion\n          curl -fsS --retry 3 --retry-connrefused -o https://www.sqlite.org/2018/sqlite-autoconf-3240000.tar.gz &&\n.suggestion\n       curl -fsS --retry 3 --retry-connrefused -o https://www.sqlite.org/2018/sqlite-autoconf-3240000.tar.gz &&\n. Any chance to put the linux sqlite setup code into a own template, so we could remove the duplication here?. Maybe we should use `Option<NonZeroU32>` here to signalling if a oid was set or not? As far as I know a oid of 0 means that the type was not specified, therefore `None` seams to be the better solution here?. Any reasons why we need a `*mut u8` and not a `*const u8` here?suggestion\n    pub(crate) fn new(value_ptr: *const u8, byte_count: usize) -> PgValue<'a> {\n```. This map call seems to be redundant.\nsuggestion\n        self.db_result.get(self.row_idx, current_idx). Either that lifetime is not required or the return value should use a explicit lifetime to make it easier to reason about which lifetime is used there.. Maybe we should make the PgValue::with_oid constructor just taking a &[u8] slice and do the constructing of that slice only once in pg/connection/cursor.rs?. We need to find some way to get the oid from the Pg: HasSqlType<BigInt> implementation. That basically means we need to find some way to construct a fake PgMetadataLookup struct here. (The implementation will not use it internally because the oid is static for BigInt). Time to fix those ancient error message\nsuggestion\n             Was a BigInt expression accidentally identified as Integer?\". suggestion\n             Was an Integer expression misidentified as BigInt?\". Remove the unused lifetime\nsuggestion\n    fn from_sql(bytes: Option<PgValue>) -> deserialize::Result<Self> {. Basically the same as for PgInterval implementation above: We need to find a way to use HasSqlType::metadata here.. Just use the actual RawValue type\nsuggestion\n    fn from_sql(value: Option<&SqliteValue>) -> deserialize::Result<Self> {. suggestion\n    fn from_sql(value: Option<&SqliteValue>) -> deserialize::Result<Self> {. suggestion\n    fn from_sql(value: Option<&SqliteValue>) -> deserialize::Result<Self> {. suggestion. suggestion\nuse byteorder::WriteBytesExt; .suggestion\nuse byteorder::WriteBytesExt; \n.suggestion\nuse backend::Backend;\n.suggestion\n    fn from_sql<'a>(bytes: Option>) -> deserialize::Result {\n.suggestion\n    fn from_sql<'a>(bytes: Option>) -> deserialize::Result {\n.suggestion\n    fn from_sql<'a>(bytes: Option>) -> deserialize::Result {\n.suggestion\n    fn from_sql<'b>(bytes: Option>) -> deserialize::Result {\n. Take a look at the install_rust template. Something similar should be done here.. We need to load the oid for each type here somehow.\nPostgresql provided `PQftype(PqResult*, usize*)` for this.\nI'm not sure if that does a additional client->server round trip or just reads the value from same internal libpq field. In the second case we can just call `PQftype` here, otherwise this should be done while constructing `PQResult` above.\ncc @sgrif because I'm not sure how libpq works internally. I think just returning `Option<NonZeroU32>` here is the better solution, so we can handle that at the calling side, because it may be ok to have no oid..suggestion\n             Was an expression of a different type misidentified as BigInt?\"\n.suggestion\n             Was an Integer expression misidentified as BigInt?\"\n.suggestion\n    pub fn oid(&self) -> Option {\n. We should set an oid here. Basically we need to find a way to call `HasSqlType::metadata` for types with a static oid..suggestion\n             Was an expression of a different type misidentified as BigInt?\"\n. That lifetime should not be requiredsuggestion\n    fn take(&mut self) -> Option>;\n.suggestion\n    fn get_raw_value(&self, index: usize) -> Option>;\n.suggestion\n    fn get_raw_value(&self, idx: usize) -> Option<&SqliteValue> {\n.suggestion\n    fn from_sql(bytes: Option>) -> deserialize::Result {\n.suggestion\n    fn from_sql(bytes: Option>) -> deserialize::Result {\n.suggestion\n    fn from_sql(bytes: Option>) -> deserialize::Result {\n.suggestion\n    fn from_sql(bytes: Option>) -> deserialize::Result {\n```. That should not be added.. Do we really need to add that link three times?. At least for local docs on linux this does not work. Needs to be\nsuggestion\n//! [`grouped_by`]: trait.GroupedBy.html#tymethod.grouped_by. This should link to SqlQuery or better to the into_boxed calls. cc @diesel-rs/core This seems to be a clever idea. Maybe we could do similar things for other query dsl types?. Link to the actual documentation. SqlQuery has no sql function, because the whole query is provided at once. Therefore that function is not necessary and should be removed. (Same for the sql field, that also seems to be unused then.). I do not see why this bound is required. (Possibly I miss something \ud83d\ude48 ). That example won't work. SqlQuery assumes that you manually write the whole sql query, including the bind parameters.\nThe sql function is something entirely different. (Though this function needs also be extended to support a variable number of joins, but that's another PR). We should expand that a bit. At least a short sentence what this does and why it may be required.. I would like to hear the opinion of at least one other core team member on this. \nIn my opinion the API should be symmetrical to SqlQuery, that means we need to add such an function there or remove it here.. This (and the next) RawValue link is not rendered correctly.. SqlQuery is a type in the public api.  This change adds a new type parameter. While that's fine from a semver point of view (the next release will be 2.0\u2026) I think we should nerveless try to introduce only breaking changes that are necessary.\nIn this case this means we just set that to some default type:\nsuggestion\npub struct SqlQuery<Inner = ()> {. Removing this breaks the CI for diesel with the postgres feature enabled.. Something like this is currently required for the oracle backend \ud83d\ude1f . I've opened #1985 for this.. Currently there is a wild card reexport of  all proc macros in our crate root. I think we should change this now to an explicit reexport list and skip sql_function_proc!  there because that macro is an implementation detail and do not need to showup twice.. Probably because of the huge quote! call in the end?. Maybe we should use _#name here as ident to prevent random name collisions?. Any chance to replace this function with the name of the function?. Move the imports above the function. Yes they don't show up, but we might wan't to have them showing up in future because the docs for custom derives contain information about the allowed attributes and such things.\nAnyway I was wrong here, sql_function_proc! needs to be reexported, because otherwise it will not be useable in this macro outside of diesel itself.. I'm fine with that. That was just a minor thing where I thought we could improve the implementation easily :wink:. I wouldn't call this \"without replacement\" because it's replaced by allowing sql_function! to also handle the no argument variant.. But for most cases sql_function! is the replacement. Therefore I would at least mention that here.. Why do we create a new wrapper type here and not just append to sql string of the existing one, similar to BoxedSqlQuery?. It should be possible to avoid calling Into<String> here, so that we could save one allocation.\nMaybe something like:\nrust\npub fn sql<T: AsRef<str>>(mut self, sql: T) -> Self {\n        self.sql += sql.as_ref()\n        self\n)\n(The same should be done for the sql function of SqlQuery)\n. This triggers the missing documentation lint, so we want to add #[doc(hidden)] here.\n```suggestion\n[doc(hidden)]\nmacro_rules! diesel_infix_operator {\n. This triggers the missing documentation lint, so we want to add `#[doc(hidden)]` here.suggestion\n[doc(hidden)]\nmacro_rules! diesel_postfix_operator {\n. This triggers the missing documentation lint, so we want to add `#[doc(hidden)]` here.suggestion\n[doc(hidden)]\nmacro_rules! diesel_prefix_operator {\n```. The next release will be 2.0 so we can make a breaking change here. Therefore I would prefer to just introduce this functionality under the old flags.\ncc @diesel-rs/core  as information.. Could we print a nicer error message here if the provided string is no valid regex?\n(Hint: If that map returns a Result it is possible to collect into a Result<Vec<_>, _>). ",
    "mfpiccolo": "Update:\nI could not get master to build locally on all three releases because of two libc mismatch types:\nsrc/connection/mod.rs:267:13: 267:45 error: mismatched types:\n expected `u64`,\n    found `usize`\n(expected u64,\n    found usize) [E0308]\nsrc/connection/mod.rs:267             identifier.len() as libc::size_t,\n                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/connection/mod.rs:267:13: 267:45 help: run `rustc --explain E0308` to see a detailed explanation\nsrc/connection/mod.rs:320:23: 320:55 error: mismatched types:\n expected `*mut libc::types::common::c95::c_void`,\n    found `*mut connection::libc::c_void`\n(expected enum `libc::types::common::c95::c_void`,\n    found enum `connection::libc::c_void`) [E0308]\nsrc/connection/mod.rs:320             PQfreemem(self.pg_str as *mut libc::c_void)\n                                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nI had to change line 276 of connection/mods.rs to use u64\n-            identifier.len() as libc::size_t,\n+            identifier.len() as u64,\nAnd I had to comment out drop for PgString on line 317-323.\nThis is probably something that has to be solved on Cargo but in the mean time the repo can build by making the changes above.\n. @sgrif  Thanks for pushing up the fix for the libc stuff.  That is weird because I tried pulling down both yaqb and pq-sys and fixing the libc to '0.2.*' but was unable to get it to build.  Not sure what I did wrong but this change worked.  Also, did you release pq-sys 0.2.0 to crates.io without pushing the commit to github?  I am guessing that you just locked the libc version there as well.\nAs for using the project, I am interested because I am writing a book on Rust for Manning that is focusing on learning Rust for programmers that only know high level languages (Ruby, JS, Python, etc).  Mostly focusing on web stuff.  Plus I really like Rust and want to start building a background job system in Rust for my consultancy.  \nIs this project going to be like AREL or will it also have the higher abstraction of an ActiveRecord-like ORM as well?\nI would definitely be interested in helping out with the documentation or development.\n. It also compiles if I set a return value for the function:\npub fn insert(new_users: Vec<NewUser>) -> Vec<User> {\n  User::conn().insert(&self::users::table, &new_users).unwrap().collect()\n}\n. @sgrif Should we add a compiler warning or something like that to remind us to change this when the casting is stable?\n. I was able to get update to work implementing AsChangeset, however I was only able to get it to build using execute_returning_count.   I could not get it to return the result using query_one.  This was the error that I was getting:\nsrc/models/user.rs:54:18: 54:37 error: the trait `yaqb::expression::Expression` is not implemented for the type `yaqb::query_builder::update_statement::UpdateStatement<yaqb::query_source::filter::FilteredQuerySource<models::user::users::table, yaqb::expression::predicates::Eq<models::user::users::columns::id, yaqb::expression::bound::Bound<yaqb::types::Integer, i32>>>, collections::vec::Vec<Box<yaqb::query_builder::update_statement::changeset::Changeset<Target=models::user::users::table>>>>` [E0277]\nsrc/models/user.rs:54     User::conn().query_one(&command)\n                                       ^~~~~~~~~~~~~~~~~~~\nsrc/models/user.rs:54:18: 54:37 help: run `rustc --explain E0277` to see a detailed explanation\nand the same error with Query:\nthe trait `yaqb::query_builder::Query` is not implemented for the type ...\n. Yep that was it.  Passing the command itself and not the borrowed command was the issue.\n. No worries.  I had not seen the codegen docs yet.  Thanks!\n. I am a little confused about where the API is going to end up after this and #30.  The pattern that I am hoping it ends up is building the command and calling an execute/run/run_all/load function on that command for all database interactions.  Something like:\nusers::table.load(&conn)                                           // All\nusers.filter(name.eq(name)).load(&conn)                            // filter\nupdate(users.filter(id.eq(id))).set(name.eq(new_name)).run(&conn)  // update\ninsert(&users::table, &new_user).run(&conn)                        // create\ninsert(&users::table, [&new_user]).run_all(&conn)                  // batch create\ndelete(users.filter(id.eq(user.id))).execute(&conn)                // delete\nEither that or calling all of them off of the connection themselves.\n. Yeah.  That is more semantic.  Will delete also support?:\ndelete(&existing_user).from(&users::table).execute(&conn)\n. :+1: \n. If this repo is going to be a popular place for people who newer to Rust (which I think it will be) it is important to show how to do it the right way.  Or don't show it at all.  \nPerhaps saving the Result as a variable and then a comment underneath about dealing with the result?\n. Nice job on the roadmap.  I agree that if we can pull it off the adapters should be third party crates.\nHere are some of my thoughts:\n\n'Cursor' ...  connection specific information in their signatures.\n\nThis sounds a bit rough but like you said we will be handled by impl Trait then that should be fine in the interim.\n\ndone in a way that additional adapters can be added as third party crates  \n\n:+1: \n\nArray is an unfortunate loss.\nJSON is an additional unfortunate loss\n\nMeaning loss as in they will need to be supported in an external crate?\n\nWe should benchmark regardless\n\nEnsuring that we don't have regressions seems like a good move if diesel is to power much of the database interaction in the Rust community.\n\nunsafe casts from Vec -> &u8 -> const u8 -> const i32\n\nThe small subset of types that SQLite supports is going to be the default types that are supported in diesel core, so this will affect all the adapters even though it wouldn't be necessary if we didn't support SQLite.  I certainly defer to your better judgement on this:\n\nwe should in theory be guaranteed that we're fine by the layer above.\n\nbut it might be prudent to be sure of this before deciding if it is worth it to support SQLite with this route.\n. Thanks Sean!   I will add docs by tonight.  There is some very strange issue with my project.  It hated the name debug_sql.  I spun up a bare bones new project to make sure the print_sql! macro worked there and it is good to go. \n. @sgrif Got some docs for the debugging struct and macros\n. Squashed.  There is only the issue of what to do with the docs for the DebugQueryBuilder struct.\ni.e.\n- Should it be #[doc(hidden)]\n- No docs\n- Docs for contributors only\nOther than that this is ready to go.\n. @sgrif I went with the doc hidden route for the debug struct.  The macros are documented so I am going to merge this in.\n. Looks great. :+1:  Well done!\n. Rapid fire PRs.  You are a machine!!  I will take a look after work.\n. Sorry I am late to the party but I updated my app with master.  Props for infer_schema!  That is some bad ass codegen! right there.   Just finished switching over the app to master and it is running smoothly.  API is looking good as well.\n. \"Everything is fine...  Nothing to see here...\"\n. @mcasper Nicely done.  I was just looking into this and saw your PR here and at rust-dotenv.\n. Looks good but we have to change travis config\n. I was thinking just remove it but I am not sure if we have to revert the other config Sean added\n. :tada:\n. Thank you!   I was just looking into this here and at dotenv when I saw your PRs come in.\n. Thanks\n. Having a little bit of trouble getting set up on my test project.  I got the migrations to run from build.rs, but I am now getting:\nsrc/main.rs:1:1: 1:1 error: use of undeclared type name `users::email` [E0412]\nsrc/main.rs:1 #![feature(plugin, custom_derive, custom_attribute)]\nwhen using infer_table_from_schema!(dotenv!(\"DATABASE_URL\"), \"users\");\nOr:\ndiesel macros>:20:19: 20:33 error: use of undeclared type name `columns::id` [E0412]\n<diesel macros>:20 type PrimaryKey = columns:: $ pk ; type AllColumns = ( $ ( $ column_name ) , +\n                                     ^~~~~~~~~~~~~~\n<diesel macros>:15:1: 17:58 note: in this expansion of table_body! (defined in <diesel macros>)\n<diesel macros>:5:1: 6:2 note: in this expansion of table! (defined in <diesel macros>)\n<diesel macros>:2:1: 2:64 note: in this expansion of table! (defined in <diesel macros>)\nsrc/models/mod.rs:1:1: 1:40 note: in this expansion of table! (defined in <diesel macros>)\n<diesel macros>:20:19: 20:33 help: run `rustc --explain E0412` to see a detailed explanation\n<diesel macros>:22:33: 22:47 error: unresolved name `columns::id` [E0425]\n<diesel macros>:22 & self ) -> Self:: PrimaryKey { columns:: $ pk } fn all_columns (  ) -> Self::\nwhen using infer_schema!(dotenv!(\"DATABASE_URL\"));\n. Dumb mistake on my part!  Everything is working as expected.  Nice work @sgrif \n. It does look like Queryable is the preferred spelling.  Google even gives a suggestion.\n\nHowever, there are several references to Queriable as an acceptable alternate spelling.\n. Code looks good to me.  What are the steps for running the commands from a project directory?\n. This looks good to me. :+1: \nDo you think it would be useful to add silence_notices() and unsilence_notices() so you could do something like this?\nconn.silence_notices();\n// multiple noisy things here\nconn.unsilence_notices();\n. I license past and future contributions under the dual MIT/Apache-2.0 license, allowing licensees to chose either at their option.\n. :+1: for #[table_name=\"foo\"]\n. Thanks for putting this together @sgrif.\nOne to many:\nThe idea here is to handle the grouping and mapping into the expected Vec's internally correct?  \nCurrently we have:\nusers.left_outer_join(posts).load(&conn).unwrap().collect() // Vec<(User, Option<Post>)>\nbut we want this to return: Vec<(User, Vec<Post>)>\nWhat you have here makes sense to me as well:\nusers.left_outer_join(posts.left_outer_join(comments)) // Vec<(User, Vec<(Post, Vec<Comment>)>)>\nusers.left_outer_join(posts).left_outer_join(comments) // Vec<(User, Vec<Post>, Vec<Comment>)>\n. @sgrif I aliased the attribute but the Queriable trait was public so do we need to alias that as well?\nSomething like?\ntrait Queriable<ST: NativeSqlType>: Queryable<ST, Row=FromSqlRow<ST>> {\n   fn build(row: Self::Row) -> Self;\n}\n. Removed alias and added changelog.\n. diesel_codegen build locally for me on nightly and on nighly-2016-01-03 but fails to build on travis.\n. I have only used Gitter once very briefly but it looks legit enough to me.\n. I use hipchat, slack and flowdock.  Flowdock is by far my favorite but I am not sure about its guarantee of history.\n. Nicely done.  :+1: \n. This looks good to me. :+1: \n. I went through briefly and everything looks good aside from the travis builds for stable and beta.  I can take a better look at it later tonight.\n. Looks good to me.  :+1: \n. This looks goo to me. \n:fire: :fire: Connection#find :fire: :fire:\nAlso I believe this commit fixes the compile tests https://github.com/sgrif/diesel/commit/a71825c6918fbb35f65108b79bca67a5c32b581e\n. This has been discussed here #64 and it was determined that only files with a leading . would be ignored. \n. I don't like the idea of removing files from the directory.  The maintained list seems reasonable since we can add known files like the ones you mentioned and issues will be opened for other use-cases that come up.  Option 2 seems to be reasonable to me as well.\nWere there other reasons aside from keeping these dirs clean for not allowing other files? @sgrif \n. If this were to go through based on the discussion in #140 you would need to update or remove the directory_containing_unknown_files_is_not_valid_migration_dir() test.\n. :heart: I was messing with this last night trying to figure out a good solution for HashSet but didn't get there.  I didn't realize that that method was already changed.\n. I have a feeling this is linked to https://github.com/rust-lang/rust/issues/12309\n. Nicely done Matt :+1: \n. This looks good to me.  Is this a preliminary DSL for migrations or is this only going to live in test?\n. :eyes: \n. That was beefy.  Looks good.  :+1: \n. Yep.  This looks solid.\n. Nicely done. :+1: \n. Agreed :+1: \n. Nice feature @sgrif!  :+1: \n. This looks good to me.  Way to be on top of Rust rolling out new features!  Looking forward to 1.9.\n\ud83d\udc4d \n. \ud83d\udc4d \nAgree with the single element tuple/struct as well.\n. Forever bumping syntex!\n. Nice find!\n. .filter(name.like(\"%\ud83d\ude00%%\").escape('\ud83d\ude00'))\nAwesome!\n. \ud83d\udc4d Like it!\n. LGTM.  I even skimmed the twitch.  Intense!   \ud83d\udcaf \n. \ud83d\udc4d \n. LGTM.\n. Nice work @killercup.  \ud83d\ude04 \n. LGTM\n. @sgrif I believe comments have been addressed.  Still need to look into compile test errors.\n. \ud83d\udc4d Thats weird.  I had them locally.  Must be my nightly version.\n. Thanks for the help! \ud83d\ude04 \n. Macros for days!   Nice work Sean.   Once travis is happy I am happy. \ud83d\udc4d \n. \ud83d\udc4d \n. The recommended approach is to use the dotenv! macro provided by the doenv crate.\ninfer_schema!(dotenv!(\"DATABASE_URL\"))\n. Both infer_schema! and dotenv! are compiler plugins which are expanding out code.  This means that dotenv! will expand out to be a string literal at compile time.  You can use env! in the standard library but you will have to get the the env set during compile time. \nhttps://doc.rust-lang.org/std/macro.env!.html\n. I mean you could just pass the database url to infer_schema!\ninfer_schema!(\"postgresql://localhost/some_database\");\n. Seems like what you really are looking for is a way to load ENV from another file through the dotenv! plugin.  You may want to open an issue here if that is the case https://github.com/slapresta/rust-dotenv.\n. This is not actually a test but I didn't have time to figure out how to test printing to stdout.  Suggestion?\n. I am testing this printsql macro in the server project I set up and if I name both of them debug_sql and print_sql I get:\nsrc/models/user.rs:40:5: 40:25 error: argument should be a single identifier\nsrc/models/user.rs:40     print_sql!(command);\n                          ^~~~~~~~~~~~~~~~~~~~\nerror: aborting due to previous error\nCould not compile `diesel_test`.\nSpent a bit of time on this last night and could not figure out why.  Is this some naming convention for macros starting with debug? Or am I missing something simple?\n. @sgrif  :fire: diesel inside of diesel\n. Probably shouldn't have this as part of the pubic api.  In that case, should this doc section be removed and the #[doc(hidden)] be added?\n. @sgrif How do you want to handle docs for internals like this.  Is doc #[doc(hidden)] fine or should there hidden docs for contributors only?\n. Oops.  Late night coding.  I will fix this shortly.\n. :scissors: :scissors: \n. What is the benefit of using a tuple struct for DeleteStatement?\n. Fair enough.  I am not a big fan of Tuple Structs because it seems like normal structs could make the code more readable than the implicit integer names.\n. One function per line is much easier to parse than:\nlet data: QueryResult<Vec<String>> = users.inner_join(posts)\n    .filter(name.nullable().eq(author_name)).select(name).load(&connection)\n    .map(Iterator::collect);\nDid you add the comment to this line to address the filter() function specifically?\nI don't think we need to separate this to be multiline though:\n.filter(\n    name.nullable()\n        .eq(author_name)\n)\n. Missing a space QueryResult<()>{\n. Why refer to libsqlite3_sys as ffi?  This is a bit confusing considering std::ffi.\n. Can we silence the migration outputs during the tests?  Looks like there is about 3200 or so.\n. I think something along those lines could be sufficient but I agree with Derek that it should have at least a quick explanation.\n. Do we want these in this file?\n. first() returns &U so that would give us Result<&U, Error> instead of Result<U, Error>\n. This got me earlier.  Took me a min to figure out why debug_sql! was not defined inside connection.  \ud83d\udc4d \n. One of the few places where I really appreciate in-code comments. \ud83d\udc4d \n. ",
    "mcasper": "Do we plan on having the user maintain the database schema manually:\n```\nstruct Database;\nimpl Database {\n  fn initialize() {\n    // lots of 'CREATE TABLE IF NOT EXISTS's\n  }\n}\nfn main() {\n  Database::initialize();\n// the rest of my program\n}\n```\nwhich seems like it would lead to some sort of one off migration system for users tracking along with the database,\nOr do we plan on having a construct to ensure you'll always get to the most up to date db schema whether you're tracking along or building for the first time?\nAnd I agree, I also would love not to have a DSL heavy migration story.\n. These look to be the PRs that added support for i64 conversion and f64 conversion respectively:\nhttps://github.com/rust-lang/rust/pull/28921/files\nhttps://github.com/rust-lang/rust/pull/29129/files\n. @sgrif How do we get around the orphan rule here? Implementing From<i32> for i64 or f64 produces \nsrc/expression/extensions/interval_dsl.rs:112:1: 116:2 error: the impl does not reference any types defined in this crate; only traits defined in the current crate can be implemented for arbitrary types [E0117]\nsrc/expression/extensions/interval_dsl.rs:112 impl From<i32> for i64 {\nsrc/expression/extensions/interval_dsl.rs:113     fn from(small: i32) -> i64 {\nsrc/expression/extensions/interval_dsl.rs:114         small as i64\nsrc/expression/extensions/interval_dsl.rs:115     }\nsrc/expression/extensions/interval_dsl.rs:116 }\nSorry if this is a super noob question, I've still got my Rust training wheels on\n. Trying to build\n``` Rust\npub struct UserChanges {\n    id: i32,\n    first_name: Option,\n    last_name: Option,\n    email: Option,\n}\nuse self::users::dsl::*;\nimpl AsChangeset for UserChanges {\n    type Changeset = Vec>>;\nfn as_changeset(self) -> Changeset<Target=users::table> {\n    let changes = Vec::new();\n\n    if let Some(first_name) = self.first_name {\n        changes.push(Box::new(first_name.eq(first_name)))\n    }\n\n    changes\n}\n\n}\ntable! {\n    users {\n        id -> Serial,\n        first_name -> VarChar,\n        last_name -> VarChar,\n        email -> VarChar,\n    }\n}\n```\nproduces the error:\nCompiling yaqb_test v0.1.0 (file:///Users/mattcasper/code/home/loudly/yaqb_test)\nsrc/main.rs:25:1: 37:2 error: the trait `core::marker::Sized` is not implemented for the type `yaqb::query_builder::update_statement::changeset::Changeset<Target=users::table> + 'static` [E0277]\nsrc/main.rs:25 impl AsChangeset for UserChanges {\nsrc/main.rs:26     type Changeset = Vec<Box<Changeset<Target=users::table>>>;\nsrc/main.rs:27\nsrc/main.rs:28     fn as_changeset(self) -> Changeset<Target=users::table> {\nsrc/main.rs:29         let changes = Vec::new();\nsrc/main.rs:30\n               ...\nsrc/main.rs:25:1: 37:2 help: run `rustc --explain E0277` to see a detailed explanation\nsrc/main.rs:25:1: 37:2 note: `yaqb::query_builder::update_statement::changeset::Changeset<Target=users::table> + 'static` does not have a constant size known at compile-time\nsrc/main.rs:25:1: 37:2 note: required by `yaqb::query_builder::update_statement::changeset::AsChangeset`\nerror: aborting due to previous error\n. And trying to use impl AsChangeset<users::table> for UserChanges { as shown above produces\nCompiling yaqb_test v0.1.0 (file:///Users/mattcasper/code/home/loudly/yaqb_test)\nsrc/main.rs:25:6: 25:31 error: wrong number of type arguments: expected 0, found 1 [E0244]\nsrc/main.rs:25 impl AsChangeset<users::table> for UserChanges {\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/main.rs:25:6: 25:31 help: run `rustc --explain E0244` to see a detailed explanation\nerror: aborting due to previous error\n. The compiler is still sad for the same (core::marker::Sized is not implemented) reason :/\n``` Rust\nimpl AsChangeset for UserChanges {\n    type Changeset = Vec>>;\nfn as_changeset(self) -> Self::Changeset> {\n    let mut changes = Vec::new();\n\n    if let Some(first_name) = self.first_name {\n        changes.push(Box::new(first_name.eq(first_name)))\n    }\n\n    changes\n}\n\n}\n``\n.type Changeset = Vec>>;is the line it's complaining about, isusers::tablethe right type to be setting as the Target?\n. @mfpiccolo I gotupdatewithAsChangesetto build just fine usingquery_one`:\n``` Rust\nlet changeset = UserChanges {\n    id: user_id,\n    first_name: body.get(\"first_name\").map(|attr| attr[0].to_owned()),\n    last_name: body.get(\"last_name\").map(|attr| attr[0].to_owned()),\n    email: body.get(\"email\").map(|attr| attr[0].to_owned()),\n};\nlet command = query_builder::update(users.filter(id.eq(changeset.id))).set(changeset);\nlet result: Option = connection.query_one(command).unwrap();\n```\n. How would we feel about reversing the order?\nRust\ninsert(record).into(table)\nIt feels more consistent to me with update and delete, which both seem to follow the pattern of\nRust\naction(record).action_specific(parameter)\nSo we would be left with the API\nRust\ninsert(record).into(table)\nupdate(record).set(changes)\ndelete(record)\n. This is great! Good work :+1: \n. Definitely! We'll give it a shot\n. The commits are strong with this one\n. No issues in @mikeastock and I's app from using this, at least the basic functionality seems to be stable.\n. I like it!\nHow do we feel about having an examples/ dir to document different use cases with working code examples? The README would get pretty long if we tried to present examples of most things.\n. I'm totally fine to (and prefer to) use separate structs for changesets and queriable, but the first error comes from just using #[changeset_for(users)] on the UserChanges struct\n. Definitely, that's awesome! \n. Resolved in #58 \n. Was about to ask about that. Just remove the nightly-2015-12-03 entry, or update to today?\n. I'm assuming allowing failures on nightly is to try and get a glimpse of future breakages, so let's see what happens if we bump the date stamped version.\n. Looks like that did the trick!\n. :+1: \n. I license past and future contributions under the dual MIT/Apache-2.0 license, allowing licensees to chose either at their option.\n. Oh right, the migrations cli is out. Wonderful! Thank you\n. The decoupling would probably help a lot, as it looks like it has trouble with any edge case pluralization as well\n. Looks good to me :+1: Thanks for working on that so quickly!\n. Yep, no problems with pointing to git\n. @sgrif If we move the structs out of schema.rs, we'll need to make a new mod for the test and add it to lib.in.rs, right?\n. @sgrif I moved everything into an annotations module, tests are all green now\n. Do we like inlining the structs into the tests more because it doesn't allow them to be reused? \n. Man, I was really hoping we could reach very_special_comment level. I'm totally fine with inlining the structs in those tests, do we also want a more explicit module name?\n. Sounds good to me, inlined the structs\n. Rebased and green!\n. Most of my experience is with Campfire/Slack, but Gitter looks cool. Is HipChat still a thing?\n. :+1: \n. Should this also run any existing and pending migrations?\n. I would err on the side of only running migrations if __diesel_schema_migrations didn't previously exist, as the use case in my mind was the 'I just cloned and want to get set up' scenario. If it always ran migrations I think it would just become a replacement for diesel migration run\n. Code looks good, and I tested it out and it works :+1: \n. Looks good to me! :+1: \n. @sgrif @mfpiccolo Ready for review\n. Moved pretty much everything into diesel_cli and addressed CR comments\n. @sgrif Updated for the recent Connection changes. I'd love to get this merged if you agree with it, as I plan on going forward to try and improve test coverage on the CLI/make some small improvements\n. :+1: \n. Looks good\n. Looks good :+1: Nice work!\n. Have you tried running cargo clean && cargo build? A lot of the time cargo just needs to rebuild the package from scratch in order to pick up new link paths\n. That usually means that you've installed an incompatible version of the library (32bit vs 64bit, or for the wrong platform).\nCan you confirm that you have the correct bit version installed?\n. @sgrif @mfpiccolo Quick review?\n. Or maybe database should be a subcommand, and then have its own derivatives. So it might become\nShell\ndiesel database drop\ndiesel database setup\ndiesel database foo\n. You know, I can't immediately come up with a use case for drop on its own. Maybe just reset for now, and see if legitimate use cases for drop come in\n. Resolved by #161 \n. Resolved by #163 \n. Looks good to me!\n. I think we're going to have to move to single threaded integration tests for the CLI anyways, so that should get cleared up soon.\n. I think having diesel setup and diesel database setup be separate things makes sense, as you're right, setup does at least one thing that has nothing to do with the database. That also makes it a little nicer for database reset, as it only has to call the database specific portions of setup.\n. Alright, I think everything has been resolved. Final review @sgrif @mfpiccolo ?\n. :smile: \n. I can see the need for separate seeding functionality, in case you want to be able to populate your development environment with a bunch of fake data, but never want that to run in production (which might/will end up happening if you make it a migration).\nI do agree that migrations/seeds.(rs|sql) feels off, maybe we should have a db/ directory that holds migrations, seeds, and others, a la ActiveRecord? Or if we don't think we'll run into any other files we related to the database that need to exist, seeds could live at the root of the project.\nEither way it should end up being diesel database seed, and the setup command should call it, so I'll try to push that PR through tonight\n. @Virviil I suggested db/ only because a true seeds file doesn't really have anything to do with migrations. So in rails land it's\n- db\n  - migrations\n    - 12345_create_user.rb\n    - 67890_create_post.rb\n  - seeds.rb\nAnd if we decided to follow a similar structure, it would be the same, but with migration folders instead of single migration files.\nBut again, I don't think I would be opposed to keeping our current migrations/ dir and just searching for a seeds.(sql|rs) file at the root of the project (defined by wherever the migrations folder is) either.\n. Looks good, my only comment is just for clarification\n. Had to import iter_after as well, and lost the StripPrefixError. I figured that rather than continuing down the rabbit hole and adding our own error type to fill the gap, we can just unwrap(), as our previous checks should guarantee that it won't fail.\n. Nice work! Looks good\n. How do we plan on divvying up the test suite as we add specific support for more databases? Whatever the most recent database is gets a bunch of tests converted and thrown at it? Or do you think we'll eventually want to build out full test suites for each one we specifically support?\n. It was! Sorry, I thought I closed this\n. I've started and stopped this a few times and made it most of the way through, but what I've read looks good to me. Would love someone else to read through as well\n. Resolved by #213 \n. @sgrif It already does\nshell\n$ diesel setup\nCreated migrations/ directory at: /Users/mattcasper/code/home/test/migrations\nCreating database: my_db\n. https://github.com/sgrif/diesel/blob/master/diesel_cli/src/main.rs#L216\n. Looks good to me\n. Resolved by #230\n. :+1: \n. Yeah sorry about that, the first commit should be a little easier to diff now\n. This is great, making the documentation more approachable is a huge win IMO.\n. Neat. Should we standardize on Display vs Debug in these error messages?\n. Many(expressions) such expressions\nLooks good to me :+1: \n. Nice work! :+1: \n. Yeah - because diesel_cli is a binary package, I couldn't find a great way to share the code easily other than making it its own crate\n. The TestEnvironment/TestDatabase/TestConnection structs and associated methods\n. Sorry that's not actually a clear answer. Those structs setup a clean environment for each test to run in, so they're needed in each tests file. I would have loved to put them all in just a module inside of diesel_cli, but I don't think the tests directory supports that, and we can't import the package into the tests since it's a binary\n. That's what I tried at first, but I don't know what black magic they do in their Makefile to get that all to work\n. Of course... Alright, off to a support module it goes!\nOn Wednesday, February 10, 2016, Sean Griffin notifications@github.com\nwrote:\n\nhttps://github.com/rust-lang/cargo/blob/master/Cargo.toml#L57-L58 no\nblack magic involved\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/200#issuecomment-182447756.\n. Looks good to me :+1: \n. Ouch. CLI Please\n\n:+1: \n. It looks like our build is failing on the most recent nightly as well, I'll look into it. In the meantime, it should work on nightly-2016-01-23 or older, or beta/stable, so you could switch to one of those for now\n. Squashing!\n. I'm not sure why Travis decided to ignore that last commit :confused: Hopefully the rebased commit will get picked up\n. Actually this doesn't need to rely on #213, reopening off master.\n. Ooo yeah, probably\n. Thanks for this!\n. The tests that do that are probably obsolete now, or could be replaced by integration tests. I'll take a look tonight\n. @sgrif The CLI test suite also passes on a (my) Windows machine on this branch.\n. Hi @yohanesu75! You can definitely use a sqlite backend.\nThe CLI figures out what backend to use based on your DATABASE_URL, which is why it correctly used SQLite.\nI'm pretty certain that the getting started demo is written all using Postgres, so a lot of it won't be compatible. It looks like you figured out to use the SqliteConnection struct instead of PgConnection, but you're correct, the infer_schema macro doesn't work for SQLite yet. I'm not entirely sure if infer_table_from_schema(table) works for SQLite, but I believe it doesn't work yet either. Instead you'll have to use the table! macro for each of your tables.\nhttp://docs.diesel.rs/diesel/macro.table!.html\n. :+1: Thanks! We can hit the rebuild button and merge later today, like you said\n. Thanks so much for working on this @sgrif :clap: \n. Hey @aeikenberry!\nIt looks like a PR got merged into the main Diesel crate recently (that diesel_cli depends on) that is causing this issue, I'll get this fixed real quick and investigate why our tests didn't catch this. \n. Ah, so it looks like this is being caused by the currently published version of diesel_cli compiling diesel 0.5.3, which it does not play nicely with. Once @sgrif publishes a new version of diesel_cli, this should be fixed\n. It looks like you're using postgres, so you should be able to work around this with \ncargo install diesel_cli --no-default-features --features postgresql\nUnfortunately diesel_cli by default compiles all the different connection types, which requires those backends to be installed. Still working on a way around this so that cargo install diesel_cli will always just work.\n. libsqlite3-dev should be plenty, I think the sudo: required was the real ticket. (Vaguely) According to Travis docs, it looks like that's required to install any packages: Allows use of sudo (e.g., for installing apt packages). \nHowever, it looks like we don't even install sqlite in our .travis.yml, we just have sudo: required, so that may be all you need.\n. Ah, good point. I'll investigate this tonight\n. D: Sorry! Silly Github auto closing issues....\n. Yeah I think that'd work, I'll update this real quick\n. @sgrif We're good to go\n. :+1: \n. Sorry about that!\nTurns out that when dropping/creating a database, we connect to the user's DATABASE_URL minus the database, so if a user is supplied, we would connect to postgres://user@localhost, which postgres interprets as us wanting to connect to the user database as well.\nAnyways, I pushed up a fix here: https://github.com/sgrif/diesel/pull/248\n. I love me some nice error messages :+1: \n. Looks good!\n. :+1: \n. \ud83d\udc4d \n. \ud83d\udc4d \n. Absolutely! #264 \n. Looks like this has been handled in master.\n. Hehe how fun, \ud83d\udc4d\n. Do we want docs.diesel.rs/<VERSION> to support every historical version of diesel, or just the most recent (major?) release? Just the past couple releases?\n. Finally, emoji support!\n. Yay caching!\nI also agree that those refactors belong in a separate PR, so looks good to me \n. Thanks for taking care of the @sgrif, LGTM \ud83d\udc4d \n. Most of the time pg_config will be installed to /usr/bin/pg_config, which is almost definitely on your $PATH. To try and find it on your machine, you could run sudo updatedb && sudo locate pg_config, which will list the absolute paths of files that match. If it's not anywhere, that means you're missing libpq-dev, and will need to install that.\nIf you're not looking for sqlite support, you should install diesel_cli with\nshell\ncargo install diesel_cli --no-default-features --features postgres\nwhich won't compile the sqlite libs. If you do want sqlite support, you'll also need to install sqlite on your machine.\n. \ud83d\ude32 \nWell that's no good! If you don't beat me to it, I'll take a look tonight\n. Sorry for the long absence, I think I agree that this is the best approach we can support within Diesel right now.\nMaybe shorten the command name to just bash-completion? To me it just seems a little friendlier to type, and most users should be familiar with what it is.\nAlso, looks like there are some conflicts to deal with now :/\n. Looks good to me too!\nShould be pretty simple to add the test to migration_run.rs, happy to do so if you want @sgrif \n. Much better, thanks!\n. Should we potentially make this >= 2? In case some projects or companies want to be able to have other files in the dir, like example_output.txt?\n. Yep\nhttps://doc.rust-lang.org/std/error/\n. Ahhh okay, I'll change the description\n. Do we interpolate crate name in this file (and others) to reduce workload in the event of a rename?\n. Got it, thanks\n. FWIW, SELECT 1 can return 0 or 1 rows\n``` sql\nSELECT 1 FROM information_schema.tables where table_name = '__diesel_schema_migrations';\n ?column?\n\n(0 rows)\nCREATE TABLE __diesel_schema_migrations ();\nSELECT 1 FROM information_schema.tables where table_name = '__diesel_schema_migrations';\n ?column?\n\n    1\n\n(1 row)\n```\nI wanted to use SELECT EXISTS ( SELECT 1 ... ) but that always returns a row, and I couldn't find a nice way to execute an arbitrary SQL command and get the result back in the codebase.\nAll that said, it could definitely use some tests\n. Yeah this is currently the only function that can create that table.\n. I like your solution a lot better, but just to put it out there:\nDropping __diesel_schema_migrations table\nSELECT 1: 0\nSELECT EXISTS (SELECT 1 ...): 1\nCreating __diesel_schema_migrations table\nSELECT 1: 1\nSELECT EXISTS (SELECT 1...): 1\nGenerated by this test code: https://gist.github.com/mcasper/b1172ccd4290bcfb1627\n. Why does this also return the connection now?\n. Scratch that, misread it\n. We should probably decide on style guidelines for when chaining functions together across multiple rows. One function per row? As many as will fit within the soft 80 char limit?\n. Not specifically the filter line, just that this chain demonstrated the mixing of styles.\nSo maybe the guideline is to keep each line of the chain short and readable then\nRust\nlet result = my_struct.foo_function()\n  .bar_function().unwrap()\n  .baz_with_longer_sig()\n. What does this impl accomplish?\n. Agreed\n. To inside the silence_notices block?\n. Agreed, though I've been trying to come up with a good generic name for this. system_url? admin_url? url_i_connect_to_to_drop_tables?\n. Yeah but how do we want to represent it in functions that deal with both a specific database's url, and the generic url?\n. In that case should create_database and drop_database be methods on Connection? In that case the split_pg_connection_string will move to a more logical place, as that will also be backend specific (and as you pointed out, Sqlite just rm -rfs a directory)\n. That could be used to generate the \"down\" part of the path after we've figured out the common ancestors, yeah. I think it would just replace line 294-296\n. According to the tests, yes! But the only way to use relative_from/strip_prefix is to be on nightly :/\n. Are we keeping the bind variable around for clarity?\n. Should these ids all be type Serial?\n. Gotcha, didn't know if we were going to be using it to represent any auto incrementing integer\n. Could this be written as connection.manage_updated_at_for_table(&table_name).unwrap_or_else(handle_error)?\n. Do you pronounce it dotenv or env?\n. Ignore me. Misread the comment\n. The user also has to add $CARGO_PATH/bin to their PATH, worth mentioning? Or leave that to learning rust and cargo?\n. A few things here, most of which I assume were intentional and will be true in 0.5\n- PgConnection lives in diesel::connection::pg::PgConnection right now\n- \"postgres\" isn't currently a valid feature (listed above in the Cargo.toml)\n- diesel::Connection has to be imported for Connection.establish to be available\nAgain, I assume most of these things will be true by 0.5, just bringing them up\n. is meant to be follow along. feels a little awkward. Maybe reword to is meant to be followed in order.?\n. Nitpicking: The tool is called dotenv, should we list it as such? Especially since we have to put it in the toml as that\n. Let's jump right\n. The paren on this line should probably be closed off on the next line, like\n(at least with the title I chose. Your output should look something like):\n. Do we still want this to be hidden?\n. Ah, true\n. Fair enough, I'll close this for now\n. No worries :p\nOn Wednesday, February 10, 2016, Sean Griffin notifications@github.com\nwrote:\n\nIn diesel_cli/tests/migration_generate.rs\nhttps://github.com/sgrif/diesel/pull/200#discussion_r52511615:\n\n+fn diesel_migration_generate_makes_valid_migration_directory() {\n-    let test_environment = TestEnvironment::new();\n  +\n-    let migrations_dir = test_environment.root_path().join(\"migrations\");\n-    fs::create_dir(&migrations_dir).unwrap();\n  +\n-    let diesel_exe = env::current_exe().unwrap().parent().unwrap().join(\"diesel\");\n-    let mut command = Command::new(diesel_exe);\n-    command.arg(\"migration\")\n-        .arg(\"generate\")\n-        .arg(\"create_posts_table\")\n-        .current_dir(&test_environment.root_path());\n-    command.output().unwrap();\n  +\n-    let create_posts_dir = fs::read_dir(&migrations_dir).unwrap().nth(0).unwrap().unwrap().path();\n-    let filenames: Vec = create_posts_dir.read_dir()\n\nSorry. :(\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/200/files#r52511615.\n. Doesn't this need to return something?\n. Oh neat, I didn't know the compiler would let this slide. Does this emit an unreachable_code warning?\n. Unfortunately expression level attributes weren't stabilized in 1.7 :/ \nhttps://github.com/rust-lang/rust/blob/1.7.0/src/libsyntax/feature_gate.rs#L232\n. \n",
    "cyplo": "Hello ! Just a drive-by on my side here, hope that helps more than introduces noise. \nIn general - a thumbs up for a idea of starting small, with just SQL files and a convention there.\nMy experience almost always was that the DB migration solutions converge on something close to plain SQL files. With some mechanism to order them and tell which DB instance had which script ran against it already. Sometimes there are also overrides in place, e.g. something like \"in general launch this script, but if running on this super special instance, also run this other script in addition.\". However, my experience is mostly in largish backend systems, so may not apply to the most common use case here.\nSummarizing, if diesel would support some simplistic mechanism for just running bare SQL files as migrations I would be perfectly happy. A plus for a mechanism inside the ORM that would tell me, while connecting to the DB, that \"hey, it seems that the newest migration I was able to find is this, but DB has this other one as the last applied.\"\nAs for taking this further, into a DSL land, I have mixed feelings here. \nI think I would rather see an ability to generate raw SQL basing on the Rust types that are my model, and then those files can be just used a basis for an actual person to review them and commit as migrations.\nthank you by the way, for diesel \nhave a great day everyone !\n. Hi ! Thanks for sharing your thoughts openly !\nDo you think it would be valuable to live with the pain for a while now ?\nI.e. have just SQL migrations for both postgres and mysql for a while to see what patterns emerge there and then try to DSLize them and only them first ?\n. Hi ! Is it easy to detect flakyness locally, e.g. would just rerunning the suite couple of times locally give you intermittent failures ?\n. I'm interested in fixing it, will try to get a PR on the weekend possibly\n. These were the only vars used in tests for that file. Haven't search for all vars in all tests though, maybe worth making a separate issue to do just that  - not sure here.\n. Thanks ! Same here, I just had a bit of unexpected \"can't go to work today\" time, so why not spend it pushing a PR ? :D\n. Would caching the binary in appveyor's cache help ?. Seems that the dependency got updated, is the problem gone now ? thanks !. Hey ! Any particular areas you would like to see fuzzed first ? data coming from the database connection ? user-supplied queries ? something entirely different ? I can try taking a look into hooking up cargo-fuzz in some nearish future I think.. No worries, I consider myself warned now :) If I get to work on this in some time and get stuck - will definitely describe what I did and what worked and what not. thanks a lot !. Hey, haven't had much luck/time to really take this on so far, feel free to pick it up if someone else is interested. Would love to pair on this one if you want btw. I will take a second look when I'll have some more time. Thank you !. ",
    "martinth": "I will also leave an (unrequested) comment on this matter just because I find diesel pretty interesting :)\nI'm mainly a Python developer and I really like the way alembic is doing it's migrations. Basically each migration is a Python file with an upgrade and downgrade function. Alongside each file stores it's own version identifier (based on a file hash) and the \"down\" revision which is the identifier of the migration that should run before that. On runtime, alembic inspects all migration files and figures out the migration path by following the \"down\" pointer to the root. One nice thing you get from this is the fact that you have a builtin collision detection. If two people add two migrations in different (vcs-)branches they will both have the same \"down\" revision, leading to a (migration-)branch which alembic detects and asks you to correct.\nI'm not so sure on how you could port this idea to Rust, since this methods relies on things like dynamic importing and introspection. \n. Since this page is ranked high when you search for \"diesel sqlite windows\":\nFor reference , if you want to install diesl_cli for usage with Sqlite, you:\n- download the precompiled Windows binaries from https://sqlite.org/download.html\n- extract them to a folder (i.e. C:\\sqlite64)\n- run a cmd terminal with the 64bit msvc toolchain in the path: \"Win + R\" and execute %comspec% /K \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat\" amd64 \n- cd C:\\sqlite64 and run lib /def:sqlite3.def /out:sqlite3.lib\n- add  C:\\sqlite64  to PATH\n- create an environment variable SQLITE3_LIB_DIR also pointing to C:\\sqlite64\n- restart terminal and run cargo install diesel_cli --no-default-features --features sqlite\nNot really straightforward if you aren't a Window developer (which I'm not) but this should work \ud83e\udd1e \n. ",
    "mikeastock": "I am interested in helping write documentation as I try to use the library! I believe @mcasper is willing to help as well. We are building a simple API backend using Iron and would love to try to use yaqb.\n. I license past and future contributions under the dual MIT/Apache-2.0 license, allowing licensees to chose either at their option.\n. ",
    "samphippen": "ActiveDiscord\n. toofr: that one orm for rust.\n. conveyorm\n. @ixjf the diesel core team have explicitly decided we will not be adding first party support for MySQL. That said, we welcome anyone who is interested in building a 3rd party crate that integrates with diesel to leverage this support. If you'd like to do that, we'd absolutely love to see it and we'd be able to support you to some degree. Thanks \u2764\ufe0f \n. I like the idea but I feel like I don't fully get it. Happy to do a screen-share if you'd like to walk me through it.\n. I mean, I have no objections, but I feel like I'm not the best judge.\n. :+1:\n. LGTM\n. LGTM.\n. Few comments. Would like thoughts, but they're not desperate merge blockers.\n. Your tests here seem legit, but you've got like a billion fiddly little boolean cases, are there any important ones that are missing?\n. LGTM.\n. \ud83d\udc4d \n. how ridiculous would it be to write a test for this?\n. Is there a c function to check whether an address is owned by the program? Then you could check the pointer address\n. I'd say we don't need a test here then, and this is \ud83d\udc4d \n. \ud83d\udc4d \n. LGTM\n. LGTM\n. LGTM\n. I like it.. Could this be a string? Feels like the property you want here is sortable, not \"only a number\". For example: leading zeroes might be useful, or users might want to have hexadecimal or similar. Thoughts?\n. yes on ignoring .\n. this branch is at a different level of abstraction than the others. What do you think about extracting this into a function also?\n. given that this is main.rs, are any of the things in here actually public?\n. ah ok. Either way, this is mostly fine, it just caught me as a little odd that the branches weren't balanced. Do with that information what your much better informed than me self wants to do :)\n. This double underscoring squicks me out. I see this is in codegen so maybe it's conventional? It's applied consistently, so maybe no change here is necessary?\n. I'd like to see the conditional here pulled out into a function, expression, local or something. It feels like using it as an inline expression here is trying to be \"too clever\". Thoughts?\n. same as above\n. also same as above, suggests refactoring opportunity?\n. is it advisable/good to combine the unsafe blocks here?\n. These arguments to sqlite3_exec are pretty arcane. Is it easy to introduce either named variables or put comments here to explain what they do?\n. A comment or named function here would help me understand what's going on. As it is, I had to pause to read this a couple of times.\n. This is obvious, simple and minimal. I like it.\n. is this not being unsigned a sqlite implementation detail?\n. I am not smart enough to understand this, could we get either comments or named functions to explain what it does?\n. is \"tpe\" conventional in rust for a \"variable which is a type\"?\n. indentation here is weird.\n. :+1: \n. this feels really arcane, would adding comments here help?\n. same.\n. I feel like there's a lot of duplication here, which is causing my previous \"arcane\" comments, I wonder if we can pull some of that out?\n. The knowledge that \"\" -> \"``\" escapes a sqlite identifier is **really** specific. Is it worth adding a comment or named function here?\n. These numbers are confusing to me. I appreciate there's some really specific implementation details, but it'd be good to expose what they are with english language. Can we make them less confusing?\n. \ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f\n. Is it worth explaining the acronymCRUDhere. Generally, in guides like this, it's a good idea to define each term the first time it's used.\n. is it worth adding a thing that points out this is cargo.toml here?\n. thefor ushere is redundant.\n. this is a beautiful sentence.\n. Applied and reverted are not antonyms. I wonder if there are two words here we could use that are true antonyms of each other.\n. I might delete the \"us\" here.\n. The dangling preposition on this clause makes me unhappy, can this read \"into which we can read our data,\"?\n. I would drop the \"our\" from \"our tables and columns\"\n. this sentence is very complex, is there any way of breaking it apart?\n. \"Theinfer_schema!` macro connects to the database URL which it is given. The macro also creates a bunch of code based on the database schema to represent all of the tables and columns.\"\n. worth emboldening?\n. \"let's show how to delete things\" is an awkward sentence.\n. this structure is much more clear than the previous structure. I like it. \n. I am bad at remembering boolean binding rules, do you think wrapping the ampersand expressions in parentheses would aid readability here?\n. This stands out to me as a little odd, I would expect that if we fail to unwrap, we want false, but I suspect I'm just ignorant?\n. this isn't single level of abstraction, but it looks like it could be with a few changes? Is it worth it?\n. :+1:\n. ",
    "r00k": "flibbets \n. smecker \n. dingbat\n. leper \n. ",
    "derekprior": "Storm (portmanteau of ruST and ORM)\n. I was trying to riff off the theme of correctness, went to its synonym \"exactitude\", and came up with \"Exacta\", which is the name of a bet in horse racing where you predict the first two horses in the correct order. \n. I license past and future contributions under the dual MIT/Apache-2.0 license, allowing licensees to chose either at their option.\nWhatever @sgrif decides if fine by me.\n. \"PostgreSQL and Rust nightly\" or something similar? At first read I thought \"nightly\" applied to Postgres.\n. If this needs to be said then does it maybe deserve a link?\n. \"a .env file...\"\n. The ordering of this all took me a bit by surprise because we did something related to dotenv already (albeit, we just added it's file) and only now are we declaring the dependency.\nI gather that's possibly because diesel_cli depends on .env internally?\n. Having read a bit more, I'd consider re-ordering everything after generating the project. Maybe:\n1. set up your project dependencies in the cargo.toml file.\n2. introduce diesel cli. What's it for? Why isn't it a project dependency? How do I install it?\n3. Use .env and diesel cli to create our database.\n. This link does not work\n. Can you give a quick summary of what diesel_codegen does or at least let me know we're going to cover that later if indeed we do?\n. Maybe something like: \"Migrations allow us to evolve the database schema over time. Each migration can be applied (up.sql) or rolled-back (down.sql). Applying and immediately rolling-back a migration should leave your database schema unchanged.\"\nMy chief worry was the term run. You run your down migration too, really...\n. which will roll back and then apply your migration again.\n. run troubles me here for the previously specified reason. Maybe I'm overthinking it.\n. I think the use of the term run, both in the cli and the documentation bothers me because regardless of the direction of the migration, you are running something.\n. ",
    "killercup": "As Rust was named after the fungus, I think an appropriate name would be a fungus whose name contains \"orm\" :smile: \n. Wow, I hadn't realized how many people want to have this! :) @emk, it would be amazing if you got company time to work on this! Maybe you, @archer884 and @norcalli can all work together on this!\n\nShould I just go ahead and bang out a PR showing what I mean?\n\nMaybe. Or, you could try and do this as a plugin crate. (If you think adding this to diesel is easier and more efficient, you can of course still open a PR!)\nDiesel has a bunch of facilities to make implementing custom types easier, and as @sgrif mentions in the issue description, it may be possible to add this in a separate crate. This may be a worthwhile effort as it could also show that it is possible to write plugins for diesel and how to do it. Currently, there is just diesel_full_text_search that I know of (and it doesn't even have a Readme\u2026 I just field diesel-rs/diesel_full_text_search#1).\n(Initially I was worried how quickly you'll run into the limits of the current orphan rules, but I think you'll be fine if you define a custom Jsonb type and impl all traits on this, or as extension traits.). @dbrgn exactly. We should probably make this a meta issue with a check list of stuff we want to have.. @YetAnotherMinion I'd rather put it in markdown file in the repo, like contributing.md.. Just saw https://github.com/rust-lang/rust/pull/43000 and remembered this issue.\nI think we talked about it, but I'm not sure what the result was: Did we ever try something like the following?\n```rust\n![cfg_attr(feature=\"unstable\", feature(on_unimplemented))]\n[cfg_attr(feature=\"unstable\", rustc_on_unimplemented(\"To query \u2026 you can find more info in our docs at http://diesel.rs/\")]\npub trait FromSql // \u2026\n```. @euclio @kballard sorry, I wasn't watching this issue. We would definitely appreciate your help! I'm not sure I can really follow it, but I think the main issue with #344 is that we need to make sure that SQLite gives us date/times in a format we can definitely parse.\nMaybe you can drop by our Gitter room and we see how we can tackle this?. By the way, I wrote this shell script to quickly check if everything still compiled (without running the tests, it takes ages on my machine). Maybe it's useful to you.\n. > The where change would mean the line with the second predicate would have to change if I want to delete the first.\nThat's my issue with the current style as well. I really enjoy the visual style of function arguments (it's quite nice to read once one gets used to it), but it's pretty bad for diffs as well. At least rustfmt now allows setting more trailing commas! :smile: \n. > Just so I'm clear, when you say \"the current style\", you mean the style proposed by this PR?\nYes. I meant the style that rustfmt currently outputs by default.\nI'm not sure if you saw this (or remember it, it was some time ago), but this problem was also discussed in https://github.com/rust-lang/rfcs/pull/1190.\n. Before going all the way to prefect hashing, I think you could quite easily exchange the default hashing function (SipHash IIRC) to one better suited to hashing small things (like FNV) for another improvement of a few ns.\nEdit: This only works when assuming the majority of HashMap keys is small. This shows FNV to be the fastest hasher for keys < 32 bytes. But it also shows that we are talking about an improvement of less than 15ns per lookup\u2026\n. The Docker image that compiles your Diesel app needs to have libpq\ninstalled.\nAngel Daniel Munoz Gonzalez notifications@github.com schrieb am Sa. 9.\nDez. 2017 um 05:09:\n\nhey sorry old issue, but what if I run a postgres image on docker?\nnaturally pg won't be on my path; what's the course of action then? just\nplain install?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/286#issuecomment-350422352,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXwiZNeLqUfoq-O-h9qsMLRTezAwVks5s-gf2gaJpZM4ILoUu\n.\n. Yep, this is actually https://github.com/rust-lang/rust/issues/12249 from feb 2014 \ud83d\ude04 \n. (Comment addressed)\n\n(Edit: Now with less typos.)\n. cf. https://www.reddit.com/r/rust/comments/4gbl2j/whats_everyone_working_on_this_week_172016/d2gaxp3?context=5\n. (Assuming the code still worked was a bit far fetched. I'll look into the failure tonight and will try to fix it)\n. Should be good to go now.\n. Currently, these warnings remain.\n. (Updated to split into two commits and remove change for doc_markdown false positive.)\n. I just updated the PR to update clippy and deny warnings unless clippy is used. I also added a clippy 'step' to travis. You can see some of the remaining warnings here: https://travis-ci.org/diesel-rs/diesel/jobs/126730544#L1039\n. I just rebased this on master and updated to the latest clippy version (maybe that needs a newer nightly -- Travis will tell us).\nI've also added some _allow_s for lints which I don't think are useful here (option_map_unwrap_or_else and option_map_unwrap_or or for specific parts of the code I didn't want to change. git grep -i 'feature = \"dev\", allow' should show all instances.\n. Travis confirms that this clippy version does not compile with the nightly from May 9. @sgrif, I think you mentioned that in the future you wanted to use the nightly from the date the latest stable was released, right? According to http://rusty-dash.com that'd currently be May 27 and the next one will be Jul 8.\nI'm okay with downgrading clippy to get this merged, btw.\n. I finally updated this PR to a newer clippy version and to fix all the lints (I also enabled a few optional ones). This passes locally with a nightly from 2016-09-29. Once we bump nightly (probably along with the macros 1.1 stuff), I'd like to try to land this.\nAfter that, I'll add clippy to other crates.\n. Rebased, bumped Clippy to version 0.0.103, and allowed/fixed some new lints. Since Clippy fails on current nightly, I made Travis stick to the one from clippy's last release.\nLet's see if they manage to release 0.0.104 soon and merge after that.. Rebased, again :D\nThe most recent nightly is from the 19th (6 days ago), which is kinda unfortunate. Since this is open for 3/4 of a year now, I'll not squash this all right now but wait for one more nightly, and maybe for @sgrif to have quick look.\nIdeally, I'd like to add another travis env with a fixed nightly that runs clippy (and is an allowed failure), until we can install clippy with rustup and have a guarantee that it compiles at all times.. Finally! This is\n\nadding the latest clippy 0.0.103 as an optional dependency with the lint feature\nimproving a whole bunch of stuff in the various crates to make clippy real happy\ngreen with #[deny(warnings)]!\nadding a new entry in Travis' build matrix (which compiles quite fast as it is using no-trans)\n. \ud83c\udf89 . I'm pretty sure that's fixed by #312, but it's not on crates.io yet.\n\nAlso, you should always use the nightly version that diesel_codegen uses (e.g., multirust update nightly-2016-04-08 && rustup override add nightly-2016-04-08).\n. Fixed in #312, not yet on crates.io.\n. No idea, that's up to Sean :)\nYou can use diesel = {git = \"https://github.com/diesel-rs/diesel\"} in the meantime, though.\n. I think you can disregard the travis error on beta as this beta is newer than the latest nightly we support for codegen! (It's rustc 1.12.0-beta.1 (822166b84 2016-08-16))\n. @robertmaloney There is a weird error with compiling compile_test on Travis; but I just looked and after rebasing on master can't reproduce this locally. Can you maybe rebase this and see how it goes? Otherwise I can do a new PR to do that.\n. The first 3 commits LGTM, that last one I have to re-read in the morning \ud83d\ude04 \nDo you want to maybe add some more documentation to the Queryable macro? The docs for Insertable are quite extensive and mention how the macro can be used with the custom_derive crate, for example.\n. Just noticed this when comparing the code with that in #324 :)\n. LGTM!\n(After comparing the diff with that from #324 and looking at the code for 5min, I believe I can actually understand your macros now. Took me a while to parse the order in which the macro arms were called; GitHub's syntax highlighting of only the $ doesn't help either\u2026 \ud83d\ude04 )\n. Sorry, just a drive-by comment: This is meant to be used with custom_derive, right? Can you add examples/docs? I tried following the flow of the macros, and all I can say is that they appear to make sense. \ud83d\ude04  (I don't know what edge cases to look for though)\n\nAm 04.07.2016 um 11:47 schrieb Sean Griffin notifications@github.com:\nUpdated and ready for review @diesel-rs/contributors\n\u2014\nYou are receiving this because you are on a team that was mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. FYI in SQLite you could try to do something similar with a text column and CHECK:\n\nsql\nCREATE TABLE track (\n  id INTEGER PRIMARY KEY,\n  track TEXT CHECK(track IN ('download', 'stream')) NOT NULL\n);\n. Oh, wow! That sounds great! Thank you for digging into this!\nCurrently, the SQL types and the Rust types are divided; the table! macro\nwill contain a SQL type and a struct with e.g. Queryable has the ability to\ndeserialize these types into the actual Rust types it contains. What you\ndescribed sound like for an inferred enum, SQL and Rust type are the same.\nI haven't thought much about this, maybe it makes sense. Just thought I'd\nmention it.\n@jethrogb was on Gitter a few weeks ago and wanted to implement a\ncustom type. Maybe you can get some additional information from the log\nthere.\nHappy holidays!\nStu Black notifications@github.com schrieb am Sa. 24. Dez. 2016 um 07:50:\n\nI've been able to address (1) and (2), but getting everything working in\nthe integration tests has run head-long into #348\nhttps://github.com/diesel-rs/diesel/issues/348. If anyone has\nsuccessfully figured out the minimal footprint of traits needed to make a\nsimple, atomic SQL type, some documentation or example code would be\nwelcome.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/343#issuecomment-269072202,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX8AJ9cTIqXkGKoakndQpU0iVYeriks5rLMCugaJpZM4IlWGG\n.\n. I would at least add a doc comment for the trait :)\n\nI don't have a preference for the name, though. That's up to @sgrif ;)\n. Totally off topic, but: Do you have a file with info on diesel internals somewhere? That one diff is full of PK and I'm not sure everyone can see that's meant to say 'primary key' \ud83d\ude04  (That's what it means, right? I didn't just make this up, did I??)\n. I actually like PK because it's concise. I was just wondering if you documented the meaning somewhere (e.g. regex has a nice Hacking.md file).\n. LGTM! (Or, well, consistent ;))\n. I'm pretty sure you can write it like 20160612-132127_add_foo or even 2016-06-12T13-21-27_add_foo. The 'version' is determined by the filename part before the first _.\n\nBrowsing through the migration code, it looks like for all entries in the migrations/ directory, migration_from(path) is called, which tries to build a tuple struct with (path, version), where the 'version' is determined by version_from(path). This is where it gets interesting: It just splits the string at the first _ and returns the first part:\nrust\n.split(\"_\")\n.nth(0)\n. Ah, got it. So you basically want to change the generate output, not the underlying migration organisation stuff.\n. We may be able to add an on_unimplemented annotation for better errors in these cases (on nightly), but it seems like there are some problems with blanket impls (which funnily enough Sean found while building diesel): https://github.com/rust-lang/rust/issues/29628\n. @thejefflarson Well, that depends on how much time and effort you want to put into this :) Here are some options:\n1. Normalize that database so it uses a more sane schema :) Edit: You can also use Views for that, of course.\n2. Submit a PR to diesel to add a \"really-huge-tables\" feature, where you repeat this stuff for far longer.\n3. Improve Rust itself to have more generic tuple support\n. I would probably go with the third as it's the most specific representation: You can easily match against a very specific error as well as an error class if you know it's a common one that you want to deal with explicitly.\nLet me fiddle a bit:\n``` rust\nfn save_user(&self, &new_user) {\n    let saving = insert(&new_user).into(users::table).execute(self.connection);\nif let Err(Error::DatabaseError(DatabaseErrorKind::ConstraintViolation(ConstraintKind::Unique))) = saving {\n    //? Is there a way to easily know which field(s) the constraint failed for?\n    let suggestion = format!(\"{}1\", new_user.name);\n    return self.abort_with(MyError::NameTaken(suggestion));\n} else if let Err(Error::DeserializationError(_)) = saving {\n    return self.abort_with(MyError::ShitsOnFire);\n}\n\nlet result = try(saving); // No custom message for the rest\n...\n\n}\n```\nThis looks a bit verbose, but is really specific. Maybe you could implement some convenience methods on Error?\n(Back in the old days, I once parsed the string representation of a MongoDB error because the JS driver only gave me access to that. Not that great of an afternoon.)\n. You seem to like exclamation marks \ud83d\ude04\nI haven't read through all the changes; I just wanted to mention: Regarding formatting, less diff-noise is generally better. (E.g., avoiding visual indentation for function definitions and chains, putting the where at the end of the fn definition, etc.)\n. LGTM\nThis is a good start and probably covers 80% of the db errors in my apps \ud83d\ude04\n. AFAIK cargo install only installs the binary. There is https://github.com/rust-lang/cargo/issues/2729 open requesting to install other files.\nWhile I would like to have this, I'd probably just (a) want to use a system package manager (brew, apt; long term thing) or (b) install diesel-cli myself from the repository (short term and while developing diesel itself of course).\n. Wow, that was quick! It might be nice to make this configurable in the future but if this breaks your current setup I think this is good as-is.\nCan you mention \"Fix #373\" somewhere in the commit message? This will automatically close that issue when this is merged.\nIt would be great if you could also add a test for this. I think there are already some teste for infer_schema!, so you could probably just add a view to the db schema.\n. I think this already works for SQLite because of this line.\nI'm going to rebase this and write a small test. Or, actually, I'm just going to add views to the diesel_test migrations, as there don't seem to be any tests for infer_schema itself.\n. @cascalheira I rebased your branch on master and added some tests. #434 includes your commits (with you as author, of course), so I'll close this PR. Feel free to comment over there :)\n. @AndiDog IIRC there is an execute(&connection) method you could use.\n. This can be solved by https://github.com/Phrohdoh/rs-diesel-sqlite/issues/2. Now that we are using macros 1.1 we might be able to generate a bit of documentation for these generated modules (macro_rules macros can't do that), e.g. explaining that/when this code was generated, and add a textual description of the schema and how to use it. This might also be nice when using an IDE that can show descriptions for items.. LGTM, left a few inline comments.\nBtw, I think #[table_name(posts)] is pretty weird, because it looks like a function call \u2013 of a setter method \u2013, but doesn't read like one. I would really like to see #[table_name=\"posts\"], but I understand that current macros don't support that. #[set_table_name(\"posts\")] would be a bit better (yes that's a string not an ident that comes from god knows where), but not enough to justify the change. Thanks for reading this rant \ud83d\ude04\n. I can reproduce this with:\n``` rust\n// diesel_tests/tests/insert.rs\n[test]\nfn insert_records_empty_array() {\n    use schema::users::table as users;\n    let connection = connection();\n    let new_users: &[NewUser] = &[];\nbatch_insert(new_users, users, &connection);\nlet actual_users: Vec<User> = users.load::<User>(&connection).unwrap();\n\nlet expected_users: Vec<User> = vec![];\nassert_eq!(expected_users, actual_users);\n\n}\n```\nThis fails only with Postgres, as SQLite inserts multiple records one at a time in a simple for loop (that iterates zero times in this case).\nEdit: @sgrif I think I have an idea how to prevent this. Let me fiddle with it a bit, I'll send a PR. (No promise that it'll be elegant, though.)\n. I'm not sure if this implementation is elegant. I'm especially wondering whether the \"insert/update is empty\" state can be more cleverly encoded in the type system. The methods I added should, to a large extend, be constant evaluable and will probably be inlined anyway. Are there any other edge cases we need to deal with here?\n. > For now I think this is fine. However, I don't like having an additional on QueryFragment. Let's just have to_sql on InsertStatement and InsertQuery do nothing if InsertValues#is_empty returns true.\nI tried that at first (changing <InsertStatement as QueryFragment>::to_sql to do nothing), but that would mean that the QueryBuilder is still used to execute a query late, right? And that query is invalid (incomplete or empty).\nOr maybe I just forgot something. (What are your reasons for not wanting an is_empty method, by the way?)\n\nOne other option would be to do something like Err(AbortQuery), but have the connection handle it.\n\nInteresting idea; this could potentially be re-used for other circumstances where queries should be aborted for some reason (though I can't come up with another case right now). The overhead of doing this is potentially the same as checking for is_empty but could be done higher up (in the connection handler).\nLet me know what you want to do. (Also, feel free to change is in some other way and skip this PR entirely, I'm okay with that.)\n\nAm 30.07.2016 um 14:38 schrieb Sean Griffin notifications@github.com:\nI'm especially wondering whether the \"insert/update is empty\" state can be more cleverly encoded in the type system.\nHaving column_names return an option seems like a reasonable place to do that, since that's the place that we're doing something which can panic. I'm not sure if that would be too implicit though, with the structure that we have. If column names returned something rather than operating on the query builder, I'd feel better about it but we'd need const fn to do that efficiently.\nFor now I think this is fine. However, I don't like having an additional on QueryFragment. Let's just have to_sql on InsertStatement and InsertQuery do nothing if InsertValues#is_empty returns true. One other option would be to do something like Err(AbortQuery), but have the connection handle it.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @sgrif updated to return a (new) Error::EmptyQuery and handle that in load_dsl.\n. I discussed this with @sgrif and we want to reactor the QueryBuilder to not return a Box<std::error::Error> but a QueryBuilderError that has an AbortQuery variant. I'll write a PR that refactors how errors are handled here (and elsewhere, and probably introduce the quick-error to make this more concise), and try to land it for 0.8 (it's a breaking change).\n. Nice work, I like that you try to reuse this in the procedural macro :)\n\nLeft a few comments inline, LGTM all in all.\n. Wow, that's quite a bit of code that you managed to get rid of! I guess to_stable_macro_tokens is the main addition here. I can't pretend to understand everything that goes on here but it looks consistent and useful, so \ud83d\udc4d from me :)\nTravis fails in diesel_tests/target/debug/build/diesel_tests-10b02b5ec417d2a0/out/lib.rs:206:9 with \"expected type i32, found type std::option::Option<i32>\".\n. Thanks for the detailed report!\nHasMany! is not available in version 0.6.2, as it was introduced just 2 days ago in https://github.com/diesel-rs/diesel/pull/386. The docs are rendered for the master branch. While there should be a new release 0.7 soon, you can track master in the meantime.\n. Lgtm!\n. Lgtm.\nAre there any other places where you used Vec speicifically? (Though it's not a breaking change to change to IntoIter, right? Should strictly allow more stuff.)\nAlso, that tuple macro is crazy but still getting crazier. I like it \ud83d\ude04\n. > ```ignore\n\n. @shssoichiro Oh! You might want to hold off on this one right now. There are known bugs when using custom_derive! and we'll probably not spend much time fixing them and instead build something using macros 1.1.\n. Okay, so this change adds a bunch of lifetimes and references all over the place \u2013 and not enough according to travis \ud83d\ude04 \nComposite indices will probably be exception, so I wouldn't want to make life hard for \"regular\" users just to make composite indices really nice. But on the other hand: I really like Cow and think it should get way more exposure (and some more default impls).\nAnother option would be a custom wrapper around Cow<'a, Id> (that de-refs to Cow) but has some custom index-specific behaviour (if that makes sense).\n. FYI:\n\nNot sure why Cargo is trying to get 0.7.1 when I am explicitly telling it to use 0.7.0 -- could be a Cargo bug?\n\nCargo treats 0.7.0 as ^0.7.0, which is the version range \u22650.7.0 AND < 0.8.0.\n. Sorry, I haven't had much time to work on this. It should actually not be a block for a macros 1.1 release and can later than 0.8. (Though it will be a breaking change for people depending on these error types.)\n\nAm 06.10.2016 um 17:41 schrieb Jameson Little notifications@github.com:\nAny progress on this? I'm excited about using diesel with the new macros 1.1 support, and this looks like the last major blocker.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Just that I'm more familiar with quick_error. What advantages does error_chain give us?\nAm 02.11.2016 um 12:32 schrieb Georg Semmler notifications@github.com:\nI would like to look into this. Is there any specific reason why quick_error and not error_chain is used?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I'm closing this as it's just a bunch of conflicts right now. I'd really like to spend some time doing this right, with a good forward-compatibility story, before we go 1.0.. A bunch of stuff for composite PKs landed recently, like the annotations in\ntable!. Have a look at the release notes, or the PRs for that if the\nmacro docs don't include it.\n\nConnor Brewster notifications@github.com schrieb am Di. 27. Dez. 2016 um\n05:14:\n\nHi @sgrif https://github.com/sgrif, is there anywhere where I can track\nthe progress of composite PK support?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/398#issuecomment-269267140,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX8_cLrKInwL9pZP69z3uh8UrRCETks5rMJCfgaJpZM4JfVsd\n.\n. Please note that futures-rs also has a Stream trait!\n. LGTM!\n\nDo we have a place where we say which Rust versions we support? Maybe just mention it again in the changelog?\n. @cengizIO, FYI, @sgrif just said:\n\nUntil 1.0, I think it's reasonable that we only support the latest version of Rust. Once we hit 1.0 we can evaluate if we need to do something different.\n\nIt'd just add this as a note to the Changelog to remind people to update to Rust 1.10 if they haven't yet.\n. Sorry, I seem to have forgotten to check up on this PR. Looks like this is good to go! Thanks again for working on this, @cengizIO!\n. I left a bunch of totally unrelated comments, but i also followed the macro callbacks, which LGTM!\n. LGTM. The travis failure is because of the beta being for 1.12.\nDo you maybe want to put a Readme file in the examples directory explaining how this is related to the guide?\n. I'm pretty sure you need to use an older nightly -- try the one from\n2016-07-07 (same as in Travis file).\nIn general, each diesel version will be tested against the nightly from the\ndate of release of the latest stable.\nAndrew Ryan Lazarus notifications@github.com schrieb am Mi. 17. Aug. 2016\num 08:54:\n\n401 https://github.com/diesel-rs/diesel/pull/401 causes my build to\nfail.\nExample project that fails:\nhttps://github.com/nerdrew/diesel_belongs_to_test\nFailure:\n% rustc --version\nrustc 1.12.0-nightly (197be89f3 2016-08-15)\n% cargo test\n   Compiling libc v0.2.15\n   Compiling byteorder v0.3.13\n   Compiling winapi v0.2.8\n   Compiling regex-syntax v0.3.4\n   Compiling diesel_codegen_syntex v0.7.1\n   Compiling pq-sys v0.2.3\n   Compiling winapi-build v0.1.1\n   Compiling utf8-ranges v0.1.3\n   Compiling kernel32-sys v0.2.2\n   Compiling diesel v0.7.0 (file:///./diesel)\n   Compiling thread-id v2.0.0\n   Compiling thread_local v0.2.6\n   Compiling memchr v0.1.11\n   Compiling aho-corasick v0.5.2\n   Compiling regex v0.1.73\n   Compiling dotenv v0.8.0\n   Compiling dotenv_codegen v0.9.0\n   Compiling dotenv_macros v0.9.0\n   Compiling diesel_codegen v0.7.0 (file:////diesel_codegen)\n   Compiling test_diesel v0.1.0 (file:///./test_diesel)\nerror: expected ident, found ,\n  --> :28:70\n   |\n28 | ( foreign_key_kind = $ foreign_key_kind , $ ( $ remaining_args ) * ) , fields\n   |                                                                      ^\nerror: expected ident, found ,\n  --> :28:70\n   |\n28 | ( foreign_key_kind = $ foreign_key_kind , $ ( $ remaining_args ) * ) , fields\n   |                                                                      ^\nBuild failed, waiting for other jobs to finish...\nerror: Could not compile test_diesel.\nTo learn more, run the command again with --verbose.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/406, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX8C5XhiH9qa5Te1dREaWCZi7_t6bks5qgrAegaJpZM4JmJbv\n.\n. More documentation is always good :)\n\nI'm not sure how wise it is to mention database specifics, though (like representing bool as int on SQLite). Assuming diesel gets adapters for other DBMSs we could end up needing to mention n specific cases for each SQL type. Let's keep it for now, though.\nMight be a good idea to mention the correct usage of these types (i.e., don't use the in structs, use Rust's types) in the guide as well.\n. LGTM, though I'd probably add a few tests for edge cases like inserting a datetime in one time zone and trying to get it out in another. Is this a feature that is regularly used? Do you want to add some docs for that (even if you copying the ones from timestamp)?\n. I'm not sure how to define a workspace in / when all crates live in /<name>/, most projects have one top-level crate where they define a workspace. https://github.com/matthiasbeyer/imag/pull/624 is an example of a project with not top-level crate trying to add workspaces.\n. This has been done, so I'm gonna close this issue. See #557, though.. The compile-fail tests can't seem to find the necessary crates (log).\n. LGTM.\nSeems to save a bit of time, but not that much. Is the diesel crate built with different features multiple times in the same build (e.g. diesel_test using different features than when building the diesel crate itself)? If so, can we reduce this further?\nTotally unscientific timings from travis:\n| Test | master | PR branch |\n| --- | --: | --: |\n| nightly sqlite | 8:46 | 7:07 |\n| nightly pg | 10:11 | 9:38 |\nLong CI builds are luckily not really that much of a problem here, as Travis times out after an hour and one build only takes about 10min right now. (Getting incremental compilation for development will be much more of a difference.)\n. FYI, Postgres and SQLite are build by different travis jobs, so that won't matter here. Adding cache: cargo to the .travis.yml might bring more visible improvements.\n@Bobo1239 can you reorder it so that everything with 'sqlite' in it is at the top? That should be as good as we can currently get here.\n. @Bobo1239 Master already adds cache: cargo. Can you maybe rebase this PR?\n. I think renaming the examples' crate names is fine. The website links to a\nspecific commit, so it won't matter when people click on the links over\nthere; and the meaning should be pretty obvious otherwise.\nThanks for sticking with this PR! I'm sorry for changing so much\ncargo/Travis related stuff in the meantime :)\nBoris-Chengbiao Zhou notifications@github.com schrieb am Sa. 10. Sep.\n2016 um 03:19:\n\nHm, I'm not sure what the best course of action is.\nAdding the example stages to the workspace requires renaming the crates\nbecause a workspace mustn't have crates with identical names. Then we would\nalso have to rename the extern crates in the binaries.\nOtherwise we could set a separate workspace for each example stage (by\ncreating an empty [workspace] section in each Cargo.toml) but recompile\ndiesel each time and possibly confuse newcomers.\nAny other suggestions?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/413#issuecomment-246078740, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX8Ma5AhF76U60sVOiWKP8XV1S1gWks5qogWygaJpZM4JoW_4\n.\n. Interesting. Full error:\n\nerror: 2 unexpected errors found, 1 expected errors not found\nstatus: exit code: 101\ncommand: rustc tests/compile-fail/codegen_does_not_add_save_changes_method_on_structs_without_primary_key.rs -L /tmp --target=x86_64-unknown-linux-gnu --error-format json -Z unstable-options -L /tmp/codegen_does_not_add_save_changes_method_on_structs_without_primary_key.stage-id.compile-fail.libaux -C prefer-dynamic -o /tmp/codegen_does_not_add_save_changes_method_on_structs_without_primary_key.stage-id -L ../target/debug/deps/\nactual errors (from JSON output): [\n    Error {\n        line_num: 2,\n        kind: Some(\n            Error\n        ),\n        msg: \"2:11: 2:25: multiple matching crates for `diesel_codegen` [E0464]\"\n    },\n    Error {\n        line_num: 2,\n        kind: Some(\n            Note\n        ),\n        msg: \"2:11: 2:25: candidates:\"\n    },\n    Error {\n        line_num: 2,\n        kind: Some(\n            Note\n        ),\n        msg: \"2:11: 2:25: path: /home/travis/build/diesel-rs/diesel/target/debug/deps/libdiesel_codegen.so\"\n    },\n    Error {\n        line_num: 2,\n        kind: Some(\n            Note\n        ),\n        msg: \"2:11: 2:25: crate name: diesel_codegen\"\n    },\n    Error {\n        line_num: 2,\n        kind: Some(\n            Note\n        ),\n        msg: \"2:11: 2:25: path: /home/travis/build/diesel-rs/diesel/target/debug/deps/libdiesel_codegen-fd5341f1d057230b.so\"\n    },\n    Error {\n        line_num: 2,\n        kind: Some(\n            Note\n        ),\n        msg: \"2:11: 2:25: crate name: diesel_codegen\"\n    },\n    Error {\n        line_num: 2,\n        kind: Some(\n            Error\n        ),\n        msg: \"2:11: 2:25: can\\'t find crate for `diesel_codegen` [E0463]\"\n    }\n]\nI'm not exactly sure what happens here. It seems that diesel_codegen gets compiled a few times (as there are two artifacts available at this point), and compiletest uses prefer-dynamic in combination with the general deps directory for any libraries.\nA few lines above this in the logs, you can see the call\n\nRunning rustc tests/compile_tests.rs --crate-name compile_tests -g --test -C metadata=6da6d16cb7f217d4 -C extra-filename=-6da6d16cb7f217d4 --out-dir /home/travis/build/diesel-rs/diesel/target/debug --emit=dep-info,link -L dependency=/home/travis/build/diesel-rs/diesel/target/debug/deps --extern diesel_codegen=/home/travis/build/diesel-rs/diesel/target/debug/deps/libdiesel_codegen.so --extern compiletest_rs=/home/travis/build/diesel-rs/diesel/target/debug/deps/libcompiletest_rs-49b8be839ef33737.rlib --extern diesel=/home/travis/build/diesel-rs/diesel/target/debug/deps/libdiesel.rlib -L native=/usr/lib/x86_64-linux-gnu -L native=/usr/lib/x86_64-linux-gnu\n\nwhich contains a lot more specific dependencies.\nI don't know how to fix this in a nice way. Work arounds might be: Moving the example compile step to be last/moving compile test further up, or manually removing dynamic libs like codegen/codegen_syntex before compiletest.\n. @Bobo1239 I don't think this does anything on stable: TRAVIS_RUST_VERSION=$TRAVIS_RUST_VERSION./test_stable does not execute anything unless you add a space between $TRAVIS_RUST_VERSION and ./test_stable. The travis log here for stable with postgres doesn't seem to show anything related to compiling the examples.\n. Sure, go ahead. I don't think anyone is working on this. Have you seen\nany? The implementation might be similar.\nJosh Holmer notifications@github.com schrieb am Do. 15. Sep. 2016 um\n13:43:\n\nI'd like to work on this, if no one else has started it.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/414#issuecomment-247305828,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX3tTUd9Xkx85waFmpLUW4LP96Jknks5qqS9PgaJpZM4Jot2m\n.\n. Thanks, LGTM!\n\nI think we can get rid of one more fixme (see inline comment) :)\n. LGTM. Do you maybe want to add some docs on how to use this? (Mentioning that the table! macro allows a comma separated list of columns for composite primary keys should suffice.)\n. LGTM.\nIs there a way to test this? (I don't think it's really necessary.)\n. While I think this could be a nice CLI feature as it uses the same DB interface as diesel, you should note that all databases I know come with simple tools to do load data from a file. E.g., psql --dbname=testdb --file=test-data.sql for Postgres.\nAnother idea might be seeding with Rust code instead of a static SQL file. Just create an (additional) binary like src/bin/seed.rs.\n. IMHO, CSV is nice when you first look at it, but then you try to import a text/date/foreign key/enum/decimal field and everything explodes\u2026 ;)\n. > Could there be a compile time test/lint for this?\nSee #573. Hey, thanks for the pull request!\nI'm totally inexperienced in how to deal with date/time types in Rust, but I know that diesel already supports chrono (the impl for Postgres lives here). Sorry if this is a dumb question, but: Why not use this? IIRC, chrono internally uses the time crate as well and seems to support more use cases while having a more powerful API.\n. deprecated_time sound so\u2026 degrading. I propose calling it good_old_time! \ud83d\ude09\n. Hi, thanks for reaching out and writing an issue instead of just giving up and moving on! (Something I'm sure guilty of\u2026)\nSo, with 0.7, the codegen story change a bit, which is why the getting started guide is probably out of date. This is being worked on! In PR #404 you can see we are about to add the example code from that guide to this repository.\nAs the changelog entry for 0.7 (here) mentions, \"diesel_codegen has been split into two crates.\" @sgrif wrote a bit in this commit message on how to migrate.\nYour error\u2014thanks for adding this\u2014already mentions what the problem is: There are two different versions of syntex in use. I admit, that's a bit hard to read \ud83d\ude04 I was actually looking at the Travis logs for #404 when I noticed that.\nYou are using diesel_codegen_syntax in version 0.7.2, right? That version has an upper bound on syntex version 0.43 (you mentioned 0.42 above). So, try to use 0.43? Can you check in your Cargo.lock what syntex you are using? If there are multiple versions, try to make sure to reduce it to one.\nI hope that helps\u2014this is just me guessing, actually\u2026\n. I think this would be useful to have. I don't like the as [\"name\"] syntax though. In other contexts, it seems to work in the opposite way (use external::stuff as my_name).\nAs there is currently no way in a stable macro to match on \"type\" as ty -> VarChar, we need to think of another syntax (or wait for lit to be stabilized: rust-lang/rust#35625).\nHow about ty (aka \"type\") -> VarChar or ty (column \"type\") -> VarChar? I especially like the last one, as it may be verbose but is absolutely clear. If you want to go even more verbose, (using column \"type\") or (using table \"with_weird_table_name\") reads nice as well.\nrust\ntable! {\n    objects\n    (table \"weirdly_long_table_name_for_something_as_simple_as_objects\")\n    (id)\n    {\n        id -> Uuid,\n        label -> Nullable<VarChar>,\n        ty (column \"type\") -> Nullable<VarChar>,\n        created_at -> Timestamp,\n        updated_at -> Timestamp,\n    }\n}\n. @kardeiz Why not use #[rename=$name:expr] so it looks like a regular attribute?\nI think is actually more confusing\u2014because we are in a macro context where there are no items that can have actual attributes (as seen by rustc). If the macro was using struct syntax (basically : instead of ->), it might make more sense to use attributes-like syntax. (This is probably harder to parse, too.)\n. I can see your pain, @SergioBenitez, but also understand that @sgrif doesn't want to spend his time tracking nightly (with a delay of X days anyway).\nIs there a compromise we could make? E.g., bump codegen version more often, but use semver's beta flag/build numbers to specify the nightly targeted? Something like diesel_codegen 0.7.3+20160904?\n. Thanks. If the UUID crate's API as used by diesel did not change it, would it make sense to allow ^0.2, ^0.3?\n. @shssoichiro Since 0.2 and 0.3 are not SemVer compatible according to cargo, it is my understanding that cargo will build both versions\u20140.3 because you want it, and 0.2 because diesel wants it. And diesel's trait will only get implemented for the 0.2 Uuid type.\nIf you change diesel to allow more version of uuid, say >=0.2.0, <0.4.0, cargo can give diesel the same version of uuid (0.3) that you get in your own code with extern crate uuid.\n. Sweet. Thank you!\nAs uuid's bump from 0.2 to 0.3 was just to allow newer versions of serde, this should not give us any trouble* :)\n* if you are using serde: please note that newer versions of serde-codegen are depending too-recent versions of syntex/nightlies\n** famous last words\n. And it's green! \ud83d\udc9a\n. @sgrif I'm not sure how to elegantly test the Postgres version. For SQLite we can just open a new :memory: database, create tables and views, and see that it works (i.e. ignore the views). For Postgres this is more tricky. Would it make sense to write compile-tests for this? Or do we just trust that it works based on the fact that we call infer_schema! in diesel_test and the migrations now include views?\n(Sorry, I meant to send that comment yesterday\u2026)\n. Added a simple test for postgres. Tell me if you want to have more.\n. Feel free to merge or squash-merge this as soon as travis likes it. I just pushed a revert for the migrations.\n. LGTM. Left a comment about creating \"true\"/\"false\" token tree later, but is not important.\nCan you fix the spelling of 'applied' here while you are at it? :)\nBy the way, you could probably update some of the calls to cx.span_err with some of the new inline span annotations that came error message styles. Though diesel's code gen the error messages are okay as is.\n. Yes, @golddranks. Only the infer_* macros (like infer_schema!) connect to the database at build time. Using table! declarations (like the ones output by this cli command) will allow you to build your diesel project from sources alone.\n(Of course, you'll need to personally make sure your db schema is correct/up-to-date if you don't use the infer_* macros, just like with any other ORM.). Actually, we will need to update the guide on how to use the codegen crate with macros 1.1 in stable Rust 1.15 instead soon :). Yep, it'll be ready with Rust 1.15, so\u2026 less than 24 hours!\nJameson Little notifications@github.com schrieb am Do. 2. Feb. 2017 um\n02:05:\n\nAwesome. Well a new crate be pushed soon with support for stable Rust?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/439#issuecomment-276834827,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXxdPzLEft3iDtX_tCXA--Mqf_Djtks5rYSvsgaJpZM4J7Ln0\n.\n. LGTM. Looking forward to the actual macros 1.1 implementation :)\n. LGTM. You can ignore the nit with the maybe-simplifyable code.\n. Oh, on travis, stable and beta (correctly) fail with an unknown attribute error. Is it correct that these new attributes are visible to the stable libsyntax?\n\nA workaround is replacing\n```\n[changeset_options(treat_none_as_null = \"true\")]\n```\nwith something like\n```\n[cfg_attr(diesel_derive, changeset_options(treat_none_as_null = \"true\"))]\n``\n. Thanks!\n. We landed (simple) composite key support fortable!in #417 (currently only in master, will be in the next release). Can you try this and see if it works for you?\n. I guess this is solved then?\n. One way to solve this is to box the query in each branch (with.into_boxed()`).\nMarcel M\u00fcller notifications@github.com schrieb am So. 2. Okt. 2016 um\n05:24:\n\nDue to the fact that the filter method returns a new type I'm unable to\ncreate a 'dynamic' query. Basically I want to do something like this:\nlet mut query = submissions.limit(self.settings.limit));\nif let Some(user) = self.submitter {\n    query = query.filter(user_id.eq(user.id));\n}\nif let Some(n) = self.title {\n    query = query.filter(title.like(n));\n}\nif let Some(desc) = self.description {\n    query = query.filter(description.like(desc));\n}\nThis fails to compile due to the fact that query gets typed right away and\nit might or might not change.\nIs this something that can be addressed? I'd rather not have N! code\npaths to run through.\nA macro would be a suitable replacement, however I am not knowledgeable\nenough to create it.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/455, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXy9p9ZxezbegJVxvvvQt3ox69NM5ks5qvyPqgaJpZM4KL7Dn\n.\n. So, the 0.8 announcement should probably mention that people using embed_migrations! should not update just yet.\n\nCI failure is because of extern crate dotenv_codegen in diesel_test/build.rs and breaking changes in syntax. (Did you mean to remove the specific nightly date?)\n. Sorry, I haven't had time to look at this so far :(\nThe CI error is because this compiles compiletest 0.2.4 which expects a nightly from 2026-10-07 (see https://github.com/laumann/compiletest-rs/pull/50; we use 2016-09-29). You probably need to change the dependency to =0.2.3.\n. Thanks again for doing this!\n(And so quickly! When I say \"I'll look into it on the weekend\" I always end up doing it two weeks later\u2026)\n. What error are you getting? I think you are running into the default column number limitation. The docs for table! (which is also used internally) say:\n\nBy default this allows a maximum of 16 columns per table, in order to reduce compilation time. You can increase this limit to 26 by enabling the large-tables feature, or up to 52 by enabling the huge-tables feature. Enabling huge-tables will substantially increase compile times.\n\nDoes this work for you when enabling the large-tables feature for Diesel in your Cargo.toml?\n. > What there is to write in Cargo.toml to enable it?\nWhere you define diesel as a dependency, you can also list the features you want to enable, like so:\ntoml\n[dependencies]\ndiesel = { version = \"0.8\", features = [\"postgres\", \"large-tables\"] }\n. Great!\n. @lancecarlson I understand your frustration, but sadly it's a known limitation right now. In Diesel, but also in Rust itself: Tables are represented as tuples and currently, Rust does not have a way to deal with arbitrarily large tuples.\nIf you want to know more, have a look at Diesel PR #747, the resulting https://github.com/rust-lang/rfcs/pull/1921 and the newer https://github.com/rust-lang/rfcs/pull/1935.. Sorry, they are currently not supported. \nThere is an issue tracking this here: https://github.com/diesel-rs/diesel/issues/343\n. Oh, nice! Do we handle empty arrays anywhere else? Can you add a test for this?\n. @weiznich I just remembered that I tried fixing that and @sgrif and I discussed an implementation in https://github.com/diesel-rs/diesel/pull/385, which resulted in our idea to refactor the error handling instead of introducing an is_empty method for this one case.\n. LGTM once the compile fail tests are fixed (and maybe another one is added to test/document that you currently can't use a 5-tuple as primary key?).\n@Drakulix, you asked for composite PKs on Gitter: Would you like to test this branch with your app?\n. @ruipserra, sorry for taking to long to reply. Some of the code changed in the meantime (and fundamentally in regard to proc macros IIUC) so there are a few conflicts now. Can you have a look?. @ruipserra Basically all the files have conflicts now \ud83d\ude22 Would you like to rebase/redo this? Otherwise I'd close this PR and we can try to do this again later.. @ruipserra Thanks again for your effort! You're welcome to open a new PR or reopen this one as you see fit, and also to bug me about to to get it merged quickly! :). Cargo treats plain version numbers as if there was a ^ in front of it. If\nyou want the exact version, you need to write =0.8.0.\nCl\u00e9ment Renault notifications@github.com schrieb am Mi. 2. Nov. 2016 um\n22:45:\n\nIt's 0.8.0 and not ^0.8.0\nhttps://github.com/diesel-rs/diesel/blob/master/diesel_codegen/Cargo.toml#L15\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/490#issuecomment-258008677,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX-ilQ3NPfr4P7Vd07o8uofvjj2Qgks5q6QRygaJpZM4KnH5_\n.\n. Interesting change. The code looks good, but I'm not familiar enough with the macros 1.1 changes to actually determine if it is good :)\nSince infer_table_from_schema! isn't highly used, I think this is OK, but we might want to start looking at alternatives long term.\n\nI agree. Also, this is another reminder to implement #437.\n. IIRC, #493 aims to fix the _Dummy error\n. @bronson sorry for the short but still delayed answer; you can find the getting started code at https://github.com/diesel-rs/diesel/tree/master/examples and the website text at https://github.com/sgrif/diesel.rs-website. I think what you are looking for are diesel's 'large-table' and\n'huge-table' features that allow tables to have more columns. You can\nactivate (one of) them in your Cargo.toml file.\nnoyez notifications@github.com schrieb am Mi. 23. Nov. 2016 um 22:14:\n\nI am a Rust beginner, so I apologize if this is not a bug and that i\nmissed something obvious.\nrust version: rustc 1.13.0 (2c6933acc 2016-11-07)\ndiesel version: 0.8.0 (using getting_started_step_4 projects as template)\nI attempted to use a table with 17 fields using the diesel framework and\ncompilation fails. Compilation succeeds with 16 fields. Attached (\ndiesel-many-fields.tar.gz\nhttps://github.com/diesel-rs/diesel/files/610016/diesel-many-fields.tar.gz\n) is a modified project based from the examples/getting_started_step_4\nproject. The tar file can be unpacked in the examples/ directory, and the\nscript test_stable.large can be run compile the code.\nOf Note, line 30 in src/models.rs and line 15 in\nmigrations/20160815133237_create_posts/up.sql. if each line is commented\nout, the code compiles, if each line is active, code does not compile.\nerror[E0277]: the trait bound (schema::posts_large::columns::f_00, schema::posts_large::columns::f_01, schema::posts_large::columns::f_02, schema::posts_large::columns::f_03, schema::posts_large::columns::f_04, schema::posts_large::columns::f_05, schema::posts_large::columns::f_06, schema::posts_large::columns::f_07, schema::posts_large::columns::f_08, schema::posts_large::columns::f_09, schema::posts_large::columns::f_10, schema::posts_large::columns::f_11, schema::posts_large::columns::f_12, schema::posts_large::columns::f_13, schema::posts_large::columns::f_14, schema::posts_large::columns::f_15, schema::posts_large::columns::f_99): diesel::SelectableExpression<schema::posts_large::table, (diesel::types::Integer, diesel::types::Text, diesel::types::Text, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Bool)> is not satisfied\n  --> src/lib.rs:12:1\n   |\n12 | include!(concat!(env!(\"OUT_DIR\"), \"/lib.rs\"));\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ trait (schema::posts_large::columns::f_00, schema::posts_large::columns::f_01, schema::posts_large::columns::f_02, schema::posts_large::columns::f_03, schema::posts_large::columns::f_04, schema::posts_large::columns::f_05, schema::posts_large::columns::f_06, schema::posts_large::columns::f_07, schema::posts_large::columns::f_08, schema::posts_large::columns::f_09, schema::posts_large::columns::f_10, schema::posts_large::columns::f_11, schema::posts_large::columns::f_12, schema::posts_large::columns::f_13, schema::posts_large::columns::f_14, schema::posts_large::columns::f_15, schema::posts_large::columns::f_99): diesel::SelectableExpression<schema::posts_large::table, (diesel::types::Integer, diesel::types::Text, diesel::types::Text, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Bool)> not satisfied\n   |\n   = note: required because of the requirements on the impl of diesel::query_builder::Query for diesel::query_builder::SelectStatement<(diesel::types::Integer, diesel::types::Text, diesel::types::Text, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Bool), (schema::posts_large::columns::f_00, schema::posts_large::columns::f_01, schema::posts_large::columns::f_02, schema::posts_large::columns::f_03, schema::posts_large::columns::f_04, schema::posts_large::columns::f_05, schema::posts_large::columns::f_06, schema::posts_large::columns::f_07, schema::posts_large::columns::f_08, schema::posts_large::columns::f_09, schema::posts_large::columns::f_10, schema::posts_large::columns::f_11, schema::posts_large::columns::f_12, schema::posts_large::columns::f_13, schema::posts_large::columns::f_14, schema::posts_large::columns::f_15, schema::posts_large::columns::f_99), schema::posts_large::table>\n   = note: required by diesel::query_builder::AsQuery\n   = note: this error originates in a macro outside of the current crate\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/500, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXxxKj82rPjgb4Wv8TVTSLRkXpvenks5rBKzTgaJpZM4K7Db7\n.\n. FYI tracking issue for Postgres' custom enum types is #343. @nerdrew, can you also have a look at the conflict and the CI failure? If you don't have time, that's okay, I can do it tomorrow.\n\nTravis says:\nerror: unused variable: `lifetimes`\n  --> /home/travis/build/diesel-rs/diesel/diesel_codegen/src/identifiable.rs:10:9\n   |\n10 |     let lifetimes = model.generics.lifetimes;\n   |         ^^^^^^^^^\n   |\nwhich surprises me because\n\nit's not a bug in cargo/rustc (yay, CI works again!),\nthis line is not in identifiable.rs:10 but in insertable.rs:21 (maybe proc macros messing up the source of the error),\nlifetimes is passed to the _Insertable! as (#(#lifetimes),*),\nand it compiles fine locally with my nightly from 2016-09-28.\n\nYou can find the code in its current form here. Maybe adding #[allow(unused_assignments)] (or similar, with a comment) as a temporary solution is fine.. Thanks!\nSQLite doesn't have these literals, but the examples are Postgres specific anyway. So I see no reason not do merge this!. LGTM. Cleanups are always welcome.\n(I'm not sure if it helps you, though. pg/connection/{mod,raw,result}.rs and others, incl. most sqlite stuff, still use libc.). The alternative being writing the schema name explicitly? I'm okay with being explicit here. infer_schema does so much magic already! It might also be nice to write the schema name as an ident, so it's not surprising we generate a module with that name.\nI'm a bit confused about the story with the other backends. Using PG, \"schema\" obviously means what PG calls \"(custom) schema\". In SQLite, it means \"attached database\", right? (What you get when you do ATTACH DATABASE foo as foo which lets you query it as \u2026 FROM foo.table_name, like a PG custom schema). I have no idea if MySQL has something like that.\n\ngive a decent opt-in for MySQL if you actually needed to compile with multiple databases\n\nWhat do you mean by \"compile with multiple databases\"? All three backends could, in theory, be used with multiple connections to multiple databases, couldn't they? (Assuming some trickery with build scripts maybe even using infer_schema.) What makes MySQL special here?. > and the database name appears where the schema name appears in PG\nDamn, that is unfortunate. So that means implementing schema inference with custom schemas gives up\u2026 multiple dbs in MySQL? Crazy.\nSo, the options are to (a) not try to load all the custom schemas automatially or (b) special-case this for pg and tell people why that is. I say, go with option (a) and make people type their custom schemas' names so they know they will get them.\n\nUnfortunately, if we want to be able to use macros 1.1, we can only take string literals as arguments.\n\nCan you do ($database_url:expr, $schema:indent) and expand to #[options(database_url=strigify!($schema))] so users can only supply something that can become a module name? \n. Yay, all green!. Good point, will remove some more stuff!. More stuff removed \u2705 . Did you enable the \"chrono\" feature in your Cargo.toml for the diesel dependency? The docs say the impl is only available when it's enabled.. \n. What do you mean by this? Can you maybe describe what you want to do and how you think diesel should help you with this?. Oh, you mean the documentation. Yeah, the guide doesn't describe everything.\nYou have seen the API documentation, right? It can be confusing in the\nbeginning, but contains a lot of detailed information on most of diesel's\nfeatures.\nWhat are you missing the most? What are you trying to do that is not\ndocumented? The plan is to add more guides for specific use cases of diesel\nin the future.\nsackery notifications@github.com schrieb am So. 18. Dez. 2016 um 06:01:\n\nDocument in diesel.rs is so simple and not fully, it's just a guide.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/545#issuecomment-267803643,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX-Ox61CMdMprTHPB5hStu3J1pLShks5rJL4igaJpZM4LOwKo\n.\n. I haven't heard back, so I'm gonna close this. I have opened a new issue for implementing #[deny(missing_docs)], though: #563.. Thank you!\n\nWe should probably have a check for that in CI (same with links in docs, we had a PR for that as well recently).. @sgrif The errors I mentioned in #548 seem to only turn up with recent nightlies. While 2016-12-15 compiled it fine, 2016-12-18 noticed the unused type alias.\nI'll merge these fixes right now. Setting #![allow(dead_code)] in a macro-generated module seems okay to me. This could potentially also be an issue for users using #![deny(warnings)]. Maybe we can look into this more deeply at a later date.. Oh \u2014 would it make sense to add an #[allow(warnings)]? Does that even work?\n\nAm 22.12.2016 um 21:11 schrieb Sean Griffin notifications@github.com:\nI think that allow on the entire generated module is fine. Agreed that all generated code must always be warning free.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. This has been recently fixed in master (have a look at the last two PRs\nthat were merged)! Can you give it a try and see if it works for you?\nEthan Frei notifications@github.com schrieb am Fr. 23. Dez. 2016 um 01:30:\n\nI recently updated my project to diesel 0.9 from 0.5. I've migrated\nsuccessfully, as there are no errors and it's working correctly, however\nI'm getting one particular warning which repeats 9 times when I build:\nwarning: type alias is never used: BoxedQuery, #[warn(dead_code)] on by default\n --> /builds/freiguy1/proj/db/src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = note: this error originates in a macro outside of the current crate\nI apologize if I missed some documentation on this. I'm using rust\nnightly-2016-12-18.\nThanks!\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/551, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXwKHel8CpHBfdMDZfUH6rl5Anvwiks5rKxYagaJpZM4LUfkK\n.\n. We talked on Gitter about this: logs.. In production, you probably want to use connection pooling. Have a look at r2d2-diesel (and lazy_static). I think there is an iron-diesel crate, maybe you can have a look at how they did it.\n\nWe have a gitter.im channel (linked in the Readme; also works via IRC) if you want to say hello :)\n\nAm 28.12.2016 um 06:56 schrieb Robert Balicki notifications@github.com:\nHappy to take this to an IRC channel/slack group, but couldn't find one. Not sure if rust-beginners is appropriate, either.\nI'm writing a web app using diesel and rocket, and in every route handler I'm calling establish_connection (straight from the getting started guide). Is this unnecessary overhead? Should I store a single connection to a database somewhere, and reuse that one?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Oh, travis-cargo doesnt seem to like generating and uploading docs using Cargo workspaces. Which is also a problem on master.. FTR: Since macros 1.1 does not allow supplying parameters to the derive calls itself, we unfortunately need to deal with attribute namespacing. Diesel already does a bit of that with attributes like changset_options and less generic names like table_name, or primary_key, but I can see that options is a problem.\nLuckily, as you note, this should not be a user-facing breaking change. The options attribute is only used in the macros infer_schema!, infer_schema_from_table!, and embed_migrations!. I would accept a PR to change these attribute names to something more specific, like infer_schema_options, infer_table_from_schema_options, and embed_migrations _options.\nIt should suffice to change the names here, here, and here.. Happy new year!\n\nIs primitive_impls! exported somewhere?\n\nOh, good point. Only a few macros are exported. And I'm not sure if we want to expose primitive_impl! as-is because we'll probably need to guarantee backward compatibility for its implementation details (macros are hard). I'll have to think about that. @sgrif probably has some thoughts on that as well.\n\nWhere should I add tests that create a table and do more complex experiments? If you can point me at an existing file, I'd be happy to generalize from there.\n\ndiesel_tests is a complicated beast! :) There is a lot in there and I can't pretend to know all of it. There is even a small schema creating DLS! I'd suggest looking at this (or similar) tests that define a new table in a transaction.\nIf you want to dig even deeper into diesel tests, have a look at types_roundtrip.rs :)\nFor doc tests, I don't think it's easily possible to add custom derive there. You can use the regular macros with the struct definition though. A lot of magic is also done in src/doctest_setup.rs. Have a look at this doc comment as a example.. I agree. Integration tests are the most important thing that this PR needs.\nIt shouldn't be too hard if you find the right things to copy the\nboilerplate from. Let me know if you need any help. Otherwise I'll have\nsome time at the end of the week where I'll do more Diesel stuff, and could\nadd the Integration tests. (A lot of people will be happy when this\nlands!)\nEric Kidd notifications@github.com schrieb am Mo. 9. Jan. 2017 um 23:20:\n\nYes, it would really help to have a list.\nI've been procrastinating a bit on the integration tests, because the\nrequested tests for json/jsonb are much more extensive than the existing\ntests for UUID, so I'm going to have to come up to speed on a fair bit of\nthe code base to implement them.\nI think operators should not block the list.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/561#issuecomment-271426196, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX9myXEPOdgPjmxfqTYc6jSofAvy6ks5rQrK0gaJpZM4LYkJK\n.\n. @norcalli Did you write any tests yet? I just wrote a doc test and opened https://github.com/faradayio/diesel/pull/1 for it. More tests will be better though :). You're welcome. I'd love to add some more integration tests/doc comments with custom derives using serde (because this will show the roundtrip how its meant to be), but I saw we didn't use codegen in doc comments anywhere. Probably with a good reason; I opened #576 nevertheless.\n\nAnyway, I wont get to it today, but I'll try to add a few integration tests tomorrow or on Sunday \u2013 unless @norcalli wants to/has time to write some.\nDo you have any other things you want to add here before landing this, @emk?. @emk I have some time this weekend and would love to merge this. The type Json = Jsonb thing is still open. If you have some time, it would be awesome if you want to tackle this, otherwise I'll try to do that, or leave it open for a future PR.. So, before this lays around for another week: Let's merge this! We can always tweak it some more later on.. > first commit in Rust\nWow, that's amazing, @mattjmcnaughton!\nAdding the deny itself will just make it not compile any more until all items in that list have doc comments. So we'll have to wait a bit before we can add this. :) Locally, you could also use #[warn(missing_docs)] to let the compiler give you a warning for all the undocumented public items in the code base (basically my list).\nThat's a lot of items to write documentation for, so I it makes sense to have a lot of smaller PRs adding docs for singular modules or traits.\nOh, and I totally forgot to link to these guidelines to keep the doc comment style consistent. (Not that I want each doc comment as extensive as the examples in there, though! Please let me know if you have suggestions to improve these guidelines.). Exactly. And thank you!\nSince there are a lot of items to document, this does not need to (and\nprobably should not) be a one person job. If more people want to help, I'll\nadd a check list here to track what has already been documented.\nIf you have any questions regarding the code or the API to document, feel\nfree to drop by our Gitter room :)\nMatt McNaughton notifications@github.com schrieb am Sa. 7. Jan. 2017 um\n03:41:\n\nSounds like a plan (and thank you for the quick response)! As I understand\nthe code, and as I get the change, I'll make some separate prs with the\ndocumentation changes, and when the documented items are fixed, I'll make a\npr that adds #![deny(missing_docs)].\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/563#issuecomment-271057314,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXxNUaUBr9jJUyekDKsLrBQW5Yvd7ks5rPvt1gaJpZM4LYwv1\n.\n. I just added a few more details on how contribute to the issue description: https://github.com/diesel-rs/diesel/issues/563#issue-198278768. Thank you! Every small contribution counts! Don't worry if it's not perfect\nat your first try; that's what code review is for! We'll get there together\n:)\n\nErich Cordoba notifications@github.com schrieb am Do. 26. Jan. 2017 um\n07:36:\n\nSent a very simple (and probably wrong) PR #592\nhttps://github.com/diesel-rs/diesel/pull/592\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/563#issuecomment-275317797,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX1kJnAqU8PzmyYqmzlwtx_3sNFEtks5rWD7sgaJpZM4LYwv1\n.\n. Oh, good catch!\n\nCan you add a test to see that this is actually a sane value? Like, add a test that runs a migration and check that run_on is set to something greater than 1 hour go. (Huh, I actually have no idea if/where we have tests for this behavior. If you can't find anything, let me know.). > Is it okay to use CURRENT_TIMESTAMP with Diesel given these limitations?\nI think that is fine for the migrations table. If it turns out to be a problem wen can still add backend specific code later. Or, I don't know, add a sleep(1) somewhere ;). Wait\u2014why don't we specialize this for the specific backends? I would like to not try to be clever here and do what is best practice for the backend in question. Sorry for thinking about this earlier.\n(I'm thinking of introducing a new MigrationsSetup trait (or similar) that is implemented for both PgConnection and SqliteConnection and contains a fn setup_migration_table, and replacing the implementation of create_schema_migrations_table_if_needed with a call to that function.). Well, if setup_helper_functions is already there, sure. I was just thinking\nof being a bit more explicit, as it is not really a concern for the\nconnection itself, but the backend. I'm all for keeping consistency though,\nand we can always refactor this later.\nAdrian Perez notifications@github.com schrieb am Di. 3. Jan. 2017 um\n01:08:\n\n@killercup https://github.com/killercup: That sounds very sensible, and\ncertainly would be future-proof if later on the __diesel_schema_migrations\ntable needs a more complex schema. One question, though: If both\nimplementations of Connection are going to have a fn\nsetup_migration_table(), wouldn't it make more sense to have the function\ndirectly in the Connection trait instead of adding a new trait? (For\nexample fn setup_helper_functions() is there).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/564#issuecomment-270034941, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXywbTaUSWIp4LzBzafCi6R4F3p-jks5rOZDJgaJpZM4LZEK1\n.\n. On my machine with Postgres 9.6, the tests pass. Travis is using Postgres 9.4, though, and it fails with syntax error at or near \"SELECT\". Is this a newly supported thing?. Very nice! Thanks again!. Travis failures are from proc_macro becoming stable and deny(warnings). Will make a PR to remove the feature attrs later.\nAm 07.01.2017 um 23:14 schrieb Sergio Benitez notifications@github.com:\nFailures are unrelated to these changes.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. @SergioBenitez can you rebase this on master to see if the tests pass? I'll merge it after that.. Sweet! Merging!. You can create the table DSL for views by calling the table! macro yourself. Does this solve your problem?. Is there a nice way to do this? All I can think of is something like\n```rust\n[cfg(not(any(feature = \"sqlite\", feature = \"postgres\")))]\nmod hello_you_need_enable_one_of_the_backend_adapters_as_cargo_feature_thank_you;\n``. Oh, interesting, I didn't know that=` was the POSIX version. Do you know if there are any differences between the two, and if they could be problematic?. Nice research, TIL! Locally, I'm probably using Apple's BSD adaption, though I have gnu coreutils installed as well. I'd say this is a \"sh is assumed to be bash\" thing as well, since this is what it defaults to on most machine, incl. mine and Travis CI (even though I'm an avid fish user).\nI'll merge this as soon as you pushed the && changes :). Thanks for sticking with this, @dstu! The commit churn is no problem, Github allows to squash before merging :). Yeah, having lints for that would be awesome, even if to just add notes on Rust errors. Maybe we can give users some suggestions on how to make their code cleaner as well (though that is by far not as important as actually catching and explaining errors).\nIIRC, clippy (cc @llogiq) contains a lint to catch invalid regexes, maybe they have a story for supporting other external crates? (Though regex is, to me, \"practically in std\"!)\n\nAm 12.01.2017 um 15:16 schrieb Sean Griffin notifications@github.com:\nSome of the most common issues that people run into are:\n\u2022 Column order doesn't match struct field order\n  \u2022 Column type doesn't match struct field type\n  \u2022 Struct doesn't have a field for all the selected columns\nI'd eventually like to allow the order to differ from the table definition, but I'm not confident that we will ever be able to do that. While I do want to make sure that the errors from the compiler alone give at least enough information for experienced users to figure out what's going wrong, we can do better. I've often thought about trying to do more validation inside of #[derive(Queryable)]. However, the issue there is that we can't get information about the code other than the item being annotated, meaning we can't ask things about the table mod. We also have no database connection, so we can't go to the schema to ask questions either.\nOne issue I have with just validating from that derive though is that it assumes:\n\u2022 The user is using infer_schema! to define that table\n  \u2022 The struct is meant to be one-to-one with a table that has the same name\n  \u2022 The select clause used to construct this will contain all the columns from a given table\nAnd I've tried to avoid all of those assumptions in the design. So I think a lint makes a lot more sense, as it has access to way more information (meaning we don't need a database connection), and they can be much more granularly allowed by the user.\nI'm unsure if these lints would be able to occur early enough to catch the most common cases, but we should definitely explore this option. Ideally I'd like to avoid using a database connection for this, and have it only affect types which implement HasTable, find the module based on the value of that associated type, and base the linting off the value of AllColumns and SqlType. I'd like to try and provide a specific error message with suggestions on how to correct for all of the following, probably in this order:\n\u2022 struct order doesn't match column order (this one should only fail if all the field names match a column name, and the number of fields matches the number of columns)\n  \u2022 struct does not have a field for each column\n  \u2022 two or more struct fields have the same name as a column but appear in swapped positions\n  \u2022 field type doesn't match column type (error message should ideally include which Rust types could map to the column type, or what SQL type they could change their column to match the rust type)\nOne other slightly less common mistake I've seen people make, which we could definitely catch with a lint is people thinking that they should be putting diesel::types::Timestamp on their struct directly.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Orthogonal to lints, but related to nicer errors: https://scribbles.pascalhertleif.de/hook-into-rustc-errors.html. Good question, @dstu! I'm a lazy person, so I don't want to wait for all the tests to run! :) When I added the doc test to #561, I used:\nbash\n$ pwd # in diesel crate dir\n\u2026/diesel/diesel\n$ env RUST_BACKTRACE=1 DATABASE_URL=postgresql://pascal@localhost/diesel_test DATABASE_URL_FOR_SCHEMA=postgresql://pascal@localhost/diesel_schema cargo +nightly test --no-default-features --features \"postgres serde_json unstable\" -- Jsonb\nThe important parts are the features, and the -- <whatever> after the cargo test arguments, as that tells the test runner to only execute the tests whose names contain the <whatever>.\nIf you are happy with your changes and your new/changed tests run, you can run the whole test suite. Or, you know, let Travis to it when you open a PR ;). Moving this to a top-level comment so it doesn't get lost. In reply to https://github.com/diesel-rs/diesel/pull/577#discussion_r96125450:\nOrrrr, rustfmt! \ud83d\ude1e Well, I guess we need to define our own formatting, then. You encoded some rules implicitly. Can you document them? I'd start with:\n\nSeeing { increases indentation level\nSeeing } decreases indentation level\nInsert newline after {, }, ,, and ;\nDon't put spaces:\nbetween ident and !,\nbetween path segments and ::\nafter ( and before )\nbefore ,\n\n\nInsert spaces\naround arrows (->, and probably also =>)\nafter keywords like mod, and use\n\n\n\nI'd really like to put this whole formatting business into its own module, encode the rules as well documented as possible and add a bunch of tests.. Thanks, @weiznich!\nThe nightly failures are from compile-tests, and we need to fix them. It seems to me that either some compiler messages changed because of changes by use (unlikely) or by changes in a new nightly (with nicer/other error messages). ~~I'll have a look this evening.~~ Can't make the time, will try again tomorrow.. As promised, I made a few more changes to the print-schema/inference code: https://github.com/weiznich/diesel/pull/2\nThe most important abstraction is are the new TableData and TableDataWithTokens types that are passed around. I think this makes the code a bit clearer and easier to handle. What do you think?\nI'm not sure if this gets run on Travis, but I didn't want to open a new PR on the main repo to not fork the discussion. The tests pass locally though, except for that weird thread panicked while panicking. aborting. failure I haven't investigated further.. Thanks, @weiznich. I like your changes, very nice! Travis reports some failures in some unit tests, can you have a look? There are some known problems with recent nightlies; I'll try to get it to run on a known good version.. Oh, and if you merge master into this (or rebase on master if like), the tests should pass again on nightly (#596).. Awesome! Merged! \ud83c\udf89 . Why are you running cargo install? Which version of rust are you using? Did you follow the guide?\n\nAm 14.01.2017 um 16:19 schrieb Zakordonets Sergey notifications@github.com:\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>cargo install\nCompiling quote v0.3.10\nCompiling winapi-build v0.1.1\nCompiling libc v0.2.19\nCompiling unicode-xid v0.0.3\nCompiling memchr v0.1.11\nCompiling pq-sys v0.2.7\nCompiling winapi v0.2.8\nCompiling kernel32-sys v0.2.2\nCompiling aho-corasick v0.5.3\nCompiling syn v0.10.6\nCompiling utf8-ranges v0.1.3\nCompiling byteorder v0.3.13\nCompiling regex-syntax v0.3.9\nCompiling diesel v0.9.1\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:49:41: 49:47 error: expected expression, found 1\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:49 if row.next_is_null($Tuple) {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:49:41: 49:47 error: expected {, found 1\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:49 if row.next_is_null($Tuple) {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:49:41: 49:47 help: place this code inside a block\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:66:38: 66:42 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:66 ($($T::build(row.$idx),)+)\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:66:38: 66:42 error: expected one of ,, ., ::, ?, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:66 ($($T::build(row.$idx),)+)\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:66:38: 66:42 error: expected one of ), ,, ., ::, ?, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:66 ($($T::build(row.$idx),)+)\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:78:28: 78:32 error: expected expression, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:78 if $idx != 0 {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:94:28: 94:32 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:94 $(self.$idx.is_safe_to_cache_prepared() &&)+ true\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:94:28: 94:32 error: expected one of ., ::, ;, ?, }, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:94 $(self.$idx.is_safe_to_cache_prepared() &&)+ true\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:118:28: 118:32 error: expected expression, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:118 if $idx != 0 {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:129:28: 129:32 error: expected expression, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:129 if $idx != 0 {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:145:37: 145:41 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:145 match &self.$idx {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:145:37: 145:41 error: expected one of ., ::, ?, {, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:145 match &self.$idx {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:167:37: 167:41 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:167 match &self.$idx {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:167:37: 167:41 error: expected one of ., ::, ?, {, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:167 match &self.$idx {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:186:37: 186:41 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:186 match &self.$idx {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:186:37: 186:41 error: expected one of ., ::, ?, {, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:186 match &self.$idx {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:206:37: 206:41 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:206 match &self.$idx {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:206:37: 206:41 error: expected one of ., ::, ?, {, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:206 match &self.$idx {\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:242:29: 242:33 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:242 ($(self.$idx.as_changeset(),)+)\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:242:29: 242:33 error: expected one of ), ,, ., ::, ?, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:242 ($(self.$idx.as_changeset(),)+)\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:251:28: 251:32 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:251 $(self.$idx.is_noop() &&)+ true\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:251:28: 251:32 error: expected one of ., ::, ;, ?, }, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:251 $(self.$idx.is_noop() &&)+ true\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:258:49: 258:53 error: unexpected token: 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:258 let noop_element = self.$idx.is_noop();\n^~\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:258:49: 258:53 error: expected one of ., ::, ;, ?, or an operator, found 0\nC:\\Users_.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-0.9.1\\src\\types\\impls\\tuples.rs:258 let noop_element = self.$idx.is_noop();\n^~\nBuild failed, waiting for other jobs to finish...\nerror: failed to compile diesel_demo_step_3 v0.1.0 (file:///D:/idea%20projects/rust_diesel/diesel/examples/getting_started_step_3), intermediate artifacts can be found at D:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3\\target\nCaused by:\nCould not compile diesel.\nTo learn more, run the command again with --verbose.\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Yes that's the guide I mean. (I think you want to use cargo build or cargo run; cargo install is for installing rust applications on your system.)\nI don't think diesel 0.9 works with rust 1.11. Can you update to 1.14?. Cool! As the guide mentions, the first three steps are assuming you are using a semi-recent nightly compiler. Step 4 adds support for building on stable.\nFYI: Diesel will work on stable with the release of Rust 1.15 on February 3!. It depends on how much you like to have adventures! ;)\nPersonally, I'd use the latest nightly with Diesel from git -- there were a\nbunch of nice bug fixes and you will be able to quickly upgrade to Diesel\n0.10 when it gets released. It is nightly though, so it is not tested that\nwell and might contain bugs we don't know about.\nUsing stable with the build steps described at the end of the guide is not\nas exciting but also a totally valid option.\nActually, there might even be a beta release that contains the new macros\nthat will become stable in 1.15.\nHeh, now I've listed all release channels. Sorry for rambling\u2026\nZakordonets Sergey notifications@github.com schrieb am Sa. 14. Jan. 2017\num 17:17:\n\nwhat version of rust and diesel should i use to play around with diesel\ntoday ?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/578#issuecomment-272634023,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX1AyXqHLQCx5_2Rmqi1qQuvdtzckks5rSPUCgaJpZM4LjpwB\n.\n. Did you use the diesel version from git master? Also, did you set nightly to be the default toolchain to be used? Otherwise you might need to call it like cargo +nightly build.\nmy goal is to test how much of performance cat i squeeze out of rust+Diesel vs php+PDO\n\nWith a CPU-heavy, Rust will probably run laps around PHP, with database-heavy application it might be not that much of a difference.. Thanks for the quick fixes, @dstu!\n(By the way, Github says the mail address in your commits is not associated with your Github user, but it's just a matter of adding it to the list in your account settings.). Nice! I saw your branch a while ago, and am glad to see this PR. This is quite a lot of code! I'll try to read through it this evening, or tomorrow afternoon. Feel free to bug me if I forget about it though :). @sgrif worked on supporting UPSERT in November (ON CONFLICT DO UPDATE), which turned out to be pretty tricky.\nDo you expect to get a return value with all the skipped rows?. Thank you, especially for the very nice explanation!\nWe were planning on releasing 0.10 at the beginning of February but I don't see any reason not to release a 0.10.rc1 sooner :). First off, it shouldn't hurt to have both: Most people will use postgres in production, and enabling support for sqlite should not be a problem.\nI saw you had problems (#587) getting postgres (or, more specifically pg-sys) to work on Windows, so maybe we should also link to this. (We are planning on using our own postgres driver in the future, by the way, which will not need linking to libpg.)\nThe sources of diesel.rs are here: https://github.com/sgrif/diesel.rs-website (it's not in this orga because of something about github pages and DNS setup IIRC). It might make more sense to explain the available features in diesel_cli's Readme (here), though, and only link to that on the website.. Seems to be resolved by sgrif/diesel.rs-website#29.. Is this only the case with diesel_cli? Otherwise you should probably also open an issue at https://github.com/slapresta/rust-dotenv :)\n\nAm 21.01.2017 um 17:44 schrieb Tim notifications@github.com:\nI haven't quite diagnosed this, but on Windows using PostgreSQL, this works:\ndiesel setup --database-url=postgres://postgres:myadminpass@localhost/my_db\nBut if I put DATABASE_URL=postgres://postgres:myadminpass@localhost/my_db in .env and run diesel setup it prints:\n\ndiesel setup\nCreating database: localhost:5432\ncould not translate host name \"postgres\" to address: Unknown host\n\nThat... doesn't seem right.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. . Seems to work fine! Thanks, @jimmycuadra!. Nice. Thanks, @theduke!\nWe currently cheated this issue by using absolute URLs (well, absolute paths) in a few places. This is good for now, but we should revisit this when a better solution (e.g. https://github.com/rust-lang/rfcs/pull/1946) is available.. Shouldn't be too much work.\ncc @emk. I saw this failure as well but couldn't reproduce it locally. Are you using\nthe 0.9 from crates.io or from git master?\nDid maybe one of our dependencies change? (We use clap for the CLI.)\nivanceras notifications@github.com schrieb am Mi. 1. Feb. 2017 um 07:40:\n\nThis used to work on early versions of disel_cli, but now I re-installed\ndiesel_cli 0.9.0 it will keep displaying the help message.\n$diesel migration generate create_users\ndiesel-migration-generate\nGenerate a new migration with the given name, and the current timestamp as the version\nUSAGE:\n    diesel migration generate [OPTIONS] \nFLAGS:\n    -h, --help    Prints help information\nOPTIONS:\n        --database-url             Specifies the database URL to connect to. Falls back to the DATABASE_URL environment variable if unspecified.\n        --migration-dir     The location of your migration directory. By default this will look for a directory called migrations in the\n                                                 current directory and its parents.\n        --version             The version number to use when generating the migration. Defaults to the current timestamp, which should\n                                                 suffice for most use cases.\nARGS:\n        The name of the migration to create\nHowever with a correct .env with the DATABASE_URL set correcly, diesel\nsetup works and creates the needed database and tables.\nTested both on MacOS and ubuntu 16.04, with the same behavior.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/602, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX62gtYB2buaW3vmn1F8rh0YKuSW8ks5rYCjLgaJpZM4Lzic8\n.\n. So it's a breaking change in clap? cc @kbknapp\n\n@weiznich, why would it ever load a clap \u2265 2.11, though? diesel_cli contains a Cargo.lock :O\nI really hope this has nothing to do with workspaces :/ (or I'll need to cc some more people). Quick workaround: clap = \"=2.19.3\". We should probably remove diesel_cli from the workspace for now.. > error: macro undefined: 'options!'\nSound like we missed something in #565?. The tutorial will be updated soon when the new version is released (it\ndoesn't track master).\nfivethousand notifications@github.com schrieb am Do. 2. Feb. 2017 um\n18:17:\n\nOh.\nThe example (or at least the first steps) do compile and work after\nremoving\n![feature(proc_macro)]\n(as suggested).\nMaybe this should be added to the tutorial until the issue is fixed.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/605#issuecomment-277021101,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX8-cvTew_qeyF-eC_p-oTg_xF-pFks5rYg-MgaJpZM4L1TB3\n.\n. @sgrif, I think we talked about moving these macros to pure custom derives a while ago. Do you want to do that right now?\n\nAnyway, it should be one PR per macro IMHO.. Ohhhh right, $crate, I remember. That's obviously not possible in a separate derive crate. You can't rename an extern crate, can you? So the full path may be ugly, but not inherently worse.. Well, that was easy :). Oh. This kinda got hit by the MySQL stuff that was merged this week. Can you rebase?. Hm. To solve this, you'll either need to\n\nadjust the table! macro to find\u2014at expansion time\u2014column names that equal the table name (not even sure if you can encode that as macro), or\nadjust the schema inference (codegen) to return an error there (or maybe rename the column).. We have a bunch of dependencies that allow ranges of versions. The easiest way is to just open a PR which increases uuid's version range to \u22640.5 and see what happens on CI :)\n\n(I'm not sure how extensive our tests for this are. Maybe you can also add an integration tests using both serde and uuid?)\n\nAm 06.02.2017 um 12:56 schrieb Eric Kidd notifications@github.com:\nHello! I am working to upgrade one of our Rust projects to the latest diesel and serde, but the latest serde only seems to work with uuid 0.4.0, and diesel only supports uuid 0.3.1. I think it should just be possible to allow either version of uuid, but I'm not quite sure how to verify that.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. I'm only reading this via email. The problem was adding the belongs_to attribute twice?\nDoes the documentation mention this? (If not, PR welcome!)\n\nAm 07.02.2017 um 12:21 schrieb Boscop notifications@github.com:\nAh, nevermind, I had changed this:\n[belongs_to(User)]\n[belongs_to(Post)]\nto this:\n[belongs_to(User, Post)]\nbecause I assumed it would work, just like:\n[derive(Queryable, Insertable, new, Debug, Associations)]\nNow that I changed it back to the former version, it compiles, yay!\nThanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Enable Github linking magic: https://github.com/diesel-rs/diesel/issues/628. No worries, we can squash for you before we merge.\n\nAm 07.02.2017 um 17:01 schrieb ivanceras notifications@github.com:\nomg. I don't know how to squash commits :( Can we close this and do another PR with the same changes?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Travis fails in information_schema::tests::load_table_names_loads_from_custom_schema because the tables are not in the expected order.. I don't see anything we can do here, except release a new version soon. The reason this is not in 0.10.1 is that switching to chrono 0.3 is a breaking change for everyone who uses chrono 0.2. So, it'll end up in the 0.11 release. Until then, you'll have to depend on the git master version if diesel.. Like this http://doc.crates.io/specifying-dependencies.html#specifying-dependencies-from-git-repositories\n\nAm 09.02.2017 um 23:51 schrieb sackery notifications@github.com:\n@killercup how to use github version\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Fixed the lint, now errors with\n\nthread 'database_drop::database_drop_drops_database' panicked at 'Unexpected stdout ', tests/database_drop.rs:15\n\nwhich looks like a legit failure.. > Oh man I wish I'd realized this was going to be number 666. I would have made it a PR that enabled MySQL on CI or something.\nStill have that chance! Rebase it ~~to hell~~ to another branch ;). 0.10.1. If you specify diesel = { version = \"0.10\", features = [\"sqlite\"] } though, cargo will already pick the latest 0.10.x release.\n\nAm 11.02.2017 um 12:52 schrieb Freinn notifications@github.com:\nThanks @Eijebong. Solved. Should I use diesel 0.10.1 or 0.10?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. What else should be in this file?\n\n[x] local setup\n[x] link to issue tracker, and what information to supply\n[x] link to CoC\n[ ] general walkthrough through the test infrastructure\n[ ] ???\n[ ] PROFIT!!. We tried that last year in #197. Does rustfmt support a diff-friendly formatting yet? All my cries for trailing commas and consistent block ident are to reduce git churn and rightward drift, basically.. Cool. Thanks for researching this!\n\nThe where on a new line is very unfortunate to me. Why are its entries (from the second on) indented by two levels? At least they got a trailing comma in there. ;)\nAside from that there are two edge cases that always seem to trip rustfmt up (I should probably open/have opened issues about that): Closures in method chains, and deeply nested types.\nFTR, here's how I'd format a complex closure in a nested method chain (similar but not identical to how you did it #692):\nrust\nlet foobar_thingy_name: ImATypeName =\n    syn::aster::from_generics(model.generics.clone()) // <- on a new line, doesn't have to, though\n    .with_predicates(\n        model.generics.lifetimes // <- yes this is on a new line as well\n        .iter()\n        .map(|l| syn::WherePredicate::RegionPredicate( // <- expr, so not in a block\n            syn::WhereRegionPredicate {\n                lifetime: l.lifetime.clone(),\n                bounds: vec![insert.lifetime.clone()],\n            }\n        ))\n    )\n    .build(); // <- indented 1 level\nAnd here are deeply nested types (also from #692):\n```rust\ntype Lorem = (ColumnInsertValue::Expression(Version,\n    AsExpression<\n        <::SqlType as IntoNullable>::Nullable,\n    >,\n),);\ntype NullableColumn = AsExpression<\n    <::SqlType as IntoNullable>::Nullable,\n\n;\n```\n\nwhich is to be read like\nrust\ntype Lorem = (ColumnInsertValue::Expression(Version,\n    AsExpression<\n        <<Version as Expression>::SqlType as IntoNullable>::Nullable,\n//       '----------.----------'\n//           inner-most type\n//      '------------------------.-----------------------'\n//             2nd level: don't break this into lines\n    >\n),);\nIf you can't put the inner (two) type levels on a line, you should probably introduce aliases.\nIf you can put any of these on one line (without the comments of course) and rustfmt them into something vey similar to what I wrote here, I'm happy :)\nUpdate: Currently this ends with\nsh\n$ rustfmt fmt.rs\nRustfmt failed at fmt.rs:1: line exceeded maximum length (maximum: 100, found: 136) (sorry)\nand produces:\n```rust\ntype Lorem = (ColumnInsertValue::Expression(Version, AsExpression< <::SqlType as IntoNullable>::Nullable, >, ),);\ntype NullableColumn = AsExpression< <::SqlType as IntoNullable>::Nullable, >;\nfn main() {\n    let generics = syn::aster::from_generics(model.generics.clone())\n        .with_predicates(model.generics.lifetimes.iter().map(|l| {\n            syn::WherePredicate::RegionPredicate(syn::WhereRegionPredicate {\n                lifetime: l.lifetime.clone(),\n                bounds: vec![insert.lifetime.clone()],\n            })\n        }))\n        .build();\n}\n```. It seems to me that rustfmt and the formatting strike team are slowly but surely stabilizing on a code style. And even one I personally like! Things are looking good!\nI think we can soon try this whole endeavor again, but with the default configuration.. > This PR includes tests which use quickcheck for this.\nHeh, I even looked for this but misremembered what the macro did. Thanks again!. No idea why I went with the most complicated way possible and tried to play human SAT solver. The code is much simpler now.. Yeah, that's way better.\n@Mrmaxmeier, I'd keep the cli test and add a small unit test to diesel_infer_schema/src/sqlite.rs as well. (Do the others have tests for that? If not, maybe you can add them for PG and MySQL too).. Thanks, great work!. What macros are you specifically talking about?\nSome of them are explicitly not public API (so we can have breaking\nchanges) and are only used by the code gen crate, or internally.\nRam Kaniyur notifications@github.com schrieb am Sa. 18. Feb. 2017 um\n11:32:\n\nWhy are they all #[doc(hidden)]? Are we not supposed to use them?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/730, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX0BrECyyxUvdr21-5XB4U0eOgwxmks5rdsjTgaJpZM4MFE4n\n.\n. Thanks again! Sorry it took a while to merge this :). Rebased. All green.. > error: package pq-sys v0.4.0 specifies that it links to pq but does not have a custom build script\n\n. Oh and if this works, we might want to add some badges to the Cargo.toml files.. Merged as part of #804. @sgrif, I think all your comments were addressed. This looks good to me now. The conflict in CHANGELOG.md is easy to resolve, and can be done while merging.. Thanks for working on this, @pfernie!. Sorry, this totally fell through the cracks of my Github notifications. We don't currently have a fixed code style than can be enforced by rustfmt (patiently waiting for the fmt rfcs). Can you can remove the change introduced by formatting? (Alternatively, reset the tests/types file and only add your new tests.)\nThere's a small conflict in Cargo.toml. Might be a good chance to rebase and squash some of these commits. (That's not required though, or I can do it if you want.). Thanks! I say: Let's merge this!. I knew I forgot something! I'll add it in a sec.. Also TILgit merge --allow-unrelated-histories :). Thanks!\nIt's \"only\" the third step as the third is the one that contains everything in the guide, the steps are cumulative. ;) Step one is \"show posts binary\", step two \"add write posts binary\", and step three \"add publish and delete\".\n\nAm 23.02.2017 um 23:23 schrieb Taryn Hill notifications@github.com:\n@killercup Yes, I'll license this under MIT+Apache2!\nOnce this is merged I'll delete my repo entirely.\nHow is this only the third step?\nThat repo covers everything in the getting started guide.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Changed the license, merging.. One solution is being tracked in #999. Merged and added https://github.com/diesel-rs/diesel/commit/71cb54ff8b54986428c280e9f33fc1ddc02e5421. Thanks for staying on this!. @heyztb sure, go for it! Maybe open a PR with a rough idea what you want to test and then iterate on that? This way, we can give you feedback as early as possible. Alternatively, feel free to ask questions here or (preferred) on Gitter.. @heyztb cool!\nVery good question regarding the interativity! I actually totally forgot about that. It would be nice to test that, but it's totally fine to start with unit tests: We are trying to make sure the diesel examples are fine, not that stdin works, after all :)\nIn my capacity as author of assert_cli and CLI working group lead, I am very interested in making sure we can write those tests, however! There is https://github.com/assert-rs/assert_cmd/issues/28 which tracks this in some fashion. For all things CLI (testing or otherwise) you are also very welcome to join https://gitter.im/rust-lang/WG-CLI (or #cli-wg on the rust-lang discord) and to ping me directly.. Thanks again, @pfernie!. Thanks again!. Can you run with env RUST_BACKTRACE=full in front of the command?\nWhat version of postgres are using? On which platform?\n\nAm 13.03.2017 um 21:00 schrieb packapotatoes notifications@github.com:\nI'm working on the getting started guide, but when i run diesel migration run I get the following cryptic error:\nRunning migration 20170313193655\nthread 'main' panicked at 'internal error: entered unreachable code: Per PGs documentation, all errors should have a message', .cargo/registry/src/github.com-1ecc6299db9ec823/diesel-0.11.4/src/pg/connection/result.rs:91\nnote: Run with RUST_BACKTRACE=1 for a backtrace.\nI believe I have done everything correctly preceding this.\nI am using\n\u2022 rustc 1.17.0-nightly\n  \u2022 diesel 0.11.0\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Thanks!\npostgres \u2014version should work. Otherwise, apt-cache show postgresql (or whatever that package is called).\n\nAm 13.03.2017 um 21:10 schrieb packapotatoes notifications@github.com:\nI am running Linux Mint 18.1 (Ubuntu 16.04)\nI believe I am using postgres 9.6, how can I check for sure?\nHere is the additional output:\nRunning migration 20170313193655\nthread 'main' panicked at 'internal error: entered unreachable code: Per PGs documentation, all errors should have a message', .cargo/registry/src/github.com-1ecc6299db9ec823/diesel-0.11.4/src/pg/connection/result.rs:91\nstack backtrace:\n   0:     0x55c054dba043 - std::sys::imp::backtrace::tracing::imp::unwind_backtrace::h3c67687ba454b78b\n                               at /checkout/src/libstd/sys/unix/backtrace/tracing/gcc_s.rs:49\n   1:     0x55c054db6524 - std::sys_common::backtrace::_print::h701c2403afe49d2d\n                               at /checkout/src/libstd/sys_common/backtrace.rs:71\n   2:     0x55c054dbc19c - std::panicking::default_hook::{{closure}}::h07b8ee04b5734d1a\n                               at /checkout/src/libstd/sys_common/backtrace.rs:60\n                               at /checkout/src/libstd/panicking.rs:355\n   3:     0x55c054dbbd66 - std::panicking::default_hook::h23eeafbf7c1c05c3\n                               at /checkout/src/libstd/panicking.rs:371\n   4:     0x55c054dbc59b - std::panicking::rust_panic_with_hook::hd0067971b6d1240e\n                               at /checkout/src/libstd/panicking.rs:549\n   5:     0x55c054dbc424 - std::panicking::begin_panic::h1fd1f10a3de8f902\n                               at /checkout/src/libstd/panicking.rs:511\n   6:     0x55c054dbc399 - std::panicking::begin_panic_fmt::haa043917b5d6f21b\n                               at /checkout/src/libstd/panicking.rs:495\n   7:     0x55c054d93b06 - ::message::he632342bedd1fc35\n   8:     0x55c054d98c05 - ::description::he3bf3999aefbb8de\n   9:     0x55c054d977a5 - ::fmt::hf638487e386e20cb\n  10:     0x55c054de6255 - core::fmt::write::h0dfe169107a72abb\n                               at /checkout/src/libcore/fmt/mod.rs:911\n  11:     0x55c054db2193 - ::write_fmt::h334c4f73bdd7ac1f\n                               at /checkout/src/libstd/io/mod.rs:1015\n                               at /checkout/src/libstd/io/stdio.rs:460\n  12:     0x55c054db2fc6 - std::io::stdio::_print::h83b8589704f0a522\n                               at /checkout/src/libstd/io/stdio.rs:680\n  13:     0x55c054caf91e - diesel::run_migration_command::h7aeda08d0b501122\n  14:     0x55c054caa72f - diesel::main::h0e6d44d4297b2522\n  15:     0x55c054dc353a - __rust_maybe_catch_panic\n                               at /checkout/src/libpanic_unwind/lib.rs:98\n  16:     0x55c054dbcd46 - std::rt::lang_start::hb7fc7ec87b663023\n                               at /checkout/src/libstd/panicking.rs:433\n                               at /checkout/src/libstd/panic.rs:361\n                               at /checkout/src/libstd/rt.rs:57\n  17:     0x7f84fac5782f - __libc_start_main\n  18:     0x55c054c84438 - _start\n  19:                0x0 - \n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Should be fine now, cc #808 . That is what I'm doing with pascalhertleif.de and scribbles.pascalhertleif.de. It's pretty easy to do if you can set a custom name server for your domains.\n\nAm 16.03.2017 um 20:12 schrieb Sean Griffin notifications@github.com:\nhttps://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/ makes it sound like we can use Cloudflare in front of the site to provide a valid SSL certificate without costing us money. I haven't looked into this in depth yet, but would love for someone to look into this.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Set up cloudflare. After the ns settings take effect, traffic should go through them and we'll get a valid ssl cert for free.\nFixes #800. Seems to work!. I'm really bad at debugging stuff like this, so all I can offer is a bunch of links to source code.\nIn your stacktrace, I see the following line from diesel\n\n```\n7  0x0000555555627670 in diesel::pg::connection::raw::{{impl}}::drop (self=0x7fffffff92e0)\nat /home/skeleten/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-0.11.4/src/pg/connection/raw.rs:95\n```\n\nwhich is this code:\n\nrust\nunsafe { PQfinish(self.internal_connection) };\n\n(Of course the segfault is in unsafe code!)\nLooking further, it seems that this drop is called at the end of the user_seen function, when conn goes out of scope. It was called here. The connection comes from this function, which basically just calls diesel's PgConnection::establish(&db_url).. @DorianListens looks good. Can you add a change log entry real quick? I'll merge it this evening.. Thanks! You'll also need to bump the nightly version in the .travis.yml file.. That is weird! Can you push a new comment (maybe just edit/add a comment or something like that) to trigger travis again and see if it's just a caching problem?. Cool, thank's for that. Can you amend without that comment now? \ud83d\ude04 I'll merge it immediately.. Thanks again!. I think you need --no--default--features as well. See cargo install -h for\nmore info.\nEijebong notifications@github.com schrieb am Mi. 22. M\u00e4rz 2017 um 12:27:\n\ncargo install diesel_cli --features postgres,sqlite will allow you to\ncompile diesel_cli without mysql support\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/818#issuecomment-288370734,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX8X5uMmT8RewQESCqy5NIYTbCU6Fks5roQWUgaJpZM4MlCKy\n.\n. Oh, sorry! I didn't know that when setting up Cloudflare. I think I whitelisted Tor traffic now. Can you try again?. Yeah, if you can use >= 0.8, < 0.10, it will not be breaking change for our users :). No need to change the examples, just the library core crates.\nAm 24.03.2017 um 17:18 schrieb Eijebong notifications@github.com:\nI'll change it tonight. What about examples ? Should I loosen those dependencies too?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. @Eijebong CI failure seems legit. Thanks, CI seems happy, merging. Thanks!. Very cool! It's great to see someone working on this. I think @sgrif mentioned his frustration regarding missing big decimal support several times (I think he was close to writing an impl himself) \ud83d\ude04\n\nShould the num dependency be optional/a feature?\n\nYes please :). @theduke From @rubdos' checklist above I was assuming the bigdecimal release, but maybe that already happend (looking at https://crates.io/crates/bigdecimal)? I guess you could always have a look at https://github.com/akubera/bigdecimal-rs/issues :)\nRegarding the other unchecked points:\n\nOther databases; if someone wants to help here, feel free to file pull requests to my bigdecimal branch on my repo.\n\nI'm fine with landing this for postgres only right now.\n\nInitialize the damn digits vector to something senseful.\n\nDon't worry about that, it's really minor.\n\nDo we want FromSql<>/ToSql<> for f64/f32?\n\n@rubdos, can you elaborate a bit on the use cases? A ToSql impl makes it easy to insert stuff without needing a specific Rust type (just a literal 13.37 should work), so that may be nice. But from what I understand there will probably always be the possible of introducing some inaccuracy in any of these conversions, right?. Okay, this is green! Do you want to do anything more in this PR? I'm not totally up to date on what happened so far, but from the comments it looks like it might actually be good to land?. Thanks! I think we've iterated enough here, and we can always improve it in future PRs. Let's finally get this merged!. > What's the proper type I should put here? ordered_names: Vec ?\nLooks good.\nHave a look at https://github.com/diesel-rs/diesel/blob/master/CONTRIBUTING.md#setting-up-diesel-locally. To test doc changes, run cargo test --doc in the diesel directory.. Thanks again!. Thanks! Squashed and merged :). Alright! #837 is on master. So, the next question is: What needs to happen to make this easily usable?\n\n[x] Numeric \u2194 BigDecimal conversion\n[ ] Full query/insert example of table using Numeric and struct using BigDecimal\n[ ] Fix avg docs (and maybe look at other functions using Numeric)\n\nOpen points from #837:\n\n[ ] Do we want FromSql<>/ToSql<> for f64/f32?\n[ ] Support other databases; if someone wants to help here, feel free to file pull requests to my bigdecimal branch on my repo.\n\n(Do we want to make this a meta issue for all things Numeric? I can move the todo lists to the main issue descriptions. Also, feel free to add more points, or open new issues for parts of this!). FYI this works\ntoml\nlibsqlite3-sys = { version = \"=0.7.1\", optional = true }. Thanks, @jgallagher! This should fix this issue for now. Can you confirm this, @SergioBenitez?\nUpdating our dependency on libsqlite3-sys to a version >0.7 is a breaking change to diesel, especially as this is a system lib that can only be linked once. So, this will happen with the 0.13 release at the earliest.\nI'm not sure if what minimum version of sqlite we require, but 3.7.16 was release on 2013-03-18, so I'm pretty sure it's not a problem to require that. (We also have #829 open to add a bundled sqlite.). Dupe of #378, still very much a valid bug.\nDoes #[allow(missing_docs)] on the mod created by diesel help you.. > A nullable + a non nullable column will not compile though. Should I add a compile-test for that ?\nHm, that's not really a feature, though, is it?\nIs there anything that stands in the way of merging this? I didn't really follow the discussion that lead to the implementation, so I'm not sure which edge cases to look for. Maybe open an issue for (a discussion about) unlocking more possibilities with specialization?. Awesome! Thanks for sticking with this.\nThe diff looks pretty wild! Haven't read that much macro code in a while. I'll try to review it this evening. Maybe @Eijebong wants to have a look as well and play a round of \"human substitution machine\"? ;)\n@sgrif did we ever talk about this? You might also have some thoughts on this (and the syntax I suggested).. This compile fail test works:\n```rust\n[macro_use] extern crate diesel;\ntable! {\n    /// User's table\n    users {\n        /// A user's ID\n        id -> Integer,\n    }\n}\ntable! {\n    12\n    //~^ ERROR expected ident\n}\nfn main() {}\n```\nMaybe you can add this one with one more case for the explicit error thing you introduced. We can always add more tests later. (I'd add \"compile-success\" tests as more doc tests.). Okay, it seems compiletest is a bit fuzzy in what macro errors it finds or even looks for. This works for me:\n\none table! call per test\nexactly one \"error-pattern\" matcher below\n\nFor example:\n```rust\n[macro_use] extern crate diesel;\ntable! {\n     some wrong syntax\n}\n// error-pattern: invalid table! syntax\nfn main() {}\n```\nand \n```rust\n[macro_use] extern crate diesel;\ntable! {\n    12\n}\n// error-pattern: expected ident\nfn main() {}\n```\nAlso, I just remembered something: You macro syntax allows all attributes, not just doc ones. Is this on purpose? Do we want that?\n```rust\n[macro_use] extern crate diesel;\ntable! {\n     #[foobar]\n     posts {\n         id -> Integer,\n     }\n}\n// error-pattern: invalid table! syntax\nfn main() {}\n```\n(This fails with \"attribute foobar is currently unknown to the compiler\" by the way.). > This did not work for me.\nWeird. It worked locally, but I'm using a newer nightly than the clippy CI target. Will check again later.\n\nThis could be quite handy, because so you can also add things like #[allow(missing_docs)] to the generated code. (Maybe this should also be documented?)\n\nI'm not convinced we actually want that. It's not clear to the user where the attributes end up, and, more important, this macro should not be seen as something to generate Rust code (IMO), but as something that creates a mapping to \"the SQL side\".. Ah, thanks for the ping. So, from my side, nothing changed. Personally, I'd like to add this in a small, isolated increment. I.e, this PR should only allow doc comments in table! (and nothing else), with all the tests that come with that. I still don't think we should allow arbitrary attributes in this macro.\nBut this is just my opinion. What do you think, @Eijebong, @sgrif?\n@weiznich, can you easily restrict this to only allow doc comments or is that much work? I'll try to look at the compiletest and hope I can get it to work.. Just had a look at the compile tests. They work for me.\nJust like Travis, I'm running compiletest-rs 0.2.5 with\nrustc 1.18.0-nightly (63c77214c 2017-04-24)\nbinary: rustc\ncommit-hash: 63c77214c1d38789652b465694b254205d1886e0\ncommit-date: 2017-04-24\nhost: x86_64-apple-darwin\nrelease: 1.18.0-nightly\nLLVM version: 3.9\nChanging your second test to what I actually wrote above (with error-pattern) works:\n```rust\n[macro_use] extern crate diesel;\ntable! {\n     some wrong syntax\n}\n// error-pattern: invalid table! syntax\nfn main() {}\n```\nThe third one works as well with your latest changes and with this error matcher:\n```rust\n[macro_use] extern crate diesel;\ntable! {\n     #[foobar]\n     //~^ ERROR expected ident, found #\n     posts {\n         id -> Integer,\n     }\n}\nfn main() {}\n```\nOther than that, I still don't like the \"environment variable invalid table! syntax not defined\" message, and it's weird how big this PR is for this simple change. But, well\u2026. One thing we need to ensure here is that we can extend the macro later to allow renames (yes, we want to have something #424 after all).. Yep!\nAny concrete ideas what the documentation needs to cover that is currently missing? We want to add more guides (there is one PR to add a guide on updates), and any indicator what is needed the most would be helpful. :). Just as a heads up to others, @hobofan said he'd like to start a query builder guide, and @notryanb want to document model derives/traits.. \ud83c\udf89 . I'd call it #[diesel(skip_deserializing)] to be similar to serde. And we should probably only allow that for fields whose type implements Default.. > What I was searching is a way to totally ignore that field in the database. That means, Diesel to load (in that case) always None in the author field. For being able to add data after query to the struct.\nOh, yes, I think that's what I understood as well. I was suggesting \n\nan attribute name that would not collide with other crates,\n\nand to use the Default trait to figure out what the value of that field should be when diesel tries to deserialize into a User.\n(We could specialize this to Option<_>, but I'd rather not, as this is exactly what Default is for. Option<_>::default() == None, but also String::default() == \"\" and Vec::default() == vec![].)\n\n\nDid I get that right?\n\nis possible to have something like #[loads_has_many(authors)] to tell diesel to load all the authors in that field?\n\nCurrently, it's possible to get (User, Vec<Author>) but you'd have to write a bit of boilerplate to put that into a new struct. I can see why this is nice to have (and a lot of ORMs have this), but I'm not quite sure how it'd fit Diesel's design. This is usually the \"feature\" that leads to n+1 query bugs, and we currently try to stay away from mangling models with association data. So, I'd try to work with tuples (using type aliases liberally), and see how it goes.. Yes, add #[allow(unused)] to the mods here.. Thanks!\nI'm merging this right now without a lot of thinking about other possible lints that we could enable because this prevents most-likely-unnecessary warnings without the user activating any lints.. <2 should be good. If anything breaks, we'll just remind they serde developers ;). Looks good. Do you want to add a smaller unit test as well at the end of the pretty file?. There are literally no feature changes in clippy between 0.0.125 and 0.0.126. Did anything cool land in nightly since April 19?\nYou can always rustup overwrite add nightly-2017-04-19 in your diesel directory.. Laziness :) I'm fine with merging this as you already put the work in\nbasically but it's more fun to update clippy when there are new lints that\nhelp us :)\nDorian Scheidt notifications@github.com schrieb am Mi. 26. Apr. 2017 um\n18:36:\n\nSure, I could, but we'd need to make these changes eventually, wouldn't\nwe? Is there a reason to lag behind nightly?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/873#issuecomment-297469011, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX45g6zIjQjMFBbKi38rXJufOde0lks5rz3JzgaJpZM4NJD_O\n.\n. Seems better than before to me, but I have no idea what appveyor DownloadFile does under the hood. On the other hand, other repos use curl here as well, so it can't be that bad :D\n\nI'll merge this. Let's see if this reduces some of the spurious failures.. Off the top of my head, I'd say\n\n[x] integration tests (maybe just enabling/copying pg tests) that use a struct with a Date/Time/DateTime field (i think you need expression_impls! and queryable_impls! at least)\n[x] roundtrip tests\n[x] mention the sqlite impl (and maybe also caveats of it) in the docs, e.g. in diesel::types::Date\n[x] changelog entry\n\n(feel free to copy this list). Ah, yeah, that was the change I was thinking of. I'll merge this then!. Did you test this code locally? Can we (easily) make this a non-ignore test?. Thanks!\nCurrently blows up on MySQL though :( \"You have an error in your SQL syntax\". Not it failes due to compiletest_rs stuff. Not even sure why that runs on the clippy target :/ I'll have a look later what's up with that. Nah, that's not the real problem. The nightly targets will work again tomorrow. What I'm wondering is why the clippy target runs compile test. It shouldn't do that.. Disable the compile test stuff for the clippy target. Can you rebase on master? And feel free to merge when CI is green!. Thanks!. Thanks. Let's add docs for (i)like in another PR and merge this as-is.. \n. Nice. I'd put stuff like this in Readme files somewhere in src/, but this is good as well.. I would expect parsing the data coming out of the database would be the most interesting.\nBe warned, though. You'll probably have to do a whole bunch of freaky things to get access to these function in a way you can fuzz them. I was originally thinking stuff like #[path=\"../../diesel/pg/lorem/ipsum.rs\"] mod ipsum; in the fuzzer script but I'm not sure if that'd work well.\n\nAm 23.05.2017 um 20:57 schrieb Cyryl P\u0142otnicki notifications@github.com:\nHey ! Any particular areas you would like to see fuzzed first ? data coming from the database connection ? user-supplied queries ? something entirely different ? I can try taking a look into hooking up cargo-fuzz in some nearish future I think.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Thank you for giving it a try :) Feel free to drop into gitter if you get stuck, I'm sure we can figure out how to get this working.\n@Eijebong, sure, but types roundtrips usually only test valid data. Fuzzing makes sure we don't explode when we get invalid data :)\n\nAm 23.05.2017 um 21:05 schrieb Cyryl P\u0142otnicki notifications@github.com:\nNo worries, I consider myself warned now :) If I get to work on this in some time and get stuck - will definitely describe what I did and what worked and what not. thanks a lot !\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. \ud83d\udc4d . > does let where_clause = box if {... look less weird to you?\nA bit less weird, yeah. But I'm weird myself because if x { 1 } else { 2 }.boxed() looks fine to me \ud83d\ude04. Okay, let's merge this and refine later if someone gets around to it :). No, it's fine :). We talked a bit about this yesterday and my idea was to to make this a bit easier to read by using an empty table as a starting point and adding one row and then one per transaction.\nBut if that is too much work, I'm fine with merging this as-is. We can always refine this later.. More links are more good.. Thanks!. I have experience in dealing with appveyor or sqlite on windows, but this looks good\u2026 and green! So, \ud83d\udc4d from me. Anyone else want to have a look? @sgrif?. Thanks!\nFrom a cursory look it seems that hwaddr is not a well-established crate, it just has a few downloads and no crates that depend on it. I'd rather we not add it as a dependency right now and go with [u8; 6] for now.\nAnother thing, can you maybe add a longer doc test that shows how all the Postgres network types can be used? If you can't get it work right away or find a similar doc test, we can always do it later.. Do you want to add a test for this? Otherwise this looks good to get merged.. Oh, I thought that'd end up as part of the compile error in compile test (when provoking a compile error). But, you could of course call this as a subcommand and\u2026 nope, not worth it ;). Thanks. Can you provide a bit more information what this \"SQLITE_BUSY situation\" is and how this solves it? :)\n\nAm 02.06.2017 um 11:08 schrieb wangcong notifications@github.com:\nsimilar to:\njgallagher/rusqlite@05b03ae\nthis should reduce SQLITE_BUSY situation\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/diesel-rs/diesel/pull/929\nCommit Summary\n\u2022 Set default busy timeout to 5 seconds\nFile Changes\n\u2022 M diesel/Cargo.toml (1)\n  \u2022 M diesel/src/lib.rs (2)\n  \u2022 M diesel/src/sqlite/connection/raw.rs (16)\nPatch Links:\n\u2022 https://github.com/diesel-rs/diesel/pull/929.patch\n  \u2022 https://github.com/diesel-rs/diesel/pull/929.diff\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. ## Musings on how to implement this\nWe could use quick-error, a macro crate that will reduce much of the overhead our error code currently has. This will also make it feasible to add more specialized error variants to parts of diesel.\nBut why stop with syntactic? The error_chain crate is quick-error on steroids and has become sort of a standard for many. It offers a lot of what we want, incl. nice macros for generating error types and early returns, converting strings to errors ad-hoc (nice for development), and backtraces (when RUST_BACKTRACE is set). It exposes the ErrorKind enum as a public field, though, which allows chaining errors, but also makes it a breaking change to add variants if the error type is public.\nA way around that might be to write an opaque error type ourselves that implements Error but little else, and use error-chain internally. I'm not sure how much overhead that introduces when dealing with an error, but the opaque struct could be pointer-sized (struct Error(Box<InternalError>)). We might need to add a method to construct diesel errors from external crates, but I guess that is no big deal.. This might also be a good chance to refactor our code style to return errors: error-chain has two nice macros, bail!(\"foo\") (return error) and ensure!(x < 42, \"foo\") (assert! that returns error instead of panicking) that we might want to make use of (or copy).. Update: Seems like people are actively working on #[non_exhaustive]: https://github.com/rust-lang/rust/issues/44109. Awesome, thanks!. I'll merge this. I was gonna suggest mentioning it in the change log, but #948 will already do that.. Thanks for the latest patches. Let's get this merged!. I was this close to merging this\u2026 but you need to rebase since the only other merge recently broke this \ud83d\ude05. r? @weiznich . ~~Ah, well, restricting the macro to doc comments disallows #[doc] attributes. I'll work on that.~~ Actually, I'm just pretty bad at writing [replace] sections.. > The macro is able to parse this\nYes, my bad. I wasn't able to parse my own Cargo.toml content ;)\n\nThere are some tests are failing. (diesel_cli::print_schema).\n\nYep, I'll try to make the codegen produce nice doc comments (instead of the attributes).\n@dtolnay, is there a way to write a quote! call that results in something like /// foo bar? (Incl. substitutions)\nTo get nice output when showing the generated code (we do that in the diesel print-schema CLI tool), I would like to write something like\nrust\nquote!(table! {\n    /// Representation of the `#table_path` table\n    ///\n    /// (Generated by Diesel's `infer_schema!` macro.)\n    #table_path (#(#primary_keys),*) {\n        #(#tokens),*,\n    }\n})\nbut the #table_path isn't substituted. (It doesn't have to be exactly this code, just something that results in the doc comment.)\nOtherwise, we'll have to expand our pretty printing (no big deal, but would be nice to not have to do this ;)).. Over lunch, I managed to get it this far:\nrust\ntable! {\n    /// Representation of the `balances` table.\n ///\n /// (Generated by Diesel's `infer_schema!` macro.)\n balances (id) {\n        /// The `id` column of the `balances` table.\n ///\n /// Its SQL type is `Integer`.\n ///\n /// (Generated by Diesel's `infer_schema!` macro.)\n id -> Integer,\n        /// The `created_at` column of the `balances` table.\n ///\n /// Its SQL type is `Text`.\n ///\n /// (Generated by Diesel's `infer_schema!` macro.)\n created_at -> Text,\n \u2026\n    }\n}\nSo, 'only' some minor indentation adjustments to the pretty printer (and test fixes) left to do!\n@weiznich (and everyone else!), I'll probably not get around to this before tomorrow evening. As you wrote most of the pretty printer, feel free to chime in on this PR :)\nAlso unpinging @dtolnay, I managed to work out how to do it (there might still be a better way).\n. Rebased and fixed recursion limit fun (see last commit).\nr?. Good idea, @Eijebong. Shouldn't be too hard, just a matter of passing one more flag down to the expand fns. Do you think we should do that here or in a follow-up PR?. Okay, then let's do is in another PR, this one's already large enough.\nr? @sgrif. I don't mind rebasing this, it's probably easier than updating #1080\nSean Griffin notifications@github.com schrieb am Mo. 7. Aug. 2017 um\n18:33:\n\nShould this wait until after #1080\nhttps://github.com/diesel-rs/diesel/pull/1080 ?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/957#issuecomment-320713715, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXwgKINRXc_YnSrSOeq_WKuCJW4fqks5sVzxdgaJpZM4N9_eU\n.\n. Okay, ~~rebased~~ rewritten on top of #1080. This now also fixes/refactors some related parts of the code. Let's see what CI says! (My local mysql setup has apparently gone up in flames during a recent update.). Thanks for the review. Will merge this and then begin a PR to make the comment optional in the CLI output. cc https://github.com/rust-lang-nursery/rustfmt/issues/1739. @PlasmaPower thanks, I totally missed that!\n\nIdeally, I want to have a larger discussion about how to design our macros in general, but that is not a pressing matter right now. sql_function! specifically does not seem like one that is usually written over multiple lines, though. @Eijebong, was this just triggered by the rustfmt bug? I'm fine with adding this, but I don't really want to stabilize/guarantee that this macro parses \u22651 trailing comma.. I've opened #977 to get a general discussion going. I'm going to close this for now, but depending on what we decide, we can reopen and merge this in the future.. Nice, saw the chrono 0.4 announcement earlier and thought we should bump the dep in diesel asap :)\nShould we enable chrono's serde feature when our serde feature is enabled? Can we?. Thanks! Let's talk a bit more about the use case of this. I think I was a bit quick to suggest this.\nCurrently, we can convert to/from serde_json::Value and chrono::DateTime. Can the two ever interact in a way that the user can omit chrono's serde feature in their own Cargo.toml? I don't think so. This would mean automatically activating this would be superfluous in some cases, and may actually be confusing in others (features are additive and diesel silently activating this may be confusing in a \"why does this even work?\" way).\nVery interested in your opinions!. > This PR was largely a \"oh, huh, that does work\" situation.\nAnd that's totally fine \ud83d\ude04 \n\nIt would mostly just enable the #[derive...] calls for upstream, but if users are using chrono then they probably should just enable the feature themselves.\n\nYeah I too think that's the only thing happening with the PR. And user's should do that explicitly.\nI'll close this PR for now, but feel free to ping me/reopen when you can think of another reason to have this :). Indeed. Resolved by sgrif/diesel.rs-website#29.. Thanks!\n@juliusdelta, just a heads up: You mentioned you were interested in doing #939 yourself. Since this is a small change, I'll merge this and close the issue. If you want to help out in another way, we'd be delighted! Have a look at our open issues and/or drop by on gitter if you have any questions or just want to chat :). Yes, this is something we want to allow. There is a previous discussion (probably outdated a bit by now) in #424.\n@Fiedzia do you have a concrete suggestion for the syntax to rename columns in table!?. Also interesting: Column names that collide with type names that are in scope: #1018. Very nice issue description! (We should steal this and make it a template!)\nI think your problem stems from chrono recently yanking its 0.3.1 version and releasing 0.4 with serde 1.0 support instead (this was a breaking change in 0.3.1!). Diesel 0.13.0 does not support chrono 0.4. Which means two versions of chrono will be built, and they are not compatible to each other.\nCan you try using diesel master instead?\ntoml\ndiesel = { git = \"https://github.com/diesel-rs/diesel\", features = [\"postgres\", \"chrono\"] }. > I've been going round in circles with this, but if it isn't actually a Diesel issue then I apologise in advance. Thanks for all the work on Diesel, it's excellent! :)\nThanks :) If it turns out this is a problem with two chrono versions, you can use cargo-tree to see this more easily.. > Thanks! I can't take credit for it though, I just filled in the details you ask for :)\nlol \ud83d\ude05. Does cargo tree give you two diesel versions? I'd assume so, because r2d2-diesel uses the latest diesel, not its master branch.\nMaybe a better way to get this going is to not specify diesel master, but 0.13.0 and adding\n[replace]\n\"diesel:0.13.0\" = { git = \"https://github.com/diesel-rs/diesel\" }\nThis replace every occurrence of diesel 0.13 in your dependency graph. (You might need to add the same lines for tje other diesel-* crates.). Thank you! I'm glad this works for you. With the next release of Diesel, 0.14, you should only need to increment the diesel and r2d2 version, remove the [replace], and it should all just work\u2122 :). @vityafx these look like serde issues\u2014most likely because you are using serde 0.9 and chrono requires 1.0.. Rocket 0.3 will include it: https://github.com/SergioBenitez/Rocket/issues/273#issuecomment-301339550\nMaybe you can use rocket's master branch until then?. I actually just rediscovered we already have that written down: https://github.com/diesel-rs/diesel/blob/f7bb506ffc62ec72aafe60d7909d3614e3ff5376/CONTRIBUTING.md#submitting-bug-reports\n(And guess who with their shitty memory wrote all that? xD). Good changes. Let's merge this, then!. Thanks, @adwhit!. Hi, thanks for detailed issue!\nI just reproduced this locally and your email field is nullable, i.e., it is inferred to be a Nullable<Varchar>. There is no like method defined for that type.\nNot sure if that is a SQLite thing or if the impl is just missing from Diesel, though.\n\nAm 29.06.2017 um 12:51 schrieb Luke Chen Shui notifications@github.com:\nSetup\nVersions\n\u2022 Rust:1.20.0-nightly\n  \u2022 Diesel:0.13.0\n  \u2022 Database:sqlite\n  \u2022 Operating System: Ubuntu x86_64 GNU/Linux\nFeature Flags\n\u2022 diesel:sqlite\n  \u2022 diesel_codegen:sqlite\nProblem Description\nBasically, it seems my program won't compile because the .like() method cannot be found on one of my table columns\nWhat are you trying to accomplish?\nTo delete a user from my sqlite database using his email.\nWhat is the expected output?\nThe program should compile\nWhat is the actual output?\nerror[E0599]: no method named like found for type schema::__diesel_infer_schema::infer_users::users::columns::email in the current scope\n--> src/database.rs:41:39\n|\n41 |     diesel::delete(users.filter(email.like(pattern)))\n|                                       ^^^^\n|\n= note: the method like exists but the following trait bounds were not satisfied:\n        &mut schema::__diesel_infer_schema::infer_users::users::columns::email : diesel::Expression\n= help: items from traits can only be used if the trait is implemented and in scope\n= note: the following trait defines an item like, perhaps you need to implement it:\n        candidate #1: diesel::TextExpressionMethods\nerror: aborting due to previous error(s)\nSteps to reproduce\nup.sql:\n-- Your SQL goes here\nCREATE TABLE users (\n  id INTEGER PRIMARY KEY,\n  name VARCHAR,\n  email VARCHAR UNIQUE,\n  password VARCHAR\n)\nmodels.rs:\nuse super::schema::users;\n[derive(Queryable)]\npub struct User {\n    pub id: i32,\n    pub name: String,\n    pub email: String,\n    pub password: String,\n}\n[derive(Queryable, Insertable, Debug, Associations)]\n[table_name = \"users\"]\npub struct NewUser<'a> {\n    pub name: &'a str,\n    pub email: &'a str,\n    pub password: &'a str\n}\ndatabase.rs:\nextern crate diesel;\nuse diesel::sqlite::SqliteConnection;\nuse diesel::prelude::;\nuse models::NewUser;\nuse std::error::Error;\nuse super::;\npub fn establish_connection() -> SqliteConnection {\nlet database_url = \"potara.db\";\nSqliteConnection::establish(&database_url)\n    .expect(&format!(\"Error connecting to {}\", database_url))\n\n}\npub fn create_user(name: &str, email: &str, password:&str) -> Option {\n    use schema::users;\nlet connection = establish_connection();\n\nlet new_user = NewUser {\n    name: name,\n    email: email,\n    password: password\n};\n\nmatch diesel::insert(&new_user)\n    .into(users::table)\n    .execute(&connection){\n        Ok(num) => {\n            Some(num)\n        }\n        Err(error) => {\n            None\n        }\n    }\n\n}\npub fn delete_user(email_target:String) -> usize{\n    use schema::users::dsl::*;\n    let connection = establish_connection();\n    let pattern = format!(\"%{}%\", email_target);\n    diesel::delete(users.filter(email.like(pattern)))\n        .execute(&connection)\n        .expect(\"lol\")\n    // match \n    //     .execute(&connection){\n    //     Ok(num) => {\n    //         Some(num)\n    //     }\n    //     Err(error) => {\n    //         None\n    //     }\n    // } \n}\nmain.rs:\n![feature(plugin)]\n![plugin(rocket_codegen)]\n![plugin(maud_macros)]\n[macro_use]\nextern crate serde_derive;\nextern crate toml;\nextern crate rocket;\nextern crate mime_guess;\nextern crate maud;\n[macro_use]\nextern crate diesel;\n[macro_use]\nextern crate diesel_codegen;\nextern crate dotenv;\nmod schema;\nmod models;\nmod utilities;\nmod pipeline_config;\nmod assets;\nmod template;\nmod router;\nmod database;\nfn main() {\n    router::init();\n}\nschema.rs:\ninfer_schema!(\"dotenv:DATABASE_URL\");\nChecklist\n\u2022 [*] I have already looked over the issue tracker for similar issues.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Cool! So, you were able to make the column NOT NULL?\nWe might want to have a nicer/documented solution for that, but we can create a new issue for that.. Do we have tests for any of these impls?. Okay, we can add more later if necessary.. Seems like a good idea in general, even if it's just to show people what nightly we run on CI for clippy.\nWe need to make sure to update both this and travis.yml at the same time in the future, though.. > \ud83d\udc1c\ud83d\udc1b\ud83d\udc1e\ud83d\udd77\nsuch resilient\nvery flow\nmuch working\n\nAm 28.07.2017 um 15:57 schrieb Carol (Nichols || Goulding) notifications@github.com:\nworkflow cockroach\nwait wut\n\ud83d\udc1c\ud83d\udc1b\ud83d\udc1e\ud83d\udd77\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Just talked to @skade who's now searched for and found the cargo install diesel-cli --no-default-features --features \"postgres\" incantation three times. I was about to open an issue to add some info on diesel-cli's feature flags to its Readme file, but it turns out they are just to enable backends (or clippy) and this issue here will make these docs useless anyway.. > The citext module provides a case-insensitive character string type, citext. Essentially, it internally calls lower when comparing values. Otherwise, it behaves almost exactly like text.\n\nhttps://www.postgresql.org/docs/9.6/static/citext.html. @sgrif are you good with merging this? I'd probably want to add a test for inferring all these types, but I think that's not that easy right now.. Thanks again!. If you User struct only has the id field, do you even need the .select? Or was this just as an example? IIRC we always enumerate all the columns we want to query, so it's never select *. Thus, another workaround would be to write a SlimUser struct :). I don't think this is easily possible right now\u2014you'd need to implement a bunch of traits, like ToSql and FromSql, cf. this test.\n\nIt'd be possible to write derive macro that makes common newtype case (for wrappers of primitive sql types) a bit more elegant by generating the implementations for you.. Oh yes, I meant as an external proc-macro crate.\n(This might copy a bunch of code from the diesel-internal implementations of primitive SQL types, though.)\n\nAm 10.07.2017 um 17:53 schrieb Sean Griffin notifications@github.com:\nI think that would be a strong candidate for something that should best live as a third party crate, not as part of Diesel itself. However, I'm happy to assist someone in implementing such a crate.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Good catch, thanks!. Interesting case, and one I haven't seen in production so far! We've seen many column names that are also Rust keywords (like type), but a collision because the column name is also type name is a new one!\nI'm fairly certain we know the right solution for this, though: Allowing you to rename the columns on the Rust side. This is tracked by #967.\nI hope it's okay for me to close this issue (to continue discussion in #967); if not, or if I missed something, just let me know. :). cc @rubdos who added BigDecimal support for Postgres. @Fiedzia CI fails with\nerror[E0119]: conflicting implementations of trait `query_builder::query_id::QueryId` for type `types::Numeric`:\n   --> /home/travis/build/diesel-rs/diesel/diesel/src/types/impls/mod.rs:160:9\nCan you have a look at this?. I finally came around to it, @llogiq! :). Is this documented explicitly in the dsl docs? (I'll check and add if not.)\nThe solution to this using UFCS in the code generated by the proc macro. It\nmay be a good idea to this regardless, but I'll need to think about that\nsome more :)\nSean Griffin notifications@github.com schrieb am Fr. 21. Juli 2017 um\n13:28:\n\nThis is the expected behavior. The module needs to be in scope. You\ngenerally shouldn't import stuff from dsl outside of functions\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1032#issuecomment-316977434,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX_Sy_hod6PlE-MSO83Tkjuve0A9-ks5sQIt0gaJpZM4OfHtf\n.\n. Thanks! Just a quick heads up: If you think this fixes #1000, add \"Fixes #1000\" to the commit message. This way, Github will automatically close the issue when this gets merged.. Yeah, seems like this lint should trigger, but I don't know the specifics.\n\nI think the original idea was to either use BoxedDsl or impl Trait. Where would you want this to be documented?. Yes, sorry, that was a bit short. I only wanted to add some links to people finding this issue in the future had some more context. :)\nI don't think we can easily fix this right now, as the types are part of the API we don't want to stabilize without carefully thinking about and discussing it. But\u2014I also did only think about this for a minute right now. What would you do? And, do you think we should document BoxedDsl somewhere prominently as a workaround?. @lancecarlson sounds good!. Thanks! That looks like a lot of features!\nIt's also a huge amount of code, though\u2026 I'll try my best to find some time to play around with it. One single commit adding 472 lines is not quick to read through \ud83d\ude05 I personally love to read big additions like these in multiple commits that build on each other and whose commit messages tell me the indent of each change.\nIIRC, @sgrif mentioned in an earlier discussion about enum inference that he'd like to try to have this in (an) external crate(s). Maybe he can chime to supply his original arguments before I quote him wrong :). @weiznich, do you think this is do-able as an add-on?. Thanks!. Oh, @sgrif, that CI failure looks noteworthy:\n\nassertion failed: (left == right) (left: \"SELECT \\\"users\\\".\\\"id\\\", \\\"users\\\".\\\"n\\\" FROM \\\"users\\\" WHERE \\\"users\\\".\\\"n\\\" = $1 -- binds: [1]\", right: \"SELECT \\\"users\\\".\\\"id\\\", \\\"users\\\".\\\"n\\\" FROM \\\"users\\\" WHERE \\\\\\n        \\\"users\\\".\\\"n\\\" = ? -- binds: [1]\")\n\n\nEscaping\n$1 vs. ?\n\n(This is Postgres 9.5 on Windows.). We discussed the possibility of doing this on Gitter.. Re: @sgrif's concerns\n\nWe need to write more tests for this derive\n\u2192 please open new PRs for that -- tests for this can land right now\nIdeally, we should also have a test suite explicitly for derive macros. Not sure how much precedence there is aside from compile-test.\nWe need to document the codegen crate. This is already true and becomes more important with each line of code we add to it.\nCan rustdoc be used with proc-macro crates? I haven't tested this in a while.\nWe can already document this in Readmes and guides, and link to them from the diesel main rustdoc page.\n\u2192 Let's write more docs! (As always ;))\n(This doesn't add build/release issues AFAIK, those already exist.)\nI think this does service Diesel developers, because one can argue it makes the code base easier to contribute to. I'm not sure which of the tow, proc-macros or macro_rules, are harder to write, but currently you need to concern yourself with both. This removes the need to deal with this macro_rules macro in this specific area.\n. @sgrif wasn't there the concern of this being a breaking change? Can we\navoid this somehow by hiding certain items?\n\nSean Griffin notifications@github.com schrieb am So. 27. Aug. 2017 um\n12:19:\n\n@weiznich https://github.com/weiznich If it's ok with you, I'd like to\ndefer this change until after 1.0. We're not planning on doing another\nrelease until 1.0, and I'd really like to avoid rewriting a major part\nof the framework in that release.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1055#issuecomment-325189635,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX50AsC0oMkBHkzfyp2FMT8v6Oz8Mks5scULHgaJpZM4OpgdG\n.\n. @weiznich I meant #[doc(hidden)], so it's not perceived as part of the public API. This is, while certainly not ideal, good enough for now; and we already do that in some other places.. Also FYI, I have no problem releasing Diesel 2.0 the day general proc-macros become stable. I don't care about the numbers in version numbers as long as the breakage for our users is manageable (say, less than 15min of work for a codebase that casually uses diesel).. Sorry to derail the discussion, that was not my intention!\nPorting the custom derives only need macros 1.1.\n\nSure, but replacing/refactoring all macros (incl. table!) would be much more\u2026 whole step. One that could potentially allow some other features, like better error reporting for examples.\n\nOne could use this argument also to justify to release version 0.17 before going to 1.0 (just saying)\n\nThat argument, sure. But there is also another one for 1.0, which is: It's about focussing on the last remaining features and getting this project ready for prime time. Which is a huge step, and one I'm both excited and cautious about. :)\n. Thanks! Didn't know we still had that in there \ud83d\ude05\nI don't think the Readme needs to contain the history, though. Can you maybe reduce it down to something like this?\n\nIt depends on features introduced in Rust 1.15. Make sure to always use the latest stable release for optimal performance and feature support.. Thanks. It's not really a matter of Rust or Diesel, it's more my personal opinion that the Readme only needs to describe what is currently true :)\n\nIn general, Rust developers tend to update their compiler version quite often, as there are stable releases every 6 weeks and you only need rustup update to get the latest version. This makes describing the behavior of older compiler versions less important.. Actually, since this is such a small change, I'll just go ahead and do it so you don't have to mess around with adding a commit to that branch (from the \"patch-1\" name I guessed you used Github's interface). Hope you don't mind.\nThanks again :). @Eijebong did I resolve the conflicts correctly? Feel free to merge (or rebase for cleaner history). Thanks!\nI fear this will fail CI with must_use errors, though. Let's add insert some data and assert the results.. > There is an #![allow(unused_must_use)] at the top of the file to prevent this errors.\nLol, I apparently can't read. \u2026And I've just been drinking tea today before anyone asks! \ud83d\ude05. We can configure this in Cloudflare. I think it's already using the\n\"opportunistic SSL\" stuff of http2.\nBastien Orivel notifications@github.com schrieb am Sa. 5. Aug. 2017 um\n12:32:\n\nI think the problem is that github pages don't allow you to force https if\nyou're using a custom domain (which of course we are).\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1073#issuecomment-320436172,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX1IYBENsT2QzLwJLihwIdItlsOHnks5sVETGgaJpZM4OuaHP\n.\n. Just had a look and we are using\nOpportunistic Encryption\nOpportunistic Encryption allows browsers to benefit from the improved performance of HTTP/2 and SPDY by letting them know that your site is available over an encrypted connection. Browsers will continue to show \"http\" in the address bar, not \"https\".\n\nbut not\n\nAlways use HTTPS\nRedirect all requests with scheme \"http\" to \"https\". This applies to all http requests to the zone.. @sgrif the only external resources are code.jquery.com and Google Fonts, both are already using HTTPS.\n\nThe intra-site links seem to assume HTTP, i.e., https://diesel.rs links to http://diesel.rs/guides/. Not sure why. Also, there's a typo in the \"canonicical\" meta tag here.\ntl;dr I think we can just enable \"Always use HTTPS\".. Not sure why but this breaks some print_schema tests. Is this already fixed by #1081?. Sweet! Will review shortly\ncc #967 #342. This seems like a good idea, but I'm not sure how actionable that is for Diesel?\nYour 3 steps can be implemented in application code, right? I guess we could in theory offer helpers for that, but those might also work as an external crate.\nOr, asked in another way: What needs to change to make this easier/possible?. I have not thought about it long enough to give a qualified answer, but\u2026\nQuick thought: How about having a view for each table version? Like, \nsql\nCREATE VIEW baskets_v1 AS\n    SELECT *\n    FROM baskets\n    WHERE version = 1;\nand putting that in a\nrust\nmod schema {\n    mod v1 {\n        table! { baskets\u2026 }\n    }\n}\nAt least in postgres, simple views like this allow INSERT/UPDATE/\u2026\n\nThe migration infrastructure provided by diesel is not extensible in a way that would allow including data migrations.\n\nHuh? We allow arbitrary SQL? With embed_migrations! you can include the migration process in your app.. Thanks for the report! Seems like this is just a small missing piece. And @Eijebong already opened #1090 to fix it :). Thanks for the report! Let's try to get to the bottom of this!\nThis is the (at least) second bug found in our implementation of BigDecimal/interaction with the bigdecimal crate. Maybe it's a good idea to add a fuzzer for the roundtrip through bigdecimal, diesel, an postgres? (cc #907)\ncc @rubdos . @Eijebong we already have #907. I'm not sure we need another but, but this is a concrete proposal, not an abstract idea\u2026 do whatever you think feels right :). Yes please! I'm not sure I'd put all that in the Getting Started guide, though. Maybe add a new document about all the feature toggles Diesel has? The 3 backends are the relevant ones for the CLI, and a good start; but the same document could also talk about the features you need to enable in diesel (and diesel-codegen) to get DateTime, JSON, etc. support.. Eventually, we should cover every platform our users use. :) But we can absolutely start out with just Mac and Debian, for example!\n\nAm 14.08.2017 um 00:08 schrieb katrinabrock notifications@github.com:\nFor a guide to installing dependencies, do we need to cover windows or just Mac and common Linux flavors?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. This LGTM, but\nr? @Eijebong . Thanks!\n~~We should probably add a test for this as well, but can do so in a follow-up PR~~ Forget I said anything, it's all good. Sounds good. What other ORMs do this and can we learn from their API design?. Thanks again for working on this! What would you like to do next? :). Oh, good catch! Maybe we can set up another travis matrix entry to just build the examples\u2014this way we ensure that the diesel crates can be build (as dependencies) but can use newer features in the test code. (I'm specifically thinking about some pending changes to how include! works doc tests.). I've been thinking about this for a bit (basically since seeing your tweet), but don't have a definitive answer. Here are some arguments that come to mind:\n\nApplications written in Jan 2018 that have diesel = \"1\" in them will break if we release 1.1 that uses features added in Rust 1.25 unless the user also happens to update their compiler. So it is a breaking change.\nImportant crates like regex treat requiring a new compiler version as breaking change (cf. https://github.com/rust-lang/regex/pull/209)\nOther important crates, like futures, bump the min rust version in a minor (here 0.1.x) version (cf. 0.1.15)\nRust Epochs will happen, maybe even LTS releases.\nThe unwillingness to release Diesel 2.0 in half a year is most likely only a psychological barrier\n\nA pragmatic solution would be to trail a few month behind the latest compiler version. This probably won't help all the people who are using a Linux distro's Rust compiler version, but might cover a signification enough number cases.. cc rust-lang/rust#43782 for great cross-linking fun. We talked about this in the dev tools meeting today, the Rust PR is nominated for beta now. Explicit is better than ~~implicit~~ warnings \ud83d\ude06. I haven't heard of any plans. But this seems interesting! Are there any sqlite bindings/crates that support this? What is the expected API for this?. Good. These are just the bindings, though. Looking a bit further, I found that the rusqlite crate supports this with a semi-nice API:\nrust\ndb.create_scalar_function(\"halve\", 1, true, |ctx| {\n    let value = try!(ctx.get::<f64>(0));\n    Ok(value / 2f64)\n}) \nhttps://github.com/jgallagher/rusqlite/blob/d5bd7d960106477f4372ebf7c0ec0c0b479e17bd/src/functions.rs#L281-L310\nThis lives as long as the connection, which shouldn't be a problem when using SQLite.. My first attempt would be to add a crate_scalar_function method to SqliteConnection and see if you can make this work. It needs to live there because it needs to access the raw connection. Its content would probably be the same as this.\nThen, I'd try to make the API nice, e.g., \nrust\ncreate_function(diesel::sqlite::ScalarFunction::new(\"halve\").deterministic(true).args(1).function(|ctx| \u2026))\n(A builder is much more forward-compatible and easier to use than a method that takes a bunch of parameters IMHO.)\nAfter that, it might be nice to reduce the boilerplate. As you noted, we have a sql_function! macro. Maybe we can add a sqlite_function! macro? Something like\nrust\nsqlite_function!(halve, (value: f64) -> SqliteFnResult<f64> {\n    Ok(value / 2f64)\n});\nthat generates something that allows you to connection.create_function(halve::as_sqlite_fn()) as well as use it in queries like numbers.filter(halve(value).eq(2));. @Boscop, do you want to work on this?\nThinking about this some more, if we were to add a method that exposes the raw sqlite connection (i.e., an unsafe pointer), this could all live in an external crate. I'm not sure we really want to do that though. Maybe as part of an extra feature (\"for-diesel-extension\" or something like that)?\n\nI'm planning to use it to impl fuzzy string comparison / search.\n\nHave you seen/tried SQLite's built-in full text search? https://sqlite.org/fts5.html. Good, didn't want you to spend time writing a fuzzy search only to discover\nFTS afterwards :)\nYes, we don't support FTS currently. You should be able to add it in an\nexternal crate though.\nBoscop notifications@github.com schrieb am Do. 17. Aug. 2017 um 08:48:\n\nI'm aware of FTS but it doesn't really support the kind of fuzzy matching\nI need and it looks like diesel doesn't support FTS's MATCH expression or\nam I missing something?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1103#issuecomment-322983902,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXzkl4vlPTlObvnIfwxIDBsdVIb7lks5sY-IngaJpZM4O3JEi\n.\n. @Boscop sorry, I thought https://github.com/diesel-rs/diesel/issues/1103#issuecomment-322731710 answered that already. Yes, that is exactly how I'd try to do that. But I haven't experimented with this at all, so unless someone else has any ideas, you'll just have to try and see what issues you might run into. Start with a small POC and we can have a look and help you out :). @maghoff sure! I've never done anything with libsqlite3 directly, but I'll try to help :). @maghoff Happy new year! That looks like a good start! It also seems to be quite self-contained, right? Could this work as a separate crate that uses an extension crate to SqliteConnection?. > I need access to internal_connection in RawConnection from the raw_connection field of SqliteConnection.\n\nAh damn, I missed that one. Okay, I don't think we want to expose that right now.\nThis is looking pretty good. I'd probably not want to land this create_scalar_function fn as public API (it's too easy to mess up the usage), but do you want to open a WIP pull request? We can easier discuss the implementation there :). Sure! Probably depends on whether you think it makes sense to review as-is or if you expect to change a lot of stuff around anyway.. Thanks!. If the tables have the exact same columns, you could try\nrust\ndiesel::insert(table1::table.select(table1::all_columns)).into(table2::table). Indeed! Thanks again for that awesome PR!. Thanks for reporting! The PR that added this was #1094. Maybe you have an idea how to fix this?\n(Looks like we are also missing a test case for nullable date time types.). No worries! I'll make sure this is fixed before we release a new version with this change.\n\nAm 16.08.2017 um 21:56 schrieb estelendur notifications@github.com:\nI'm sorry, I'm very new to Rust and don't have the first idea how to fix it.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. First, I don't think we should try to infer virtual tables by default (just like we don't infer views). Does it work if you use table! (with an id column of your choosing)?\nSecond, we have no support for MATCH, but you should be able to get it to work with diesel_infix_operator!.. Thanks!. Hey, sorry for the lack of feedback here! I'm at a conference currently,\nbut maybe @Eijebong or @sgrif can have a look?\nViele Gr\u00fc\u00dfe,\nPascal\nOn Fri, Aug 18, 2017 at 11:25 PM, Alex notifications@github.com wrote:\n\nAdded posibility to setup connection with databases, which requires some\nextra arguments in URL\nFor example:\npostgresql://postgres@localhost:5432/diesel_example?ssl=true\n\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/diesel-rs/diesel/pull/1118\nCommit Summary\n\nadded possibility to provide arguments to database URL\n\nFile Changes\n\nM diesel_cli/src/database.rs\n   https://github.com/diesel-rs/diesel/pull/1118/files#diff-0 (22)\nM diesel_cli/tests/support/mysql_database.rs\n   https://github.com/diesel-rs/diesel/pull/1118/files#diff-1 (11)\nM diesel_cli/tests/support/postgres_database.rs\n   https://github.com/diesel-rs/diesel/pull/1118/files#diff-2 (11)\n\nPatch Links:\n\nhttps://github.com/diesel-rs/diesel/pull/1118.patch\nhttps://github.com/diesel-rs/diesel/pull/1118.diff\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1118, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX1v1W-RHexHdCAnWhRwHMUVPsR6aks5sZgFfgaJpZM4O8D7r\n.\n. Thanks for the report! The error you quoted comes from this function:\n\nhttps://github.com/diesel-rs/diesel/blob/bb6a35be3b8e3a4e1665f6fa93f93d1f44f7b06b/diesel/src/sqlite/connection/stmt.rs#L122-L128\nI agree, panic does see very harsh here and I too would expect a Result here. I twas introduced in 17a3034bcd799ae2f117898ba6e266151fcb87e9, the first commit to add SQLite support. Is there any scenario where the sqlite connection is essentially irreparably broken when such an error occurs? I.e., can we always return Err in the last match arm?. Follow-up to #957. Are you all afraid of this small green button? I say :shipit:. That is sadly a problem we can't easily solve in Diesel. For now, just follow the compiler's advice: Add the #![recursion_limit=\"128\"] attribute.\nPersonally, I set this to 1024 at the first error just to not have to deal with this again. Also, IIRC, the default (64 apparently) was recently increased in rustc, so maybe you'll see this error less often in the future.\nThat said, we could solve this in Diesel: We'd need to replace the macro with a procedural macro. That is not an easy feat (the macro is quite complex and has a lot of edge cases), and not currently our focus. We'll absolutely look more deeply into this once the next batch of proc-macro features becomes stable in rustc, though.. Oh, or do you have a quick fix for this in mind? I've not looked into it more deeply, but if there was an easy change we could make to consume more doc attribute tokens per macro call we'd reduce the table macro's call stack drastically. (Still, not something I really want to spend much time on\u2014there are more pressing matters\u2014but I'd accept a PR for this for sure!). Thanks for great issue! You don't see a repro repo every day :)\n\u2026and I'm make sure to actually look at that later (\ud83d\ude05), but for now, what this reminds of is a recent change in diesel 0.16: The joinable! macro. By the way, did you upgrade diesel_codegen and friends to 0.16 as well?\nSo, my first try would be to add\njoinable!(crates -> readme_rendering (crate_id));\n\nor similar. Same for any other tables that have similar errors. If that works: Great! We probably missed a foreign key in the inference (I assume you specifically defined the foreign keys everywhere). This is a bug and we'll fix it.\n\nAm 25.08.2017 um 17:51 schrieb Carol (Nichols || Goulding) notifications@github.com:\nSetup\nI have a repo demonstrating this problem here: https://github.com/carols10cents/diesel-inner-join-mvce\nVersions\n\u2022 Rust: stable 1.19.0\n  \u2022 Diesel: 0.16.0\n  \u2022 Database: postgres 9.6.1\n  \u2022 Operating System macOS Sierra\nFeature Flags\n\u2022 diesel: postgres\n  \u2022 diesel_codegen: postgres\nProblem Description\nWhat are you trying to accomplish?\nI have these tables:\n[derive(Debug, Clone, Queryable, Identifiable, Associations, AsChangeset)]\npub struct Crate {\n    pub id: i32,\n    pub name: String,\n}\n[derive(Clone, Identifiable, Queryable, Associations, Debug)]\n[belongs_to(Crate)]\npub struct Version {\n    pub id: i32,\n    pub crate_id: i32,\n}\n[derive(Insertable, Identifiable, Queryable, Associations, Debug)]\n[belongs_to(Version)]\n[table_name = \"readme_rendering\"]\n[primary_key(version_id)]\nstruct ReadmeRendering {\n    version_id: i32,\n    rendered_at: String,\n}\nAnd I would like to write diesel that generates the equivalent of:\nSELECT * FROM versions\n    INNER JOIN readme_rendering ON versions.id = readme_rendering.version_id\n    INNER JOIN crates on versions.crate_id = crates.id;\nThis looks similar to the example with users, posts, and comments in the docs that says users.inner_join(posts).inner_join(comments) generates this sql:\nSELECT * FROM users\n    INNER JOIN posts ON posts.user_id = users.id\n    INNER JOIN comments ON comments.user_id = users.id\nSo I have this query:\nlet versions_to_readme_and_crates_doesnt_work = versions::table\n    .inner_join(readme_rendering::table)\n    .inner_join(crates::table)\n    .select((versions::all_columns, readme_rendering::rendered_at, crates::name))\n    .load::<(Version, Option<String>, Option<String>)>(&conn)\n    .expect(\"error loading versions_to_readme_and_crates_doesnt_work\");\n\nWhat is the expected output?\nI expect this to compile and run the sql above.\nWhat is the actual output?\nI get this compilation error, which seems to indicate diesel is trying to join crates and readme_rendering?\nerror[E0277]: the trait bound __diesel_infer_schema::infer_readme_rendering::readme_rendering::table: diesel::JoinTo<__diesel_infer_schema::infer_crates::crates::table> is not satisfied\n  --> src/main.rs:62:10\n   |\n62 |         .inner_join(crates::table)\n   |          ^^^^^^^^^^ the trait diesel::JoinTo<__diesel_infer_schema::infer_crates::crates::table> is not implemented for __diesel_infer_schema::infer_readme_rendering::readme_rendering::table\nFull errors behind toggle:\nAre you seeing any additional errors?\nNope. There's other code in the repo that shows versions joining to crates works fine, and versions joining to readme_rendering works fine.\nSteps to reproduce\nClone https://github.com/carols10cents/diesel-inner-join-mvce and cargo run; you should get the errors shown above.\nChecklist\n\u2022  I have already looked over the issue tracker for similar issues.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Ha! Forget everything I said and only believe Bastien from now on.\n\nAm 25.08.2017 um 18:06 schrieb Bastien Orivel notifications@github.com:\nHey, thanks for the awesome bug report with a repository and everything \u2764\ufe0f\nYou need to add a enable_multi_table_joins!(crates, readme_rendering); to your code as those are not inferred by diesel.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Very good catch!\nLooks like an easy fix, luckily. From the stack trace: In this code\nhttps://github.com/diesel-rs/diesel/blob/1f8118d2b1e24288deac6d3a1cfbc3d56a125915/diesel/src/mysql/types/date_and_time.rs#L67-L71\nwe are calling chrono's from_ymd but could just as well call the from_ymd_opt method just below which would not panic.\nSame for and_hms_micro and probably many other chrono calls!. @alexeyzab great! It's yours :)\nIf you need any help, feel free to ask here or on https://gitter.im/diesel-rs/diesel!. How'd you install it? With cargo install? It writes the binary to a path\nlike .cargo/bin/. See cargo's docs for details.\nyyolf117 notifications@github.com schrieb am Sa. 26. Aug. 2017 um 13:00:\n\nI've installed \"diesel_cli\" but when I'm calling \"diesel setup\" or\n\"diesel_cli\", the exception is \"bash: diesel: command not found\". What's\nthe matter? Wasn't it supposed to insert itself into the path?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1131, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOXz8zPIZw3wTx-5ecQ-wIG2QzWAAWks5sb_rlgaJpZM4PDcl2\n.\n. So, I guess ~/.cargo/bin/ isn't in $PATH? It probably should be! ;)\n\nYou can also tell cargo install to install it somewhere else, like /usr/local/bin.\n(I think rustup adds this but only for certain shells and system.). I didn't see your edit or the question in the code block.\n\nwhat if I gave it a different name? MY_DATABASE_URL\n\nThen\u2026 you have an environment variable called MY_DATABASE_URL. But diesel_cli has no way of knowing that it exists or that it should even care about that. Thus, you'll need to pass it the --database-url argument with the (you guessed it) database url, or use the env variable name it expects.. That's what the .env file is for :) Have a look at the guide.. What do you mean? Have you read diesel --help? It's diesel\n--database-url=\"your url\".\nyyolf117 notifications@github.com schrieb am So. 27. Aug. 2017 um 05:21:\n\nI didn't find anything related to \"--database-url\" being passed as an\nargument to diesel in the command line, where is it?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1131#issuecomment-325174657,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX54OwdRwP11yTfefzFJcpdqxP8uxks5scODMgaJpZM4PDcl2\n.\n. Yeah, it's a known issue that the recursion limit is reached quite quickly\nby that macro. Just do what the compiler says and increase it to 128 or\nmore until it works :) There was another issue here with a bit more\ninformation if you want to know more details.\n\n(This default will actually change in rustc soon IIRC.)\nyyolf117 notifications@github.com schrieb am So. 27. Aug. 2017 um 10:12:\n\nwith 0.16 the exception becomes this:\nerror: recursion limit reached while expanding the macro table_body\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = help: consider adding a #![recursion_limit=\"128\"] attribute to your crate\n  = note: this error originates in a macro outside of the current crate\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1132#issuecomment-325183869,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX4GkyJxC7rinI7GMGnM1vVfGmzeVks5scSTUgaJpZM4PDuu7\n.\n. Did you try a higher limit or putting it in the schema.rs file?\n\nyyolf117 notifications@github.com schrieb am So. 27. Aug. 2017 um 12:38:\n\nI've put #![recursion_limit=\"128\"] to my main file of my crate - main.rs\n- but the error remained.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1132#issuecomment-325190413,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX2-_TIyB9uxqtsVZnT2wRaYM6rWeks5scUcmgaJpZM4PDuu7\n.\n. Yes, diesel print-schema will show you the calls to table! that\ninfer_schema! creates. You can copy those to the file instead of calling\ninfer_schema!.\nyyolf117 notifications@github.com schrieb am So. 27. Aug. 2017 um 13:08:\nyes, yes.\nis it possible to use diesel without infer_schema!(\"dotenv:DATABASE_URL\")\nby writing code manually?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1132#issuecomment-325191721,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX_sjeIAB7Bz-VyFacZH1yObmdZvkks5scU4UgaJpZM4PDuu7\n.\n. Can you quote the full error? And give more details on what your schema is?\nIt's really hard to guess :)\n\nyyolf117 notifications@github.com schrieb am So. 27. Aug. 2017 um 13:33:\n\nNow there're several errors:\nthe trait bound (......) is not satisfied\n^ the trait diesel::Expression is not implemented for .....\n= note: required by diesel::query_builder::AsQuery\n= note: this error originates in a macro outside of the current crate\n^ the trait diesel::SelectableExpression<schema ..... is not implemented for .....\n^ the trait diesel::expression::NonAggregate is not implemented for .....\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1132#issuecomment-325192797,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX5ahdLNdyBDqKK1niZm-7JYPoLF4ks5scVQYgaJpZM4PDuu7\n.\n. > I'm following the tutorial step by step.\n\nMaybe it'll help looking at the finished code that you can download and run? You can find it here.. See above: just do what the compiler suggests and increase the recursion\nlimit :)\nLisq notifications@github.com schrieb am Mo. 28. Aug. 2017 um 05:39:\n\n@killercup https://github.com/killercup\nI got a error\nerror: recursion limit reached while expanding the macro numeric_expr\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = help: consider adding a #![recursion_limit=\"128\"] attribute to your crate\n  = note: this error originates in a macro outside of the current crate\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1132#issuecomment-325252791,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX922jNiIMVwB5A1H9t5lhpD_2bX3ks5scjZbgaJpZM4PDuu7\n.\n. Ah, I see. You'll to enable the large-tables (or huge-tables) feature for diesel in your Cargo.toml. (It's off by default to make diesel compile faster.). I assume this solved the issue for you?\n\nIf you have any more questions, don't hesitate to ask here or on gitter!. > Do what the rust compiler tells you to do\nI want that on a t shirt. Diesel doesn't officially support CockroachDB and we don't test against it.\nThat said, from what I've heard, it generally works.\nDoes cockroach support the full information schema standard? The\nreferential_constraints table contains information on foreign keys and\nDiesel uses it to automatically make tables joinable. (This was recently\nadded.)\nAs a workaround, you can define the tables yourself with the table! macro\nand also manually calljoinable!.\nMichael Murphy notifications@github.com schrieb am Do. 31. Aug. 2017 um\n00:52:\n\nGetting this error when trying to load the database schema from\nCockroachDB with `infer_schema!(\"dotenv:DATABASE_URL\"):\nDatabaseError(__Unknown, \"table \\\"information_schema.referential_constraints\\\" does not exist\")\nAny idea what would cause this? Trying to convert my website from using\nthe postgres crate directly to this, so I know the dotenv that I'm using\nworks for generating a connection pool.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1134, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX8UGhzIskggRcvtfuxk_TvryvBeLks5sdeeRgaJpZM4PIFEy\n.\n. Ah, looks like it doesn't support it yet. Their tracking issue for information_schema: https://github.com/cockroachdb/cockroach/issues/8675\n\nWe can totally make this error nicer, though, and I'd love to see a PR for that :). > I can do that here, just wanted to make sure I was on the right track. :)\nAwesome, you most definitely are!. @notryanb it's yours!\n624 might be a bit more tricky. Do you have a good idea how to solve it? I could only come up with one medium and one hard way\u2026 (see https://github.com/diesel-rs/diesel/issues/624#issuecomment-326586831). I have no idea what neomake does internally, and I assume that this is very much dependent on that. Can you get it to show what cargo/rustc calls it does? Does it set the correct features and pass down the correct env vars?\nI'd probably also open that as a bug with them as it seems like diesel works fine with the build process we support (i.e., using cargo directly) :). Any news here? I'm quite tempted to close this as I don't see anything we can do in diesel about that. True. On the other hand, it's frustrating to see tests pass locally only to have CI fail on clippy. Do we mention bin/check enough in the Contributing Guide?\n\nAm 05.09.2017 um 18:38 schrieb Sean Griffin notifications@github.com:\nI'm actually wondering if we should just remove clippy from bin/test as it increases build times quite a bit. I don't think linting the tests extensively adds nearly as much value\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Yep. But if people only use bin/test, they wont ever see clippy's wonderful suggestions for their changes\n\nAm 05.09.2017 um 19:55 schrieb Sean Griffin notifications@github.com:\nIf we removed it from bin/test I would say that we should not lint tests on CI either. Only lint the main code, which is what CI does currently.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. I'm also talking about regular code. With this change, the only way to get clippy to check anything is bin/check or being surprised by CI fails\n\nAm 05.09.2017 um 21:20 schrieb Sean Griffin notifications@github.com:\nGiven that it's test code, I don't think that's a huge loss\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Well, let's just hope people find bin/check then \ud83d\ude04. Awesome, thanks @willmurphyscode!. @dikaiosune failing test issue fixed in and more details in 1f3d7b1d521d616ebd969a5c19c375807579d864.\nCan you rebase on master?. Thanks for the quick adjustments!. Thanks again, Lauri!. Oh, thanks! I didn't see that either!. #912 reverted #782 because of u16, but maybe the other additions were valid?. Just checking that we get some sensible error messages that mention the\nright types as well as Queryable. I know we don't usually match against\nconcrete error messages, but I think for this we could use partial matches\nwithout expecting much breakage from rustc updates.\nSean Griffin notifications@github.com schrieb am So. 24. Sep. 2017 um\n03:39:\n\nMerged #1184 https://github.com/diesel-rs/diesel/pull/1184.\n\u2014\nYou are receiving this because your review was requested.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1184#event-1262513494, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX63hhlfbnnsyKMf_dgmphxRUMau4ks5slbLZgaJpZM4PflZq\n.\n. @toddWannaCode that's absolutely fine! Most PRs are quite isolated in scope so you don't need to know everything beforehand. :) Feel free to have a look at and review PRs to get a feel for it, and if you like it, ping me (or another core team member) and we'll add you to the reviewers team.. Absolutely! Want me to add you to the Reviewers team?\n\nEvan Cameron notifications@github.com schrieb am So. 24. Sep. 2017 um\n23:22:\n\nI'd be interested in jumpiing into some code reviews, if you folks are\nstill looking for people.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1186#issuecomment-331741068,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX5OL_jjKy7inV3oLryKG0EqflFLaks5slsgOgaJpZM4Pf3MF\n.\n. @toddWannaCode, welcome to the league of extraordinary reviewers! :). @leshow, welcome to the ~~Four~~ Nine Horsemen of the Code Review!. @ecasilla, thank you for joining the Order of Magnitude!. Oh, I thought this was already the style we use with rustfmt\u2026 that's why I didn't really question anything! \ud83d\ude05 Are there any significant changes? One I know of is the where on its own line.. Very close! I'll make rustfmt happy and merge this :). No worries :) (I set you editor to strip trailing whitespace in .rs files). > Maybe even formalize it into a contributor guide that itself is deployed to the website?\n\nI'd like to have a \"Diesel internals\" guide that points contributors to where some common things live and how Diesel itself is organized. This will be hard to keep up-to-date, though. I'm not sure a meta-guide on how our issue tracker is organized or how to submit PRs will be good content for a full-blown guide, as it's more specific to the Github than the project itself.. Sorry for not following up on this earlier! Do you want to land this right now and add more stuff in a follow-up PR?. Let's get this landed, then!. Ah, damn, on master this has #![deny(missing_docs)] so it fails CI currently. I'll fix it.\nUpdate: #1312. > Interestingly, this causes Cargo to just\n\nunconditionally recompile the crate, regardless of whether anything has\nchanged.\n\nIt's because cargo looks for a file at ./postgresql and when it's not there it assumes it's been deleted: https://github.com/rust-lang/cargo/issues/4213. Did you try the large-tables feature?\nAbhik B Pramanik notifications@github.com schrieb am Sa. 28. Okt. 2017 um\n02:10:\n\nSetup Versions\n\nRust: 1.21.0\nDiesel: 0.16.0\nDatabase: SQLite\nOperating System OS X 10.13\n\nFeature Flags\n\ndiesel: [\"sqlite\"]\ndiesel_codegen: [\"sqlite\"]\n\nProblem Description\ninfer_schema! fails when running cargo build for this table:\nCREATE TABLE test (\n    e01 INTEGER NOT NULL,\n    e02 VARCHAR NOT NULL,\n    e03 TEXT NOT NULL,\n    e04 VARCHAR NOT NULL,\n    e05 VARCHAR NOT NULL,\n    e06 FLOAT NOT NULL,\n    e07 FLOAT NOT NULL,\n    e08 FLOAT NOT NULL,\n    e09 FLOAT NOT NULL,\n    e10 FLOAT NOT NULL,\n    e11 FLOAT NOT NULL,\n    e12 FLOAT NOT NULL,\n    e13 FLOAT NOT NULL,\n    e14 FLOAT NOT NULL,\n    e15 FLOAT NOT NULL,\n    e16 FLOAT NOT NULL,\n    e17 VARCHAR PRIMARY KEY NOT NULL\n);\nRemoving a column (e.g. e16) followed by cargo clean and cargo build\nyields a successful build.\nWhat are you trying to accomplish?\nA successful inference of the test table.\nWhat is the expected output?\nA successful build.\nWhat is the actual output?\n% cargo build\n   Compiling diesel_issue v0.1.0 (file:///Users/abhik/Development/rust/diesel_issue)\nerror[E0277]: the trait bound (__diesel_infer_schema::infer_test::test::columns::e01, __diesel_infer_schema::infer_test::test::columns::e02, __diesel_infer_schema::infer_test::test::columns::e03, __diesel_infer_schema::infer_test::test::columns::e04, __diesel_infer_schema::infer_test::test::columns::e05, __diesel_infer_schema::infer_test::test::columns::e06, __diesel_infer_schema::infer_test::test::columns::e07, __diesel_infer_schema::infer_test::test::columns::e08, __diesel_infer_schema::infer_test::test::columns::e09, __diesel_infer_schema::infer_test::test::columns::e10, __diesel_infer_schema::infer_test::test::columns::e11, __diesel_infer_schema::infer_test::test::columns::e12, __diesel_infer_schema::infer_test::test::columns::e13, __diesel_infer_schema::infer_test::test::columns::e14, __diesel_infer_schema::infer_test::test::columns::e15, __diesel_infer_schema::infer_test::test::columns::e16, __diesel_infer_schema::infer_test::test::columns::e17): diesel::Expression is not satisfied\n --> src/lib.rs:7:1\n  |\n7 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::Expression is not implemented for (__diesel_infer_schema::infer_test::test::columns::e01, __diesel_infer_schema::infer_test::test::columns::e02, __diesel_infer_schema::infer_test::test::columns::e03, __diesel_infer_schema::infer_test::test::columns::e04, __diesel_infer_schema::infer_test::test::columns::e05, __diesel_infer_schema::infer_test::test::columns::e06, __diesel_infer_schema::infer_test::test::columns::e07, __diesel_infer_schema::infer_test::test::columns::e08, __diesel_infer_schema::infer_test::test::columns::e09, __diesel_infer_schema::infer_test::test::columns::e10, __diesel_infer_schema::infer_test::test::columns::e11, __diesel_infer_schema::infer_test::test::columns::e12, __diesel_infer_schema::infer_test::test::columns::e13, __diesel_infer_schema::infer_test::test::columns::e14, __diesel_infer_schema::infer_test::test::columns::e15, __diesel_infer_schema::infer_test::test::columns::e16, __diesel_infer_schema::infer_test::test::columns::e17)\n  |\n  = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound (__diesel_infer_schema::infer_test::test::columns::e01, __diesel_infer_schema::infer_test::test::columns::e02, __diesel_infer_schema::infer_test::test::columns::e03, __diesel_infer_schema::infer_test::test::columns::e04, __diesel_infer_schema::infer_test::test::columns::e05, __diesel_infer_schema::infer_test::test::columns::e06, __diesel_infer_schema::infer_test::test::columns::e07, __diesel_infer_schema::infer_test::test::columns::e08, __diesel_infer_schema::infer_test::test::columns::e09, __diesel_infer_schema::infer_test::test::columns::e10, __diesel_infer_schema::infer_test::test::columns::e11, __diesel_infer_schema::infer_test::test::columns::e12, __diesel_infer_schema::infer_test::test::columns::e13, __diesel_infer_schema::infer_test::test::columns::e14, __diesel_infer_schema::infer_test::test::columns::e15, __diesel_infer_schema::infer_test::test::columns::e16, __diesel_infer_schema::infer_test::test::columns::e17): diesel::expression::NonAggregate is not satisfied\n --> src/lib.rs:7:1\n  |\n7 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::expression::NonAggregate is not implemented for (__diesel_infer_schema::infer_test::test::columns::e01, __diesel_infer_schema::infer_test::test::columns::e02, __diesel_infer_schema::infer_test::test::columns::e03, __diesel_infer_schema::infer_test::test::columns::e04, __diesel_infer_schema::infer_test::test::columns::e05, __diesel_infer_schema::infer_test::test::columns::e06, __diesel_infer_schema::infer_test::test::columns::e07, __diesel_infer_schema::infer_test::test::columns::e08, __diesel_infer_schema::infer_test::test::columns::e09, __diesel_infer_schema::infer_test::test::columns::e10, __diesel_infer_schema::infer_test::test::columns::e11, __diesel_infer_schema::infer_test::test::columns::e12, __diesel_infer_schema::infer_test::test::columns::e13, __diesel_infer_schema::infer_test::test::columns::e14, __diesel_infer_schema::infer_test::test::columns::e15, __diesel_infer_schema::infer_test::test::columns::e16, __diesel_infer_schema::infer_test::test::columns::e17)\n  |\n  = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound (__diesel_infer_schema::infer_test::test::columns::e01, __diesel_infer_schema::infer_test::test::columns::e02, __diesel_infer_schema::infer_test::test::columns::e03, __diesel_infer_schema::infer_test::test::columns::e04, __diesel_infer_schema::infer_test::test::columns::e05, __diesel_infer_schema::infer_test::test::columns::e06, __diesel_infer_schema::infer_test::test::columns::e07, __diesel_infer_schema::infer_test::test::columns::e08, __diesel_infer_schema::infer_test::test::columns::e09, __diesel_infer_schema::infer_test::test::columns::e10, __diesel_infer_schema::infer_test::test::columns::e11, __diesel_infer_schema::infer_test::test::columns::e12, __diesel_infer_schema::infer_test::test::columns::e13, __diesel_infer_schema::infer_test::test::columns::e14, __diesel_infer_schema::infer_test::test::columns::e15, __diesel_infer_schema::infer_test::test::columns::e16, __diesel_infer_schema::infer_test::test::columns::e17): diesel::SelectableExpression<__diesel_infer_schema::infer_test::test::table> is not satisfied\n --> src/lib.rs:7:1\n  |\n7 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::SelectableExpression<__diesel_infer_schema::infer_test::test::table> is not implemented for (__diesel_infer_schema::infer_test::test::columns::e01, __diesel_infer_schema::infer_test::test::columns::e02, __diesel_infer_schema::infer_test::test::columns::e03, __diesel_infer_schema::infer_test::test::columns::e04, __diesel_infer_schema::infer_test::test::columns::e05, __diesel_infer_schema::infer_test::test::columns::e06, __diesel_infer_schema::infer_test::test::columns::e07, __diesel_infer_schema::infer_test::test::columns::e08, __diesel_infer_schema::infer_test::test::columns::e09, __diesel_infer_schema::infer_test::test::columns::e10, __diesel_infer_schema::infer_test::test::columns::e11, __diesel_infer_schema::infer_test::test::columns::e12, __diesel_infer_schema::infer_test::test::columns::e13, __diesel_infer_schema::infer_test::test::columns::e14, __diesel_infer_schema::infer_test::test::columns::e15, __diesel_infer_schema::infer_test::test::columns::e16, __diesel_infer_schema::infer_test::test::columns::e17)\n  |\n  = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound (__diesel_infer_schema::infer_test::test::columns::e01, __diesel_infer_schema::infer_test::test::columns::e02, __diesel_infer_schema::infer_test::test::columns::e03, __diesel_infer_schema::infer_test::test::columns::e04, __diesel_infer_schema::infer_test::test::columns::e05, __diesel_infer_schema::infer_test::test::columns::e06, __diesel_infer_schema::infer_test::test::columns::e07, __diesel_infer_schema::infer_test::test::columns::e08, __diesel_infer_schema::infer_test::test::columns::e09, __diesel_infer_schema::infer_test::test::columns::e10, __diesel_infer_schema::infer_test::test::columns::e11, __diesel_infer_schema::infer_test::test::columns::e12, __diesel_infer_schema::infer_test::test::columns::e13, __diesel_infer_schema::infer_test::test::columns::e14, __diesel_infer_schema::infer_test::test::columns::e15, __diesel_infer_schema::infer_test::test::columns::e16, __diesel_infer_schema::infer_test::test::columns::e17): diesel::SelectableExpression<__diesel_infer_schema::infer_test::test::table> is not satisfied\n --> src/lib.rs:7:1\n  |\n7 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::SelectableExpression<__diesel_infer_schema::infer_test::test::table> is not implemented for (__diesel_infer_schema::infer_test::test::columns::e01, __diesel_infer_schema::infer_test::test::columns::e02, __diesel_infer_schema::infer_test::test::columns::e03, __diesel_infer_schema::infer_test::test::columns::e04, __diesel_infer_schema::infer_test::test::columns::e05, __diesel_infer_schema::infer_test::test::columns::e06, __diesel_infer_schema::infer_test::test::columns::e07, __diesel_infer_schema::infer_test::test::columns::e08, __diesel_infer_schema::infer_test::test::columns::e09, __diesel_infer_schema::infer_test::test::columns::e10, __diesel_infer_schema::infer_test::test::columns::e11, __diesel_infer_schema::infer_test::test::columns::e12, __diesel_infer_schema::infer_test::test::columns::e13, __diesel_infer_schema::infer_test::test::columns::e14, __diesel_infer_schema::infer_test::test::columns::e15, __diesel_infer_schema::infer_test::test::columns::e16, __diesel_infer_schema::infer_test::test::columns::e17)\n  |\n  = note: this error originates in a macro outside of the current crate\nerror: aborting due to 4 previous errors\nerror: Could not compile diesel_issue.\nTo learn more, run the command again with --verbose.\nAre you seeing any additional errors?\nNope.\nSteps to reproduce\nPlease see example repo\nhttps://github.com/abhikp/diesel_infer_schema_issue and follow README\nChecklist\n\nI have already looked over the issue tracker\n   https://github.com/diesel-rs/diesel/issues for similar issues.\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1280, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX9K1UDS7uWoMdDtAi3KMPrGXB-xOks5swnDqgaJpZM4QJvtD\n.\n. What is your reasoning to make this a wrapper struct and not an attribute? Am I missing something or is this a subset of #860 (and thus a dupe of it)?\nAm 03.11.2017 um 01:48 schrieb Hernan Grecco notifications@github.com:\nIs there a way to implement a (let's call it) ServerSide object (similar to Option) to tell diesel that a particular field should be ignored from any insert/update?\nThe example from the guide would then become:\n[derive(Queryable, Insertable)]\npub struct Post\n {\npub id: ServerSide\n,\npub title: String\n,\npub body: String\n,\npub published: bool\n,\n}\nand then use it in insert as:\nlet new_post = NewPost {\n    id: None // Or another special value\n    title: title,\n    body: body,\n    published: false\n};\n\ndiesel::insert(&new_post).into(posts::table)\n    .get_result(conn)\n    .expect(\"Error saving new post\")\n\nThe same could be applied to other fields like created_at and updated_at.\nSee also: #860 and this reddit discussion\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Sorry to leave this hanging so long!. You are most likely looking at the API docs for the master branch, where\nthis was changed.\nHere is the doc for 0.16:\nhttps://docs.rs/diesel/0.16.0/diesel/expression/dsl/fn.sql.html\n\u6f02\u6d41 notifications@github.com schrieb am So. 5. Nov. 2017 um 09:45:\n\nHi, all, I encountered a problem, the output:\nerror[E0425]: cannot find function sql_query in module diesel\n  --> src/models/articles.rs:31:27\n   |\n31 |         let res = diesel::sql_query(format!(\"select * from article_with_tag where id={} and published={}\", id, admin))\n   |                           ^^^^^^^^^ not found in diesel\nthe cargo.toml:\n[dependencies.diesel]\nfeatures = [\"postgres\", \"chrono\"]\nversion = \"^0.16.0\"\n[dependencies.chrono]\nfeatures = [\"serde\"]\nversion = \"^0.4.0\"\n[dependencies.diesel_codegen]\nfeatures = [\"postgres\"]\nversion = \"^0.16.0\"\nDocument said there has the sql_querymethod, but here is wrong, I want to\nknow how to call the native sql operation\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1294, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX1zc36Z4zmPaKb25r4AQBGow16w_ks5szXWpgaJpZM4QSTkB\n.\n. Good point! we should give two links in the Readme (as you are probably\nlooking at it in the repo's master branch) and link to docs.rs in the\nCargo.toml.\n\n\u6f02\u6d41 notifications@github.com schrieb am So. 5. Nov. 2017 um 11:08:\n\nOh, thanks, However, at the moment crates' docs and readme's docs both\npoint to the wrong address, which has a negative effect on the work\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1294#issuecomment-341961859,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX93gHajoXZWIVLo4UbaiWLFyQgKtks5szYkUgaJpZM4QSTkB\n.\n. I opened #1295 to change the documentation links. As this issue is about how to use raw SQL, I'll close it.\n\nThanks again!. Thank you, @driftluo for pointing this out in #1294!. What? 0.01? No, 4.200000 obviously!\n\nAm 09.11.2017 um 13:41 schrieb Bastien Orivel notifications@github.com:\nWoups rustfmt :D I knew I forgot about something\nWhat do you mean by explicit values ? Something like \"0.01000\" ?\n\u2014\nYou are receiving this because your review was requested.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. The reason is this: You can run diesel setup in basically any directory of your project, and it will look for the root directory (which is where the migrations directory needs to live) by search for a Cargo.toml.\nImmediate action item from this issues: Document this behavior.\nRefactoring for the future: The code in diesel-cli that does this is actually not very clever, and I doubt it works will with a cargo workspace setup. Cargo has a cargo locate-project command, though, and we should consider switching to calling this.\n\nAm 11.11.2017 um 16:50 schrieb Sam Whited notifications@github.com:\nSetup\nVersions\n\u2022 Diesel: 0.16.0\nFeature Flags\n\u2022 diesel: no-default-features, postgres\nProblem Description\nDiesel setup looks for Cargo.toml file unnecessarily.\nWhat are you trying to accomplish?\nSetup a database for the first time in a non-Rust project.\n$ diesel setup\nUnable to find Cargo.toml in this directory or any parent directories.\n$ touch Cargo.toml\n$ diesel setup\nCreating database: demodb\nI would not expect diesel to require or care about having an empty Cargo.toml file in the project directory. My database migrations may be stored in a separate repo from my project or my project might not be in Rust at all and merely using diesel-cli for migrations.\nChecklist\n\u2022 [x ] I have already looked over the issue tracker for similar issues.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. LGTM! Go ahead, @notryanb!. Thanks!. Let's merge this as soon as CI is green :). You probably need to remove this line\nhttps://github.com/diesel-rs/diesel/blob/209f733b6f8bafb3463c82da9ace336a13ac4a29/.travis.yml#L57\nas the include key occurs twice. I personally like the idea behind bors quite a lot, and use it for most of my projects, but I also see its downsides. For me it's mostly about being sure that master always works, and me not having to do anything. If we keep doing regular releases and basically no-one is pointing at our master branch, it's fine for master to sometimes break. Another data point: We often have PRs that are open for a few weeks. If we make sure to rebase them before merging, we can greatly reduce the risk of breaking master.\nBors also adds another feature: We can delegate the ability to \"r+\" PRs to people who don't have the ability to merge Diesel PRs on Github.. It also allowed clap 31.41.5\u2026 Do we need a lint for Cargo.toml files? @Eijebong didn't servo's tidy thing have something like that?. I ain't trusting no humans! \ud83d\ude1b. Rebase on master to get CI green?. Go for it, @virome!. Is there anything in here that is tested by CI? Did you add a link checker without me noticing? :D . Pfff and you expect to learn from your failures? I hardly learn from my own!. Thanks!. I see your reasoning and I too want faster compile times, but I don't think this is something that's easy to fix. I'd really like to know what you have in mind :)\n\nHow is it more useful than using the print command?\n\nMore useful? Hard to say. More convenient? Yes: It literally is one less thing you need to do. You will never forget to run diesel print-schema > src/schema.rs after changing your DB.\n\nThere is no way rustc ever expected code to make database connections at compile-time.\n\nThat's a very weird argument. Proc macros and build scripts can do whatever they want. They are not required to be run in a sandbox and are written in a Turing complete language.\n\nThe more projects do fancy things at compile-time, the less freedom the Rust team will have to improve compile times, AFAICT.\n\nWhat optimizations are we talking about?\n- Memoization and caching for incremental compilation? Is there a way for you to detect proc macros to be pure, .e.g. by trying to run it with miri or something like that? If so, what stops you from falling back to the way things are currently done when that fails? Or requiring proc-macros to set a \"pure\" flag? (Funnily enough, as this is Diesel's repo, I can't help but think of how in Postgres you need to annotate functions with VOLATILE, STABLE, or IMMUTABLE.)\n- Skip potentially costly LLVM-based compilation by interpreting the code in miri? Not sure how fast miri is. That may be an interesting tradeoff.. Enforcing proc macros to not have side effects and not use external resources reduces their usefulness quite a bit. I'd personally be very disappointed if this limitation was introduced. Not that I think there is any way to introduce it\u2014crater or no crater, this is a huge change of a stable feature!\nBut wait: What is actually stopping us from experimenting with miri here? I've not dived deep into how miri does its thing, but I imagine that there is a way for it to give up, at which point you could fall back to the current way of executing them. Is this not possible? Is this in combination with a \"this macro is pure\" opt-in flag not sufficient?\n\nAm 23.12.2017 um 16:00 schrieb Anthony Ramine notifications@github.com:\nMy point was that we can't experiment with using MIRI for procedural macros if procedural macros do I/O and connect to databases and whatnot.\nI've personally never expected people to do things like that, even though Rust is a Turing-complete language and used to implement them proc macros.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n. Heads up: This targets #1428's branch. As mentioned in https://github.com/diesel-rs/diesel/pull/1428#discussion_r159157276. Sorry, merging #1367 introduced a conflict here. Can you rebase on current master?\n(#1367 actually rewrote most of the guide, so maybe you can even find new typos? :D). See the change log for information in how to upgrade.\ntl;dr the derives are included in the diesel crate now. dat diff. What's your use case? Matching on the error variant is usually the way to go.. > Our policy has been that extensions live in third party crates\nYes.\n\nwe get into the question of whether we should support all the various operators for these types in Diesel\n\nThis leads to ask another question: In which context are you actually using this? Does it make sense on its own? Without operators, and helper methods around it? PgMoney is pretty simple and Pg itself doesn't give you much more than numeric ops on it. SO: Is there a small subset of Point that diesel can include without opening the door to having to add all the features?\nAlternatively: Do you usually use these types in combination with other crates? If so, should we try and get geo::Point and diesel to work together?\n\nMy current feeling is that geometric types are something that (a) can live outside of diesel and (b) is easier to iterate on and add features to if it's a 3rd-party-crate.. Currently, CI fails because cargo_metadata doesn't compile on the nightly use for clippy.. cc @spacekookie . LGTM at first glance, but is blocked by #1674 and CI needs some work to run correctly. Also, speaking of CI, it would make sense to also test this on AppVeyor but its builds look broken, too :(. Wasn\u2019t 1.26.1 just released with fixes to rustfmt?\nSean Griffin notifications@github.com schrieb am Mi. 30. Mai 2018 um\n19:42:\n\n@sgrif https://github.com/sgrif requested review from\n@diesel-rs/reviewers on: diesel-rs/diesel#1743\nhttps://github.com/diesel-rs/diesel/pull/1743 Update rustfmt.\n\u2014\nYou are receiving this because your review was requested.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1743#event-1654176953, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABOX-W2PjNW_7q7lwltqwFdNGC407i7ks5t3toAgaJpZM4UTuD4\n.\n. Hm, this looks good at a first glance.\n\nThinking about it I'm not sure if this is not actually removing externally-visible imports. So while not important for diesel_migrations (because it hides the items in a mod), you might consider it a breaking change to migrations_macros. (This is very certainly not important in practice.). Oh but it's part of the derive macro's output and thus part of the user's code, right? But like I said, doesn't matter with the mod around it. Ugh, yeah, that's\u2026 not as great as it possibly can be. I too would rather not pollute a generic trait with backend specific methods. But as a compromise between adding this (touching code that probably only we will care about) and a major breaking change that users will notice? I'm actually okay with it. Can we maybe do a \"mini crater run\" with known production users?\nDo we want to really prevent making a breaking change? How far would we go with this? We could try and specialize RawBytesBindCollector. Well, we can't use actual specialization right now\u2026 Let's imagine this: We add another type parameter with concrete default type, like RawBytesBindCollector<DB, Mode=ProperBytesBindCollector> and change all our impls to be based on that. For MySQL, we impl Backend with type BindCollector = RawBytesBindCollector<Mysql, Mode=AcutallyImproperMysqlSpecificBindCollector>. Is this now a breaking change? Or an opt-in bugfix for everyone who actually had that trait bound in their code? We can even, god forbid, do runtime checks for MySQL, right? Or am I just talking about weird stuff that would never work anyway (likely)?. In this case it's not Microsoft's but @sgrif's fault, who changed the site to no longer be routed through Cloudflare. Which should be fine, I guess? I see no reason why the other cert is not valid?. This change should be reverted before merging (but deny(warnings) is really annoying when checking for warnings)\n. Those are clippy's default values, copied from the docs. There are actually defined here and I just noticed they also included 'GitHub'. I guess we could just leave them and add diesel's own CamelCase-names-that-are-not-code when we see an invalid warning?\n. Oh, I tried making sense of the doc_markdown lint which wanted me to put\nhelper_types in back ticks. I didn't mean to leave that in. (Is there a\nclippy issue for that? I should probably create one otherwise)\nSean Griffin notifications@github.com schrieb am Mo., 25. Apr. 2016 um\n23:24:\n\nIn diesel/src/query_dsl/boxed_dsl.rs\nhttps://github.com/diesel-rs/diesel/pull/305#discussion_r60992194:\n\n/// but you might want to hide the return type or have it conditionally change.\n /// Boxing can achieve both.\n ///\n /// [iterator]: https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html\n-/// [helper_types]: ../helper_types/index.html\n+/// [helpertypes]: ../helper_types/index.html\n\nLol what\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/305/files/9b4d3b77b7c5c046956b10be79757433abbec0b2#r60992194\n. cf. https://github.com/Manishearth/rust-clippy/issues/883\n. I created a new feature so we can control if/when CI includes clippy. Do you think we should just include it every time unstable is tested?\n. I wasn't sure if it was a breaking change, so I left it as is. I think \"QueryError\" reads nicely, but if it's only used as \"RunMigrationsError::QueryError\" I would remove the suffix.\n. Clippy found this because the names ndigits and digits were too similar, I was actually glad that it did. I had to think about it for a bit to understand what was meant here and I initially thought this was n represented as bytes (but there was no n). I think num_* is still a bit weird (but was just 3 chars to add), I would probably write digit_count.\n. Interesting. I agree, I would remove that fn new() -> Self.\n\nI rarely have fn new() -> Self (i.e. with no parameter) but often use fn new(stuff) -> Self as a constructor (which may internally do stuff like StructName { field1: stuff, ... StructName::default() }).\n. The next step should be to update directly to 0.0.128, obviously \ud83d\ude04 \n. I had to look up whether you could use an exclamation point as part of an URL. Turns out you can (RFC 1738, page 3) and I don't need to file a bug with rustdoc :)\nOh, and I would probably turn this into the nicer\n\nSee the documentation for details.\n\nBut that's totally not important.\n. Could you add basically the same example as below here as well? (It's really nice to use doc tests for this, btw.)\n. Is the name 'ordering' a good choice? It only set the ordering of nulls, right? Maybe call it NullsOrdering? (I don't have a preference.) Maybe also add a short doc comment.\n. FYI: Searching the docs for \"trait:ord\" shows that there is a diesel::types::SqlOrd.\n. Did you mean Find instead of FindBy?\n. Ah, I see. I got that backwards somehow. \ud83d\udc4d \n. Looking forward to your RFC to allow\nrust\nfn foo<T: Bar>(bar: T) where\n    T: Copy,\n; // <- this guy right here\n. Or this the point where you switch to\nrust\nwhere T: Copy\n,     U: Send\n\ud83d\ude27\n. Fair enough. The easiest thing after that I can come up with right now: change that RFC to allow to put where clauses in braces.\n. probably: s/for the itself/for the CLI\n. convention in std is to always write Examples\n. You could make custom_derive a dev-dependency and doc test this as well\n. Macro looks good as far as I can tell. Nicely commented :)\n. s/requried/required\n. s/iwth/with\n. s/follwed/followed\n. s/foreing/foreign\n. Are these the only fields ever given here? Would it make sense/this more future-compatible if you add a generic token tree match at the end? Like $($other_headers:tt)*\n. &....as_str()? You might be able to get rid of that & IIRC\n. Link open issue to https://github.com/diesel-rs/diesel/issues/new?\n. no ref-link for [custom_derive]\n. s/shoudld/should\n. s/the the/the\n. > saves more than the\nSaves more what? I'd add one or more of: \"time\", \"memory\", \"money\" :)\n. Two \"most\", get rid of one.\nI'd also split this into two sentences: s/, where/. There,\n. Maybe add a link to \"N+1 query\" as not everyone might be familiar with this, e.g. to http://stackoverflow.com/q/97197/1254484. (But everyone using diesel should be!)\n. this load probably needs &conn as well\n. s/the belong/they belong\n. s/simply/in another way\n. This code block could benefit from some explicit type annotations :)\n. s/and ability/and the ability\n. Maybe give a short example like \"find all the users I follow through the Followers table\". (I guess this is what you mean)\n. Sorry to nitpick\u2026 again\u2026\nI would try to only show foos.select(foo).order(foo.asc()).load(&connection));\u2013 or include the insert as well. That assert doesn't really make sense to the reader, as they can't verify that vec!(Some(1), Some(2), None) is a correct result. (Nitpick inside a nitpick: vec![] is usually written with square brackets as they look like an array).\n. dito for this example\n. This is a private method on a public trait. Thus, not a breaking change, right?\n. I think there is a way to write that a little cleaner/functional, with flat_map and collect/fold. I'm just reading through this quickly though, and maybe come back later with an actual refactor suggestion.\n. parents is a slice you immediately call iter on (two times)\u2014why not take an IntoIter<Item=Parent> instead? Might be cheaper to clone/work with. Totally unimportant though, I guess you always deal with Vecs here anyway.\n. Ah, my bad. Got confused with impl Struct { pub fn \u2026 }\n. took me a while to see the magic to determine if this is an option is already part of __diesel_parse_struct_body :)\n. Actually, what put me off at first about this was the HashMap\u2014is this really necessary? I guess so, and I don't see a better way. Maybe use a hasher like Fnv which is optimised for smaller keys? Downsides might be that it's (a) not worth the effort (though I think this gets called quite a lot for each association), and (b) that this is not a cryptographic hasher, so it might be a security risk if users can influence the ids to do a collision attack.\nYes, I'm totally overthinking this.\n. Wait, are you actually just doing let mut result = vec![vec![]; parents.len()]; here?\n. This might be a good place to mention crates that do this, as people reading this might want to implement types themselves and having example code to look at might be nice.\n. Can you add an empty (doc) line before the examples headline?\n. Hm, I think this whole docs section should be in after_success and only run on stable.\n. This should no longer be necessary: https://github.com/rust-lang/rust/pull/30173\n. If this is a breaking change, the next version should be 0.8.0.\n\nAm 11.09.2016 um 11:56 schrieb Sergio Benitez notifications@github.com:\nIn diesel_codegen/Cargo.toml:\n\n@@ -10,7 +10,7 @@ repository = \"https://github.com/diesel-rs/diesel/tree/master/diesel_codegen\"\n keywords = [\"orm\", \"database\", \"postgres\", \"sql\", \"codegen\"]\n[dependencies]\n-diesel_codegen_syntex = { version = \"0.7.0\", default-features = false }\n+diesel_codegen_syntex = { path = \"../diesel_codegen_syntex\", version = \"0.7.3\", default-features = false }\n\nI changed the version numbers to 0.7.3 given that this is a breaking change.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Why did you change this fn to return a token tree vec? IIUC this is given the same context as changeset_impl so you could just return a bool here and match on it to create the quoted version in changeset_impl below.\n. I almost missed that line! This is where some magic happens :)\n. Is there a space missing between the variable and the script name? (I'd also explicitly use env TRAVIS_RUST_\u2026)\n. That's a weird way to write this (at least it looks weird on my too-small phone display ;)). What does the try! accomplish when you always unwrap_or?\n. Oh wait the .map caller returns a result? Did you mean to use and_then? Or unwrap_or before the map and then replace the map with an new let binding with try!(extract_treat\u2026)?\n\ntl;dr I think the type is Option<Result<_, _>> but it can be simpler :)\n. I was just confides by the nested try/map+unwrap. I think I understand it now, and I'd probably write it myself like\nrust\nlet treat_none_as_null = if let Some(a) = changeset_options_attr {\n    try!(extract_treat_none_as_null(cx, a))\n} else { false };\n(I hate typing code on an iPhone.)\n. Good question. I think it'd be fine to leave it in but currently it doesn't give us anything, so I'll remove it. If we were to support views later, we can just re-add these migrations.\n. double space\n. Add period before 'This'\n. Did you mean to change this sentence in another way?\n. Is there a reason you switched the order of the register calls (insert before query)? Same in diesel_codegen_syntex/src/lib.rs. It obviously works but I couldn't find a reason if the order makes a difference.\n. Oh, nice. You are basically using the logic you already have in Model to do the heavy lifting, right? Actually\u2014is this the exact same code?\n. Wow, there's a lot of cloning going on in these lines. I don't have any concrete advice to reduce that right now, just seems like a bad smell.\n. Memo to self: This impl is used by quote! which calls Tokens::append_separated which calls ToTokens::to_tokens\n. ~~I guess these first three calls are needed for every derive_* extension; would it make sense to put them into a separate fn?~~ Never mind you abstracted this to be a HOF instead\n. I think this match generates the same output as .expect(\"#[derive(Queryable)]\") since e is just a String\n. No, wait, I guess you were aiming for\n\n#[derive(Queryable)] cannot be used with enums\n\n(maybe add the backticks, though)\n. Maybe use the inflections crate instead and reduce this to name[..1].to_string().to_pascal_case()?\nInflector is an alternative crate that has to_singular, but no pascal case yet (cf. https://github.com/whatisinternet/inflector/pull/27)\n. Interesting. I didn't know Rails had problems with that, but I can totally see that happening. Makes sense to keep this really simple; if it doesn't work you can just set the table name explicitly anyway.\n\nAlso admit it you just want to have a function called to_pascal_case\n\nHaha, you got me \ud83d\ude09 (I usually call it UpperCamelCase because it just sounds weird to me otherwise\u2026 \"Huh, is anyone talking to me? Aww, no, they're still discussion string casing\u2026\")\n. Setting this to no_run will still compile it (which fails)\n. Sorry, but this users table doesn't have a surname column (see doctest_setup.rs).\nYou can probably add the (nullable) column in the setup for postgres, or create a new table here. (Since establish_connection starts a new transaction that is dropped when connection goes out of scope, this table will only be available in this test.)\n. Instead of using strings here (and const lists of strings in lib), you could use a set of modules with constants for derives and attributes like this. (Doesn't need to be in this PR. I just hate doing stringly typed stuff in a language like Rust \ud83d\ude09 )\n. options.len() >= 1 can probably be !options.is_empty()\n. You could also match on attr.name() and combine the ifs \n. Maybe add a link to https://github.com/diesel-rs/diesel/issues/new?\n. Yeah, having a _Dummy type in user code (which might be observable if you tell rustdoc to render private types as well) might not be as nice as having, say, _DieselSchemaInferenceHelper.\n. Travis says table! is undefined here :(\n. > unresolved name sql\n. I love how this tiny line right here is sets of a huge awesome piece of rust-macro-derive-inception as it (1) is part of a macro (2) that is contained a custom derive (3) which expands to a (set of) macro calls (4) that themselves include custom derives (5) where each one actually expands to calls to the tables! macros. You could probably write a few pages of internal docs just about that \ud83d\ude04 \n. I'm fairly certain you can omit the & in &table_name as it's already a &str. (Same for &options and &database_url above.)\n. primary_keys.is_empty()\n. maybe add a link to https://www.postgresql.org/docs/9.5/static/catalog-pg-attribute.html since the field names are pretty weird (same for the next 3 comments or so)\n. maybe add a link to https://www.postgresql.org/docs/9.5/static/catalog-pg-type.html\n. https://www.postgresql.org/docs/9.5/static/catalog-pg-index.html\n. https://www.postgresql.org/docs/9.5/static/catalog-pg-class.html\n. Why do array types start with an underscore? This ist just the values of pg_types.typname, right? (The docs don't say much about the values in there)\n. wrong pr, but: you need specify this with a version to publish it to crates.io, right?\n. Ah, of course! And this is a good way to ensure this :)\n. What good is a borrow checker if you don't borrow stuff, right?\n. You need to write compiletest_rs = \"=0.2.3\" with the = before the version number or Cargo will treat this as ^0.2.3.\n. Maybe add a link to https://github.com/diesel-rs/diesel/issues/new?\n. Isn't that match the same as migrations_expr.expect(\"Error reading migrations\") (also print the error afterwards)?\n. \"migratoins\"\n. Oh, right!\n. This sentence should be the first paragraph, so the rustdoc summary shows it instead of \"This macro can only be used in combination \u2026\". Same for the doc comments below.\n. If the convention is so dumb you can probably describe it half a sentence, e.g.\n\nusing very dumb pluralization -- it just adds an 's' at the end\n\nI'm also wondering if this is something we want to guarantee any kind of stability of (which we should mention regardless of yes or no).\n. Another good place to link to https://github.com/diesel-rs/diesel/issues/new\n. Is macro.table!.html the correct URL? I saw a rustdoc PR that go rid of the bangs in URLs but I don't know if it got merged (yet).\n. \"not already supported\" \u2192 \"not supported by the core diesel crate\"\n. Maybe link diesel_codegen to its readme/crate docs/page with explanation how to use it?\n. \"option\" \u2192 \"Option\" or \"optional\"\n. period at the end\n. Imagine you have a struct called Mouse and diesel 0.8 assumes your table name is Mouses \u2013 which for some reason it actually is. Now, diesel 0.8.2 comes with an awesome new pluralization and infers your table name is Mice.  You are also not using infer_schema so your code continues to compile. Sadly, your application doesn't work any longer.\nWe should say whether we guarantee this to never happen.\n. Sorry to nitpick, but can you put \"Attempting to use the\u2026\" in a new paragraph? It's not really relevant to the summary line IMHO.\n. I think there's an \"in\" too many in \"\u2026will never change in without \u2026\"\n. Huh? Why is this now necessary when it wasn't before?\n. This basically extracts the T from std::option::Option<T>, right? (Might be interesting to see if syn can offer a simpler API here.). FYI you commented above this\n\nFIXME: This can be cleaned up significantly when https://github.com/rust-lang/rust/issues/27245 is stable\n\nWell, https://github.com/rust-lang/rust/issues/27245 is stable now!. These two additions make so much sense. It's much clearer how this is used in grouped_by now.. I'd probably change the a bunch of 'as to 'ps here and in the code below so the relation to Parent is more obvious ('parent is too long).. That's an interesting shortcut. Funny idea for teaching: Tell people how to read a clause like this as an English sentence. E.g.:\n\nA [reference to a] Parent is Identifiable, i.e. we can find the corresponding row.\nWe know about Child that it has a table and BelongsTo Parent.\nThe [List] of [references to] Parent Ids can be turned into an IN expression based on the SqlType of the Child's ForeignKeyColumn.\nThe Child's Table can be Filtered [using our Dsl] to get the rows where the Child's ForeignKeyColumn is Eq to Any of the entries in the [List] of Parent Ids.. That looks confusing, but I guess if it compiles it's fine (rustc is better at this than I am) \ud83d\ude04 What does it mean for T to be required to be Copy here? (Though I guess this was implicitly required before as well.). Did you mean to add this under a new \"unreleased\" h2?. Changing from just pushing the table name to using QuerySource is a nice refactoring.. ~~TIL~~ TIR (remembered): In macro token trees, whitespace around . and tokens don't matter (the same way they don't matter around +). Still reads weird though ;). You already released 0.8.2 :). Why x.as_str() and not just &x? (Alternatively, make the calling fns accept AsRef<str>). Why is this better than &[MetaItem]?. Maybe also add Duration?. The changes in this file seem orthogonal to the syn update. Did you have any problems with these tests? Adding the order seems like a good idea when comparing to an ordered Vec, but it might be better in a separate PR. :). The whole change of returning owned strings and calling as_str stems from this change, right? What changed here? It should be possible to return a &'v value with a lifetime 'v that at most as long as that of item.. This looks pretty complicated, cf. https://github.com/diesel-rs/diesel/pull/508/files#r90534159. You can make this a bit more concise by the way:\n\nrust\n.filter_map(|o| match o {\n    &syn::NestedMetaItem::MetaItem(ref mi) => Some(mi),\n    _ => None\n}). Not that I know of. I'd probably replace .map(|s| s.as_str()) with .map(String::as_ref) though.\nEdit: There even is a SO question about that with basically the same answer.. I think the problem is that .map creates a reference that is only valid in its closure, but you want to return a value that lives as long as option does (and not the reference to option). Try this:\ndiff\n- let migrations_path_opt = options.map(|o| get_option(&o, \"migrations_path\", bug));\n+ let migrations_path_opt = options.as_ref().map(|o| get_option(o, \"migrations_path\", bug));. You can replace this match with an unwrap and adding #[should_panic(expected = \"There are no changes to save.\")] to the fn. You probably don't need this anymore then. As this should be a cold path anyway (is #[cold] a thing?), you could create a more fancy error message like format!(\"There are no changes to be written to `{table}`. This query cannot be built.\", table=self.table.from_clause()). Just for a fun exercise: I'm pretty sure the &s you added here are no longer necessary \u2013 the bindings are already references. (Deref coercion allows rustc to accept &&&foo where &foo was wanted.). Nice. I think you can just give it o instead of &o here (same as other comment).. FYI this whole function can be replaced with ident.into(). I added a bunch of From impls to syn a while back. I don't think we need the .map(syn::Ident::new) here anymore.. This is the magic right here, isn't it? As this assumes the default type param for Ret it is only implemented for NoReturningClause, right? And thus not implemented once you called returning. Do you want to explicitly write NoReturningClause here and maybe add a short doc comment before the impl to explain this?. Yeah I understand using the default type param you don't need to expose it publicly. I was just asking to make it more explicit in this impl :). I enjoy this too much probably.\n\nFor a bunch of life times, 'insert (read: \"tick insert\"), and the type params Operation and Returning Clause: Implement IntoInsertStatement with our table and Operation, and Return, for a reference to our struct type that lives as long as 'insert, where 'insert outlives all other lifetimes, and the InsertStatement with our table, the reference to our struct, Operation, and Returning Clause can be seen As a Query.. FTR, @sgrif admitted that the type bounds here are not really needed just there so the lifetime bounds are somewhere that is syntacticly valid :). add empty line before headline. Move second sentence to new paragraph for nice docs :). Well, you could do\n\n```rust\nlet inserts = self.records.map(|r| InsertStatement::new(self.target, r, self.operator, self.returning).execute(conn));\nlet insert_sum = inserts\n    .take_while(Result::is_ok)\n    .map(Result::unwrap)\n    .sum();\n// next element is always an error or None\nif let Some(Err(err)) = inserts.next() { Err(err) }\nelse { Ok(insert_sum) }\n```\nor something like\u2026 but it's quite long and not really more readable IMHO :/. Do you actually need to impl this for &Vec if you already have &[]? I mean, it doesn't hurt, but deref coercions should take care of that, right? Then again, you apparently need to write &**self?. Yay!. Yay\u00b2!. Uhm, no? 'a: 'b means that 'a lives at least as long as 'b. IIRC, this not really intuitive. But the nomicon and Niko seem to agree with me.. s/It not/It does not. Maybe add a comment to say this is just to return a valid sql expression that always evals to false?. I'm not sure if left is a good name for this but I don't have a better idea right now. What kind of escaping is this? The first of the slashes is for rust, the second for SQL? What is \\_ in SQL? Could this be written as r\"\\_\\_%\"?. Makes sense. ~~(Though I have no idea what table_catalog is here \ud83d\ude04)~~ Oh, the database name, basically.. Good to know! Might still read better as a raw string.\n@weiznich I'm not sure I would expect diesel to escape this if you explicitly use fn not_link(String). I found a method for stuff like name.not_like(\"%a%%\").escape('a') though (docs).. This link 404s. Should be http://docs.diesel.rs/diesel/fn.insert.html. The last item is None to default to loading the public schema, right? Might be nice to add a comment :). FTR/For the docs pass: For all schemas\u2260public this wraps the inferred tables etc in a pub mod $schema, but the inferred tables for public are inserted in the scope as-is. This may lead to collisions/uncompilable code with ugly error messages.. Can probably be .unwrap_or_else(|| \"id\".into()). .cloned()?. I think we can get rid of str_to_ident with .into(). Very nice. I will be missing these macros when macros 1.1 is stable . I hope it's clear to people reading this in the future that these are &&strs. Start new paragraph after first sentence for nice looking docs :). Add newline after headline. Doesn't the inner self.0.collect_binds(out) suffice here without the try and Ok unit stuff?. Good point. I appreciate les diff noise :). Ohhhh! First use of ? in the diesel code base? Anyway, I'm a big fan, but please, for consistency's sake, don't use it in the same line where you also use try! ;). Reading the code above, it took me a while to figure out that RawResult::new returned a QueryResult, because it really surprised me to see a new method that returns a Result.\nI don't think this is very idiomatic, but it's also what std::ffi::CString does, so I guess it's okay. I would probably call this method try_new, or try_form myself (sadly, std::convert::TryFrom is still unstable).. Huh, another new method that returns a result. Not as rare as I thought then. Carry on.. > 40k binds\nYou \"only\" send an slice of 35k NewComments actually ;). same as above. Nice. I had totally forgotten about this feature \ud83d\ude05. Makes sense as Insertable is the main thing being exported. I like the idea of \"persisting\" something, though. Probably more useful in the context of dealing with data that may or may not have been synced to the DB, thus higher in the stack than diesel.. Thank god for type aliases!. Nice. (Here was a longer comment musing about fn pointers. Shouldn't have read this commit-by-commit.). Clippy will not like this unwrap and I will probably make it a \u2026.ok_or(WeirdStuffHappend).and_then(|val| val.column_names(out)) somewhere along the line ;). s/JSON/JSONB, or this is just the same as above :)\nCan you maybe add a sentence that JSONB is storing the data in binary and thus more efficiently, and link to https://www.postgresql.org/docs/9.6/static/datatype-json.html? Maybe even quote:\n\nIn general, most applications should prefer to store JSON data as jsonb, unless there are quite specialized needs, such as legacy assumptions about ordering of object keys.\n. I'd like to add a comment on those magic oid/array_oid numbers here, with links to the postgres spec. But I can't find them, except for in other implementations and the source code\u2026. Huh, is that as Box<Error+Send+Sync not inferred?. Probably unnecessary & (bytes is already a reference). Yeah, that sounds like a solid reference :) Maybe we can link to a current release: https://github.com/postgres/postgres/blob/REL9_6_1/src/include/catalog/pg_type.h#L623-L627\n\n(We should probably go through the code and add more references for type OIDs\u2026 I hate magic numbers). \n(This broke the first meme generator I tested). Moving this into a separate, public crate is interesting. I'm not sure I agree, but I don't see many reasons against it.. Nit: All other descriptions end with a period. ~~Whew, this looks complicated. Can you add a comment describing what is happening here? Is it possible to rewrite this whole block as an iterator chain that might be easier to read?~~\nQuick rewrite as match:\nrust\nmatch c {\n    '!' | '(' | ';' | ',' | '<' => { out.pop(); }\n    ':' if last_char != ':' => { out.pop(); }\n    '>' if last_char != '-' => { out.pop(); }\n    _ => {}\n}\nStill not great though.. ~~Will continue here after lunch~~ Lunch was great, continuing\u2026. I think I'd call the subcommand \"print-schema\" instead.. Okay, IIUC this whole for-loop is to pretty print the tokens, right? Great job! In my tests you got about 80% of the formatting right in just 40 lines of code! Sadly it will look weird unless we get to 99% :)\nNevertheless, I'd either (a) put this into a separate function that takes quote::Token and a W: io::Write and make that perfect for using with our table! macro, or (b) skip this completely and use a proven tool we don't need to maintain! :)\nsyn has a \"pretty\" feature, but that seems to use libsyntax' pretty printing\u2026 which is not that great. Can we maybe pipe our string output into rustfmt? That way it might even respect the users' project's rustfmt.toml.\nMaybe @dtolnay, the great author of quote and syn, has some suggestions? :). I assume most of the code in that function and its call stack are basically what there were as part of diesel_codegen? Of not, can you point me to important differences?\nAlso, we should think about error handling here. The codegen code contains a lot of unwrap (and the diff suggests you added some more :)), but I think it won't be too difficult to move it to Result. Having done that, I'd really like for the function called here to return an Iterator<Item=(TableName, Result<Tokens, _>)> so we can emit as many table! definitions as possible and not crash at the first error. This doesn't need to be in the first version though.. Memo to @diesel-rs/core: Need to publish this crate.\nFYI, its API surface is quite small. Just two function with the signature (database_url: &str, table_name: &str) -> Tokens.. Can you skip the path and instead use an override in the workspace Cargo.toml?. Yeah, pretty printing is hard and full of people telling you about their preferred code style \ud83d\ude48 \nI'm actually fine with shipping a version that depends on having rustfmt in $PATH and just piping to it. @weiznich, what do you think?. > It is not possible to use a proc-macro lib as depenency without using the proc-macro version. \nOh, right. This seems like the best solution, then!. TIL! Thanks.. Can you add this with the current version and add an override in the root-level Cargo.toml? Otherwise crates.io won't let us publish this (IIRC).. I think this doc test needs a #[macro_use] extern crate diesel_codegen;. All that code around pop and push is a bit confusing. Am I read in reading this match as \"add a space when the last char was '>'\"? Can you write this in a simpler way?. Please remove empty lines at beginning of file (are these inserted by rustfmt?). You are dealing with < and > here. Can you add them to the rules above?. Does this render nicely as markdown? Here is the original markdown source from my comment if you want to copy its style and not rewrite it:\nmarkdown\n1. Seeing `{` increases indentation level\n2. Seeing `}` decreases indentation level\n3. Insert newline after `{`, `}`, `,`, and `;`\n4. Don't put spaces:\n    - between ident and `!`,\n    - between path segments and `::`\n    - after `(` and before `)`\n    - before `,`\n5. Insert spaces\n    - around arrows (`->`, and probably also `=>`)\n    - after keywords like `mod`, and `use`. Can you make this function return std::io::Result<()> and omit the unwrap?\nAnd now for something really profound: Tabs vs. spaces. I see you used \\t for indentation, probably because it's exactly one character. Idiomatic Rust code uses four spaces, though. Can you add a .replace(\"\\t\", \"    \") here (should be four spaces, I think Github messes it up)?. I think it'd look nicer if you use std::io::Write at the top of the file and use <W: Write> here instead of a where clause with a fully qualified path.. All these tests follow the same pattern. I think it'd be nice to reduce the boilerplate code a bit by adding a simple macro here:\n```rust\nmacro_rules! test_format_output {\n    ($test_name:ident, $input:expr => $output:expr) => {\n        #[test]\n        fn $test_name() {\n            let out = Vec::::new();\n            let mut c = Cursor::new(out);\n            let input = $input;\n        format_schema(input, &mut c);\n        let format_output = String::from_utf8(c.into_inner()).unwrap();\n\n        assert_eq!($output, format_output);\n    }\n}\n\n}\n```\nwhich you can then call like this:\nrust\ntest_format_output!{\n    test_remove_whitespace_colon,\n    \":: diesel :: types :: Text\" => \"::diesel::types::Text\"\n}. I assume this is rustfmt? Can you try to match the fn declaration style used in e.g. column_def_tokens?. Can you refactor this to let macro_call = if let Some(type_module) = extra_types_module { quote! { infer_table_from_schema!(extra_types_module=#ype_module, #database_url, #table_name); } } else { quote! { infer_table_from_schema!(#database_url, #table_name); } } so the mod and pub use doesn't need to be repeated?. This is the only place where you use syntex right? Please please please remove this dependency if it's not going to be used, it takes ages to compile. (And if we need something that syn doesn't have in this regard, I'd gladly make a PR to syn!). Yes! Finally! PascalCase! Errrr, I mean, \"upper camel case\". (On a more serious note, I think this fn should be called snake_to_type_case.)\nPlease note that all other case conversions we do are trivial conversions by choice, to not introduce surprisingly complex behavior.\nThe snake case version we get here are valid Postgres identifiers, right? What properties do they have in comparison to Rusts type identifiers?. N\u0335\u0361i\u031bc\u0358e \u0300e\u035cd\u0328\u0358\u0362g\u035c\u0361e\u0360\u035e \u0334\u031bc\u0336\u0328\u035ea\u0362\u035cs\u035e\u0229\u0335s.\u035f\u0360\nCan enum variant names contain umlauts, though?. Just a heads up: diesel_codegen_syntex will be removed in 0.10. What is this needed for? (It's fine, just maybe add a comment what requires this, so we can remove it when it's no longer needed.). I would love to see a doc comment here telling me what this type is all about. I assume it abstracts over structs and enums providing SQL types? Maybe also mention HasSqlType is implemented for everything that implements this trait.. Can you use the same inline table syntax as above?\ntoml\nsyn = { version = \"0.10.3\", features = [\"full\"] }. I hope we can not introduce this dependency. Syntex takes ages to compile.. Can you add that to your system-wide .gitignore instead? (Just like all other system-specific files to be ignored by git). I know why you did it this way, but I'm not too happy with the structure of this. I'll try to think of something.. run_test is the most generic name ever\u2026 \ud83d\ude04 how about test_formatting? I still think this would be nicer as a macro, btw ;) Also, please add space before opening bracket.. Same as above. One empty line too many. Add spaces around keyword. Two empty lines too many. Is there actually an associated backend? The type signature doesn't say anything. (Our concrete implementation do, of course. But a test connection might not.)\nHow is this trait used? From what git grep -i SimpleConnection tells me, this is only used in two ways: as trait object in migrations and as a base for more concrete connections.. While technically right, this is the same information that rustdoc shows you :)\nMentioning that it extend tre SimpleConnection trait is a good idea though.\nMaybe it helps to instead answer questions like \"When do I use this?\", or \"Where does this fit in my application?\", or \"What problem does this solve?\". Or, as this is a trait, \"What does this abstract over?\". I think you forgot a println here :). What does v stand for here and in the outer scope? Value? I agree that it should have a short name, but it's not immediately obvious what this is. Even after looking at the clap docs I only got the vague clap::Values type, which I assume can be seen as an Iterator<Item=String> here.\nCan you maybe swap out that .map.unwrap_or for a if let \u2026 else? This way it's a bit clearer we are dealing with an Option here and, hopefully, that the inner map is on an Iterator.. Can you move that if into the inner map? This way, you can combine the if there to something like if !cfg!(feature = \"postgres\") || v.contains(\".\")?. I wonder if there's a pull-based string processor crate. Like an iterator, but with replace and trim and such. #[allow(dead_code)] for consistency. Don't get me started on mysql utf8 support\u2026 a coworker recently had to migrate their Redmine instance to utf8mb4 (that's \"UTF-8, much better, fourth try\", right?), because I used an emoji in a commit message.\nThe docs say,\n\nThe name of the character set to use as the default character set.\n\nWhat does setting the default charset actually do? Does mysql use that when you don't specify the charset in a create table or create database call? Or some more magic?. Maybe also give the error_code to avoid making this branch less of a potential heisenbug. This is a quote from https://dev.mysql.com/doc/refman/5.7/en/mysql-init.html :). Might be user facing, I'd add a short description (as 3rd param). (Or turn into debug_assert instead). I'd add a comment that this is the error case that https://dev.mysql.com/doc/refman/5.7/en/mysql-init.html documents, trusting it's actually the only case where NULL is returned.. :trollface: . Maybe also\nassert!(ConnectionOptions::parse(\"/lol_no_schema/at_all\").is_err());\n\nActually\u2014how do you connect to a socket?. Ok, cool. I wasn't suggesting not setting it; always make sure to get utf-8\u2014sorry, i mean utf_real_8\u2014if you can \ud83d\ude04 . Yeah it was meant as a sanity check. If you feel like it, you could add socket:// and file:// as Err cases.. You know I link links. Can you add some? Let's say, three?. Sorry, what I meant to say was that I link likes! :D. I'd consider making it a free function\u2026\nrust\nlet bro = &self;\nu_mad(bro)?;\n:trollface: . This does some weird things. I think this is the place where I write\n\nCan you add a link to https://dev.mysql.com/doc/refman/5.7/en/mysql-set-server-option.html?. In the section starting with \"The following procedure outlines a suggested strategy for handling multiple statements\", https://dev.mysql.com/doc/refman/5.7/en/c-api-multiple-queries.html talks about how you need to write a loop that calls mysql_next_result to actually get the results for multiple queries. Especially, it says\nFor each iteration of the loop, handle the current statement result, retrieving either a result set or an affected-rows count. If an error occurs, exit the loop.\n\nHow would you interpret this? Do you maybe need to iterate the results to get all possible errors? (Currently, you are only calling did_an_error_occur after the initial execute and when setting the options.). Sounds good. Wasn't sure if \"not getting all errors\" is part of \"all kinds of nasty side effects that may blow everything up\" ;). Seriously, use ffi::enum_field_types::*;. Might be easier to read like let (types, data): (Vec<MysqlType>, Vec<Option<Vec<u8>>>) = \u2026 instead of turbofish. What is the semantic meaning of the None case here? https://dev.mysql.com/doc/refman/5.7/en/c-api-prepared-statement-data-structures.html doesn't mention what a Null pointer means here. Is the None case only relevant when calling mysql_stmt_bind_result() and getting a SQL NULL result?. I think this is one of those functions that look far nicer using ?. > my_bool \u2013 A boolean type, for values that are true (nonzero) or false (zero).\nYou expect there to always be one byte, right? (Since BOOL is stored as TINYINT(1).) Just to be sure, you could do not_none!(bytes).iter().any(|x| != 0).. I'm so glad that Vec::new promises not to allocated here. I think this could be 0_u8 as later on you treat as a my_bool (or actually point to it as a my_bool*). Beware of wrapping behavior vs. overflow in release mode (play)! Should probably make sure that needed_capacity >= written_bytes before calling reserve. Might be interesting to see if changing this from Struct-of-Vecs to Vec-of-Structs would make the code below simpler. Why can you use unwrap here without fear of panicking? (I see you construct this with Some above but am not sure the data stays untouched). Memo to self: Keeping pointer to buffer alive is now our responsibility. is meaning here is column_index. Usual garbage return value\u2026 nonzero = error. Okay, I'm probably too tired to see this. Can this set_len leak memory? Can you use truncate instead? Is this what you meant earlier? (The docs don't say much about truncate but it's source uses drop_in_place which may call destructors we don't want to run.). Same with truncate as above. Memo to self: Continue from here. That's it, I'm going to bed \ud83d\ude06 . You seem to like enum_field_types ident. And it's a fine ident, I give you that. But you could go one step further and glob import it. . Memo to self: IIUC, ptr:.as_ref generates a random lifetime, which just so happens to be called 'a here. I wonder if we can constrain this lifetime to be more meaningful. I think I've seen that once before in some other crate that also deals with reusing buffers in iterators but can't find it right now. The best I can find on \"streaming iterators\" is this thread on u.r-l.o which links to this post on /r/rust.. Okay, as best as I can tell this is indeed safe. The iterator may yields elements whose lifetime is shorter than advertised, but there is no case (going through results, build_from_row, build, from_sql) where the buffer's data is accessed after the next next call.. I'd probably calculate the indices up front in the range ((self.col_idx .. self.col_idx + count)) which, to me, is easier to read.. LGTM. LGTM. Fine. You win this ti\u2014 wait! Not so fast! You can still use self::ffi::enum_field_types as t; to reduce all the visual noise ;). Heh, life can be so simple. for_input is only ever used here. I'd change it to take a tuple and use UFCS.. (Memo to self :This catches truncated_amount == 0, underflow already triggers an assert in debug). \"typically\" with y. I think it's also \"in migrations\" (instead of \"on\").. \"Brings the ability to\" doesn't really add anything here, and removing this part of the sentence make the rest a nice headline. I'd put the sentences in separate paragraphs too, as the first one can serve as summary and second one is an example.. This is better, but still too many words for too little information. No need to make it longer than necessary \u2013 technical documentation is typically very terse. How about\n\nPerform simple operations on a backed.\nThis is used for migrations.. Same here, you can leave out \"Provides functionality to\". not(any(feature = \"sqlite\", feature = \"mysql\"))?. This whole determine_column_type function got even weirder just now. Pulling it put might be a good idea. While you're at it, can you also add a test or two for its behavior (detecting arrays, things likeint(11), and the combination of the two if applicable)?. Make that a MEDIUMTEXT and add a test which adds exactly 64k+1 bytes of text :trollface: . I hope no one ever uses a name with \u2265256 chars and sees a weird error.. Sanity restored. \u2714\ufe0f . Nah, just have a test and a noncryptic error message. Maybe. Later. It's not critical.. FTR, don't compile these tests with panic=abort.. I've seen a few lines like these in the last few days. Maybe it is time to add the glorious boolinator as a dependency?. Memo to self: Open clippy issue for denying unwrap (and other panic-able fns) in drop. I'd love to see a Cow here. Not really important for the overall picture though.. For consistency, you might also want a test for detecting integer underflow. I just assume that the actual format is always (?P<tpe>\\w)+\\((?P<len>\\d)+\\), i.e., there is a closing bracket, and len is always a non-empty string. Validating that should not be our tasks here though. Let's just deal with what MySQL gives us. (So, this is good as-is.). For symmetry, I'd add at least copy the tests values_which_already_map_to_type_are_returned_unchanged test from mysql and add one for detecting arrays.. Do you want to add a comment to this? Calling set_len twice might be confusing.. s/t/_t fixes ci. This is only about doc comments, and which CamelCasel-looking things to allow to be used without putting them in back ticks.. Indeed. This is to enable additional lints which are allow by default.. Only the screen that shows errors! \ud83e\udd23 . Huh. Does it have a special case for null but not null_mut?. That's a good reason. I'll allow the lint here (and add a link to the pg code). Sure. Good idea. Where should I put that?. Hm. I'd probably call this 'extras'. Is Quickcheck useful for anything but our tests?. Actually, if we put that in the root directory, how can we make sure the include!d file gets, well, included in the cargo package artifact?. Hm, ^0.0.X should be equivalent to =0.0.X IIRC. But better safe than sorry! \ud83d\ude05 . i think .map(Result::is_some) reads nicer. dito. droppin da bass. rustc y u no infer me happiness. Just as a sanity check, I'd always put a assert_eq!(0, connection.statement_cache.len()); (or actually assert!(connection.statement_cache.is_empty());) at the top (same below).. FTR, this is the \"real\" diff:\n\n```diff\n--- impl<'a, ST, QS, DB> QueryFragment for BoxedSe\n+++ untitled (Current)\n@@ -1,14 +1,10 @@\n-impl<'a, ST, QS, DB> QueryFragment for BoxedSelectStatement<'a, ST, QS, DB> where\n+impl<'a, ST, DB> QueryFragment for BoxedSelectStatement<'a, ST, (), DB> where\n     DB: Backend,\n-    QS: QuerySource,\n-    QS::FromClause: QueryFragment,\n {\n     fn to_sql(&self, out: &mut DB::QueryBuilder) -> BuildQueryResult {\n         out.push_sql(\"SELECT \");\n         try!(self.distinct.to_sql(out));\n         try!(self.select.to_sql(out));\n-        out.push_sql(\" FROM \");\n-        try!(self.from.from_clause().to_sql(out));\n     if let Some(ref where_clause) = self.where_clause {\n         out.push_sql(\" WHERE \");\n\n@@ -24,7 +20,6 @@\n     fn collect_binds(&self, out: &mut DB::BindCollector) -> QueryResult<()> {\n         try!(self.distinct.collect_binds(out));\n         try!(self.select.collect_binds(out));\n-        try!(self.from.from_clause().collect_binds(out));\n     if let Some(ref where_clause) = self.where_clause {\n         try!(where_clause.collect_binds(out));\n\n@@ -39,7 +34,6 @@\n     fn is_safe_to_cache_prepared(&self) -> bool {\n         self.distinct.is_safe_to_cache_prepared() &&\n             self.select.is_safe_to_cache_prepared() &&\n-            self.from.from_clause().is_safe_to_cache_prepared() &&\n             self.where_clause.as_ref().map(|w| w.is_safe_to_cache_prepared()).unwrap_or(true) &&\n             self.order.is_safe_to_cache_prepared() &&\n             self.limit.is_safe_to_cache_prepared() &&\n``.TypeIdis as large as oneu64, whileSqlis 6usizes. I'd be surprised if it matters perf-wise even in large apps but you mentionedType` should be the hot path anyway.. Good idea \ud83d\udc4d . Is this one of the things where we'd like to have https://github.com/rust-lang/rust/issues/32409?. Did clippy not suggest to derive Default here? Maybe because of the type bounds?. Thanks for testing clippy! :trollface: \nerror: item `connection::statement_cache::StatementCache<DB, Statement>` has a public `len` method but no corresponding `is_empty` method\n  --> src/connection/statement_cache.rs:29:5\n   |\n29 |       pub fn len(&self) -> usize {\n   |  _____^ starting here...\n30 | |         self.cache.borrow().len()\n31 | |     }\n   | |_____^ ...ending here\n   |\n   = note: #[deny(len_without_is_empty)] implied by #[deny(warnings)]\nnote: lint level defined here\n  --> src/lib.rs:7:9\n   |\n7  | #![deny(warnings, missing_debug_implementations, missing_copy_implementations)]\n   |         ^^^^^^^^\n   = help: for further information visit https://github.com/Manishearth/rust-clippy/wiki#len_without_is_empty\n(This was okay before as it was #[cfg(test)]). I hadn't as you refactored bin/test for mysql at the same time. Gimme a sec to add it. We should immediately open an issue after his PR is merged to actually track this \"short term workaround\" and discuss alternatives to not let it become a \"permanent temporary solution\".. Maybe put that in a macro unsafely_coerce_types!(now, Timestamptz)?. Why'd you move that out of the closure? Does borrowck not let you access this otherwise?. This is pretty much unparsable to me. Maybe format it like this?\n```rust\ntype Table = self::__diesel_schema_migrations::table;\ntype Version = self::__diesel_schema_migrations::version;\nimpl<'ins, 'a, DB> Insertable for &'ins NewMigration<'a> where\n    DB: Backend,\n    (ColumnInsertValue<\n        Version,\n        AsNullableExpr<&'ins &'a str, version>,\n    >,): InsertValues,\n```. Can you try not to break the line here? I'd split this up into\n```rust\ntype NullableColumn = AsExpression::<\n    <<#column as Expression>::SqlType as IntoNullable>::Nullable,\n\n;\n```\n\nand then use NullableColumn::as_expression(value). Can you try not to break this at as and ::? It's really hard to read this way. Using the Table alias from abovem you could write\nrust\n(ColumnInsertValue::Expression(Version,\n    AsExpression::<\n        <<Version as Expression>::SqlType as IntoNullable>::Nullable,\n    >::as_expression(version)\n),). Pls don't break at as. See above.. Can you use block ident? I'd write this as\nrust\n\u2026\n.with_predicates(\n    model.generics.lifetimes\n    .iter()\n    .map(|l| {\n        syn::WherePredicate::RegionPredicate(\n            syn::WhereRegionPredicate {\n                lifetime: l.lifetime.clone(),\n                bounds: vec![insert.lifetime.clone()],\n            }\n        )\n    })\n)\n.build();\n(Also note the space before { and trailing comma in WhereRegionPredicate). Trailing commas are good :). Trailing comma. \u2702\ufe0f . I'm a big fan of type aliases btw. They can be used to make nice \"reverse\" associated type accessors like this (IIRC):\nrust\ntype SqlType<T> = <T as Expression>::SqlType;\ntype Nullable<T> = <T as IntoNullable>::Nullable;. It's super weird to use this variant. It's in a test though, so I can see why you did it instead of introducing an arbitrary new variant.. I'm not familiar with Postgres' binary interface, so this is one of the places where I'd really like to have a link to some semi-official Postgres document that says \"-1 is null here\".. This test helper fn should probably also use RollbackTransaction. Nice docs. While you're at it you could also add a sentence or two to the other variants (even if just to say when this error can occur) :). Yes! It even points to something with postgres in the name! Perfect! \ud83d\ude04\nNo, but seriously, it helps see where this comes from (and where to look when something changed).. I was gonna suggest .cloned().unwrap_or_try(\u2026) but then remembered that what I just called unwrap_or_try does not currently exist. Until then this match is cleaner.. > inherit this from their children\nOnly noticed this now. Nicely put, will make people used to classical OOP with inheritance nervous, though \ud83d\ude04 . I'd add let source = users::table.select(sum(user::id)); (with no error) to prevent false positives.. Huh, was this ever used for anything?. Still true?. \ud83c\udf89 . I know we talked about this at length but I' still looking for a version that is just one bit nicer. Good for now, though. (I think std should have more try_ methods. try_into is a thing, and try_map, try_unwrap_or_else, et.al. should be too). I'd probably rename f to mapper. This is how I program in C, too! Add & and * until it works :trollface: \nFTR, this deref's the RefMut, then its content, and returns a reference to that.. I assume Rust doen't let you to continue to use StatementIterator::new(statement_use).collect() because temporary vars with too short a scope?. Why put that attr above and the derive below the doc string? No, wait, let me guess: Because doc strings are in fact #[doc=\u2026] and you wanted it sorted alphabetically? \ud83d\ude04 . You can probably derive(Default) this. Indent. Indent. Nicely done. It's the first line in the rendered docs and it's indented, that's why I asked.. Yes. I'm stupid. Ignore this.. I don't think this comment adds much to command(\"setup\").run. Can you write it like this?\nrust\np.create_migration(\n    \"12345_empty_migration\",\n    \"\",\n    \"\",\n);. Their reference says it means \"disable automatic builds\" but\u2026 what are \"automatic builds\" in this context? Is this about creating artifacts?. Drive-by comment: Actually, the macro is called __diesel_column!. I'd refactor this whole comma needed business with a simple MaybeComma enum instead of a bool: https://gist.github.com/killercup/e57f3f1cd83531a88510512fa2f634d4. We should probably add some (module-level) docs here. At least for contributors looking to understand diesel's inner workings. Like this maybe.. Clippy wants you to put lc_monetary in back ticks (see travis ci). Also, any reason you link to the 9.1 docs instead of more recent ones? Was this added in 9.1?. If you really need the external dependency, please use it as a feature flag itself instead of adding in to the postgres feature (not everyone will need to use these types).. What does this offer that std::net doesn't provide?. Is AF_INET actually always 2 on all architectures we support? Or does Postgres define these constants as literal integers as well? (Please add this as comment as well). The v4 code above I can follow, but I'm not sure what happens here. What's the c fn for? What format is bytes in? Is this the serialized inet_struct? Given that this is an char array, there's no need to care about endianess. And std::net::IpAddr implements From<[u8; 16]> as well as From<[u8; 4]> (for Ipv4).. Add some back ticks?. h3 after an h1. yay! i'm famous! (poor Tess). \u26a0\ufe0f Spoiler alert! \u26a0\ufe0f (There is no do_update yet). No do_update :(. (I think I forgot to add #[must_use] to this earlier). Probably wants to have #[must_use]. We should write a How To Read Diesel Type Parameters, featuring:\n\nF as From\nS as Select\nD as Distinct\nW as Where\nO as Order\nL as Limit\nOf as Offset\nG as Group By\nand the audience's favorite DB as Database Backend (not to be confused with Db). (This way it's easy to see S missing here). (I didn't add these as the crates are explicitly run with the clippy feature on CI anyway.). s/ot/to. Maybe add a line about caring about nullability to the docs (esp. as this is a subtrait of AppearsOnTable now)? Actually, to be really explicit you can still keep Expression as supertrait (it's referred to in the docs).. The most important stuff first: In this case \"greatest\" should be capitalized as it's part of the title \"{Sean,Tess} the Greatest\" (same as in \"Alexander the Great\") \ud83d\ude09. Convention in std is to always write \"Examples\" (plural). (Not important and we should probably define some doc comment rules before changing stuff like this. Also, I'll write a Rust RFC on that\u2026 soonish). Obligatory docs link: https://dev.mysql.com/doc/refman/5.7/en/sql-mode.html#sqlmode_pipes_as_concat. Nah, it's fine. Mentioning the relation to AppearsOnTable might've been nice, but it's a supertrait, so people should look at it anyway (and it has good docs).. Might be easier to convert them to HashSets and call .difference().len() == 0.. Yeah, I think that code has been there the first time I looked at diesel. I'd absolutely continue to use the abbreviations. F, S, W by themselves are not that intuitive, but if you have ever seen a SQL query, they totally make sense, and it's not worth the code bloat.\n\nMaybe, once I got to Of, I'd've switched everything to two-letter names, though (Se, Fr, Di, Wh, Or, Li, Of, Gr).. Would begin a new paragraph after the first sentence. comma after Bound. > One 'any' ought to be enough for anybody\n\n\u2013 Bill Gates. We can probably add a doc test that actually works by omitting extern crate diesel_full_text_search; and add a hidden mod diesel_full_text_search {\u2026}. Hm, it's not obvious that the syntax with the primary key field is table-name [(id-field)] [using types from (path),*] {}, with the key field after the table name. Also, IIRC, table-name can also include the schema name, but this is not documented here.. Macro changes lgtm. Wait, does this actually panic? It calls i64::add_assign, right? I don't think this is a checked add in release mode!. Maybe add a link to /diesel/fn.update.html. Have I mentioned my personal appreciation for links today? https://en.wikipedia.org/wiki/Create,_read,_update_and_delete. Also, redundant \"with Diesel\" at the end. The sentence already starts with \"Diesel provides\".. s/run be/run by/. s/3/three. Maybe mention that ? is a bind param that get substituted with false (to avoid confusion). Would also add a more complex example that uses all features together.. Oil crisis: Resolved!. empty line above? Also, AsExpression is in scope, no need to write absolute path. This is an h2. For h1, go with =.. Well, with my 4 year out of date HTML5 knowledge I'd expect rustdoc to put that in an <article> :D. Oh, were these genuine bugs that clippy found? (Not really bugs in production user-facing code but still). rustc says:\nenabling unstable features (deprecated. do not use)\n\nSo we might as well remove it everywhere.. Oh, I'm stupid, it's an assert.. So glad you didn't go with \"Seacal\"!. I just want to casually suggest linking to https://www.postgresql.org/docs/9.6/static/sql-insert.html#SQL-ON-CONFLICT here \ud83d\ude04. I think the use syntax (https://github.com/diesel-rs/diesel/pull/779#pullrequestreview-25265816) is nicer. But in any case, it'd be great to document the full syntax; at least with an example that uses everything.. True, that's why I'd mock the \"real\" diesel_full_text_search. Very smooth! \ud83d\udc4d . Your code is nice, I think you can write it a bit more concisely, though. What you are checking is that there is any migration that was not run, right? You don't ever need the list of pending migrations. So, let's use .any:\n```rust\nlet all_migrations = migrations_in_directory(migrations_dir)?;\nlet already_run = conn.previously_run_migration_versions()?;\nOk(all_migrations.into_iter()\n    .any(|m| !already_run.contains(&m.version().to_string()))\n``. (At first I was wondering why you didn't continue to use the full paths here, but then I saw this macro was only ever called here where they are imported anyway.). Can you add an empty line (well, an empty line in the doc comment) above the header? And make it plural (\"Examples\")?. \"Load _all_ users\". I think it'd be clearer if you replace this comment with explicit imports a few lines above (use self::users::dsl::{users, id, name};).Userdoes not exits or is not in scope here. Maybe copy it from another example? (This is why CI is failing, btw.). That users table is just copypasta, right? (Also in the examples below). This will be rendered as an empty line at the beginning of the code block. No need to wrap it in anOk, you already called unwrap :). Do you want to add another test below that has two Steves (and also output the ids) to show how to use order with tuples?. No worries! We're grateful for each contribution :) If it's only minor things (like anunwrap`), I can fix that before merging. Ah, interesting. Let's keep it like this for now then and refactor it later.. Can you change this to expect a doc attr as well? I.e.,\nrust\n/// Title column documentation\ntitle -> Text,\n(I'm not sure where exactly attrs are allowed, but here it seems to work: playground). If this is for cockroach db, it might be a good idea to add a cockroach feature. But that makes it look like we are officially supporting it as a backend. So, well, let's leave it as is.. This vector's length is always > 0, right? Maybe initialize it with Vec::with_capacity(n) where n is a \"usual\" number of digits?. Please the unwraps with expects that include a reason why this is a failure that should be allowed to crash the process, or propagate the error (feel free to crate a new error type if necessary) :). \"[\u2026] PostgreSQL only, requires the bigdecimal feature)\". Please add an empty line above code blocks, and below headlines. Bonus points for adding lang annotations to all code blocks, even though rust is the default (just my personal preference) :). Common style is\n# Examples. This looks more complicated than it needs to be. You can make the chaining a bit easier, e.g. by\n\n\nusing UFCS (str::to_string instead of |s| s.to_string which tells us what type/trait we are dealing with),\n\nand/or by using the \"Option::iter trick\" that treats the Option as an iterator (yielding exactly one value) so you can call flat_map on it (which consumes stuff that can be turned into an Iterator \u2013 including Option and Result!):\nrust\nlet file_name = path_buf.iter()\n    .flat_map(|p| p.file_name())\n    .flat_map(::std::ffi::OsStr::to_str)\n    .map(str::to_string)\n    .next()\n    .expect(&format!(\"Error getting file-name from {:?}\", path_buf));\nDon't overdo this :)\n\n\nOnce thing I missed at first was that path_buf is actually an Option<PathBuf> and the expect at the end also panics when this is None. I'd make that explicit, which allows us to go back to regular chaining without .iter():\nrust\nlet path_buf = path_buf.expect(&format!(\"Migration without valid file name\"));\nlet file_name = path_buf.file_name()\n    .and_then(::std::ffi::OsStr::to_str)\n    .map(str::to_string)\n    .expect(&format!(\"Error getting file name from {:?}\", path_buf));. Can you reorder this a bit?\nrust\nlet already_run = \u2026;\nlet migrations = \u2026.into_iter().map(\u2026).collect(); // Can probably infer type from function return type\nOk(migrations)\nOr, if you want to fail fast when migrations_in_directory fails, just leave that on top and shadow the binding with let migrations = migrations.into_iter\u2026.. Sorry for taking so long to answer. I think it's okay to depend on libc here (as an optional dependency). We already have libc as a transitive dependency when using the time/chrono feature.. I think that's the only place this array formatting is used in this code base. Can you change it to trailing commas and the opening bracket on the same line as the =?. s/test_cases.iter()/&test_cases. As this is also used for mysql connections, can you add a test with examples for that as well?. Can you expand on the intention of this splitting a bit (connection strings using sockets instead of host name by using the query param form)? I'm not sure I can follow this when I see it again in a few month. Maybe also add the \"template\" version of a connection string, and explicitly mention the two forms, one using the user@host/db form, and the other using query params.. Did you duplicate this line on purpose to show it's the same query? (Maybe add a comment like \"Same query as above\"). Maybe \"If [the name of] your\"?. I see what you are doing with the regex, but I think stdout.find(&tag1) < stdout.find(&tag2) is easier to read :). Similarly here. Actually, if you use specific datetimes instead of now, you could compare the whole string (and it'd be more deterministic).. Yeah, good point. Btw, is the output of that TIMESTAMP_FORMAT tested anywhere?. This is fine. But I just can't stop myself from suggesting to use a windows iterator. Which is, as I just found out, only available as a method on slices but not on iterators in std. Are we using the itertools anywhere? I'm not sure this alone is a good reason to add it as a dev dependency, but it'd be really nice to reduce this whole fn to:\nrust\nfor (a, b) in tags.iter().map(|x| output.find(x)).tuple_windows() {\n    assert!(a.unwrap() < b.unwrap());\n}\nPlaypen\nIs tag ever a Regex and not just a literal string? I think str::find suffices here, but I may be wrong. Also, if this wasn't a test but a performance-critical thing, I'd suggest using RegexSet.. This is a breaking change.. FTR, my \"is this public API?\" test: copy fn name, go to http://docs.diesel.rs, search for fn name, #results > 0 == public api. I had no idea what the CIDR type is. Maybe add a link to https://www.postgresql.org/docs/9.6/static/datatype-net-types.html or a similar page?. (Also add a link to INET docs for consistency). Why do you need to explicitly list all the bytes? Wouldn't Ipv6Addr::from(&bytes[4..20]) do the same thing?. Why do you need to explicitly list all the bytes? Wouldn't Ipv6Addr::from(&bytes[4..8]) do the same thing?. I assume this was for left over from debugging?. Maybe extend this (and err!) to also take an optional message. This way, you could make the user facing errors as well as the asserts below more descriptive.. FYI, no need for the inner braces around the closure. I'd probably also split off the Ok wrapping, i.e., let pending = all\u2026; \\n Ok(pending). Nice \ud83d\udc4d . It took me literally half a minute to see what has changed in this line xD. Spell checking sounds like a hard problem to get right in an editor plugin. Just write one that allows you to quickly create Github issues \"check speling\" tagged as \"easy for newcomers\" instead! :trollface: . the .filter_map(|s| s.parse().ok()) could also be .flat_map(str::parse). use ? for consistency :).     PostgreSQL\n    ^. Maybe add a more precise error message here? This is the same as below, so people getting this error and searching for the string will not know which one it was.. Maybe add a more precise error message here?\u00b2. Maybe add a more precise error message here?\u00b3. ftr&cc https://github.com/rust-lang/rust/issues/29864. These are a bit weird to read, but I assume they all basically defer AppearsOnTable/SelectableExpression to the inner thing of Join/JoinOn.. You used ? instead of try! below. Just wondering: On has no constraints, but it will probably always need to be On: Expression. Could adding this here (or in fn join) give better/earlier errors?. s/for/to\ns/could/can. Super unimportant, but can you change this to be actually helpful docs? E.g., \"The table containing all blog posts\", \"The post's unique ID\", \"The post's title\". Huh, is that new? Cool idea! But I can't really see when this happens, i.e., for which syntax. Can you add a compile-fail test and a comment? (Oh, and a space after the colon would be awesome!). Okay I can recognize the comments/sections but the code is quite a lot different. This will take me a while.. Is this still valid? Seems like an important comment for future maintainers.. Can you add comments what these blocks do, like above? (I know there weren't any before but I guess you know what's happening so it'd be awesome to write that down). Please put a space between the ) and the = :). Please put a space between the ) and the = :). cc https://github.com/rust-lang/rust/issues/40872 (for cross linking magic). Do you want to add some more extreme tests? To tests values that exceed u64 and f64?. This'd be more readable if all match arms where on one line (or maybe 2). Can you add a comment here giving an overview of what happens here and why encoding the BigDecimal is a bit complicated?. Same as above, would put that on less lines to make it easier to read. We tend to use ? nowadays. cc https://github.com/akubera/bigdecimal-rs/issues/13 for cross linking fun. Can you\nrust\nfn migration_dir_arg() -> Arg {\n    Arg::with_name(\"MIGRATION_DIRECTORY\")\n        .long(\"migration-dir\")\n        .help(\"the location of your migration directory. by default this \\\n            will look for a directory called `migrations` in the \\\n            current directory and its parents.\")\n        .takes_value(true)\n        .global(true)\n}\ninstead of duplicating the lines?. Casual memo to self to get a CLI logging story together (cc #150). The only diff is the way result is constructed, right? There might be a nicer way to do that, but probably not without adding a testing framework like the rspec crate\u2026 (I tried to write a simple macro but couldn't get it to work after a few minutes). I think it's time to add a\nrust\nfn diesel_type(t: &str) -> Vec<String> {\n    vec![\"diesel\".into(), \"types\".into(), t.into()]\n}. ?. Finally, after all this diff noise, this is where it gets interesting!. Sorry, that comment doesn't really add anything here. I like these methods that are no-ops for most variants, by the way. Assuming rustc can track which variant we are looking at, this should also be an easy target for dead code elimination.. Nice win for readability! I'd probably add a unit test for that, but it's simple enough that it's not really necessary (and it's tested in a whole bunch of other tests anyway). I'd put the second sentence in a section with a # Safety heading. So, after reading this I was immediately wondering if I could use bind multiple times. I think this should be part of the docs.\nAnd I know this will add a bunch of copypasta code but I'd split this up into three or four examples: {non-postgres, postgres} \u2a2f {single bind, multiple binds}. Maybe a # PostgreSQL syntax section with a sentence explaining that this is backend-specific and the two examples with $n instead of ?.. Oh, is this syntax in stable yet? If so, only very recently. This probably bumped us off to \"only works with 1.17+\".. Does this actually work? This is rendered on the /diesel/expression/dsl/fn.sql.html page, right? And bind is on /diesel/expression/sql_literal/struct.SqlLiteral.html#method.bind. Would look real pretty without the colon but an empty line below it. We usually put the else just after the }. Someone should write an RFC for automatic linking in rustdoc! :trollface: . No. Those are wrong. There are no colons after headlines when the headline actually printed as a headline. That's just as bad as people who put a space before an exclamation mark\u200a! It's not even correct to do that in French because there you use a thin space or even a hair space\u202f\u200a! Typography is art!!11one </rant> \ud83d\ude06. Hm, to make the API docs look nice, I'd combine the first two sentences to \"Creates an insert statement with default values\" and put the rest on a separate paragraph.\nWould be cool to move the non-returning test from below here.. Awesome! This'll be helpful for people following function signatures in the API docs.. Not in this PR, but maybe in the future we should add examples to these incomplete methods to show them used in context. Or at least link to where they are used in context.. True. We should think of something to make it easier to write these doc tests (and maybe also write it down somewhere). Is this the best error we get? No \"cannot derive Insertable for struct with no fields\"? doesn't matter, should be a new issue in that case. Created #920. Can you add some back ticks around the column and type names?\n\nmore efficient anyway\n\ncitation needed? \ud83d\ude09. What do you think of rephrasing that to\n\nFailed to derive Insertable for {}: Insertable cannot be used on structs with empty fields. \u2139\ufe0f Peano numbering for Plus.\n\nMaybe add this as comment headline in the source?\nMaybe move trait Plus definition here as well? Put it all in one file/mod?. \u2139\ufe0f Count occurrences with peano numbering. Once is the initial value used in impl ContainsTable<table>.\nMaybe add \u2191 as doc comment?. \u2139\ufe0f Tracks how many times a table occurs in QuerySource (from/join clause)\nMaybe add \u2191 as doc comment?. \u2139\ufe0f Constraint D: Table T occurs on left side of join one more time than on right side\nActually, why is that?. \u2139\ufe0f Expose inner count in JoinOn wrapper. \u2139\ufe0f Constraint A: Can only select column if column's table occurs exactly once in from/join. \u2139\ufe0f Constraint B: Can only select column when column's table appears on left side of Left Outer Join and not on right side. \u2139\ufe0f Constraint C: Can only select column when column's table appears once on either left or right side of Left Inner Join. Why use the same name for the type param as for the struct?. \u2139\ufe0f Right side of left inner join does not contain table on left side. Yep, it's one of those errors we should cover in the docs. Or, you know customize.\n(Also, shouldn't Succ<Never> be Once? Sadly not doable without specialization I guess). Ah, that makes sense. (I added the question today, but wrote the comment on Saturday). Can you add an example here? Doesn't even need to be doc test, just something like enable_multi_table_joins!(users, posts);. (This could also be a doc comment). This will stabilize on 2017-06-08 in 1.18.0 FYI, maybe add a fixme if this is the nicer way to do that?. Can you give this a short doc comment mentioning the purpose (in contrast to AppendSelection) and the impls in impls/tuples.rs?\nI would probably like to add some tests (aside from the integration tests) but I'm not sure where best to put that and how to only test this without writing a whole bunch of impls\u2026 so, yeah, I'm good with not testing this right now \ud83d\ude05 . I think I found a great new test case for rustfmt\u2026. Good change \ud83d\udc4d. alternatively records?.into_iter().next().ok_or(Error::NotFound). Not necessarily today, but this method could use some docs. Doesn't LoadQuery already imply LoadDsl? Or is this one of the points where rustc plays dumb?. \"Both types\" means \"the annotated struct and the parent\", right? Maybe write that out?. Eh, nice docs and all, but\u2026 \u2191. Maybe link to the joinable! docs (once that macro os no longer hidden in the docs)?. Period.. > See the [source of]. Period.. Period? Period.. Gives a whole other meaning to 'should'. This confused me for a second because id and ip look very similar \ud83d\ude04 . We usually use reference links in docs, but it's fine. No need to change this.. Good test case, but this can only check if the macro parses doc comment, not if it gets output again, right? Should be good for now, though.. Yeah, either running rustdoc and checking the html, or running something like cargo-expand and comparing its output.\nI'm actually a bit surprised I couldn't find a crate for testing macros. Something like piping cargo rustc -- --pretty=expanded into syn (at least its tokenizer) and comparing that to some quote!ed expressions. That may be an interesting project in itself.. A follow-up PR could link some easily identifiable types to their docs. I think these version constraints are not useful without upper bounds (see uuid).. From what I can gather, the num crate includes num-{bigint, traits, integer} by default. What's your reason for (a) nor just depending on num, or (b) depending on num at all? You don't even use extern crate num; below.\nFWIW, it seems that bigdecimal also depends on num and num-traits, and we should try to use the same versions.. This is good, but I fear the wall of text my scare people who do not want to report a bug. Maybe we can add something like this at the beginning?\n\nIf you want to report a bug, we added some points below you can fill out. If you want to request a feature, feel free to remove all the irrelevant text. In addition to this issue tracker, you can also talk to Diesel maintainers and users on Gitter.. Good catch! Fixed in 1ad6ad8. Isn't it \"set up\" and \"book keeping\" here?. This right here is all I ever wanted! \ud83d\ude0d. This right here is all I ever wanted! \ud83d\ude0d. Just cosmetics, but can you change it to \"MySQL\" and put the type names in back ticks (like `this`).. Same as above. Is the Deref impl used anywhere? I don't see it and given the indent of making this future-proof I'm not sure this is the only valid impl we could come up with (right now it's fine though).. Can you add a comment here why unsafe is required and why the new constructor returns &Self\u2014which is pretty unusual? (I guess it's because you want PgMetadataLookup to appear to own the connection, as it's apparently only ever used via reference). When is this used? Would it make sense to also output something about the metadata_lookup or is it expected to always be the same as out's debug formatting?. Future-proof this even more against diff churn with ... self } instead of listing the other fields (like metadata_lookup here). Ok, fin\u2014 Well, actually I get only 3 errors when removing the impls which are all from the Array which assumes out to be slice-like thing, and all other method calls on out are part of the Write impl (or rustc just gives up when after these errors, I can never tell).\n\nNo, seriously, it's fine.. Generally a good practice, which I try to follow as well. unsafe makes me question these practices, though :) I guess it's okay in this case, as its intend is pretty clear and the implementation obvious (\"oh hey compiler, this PgConnection reference is now a PgMetadataLookup reference\"). I was more surprised to see a new method that returns a reference, though!. Make sure to cargo install rustfmt-nightly which is the version with all the latest changes. (Or better yet, cargo install --git https://github.com/rust-lang-nursery/rustfmt directly) . Good example :+1:. trailing comma. Do we have a macro for these impls?. I'm very skeptical of suggesting to use brew as not everyone is using macOS, and even there, there are other ways to install it (even though I use brew myself and would recommend it).. Ah, thanks! We apparently totally forgot to mention this here!. This works? Interesting! I've only ever seen the space-separated \"postgres sqlite mysql\" syntax, which is also what cargo install --help mentions. Where did you see this?. Please note the quotes so it's seen as one string argument: cargo install diesel_cli --force --features \"sqlite postgres\" --no-default-features. I'd put \"0 rows = error\" in its own paragraph. This made me grep the document for mentions of AsChangeset. I'd probably add some subheadlines to make it a bit easier to scan the texts.. Would be awesome if we could link to a guide that covers load, but the API docs should suffice for now. I'd add an intro sentence like\n\nIf you've followed the Getting Started guide, you've already used some of Diesel's tools to work with database schemas.\n\nto set the expectation that people should already know when to use these macros and where to look for more basic info.. > is a macro that diesel_codegen provides for the backends you specified in your Cargo.toml.. Put \"skip if starts with __\" on its own line, maybe a note block. Maybe add a summary of the relationship between the macros, like\n\nSo, infer_schema! generates infer_table_from_schema! calls, and infer_table_from_schema! in turn generates table! calls.. Would move this whole paragraph below the next one and maybe even into a note block. maybe also link to https://github.com/dtolnay/cargo-expand (which rustfmts the --pretty=expanded output and even supports colorized output). I can't help but ask \"why\" :) maybe add a little sentence on only exposing certain items?. \"This is the [unit] struct\"\n\nI'd actually like to link to official docs or even just a blog post about using unit structs but I couldn't find one.. Replace second \"Each of [these] will\" with \"They will all\". Explain where types like Integer and Text come from? (or did you mention diesel::types anywhere?). \"and not [just]\". Move last to sentences to own paragraph, maybe even note block. I just wanted to give an alternative sentence structure that is a bit easier to read IMO. Took a second to comprehend what you meant by \"is a macro when you have enabled \u2026\"\nMaybe just add \"(only available if you enabled at least one backend)\"?. My first thought was something like\nsql\nSELECT * FROM users WHERE id = ? -- binds: [1]. Woah, please teach us this extraordinary vim-fu so we too can reduce test cases like this to one-liners :trollface: . Can you put \"dotenv\" in quotes?. This is fine, but if we're already editing this, I'd probably replace the \"use strings\" with something like \"correctly substitute strings starting with dotenv:\". Good intuition to not expose too many internals!\nBut\u2026 Hm. Dotenv reads environment variables (from the actual environment and from a .env file). The dotenv:FOO syntax means \"replace this with the environment variable FOO\". So I'm not sure what it could be doing if it's not substituting a string \ud83d\ude05\n\"Interpreting\" is good, too, but a bit vaguer. I like that it anthropomorphizes diesel_codegen a bit, though! :)\n#typicalTuesdayBikeshedding. What next? Did you mean take?. This link depends on the way rustdoc adds ids to certain elements on the page. I don't think this is public API and will work in future version of rustdoc. But let's keep it for now and hopefully just upgrade to glorious intra-rustdoc links later!. \"\u2026as constructed with get_result\". \"[be] divided [by]\". Sorry, more context:\n\nBy default, Diesel treats 0 rows being returned from a query that expected to return 1 row (as e.g. constructed with get_result) as an error.. Swapped the last two! (1114 is Timestamp). We just talked about this, so I know that for some reason this needs to be used in this way, but otherwise I'd have guessed that at least one of those calls to self.consume_current_result was a copypasta error\u2026 Can you add a short comment citing some mysql doc/source and say that this is on purpose?. This is not actually unsafe to call, is it? (I'd keep the unsafe section as short as possible). Same here. Would only put the ffi call in an unsafe block. Can you name these \"compile-success assertions\" by making them let statements? E.g., let _can_select_columns_from_join = posts::table.inn\u2026 (or a better name). pls add space before { (sorry my brain zooms in on inconsistencies like that). Please add empty lines before each of the above items where missing. Can you put diesel's derives last? Or\u2026 sort them alphabetically? Or anything that I can identify as 'order'? Or reveal the system you ordered them by? :D Sorry for commenting on all the nits. \u2702\ufe0f . The macro may return (), but in other tests we always append a ;. So as this is only ever used in its negated form, I'd change to filtering.check(&table_name) (which does the opposite). Huh? I thought \"statment\" was the process of calling stat?. Huh? Are we now pro Juction, Texas?. Huh? I thought that was a portmanteau of indent and intend.. Huh? I thought this was meant as \"current-y\" as in \"stream-like\".. I was about to suggest calling this filters (plural) because it's a Vec, but I guess in English 'filter' also means a composite of multiple filter-functions that filters stuff using a multitude of criteria.. This compiles without the .as_ref().map(|s| &**s) dance. Itertools has one on Iterator<&str> IIRC, but it still allocates. Which is totally not a problem because this a CLI app and if that turns out to a bottleneck\u2026. FYI all the stuff in the mod above could also be defined in this fn. Can you instead add those to you global gitignore file?. Nit: Is the name of the programming language we use written as proper name with a capital letter at the start or is lowercase okay? This looks wrong.. Hm. Should the comment be above or below the attr? Intuitively. I'd say above.. \"Type Y\"? What's the \"y\" for? (Personally, I'd of course change it to Typey McTypeface!). How about we use .get here and ~~fail gracefully or~~ panic with a custom message like we do above?. Can you make this a relative link so it works on https://docs.rs/diesel/0.15.2/diesel/pg/types/sql_types/struct.Json.html\n\n(I know this linking in Rustdoc is hack-y, I wrote an RFC for it \ud83d\ude04). Yep, as mentioned in the commit message, #1080 made this obsolete :). I would've made it a regular fn but the first arg would've always been format!(\u2026), so I made it a format-like macro. Raw strings to the rescue!\nrust\nr#\"#[sql_name = \"{}\"]\\n\"#. }  else { pls. remove empty line or move above quote! line. Use format! here just like above?. I'd use writeln! here and write! in the <Joinable<'a> as Display>::fmt method. Can't help but notice the redundant comment that is also spelt wrong (should be \"is set up\") which was successfully cargo culted into every single test case \ud83d\ude06. I see you're using rustfmt style now. I'd put the first two args on the first line, but whatever. While writing a test for that, I noticed the output types are always Timestamp here: https://www.postgresql.org/docs/9.6/static/functions-datetime.html. Ha, I've added the exact same thing locally to test something but didn't refactor anything so I didn't push it!. explain/link to explanation of CRUD?. I'd put the derive(\u2026) in back ticks, and make the link a ref link so humans can better parse this :). That last sentence might be confusing, because the Queryable trait does not add these methods. But I'm not sure how to better express this without an aside on how ExecuteDsl and LoadDsl are implemented\u2026. back ticks around Queryable, Row, maybe also User. 2 spaces indent missing?. That comment is good, but you can also just annotate the let binding and give it a speaking name:\nrust\nlet users_result: QueryResult<Vec<User>> = user.load(&db_connection);\nThis even gets rid of the turbofish (::<User>)\nIf you want t talk about the QueryResult type, use that, and maybe even add\nrust\nlet users = users_result.expect(\"Error loading users\");\nOtherwise, change it to let users: Vec<User> and just append the expect.. Where should the ^^^^ be? Underneath load? Seems a bit off, at least in Github's diff view. Do you want to talk a bit more about how to parse that error message? I don't think it's necessary, but I talked a bit about that here, feel free to adapt/copy it.. \u2702\ufe0f empty lines here and at the start of the code block. \"zero-cost abstraction\" with only one dash.\nAlso: Is code generation/macros a zero-cost abstraction? https://blog.rust-lang.org/2015/05/11/traits.html quotes\n\nWhat you don\u2019t use, you don\u2019t pay for [Stroustrup, 1994]. And further: What you do use, you couldn\u2019t hand code any better.\n\nSeems ~~abstract~~ ambiguous to me in this case. Same as above, derive in back ticks, ref link style link.. Also, maybe \"Adding\u2026 to\u2026\" instead of \"Using\u2026 on\u2026\" here?. How about:\n\nYou may pass a reference to a single struct to insert a single record. Pass a Vec or a slice to insert multiple records at once.. Id field name is typically lowercase. Other than id, timestamp fields like created_at and updated_at are also usually omitted in the Insertable structs. Nice touch with the lifetime!. Add empty line below code block. > which is why this constraint is reported to us.\n\nCan you make this a bit more\u2026 approachable? An extreme way might be:\n\nSo, when you pass it something that is not Insertable, Rust gets confused and asks for your help to make it work.. > enable  us\n\ndouble space\nAlso\u2026 this whole sentence is confusing. And using the macro is cheating! \ud83d\ude1d . \u2702\ufe0f  empty lines at start/end of code block. (Will continue to review from here later). Historically, people seem to like the name 'turbofish' more than its look. I personally prefer variable type annotations more than putting a turbofish at the end of a long chain of method calls, because you put the name right next to the type. But others may disagree, as the turbofish version of something like .load::<Post>(&c) or .parse::<i32>() can be read quite nicely as \"load posts from connections\" or \"parse this as an integer\".\nYou know what? I'll open an issue on the fmt-rfcs repo. Edit: Done. Will need \"--with-docs\" as argument on master!\n(And this is something bors would catch too). Nice test table, and Imma let you merge it, but\u2026 while self in pub do true super move. Pff, just double quote them all. stray back tick\nAlso, i'd use ref links everywhere, i.e.\n``markdown\nUsing the [#[derive(Queryable)]`] trait annotation on your model struct allows records to be queried from the database.\n[#[derive(Queryable)]]: http://docs.diesel.rs/diesel/query_source/trait.Queryable.html\n```\nwhich make this easier to read and catch syntax stuff like that. Hm, side effect is quite loaded, even in quotes. Maybe\n\nQueryable doesn't directly provide these methods, but the traits these methods come from (and that part of Diesel's prelude) require your type to implement Queryable.. Maybe combine these four sentences with conjunctions? They read like separate yet similar lists of facts.. value (or error)\n     ^\n. \"tuple[s]\". Maybe write that quote from the error message as block quote?. You can omit the std::string::s here. IntoInsertStatement in back ticks. Doesn't that conflict with\nIf your table's primary key is named differently, you can annotate the table with the attribute. now we can actually merge it. memo to self: read up to this section. > make your development easier\n\nit that something people say? Would've gone with \"make your code more ergonomic\". how about \"Usually, you don't want to change\u2026\". \"probably won't have\" -> \"don't want to have \u2026 here,\". Maybe even add the following somewhere? I don't think we ever wrote that down somewhere prominently:\n\nIt's considered good practice in diesel to have one struct per \"usage\". E.g., one struct to query users, one to create new users, one to change just the email, etc. This often corresponds to the way applications access the database. Don't be afraid to have multiple structs per database table\u2014they are not like the classes that correspond to tables 1:1 in other ORMs.. I think you meant to write a link here. > This section will review to how implement\n\nAll your review are belong to us. s/be /. belongs_to in back ticks\nOh, and add a verb somewhere, e.g. \"must\" ;). Yeah you can probably replace the last 37 lines with ellipses. Btw, is there a note about this mysterious cargo expand anywhere? I'm not sure many people know of it. I you use the \"let's just update the name because email requires double opt-in\" use case it makes more sense because then the struct is not the same as NewUser :). Ah, forget it, you can't show the Option<Option<_>> then. Sorry, commented too fast.. As this is a cold path (I hope!), can you make the error message a bit more elaborate to make this easier to debug? Something like .ok_or_else(|| format!(\"Cannot parse this date: {:?}\", mysql_time).into()). Wow, that works? Nice!. Now that is just awesome. That's pretty\u2026 noisy code with many ref/mut/as_mut thingies. Do you think let constraints = constraints.map(|mut cs| { cs.sort(); cs }); is better?. Can we link to some docs here? (If we have them). Specify where? Add \"Cargo.toml dependency settings\" somewhere?. Why not copypasta this good message to all other places this PR changes? :). Oh, and this needs to be types::Bool (same for the following VarChars). This is a very abstract thing\u2026 maybe add an example for a concrete instance of this to illustrate what it can be?. in the error message, so users can see how to use table! correctly. I'd probably flip this to if let ColumnInsertValue ::Default(..) = *self { true } else { false } (and maybe even add a method to the enum if we ever need that for another thing).. Apple writes macOS with a lowercase 'm' :). Oh, totally missed the verb here, thanks! I think it should be 'run', though.. Interesting change, I like it. I'm fairly certain the original text of this section (incl. Contributing) was copypasta from a template, though. (There was an initiative to relicense a bunch of code under MIT/Apache2). > as backend databases\nJust an FYI: I think in most other documents we call it 'database backend'. \"Use [the] --features option\"\nOr maybe \"--features flag\"? These parameters are often referred to as \"CLI flags\". I always add empty lines between code blocks and paragraphs as it improves readability a bit (easier to see segments of text) but Markdown doesn't require it. You can also specify multiple backends, so maybe use plural here?. \"command[s]\". Again, I tend to add empty lines between blocks (here headline and paragraph). \"Install add\"? What to you mean? \"Install the following to add \u2026\"?. If you mean for this block (and following line of text) to be part of the list item, I think you need to indent it by at least 3 spaces. > I always think of a \"CLI flag\" as an option that doesn't take an argument\nThat's a good point! I hadn't thought about it before and that totally makes sense. Can you add a space after the //! and before the #? (Same below). So I spend a surprisingly long amount of time reading the wikipedia pages for gasoline and diesel to see what the things that make up the fuel are called\u2026 and all I found was \"component\". Why the escaped quotes?. Hard wrap at 80 cols in total or hard wrap at \"indentation + /// + 80 cols of text\"? I think rustfmt uses the latter (or actually the minimum of the latter and 100 cols). Indeed, that's a good suggestion. That would also help us get rid of all the unwrap (but we'll have to convert them to fmt::Errors which dont carry any information). I'd tell people to just run cargo fmt --all, which will rewrite their code to be in Good Style. No need to read diffs :). Good point, that may throw people off when they are new to rustfmt and don't trust it yet. On the other hand\u2026 git diff before/after?\nI only mention this because I have never seen anyone use rustfmt's diff thing outside of CI, but it is a valid feature :). Yeah, three \"doesn't\"s is too much. Maybe:\n\nNote: There are executable SQL queries that do not implement this type. For example, an INSERT statement without a RETURNING clause can be executed, but will not implement Query. This is because it does not have a return type.. add empty line above this doc comment. First doc comment paragraph is the summary line and should not be longer than one small sentence. sql\u2192SQL. ;\u2192,. \"[so] User is the\". period. Add empty doc comment line below this one to make it a summary line. Empty doc comment line below this on. Also, one space should be enough after \"INSERT\" :). period. period. Wait, why are we including sqlite by default now?. Remember to remove the path attr when this is released!\n\nAlso: Can you add a space after the opening brace to make it consistent with the other lines?. If this is automatically included by diesel now, we should remove the\n\nusing diesel_derives. If this is automatically included by diesel now, we should remove the\nusing diesel_derives\n\nsame below in all other instances of this text. Can you add a summary line and then use # Example as headline? This way it shows up in rustdoc as \"Example:\" in some places. Maybe something like\n\nLimit of rows to return\n\nor just\n\nSet the LIMIT on the query. Can we go with \"humongous-tables\"? It fits better as the X in \"large, huge, X\". > based on directional association with other record(s)\n\nwow so many long words and generic singular/plural, it's almost a german sentence :O (I like it). I totally missed this being a //! upper-scope comment as there was no empty line between this and the next line with the mod on it. > Methods in this module\nI know what you mean, but modules don't have methods directly. Maybe\n\nThe traits in this module have methods that generally map to the keyword for the corresponding clause in SQL. Hm. Can we find something other than \"Traits with methods to\" to say this is a thing that contains things to do select things? Maybe\nModule with traits to construct SELECT statements. fair enough \ud83d\udc4d . add space before (. s/&/and\n\nadd space before (. Good advice. Maybe even add something like\n\nIt's totally fine\u2014and often desirable\u2014to have multiple Queryable structs for the same database table.. Hmm, a general note: I think docs like\nThis trait is implemented for [\u2026]\n\nare pretty much worthless for people who know how to use rustdoc. They only appear on detail pages for the trait, and these pages include a list of implementors (see rendered docs).\nBut they may be useful in other places, e.g., tooltips in IDEs; or, when they convey more the indent of which types are expected to implemented this (like in SortExpressionMethods).. You meant //!, right?. This is great! I'm pretty sure people will get error messages with AppearsInFromClause in them, and if the search for that, these are the docs they'll find. I can't think of any right now, but if we had a few \"usual error cases\" we could describe here (with fixes), that could be quite helpful. (Like the error index.). Can you link to the sqlite docs in each of these comments so people who have no idea what that is have a link to click?. This is a pretty much perfect PR but rustfmt still complains that these lines should be broken up :) See CI log for details. Good point! I made all the links I added/changed https.. Not sure this (the generic query_builder mod) is the right place to a postgres specific impl?. remove empty line. maybe split that string at VALUES into two lines. This is hard to parse for me. Maybe swap the params so the var is first? Or make a small Animal::new(\"dog\", Some(\"Jack\"), 4) builder (i.e., fn new<S: Into<String>, N: Into<String>>(species: S, name: Option<N>, legs: u32) { \u2026 } to reduce the String::from noise). sorry :(\nerror: unused import: `expression::SelectableExpression`\n --> src/query_dsl/distinct_dsl.rs:2:5\n  |\n2 | use expression::SelectableExpression;\n  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\nnote: lint level defined here\n --> src/lib.rs:17:9\n  |\n17| #![deny(warnings, missing_debug_implementations, missing_copy_implementations)]\n  |         ^^^^^^^^\n  = note: #[deny(unused_imports)] implied by #[deny(warnings)]. Yeah, but maybe someone else has a good idea for how to organize these impls?. Probably a good solution. Super unimportant and probably better in a separate PR: Instead of two lines per crate, you could also try to call this as cargo test --no-default-features --features \"%backend% extras\" --manifest-path=diesel/Cargo.toml (same is true for travis and this could make the files look more alike). This is quite detailed and well written. I fear people will not read it, though\u2026 Can you add a small example of the change needed here?\n\nThis means, if you were using diesel_codegen before, you can now replace this dependency\nwith diesel_infer_schema (or remove it completely if you're not using infer_schema! in your code):\ndiff\n[dependencies]\ndiesel = { version = \"0.10.1\", features = [\"sqlite\"] }\n-diesel_codegen = { version = \"0.16\", features = [\"sqlite\"] }\n+diesel_infer_schema = { version = \"0.16\", features = [\"sqlite\"] } \nand change the imports to\n```rust\n[macro_use] extern crate diesel;\n[macro_use] extern crate diesel_infer_schema;\n```\n(again, the second line is only necessary of you're using infer_schema!).\nIn general, a lot of project will now only need to add diesel itself as a dependency.. Diesel Derives?. Hm, why is this annotation necessary here now?. Woohoo, they listened to my feedback! \ud83c\udf89 . Why not today?. Two weeks from now:\nRandom Diesel user: Dafuq is an OID? Oh, there's a link to the PG docs, that's nice!\nPascal: Of course!\nPascal (whispering): Good thing I urged Sean to add yet another link to the docs.\n. Maybe also add an answer to: What happens when this kind of invalid data is used in a query?. Was this addition meant as part of the PG docs PR?. \"\u2026then foo you will receive\" doesn't read like English to me. Wasn't the original meant like\nthen cargo install diesel_cli will throw (you) an error like. My spidey senses are tingling. There should be a link here. To the cargo-install docs. But\u2026 where are they? Here? H\u0338ere?? Here\u0334??? Cargo team, where a\u0322re the cargo ins\u0338\u0163all docs?\u0335?\u0336!\u0301?. Fancy, you say? Then by all means, try and go with this!\n\nrust\nlet file_name = self.migration.file_path()\n    .and_then(Path::file_name)\n    .and_then(OsStr::to_str) // .... This is pretty non-documentary. If this is what you really want people to do, at least include a link. This is pretty non-documentary. If this is what you really want people to do, at least include a link. 2nd level headline?. for symmetry with the next example, i'd write it it like load/assert/load/assert. swap ) and .. plural. 2nd level headline. > With implicit ON clause. > With explicit ON clause. Oh, that's one of my favorite posts from 2017!. Btw, I'd format this as\nrust\nusers::id.eq(posts::user_id)\n.and(posts::title.eq(\"My first post\")). Oh, these two queries are not executed in a transaction. Maybe they should be.. Really? \"Super scary\"? That's what you'd name your pet spider? I'd go for something like \"Charlotte\".. maybe change this test to use a wrapper fn and ? too?. I was more concerned with the data being changed by another user/connection while you're waiting for the second query :). Damn, what kind of spiders do you have in New Mexico\u2026. Oh, wow, we published that as \"migrations-internals\" and not \"diesel-migrations-internals\"? @sgrif, wanna change that?. This is a raw string literal. You can use it when you have lots of quotes in a string and don't want to escape them. In addition to the usual quotes you add the same number of #s before and after the quotes.. s/ever/every. What is your argument for making these types lowercase? (Maybe I missed it). Yeah. I want to keep the \"it needs to know about\" aspect, though.\n\nSo Diesel is able to validate your queries at compile-time, it requires you to specify your database's schema in your code, which you can do with the table! macro. diesel print-schema or infer_schema! can be used to automatically generate these macro calls (by connecting to your database and parsing its schema).. (This comment is just to make this FIXME show up in the comments sections so it gets fixed before merging). Maybe s/most of the most important/most of the typically used?. > are expected to\n\nWhat expects this? Our derives? Macros? Maybe add this as a reason. No semantics linefeeds in the paragraph?. These \"things\" are\u2026 what exactly? \"Rust items\"? \"Operations\"? \"Functions\"? \"Methods\"?\nMaybe something like\n\nThe tools the query builder gives you can be put into these three categories:. > (to not conflict with the Rust keyword). Not sure how many people are familiar with the ops module, most probably only use the operators themselves. So, maybe link to https://doc.rust-lang.org/1.22.1/std/ops/index.html?. This (and query_dsl) are weird relative links. I assume it's supposed to lead to ./expression_methods/index.html?. Maybe also mention backend specific types?. I'd omit the \"all\" here. s/either/any. Why the protocol-relative URLs? Even if the user is using HTTP, it'd make sense to link to the HTTPS version of the docs.. s/tuple/struct\n\nor actually completely skip the \"on our tuple\". (This comment is just so we can see this TODO in the review.). Yeah, it just looked like a markdown ref link at first :). > via rust\nMaybe \"in Rust\"?. \"To be able to use these derives, make sure you have \u2026\" sounds a bit more positive. I'd write \"with each other\" instead of \"together\" but I'm no native speaker. You told people to add #[macro_use] extern crate diesel;, so maybe add it here?. Maybe expand to \"and it's accessing fields by name instead of by index, which means that you can't\u2026\". move this\u2026. \u2026just above this line, so and maybe add a comment that it's required for the types to be in scope?. I think this is good. If you are looking to make it simpler, maybe make a\nrust\nstruct User {\n    #[diesel(embed)]\n    name: UserName,\n    email: String\n}\n(with your UserName struct), and do this query (maybe even incl. the formatting):\nsql\nSELECT first_name,\n       last_name,\n       CONCAT(users.first_name, users.last_name) AS full_name,\n       email\n  FROM users\nIt doesn't show the table name fun, but is much shorter.\nYou should probably add a comment in both cases that this is just an example and that you could also do this with the query builder.. s/especially/for example\nif it were a [large] web form. I'm not really happy with\n\nfor inserting this deserialized web form data.\n\nMaybe \"on structs whose data you want to easy insert into your database\"?. I've never heard this derive attribute called \"trait annotation\" even though that's actually a good name in this case (but in general it can do more than impl a trait). maybe expand this a bit to \"But in addition to tuples, .values() also accepts a\". This sounds like it's not as good on SQLite, but it doesn't really matter in real life as there is basically no overhead to doing queries in SQLite (no networking, most likely not even a context switch). Not sure if we should add this as a remark here.. s/annotation/attribute. I'd split this into two sentences since web form are just one use case (and no guide currently does anything with web form IIRC).\n\nTypically, you will not use Queryable and Insertable together;\nThinking of web forms again, for a new record the form wouldn't have such fields as id, created_at, or updated_at.. Quick idea: extern crate serde{,_derive,_json}, derive Deserialize on NewUser, and let new_user: NewUser = serde_json::from_str(r#\"{\"first_name\": \"Gordon\", \"last_name\": \"Freeman\", \"electronic_mail\": \"gordon.freeman@blackmesa.co\"}\"#).unwrap(); here. double space. s/Implement/implement. period. \"If the [table] name differs\". s/Having the/The. s/provides for us/gives us\n\n(previous sentences used 'provide' too). trailing comma please. I'd put the return value in a comment on the next line. Some manuals use //=> foo to say \"foo\" was returned FYI. Is it \"Id\" or \"ID\"? I'd have guessed the all caps version. s/update/updated. In these cases you could also use assert_eq! (like assert_eq!(all_users.len(), 1)), though. insert empty line between code block and paragraph. There is no note associated with the first error. Unused ref link. insert empty line between headline and paragraph. omit the \"from web forms\" here too. Missing \"trait\". s/he/the. put User in back ticks. I remember, you said so only a few sentences ago. But you still haven't shown me anyOption<_>`! So: I'd skip that remark here.. such [a] relation. insert empty line between ref link definition and paragraph :). One of these is not like the other\u2026 I'd move the gitter channel to a separate sentence:\n\nPlease check out other [official guides] and [API docs] for more information on using the Diesel framework.\nIf you have any questions, join our [gitter channel], the Diesel team is happy to help.. That seems like an odd comma?. maybe link to https://www.postgresql.org/docs/10/static/functions-conditional.html#FUNCTIONS-COALESCE-NVL-IFNULL\n\n(yes i need to write at least one \"maybe link to _\" comment per docs PR). This is the first mention of QueryId. Maybe give a short description of what it does (\"Uniquely identify queries by their type\") and/or link to http://docs.diesel.rs/diesel/query_builder/trait.QueryId.html?. once again? in this guide we didn't write any new traits to extend existing types IIRC. the idea of impl MyTrait for T might be new to people reading this. not sure if there is a good documentation on this. https://doc.rust-lang.org/1.22.1/book/second-edition/ch10-02-traits.html#using-trait-bounds-to-conditionally-implement-methods is a bit short. period.. Maybe mention that this is expression::grouped::Grouped, which is currently only used internally (technically: hidden in the docs). Maybe we want to expose this in the future?. cut the 'if' here. How about \"Using custom SQL and how to extend the Query DSL\"\nI like that this takes such a prominent position in the guide; it's very useful information and more people should make use of this to build cool extension crates!. Now this is weird: I just realized all the dependencies were sorted alphabetically, except for this line. And it's my fault \ud83d\ude05 . Random remark: This file should probably have a -- This file was automatically created by Diesel header. That's a weird name\u2026 I'd probably write an fn get_dotenv_or_err_with(&str, AuthenticationError) that also includes the dotenv::var. Making this a very generic function doesn't really help here, as it internally depends on dotenv::Error anyway.. I'd move this (and the From impl) just above the helper functions (that start with find_user).. Not that it is particularly useful here, but in the 'leading by example' sense we should probably add some doc comments to the public items in this module. At least, we should add a module level doc comment that links to the #1437 guide (once it is online). I'd call more attention to this enum here and its Queryable impl as it's not just boilerplate but actually one of the 'advanced' features :) So maybe add a doc comment that describes how this is used to map NULL to Draft, and how it's a good idea to do this instead of just using  Option<NaiveDateTime>.. Maybe add\nrust\n// generated by `diesel print-schema`. Every one of these three sentences has 'Diesel' in it. Maybe use 'it' in one of them?. > each [of these] traits\njust a technicality but there are of course more traits that exist in Diesel now or in the future that this guide doesn't cover. Maybe\n\nlooking at examples for each trait [individually] and . If you link CRUD, you might also link ORM to https://en.wikipedia.org/wiki/Object-relational_mapping here. > represents the data structure\n\nHmm. Structs are data structures. (They can also represent data structures by representing an AST but that's an edge case\u2026) You can also create a struct that has a Queryable impl manually\u2026 so 'represent' may be a bit strong.\nMaybe go with \"struct is one that can be creating from the result of a database query\"?. s/the rust/Rust's. s/Users/users. Totally not important but for consistency with the doc comments in this codebase it'd put Rust types in back ticks to mark them as code. s/all the three/all three. s/tuple[s]/tuple(s)\nIIUC. s/4/four. This is the first time you use 'model struct' FYI. Maybe define what it is? Like\n\n(i.e., the structure generated by the table! macro). I'd add this sentence in parenthesis (sadly we don't have footnotes here) the first time you use/refer to a tuple :). break up sentence here, replace 'which' with 'This'. > into [a tuple] or a [regular] struct. > will be [able to be built from the] result of a raw\n\nto be precise. pls add trailing comma. pls add trailing comma. feel free to make this a multiline thing. maybe s/typical/simplest?. and then s/typical/usual. Hehe, that doesn't work, sorry! I meant that as\nrust\nextern crate serde;\nextern crate serde_derive;\nextern crate serde_json;\ni.e., you have to act as human glob-expression evaluator :). These three lines begin with 'we will'\u2026 maybe use \"First, we'll look\", \"After that, let's add\", and \"Finally, we will attempt\"?. Missed opportunity to indoctrinate the importance of trailing commas here ;). s/Id/ID. that ::<Users> should be before the (). dito: turbo fish before (). i'd omit the colon. Here, you can totally recycle that colon, though, and use it instead of the period. > and NULL any set to Some(None)\nwhat. > all [the] behaviors we need. trrrrrrrrrailing comma!. this could use a trailing comma as well (hopefully the println! supports this). trai\u2014yeah, i guess you know this by now. s/Diesel/Rust :). revenge of the 'trailing comma!' comment. pff is it my fault it doesn't redirect to https? :P. Was probably one of those 2017 jokes that no-one laughs about anymore.\nBut hey, it was introduced  #666!. Very good change. Makes it even more perfect.. Oh wow is that was rustfmt suggests? (It usually doesn't use visual indentation anywhere). This is a major change according to RFC 1105: it adds a new variante to a public enum without any non-exhaustive marker.\nWhen is this enum ever used in user code? Do you think it'd make sense to add a #[doc(hidden)] __Non_Exhaustive marker as well to really be future compatible?\n  . While changing associated types of a trait is not explicitly covered in RFC 1105, I argue that it is indeed a major change in the sense of the RFC: it's public and changes a trait's item that downstream users can use and depend on; furthermore, it does not implement Deref<&[u8]> or anything like that to reduce the needed code changes.\n. This is a programmer error, right, as it's only dependent on the function name size? Can you add a custom error message?. It's atypical Rust to have a get method panic; it should return an Option, or you should impl Index for Context. Can Box::from_raw panic, e.g. when p == NULL? Do we need to deal with this?. trailing comma. Can you add a bit more context to the assert message, like \"Got a null pointer when expecting a function pointer when calling SQLite custom function\"?\nLet's step a bit back though: This assert can panic, and thus unwind the stack. But it is in an extern fn that gets called by SQLite, right? Isn't panicking in a C context undefined behavior? Shouldn't we try to catch_unwind this whole function body if possible and set t to an error state when that happens?. Thanks for documenting this <3. keep the nicer errors?. FYI correct feature name would of course be humongous-tables. I'd either go with \"raw\" + \"barrel\", or \"sql\" + \"rust\".. We should probably make this non-exhaustive now that it's public, right?. This looks super dangerous adds a hard to see amount of items to our public API!\nI does in fact only expose MigrationError and RunMigrationsError. So let's pub use those specifically if needed.. Does this need to be public or is pub(crate) enough?. Just noticed that's it's super hard to see what's up with SimpleConnection \u2013 it's not public and the only way aside from reading the code where you can find it is in the docs for Connection (which it's a supertrait of). Not something for this PR to fix but seemed worth commenting on.. We should probably make this non-exhaustive now that it's public, right?. This looks like a place where we could special-case the unknown command: patch case and tell people they need to install it. I'd probably not have bothered with borrowing this because of all the <'a> noise \ud83d\ude05 . This is so last month already ;). This is a weird change. Something funky we should tell rustfmt people about?. It feels wrong for me to like this syntax. can you put this on the unsafe block with the transmute?. this syntax landed quite a while ago, right? would be weird to bump min required rustc version for something like this. huh, no trailing comma here seems like a bug in rustfmt. If you too are randomly wondering if Read::read_to_end is cleverly buffered: It totally is. CI says\n\nFailed to open connection to postgres://postgres@localhost/diesel_migration_run: BadConnection(\"FATAL:  database \\\"diesel_migration_run\\\" does not exist\\n\")\n\nwhich leads me to ask: Isn't it just \"setup\" here? Also, run doesn't seem to assert the command exited with zero, so it can't catch wrong calls.. ah that's true, damn. yes. (Oh? Is writing that constraint (still) necessary?). Huh, from the description I somehow expected this to be the other way around: Deserialize it \"like a string\", and then call LowercaseString::from(string) so you end up with a LowercaseString here as type of name. I can see now that this would move the whole logic into the Into impl and you can't work with the raw row data, though, so you might be converting the data twice (which in this example isn't really necessary).. Sorry, I wasn't very clear. What I meant to say: The code is correct and does what I expect it to do; it's just the description in the docs that gave me a different idea.\nrust\n/// To provide custom deserialization behavior for a field, you can use\n /// `#[diesel(deserialize_as = \"Type\")]`. If this attribute is present, Diesel\n /// will deserialize into that type, rather than the type on your struct and\n /// call `.into` to convert it.\nMaybe I just misunderstood that sentence? \"Deserialize into that type\" -- maybe write Type here? \"[\u2026] and call .into to convert it\" -- maybe \"and call Type::into::<TypeInYourStruct>()\"? It probably doesn't matter much with the example right below it, though :). Hmmmm, not sure about the name. I'd expect this to additionally verify the schema, not to error out. Cargo does something similar but calls it --locked (\"Require Cargo.lock is up to date\") and --frozen (\"Require Cargo.lock and cache are up to date\").. Good idea. Have a look at https://github.com/assert-rs/assert_cli/blob/684a8af8a790587fb6e2dedbc05f2cdddf7b29f8/src/diff.rs if you need some inspiration :) I think newer versions of the crate also include something like this style, though. SGTM!. Maybe add something like \"(please ask for features on discourse.diesel.rs instead)\" here, too for people who skipped directly to the checkboxes. Uh, are random people who want to make a PR for an \"good first issue\" issue \"members of the Diesel team\"?. please make discourse.diesel.rs a link\n(yes I'm back to making every second review comment \"please add a link\"). \"find [a] thread\". Maybe call discourse \"forum\" here because not everyone will know that this is the name of a forum software. This reads super weird if you read the \"discourse\" in \"describing your idea on our discourse\" as \"conversation\" or \"discussion\" instead of \"forum\".. you'll probably need to add an https:// here. ",
    "bwo": "This may be old news the people conversing here, but opaleye's approach to insert/update seems like a reasonably nice one, at least in haskell-land: https://github.com/tomjaguarpaw/haskell-opaleye/blob/master/Doc/Tutorial/TutorialManipulation.lhs#L48-L88\n. ",
    "Drakulix": "This is actually quite a major issue for my use case. I use my changeset struct as a proxy object for the actual database object, that is also cached and updates the records on Drop. I do not need fields, that get optionally updated, I am updating the whole record anyway. I need a way to clear the nullable fields.\nImplementing AsChangeset manually is quite verbose, an additional option for the old behaviour would be very nice.\n. well that is still quite large and verbose, as my struct has a lot of fields. I will go with that for now, but it would be nice to be able to just use #[changeset_for].\n. I totally understand that, but this recent change just moved the api hole to the less common use case, although there is a quite easy option to work around that.\nAnother Alternative might be to add a new enum that might either be Null or a value, that can be instanciated from an Option.\nThat would also solve the use case for an Option<Option<>> (if you would want to be able to optinally clear a value), without making the Api any more difficult for people not using the optional updates and not requiring anymore compiler extensions.\n. Because I am not much a database guy I try to abstract away most of the database internals and just have a nice struct representation of my internal database structures. And that change would allow me easily to have one struct to rule all use cases without write much additional code.\nSo yes that change would be completely sufficient, thanks for looking into that.\n. @sgrif Thanks!\n. Thanks for clarifying.\nI would argue then, that master then should also track master in the README:\ndiesel_codegen = { git = \"https://github.com/sgrif/diesel\" }\nThe current Readme is confusing, because the most obvious example is broken.\n. I can do a quick override to this branch in some hours. But I will most likely not spend too much time on it. If I encounter any serious bugs I will report back.\n. Gitter conversation of the test as reference:\n@sgrif do you have some time to quickly test that pull request with me?\nI am getting the following error:\n``\nerror[E0277]: the trait boundfor<'a> (database::user_has_app::columns::app_id, database::user_has_app::columns::user_id): diesel::EqAll<&'a (uuid::Uuid, uuid::Uuid)>is not satisfied\n  --> src/database/schema.in.rs:81:6\n   |\n81 | impl Identifiable for UserHasApp\n   |      ^^^^^^^^^^^^ traitfor<'a> (database::user_has_app::columns::app_id, database::user_has_app::columns::user_id): diesel::EqAll<&'a (uuid::Uuid, uuid::Uuid)>not satisfied\n   |\n   = help: the following implementations were found:\n   = help:   <(L1, L2) as diesel::EqAll<(R1, R2)>>\n   = note: required because of the requirements on the impl offor<'a> diesel::FindDsl<&'a (uuid::Uuid, uuid::Uuid)>fordatabase::user_has_app::table= note: required bydiesel::associations::Identifiable`\nerror: aborting due to previous error\n```\nSean Griffin @sgrif 12:25\nI'm in the airport on my way to Russia atm, sorry\nVictor Brekenfeld @Drakulix 12:26\nalright, I will continue trying\nSean Griffin @sgrif 12:27\nI think that should be a tuple of refs not a ref of a tuple\nVictor Brekenfeld @Drakulix 12:33\nIdentifiable expects: fn id(&self) -> &Self::Id;\nSo my Id type is currently: type Id = (Uuid, Uuid);\nIf I change that to: type Id = (&Uuid, &Uuid);, the compiler complains about missing lifetimes, which is to be expected.\nSo the new implementation looks like:\nrust\nimpl<'a> Identifiable for UserHasApp<'a>\n{\n    type Id = (&'a Uuid, &'a Uuid);\n    type Table = user_has_app::table;\n    fn table() -> Self::Table\n    {\n        user_has_app::table\n    }\n    fn id(&self) -> &Self::Id\n    {\n        &(self.app_id, self.user_id)\n    }\n}\nAnd at this point I need to add a lifetime to UserHasApp via PhantomData...\nSean Griffin @sgrif 12:34\nHm\nThat seems wrong\nVictor Brekenfeld @Drakulix 12:34\nyes\nVictor Brekenfeld @Drakulix 12:39\nthe eqall implementations for those tupels most likely need to handle references, because Identifiable returns &Self::Id\nSean Griffin @sgrif 12:40\nAgree\nVictor Brekenfeld @Drakulix 12:41\nanyway thanks for trying, I dont have the time to debug this any further right now, but I can add those overrides for another test anytime. Just ping me here or on the pullrequest.\nSean Griffin @sgrif 12:41\nYeah that's more than enough info for me to move forward. Thanks.\n. any news?\n. Thanks! I should get the chance to try it out in a couple of days and report back.. A quick grep on my two largest code bases using diesel (both deployed at work and the only ones I really care about, because the rest is hobby and I would always happily accept using better code, even if it breaks compatibility) showed that I am not using tuples anywhere.\nI barely use select, I mostly use filter, update().set(...) always with the full object (or use .save() instead) and order never with more then one argument.\nThis is probably a result from my programming background, I was mostly used to OOP before using Rust, which I would not necessarily call object orientated. I am not a big fan of databases and try to avoid them where not favorable in terms of performance and that probably results in trying to use common code patterns, when dealing with DBs.\nThat's why I keep most operations simple (get & set) and only use queries where I need to.\nAnd diesel makes this very comfortable.\nRegarding documentation I would definitely say the examples can be improved not only in regards to hlist!, but simply to provide more examples. I would maybe use more complex queries, if it wouldn't be so difficult and annoying to browse all those traits to find out, what I can use in combination with what else. If it does not provide an obvious performance penalty I mostly don't use, what else diesel has to offer.. ",
    "Meyermagic": "I'm going to start working on this soon (those livestreams are good advertising). I'm not familiar with your codebase, though, and want to make sure I have the right idea of how this will work.\nI haven't yet started coding, but I see two main issues right now:\n1. Union/Intersect/Except only work with SELECT in at least PG 9.4, and not with UPDATE ... RETURNING even with a compatible type. So I can't just use AsQuery as is while relying on matching SqlType.\n2. Union/Intersect/Except can be called on a simple select query or a compound one, but most DSL methods can only be called on simple queries.\nMy high-level plan is then:\nIntroduce a CompoundSelectStatement enum with Union, Intersect, and Except variants. This should satisfy AsQuery when T: AsQuery, U: AsQuery with compatible types, but with an additional bound to satisfy 1.\nIntroduce three new DSL methods UnionDsl, IntersectDsl, and ExceptDsl which also require the trait added to satisfy 1.\nAdd a new bound to the other DSL methods, something like NotCompoundQuery, to satisfy 2.\nIs there a Contribution Guide or architecture document or similar? I feel like a higher-level perspective might be helpful.\nDisclaimer: I haven't put down any code for this yet, only poking around on GitHub. This might be way off-base.\n. Yes, I noticed that too. Should have a patch by Monday if I have time.\n. Might be better to keep Union and UnionAll as separate structs to avoid the 1 byte of overhead and potentially allow us to track \"distinctness\" with the type system?\n. I'm not sure what the correct way to make this ergonomic is.\n. ",
    "robertmaloney": "It seems that both SQLite and Pg support ORDER BY, LIMIT, OFFSET, and maybe others without treating it as a subquery. Should we implement those DSLs?\n. Did you want to set updated_at upon INSERT as well?\n. Alright, and you wanted a procedure like this?\nsql\nCREATE OR REPLACE FUNCTION diesel_manage_updated_at(_tbl regclass) RETURNS VOID AS $$\nBEGIN\n  EXECUTE format('CREATE TRIGGER set_updated_at BEFORE INSERT OR UPDATE ON %s FOR EACH ROW EXECUTE PROCEDURE set_updated_at()', _tbl);\nEND;\n$$ LANGUAGE plpgsql;\n. Oh yeah, had that one written prior to your response haha. Apologies if this is obvious, but where do you imagine these helpers existing? Should the updated_at/created_at -> Timestamp pairs be reserved and handled with this procedure automatically within the migration code, or exposed to the user so they can decide whether or not diesel should manage it for them? Or is there a plan to implement a migration DSL in Rust, akin to Rails (e.g. add_timestamps)?\n. I've been looking into what exactly would it take to implement this, constrained by the SQL format of migrations. If they wanted to, a user could write valid SQL with alternating capitals and one word per line, and it'd be accepted by Pg. So implementing a check for the phrase updated_at TIMESTAMP and then parsing the table_name would most likely mean collapsing all whitespace, and then using the regex crate's capture groups.\nI also thought about a pseudo-DSL using SQL comments, but a good design of that basically means implementing the foundation of a DSL entirely.\n. Ah, yeah I was overthinking it. In thinking of a better name, what are your thoughts on enable/disable_automatic_updated_at_for_table.\n. Thats fine, I'm holding off on this anyways until the DB setup flow is refactored. Thank you for letting me know.\n. Fixed :+1:\n. Current comments have been addressed.\n. Because combination queries support ORDER BY, LIMIT, and OFFSET, it might be better to extract these fields away from SelectStatement into another struct, in order to better reflect the SQLite diagram (which I suspect is a similar syntax tree to Pg). However that might mean a preliminary PR. Thoughts @Meyermagic @sgrif?\n. @sgrif Yeah, I still want to finish this up, but I have to a lot more work for it, and I need to relearn the codebase \ud83d\ude04 . I'll close it for now and reopen when I get to a good point.. @killercup That worked, thanks!\n. Implementing in Connection will have to happen eventually, so I figured I might as well add the skeleton for it. I left out the unimplemented!() just because it would crash whenever someone wanted to setup their database in SQLite. Would you rather I make a temporary function in migrations that's called only when the postgres feature is applied?\n. Done. I put the sql in a setup folder.\n. Done\n. Done\n. Couldn't find such an impl, so I tried making it myself:\nrust\nimpl<T, Source, Predicate> SelectableExpression<FilteredQuerySource<Source, Predicate>> for T where\n    T: Expression + SelectableExpression<Source>\n{\n}\nbut it apparently conflicts with this:\nrust\nimpl<'a, T: ?Sized, ST, QS> SelectableExpression<QS, ST> for &'a T where\n    T: SelectableExpression<QS, ST>,\n    &'a T: Expression,\n{\n}\nAm I missing something?\n. Woops, that's a typo. Interesting that it still passed! Removed.\n. It passed\n. ",
    "masklinn": "How do you figure that'd work for examples using main e.g. second example of the readme?\n. ",
    "defyrlt": "I think that .unwrap() is a great thing for docs/examples. You don't have to teach your users how to handle error cases - there's a chapter in the Book for it.\n. That's the full code. I thought that deriveing Queriable will be enough.\nUsing table! macro does not make it compile though.\n``` rust\n![feature(custom_derive)]\n[macro_use]\nextern crate diesel;\nuse diesel::*;\ntable! {\n    users {\n        id -> Serial,\n        name -> VarChar,\n        favorite_color -> Nullable,\n    }\n}\n[derive(Queriable, Debug)]\npub struct User {\n    id: i32,\n    name: String,\n    favorite_color: Option,\n}\nfn main() {\n    let connection = Connection::establish(env!(\"DATABASE_URL\"))\n        .unwrap();\n    let users: Vec = users::table.load(&connection)\n        .unwrap().collect();\nprintln!(\"Here are all the users in our database: {:?}\", users);\n\n}\n```\nrust\nsrc/main.rs:27:19: 27:28 error: the trait `diesel::query_source::Queriable<(diesel::types::Integer, diesel::types::VarChar, diesel::types::Nullable<diesel::types::VarChar>)>` is not implemented for the type `User` [E0277]\nsrc/main.rs:27         .unwrap().collect();\n                                 ^~~~~~~~~\nsrc/main.rs:27:19: 27:28 help: run `rustc --explain E0277` to see a detailed explanation\nsrc/main.rs:26:41: 26:58 error: the trait `diesel::query_source::Queriable<(diesel::types::Integer, diesel::types::VarChar, diesel::types::Nullable<diesel::types::VarChar>)>` is not implemented for the type `User` [E0277]\nsrc/main.rs:26     let users: Vec<User> = users::table.load(&connection)\n                                                       ^~~~~~~~~~~~~~~~~\nsrc/main.rs:26:41: 26:58 help: run `rustc --explain E0277` to see a detailed explanation\nerror: aborting due to 2 previous errors\nCould not compile `try_diesel`.\n. If I don't use table! - where should I get the users module?\nNaa, it didn't work out :(\nrust\n[dependencies]\ndiesel = \"*\"\ndiesel_codegen = { version = \"^0.1.0\", default-features = false, features = [\"nightly\"] }\n``` rust\n![feature(custom_derive, custom_attribute, plugin)]\n![plugin(diesel_codegen)]\n[macro_use]\nextern crate diesel;\nextern crate diesel_codegen;\nuse diesel::*;\n```\nrust\n   Compiling aster v0.8.0\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:950:35: 950:52 error: use of undeclared type name `ast::ImplItemKind` [E0412]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:950     pub fn build_item(self, node: ast::ImplItemKind) -> F::Result {\n                                                                                                                         ^~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:950:35: 950:52 help: run `rustc --explain E0412` to see a detailed explanation\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:979:20: 979:44 error: failed to resolve. Could not find `ImplItemKind` in `syntax::ast` [E0433]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:979         let node = ast::ImplItemKind::Const(const_.ty, const_.expr.expect(\"an expr is required for a const impl item\"));\n                                                                                                          ^~~~~~~~~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:979:20: 979:44 help: run `rustc --explain E0433` to see a detailed explanation\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:979:20: 979:44 error: unresolved name `ast::ImplItemKind::Const` [E0425]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:979         let node = ast::ImplItemKind::Const(const_.ty, const_.expr.expect(\"an expr is required for a const impl item\"));\n                                                                                                          ^~~~~~~~~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:979:20: 979:44 help: run `rustc --explain E0425` to see a detailed explanation\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:990:20: 990:45 error: failed to resolve. Could not find `ImplItemKind` in `syntax::ast` [E0433]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:990         let node = ast::ImplItemKind::Method(method.sig, method.block.expect(\"a block is required for a method impl item\"));\n                                                                                                          ^~~~~~~~~~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:990:20: 990:45 help: run `rustc --explain E0433` to see a detailed explanation\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:990:20: 990:45 error: unresolved name `ast::ImplItemKind::Method` [E0425]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:990         let node = ast::ImplItemKind::Method(method.sig, method.block.expect(\"a block is required for a method impl item\"));\n                                                                                                          ^~~~~~~~~~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:990:20: 990:45 help: run `rustc --explain E0425` to see a detailed explanation\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1001:20: 1001:43 error: failed to resolve. Could not find `ImplItemKind` in `syntax::ast` [E0433]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1001         let node = ast::ImplItemKind::Type(ty);\n                                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1001:20: 1001:43 help: run `rustc --explain E0433` to see a detailed explanation\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1001:20: 1001:43 error: unresolved name `ast::ImplItemKind::Type` [E0425]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1001         let node = ast::ImplItemKind::Type(ty);\n                                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1001:20: 1001:43 help: run `rustc --explain E0425` to see a detailed explanation\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1012:20: 1012:44 error: failed to resolve. Could not find `ImplItemKind` in `syntax::ast` [E0433]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1012         let node = ast::ImplItemKind::Macro(mac);\n                                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1012:20: 1012:44 help: run `rustc --explain E0433` to see a detailed explanation\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1012:20: 1012:44 error: unresolved name `ast::ImplItemKind::Macro` [E0425]\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1012         let node = ast::ImplItemKind::Macro(mac);\n                                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~\n/home/user/.cargo/registry/src/github.com-0a35038f75765ae4/aster-0.8.0/src/item.rs:1012:20: 1012:44 help: run `rustc --explain E0425` to see a detailed explanation\nerror: aborting due to 9 previous errors\nCould not compile `aster`.\nAnd I make it diesel_codegen = \"*\"\nrust\nsrc/main.rs:29:19: 29:28 error: the trait `diesel::query_source::Queriable<(diesel::types::Integer, diesel::types::VarChar, diesel::types::Nullable<diesel::types::VarChar>)>` is not implemented for the type `User` [E0277]\nsrc/main.rs:29         .unwrap().collect();\n                                 ^~~~~~~~~\nsrc/main.rs:29:19: 29:28 help: run `rustc --explain E0277` to see a detailed explanation\nsrc/main.rs:28:41: 28:58 error: the trait `diesel::query_source::Queriable<(diesel::types::Integer, diesel::types::VarChar, diesel::types::Nullable<diesel::types::VarChar>)>` is not implemented for the type `User` [E0277]\nsrc/main.rs:28     let users: Vec<User> = users::table.load(&connection)\n                                                       ^~~~~~~~~~~~~~~~~\nsrc/main.rs:28:41: 28:58 help: run `rustc --explain E0277` to see a detailed explanation\nerror: aborting due to 2 previous errors\nCould not compile `try_diesel`.\n. Got latest nightly. It works! Sorry, I should've done this before.\nHow about making #[derive(Queriable)] smart enough to produce appropriate table! call? Does it seem to be possible?\n. How about marking fields like this?\n``` rust\n[derive(Queriable, Debug)]\npub struct User {\n    #[column_type = Serial]\n    id: i32,\n    #[column_type = VarChar]\n    name: String,\n}\n```\nUPD: this particular issue is closed. Let's make another one for automatic generation of table! call?\n. ",
    "hiimtaylorjones": "Shouldn't this be closed because of the above PR? If not, I'm more than willing to finish what work wasn't covered by #45!\n. Ah, I see what you're talking about.\nUpon doing a global project search for /// assert_eq!(, I've found that cases that use .unwrap() in the assert are all using Ok([statement]) now. Is this the desired beahvior? \nAnyways, I'm recommending closing this issue and my Issue #34 PR if everything is as it should be. Sorry for the misunderstanding!\n. I'm down to write some docs about this. \n@dikaiosune - could you maybe provide some common examples where this might occur?\nI really like the suggestion of documenting what Rust.to.SQL mappings are currently supported by Diesel. I think it'll bring down the amount of Issues of \"Why doesn't rust_thing convert to SQL?\" in the future.\n. @dikaiosune - Sweet. I'll see what I can dig up there.\n@sgrif - noted. \n. Hey everyone,\nThis totally fell of my radar. For that, I apologize. Though this conversation is about a year old, I decided to still take a shot at the issue. \nWhile, the need for SQL mapping types still exists, I figured that I'd at least write up something to cover the ground in the meantime. That commit can be found here. Please let me know if I'm completely right, wrong, or somewhere in between!\nAs far as the proposed mapping documentation is concerned, where exactly would be the best place to insert that documentation? . I think restrictions and drawbacks are worth it for what we gain. It'll definitely require a lot of work to redo a lot of guide documentation, but it'll hopefully make Diesel better in the long run!. \ud83d\ude22 Well that's a bummer. \nThanks for the pointer! Pushing up the change in a few.\n. Hmmmmmm.\nMaybe we should leave unwrap() in there then. Whatcha think @sgrif?\n. Oh! I see how the docs are being picked up and interpreted now. Will do.\n. ",
    "reem": "@sgrif on the other hand supporting lifetimes is important since there are types like Cow<'a, str> which could be used to allow borrowed data on the encoding end and would deserialize into a owned string of type Cow<'static, str>.\n. Does that actually compile? I would guess that in the FromSql implementation you'd need Cow<'static, T>.\nIt's very tricky to get bounds correct in codegen, even the built-in derives are overly restrictive in basically all non-straightforward cases.\n. Ah, I see, that's a nice generalization.\n. A better way to indicate this is to return !, which is the type of panic!(), which should have less inference errors and actually indicate that code following this is unreachable.\n. ",
    "palango": "How can I run the compile-fail tests? If I run cargo test in the diesel and diesel_test directories I only get green tests.\n. Should I squash the commits?\n. I license past and future contributions under the dual MIT/Apache-2.0 license, allowing licensees to chose either at their option.\n. > I think you didn't run the migrations so the database doesn't exist and diesel cannot infer the schema\nDoesn't Running migration 20170124012402 mean that the migrations are run?. It looks like that (just removed the relative path from the diesel program:\n```\n!/bin/sh\nset -e\nexport DATABASE_URL=\"/tmp/test_examples.db\"\nfor dir in $(find . -maxdepth 1 -mindepth 1 -type d); do\n  cd $dir\n  diesel database reset\n  cargo build\n  cd ..\ndone\n. If I open the test_database.db file and look at the schema it looks right:sql\nsqlite> .schema posts\nCREATE TABLE posts (\n  id INTEGER NOT NULL PRIMARY KEY,\n  title VARCHAR NOT NULL,\n  body TEXT NOT NULL,\n  published BOOLEAN NOT NULL DEFAULT 0\n);\n```. > Do you have a .env file somewhere in there ?\nNo. That helped for me as well.. ",
    "iqualfragile": "make sure (pre 1.0) that the libraries design allows generating database-agnostic sql (or well plugging in custom sql generators for different databases), i think that might be easily forgotten when mainly using postgress as backend.\n. About differences in types supported by different databases:\nAnother option would be providing a fallback, so for example just saving an ip address, which is a native type in postgres into a 32 bit integer in sqlite.\n. Would it be an option to just put support for different engines into different modules, so you can just import the right one for your application? That would remove the ability to dynamically configure your application to use another database, but might reduce coding complexity.\n. there is another big problem with sqlite, as its column types are more of a recommendation, i.e. you can store a string into an integer field and sqlite won't complain. while i strongly doubt this should be supported for the insert/update, it needs to be kept in mind on the select side of things.\n. maybe support for composite primary keys? I guess that would mean some changes, not sure if the api would change though.\n. damn, second fixed bug in diesel i run in today.\n. btw on the embracing sqlite philosophy of untyped sql: i really really don't think thats a good idea, i would just handle it as if the type definitions would be definitive, just like postgress does. there is not really a good usecase for storing different types into the same collumn anyways.\njust fail with a good error message if someone put stupid values into the db.\n. ",
    "tafia": "Could you describe what has to be done to implement a new database ?\nI'd also like to have sqlite (in particular) implemented in diesel and I'd like to help if possible.\n. Of course I understand.\nI didn't really try reasoning about what should be generic or not. My main\nfocus was to ensure postgresql was in its own module without breaking too\nmuch things.\nTake your time.\nThanks\nOn 29 Dec 2015 09:18, \"Sean Griffin\" notifications@github.com wrote:\n\nThanks for the PR. There's some failing tests, but I think I can handle\ngetting them passing. I think it's still a bit premature to try and\ngenericise these interfaces, but this all seems pretty reasonable at first\nglance. This is a pretty hefty PR, so it'll take me a day or two to get\nthrough it.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/72#issuecomment-167689876.\n. Pushed one more commit to relocate postgresql data types and extensions to postgresql directory.\nContrary to Connection/DbResult, the code was already generic. The only changes are use expressions within postgresql folder and lib.rs\n\nEDIT: Also renamed PGConnection/PGDbResult to PgConnection/PgDbResult to align with data types names (and they feel more rustic)\n. No pb!\nOn 24 Jan 2016 01:18, \"Sean Griffin\" notifications@github.com wrote:\n\n@tafia https://github.com/tafia Thanks for starting the work on this,\nbut there's a lot of feedback that still needs to be addressed, and we're\nnow at the point where this change is actually needed. I'm going to close\nin favor of #128 https://github.com/sgrif/diesel/pull/128.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sgrif/diesel/pull/72#issuecomment-174203573.\n. \n",
    "Aatch": "\n\nIs the compiler smart enough to eliminate some copying if I only use one field of the returned struct, and the function impl is just a struct literal?\n\n\nProbably.\n\n\nIs this still true if it's going through a trait object?\n\n\nProbably not, unfortunately. Since it can't inline a virtual call, it needs to allocate the full return value on the stack for the function to use.\n\n\nDoes it even matter? Is our worst case for a performance hit a few extra i32 copies? We should benchmark regardless\n\n\nDepending on the size of the returned value, it probably won't make a huge difference. When dealing with databases, you have to compare this stuff to the performance of I/O. Reading/writing to the network or a file is going to dominate any profile, so worrying about a few extra copies here and there is probably not going to matter.\n. ",
    "metaskills": "Thanks for including me Sean. I think I can speak to one point well about bind params and my experience with SQL Server and Ruby's TinyTDS gem. I know of no C API outside of the ODBC layer for the DBLIB protocol that is essentially SQL Server. I punted on this use TSQL when I did support for bind params in the SQL Server adapter. Check out this really old engineyard post for details. Basically, we do bind params at the SQL layer by wrapping the SQL as a param to a stored procedure which has n arguments that include the type and value of each param. I am unsure if this, like SQLite, is at odds with your architecture. Happy to go into details on any topic if you think it helps. \n. @placrosse The TinyTDS gem makes exclusive use of the DBLIB API in FreeTDS. Love it.\n. ",
    "placrosse": "While not perfect, www.freetds.org does have a 'C' library that can connect to Sybase and MS SQL Server, including some support for the dblib API.  We used rust-bindgen with it, and are testing it out now.\nI'm very interested in seeing if it can be made to work with Diesel (eventually).\n. Yes, @sgrif , I am very interested in doing just that.\n. ",
    "ixjf": "In regards to MySQL, are there any plans for support in the near future, or is it still slated for close-to-1.0? This is not an \"I prefer MySQL\" as in \"I don't want to work with PostgreSQL\", but the project I'm working on uses MySQL for other services and it's just not feasible to move to PostgreSQL and SQLite is not a good alternative due to its performance.\n. ",
    "werner": "Hi, what is the status of this? Is there a way to support views? Is this in the roadmap?, thanks.. ",
    "mjanda": "@werner You can create your own schema for views manually (and keeping it in sync if you change your views) and it works.. What about just adding support for having seed.sql alongside up/down.sql files and running it after up.sql if --seed argument is used.\nHaving it together with migrations would mean less time keeping seeding data up to date with current db structure, help test migrations when altering db etc.. It seems like it's using update ... from syntax and building that update sql manually.\nhttps://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/Rust/actix/src/db_pg.rs#L180\nNice, didn't even know postgresql can do that.. ",
    "archer884": "So, I was just trying to use Jsonb in a table and I had kind of assumed--until I ran into this error--that diesel would give the json to me as a string and I could deserialize it myself. No dice. Instead, I get a compilation error. Rather than wait for the absurd feature (querying jsonb with diesel, I guess?), what about just letting diesel give me the data instead of exploding? :)\n. That part was quoting you from above:\n\nSo let's talk borderline absurd features.\n\n:)\n. ",
    "jimmycuadra": "@archer884 Did you end up implementing this as Sean described? I have a table with a jsonb column and was hoping someone had already done the heavy lifting of creating a Diesel type for it that I could copy/paste. :}\n. Thanks! I can make a PR to add some docs explaining this. Is there anything else actionable here? Maybe a way to name the types and data_types module that's more clear?\n. I'll see if I can narrow it down some more and get a simpler reproduction. Thanks for taking a look!\n. Sorry, no, I haven't checked it again since first opening the issue. I've been knee deep in other projects. You can let it sit for now and I will leave a comment as soon as I update the branch and verify it's still a problem and/or figure out a smaller reproducible test case.\n. I got a chance to look at this again and was able to reproduce the error without so much set up and unrelated code. Take a look here: https://github.com/jimmycuadra/diesel_error\n. Ah ha! Glad it was simple as that! Thanks so much.\n. I'm also wondering this. In my case, I want to use a custom type in a table struct that Diesel should treat as a String for all intents and purposes. It's not clear to me how to achieve this. I started out by trying to just implement ToSql for my type, but it seems like there is a rabbit hole of traits that need to be satisfied, cause I get errors like \"diesel::Expression is not satisfied\" and \"diesel::Expression:NonAggregate is not satisfied.\"\n. Any idea of the timetable for this? Is this a post-1.0 feature? I've got a few things I need it for already.\n. Also, it looks like I'm going to need PG's advisory locks. Should I open a separate issue for that, or shall we repurpose this one to cover support for all the various concurrency control mechanisms in PG?\n. Looks like there was already an issue for it that I missed at #42 anyway. Closing this out.\n. Did the details of how to do this change in diesel 0.10? I'm now getting these errors, using diesel and diesel_codegen 0.10.0 (with the postgres feature):\n``\nerror[E0277]: the trait boundruma_identifiers::UserId: diesel::Expressionis not satisfied\n  --> src/models/profile.rs:18:1\n   |\n18 | #[derive(AsChangeset, Debug, Clone, Identifiable, Insertable, Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the traitdiesel::Expressionis not implemented forruma_identifiers::UserId|\n   = note: required because of the requirements on the impl ofdiesel::Expressionfor&'insert ruma_identifiers::UserId= note: required because of the requirements on the impl ofdiesel::expression::AsExpression>for&'insert ruma_identifiers::UserId`\n   = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound ruma_identifiers::UserId: diesel::Expression is not satisfied\n  --> src/models/profile.rs:18:1\n   |\n18 | #[derive(AsChangeset, Debug, Clone, Identifiable, Insertable, Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::Expression is not implemented for ruma_identifiers::UserId\n   |\n   = note: required because of the requirements on the impl of diesel::Expression for &'insert ruma_identifiers::UserId\n   = note: required because of the requirements on the impl of diesel::expression::AsExpression<diesel::types::Nullable<diesel::types::Text>> for &'insert ruma_identifiers::UserId\n   = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound ruma_identifiers::UserId: diesel::Expression is not satisfied\n  --> src/models/profile.rs:18:1\n   |\n18 | #[derive(AsChangeset, Debug, Clone, Identifiable, Insertable, Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::Expression is not implemented for ruma_identifiers::UserId\n   |\n   = note: required because of the requirements on the impl of diesel::Expression for &'insert ruma_identifiers::UserId\n   = note: required because of the requirements on the impl of diesel::expression::AsExpression<diesel::types::Nullable<diesel::types::Text>> for &'insert ruma_identifiers::UserId\n   = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound &'insert models::profile::Profile: diesel::Insertable<schema::profiles::table, DB> is not satisfied\n  --> src/models/profile.rs:18:1\n   |\n18 | #[derive(AsChangeset, Debug, Clone, Identifiable, Insertable, Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::Insertable<schema::profiles::table, DB> is not implemented for &'insert models::profile::Profile\n   |\n   = help: the following implementations were found:\n             <&'insert models::profile::Profile as diesel::Insertable>\n   = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound ruma_identifiers::UserId: diesel::Expression is not satisfied\n  --> src/models/profile.rs:18:1\n   |\n18 | #[derive(AsChangeset, Debug, Clone, Identifiable, Insertable, Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::Expression is not implemented for ruma_identifiers::UserId\n   |\n   = note: required because of the requirements on the impl of diesel::Expression for &'insert ruma_identifiers::UserId\n   = note: required because of the requirements on the impl of diesel::expression::AsExpression<diesel::types::Nullable<diesel::types::Text>> for &'insert ruma_identifiers::UserId\n   = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound DB: diesel::backend::SupportsDefaultKeyword is not satisfied\n  --> src/models/profile.rs:18:1\n   |\n18 | #[derive(AsChangeset, Debug, Clone, Identifiable, Insertable, Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::backend::SupportsDefaultKeyword is not implemented for DB\n   |\n   = help: consider adding a where DB: diesel::backend::SupportsDefaultKeyword bound\n   = note: required because of the requirements on the impl of diesel::insertable::InsertValues<DB> for (diesel::insertable::ColumnInsertValue<schema::profiles::columns::id, &'insert ruma_identifiers::UserId>, diesel::insertable::ColumnInsertValue<schema::profiles::columns::avatar_url, diesel::expression::bound::Bound<diesel::types::Nullable<diesel::types::Text>, &std::option::Option<std::string::String>>>, diesel::insertable::ColumnInsertValue<schema::profiles::columns::displayname, diesel::expression::bound::Bound<diesel::types::Nullable<diesel::types::Text>, &std::option::Option<std::string::String>>>)\n   = note: required by diesel::insertable::InsertValues\n   = note: this error originates in a macro outside of the current crate\nerror[E0277]: the trait bound ruma_identifiers::UserId: diesel::query_builder::QueryFragment<DB> is not satisfied\n  --> src/models/profile.rs:18:1\n   |\n18 | #[derive(AsChangeset, Debug, Clone, Identifiable, Insertable, Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait diesel::query_builder::QueryFragment<DB> is not implemented for ruma_identifiers::UserId\n   |\n   = note: required because of the requirements on the impl of diesel::query_builder::QueryFragment<DB> for &'insert ruma_identifiers::UserId\n   = note: required because of the requirements on the impl of diesel::insertable::InsertValues<DB> for (diesel::insertable::ColumnInsertValue<schema::profiles::columns::id, &'insert ruma_identifiers::UserId>, diesel::insertable::ColumnInsertValue<schema::profiles::columns::avatar_url, diesel::expression::bound::Bound<diesel::types::Nullable<diesel::types::Text>, &std::option::Option<std::string::String>>>, diesel::insertable::ColumnInsertValue<schema::profiles::columns::displayname, diesel::expression::bound::Bound<diesel::types::Nullable<diesel::types::Text>, &std::option::Option<std::string::String>>>)\n   = note: required by diesel::insertable::InsertValues\n   = note: this error originates in a macro outside of the current crate\n```\nThe struct in question is:\n``` rust\n[derive(AsChangeset, Debug, Clone, Identifiable, Insertable, Queryable)]\n[table_name = \"profiles\"]\npub struct Profile {\n    pub id: ruma_identifiers::UserId,\n    pub avatar_url: Option,\n    pub displayname: Option,\n}\n```\nThe previously working implementations for ruma_identifiers::UserId can be found here: https://github.com/ruma/ruma-identifiers/blob/29f76ca95d295bca36ec53cd8da72217c5aa0f75/src/lib.rs#L689. Moving my question to its own issue: https://github.com/diesel-rs/diesel/issues/640. Done!. #[non_exhaustive] would address the issue of adding new variants, but it doesn't address the ability to change internal representations of enum variants like Sean mentioned.. Here's a link to the Rust issue reported in the warning: https://github.com/rust-lang/rust/issues/50504. It seems the Diesel team (or at least Sean) was already aware of this issue. Maybe now the circumstances have changed since Rust 2018 has shipped and this is now a hard error under the edition.. https://github.com/diesel-rs/diesel/issues/1785 also seems related.. ",
    "lancecarlson": "I need this too. This and Tsvector get hung up. How difficult is this to implement? It looks like I may have to drop down to rust-postgres.... @sgrif Perhaps it would make sense to put it on this page somewhere?\nhttp://docs.diesel.rs/diesel/prelude/index.html\nIt's a tad but awkward here too but seems closer? If you think this may sure, I can whip something up. Maybe on the bottom? Or above traits?\n@killercup @eijebong, thoughts?. Actually, I think it should go here:\nhttp://docs.diesel.rs/diesel/index.html\nUnder a debugging section. I also think the main page should have more stuff. Rocket's main API docs page does a good job and mimicking their format would make diesel's API docs seem more inviting.. I just ran into this issue and this is ridiculous. Why is there such a thing as \"large table support?\" Shouldn't it default to any size table you like? . Did you figure out this issue? The error is saying it can't find your env variable, likely because you are missing your .env file as you suggested.. @killercup For the last one, perhaps adding language to end of this section would make sense?\nhttp://docs.diesel.rs/diesel/macro.table.html#dsl\nSomething along the lines of: Only import this into the scope of a function you a building the query in otherwise it will pollute the namespace. \nPerhaps an example could be provided that looked something like this:\nrust\n// bad\nuse diesel_demo::schema::posts::dsl::*;\nfn main() {\n    // good\n    use diesel_demo::schema::posts::dsl::*;\n}\nIf you're cool with this, I'll make a PR. . When I encountered this issue, the error I got was:\nerror importing: DatabaseError(\"invalid digit in external \\\"numeric\\\" value\"). I think that @eijebong was able to isolate the issue to values smaller than 1/10000. I haven't tested this yet but it seems right!. Another suggestion I was thinking about was to have a table for each database that shows a list of the rust types that correspond with the schema types and the exact database type. Currently it is a bit cumbersome to have to click on each type to look these up. I'm sure it will also reduce the amount of questions that come through gitter about what types need to be used.. Thinking this through, I would imagine the syntax might look like this:\nrust\ndiesel::insert(diesel::select_table).into(diesel::insert_into_table);\nI'm not sure that the dsl adds anything over the SQL unless it can generate the columns from the struct because (at least in postgres) you have to cast the select output into a table with an explicit column manifest/schema.. Absolute URL?. ",
    "theduke": "Any movement on this?\nIt's really crucial for me.\nMost important would be just supporting fields with a \"Value\" type from serde_json.. @sgrif would it be possible to leave logging up to the user by providing hooks on the connection?\nI'm thinking something like this:\n```rust\ntrait Connection {\n  ...\n  /// Register a function that will be called before each executed statement. \n  fn pre_execute(&mut self, hook: F)\n    where F: Fn(query: &str, args: &[?]) -> bool;\nfn on_success(&mut self, hook: F) where ..;\n  fn on_error(&mut self, hook: F) where ..;\n}\n```\nThis would allow customized logging, only logging errors, profiling by measuring execution time, .... No there is not, but the UUID could just be (de)serialized to  BINARY or TEXT, which would be much nicer than having to convert manually. @sgrif . A lot of other ORM CLIs have  dump and load commands to export and import data. (Django ORM, Doctrine, ...)\nUsually supporting CSV and JSON as formats.\nIt's a very nice feature to have during development.\nIt's significantly more convenient to create test data via your web interface and then dump it, rather than having to constantly write/update rust code to do the same. \nIt allows even non-devs to create realistic data, and other devs can just load it up without having to worry /know about database specific dump / restore tooling (like pg_dump).\nbash\ndiesel dump -f json --all --out-dir=./data\ndiesel database reset\ndiesel load data\nWhen dumping all tables, a file for each table would be created.\nThe load command must figure out a foreign key dependency graph to load the tables in a correct order.. Stumbled over this too.\nQuite a big bug / gotcha.\nAny fix upcoming?. Could there be a compile time test/lint for this?. Duplicate of #1134, so one of them can be closed.\nThis issue is older, but the other one has more disussion.\n. I just tested the docs at http://docs.diesel.rs/diesel/index.html with a linkchecker.\nIt reports no broken links, so I think this can be closed.. Will do.. @sgrif regarding the changelog, should I add it to 0.11.3 and leave the date empty?. @killercup  thanks for making up for my laziness!\n. Any movement on this?\nHas it been decided to go forward with hlists?\nAlso, @sgrif , as I understand it, this would \"fix\" the restrictions on number of columns in a table, right?. What's blocking this?\nAnything I can do to help out?. @killercup \nYou have probably put more thought into it, but, off the top of my head, here is a raw structure for the documentation.\n\nQuickstart: \n    A short single file (main.rs) example that shows how to: create a schema with table!, get a connection (don't bother with dotenv), run a raw SQL statement to create a table (not bothering with a migration), insert, query and delete rows. \n    Concise, just get you something running quickly, and refer to best practices being mentioned in later chapters (dotenv, migrations, project structure, etc).\n    Separate mirrored version for each backend would be nice.\nConcepts\nSchema: explain schema and DSL, and different ways to get one (infer, table! macro)\nModels: explain the traits (Queryable, Insertable, identifiable) and how they are used + how deriving works\nCLI (short intro, important for migrations, more detailed docs below)\nMigrations\nBackends (postgres, mysql, sqlite)\nRecommended Project Structure\n\n\nQueries: most important -  Include lot's of examples\nDSL: \nbasic insert/update/delete, arguments\nquerybuilder\nComplex Queries (joins, ...)\nExecuting Raw SQL\nWith Models\nAssociations\n\n\n\nBackend\n    Documentation for setup and custom features for each database\n\nPostgres\nMySQL\nSqlite\nAdvanced\nCustom Types (related traits, how to implement)\nHandling Migrations (embed in binary, etc)\n...\nCLI: CLI features and available commands\n  . I'd  recommend not just writing more guides, but writing a structured documentation like above that can also be used as a sort of reference to quickly look up how to do certain things.\n\n\n\nEspecially with a ORM that's very valuable, imo.\nI'm not in love with how https://github.com/azerupi/mdBook looks, but it's good enough for Rust, so using that might be an option, and certainly less work than building something custom.. To suuport what @alanhdu said, i think the Queries section in my outline is by far the most important.. So since diesel is actually faster than simple pgbench, I think this can be closed?\n@sgrif @u2 . Could QueryFragment have a trait bound for Debug?. Oh sure, I looked for a website repo on the diesel-rs repo but couldn't find it, so I just did it here.. 15 minutes is a lot better then when I tried to implement the same thing.\nIt took around an hour for me with 128 columns, if I remember correctly.\nIt's still way too long to be sensible though, imo.. @sgrif thanks for picking up my suggestion and implementing it, it's much appreciated!\n. Doing a PR for this feels kind of emberassingly simple. ;). Actually, then let's close this and wait for someone else to find it. ;). Oh I didn't realize there already was a Migration trait, thanks for pointing that out.\nThe point of making Migration generic over the Backend is to make it possible to use regular diesel code for changes that are not plain SQL. (Like update all columns in a table by mapping over the value, within a transaction, or whatever).\nThis also would make it possible to implement backend-specific migrations to support multiple backends.\nThis could of course also be done just by structuring the migrations differently, but it would be nice to implement Migration on the same struct for different backends.\nBut otherwise, yeah, all that would be needed is a macro that takes an array of migrations and generates the code for running them, and potentially an extension to diesel-cli for generating migrations.. @sgrif just for the record, to me this request was not about migrations declared as code.\nI much prefer to write them as actual sql statements. I don't see much value in the \"down for free\" thing either.\nBUT there are situations where you need to migrate the actual data, not the database schema, and which can't easily be done with SQL. Potentially with scripting the database a la pl/pgsql but it's usually much easier with regular application code.\nThis would be the prime use case for me.. FYI, building with current nightly fails again at the moment for me.\nEnabled features: [\"sqlite\", \"r2d2\", \"chrono\"].\nError:\nerror[E0275]: overflow evaluating the requirement `<&_ as insertable::Insertable<_>>::Values`\n  |                                                                         \n  = help: consider adding a `#![recursion_limit=\"512\"]` attribute to your crate\n  = note: required because of the requirements on the impl of `insertable::Insertable<_>` for `(&_, &_, &_)`\n  = note: required because of the requirements on the impl of `insertable::Insertable<_>` for `&(_, _, _)`\n  = note: required because of the requirements on the impl of `insertable::Insertable<_>` for `(&(_, _, _), &_, &_)`\n  = note: required because of the requirements on the impl of `insertable::Insertable<_>` for `&((_, _, _), _, _)`\n  = note: required because of the requirements on the impl of `insertable::Insertable<_>` for `(&((_, _, _), _, _), &_, &_)`\n.....\n.......\n. Understood.\nThe README should really reflect this new policy, though.\n. Guess I missed that. cough. ",
    "norcalli": "I would like to use diesel for a project at my job, and we use jsonb extensively. I would like to take on the project of implementing this, but I would need some help getting started.. This doesn't seem to have made it into the 0.8 release for Postgres, is it possible to prioritize a backend specific method for the next release? If I have the time, I may be able to send a PR (over the next few weeks). I understand.. I didn't mean to submit that comment, dang mobile. I understand, as I've had some dealings with trying to implement it myself in Scala/Slick, and I appreciate waiting to implement it properly.\nHave a good vacation!. What would you say is left for this PR to be acceptable? Implementing operators, integration tests, and perhaps the JsonB type alias?. I agree that operators are not essential and should/could come later. If I have some free time, I'll see about making some integration tests for you as well in a PR against this branch. Between all of us, someone should be able to get in an integration test or two :P. ",
    "emk": "I have a rather pressing need for this on a work project that's experimenting heavily with diesel, and I can almost certainly talk my boss into letting me work on this on company time extremely soon. (We really like diesel so far! But we want to use it for more things.)\nProbably the nicest and richest JSON representation in Rust right now is serde_json::Value. It's supported by lots of other libraries, and you can serialize and deserialize it in either direction:\nraw JSON String or Vec<u8> \u2194 serde_json::Value \u2194 Rust data structure implementing Serialize or Deserialize\nIt's super handy. The rust-postgres crate has some code showing how to set this up.\nOf course, this could be put under a serde_json feature, like the Uuid and chrono types are.\nShould I just go ahead and bang out a PR showing what I mean?. @killercup Thank you for the encouragement!\nI've opened a \"work in progress\" PR at #561, just so we can visualize what I'm thinking about. I agree that it would be an interesting possibility to do this as a separate plugin, but I'd prefer to try that after we see it working inside diesel itself!\nAlso, for the first version, I'm just targeting serialization and deserialization, and not the specialized JSON query operators. If we can begin by getting JSON into and out of the database, that will already help with a lot of use cases.\nAnyway, anybody who wants to help out is encouraged to check out #561, and submit comments, bug reports, and further PRs. :-) I'll continue the implementation discussion there.. I now have a preliminary implementation of the json and jsonb data types and conversion to and from serde_json::Value at #561! I haven't attempted to implement any of the JSON-specific query operators.\nSee #561 for instructions on how to try this out, and please let me know if it works!. I would be interested on working on this (as soon as I finish the uuid upgrade and integration tests). Do you have any ideas about what the API should look like?. Hmm, yeah, that's complicated enough that it would take me a long time to get up to speed.\nAre there any reasonably good ways to work around this missing feature? It turns out that we need it fairly badly in our Rust production app. I can obviously fall back to postgres and send raw SQL if all else fails. The feature we really need is ON CONFLICT DO NOTHING on a vector of records (specifically the second line of your example), which might make this slightly easier to work around.\nAny thoughts on the best way to tackle this?\n(I'm currently working on integration tests that prove we can mix serde and uuid and diesel without any problem, for the other issue I opened.). It's great to have this!\nI accidentally omitted use diesel::pg::upsert::OnConflictExtension; from my file, and Rust printed:\nerror: no method named `on_conflict_do_nothing` found for type `models::score::Score` in the current scope\n   --> src/scoring.rs:303:43\n    |\n303 |                     diesel::insert(&score.on_conflict_do_nothing())\n    |                                           ^^^^^^^^^^^^^^^^^^^^^^\n    |\n    = help: items from traits can only be used if the trait is in scope; the following trait is implemented but not in scope, perhaps add a `use` for it:\n    = help: candidate #1: `use diesel::pg::upsert::OnConflictExtension;`\nBut this was then followed by dozens of lines of errors like the following:\n= note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord<models::score::scores::table>` for `&std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<std::vec::Vec<_>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>`\nI'm not sure what's going on with that error message, but in addition to spamming my error output console, it looks a bit suspicious. We do have huge-tables enabled, but I can't figure out why that would result in very deeply nested vectors. So this might really be a separate issue, but I don't understand enough diesel internals to diagnose it.. Ah, thank you! Good to know. Is there an upstream bug for that which I can watch?\nI've fixed that, but now I'm hitting more weird errors. The following code compiles fine:\nrust\n                for score in new_scores {\n                    diesel::insert(&score.on_conflict_do_nothing())\n                        .into(scores::table)\n                        .execute(&*dconn)?;\n                }\nBut if I change it to:\nrust\n                for score_chunk in new_scores.chunks(5000) {\n                    diesel::insert(&score_chunk.on_conflict_do_nothing())\n                        .into(scores::table)\n                        .execute(&*dconn)?;\n                }\n...I get:\nerror: no method named `execute` found for type `diesel::query_builder::insert_statement::InsertStatement<models::score::scores::table, &diesel::pg::upsert::on_conflict_clause::OnConflictDoNothing<&&[models::score::Score]>>` in the current scope\n   --> src/scoring.rs:306:26\n    |\n306 |                         .execute(&*dconn)?;\n    |                          ^^^^^^^\n    |\n    = note: the method `execute` exists but the following trait bounds were not satisfied: `diesel::query_builder::insert_statement::InsertStatement<models::score::scores::table, &diesel::pg::upsert::on_conflict_clause::OnConflictDoNothing<&&[models::score::Score]>> : diesel::query_builder::QueryFragment<_>`, `&diesel::query_builder::insert_statement::InsertStatement<models::score::scores::table, &diesel::pg::upsert::on_conflict_clause::OnConflictDoNothing<&&[models::score::Score]>> : diesel::query_builder::QueryFragment<_>`, `&mut diesel::query_builder::insert_statement::InsertStatement<models::score::scores::table, &diesel::pg::upsert::on_conflict_clause::OnConflictDoNothing<&&[models::score::Score]>> : diesel::query_builder::QueryFragment<_>`, `&mut diesel::query_builder::insert_statement::InsertStatement<models::score::scores::table, &diesel::pg::upsert::on_conflict_clause::OnConflictDoNothing<&&[models::score::Score]>> : diesel::query_builder::QueryId`\nI've tried several variations of the basic syntax, but it generally results in errors before reaching execute.\n(I'm inserting rows in batches of 5,000 to avoid generating SQL INSERT INTO statements with more than 65,535 ? placeholders. This was necessary in earlier versions of diesel but I haven't checked the latest.). Here's what happens:\nerror[E0308]: mismatched types\n   --> src/scoring.rs:304:36\n    |\n304 |                     diesel::insert(score_chunk.on_conflict_do_nothing())\n    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected reference, found struct `diesel::pg::upsert::on_conflict_clause::OnConflictDoNothing`\n    |\n    = note: expected type `&_`\n    = note:    found type `diesel::pg::upsert::on_conflict_clause::OnConflictDoNothing<&&[models::score::Score]>`\nThe &&[..] is coming from on_conflict_do_nothing, maybe?\n. &(*score_chunk).on_conflict_do_nothing() produces:\nerror: no method named `on_conflict_do_nothing` found for type `[models::score::Score]` in the current scope\n   --> src/scoring.rs:304:52\n    |\n304 |                     diesel::insert(&(*score_chunk).on_conflict_do_nothing())\n    |                                                    ^^^^^^^^^^^^^^^^^^^^^^\n    |\n    = note: the method `on_conflict_do_nothing` exists but the following trait bounds were not satisfied: `[models::score::Score] : std::marker::Sized`\nThe second produces:\nerror[E0277]: the trait bound `[models::score::Score]: std::marker::Sized` is not satisfied\n   --> src/scoring.rs:305:37\n    |\n305 |                     diesel::insert(&OnConflictExtension::on_conflict_do_nothing(score_chunk))\n    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::marker::Sized` is not implemented for `[models::score::Score]`\n    |\n    = note: `[models::score::Score]` does not have a constant size known at compile-time\n    = note: required because of the requirements on the impl of `diesel::pg::upsert::OnConflictExtension` for `[models::score::Score]`\n    = note: required by `diesel::pg::upsert::OnConflictExtension::on_conflict_do_nothing`\nThere's probably a magic permutation which will work, but I haven't found it yet.. OK, cool. :-) Thank you for your help figuring this out!. This (or something like it) would be lovely! I would love to add Diesel support for a couple of types in https://github.com/faradayio/bigml-rs, but right now, it's prohibitively difficult to implement the full set of traits.. > In an ideal world one would only have to implement ToSql and FromSql for any custom type.\nOr if that fails because of trait coherence rules, then implementing ToSql and FromSql, and then calling one or more macros might also work.. OK, I think we're getting pretty close to a workable prototype! All the tests pass (including the new round-trip tests) and the following compiles:\nrust\ntable! {\n    jsons {\n        id -> Integer,\n        data -> Jsonb,\n    }\n}\nI'm going to try converting more code in one our projects, and see how it works. But first, a quick discussion of why I built this the way I did.\nWhy serde_json::Value is a good default JSON representation in Rust\nWhen working with JSON data, there are three representations we might want to use:\n\nA raw JSON &str or &[u8]. This is the format in which programs will tend to send and receive JSON data.\nA \"parsed\" representation of JSON. For example, serde_json::Value has the constructors Value::Bool, Value::Null, Value::String, etc., and it allows us to manipulate JSON data easily.\nA Rust data structure. For example, we might want to convert between { \"x\": 1, \"y\": 2 } and Point { x: 1, y: 2 }.\n\nAn ideal Rust JSON library should make it simple to convert between all three representations. There are a number of Rust libraries for working with JSON. The most popular are rustc_serialize and serde_json. Ideally it would be possible to support both, but if we were to choose one, serde_json is probably the better choice, because it has excellent support for converting between (1), (2) and (3). At the moment, some serde features do require a codegen plugin, but that will go away when Macros 1.1 lands. Also, serde appears to be the favorite choice among newer crates. I'd be happy to try to implement rustc_serialize, though!\nShould we support conversion to and from String and Vec<u8> using ToSql and FromSql?\nIf it's possible to easily support both these formats and serde_json::Value, then I would definitely be in favor of doing so!\nWhat about the JSON query types described in https://github.com/diesel-rs/diesel/issues/44#issue-120068652?\nThese are really interesting, but they're probably less urgent than simply reading and writing JSON data. Also, I'm not sure how to implement them. But I'd be happy to accept suggestions!\nIs this code ready to merge?\nWell, I'd love some feedback first! But so far, it seems to cover the basic use cases. I'm going to test this further by converting more internal code, and make sure there are no surprises. I'll let you know how it goes.\nI'd also love feedback and test reports from other potential users! To test this out, run:\nsh\ncd myproject-using-diesel\ngit clone -b pg-json-types https://github.com/faradayio/diesel.git\n...and add the following to your Cargo.toml:\ntoml\n[replace]\n\"diesel:0.9.1\" = { path = \"diesel/diesel\" }\n\"diesel_codegen:0.9.0\" = { path = \"diesel/diesel_codegen\" }\n\"diesel_codegen_shared:0.9.0\" = { path = \"diesel/diesel_codegen_shared\" }\n\"diesel_codegen_syntex:0.9.0\" = { path = \"diesel/diesel_codegen_syntex\" }. Thank you for the detailed review! I'll respond to your detailed comments with either fixes or responses shortly.\n\nEdit: Btw, I'm 75% certain that your code (with namespaces adjusted) would work as an external crate as-is. :)\n\nIs primitive_impls! exported somewhere? Because I've been trying to add Diesel integration for several types in https://github.com/faradayio/bigml-rs, and every time I try it, I wind up missing the queryable_impls! and expression_impls! macros that are used by primitive_impls!. If there were some way to access the necessary macros, then this would probably work fine.\n\nHmm, you mean like update(foo).set(bar.eq(r#\"{\"baz\": true}\"#)).execute(&connection)? I'm not sure if we should go that far. Is that a use case you have?\n\nNo, we have no immediate use case for this. The only thing I can imagine is grabbing raw JSON and sending it directly to a web client without deserializing and re-serializing it. If somebody wants it, they can always add it later. :-). > Other than the inline comments (from a quick read-though): Can you add some integration tests? E.g., create a table that has a jsonb column address, define a #[derive(Serialize, Deserialize)] struct Address { \u2026 }, and do some CRUD work on that column? This could also be done in a doc comment, so we generate a bit of documentation at the same time :)\nI'd love to add better integration tests! Right now, we do have the tests in diesel_tests that test the actual translation of JSON and jsonb between PostgreSQL and diesel, and those seem to work. This provides almost exactly the same test coverage as the existing uuid type, which I used as an example.\nWhere should I add tests that create a table and do more complex experiments? If you can point me at an existing file, I'd be happy to generalize from there.\nI'd also love to be able to test something like the code below, but I can't get table! or Queryable working in any of the obvious places (doc comments, etc.) without a bunch of errors.\n```rust\n[cfg(feature = \"postgres\")]\n[allow(dead_code)]\nmod jsonb_compile_test {\n    extern crate serde_json;\ntable! {\n    json_values {\n        id -> Integer,\n        value -> Jsonb,\n    }\n}\n\n#[derive(Queryable)]\nstruct JsonValue {\n    id: i32,\n    value: serde_json::Value,\n}\n\nfn get_json_value(conn: &diesel::Connection, id: i32)\n                  -> Result<JsonValue, diesel::Error> {\n    json_values::table.find(id).load::<JsonValue>(conn)\n}\n\n}\n```\nAnother patch is incoming soon which should address most of your other comments.. OK, I've pushed a bunch of fixes suggested in the code review. Thank you for looking at this PR!. Yes, it would really help to have a list.\nI've been procrastinating a bit on the integration tests, because the requested tests for json/jsonb are much more extensive than the existing tests for UUID, so I'm going to have to come up to speed on a fair bit of the code base to implement them.\nI think operators should not block the list.. @killercup I've merged your doc test onto my PR branch. Thank you!. Nope. I'm pretty happy with this personally, but if you want to combine the Json and Jsonb types somehow, we should do that.\nI'm dealing with an urgent production problem today, unfortunately.. We just ran into a case where we need this for our production application using a mix of diesel's PostgreSQL backend and some postgres. I'm probably going to have to roll back the diesel conversion of several tables that I just did. :-/\nHow much work would it be for me to implement this?. Looks good!\nI see this has been fixed on master and tagged for 0.10.1, but I don't think 0.10.1 has been published to crates.io yet.. Thank you! I've just successfully upgraded serde and it works fine with diesel's UUID support again. :+1:. Unfortunately, my only source for the magic numbers was Googling around and looking at what other libraries did, then confirming that it worked. :-/ I'll keep looking.. Unfortunately, that does not seem to be the case. I tried removing it and got expected trait std::error::Error, found enum pg::types::json::serde_json::Error.. ",
    "lholden": "@sgrif have you seen the rust-postgres-derive crate? \"Syntax extensions to automatically derive FromSql and ToSql implementations for Postgres enum, domain, and composite types.\" https://github.com/sfackler/rust-postgres-derive\nSomething like it might make sense for Diesel.. @cbrewster @killercup The composite stuff works... but many to many stuff is still messy by the looks of it.\nAn example of specifying a composite key in the table! macro:\nrust\ntable! {\n    firsts_seconds (first_id, second_id) {\n        first_id -> Integer,\n        second_id -> Integer,\n    }\n}\nAnd then I guess you can do a join query on the firsts_seconds and seconds where the first_id matches the id of the first you are starting with. . Figured I'd leave a comment here in case people go looking to use hstore with diesel. I've created a create that successfully serializes to/from hstore. Right now it's using a wrapper type due to not being able to impl AsExpression for HashMap. Sgrif had an idea for how this could be gotten around... so once I've explored that idea I'll get the crate published and share a link here so that others can use it.\nIt does not currently support any of the hstore operators however. Would love to end up doing this eventually. . ",
    "dbrgn": "PR #561 was merged, but this is still open. (For the record, Jsonb support can be enabled with the serde_json feature.)\nIt looks like the basic support is here, but without the operators, right?. I'd also like to request some documentation on this issue. I managed to implement FromSqlRow for a String based enum with the help from #429, but I can't get AsExpression working.. Finally got AsExpression to work: https://gist.github.com/dbrgn/9e88f54e23b4640bb3641734277a85dd. I'm also having segfaults for docker_cli in a musl based docker image.\nSteps to reproduce:\n$ docker run --rm -t -i clux/muslrust:stable /bin/bash\nroot@5caf11686839:/# apt-get update && apt-get install -y postgresql libpq-dev\nroot@5caf11686839:/# cargo install diesel_cli --no-default-features --features postgres\nroot@5caf11686839:/# /root/.cargo/bin/diesel \nSegmentation fault (core dumped)\nWhen debugging the coredump:\n```\ngdb /root/.cargo/bin/diesel core.357\nReading symbols from /root/.cargo/bin/diesel...done.\n[New LWP 357]\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nCore was generated by `./diesel'.\nProgram terminated with signal SIGSEGV, Segmentation fault.\n0  0x0000000000547607 in __vdsosym ()\n(gdb) bt\n0  0x0000000000547607 in __vdsosym ()\n1  0x00000000005463d3 in cgt_init ()\n2  0x00007ffc194bdce0 in ?? ()\n3  0x0000000000000000 in ?? ()\n```\nDoes that help?. Thanks, I wasn't aware of that.. @killercup did the requested changes and fixed the tests.\nRegarding the user table, see my comment above.\nLet me know if I should rebase / squash the commits in this PR.. @rubdos Numeric is something like a decimal type, right? so I guess what we'd lose is precision?. If Numeric is a decimal type, maybe there's a loss-free decimal type available in the Rust ecosystem? Or maybe we could add our own wrapper that can be converted to a float explicitly, if desired?. Refs #842.. This doesn't seem to work:\nerror[E0308]: mismatched types\n  --> src/db/mod.rs:69:77\n   |\n69 |         Ok(connection) => embedded_migrations::run_with_output(&connection, io::stdout())\n   |                                                                             ^^^^^^^^^^^^ expected mutable reference, found struct `std::io::Stdout`\n   |\n   = note: expected type `&mut std::io::Write`\n              found type `std::io::Stdout`\nInstead, you need to pass a mut reference:\nembedded_migrations::run_with_output(&connection, &mut std::io::stdout());\nHow come this wasn't caught by the test suite?\nAlso, maybe replace the Example: headline with # Examples? See https://github.com/diesel-rs/diesel/pull/840#pullrequestreview-31039462. Something else I noted: When using run_with_output instead of run, rust complains about the run function not being used:\nwarning: function is never used: `run`, #[warn(dead_code)] on by default\n  --> src/db/mod.rs:62:1\n   |\n62 | embed_migrations!();\n   | ^^^^^^^^^^^^^^^^^^^^\n   |\n   = note: this error originates in a macro outside of the current crate\nMaybe @weiznich knows how to deal with the warning?. @killercup Ok, I'll create a pull request :). I started. It's not in any working state yet though. https://github.com/dbrgn/diesel-hstore-rs. Oh, don't merge this yet, I found another problem in these docs.... Done: Updated the target of the count link :). No, it is required. Without it:\nerror[E0433]: failed to resolve. Use of undeclared type or module `users`\n  --> src/doctest_setup.rs:141:6\n   |\n141|     (users)\n   |      ^ Use of undeclared type or module `users`\nI thought about moving the table!  macro into the doctest_setup.rs module, but in some places the invocation is being displayed in the docs, so I didn't touch it and instead copied it around.. ",
    "tyre": "What's the work involved in supporting any serde_json::Serializable vs. just serde_json::Value? Happy to help out if I can.\nThe use case is an API client that returns a struct. The struct is serializable, but isn't a serde_json::Value, so to store the raw value I need to re-serialize, then re-de-serialize into a generic serde_json::Value.. @weiznich Fixed!. ",
    "jonnybrooks": "Was wondering if any progress has been made implementing json operators e.g. -> and such yet? If not, I'd love to try to implement this as I'm very interested in seeing this functionality in Diesel. ",
    "crackofdusk": "I wrapped the delete statements in try! instead so that we still acknowledge the possibility of an error.\n. All squashed, thanks for your feedback!\n. QueryResult<Vec<(...)>> is awkward here because load returns QueryResult<Cursor<_,_>>.\nWould the following be okay instead?\nrust\nfn users_with_name(connection: &Connection, target_name: &str)\n    -> Option<Vec<(i32, String, Option<String>)>>\n{\n    use self::users::dsl::*;\n    users.filter(name.eq(target_name)).load(connection)\n        .ok()\n        .map(|x| x.collect())\n}\n. Of course, silly me.\n. ",
    "lephyrius": "@sgrif That's how it is working with legacy code. :)\nTHX!\nWhy can't it be configurable? (might be a stupid question by me. Only knowing C++ templates. )\n. @sgrif it works!\nStill missing JSONB and HSTORE :(\n. @Eijebong Yes, let's close this.. ",
    "iamsebastian": "I'm totally sure it will be not a default case, but at the moment I got three tables (the whole db contains ~ 50 tables) with more than 26 columns (up to 40 columns). Is there are any chance, to get this compiled? I just tried to migrate an old data-structure from MySQL to Pg and would like to do a test-connection with the diesel-demo (, where the structure gets magically converted to ORM :grinning: )\n. Well done, sir. Thank you, Sean.\n. Would be a great addition, as I write a new Postgresql-rust/Nickel project, based on an existent MySQL-PHP project with dozens of tables.\n. Am I able to print out the schema with the infer_schema! macro, @sgrif ?\n. Because sometimes, as I started to use rust & diesel.rs, I struggled around if I had chosen the correct types, that match the types defined in the different postgres-tables (I migrated freshly to a postgres database from our mysql-production database).\n. ",
    "sologub": "I'd like to note that the Queryable name is used with a similar functionality in .NET LINQ, so the name difference may become a source of pain for .NET devs.\nBut I understand that this is a breaking change, so please feel free to just close this issue if you consider it unimportant.\n. ",
    "tomhoule": "Ok, thanks!\n. Well, I have been playing a little with diesel and I wrote a rough port of the rust-postgres support for chrono::DateTime using a wrapper struct to implement the Expression, FromSql<Timestamp> and ToSql<Timestamp> traits. The code seems to work (my tests are not very thorough, and I haven\u2019t checked if it works well for building queries yet, just (de)serialization) for the very limited case it covers.\nIt assumes everything is UTC and does not try to deal with timezones at the moment, but it should be possible at least to the same extent as what exists in rust-postgres.\nThe rust-postgres implementation of the feature is in this file\nIf it can be of any help, I can share, expand, complete and polish up the code, write tests and make a PR.\n. I worked a little on this, I doubt it is fully functional, but I\u2019ll open a PR right away so you can see if it is worth continuing.\nMy first implementation was in application code, but of course I had to wrap it in a newtype, and write down the serde traits for serialization, etc. So that was not particularly ergonomic.\n. Wow, that was quick! Great! (It\u2019s my first real code PR on github!) Thanks for the guidance!\nI was just checking the official documentation and even the postgres source (that was not very helpful) to see how binary timestamps are handled with respect to timezones.\nI can\u2019t say I grok all the implications of the impls with timezones, so it is probably safer to remove them indeed.\nWhat I understand from the official docs is that the binary representation is always UTC, and timestamptz is only meant to indicate a time zone should be provided in the input expression so postgres can properly convert it to the internal UTC representation. On the output side, everything is converted to (or interpreted as, if it is a timestamp sans timezone) local time. (I may very well be wrong).\nI will most definitely try to do dates and times too if no one else does it first.\n. The tests have been rewritten, they are a lot prettier now.\nThe last rebase was a bit hairy, I think it has been dealt with adequately but am not 100% sure.\n(I am going to sleep now, I will be back tomorrow morning)\n. Done!\n. It\u2019s been a pleasure. As an unexperienced developer, the feedback you provided is very much appreciated. I will try to work on dates with what you have already written this evening (western european time) if no one else has by then.\n. True, it\u2019s done.\n. Also done!\n. Should I update the other tests in the module as well?\n. Cool, will do.\n. ",
    "JohnMH": "Why is there no \"sql type\" for unsigned integers? In MySQL, for example, it is perfectly valid to have an INT UNSIGNED.. ",
    "cmr": "Looks good\nOn January 11, 2016 11:50:34 AM EST, Sean Griffin notifications@github.com wrote:\n\nreview? @cmr\nDid I miss anything?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/sgrif/diesel/pull/85#issuecomment-170615164\n\n\nSent from my Android device with K-9 Mail. Please excuse my brevity.\n. ",
    "beefsack": "Have been using the current iteration of associations and has been working really well in my testing.\nOne case I'm not sure the current implementation covers is as below; having multiple belongs_to for through different fields to the same table.\n```rust\n[derive(Debug, PartialEq, Clone, Queryable, Identifiable, Associations)]\n[belongs_to(User, foreign_key=\"source_user_id\")]\n[belongs_to(User, foreign_key=\"target_user_id\")]\npub struct Friend {\n    pub id: Uuid,\n    pub created_at: NaiveDateTime,\n    pub updated_at: NaiveDateTime,\n    pub source_user_id: Uuid,\n    pub target_user_id: Uuid,\n    pub has_accepted: Option,\n}\n```\nThe error is:\nfile: 'file:///...%3CBelongsTo%20macros%3E'\nseverity: 'Error'\nmessage: 'conflicting implementations of trait `diesel::associations::BelongsTo<db::models::User>` for type `db::models::Friend`:\nconflicting implementation for `db::models::Friend`'\nat: '37,1'\nsource: 'rustc'\nI'm not seeing these sorts of relationships defined in the issue description so thought I would bring it up.. Dupe of #960.. ",
    "sbstp": "I don't think that what @beefsack pointed out has been fixed.\nHere's what I'm trying to do and the error I get\n```rust\n[macro_use]\nextern crate diesel;\nuse diesel::prelude::*;\nmod schema {\n    table! {\n        humans {\n            id -> Integer,\n            name -> VarChar,\n            father_id -> Integer,\n            mother_id -> Integer,\n        }\n    }\n}\nuse schema::*;\n[derive(PartialEq, Debug, Associations, Identifiable, Queryable)]\n[belongs_to(Human, foreign_key = \"father_id\")]\n[belongs_to(Human, foreign_key = \"mother_id\")]\nstruct Human {\n    id: i32,\n    name: String,\n    father_id: i32,\n    mother_id: i32,\n}\n```\n``\nerror[E0119]: conflicting implementations of traitdiesel::associations::BelongsTofor typeHuman:\n  --> src/main.rs:20:28\n   |\n20 | #[derive(PartialEq, Debug, Associations, Identifiable, Queryable)]\n   |                            ^^^^^^^^^^^^\n   |                            |\n   |                            first implementation here\n   |                            conflicting implementation forHuman`\n   |\n   = note: this error originates in a macro outside of the current crate (in Nightly builds, run with -Z external-macro-backtrace for more info)\nerror: aborting due to 2 previous errors\n```\n. @Raytlty I think there is. Just newtype the Human struct as two different strucs like so: struct Father(pub Human), struct Mother(pub Human) and use #[belongs_to(Father, foreign_key = \"father_id\")]\n#[belongs_to(Mother, foreign_key = \"mother_id\")]. Haven't tested it but it should work.. ",
    "Raytlty": "@sbstp I wonder if there are any solutions for this problem. THANKS.. @sbstp Thanks, I just test it and it work! . @weiznich  Much Appreciate! I figured it out yesterday. THX reply.. ",
    "brendanzab": "The reliance on Syntex scares me, as somebody who wished to introduce Rust for one of our data analytics projects. I would have definitely been more confident if there were macro alternatives available, in lieu of the stabilization of syntax extensions :(\n. ",
    "hayathms": "Please show how to use this Timestamptz. I am having error infer_schema on db for timestamp pg fields.\nneed more examples covering a practical pg table implementation. I am trying to migrate old django projects in to Iron+Diesel and having issues here.\n. ",
    "pseudomuto": "Just browsing around here...did #126 close this?\n. ",
    "YetAnotherMinion": "Would copy pasting this information to the GitHub wiki make sense? I am completely unfamiliar with the GitHub API, so if putting information in issues makes it easier to programmatically export it from GitHub then I retract. I saw that the wiki has zero pages and that made me pause and come back to ask for permission.\nedit: Or as it occurred to me, just put the markdown files into the repository itself, perhaps in a brand new contributing or meta-doc directory.. @sgrif Good idea. I tried it and found the URL crate is unable to parse the postgres percent encoded unix domain socket format (postgresql://%2Fvar%2Flib%2Fpostgresql/dbname), which is the one connection string format I actually need. Other than that the code is really short. \nWhen you go to handling the error case, it looks like you are back to manually implementing regex.\n```rust\nfn change_database_of_url(database_url: &str, default_database: &str) -> (String, String) {\n    let mut connection_string = match Url::parse(database_url) {              \n        Ok(string) => string,                                                 \n        Err(_) => {println!(\"{}\", database_url); panic!()},                   \n    };                                                                        \n    let database: String = connection_string.path().trim_left_matches('/').to_string();\n    connection_string.set_path(default_database);                               \n(database, connection_string.into_string())\n\n}\n``. Note that using URL crate will not solve the problem of being unable to use question mark character in the name of MySQL databases.. @jaemk provided regex panics onr\"postgresql://user@host:3200/dbname?param1=value1&p2=v2\"`\nI think that before any more effort to implement connection string parsing is expended, we need to determine exactly what the grammar for Postgres and MySQL connection strings are. We have tried the route of \"string split here and there\" or run a quick regex which satisfies 95% of users but now the long tail has dragged itself out of the woods.\nAka: We need the specification for connection strings beyond just the cutesy \"these are the parts of the connection string\" provided by database online documentation. What characters are allowed in each part? Are there escapes? Once we have a complete specification we can proceed with firm footing. Otherwise this piece of code will be rewritten half a dozen times over coming years as each new technically correct connection strings slams into the \"works for me\" code merged by the previous voyager.\nedit: I submit that the database C driver code is the final authority. Postgres at least has the code available for free here https://github.com/postgres/postgres/blob/674677c705f11464857e6dfd0a0d6104656d9c4a/src/interfaces/libpq/fe-connect.c#L5174. after reading the libpq source I can speak authoritatively that for Postgres that\n\nthe user cannot contain the characters '@' and '/' but can contain the ':' character\nthe password cannot contain the '@' or ':' character but can contain the '/' character\nthe netloc cannot contain the ':', '/', '?', or ',' characters\nthe dbname cannot contain the '?' character\n\nGiven the context dependent requirements for parsing, I doubt that a readable regex can be constructed to parse this string. It would be simpler to wire up rust C-bindings to the already functional postgres C code where the automata has been constructed by hand over several hundred lines.\n. @jaemk Obviously it is possible by definition to write a regex because that C parser is a finite automata. However there are two problems I forsee with regex based solution\n1. Readability. Consider the email specification -- looks like an even simpler grammar than connection strings -- which has an ungodly long regex.\n2. The full connection spec needs to be met. This simple pull request (which greatly expands subset of connection strings that will now be parsed correctly) has brought every nitpicker out of the woodwork complaining how it is not perfect. It is apparent to me that only a perfectly standards compliant implementation will be allowed to merge.\nI just want the correct functionality for non standard directory unix sockets to be available from upstream so I can stop screwing around with symlinks. The whole point of using a non standard directory was so I did not have to learn where each different distro's postgres package considers \"default\" .\nThe code sitting in front of you today satisfies:\n\nif connection strings are restricted to a reasonable subset,\n\nand does not pull in an extra dependency on the regex crate for the extremely simple use case of change the database name. That's it. The entire business requirement is only to parse the database name, nothing else.. @sgrif \n\nSince this applies to drivers other than libpq (and even our PG driver won't use libpq forever), I'd prefer to keep our specification separate. That said, I suspect that they will align more often than not.\n\nI do not understand your reasoning for deciding to introduce a new competing universal standard here, could you elaborate?\nI understand that it is very tempting to change the specification to cover the case of shoving a potentially square peg into the off the shelf round hole by just banning square pegs. \n\nNo, we can fix one issue at a time, and open issues for each bug as they come in.\n\nThis is exactly what I do at work because my boss's incentive compensation is tied to average age of tickets. That line of thinking is what we all do 5 days a week at work, and it is exactly that approach that drive me nuts.  It is the weekend, it is my time, let cost-benefit of complete resolution be damned. I -- personally -- would strongly prefer to implement The Right Thing That Completely Addresses The Underlying Problem (tm).\nI understand the aversion to writing lots of code. The best code is the lines you never write. However there is no business pressure to be quick right now. No manager pressuring you to just hack something together so you can close the ticket before lunch (to avoid that extra 30 minutes of time to close). We can take as long as we want to implement a robust, simple, and sound solution that completely solves the issue. No more connection string related issues is a glorious future that I can look forward to. \n\nIf the consensus is to use the URL crate then I can go to the URL repository, spend time to understand their code, submit PR, wait weeks to get it merged, wait more weeks to get a point release, come back here and introduce the fixed URL crate.\nAt this point I don't care about turnaround. My original hope was that I could fix the problem I encountered that Friday at work on my own time over the weekend so that crates.io would have the fixed version when I came into Monday. I was encouraged by the active Gitter channel, that I got a response to my questions, and even PR comments the next day. But then nothing happened and I had to go into work that Monday and spend time inserting the patched version of diesel into build farm and development images. That is just another sunk cost now.\nThe reason I am still here and willing to work on this is because I care about the elegant and correct. It would please me to be part of the \"it just works\" foundation of the world, where anyone in the future can switch to diesel, use their existing connection strings, and it always works. No chasing rabbit holes where you think the database was set up incorrectly (because coincidentally you just upgraded the OS for the developer image).\nMy argument against your proposal to require a URL grammar for connection strings is that it stands against the principle of least surprise. The least surprise for me would be to take an existing connection string from a working application, add it to diesel, and it always works. I don't think introducing a new proprietary format is the best tradeoff to make; against having a free internet volunteer spend an hour porting some while loops from C to Rust. \n. Appveyor cannot reach crates.io, that is why CI is failing.\nUpdating registry `https://github.com/rust-lang/crates.io-index`\nerror: failed to load source for a dependency on `time`\nCaused by:\n  Unable to update registry https://github.com/rust-lang/crates.io-index\nTo learn more, run the command again with --verbose.. After examining URL RFC and the URL crate, I do not thing that getting percent encoding for the host will be free. out of \n```\nurl            = httpurl | ftpurl | newsurl |\n                 nntpurl | telneturl | gopherurl |\n                 waisurl | mailtourl | fileurl |\n                 prosperourl | otherurl\n```\nYou are correct that the database connection strings are defined within the URL RFC\n```\n3.1. Common Internet Scheme Syntax. How\n//:@:/\nSome or all of the parts \":@\", \":\",\n   \":\", and \"/\" may be excluded.  The scheme specific\n   data start with a double slash \"//\" to indicate that it complies with\n   the common Internet scheme syntax. The different components obey the\n   following rules:\nuser\n    An optional user name. Some schemes (e.g., ftp) allow the\n    specification of a user name.\n\npassword\n    An optional password. If present, it follows the user\n    name separated from it by a colon.\n\nThe user name (and password), if present, are followed by a\n   commercial at-sign \"@\". Within the user and password field, any \":\",\n   \"@\", or \"/\" must be encoded.\n```\nHowever it looks like the URL crate only implements a subset of the grammar, specifically the subset useful for a browser. They do not have a generic parser for Common Internet Scheme Syntax. For web urls (http, https, ftp, gopher), percent encoding is not permitted in the host part. To use the URL crate it looks like you would need to introduce a new abstraction for  Common Internet Scheme Syntax and I am not sure how well that would be received as it is pretty orthogonal to the purpose of Servo's needs.. @sgrif  That is really unfortunate given that I gave you every change you asked for. You wanted to use the URL crate and I put that into the PR, you wanted to not handle every case, I put a panic! in for the todo.\nI registered my strong objections to your design choices but in the patch I submitted over a month ago I put in exactly what you asked for and nothing more.\nIt feels like you did not even read the PR, which is very short (+51 -15), and just made a decision based on the large amounts of text I produced to support my position that using the URL parser crate was a Bad Idea.\nGithub is not showing me any merge conflicts, what do you mean?. My opinion is that if you want to parse database connection strings, you should create a separate crate for that functionality instead of using a different grammar that is \"kinda close\" to what you actually want to parse. Then go into the authoritative C source code of the database drivers and use corrode to transfer the parsing grammar into rust (or do it by hand). \nedit: after reading the libpq source I can speak authoritatively that for Postgres that\n- the user cannot contain the characters '@' and '/' but can contain the ':' character\n- the password cannot contain the '@' or ':' character but can contain the '/' character\n- the netloc cannot contain the ':', '/', '?', or ',' characters\n- the dbname cannot contain the '?' character\n. @sgrif \n```diff\ndiff --git a/diesel_cli/Cargo.toml b/diesel_cli/Cargo.toml\nindex 990e6dd..ff855e5 100644\n--- a/diesel_cli/Cargo.toml\n+++ b/diesel_cli/Cargo.toml\n@@ -22,6 +22,7 @@ dotenv = \">=0.8, <0.11\"\n infer_schema_internals = { version = \"1.1.0\" }\n clippy = { optional = true, version = \"=0.0.174\" }\n migrations_internals = { version = \"1.1.0\" }\n+url = \"1.6\"\n[dev-dependencies]\n difference = \"1.0\"\ndiff --git a/diesel_cli/src/database.rs b/diesel_cli/src/database.rs\nindex 5576ff2..1c0a6ce 100644\n--- a/diesel_cli/src/database.rs\n+++ b/diesel_cli/src/database.rs\n@@ -5,6 +5,7 @@ use diesel::*;\n use migrations_internals as migrations;\n #[cfg(any(feature = \"postgres\", feature = \"mysql\"))]\n use super::query_helper;\n+use url::Url;\nuse database_error::{DatabaseError, DatabaseResult};\n@@ -323,10 +324,20 @@ pub fn database_url(matches: &ArgMatches) -> String {\n#[cfg(any(feature = \"postgres\", feature = \"mysql\"))]\n fn change_database_of_url(database_url: &str, default_database: &str) -> (String, String) {\n-    let mut split: Vec<&str> = database_url.split('/').collect();\n-    let database = split.pop().unwrap();\n-    let new_url = format!(\"{}/{}\", split.join(\"/\"), default_database);\n-    (database.to_owned(), new_url)\n+    // This method accepts a MySQL or Postgres connection string that conforms to URL BNF grammar\n+    // only (and not the database connection string grammars) and returns the name of the database\n+    // and a new connection string to the database specified by the default_database argument. If\n+    // the database name is not specified in the connection string then we default to an empty\n+    // string. NOTE: This function does not validate connection strings (look at the signature, no\n+    // Option or Result is there).\n+\n+    // TODO: handle unix connection strings with percent encoded paths such as:\n+    //  postgres://%2Fvar%2Flib/dbname\n+    let mut url = Url::parse(database_url).expect(\"failed to parse connection string\");\n+    let database: String = url.path().trim_left_matches('/').to_string();\n+    url.set_path(default_database);\n+\n+    (database, url.into_string())\n }\n#[cfg_attr(feature = \"clippy\", allow(needless_pass_by_value))]\n@@ -341,14 +352,42 @@ mod tests {\n #[test]\n fn split_pg_connection_string_returns_postgres_url_and_database() {\n\n\nlet database = \"database\".to_owned();\nlet base_url = \"postgresql://localhost:5432\".to_owned();\nlet database_url = format!(\"{}/{}\", base_url, database);\nlet postgres_url = format!(\"{}/{}\", base_url, \"postgres\");\nassert_eq!(\n(database, postgres_url),\nchange_database_of_url(&database_url, \"postgres\")\n);\n// format: (original_string, dbname, expected_changed_string)\nlet test_cases: [(&'static str, &'static str, &'static str); 10] = [\n(\"postgresql://\", \"\", \"postgresql:///postgres\"),\n(\"postgresql://localhost\", \"\" ,\"postgresql://localhost/postgres\"),\n(\"postgresql://localhost:5433\", \"\", \"postgresql://localhost:5433/postgres\"),\n(\"postgresql://localhost/mydb\", \"mydb\", \"postgresql://localhost/postgres\"),\n(\"postgresql://user@localhost\", \"\",\"postgresql://user@localhost/postgres\"),\n(\"postgresql://user:secret@localhost\", \"\", \"postgresql://user:secret@localhost/postgres\"),\n(\"postgresql://other@localhost/otherdb?connect_timeout=10&application_name=myapp\", \"otherdb\", \"postgresql://other@localhost/postgres?connect_timeout=10&application_name=myapp\" ),\n(\"postgresql:///mydb?host=localhost&port=5433\", \"mydb\", \"postgresql:///postgres?host=localhost&port=5433\"),\n(\"postgresql://[2001:db8::1234]/database\", \"database\", \"postgresql://[2001:db8::1234]/postgres\"),\n(\"postgresql:///dbname?host=/var/lib/postgresql\", \"dbname\", \"postgresql:///postgres?host=/var/lib/postgresql\"),\n// TODO: Support opaque origins\n//(\"postgresql://%2Fvar%2Flib%2Fpostgresql/dbname\", \"dbname\", \"postgresql://%2Fvar%2Flib%2Fpostgresql/postgres\"),\n];\nfor &(database_url, database, postgres_url) in &test_cases {\nassert_eq!((database.to_owned(), postgres_url.to_owned()), change_database_of_url(database_url, \"postgres\"));\n}\n}\n+\n\n[test]\n\nfn split_mysql_connection_string_returns_mysql_url_and_database() {\n// format: (original_string, dbname, expected_changed_string)\nlet test_cases: [(&'static str, &'static str, &'static str); 8] = [\n(\"mysql://\", \"\", \"mysql:///information_schema\"),\n(\"mysql://localhost\", \"\" ,\"mysql://localhost/information_schema\"),\n(\"mysql://localhost:5433\", \"\", \"mysql://localhost:5433/information_schema\"),\n(\"mysql://localhost/mydb\", \"mydb\", \"mysql://localhost/information_schema\"),\n(\"mysql://user@localhost\", \"\",\"mysql://user@localhost/information_schema\"),\n(\"mysql://user:secret@localhost\", \"\", \"mysql://user:secret@localhost/information_schema\"),\n(\"mysql://other@localhost/otherdb\", \"otherdb\", \"mysql://other@localhost/information_schema\"),\n(\"mysql://other@localhost:1122/otherdb\", \"otherdb\", \"mysql://other@localhost:1122/information_schema\"),\n];\nfor &(database_url, database, mysql_url) in &test_cases {\nassert_eq!((database.to_owned(), mysql_url.to_owned()), change_database_of_url(database_url, \"information_schema\"));\n\n}\n     }\n#[test]\ndiff --git a/diesel_cli/src/main.rs b/diesel_cli/src/main.rs\nindex 3f689b1..4025e51 100644\n--- a/diesel_cli/src/main.rs\n+++ b/diesel_cli/src/main.rs\n@@ -15,6 +15,7 @@ extern crate clap;\n #[cfg_attr(any(feature = \"mysql\", feature = \"postgres\"), macro_use)]\n extern crate diesel;\n extern crate dotenv;\n+extern crate url;\n extern crate infer_schema_internals;\n extern crate migrations_internals;\n ``. Related, the column namenodesalso causes the table macro to fail. One of diesel's internal modules is namednodesand that causes an ambiguous import error when the table macro is expanded.. Looking at #1561 which also adds a type to diesel, do I need to implementSelectableExpression,AppearsOnTable,Expression? Also isQueryFragment` impl needed?. - Added link to Postgresql docs for Point datatype in changelog.\n- Used intra module documentation links\n- Removed unnecessary box errors\n- Rustfmtted\n\n\nThe doc test example still fails. Should I choose a different example (like using the point as a member on a struct instead of querying on the value of the point) or does query fragment need to be implemented so a point's value can be used in a where clause?\nMy use case never directly queries a point value, if I am doing point related queries then I have already hand wrote the sql anyway (bounding box queries) and I am usually returning the entire row.\n. I looked into adding the Postgres geometric operators to diesel in src/pg/expression/operators.rs and src/pg/expression/expression_methods.rs. The design constraint I ran into there is that some geometric operators have restrictions on operand types for both left and right hand sides.  For example, the is horizontally aligned operator ?- is implemented by PG for point -> point -> bool, but not for polygon -> polygon -> bool.\nI want to verify my understanding of the design of expression methods with you:\n- The operator structs are in the public API where anyone can shove any type into them?\n- The SQL generated from raw use of operator structs may not be supported by the backend?\n- Traits are used to provide builder pattern dsl methods for valid combinations only?\n- If you use the .method style dsl then the generated SQL will be valid for the backend, i.e. no operator errors?\nI am leary to blindly create a trait like PgGeometricExpressionMethods that happens to work for all point -> point -> result operators, but then puts the next person who wants to add another geometric type such as circle into a bind because the trait bounds on my naive PgGeometricExpressionMethods were too loose.\nA naive forward compatible design would be to just have a separate trait for each geometric operator that is generic over right and left hand side types, with impls for each possible type signature. I would  use a script to brute force find valid type signatures for each operator.\nAll other approaches I could think of were more complicated.. Having another crate for geometric operators is fine with us (what we are doing already). Do you think that crate should be owned by diesel-rs just like diesel_full_text_search or operated by a random third party?\nThe only reason I thought of upstreaming into diesel is like you said:\n\nbecause these types are in ever PG installation, not an extension.\n\nI brought up adding the operators because I noticed when writing tests that the Eq operator is not valid for point type in Postgres, but diesel lets it compile anyway (fails at runtime with DatabaseError). The runtime error when using schema::dsl::column_name.eq(PgPoint(3,4)) is what I was referring to with:\n\nIf you use the .method style dsl then the generated SQL will be valid for the backend, i.e. no operator errors?\n\nPlease let me know if there are any more changes, more tests, etc.. that you would like me to make.\n. @vjousse https://github.com/ThinkAlexandria/diesel_geometry\nhttps://crates.io/crates/diesel_geometry\nOnly the types and operators that my work needed have been implemented so far. PgPoint, PgBox, the <@ \"is contained by\" operator, and ~= \"same as\" operator. Open an issue if you need more types or operators.. So I went and looked up libc's implementation. https://doc.rust-lang.org/1.7.0/libc/constant.AF_INET.html. It is always 2. Now if you can point me to a list of all the architectures diesel supports I will happily go and verify the values of AF_INET for all of the architectures. from postgres source code https://doxygen.postgresql.org/utils_2inet_8h.html#a8ba3e5fe500d587d3eb8699968450b18, they rely on AF_INET from . New unit test added. This function should correctly parse every valid Postgres connection string. On the other side of the fence, not all valid MySQL connection strings are supported. I could not find official documentation of MySQL connection string grammar (found the JDBC and ODBC, but not the c library), so I just used the grammar documented in diesel itself (http://docs.diesel.rs/diesel/mysql/struct.MysqlConnection.html).. @sgrif You mean code looking like this PR? https://github.com/diesel-rs/diesel/pull/861/files. Should this be just a raw tuple i.e. (f64, f64)?. Do I need a debug_assert! counting the number of bytes I expect (16bytes for point)? Some types have it, some don't.\n. ",
    "Virviil": "I have installed it by the \"official\" way frm here: http://www.enterprisedb.com/products-services-training/pgdownload#windows\n...\\PostgreSQL\\9.5\\bin realy was not in my PATH.\nAfter adding problem is not solved. \n. Yes, cargo clean solved the problem, thank you. Mb you previous post should be somehow added to readme or faq, i didn't found anything about PATH, and in windows world it's probably not so obvious as in nix.\n. I took the idea from here:\nhttp://www.xyzpub.com/en/ruby-on-rails/4.0/seed_rb.html\nDont think, that seeds.sql is the best way to make the bootstrap, but migrations for now are made without orm but with sql raw syntax, so I made seeds also in row sql. This is \"first\" iteration, just not to start conversation about new feature without some \"working\" solution.\nAlso, I think that seeds should be called directly with setup, but didn't want to change run_setup_command code, so this is probably up to maintainers.\nAlso, some instrument to generate seed from existing database should be performed. Mb \nseed export --table_name to add/replace full table data into seed.{ext}\n. > Dont think, that seeds.sql is the best way to make the bootstrap\nI thought about seeds.toml file with such structure:\n``` toml\n[[table_name]]\ncol1 = \"val1\"\n...\ncoln = \"valn\"\n[[table_name]]\n...\n[[table2_name]]\n...\n```\nor mb seeds.rs which would use foo::schema::*and working with ORM types directly.\n\nconcrete use case\n\nSchema and data should be separated, because for testing, dev databases you can need some mock data, and for some test this data should be not random, but in deployment you dont need this mock data.\n\nwe should have a db/ directory that holds migrations, seeds, and others, a la ActiveRecord\n\nIn ActiveRecord migration is single file, which store up, down, and change description. but here each migration probably should be stored in a directory, because have 2 sql files, so what the difference of the name of root dir: migrations or db? The only benefit of having db dir, as I understand, is having there gitignored db.toml file, which can automaticly give connection string for diesel_cli or even for the entire app.\n. ",
    "bradurani": "It seems like in the future you might want to return more than just the data returned by the query. What if you have query timing turned on for instance, and want to return the execution time along with the results?\n. I'm still very new to Rust, so forgive me if I'm way off base, but returning Vec<T> requires you to do the grouping before reading the first result, which means you're doing extra work in the odd case that the query results are never used, right? With Box<Iterator<Item=T>>, you can group the results only after the first .next() and be lazier, yet still avoid the exponential algorithm, no?\n. Procore\nhttps://camo.githubusercontent.com/28339e0cd0c4f5ddb3b4f63f369ce4e38a8cb7bc/68747470733a2f2f7777772e70726f636f72652e636f6d2f696d616765732f70726f636f72655f6c6f676f2e706e67. ",
    "Ciantic": "Hmm, now it gives a longer error:\nnote: ld: skipping incompatible C:/Copies/.../PgSQL/lib/libpq.dll when searching for -lpq\nld: skipping incompatible C:/Copies/.../PgSQL/lib/libpq.dll when searching for -lpq\nld: cannot find -lpq\n. Yes I also suspected this from the error message. It seems to be incorrect version (32 bit), if I could only find portable 64bit version to try...\nBut I think the cargo clean && cargo build solved the first issue so perhaps you can close this.\n. Note for future reference:\nI found the 64 bit binary zip, which is portable already: http://www.postgresql.org/download/windows/ (note the small zip archive link at the end)\n. ",
    "tamird": "Done and done.\n. there's no need to allocate here. How about:\nrust\nfile_names(path).map(|files| {\n  files.contains(\"down.sql\") && files.contains(\"up.sql\")\n}).unwrap_or(false)\n. To clarify, are you asking that I make that change throughout?\n. Done.\n. errant blank line. (in the wrong commit). (in the wrong commit). (in the wrong commit). ",
    "dpc": "slog is like LEGO for Rust logging, so exposes all the important details. That's why eg. creating logger might feel verbose. I've changed strategy a bit, and to smooth the learning curve I explicitly advise newcomers to use https://docs.rs/sloggers \nAlso, if diesel wants to shield users from the complexity of building a Drain and root Logger in slog, the following can be done:\nimpl Connection {\n   fn set_stderr_logger(level: Level) { ... }\n   fn set_stdout_logger(level: Level) { ... }\n   fn set_file_logger(level: Level, path: &Path) { ... }\n   fn set_custom_logger(log : slog::Logger) { ... }\n}\n\nso, as many common methods, that do the hard part for the user and set up the right logging configuration, and one \"advanced\" method for brave souls who need something custom, and want to get more dirty with slog.. I'm sorry. I was/am busy. I was wondering if this might have something to do with lack of attached tty or something. I'm fine with closing. Maybe someone will Google it, or I'll get more time to investigate localy.. I have found a reason. Basically, I'm using neomake and it will run cargo check in the src/, as opposed to root project directory. This usually works just fine. But here, in my src/schema.rs I have:\n\ninfer_schema!(\"dotenv:DATABASE_URL\");\nand my DATABASE_URL points to test.db, which is relative. It works fine when I'm in root directory, but in relative directory, it will just create an empty test.db and fail to infer anything.\nSince cargo build does work when started in ./src I don't think this is a neomake problem.\nIt is a bit of a footgun, and it would be great if could be avoided somehow.. ",
    "lolgesten": "@sgrif enabling log_statement 'all' isn't a good workaround. I'm trying to figure out why an insert is throwing off my constraints, so I tried to log all and found this:\n2018-03-08 09:12:58.527 GMT [70] STATEMENT:  INSERT INTO \"live\" (\"recording_id\", \"time_stamp\", \"time_offset\", \"user_id\", \"role\", \"kind\", \"reason\", \"ice_conn_state\", \"state\", \"moderator\", \"screen\", \"camera\", \"mic\", \"actual_enc_br\", \"available_send_bw\", \"retransmit_br\", \"available_recv_bw\", \"target_enc_br\", \"bucket_delay\", \"transmit_br\", \"origin\", \"track\", \"bit_rate\", \"packet_rate\", \"packet_loss\", \"jitter\", \"rtt\", \"nack_count\", \"peak_level\", \"fir_count\", \"pli_count\", \"framerate\", \"avg_encode_time\", \"avg_qp\") VALUES ($1, $2, $3, $4, $5, $6, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT), ($7, $8, $9, $10, $11, $12, $13, DEFAULT, $14, $15, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT, DEFAULT)\nI.e. the postgres logs do not actually show you the values, so it's not a good replacement for hunting down bugs.. ",
    "jgillich": "Yes, please. Here is one that drives me crazy:\n``\nsrc/models/artist.rs:17:61: 17:66 error: the traitdiesel::types::FromSqlRowis not implemented for the typecollections::string::String` [E0277]\nsrc/models/artist.rs:17         match artists::table.filter(artists::name.eq(name)).first(conn) {\n                                                                                ^~~~~\n\nsrc/models/artist.rs:17:61: 17:66 help: run rustc --explain E0277 to see a detailed explanation\nsrc/models/artist.rs:17:61: 17:66 help: the following implementations were found:\nsrc/models/artist.rs:17:61: 17:66 help:   >\nsrc/models/artist.rs:17:61: 17:66 help:   >\n```\nModel:\n```\n[derive(Queryable)]\npub struct Artist {\n    pub name: String,\n    pub id: i32\n}\n```\nI looked at the tests and the code looks alright. But I'm also just getting started with Diesel, so maybe I got something fundamentally wrong..\n. Oh wow, the order matters? I had no idea haha, thanks!\n. Ah, I missed infer_schema only works with pg, so this will be fixed by https://github.com/sgrif/diesel/pull/226\n. What exactly would I have to install? I've added libsqlite3-dev, is there anything that would be needed?\nI do plan on using both in the future actually.\n. No, you can set addons.apt.packages when you're using containers. Check the build log (Installing APT Packages), it was definitely installed. So yes, the issue is that diesel_cli only builds in VMs.\n. ",
    "TheNeikos": "\nOrder Matters\n\nI believe this is something that could be adressed (for now) in the guide as I just stumbled onto this as well, and it cost me around more than hour trying to find out what is going on.\n. Hm, doing that gives me this error:\n``\nerror[E0275]: overflow evaluating the requirement, diesel::types::Integer), models::schema::submissions::table, > as diesel::boxed_dsl::InternalBoxedDsl<', _>>::Output--> src/models/submission.rs:389:55\n    |\n389 |             query = query.filter(user_id.eq(user.id)).into_boxed();\n    |                                                       ^^^^^^^^^^\n    |\n    = note: consider adding a#![recursion_limit=\"128\"]` attribute to your crate\n```\nAdding that attribute just raises it to 256 :v\n\nEdit: Okay, adding into_boxed to the first line makes it compile. So there is that.\nThanks!\n. ",
    "ggrochow": "This is one you helped me with in gitter.im \nerror[E0277]: the trait bound `(): diesel::Queryable<(diesel::types::Integer, diesel::types::Integer, diesel::types::Text, diesel::types::Text, diesel::types::Timestamp, diesel::types::Timestamp, diesel::types::Text, diesel::types::Text), diesel::pg::Pg>` is not satisfied\n  --> src/models/file.rs:66:24\n   |\n66 |         let res = self.save_changes(&conn)?;\n   |                        ^^^^^^^^^^^^ the trait `diesel::Queryable<(diesel::types::Integer, diesel::types::Integer, diesel::types::Text, diesel::types::Text, diesel::types::Timestamp, diesel::types::Timestamp, diesel::types::Text, diesel::types::Text), diesel::pg::Pg>` is not implemented for `()`\nadding an explicit type annotation to res solved this issue\nlet res: Self = self.save_changes(&conn)?;. I'm also having this error, Debian 8.7\nJust following along with the getting started, diesel setup worked fine.\ndiesel 0.9.0\nrustc 1.16.0-nightly (df8debf6d 2017-01-25)\ncargo 0.17.0-nightly (67e4ef1 2017-01-25)\nI also did a cargo install diesel_cli --vers 0.8 and it still gave me same migration error.. It looks like your database table wasn't created with the correct id Integer type. Could you post your up.sql file from the migration that created the table?\nI think the issue here is that your id field is a BigInt which converts into a rust i64 not i32\nI was able to pass all the tests for this example locally (by cloning the repo, and running the test_all script). Could you try to diesel database reset that example database, and give it a run. ( still have a feeling that the table isn't setup properly, this should re-do it )\nIf that doesn't solve the issue, could you let us know the mysql version + OS you are using? \nand if any of the other db-backends examples dont work?. ",
    "flybayer": "I'm stuck with the below error and can't figure it out. The postgres table was created with Rails which manages the schema.\nError\n(reformatted a bit for readability)\n``\nerror[E0277]: the trait bounddiesel::types::Timestamp: diesel::types::FromSqlRowis not satisfied\n  --> lora/src/lib.rs:45:31\n   |\n45 |     let results = end_devices.load::<EndDevice>(&connection).expect(\"Error loading devices\");\n   |                               ^^^^ the traitdiesel::types::FromSqlRowis not implemented fordiesel::types::Timestamp|\n   = note: required because of the requirements on the impl ofdiesel::types::FromSqlRow<(\n       diesel::types::BigInt,\n       diesel::types::Nullable,\n       diesel::types::Nullable,\n       diesel::types::Timestamp, \n       diesel::types::Timestamp), _>for(i64, \n     std::option::Option, \n     std::option::Option, \n     diesel::types::Timestamp, \n     diesel::types::Timestamp)`\n= note: required because of the requirements on the impl of diesel::Queryable<(diesel::types::BigInt, diesel::types::Nullable<diesel::types::Text>, diesel::types::Nullable<diesel::types::Text>, diesel::types::Timestamp, diesel::types::Timestamp), _> for models::EndDevice\n```\nModel\n```rust\n[derive(Queryable)]\npub struct EndDevice {\n    pub id: i64,\n    pub eui: Option,\n    pub app_key: Option,\n    pub created_at: types::Timestamp,\n    pub updated_at: types::Timestamp,\n}\n```\nMy DB Table\nlens_development=# SELECT * FROM end_devices WHERE id=87;\n id |           eui           |             app_key              |         created_at         |         updated_at\n----+-------------------------+----------------------------------+----------------------------+----------------------------\n 87 | 00-80-00-00-00-00-01-01 | 4F7E61E31F2E9AF39DC0C52CE542909F | 2017-05-04 21:58:56.668025 | 2017-05-04 21:58:56.668025. Thank you @Eijebong, I got it working!\nFor reference, this is working:\n```rust\nuse chrono::prelude::*;\n[derive(Queryable, Debug)]\npub struct EndDevice {\n    pub id: i64,\n    pub eui: Option,\n    pub app_key: Option,\n    pub created_at: NaiveDateTime,\n    pub updated_at: NaiveDateTime,\n}\n```. ",
    "Eijebong": "You shouldn't use diesel::types::Timestamp\nAdd the chrono feature instead and use chrono types.. Oh, I missed this one :o \nCan this be closed now or is SQLite still missing something regarding date/time ? (see #887). Yeah, it makes sense. Fixing it\nEdit: after lunch. This is now fixed. @gentoo90, thanks for the report :). Any ETA for postgres support ? :)\n. Yes, it's a blocker.\n. Cool, thank you !\n. Already fixed on master, see #312 \n. Are you sure you're having the same problem ? Can you paste the error you're seeing too ?. The problem is that we can't just change those ident by path as a path cannot be followed by a -> nor by a ( so it would require changing to something like joinable!(foo::bar => baz::lol { foo::bar::field }). I think this one can be closed now that #1070 and #1077 have landed.. Fixed by #1084 and #1110 . This has been finished in #887. Closing. @nox  https://github.com/diesel-rs/diesel/releases/tag/v0.6.2\n. This can be closed now that #827 has been merged :). I think this can be closed now.. @Thomasdezeeuw #854 http://docs.diesel.rs/diesel/macro.embed_migrations.html ^^. I tried it and can't reproduce. Has this been fixed and the issue forgotten ? Maybe postgres has been fixed ?. #426 I think this is related.\nhttp://diesel.rs/guides/getting-started/ \nYou can read the latest supported nightly here. You should use the 2016-08-18 one.\n. This has been merged as part of #915 \nThank you @tshepang for the original implementation :). This can be closed now that #1074 has landed.. @emk If you really need this, you can use custom psql functions with sql_function!. I just tried it and got\nthread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: QueryBuilderError(StringError(\"There are no changes to save. This query cannot be built\"))', /checkout/src/libcore/result.rs:860:4\nI think this can be closed as we can't detect that there are no changes earlier than that.\n@Boscop Feel free to reopen if you think I'm wrong. I don't think you can join more than 2 tables for now, have a look at #89 . Sure. https://github.com/diesel-rs/diesel/blob/master/diesel/Cargo.toml#L15\nYes it did :) But only on master.. I think you need to install libsqlite3-dev. I'm working on that now, I just have some questions:\n- How do we treat infinity ?\n- OIDs ? Apparently each range has a different OID and arrays of ranges too. Should I request a metadata thing in the CanAppearInRange trait ?. Fixed by #1021 . I like the first one, but it might not be as good if the error message is very long.. You have a typo in the commit message, it should be \"too few\", not \"to few\" ;-)\nNot sure if you really care about that but eh.... Yeah, you should use the master branch of diesel, use chrono 0.2 or wait for 0.11.\nSince the migration to chrono 0.3 was a breaking change, it wasn't released in 0.10.x\nSee #648 \n. Hu... Should I just add a #[feature(postgres)] on the test ? Or transform this case into an error ? . I didn't think about it but an empty query on pg will panic event outside of migrations.. Eh, when you add your changes before commiting it's better.... Ok, I had to change the database name to diesel_example, otherwise another test failed later but now tests are passing :). I think everything has been implemented now :)\nFeel free to reopen if we missed something. You should use .execute(&connection) as mysql does not support the RETURNING clause.\nYou can have a look at #718 if you want to see mysql adapted examples. pq-sys is generating bindings for postgres at compile time and uses bindgen for that. Bindgen requires clang.. Urgh, it's that deadlock again... See #828 \nJust ignore it.. I think this is missing a CHANGELOG entry. https://github.com/diesel-rs/diesel/commit/6a932c3e2f24ced7a61906d6737376ed0218b423\nThis is not true anymore. We still need an example though. Related to #600. Is there any tool that can check the documentation at build time to find dead links ?. Is there anything else to do here ?. @sgrif Are you talking about the spaces around the dot ?\n. The last time I had an error like that it's because I was trying to run an empty migration. I fixed that in 2c4db017dd715e090b831457498a2e36358249fe\nAre you sure your up.sql isn't empty (Not sure if 0.11.0 has that commit)\nThere were other status that diesel treats as an error and do not have error messages.\nhttps://github.com/postgres/postgres/blob/93e6e40574bccf9c6f33c520a4189d3e98e2fd1f/src/interfaces/libpq/fe-exec.c#L177\nMaybe something in there ?. Oh, I forgot this issue, #821 fixed it :). This seems fine to me, the only thing is that it would be great to return a different code when we have pending migrations so it's easier to use from shell scripts but apparently we always return 0 for every command right now.\nThis can be merged as is I think, and we have tests so it will not be forgotten during the Migrations rework if it ever happens :). cargo install diesel_cli --features postgres,sqlite will allow you to compile diesel_cli without mysql support\n. Wait, wasn't this fixed ? https://github.com/slapresta/rust-dotenv/pull/32. #814 :). I'll change it tonight. What about examples ? Should I loosen those dependencies too?. I think you didn't run the migrations so the database doesn't exist and diesel cannot infer the schema. Oh, missed that :p \nI still think that the database is not in the correct state.\nWhat did you change in the test_all script ?. Do you  have a .env file somewhere in there ?. Weird then :( I don't have any more ideas maybe someone with more knowledge than me can help you, sorry. I took the liberty of rebasing and adding a CHANGELOG entry. Thanks for your work on this @ggrochow . Going to make a lot of coffee and try to solve this tonight. Ok, after 2 hours battling with my windows VM to install launch link postgresql...\nINSERT INTO users (id, name) VALUES(1, 'Sean'), (2, 'Tess')   \nCREATE UNIQUE INDEX ON users (name) WHERE name != 'Tess'\nThose are the two queries creating the deadlock\nThe easy fix is to run tests with RUST_TEST_THREADS=1. This has been fixed by https://github.com/diesel-rs/diesel/commit/523ffb39f88fb026e69fa51f848ee2de12f16dc4. The Decimal type is currently being implemented for postgres in #837. I'll probably implement it for MySQL once it's done for pg.\nmediumint cannot be deserialized as is since there is not i24 type. Would considering it as an integer be ok ? @sgrif \n. Yeah, and we can't add support for it as there is no type in rust to serialize/deserialize it.. Yeah that deadlock is annoying :(\nI think commits in this PR need to be squashed anyway so just add one or amend the last one.. Any new on that @rubdos ? :). The nested Nullable thing was just me not understanding something.\nA nullable + a non nullable column will not compile though. Should I add a compile-test for that ?. Is this really an issue ? I just tried and I was able to insert 2^256 in an integer field. SQLite does not really care about types. It would be confusing for users to deserialize what they think is an integer to an i64 though as I'm sure nobody knows about this bug. If you need to retrieve a I Bigint from SQLite, you can use the table macro and say it's a bigint . Yeah the unused function makes sense, maybe we should add an #[allow(dead_code)] on it.. Is there still something blocking this one ?. Oh I missed that :o . Done. Urg that deadlock is annoying >_<. Plus clippy is always behind nightly sometimes by two or three days.. Here is the table! invocation\ntable! {\n    events (time) {\n        time -> Timestamp,\n    }\n}\nI tried you code myself on rust nightly and it didn't compile either.\nRemoving the .select(time) make the code compile though. \nI'm looking at the code right now to find an explanation ^^. https://github.com/chronotope/chrono/commit/dcf193323b59b8c85f0be708d5ba2b6a1a1654d2\n:(. I just took #344, rebased, fixed what needed to be fixed and added tests.\nWhat kind of things does it need ?. Fixed and rebased.. Merged. Thanks @kardeiz for the original implementation :). 24c48b1d83c8970a9e1ad6d68987e060911d99ee Yup. I tested that we really needed the use statement yes.\nI'll try to turn this into a non-ignore test, that's a good idea. Typing is hard :/. https://github.com/laumann/compiletest-rs/commit/904ec75edeeb67f892c29bf6c7d9ca0b9a809acf It's because of that I guess. They updated for the latest nightly, and released a new version. Do you want me to pin the compiletest_rs version to 0.2.5 ?. Oh, ok ^^. There was no doctest for like and not_like hence why there isn't any for ilike and not_ilike. I can add some though if you want ^^. Ok github, next time tell me somebody already reviewed it and said the exact same thing please !. Diesel 0.12 doesn't support serde 1.0 nor uuid 5.0\nIf you want to use them, use diesel master branch. . Sure :). We already have tests for that @killercup (types_roundtrips). Oh, ok :). I took the commit message from #456, can change it if you want. \ud83c\udfb6  Hello deadlock my old friend... \ud83c\udfb6 . As I said, I could split it in two examples,one with a commit and one with a rollback. Yep, thank you very much !. Have a look at #860 too ^^. The question is how do you translate '1 month'::interval to a Duration ?. This fixes test on latest nightlies (since rust added an unused macros lint).\nThank you for this :). Cool, can you add a changelog entry ?. Sorry for the delay, this looks pretty good now.\nCoud you just remove the documentation for INET and CIDR and open another PR with those as they're unrelated to MACADDR ? . Tests are failing, you removed mk_macaddr. I don't think it's possible to add a test as we cannot capture stderr in a test and check it without doing some crazy things with libc or something like that.... https://github.com/rust-lang/rust/pull/48934 This is now fixed :). In the future, there might be https://github.com/rust-lang/rfcs/pull/2008 which would fix this problem. Sure ^^. Would users.filter(not(name.ilike(\"%coucou\"))) do the same thing as users.filter(name.not_ilike(\"%coucou\")) ?\nEDIT: Yep\n```\n[local] eijebong@test_rust=# EXPLAIN ANALYZE SELECT name FROM users WHERE NOT(name ILIKE '%coucou');\n                                             QUERY PLAN                                             \n\nSeq Scan on users  (cost=0.00..25.88 rows=1270 width=32) (actual time=0.004..0.004 rows=0 loops=1)\n   Filter: ((name)::text !~~* '%coucou'::text)\n Planning time: 0.095 ms\n Execution time: 0.030 ms\n(4 rows)\n[local] eijebong@test_rust=# EXPLAIN ANALYZE SELECT name FROM users WHERE name NOT ILIKE '%coucou';\n                                             QUERY PLAN                                             \n\nSeq Scan on users  (cost=0.00..25.88 rows=1270 width=32) (actual time=0.004..0.004 rows=0 loops=1)\n   Filter: ((name)::text !~~* '%coucou'::text)\n Planning time: 0.093 ms\n Execution time: 0.030 ms\n(4 rows)\n```\n. Ok, so I added a doctest, not sure if it's enough. Yay, thanks ! (I'll review it tomorrow, it's way too late for that now). Closed by #954 \nThank you. Yup, thanks :). Oh, you merged the has_manyone :p . So if I understand correctly, diesel print-schema will also print those comments ?\nCan we have something like a flag to disable that behavior ?. No opinion on that. Yeah, this was triggered by the rustfmt bug (which is now fixed and released). Maybe we can close this since I don't think there is a way to guarantee that we only parse <= 1 trailing comma without duplicating every declaration.. The repo is here https://github.com/sgrif/diesel.rs-website. Yeah, see #960 :(\nThat bump is really unfortunate since it was a complete breaking change. You either need to wait for diesel 0.14 or use the master branch . @sgrif And I think it wouldn't look good with keywords (if it even works), type as type_ vs \n```\n[column_name=\"type\"]\ntype_\n```. Fixed by #1084 and #1110 . Yeah it's pretty good but it only works for bugs, not for feature requests.. Wow, this is a nice report :o \nYour created_at column is not defined as NOT NULL. You should deserialize it in an Option<NaiveDateTime> instead of NaiveDateTime. Huuu if you inserted those values with diesel it should work. Maybe you ran into a bug in the implementation of Datetime for sqlite. See #969 for the issue template. (And yes a PR would be welcome :)). Thanks for the report. It is indeed a bug (we're missing a debug_to_sql! call for Timespec).\nHere is what you would get with the debug_sql! function if it worked, I hope it can help you while you're waiting on this to be fixed :)\nsql\nSELECT `version_downloads`.`id`, `version_downloads`.`version_id`, `version_downloads`.`downloads`, `version_downloads`.`counted`, `version_downloads`.`date`, `version_downloads`.`processed` FROM `version_downloads` WHERE `version_downloads`.`version_id` = ? AND `version_downloads`.`date` BETWEEN date(?) AND date(?) ORDER BY `version_downloads`.`date`\n. We have like... 2 tests in diesel_tests/tests/debug/mod.rs and that's it.. Nah the rust-toolchain file is only here for developers since it tells rustup to use that particular rust version (allowing devs to run tests without disabling/updating clippy).\nI think appveyor should still run stable only.\n@killercup btw, #981 broke appveyor since it's using rustup (travis isn't).. Sure, but since we're putting everything in one file, does it mean we'll have to parse this file when running  diesel update ?. How do you retrieve the version of the file at the \"current metadata version entry\" ?. Ohh I think I misunderstood your comment. I thought you wanted every setup SQL to be in one file in diesel.... Yep, it all makes sense now.. Ok so I fixed everything and added some documentation (I forgot we had documentation on SQL types...). It should be all good now, I'm just waiting for someone else to check that I didn't forget anything and we're goof to go. I took the liberty of fixing the data_types thing to save you a roundtrip as the comment states that it should only be used for types that don't have a matching primitive type.\nGoing to merge this now, thank you for doing this \ud83d\udc4d . I'll see if I can add a test yeah. I think you'd also need the HasSqlType trait which is a bit more difficult as it's different for every backend.. Oh, right, this is the same trait for every backend... I'm dumb :). Oh, you also need to rebase, it should be easy, you have to change the mysql metadata function so it takes _: &(). Hmm this is a git usage mistake. The first different commit is d9778d406b6db5a5d2ec1361c073021e0bacf9ea which is\n 9f4e9d379b6524a5c122979867df4a614b156f7a in this PR.\nI don't know why, but the parent commit isn't the same.\n@Fiedzia How did you rebase ? :p . Mhhh weird that should have worked.\nDid you have any conflict ? Did you resolve then properly ?. Took the liberty to rebase and add a changelog entry, I'll merge once tests are green.. Thanks !. Thanks. Sure \ud83d\udc4d. > I'm not 100% sure why but it's showing I added #[test] and [cfg(feature=\"postgres\")] to the spec below it instead of to itself but I didn't \ud83e\udd14 ...\nIt's just how git does things, sometimes it's a bit messed up, but it looks ok to me. 10 000 is suspicious since pg stores numeric values in base 10k. Yep, thanks. @golddranks Thanks for the heads up :) MySQL seems to like both \"$\" and \"%24\" though and this PR is only targeting MySQL\n@nottxy Sorry it took so long for someone to have a look at it :/\nAlso can you add a test that checks that percent decoding is working ? (There are examples at the bottom of the file).. I think the problem is that github pages don't allow you to force https if you're using a custom domain (which of course we are).. Yeah, I can add that \ud83d\udc4d . Wait, that commit message is so bad. Closed by #1082 \nThanks for the report :). Well, @sgrif said \"tomorrow\" yesterday, so I'd say next week :) . Oh yeah, we never actually settled on anything.. Nope, it only covers column renaming.. Sure, I can add tests here :). I opened #1096 to fix this one. Fixed by #1096 \n@killercup Should we open another issue asking to add more fuzzing to decimal tests ?. I forgot about this one... Well now they're linked, I think it's ok. I think that error is because we're manually allowing Add for this column in the test suite. The line needs to be removed.. Why aren't other types Add and Sub ? I guess it doesn't really matter for this PR since we can easily add them later to the list.. Thanks. Ok, so tests are passing on nightly :) Now we have to wait for releases. cc #967 #342. This will be merged in #1123 . I can't reproduce the print-schema bug :/\n@Boscop What OS are you running ?. Rendered. Yeah, this won't be an issue anymore with the new debug_query\nThe error is basically saying that rust doesn't know how to serialize the Uuid type for the Debug backend (which has been removed)\nHere is what it would look like (I only kept id and role_id)\nsql\nUPDATE \\\"users\\\" SET \\\"role_id\\\" = $1 WHERE \\\"users\\\".\\\"id\\\" = $2 -- binds: [Uuid(\\\"5487ef73-fe8a-47d0-b573-c2c13a05ae47\\\"), Uuid(\\\"91e63d03-d4fe-40ea-97da-392c96c4cf11\\\")]. I think this is probably a bug as I don't see why boxed queries shouldn't be used with a delete statement.. Hey, thanks for the awesome bug report with a repository and everything \u2764\ufe0f \nYou need to add a enable_multi_table_joins!(crates, readme_rendering); to your code as those are not inferred by diesel.. @mmstick Do what the rust compiler tells you to do, add a #[recursion_limit=\"128\"] at the root of your crate. I don't think anyone is working on it so feel free to work on it.\nIf you have any question don't hesitate to ask here or on our gitter room (link it the README). As I said on gitter, I don't think this is the right fix.\nBelongsTo! does take #[table_name(...)], what you're usually looking for when you're doing associations is #[belongs_to(...)].. joinable! calls are now inferred by infer_schema!. Just remove it and it should work :). Sure, why not. Can you also add a test for this ? :). I think you just need to put it between quotes --database-url \"postgres://myuser:mypassword@localhost/mydb\". Oh sorry, I can't read... It's not the shell that's saying that, it's PG itself. Do you have any special character in the password ? If so I think you need to percent encode them. Fixed by #1252 . Yeah, you can just do\nkey -> Text,\nvalue -> Binary\nif you're not using any use statement in the table! call, we stick a use diesel::types::* in there, hence the warning.. #1290 . Why are you putting 103 if your table only has 80 ?. Not sure what you're calling models, but no, we don't have any tool to help you write the Queryable structs. However, if you're not using infer_schema!, you can use diesel print-schema and copy/paste the output in your schema.rs.. Yeah you can't have a column with the same name as the table. You can rename the column by putting a #[sql_name=\"level\"] on it and renaming it to level_ or whatever other name you can think about. http://docs.diesel.rs/diesel/macro.table.html. No, you can't blacklist tables from infer_schema! so you have to do everything with table!. diesel print-schema will help you do that :p . Isn't that the same thing as #860 for Queryable ?. Woups rustfmt :D  I knew I forgot about something\nWhat do you mean by explicit values ? Something like \"0.01000\" ?. Ok... Nice one me... Next time please pull before doing something. Seeing how many \"Fix build on master\" commits we're getting recently, I'm :+1: on the idea. I don't know if it's linting stuff like that but we can ask :p \ncc @nox ? Any interest in linting unbounded dependencies ?. imporitng. https://git.bananium.fr/enib/enibar/blob/master/application/rapi/rapi_codegen/src/model.rs#L31-56\nHere's what I'm doing in a project (for now it's minimal but I intend to expand it as the migration from python to rust progresses), if there is an interest I guess I could release it as a diesel_models crate or something like that.. Very similar to #1354. @juliusdelta Friendly ping :). Do what the compiler tells you, add a #![recursion_limit=\"128\"] attribute to your crate. It's already included in diesel print-schema.\nEven when ignoring the technical details of that implementation, I think that infer_schema! is really confusing for people as we often have some questions about code not compiling because the database used for the compilation is wrong or migrations haven't been run yet.. Want me to open a PR for the 1.0 branch too ?. You probably have multiple versions of diesel in your dependencies. Check that you're using the right version for r2d2 (it should be the same as the diesel one) and run cargo update.. You shouldn't have diesel_codegen as it was removed in 0.99, see the changelog https://github.com/diesel-rs/diesel/blob/master/CHANGELOG.md. I should update the rocket example.... Maybe this should be added as a comment in the code ? (Would've been nice in the commit message but it's too late for that :p). Thanks ^_^. Also you have a typo in the commit, errors, not errorsx :p . @killercup While this is a breaking change, it just doesn't compile with r2d2 0.7 so this won't break any build that's not already broken. @notryanb Yeah, the failure is the same as in #1595 \nI think we need to rustup because cargo_metadata isn't compatible with the nightly we're using anymore. #1597 . You're probably missing the chrono feature on diesel. Ha, that's why, you have to tell diesel this is a datetime. Either change the type of start_time to DATETIME (or is it TIMESTAMP ?) in your migration or lie to diesel when you describe the table with table! and replace Text by Timestamp for that column (can't do that if you're using infer_schema!). You need to enable at least one feature. cargo test --features sqlite for example. Ha you're running tests from the root, that's probably why. We don't do that. You should use bin/test instead to run all tests. It's written there https://github.com/diesel-rs/diesel/blob/master/CONTRIBUTING.md#setting-up-diesel-locally (5.)\nTo use it in your project, you can add a [replace] section in your Cargo.toml. You also need to pin your compiler to the same version we're using, you can find it there: https://github.com/diesel-rs/diesel/blob/master/.travis.yml#L45\nThis is also written in the contributing file ;). You're missing the image column in your Dummy struct. Here diesel is telling you that it can't deserialize a (Int4, Varchar, Nullable<Bytea>)into a (i32, String) (which is a tuple representation of your Dummy struct.\nAdding a image: Vec<u8> line to your struct should fix this.. You could also do that. But if you still want your structure, the common thing is two have two different structs, one that is Insertable and one Queryable.. :+1: It should be pretty easy to provide support for those types in a 3rd-party crate.\nI see another advantage to that, this way we don't depend on geo which means that breaking changes in that crate don't mean breaking change in diesel (which would force us to go 2.0 for example).\nFor the infer_schema/print-schema, this is another argument for a config file IMO.. Ha tests are failing, that's why this wasn't done. @sgrif said this week, so probably next week ;). diesel print-schema does exactly that. Do you mean Queryable structs ? You don't. You have to write them yourself.. IMO this is out of the scope of diesel and since SQL types aren't 1 <=> 1 with rust types we couldn't really generate them anyway.\nYou could reuse the code from diesel_infer_schema to write such a tool though.. You either need to install libpq-dev, libmysqlclient-dev or tell cargo not to compile diesel with those two backends with cargo install diesel_cli --no-default-features --features sqlite.\n(Packages names depend on your distribution, they might be different. I'm pretty sure those are right for debian). Unless I missed it, this isn't used in our public API. Let's see if this actually fixes the nightly tests. Yep... I thought this was clippy but nope... Going to report the bug. https://github.com/rust-lang/rust/issues/49207. Nice, I guess I'll close this in favor of #1600 then since it already fixes clippy tests. @killercup This is going to fail because of https://github.com/rust-lang-nursery/rust-clippy/issues/2560. You have to bump compiletest too. @gasabr Sure, go for it :+1: . Sure, go for it. If you need help we can either discuss it here or on our gitter channel (sorry missed the other ping). Check that you don't have multiple versions of uuid in your lockfile. Documentation probably. I couldn't even find it. @weiznich What if I want to use diesel 0.16 though ? :/\nI agree that those questions are way too frequent but yanking old versions doesn't sound like a good solution to me.. If there's a way to get the version of diesel used in a build script, we could add one which makes the compilation fail and release 0.16.whatever. Dupe of #1700 and #1701 \nThis is getting fixed there: https://github.com/rust-lang/rust/pull/50876. It's a rustc bug, see #1700 #1701 #1705 #1711 #1729, https://github.com/rust-lang/rust/issues/50825 and https://github.com/rust-lang/rust/pull/51042. It's not merged yet ;). No because it's not something that's actionable on our part so it shouldn't even have been opened here in the first place ;). It's a rustc bug, see #1700 #1701 #1705 #1711 #1729, #1730, #1731, rust-lang/rust#50825 and rust-lang/rust#51042. cargo expand:\n```rust\n![feature(prelude_import)]\n![no_std]\n[prelude_import]\nuse std::prelude::v1::*;\nextern crate diesel;\n[macro_use]\nextern crate diesel_migrations;\n[macro_use]\nextern crate std;\nfn main() {\n    ::io::_print(::std::fmt::Arguments::new_v1(\n        &[\"Hello, world!\\n\"],\n        &match () {\n            () => [],\n        },\n    ));\n}\n[allow(dead_code)]\nmod embedded_migrations {\n    struct _Dummy;\n    extern crate diesel;\n    extern crate diesel_migrations;\n    use self::diesel_migrations::;\n    use self::diesel::migration::;\n    use self::diesel::connection::SimpleConnection;\n    use std::io;\n    const ALL_MIGRATIONS: &[&Migration] =\n        &[&EmbeddedMigration{version: \"20180220220249\",\n                             up_sql:\n                                 \"CREATE TABLE broadcastsv1 (\\n    broadcaster_id VARCHAR(64) NOT NULL,\\n    bchannel_id VARCHAR(128) NOT NULL,\\n    created TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,\\n    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP NOT NULL,\\n    version VARCHAR(200) NOT NULL,\\n    PRIMARY KEY(broadcaster_id, bchannel_id)\\n);\\n\",}];\n    struct EmbeddedMigration {\n        version: &'static str,\n        up_sql: &'static str,\n    }\n    impl Migration for EmbeddedMigration {\n        fn version(&self) -> &str {\n            self.version\n        }\n        fn run(&self, conn: &SimpleConnection) -> Result<(), RunMigrationsError> {\n            conn.batch_execute(self.up_sql).map_err(Into::into)\n        }\n        fn revert(&self, _conn: &SimpleConnection) -> Result<(), RunMigrationsError> {\n            {\n                {\n                    ::rt::begin_panic(\n                        \"internal error: entered unreachable code\",\n                        &(\"src/main.rs\", 10u32, 1u32),\n                    )\n                }\n            }\n        }\n    }\n    pub fn run(conn: &C) -> Result<(), RunMigrationsError> {\n        run_with_output(conn, &mut io::sink())\n    }\n    pub fn run_with_output(\n        conn: &C,\n        out: &mut io::Write,\n    ) -> Result<(), RunMigrationsError> {\n        run_migrations(conn, ALL_MIGRATIONS.iter().map(|v| *v), out)\n    }\n``. I don't think they're that unstable and I'd prefer to review0.13 -> 0.14and then0.14 -> whateverthan jumping two versions.. Superseded by #1789. @killercup Yeah, you can see it in the expanded code here https://github.com/diesel-rs/diesel/issues/1739#issuecomment-393639282. While I'm not happy with the patch as it's technically a breaking change, the path to update seems pretty straightforward and it fixes a bug that shouldn't be here in the first place and that users might hit pretty easily...\nMy main problem is that accepting that as a non breaking change sets a precedent that I'm really reluctant to set as I'm pretty attached to semver but we also aren't ready for 2.0.... The problem with specifying it there is that it's going to be forgotten IMO. @weiznich What about nightly then ?. This is needed for #1742 . Yeah I need to find time to get #1742 in there. Superseded by #1789. Thx. Yep, [eq_any`](http://docs.diesel.rs/diesel/expression_methods/trait.ExpressionMethods.html#method.eq_any). https://github.com/diesel-rs/diesel/blob/master/diesel_tests/tests/custom_types.rs You can have a look here. Thanks :). This has been fixed by https://github.com/diesel-rs/diesel/pull/1787. https://github.com/diesel-rs/diesel/commit/54b21b0d8d285ebce1c9df363a5b2eecf3e8298e It's already on master. This won't compile with syn < 0.15.22 right ? If so please change the version of sun in the Cargo.toml to 0.15.22\nAlso is this in some unstable API ? If it.s not maybe the right call would be to ask for that version to be yanked. @weiznich If it doesn't compile with syn 0.15.21 then someone doing cargo update -p diesel will end up with a broken project and will have to manually think about doing cargo update -p syn. Ha then disregard :p . Yeah, it's coming from infer_schema_macros 1.4.0 which is used in diesel_infer_schema, no idea why it makes compilation fail though.... Lgtm with ci fixed. you'll only the => you'll only need the. Yeah, It's a copy/paste from the test above, i'll remove it ^^. Sure. If we use schema::posts::dsl::* then we need to change the body and title variable names;\nI added use schema::posts::dsl::{posts, id}; instead. Ok, i'll create a table for that then :p . Oh yeah, this looks way better :). Yeah, I was not really inspired, but wanted to show that you can use sql literals as filters because I didn't know that myself before you told me ^^. \ud83d\udc4d . Erf, this is public API ? :(. Oups. :+1:. Haha, you don't like addding things ? :(. Glad I'm not the only one. I need to automagically enable spell checking for .md files to avoid things like that in the future ^^. Okay' I'll fix that :). Oh, I didn't know that one ^^. Right, I had some troubles using the macro outside and the #[macro_export] stayed. This is in pg/expression/predicate.rs\nEDIT: Oh, right, the third argument.... o_o how did this even get in there ?. It was just missing the #[macro_use]\nDo you want me to move the pg/expression/helper_types.rs in there ?. Why use _pass here and _ above ?. Maybe we should still do something if it fails ? If it fails, it's probably a bug and it should be fixed.. What happens here for the is_safe_to_cache_prepared pass ?\nIf distinct is false, and then select is true ?\nUltimately, only the last one means something right ?\nMaybe you should use **result &= true/false everywhere ?. Oh, yeah, I didn't notice that was the case ^^' Then it works. I understand that this is not the end of the world if we hit that false but as you said it should never happen. The problem is that if it ever happens, it'll go unnoticed for a long time (forever is still a long time !).\nPrinting \"this is a diesel bug, please report\" to stderr might be a good solution.. Derp !\nI'll fix that... must haveguG or something like that, thanks vim !. Yep, this is the only difference. I duplicated every test (one for arg and one for env).\n. Oh, that's a nice way to do it.. Nope, vec![t.into()] didn't work. Nor can we that you're binding the right number of values. https://github.com/rust-lang/rust/commit/8e97693b2cbcaeb745643ee1b37058e8dde2efa1#diff-5cafcf46bfb947f8e58fa5c16d39018cR8\n1.17. No it doesn't... I think I didn't wait for cargo doc to finish before testing.. Haha, I really love those colons. Ok ok, sorry \ud83d\ude22. The problem with moving the test here is that I don't have access to schema_dsl which means 3 SQL queries to create the table with default values.. Yeah, it's not a good error message, but at least it doesn't compile ^^. Can we even customize the error message there ?. We're dropping users and creating it again which would commit the transaction IIRC. We should really do something about this being needed everywhere.... This isn't needed in this doctest. Can you hide that ? I don't think we need the user where to get diesel types and it makes the examples less readable. Same as the types::MacAddr. And again ^^. Nice, we love links :). Hu, @sgrif said that :p Maybe I should remove that part.. Yeah, this is much more readable. error[E0271]: type mismatch resolving `<users::table as diesel::query_source::AppearsInFromClause<posts::table>>::Count == diesel::query_source::Succ<diesel::query_source::Never>`\n  --> src/main.rs:30:18\n   |\n30 |     let _ = join.select(posts::title);\n   |                  ^^^^^^ expected struct `diesel::query_source::Never`, found struct `diesel::query_source::Succ`\n   |\n   = note: expected type `diesel::query_source::Never`\n              found type `diesel::query_source::Succ<diesel::query_source::Never>`\nThis is really hard to understand what's going on here. Is there any way this could be better ?. Same error here. This means diesel is compatible with rust >= 1.18. You might want to write it in the README or in the CHANGELOG.. I would probably have named it get_first_or_not_found. Why not use diesel::expression::not ? That's what rust told me to use when it was missing. Will this ever be possible ? If so, maybe add a FIXME here ?. Hu ? You remove has_many, not belongs_to. That struct name though \ud83d\ude06 . custom on to #[belongs_to]. lol, @sgrif should I make this public ?. Done. Why is this one on two lines ? All the others are on one line. This should be [bigdecimal-0.14.0]. Should this be a FIXME ?. This should probably be be \"0.0.7\" as I think \"1.42.51\" matches \">=0.0.7\" :p . What does that mean ?. Well if you're using the chrono feature in diesel, the chrono version it's using is using is set by diesel.. Nice changelog entry \ud83d\udc4d . This only needs to derive Debug, Clone, Copy and Default.. To make this work, you need to bring TinyInt in diesel::types. You can have a look at how we did that for pg here: https://github.com/diesel-rs/diesel/blob/master/diesel/src/types/mod.rs#L273\nFor that you need to make the types module from mysql public too. This isn't needed anymore once you have primitive_impl!. This isn't needed anymore once you have primitive_impl!. I guess this could work. I would personally prefer if you used\nrust\nout.write_i8(*self)                                     \n    .map(|_| IsNull::No)                                \n    .map_err(|e| Box::new(e) as Box<StdError+Send+Sync>). Maybe add a comment to explain why this is here ?. Yeah, I tried to compile it without the extras features and found it weird that I'd have to add ::types and forgot it. \u2702\ufe0f . \u2702\ufe0f . \u2702\ufe0f . \u2702\ufe0f . Yout don't need the type:: here. period. This sentence is weird IMO.\nWhat about \"Collecting and serializing SQL bound values\" ?. To be consistent with L85-94, add a period at the end of each bullet point. SQL. This would confuse me if I didn't know what it was doing. What about \"Add the given SQL identifier to the query [...]\". Same thing as push_identifier. \"Push a bind parameter onto the given query. The value will automatically be bound at the execution\" ?. I meant that the \"at the end\" in the sentence was confusing.. I thought it was a standard term. I don't have any other idea :/. Why is this needed ?. We don't reexport BigDecimal for postgres, why should we for MySQL ?\nI think you can remove the whole sql_types module :). \u2702\ufe0f . \u2702\ufe0f . Why does this need to be pub use ?. \u2702\ufe0f . I just copy/pasted it from the postgres source code but yeah I can change that to binary literals if you want to. I don't think they're easier to read when they're not visually aligned. How would I know the expected size ?. Won't this break everything with indexed VARCHAR(255). and encoding. 1.0.0 ? Didn't you want to make a quick 0.15 instead ?. .. Done :). You can just use assert!(!result.stdout().contains(\"00000000000000\")) here. ldconfig -p | grep mysql. Yeah, it's weird, in the example it's separated by spaces and has no comma. Maybe you meant it the other way around ?. This is the exact same test as https://github.com/diesel-rs/diesel/pull/1051/files#diff-b33826ad230edbe4ba2ad2925b396345R162\nNot sure if it's worth keeping. Can we find something to add between the query and the parameters ? It's a bit confusing IMO. :+1: for me. Nice one :D . This is not true for MySQL IIRC. Nit: \"// It is\". Oh, nice catch. Sure. primitive_impls but it doesn't like generic stuff and I think it also implements other things.. \\o/. Wouuuups. I would say \"Check [...] instead of call\". Oh, I didn't know flat_map, neat. \u2702\ufe0f ?. Why isn't this one in ::postgres ?. Well, it only works for PG, I'd say it's PG specific :p . Assuming they do. But yeah ok, it makes sense. This name feels weird. What about should_ignore_table ?. Oh, I just had a hard time understanding why this was here... I would have preferred write!(f, \"\\n\");, it would look less like something you forgot to remove. Doesn't rust have a .join method ?. now. relevant. error[E0119]: conflicting implementations of trait `types::FromSql<mysql::types::Datetime, mysql::backend::Mysql>` for type `std::borrow::Cow<'_, _>`:\n  --> src/mysql/types/date_and_time.rs:56:1\n   |\n56 | / impl<T: ToSql<Timestamp, Mysql>> FromSql<Datetime, Mysql> for T {\n57 | |     fn from_sql(bytes: Option<&[u8]>) -> Result<Self, Box<Error+Send+Sync>> {\n58 | |         <T as FromSql<Timestamp, Mysql>>::from_sql(bytes)\n59 | |     }\n60 | | }\n   | |_^ conflicting implementation for `std::borrow::Cow<'_, _>`\n   | \n  ::: src/types/impls/primitives.rs\n   |\n91 | / impl<'a, T: ?Sized, ST, DB> FromSql<ST, DB> for Cow<'a, T> where\n92 | |     T: 'a + ToOwned,\n93 | |     DB: Backend + HasSqlType<ST>,\n94 | |     T::Owned: FromSql<ST, DB>,\n...  |\n98 | |     }\n99 | | }\n   | |_- first implementation here. Haha woups, I forgot that, it was to see which invocation was failing. (I had to recompile rust to remove the \"something happened in this macro\" but then I couldn't distinguish which one it was, so I had typey, typee, typei, well you see the idea. Should be Rust, you're right. Nice :). I think this is fine but @sgrif already emitted concerns about using macros for so few calls (2 in this case). I guess this file wasn't removed in the PR that changed how pretty printing was done ?. \ud83d\udc4d . Half those keywords aren't even valid SQL identifier :p. This one doesn't respect what you said about letting a blank line between each type of declaration. Why do we need this ?\n. Oh in the travis UI, makes sense \ud83d\udc4d . Is this the first deprecated stuff that is actually tested ? Weird. Maybe you should point to\n ```\n[sql_name = \"users\"]\nusers_\n``. Oh.... \ud83d\udc4d This commit didn't have enough git churn in it :D. Why isn't you commit talking about that ? Should this have been in another PR ?.  What aboutthe function signature and its body?. I like this, this is way clearer than the doc that was there before :+1:. retrieving. retrieving. I see you and you copy/paste skills :D . violated. \\NUL` byte otherwise it looks like a typo for NULL. More like it can't prevent 100% of them. Maybe precise the type instead of saying into chrono ?. Can this be changed to https ? See #1293 too. Hu ? \u2702\ufe0f . Maybe we should open an issue for that ?. That's a lot of new lines :o . actual. Why is this here ?. Lol, okay'. This is kinda meh but I guess we don't have any other choice. That's a weird way to put that. Did rustfmt do that ?. contain. sed -i s/types/sql_types/ probably :D. This needs to be removed too ^_^. This should just be \"0.8\" IMO. Nice struct name. What's the point of AsExpression without any sql_type ? Should we maybe make this an error instead ?. parse_quote! really is awesome \u2764\ufe0f . Why is this in a block ?. call_site => __diesel_use_everything!() ? It looks weird without the space. Unsigned strings let's go ! :trollface:. @sgrif I personally didn't find a way to do it when I needed it. Shouldn't this be Nullable<Timestamp>. what's going on here ?. Ohhh I didn't see the order was wrong :D . Nah, because you could have lots of code, add a column to you Queryable struct and still want the project to compile instead of throwing 20 000 compile errors telling you that #[check_types] is for debugging only.. Why is this needed ?. I don't think this is right. They're not missing, just wrong impls. Makes sense I guess. Not sure how I feel about this one.... Is this worth reporting a bug on clippy ?. :(. :+1: . Shouldn't this be Interval. :scissors: . Does this do anything ?. Oh :+1: . :laughing: . Can we not do that ? :p . Clippy complained about it ;). I guess this is set by clippy when you run it ?. :laughing: . This could also be to_string instead of creating another Ident. That would make it clearer that it's not going to be used in a quote! call.. Hu ? This isn't a dummy mod then. :/. I'd look for part of the syntax error instead. Same comment here. This is not used, right ?. I meant the struct below sorry (was on phone). Oh \u00e8_\u00e9 I'm blind.... Nah that's fine by me. Only 3 pages ? Lucky users :p. Isn't that wrong ?. Is this new ? . Nice. Why not travis-cargo ?. And will it still work ? I guess travis-cargo it used to avoid timeouts ?. Why were we even using it then ?. Yeah, quote is recursive, I'm actually curious as to why we don't hit the recursion limit. ",
    "chriskrycho": "What exactly constitutes a \"reasonable installation\"? I've got Windows VMs set up for other reasons, would be happy to test it and see what pops out, if anything.\n. I'll give it a whirl sometime tomorrow; at the very least I should be able to report what's broken out of the gate as a totally-new user.\n. If I get the time, I\u2019ll be happy to! (No promises; every time I make a promise in OSS I break it and am sad.)\n. Huzzah! (Sorry I couldn\u2019t help. But still: huzzah!)\n. ",
    "sunshowers": "Hi @sgrif -- you mentioned that there would be a doc page on how to do this. I looked for it but couldn't find it -- could you link to it?. OK, I found https://github.com/diesel-rs/diesel/blob/master/diesel_tests/tests/custom_types.rs. Looks promising.. ",
    "emptyflash": "Not sure if you came across this in your searching, but apparently Travis CI provided a workaround for upgrading sqlite3, but unfortunately it only seems to work on their legacy infrastructure.\n. Actually, scratch that. I was able to get the build to pass by manually installing the workaround and setting the distro to precise instead of trusty.\n. Agreed. Maybe Travis is manually changing the version they have installed? I can't see a reason why the build would pass from manually upgrading sqlite if the installed default version really is 3.8.\nWould you be willing to consider switching to a different CI system? I've had a pretty pleasant experience using CircleCI.\n. Just did a sanity check, and the version really is 3.8, so maybe the codegen is compatible with 3.7.15, but not 3.7.9 nor 3.8? \n. Ah, I see that now. The error I was getting original had something to do with lifetimes, but I think that was unrelated.\n. Whoops, meant to open this on my fork. Why won't github let you delete pull reqeusts\n. Just to be clear, relative_from isn't being used because it's marked unstable (rust-lang/rust#23284), so once 1.7 is stable we should replace strip_prefix with Path#strip_prefix?\n. Good to go :+1: \n. ",
    "aperezdc": "There's an attempt to implement this in PR #344 \u2014 which is a bit old and seems to need some love.. I am preparing a small PR to make the macros public, as I would like to use them as well. Would it make sense to also make primitive_impls! public?\nEdit: There's also not_none! in the same source file, but it is small and easy to understand, so my guess is that it would be better to keep it private.. Oops, the PostgreSQL running in Travis-CI are choking on DATETIME('now') when inserting values:\nCreating database: diesel_getting_started_step_4\nfunction datetime(unknown) does not exist\nAnother option is using DEFAULT CURRENT_TIMESTAMP, which it is also supported in PostgreSQL \u2014 as I have just learnt. I'll push an update with that, and see how it goes. Hopefully it'll work just fine, otherwise we'll need to have different SQL for each database.. There are two limitations with CURRENT_TIMESTAMP:\n\nInside a transaction, it will yield always the same value: the timestamp at which the transaction was started.\nIn order to support SQLite, we cannot use the parameter to specify the number of decimal digits (e.g. CURRENT_TIMESTAMP(2) as supported by PostgreSQL), so subsecond timestamp resolutions are not possible.\n\nMy (very) limited understanding is that it should be fine, as casting 'now' to a TIMESTAMP value was giving a seconds value already... Is it okay to use CURRENT_TIMESTAMP with Diesel given these limitations? . @killercup: Sure thing! I'll update with a test case. I'm at work right now but I'll totally going to give it a try later \u2014 also I am learning Rust in the process so please bear with me :innocent: . Okay, I keep being tripped by PostgreSQL not having a DATETIME() function... the best cross-database snippet I have been able to come up with for the check is something like this for PostgreSQL:\nfoo=# SELECT t,v, CAST(t AS text) < CAST(current_timestamp AS text) FROM foo;\n             t              |  v  | ?column? \n----------------------------+-----+---------\n 2017-01-02 18:35:36.832241 | 100 | t\n(1 row)\nand the following for SQLite:\nsqlite> SELECT t,v, CAST(t AS text) < CAST(current_timestamp AS text) FROM foo;\n2017-01-02 17:20:43|100|1\nIt looks a bit brittle to do a CAST and then comparing strings lexicographically... which coincidentally works because both databases format the timestamps as ISO8601 (or alike), which have a fixed width and can be compared this way.\n@killercup What do you think of using the query above in the test case? Is it okay, or is it too crappy and would it be better to use different queries depending on the database being used?. @killercup: That sounds very sensible, and certainly would be future-proof if later on the __diesel_schema_migrations table needs a more complex schema. One question, though: If both implementations of Connection are going to have a fn setup_migration_table(), wouldn't it make more sense to have the function directly in the Connection trait instead of adding a new trait? (For example fn setup_helper_functions() is there). . @sgrif: Let's go with CURRENT_TIMESTAMP, then. I'll see if I can find a non-crappy way of writing the test case. Maybe one option is to write two test cases: one for PostgreSQL and anothe one for SQLite. How does that sound?. Funnily enough, running the PostgreSQL version of the query locally with psql works, trying to run cargo test --no-default-features --features postgres ends up in SIGILL (a panic while panicing), and in Travis-CI the test doesn't pass... It's a bit odd, if somebody has any idea, I would like to hear it. I'll keep trying to solve the issue with the test case anyway.. @killercup: Mmmh, it could be. Thanks for the suggestion, I'll check the differences among versions from the PostgreSQL manuals. If that's the case, most likkely using explicit CAST expressions (CAST('now' as TIMESTAMP)) instead of the type names as type prefixes (TIMESTAMP 'now') would work.. \n. @sgrif: Using CURRENT_TIMESTAMP is working fine for both SQLite and PostgreSQL, and the same SQL snippet is used with both databases to create the __diesel_schema_migrations table.\nThe remaining issue writing the an unit test in such a way that the query won't return true when the inserted value for run_on has an invalid value. Syntax to work with timestamps/intervals and operate with them is different in both databases, and that's what I fixed with the last push :wink: . As per @sgrif's comment, probably this can be merged now.\n@killercup: WDYT?. You're welcome! Thanks for your patience with me, and for merging the fix :slightly_smiling_face: . Yay! Thanks for merging :smiley: . ",
    "euclio": "Any way I can help get this moving? What still needs to be done?. Right, but I think one use case would be for a :memory: database where you cannot create multiple connections to it.\n. I would like to see #184 resolved. As I said on the issue, I'd like to help with this but I'm having trouble finding time.. SQLite has support for opening databases with URIs such as file::memory:?cache=shared, which allows you to turn various knobs while opening the database (caching, read-only, etc.). However, this support is disabled by default. An application may request URI support by supplying the correct flags to sqlite_open_v2. Observe that if you use that URI with diesel a file named file::memory:?cache=shared will be created instead of an in-memory database (at least, it will for a brewed sqlite on Mac OS).. Perhaps an example will make the issue clearer?\nThis program creates the database in memory, which is expected when using a URI.\n```rust\nextern crate rusqlite;\nuse rusqlite::Connection;\nfn main() {\n    Connection::open(\"file::memory:?cache=shared\").unwrap();\n}\n```\nOn the other hand, this program creates the database in a file called file::memory:?cache=shared.\n```rust\nextern crate diesel;\nuse diesel::prelude::*;\nfn main() {\n    SqliteConnection::establish(\"file::memory:?cache=shared\").unwrap();\n}\n```\n. That's correct.. Yes, will address your comments within the week.\nOn Sat, Feb 3, 2018, 4:56 PM Sean Griffin notifications@github.com wrote:\n\n@euclio https://github.com/euclio Are you still interested in finishing\nthis?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/pull/1292#issuecomment-362857721,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABTxFlSdKhm97xG_tJGk7BMoQZtU0xY5ks5tRNYhgaJpZM4QQoO6\n.\n. Addressed comments.. Cool, will address feedback within the week. There hasn't been an impetus for me to work on this since my own project that uses Diesel has stalled, but if there's more interest than just me I'm happy to work on it :). @sgrif This is ready for another review. Failure on nightly is unrelated.. Thanks for the ping, @joelgallant. Rebased.. Ping @sgrif . My understanding is that this flag is required to use the shared memory cache mode when opening a file with URI file::memory:?cache=shared.. \n",
    "lilyball": "Same here. I'd love to see this get done, and I'm happy to help if someone wants to provide some direction.. ",
    "gentoo90": "Are there any plans to add schema inference for DATE, TIME, DATETIME and TIMESTAMP?\nCurrently (master, 560f650a89ffd283888362) they all fail:\ndiesel/diesel_cli $ sqlite3 test_datetime.db 'CREATE TABLE test (id INTEGER PRIMARY KEY, dt DATETIME)'\ndiesel/diesel_cli $ echo 'DATABASE_URL=test_datetime.db' > .env\ndiesel/diesel_cli $ RUST_BACKTRACE=1 cargo run print-schema\n    Finished release [optimized] target(s) in 0.0 secs\n     Running `/home/igor/projects/rust/diesel/target/release/diesel print-schema`\nthread 'main' panicked at 'Could not load table `test`: StringError(\"Error determining type of test.dt: Unsupported type: datetime\")', /checkout/src/libcore/result.rs:859. Thanks for the fix!. > Thanks! That's a This should only work on strings, though, right? Or does it work on numbers and binaries, too?\nWell, applying it to INTEGER doesn't cause any syntax errors.\nsql\nselect * from projects where id = 1 collate nocase. @sgrif Write now I don't have time for this. Also I lack knowledge of MySQL and PostgreSQL to do it properly.. > The COLLATE operator is a unary postfix operator that assigns a collating sequence to an expression. The COLLATE operator has a higher precedence (binds more tightly) than any binary operator and any unary prefix operator except ~. (COLLATE and ~ are associative so their binding order does not matter.) The collating sequence set by the COLLATE operator overrides the collating sequence determined by the COLLATE clause in a table column definition.\nhttps://sqlite.org/lang_expr.html#collateop\nFor example:\nsql\nSELECT * FROM [projects]\n    WHERE [name] COLLATE NOCASE = 'test' COLLATE RTRIM\n    ORDER BY NAME COLLATE NOCASE COLLATE BINARY;\nis syntactically correct.. Probably a good idea.\n\nAn application can register additional collating functions using the sqlite3_create_collation() interface.\n\nhttps://sqlite.org/datatype3.html#collating_sequences. I thought about this too, but then I found out that other DB engines also have COLLATE, and it's used a little differently.\nhttps://www.postgresql.org/docs/9.6/static/collation.html\nhttps://dev.mysql.com/doc/refman/5.7/en/charset-collate.html\nIf this trait will be reused for them, then it's probably better to allow non-static strings here.. ",
    "krypt-n": "The SqliteConnection doesn't implement Send. I dont think this restriction is useful, since Sqlite can be (and usually is) compiled with multi-thread support (And PgConnection implements Send).\nrusqlite uses unsafe impl Send for Connection {} to archieve that.\n. ",
    "drusellers": ":+1:\n. I also use schemas outside of public. \n. ",
    "seamusabshere": "hey @sgrif do you have a WIP branch for this?. > I am going to do on_conflict_do_nothing before the rest though, I might be able to finish just that piece of it soon.\ni feel like this would cover 80% of use cases, thanks for your expertise @sgrif . hey @sgrif please do push this out to us if you have other priorities. @sgrif this is awesome!. huzzah it passed. ",
    "nerdrew": "Hmmm. How do I types_roundtrip.rs?\n. Lol. Straightforward took me a while :) Not sure if PgUuid is the best way to do this, but it's the only thing I could get to work with quickcheck.\nI can squash the commits if desired, but kept them separate for review.\n. Ok, removed the new type.\n. Thoughts?\n. Ya, still want to land this. Was traveling for work last week and couldn't get to this. Sorry for the delay.\n. Hmmm. I'm getting compile errors when trying to use this now.\nsrc/db/models.rs:184:1: 184:25 error: the trait `diesel::Expression` is not implemented for the type `uuid::Uuid` [E0277]\nsrc/db/models.rs:184 #[insertable_into(logs)]\n                     ^~~~~~~~~~~~~~~~~~~~~~~~\nsrc/db/models.rs:184:1: 184:25 note: in this expansion of #[insertable_into] (defined in src/db/models.rs)\nsrc/db/models.rs:184:1: 184:25 help: run `rustc --explain E0277` to see a detailed explanation\nsrc/db/models.rs:184:1: 184:25 note: required by `diesel::expression::AsExpression::as_expression`\nsrc/db/models.rs:184:1: 184:25 error: mismatched types:\n expected `diesel::expression::bound::Bound<diesel::types::Uuid, &uuid::Uuid>`,\n    found `&uuid::Uuid`\n(expected struct `diesel::expression::bound::Bound`,\n    found &-ptr) [E0308]\nsrc/db/models.rs:184 #[insertable_into(logs)]\n                     ^~~~~~~~~~~~~~~~~~~~~~~~\nsrc/db/models.rs:184:1: 184:25 note: in this expansion of #[insertable_into] (defined in src/db/models.rs)\nsrc/db/models.rs:184:1: 184:25 help: run `rustc --explain E0308` to see a detailed explanation\nsrc/db/models.rs:185:23: 185:23 error: the trait `diesel::Expression` is not implemented for the type `uuid::Uuid` [E0277]\nsrc/db/models.rs:185 #[changeset_for(logs)]\n                                           ^\nsrc/db/models.rs:185:1: 185:23 note: in this expansion of #[changeset_for] (defined in src/db/models.rs)\nsrc/db/models.rs:185:23: 185:23 help: run `rustc --explain E0277` to see a detailed explanation\nIdeas?\n. Yup, that was it. Thanks! Also, rebased again. The test failures don't look related to this PR.\n. Sorry. Was busy last couple nights and didn't get a chance to make the fixes. THANKS FOR FIXING / MERGING!\n. Follow up question: is it possible to have multiple joins? I see a test for a join through, but what about cases where there isn't a through?\nWhat I want:\nrust\nlogs::table.select((logs::id, users::id, hosts::id))\n    .inner_join(hosts::table)\n    .inner_join(users::table)\n    .limit(1)\n. Ah, ok. I'm using .cargo/config to override diesel and diesel_codegen to use master. Sounds like I need to add diesel_codegen_syntex to that list too. :)\n. General workflow question: do you prefer \"fixup\" commits and then squash before merging, or should I just amend this commit?. @sgrif ya, those \"used variable\" errors are caused by quote changes. The errors are real. Fixing now.. Total guess here. Is this appropriate? Does there need to be an expression_impls, etc too?\n. Will do\n. Will do\n. yup\n. Yup, can do.\n. Makes sense, but my rust-fu is not very good. I added something, but I'm not sure it is any clearer.\n. I'm not sure about this change or the next one, but I couldn't get it to compile on my nightly without it.\n% rustc --version\nrustc 1.9.0-nightly (c9629d61c 2016-03-10)\n. Error: \ntests/types_roundtrip.rs:88:9: 88:18 error: a module named `connection` has already been imported in this module [E0252]\ntests/types_roundtrip.rs:88     use super::*;\n. Hmmm. I also had to make this public:\ndiesel/src/pg/types/mod.rs:15:21: 15:44 error: extern crate `uuid` is private\ndiesel/src/pg/types/mod.rs:15     pub type Uuid = super::uuid::uuid::Uuid;\nDoes that seem right?\n. Yup. Fixed in the nightly I just installed. Removed.\n. Done.\n. No reason. What would you prefer?. std::time::Duration conflicts with super::Duration.. Should I break out the ordering changes to the tests into a separate PR or do you want to fix it more holistically? . It isn't. I just couldn't get it to compile using references :(. I think this is the change that prompted the &str to String and &[..] to Vec changes.\nMetaItem::List needs to be transformed into a list of MetaItem's. I couldn't figure out how to return a slice of these. Ideas?. It isn't. It looks like I can get rid of this Vec.. Is there a way to pass the lifetime of options to get_option and use that as the lifetime on the returned str? I couldn't get that to work, which is why I switch the return value of get_option to String (and all the associated changes str to String).. Will fix.. Yup. Fixed.. Will remove the order changes. The rest seems to be atomic though, yes?. Is there a cleaner way to go from Option<String> to Option<&str>?. Done. Done.. Good to know; unnecessary in this PR now though ;). Just the &s for the &strs right? I still need them for the options: Option<Vec<MetaItem>> returned from get_options_from_input?. Removed.. TIL.. Done.. The whole path_ident function? I.e. path_ident(ident) => ident.into()?. The method is public, does that matter in this case?. Cool. I removed it. Let me know if the pub makes it need to stay.. ",
    "Shiney": "Thanks\n. ",
    "zamith": "Even if I copy the database to the project's folder it's the same thing. I even tried creating a new database with sqlite3 test.db, change the DATABASE_URL to be ./test.db, and ran the ruby and rust scripts again.\nThe result for ruby was an error because there was no table (expected), on diesel it complained with the \"unable to open database file\" again. \nThere's probably something I'm doing wrong in the rust code. I've pushed it up here.\n. I get the same error if I remove the test.db file, and run diesel setup. I'm guessing this never happens on the tests because they all start the connection with :memory:.\n. How can I run that? I can try that locally on my machine, and try to figure out what I'm doing wrong.\n. Hum... But even if I have the file on the same directory it is failing for me. I'm defining the path as ./foo.db is that not the correct way?\n. That's correct. By removing the quotes it works. That's probably something that could be added to dotenv rust then.\nThanks and sorry for the trouble.\n. ",
    "barosl": "Ah, thanks for the explanation!\nI think I can live with .filter(sql(\"TRUE GROUP BY ...\")) for now, because although it's a bit silly as you said, there seems to be no other \"better\" workarounds out there. I was a bit worried if there were better alternatives, but given your explanation, I'm fine with using the best workaround. I can perfectly wait until you guys introduce a true group_by function.\nThe reason why I used .order(sql::<Text>(\"sum\")) was that whatever I put there, it compiled and worked. So I put the one that looked the most \"generic\" (Text). But thinking again, it seems that the reason why it compiled was that .order() requires its parameter to be orderable, and Text happens to be SqlOrd. Is my assumption correct?\n. > I just pushed a better workaround.\nOh, I thought the added group_by was for internal use because you said it was not part of the public API. By \"public API\" did you mean the method was #[doc(hidden)]?\n\nMy comment about the type was for your select clause, not your order clause.\n\nOops, it seems that the pasted code above is different from my production code. I actually did use BigInteger correctly in the select clause (it doesn't even compile if I use other types, actually), so what caused me confused is what to use in the order clause. I guess, even though .order doesn't care about types particularly, using BigInteger in there too is \"correct\". Am I right?\n. Awesome! Thanks for the explanation.\n. I've added a new commit, please check it out.\n. This is being fixed by #217, stay tuned!\n. You can also \"override\" some crates globally. Create a file named ~/.cargo/config, and type this:\npaths = [\n    \"/home/barosl/cloned-git-repos/diesel\",\n]\nIn this way you don't need to modify your Cargo.toml. But don't forget to remove the global path after the official version is released, otherwise you will use the outdated (cloned) version forever.\n. ",
    "Boscop": "Does this mean it's not possible to group by a non-fkey column? \nE.g. select version, count(*) from clients group by version order by version. Thanks. @golddranks Is this correct?\nrust\nfn time_to_json(t: NaiveDateTime) -> String {\n    DateTime::<UTC>::from_utc(t, UTC).to_rfc3339()\n}\nThis results in a string like \"2017-01-06T09:27:39.833109+00:00\".\n(I set the postgres timezone to UTC whenever my server starts (so that now() returns the UTC time), and I use NaiveDateTime in my ORM structs, and store all times as UTC with the timestamp postgres type in the db.)\nAnd then in js:\njs\nmoment(new Date(post.timeStr)).fromNow()\nTo show a post's relative time in the client's timezone using moment.js.. @marcusball Good to know, but right now I'm converting the row struct to an api view struct anyway, because not all fields should be exposed to the json api (such as users' email).\nI want now() to be in UTC, so I do this at the start of my server:\nrust\ndatabase::connection().get().unwrap().execute(\"SET TIME ZONE 'UTC';\").unwrap();\nWould it be sufficient to do it once as a migration?\nOr, should I do this more often than when the server starts? \nLet's say the connection from server to db breaks down for some reason (db restarts) should I execute this upon all reconnections?\n. I now use NaiveDateTime and store all my times in UTC, and convert them to client time in the frontend.. Not necessary. I just want to make sure that all tags are in the table after the query.\nSo I can get all their ids with the next query.. With the help of @killercup I figured out what the problem was (thanks a lot!):\nAt the end of the query, there is only one column 'f' with all the columns as tuple members. In the postgres cmd line I thought it looked like a normal row -.-\nBtw, this is my ORM/schema:\n```rust\n[derive(Queryable, Identifiable, Clone, Associations, Debug)]\n[belongs_to(User)]\npub struct Filter {\n    pub id: i64,\n    pub user_id: i64,\n    pub created_at: NaiveDateTime,\n    pub updated_at: NaiveDateTime,\n    pub name: String,\n    pub description: String\n    pub code: String,\n    pub params: String,\n    pub tags: Vec,\n}\n@killercup suggested I name all the rows explicitly to pull them through to the outer scope instead of using the catchall '*' (I also tried `filters.* AS f`, but it's a syntax error). This works:rust\n    let query = sql(&format!(r#\"\nWITH ranking AS (\n    SELECT \n    FROM (\n        SELECT\n            ts_rank(\n                to_tsvector('english', filters.name) ||\n                to_tsvector('english', filters.description) ||\n                to_tsvector('english', array_to_string(filters.tags, ' '))\n            , plainto_tsquery('{}'), 32) AS score,\n            id,\n            user_id,\n            created_at,\n            updated_at,\n            name,\n            description,\n            code,\n            params,\n            tags\n        FROM filters\n    ) s\n    WHERE score > 0\n    ORDER BY score DESC\n)\nSELECT \n            id,\n            user_id,\n            created_at,\n            updated_at,\n            name,\n            description,\n            code,\n            params,\n            tags\nFROM ranking;\n    \"#, search_terms));\n    query.get_results::(&database::connection().get().unwrap()).map_err(|e| e.into())\n```\nBut it's unelegant because:\n1. column names are duplicated\n2. query has to stay in sync with the schema and this is not enforced at compile time\nSo my remaining questions are:\n- Is there a way to avoid this and write it in a way such that I don't have to change the query when adding new columns to filter?\n- I could get the original to work if there is a way to splat/unpack a tuple into columns. Is there a function for this in postgresql?\n- Still the SQL injection issue... Thanks!. @durango Thanks!\nNow I'm reusing the connection and that assertion succeeds, BUT later when I actually call search_filters I get:\nerror: prepared statement \"search_filters\" does not exist\nand in my pg_log:\n2017-01-27 14:28:19 CET ERROR:  prepared statement \"search_filters\" does not exist\n2017-01-27 14:28:19 CET STATEMENT:  EXECUTE search_filters('bar');\nI'm calling it like this:\nrust\npub fn search(search_terms: &str) -> Result<Vec<Filter>, error::MyError> {\n    use diesel::prelude::*;\n    use models::schema::filters::dsl::*;\n    use diesel::expression::sql_literal::sql;\n    let query = sql(&format!(\"EXECUTE search_filters('{}')\", search_terms));\n    query.get_results::<models::filter::Filter>(&*database::connection().get().unwrap()).map_err(|e| e.into())\n}\nPrepared statements are only stored during a session. But what constitutes a session when I'm using a session pool like this?\n```rust\nuse std::env;\nuse diesel::pg::PgConnection;\nuse r2d2_diesel::ConnectionManager;\nuse r2d2;\nlazy_static! {\n    static ref CONNECTION: r2d2::Pool> = {\n        let database_url = env::var(\"DATABASE_URL\")\n            .expect(\"DATABASE_URL must be set\");\n        let config = r2d2::Config::default();\n        let manager = ConnectionManager::::new(database_url);\n        r2d2::Pool::new(config, manager).expect(\"Failed to create pool\")\n    };\n}\npub fn connection() -> r2d2::Pool> {\n    CONNECTION.clone()\n}\n```\nIn my pg_log I notice A LOT of these lines:\n\n2017-01-27 14:28:35 CET LOG:  could not receive data from client: An existing connection was forcibly closed by the remote host.\n\nDoes that mean that after every statement execution I do, the pool drops the connection, and the session ends?\nIf so, what would you do to ensure that the timezone and the prepared statement are always set before any statements are executed?\nIs it possible to run a some given startup code whenever the pool creates a new connection/session?\nAnd does it make sense, performance wise, to run that code every time a new connection starts?\nOr is there a way to abstract from that, and make it appear like one continuous session while my server runs?\n. I figured some stuff out..\nWith the code below it seems to work.\nIs this the right way to solve the problem / how prepared statements are usually set when a connection pool is used that drops the connection?\n```rust\nuse std::env;\nuse diesel::pg::PgConnection;\nuse r2d2_diesel::ConnectionManager;\nuse r2d2;\nlazy_static! {\n    static ref CONNECTION: r2d2::Pool> = {\n        let database_url = env::var(\"DATABASE_URL\")\n            .expect(\"DATABASE_URL must be set\");\n        // let config = r2d2::Config::default();\n        let config = r2d2::Config::builder().connection_customizer(box MyCustomizeConnection).build();\n        let manager = ConnectionManager::::new(database_url);\n        r2d2::Pool::new(config, manager).expect(\"Failed to create pool\")\n    };\n}\npub fn connection() -> r2d2::Pool> {\n    CONNECTION.clone()\n}\nuse r2d2::CustomizeConnection;\n[derive(Debug)]\nstruct MyCustomizeConnection;\nimpl CustomizeConnection for MyCustomizeConnection {\n    fn on_acquire(&self, conn: &mut PgConnection) -> Result<(), E> {\n        use diesel::Connection;\n        use diesel::expression::sql_literal::sql;\n        use diesel::LoadDsl;\n        conn.execute(\"SET TIME ZONE 'UTC';\").unwrap();\n        conn.execute(\"\n            PREPARE search_filters(text) AS\n            WITH ranking AS (\n                SELECT \n                FROM (\n                    SELECT\n                        ts_rank(\n                            to_tsvector('english', filters.name) ||\n                            to_tsvector('english', filters.description) ||\n                            to_tsvector('english', array_to_string(filters.tags, ' '))\n                        , plainto_tsquery($1), 32) AS score,\n                        id,\n                        user_id,\n                        created_at,\n                        updated_at,\n                        name,\n                        description,\n                        code,\n                        params,\n                        tags\n                    FROM filters\n                ) s\n                WHERE score > 0\n                ORDER BY score DESC\n            )\n            SELECT \n                        id,\n                        user_id,\n                        created_at,\n                        updated_at,\n                        name,\n                        description,\n                        code,\n                        params,\n                        tags\n            FROM ranking;\n        \").unwrap();\n        assert_eq!(Ok(1), sql(\"SELECT count() FROM pg_prepared_statements;\").get_result::(conn));\n    Ok(())\n}\n\n}\n. Yes, thanks! \nBtw, I switched to a function, because it persists across sessions:sql\nCREATE OR REPLACE FUNCTION  search_filters(search_terms text)\nRETURNS SETOF filters AS\n$func$\nBEGIN\n    return query\n    select * from filters\n    where\n        ts_rank(to_tsvector('english', filters.name) ||\n                to_tsvector('english', filters.description) ||\n                to_tsvector('english', array_to_string(filters.tags, ' ')),\n        plainto_tsquery(search_terms), 32)\n    > 0\n    order by\n        ts_rank(to_tsvector('english', filters.name) ||\n                to_tsvector('english', filters.description) ||\n                to_tsvector('english', array_to_string(filters.tags, ' ')),\n        plainto_tsquery(search_terms), 32)\n    desc;\nEND;\n$func$\nLANGUAGE 'plpgsql';\n. Yeah, posts can have a parent post that they reply to.\nWill it be possible in the future to write `Post::belonging_to(&post)` for a self-referential association like this?. Yay!. @golddranks I have:rust\n[derive(Queryable, new, Debug, Associations)]\n[belongs_to(User)]\n[belongs_to(Post)]\n[derive(Insertable)]\n[table_name=\"likes\"]\npub struct Like {\n    pub user_id: i64,\n    pub post_id: i64,\n}\n...\n[derive(Queryable, Identifiable, Clone, Associations, Debug)]\n[belongs_to(User)]\n// #[belongs_to(Post, foreign_key=\"parent\")]\npub struct Post {\n    pub id: i64,\n    pub user_id: i64,\n    pub parent: Option,\n    ...\n}\nIf I add `#[has_many(Like)]` to Post, I get:rust\nerror[E0223]: ambiguous associated type\n    |\n130 | #[derive(Queryable, Identifiable, Clone, Associations, Debug)]\n    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ambiguous associated type\n    |\n    = note: specify the type using the syntax <models::like::Like as Trait>::table\n    = note: this error originates in a macro outside of the current crate\n```\nWhat now?. @golddranks Thanks, I changed it to #[has_many(likes)], but now I get:\nrust\nerror[E0308]: mismatched types\n    |\n194 |       likes::table.inner_join(posts::table).filter(user_id.eq(uid)).count()\n    |                               ^^^^^^^^^^^^ expected struct `models::schema::__diesel_infer_schema::infer_users::users::table`, found struct `models::schema::__diesel_infer_schema::infer_posts::posts::table`\n    |\n    = note: expected type `models::schema::__diesel_infer_schema::infer_users::users::table`\n               found type `models::schema::__diesel_infer_schema::infer_posts::posts::table`. Ah, nevermind, I had changed this:\n```rust\n[belongs_to(User)]\n[belongs_to(Post)]\nto this:rust\n[belongs_to(User, Post)]\nbecause I assumed it would work, just like:rust\n[derive(Queryable, Insertable, new, Debug, Associations)]\n```\nNow that I changed it back to the former version, it compiles, yay!\nThanks!. @killercup The issue (at the end) was that I thought one could specify multiple structs that a struct belongs to in one #[belongs_to()] attribute, because it works with #[derive()]..\nBtw, now this works:\n```rust\npub fn get_likes_count(&self) -> Result {\n    use diesel::prelude::;\n    use models::schema::likes;\n    use models::schema::posts;\n    use models::schema::posts::dsl::;\nlikes::table.inner_join(posts::table).filter(user_id.eq(self.id)).count()\n    .get_result(&*database::connection().get().unwrap()).map_err(|e| e.into())\n\n}\n```\nBut this doesn't:\n```rust\npub fn get_liked_posts(&self) -> Result, error::MyError> {\n    use diesel::prelude::;\n    use models::schema::likes;\n    use models::schema::posts;\n    use models::schema::posts::dsl::;\nlikes::table.inner_join(posts::table).filter(user_id.eq(self.id))\n    .get_results(&*database::connection().get().unwrap()).map_err(|e| e.into())\n\n}\n```\n\nthe trait diesel::types::FromSqlRow<((diesel::types::BigInt, diesel::types::BigInt), (diesel::types::BigInt, diesel::types::BigInt, diesel::types::Timestamp, diesel::types::Timestamp, diesel::types::Nullable<diesel::types::BigInt>, diesel::types::Text, diesel::types::Text, diesel::types::Nullable<diesel::types::Timestamp>, diesel::types::Integer, diesel::types::Nullable<diesel::types::BigInt>, diesel::types::Nullable<diesel::types::BigInt>, diesel::types::Nullable<diesel::types::BigInt>)), diesel::pg::Pg> is not implemented for (i64, i64, chrono::NaiveDateTime, chrono::NaiveDateTime, std::option::Option<i64>, std::string::String, std::string::String, std::option::Option<chrono::NaiveDateTime>, i32, std::option::Option<i64>, std::option::Option<i64>, std::option::Option<i64>)\n\nBecause the output has the columns of likes and posts, but it should only have the columns of posts.\nWhat's the correct way to do this?. I also tried splitting it up into two queries like this:\n```rust\npub fn get_liked_posts(&self) -> Result, error::MyError> {\n    use diesel::prelude::;\n    use models::schema::likes;\n    use models::schema::posts;\n    use models::schema::posts::dsl::;\nlet conn = &*database::connection().get().unwrap();\nlet likes = models::like::Like::belonging_to(self).load(conn)?;\nmodels::post::Post::belonging_to(&likes).order(created_at.desc()).load(conn)?\n\n}\n```\nBut I get:\n\nerror: no associated item named belonging_to found for type models::like::Like in the current scope\nnote: the method belonging_to exists but the following trait bounds were not satisfied: models::like::Like : diesel::associations::HasTable, models::like::Like : diesel::associations::HasTable, models::like::Like : diesel::associations::HasTable, models::like::Like : diesel::associations::HasTable, models::like::Like : diesel::BelongingToDsl<&[_]>, ......\n\nBut I have:\n```rust\n[derive(Queryable, Insertable, Associations, new, Debug)]\n[belongs_to(User)]\n[belongs_to(Post)]\n[table_name=\"likes\"]\npub struct Like {\n    pub user_id: i64,\n    pub post_id: i64,\n}\n[derive(Queryable, Identifiable, Associations, Debug, Clone)]\n[has_many(likes)]\npub struct User {\n    pub id: i64,\n    ...\n}\nSo why doesn't `Like` have the method `belonging_to()`?. @sgrif Thanks!\nI did that now:rust\n[derive(Queryable, Identifiable, Insertable, Associations, new, Debug)]\n[belongs_to(User)]\n[belongs_to(Post)]\n[primary_key(user_id, post_id)]\n[table_name=\"likes\"]\npub struct Like {\n    ....\n}\n[derive(Queryable, Identifiable, Associations, Clone, Debug)]\n[belongs_to(User)]\n[has_many(likes)]\npub struct Post {\n     ...\n}\n```\nbut I still get errors:\n```rust\npub fn get_liked_posts(&self) -> Result, error::MyError> {\n    use diesel::prelude::;\n    use models::schema::likes;\n    use models::schema::posts;\n    use models::schema::posts::dsl::;\n    use models::like::Like;\n    use models::post::Post;\nlet conn = &*database::connection().get().unwrap();\nlet likes: Vec<Like> = Like::belonging_to(self).load(conn).map_err(|e| e.into())?;\nPost::belonging_to(&likes).order(created_at.desc()).load(conn).map_err(|e| e.into())\n\n}\n```\n\nerror[E0277]: the trait bound models::post::Post: diesel::BelongingToDsl<&std::vec::Vec<models::like::Like>> is not satisfied\n\nThis version also doesn't work; how can I get rid of the columns of likes in the join result?\n```rust\npub fn get_liked_posts(&self) -> Result, error::MyError> {\n    use diesel::prelude::;\n    use models::schema::likes;\n    use models::schema::posts;\n    use models::schema::posts::dsl::;\n    use models::like::Like;\n    use models::post::Post;\nlet conn = &*database::connection().get().unwrap();\nlikes::table.inner_join(posts::table).filter(user_id.eq(self.id))\n    .get_results(conn).map_err(|e| e.into())\n\n}\n```\n\nerror[E0277]: the trait bound (i64, i64, chrono::NaiveDateTime, chrono::NaiveDateTime, std::option::Option<i64>, std::string::String, std::string::String, std::option::Option<chrono::NaiveDateTime>, i32, std::option::Option<i64>, std::option::Option<i64>, std::option::Option<i64>): diesel::types::FromSqlRow<((diesel::types::BigInt, diesel::types::BigInt), (diesel::types::BigInt, diesel::types::BigInt, diesel::types::Timestamp, diesel::types::Timestamp, diesel::types::Nullable<diesel::types::BigInt>, diesel::types::Text, diesel::types::Text, diesel::types::Nullable<diesel::types::Timestamp>, diesel::types::Integer, diesel::types::Nullable<diesel::types::BigInt>, diesel::types::Nullable<diesel::types::BigInt>, diesel::types::Nullable<diesel::types::BigInt>)), diesel::pg::Pg> is not satisfied. This seems to work:\n```rust\npub fn get_liked_posts(&self) -> Result, error::MyError> {\n    use diesel::prelude::*;\n    use models::schema::likes;\n    use models::schema::likes::dsl::user_id;\n    use models::schema::posts;\n    use models::schema::posts::dsl::created_at;\n    use models::like::Like;\n\nlet conn = &*database::connection().get().unwrap();\nOk(posts::table.inner_join(likes::table).filter(user_id.eq(self.id)).order(created_at.desc()).get_results(conn)?.into_iter().unzip::<_, _, _, Vec<Like>>().0)\n\n}\nBut with get_results() I'm getting a Vec<(Post, Like)>, but I only need the Vec<Post> so I unzip it and throw away the Vec<Like>, which is wasteful..\nIs there a better way to get all the posts that this user likes?. Ah, I found a way that works:rust\npub fn get_liked_posts(&self) -> Result, error::MyError> {\n    use diesel::prelude::*;\n    use models::schema::likes;\n    use models::schema::likes::dsl::user_id;\n    use models::schema::posts;\n    use models::schema::posts::dsl::created_at;\nlet conn = &*database::connection().get().unwrap();\nOk(posts::table.inner_join(likes::table).filter(user_id.eq(self.id))\n    .select(posts::all_columns).order(created_at.desc()).get_results(conn)?)\n\n}\nIs this the best way to do it?. Thanks!. I understand.\nSo currently the only way to do it is like this?rust\nlet query = sql(&format!(\"select users. from users join follows on id = sub_id where pub_id = {}\", self.id));\nquery.get_results::(&database::connection().get().unwrap()).map_err(|e| e.into())\n```. Ok, but I get an error:\n\nerror[E0282]: unable to infer enough type information about SE\n\n(It underlines get_results.)\nWhen I write it like sql::<User>(..), I get:\n\nerror[E0277]: the trait bound (i64, std::string::String, std::string::String, std::string::String, chrono::NaiveDateTime, chrono::NaiveDateTime, std::option::Option<i64>): diesel::types::FromSqlRow<models::user::User, _> is not satisfied. @sgrif Isn't that what I'm doing with sql::<User>(..)?\nrust\nlet query = sql::<User>(&format!(\"select users.* from users join follows on id = sub_id where pub_id = {}\", self.id));\nquery.get_results::<User>(&*database::connection().get().unwrap()).map_err(|e| e.into()). Thanks a lot, it works!. Does this mean that citext is not supported anymore? Why? \nI really want to use citext for e.g. username and email address columns.. The sqlite crate that diesel uses exposes these functions here:\nhttps://github.com/jgallagher/rusqlite/blob/master/libsqlite3-sys/sqlite3/bindgen_bundled_version.rs#L1281-L1360\n. Nice, there's also create_aggregate_function() and remove_function().\nThe functions would have to be created in r2d2::CustomizeConnection::on_acquire(), right?\n\nWhat would have to be done to expose this functionality so that it can be used with diesel?. Yes that would be great. \nI'm planning to use it to impl fuzzy string comparison / search. . I'm aware of FTS but it doesn't really support the kind of fuzzy matching I need and it looks like diesel doesn't support FTS's MATCH expression or am I missing something?\nEDIT: factored out the rest of this comment into a new issue: https://github.com/diesel-rs/diesel/issues/1112. Another custom function that I'd like to have in a query is |s| Path::new(s).file_stem()\nWhere would one have to start when adding this feature?\nHere is the relevant code in rusqlite.\nWould these functions have to be added here?\nAnd then exposed/forwarded here?\n. @maghoff Not yet, I was very busy working on other stuff..\n@sgrif Wouldn't people usually register their custom sqlite functions in r2d2::CustomizeConnection::on_acquire()?. It works when I don't use the infer_schema! macro (because it doesn't support excluding tables), but instead write the schemas of all tables manually and then:\nrust\ntable! {\n    foo(rowid) {\n        rowid -> Integer,\n        path -> Text,\n    }\n}. Win 8.1. Ah, I didn't know that. Thanks!. I'm not an sqlite expert but I tested it in the REPL and I don't see a reason why the connection wouldn't be perfectly usable afterwards. . Thanks, #[changeset_options(treat_none_as_null = \"true\")] seems like an acceptable workaround for now, but do you see my point?:\n- The expected semantics of save_changes() after setting a field to None are like saving a text file in an editor, after setting one line to empty (not removing the line). It would still save this change!\n- The semantic difference between save_changes() and update() is the difference between overwriting a file after changing some lines and applying a patch to a file.\n- Usually, if one wants to be able to call both save_changes() and update() on a table, they would define a separate changeset struct for update() that only includes the fields they are \"patching\".. Thanks for the quick reply.\nBy input you mean the recommended use-case in an API server is to deserialize the request directly into a changeset struct? \nI never do that, I always have separate data types for controllers (different requests act on data in different ways and not every request should be allowed to change all fields, e.g. editing a reply post should not allow changing its parent_id), models (the ORM structs) and views (different users can see different fields).\nSo for edit requests I always deserialize into a FooEdit struct first, do the validation on that, then create a FooUpdate struct instance from that and then call update() with that. (My controllers never call diesel functions directly, they call methods on the ORM struct that call the diesel functions.)\nSo I usually define a FooUpdate struct for every Foo struct that participates in the API.\nBut for internal ORM structs that are not changed by requests directly, I usually derive AsChangeset on Foo itself and then call save_changes() directly on a Foo instance.\n\n\nHow common is it to deserialize a request directly into the actual changeset struct?\n\n\nAnd in those use cases, wouldn't that changeset struct usually be a separate struct (FooUpdate) than the model struct (Foo), with the fields suitably Option-ized? (So it would still allow Foo::save_changes() to behave differently than updating with a FooUpdate.) Otherwise, the API would be very insecure, every model field could be changed by a request (unless the controller does extra measures to prevent that, like using record update syntax with only overwriting the allowed fields, but it's too easy to forget doing that.). Hm, shouldn't model structs be both Queryable and Identifiable? Should it be separate structs? But how would their fields differ?\n\n\nI never used any other ORMs before diesel, I just learned how to use diesel about a year ago by looking at this project.. (But I knew some sql/postgres before.)\nAll its model structs are Queryable and Identifiable, (e.g. User here).\nSo in my projects I used the same structure, e.g.:\n```rust\n[derive(Debug, Queryable, Identifiable, Associations, AsChangeset)]\n[belongs_to(Place)]\n[belongs_to(Customer)]\n[table_name = \"clients\"]\npub struct Client {\n    pub id: i64,\n    pub customer_id: Option,\n    pub created_at: NaiveDateTime,\n    pub updated_at: NaiveDateTime,\n    pub place_id: Option,\n    pub unique_id: String,\n    pub version: i32,\n    pub last_seen: NaiveDateTime,\n}\n[derive(Insertable)]\n[table_name = \"clients\"]\npub struct NewClient<'a> {\n    pub unique_id: &'a str,\n    pub version: i32,\n}\n``\n(And then I call e.g.client.save_changes()`.)\nBtw, please don't deprecate save_changes(), it's very useful, and the above workaround makes it work in my use case :). But then how to support case-insensitive string comparison with a custom Citext type?. Ah, I shouldn't reverse the byte order.. \nNow it shows the same value.\n\nBut now the question arises, what's the correct way to serialize geography points? \nIs it valid to write geography points as EWKB in any expression? such as in insert statements, or as argument to functions like ST_DWithin?. Any update on this? :). ",
    "nokaa": "In case anyone else runs into this, a temporary fix is to clone the repository and copy the files in diesel_codegen to wherever cargo stores repositories. In my case, this was\n~/.multirust/toolchains/nightly/cargo/registry/src/github.com-xxxxxxxxxxxx/diesel_codegen-0.5.0\n. @sgrif I attempted to do that, but I was unsure what url to use for diesel_codegen. https://github.com/sgrif/diesel/diesel_codegen and https://github.com/sgrif/diesel/tree/master/diesel_codegen both failed to clone.\n. I didn't realise that was possible. Thank you! That is much easier.\n. ",
    "benaryorg": "I'm sorry, I just noticed something else related to the documentation and fixed it. That wasn't a typo so I thought closing, and reopening with a new title might be the better idea.\n. If by \"squashing\" you mean unifying them into one commit, yes I can.\n. ",
    "johalun": "Ok, so just specifying a file as DATABASE_URL \"diesel setup\" and \"diesel migration run\" generates a database correctly but when I try the write_posts/read_posts (which works with pgsql) I get connection error:\n[mirama@PC1-13-0006 diesel_demo$ cargo run --bin write_posts\n     Running target/debug/write_posts\nthread '' panicked at 'Error connecting to /home/mirama/dev/diesel_demo/diesel_demo.sqlite: BadConnection(\"missing \\\"=\\\" after \\\"/home/mirama/dev/diesel_demo/diesel_demo.sqlite\\\" in connection info string\\n\")', ../src/libcore/result.rs:746\nnote: Run with RUST_BACKTRACE=1 for a backtrace.\nProcess didn't exit successfully: target/debug/write_posts (exit code: 101)\n. Oh I see.. I have to use different API for sqlite :) That brings us to the next problem. infer_schema!() is not implemented for sqlite. What is the way to solve this with sqlite?\n. Thanks!\nSent from my iPhone\n\nOn Feb 21, 2016, at 06:45, Sean Griffin notifications@github.com wrote:\nYou need to call table! directly for SQLite at the moment.\n\u2015\nReply to this email directly or view it on GitHub.\n. \n",
    "astraw": "Well given the quote We achieve this by having Diesel eliminate the possibility of incorrect database interactions at compile time it wasn't clear to me that Diesel was doing runtime checking on top of compile time checks. So, sure, traditional ORMs should stop injection attacks, but Diesel is very different from ORMs I've used.\nI do think that some documentation (one sentence) somewhere saying that SQL injection is stopped via escaping identifiers at runtime would be useful.\n. ",
    "metmirr": "I am getting same error:\n```\nfailed to compile diesel_cli v0.7.1, intermediate artifacts can be found at /home/user/target-install\nCaused by:\n  Could not compile diesel.\n``\n. By the way I don't have installed nightly rust.  May it is cause the error? \n.rustc 1.8.0 (db2939409 2016-04-11)`\n. Updated 1.10, got following error:\n``\nerror: linking withcc` failed: exit code: 1\nnote: \"cc\" \"-Wl,--as-needed\" \"-Wl,-z,noexecstack\" \"-m64\" \"-L\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib\" \"/tmp/cargo-install.IchmseIjqLSz/release/diesel.0.o\" \"-o\" \"/tmp/cargo-install.IchmseIjqLSz/release/diesel\" \"-Wl,--gc-sections\" \"-pie\" \"-Wl,-O1\" \"-nodefaultlibs\" \"-L\" \"/tmp/cargo-install.IchmseIjqLSz/release\" \"-L\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps\" \"-L\" \"/usr/lib/x86_64-linux-gnu\" \"-L\" \"/usr/lib\" \"-L\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib\" \"-Wl,-Bstatic\" \"-Wl,-Bdynamic\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libclap-9bc84d3c3d1b047d.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libansi_term-3a668ea74b382988.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libvec_map-f8aa344cc08e9b03.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libdotenv-695bff8444756e3d.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libbitflags-e61ad67c3301e77d.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libdiesel-2d4d8ef254ad0303.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/liblibsqlite3_sys-755891849c290f5c.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libpq_sys-d9fc24829db90d4f.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libchrono-7342810e34d1c30d.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libtime-750bfdd52feafcb7.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libnum-262f3a136066b482.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libnum_iter-50df698bc905252c.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libbyteorder-f3f7821512ca2fd0.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libregex-a1c323daba09617d.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libthread_local-e5ce0d44bcaf00e6.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libutf8_ranges-5c6a6dacba3be7ce.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libaho_corasick-e528bf4fdf3954ff.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libmemchr-c555f740a543880f.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libthread_id-bcd46c79a620a618.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/liblibc-1bd8847afb79f283.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libnum_integer-52fdddf28cd8e924.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libnum_traits-ca71ec056d3f4118.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libregex_syntax-b24da02611351433.rlib\" \"/tmp/cargo-install.IchmseIjqLSz/release/deps/libstrsim-cb9b0c8013c1be6f.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/libstd-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/libcollections-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/libpanic_unwind-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/librustc_unicode-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/libunwind-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/librand-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/liballoc-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/liballoc_jemalloc-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/liblibc-e8edd0fd.rlib\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib/libcore-e8edd0fd.rlib\" \"-l\" \"sqlite3\" \"-l\" \"sqlite3\" \"-l\" \"sqlite3\" \"-l\" \"pq\" \"-l\" \"util\" \"-l\" \"dl\" \"-l\" \"pthread\" \"-l\" \"gcc_s\" \"-l\" \"pthread\" \"-l\" \"c\" \"-l\" \"m\" \"-l\" \"rt\" \"-l\" \"util\" \"-l\" \"compiler-rt\"\nnote: /usr/bin/ld: cannot find -lsqlite3\n/usr/bin/ld: cannot find -lsqlite3\n/usr/bin/ld: cannot find -lsqlite3\ncollect2: error: ld returned 1 exit status\nerror: aborting due to previous error\nerror: failed to compile diesel_cli v0.7.1, intermediate artifacts can be found at /tmp/cargo-install.IchmseIjqLSz\n``\n. I already have sqlite3\n. It worked with--no-default-features --features \"postgres\"` \nThank you for help.\n. ",
    "indiv0": "@sgrif the problem as I see it is that diesel_codegen and other projects don't automatically use the latest version of syntex available. This is especially problematic because (as you describe), most times the update is not a breaking change.\nA local solution to this problem (i.e., on your's and dotenv's end) would be to set the version requirements to >= 0.28.0. This would allow cargo to automatically bump to the latest version.\nThis would fix the behaviour currently caused by using the caret (^) operator, which for pre-1.0.0 versions limits the project to >= 0.28.0 < 0.29.0, so we only get patch-based changes.\nThis is, however, problematic because packages which use this method will automatically pull in breaking changes to syntex, which will break their local builds.\nThe actual, long-term solution appears to be for syntex to version their builds more correctly according to semver.\nIf these version bumps are indeed non-breaking changes, then the syntex maintainers should be using patch bumps instead of minor bumps while they are pre-1.0.0.\nIf syntex can be considered stable now, then the solution is slightly different but still similar: set the version to 1.0.0 and use the minor version for non-breaking changes.\nI may be looking at this incorrectly, but for example, https://github.com/serde-rs/syntex/pull/38/files does not appear to introduce a breaking change to the syntex API but rather exposes a new method in the API, so it should've been a patch bump (as syntex is still pre-1.0.0).\nI realize that semver says that pre-1.0.0 we shouldn't expect any consistency from APIs, but clearly this is resulting in an issue which needs to be worked around.\n@erickt, @sgrif any thoughts or comments?\n. Also it looks like @mcasper closed this issue (thank you btw!) just as I posted the comment, so yeah this is probably best discussed somewhere in a dedicated issue.\n. @sgrif Well since the result of syntex introducing a breaking change is forcing the update on everyone (not just the projects the change actually affects), then semver isn't able to do its job of allowing libraries which don't explicitly need it to stay on earlier releases.\nThe alternative workaround is then allowing libraries to use different versions of syntex independently.\nI'm curious if individual packages re-exporting syntex could be a solution.\nWould something like this be a plausible option for it?\n``` rust\n[cfg(feature = \"with-syntex\")]\nmod inner {\n    extern crate diesel_codegen;\n    extern crate serde_codegen;\nuse std::env;\nuse std::path::Path;\n\npub fn main() {\n    let out_dir = env::var_os(\"OUT_DIR\").unwrap();\n\n    for &(src, dst) in &[\n        (\"src/main.in.rs\", \"main.rs\"),\n        (\"src/api/v1/policy.in.rs\", \"policy.rs\"),\n        (\"src/api/v1/tracks.in.rs\", \"tracks.rs\"),\n    ] {\n        let src = Path::new(src);\n        let dst = Path::new(&out_dir).join(dst);\n\n        generate_diesel(src, dst);\n        generate_serde(dst, dst);\n    }\n}\n\npub fn generate_diesel(src: Path, dst: Path) {\n    let mut registry = diesel_codegen::syntex::Registry::new();\n    diesel_codegen::register(&mut registry);\n    registry.expand(\"\", &src, &dst).unwrap();\n}\n\npub fn generate_serde(src: Path, dst: Path) {\n    let mut registry = serde_codegen::syntex::Registry::new();\n    serde_codegen::register(&mut registry);\n    registry.expand(\"\", &src, &dst).unwrap();\n}\n\n}\n[cfg(feature = \"nightly\")]\nmod inner {\n    pub fn main() {}\n}\nfn main() {\n    inner::main();\n}\n```\n. @sgrif @erickt so is re-exporting syntex crates not a viable option?\n. ",
    "erickt": "@sgrif: any chance aster could help mitigate breaking changes?\n. @sgrif: Ugh I'm sorry to hear that. Is this because you're trying to support nightly plugins at the same time as stable rust with syntex?\n. cc @dtolnay\n@sgrif: where is this crate defined? In diesel_codegen I just see 0.6.1, which is pinned to a specific syntex version, 0.31.0.\n. ",
    "anp": "Are the current docs building with all features enabled? As an example, I see uuid as an optional crate in Cargo.toml, but searching the current docs doesn't return any results about UUID columns.\n. @hiimtaylorjones It came up for me when I was inserting responses from GitHub's API into the database. Still not sure why the heck GitHub was returning null bytes, but it is valid UTF-8, even though (apparently) Postgres doesn't accept null bytes.\nI've been thinking about writing something similar, but my plate's a little full at the moment.\n. Also, this seems related but I'm not sure. When I change the line with #[insertable_into(testing)] in the above main.rs to this:\n``` rust\nuse diesel::{ExpressionMethods, FilterDsl, LoadDsl, Queryable, SaveChangesDsl, Table};\n[changeset_for(testing)]\n```\nI get a different super fun error:\n``\n$ multirust run nightly cargo build\n   Compiling diesel_repro v0.1.0 (file:///home/adam/rust-projects/diesel_repro)\nsrc/main.rs:11:26: 11:26 error: the trait boundstd::vec::Vec: diesel::Expressionis not satisfied [E0277]\nsrc/main.rs:11 #[changeset_for(testing)]\n                                        ^\nsrc/main.rs:11:1: 11:26 note: in this expansion of #[changeset_for] (defined in src/main.rs)\nsrc/main.rs:11:26: 11:26 help: runrustc --explain E0277to see a detailed explanation\nsrc/main.rs:1:1: 11:26 error: mismatched types:\n expecteddiesel::expression::predicates::Eq>, &std::vec::Vec>>,\n    founddiesel::expression::predicates::Eq>(expected structdiesel::expression::bound::Bound,\n    found &-ptr) [E0308]\nsrc/main.rs: 1 #![feature(custom_attribute, custom_derive, plugin)]\nsrc/main.rs: 2 #![plugin(diesel_codegen)]\nsrc/main.rs: 3 \nsrc/main.rs: 4 #[macro_use]\nsrc/main.rs: 5 extern crate diesel;\nsrc/main.rs: 6 \n               ...\nsrc/main.rs:11:1: 11:26 note: in this expansion of #[changeset_for] (defined in src/main.rs)\nsrc/main.rs:1:1: 11:26 help: runrustc --explain E0308to see a detailed explanation\nsrc/main.rs:11:26: 11:26 error: no method namedget_resultfound for typediesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)>in the current scope\nsrc/main.rs:11 #[changeset_for(testing)]\n                                        ^\nsrc/main.rs:11:1: 11:26 note: in this expansion of #[changeset_for] (defined in src/main.rs)\nsrc/main.rs:11:26: 11:26 note: the methodget_resultexists but the following trait bounds were not satisfied:diesel::query_builder::update_statement::UpdateQuery<(testing::columns::id, testing::columns::arr), diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)>> : diesel::query_builder::QueryFragment<>,&diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::AsQuery, : diesel::query_builder::QueryFragment<>,&diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::Query,&diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::Query,diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::Query,diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::Query,&mut diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::AsQuery, : diesel::query_builder::QueryFragment<_>,&mut diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::Query,&mut diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::Query,&mut diesel::query_builder::update_statement::UpdateStatement>>, (diesel::expression::predicates::Eq>, &std::vec::Vec>>,)> : diesel::query_builder::Queryerror: aborting due to 3 previous errors\nerror: Could not compilediesel_repro`.\nTo learn more, run the command again with --verbose.\n```\nIt looks to me like both errors are choking on a &std::vec::Vec<std::string::String> where I would expect to see std::vec::Vec<std::string::String> (although I'm not really familiar with the codegen systems here).\n. Thanks for the clarification on references.\nOK, tried a few things with the column still allowing nulls and without, and everything appears to be working for my use case. But I have a question about handling nulls in PG arrays.\nWith insertable_into and a nullable column, if I use Option<Vec<String>>, everything compiles. However, if the column allows NULLs, I would think that properly modelling a nullable text[] would actually be Option<Vec<Option<String>>>, or maybe Vec<Option<String>>, since it seems like postgres will let you put a NULL in the middle of the array. I'm looking at this portion of the docs for the PG array type:\nhttp://www.postgresql.org/docs/current/static/arrays.html\n\nFor example, if array myarray currently has 4 elements, it will have six elements after an update that assigns to myarray[6]; myarray[5] will contain null.\n\nHow would diesel handle null-in-the-middle arrays when deserializing to Option<Vec<String>>? Also, the postgres docs don't seem clear on whether the quoted operation is permitted on a NOT NULL column (is NOT NULL for an array column referring to the array itself, its contents, or both?).\n. What about supporting timestamp with time zone columns for PG? There would be a clear (in my mind) mapping:\n- NaiveDateTime -> timestamp / timestamp without time zone\n- DateTime<Tz> -> timestamptz / timestamp with time zone\nEDIT: related to #106 \n. Re: ORDER BY vs. sorting in Rust, I agree it's nice to not be backend dependent. Also fewer places to make errors as a new contributor :).\nMy assumption re: runtime perf is that this code is called on very small (surely <1000) vectors, rather infrequently. I guess the inference results aren't cached, so if one were using infer_schema! in their code--as opposed to print-schema--this might have an observable performance impact for very large databases. Seems unlikely?. Related question: I modified the existing test for printing foreign keys to pass with this ordering, but I also see that there is a specific ordering test for table descriptions. Given that this is a small change, and not that complex, I'm assuming you're OK with not adding a new test?. Looks like the Windows CI failure is due to rustc type inference:\n``\nThe columntagsis of typevarchar[]. This will cause problems when using Diesel. You should consider changing the column type totext[].\nerror[E0282]: type annotations needed\n  --> tests\\select.rs:99:22\n   |\n99 |     let actual_data: Vec<_> = source.load(&connection).unwrap();\n   |         -----------  ^^^^^^ cannot infer type for_|         |\n   |         consider givingactual_data` a type\n```\nDoesn't seem related to any of my changes here, but I could be wrong. A minimal version of the code which is failing seems to work for me: http://play.integer32.com/?gist=363dae41488a865fbcc18bbd3f971c8d&version=stable\nEDIT: happening on travis/linux too. Postgres only so far.. @killercup rebased, looks like tests are passing.. Good point! Just pushed a cleanup for that. No need for an assignment, that can be the terminating expression for the function.\n(related: i simply cannot wait for pattern ergonomics improvements!). ",
    "cmsd2": "yep that works perfectly. thanks!\n. ",
    "sinistersnare": "It looks like this can be closed.\n. ",
    "freiguy1": "Ugh figured it out. INTEGER in sql code...\n. thank you!. ",
    "TheOpenDevProject": "@sgrif Sorry about the delayed response. Not a problem, Do you hang out in any IRC channels on mozilla or freenode?\n. ",
    "AngelMunoz": "hey sorry old issue, but what if I run a postgres image on docker? naturally pg won't be on my path; what's the course of action then? just plain install?. ",
    "gregcline": "Maybe it could go in the LoadDSL trait documentation here: http://docs.diesel.rs/diesel/prelude/trait.LoadDsl.html\nI know I ended up there looking for my different options for executing queries, and it seems that this trick depends on decoupling the actual execution call from building the query. \n. ",
    "Cottonwoods": "Sounds good, thanks\n. ",
    "llogiq": "I see. No hurry, I'll need some time to finish the rest anyway. Thank you for the quick response! :+1:\n. @sgrif Thanks for the ping and the fast implementation. I'm very impressed with what I see so far. In fact I'm so impressed, I may blog about it.\n. Cool! :+1:\n. I'm already proud :smile:. Feel free to open clippy issues with suggestions. I personally don't know enough about the inner workings of Diesel, so I don't know how to typecheck the schema, but I think at least linting fields of a fixed type within a struct is definitively easy.. Ok I get this right: We want to lint structs that have a #[derive(Insertable)] annotation and contain refs?\nThe problem here is that the error message is likely emitted (and compilation stopped) before lints run, so there's not much we can do.. ",
    "tessgriffin": "Documentation seems very reasonable. Looks good to me!\n. When you run the diesel migration, does it create just one file or two? Lines 62 and 63 imply 2 to me. If that's the case, you should say on line 68 \"We'll edit our migrations\". \n. I think it would make sense then to visually separate the two. Even just a white line. Something to indicate that there are two files (even though yes, it's one migration)\n. So at this point, we've saved a \"draft\"? So is it not actually written to the database yet? The next section we create the update functionality. So does it only get saved to Postgresql at that point?\n. Yeah, I think so. I can't tell if the published part is cheeky because you're working with posts, or if that's an actual thing? I'm just confused as to where this is actually being saved to the database\n. You should expand on it more. Is a \"draft\" something on the diesel side? At what exact point does the record get inserted into the database?\n. I think the terms are just confusing. You say show posts won't render because it's not 'published'. To me that implies that it's not saved in the database? I guess I don't relate 'publishing' to calling update. I might be clearer to have say a 'rough draft' when it's first saved into the database. And you're updating the post to be a 'final draft'\n. That could be partially my fault to. I didn't even realize there was a published column on the database. I think this example would probably be fine as long as you say \"hey, we set this to be false by default, now let's update it to be true\". That would make sense if it's more explicit.\n. Yeah, that'd be a great thing to point out. And then to point out in your update that that's the column that you're changing.\n. I think even here on this line. You could say \"Unfortunately, running show_posts still won't display our new post because we published to default to false in the database earlier. We'll have to 'update' our post to publish it!\" or something like that.\n. ",
    "CryZe": "I'm not sure if this is the same issue, but diesel_codegen fails to compile on the latest nightly builds (for roughly a week now):\n/tmp/cargo_393z/.cargo/registry/src/github.com-88ac128001ac3a9a/diesel_codegen-0.6.1/src/insertable.rs:86:46: 86:54 error: no associated item named `empty` found for type `syntax::ptr::P<_>` in the current scope\n/tmp/cargo_393z/.cargo/registry/src/github.com-88ac128001ac3a9a/diesel_codegen-0.6.1/src/insertable.rs:86         cx.typaram(span, str_to_ident(\"DB\"), P::empty(), None),\nLooks like this commit killed it: https://github.com/rust-lang/rust/commit/9108fb7bae11f18715d971eeae1e5ca84662e1ee#diff-97bf1faa36ad558417a71680410472c8L141\nNvm, looks like you fixed this already.\n. ",
    "inxi-pc": "@mfpiccolo  hi, thanks..but could i use other way like my mentioned, because my .env file is using in project, and format is not compatible dotenv..\n. @mfpiccolo  you means my mentioned way is in run time, so we cant use this. Because the macro! only can accept the string literal?\nrust\ninfer_schema!(env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\"));\nThe way in complier time is a little not friendly..\ni have a matter, dotenv! also get content from file, if we can set a string literal param for dotenv!?\n. Got it, @sgrif thanks\n. ",
    "deadalusai": "One note - it looks like it is also possible to compile diesel_cli without Postgres support. Is it reasonable to add an error message for that edge case as well?\n. The issue I see is that fn backend may return \"postgres\", and the code which switches on that value will again hit the unreachable! branch.\nEdit: This is if you compile w/out Postgres support and then invoke diesel with a \"postgres://\" database url.\n. ",
    "brookst": "Which READMEs need updating? diesel_codegen/README.md seems to be the only one that lists a nightly. Should that be the same as the one run in Travis? (It says 2016-03-11 while Travis is currently pinned to 2016-04-07)\nThe change was introduced for rust-1.7.0 so I guess it breaks for versions earlier than that. Is that worth mentioning?\n. Ok, I've bumped Travis and the README. Tests reran fine.\n. Yes this was the reason for #312, I should have stated that was the error. Either work off of diesel master or use a nighty prior to 2016-04-25.\n. ",
    "derekdreery": "Thanksyou :+1: \n. Related issue - it may be useful to group migrations into year-month to stop the folder getting too full.\n. Hi - I might be being silly, but isn't the whole mod doc_hidden already.\n. A first step in pseudecode would be (in infer_schema)\nfor column in columns:\n    while column.type is domain\n        column.type = column.type.base_type\n    ... carry on as usual\nThis would mean they were useable in diesel, just that no extra type information is inferred.. I've thought about this some more and I'm not sure if what I suggested is better than implementing a custom data type (I think I saw ToSql and FromSql in the source). I'm not sure what the best solution.. I'm trying to create my own [ErrorKind] setting the ConnectionError as the cause.\n[ErrorKind]: https://boats.gitlab.io/failure/error-errorkind.html. Nice one!!. It would be good if diesel re-exported BigDecimal when the numeric feature is enabled, then there's no chance of a clash.. The standard solution of how to use 2018 macros and be backwards compatible is in the edition guide: macro changes. Someone could implement this for diesel now. The bit I wouldn't know how to do is how to generate the table! macro in schema.rs differently in the different editions. Maybe there could be an option on diesel_cli for the edition, and it tries to detect it from Cargo.toml otherwise.. I don't think the docs add that much, so I'll probably just close if that's ok.. Urgh, I was sure I'd looked. Apologies.. ",
    "sphinxc0re": "Oh, okay thank you. When will this be updated on crates.io?\n. Still won't compile\nEDIT: I will wait then\n. ",
    "fuyingfuying": "@mcasper pg_config is installed to /usr/bin/pg_config in my machine. And it is on my $PATH. But the error still exists.\nbash\nfuying@fuying-linux:~$ echo $PATH\n/home/fuying/.multirust/toolchains/nightly/cargo/bin:/home/fuying/.multirust/toolchains/nightly/bin:/home/fuying/.cargo/bin:/usr/lib/postgresql/9.4/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\n. @sgrif Yes, I have installed libpq. I used the method of @mann-ed . And it works. Thanks for your help\n. @mann-ed Use your method, and it works, Thanks for your help\n. @sgrif \nOn my computer, 'pg_config' is not installed:\n``` bash\nfuying@fuying-linux:~$ pg_config --libdir\nYou need to install postgresql-server-dev-X.Y for building a server-side extension or libpq-dev for building a client-side application.\n```\n. @sgrif \nok\n. I use ubuntu 15.10, and the version of rust is: \n``` bash\nfuying@fuying-linux:~/rustprojs/simtraining$ rustc --version\nrustc 1.10.0-nightly (d91f8ab0f 2016-05-07)\nfuying@fuying-linux:~/rustprojs/simtraining$ cargo --version\ncargo 0.11.0-nightly (b304305 2016-05-06)\n```\ncargo.toml:\n``` toml\n[package]\nname = \"simtraining\"\nversion = \"0.1.0\"\nauthors = [\"fuying\"]\n[dependencies]\ntime = \"^0.1\"\nrand = \"^0.3\"\nlibc = \"^0.2\"\nmio = \"^0.5\"\nserde = \"^0.7.0\"\nserde_json = \"^0.7.0\"\nserde_macros = \"^0.7.0\"\niron = \"^0.3.0\"\nrouter = \"^0.1.1\"\ndiesel = { git = \"https://github.com/diesel-rs/diesel.git\" }\ndiesel_codegen = { git = \"https://github.com/diesel-rs/diesel.git\", default-features = false, features = [\"nightly\", \"postgres\"] }\ndotenv = \"^0.8.0\"\ndotenv_macros = \"^0.8.0\"\n[dev-dependencies]\nrand = \"^0.3\"\n[target.x86_64-pc-windows-msvc.dependencies]\nwinapi = \"^0.2\"\nws2_32-sys = \"^0.2\"\n[target.x86_64-pc-windows-gnu.dependencies]\nwinapi = \"^0.2\"\nws2_32-sys = \"^0.2\"\n[target.i686-pc-windows-msvc.dependencies]\nwinapi = \"^0.2\"\nws2_32-sys = \"^0.2\"\n[[example]]\nname = \"test-router\"\npath = \"examples/testrouter.rs\"\n[[example]]\nname = \"test-create-user\"\npath = \"examples/testcreateuser.rs\"\n```\n. @sgrif \nthank you very much\n. @sgrif \nsorry to bother you. Another question is how can i deserialize an embedded struct obiect? It likes this: \n[derive(Queryable)]\n[insert_into(users)]\nstruct User {\n       //...\n}\n[derive(Queryable)]\n[insert_into(posts)]\nstruct Post {\n       //...\n       user : User\n}\nDoes it correct? Because I am outside and can't test it. So if you are not busy, please help me.\nBy the way, does diesel support json or jsonb type? And if diesel can support it, where can I find its docs and how to use it? Thank you very much.\n. @sgrif\nthank you very much.\n. @sgrif\nthank you very much.\n. @sgrif Please help me! I've tried some methods, but no way to solve the error. Is it a bug of diesel or a bug of the nightly rust compiler???\n. @sgrif Ok, it works, thanks for your help.\n. @sgrif \nWhere is the file \"Travis.yml\" placed?? How can I find it.\n. @sgrif  Thanks for your help! It works. ^_^\n. @sgrif Where can i find the gitter room. Please give me an URL. Thanks!\n. @sgrif thanks, I've been in there.\n. ",
    "mann-ed": "I had the same issue. I found that my postgresql lib was under /usr/pgsql-9.3/lib/. So i symlink the libpq.so.5 to /usr/lib/libpq.so\nsudo ln -s /usr/pgsql-9.3/lib/libpq.so.5 /usr/lib/libpq.so\nThen it compiled just fine. I'm on Fedora and have postgresql93-libs installed.\nHope that helps.\n. ",
    "xahon": "I just stucked into the same error. I had already installed libpq5 and libmysqlclient20 on my pc. Solution was sudo apt install libpq-dev libmysqlclient-dev and everything compiled successfully with cargo install diesel_cli without extra parameters. ",
    "alejandrotamayo": "@mann-ed method worked for me in linux mint.\nthank you very much!!!. ",
    "nmrshll": "Just went through this problem too, it would be useful to document which packages need to be installed in order for the installation to succeed, per OS/distro.\nApart from that great lib ! it hits the sweet spot between sql by hand and full blown ORM magic.. ",
    "arielb1": "This should be better in rustc 1.10.\n. ",
    "vityafx": "@Eijebong No, it's okay. I have just realized that the problem is in another table where I had simple\nuser_id uuid references users(id)\n\nSo it was nullable.. I have implemented storing of chrono::Duration in the BigInt field of SQLite 3. I decided to use BigInt since it converts to i64 type which is the minimal unit the chrono::Duration. I am gonna implement it for the pgsql too tomorrow.. @sgrif  Actually, I use 0.14 and 0.14.1 now and I have these errors:\n``\nerror[E0277]: the trait boundchrono::NaiveDateTime: phone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::Serializeis not satisfied\n --> src/models.rs:9:88\n  |\n9 | #[derive(Debug, Clone, Queryable, Identifiable, Insertable, Associations, AsChangeset, Serialize, Deserialize)]\n  |                                                                                        ^^^^^^^^^ the traitphone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::Serializeis not implemented forchrono::NaiveDateTime|\n  = note: required byphone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::ser::SerializeStruct::serialize_field`\nerror[E0277]: the trait bound chrono::NaiveDateTime: phone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::Deserialize is not satisfied\n --> src/models.rs:9:99\n  |\n9 | #[derive(Debug, Clone, Queryable, Identifiable, Insertable, Associations, AsChangeset, Serialize, Deserialize)]\n  |                                                                                                   ^^^^^^^^^^^ the trait phone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::Deserialize is not implemented for chrono::NaiveDateTime\n  |\n  = note: required by phone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::de::SeqVisitor::visit\nerror[E0277]: the trait bound chrono::NaiveDateTime: phone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::Deserialize is not satisfied\n --> src/models.rs:9:99\n  |\n9 | #[derive(Debug, Clone, Queryable, Identifiable, Insertable, Associations, AsChangeset, Serialize, Deserialize)]\n  |                                                                                                   ^^^^^^^^^^^ the trait phone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::Deserialize is not implemented for chrono::NaiveDateTime\n  |\n  = note: required by phone::_IMPL_DESERIALIZE_FOR_PhoneInfo::_serde::de::MapVisitor::visit_value\nerror: aborting due to 3 previous errors\nerror: Could not compile omp-mdm-server.\nTo learn more, run the command again with --verbose.\n```\n```rust\n[derive(Debug, Clone, Queryable, Identifiable, Insertable, Associations, AsChangeset, Serialize, Deserialize)]\n[table_name = \"phones\"]\n[primary_key(imei)]\n[belongs_to(User)]\npub struct Phone {\n    pub imei: i64,\n    pub model: String,\n    pub vendor: String,\n    pub manufacturer: String,\n    pub last_sync: NaiveDateTime, // In UTC\n    pub user_id: i32,\n}\n```\n```toml\n[dependencies]\nrocket = \"0.2.8\"\nrocket_codegen = \"0.2.8\"\nrocket_contrib = \"0.2.8\"\nserde = \"0.9\"\nserde_derive = \"0.9\"\nserde_json = \"0.9\"\nr2d2 = \"0.7.2\"\nr2d2-diesel = \"0.14\"\nchrono = { version = \"0.4\", features = [\"serde\"] }\n[dependencies.diesel]\nversion = \"0.14\"\ndefault-features = false\nfeatures = [\"sqlite\", \"chrono\"]\n[dependencies.diesel_codegen]\nversion = \"0.14\"\ndefault-features = false\nfeatures = [\"sqlite\"]\n``. @killercup oh well, yes, totally forgot about that but I did knew that! :-D Just rocket uses old serde, this is the problem, I guess, but I can't change it :( Thanks.. @killercup a very good notice, I have just found this information too (about it's master branch), but thanks for such a nice help here anyway! . @sgrif could you be so kind giving an example please? (I am interested in sqlite and postgre-sql).. Can we have a list of all available types for use with diesel? And also with all backends (pg, sqlite, mysql, and so on)? This would be very useful.. Tried to change toNaiveDateTime`:\nrust\nerror[E0277]: the trait bound `chrono::NaiveDateTime: diesel::Expression` is not satisfied\n --> models.rs:6:35\n  |\n6 | #[derive(Debug, Clone, Queryable, Insertable)]\n  |                                   ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `chrono::NaiveDateTime`\n  |\n  = note: required because of the requirements on the impl of `diesel::Expression` for `&chrono::NaiveDateTime`\n  = note: required because of the requirements on the impl of `diesel::expression::AsExpression<diesel::sql_types::Text>` for `&chrono::NaiveDateTime`\n  = note: this error originates in a macro outside of the current crate (in Nightly builds, run with -Z external-macro-backtrace for more info). @Eijebong \nI don't miss it:\n```toml\nr2d2-diesel = \"1\"\nr2d2 = \"0.8\"\n[dependencies.diesel]\nversion = \"1\"\nfeatures = [\"sqlite\", \"chrono\"]\n[dependencies.chrono]\nversion = \"0.4\"\nfeatures = [\"serde\"]\n```. The diesel migration sql script:\nsql\n-- Your SQL goes here\nCREATE TABLE punishments (\n    user_id INTEGER NOT NULL,\n    server_id INTEGER NOT NULL,\n    start_time TEXT NOT NULL,\n    duration TEXT NOT NULL,\n    reason TEXT NOT NULL,\n    PRIMARY KEY (user_id, server_id)\n). @Eijebong I thought that was the problem! :) But I looked over the documentation of diesel and the code for the diesel::sqlite::types::chrono module. I saw that there is a implementation of FromSql<Text> or something like that. Looking over tests there convinced me this should work. I also looked at the sqlite 3 data types page and did not find anything like TIMESTAMP or DATETIME types there, I suppose, the date time types should be stored as TEXT, INTEGER or REAL in the sqlite. As for infer_schema!, I don't use it, I use DATABASE_URL=database.db diesel print-schema > schema.rs instead.. Checked again - there is nothing like FromSql<Text, Sqlite>, I was wrong. But there are two more questions I need answers for: what sql types should I use for datetime for the sqlite 3? And we should really list all the type mappings for all the database the diesel support.. Thank you. I somehow thought that the DATETIME is not proper type for the sqlite 3 database. Actually it is, so everything is fine. As for infer_schema, I don't use it but use print-schema instead as it was suggested in the diesel.rs website.. @weiznich Can't I simply implement FromSql and Tosql for the chrono::Duration as it is done for the NaiveDateTime, NaiveDate and NaiveTime structures?. Oh, well, I was not clear enough :) I wanted this to be done in the diesel itself if it is not. I think it is not, especially for v.1.1.1, so I did my own implementation.. @weiznich Could you help me with implementing this in my fork? It seems to me it does not work even so:\nmodels.rs:6:35\n  |\n6 | #[derive(Debug, Clone, Queryable, Insertable)]\n  |                                   ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `chrono::Duration`\n  |\n  = note: required because of the requirements on the impl of `diesel::Expression` for `&chrono::Duration`\n  = note: required because of the requirements on the impl of `diesel::expression::AsExpression<diesel::sql_types::BigInt>` for `&chrono::Duration`\nHow can I implement it? I thought this way enough:\n```rust\nimpl FromSql for chrono::Duration {\n    fn from_sql(value: Option<&::RawValue>) -> deserialize::Result {\n        let i64_value = >::from_sql(value)?;\n        Ok(chrono::Duration::nanoseconds(i64_value))\n    }\n}\nimpl ToSql for chrono::Duration {\n    fn to_sql(&self, out: &mut Output) -> serialize::Result {\n        if let Some(num_nanoseconds) = self.num_nanoseconds() {\n            ToSql::::to_sql(&num_nanoseconds, out)\n        } else {\n            Err(format!(\"{:?} as nanoseconds is too larg to fit in an i64\", self).into())\n        }\n    }\n}\n``. @weiznich looks like it worked, thanks.. @sgrif could you explain please? Why not?. @sgrif This is sad. I have implementedchrono::Durationfor bothpostgresqlandsqlitebackends, all tests are passed and everything works good. thechrono::Durationtype is nothing more but justi64value with nanoseconds, so it absolutely fits into theBigIntegertypes of SQL which is exactly 8 bytes for bothpostgresqlandsqlite.. @sgrif So, what is wrong withDuration` exactly, since it is just a number which can be stored perfectly fine? You still think it is so bad to have an implementation for it?. @sgrif what do you think about that? https://github.com/vityafx/diesel-chrono-duration\nCould you review it please? :-[. @weiznich I have added the information you asked for.\n@Eijebong The result is still the same. I had tried that before, actually. It was what I started with.. @Eijebong well, was written it somewhere and I missed that? :)\nOkay, what about using it in my project then? How can I add my local fork as a dependency correctly?\n``\n$ ./bin/test\n   Compiling clippy v0.0.185\n   Compiling getopts v0.2.17\n   Compiling either v1.4.0\n   Compiling if_chain v0.1.2\n   Compiling semver-parser v0.7.0\n   Compiling bitflags v0.9.1\n   Compiling antidote v1.0.0\n   Compiling quine-mc_cluskey v0.2.4\n   Compiling pulldown-cmark v0.0.15\n   Compiling toml v0.4.5\n   Compiling itertools v0.6.5\n   Compiling syn v0.11.11\n   Compiling scheduled-thread-pool v0.2.0\n   Compiling semver v0.6.0\n   Compiling quickcheck v0.4.1\n   Compiling r2d2 v0.8.2\n   Compiling serde_derive_internals v0.19.0\n   Compiling derive-error-chain v0.10.1\n   Compiling serde_derive v1.0.27\n   Compiling dotenv v0.10.1\n   Compiling cargo_metadata v0.2.3\n   Compiling clippy_lints v0.0.185\nerror[E0599]: no method namedlayout_offound for type(rustc::ty::TyCtxt<'a, 'tcx, 'tcx>, rustc::ty::ParamEnv<'tcx>)` in the current scope\n    --> /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/clippy_lints-0.0.185/src/utils/mod.rs:1041:28\n     |\n1041 |     (cx.tcx, cx.param_env).layout_of(ty)\n     |                            ^^^^^^^^^\nerror[E0599]: no method named layout_of found for type (rustc::ty::TyCtxt<'a, 'tcx, 'tcx>, rustc::ty::ParamEnv<'tcx>) in the current scope\n    --> /home/user/.cargo/registry/src/github.com-1ecc6299db9ec823/clippy_lints-0.0.185/src/utils/mod.rs:1063:28\n     |\n1063 |     (cx.tcx, cx.param_env).layout_of(ty).ok().map(|layout| layout.align)\n     |                            ^^^^^^^^^\nerror: aborting due to 2 previous errors\n``. @Eijebong could you provide an example of how I add thedieselinto the[replace]` section please? I tried that today but with no success:\n```toml\n[dependencies.diesel]\nversion = \"1\"\nfeatures = [\"sqlite\", \"chrono\"]\n[replace]\n\"diesel:1.1.1\" = { path = \"../../diesel/\" }\n```\nAccording to what I see during the compilation, my replace section is ignored.. I have a project without workspaces which uses diesel. Can I use local diesel there?. The patch section does not work for me at all, looks like it is not even parsed.\nAdding the empty workspace section helped but:\n``\nerror: cannot find macroimpl_Insertable!` in this scope\n --> :1:1\n  |\n1 | impl_Insertable ! { ( struct_name = Punishment , table_name = punishments , struct_ty = Punishment , lifetimes = ( ) , ) , fields = [ { field_name:  user_id ,  column_name:  user_id ,  field_ty:  i64 ,  field_kind:  regular ,  inner_field_ty:  i64 ,  } { field_name:  server_id ,  column_name:  server_id ,  field_ty:  i64 ,  field_kind:  regular ,  inner_field_ty:  i64 ,  } { field_name:  start_time ,  column_name:  start_time ,  field_ty:  NaiveDateTime ,  field_kind:  regular ,  inner_field_ty:  NaiveDateTime ,  } { field_name:  duration ,  column_name:  duration ,  field_ty:  chrono :: Duration ,  field_kind:  regular ,  inner_field_ty:  chrono :: Duration ,  } { field_name:  reason ,  column_name:  reason ,  field_ty:  String ,  field_kind:  regular ,  inner_field_ty:  String ,  } ] , }\n  | ^^^^^^^^^^^^^^^\nerror: aborting due to previous error\nTo learn more, run the command again with --verbose.\n```\nThis was for:\n```toml\n[dependencies.diesel]\nversion = \"1\"\nfeatures = [\"sqlite\", \"chrono\"]\n[replace]\n\"diesel:1.1.1\" = { path = \"../../diesel/diesel\" }\n[workspace]\n```\nIf I try to set the root path where is the diesel workspace (or repository root):\n```toml\n[dependencies.diesel]\nversion = \"1\"\nfeatures = [\"sqlite\", \"chrono\"]\n[replace]\n\"diesel:1.1.1\" = { path = \"../../diesel\" }\n[workspace]\n```\nI get this:\n``\ncargo build \nerror: failed to load source for a dependency ondiesel`\nCaused by:\n  Unable to update file:///home/user/diesel\nCaused by:\n  found a virtual manifest at /home/user/diesel/Cargo.toml instead of a package manifest\nCargo-Process exited abnormally with code 101 at Tue Feb  6 17:33:28\n``. Fixed that by adding adiesel_derives` as a replacement, so finally it looks like:\n```toml\n[dependencies.diesel]\nversion = \"1\"\nfeatures = [\"sqlite\", \"chrono\"]\n[replace]\n\"diesel:1.1.1\" = { path = \"../../diesel/diesel\" }\n\"diesel_derives:1.1.0\" = { path = \"../../diesel/diesel_derives\" }\n[workspace]\n```. So I end up with this:\n```rust\n[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, FromSqlRow, AsExpression)]\n[sql_type = \"Integer\"]\npub enum PunishmentType {\n    /// The user is locked from adding to game queues.\n    Locked,\n    /// The user can't speak but can read the chat.\n    Muted,\n    /// The user is banned from the server.\n    Banned,\n}\nimpl From for PunishmentType {\n    fn from(value: i32) -> PunishmentType {\n        match value {\n            0 => PunishmentType::Locked,\n            1 => PunishmentType::Muted,\n            _ => PunishmentType::Banned,\n        }\n    }\n}\nimpl FromSql for PunishmentType\nwhere\n    i32: FromSql,\n    DB: Backend,\n{\n    fn from_sql(value: Option<&::RawValue>) -> deserialize::Result {\n        >::from_sql(value).map(PunishmentType::from)\n    }\n}\n```\nBut as you said, when I try to execute a query I get problems:\n``\nerror[E0277]: the trait bounddiesel::insertable::ColumnInsertValue>: diesel::insertable::InsertValuesis not satisfied\n  --> src/db/punishments.rs:56:10\n   |\n56 |         .execute(&*connection)?)\n   |          ^^^^^^^ the traitdiesel::insertable::InsertValuesis not implemented fordiesel::insertable::ColumnInsertValue>|\n   = help: the following implementations were found:\n             <diesel::insertable::ColumnInsertValue<Col, Expr> as diesel::insertable::InsertValues<<Col as diesel::Column>::Table, DB>>\n             <diesel::insertable::ColumnInsertValue<Col, Expr> as diesel::insertable::InsertValues<<Col as diesel::Column>::Table, diesel::sqlite::Sqlite>>\n   = note: required because of the requirements on the impl ofdiesel::insertable::InsertValuesfor(diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>)= note: required because of the requirements on the impl ofdiesel::query_builder::QueryFragmentfordiesel::query_builder::ValuesClause<(diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>), db::schema::punishments::table>= note: required because of the requirements on the impl ofdiesel::query_builder::QueryFragmentfordiesel::query_builder::InsertStatement>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>), db::schema::punishments::table>, diesel::query_builder::insert_statement::Replace>= note: required because of the requirements on the impl ofdiesel::query_dsl::load_dsl::ExecuteDsl<_, diesel::sqlite::Sqlite>fordiesel::query_builder::InsertStatement>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>, diesel::insertable::ColumnInsertValue>), db::schema::punishments::table>, diesel::query_builder::insert_statement::Replace>`\nerror: aborting due to previous error\n```\nHow do I fix this?. When I had it there was another error:\n``\nerror[E0119]: conflicting implementations of traitdiesel::serialize::ToSql, >for typedb::models::PunishmentType:\n  --> src/db/models.rs:16:74\n   |\n16 |   #[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, FromSqlRow, AsExpression)]\n   |                                                                            ^^^^^^^^^^^^ conflicting implementation fordb::models::PunishmentType`\n...\n41 | / impl ToSql for PunishmentType\n42 | | where\n43 | |     i32: ToSql,\n44 | |     DB: Backend,\n...  |\n48 | |     }\n49 | | }\n   | |- first implementation here\n```\nMy table is:\n```rust\n[derive(Debug, Clone, Queryable, Insertable)]\n[table_name = \"punishments\"]\npub struct Punishment {\n    /// The ID of the punishment in the table.\n    pub id: i32,\n    /// The punished user id\n    pub user_id: i64,\n    /// The server id on which the user is punished on\n    pub server_id: i64,\n    /// The punishment start time\n    pub started_at: NaiveDateTime,\n    /// The punishment duration\n    pub duration: chrono::Duration,\n    /// The punishment reason\n    pub reason: String,\n    /// The punishment type\n    pub punishment_type: PunishmentType,\n    /// The processed mark. The punishment is processed when it is expired and all the things were done. This mark\n    /// can also be used for checking whether it is needed to do something if the punishment is expired or not.\n    pub processed: bool,\n}\n```\nand schema:\nrust\ntable! {\n    punishments (id) {\n        id -> Integer,\n        user_id -> BigInt,\n        server_id -> BigInt,\n        started_at -> Timestamp,\n        duration -> BigInt,\n        reason -> Text,\n        punishment_type -> Integer,\n        processed -> Bool,\n    }\n}\nThank you for trying to help me :). @weiznich That did! How did it work? All you changed was a generic type to specific one.... Probably this is it: https://docs.rs/diesel_migrations/1.1.0/diesel_migrations/macro.embed_migrations.html\n. @brandur Yes, I am already trying this right now. But I am gonna perform migrations silently, without needing for explicit command call, so you just run the app in the docker image and the database is set up. Thanks for your response, now I am sure this is it.\nThis issue would not be created if the diesel had all of this great stuff documented. The project is so big and is so complex. A lot of time I just have to go to this repository and try searching in the code.. @brandur How do you compile it in the rust-musl-builder?\n```\n   Compiling diesel_migrations v1.1.0\nerror: /home/rust/src/target/release/deps/libmigrations_macros-8295541ac8c86046.so: undefined symbol: SSL_set_ex_data\n  --> /home/rust/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel_migrations-1.1.0/src/lib.rs:77:1\n   |\n77 | extern crate migrations_macros;\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: Could not compile diesel_migrations.\nwarning: build failed, waiting for other jobs to finish...\nerror: build failed\nThe command '/bin/sh -c cargo build --release' returned a non-zero code: 101\ntime=\"2018-03-09T21:21:28Z\" level=fatal msg=\"exit status 101\"\n```\nOr, hm, you dont..\nInteresting thing:\n```\nnm /usr/lib/x86_64-linux-gnu/libssl.a | grep SSL_set_ex\n00000000000048f0 T SSL_set_ex_data\n```\n@sgrif  Yes, but before that I had to read a part of source code. This crate was not mentioned on the https://diesel.rs or diesel docs.. @brandur I have done that already without success.. @brandur I have doubly checked that the library is there and it contains the needed symbol. I am stuck because everything seems to be okay but it is not. Thanks for the help anyway.. @sgrif I am doing embed_migrations! in my build.rs so there is no problem at all to do that. And in the build.rs we can do everything we want at compilation, even calling diesel migration run actually. Why not to add a function to the embed_migrations! that will create the schema file?. Wow, that's sad news. Thank you for this link :( So the only way now is invoking a command it seems.. Can I still have a file in src directory which includes contents from generated file in the target directory? According the link you posted, this will not violate any rules because the directory will remain unchanged.. ",
    "Arzte": "Same issue when cloning it down and pointing at the path. https://travis-ci.org/Alchemist-rs/Alchemist/jobs/130398227\n. Any update on this?\n. ",
    "tmahmood": "Just a note, I faced similar issue. it's important that after you've made changes to the migration, run \ncargo clean\nFrom my limited understanding, I assume the custom code generator does not update the generated code and uses the old database definition, So we need to clean the generated code\nI am sorry, for least clear explanation as I'm sleepy and just figured out the problem. I hope it helps someone.\n. ",
    "theredfish": "@tmahmood thank you :) your solution solved my issue. ",
    "bpbp-boop": "I just ran into this \n```rust\ntable! {\n    matches (id) {\n        id -> Integer,\n        date -> Nullable,\n        time -> Nullable,\n        home_team_id -> Nullable,\n        away_team_id -> Nullable,\n    }\n}\ntable! {\n    teams (id) {\n        id -> Integer,\n        name -> Text,\n    }\n}\njoinable!(matches -> teams (home_team_id));\njoinable!(matches -> teams (away_team_id));\n```\nHave any workaround surfaced since this was opened? . Thanks!. ",
    "orionz": "Things were configured wrong on my side - fixed.\n. ",
    "raywu": "@sgrif can you show me how to check what data directory postgres is pointing to?\nWould something like this work?\n```\n// check installed version\n$ postgres --version\npostgres (PostgreSQL) 10.4\n// check directory version\n$ psql development_env\nselect version();\n                                               version\n\n\nPostgreSQL 9.5.3 on x86_64-apple-darwin14.5.0, compiled by Apple LLVM version 7.0.2 (clang-700.1.81), 64-bit\n(1 row)\n```\n. ",
    "toudi": "oh, I was just about to ask the same question :D I actually thought that in the SQL file there could be like a comment section or something, like:\ncreate table ... ( whatever your default syntax is )\n--- backend: sqlite ( or postgreSQL )\ncreate table .... ( whatever the backend-specific syntax is )\nso that if there is no backend: whatever section in the file, the migration could be applied from the whole file contents, but if there is, the file could be seeked to the contents of the comment\nwould you accept a PR of such a feature or do you believe that this shouldn't exist / and / or is too dangerous? I am actually very new when it comes to rust, but if I could help, I'd love to\n. ",
    "xiaofann": "forget use deref trait. just add operator * behind & like (&*connection)\n. ",
    "durka": "They didn't seem to match the crates.io version we were looking at on IRC, but I guess we were confused.\n. ",
    "kardeiz": "I think having a renaming convention would be a good idea for the infer_schema macro, but I think it would be nice to be able to explicitly specify the renaming/mapping using the table macro (something like column_name=\"type\".\nAlso, note that the column_name field annotation for models also doesn't allow Rust keywords.\n. @sgrif Right, I'm not sure the best way to handle this\u2014I was mostly going by how rusqlite gets datetimes out of sqlite. I'm not a sqlite expert, but it appears sqlite can store datetimes as epoch-second ints.\nThe only issue with this is that in sqlite, CURRENT_TIMESTAMP always creates a string in the format above. You can work around this like strftime('%s', CURRENT_TIMESTAMP) to get seconds, but if you happen to insert the default CURRENT_TIMESTAMP and then try and extract it as a numeric, you will get just the year component (for example, select cast(CURRENT_TIMESTAMP as numeric) gives 2016). I believe expression::dsl::now would have to be specialized for sqlite with a workaround in order to use integers.\n. I'm not sure if I understand completely, but when I do:\nlet as_i32 = not_none!(value).read_long();\nprintln!(\"{:?}\", &as_i32);\ninside the from_sql function for NaiveDateTime, where the sqlite value is one inserted by CURRENT_TIMESTAMP, it prints 2016. It seems to be doing the same thing as select cast(CURRENT_TIMESTAMP as numeric), which makes it seem like sqlite is actually just storing the formatted datetime string.\n. I prefer the time API and don't need the additional features of chrono. I also depend on other crates that depend on time and I don't really want to carry around more than one time library.\n. @sgrif Is that really necessary? I understand wanting to not give the impression that time is the authoritative datetime type, but I think that's the nature of crate names, and I think calling it deprecated_time is more misleading (and degrading!) than leaving it as is.\n. Even if it is a small set of protected words, there are cases (e.g., working with a legacy database) where you can't avoid them.\nThere are other cases (though along the same legacy line) where you might want a re-mapping even when not strictly required (e.g., non-underscored field name to snakecase). \nAs I noted on #342, I think having a convention for infer_schema would be great; I just think it would be ideal to be able to configure this relatively easily when desired (e.g., some people might prefer to work with a type_ field rather than ty).\nAlso, how would the convention work when going in the ty -> type direction (e.g., when using the table macro)? Would \nrust\ntable! {\n    objects {\n        ty -> Nullable<VarChar>\n    }\n}\nmap to a field named \"type\" or \"ty\"?\n. @killercup I think your suggestion is good (especially the more verbose one), but what I was thinking (after my initial PR but before your comment) was the serde-like [rename=\"type\"], which could either be in a position analogous to standard field annotation:\nrust\ntable! {\n    objects {\n        id -> Uuid,\n        [rename=\"type\"]\n        type_  -> Nullable<VarChar>\n    }\n}\nor like:\nrust\ntable! {\n    objects {\n        id -> Uuid,        \n        type_ [rename=\"type\"] -> Nullable<VarChar>\n    }\n}\nor using column_name/table_name instead of rename.\n. Is it even possible to create a new ident type_ from a given ident type inside macro_rules? \nOr (as noted above) if you are requiring the user to provide the type_ ident to map a SQL column \"type\", how would a user map a column named \"type_\" (however unlikely a column name that may be)?\nIn any case, I think I fundamentally disagree with this, and it seems like renaming Rust keywords would add more complexity than this PR (or something similar). \nAs a potential Diesel user I would prefer to be required to do some configuration rather than work with some relatively arbitrary convention (appending underscore to reserved name).\nHowever, I do agree that the rename-on-use workaround would be acceptable for most cases. \nIn any case, thanks for considering and for the explanations\u2014. Cool, thanks!. @sgrif, I think this just has to do with not consuming/flushing the query result. If I change\nconn.execute(\"SELECT 1\").map(|_| ()).map_err(Error::QueryError)\n\nto\nsql::<::diesel::types::Bool>(\"SELECT 1\")\n    .get_result::<bool>(conn)\n    .map(|_| ())\n    .map_err(|_| Error::QueryError)\nit works fine.\nI don't know if this is the most efficient way to do a health check. MySQL has a ping mechanism, but I don't know all the considerations around it, and it wouldn't work for a generic Connection in r2d2-diesel. \nOr maybe there is just some way to flush/drop the row/value without using it?. I don't think this issue should have been closed. The initial poster specifies:\n\nSame thing should be applied to table names.\n\nBut the fix in #1084 only applies to column names. I also am interested in a fix that applies to table names as well.. I haven't looked too closely but does this cover renaming table names as well? Sorry if I've missed something or if this is handled elsewhere\u2014I haven't followed this too closely since my PR #424 (which did cover renaming tables).\n. Yeah, I realized how hacky this was after I wrote it. I didn't think about moving them out of the backend-specific modules, but I also don't know the appropriate place for them (diesel/types/mod.rs ?).\n. ",
    "carsonmyers": "Is there currently a good way around this? Like a custom de/serializer?. ",
    "dstu": "As an outsider who looked through the code to figure out if there is a way to do this, it appears that supporting a user-defined Postgres type requires knowing the object identifier that is in use for that type. In the case of enums, this requires extracting information from pg_type and pg_enum tables. All told, you're looking at:\n\nGetting your type information out of relevant postgres system catalogs. You'll need to refer to pg_type and pg_enum, along the lines of:\nsql\nselect pt.typname, pt.typtype, pt.typcategory, pe.enumlabel, pt.oid\n  from pg_type pt\n  inner join pg_enum pe on pe.enumtypid = pt.oid\n  where pt.typcategory = 'E';\nCreating peer/placeholder types, analogous to diesel::types::Date, for each type so discovered.\nRegistering these types with diesel. Refer to diesel/src/types/impls/ for examples.\n\nSince runtime database information is needed, some sort of codegen macro along the lines of infer_schema! seems necessary. I'll probably take a crack at this over the next few days, but I can't promise much.. I've put together a rough, partial implementation of Postgres enum support, which creates a macro called infer_enums that acts much like infer_schema, except it creates Rust types for each enum type it discovers in the database. Please be aware that these changes are owned by Google and not actually mine to redistribute until I get a copyright release, so I've (temporarily) deleted my public fork. I hope that I'll get an okay to make my changes public after the Christmas holiday.\nUnfortunately, there are currently a few assumptions about type definitions that make it difficult to use custom enum types in tables:\n\nIt is necessary to create a fresh impl of HasSqlType for each type that infer_enums discovers, but you cannot do that outside of the diesel crate. I think this can be worked around, but at present I don't see how to do this without a significant refactor.\ninfer_schema assumes that column types correspond to types declared in the namespace diesel::types, which is no longer true if arbitrary new enum types can be created in other crates.\n\nI haven't actually done the legwork necessary to know how to deal with encoding or decoding enum values to/from raw bytes for handoff with Postgres. I assume that this will essentially entail handling type-tagged integers.\nFinally, handling schemas correctly is on the back burner until everything else is taken care of. It'll require an additional join.. I've been able to address (1) and (2), but getting everything working in the integration tests has run head-long into #348. If anyone has successfully figured out the minimal footprint of traits needed to make a simple, atomic SQL type, some documentation or example code would be welcome.. My pleasure. I suspect that it will not be too difficult to extend this work to create Rust struct types automatically from user-created composite types in Postgres, and I'm also considering that.\n\nWhat you described sound like for an inferred enum, SQL and Rust type are the same. I haven't thought much about this, maybe it makes sense.\n\nThat is exactly what the current implementation does.  I have wondered a bit as to whether this is really the right thing to do, but I still believe it is. It might be a good idea store some metadata with the generated type (probably in a static impl of some DieselEnum trait), but I see no reason to stick it on a separate \"backend\" type. Future extensions might be backend-specific, such as when creating proper Rust enums for MySQL enum columns or providing an impl of Cmp that matches the ordering that Postgres imposes on enum variants, but I don't see a particular need for a different type.\nThere is probably a long-range design issue lurking behind the scenes here. I've already run into a few instances of code assuming that SQL types live in diesel::types, and the proposed change for #429 also does that. I'm working around this for now with a hard-coded list of built-in SQL types, but that seems a poor solution. If types are going to be generated during compilation like this, a compile-time type registry might be a very good idea. Otherwise, we are going to be left with relying on heuristics to determine how to resolve a given type name. For now, the heuristic is: if the type is builtin, resolve it absolutely in diesel::types, or else resolve it locally because a macro just generated it in the current namespace. This is brittle.\n\n@jethrogb was [on Gitter][1] a few weeks ago and wanted to implement a custom type. Maybe you can get some additional information from the log there.\n\nI think I have the necessary traits implemented, but I'm still running into problems. A second pair of eyes will help once I have permission to share a patch.. I just got the OK to contribute and copyright release from my friendly neighborhood corporate overlords, so I'll reinstate my fork soon.. Feature bumps and deprecations from the 1.15 release and deprecation of custom_derive (https://github.com/rust-lang/rust/issues/29644) seem to have complicated things a little bit. I note that sh bin/test integration no longer runs successfully on the master branch (under rustc 1.16.0-nightly (47c8d9fdc 2017-01-08)). I believe that I was previously able to run that command to success on top of my changes in late December, on some older rust nightly. Please let me know what I should be doing to run tests.\nI've pushed what was (more or less) working back in December to the custom_types_in_database_columns branch of my fork. I'd open a PR, but I don't think things are quite working yet. What's the deal with the test script?. The most significant test failures seem to be #571, which is not directly related to adding support for enums. With a fix patched in locally, the problem I am currently running into is that types which are declared in a dummy namespace by infer_enums! don't seem to be visible when they are used in table declarations generated by infer_schema!. For example, diesel_tests/schema.rs currently reads:\nrust\ninfer_enums!(\"dotenv:DATABASE_URL\");\npub use self::__diesel_infer_enums::UserType;  // Inserted by hand; shows that the type exists.\ninfer_schema!(\"dotenv:DATABASE_URL\");  // Errors here because UserType isn't known.\nI have tried changing the table declarations generated by InferSchema so that they use a relative type name. This is done in diesel_codegen_shared/src/schema_inference/pg.rs, where the path to non-builtin types is constructed. Using a type like super::UserType or super::__diesel_infer_enums::UserType doesn't work. In fact, if a type name like super::UserType is provided, the compiler helpfully says:\nerror[E0412]: unresolved type `super::UserType`\n --> tests/schema.rs:7:1\n  |\n7 | infer_schema!(\"dotenv:DATABASE_URL\");                                                                                                                                                        \n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ no resolution found\n  |\n  = help: possible candidates are found in other modules, you can import them into scope:\n  = help:   `use schema::__diesel_infer_enums::UserType;`\n  = help:   `use type_inference::postgres::__diesel_infer_enums::UserType;`\n  = note: this error originates in a macro outside of the current crate\nI suspect that converting a literal \"self\" or \"super\" with syn::PathSegment::from is not quite the right thing to do, since those are keywords that may require special treatment. But that does not explain why UserType wouldn't be visible when it is being exported explicitly with pub use.\nA couple of different hacks (running infer_enums! in its own module and importing from that, trying to do enum declaration and table schema declaration in the same procedural macro) haven't panned out so far.\nI'll have to try to boil this down to a simple example to verify it, but this is acting an awful lot like the enum types whose declarations I'm generating are not visible in the code that generates the table schema.. You can work around the question of how to look up dynamically generated types by requiring that the user specify the module where any non-builtin types can be found, so that's how things now work. This isn't great (and raises questions about how to deal with types derived from schemas, which one might reasonably want to live in sub-modules), but it looks like it works for now.\nI must have been recollecting wishfully when I said that I thought most tests were passing earlier. I'm now running into some deficiencies in implementing the interfaces needed to make a custom type queryable/insertable/updateable/etc. This is all in diesel_codegen/src/type_inference.rs. An experienced eye there would be very helpful in noticing any obvious omissions or deficiencies.. I will continue further discussion of the implementation I'm working on in #580.. #580 has been closed as discussed there. (It needed to be factored apart and fell too far behind diesel main.)\nI have been swamped with events at work and in my personal life, and this has prevented me from pulling a set of new PRs together. I'd be happy to discuss this further with anyone who is interested in getting a PR together sooner, and I will share whatever I can put together, when I can.. Thanks for this effort. It should make it easier to deal with #343.\nAIUI, registering a new type T entails entails adding a diesel::types::HasSqlType<T> impl to a database type that is also in diesel. Since both the trait and the implementing type are in diesel, foreign crates can't add an impl. I worked around this in #580 by creating a trait that can be implemented for T directly and a blanket impl of HasSqlType. If it seems warranted, can we coordinate on this change? (I can factor it out into a separate PR if that seems warranted. Or maybe further discussion and design are warranted, since it is arguable that it would be simpler to do away with HasSqlType entirely.)\nEdit: Sorry, I should have read the issue more closely. It looks like you are not adding a new database type, but registering a Rust type for use with Diesel. Please disregard the above if it does not actually apply to your situation.. I can't find a reference to /bin/test that uses == for string comparison.m, so I see no reason to use == at all. What platform are you on? Could built-in shell behavior that overrides calling test be at fault? This might be some version of a \"/bin/sh isn't actually sh, it's Bash or some other shell, and using an idiom from that shell breaks for people who actually use sh.\"\nFor reference: \n\nPOSIX: s1 = s2\nGNU test: STRING1 = STRING2\nApple's \"legacy\" doc for an old BSD test: s1 = s2\nFreeBSD: s1 = s2\n\nI note that my review of the subject shows that the way I pass more than 4 arguments to test is itself not strictly correct, so I'll revert that change when I'm able to.. This should be set now. Sorry about the merge commit. I'm not certain of a good way to get rid of it without opening a new PR. If there's something you'd like me to do about it, let me know.. What do you recommend doing to ensure that doctests are working properly? What is the best way to run modified doctests to ensure that they work properly? cargo test, bin/test, or something else?. This can be broken up fairly easily; it is quite feasible to implement support simply for generating enum types to match what's in a database.\nI'll make changes to the PR that address the comments so far when I have more time this week.. I apologize for not having been on top of this. I may be able to put some more time into it this weekend. I still need to rebase on top of the latest Diesel release and restrict this PR's scope to consist only of generating types for Postgres enums.. After looking at how far diesel has progressed since I wrote this PR, I have concluded that it must be rewritten. The basic approach (query Postgres catalog tables to get enum definitions) is still perfectly valid, but diesel's switch to using SQL schema standard means that the way this is done has to change. I am closing this PR and will move discussion back to #343.. It looks like there's already an override in /Cargo.toml:\n[replace]\n\"diesel_codegen:0.9.0\" = { path = \"diesel_codegen\" }. Done.. Yes, I was trying to use syntex to work around some issues but don't need it right now. I'll kill the dependency if it's not needed (which it probably won't be) before any merge.. OK on changing the method name.\nRight now, this PR converts a Postgres type name or variant foo_bar into FooBar on the Rust side. There are bool arguments to the macro expansion methods to control whether this happens, but they aren't currently used because there is no macro-level interface for toggling them.\nI think it makes sense to map to Rust-style naming, but I am willing to be convinced otherwise. If any name manging could happen, clearly documenting default behavior and providing an option to turn it off are also necessary.. In Rust, it's an open issue.\nIn Postgres, it appears perfectly valid to have both types and variants contain umlauts. I'll have to dig deeper into the documentation to see if there are any surprises with regards to other unusual characters.\nIt seems like eventual convergence (arbitrary whitespace-free Unicode allowed) is an eventual goal, but it would probably be better to check explicitly that we're generating a legal type name and die with a reasonable explanation rather than letting rustc barf.. The quote! macro makes use of (potentially deep) recursion, and my large invocations of it are running into the default limit. This number should be tuned to fit whatever this PR's eventual needs are; it may be that we wind up needing something smaller at first.. Agreed. I don't think this will be needed.. Formatting is mostly a combination of what rust-mode does in Emacs and my attempts at respecting cosmetic issues like line length as per a hazy recollection of the recommendations aturon compiled. If you prefer, I'll run rustfmt over things before declaring this ready for a merge.. I really don't like the solution of the user manually specifying extra_types_module.\nFrom a usability standpoint, it would be nicer to be able to infer_everything! and just get tables, types, and (eventually) views from the database.\nFrom a design standpoint, this is just kicking the problem down the field a short distance. As-is, all peers to SQL types live in diesel::types, and library internals freely assume this. Looking up types that are not on a whitelist on a single user-specified alternate path works for now, but a few problems are readily evident:\n\nAll DB-derived types are assumed to live in one namespace. In Postgres, you have the potential for multiple namespaces (which naturally arise from each distinct database connection string, or even from schemas nested inside of a database). This could lead to name clashes if, for example, identically named types are declared in different databases or schemas. (It seems like a good solution is to recommend strongly that different invocations of infer_schema! use different extra_types_module settings, but I'd prefer a cleaner design where remembering to do that sort of thing isn't necessary.)\nThe binding between a DB type and a Rust type is implicit (based on type name alone). This loose coupling could lead to bugs whenever there are name clashes.\nIt is quite conceivable that a user will want to use types that come from disparate Rust namespaces, at which point they will have to do a lot of tedious and potentially confusing re-exporting with pub use (so that everything is in one namespace), or we will have to extend this mechanism to support having multiple extra type paths.\n\nThis could be solved by creating an intermediate representation of types in a database schema and mapping DB types to Rust types through that. This would require threading some sort of global table state through most of the code generation process, so the effects of adopting this design would be felt throughout a lot of Diesel. (Perhaps simply having a global shared structure would be adequate, since it will only be used at compilation time.)\nHaving a central, explicit set of data structures that describe types, tables, views, procedures, etc., could be quite useful. I suspect that some sort of compile-time metadata model would be very helpful for validating what is read from the database (\"table has a primary key structure we don't support\"), generating good error messages (\"typename foobaz is not a valid Rust identifier\"), debugging/testing (write tests against the intermediate representation code), streamlining code generation (all necessary state is in one obvious place), and error reporting (have richer local state from which to produce meaningful error messages).\nThis approach could go very wrong by being too top-heavy and prematurely putting straightjacketing Diesel. The project has gotten really far without building a top-down intermediate model of database components, and maybe it's best to keep it that way for now. It would be unpleasant to have to refactor a big metadata layer every time you want to support a new DB feature.\nIf it seems a good idea, I suggest working towards merging just the enum declaration part of this PR and opening a separate issue to discuss whether a metadata model is necessary or a good idea. That discussion may yield solutions to the problems I've described here which can be used to add DB type support to infer_schema! without having to commit to a great deal more overhead.. ",
    "kybishop": "Hey @sgrif, does your comment and gist here still apply as a valid workaround until this issue is sorted?. ",
    "coder543": "I just encountered this bug. Not having this feature means I'm (at least for now) switching from strongly-typed enums in my database to varchars... which is not great. I would love to have this feature.. I don't necessarily agree with the decision, but I appreciate the way you're approaching the situation. I personally think enums are important enough to be a special case, but as long as it is possible to support them in Diesel, that's good enough for me. As you said, an outside crate could be developed to provide an opinionated solution to this issue that could act as a way to reduce boilerplate for those who are interested.\nLooking at the example code you linked to, it seems pretty reasonable to me. My only real question at this point: is using infer_schema! is possible with a database that has custom types in some/all of the tables? I've been busy with other projects for awhile now, but from what I recall, infer_schema! might have actually generated code which could not compile in such cases, and I don't remember finding a way to inject the custom types into the namespace that infer_schema! created.. So there's no way we can make it type-safe to sum a column that we know is made of 64-bit integers into a 128-bit integer value? At compile time we have all the information needed, don't we?. The Numeric that we get back from the database really must map precisely to an integer if the only values summed were integers. The only values being summed are integers. Assuming that it will fit into 128-bits is the same trade-off as assuming a summation of 32-bit integers will fit into a 64-bit integer, which is already being done.\nI would rather have the option to sum a 64-bit column into a 64-bit integer with possible overflow than to deal with pulling in a BigDecimal crate, but I think summing into a 128-bit integer fits better with the model that's already in use than summing into a 64-bit integer, and will practically ensure no overflow happens. It's much more likely that someone will have at least 2^32 rows of 32-bit integers and overflow a 64-bit integer than it is for them to have at least 2^64 rows of 64-bit integers and overflow a 128-bit integer. But ok, if there's no way that we can make this work... then I guess there's nothing to be done, although I don't fully agree.. ",
    "dsvensson": "@dstu it would be nice if inferring schema is not required, other than perhaps creating a first example of a Rust enum (which might then be renamed, while keeping some annotation or so for the name used in Postgres... mapping)... and then connecting the dots upon actual connect, rather than having any kind of ids hardcoded. Or did I misunderstand you there when you mentioned \"Since runtime database information is needed, some sort of codegen macro along the lines of infer_schema! seems necessary\" ? . ",
    "turboladen": "FWIW, if working with pg enums in diesel meant having to define a rust annotated struct (or... enum?) to represent the pg enum, that'd seem totally reasonable to me.. ",
    "adwhit": "Just thought I'd mention to anyone who comes across this issue that I've made a crate to derive the necessary trait impls, it's up on crates.io. Feedback welcome.. Just a guess - \nAccording to the docs, diesel::types::Time can only be converted to/from chrono::NaiveTime, whereas you are attempting to convert chrono::DateTime.. ",
    "nox": "You published diesel 0.6.2 but it's not in the Git repository. Did it become closed-source?\n. Ok, you just forgot to push the branch then?\nhttps://github.com/diesel-rs/diesel/blob/master/diesel/Cargo.toml#L3\n. That doesn't explain why master isn't 0.6.2. Could you make master the 0.6.2 version as expected?\n. We never use version ranges in Servo, but we have no lints for that no.. How is it more useful than using the print command? The more projects do fancy things at compile-time, the less freedom the Rust team will have to improve compile times, AFAICT.. My point was that we can't experiment with using MIRI for procedural macros if procedural macros do I/O and connect to databases and whatnot.\nI've personally never expected people to do things like that, even though Rust is a Turing-complete language and used to implement them proc macros.. > Given that proc macros are capable of running any arbitrary code, the Rust team will always need to assume that proc macros do anything, including network or Disk IO. Whether our project takes advantage of those capabilities is irrelevant.\nThat's because MIRI wasn't a thing when proc macros landed. If no one uses them in such dubious ways, the Rust team will be able to easily switch their evaluation to MIRI. If popular projects start relying on this behaviour, they won't be able to.\nTo me your justification of your usage of proc macros sound like people wanting Rust to enforce a specific order in HashMap to be able to rely on it.\n\nPerhaps seeing these use cases in the wild will change your expectations. You may also be interested in embed_migrations!, which would also prevent things like using MIRI for proc macros.\n\nNo, I'll keep trying to make those disappear, because that's not where that code should run in the first place. I'll stop pursuing that objective here, though.. > Again, claiming that our project has any impact on that is ridiculous. It is impossible to know if anyone is using Rust in a certain way. You can say for sure that someone is using something, but unless you have access to everybody's closed source repositories, it is impossible to say that someone isn't using something.\nIn general, Rust has never been quite afraid of changing behaviour after the fact if a Crater run ends up green.\n\nFrankly, I'm not sure what gives you the right to say where other people's code should or shouldn't be run\n\nOops, I'm sorry I meant to add \"in my book\" after that and removed it after I rephrased the sentence. :(. This is a breaking change, i.e. it can make downstream fail to compile.. There is no such thing as a \"minor breaking change\". A breaking change should come with a major bump. And even if the new type implemented Deref<[u8]>, this would still be a breaking change anyway.. I read it, and at no point it says \"minor breaking change\". It does define a few ways a breaking change could be accepted as part of a minor bump, though, that I concede. Highly surprised by that though.\nThat particular change though, isn't such a change as per RFC 1105 AFAICT. It is a non-trivial change to associated types in an implementation. At the very least, I don't think that the fact that existing code could have been written in a forwards-compatible way is an argument to quality that change as a \"minor breaking change\".\nAs for looking at the raw bytes, isn't that required if an end user wants to use spatial types?. ",
    "leoschwarz": "I have the same problem right now, apparently the situation has still not improved by much or I'm not able to find the relevant modules.\n(Also I think this and #162 are essentially duplicates.). ",
    "kaj": "So, should I rename the trait, or is it fine as is?\nAnything else? @killercup ? @sgrif ?\n. I tried moving the added code into to pg submodule, as @sgrif suggested 25 days ago.  It turns out a bit harder than I anticipated. As far as I understand, the problem is that the postfix_expression! macro don't allow me to specify a backend implementation, as the infix_predicate! macro does.\nAny help fixing this would be much appreciated.\nPS.  Sorry for being away for so long.\n. After merging master into the branch I read the compiler errors more carefully and managed to fix the problem (which actually was rather simple).  I also changed the name of the trait for consistency with similar traits and changed the doctests to test actual results rather than generated SQL.\nI used src/doctest_setup.rs to get a connection, but a local table specific for the test.  I had to include a table! definition for users even though I don't use it.  I see FIXME comments about the same thing in e.g. src/pg/expression/expression_methods.rs .\n. Done.  The documentation link (as many changelog entries have) will be a 404 in this case, but I hope it will be the correct url if / when this PR is merged / released.\n. Ok. Are you talking about just the \"use\" structure, or moving the actual code into expression_methods.rs?\n. Ok, done.  Anything else, @sgrif ?\n. Updated again after suggestions from @killercup .  Ok?\n. Funny and cool!  :sunglasses: \nYet I think this should probably be closed (without merge) to unclutter the PR list.. The broken azure build seems to be fixed in #1952 .\n. Sure, will do!\n. I don't know.  I thought about it as a trait on ordering, providing methods that work on orderings (it is implemented for Asc and Desc).  But maybe it should be thought of as a trait for where to put the nulls, and in that case NullsOrdering (or something similar) is a better name.\n. Ah, so maybe I should put these methods in that trait instead?  Hm.  On second thought, I guess not, since that trait is implemented for column types, and not for Asc and Desc.  So if I put nulls_last() there it would be possible to order(foo.nulls_last()) but not order(foo.desc().nulls_last()), and that would make no sense at all ...\n. The thing I really want to show is that the order of the elements, in this case vec![Some(3), Some(17), Some(4711), None, None] would have been equally correct, but vec![Some(2), None, Some(1)] would have been obviously wrong.  Right?\nBut actually showing the table definition and contents might be a good thing.  I'll take a look at it.\nThe bracket thing: Yes, will fix, thank you!\n. ",
    "Matrix-Zhang": "any one can help me? right now, i can quey the record with the PgTimestamp type, \n```\n[derive(Queryable, Debug, Clone)]\npub struct DevicePeriod {\n    pub id: i32,\n    pub device_id: i32,\n    pub date_time: PgTimestamp,\n    pub confirmed: bool\n}\n```\nbut how to write the insertable ? \n```\n[insertable_into(device_period)]\npub struct NewDevicePeriod<'a> {\n    pub device_id: i32,\n    pub date_time: NaiveDateTime //here, will build error, change to PgTimestamp is ok, but the chrono timestamp is since 1970\n}\n```\n. i found the pg types sources have to_sql for NaiveDateTime, but i don't know how to use it\n. posts is integer, the sever will recive the user input as filter, su as \"1,2,5-8\"\nso, i need build the filter from the user's input\n. ",
    "travismiller": "Would something like this work?\nThis PoC just exposes a run function where you can send arguments directly to the Clap Application.\nrust\n// diesel database setup\ndiesel_cli::run(vec![\"database\", \"setup\"]);\nThe crux of this uses https://docs.rs/clap/2.32.0/clap/struct.App.html#method.get_matches_from\nIt probably makes more sense to use https://docs.rs/clap/2.32.0/clap/struct.App.html#method.get_matches_from_safe so that an API user could handle a result.. ",
    "davidszotten": "the dates are prepended by the cli when calling e.g. diesel migration generate foo. \nindeed, as you've discovered, internally diesel seems to only use the first part:\ntable __diesel_schema_migrations\n+----------------+----------------------------+\n|        version | run_on                     |\n|----------------+----------------------------|\n| 20160612132127 | 2016-06-15 11:38:36.130818 |\n| 20160614153823 | 2016-06-15 11:38:36.130818 |\n| 20160614173422 | 2016-06-15 11:38:36.130818 |\n| 20160615122959 | 2016-06-15 11:38:36.130818 |\n| 20160615123204 | 2016-06-15 11:38:36.130818 |\n+----------------+----------------------------+\nSELECT 5\nTime: 0.002s\nhence this issue\n. yes, though having the identifiers in the migrations table also separated with an underscore might also be helpful i guess\n. i'm pretty new to rust. is there no way for e.g. cargo install to ship the completion script as well?\n. as a user of diesel (and by definition a rust developer), cargo install seems like a perfectly fine way to install the cli to me. it's unfortunate that we can't ship the generated completion script, and, it seems the only entry point to gen_completions is to give it an output dir. this seems unintuitive to me (e.g. \"please run diesel generate-bash-completion /etc/bash_completion.d to have it write a file in that directory)\nthoughts on such an api? might it be possible for the build.rs in this pr to read the generated bash code and then compile the contents into the app (to support something like diesel generate-bash-completion >  /etc/bash_completion.d/diesel\n. don't love generate-bash-completion as a name so open to suggestions. also, should it be \"hidden\" under some sub-command?\n. looks like rustup failed on one of the travis jobs. think you need more access than i have to re-trigger the build\n. clap can now generate completions to a string; no need for codegen\n. just to follow up on this. if this feature isn't suitable for this project, please let me know and i'll close the pr. if this is interesting, but there are issues with the implementation, i'll happily work with you to fix/improve\n. no worries. command shortened and commits rebased+squashed \n. thanks!\n. yup. thanks\n. ",
    "thejefflarson": "Nevermind, I should read the docs:\nhttps://github.com/diesel-rs/diesel/blob/db9ec59089f3212fd7baaa1e069acb7e8cb6204c/diesel/src/macros/mod.rs#L60\nThanks for the fantastic library!\n. One question, suppose I have a table with hundreds of fields (I know, I know -- I'm a journalist and we get crazy data) is there anything I can do?\n. @killercup Ha ok. 1 is sometimes not possible (I'm side-eying the census here, though I almost always don't need the whole thing).\nI might take you up on 2 -- though even for me I can only think of a handful of datasets that may need more than 52 fields. I think I can do it if I need it, thanks for the pointer! And thanks for taking the time!\n. ",
    "jooert": "Sounds great!\n. ",
    "flosse": "\nAs far as I'm aware there is no data type in SQLite that maps to UUID?\n\nI'm sorry. You're totally right!\n. ... ok, I found the mistake via #477 :). A slightly better error message would be great for the future ;-). I got the same issue!. ",
    "0xcaff": "I've implemented storing UUIDs in SQLite using BINARY(128) and a wrapper type in my package.\nCode:\nhttps://github.com/forte-music/core/blob/fc9cd6217708b0dd6ae684df3a53276804479c59/src/models/id.rs#L67-L121\nSQL:\nhttps://github.com/forte-music/core/blob/feature/sync-engine/migrations/2018-05-14-200933_setup/up.sql#L1-L12\nUsage:\nhttps://github.com/forte-music/core/blob/fc9cd6217708b0dd6ae684df3a53276804479c59/src/models/album.rs#L10-L21\nI can make a pull request with an adaptation of this code if anyone is interested.. I\u2019d like thoughts from a contributor before making a PR. Thoughts @sgrif?. Playing devils advocate here.\nI'd argue that uuid is a fundamental type. Many applications use the uuid create and diesel already has support for using it with some SQL dialects (postgres). It's useful to have a built, tested and discoverable implementation for users of diesel. Writing a new type wrapper is annoying because of the need for boilerplate type conversion code.\nAlso, chrono::NaiveDate violates these rules. It is serialized as TEXT for SQLite. https://github.com/diesel-rs/diesel/blob/85e0007684d7547379d1fa69de5146b04695bc19/diesel/src/sql_types/mod.rs#L267-L282. Hm, on second thought, fts virtual tables are special enough that the workaround is probably the best way to go. Here's a minimal example of using FTS.\nHere's a minimal example of using full text search:\nmain.rs\n```rust\n[macro_use]\nextern crate diesel;\nmod database;\nuse database::email;\nuse diesel::prelude::*;\nfn main() {\n    let conn = SqliteConnection::establish(\"./test.sqlite\").unwrap();\nlet values = email::table\n    .select((email::rowid, email::rank))\n    .filter(email::whole_row.eq(\"john\"))\n    .first::<(i32, f32)>(&conn)\n    .unwrap();\n\nprintln!(\"{:?}\", values);\n\n}\n```\ndatabase.rs\n```rust\ntable! {\n    email(rowid) {\n        rowid -> Integer,\n    #[sql_name = \"email\"]\n    whole_row -> Text,\n    rank -> Float,\n}\n\n}\n```\nup.sql\n```sql\nCREATE VIRTUAL TABLE email USING fts5(sender, title, body);\nINSERT INTO email (sender, title, body) VALUES ('John Doe', 'Hello World', 'Welcome john to the land of the awesome');\n```\nRunning\n``\n/usr/bin/cargo run --color=always --package diesel-fts --bin diesel-fts\n   Compiling diesel-fts v0.1.0 (file:///home/me/projects/diesel-fts)\n    Finished dev [unoptimized + debuginfo] target(s) in 1.39 secs\n     Runningtarget/debug/diesel-fts`\n(1, -0.000001375)\nProcess finished with exit code 0\n``. When will this fix be released?. Here's a complete example of storing a custom type in a SQLBINARY` column.\nhttps://github.com/forte-music/core/blob/ddb49db78080ef661834657b66de4e2c74675149/src/models/id.rs#L73-L85. ",
    "sameer": "I'm interested @0xcaff, would appreciate it if you have the time to do a PR for this.. Either it should be implemented for both or none. It's misleading to implement it for NaiveDate and not Uuid since both can technically be serialized.\nIf it shouldn't be, is there some way this could be provided in a standardized manner? It is odd for users to have to manually implement ToSql and FromSql for types that can be serialized in general.. ",
    "aochagavia": "No problem. Thank you for the library!\n. ",
    "dtolnay": "@sgrif Syntex does not make breaking changes in minor updates. Cargo does not consider 0.x.0 and 0.(x+1).0 to be semver-compatible.\n@MrBlobbyJr diesel_codegen builds just fine using syntex. It does not build on the latest nightly but @sgrif says that is not supported.\n. What happens tomorrow?. I believe this is a consequence of https://github.com/serde-rs/serde/commit/30361ac6d022839be19fc608645756ed1be839ab which leverages the rustc fix for https://github.com/rust-lang/rust/issues/47311. Serde makes no attempt to support old nightlies.. Thanks for the ping. This is why you should only glob import from modules that are documented for glob importing, like preludes. Neither the standard library nor I am going to consider something like this a breaking change for affecting glob imports.. This was fixed upstream in https://github.com/rust-lang/rust/pull/36782 and the workaround is no longer necessary.\n. I added an impl<T: ?Sized> PartialEq<T> for Ident where T: AsRef<str> in syn 0.5.0 so the explicit as_ref() will no longer be necessary.\n. I filed https://github.com/dtolnay/syn/issues/25 to make attribute parsing less annoying.\n. I added syn::LifetimeDef::new(\"'a\") in syn 0.8.5 to simplify this a bit.\n. Do you think it makes sense to add these upstream as constructors? syn::Ty::ident(i), syn::Ty::path(p), syn::Path::ident(i) or something like that. And should the ident ones take Ident or Into<Ident> so they can be called with strings?\n. I changed this to parse_macro_input in syn 0.6.0 which handles only structs and enums, as opposed to the entire array of items (functions, modules, typedefs, statics, extern crates, traits, impls, etc). The parse_item is behind a feature flag because it compiles a bit slower and most people don't need it.\n. Or equivalently, quote!(#item #output).to_string().parse().unwrap().\n. I added attr.value.name() -> &str in syn 0.7.1 and attr.name() -> &str in 0.8.5.\n. You're right, let's always take ownership of the iterator. What do you think of adding #(&fields)* as a way to not take ownership equivalent to what happens currently?\n. Just like you, I don't want to be in the business of maintaining a pretty-printer either :smiling_imp:. If you care about formatting, run it through rustfmt::run which writes formatted code to stdout. Or the approach I took in cargo-expand which is check whether rustfmt is available on the path and pipe to it if found.. Ident is cheaply copyable so I would not bother with Cow here.\nrust\npub fn table_name(&self) -> syn::Ident {\n    self.table_name_from_attribute\n        .unwrap_or_else(|| infer_table_name(self.name))\n}. This can be item.ident without clone().. Some(x) => Identifier::Named(x). You are going to want another split_for_impl after this line.\nrust\nlet (impl_generics, _, _) = impl_generics.split_for_impl();\nOtherwise it does not work for types that have generic type parameter defaults.\n```rust\n[derive(AsChangeset)]\n[table_name = \"users\"]\n[primary_key(name)]\nstruct Changes2 {\n    name: T,\n    hair_color: String,\n}\n```\nerror: defaults for type parameters are only allowed in `struct`, `enum`, `type`, or `trait` definitions.\n   --> tests/update.rs:390:14\n    |\n390 |     #[derive(AsChangeset)]\n    |              ^^^^^^^^^^^\n    |\n    = note: #[deny(invalid_type_param_default)] on by default\n    = warning: this was previously accepted by the compiler but is being phased out; it will become a hard error in a future release!\n    = note: for more information, see issue #36887 <https://github.com/rust-lang/rust/issues/36887>. quote_spanned! can make this more concise but it is up to you whether you prefer the explicit way or the concise way.\nrust\nquote_spanned!(call_site=> .). I don't know. :( Serde hasn't hit this because we don't generate macros from macros. File a Rust issue with a minimal repro if you convince yourself it is a bug.. Yeah the design constraints here are a bit unusual. If you have something like quote_spanned!(a ??? b) the objective was to make it look visibly off-balance and draw the eye a particular way, due to a being evaluated in the context of the procedural macro and b being evaluated in the generated code. I am happy with this design and I believe it has the intended effect.. ",
    "porglezomp": "The policy and the date of the most recent release (perhaps with the rustup override invocation needed to get it) should probably be somewhere more prominent in order to prevent this confusion in the future.\n. Thanks, that's really the solution I needed here.\n. ",
    "cascalheira": "@killercup Thank you for the fast reply. I just changed the commit message and added \"Fix #373\" to it.\nAbout the tests, i will try to do that later today or tomorrow. I am quite new to rust and need to figure how to write that test (from what i saw so far, it shouldn't be hard, but i still need the time to figure it out).\n. @killercup As making it optional, i don't really think that is a good idea because views don't actually have primary keys. In my opinion, views should be dealt in some other way.\n. @sgrif I just added a changelog entry and modified the SQL query so that instead of excluding views from the query, it only fetches 'BASE TABLES'.\nAs diesel doesn't have any kind of views support i don't really see the point of adding another test. This will just enforce propper behaviour when fetching tables (views aren't really tables).\nLet me know if you need me to change something else.\n. Seems like SQLite also supports views and also fetches them in the same way, alongside with normal tables: Stack Overflow. I don't use SQLite but next week i can do a new pull request with the SQLite fix.\nAs it currently is, diesel crashes if we have a view (views are just queries, not tables and as such have no primary keys) so the current tests would already be what we need to test this situation. If you still want me to add something to the tests just for the sake of it, i will just add the SQL to create a view and check if it wasn't fetched (If it were, it would crash diesel anyway when using infer_schema!).\n. @killercup Sorry for the late answer i've been quite busy lately :)\nThank you for including that as it will make possible for me to use the master branch on my projects.\n. ",
    "AndiDog": "I might just do a simple one, but first I need to resolve this issue:\n.get_result(conn));\n ^^^^^^^^^^ trait `diesel::sqlite::Sqlite: diesel::backend::SupportsReturningClause` not satisfied\nEven though it makes sense for an insert statement (since getting inserted rowid is another query), I need a solution for sqlite, e.g. .exec(conn) which doesn't get a \"return value\".\n. ",
    "rogeruiz": "I may take a crack at this with my changes to rogeruiz/tick#4 which will be using SQLite. I hope the easy-for-newcomers label is the true in my case. \ud83d\ude00 \n. ",
    "Frederick888": "I'm new to Diesel and still a little confusing with the SQLite. I know that we could use execute(conn) to execute the query, but how could I retrieve the created object without get_result()?. @sgrif So what is the equivalent call in Diesel as sqlite3_last_insert_rowid?. ",
    "Gisleburt": "Updated link to BoxedDsl: http://docs.diesel.rs/diesel/query_dsl/methods/trait.BoxedDsl.html. ",
    "cengizIO": "Hello!\nI can work on this, if there's nobody already assigned.\n. Hello @killercup, @sgrif \nI replaced old if block with new matchers but currently having borrowing/ownership issues.\nI brought a Postgres docker instance up and fixing borrow checker errors one by one.\nWill submit a PR in following days.\nThanks\n. Sorry it's been a very busy week. \nI'm back to working on this.\n. @killercup Should we open an issue for it?\n. @sgrif Oops. I missed your comment.\n. @killercup I guess changelog is only updated while tagging releases. Am I right?\n@sgrif I just added the sqlite part.\n. ",
    "gsquire": "This could help too: https://gist.github.com/sgrif/68cbba9a87084da3a2e8c42a12e7d6cf\n. I can help with this.\n. I don't have much experience in the codebase but I'd like to help review.. ",
    "bahlo": "@killercup: Thanks for your help, didn't think of that. \ud83d\ude48 \n. Hey, I'd also like to be in the review team. . ",
    "shssoichiro": "I'd like to work on this one.\n. Got it! I'll check back later if this still ends up being necessary.\n. Hi, I'd like to go ahead and work on this.\n. I'd like to work on this, if no one else has started it.\n. I'm struggling a bit getting my initial test to pass. I have an implementation which compiles, which is based off of how count works, but my ExistsDsl trait doesn't seem to be implemented for the correct traits. I'm getting:\n---- query_dsl::exists_dsl::ExistsDsl_0 stdout ----\n    error: no method named `exists` found for type `users::table` in the current scope\n  --> <anon>:15:20\n   |\n15 | let exists = users.exists().first(&connection);\n   |                    ^^^^^^\n   |\n   = note: the method `exists` exists but the following trait bounds were not satisfied: `diesel::query_builder::SelectStatement<(diesel::types::Integer, diesel::types::Text), (users::columns::id, users::columns::name), users::table> : diesel::exists_dsl::ExistsDsl`, `&users::table : diesel::QuerySource`, `&users::table : diesel::query_builder::AsQuery`, `_ : diesel::exists_dsl::ExistsDsl`, `_ : diesel::Expression`, `&users::table : diesel::query_builder::Query`, `&mut users::table : diesel::QuerySource`, `&mut users::table : diesel::query_builder::AsQuery`, `_ : diesel::exists_dsl::ExistsDsl`, `_ : diesel::Expression`, `&mut users::table : diesel::query_builder::Query`\n   = help: items from traits can only be used if the trait is implemented and in scope; the following trait defines an item `exists`, perhaps you need to implement it:\n   = help: candidate #1: `diesel::exists_dsl::ExistsDsl`\nWhen currently my ExistsDsl implementation looks like this:\n```\npub trait ExistsDsl: AsQuery {\n    type Output;\nfn exists(self) -> Self::Output;\n\n}\nimpl ExistsDsl for T\n    where T: QuerySource + AsQuery,\n          T::Query: ExistsDsl + Expression {\n    type Output = SelectStatement, ()>;\nfn exists(self) -> Self::Output {\n    select(exists(self.as_query()))\n}\n\n}\n``\n. This is what I had thought as well, that I would need to make code changes to satisfy the tests passing with uuid 0.3. However, with diesel 0.7.2 which requires uuid ^0.2, if I have in my app's Cargo.toml that I want uuid ^0.3, the app will fail to build, saying thatdiesel::expression::Expressionis not satisfied foruuid::Uuid. If I change my application's Cargo.toml to require uuid ^0.2, the build succeeds. So for whatever reason, if there's a version mismatch in the uuid crate between diesel and my Cargo.toml, the diesel traits don't get implement for my app's version ofuuid::Uuid`. \nNote that this is with the 2016-08-18 rustc nightly that is recommended for diesel. \n. Awesome. I've updated my PR to allow version = \">=0.2.0, <0.4.0\" for diesel's uuid.\n. @Eijebong I used what you wrote as a base for building this library: https://github.com/shssoichiro/diesel-derives-extra. It's a little rough for now but I'll clean it up and probably add more methods as feedback is generated from using it. I think the main benefit of putting this into diesel itself would be that the traits could be pulled in with diesel::prelude::* and remove the need for the extra trait imports, but I don't think that's enough to push this into diesel if the maintainers don't feel it fits with the core goals of diesel. I'm fine with keeping this as a third-party crate.. Would you suggest I move the \"quickcheck/unstable\" feature in diesel_tests/Cargo.toml from our unstable feature to the postgres feature? The tests fail to compile without that flag, since quickcheck only has impls for SystemTime behind their unstable flag.\n. Fixed!\n. ~~Looks like it passes on stable with quickcheck/unstable turned on. Should be good to go now.~~\n. Sorry, looks like I was wrong. If I take out this test from behind our \"unstable\" feature flag, the test suite fails to compile on stable.\nthe trait boundstd::time::SystemTime: diesel::Queryableis not satisfied and several simliar errors.\n. Looks like this is because diesel::std_time is behind the unstable flag. If we remove it, the tests pass on the latest stable. Should I go ahead and remove that flag from std_time?\n. Pushed. Should be good to go.\n. ",
    "vitiral": "I am having the same issue:\n```\nrustup show\nDefault host: x86_64-unknown-linux-gnu\ninstalled toolchains\nstable-x86_64-unknown-linux-gnu\nnightly-x86_64-unknown-linux-gnu (default)\nactive toolchain\nnightly-x86_64-unknown-linux-gnu (default)\nrustc 1.12.0-nightly (8787a1233 2016-08-11)\n```\nI just did a literal copy-paste of the tutorial (including version = \"0.7.0\" and got this rather confusing error:\ndiesel_demo git:(master) cargo run --bin show_posts\n    Updating registry `https://github.com/rust-lang/crates.io-index`\nerror: Package `diesel_codegen v0.7.1` does not have these features: `nightly`\nSo it seems to be using v0.7.1 instead of 0.7.0.\nFix\n- Take \"nightly\" out of diesel_codegen and set version to \"0.7.1\"\n- set dotenv_macros version to \"0.9.0\"\nThen it seems to compile and run\n. I would recommend just changing the \"getting started\" guide to using the newer versions. Not sure why Cargo is trying to get 0.7.1 when I am explicitly telling it to use 0.7.0 -- could be a Cargo bug?\n. The broken code is at (static link to commit):\nhttps://github.com/vitiral/notes/tree/bc4941d8427654818919d97448c52b866b2725d6/rust/diesel/diesel_demo\n. re-reading the tutorial I see that you require a specific nightly version. I will just use that -- thanks!\n. Thanks a ton! Would be great if this could be incorporated into the documentation -- the fact that this is handled automagically makes diesel even more appealing :)\nI imagine if I wanted to pointed to a name_id foreign key instead then this would be a two step process? (first create the Name and/or query the name_id, then create the Run?)\n. the fact that you are adding a row to both the tests table and the runs table at once is pretty cool IMO.\n. discovered by @TheAustinJones. thanks! It would be great to add that to the tutorial. For others seeing this, those features are documented here:\nhttps://github.com/jgallagher/rusqlite/blob/master/libsqlite3-sys/Cargo.toml. ",
    "hugo": "It makes readability worse on narrow browser windows that aren't quite narrow enough, though. The full width breakpoint should be the same on desktop. \n\nOn 5 Aug 2016, at 15:02, Sean Griffin notifications@github.com wrote:\nI believe this is intentional to improve readability on tablets\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "beatgammit": "Any progress on this? I'm excited about using diesel with the new macros 1.1 support, and this looks like the last major blocker.\n. @macobo - I'm guessing it's The Bike Shed.. I don't know if this exists yet, but perhaps documentation (e.g. an example on the website) about how to integrate Diesel into an async project without blocking the whole event loop. If this example does connection pooling, then this seems like a reasonable solution until the async ecosystem in Rust stabilizes some.\nI'm using Diesel on a site that I hope will have high volume database operations (mostly simple CRUD, but relatively high volume, as in potentially hundreds or even thousands more-or-less concurrently). I'll be figuring out how to do pooling properly, but I honestly wouldn't go through this effort if I wasn't dead-set on using Rust and another solution has an out-of-the-box solution (e.g. Go is \"good enough\").\nAnd honestly, an async interface into a thread pool of synchronous connections is probably better for a high traffic site anyway, which is probably the bulk of the \"async or bust\" crowd. That's not to say that async in Diesel isn't useful, just that we can probably solve the problem for most people with documentation.. Rust 1.15 should be out this week, is there any preliminary documentation?\nI tried compiling on the beta branch and I get compile errors on diesel_codegen: (\"#[feature] may not be used on the beta channel\") using the latest diesel_codegen 0.9.0 on crates.io and beta 1.15.0-beta.5 (built Jan 19). If I build from the latest git head, I get a different compile error, but in infer_schema!, so I guess it's just not published yet (I can file that compile error separately if you like, but here's the invocation: infer_schema!(\"dotenv:DATABASE_URL\");, and .env: DATABASE_URL=test.sqlite).. Awesome. Will a new crate be pushed soon with support for stable Rust?. I also noticed that the link to update in IncompleteUpdateStatement is broken as well (I'm guessing it should be update_statement? I think this one is because something was renamed.. I'll try again on the beta compiler. I was using the latest nightly (from Tuesday I think).\nOk, here's the error I got when running with --verbose:\n      Running `rustc --crate-name kingdoms src/lib.rs --crate-type lib --emit=dep-info,link -C debuginfo=2 -C metadata=8803b6454b81cb08 -C extra-filename=-8803b6454b81cb08 --out-dir /home/otto/src/kingdoms/target/debug/deps -L dependency=/home/otto/src/kingdoms/target/debug/deps --extern serde=/home/otto/src/kingdoms/target/debug/deps/libserde-3b541f18042a189e.rlib --extern diesel_codegen=/home/otto/src/kingdoms/target/debug/deps/libdiesel_codegen-4fec4c5b49099acd.so --extern dotenv=/home/otto/src/kingdoms/target/debug/deps/libdotenv-75d8ce5725f9d0e8.rlib --extern tokio_core=/home/otto/src/kingdoms/target/debug/deps/libtokio_core-70b906545a29c574.rlib --extern serde_derive=/home/otto/src/kingdoms/target/debug/deps/libserde_derive-bb0d6dc974011064.so --extern futures=/home/otto/src/kingdoms/target/debug/deps/libfutures-e55d45cfd50e0707.rlib --extern serde_json=/home/otto/src/kingdoms/target/debug/deps/libserde_json-85c7805edd047502.rlib --extern router=/home/otto/src/kingdoms/target/debug/deps/librouter-2997412ffea4968d.rlib --extern iron=/home/otto/src/kingdoms/target/debug/deps/libiron-72125e3b31590887.rlib --extern clap=/home/otto/src/kingdoms/target/debug/deps/libclap-f2820a3ff71ece60.rlib --extern diesel=/home/otto/src/kingdoms/target/debug/deps/libdiesel-bf8106fecd2b1076.rlib --extern hyper=/home/otto/src/kingdoms/target/debug/deps/libhyper-f076905ec4b248f0.rlib -L native=/usr/lib -L native=/usr/lib`\nerror: custom derive attribute panicked\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = help: message: This is a bug. Please open a Github issue with your invocation of `infer_schema!\n  = note: this error originates in a macro outside of the current crate\n\nerror: Could not compile `kingdoms`.\n\nCaused by:\n  process didn't exit successfully: `rustc --crate-name kingdoms src/lib.rs --crate-type lib --emit=dep-info,link -C debuginfo=2 -C metadata=8803b6454b81cb08 -C extra-filename=-8803b6454b81cb08 --out-dir /home/otto/src/kingdoms/target/debug/deps -L dependency=/home/otto/src/kingdoms/target/debug/deps --extern serde=/home/otto/src/kingdoms/target/debug/deps/libserde-3b541f18042a189e.rlib --extern diesel_codegen=/home/otto/src/kingdoms/target/debug/deps/libdiesel_codegen-4fec4c5b49099acd.so --extern dotenv=/home/otto/src/kingdoms/target/debug/deps/libdotenv-75d8ce5725f9d0e8.rlib --extern tokio_core=/home/otto/src/kingdoms/target/debug/deps/libtokio_core-70b906545a29c574.rlib --extern serde_derive=/home/otto/src/kingdoms/target/debug/deps/libserde_derive-bb0d6dc974011064.so --extern futures=/home/otto/src/kingdoms/target/debug/deps/libfutures-e55d45cfd50e0707.rlib --extern serde_json=/home/otto/src/kingdoms/target/debug/deps/libserde_json-85c7805edd047502.rlib --extern router=/home/otto/src/kingdoms/target/debug/deps/librouter-2997412ffea4968d.rlib --extern iron=/home/otto/src/kingdoms/target/debug/deps/libiron-72125e3b31590887.rlib --extern clap=/home/otto/src/kingdoms/target/debug/deps/libclap-f2820a3ff71ece60.rlib --extern diesel=/home/otto/src/kingdoms/target/debug/deps/libdiesel-bf8106fecd2b1076.rlib --extern hyper=/home/otto/src/kingdoms/target/debug/deps/libhyper-f076905ec4b248f0.rlib -L native=/usr/lib -L native=/usr/lib` (exit code: 101)\n\ndiesel_codegen is using this commit: 7dd95eb847e14934a7f04d8039950707f973a6ba.\nrustup show (just updated today, though I can switch to the previous beta if you like):\nDefault host: x86_64-unknown-linux-gnu\n\ninstalled toolchains\n--------------------\n\nstable-x86_64-unknown-linux-gnu (default)\nbeta-x86_64-unknown-linux-gnu\nnightly-2016-12-16-x86_64-unknown-linux-gnu\nnightly-2017-01-15-x86_64-unknown-linux-gnu\nnightly-x86_64-unknown-linux-gnu\n\nactive toolchain\n----------------\n\nbeta-x86_64-unknown-linux-gnu (directory override for '/home/otto/src/kingdoms')\nrustc 1.16.0-beta.1 (5276ba72e 2017-01-31)\n\n. I get the same problem on the nightly you listed using diesel_codegen master:\n     Running `rustc --crate-name kingdoms src/lib.rs --crate-type lib --emit=dep-info,link -C debuginfo=2 -C metadata=8803b6454b81cb08 -C extra-filename=-8803b6454b81cb08 --out-dir /home/otto/src/kingdoms/target/debug/deps -L dependency=/home/otto/src/kingdoms/target/debug/deps --extern futures=/home/otto/src/kingdoms/target/debug/deps/libfutures-e55d45cfd50e0707.rlib --extern tokio_core=/home/otto/src/kingdoms/target/debug/deps/libtokio_core-70b906545a29c574.rlib --extern diesel=/home/otto/src/kingdoms/target/debug/deps/libdiesel-bf8106fecd2b1076.rlib --extern router=/home/otto/src/kingdoms/target/debug/deps/librouter-2997412ffea4968d.rlib --extern iron=/home/otto/src/kingdoms/target/debug/deps/libiron-72125e3b31590887.rlib --extern dotenv=/home/otto/src/kingdoms/target/debug/deps/libdotenv-75d8ce5725f9d0e8.rlib --extern serde=/home/otto/src/kingdoms/target/debug/deps/libserde-3b541f18042a189e.rlib --extern serde_json=/home/otto/src/kingdoms/target/debug/deps/libserde_json-85c7805edd047502.rlib --extern hyper=/home/otto/src/kingdoms/target/debug/deps/libhyper-f076905ec4b248f0.rlib --extern clap=/home/otto/src/kingdoms/target/debug/deps/libclap-f2820a3ff71ece60.rlib --extern diesel_codegen=/home/otto/src/kingdoms/target/debug/deps/libdiesel_codegen-4fec4c5b49099acd.so --extern serde_derive=/home/otto/src/kingdoms/target/debug/deps/libserde_derive-bb0d6dc974011064.so -L native=/usr/lib -L native=/usr/lib`\nerror: custom derive attribute panicked\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = help: message: This is a bug. Please open a Github issue with your invocation of `infer_schema!\n  = note: this error originates in a macro outside of the current crate\n\nerror: Could not compile `kingdoms`.\n\nCaused by:\n  process didn't exit successfully: `rustc --crate-name kingdoms src/lib.rs --crate-type lib --emit=dep-info,link -C debuginfo=2 -C metadata=8803b6454b81cb08 -C extra-filename=-8803b6454b81cb08 --out-dir /home/otto/src/kingdoms/target/debug/deps -L dependency=/home/otto/src/kingdoms/target/debug/deps --extern futures=/home/otto/src/kingdoms/target/debug/deps/libfutures-e55d45cfd50e0707.rlib --extern tokio_core=/home/otto/src/kingdoms/target/debug/deps/libtokio_core-70b906545a29c574.rlib --extern diesel=/home/otto/src/kingdoms/target/debug/deps/libdiesel-bf8106fecd2b1076.rlib --extern router=/home/otto/src/kingdoms/target/debug/deps/librouter-2997412ffea4968d.rlib --extern iron=/home/otto/src/kingdoms/target/debug/deps/libiron-72125e3b31590887.rlib --extern dotenv=/home/otto/src/kingdoms/target/debug/deps/libdotenv-75d8ce5725f9d0e8.rlib --extern serde=/home/otto/src/kingdoms/target/debug/deps/libserde-3b541f18042a189e.rlib --extern serde_json=/home/otto/src/kingdoms/target/debug/deps/libserde_json-85c7805edd047502.rlib --extern hyper=/home/otto/src/kingdoms/target/debug/deps/libhyper-f076905ec4b248f0.rlib --extern clap=/home/otto/src/kingdoms/target/debug/deps/libclap-f2820a3ff71ece60.rlib --extern diesel_codegen=/home/otto/src/kingdoms/target/debug/deps/libdiesel_codegen-4fec4c5b49099acd.so --extern serde_derive=/home/otto/src/kingdoms/target/debug/deps/libserde_derive-bb0d6dc974011064.so -L native=/usr/lib -L native=/usr/lib` (exit code: 101)\n\nTo be clear, I can use the published crate on nightly, but using master breaks on all rustc that I've tried.. Nvm, it seems to fail regardless of what I try... in any case, I'm not blocked by this issue, I just wanted to make sure it was addressed before a new crate was published targeting the new rust 1.15.\nLet me know if there's anything else I can do to help. If it's really a bug in rust, then there's not much we can do, but I can try to make a smaller test case to reproduce it if that'll help.. Ok, it looks like it's potentially partially my fault. I was messing with the URI in .env to try to get it to work on the beta release, and I then got errors from that. I'm working through the errors on the nightly mentioned earlier in this chain.\nEDIT: I fixed the URI and it builds on nightly-2017-01-19 with the version from crates.io, but fails to build from diesel_codegen master.. Ok, I figured it out. I was using diesel_codegen from master, but diesel from crates.io and I had to set the \"sqlite\" feature when I updated to diesel master (I guess it was default on in diesel but not diesel_codegen before?). I rebuilt using the latest beta (1.16) and it worked.\nSo, TL;DR: update both diesel and diesel_codegen to the latest master and it compiles on the latest beta.\nEDIT: as a bonus, it seems it also compiles on 1.15 stable, which was just released like 30 minutes ago!\nEDIT: it also works with the versions published to crates.io. I guess I was just a worry wart. I thought it was going to be a 0.9.2 release or something, but having both at 0.10 makes sense. Thanks so much for your hard, I think this can be closed.. Yes, the .env file was invalid in my test. I threw a sqlite:// in front of the filename (to make it look more like postgres) thinking maybe it was just a poor error message, but it was failing before even getting to that point. As I mentioned above, it was a mismatch between diesel_codegen 0.10 and diesel 0.9, which was resolved by setting both to pull from master. The error message I got once it got past whatever it was panicking on was helpful:\n\n= help: message: called Result::unwrap() on an Err value: StringError(\"Failed to establish a database connection at sqlite://test.sqlite. Error: BadConnection(\\\"Unable to open the database file\\\")\")\n= note: this error originates in a macro outside of the current crate\n\nThe crates you just published work OOTB with my previously working .env entry, so this is now resolved and works with the stable compiler. So all I need to do is update my Cargo.toml to pull the latest crates from crates.io.. ",
    "cbrewster": "Hi @sgrif, is there anywhere where I can track the progress of composite PK support?. @killercup awesome! Is there a recommended way to handle many-to-many yet or is that still in the works?. ",
    "Kerollmops": "Hi everybody !\nIs there some news on many-to-many joins ?\nI noticed that infer_schema! only supports tables with primary keys and that's not mandatory for many-to-many joins.\nTherefore I don't know how to represent simple tables joins between Users and Teams (for example).\nThanks \u2764\ufe0f \nEDIT: Ooops! It seems the table! macro can help me.... It's 0.8.0 and not ^0.8.0\n. Ho ! ok ! My bad ! I didn't know this !\n. There is a problem here, the r2d2 version you chose here doesn't make r2d2::Error public and make the diesel r2d2 reexport to not compile. In the diesel 0.8 version, the Error type is now public.\nrust\nerror[E0603]: trait `Error` is private\n  --> /Users/crenault/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-1.1.1/src/r2d2.rs:11:22\n   |\n11 | pub type PoolError = self::r2d2::Error;\n   |                      ^^^^^^^^^^^^^^^^^. Whooops, it seems to be fixed in master... sorry about that, a simple cargo update fixed the old r2d2 version I got. ",
    "chpio": "@sgrif maybe something like the \"async iterator\" in JS? Which would return an Iterator<Item=Future<T>>, the consumer would then call await on each future, but for this to work we would need compiler support for await. We could also make a simple helper function which would take an Iterator<Future> and a closure and iterate over the Iterator and calling the closure when the Future is ready.\n. @ivanovaleksey \n1. it's not real async code, we are talking about handling the whole connection asynchronously, not running blocking code on a threadpool\n2. you can't do more concurrent queries than there are cpu cores (CpuPool::new_num_cpus())\nnot saying it's \"wrong\". https://tokio.rs/blog/2018-05-tokio-fs/#blocking. ",
    "macobo": "@sgrif off-topic, but curious as to the reasons for moving off of libpq. Could you also post a link to the podcast?. ",
    "pyros2097": "Well there is tokio-postgres now which you can use for your async stuff.\nhttps://docs.rs/tokio-postgres/0.2.1/tokio_postgres/. ",
    "yazaddaruvala": "Just want to clarify, will async make the 1.0 milestone?\n. I understand your frustrations with the current API, and understand you don't want to build async support just yet, only to re-do it later. All of that makes perfect sense, and this is your project so absolutely do what you feel is best.\nI just want to point out that your rationale for \"async isn't a big deal\" is full of selection bias (i.e. inaccurate), and you're doing yourself a disservice by believing those stats.\n\nFinally, I hear a lot of people saying that the lack of async support is the big blocker for them using Diesel, but I'm not buying it.\n\nYou're using the stats for tokio-postgres to infer the popularity of async needs and since it is not popular you infer that async is not a blocker.\nHowever, this is inaccurate, people who view async as a blocker are not using sync-Rust instead. They are simply not using Rust.\nAt least for me, I do not use Rust for any web based applications because, while hyper is pretty good, there is no great ecosystem around async in Rust yet.. ",
    "batisteo": "Just a heads up on Pleingres, \u201cAn asynchronous, Tokio-based, 100% Rust postgres driver\u201d, as mentioned in the Pijul blog.\nIt might be an inspiration or a base for the future work. Or not.\n. For Fedora lovers: sudo dnf install libsqlite3x-devel. ",
    "fluxxu": "This method is considered as a workaround\nJust use \nhttps://github.com/alexcrichton/futures-rs/tree/master/futures-cpupool\nto wrap diesel's operations, then you can use diesel with futures/tokio nicely.\nDefine something like\n```rust\nuse futures::prelude::*;\nuse futures_cpupool::CpuPool;\nuse diesel;\npub type Conn = diesel::pg::PgConnection;\npub fn exec_async(&self, f: F) -> impl Future\n  where\n    T: Send + 'static,\n    E: From<::diesel::result::Error> + Send + 'static,\n    F: FnOnce(&Conn) -> R + Send + 'static,\n    R: IntoFuture + Send + 'static,\n    ::Future: Send,\n  {\n    lazy_static! {\n      static ref THREAD_POOL: CpuPool = {\n        CpuPool::new_num_cpus()\n      };\n    }\nlet pool = /* clone a ref of diesel's connection pool */;\nTHREAD_POOL.spawn_fn(move || {\n  pool\n    .get()\n    .map_err(|err| E::from(err))\n    .map(|conn| f(&conn))\n    .into_future()\n    .and_then(|f| f)\n})\n\n}\n```\nThen you can\nrust\nexec_async(|conn| {\n  diesel::insert_into(??).values(??).execute(conn)\n}).and_then(...). @killercup \nYes I did:\ntoml\n[dependencies]\nchrono = \"0.2.25\"\ndiesel = { version = \"0.9.0\", features = [\"chrono\"] }\ndiesel_codegen = { version = \"0.9.0\", features = [\"postgres\"] }\nAnd DateTime also come from chrono crate but it works.. http://docs.diesel.rs/diesel/query_builder/trait.AsChangeset.html\n\nBy default, any Option fields on the struct are skipped if their value is None. If you would like to assign NULL to the field instead, you can annotate your struct with #[changeset_options(treat_none_as_null = \"true\")].. Sorry I have to create a new one: https://github.com/diesel-rs/diesel/pull/1426 because I can't figure out how to edit this pull request.\nIt says from unknown repository.. \n",
    "ivanovaleksey": "@vorot93 @friktor @lnicola is the example above wrong?. I would like to give it a try.\nHowever, I am not very fluent in Rust and I totally don't understand how Diesel works.\nDo you have extra-patience for this? \ud83d\ude04 . Yeah, I see merged #1534 and I wonder doesn't it close this issue.\nThank you for your work!. @weiznich I have updated grammar :). As it was proposed by @sgrif I decided to cherry-pick Sean's code and add my small updates in this PR (which I originally opened).\n@sgrif @weiznich could you please check my original message about joinable!?\n. Well, I guess joinable!(abac_policy -> namespace (namespace_id)); was removed because there was single FK to namespace table\nforeign key (namespace_id) references namespace (id) on delete cascade\nand then I added another 3 FKs\nforeign key (subject_namespace_id) references namespace (id) on delete cascade,\nforeign key (object_namespace_id) references namespace (id) on delete cascade,\nforeign key (action_namespace_id) references namespace (id) on delete cascade\nand there is no way no automatically detect which one should be use by default.\nIt seems pretty reasonable to me. It is my bad that I was complaining about that \ud83d\ude1e \nSo, I believe this PR is ready to be merged.\nI guess CHANGELOG entry should be added to reflect that there is no more limitation about composite PK size, right?. @sgrif thanks for the elegant solution!\nShouldn't we update documentation about limits on composite PK size?\nI mean diesel/src/macros/mod.rs file .\nAre any updates required to print-schema tool? Right now it checks PKs count explicitly.\n. @sgrif do you mean I could push updates to this PR? Not sure if I am allowed to do this. Isn't it allowed only for maintainers? \nI guess I can check out PR locally but then my changes would land as new PR (if I am not missing anything).\nAnd what do we have now? There is no special limit on PK size, so \n- in diesel/src/macros/mod.rs we could just place \n/// Tables with no primary key are not supported.\n- in diesel_infer_schema/infer_schema_internals/src/inference.rs we could remove else if arm altogether\nright?. @sgrif I run print-schema (with PK size commented) and joinable! was removed too (like in my original PR).\nDoes it mean that something else should be patched?\n```diff\ndiff --git a/migrations/2018-04-16-123630_create_abac_policy/up.sql b/migrations/2018-04-16-123630_create_abac_policy/up.sql\nindex d38cf17..6014480 100644\n--- a/migrations/2018-04-16-123630_create_abac_policy/up.sql\n+++ b/migrations/2018-04-16-123630_create_abac_policy/up.sql\n@@ -1,13 +1,21 @@\n create table abac_policy (\n-  id uuid default uuid_generate_v4(),\n   namespace_id uuid not null,\n+  subject_namespace_id uuid not null,\n+  subject_key text not null,\n   subject_value text not null,\n+  object_namespace_id uuid not null,\n+  object_key text not null,\n   object_value text not null,\n+  action_namespace_id uuid not null,\n+  action_key text not null,\n   action_value text not null,\n   issued_at timestamp not null default now(),\n   not_before timestamp,\n   expired_at timestamp,\nforeign key (namespace_id) references namespace (id) on delete cascade,\n-  primary key (id)\n+  foreign key (subject_namespace_id) references namespace (id) on delete cascade,\n+  foreign key (object_namespace_id) references namespace (id) on delete cascade,\n+  foreign key (action_namespace_id) references namespace (id) on delete cascade,\n+  primary key (namespace_id, subject_namespace_id, subject_key, subject_value, object_namespace_id, object_key, object_value, action_namespace_id, action_key, action_value)\n );\ndiff --git src/schema.rs src/schema.rs\nindex 8707262..2ff1bc1 100644\n--- src/schema.rs\n+++ src/schema.rs\n@@ -17,11 +17,16 @@ table! {\n }\ntable! {\n-    abac_policy (id) {\n-        id -> Uuid,\n+    abac_policy (namespace_id, subject_namespace_id, subject_key, subject_value, object_namespace_id, object_key, object_value, action_namespace_id, action_key, action_value) {\n         namespace_id -> Uuid,\n+        subject_namespace_id -> Uuid,\n+        subject_key -> Text,\n         subject_value -> Text,\n+        object_namespace_id -> Uuid,\n+        object_key -> Text,\n         object_value -> Text,\n+        action_namespace_id -> Uuid,\n+        action_key -> Text,\n         action_value -> Text,\n         issued_at -> Timestamp,\n         not_before -> Nullable,\n@@ -78,7 +83,6 @@ table! {\njoinable!(abac_action_attr -> namespace (namespace_id));\n joinable!(abac_object_attr -> namespace (namespace_id));\n-joinable!(abac_policy -> namespace (namespace_id));\n joinable!(abac_subject_attr -> namespace (namespace_id));\n joinable!(identity -> namespace (provider));\n joinable!(namespace -> account (account_id));\n```\n. @sgrif sorry for being silent all these days. Yes, I am still interested in this.\nI plan to follow this way\n\nfeel free to clone this branch, make your changes, and then open a new PR\n\nand add changes proposed in this comment.\nBy the way, could you please take a look at this comment.\nIt looks to me like a problem.\n. @sgrif I have cherry-picked you commit and decided to continue a work on my initial PR https://github.com/diesel-rs/diesel/pull/1699.\nI guess this PR can be closed.. @Diggsey thanks, yes it makes sense.\nSorry for that, the problem exists on crates.io but it is already fixed on master.\nI somehow missed it.. I am not sure if we should make changes here at all but it seemed to me that a word \"key\" was missing.\nI am not so good in English grammar, so I can't decide here :). ",
    "lnicola": "@ivanovaleksey I can't say it's correct, as I didn't test it (e.g. I'm not sure about the trait bounds). In theory it should work. However,\n\nit won't work with the async database drivers (I know there are a couple of implementations)\nit's rather verbose\nCpuPool is fixed-size; in general I'd prefer a more flexible thread pool\nafter the tokio changes that are coming soon, it will look a bit different (but still with a fixed thread pool)\n\nSo it works, but I'm not a fan of that approach.. It's not an issue for SQLite, but diesel deduces the type as i32 IIRC.\n\nIf you need to retrieve a I Bigint from SQLite, you can use the table macro and say it's a bigint\n\nYeah, that works.. > As far as I can tell there's no compiler that demonstrates a concrete problem here\nThe issue can be observed on nightly, with the use_extern_macros feature enabled: https://play.rust-lang.org/?gist=51baef8107264c2aafaf140c4d045e86&version=nightly&mode=debug, and it affects Diesel in the same way.\nI'll post here again if use_extern_macros gets stabilized and it's still hard to use it with Diesel.. ",
    "vorot93": "@ivanovaleksey Pretty much what @chpio said. This code simply masks the blocking operations behind a thread pool. This doesn't help in the high load use case where large number of incoming DB queries will cause unacceptable delays for each of them.. ",
    "hayd": "See also actix-diesel example https://github.com/actix/examples/blob/f8e3570bd16bcf816070af20f210ce1b4f2fca69/diesel/src/main.rs#L64-L70\nPerhaps offering a canonical pool implementation might be useful, that way diesel could have async/futures API without using async drivers (yet).\nThis sync driver / async API is how slick (scala) works https://stackoverflow.com/a/29597868/1240268 and might suffice to appease the \"people who view async as a blocker\" (at least some of them).\n\nAside:\n\nCpuPool is fixed-size; in general I'd prefer a more flexible thread pool\n\nIME it's desirable to have a fixed size (with potentially multiple pools), that way all connections are made on startup... and generally your db server won't allow an unlimited number of connections anyway.. ",
    "a3kov": "This article by the SQLAlchemy author is a very good read on the topic (while it's about Python many facts listed there still hold in the Rust world): \nhttp://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/\n. ",
    "gfortaine": "@sgrif Maybe one could reconsider this issue. Indeed, things seem to brighten on this topic thanks to futures 0.3, and the introduction of non-'static futures, cf the article Wherefore art thou Romio? from @withoutboats for a more detailed explanation \ud83d\udc4d :\n\nThe benefit of non-'static futures\nOn the other hand, the other big thing I\u2019ve found is a lot of opportunities that async/await opens up in terms of API design. In particular, one problem that the futures 0.1 ecosystem has suffered from is the fact that all futures need to be 'static, so they can\u2019t contain any references. This is, of course, just a special case of the general problem of \u201cself-referential futures\u201d that pinning was designed to solve, but its a variation on the theme that\u2019s worth highlighting.\n\ncc @mehcode\n. ",
    "mehcode": "@gfortaine I currently have some WIP stuff but its waiting on Diesel being a 2018 edition crate. PRs like #1956 need to be merged in (and there are a few other things like, turning on the future_compatibility lint and fixing all the problems that come up, that could be done to help out). \nFurthermore we are also blocked on https://github.com/rust-lang/rust/issues/56409 being stabilized and diesel being bumped to a MRV of 1.34 (expected version for this feature) as proc-macro crates (that are used in the crate that provides its runtime) cannot be edition 2018 without that feature.. @weiznich I would rather not block on that feature and just take the small performance hit with Box<Future< .. >> for trait methods. \nThat said, I assume we're going to likely put the async stuff behind a documented unstable feature flag until everything is stabilized to do it perfectly but there is a large ecosystem clamoring for some level of support here.. That's what I'm intending to do. \nBut it still leaves us blocked on https://github.com/rust-lang/rust/issues/56409 as we must compile as a 2018 edition crate first and we can't put that behind a feature flag.. Sorry it took me so long to come back to this.\n\nAs an aside, is there a specific reason that using .env as a \"configuration file lite\" is something you don't want to do?\n\nIn my projects I have (something like):\n.\n\u251c\u2500\u2500 Cargo.lock\n\u251c\u2500\u2500 Cargo.toml\n\u251c\u2500\u2500 config\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 default.toml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 production.toml\n\u251c\u2500\u2500 migrations\n\u2514\u2500\u2500 src\nConfiguration flows in from config/default.toml, is overridden by config/${env}.toml, and finally, is overridden further by the environment. \nWhen I add a .env file (which is intended to be sourced by dotenv) for consumption by the compiler and the CLI, I now have duplicated the development database URL in .env and config/default.toml.  \n\n\nOnce we get Macros 1.1 for bang macros or macros 2.0 [...]\n\nI can understand that. At least it's on the radar and that build.rs isn't that horrible in the meantime.\n\n[...] (though you'll end up needing to give that the database URL as well either through an environment variable or an argument) [...]\n\nNow here is where I'd like to make an actionable suggestion.\nWould it be acceptable to expose a programmatic interface for running the CLI? It doesn't seem that coupled to the main.rs.\nI'm thinking something along the lines of:\nrust\ndiesel_cli::run();\ndiesel_cli::run_with_args(&matches);\n^ That would just do essentially what the main function does in diesel_cli/main.rs.\nMy vision for this is being able to mount the diesel cli so it's run like $ my-app diesel _. This way my-app can communicate whatever it needs to the CLI. \nAnother idea that could work is doing src/bin/diesel.rs and cargo run --bin diesel -- ... The official diesel CLI could even detect this pattern and use the \"local\" diesel instead.. Even something simple like:\n```python\ndb = get(\"database\")\nfor x in migrations:\n  db.run(x)\nfor _ in migrations:\n  db.redo()\nfor x in migrations:\n  db.run(x)\n```\nWould at least run each down and catch any left over entities.\nI'm thinking diesel migration check to be a good command name. . @sgrif @weiznich As Diesel 2.x is being worked on now. Can this be reconsidered? Otherwise boxed async queries aren't going to be feasible. We just need the Send bound. . Postfix macros would be nice here:\nrust\nusers::table.aliased!(users2) \nThough it'd have a similar problem to \"inline declarations\". I wonder if that could be resolved with both a marker trait for aliases and specialization for a default impl of AppearsInFromClause for types that implement the marker.. @weiznich I'm not qualified to try and understand the inner workings here but I just want to express how much I would greatly appreciate this being considered for the next diesel release. There is such a large amount of SQL that diesel cannot cover because of this feature.. Not sure. Hope she's okay.\nPerhaps @sgrif knows? \nIt seems @sgrif has write access on crates.io in any case.. Closing as I don't have the time to drive this forward. I'll wait until a new dotenv rolls out from @sgrif or someone else.. I'll give it a go later. Thanks for the link.\n\nTook the time to read the contributing file. Tests aren't too bad to setup. I'd appreciate a docker command to do it that's all internalized so messing around with .env isn't needed. Personally the docker-compose doesn't help me that much. But that's neither here nor there for this PR.. @weiznich This should be good to go now. I tried to be conservative and only marked diesel as 2018 and a few supporting crates. \nI explicitly left diesel_cli as edition 2015 but used macro imports to test that scenario.\nI also explicitly left all examples as edition 2015 to test that standard usage has remained acceptable.. Decided to tear this PR apart into several small PRs to slowly move us forward here. See #1956 for the first one.. This is one of the main reasons I want to do #1958 \n\n@thsowers See: https://github.com/diesel-rs/r2d2-diesel/blob/master/examples/postgres.rs -- adapting it is simple. You just use diesel::r2d2 instead of r2d2.. Good point. I didn't think about this.\n\nFrom what I understand derive macros are not meant to be imported separately from their traits. On phone so I can't look it up but I remember a discussion about this where it was agreed importing them separately should be discouraged.\nRemember that macros have a different namespace than traits.\nrust\n// Import _both_ the derive macros and trait\nuse diesel::deserialize::Queryable;\nrust\n// import derive macro and trait separately\nuse diesel::derives::Queryable;\nuse diesel::deserialize::Queryable;. @weiznich Why 2.0? This isn't a breaking change. No matter where we move the macro re-exports, #[macro_use] usage will remain the same.. @sgrif @weiznich Any thoughts on how we want the macros?\nMy basic proposal would be:\n\nDerive macros available when importing their respective traits (e.g., use diesel::deserialize::Queryable will import both the derive and the trait)\nOther macros placed in related modules. The more I think on it, the more I dislike a generic diesel::macros bucket. . Some bad news. Rust doesn't let you organize macro_rules macros. What that means is they all have to be at root. We could move out all the macros into a diesel-macros crate and then that should allow us to organize into modules via re-exports.\n\n\nI did organize the derive() macros and re-exported them with their traits. I came across 3 that didn't map to a specific trait so I just left those being exported from diesel root.. You're welcome to help out here. Waiting on me for things is a bad idea (my free time is always odd). \nI would turn on the future_incompatible warning for one crate at a time and fix anything that pops up.. Sorry for the delay - https://discourse.diesel.rs/t/proposed-change-add-send-bound-to-boxed-query-types/67. @sgrif Any thoughts on the proposal?. With the state that dotenv is in I'd rather see it get removed or rewritten and replaced. Hope the original creator is doing okay.. ",
    "MarkJr94": "I'm still having this issue, with diesel version 0.7.1 from crates.io. Am I doing something wrong?\n. Ah, thanks for the clarification, and sorry for the confusion.\n. ",
    "Bobo1239": "@sgrif That should not be necessary because of implicit relations.\n\nThe package.workspace can be omitted if it would only contain ../ (or some\nrepetition of it). That is, if the root of a workspace is hierarchically the\nfirst Cargo.toml with [workspace] above a crate in the filesystem, then that\ncrate can omit the package.workspace key.\n. Just force pushed because I failed the commit message...\n. Reordering the tests in bin/test didn't really improve times on my system but I also don't really know how the different crates and features work together so maybe I did it suboptimally.\n\n(cd diesel && cargo test --features \"unstable chrono sqlite\")\n  (cd diesel_cli && cargo test --features \"postgres\" --no-default-features)\n  (cd diesel_tests && cargo test --features \"unstable_postgres\" --no-default-features)\n  (cd diesel_codegen_syntex && cargo test --features \"postgres\" --no-default-features)\n  (cd diesel_cli && cargo test --features \"sqlite\" --no-default-features)\n  (cd diesel_tests && DATABASE_URL=/tmp/test.db cargo test --features \"unstable_sqlite\" --no-default-features)\n  (cd diesel_compile_tests && cargo test)\n. yeah I just noticed it\n. Hm, I'm not sure what the best course of action is.\nAdding the example stages to the workspace requires renaming the crates because a workspace mustn't have crates with identical names. Then we would also have to rename the extern crates in the binaries.\nOtherwise we could set a separate workspace for each example stage (by creating an empty [workspace] section in each Cargo.toml) but recompile diesel each time and possibly confuse newcomers.\nAny other suggestions?\n. Examples testing works now but compiletest fails because there are multiple matching crates for 'diesel_codegen' in the target/debug/deps/ directory. Any ideas how to fix this?\n(I tried creating a workspace just for the compiletests but cargo complains about diesel_codegen being in another workspace then)\n. @sgrif Removing doesn't work because of\nerror: current package believes it's in a workspace when it's not:\ncurrent:   /home/bobo1239/development/Rust/diesel/diesel_compile_tests/Cargo.toml\nworkspace: /home/bobo1239/development/Rust/diesel/Cargo.toml\nor rather\nerror: package `/home/bobo1239/development/Rust/diesel/diesel/Cargo.toml` is a member of the wrong workspace\nexpected: /home/bobo1239/development/Rust/diesel/diesel_compile_tests/Cargo.toml\nactual:   /home/bobo1239/development/Rust/diesel/Cargo.toml\nafter a separate workspace is introduced for the compiletests.\nI'll try to somehow find out which files are present in target/debug/deps and then think of an appropriate course of action.\n. @killercup Any idea why the version with env doesn't work?\n. @killercup That makes sense though Rust 1.12 is out so we don't need the conditional anymore anyways.\nI just saw the Macro 1.1 PR and will probably postpone updating this until it landed.\n. Hitting the multiple matching crates for diesel problem again... I excluded the compile tests from the workspace as I don't know any way to fix this other than manually deleting the lib files which is imo too hacky.\n. insert_into is new and hasn't been published yet (see changelog). The documentation link in the readme tracks the master branch whereas the docs for the released version can be found on e.g. docs.rs.. @NotBad4U Hm, I'm getting the same error. Unfortunately I don't know what the problem is. Sorry.. @killercup Somehow I'm unable to get this right... I tried [...] && env TRAVIS_RUST_VERSION=$TRAVIS_RUST_VERSION ./test_stable but the variable is lost in the script. (even when only adding a space [...] && TRAVIS_RUST_VERSION=$TRAVIS_RUST_VERSION ./test_stable)\n. ",
    "Thomasdezeeuw": "@sgrif your example helps a lot to understanding the embed_migrations macro, maybe it's worth adding it to the docs?. I didn't see that, I was using local (outdated) documentation. Great that it's in!. It took me too long to figure this out so this is the code required:\n```rust\nno_arg_sql_function!(RANDOM, (), \"Represents the sql RANDOM() function\");\n// Usage, using the post schema from the getting started guide.\nlet results = posts\n    .order(RANDOM)\n    .limit(5)\n    .load::(&*connection)\n    .expect(\"unable to load posts\");\n```\nWhich will generate the following query:\nsql\nSELECT * ORDER BY RANDOM(). ",
    "azerupi": "Yeah I figured there would an easy way to load sql files in the db. Maybe that wouldn't add enough to be worth implementing.. \nWhat about the csv idea? Would that make any sense? In my head it seems easier to maintain a csv file with a couple of entries than a sql file when your database evolves often. But then again, I have very little experience :wink: \n. @sgrif would there be another format more suitable for this task or is it just not worth the effort in general?\n. ",
    "TedDriggs": "I got bitten by this, and also discovered that I had to blow away my target directory after fixing the up.sql file for the Rust struct to work as expected.. ",
    "zhangsoledad": "This is big big gotcha\uff01\uff01. ",
    "willmurphyscode": "I'd like to help with this, but I'm not sure exactly how to get started. @sgrif mentions in https://github.com/diesel-rs/diesel/issues/573 that we don't want to talk to the database when running the linter. Should this linter inspect the structs and the .sql files in the migrations? If so, will the linter need to find both CREATE TABLE and ALTER TABLE calls and figure out what the table currently looks like?. > It's coming from the glob import on diesel::types::*. diesel::types::ops is not internal, it's public API. we just need a more scoped import.\nI'd like to work on this but I could use a hand getting started.\nAm I correct in thinking that https://github.com/diesel-rs/diesel/blob/6b4013d5e65fc4d988257afec403ad7db00882fa/diesel/src/macros/mod.rs#L275 is where we need to import something more specific? What should the import be?\nAlso, it looks like we're looking for imports of diesel::sql_types::* now, since there aren't diesel::types any more, after https://github.com/diesel-rs/diesel/commit/b95c9d2b0d78dbe597ade51f35dcee4130235399, correct?\n. Is there work left to be done on this issue? It looks like there are two merged pull requests, one of which specifically addresses #[derive(Insertable)]. . Is anyone presently working on this? If not, I'd like to volunteer to give this a try. . It looks like the diesel_tests project failed to build on Windows for Postgres. I'm a bit surprised, since I would expect this change either to succeed or to fail everything everywhere. \nI'm also surprised that this build: https://ci.appveyor.com/project/sgrif/diesel/build/1.0.1006 passed while this build: https://ci.appveyor.com/project/sgrif/diesel/build/1.0.1007 failed when the commit between them was this: https://github.com/diesel-rs/diesel/pull/1145/commits/c0bbc9f55263c95d514236c796e9c1965ab5f2f8 which has only a whitespace change. \nI'll attempt to repro this myself, but honestly my Windows computer is not set up for development at all, so I could use a little bit of assistance. (Also, it might be worth investigating a pipeline issue, since apparently a whitespace-only commit broke a build.) . It looks like https://github.com/diesel-rs/diesel/pull/1146 is failing CI builds with the same error, but also failing them for Postgres on Linux, not just Windows. . @dikaiosune It looks like https://github.com/diesel-rs/diesel/pull/1145 is failing with the same error, which makes it seem like indeed some change outside these two PRs is causing the failure. \nI can repro this Linux failure locally, but I haven't been able to pin down the cause yet. . This line, and others in the same file, were not caught by bin/test. I changed them anyway, because it seems like they should have been caught by bin/test, and I assume future development might make bin/test catch them.. Also, this line and the other line in this file were not caught by bin/test, but I changed them because I assume they should have been linted the same way as the rest of the code, and in the future they might be. . Thanks! I must've missed that one. I'll push up a change in a minute. . ",
    "stephen-standridge": "That did it @killercup, thank you! This is my first rust project, so I'm still learning many of the debugging skills. Now I know version management is an active process with cargo.\n@sgrif Thank you!\nI'm really glad this project exists and that you all are so responsive with it!\n. ",
    "devinrsmith": "I'm just getting started and have been having a bad time. I've been following the current guide http://diesel.rs/guides/getting-started/ using the specific rust nightly. This issue is specifically labeled as \"out of date\", but I was under the impression that given rust's semantic versioning, old rust examples should just work.\nBut it won't even start compiling.\nsh\n$ cargo build\n    Updating registry `https://github.com/rust-lang/crates.io-index`\nerror: Package `diesel_codegen v0.7.0` does not have these features: `nightly`\nRemoving the nightly feature from the toml gets a bit further, but quickly runs into compile errors:\nsh\n/Users/dsmith/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv_codegen-0.8.1/src/dotenv_macro.rs:13:66: 13:80 error: type name `ast::TokenTree` is undefined or not in scope [E0412]\n/Users/dsmith/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv_codegen-0.8.1/src/dotenv_macro.rs:13 pub fn expand_dotenv<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                                                                                                                                                                           ^~~~~~~~~~~~~~\n/Users/dsmith/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv_codegen-0.8.1/src/dotenv_macro.rs:13:66: 13:80 help: run `rustc --explain E0412` to see a detailed explanation\n/Users/dsmith/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv_codegen-0.8.1/src/dotenv_macro.rs:13:66: 13:80 help: you can import it into scope: `use syntax::tokenstream::TokenTree;`.\n/Users/dsmith/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv_codegen-0.8.1/src/dotenv_macro.rs:25:50: 25:64 error: type name `ast::TokenTree` is undefined or not in scope [E0412]\n/Users/dsmith/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv_codegen-0.8.1/src/dotenv_macro.rs:25 fn expand_env(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                                                                                                                                                           ^~~~~~~~~~~~~~\n/Users/dsmith/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv_codegen-0.8.1/src/dotenv_macro.rs:25:50: 25:64 help: run `rustc --explain E0412` to see a detailed explanation\n/Users/dsmith/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv_codegen-0.8.1/src/dotenv_macro.rs:25:50: 25:64 help: you can import it into scope: `use syntax::tokenstream::TokenTree;`.\nerror: aborting due to 2 previous errors\nI'm new to rust, so I'm not sure where to turn to next. I'm not sure where the issue lies. Is this an issues with diesel? Is this an issue with a dependency? Is the guide in error? Did somebody break the semantic versioning rules such that the example no longer works now? If so, can the example be updated with very specific versions to get things running? Am I using the wrong nightly?\nWhen a large public project such as diesel doesn't compile, especially given a \"getting started\" guide, it reflects poorly on rust IMO. Hoping this can be resolved quickly!\n. ",
    "Emilgardis": "@devinrsmith\nA breaking change to ast caused this (see slapresta/rust-dotenv#44).\nHowever, another error pops up after that will in some time hopefully be fixed with #426, but meanwhile to use all of this replace your dependencies section with\n[dependencies]\ndiesel = { git = \"https://github.com/SergioBenitez/diesel\" }\ndiesel_codegen = { git = \"https://github.com/SergioBenitez/diesel\", default-features = false, features = [\"postgres\"] }\ndotenv = {git = \"https://github.com/slapresta/rust-dotenv\" }\ndotenv_macros = {git = \"https://github.com/slapresta/rust-dotenv\" }\nThis solution is not pretty, but it works. These problems come from that diesel only \"supports\" new nightly releases with steps of 6 weeks. \nI've also just started using diesel, and this was a huge :-1: for me. But the problem is really on our part, nightly is not stable after all. (Protip: If you want to skip all the mess, with rustup run rustup default nightly-2016-08-18, or if you don't have rustup, install it.)\nAs a sidenote, the getting started guide is probably one of the best I've seen, I even learnt something new about how cargo treats --bin.\n. This was my first comment on diesel (?). And I can understand the decision you've made, it makes sense. \nEdit:: To add some value to this comment, what do you think of the idea @killercup had?\n. I considered sorting the (un)signed types properly, but I thought it wouldn't really matter.\nAlso, should we care about columns like \"i32\"?. ",
    "belst": "I do like the way serde solves this: https://github.com/serde-rs/serde/blob/4a0bf4de65b7787088c6c6ce3cc3b69fc1cc1a16/serde_codegen_internals/src/attr.rs#L109\nbasically it would look like this:\n```\n[derive(Queryable)]\nstruct Foo {\n    id: i32,\n    #[diesel(rename=\"type\")]\n    type_: String,\n    foo: bool,\n}\n```. ",
    "nambrot": "I'm a newbie to Diesel, but is there any recommended workaround for having columns named type right now?\nI'm trying to connect to just a specific table to avoid that problematic column by using infer_table_from_schema! but then get \nerror[E0412]: cannot find type `Datetime` in this scope\n --> src/schema.rs:2:1 . ",
    "Fiedzia": "\nThe consensus was that there's not really a strong motivation for this feature in terms of general renaming of columns.\n\nIt is necessary when working with existing databases. The table names are often out of touch with reality (or reality of specific application), but cannot be changed, they may be inconsistent and we want consistency in codebase, or were automatically generated and we want human-friendly names for them in our app.\nI've seen all those cases and I can't imagine an ORM that can't cope with that. To rephrase: I have no control over a database, and I want to use an ORM. Therefore ORM should be able to fix as many db issues as possible.\n\nany code which does successfully compile but doesn't have the name you want can always be renamed in Rust by pub use foo as bar\n\nThis is a) horribly ugly and b) involves looking at (and changing) two places instead of one, while every single ORM I've ever worked with this was always stated once at the place of model definition, Therefore it has the horrible feature of surprising users.. I am planning to use diesel, but I haven't yet, so +1 for changing it now. Compile time matters to me.\nIs the columns! as intuitive as I think (not being familiar with diesel)? In that case I am definitely for it.. The naive solution would be to add some form of \"real name\" as foo -> Integer,\nbut ideally table! enhancement should take into account other things one may want to set there.\nI consider Django ORM to be a golden standard in this regard because it incorporates\na lot of domain knowledge in this aspect (among other reasons), and for example here are some of the things it allows to set in field definition:\n\nnullability\ncan the value be blank\nchoices (this one is also important for me)\ncolumn name\nif an index should be created for this field (multifield indexes are property of a table)\ntablespace\ndefault value\nif it is primary key (multifield indexes are property of a table)\nhuman-readable field name\nvalidators\n(some other django-related bits I'll ignore here)\n\nas well as properties specific for particular field type:\n\nprecision (for decimal fields)\nmax_length for text fields\n\nhttps://docs.djangoproject.com/en/1.11/ref/models/fields/\nPerhaps not all of it makes sense for Diesel, but I'd prefer to have generic and extensible solution for setting field and table attributes.\nAs  for syntax, I'd suggest something similar to Django:\nrust\ntable! {\n    users {\n        id -> Integer(primary_key: true),\n        name -> VarChar(db_column: \"username\", max_length:120),\n        properties:\n            indexes: ...\n            db_table: \"user\"\n    }\n}\n(I find \":\" more readable than \"=\")\n.  > #[database_name=\"username\"]\nI don't mind the format for setting attributes, but I'd prefer to call this attribute column_name or database_column_name - that makes clear what it does even for someone not familiar with diesel. \n\nI'd also like to see a concrete proposal for the conventional renames for Rust keywords.\n\nDjango adds _field sufix in this case. Since Diesel uses column name, that would be _column.\nhttps://github.com/django/django/blob/master/django/core/management/commands/inspectdb.py#L202\nHowever, this is inconsistent with column names being numbers, which need to prefixed, so perhaps just always prefixing would be better. Therefore my proposal would be:\n\"mod\" => column_mod\n\"12345\" => column_12345\nI'd be happy if whole normalization (and adding comments to explain it) would be stolen from Django.. You will need to have some convention, interact with user or generate code that doesn't compile (as it is now). Of those three, I'd definitely prefer convention. Interacting with database tool for some large database is not something I'd enjoy doing. I am working with a system that has dozens of databases and thousands of tables. I have no idea how many of those are not valid identifiers in Rust, but I do not want to go through all of them and make a decision how it should be renamed for every case.. > Why should we special case numbers but not spaces? \nMy opinion is that Diesel should handle everything - I've linked to Django as it covers a lot of cases (I am not sure if all, but many more than just numbers and keywords).\n\ninfer_schema! does not need to handle absolutely every possible edge case, as long as we provide the tools for users to make it work\n\nThe problem is that this can be extremely tedious and user-unfriendly work. There is no point in users doing it at all.. > I agree, which is why the overwhelming majority of the time, you won't see column names that aren't valid SQL identifiers.\nThey do exist though, I can't ignore that, and I want the tools I am using to deal with that without involving me. I do not want for example to break my build scripts just because someone decided to add some column that Rust doesn't like. This is trivial problem to solve and I see no reason why a database tool should ever expose such issues to users. Perhaps look at this in context of creating web project as a whole, which includes using multiple tools. Preferably all of them should work as smoothly and automatically as it is possible.. Great, thanks.. I'm not sure about those 14 commits, but I've fixed all other issues.. > I'm not entirely sure what the semantic differences of these types are\nNone I believe. If I read MySQL docs correctly, Mysql will handle them differently on the server side (at storage level), but there is no difference in the transport layer. At storage level those types simply differ in allowed max size.\n\nWhat use cases does this add for you?\n\nSchema generated by diesel print-schema compiles. Also I'd like to have ability to generate create table sql from diesel schema definition (I am not sure if/how that works yet, but being specific here would help in achieving that). . This is part of solution for #830 \n. Could we have it as an example in the docs and tests?. UserId as an example of having custom type, explaining what one needs to do\nto achieve that.\nOn 13 Jul 2017 17:27, \"Brandon W Maister\" notifications@github.com wrote:\n\nHave what as an example in which docs/tests?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/1014#issuecomment-315130591,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAOrM_xF-t-eyd4zwpzqVRHLIIhgLncwks5sNkVzgaJpZM4OTBE5\n.\n. Exactly. I've updated docs and I am not reexporting BigDecimal anymore. I'll will still need to add tests.. I've enabled pg tests for mysql. Its me. I did git pull --rebase upstream master . I had conflicts and I resolved them with no particular issues.. I believe I resolved all issues, builds are failing due to problem with rust nightly:\nhttps://github.com/rust-lang/rust/issues/43153. Linking the original issue here: #830 . \n",
    "SergioBenitez": "I understand the desire to not want to track nightly with a rigid schedule. Not doing so is okay with me. I like where your idea of a compromise is heading. My main issue with the policy is that it seems that it specifically does not allow changes to support newer nightlies than those released on the Rust schedule.\nWhat if the policy is to simply work with some recent nightly version without a schedule? That is, the README can simply say: \"last tested nightly release: 9/05/2016\". This way, contributors can keep Diesel up to date between Rust releases without @sgrif worrying about it. I don't have much of a preference as to how version numbers fit into this idea.\n. @sgrif What is your decision on this PR? I'm proposing that you accept changes to bring Diesel up to date with the latest nightly, not that you keep Diesel up to date with the latest nightly. This means that those of us that want to use Diesel on the latest nightly can do so without burdening you with the maintenance required to keep it up to date.\n. Any update on this? Just hit this bug.\n. @sgrif That seems like a direction that might take some time, if it is resolved in your favor at all. The issue seems to be that a recent change put macros and derives in the same namespace, thus Queryable! and [derive(Queryable)] collide. It does not seem like it would be onerous to rename one of the two, presumably the macro, to something different. Alternatively, you could provide a duplicate macro with a different name (say, Queryable_) that is only used for code generation so that Queryable can still be used by others. This would resolve the conflict while keeping the ergonomics you're presumably aiming for.\n. I found it confusing that different \"options\" parameters had the same name. I think having different names makes the code easier to read and grep later. . Sure. That's rustfmt, by the way. . Failures are unrelated to these changes.. Done.. @killercup Indeed, this issue is resolved. Unfortunately another sprung up, but I'll deal with that in a different issue tracker. :)\nThanks for being quick about this, @killercup, @jgallagher!. Any chance you'd be willing to push a point release with this change? Due to the linking restrictions for -sys libraries, this is preventing updating other libraries.. > That said both, rocket and uuid have not reached 1.0 yet. That means if you decided to use them you should except breaking things here. (To be clear: It is absolutely ok for them to do this changes, but don't expect a library that has declared some form of stable feature set to follow them.)\nTo be clear, strictly speaking, it is not okay, in Rust, for pre 1.0 libraries to have breaking changes between 0.v.a and 0.v.b releases, where b > a. In other words, all 0.v.x releases must be backwards compatible. Rocket takes this very seriously and, to my knowledge, has never violated this guarantee.\nI don't have any particularly good ideas about how to resolve the issue at hand, unfortunately. ~~Perhaps Rocket can widen the accepted range of uuid.~~ Unfortunately this isn't a possibility with Rocket as Rocket's Uuid type derefs into the uuid crate's Uuid, so any breaking changes are inherited.. @terry90 The problem, as I stated, is that the wrapper derefs to the internal type, revealing all of its methods. So, if the internal type changes due to a version bump, Rocket user's code breaks.. It has not been released. As such, we'll need to point to Git for the time being.\n. Even with the local override, this is required because version 0.7.3 hasn't been published to crates.io. From the Cargo documentation:\n\nNote: using a local configuration to override paths will only work for crates that have been published to crates.io. You cannot use this feature to tell Cargo how to find local unpublished crates.\n. I changed the version numbers to 0.7.3 given that this is a breaking change.\n. It's not a breaking change in the semver sense, I believe. I bumped the version since 0.7.3 will work with the latest nightly while 0.7.2 will not.\n. \n",
    "pop": "Forgive my ignorance, I am new to the world of Rust and have much to learn, but is there a reason Diesel doesn't just track Rust Beta?\nIt seems like Diesel verifies it works on Rust's six weeks release cycle (which is how often Beta is updated), but instead of running rustup default beta a developer has to rustup default nightly && rustup override set nightly-XXXX-YY-ZZ.  Just seems like unnecessary hassle and an easy way for newbies to make mistakes.\nSince Diesel has become the defacto & most stable Database ORM it might be worth considering tracking something more stable than an outdated nightly.\n. NVM, fixed in PR #426. This can be closed.\n. ",
    "Zarathustra30": "Ah. I did do the migration specified in Getting Started:\nCREATE TABLE posts (\n  id SERIAL PRIMARY KEY,\n  title VARCHAR NOT NULL,\n  body TEXT NOT NULL,\n  published BOOLEAN NOT NULL DEFAULT 'f'\n)\nBut now that I look at it, I see serial right there. Which I now realize needs to be an Integer.\nNow that I have fixed it, I'm getting completely different error messages, which is always a good sign.\n. ",
    "bronson": "I also hope for the ability to print the schema.  Rails's schema.rb has saved my bacon a number of times when migrations diverged for whatever reason ( a dev ran a migration on a branch but it changed when hitting master, etc).\nCommitting schema.rb to the source tree makes it really easy to see if the user's database matches what the code expects.  Without it, database issues become more of a poke-and-pray operation.. I just hit this too, couldn't finish step 1 in the getting_started guide.  Ah, nightlies!\nLooks like rustc needs a little more time in the oven...  I'll try again in a few weeks.\n. Oh good.  I'll try again in a few days.\nHow far back to I need to go if I want to keep going tonight?  Maybe a month old nightly?\n. rustup toolchain install nightly-2016-11-06, thanks!\n. Hm, late oct / early nov only appear to work on Linux.  Getting consistent ICEs on Mac:\nthread 'rustc' panicked at 'index out of bounds: the len is 363930 but the index is 363930', ../src/libserialize/leb128.rs:47\nnote: Run with `RUST_BACKTRACE=1` for a backtrace.\nowell, I'll try again in a few days.  sgrif, just curious: which platform to you use for Diesel dev?\n. Yep, that worked!  Thanks for ignoring my attempts to give up.\n. Right on, looks great.  cargo update and everything works again.. And the error is pretty darned confusing:\n``\nerror:#[derive]` for custom traits is not stable enough for use. It is deprecated and will be removed in v1.15 (see issue #29644)\n --> src/models.rs:1:10\n  |\n1 | #[derive(Queryable)]\n  |          ^^^^^^^^^\n  |\n  = help: add #![feature(custom_derive)] to the crate attributes to enable\nerror: aborting due to previous error\nerror: Could not compile diesel_demo.\n``. Same thing withsrc/models.rs` in step 2, \"We'll want a struct to use for inserting a new record.\"  It's not clear that the new code should integrate with the existing.. Thank you, I'll submit PRs there.. ",
    "marcusball": "Regarding a reason why one might not want to use infer_schema!: I believe this subcommand would solve an issue I encountered a few weeks ago\u2014correct me if this wouldn't. \nI wanted to write a small utility for an existing production database, so I decided to try diesel for it. However, infer_schema! failed for me because some of the tables in the existing database are (or were) unsupported by diesel because they had zero or 2+ rows constituting primary keys. This subcommand\u2014and, admittedly, knowledge of the table! macro\u2014would have helped me only interact with the specific tables I wanted, rather than having to infer the whole database schema.  . I don't know about using rustc_serialize, but if you use serde, I think you could use the #[serde(serialize_with = \"path\")] attribute to specify the function that should serialize the timestamp field. You can then use the aforementioned time_to_json function, or something similar, to create the string for serialization handler. \nEdit: I'm dumb, this is not necessary at all. If you're using chrono, you can just add either of the features \"serde\", \"rustc-serialize\" to the chrono dependency.. The error I'm getting is: \n```\ndocs.diesel.rs uses an invalid security certificate. \nThe certificate is only valid for the following names: www.github.com, .github.com, github.com, .github.io, github.io, *.githubusercontent.com, githubusercontent.com \nError code: SSL_ERROR_BAD_CERT_DOMAIN\n```\nThis is probably a transition to the custom domain on Github Pages. . ",
    "golddranks": "Let's say that I have to build my project in some environment that, for reason or another, I'm unable to install Postgres in. Does this make possible for me to print the schema as rust source code in my dev environment, and distribute that as a source code file to get rid of the Postgres dependency in the build environment?. @nkhinchi Do you have the .env file or the environmental variable set up? That looks more like it's missing.\n. I used chrono::DateTime<UTC>, (you might have to use NaiveDateTime) in my model structs. It has the to_rfc3339() method, which outputs strings that is easily parseable in JavaScript. The pain in the ass is that chrono::DateTime<UTC> doesn't serialize to the rfc3339 format by itself, so you have to have some kind of workaround: for example a struct with chrono::DateTime<UTC> for fetching from the database, then convert that to struct that is identical to that but stores the timestamp as a String, and then serialize that to JSON.. Btw. I've issued an issue in chrono repo some time ago to highlight the awkwardness of serialization to JSON. https://github.com/lifthrasiir/rust-chrono/issues/115. I prefer using timestamptz in my schema, so I don't have to stick the timezone later on. That looks correct but don't take my word for it :D. I think that the question in a sense was: which types to use in application code models that are compatible with PgTimestamp and easily convert to JSON.\nTo that question the answer seems now clear: use chrono::DateTime and Swede for serializing, that works out of the box.. Serde, not Swede. Damn you smartphones XD. You have to derive the trait Associations for the structs corresponding to the joined tables. You have to also annotate the structs using belongs_to and has_many attributes. Without those annotations the tables won't implement the JoinSource traits.. I'm not 100% sure about the problem because the error message isn't too descriptive, but at least has_many annotation should have the name of the DB table, not the name of the struct. (belongs_to has the name of the struct, as you currently have.) I don't know why, and I know it's annoying that they are asymmetric in that way, but try fixing that. (@sgrif and @killercup: is there any intuitive reason that helps us to be convinced like \"of course it should be that way\"?). You might want to add foreign_key annotations too. The table likes having no own id field may cause it to be confused about which fields to use.\nAlso, the error message sounds like it's infering the types wrong. Is there anything external that might make it expect users instead of posts? What is the type of user_id in the filter clause?. Note that the default percent encoding of the url crate doesn't encode every special characters in URLs. You need to define your own encoding for them. (For reference: https://github.com/servo/rust-url/issues/353 )\nIn my experience, Postgres doesn't like having the character $ in the URL; the URL doesn't work if one's password contains $.\nHere's an encoding set I defined in my code to circumvent the problem. Feel free to use:\n    define_encode_set! {\n        // This encode set encodes all the reserved URL delimiters defined\n        // in [RFC3986](https://tools.ietf.org/html/rfc3986#section-2.2).\n        // Contains the `SIMPLE_ENCODE_SET` and additionally characters :,\n        //  /, ?, #, [, ], @, !, $, &, ` , (, ), *, +, ,, ;, =\n        pub RESERVED_ENCODE_SET = [SIMPLE_ENCODE_SET] | {\n            ':', '/', '?', '#', '[', ']', '@', '!', '$',\n            '&','\\'', '(', ')', '*', '+', ',', ';', '='\n        }\n    }\n\n. ",
    "durango": "I'm wondering if setting the search_path would alleviate this issue:\nsql\nSET search_path=public,tiger,postgis;\nOn that note, it would be important to specify which schemas diesel should infer (inferring tiger or postgis would be a waste)\n. Try declaring &*database::connection().get().unwrap() and use the same connection for each statements. I believe so, is everything all sorted out for you?. This can be closed now, since it's done :+1:. ",
    "paulhandy": "Thank you. I glazed over that part about the nightly version.\n. ",
    "pka": "After an hour or two of trying to compose a query like this, I gave up and looked through all issues finding this solution on page 15 of the closed tickets\nThis deserves a hint in the documentation (or a more prominent one, in case it's already documented). The ability to compose queries programmatically in a readable way is a fundamental advantage of an ORM compared to raw SQL. Thanks for this great library!. What about a sentence in the Getting Started guide like \"In cases where you want to conditionally modify a query, use into_boxed to box the pieces of a query into a single type.\"?. ",
    "tredoe": "I'm supposed that is the problem.\nWhat there is to write in Cargo.toml to enable it? I could not find in doc.\n. The error that I get is like\nerror[E0277]: the trait bound `(...)>` is not satisfied\n. I had in Cargo.toml:\ndiesel = \"^0.8\"\ndiesel_codegen = { version = \"^0.8\", features = [\"postgres\"] }\n. It works now using:\ndiesel = { version = \"^0.8\", features = [\"large-tables\"] }\ndiesel_codegen = { version = \"^0.8\", features = [\"postgres\"] }\nThanks!\n. ",
    "mattdeboard": "Actually I guess this answers my other question. Hi, so the trouble I'm having is that any table with more than 24 columns (these are extant tables) throws this error. I can run diesel print-schema fine. It outputs the right schema. So since apparently !infer_schema(\"dotenv:DATABASE_URL\", \"foo\") is equivalent to diesel print-schema -s foo I'm surprised this isn't working correctly.\nI tried doing diesel print-schema -s foo > src/models.rs but even then, when I do cargo run, the compiler complains about the recursion limit. Can you explain what the problem is exactly?\nedit: Ok apparently the answer is this is a limitation of Rust itself. Here is an explanation with pointers to more detailed explanations.. @Kazakuri Ya I have added that to the top of my main.rs but it's still happening. Any idea?\nAlso I added the huge-tables feature to diesel, but STILL getting the error. There are less than 52 columns on the table :-. ",
    "robsaunders": "The error for this is so ambiguous it's kind of ridiculous. Hopefully rust improves, removes this limitation for enums, and people stop using huge macros as fundamental functionality in their libraries.. ",
    "oeb25": "FYI using the macro around the struct results in the same error eg.\nrust\n// src/models.rs\nQueryable! { struct Thing { ... } }\nbash\nerror: `Queryable` is a derive mode\n --> src/models.rs:3:1\n  |\n3 | Queryable! { struct Thing { ... } }\n  | ^^^^^^^^^\nhaving\n``` rust\n// src/lib.rs\nextern crate dotenv;\n[macro_use] extern crate diesel;\n[macro_use] extern crate diesel_codegen;\nuse diesel::prelude::*;\nuse diesel::pg::PgConnection;\nuse dotenv::dotenv;\nuse std::env;\npub mod schema;\npub mod models;\n```\nAny update on this? I read jseyfried's comment on the issue on the rust repo, but I'm not entirely sure what this means for Diesel.\nDoes this require a change in Diesel, user code or are we waiting for a fix in rust?\n. ",
    "ruipserra": "Yeah, that makes sense. I'll update the PR later today, or as soon as time permits.\n. Hi @killercup, I'm so sorry, I completely forgot about this one. I'll try this again soon, but for now I'll close this PR.. ",
    "Shtong": "I did not have it in the path at the time I wrote the issue. I just made another test adding sqlite3 to the path and it allowed me to skip the \"add sqlite3 the the LIB envvar\" part, although using SQLITE3_LIB_DIR is still required to compile libsqlite3-sys.\n. I'll see if I can find where that lib name (pq.lib) comes from, that will be an occasion to learn rustc! As for sqlite3, since it's not required for the tutorial, maybe the tutorial should be updated to install diesel-cli without sqlite support (replacing cargo install diesel_cli with something like cargo install diesel_cli --features postgres)\n(sorry for the close, clicked the wrong button)\n. ",
    "viperscape": "@sgrif I know this is closed, but I am receiving linker errors when building with diesel for postgres. Interesting, I can use the rust-postgres lib without issue. Any news on the new pg driver for diesel? Thanks. ",
    "spasius": "Linker takes errors when building with diesel for postgres on Windows 7 64-bit, both stable and nightly.\nrust-postgres works fine.. ",
    "gbip": "I can't build diesel for sqlite on windows 10 64 bit with the stable and the nightly toolchain.\nLINK : fatal error LNK1181: cannot open input file 'sqlite3.lib'\nI tried adding the sqlite dll in .rustup\\toolchains\\nightly-x86_64-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib, but I have no idea how to get sqlite3.\nIt seems that this link present some steps to correctly setup sqlite3.. ",
    "spease": "I'm also getting this error. I was able to generate sqlite3.lib, but I don't know how to set the libpath arguments for the linker.. Figured it out.\nAs admin:\nchoco install sqlite3\ncd C:\\ProgramData\\chocolatey\\lib\\SQLite\\tools\nlib /def:sqlite3.def /out:sqlite3.lib\nAs dev user:\ncd C:\\ProgramData\\chocolatey\\lib\\SQLite\\tools\ncargo install --no-default-features --features sqlite. You might be able to simplify those instructions if you use chocolatey to install sqlite. Of course, that assumes you have chocolately installed.\nThat being said, a cholocatey package that provides the lib would make it virtually painless if you had chocolatey installed. Is there a license-related reason for it not being provided with SQLite?\nI can\u2019t help but think there should also be a better way...eg have the application check for the library and generate it using the above commands if needed. But I don\u2019t know enough about the executable format to know if it\u2019s impossible to execute any code before it attempts to load dependant libraries.. This is fantastic. Just realized this is probably easier than i thought - the \"bundled\" feature is actually on libsqlite3-sys. So you can do\nlibsqlite3-sys = { version = \"0.9.1\", features = [\"bundled\"] }\nWould still be nice if this was a diesel feature for convenience purposes (not sure if it could apply to postgresql if it's enabled, but that would make sense). It should definitely be documented somewhere. . Take a look at my post just above yours. If you include that in your Cargo.toml in addition to diesel, diesel will use libsqlite3-sys with the bundled feature and it should obviate the need for messing with the DLLs and libs. That's what I used to get diesel working with our CI system.. The serde documentation does a good job of enumerating attributes:\nhttps://serde.rs/\nIn general one problem I've run into has been understanding what the diesel API is. I've been using the generated documentation, and it seems to lack descriptive text for many things, eg load vs get_results.\n\nOn Apr 20, 2018, at 02:54, Georg Semmler notifications@github.com wrote:\nThere is not much we can do about this. The table! macro is just a plain macro_rules macro that gives us no way to emit custom error messages.\nThe documentation of the table! macro already mentions #[sql_name=\"\u2026\"] so I'm quite unsure what else we could do to improve this. In my opinion the only improvement that could be done is to add more documentation on this. The questions is where and what.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I didn't realize there were that many derives - I've seen FromSql and ToSql, and I think there's a AsExpression trait that it looked like I had to use with them. However, in general, I've had to do a lot of digging through source code to understand how to do things, more digging than I would expect most people would do before they give up. There seems to be a sore deficit of application-related examples.\n\nIn general, I'd try to keep an \"interface\" (whatever that may mean) as simple as possible, but if it has to be complex, I'd definitely expect to need a fair amount of documentation. In general I'd expect a larger API would require more specialized documentation, not less (that being one reason I'd try to keep it as small as possible ;) ).\nI understand you guys have limited time and probably aren't being paid, I'm just a little worried about the balance of functionality to documentation. There's a lot of functionality that exists, I suspect I can do pretty much everything I want with diesel, but it's often very difficult to figure out how.. ",
    "ForsakenHarmony": "@sgrif what happened to that postgres driver?. ",
    "shawntabrizi": "I think the best way to address this issue now is following these instructions:\n\nIf you are using a system without an easy way to install sqlite (for example Windows), you can use a bundled version instead:\ncargo install diesel_cli --no-default-features --features \"sqlite-bundled\". \n",
    "mZbZ": "\nSince this page is ranked high when you search for \"diesel sqlite windows\":\nFor reference , if you want to install diesl_cli for usage with Sqlite, you:\n* download the precompiled Windows binaries from https://sqlite.org/download.html\n\n* extract them to a folder (i.e. `C:\\sqlite64`)\n\n* run a cmd terminal with the 64bit msvc toolchain in the path: \"Win + R\" and execute `%comspec% /K \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat\" amd64`\n\n* `cd C:\\sqlite64` and run `lib /def:sqlite3.def /out:sqlite3.lib`\n\n* add  `C:\\sqlite64`  to `PATH`\n\n* create an environment variable `SQLITE3_LIB_DIR` also pointing to `C:\\sqlite64`\n\n* restart terminal and run `cargo install diesel_cli --no-default-features --features sqlite`\n\nNot really straightforward if you aren't a Window developer (which I'm not) but this should work \ud83e\udd1e\n\nThanks so much for this\nFor those looking for help using the gnu toolchain on windows (with MinGW), step 3 isn't necessary and step 4 becomes:\ncd C:\\sqlite64 and run C:\\path\\to\\MinGW\\bin\\dlltools.exe -d sqlite3.def -o sqlite3.a\nEverything else is the same \ud83d\ude03 . ",
    "umurgdk": "@sgrif What is the situation for point types?. ",
    "ghotiphud": "Enabling the \"large-tables\" feature fixes the compiler panic, but still getting warnings about _Dummy being defined multiple times.\n. That's alright. I was just walking through the getting started guide when I hit this, so I'm going to take a look at rust-postgres and check back later.  Thanks for your work on this, seems like it's going to be pretty awesome!\n. Docker compose doesn't wait for the DB container to start up.  Try https://github.com/vishnubob/wait-for-it. Example use in this repo https://github.com/ghotiphud/rust-web-starter. ",
    "nkhinchi": "Hi, I am getting the same error on rustc 1.14.0-nightly (cae6ab1c4 2016-11-05)\nerror: custom derive attribute panicked\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = help: message: called Result::unwrap() on an Err value: StringError(\"Failed to load environment variable DATABASE_URL: environment variable not found\")\n  = note: this error originates in a macro outside of the current crate\nerror: Could not compile diesel_demo.\nI am using code from the examples directory to test diesel.\n. Thanks, that did the trick. I was struggling with the original error before.\n. So, reverting back to diesel_codgen v0.8.1 and rustc 1.14.0-nightly solved the issue. . ",
    "noyez": "Thank you, this is indeed that case. I added the following to Cargo.toml, and it compiled successfully. \n[dependencies]\ndiesel = { version = \"0.8.1\", features = [\"large-tables\"] }\n. Trying to fix lineage of PR. It was based on master however it should be tracking the current release branch, which is currently 1.3.x. Rookie mistake on my part. . Ok. Based off master again. Sorry for the extraneous changes. \n. sure, why not? Change to use Local::from_utc_datetime pushed. . ",
    "quadrupleslap": "Pointing out the obvious, it's easy to cast it into an integer with as and match it back if you wanted to, but that removes the guarantee that values always represent the variants of the enum.. Nevermind, I found it at #335 .. Welp, never mind, there's a nullable method in ExpressionMethods that does exactly what's needed. But it'd be nice if this was somehow implicit, or easier to figure out.. ",
    "arnau": "Ah, I didn't realise I could use .ne(any(array)). Thanks!. Ah! Thanks!. ",
    "logannc": ":D\nI'd be happy to help if I can. I need to take some more time to look at the code, but would copying the SQLlite implementation and adjusting it to work with MySQL be a decent place to start?. ",
    "sbditto85": "\ud83d\udc4d . Any update on what you've done @logannc? Would it help to have someone else?. ",
    "phungleson": "Hey mate, I am trying to tackle this but it seems more complicated than I initially thought.\nDo you have any other examples rather than the one in RFC #873? or any simple ideas that I can refer to, like how the macro type might look like in the case of EqAll?. ",
    "compressed": "Thanks for working on this, really excited to see this!\nI'm okay providing the schema names by hand, I don't see that as an issue. I agree that it will make it clearer this way also, especially if you have a database with tons of schemas, but only plan on using a few.\nJust to clarify though, can we provide multiple schemas, e.g. infer_schema!(\"dotenv:DATABASE_URL\", \"custom_schema1, custom_schema2\");?. Oh I see, that works too!. Oops. Need to fix tests too.. Sure, will do.. I believe this was a breaking change. I had code that was doing something like this:\nrust\nlet mut v = Vec::new();\n// populate v\nv.insert_into(table).execute(conn);\nv.clear();\n// populate v again\n..\nNow with this impl, this code fails to compile because the insert_into is going to move v, whereas before v would have just been borrowed by insert_into. The fix is easy enough though (&v).insert_into(). Maybe makes sense to call this out more clearly in the CHANGELOG?. That sounds better to me because, looking again, patch_file and with_docs are universal options that would apply to all schemas. It would certainly make for a shorter and easier to understand file. I'm not sure if you'd want schema specific import_types (I don't use that feature currently).. ",
    "sackery": "Document in diesel.rs is so simple and not fully, it's just a guide.\n. So must to fallback to 0.2\n. @killercup how to use github version. ",
    "mujx": "Ok, I think I found a solution for the inner query, but I am not so sure how to approach the second step.\nCurrenlty it fails with \nno method name 'get_results' found for type 'diesel::query_builder::SelectStatement<..\n```rust\nlet max_ordering = max(elems::ordering).aliased(\"max_ordering\");\nlet grouped = elems::table\n    .with(max_ordering)\n    .select((elems::type, max_ordering))\n    .filter(elems::type.eq_any(vec![ElemType::Two, ElemType::Eight]))\n    .groub_by(elems::type)\n    .aliased(\"grouped\");\nlet results: Vec = elems::table\n    .with(grouped)\n    .filter(grouped.eq(elems::table.select((elems::type, elems::ordering))))\n    .get_results(connection)?;\n```\n. The relative links don't work when the links appears on multiple pages with different roots. For example with the current setup Expression and AsExpression work here but break here. The opposite will happen if the links were expression/trait.Expression.html and expression/trait.AsExpression.html.\nSo you are right that there is a need to refer to the root of the package, without hard coding it.. ",
    "mattico": "Oh, and I'm using the SQLite backend. That's probably important \ud83d\ude06 . Thanks! :+1:. ",
    "TheWaWaR": "\nINTEGER. The value is a signed integer, stored in 1, 2, 3, 4, 6, or 8 bytes depending on the magnitude of the value.\nBut as soon as INTEGER values are read off of disk and into memory for processing, they are converted to the most general datatype (8-byte signed integer).\n\nhttp://www.sqlite.org/datatype3.html#storageclasses\nSeems INTEGER should map to i64 in SQLite3?. ",
    "rbalicki2": "thank you!. Come to think of it, this is not really core to diesel's mission. It's probably better as an external library. It might need to know about diesel's Insertable, etc. derivations, but otherwise would probably be best as a separate library.. @killercup I've only ever installed the entire postgres package. If there's a way to install libpq that doesn't involve installing all of postgres, I could mention that. I figure for most users, they want postgres installed if they are going to be using the postgres features, but that may not be true if this is being used programmatically (e.g. as part of a build process). ah, the reason I suggested brew is that the mysql website doesn't really help at all :-D the \"install for mac os x\" page, for example, references a DMG but provides no links to download it.... Aaaaand it does.. ```\n546 ~/Documents/code/diesel > cargo install diesel_cli --force --features sqlite postgres --no-default-features\nerror: Invalid arguments.\nUsage:\n    cargo install [options] []\n    cargo install [options] --list\n547 ~/Documents/code/diesel > cargo install diesel_cli --force --no-default-features --features sqlite postgres\nerror: Invalid arguments.\nUsage:\n    cargo install [options] []\n    cargo install [options] --list\n```\nCan you double check that the space separate version works for you? Maybe I have something weird on my machine. (omitting either of the features allows the install to proceed). \ud83d\udc4d  awesome. will fix. Sounds good, definitely. ",
    "quodlibetor": "I believe that in order to safely run migrations you need to be using the table! macro, rather than infer_schema!, right?\nI would love to see more docs around migrating from infer_schema!, which the getting started guide uses, and towards table!, which is what (I assume) you should be using in production. Even just linking to the table! macro from infer_schema! would have helped me when I was getting started.. awesome, thanks!. @killercup you mean conditionally depending on chrono's serde feature if Diesel's serde is enabled? I think that would be reasonable, reducing the \"why isn't serde working\" stumbling block.\nIt seems like it's possible (stackoverflow example).. I'm not actually sure how the mapping from serde_json::Value -> chrono::DateTime works right now, is it mostly the To/FromSql traits? Looking through diesel's chrono code I don't see any specific benefit to enabling the serde feature. It would mostly just enable the #[derive...] calls for upstream, but if users are using chrono then they probably should just enable the feature themselves.\nSo, yeah, I don't see a a tremendous amount of benefit to auto-enabling the serde feature in chrono if not having it is fine. This PR was largely a \"oh, huh, that does work\" situation.. I agree with that decision \ud83d\udc4d. I've just implemented a DieselNewType custom derive which seems to work, although I'm not sure what stress-testing it would look like: https://github.com/quodlibetor/diesel-newtype \nI would appreciate some eyes on it (bug reports/pull requests). If the name seems reasonable and we can get it into good enough shape I'm happy to upload it to crates.io and/or move it into the diesel-rs org.. I've been wanting to create newtypes, but I've been too lazy to actually do the various From/Tos, so I just created a \"ToUnderlying\" trait that only my db modules have access to, and have been using that.\nWith this I've swapped out a couple of my IDs in a couple of structs and, like I said, it seems to do... oh you've responded.\nThose all look easy enough, thanks! I'm heading out for the weekend soon, but I should be able to implement them early next week if no one beats me to it.. I couldn't find any obvious way of verifying that my derive generates something reasonable, is there an example test file that guarantees that everything works without a db, or should I just bite the bullet and copy your db setup code?. And here I've been assuming my assumptions were great. That makes my decision making easier.. Have what as an example in which docs/tests?. Ah, yeah a \"custom types\" guide, explaining what each trait enables as you implement it, would be nice to have. I might be able to write something like that as I add tests and discover additional functionality for diesel-newtype.. I've implemented (thanks entirely to @sgrif's help) auto-queryable and auto-asexpression for diesel-newtype in quodlibetor/diesel-newtype#2. There are even tests that verify that obvious things that should work do work. If anybody wants to try substituting in a newtype using it now might be a reasonable time, although admittedly there's a decent chance that what you'd be doing is helping me debug rather than actually making your code better.. So I ran into the fact that diesel's query builder operates pretty much entirely on the SQL types of AsExpression types, which means that the current implementation of NewTypes aren't type-safe all the way through to the query-builder. Documented here in this commit. \nI haven't been able to come up with something that would allow strong typing on the rust side of the query builder and still... work... with the rest of diesel. It seems like it is by design that queries operate on SQL types. I mean, it makes sense too, it's not like it's a bad decision.\nI'm starting work on a guide around implementing columnar types, and I'm curious if that is an accurate description of the way that diesel treats rust types once they enter the query builder. Additionally, that would affect how I document diesel-newtype.. Okay so that sounds like my understanding is correct but databases may support doing it on their side. I didn't even consider that.. Technically I believe these are all Gregorian not Julian. Chrono certainly doesn't actually deal with the Julian calendar, and sqlite documents itself as being gregorian.\nI really doubt many people would be confused by the distinction unless they have to deal with Julian calendars, which is probably just historians?. Oh no. You're obviously right, I should have read the whole function before I got confused by the variables.. ",
    "jasonl": "I'll add a data point here - we're using embed_migrations! to ship our migrations to production, as we used docker as a deployment mechanism, and having everything in a single binary makes things easier. \nWe're not yet deploying multiple instances of the container, so haven't run into any potential problems with multiple instances running migrations at once, but a bit of thought says that they should be okay, and if not, the migrations could easily be wrapped with a PG advisory lock or similar.\nSo far this approach works very well for us.\n. Thanks for the quick response!. For me, the ability to join to more than one table would be amazing. I'd like to help, but a lot of the internals of diesel are way beyond my Rust ken.. ",
    "vmalloc": "For people coming here looking for an up-to-date way of embedding migrations (with diesel 1.x), the current way of doing it is:\n\nAdd diesel_migrations to your dependencie\nInclude an extern crate diesel_migrations in your crate, and make sure to decorate it with #[macro_use]\nAt the beginning of your code, add embed_migrations!()\nTo run the migrations, Use embedded_migrations::run(&db_conn). Also hitting this issue and was wondering if there is a workaround to getting it work.... I managed to work around it by replacing count_star() with diesel::dsl::sql<diesel::sql_types::BigInt>(\"count(*)\"). Yuck, but works.... I'm also wondering when this is going to get released. Hit it just now as well.. Oops, my bad. Fixed. You're right. That's a lot better.. fixed.. Fixed.. \n",
    "mattjmcnaughton": "@killercup I'd love to take a stab at this if possible (first commit in Rust)! I've modified the code to include the #![deny(missing_docs)] and am happy to submit a pr for that. Were you also envisioning this diff fixing all of those items missing documentation as well?. Sounds like a plan (and thank you for the quick response)! As I understand the code, and as I get the change, I'll make some separate prs with the documentation changes, and when the documented items are fixed, I'll make a pr that adds #![deny(missing_docs)].. ",
    "stuartellis": "I'm new to Rust, but I'd be happy to help with this.. @killercup - Thank you for that.\n@mattjmcnaughton - FWIW, I think that I'll start with just CONTRIBUTING.md and README.md files before trying anything more in-depth myself.. Just to say that I am not going to be able to work on this, unfortunately (too many projects, something has to give).. ",
    "ericho": "Sent a very simple (and probably wrong) PR #592 . Thanks @killercup I'll address the changes :smile: . Looking more deeply in the code (and trying to learn rust :smile:) it looks to me that SimpleConnection is only used on migrations as you pointed. And in migrations, only the batch_execute function is used.\nFor any new implementation of Connection the SimpleConnection trait shall be implemented as well as batch_execute in order to support migrations. \nSo, I have a couple questions:\n1. Should batch_execute be documented as well? Currently is marked as #[doc[hidden]]\n2. Why not using Connection instead of SimpleConnection in migrations?\n. I just realize that if I delete my branch the PR is closed as well :( I created the #766 \nSorry for the mess.. . What would the desired output for a failed migration run? Something like :\nRunning migration 20170308040245\nMigration on /path/to/migration/up.sql failed with : unrecognized token: \"{\"\nor \nRunning migration 20170308040245\nExecuting migration script /path/to/migration/up.sql\nFailed with : unrecognized token: \"{\"\nI'm just wondering what would be the best way and place to put the message.. And I also saw #397 should this wait until the refactor is completed?. Comments addressed from #592 \nI made a mess with my branch and I was unable to rebase. . :open_mouth: I forgot to add that file. \nNow it's there. . I make a mistake in the last commit, now the build passed \ud83d\ude04 . I can reproduce this (and possibly fix). If DATABASE_URL is not set, then you will see the error and you'll see it all the next times you run cargo build, without matter if DATABASE_URL is set or not. \nTry to run a cargo clean before running the script again. That worked for me to solve the issue.. ",
    "am0d": "Sorry for the slow response.  It seems calling the macro myself does solve the problem a little, although I would definitely prefer to have the view inferred for me to ensure at compile time that it matches the definition in the database.. Thank you, that did fix it for me.  I was still on r2d2 0.7.4, upgrading to 0.8.2 fixed the build for me.. ",
    "pfernie": "I was looking at this sort of functionality today as well (using postgres). The quick-and-dirty approach of hacking diesel_infer_schema to include table_type='VIEW' when reading information_schema.tables is insufficient, as views fail to satisfy some requirements of diesel for tables, notably having a PK. The following questions/issues are what came to mind; posting them here to get a feel for what roadmap/plan exists for supporting (read-only) views, if any:\n\nViews (at least in PG) do not support constraints (namely primary keys), which diesel requires for tables.\nPresumably, it should not be possible to, e.g., #[derive(Insertable)] on views or allow views to be involved in mutating operations.\nAs such, view metadata/schemas, etc., while largely similar to tables in terms of schema parsing/generation & usage for selects, should probably be distinct in w.r.t. types (diesel_infer_schema::view_data::ViewData, trait View, etc.).\nHowever, I am unsure how items 1 & 3 would play with the type machinery w.r.t. join semantics, etc. A superficial look suggests \"not well\", as Table and PrimaryKey are referenced much in those APIs.\n\"nullability tracking\" is not well developed in PG, meaning that inferred schemas will most likely be populated with Option fields even if the source table columns are not actually nullable.\n\nIt seems introducing inferred views could not be quickly/easily integrated; it would perhaps require the introduction of some trait or abstraction (Identifiable, Joinable?). Would it be worthwhile to implement \"basic inferred\" views that can be selected but not involved in the join API? Or does support for this warrant more thought?. I updated per the comments, although I have not put in doc tests yet.\nI may still be getting the naming wrong here; I renamed pg::types::money::PgMoney to pg::types::money::PgCents, sort of in line with that is done with e.g. PgTimestamp, etc. pg::types::sql_types::Money, however, I left named as-is to mean \"some representation of Money\". But, in client code I end up using PgCents in my structs, and it is good to know in client code that I'm dealing w/ cents... seems like I am making this too complicated. Should there only be a single struct Cents defined, instead of both pg::types::sql_types::Money and pg::types::money::PgCents? If so, should it be defined as pg::types::money::Cents and then re-exported in pg::types::sql_types? Sorry if this should be obvious...\nRE: using the name Cents; I associate cents specifically with 1/100ths, so I wonder if it's the appropriate name here since it actually depends on the lc_monetary setting (could be 1/1000th, etc.)? I understand wanting to make explicit what the struct is encoding as opposed to Money which could be any representation. I'm not sure I have a better suggestion; MoneyMinorUnits maybe?\nOnce I understand/tidy up naming I can clean up the commits on this branch and put in the doc tests as well.. Updated with a doctest and the suggested naming. This ended up being:\n pg::types::money::PgMoney exported as pg::data_types::Cents and diesel::data_types::Cents.\n pg::sql_types::Money, re-exported as diesel::types::Money\nI don't feel strongly about the choice of the Cents name, but just curious if there were thoughts on my suggestion of using a name that isn't specifically associated w/ \"1/100th\" units. Again, not sure I have great alternate suggestions; MoneyMinorUnits, SmallestMoneyUnits...? Cents maybe is just the best as it's intuitive(?) even if it's not universally accurate...\nOtherwise, let me know if I should clean up the commits on this PR to remove the various rename noise.. Makes sense; straight PgMoney export added in addition to the Cents alias.. @sgrif just wanted to see if the latest changes addressed any outstanding comments. Not trying to be pushy on the PR, just unsure what sort of visibility updates have if I don't post a comment or mention.... Good question... I cannot think of a case where wrapping or saturation would make any kind of sense, so checked arithmetic is probably the way to go. I updated the PR to use checked_{add,sub} and return Option so clients must deal with the error case. It also removes {Add,Sub}Assign as the only choice there otherwise would be to panic!. I think these are sane defaults, although obviously less ergonomic.. Very well; the ergonomics w/o the Option are definitely nicer. I implemented as such; I don't know convention for libraries and panics, I used expect() to provide some context as well as a brief \"# Panics\" doc comment.. sigh, you're right, {add,sub}_assign were not doing it checked; that's what I get for skipping \"trivial\" tests. Corrected now + proper tests; also improved the documentation. Wasn't aware of the #[should_panic(expected = \"..\"] parameter, added that as well.. The error messages weren't that great; I added a commit to make the error case more explicit by identifying the extra items in either set.\nUsing a HashSet  would require that the returned objects impl Hash, which for example schema::User in the tests currently does not. Doesn't seem like a big deal to simply add, but OTOH we're talking about small test sets here, so the less constrained (although perhaps less efficient) Vec seems reasonable? Don't feel strongly about it. That being said, the Vec approach also does allow for the slightly clearer error messages...\nIf/when this gets merged, happy to submit a later PR to perhaps move the macro up higher up in the modules and using in other tests where appropriate when I have time.. ",
    "Mingun": "\nthread panicked while panicking. aborting.\n\nVery likely that this happen because you unwrap error in Drop. I encounter with exactly such error some days ago.. Why in general the problem with positions instead of names exists? Why it is impossible just to look much at field order in DB, match their by names with fields in Rust structure once at compilation time and then use DB ordinals instead of ordinal positions of fields in Rust structure?\n. @weiznich, as far as I know, diesel at compilation looks at DB scheme. Therefore to me it is unclear why it is impossible to look at an order of fields in DB schemes, for each field in Rust structure to find its column number in the scheme and to use it instead of taking field ordinal from Rust structure. In preudocode:\nrust\nlet db_scheme = load_from_db(...);\nfor field in rust_struct {\n  field.db_pos = db_scheme.find_column(rust_struct.table_name, field.name).pos;\n}\n...\nbind_by_index(..., field.db_pos, ...);\n\nFor example what's about queries selecting the result of some function?\n\nWe speak about problems of compliance of an order of fields in the Rust structure and in the DB table from where here functions?.... I think, you can describe, than usually there will be changeset and what are T and U. ",
    "Ga1der": "rust version is 1.11.0\ncargo build gives the same result\nthis is a example from https://github.com/diesel-rs/diesel/tree/master/examples/getting_started_step_3\nwhat guide do you mean ? this one ? http://diesel.rs/guides/getting-started/ yes i did. thx it helped \n```\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>rustup update\ninfo: syncing channel updates for 'stable-x86_64-pc-windows-gnu'\ninfo: downloading component 'rustc'\n 34.7 MiB /  34.7 MiB (100 %)   5.2 MiB/s ETA:   0 s\ninfo: downloading component 'rust-std'\n 41.9 MiB /  41.9 MiB (100 %)   8.5 MiB/s ETA:   0 s\ninfo: downloading component 'cargo'\n  4.1 MiB /   4.1 MiB (100 %) 675.4 KiB/s ETA:   0 s\ninfo: downloading component 'rust-mingw'\ninfo: downloading component 'rust-docs'\n  6.9 MiB /   6.9 MiB (100 %) 991.6 KiB/s ETA:   0 s\ninfo: installing component 'rustc'\ninfo: installing component 'rust-std'\ninfo: installing component 'cargo'\ninfo: installing component 'rust-mingw'\ninfo: installing component 'rust-docs'\ninfo: checking for self-updates\nstable-x86_64-pc-windows-gnu updated - rustc 1.14.0 (e8a012324 2016-12-16)\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>\n```\nbut now i have another problem\n``\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>cargo build\n    Updating registryhttps://github.com/rust-lang/crates.io-index`\n   Compiling quote v0.3.10\n   Compiling winapi-build v0.1.1\n   Compiling pq-sys v0.2.7\n   Compiling utf8-ranges v0.1.3\n   Compiling byteorder v0.3.13\n   Compiling libc v0.2.19\n   Compiling unicode-xid v0.0.3\n   Compiling memchr v0.1.11\n   Compiling kernel32-sys v0.2.2\n   Compiling syn v0.10.6\n   Compiling aho-corasick v0.5.3\n   Compiling winapi v0.2.8\n   Compiling diesel v0.9.1 (file:///D:/idea%20projects/rust_diesel/diesel/diesel)\n   Compiling regex-syntax v0.3.9\n   Compiling thread-id v2.0.0\n   Compiling thread_local v0.2.7\n   Compiling regex v0.1.80\n   Compiling dotenv v0.8.0\n   Compiling diesel_codegen_shared v0.9.0 (file:///D:/idea%20projects/rust_diesel/diesel/diesel_codegen_shared)\n   Compiling diesel_codegen v0.9.0 (file:///D:/idea%20projects/rust_diesel/diesel/diesel_codegen)\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:40:3\n   |\n40 | #[proc_macro_derive(Identifiable, attributes(table_name, primary_key))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:45:3\n   |\n45 | #[proc_macro_derive(Insertable, attributes(table_name, column_name))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:50:3\n   |\n50 | #[proc_macro_derive(AsChangeset, attributes(table_name, column_name, changeset_options))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:55:3\n   |\n55 | #[proc_macro_derive(Associations, attributes(table_name, has_many, belongs_to))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:60:3\n   |\n60 | #[proc_macro_derive(InferSchema, attributes(infer_schema_options))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:66:3\n   |\n66 | #[proc_macro_derive(InferTableFromSchema, attributes(infer_table_from_schema_options))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:72:3\n   |\n72 | #[proc_macro_derive(EmbedMigrations, attributes(embed_migrations_options))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the proc-macro crate type is experimental\n  |\n  = help: add #![feature(proc_macro)] to the crate attributes to enable\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:35:1\n   |\n35 | #[proc_macro_derive(Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:40:1\n   |\n40 | #[proc_macro_derive(Identifiable, attributes(table_name, primary_key))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:45:1\n   |\n45 | #[proc_macro_derive(Insertable, attributes(table_name, column_name))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:50:1\n   |\n50 | #[proc_macro_derive(AsChangeset, attributes(table_name, column_name, changeset_options))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:55:1\n   |\n55 | #[proc_macro_derive(Associations, attributes(table_name, has_many, belongs_to))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:60:1\n   |\n60 | #[proc_macro_derive(InferSchema, attributes(infer_schema_options))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:66:1\n   |\n66 | #[proc_macro_derive(InferTableFromSchema, attributes(infer_table_from_schema_options))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:72:1\n   |\n72 | #[proc_macro_derive(EmbedMigrations, attributes(embed_migrations_options))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: aborting due to 8 previous errors\nerror: Could not compile diesel_codegen.\nTo learn more, run the command again with --verbose.\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>\n```. what version of rust and diesel should i use to play around with diesel today ? \n. my goal is to test how much of performance cat i squeeze out of rust+Diesel vs php+PDO. btw nightly\n```\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>rustup update nightly\ninfo: syncing channel updates for 'nightly-x86_64-pc-windows-gnu'\nnightly-x86_64-pc-windows-gnu unchanged - rustc 1.16.0-nightly (1a2ed98d3 2017-01-13)\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>cargo build\n   Compiling diesel_codegen v0.9.0 (file:///D:/idea%20projects/rust_diesel/diesel/diesel_codegen)\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:40:3\n   |\n40 | #[proc_macro_derive(Identifiable, attributes(table_name, primary_key))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:45:3\n   |\n45 | #[proc_macro_derive(Insertable, attributes(table_name, column_name))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:50:3\n   |\n50 | #[proc_macro_derive(AsChangeset, attributes(table_name, column_name, changeset_options))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:55:3\n   |\n55 | #[proc_macro_derive(Associations, attributes(table_name, has_many, belongs_to))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:60:3\n   |\n60 | #[proc_macro_derive(InferSchema, attributes(infer_schema_options))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:66:3\n   |\n66 | #[proc_macro_derive(InferTableFromSchema, attributes(infer_table_from_schema_options))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: attribute must only have one argument\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:72:3\n   |\n72 | #[proc_macro_derive(EmbedMigrations, attributes(embed_migrations_options))]\n   |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the proc-macro crate type is experimental\n  |\n  = help: add #![feature(proc_macro)] to the crate attributes to enable\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:35:1\n   |\n35 | #[proc_macro_derive(Queryable)]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:40:1\n   |\n40 | #[proc_macro_derive(Identifiable, attributes(table_name, primary_key))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:45:1\n   |\n45 | #[proc_macro_derive(Insertable, attributes(table_name, column_name))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:50:1\n   |\n50 | #[proc_macro_derive(AsChangeset, attributes(table_name, column_name, changeset_options))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:55:1\n   |\n55 | #[proc_macro_derive(Associations, attributes(table_name, has_many, belongs_to))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:60:1\n   |\n60 | #[proc_macro_derive(InferSchema, attributes(infer_schema_options))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:66:1\n   |\n66 | #[proc_macro_derive(InferTableFromSchema, attributes(infer_table_from_schema_options))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: the #[proc_macro_derive] attribute is an experimental feature (see issue #35900)\n  --> D:\\idea projects\\rust_diesel\\diesel\\diesel_codegen\\src\\lib.rs:72:1\n   |\n72 | #[proc_macro_derive(EmbedMigrations, attributes(embed_migrations_options))]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nerror: aborting due to 8 previous errors\nerror: Could not compile diesel_codegen.\nTo learn more, run the command again with --verbose.\nD:\\idea projects\\rust_diesel\\diesel\\examples\\getting_started_step_3>\n```. well, so far no luck\nbut i did run tests with sfackler/rust-postgres and results were not so impressive unfortunately\nrust-postgres is about twice as fast compared to PDO\nbut pg_connect surprisingly gives the same result so ...\nthanks for your help anyway ). ",
    "gsollazzo": "Hi! \nWhen can we expect to see this PR merged in master?\nThanks. ",
    "shepmaster": "\nrelease a 0.10.rc1 sooner :)\n\nThat would be exciting, thank you! Make sure you use a newer cargo nightly in order to send the information up to crates.io ;-). ",
    "Cobrand": "You should probably copy/paste libpq.a and .dll in C:\\\\lib\\rustlib\\x86_64-pc-windows-gnu\\lib\\\nif you don't want to copy the dll, you could edit $HOME/.cargo/config so that the linker knows where to lookup your dll, I think like this :\ntoml\n[target.x86_64-pc-windows-msvc.pq]\nrustc-link-search = [\"C:\\\\Program Files\\\\PostgreSQL\\\\pg96\\\\lib\"]\nrustc-link-lib = [\"pq\"]\nor you could specify the lookup directly in your cargo command line, like so :\ncargo rustc --release -- -L C:\\\\Program Files\\\\PostgreSQL\\\\pg96\\\\lib\nI am on linux myself so I can't say that these work for sure (at least the first one should), but at least it's something. I edited my post. ",
    "Timmmm": "I also found that the instructions in pq-sys worked, specifically set an environment variable LIB_PQ_DIR=C:\\Program Files\\PostgreSQL\\pg96\\lib worked. You have to do cargo clean after setting it.\nHow do I edit .cargo/config? Something like this?\n[build]\nrustflags = [\"-L\" \"C:/Program Files/PostgreSQL/pg96/lib\"]\n. Ah this did the trick:\n[target.x86_64-pc-windows-msvc.gnu]\nrustc-link-search = [\"C:\\\\Program Files\\\\PostgreSQL\\\\pg96\\\\lib\"]\nNo need for the rustc-link-lib.. Yeah I'm not sure. I'll build a little test app to try it.. Actually scratch that, it does work. The problem was I also had an actual environment variable set and that apparently takes precedence over .env. It was set to postgresql://localhost:5432/. Seems like a bug in the URL parser. \nIn any case, this was a bit hard to diagnose. A simple way to make it a lot easier would be to print the URL that it is trying to connect, at least for diesel setup, and ideally fix the URL parsing.\nLooks like this is the code.\nLooks like it splits on / and gets the last component, which is why it failed. Why not do proper URL parsing? Here is some nice code I have lovingly crafted using Servo's url parsing crate.\nrust\n/// Split a postgres URL into the address part and the database name, and appends \"postgres\" to the\n/// end for some reason (TODO: seems weird; why?)\n///\n/// # Examples\n///\n///\n/// assert_eq!(split_pg_connection_string(\"postgres://user:pass@domain:port/database\".to_string()),\n///            Ok((\"database\".to_string(), \"postgres://user:pass@domain:port/postgres\".to_string()));\n/// assert_eq!(split_pg_connection_string(\"postgres://user:pass@domain:port/database\".to_string()),\n///            Err(?));\n/// ```\n//#[cfg(feature = \"postgres\")]\nfn split_pg_connection_string(database_url: &str) -> Result<(String, String), String> {\nlet mut pg_url = Url::parse(database_url).map_err(|_| \"URL parse error\".to_string())?;\n\nif pg_url.scheme() != \"postgres\" && pg_url.scheme() != \"postgresql\" {\n    return Err(\"Scheme must be postgres or postresql\".to_string());\n}\n\nlet database = {\n    let path: Vec<_> = match pg_url.path_segments() {\n        None => return Err(\"Scheme cannot have paths (this should never happen)\".to_string()),\n        Some(x) => x.collect(),\n    };\n\n    if path.len() != 1 || path[0].is_empty() {\n        return Err(\"You must specify a single path element, e.g. postgres://.../database\".to_string())\n    }\n    path[0].to_owned()\n};\n\npg_url.set_path(\"postgres\");\n\nOk((database, pg_url.into_string()))\n\n}\n```\nAlso it would be nice if diesel setup reported the URL it tries to connect to.. ",
    "jethrogb": "This can probably be solved by putting the default type parameters back on IntoInsertStatement. When writing <T as AsQuery>::Query: SelectDsl I seem to have better luck. That only works because the references there are 'static. The Box is necessary for the implicit 'static bound on M. But you're right, I can get rid of the collection like so: [Box::new(my_migration) as Box<Migration>].iter().map(|v|&**v). That error is coming from the postgres backend (backend/libpq/be-secure.c), something must be intercepting your kill signal. You might also try using tcpkill instead of killing the server process.. That requires a network round-trip to complete. For the connection pooling use, that basically means every query now takes twice as long.\nAlso, that still doesn't let you distinguish between network errors and other random DB server errors.. Cool, should've read the changelog better I suppose :smiley: . I don't think the build failures are related to this PR.. My immediate use case is CockroachDB client-side transaction retries for which you need to check error code 40001.. > what do you think about returning the SQLSTATE code, rather than a backend specific one?\nI'm not sure what this distinction is.\n\nEither way, this won't be merged until after 1.0 has been released.\n\nI'd recommend merging it now while you can still change the DatabaseErrorInformation trait without affecting compatibility.. > One is an ANSI standard that is consistent across backends. I actually didn't even think about the fact that PG has no error codes besides SQL state codes. \n\nI also don't like the name code since other backends have \"error codes\" which are not SQLSTATE identifiers.\n\nI see. That seems fine with me, although I can't find any evidence that SQLite implements this particular part of the standard. Also it looks like about 80% of the error codes MySQL returns correspond to SQLSTATE HY000, so I'm not sure how useful that is.\n\nI was thrown off by the fact that this returns i64. This function can't return i64, SQLSTATE codes are 5 character strings. e.g. \"2BP01\"\n\nI didn't realize this. I can easily change it if/when you want to merge this.\n\nThis pull request is fully backwards compatible.\n\nIt adds a trait method. Implementors of DatabaseErrorInformation will not compile with this change without a change in the implementation.. Again, SQLSTATE seems pretty useless:\n\nI can't find any evidence that SQLite implements this particular part of the standard. Also it looks like about 80% of the error codes MySQL returns correspond to SQLSTATE HY000, so I'm not sure how useful that is.. \n",
    "csharad": "#[macro_use] extern crate diesel;\n#[macro_use] extern crate diesel_codegen;\nextern crate dotenv;\n\nuse diesel::prelude::*;\nuse diesel::mysql::MysqlConnection;\nuse dotenv::dotenv;\nuse std::env;\nuse schema::numbers;\npub fn establish_connection() -> MysqlConnection {\n    dotenv().ok();\n\n    let database_url = env::var(\"DATABASE_URL\")\n        .expect(\"DATABASE_URL must be set\");\n    MysqlConnection::establish(&database_url)\n        .expect(&format!(\"Error connecting to {}\", database_url))\n}\n\nmod schema {\n    infer_schema!(\"dotenv:DATABASE_URL\");\n}\n\n#[derive(Debug, Queryable)]\nstruct Number {\n    id: i32,\n    number: i32\n}\n\n#[derive(Insertable)]\n#[table_name=\"numbers\"]\npub struct NewNumber {\n    number: i32\n}\n\n#[derive(AsChangeset)]\n#[table_name=\"numbers\"]\npub struct ChangeNumber {\n    number: Option<i32>\n}\n\nfn main() {\n    let connection = establish_connection();\n    let results = numbers::table.limit(5).load::<Number>(&connection).expect(\"error\");\n    println!(\"{:?}\", results);\n\n    let n = NewNumber { number: 1 };\n    diesel::insert(&n).into(numbers::table).execute(&connection).expect(\"errr\");\n\n    let change = ChangeNumber { number: None };\n    diesel::update(numbers::table.find(1)).set(&change).execute(&connection).unwrap(); \n}\n\nThis code ends up with the same error but for mysql.. Only Timestamp and Date are Add and Sub. Should I remove others from __diesel_generate_ops_impls_if_date_time or add impls for them?. ",
    "ivanceras": "Yes, by installing it via cargo install diesel_cli\nI'm using rust nightlies\nsh\n$cargo -V\ncargo 0.17.0-nightly (40a4ce6 2017-01-06)\n$rustc -V\nrustc 1.16.0-nightly (47c8d9fdc 2017-01-08)\n. omg. I don't know how to squash commits :( Can we close this and do another PR with the same changes?. My bad, this is vim swap files. I should start using global .gitignore. ",
    "drbawb": "I'm also running into this problem:\nMac OS 10.11.16\nrustc 1.16.0-nightly (df8debf6d 2017-01-25)\ncargo 0.17.0-nightly (67e4ef1 2017-01-25)\ndiesel 0.9.0\nThe command was installed w/ cargo install diesel_cli\ndiesel setup worked fine, diesel migration generate create_entries did create the migrations/ folder, but it did not create the migration files. The CLI usage text is outputted to the console instead.. Not sure if this is related, but I'm also having issues w/ infer_schema! while trying to follow along with Getting Started, however I was using PostgreSQL instead of SQLite.\nThe error I receive:\n```\n$ rustc -V\nrustc 1.16.0-nightly (df8debf6d 2017-01-25)\n$ cargo build\n   Compiling aqua v0.1.0\nerror: macro undefined: 'options!'\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = note: this error originates in a macro outside of the current crate\nerror: aborting due to previous error\nerror: Could not compile aqua.\n```\nThis is the database connection string \n$ cat .env\nDATABASE_URL=postgres://drbawb@192.168.1.11/aqua_diesel\n\nLet me know if there's any other debug information I could gather for you. . ",
    "kbknapp": "Interesting. I'm not aware of any breaking changes in from clap 2.19 to 2.20. I'll look into this more and see if I can find anything.. It's possible it could be a regression bug, would someone mind filing an issue on the clap repo? I'm on mobile right now. Also compiling clap with the features = [\"debug\"] will help as well.\n. I'm looking into this bug as we speak, if it's what I think is happening I\nshould have a fix out momentarily.\nOn Feb 2, 2017 3:09 PM, \"Sean Griffin\" notifications@github.com wrote:\n\nI'm going to remove the Cargo.lock from the tree as well, since crates.io\nwill never use it by the look of things.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/602#issuecomment-276966918,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGnttvgR8PW-jXZvGzyYzc9vInBU9LWSks5rYeOUgaJpZM4Lzic8\n.\n. \n",
    "alexcrichton": "@sgrif thanks for the cc! Yeah currently there's no opt-out, but that's tracked at https://github.com/rust-lang/cargo/issues/3192. Right now procedural methods have no method of preserving span information of expanded code or otherwise dealing with spans. That's all due to the usage of strings on both ends of the interface where you to_string a TokenStream and then parse back into a TokenStream. Clearly this isn't the best interface for all of time, so we'd like to fix that!\nUpstream in rust-lang/rust the proc_macro crate is getting an enhanced API which will enable preserving and customizing span information of streams coming out of and going back into the compiler. This should be a great benefit to all procedural macros in terms of error messages and debugging usability.\nAll of those new APIs, however, are naturally unstable. They'll take some time to stabilize and the timeline for stabilization is unclear. To work around this the proc_macro2 crate is an attempt to sidestep this stabilization timeline. The proc_macro2 crate intends to provide the exact same API as proc_macro (if it were stable) yet also compile on stable Rust. To do that proc_macro2 by default will use the to_string and parse interfaces to convert to/from TokenStream. You can, however, enable the unstable feature of the proc_macro2 crate which actually compiles against the unstable interface of proc_macro. This requires a nightly compiler, but should be able to losslessly preserve all span information.\nSo basically tl;dr; proc_macro2 is future-proofing. Macros written against it have a turnkey solution for better spans on nightly today, and will have a turnkey solution for better spans in the future once the new proc_macro API is stabilized.\nDoes that make sense?. @sgrif yeah CARGO_MANIFEST_DIR should always be an absolute path. Oh for futures something like with-deprecated was only ever intended to be internal and it was purely an accident that it ended up being released publicly. This is indeed a pretty tricky thing and it means that moving functionality behind an on-by-default feature is technically a breaking change if lots of users were previously using default-features = false. The best solution for this in Cargo is to say \"specifically don't pull in this feature in the set of default features\", but Cargo doesn't currently have a way to express that.. ",
    "fivethousand": "Same error here: \n\nmacro undefined 'options!'\n(Linux/PostgreSQL/Rust nightly 1.16/Diesel 0.9.1). Oh.\nThe example (or at least the first steps) do compile and work after removing\n![feature(proc_macro)]\n\n(as suggested).\nMaybe this should be added to the tutorial until the issue is fixed.. ",
    "trombonehero": "It's true that is_not_null is documented, but to find that documentation I need to know either:\n\nthat it's called is_not_null (which is the thing I wanted to learn) or\nthat the list of such expressions are documented in diesel::expression::expression_methods::global_expression_methods::ExpressionMethods.\n\nMy suggestion is that something between the high-level http://diesel.rs/guides/getting-started and the low-level API docs could be helpful for people trying to learn Diesel. Something like \"here's how these SQL clauses translate into Diesel expressions\" would be great.. That does seem to fix it... thank you!\nNow I suppose the question is: what documentation fixes might help others avoid this particular pothole in the future?. Ok, so it sounds like v0.17.0 will \u201cjust work\u201d? If so, that\u2019s great! Thanks.. ",
    "alexcameron89": "I think this is fixed and good to close.. Thanks @killercup! I always forget to use that feature , l will remember to in the future\ud83d\ude04 . I'll give this one a try \ud83d\udc4d . fuction -> function. it's -> its. handle's -> handles. ",
    "TimNN": "Is this really fixed? The one PR linking this issue only mentions select and filter and also states:\n\nBut we should probably also add this to/think about insert, update and delete before we close that issue.\n\n(I also just spend some time trying to figure out why my update wasn't executing until I noticed I was missing an .execute when adding an diesel::debug_sql. I'm pretty sure there were no warnings).. ",
    "AndrewSpeed": "I'm happy to put a PR up for this, if no one else is working on it. I'll take a look at implementing this. \ud83d\udc4b Would anyone object to me working on this issue?. Errors should be addressed. I had some issues getting the tests to run locally, but I think that was down to me not specifying the version on the MySQL Docker container, meaning it was different to the version used to compile the code :man_facepalming: \nRegarding CONTRIBUTING.md, I couldn't get the cargo fmt instructions working, specifically the --write-mode. Do these instructions need updated, or was I missing something?. It looks like CI is failing due to unstable features being tested for the stable and beta versions, but I'm not sure what the cause of this is. \ud83d\udc4d can do, would this go into the tests under diesel_cli or somewhere else?. I wasn't sure if adding the must_use here was necessary or not, feedback welcome. ",
    "mckinley-olsen-oc": "I ran into the issue in the first post, where diesel::query_source::InnerJoinSource has no method named load\nMy issue was that I had not specified the #[belongs_to] annotation with the name of the column referenced in the foreign key; I had only done this in the #[has_many] annotation. \nOn closer read of the documentation, it does mention the ability to specify this on #[has_many] as well as #[belongs_to]; in my oversight, I hadn't realized both were required, as the example in the documentation is only on the #[has_many]. ",
    "andy128k": "I'm new to Rust and Diesel. but what I love is type safety and all great things LoadDsl does. That's why I'd prefer \"better sql\" instead of new untyped API.\nNice ORMs like ActiveRecord and Django's ORM allows to put bits of SQL but keep the rest of code working with typed models.\nI'm playing with Diesel and see a lot of limitations (like inability to make multiple joins or multiple belongs_to) and that's ok. Even with raw SQL Diesel is still great.\nI created couple workarounds to solve issues with raw sql queries.\nFirst is obvious -- no binds so I just use PQescapeString.\nSecond one is unpredictable order of columns in queries with *, so this ugliness was born https://gist.github.com/andy128k/b3cae82d13e38f51c4c5bf56f5d6540a. ",
    "diggyk": "I know the helpers are not ready, but can timestamp or i64 be used at all at the moment?  I'm having trouble with a struct that I want to use as Insertable:\n[derive(Insertable)]\n|          ^^^^^^^^^^ the trait diesel::Expression is not implemented for i64. Looks like the issue I was having is that I was using int(20) instead of \"bigint\" in my table definition.  And when using infer_schema, bigint looks for a type of Bigint, which doesn't exist.  Anyway, I use the table macro instead of inferring and everything works (except timestamp). ",
    "Aaronepower": "@sgrif I did not run diesel migration run the guide doesn't say to?. Ahh, I couldn't see the first command. With diesel migration run it works.. ",
    "freinn": "Thanks @Eijebong. Solved. Should I use diesel 0.10.1 or 0.10?. Thanks @killercup. I close because is solved.. Thanks for the caring in your answer, and your consideration. I've uploaded my private git repo to github so you can test it easily, here. My code organization is poor. I have to split it into modules but I prefer to have all working before.. ",
    "Dylan-DPC": "Hi. Interested in working on this. @sivakov512 it is an unrelated issue with clippy which strangely doesn't happen on other commits. Can you try restarting the build? (on travis, there is a button on the right).  . @sivakov512 you don't have to do anything here. It is a clippy bug so either we need to wait for that to be resolved or clip on to another nightly.  . ",
    "sivakov512": "Hi! I make PR here.. Can anybody help with this?\n\nI dont know what it mean :(\n. No, i have no restart button, because i am not a project member.. @sgrif, I tried to update clippy version, but now there are another problems . @sgrif, fixed . I do not understand how to fix the last problem in CI. @sgrif, can you help me? . @sgrif, I did something wrong and I had to create a new PR here.. @Eijebong, any new comments? Or merge it? =). Any news here?. Oh, sorry. Fixed.. Frankly, I just do not know why this is and therefore copied from the Name signature. The text of the syntax error is different for different databases, so I did so. How can I do it better and do we need syntax error text in tests?. Struct below (MigrationFileName) used in public function file_name, that used here and here. ",
    "alexkamp": "I called diesel in a directory which contains a .env file with\nDATABASE_URL=postgres://postgres:***@postgres/reminder\n(of course the pwd is not ***). \n\ncargo -V\ncargo 0.16.0-nightly (6e0c18c 2017-01-27)\nrustc -V\nrustc 1.15.1 (021bd294c 2017-02-08)\n\ndiesel_cli v0.10.1\nI just noticed that in fact no diesel-command works. Even diesel -v segfaults. That made me wonder whether there is something fishy about my setup, however, compiling a hello-world with rustc works as expected. Anything more I can try? . First of all, thanks for your help!\nThe behaviour does not change for diesel_cli --no-default-features --features postgres. I can not execute a program which links against pq-sys.\nI wrote a docker file and a shell script to reproduce the problem.\nThe script starts postgreSQL in a Docker container, then it builds a container with rustup and diesel in it, links it to the postgreSQL instance and opens a root shell into the container. On my machine, diesel setup fails within this container. \nenvironment.tar.gz\nPlease mind: \n(1) The script does not tidy up in the end. That is, both docker container and the image stay around. \n(2) The script links the project files (an empty project created with cargo) into the container. On my machine, this works only if se linux is disabled. . ",
    "dvdplm": "Wow, that was fast! :). ",
    "KeenS": "Er.. subnetmask can be represented in u8, no need to have the same bits as addresses.. No problem at all. Thank you.. > Is there a reason you used a third party crate rather than implementing it for IpAddr from the standard library? \nIpAddr in std only provides data for IP addresses. The ipnetwork crate provides IP addresses and netmasks. It uses std::net::IpAddr for IP address part.. As you can see, I'm asking if a can use libc crate. If possible, this patch will complete soon.. Now I resolved the requested change. As libc doesn't define AF_INET on Windows, I defined it manually (which is also the way rust's std::net does).. A test which isn't related to this patch is failing. How can I fix it?. @Eijebong I see, thank you.\n@killercup then, I finished resolved your comment and ready to merge.. yes, I'm using rustfmt. Is there any formatting style guide (like rustfmt.toml)? Or, if isn't, I'll revert the diff by hand.. Here, I reverted the format and rebased on origin/master(b17bb9cb92fd034ba39c84829f4a53fbaddc7036).. Of cause, I know I can do it with sql function\nrust\nsql::<Integer>(\"INSERT INTO users DEFAULT VALUES RETURNING id\"). I suppose allowing empty structs to derive Insertable (in that case, empty structs will use DEFAULT VALUES) or providing another function like insert_defaults() will do.. Thank you for pointing the problem out. I found I confused duration with interval, it's intervals on the calendar, not time intervals. Then I close this as invalid request. I'm sorry for troubling you.. > I'd rather we not add it as a dependency right now and go with [u8; 6] for now.\nThough the crate is simple enough to check the whole code (this is the reason I tried to adopt this crate), I agree with you. I'll fix the code\n\nAnother thing, can you maybe add a longer doc test that shows how all the Postgres network types can be used?\n\nSure. I'll write docs for macaddr, cidr and inet referring docs of money.. @killercup I did it. @Eijebong updated at your suggestion.. Added. Is the section title correct?. @Eijebong ping. Sure. I've removed unrelated changes and rebased on origin/master.. I'm sorry for my carelessness. Fixed it.. Thank you. I'll use surrogate keys.. :). all is done. rebased.. Is this planned to be developed for diesel 2.0? (And is diesel 2.0 is planned?)\nI want to use partitioned tables, which doesn't support primary key.. I found diesel_cli supports table filtering.\nhttps://github.com/diesel-rs/diesel/blob/master/diesel_cli/tests/print_schema/print_schema_except_tables/diesel.toml\nI'm going to use it until diesel 2.0 get released. blocked by #1889 , i guess. . Some jobs of CI on Azure is failing with unknown reason and some are canceled somehow. . force rerun resolved everything.. @weiznich It's ready to review.. fixed message. And also, I found the filtering is referencing non-existent argument. Thus fixed to refer \"table-name\"\n$ cargo run -p diesel_cli --features postgres --no-default-features -- print-schema --except-table-regexes  'a('\n   Compiling diesel_cli v1.4.0 (/home/shun/Rust/diesel/diesel_cli)\n    Finished dev [unoptimized + debuginfo] target(s) in 4.28s\n     Running `/home/shun/Rust/diesel/target/debug/diesel print-schema --except-table-regexes 'a('`\ninvalid argument for table filtering regex: regex parse error:\n    a(\n     ^\nerror: unclosed group. Nightly tests are failing because try_from has been stabilized. It's not relevant to this PR. I see.. > And std::net::IpAddr implements From<[u8; 16]> as well as From<[u8; 4]> (for Ipv4)\nI didn't notice that impl. I'll use it.. To tell the truth, I'm not confident. To err on the side of caution I want to use libc crate. Is it possible to depend on libc only for using a constant?. CIDR is a common word in network area. Anyway I'll add a link to the page.. Yes, it's a debugging code. It's my mistake.. It's less cumbersome. I'll adopt it. Thank you.. Ops, you cannot do Ipv6Addr::from(&bytes[4..8]) because bytes[4..8] returns [u8] and Ip4Addr::from is implemented only for u32 or [u8; 4].. The same above. From<&[u8]> isn't implemented for Ipv6Addr.. Updated nightly version to pass test. Is this acceptable? To say more, what's the policy of supported nightly version?. try_from has been stabilized (ungated) at nightly but it is still nightly only API.. I see.. ",
    "Mrmaxmeier": "Sure, that makes sense and is consistent with the code that does this ordering on Postgres/MySQL already.\nI've added the same behavior to the SQLite variant. Should I keep the tests and move them to diesel_tests?. I've added unit tests for SQLite, PG and MySQL and Travis seems happy with them.. ",
    "Ameobea": "I'm getting this same issue; unable to perform any queries using r2d2-diesel and MySQL.  Is there a fix on the radar for this?  I've tried to look into a solution on my own but I'm very unfamiliar with diesel and databases in general.. ",
    "martijndeh": "I rebased, awaiting Travis results.... ",
    "langzime": "think you. ",
    "kud1ing": "I didn't know about cargo install diesel_cli --no-default-features --features sqlite. I was following the getting started guide. Maybe it could be mentioned there.. Sorry, I accidentally copied the example with the Postgres feature enabled. :/. No thanks, I am fine. The issue #735 regarding the CLI maybe could be mentioned in the guide, though.. ",
    "leshow": "Ah, thanks. I was following along in getting started and it wasn't listed there.\nOut of curiousity, what are you using clang for? There's no C in the project.\nEdit: Reading the link answered my own question, thanks.. I'd be interested in jumpiing into some code reviews, if you folks are still looking for people.. @killercup Sure, sounds good.. > Second is that you can no\nlonger pass a subselect to the same table. I'm not entirely sure how we\ngo about fixing this just yet, but that's a much more niche use case\nanyway.\nFor clarity, does this mean something like SELECT foo FROM table_a IN (SELECT bar FROM table_a) is no longer possible, because they select from the same table?. barring the \n|\n26 | let data: Vec<(User, Post)> = users.inner_join(posts)\n   |                                     ^^^^^^^^^^ the trait `diesel::query_source::AppearsInFromClause<schema::users::table>` is not implemented for `schema::posts::table`\nbuild error, it looks good to me.. ",
    "kirs": "https://gist.github.com/9396e192b68cabf13c54820238b39c58. BTW, I'm running rust 1.15.1.\n$ cargo update\n    Updating registry `https://github.com/rust-lang/crates.io-index`\n``\n$ RUST_BACKTRACE=1 cargo install --verbose\n       Fresh byteorder v1.0.0\n       Fresh utf8-ranges v0.1.3\n       Fresh winapi-build v0.1.1\n       Fresh libc v0.2.20\n       Fresh winapi v0.2.8\n       Fresh regex-syntax v0.3.9\n       Fresh quote v0.3.13\n       Fresh unicode-xid v0.0.4\n       Fresh memchr v0.1.11\n       Fresh synom v0.11.0\n       Fresh aho-corasick v0.5.3\n       Fresh pq-sys v0.4.2\n       Fresh syn v0.11.6\n       Fresh kernel32-sys v0.2.2\n       Fresh diesel v0.11.2\n       Fresh thread-id v2.0.0\n       Fresh diesel_infer_schema v0.11.0\n       Fresh thread_local v0.2.7\n       Fresh regex v0.1.80\n       Fresh dotenv v0.8.0\n       Fresh diesel_codegen v0.11.0\n   Compiling diesel_demo_step_3_pg v0.1.0 (file:///Users/kir/Projects/opensource/diesel_start)\n     Runningrustc --crate-name diesel_demo_step_3_pg src/lib.rs --crate-type lib -C opt-level=3 -C metadata=a7e40dfea0887d49 -C extra-filename=-a7e40dfea0887d49 --out-dir /Users/kir/Projects/opensource/diesel_start/target/release/deps --emit=dep-info,link -L dependency=/Users/kir/Projects/opensource/diesel_start/target/release/deps --extern dotenv=/Users/kir/Projects/opensource/diesel_start/target/release/deps/libdotenv-c0ef68bcfc5b2489.rlib --extern diesel_codegen=/Users/kir/Projects/opensource/diesel_start/target/release/deps/libdiesel_codegen-eefe7fa2e56aaa65.dylib --extern diesel=/Users/kir/Projects/opensource/diesel_start/target/release/deps/libdiesel-82ac424c6bfc818c.rlib -L native=/usr/local/opt/postgresql/lib`\nerror: custom derive attribute panicked\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = help: message: assertion failed: !p.is_null()\n  = note: this error originates in a macro outside of the current crate\nerror: failed to compile diesel_demo_step_3_pg v0.1.0 (file:///Users/kir/Projects/opensource/diesel_start), intermediate artifacts can be found at /Users/kir/Projects/opensource/diesel_start/target\nCaused by:\n  Could not compile diesel_demo_step_3_pg.\nCaused by:\n  process didn't exit successfully: rustc --crate-name diesel_demo_step_3_pg src/lib.rs --crate-type lib -C opt-level=3 -C metadata=a7e40dfea0887d49 -C extra-filename=-a7e40dfea0887d49 --out-dir /Users/kir/Projects/opensource/diesel_start/target/release/deps --emit=dep-info,link -L dependency=/Users/kir/Projects/opensource/diesel_start/target/release/deps --extern dotenv=/Users/kir/Projects/opensource/diesel_start/target/release/deps/libdotenv-c0ef68bcfc5b2489.rlib --extern diesel_codegen=/Users/kir/Projects/opensource/diesel_start/target/release/deps/libdiesel_codegen-eefe7fa2e56aaa65.dylib --extern diesel=/Users/kir/Projects/opensource/diesel_start/target/release/deps/libdiesel-82ac424c6bfc818c.rlib -L native=/usr/local/opt/postgresql/lib (exit code: 101)\n```\nNot sure if RUST_BACKTRACE=1 makes the output different.\nI also tried grepping target/release/deps for !p.is_null() assertion but there was nothing.. ```\n$ rustc -vV\nrustc 1.15.1\nbinary: rustc\ncommit-hash: unknown\ncommit-date: unknown\nhost: x86_64-apple-darwin\nrelease: 1.15.1\nLLVM version: 3.9\n$ diesel print-schema\ntable! {\n    posts (id) {\n        id -> Int4,\n        title -> Varchar,\n        body -> Text,\n        published -> Bool,\n    }\n}\n```\nI'm curious about how did you find the assertion.. It works on nightly.. Thanks for your help! Should we close the issue?. ",
    "cramertj": "I'd prefer Diesel continue to use tuples, but that there was an easier way to impl traits for tuples. As I commented on the RFC, I want to see Split and Cons traits added to the language and implemented for all tuples through some sort of intrinsic. @eddyb has a working prototype here (this implementation uses macros, but that would be unnecessary if an intrinsic of some kind was provided).\nI believe this solution mitigates many of the drawbacks you listed above, namely:\n- \"Tuples are in the standard library. hlists aren't.\"\nThis approach would allow users to keep using tuples, a familiar type, and to avoid introducing hlist! macros all over the place.\n- \"diesel::hlist::Cons<Foo, diesel::hlist::Cons<Bar, diesel::hlist::Nil>> is harder to read than (Foo, Bar)\"\nSince this approach allows users to use tuples directly, they don't have to try and parse new cons-cell types.\nOverall, I think the addition of Split and Cons traits offers the best of both worlds: familiar std types, Rust syntax, smaller generated code, faster compile times, and a standard way to handle heterogeneous lists in Rust.\nedit: Adding this here since it was mentioned in the RFC-- @eddyb thinks we could maybe add impl<H, ...T> Foo for (H, ...T) which would prevent the coherence issues with impl<T> for T: Split and co.. ",
    "PlasmaPower": "\nUltimately if we make this change, hlists become a very fundamental part of people interacting with Diesel, which makes me uncomfortable leaving that in the hands of another crate unless it's already well established within the community. There also isn't a crate that is maintained and just does hlists. Having a type which is local to Diesel is useful for us from a coherence point of view.\n\nMaybe we should create a crate hlists under the diesel-rs GitHub user, for both diesel and whoever else wants hlists.. I agree that frunk-core would be a reasonable solution, but I do have my concerns. First, frunk isn't currently all that popular. It only has about 4% of the downloads of diesel. Therefore, it's a lot less likely to be properly maintained. Second, at the moment frunk-core exists solely for frunk. It's subject to change, and later on it may expand its scope, adding unnecessary baggage to diesel projects.\nWhile these might not seen like huge concerns, I am worried because changing the hlists backend would be a breaking change for pretty much all diesel projects (which we would want to avoid if possible). I guess we could re-export hlists to avoid a lot of the breakage, but it's still far from optimal.. @killercup The latest commit tests trailing commas by modifying an existing test.. ",
    "tupshin": "I am hugely in favor of moving to HLists in general. Regarding an internal HList vs using an existing crate, I partially agree with your reasoning. However, it is worth noting that frunk-core actually consists of not much more than HList.\nSo while it might not be the right time to standardize on an external one, worth keeping on eye on that one.. Totally fair points.. Agree about a third party crate, and thanks, that's a very useful suggestion for how to approach it.. As an out-of-tree effort, how would I go about running the test suite against my implementation?. ",
    "withoutboats": "One thing that's interesting about hlists (but possibly not relevant to diesel) is the difficulty in pulling a particular type out of an hlist. Today, you need a trait that's indexed by peano numbers.\nWith intersection impls, if you don't care about being able to pull multiple values of the same type out of an HList, it becomes possible without that (but, again, it has the restriction that you essentially 'leak' any existing T if you put another T in the list). Here's a code sample of how it works:\n```rust\ntrait Hlist { }\nstruct Cons(T, U);\nimpl Hlist for () { }\nimpl Hlist for Cons { }\n// Base case\nimpl AsRef for Cons where U: Hlist {\n    default fn as_ref(&self) -> &T {\n        &self.0\n    }\n}\n// Recursive case\nimpl AsRef for Cons where U: Hlist + AsRef {\n    default fn as_ref(&self) -> &X {\n        self.1.as_ref()\n    }\n}\n// Intersection impl\nimpl AsRef for Cons where U: Hlist + AsRef {\n    fn as_ref(&self) -> &T {\n        &self.0\n    }\n}\n``. This should be possible in a post-chalk world. Would not be possible ifUserwas a type parameter, but after chalk we should be able to normalize this tousers` or w/e.. ",
    "J-F-Liu": "In favor of this change, the main concern is how much impact of runtime performance.\nFor naming use a small word is better, like cols!, fields!.. ",
    "lloydmeta": "@all Just chiming in because I was summoned.\nRegarding frunk (and frunk-core): I'm open to any suggestions of re-organising the repository and overall improving it, so that it can be made more useful. That also includes keeping the scope of it small. I should also mention that the \"core\" suffix in frunk-core doesn't mean it's meant just for frunk, all it means is that it contains functionality that frunk will depend on (e.g. Validation uses HList) :)\nI also intend to maintain it for the foreseeable future, but more maintainers are always welcome !\nEDIT:\nFrom what I can see, there is a lot of overlap between the HList here and what is already in Frunk, so I think there are benefits to reusing the one I have in Frunk.\nA bit of history\nFor what it's worth, I come from Scala where a similar situation happened in an ORM (Slick) where originally the HList implementation from Shapeless (a generic programming focused lib)  was not used. This caused some headaches for a while because while Slick users had built code around Slick's HList, Shapeless's HList implementation, being a core focus of the lib, eventually surpassed it in many aspects. You could definitely convert between the two though, but that sometimes caused confusion and was a source of extra boilerplate.\nHaving said that, eventually a bridge library was made so that one could use Slick with Shapeless HList, but it took  a couple years for one to show up, and migration is not exactly automatic.. ",
    "blakepettersson": "Is this change a prerequisite for being able to arbitrarily construct selects and order bys based upon run-time parameters (without having to directly fall back to SQL)? It's not currently clear to me how this works in Diesel today.. Thanks for the explanation! I presume that adding this method only really makes sense on a boxed query, and hence should only be implemented for BoxedSelectStatement?. Hmm, maybe then_order_by should instead be called append_order_by?. ",
    "3541": "Any progress on this issue? I also have need of this feature. If there's anything I can do to help with the implementation, I can try to do so.. ",
    "Phrohdoh": "@killercup Yes, I'll license this under MIT+Apache2!\nOnce this is merged I'll delete my repo entirely.\nHow is this only the third step?\nThat repo covers everything in the getting started guide.. LGTM (would suggest a squash, personally). ",
    "pwestrich": "I get the exact same error message:\n``\n$cargo rustc --bin main -- -Ztrace-macros\n   Compiling project v0.1.0 (file:///Users/pwestrich/Documents/Repositories/project)\nerror: no rules expected the token)`\n --> src/schema.rs:2:1\n  |\n2 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = note: this error originates in a macro outside of the current crate\nerror: Could not compile project.\nTo learn more, run the command again with --verbose.\n```. Without that flag, cargo gets angry at me, because I have both a library and an executable in the same crate.\nWhen I replace infer_schema!(\"dotenv:DATABASE_URL\"); with the output from diesel print-schema, I get the same error message, except this time, it's the table! macro that causes it.\nNow if I run it with the --lib flag (something I hadn't thought of until now), I get a good 6k lines of output from cargo here.\n. How in the world did I get an unsigned float? That's certainly not a thing that exists.\nI'll go check my schema and make sure I don't have any imaginary types floating around.. That would certainly be nice.\nRemoving the unsigned attributes, I'm now getting a new set of error messages. I'm guessing form them that you don't support the char type either? Is there a list I can reference somewhere?. I'm not using any other crazy types, so I don't think I'll need any added, though I'm sure it would be nice in the future to support all the types the respective databases do at some point.\nI'll just make my chars into varchars for the time being.. ",
    "dessalines": "This should be reopened, its still an issue. . This should bypass the mysql system requirement and give you a warning if that part of it fails. All diesel-cli installs now fail on a system without mysql. \nSo yes, I arrived at this thread(which was closed), and implemented the suggestion above. Everyone who doesn't use mysql has to get to this page if they want diesl-cli to work. It would be better to either fail and refer to this fix, or to pass with a warning telling you the mysql stuff didn't install. . ",
    "tbg": "Ok, added the env var, looks like CI passes. I'm still getting transient failures locally that are difficult to debug, but I suppose I don't need to solve that in this PR. I'll look into addressing some of the new TODOs but let me know if the rest looks good.. @sgrif ping - I think I'm done here, please let me know if that's not the case.. I rebased again since it sat for a while. Still ready as far as I'm concerned.. Actually the issue to track here is probably https://github.com/cockroachdb/cockroach/issues/13787 -- TL;DR it somewhat works, but a few workarounds are needed at the moment.. But setup also runs the migrations, which I don't want - the state left behind by this by the example can't be handled by those in diesel_tests (which have a different migration history, but overlapping table name posts).. See above, the examples leave diesel_test.posts behind which clashes which the migration history use in the diesel_tests. Or, rather, that's what it looked like to me.\n\nThis is not an acceptable solution.\n\nI agree, and it's definitely going on. After all, the database is shared across all tests...\nThere are also two more issues I haven't even looked into yet (well, I've tried, but didn't manage):\n\nthe sqlite diesel tests are sometimes built in a way that the inferred schema is empty (see the PR description), and since nothing invalidates the binary when the sqlite database changes, you need to force rebuild of the test so that it can pass\nnot a schema problem, but sometimes the postgres times_relative_to_now_encode_correctly() fails (i.e. the assertion fails). Again, this disappears immediately when I force a rebuild (as happens when I expand the assertion to print what's going on). This usually happens after I've had the laptop in sleep mode or when I run it the first time from a clean slate.. I suppose it could work out better if all tests assumed that their database may or may not exist. At least some of them require it preexisting (I'd wager most), for example dropping the touch in the test_all scripts for the examples gives\n\n```\n+ cd diesel_infer_schema\n+ cargo test --features 'lint postgres'\nwarning: package replacement is not used: https://github.com/rust-lang/crates.io-index#diesel_infer_schema:0.11.0\nwarning: package replacement is not used: https://github.com/rust-lang/crates.io-index#diesel_codegen:0.11.0\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs\n     Running /Users/tschottdorf/rust/diesel/target/debug/deps/diesel_infer_schema-a9de714f71691e1f\nrunning 6 tests\ntest information_schema::tests::load_table_names_loads_from_public_schema_if_none_given ... FAILED\ntest information_schema::tests::get_table_data_loads_column_information ... FAILED\ntest information_schema::tests::load_table_names_loads_from_custom_schema ... FAILED\ntest information_schema::tests::get_primary_keys_only_includes_primary_key ... FAILED\ntest information_schema::tests::load_table_names_output_is_ordered ... FAILED\ntest information_schema::tests::skip_views ... FAILED\n``. Unfortunately, all of that juggling environment variables makes that not-so-easy. We could introduce yet another set of env vars ({PG,MYSQL}_EXAMPLE_DATABASE_URL`?) and use that. Or try to change the database ad-hoc, but trying to do that in bash is going to be frail.\nOr, not run those examples normally. However, once you did so manually, you'd run into the same problems again, so I'd rather avoid that option. Any preference on your end?\nAlso, any pointers on how I can investigate the result of infer_schema!(\"dotenv:SQLITE_DATABASE_URL\"); to track down the other spurious failure I mentioned?. Yeah, the issue will hopefully disappear when the examples stop overlapping (the other thread).. Removing this hard-coding was part of why I opened this PR (I thought that was clear from the description and the commit messages). The instructions in CONTRIBUTING.md suggest that you get to decide what you're running the tests against, and the hard-coding doesn't work for everyone (even with trivial local servers, for example I would have to add postgres@ to the hardcoded string).\nSo, removing the hard-coding, I naturally let them run against what we have, which is {MYSQL,PG}_DATABASE_URL, but as you pointed out, that's not a good idea due to the interaction with the tests. That's why I remove that state and so it works, but I agree that it's not a good solution (for example, if the example fails half-way through).\nOne could argue that it would be easiest to just hardcode it all and force folks to run things at the right location. I don't think that's a great solution though, and certainly it isn't fun for CI, (for example, you don't run the example in appveyor, probably because there you require user and password) but it could work.\nMy preference so far (and one that should hopefully also reflect your position) is an extra set of .env vars to be used for running the examples.\nWhen I cloned the project, I wasn't planning on spending so much time on running the tests, but now that I have I think there's some work to be done to lower the barrier of entry, and ideally that would mean opening CONTRIBUTING.md, starting the databases anywhere I want, creating an appropriate .env and then be able to run ./bin/test (i.e. what I'm trying to achieve here).. Done.. Done.. We don't. I removed it.. Done.. ",
    "jnferner": "alright :) Should I reopen it right now on master?. That was quick! Thank you for your help. Really enjoying diesel so far :). ",
    "AlexPikalov": "@tupshin I could help with this stuff if there'd be an agreement that it makes sense.. @tyranron unfortunately, no news from my side. During last months, I was involved into development of version 2 of the driver. I'd like to start working on that ASAP.. ",
    "tyranron": "@tupshin @AlexPikalov any news?. ",
    "ivan-brko": "Hi,\nI'd like to get familiar with this project so I want to help with this issue.\nIf I understand correctly, for all the examples in the examples directory a test needs to be written to confirm that they are all working properly. So, besides verifying that the binaries output is good, would this also include checking that the database is in expected state after every step?\nThis could be written as a Rust integration test or is something like .py script for each backend more preferable?\n. ",
    "cgm616": "I'm interested in this issue because I'm trying to figure out how to test my own application that uses diesel. Will I have to run my own CI server with a DB to connect to and verify after every command? There has to be a better way. \nHopefully tests in the examples will give me an idea. . ",
    "heyztb": "Since there hasn't been any activity on this since 2017, I'd like to tackle this issue \ud83d\ude04 \n. @killercup - Sounds good. I'll open a PR once I've got a tentative test up and running. I'm going to work on the Postgres example first, mainly because I'm not sure exactly which library I need to install in order to work with MySQL (I'm on macOS Mojave, btw).\nI do have a question, and I figured this would be an appropriate place to ask but I'm also going to link this issue to the Gitter channel and get some feedback there -\nI understand that this issue asks for Integration tests, and I've taken a look at the assert_cmd crate, but I'm not too sure how I'd pass in arguments to the various binaries. I'd rather the tests not require actual user input, and I would like to simulate that instead. My question is, how do I go about passing in things like the title and body of a post in my tests? There's no straightforward way from what I can tell, so are we sure that unit tests aren't more appropriate for this? Thanks for the help. I look forward to contributing more!. ",
    "jgallagher": "Not anymore! 0.7.0 did, but we had huge problems running bindgen at compile time too. 0.7.1 goes back to shipping prebuilt bindings (with a better system for dealing with older SQLite versions). . > I'm not opposed to it, but IIRC your API is based off of the rust-postgres crate, correct? That makes it pretty fundamentally incompatible for us unfortunately.\nIt is, yeah. Is there a short synopsis for \"fundamentally incompatible\"? That seems surprising.. > Statement having a lifetime parameter attached to it\nAh, yeah, this has come up before. Do you solve this by having statements and rows hang on to Rc'd connections? I've wondered if I could add something like that to rusqlite without duplicating a ton of code. We don't currently have a great story for \"prepare this once and keep it around\" other than an internal cache keyed by the query string.\n\nand bind parameters requiring dynamic dispatch (which basically required boxing)\n\nThis one is tougher to get around, although the part of rusqlite that actually does the dynamic dispatch to bind a parameter is quite small. You want to be able to say \"bind this value of a statically-known type to parameter with index N\"? I'll noodle on that.. Short story long -\nAt some point bindgen started outputting macro-like constants, and libsqlite3-sys was \"double exporting\" a bunch of constants that we had previously included manually (see jgallagher/rusqlite#252). 0.7.2 removed the manual constants, instead relying on the bindgen-generated ones.\nHowever, I made a mistake here - there were manual constants (like the three in the diesel error above) that are newer than SQLite 3.6.8 (the default bindgen bindings chosen if you don't select an explicitly newer version of libsqlite3-sys). The removal of the manual constants means any users of constants that were added after SQLite 3.6.8 just got an unexpected breaking change - sorry about that!\nI'm taking @killercup's suggestion and doing two things:\n\nYanked libsqlite3-sys 0.7.2 (already done a few hours ago)\nPublishing libsqlite3-sys 0.8.0 that includes a feature requiring a SQLite at least as new as 3.7.16, which is when these constraint constants were added.\n\nThe fix to use 0.7.1 works as long as you're linking against SQLite 3.7.16 or newer, but the \"right\" fix will be to use 0.8.0 with the min_sqlite_version_3_7_16 feature enabled. I can PR this to diesel once I get 0.8.0 published.. ",
    "Kintaro": "I meant more in terms of providing client certificates and keys.. Nice. Thanks a bunch. Would really help. We're building a prototype for\nsome financial systems and it worms at the moment with the mysql crate. But\nthe added readability abf exchanfabimity for pg and sqlite would really\nhelp to put it into prod.\nOn Thu, Mar 9, 2017, 20:11 Sean Griffin notifications@github.com wrote:\n\nYes, I will add support for that as well\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/diesel-rs/diesel/issues/786#issuecomment-285323471,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAG0Ca5f8b2wpaGnvXsJcatY81i9n7Zoks5rj94ZgaJpZM4MWdcr\n.\n. \n",
    "marti1125": "Hello I can't connect with Heroku its required: \nAll connections require SSL: sslmode=require.\n. ",
    "packapotatoes": "I am running Linux Mint 18.1 (Ubuntu 16.04)\nI believe I am using postgres 9.6, how can I check for sure?\nHere is the additional output:\nRunning migration 20170313193655\nthread 'main' panicked at 'internal error: entered unreachable code: Per PGs documentation, all errors should have a message', .cargo/registry/src/github.com-1ecc6299db9ec823/diesel-0.11.4/src/pg/connection/result.rs:91\nstack backtrace:\n   0:     0x55c054dba043 - std::sys::imp::backtrace::tracing::imp::unwind_backtrace::h3c67687ba454b78b\n                               at /checkout/src/libstd/sys/unix/backtrace/tracing/gcc_s.rs:49\n   1:     0x55c054db6524 - std::sys_common::backtrace::_print::h701c2403afe49d2d\n                               at /checkout/src/libstd/sys_common/backtrace.rs:71\n   2:     0x55c054dbc19c - std::panicking::default_hook::{{closure}}::h07b8ee04b5734d1a\n                               at /checkout/src/libstd/sys_common/backtrace.rs:60\n                               at /checkout/src/libstd/panicking.rs:355\n   3:     0x55c054dbbd66 - std::panicking::default_hook::h23eeafbf7c1c05c3\n                               at /checkout/src/libstd/panicking.rs:371\n   4:     0x55c054dbc59b - std::panicking::rust_panic_with_hook::hd0067971b6d1240e\n                               at /checkout/src/libstd/panicking.rs:549\n   5:     0x55c054dbc424 - std::panicking::begin_panic::h1fd1f10a3de8f902\n                               at /checkout/src/libstd/panicking.rs:511\n   6:     0x55c054dbc399 - std::panicking::begin_panic_fmt::haa043917b5d6f21b\n                               at /checkout/src/libstd/panicking.rs:495\n   7:     0x55c054d93b06 - <diesel::pg::connection::result::PgErrorInformation as diesel::result::DatabaseErrorInformation>::message::he632342bedd1fc35\n   8:     0x55c054d98c05 - <diesel::result::Error as std::error::Error>::description::he3bf3999aefbb8de\n   9:     0x55c054d977a5 - <diesel::migrations::migration_error::RunMigrationsError as core::fmt::Display>::fmt::hf638487e386e20cb\n  10:     0x55c054de6255 - core::fmt::write::h0dfe169107a72abb\n                               at /checkout/src/libcore/fmt/mod.rs:911\n  11:     0x55c054db2193 - <std::io::stdio::Stdout as std::io::Write>::write_fmt::h334c4f73bdd7ac1f\n                               at /checkout/src/libstd/io/mod.rs:1015\n                               at /checkout/src/libstd/io/stdio.rs:460\n  12:     0x55c054db2fc6 - std::io::stdio::_print::h83b8589704f0a522\n                               at /checkout/src/libstd/io/stdio.rs:680\n  13:     0x55c054caf91e - diesel::run_migration_command::h7aeda08d0b501122\n  14:     0x55c054caa72f - diesel::main::h0e6d44d4297b2522\n  15:     0x55c054dc353a - __rust_maybe_catch_panic\n                               at /checkout/src/libpanic_unwind/lib.rs:98\n  16:     0x55c054dbcd46 - std::rt::lang_start::hb7fc7ec87b663023\n                               at /checkout/src/libstd/panicking.rs:433\n                               at /checkout/src/libstd/panic.rs:361\n                               at /checkout/src/libstd/rt.rs:57\n  17:     0x7f84fac5782f - __libc_start_main\n  18:     0x55c054c84438 - _start\n  19:                0x0 - <unknown>. psql -c 'select version();' gives me\nPostgreSQL 9.5.6 on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 5.3.1-14ubuntu2) 5.3.1 20160413, 64-bit\npostgres --version tells me No command 'postgres' found, is that a problem?\napt-cache show postgresql shows both 9.6 and 9.5 installed. Is this a problem? Should I uninstall one of them?\n@Eijebong up.sql is identical to what is on the getting started page\n. well....I'm an idiot. Instead of editing the created up.sql and down.sql I accidentally made my own new files in the wrong directory. Problem solved, thanks all.. ",
    "arthurnn": "I guess you could try https://konklone.com/post/github-pages-now-sorta-supports-https-so-use-it to add ssl to diesel github pages?\n@parkr will know better.. ",
    "pwoolcoc": "Closing this because I just had to remove the \"sqlite://\" from the URL. Doing DATABASE_URL=/tmp/database.sql diesel setup seems to work fine.. ",
    "genya0407": "@sgrif I understarnd your opinion, and I have no objection to it.\nHowever, then, I think the DateTime<Local> support for Insertable is lack of consistency.\nIf Diesel's position is 'conversion should be explicit in the users of Diesel', DateTime<Local> support for Insertable also should be duplicated.. ",
    "Rukenshia": "Nevermind, just saw that I need to add uuid to my features in the Cargo.toml. . ",
    "skeleten": "The intrigung part in my opinion is, that user_seen executes before (on the ServerCreate event) but only segfaults, when called by the message_create_event function. Is there any additional information I can provide?. It seems my development machine is using\nlocal/postgresql-libs 9.6.1-3\n    Libraries for use with PostgreSQL\nwhile on my host machine it is libpq-dev is 9.5.6-0ubuntu0.16.04. I'm compiling on my development macheni (as server does not seem to have the resources needed to compile the crate) . Stepping through the function with GDB implies its establishing the connection successfully (it does not return early). It seems it won't let me compile on my Arch machine \n``\nerror: could not find native static librarypq`, perhaps an -L flag is missing?\nerror: Could not compile pq-sys.\n```\nThis also happens under a OpenSUSE WSL.\n. I updated the postgres version on my host to 9.6.2 and built it on an ubuntu version with the same version. It still segfaults though.. Trying to compile on my host machine literally runs out of memory :( Maybe I'll upscale it for a bit to try out, though. I did upsize the droplet to be able to actually compile it on the host; it still shows the same behaviour though.\nEdit: On my local VM (Ubuntu 16.04) it works seems to work just fine as well.. ",
    "gnmerritt": "I'm seeing what appears to be a similar segfault when running cargo test on travis-ci or in the travis docker container. The tests pass fine on my mac, and it seems that the problem started when I added multiple tests that make PG connections.\nHappy to try and help run this down, please let me know what additional information I can provide.\ndiesel 1.3.3, postgres 9.2.24\n$ uname -a\nLinux d63a69da3a83 4.9.93-linuxkit-aufs #1 SMP Wed Jun 6 16:55:56 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n$ rustc --version\nrustc 1.32.0-nightly (451987d86 2018-11-01)\n$ cargo --version\ncargo 1.32.0-nightly (1fa308820 2018-10-31)\n```\n...\n21 0x00007f9d33a30837 in ?? () from /usr/lib/x86_64-linux-gnu/libpq.so.5\n22 0x00007f9d33a308d6 in PQfinish () from /usr/lib/x86_64-linux-gnu/libpq.so.5\n23 0x000055bae32e2f76 in _$LT$diesel..pg..connection..raw..RawConnection$u20$as$u20$core..ops..drop..Drop$GT$::drop::h9d3078a13338664b (self=0x7f9d23062240)\nat /home/travis/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-1.3.3/src/pg/connection/raw.rs:101\n\n24 0x000055bae201746f in core::ptr::drop_in_place::h7521eae5e9bdbb05 () at /rustc/451987d86c89b38ddd8c4c124f1b9b6d4ded6983/src/libcore/ptr.rs:194\n...\n```\nexample failing job on travis: https://travis-ci.org/otterandrye/photothing-api/jobs/449963414. there's nothing helpful in the DB logs either, just seeing the connections drop when the test binary segfaults:\n2018-11-05 03:33:29 UTC LOG:  could not receive data from client: Connection reset by peer. I filed an issue against rocket with some more information: https://github.com/SergioBenitez/Rocket/issues/829.\nI'll try rust-san next time I'm on the appropriate machine and report back. I've got the failure reproduced in a docker container with my rocket app. \nOne other thing: I noticed in the libpq docs that you're supposed to call PQfinish even on failed connection attempts so I wonder if that's relevant. . Here's the libpq versions on the container where things are failing:\n$ dpkg --list | grep libpq\nii  libpq-dev                                11.0-1.pgdg14.04+2                         amd64        header files for libpq5 (PostgreSQL library)\nii  libpq5:amd64                             11.0-1.pgdg14.04+2                         amd64        PostgreSQL C client library\nI'm working on getting the environment needed to reproduce into a Dockerfile, will post here once I've got the same failure.. Ok, I've got the segfault reproducible in a container. Here's the Dockerfile: https://github.com/gnmerritt/diesel-explosion/blob/master/Dockerfile. It's libpq versions are:\nii  libpq-dev                                11.1-1.pgdg14.04+1                         amd64        header files for libpq5 (PostgreSQL library)\nii  libpq5:amd64                             11.1-1.pgdg14.04+1                         amd64        PostgreSQL C client library\nTo reproduce you just need to docker build & docker run the container - after it fails you can optionally start a shell and explore with gdb etc. Please let me know if there's anything else I can do to help here, we're well out of my usual comfort zone :-D . I'll give rusttls a try now and report back. \nOther random piece of intel: this seems to have something to do with the travis-ci containers, I wasn't able to reproduce the segfault with either of FROM debian:sid or FROM debian:testing in the docker image. . ",
    "Shnatsel": "If you could compile Diesel with address sanitizer it might be able to provide more specific information on where and why the segfault is happening. You'll need a nightly compiler and pass one flag to it, see https://github.com/japaric/rust-san for details.. ",
    "matthewkmayer": "This looks like an interesting bug!\nLet's try using rustls with 0.35.0 of Rusoto). That should remove any use of openssl from Rusoto, thus reducing the suspected areas of code. That should let us figure out where this issue should be filed, since it doesn't appear to be a diesel issue. \ud83d\ude04 . ",
    "DorianListens": "I've updated the code, but I'm not exactly sure how to test this behaviour. I've looked at the migration tests for diesel_cli, but they do all their testing through the CLI, which makes sense.\nI experimented with adding a new migration subcommand for this, but that doesn't seem very useful. I can push that here if you think it would be a worthwhile addition to the CLI, but otherwise I'd appreciate further guidance on adding tests at this level.. I've pushed up a commit that adds a subcommand here and some tests. As I said previously, I don't know that this is necessary, but I figured I'd put it up so others can comment. I'd be happy to remove this commit if you think thats the right thing to do.. The AppVeyor failure seems to have been caused by a database deadlock, I can't imagine it was introduced by this change.. I've rebased this on master, but looking at #868 it might be better to wait until the suggested refactoring lands and then include this method in the new Migrations struct. Let me know what you think!. Also: the Migrations struct would be a perfect place to add some more tests for this without needing to add it to the CLI.. Updated the implementation to remove the unnecessary braces. Anything else, or is this ready to be merged?. Oh, of course! Thanks!. My change to the .travis.yml file didn't seem to actually get travis to upgrade it's nightly rust version. Is there something else I need to do here?. Yep, that seemed to do the trick!. Whoops!. Sure, I could, but we'd need to make these changes eventually, wouldn't we? Is there a reason to lag behind nightly?. Entirely reasonable. I was operating under the principle that \"rustup update && bin/test\" should \"just work\", but I'm happy to be a little less enthusiastic about nightly releases and instead pin myself to the version in .travis.yml.. I imagine there are probably other instances of codegen producing less-than-helpful errors, but I don't really have any familiarity with the codegen system, so I don't know where they are. I'd be happy to merge this as is, since it makes things better, but I'm also happy to wait and add more improvements to this PR directly.. Great suggestion! I wasn't aware of the .any method!. Works for me!. ",
    "thombles": "A note for anyone finding this later\u2014features are space-separated so the working command is:\ncargo install diesel_cli --no-default-features --features \"postgres sqlite\". ",
    "Gurpartap": "dotenv crate's issue, perhaps. .env file needs to be\nDATABASE_URL=postgres://user:pass@localhost:5432/dbname?sslmode=disable\ninstead of \nDATABASE_URL=\"postgres://user:pass@localhost:5432/dbname?sslmode=disable\"\nAnd now it works.. ",
    "burdges": "Yup, work fine now.  Thanks!  :). ",
    "felipesere": "Nudge... Can this be merged? \ud83d\ude38 \n. ",
    "HarmonEpsilon": "Sure thing.\nCREATE TABLE posts (\n  id INTEGER PRIMARY KEY,\n  title VARCHAR(100) NOT NULL,\n  body TEXT NOT NULL,\n  published BOOLEAN NOT NULL DEFAULT FALSE\n);\nI also cloned the repo and tried compiling Part 3 of the MySQL example and ran into the same problem.. There it goes. It's working now. Thanks.. ",
    "Thomspoon": "Since the diesel_infer_schema seems to only work off of the default SQL types, this might require some direction on how a maintainer can help out.\nedit: I have a custom U24 struct for Mediumint, and BIT is the same as TINYINT(1), which is already handled by the code so a pub type could be used there to finish that one.. I figured primitives were the only acceptable types. If mediumint could just be a i32, that would solve a lot of problems at the expense of one byte per use.. The problem is that the workaround for most other database connectors written in rust is by using percent-encoding, since most are URL based and therefore use the URL parsing standard. The percent-encoding allows you to use your personal password, no matter what it is, without causing errors in the parser for the respective connector. It's as simple as utilizing the percent encoding code already included in the URL crate that is being used for the MySQL portion of the connector.. This seems cleaner than the FamilyLT/RefFamily solution that we came up with in #1833. I was worried about having an Enum for all the possible OIDs, but I'm not sure how feasible that is.. Fixed. Fixed, added new method.. Mostly because above we were discussing using NonNull :)\n. I'll test the ftype call and see if I get valid OIDs out of it!. removed.... @weiznich It looks like the impl for PgMetadataLoop and PgTypeMetadata both query pg_type, which wouldn't be performant. What does the PGftype call in pg/connection/result.rs do that requires us to redefine the OID later?. ",
    "rubdos": "Task list, to keep track:\n\n[x] DECIMAL #1019\n[ ] MEDIUMINT\n[x] VARCHAR #1012\n[x] VARBINARY #1012\n[x] TINYBLOB #1012\n[x] TINYTEXT #1012\n[x] MEDIUMBLOB #1012\n[x] MEDIUMTEXT #1012\n[x] LONGBLOB #1012\n[x] LONGTEXT #1012\n[x] BIT #1012\n\nFeel free to copy this comment in the top. IMO, this makes it easier to keep track of the issue :-)\nedit: Mmm, nevermind. Seems like only MEDIUMINT is missing.. > Yes please :)\nRoger that.. It's optional now; I added it to extras, I hope that's okay.. It should build by now :). It's been rebased on origin/master, and only crates from crates.io are used now.. > Read the code but won't pretend to have understood everything :) I left some general comments.\nThanks for the comments, I'll try to address them all. The initialization of the vector will be a tough one though, but I'll try to figure something out :-). @theduke:\n\nWhat's blocking this?\n\nMe, basically :)\n\nAnything I can do to help out?\n\nNah, I'm finishing this off today. I need it now\n\n@theduke From @rubdos' checklist above I was assuming the bigdecimal release, but maybe that already happend (looking at https://crates.io/crates/bigdecimal)? I guess you could always have a look at https://github.com/akubera/bigdecimal-rs/issues :)\n\nA new release, mostly. I'll trigger that with @iterion and the others at BigDecimal as soon as the ToSql implementation works decently. It's bugged as hell, needs a complete rewrite.\n\nRegarding the other unchecked points:\nOther databases; if someone wants to help here, feel free to file pull requests to my bigdecimal branch on my repo.\n\nI'm fine with landing this for postgres only right now.\n\nRoger that\n\nInitialize the damn digits vector to something senseful.\n\nDon't worry about that, it's really minor.\nDo we want FromSql<>/ToSql<> for f64/f32?\n\n@rubdos, can you elaborate a bit on the use cases? A ToSql impl makes it easy to insert stuff without needing a specific Rust type (just a literal 13.37 should work), so that may be nice. But from what I understand there will probably always be the possible of introducing some inaccuracy in any of these conversions, right?\n\nYes indeed. It would be nice when one doesn't care about accuracy, but it could introduce bugs for people that do care about accuracy.. I cleaned up the commit history a bit, and rebased on master from today.. @sgrif\n\nIf nothing else, this error message should more specifically state that the reason this is treated as an error is that the bigdecimal crate does not provide support for NaN, not that Diesel wishes to treat it as an error\n\nI elaborated the error. Whenever we have that fixed, I'll come back. Classical \"my use case doesn't encounter NaN\", so I would rather have someone interested in NaN's implement this.. Good news, BigDecimal 0.0.7 is out, so this should start building :-). > Okay, this is green! Do you want to do anything more in this PR? I'm not totally up to date on what happened so far, but from the comments it looks like it might actually be good to land?\nWell, the ToSql impl is a bit messy, but if you guys are okay with that currently, it's good for me. I'm using it \"in production\" already :P. I updated on origin/master; now gonna fix the comments.. Well, I fixed what was there to fix! :-). I removed num~~{,-integer}~~ dep~~s~~, and got rid of the merge commit.. See PR #837. Would you be interested in a direct conversion to f64, and f32? If so, we should discuss whether that's a good idea or not; after all, you'd loose some data when doing the conversion, but for avg() it might not even be bad.. > If Numeric is a decimal type, maybe there's a loss-free decimal type available in the Rust ecosystem? Or maybe we could add our own wrapper that can be converted to a float explicitly, if desired?\nI refer again to #837; that directly solves this issue. The loss-free decimal type in the Rust ecosystem is done by the bigdecimal crate, by @akubera, @iterion and me, in collaboration with the num crate. The BigDecimal type allows for a direct conversion to float, which is currently in development.. to_f64 is decently implemented now (before it only gave the integer value), and should be merged soon\u2122.\nNext up is finishing #837; I think all of what I need is available in BigDecimal or its merge requests now.. > Do we want FromSql<>/ToSql<> for f64/f32?\nActually, I want to vote \"no\" on this. Although Rust does very well enforce types, I think this might confuse users. When you have Numeric in your database, you don't \"just\" want to read it out as f64/f32 as a test. Especially since now you can just go extern crate bigdecimal; struct A{a: BigDecimal} and be compatible with diesel...\n\n(Do we want to make this a meta issue for all things Numeric? I can move the todo lists to the main issue descriptions. Also, feel free to add more points, or open new issues for parts of this!)\n\nGood with me.. > Full query/insert example of table using Numeric and struct using BigDecimal\nI grant you this and this file under both Apache 2.0 and MIT licenses; so you can use the code to put it in examples.\nI don't have migrations in that project, but feel free to ask for more files if you want. There are example insertions, and example selections, and even some other fancy logic to make an invoice from them.. Oh that 10k coding... Seems like we need tests sub 10^-4 and super 10^4 thus.. This one stays for today, I'll take a look later.. I added one for 2^64. Mmm. What about \"0.0\"? BigDecimal will probably release some more minor additions before it's 1.0; and it'll be pretty tedious to bump the version every time.. Done :). ",
    "jaemk": "Thanks for reviewing! I've updated with your suggestions and I'll add the changelog entry and new tests shortly!. Changelog entry and tests have been added!. Tests are updated!. migration_list tests are cleaned up. Any way to re-run the appveyor tests without pushing another commit? Looks like it deadlocked on an unrelated test.. Alright, tests are updated and commits are cleaned up.. Since you're doing the work of parsing the connection strings, maybe it would be worthwhile to move it to a separate function and actually pull out all the info. Going off of the following cases:\n// These are the only possible results\n    //   MySQL: [\"mysql:\", \"\", \"[user[:password]@]host\"]\n    //   MySQL: [\"mysql:\", \"\", \"[user[:password]@]host\", \"database_name\"]\n    //   Postgres: [\"postgresql:\", \"\", \"[user[:password]@][netloc][:port]\"]\n    //   Postgres: [\"postgresql:\", \"\", \"[user[:password]@][netloc][:port]\", \"dbname[?param1=value1&...]\"]\nyou could pull everything out with a regex. This would also allow parsing mysql database names that have ? and passwords with non a-z characters (see issue #871 ). See playpen (updated for optional password). @YetAnotherMinion If the full connection string spec needs to be met, then yes it may be beneficial to write up some C-bindings. On the otherhand, if connection strings are restricted to a reasonable subset, I think a regex would work fine. Here's an updated version for optional passwords playpen. The tricky part would be the : being allowed in the username.\n\nAka: We need the specification for connection strings\n\n^ definitely. Yes, using .find looks much better and makes more sense for the test with a bunch of tags! I'll change that up later today.. I left explicitly formatted datetimes out of the expected output in case the migrations::TIMESTAMP_FORMAT ever changes.. It looks like one of the diesel_cli test mods has a migration_generate_creates_a_migration_with_the_proper_name test, but it uses a regex that only verifies the expected length of the timestamp. I'll update that so it asserts the timestamp matches migrations::TIMESTAMP_FORMAT.. Using some form of windows/tuple_windows we can also have a better assertion error message. I think I'll just use std::slice::windows for now so we don't need to pull in itertools (playpen).\n\nIs tag ever a Regex\n\nWoops, you're right, we can just use str::find\n\nRegexSet\n\nThat's really useful!. ",
    "kollapsderwellenfunktion": "i cloned this repository and build redis-cli by myself.(had to deactivate sqlite feature which seems to be broken) and now it works.\ni installed the non working version with cargo install diesel_cli\nstrange. but it now works for me.\n. ",
    "dreuter": "Same here...\nI ran cargo install --force diesel_cli again and the error disappeared.\nMaybe it is worthwhile noting that I installed diesel_cli prior to adding diesel to any Cargo.toml.\nI am also running postgres 9.5.5. ",
    "stanislavkozlovski": "17 | let ordered_names = users.select(name).order(name.desc()).load(&connection).unwrap();\n   |                                                           ^^^^ cannot infer type for `U`\n   |\n   = note: type annotations or generic parameter binding required\nWhat's the proper type I should put here? ordered_names: Vec<String> ?\nHow can I run these tests locally before committing, I feel stupid relying on the CI. Sorry it's a bit hard to write code in comments with nowhere to test it, haha. Will do!. ",
    "AlexNav73": "The problem was in my PATH environment variable. When I append PATH with value of PQ_LIB_DIR it solved the problem.. ",
    "gheoan": "I am affected by this too. I am using MySQL. The CLI should show a message indicating that the database was not installed corectly instead just exiting with no output. Can this issue be reopen?. ",
    "yuana1": "@gheoan   Add 'C:\\Program Files\\MySQL\\MySQL Connector.C 6.1\\lib' to your PATH\n\n. ",
    "aulisius": "The problem lies in the libsqlite3-sys crate I believe\nThe recent commit doesn't export the constants as public. . ",
    "SecurityInsanity": "Seems that appveyor build failed to download rustup, and not something I did:\nappveyor DownloadFile https://win.rustup.rs/ -FileName rustup-init.exe\nError downloading remote file: One or more errors occurred.\nInner Exception: The request was aborted: Could not create SSL/TLS secure channel.\nCommand exited with code 2\nIs there a way I can retrigger that?. > I'm not sure this is the right way to do this, though. First off, cargo features are meant to be additive, but this basically disables a feature. In this case I don't think it's much of a problem.\nYea It's admittedly not the best solution. Really I'd love to just do the work necessary to make CockroachDB a fully supported backend, but:\n\nThat's a pretty big change.\nHas side effects for everyone maintaining this.\nMeans we have to add it to the testing setup, and there isn't a good way to spin one up really without something like docker (a dependency I don't think is worth adding for just cockroach).\n\n\nI'm generally not very happy with these timestamp helpers. Not because of the helpers themselves, they are quite nice, in fact, but that they are an implicitly available feature. I've talked with @sgrif about these helpers in February (not in public chat, sorry) and one idea was to introduce a \"default migration\" (when calling diesel setup) that adds them. This would mean that we need to make this work with existing code bases/migrations though, and it was not worth the effort to revisit this until now.\n\nA default migration being introduced could be a nice change (assuming it could be removed, for say this purpose here (mashing one db to work with another dbs settings)). I'd still think it'd be a worthwhile change so it's easier to tell what's being added by diesel. I'd be interested in taking a look into it at the very least. \n. After digging through default migrations for awhile now. I've run into roadblocks with how that'd work for existing consumers. Any solution I seem to come up with seems subpar.\nHowever that being said I'd really love to get the ability to skip these in. Do you have some ideas about working with existing code bases I could pick your mind on, and/or a way you can think to do this the \"right way\" :tm: ?. ",
    "wadsager": "What roadblocks did you encounter?. ",
    "suryakencana007": "yes i can run but nothing happend\n\nHere the Cargo.toml\n\nMy Rust and Cargo version\n\nThank you for helping me. ",
    "alanhdu": "FWIW I just ran into this but with a column named builder.. Huh... ok then, I've split the builder thing off into https://github.com/diesel-rs/diesel/issues/934.. To add my two cents:\nThe single biggest thing that'd make Diesel easier to learn is to add way more examples.  Basic SELECT, INSERT, DELETE, and UPDATE queries are covered already, but for anything non-trivial it was much easier to look at Diesel's tests than at the API docs. Honestly, I think finding some SQL tutorial somewhere and documenting how to do every single query with Diesel would be a huge improvement.\nIn particular:\n- How do you use GROUP BYs? I can do simple things, but eventually resorted to raw SQL because I couldn't figure out how to do a GROUP BY ___ HAVING filter.\n- I still have no clue how to do a JOIN with Diesel\n- I'm not sure there actually is a guide to dropping down to raw sql() -- I just kind of copy-pastad other code that seemed to work.\n- How do transactions work? I kind of get the gist from reading the tests, but actual documentation would be great!\n- On a smaller note, I wasted a lot of time trying to finding ne_any. - A table mapping operators to functions (or even just a a link to http://docs.diesel.rs/diesel/expression/expression_methods/global_expression_methods/trait.ExpressionMethods.html) would have saved me a lot of time.\n. Oh and also... I'm not sure how feasible this is, but I'd love a guide on how to read Diesel's compilation errors. They get pretty nasty, and sometimes I honestly have no clue how to use them to figure out what's wrong.. ",
    "DavidBM": "One think that I miss, is a list of all possible items. Like possible annotations for models in the struct. Sometimes, just a list of all the items helps as an index to see the possibilities. \nIs not to make the information more easy to read, is to have a entry point to see all the information. \nNow I'm searching if there is any annotation for telling diesel that ignore one field of the struct. I'm searching in the issues, in google, in the docs, but I don't find any place with all the possible functions, macros, annotations, etc of Diesel. In other frameworks I can read the full documentation in case of not finding the answer, here... there is no \"all documentation\". \nAs @alanhdu says in https://github.com/diesel-rs/diesel/issues/853#issuecomment-292817084 in the last point, a list of things that can be done.. Umm, I don't know if I explain correctly the idea, maybe the serde annotation in my code confuses more than helps. \nWhat I was searching is a way to totally ignore that field in the database. That means, Diesel to load (in that case) always None in the author field. For being able to add data after query to the struct.\nOther question than can help. Having this struct:\n```rust\n[derive(Clone, Debug, Queryable, Serialize, AsChangeset, Identifiable, Associations)]\n[has_many(authors)]\npub struct User {\n    pub id: i32,\n    pub email: String,\n    pub author: Vec\n}\n``` \nis possible to have something like #[loads_has_many(authors)] to tell diesel to load all the authors in that field?. Ok, you understand correctly :)\nThanks! I will check this frequently!. ",
    "blanham": "Perhaps it might make sense to create a new repo specifically for the diesel.rs homepage? At the very least the existing guide could be expanded.. ",
    "notryanb": "Update - I'm currently working on updating the Associations docs for v1.0 and a separate guide for Joins.. Now that df5a6e8d39c001a6ebe0944ee34a2068316fbacb has been merged, I believe this can now be closed.. @hobofan - Just checking in to see if you're still working on this issue (or need help?). I think it is still a good idea and would be helpful with the 1.0 release just around the corner.. @killercup Thanks for all the input! I'll start working on these changes.. Revisions from this weekend\n- Implemented ref links\n- Added a small conclusion section\n- Changed some verbiage in a few sections, removed some redundant points.\n- Fixed a few markdown formatting issues.. @killercup @sgrif - I made some small changes to Queryable. I felt I wasn't conveying its purpose correctly, so I changed some verbiage and updated the example.. @killercup - I'd like to tackle this issue. I think I may be able to also solve #624 while doing this?. \ud83d\udc4d I'll look into #624 separately.. Updated a few things @sgrif @killercup @Eijebong \n- invalid table! macro error is now more actionable & tests were updated\n- diesel_infer_schema/src/inference.rs error now references the correct crate\n- diesel_cli now has a compile_error! for being installed without any backend specified.. @sgrif I think that makes sense. It's redundant and confusing if they're both reporting the same error with different messages.. I'd like to start working on this, if no one else has already claimed. I'm also open to working with someone if they would like to help out.. @weiznich - Good point. I have an issue open - #1235 addressing the associations docs (mostly just the examples), but I'll adjust the explanations as well.. \ud83d\udc4d . LGTM \ud83d\udc4d . Also - are there any performance benefits to using two args instead of a range?. LGTM \ud83d\udc4d. This PR is a WIP. I'm still working through the docs and taking notes. . @sgrif @Eijebong @killercup Haven't heard anything in a while about this - Just checking in.. LGTM \ud83d\udc4d\n@Ppjet6 I think a redirect might be a good idea if we want to force TSL for some reason? I don't really know enough to make a sound decision, but I'm assuming this helps with SEO?\nside note - is there a way to 301 http -> https for docs pages?. @killercup @Eijebong - I'd like to merge this. Good to go?. @sgrif Is this slated for the 1.0 release?. Has this caused problems in the past (anyone complained about those crates showing up) or do you think it just generates \"noise\" for crates.io search results? Either way, it makes sense for these specific crates.. @sgrif - I'm interested in this after I get some of the documentation / guide issues out of the way.. @sgrif - I will close out #1305 once we can merge this - as this PR does a much better job.. @sgrif @weiznich Just checking in. The CI failure looks to be unrelated to the implementation.. Resolved in #1657. Where in the docs do we mention\n\nWe have stated in the past that folks should not rely on the exact types used in impl Backend\n\n?\nThis PR looks good to me and I agree it is unlikely that this would be a breaking change for the majority of users.. I definitely like talking about the QueryResult and I think this point will be illustrated better by type annotating the let binding like you have shown. \nMy only concern is for the current guide on the Diesel website. All the examples I've seen use the turbofish and I would just like to maintain consistency. Is one of the ways more idiomatic || rusty? . I'll look into the formatting for this. It is under .load. Looks fine in vim && my markdown preview, but there might be some inconsistent spacing issues from when I pasted it from the cli.. Awesome! \ud83d\ude04 . I want to make sure this PR abides by Diesel (unofficial) Contributing docs. :smile: . I originally thought this should be a bulleted list for a quick reference, but that is not how the rest of the guide is structured. \nHow about...?\n\nThere are some considerations to be made when implementing the Queryable trait. First, you must include all the table's fields in your model struct. Queryable needs to know how many columns are in each row in order to build() that row. Also, your struct should be named in the singular form of its corresponding table name, as Queryable does not support the #[table_name=\"\"] attribute.. whoops! That will be omitted. The next line is what I was trying to convey.. I think this is a really important point. I'm coming from a rails background, so this seemed alien at first. I'll think about a good spot to add it.. \ud83d\ude01 . Should that link appear in the error message or a comment just above the code?. Ah, good point! I totally forgot about this.. @sgrif Do you think this line warrants line breaks (just over 80 chars)? I'm referencing #120 long function signatures.\n. No longer takes range? Should this say \"using given bound\"?. Same thing here. . Tools & Libraries? \ud83e\udd14 I think what you have written does a good job (Crates as the heading). Technically, each one of those \"components\" is a crate and there is a short description detailing its purpose. I don't see any ambiguous language that would confuse someone or inhibit them from getting to the correct documentation from your links. \n\n... although, they are \"containers\" that \"hold diesel\" code. We can call them Tanks.. \ud83d\ude06 . Awesome! I misunderstood the current docs. I'll make note of this as well.. @killercup I've used write-mode=diff recently because the local rustfmt version I have is newer than CI and caused my PR to fail after formatting. I suppose it would show up in a git diff anyway, but I did find it helpful.. \ud83d\ude06 . Good point. I've seen people ask questions re: multiple structs for same table before (the code example shows that \ud83d\ude04 ).. @weiznich - I'm still becoming familiar with rust idioms and clap! \ud83d\ude05. From what I understand, Pathbuf::from indicates that you expect the MIGRATION_DIRECTORY value will always convert without fail. Why do we need to chain .or_else and then match on the subcommand (name?, not sure which value of the tuple 1 represents)?. Awesome!!! \ud83d\ude04  Thanks so much! I'll finish review ASAP this week (unless someone else beats me to it).. @weiznich Add the definitions for the doc-test example or re-word the preceding paragraph? The tables are imported via doctest_setup.rs.. @weiznich  Ugh, I realized I read that comment completely wrong (...right when I woke up). I plan to have a separate guide covering manual trait implementation. The idea is that it will be tied to more specific use cases, while this guide is a general overview.. <3. Should we mention #[macro_use] extern crate diesel; anywhere?. What does the r# do here or is it a typo?. Lots of \"this\". Maybe reword this block to something similar to...\n\nDiesel ensures that your queries are valid at compile time by knowing about your schema. This is done using  [the table! macro][table!], which is usually generated by diesel print-schema or [infer_schema!]\n\n?. docs are hidden for this function Does it still need to be inlined?. Should we follow a particular style for derives (or is this rustfmt's fault...)? There are a few derives in this PR that split lines like this into the following format, which group traits (by origin?). I'm fine with the inconsistency - just checking.\n```\n[derive(Debug, Clone, Copy, PartialEq, Eq)]\n[derive(Queryable, Insertable, Associations, Identifiable)]\n``. @sgrif I'm not 100% convinced this is a great example, as I don't want to mislead readers about joins. However, it does illustrate thatQueryableByName:\n- doesn't have to be restricted to a single table\n- May reference columns not available in schema\n- Supports nestedQueryableByName` structs\n- You can mix the annotations (table_name / sql_type)\nIs there a common use case that might illustrate this better? . haha! It seemed to make total sense that the compiler could figure that out, but I didn't actually try it. . This is a good point. I'll update this test case.. Any examples of this elsewhere?. Ack, I totally forgot about this!. @sgrif Do we need this method? If we don't plan on supporting .filter(sql(\"id > 1\").sql(\" AND name <> 'Ryan'\"))... I think I can omit this.. Does this create diesel.toml in the project root if it doesn't already exist?. ",
    "aliyazdani": "I'd love to see more docs too - especially for sqlite.  This is my first try at Diesel with Sqlite3.  Most of the examples I find are for PG and unfortunately we don't have that option atm.  The examples on the repo for sqlite are extremely basic.  I managed to get my inserts and updates working but a basic select query is generating a ton of compiler errors that are hard to understand.  I can't imagine what a join requires.\nI'd be happy to lend a hand if needed (even though I'm still a Rust noob at this point).  Thanks!. ",
    "wangzhengqing": "i have readed the document. but i still dont know how to use \"use schema::posts::dsl::*\". diesel created these models or i have to write by myself?  i really dont know how to do it.. ",
    "u2": "$ cat test.sql    \n\\set aid random(1, 100000 * :scale)\n\\set bid random(1, 1 * :scale)\n\\set tid random(1, 10 * :scale)\n\\set delta random(-5000, 5000)\nBEGIN;\nINSERT INTO distributors (did, name) VALUES (3, :bid);\nEND;\n(pyethapp)\n$ pgbench -c 15 -t 300 pgbench -r -f test.sql  \nstarting vacuum...ERROR:  relation \"pgbench_branches\" does not exist\n(ignoring this error and continuing anyway)\nERROR:  relation \"pgbench_tellers\" does not exist\n(ignoring this error and continuing anyway)\nERROR:  relation \"pgbench_history\" does not exist\n(ignoring this error and continuing anyway)\nend.\ntransaction type: test.sql\nscaling factor: 1\nquery mode: simple\nnumber of clients: 15\nnumber of threads: 1\nnumber of transactions per client: 300\nnumber of transactions actually processed: 4500/4500\nlatency average = 1.039 ms\ntps = 14436.819665 (including connections establishing)\ntps = 14607.259483 (excluding connections establishing)\nscript statistics:\n - statement latencies in milliseconds:\n         0.001  \\set aid random(1, 100000 * :scale)\n         0.001  \\set bid random(1, 1 * :scale)\n         0.000  \\set tid random(1, 10 * :scale)\n         0.000  \\set delta random(-5000, 5000)\n         0.172  BEGIN;\n         0.244  INSERT INTO distributors (did, name) VALUES (3, :bid);\n         0.365  END;\n(pyethapp)\nwhile excluding establishing connection, the tps is about 14607.259483.\nbut when I change to one connection and one thread:\n$ pgbench -c 1 -t 1 pgbench -r -f test.sql  \nstarting vacuum...ERROR:  relation \"pgbench_branches\" does not exist\n(ignoring this error and continuing anyway)\nERROR:  relation \"pgbench_tellers\" does not exist\n(ignoring this error and continuing anyway)\nERROR:  relation \"pgbench_history\" does not exist\n(ignoring this error and continuing anyway)\nend.\ntransaction type: test.sql\nscaling factor: 1\nquery mode: simple\nnumber of clients: 1\nnumber of threads: 1\nnumber of transactions per client: 1\nnumber of transactions actually processed: 1/1\nlatency average = 5.903 ms\ntps = 169.405387 (including connections establishing)\ntps = 487.329435 (excluding connections establishing)\nscript statistics:\n - statement latencies in milliseconds:\n         0.031  \\set aid random(1, 100000 * :scale)\n         0.002  \\set bid random(1, 1 * :scale)\n         0.000  \\set tid random(1, 10 * :scale)\n         0.001  \\set delta random(-5000, 5000)\n         1.834  INSERT INTO distributors (did, name) VALUES (3, :bid);\n(pyethapp)\nI am a bit confused, why it's slower than diesel. The cargo bench is not in one thread?. Thank you.. ",
    "matt4682": "I think the only real use case for skipping a field on Queryable would be to imitate the classic ORM approach to associations.\nUsing the example code from the association docs:\nrust\nlet user = try!(users::find(1).first(&connection));\nlet posts = Post::belonging_to(&user).load(&connection);\nthen you would make posts a proper child of user:\nrust\nuser.posts = posts;\nThe docs say that you could pass it around as (User, Vec<Post>) but that doesn't exactly play nicely with serializing to JSON, which seems to be the initial reason behind this issue. The typical JSON representation would be:\njson\n{\n   \"id\": 0,\n   \"name\": \"Foo\",\n   \"posts\": []\n}\nBut passing it around as a tuple would have it represented as:\njson\n{\n  \"user\": {\n     \"id\": 0,\n     \"name\": \"Foo\"\n  },\n  \"posts\": []\n}. ",
    "TatriX": "My use case. I have a struct:\n```rust\n[derive(Deserialize, AsChangeset)]\n[table_name = \"users\"]\npub struct UpdateUserData {\n    username: Option,\n    email: Option,\n    bio: Option,\n    image: Option,\n    #[skip_somehow_plz]\n    password: Option,\n}\n``\nI use this struct to parse POST params and then I'd like to use it as a changeset.\nBut my table doesn't have apasswordfield. It hashash` field.\nSo I want to skip password field in the changeset and set hash manually based on password.. As far as I know this depends on #1512\nOriginal use case currently can be fulfilled with nested structs and query with join.\nExample from @weiznich:\n```rust\n[derive(Queryable)]\nstruct Foo {\n    id: i32,\n    name: String,\n    bar: Bar,\n}\n[derive(Queryable)]\nstruct Bar {\n     id: i32,\n    name: String\n}\nlet r: Vec = foo::table.inner_join(bar::table).select((foo::id, foo::name, (bar::id, bar::name)).load(conn)?;\n```\nI'm ready to take this issue if you think this should be implemented.. It has a good use case to be implemented on Quaryable too. Basically it's the same as with Insertable.\nI want to be able to reuse the same struct to do select queries, then fill the Option<NestedStruct> from another select and pass it to the json serializer.. ",
    "carlosdp": "I have the same use case as @TatriX, the reason I want the field to be in the same struct as Insertable is because I use it for field validations as well.. It looks like the fmt is running on 1.26 but I'm on the latest stable 1.28, and maybe they format differently?. Gotchya, should be good to go now @weiznich . ",
    "mikhail-krainik": "\nI've definitely warmed to the idea of marking a field as ignorable for update/insert (to skip a field for update, you can always use my hilarious, hacky workaround for now. I'm not sure I see the use case for skipping something on Queryable though. If you want to populate other data after loading, it seems like it'd make more sense to have another struct that is struct Foo { data_from_database: DbModel, other_data: whatever }\n\nThe link is broken. Could you repeat your solution? I have a structure with only one field other in update and create action (e.g. upsert action), and I want to use one struct with more than 40 fields in two cases.. ",
    "fbruetting": "Diesel.zip\nI extracted a minimal example out of my program for you.\n\nFor showing the error, just run diesel migration run --database-url data/test.db and cargo build.\nFor successful compilation, fill in the missing NOT NULL in the migration up.sql file, delete the database and the target directory, create the database again and run cargo build.\nAfter a successful compilation, you can delete the NOT NULL statement again in up.sql, and it still will compile fine.\nHere you can delete the target directory, and the full compilation runs fine.\nNow you delete the database and create it again (without the NOT NULL statement), and incremental compilation still runs fine.\nIf you THEN delete the target directory, you'll have a full compilation, and the error appears!\n\n\n\nThere should be a better error message, if there's an error in the up.sql. Assuming something that should be, is always a source of problems \u2013 please handle this more strictly!\nOther question: Why doesn't Diesel work without these NOT NULL statements?\n// PS 1: Why is a completely empty database file created at compilation, if I don't create it by running the diesel command?\n// PS 2: How can I put the migrations directory into my db directory?\n. Would be cool if this could be merged. Diesel currently doesn\u2019t align with the Rust book, so it is hard for beginners to grasp, why we need to use external crate, as this command is not introduced in the book anymore! By needing to place this into the crate root, Diesel also violates the privacy aspect of modules, described in the book.. ",
    "sganz": "I found this page for PG\nhttps://www.postgresql.org/docs/9.5/static/libpq-connect.html\nHas a line in it - Percent-encoding may be used to include symbols with special meaning in any of the URI parts. \nI may not be thinking the right way on this but seems it's OK to encode it. Because the characters are not valid (from a specific db perspective) might be another concern. The hope is that all connectors have similar mechanism to encode. \nTake this all with a grain of salt as I'm new to rust, new to diesel.\n. ",
    "iH8c0ff33": "@sgrif \nI'm really sorry for having been that dumb. Thanks for the time you spent helping me.. ",
    "m-r-r": "Thanks for responding so fast!\nThat's the first time I open an issue and someone replies literally 2 minutes later :-)\n\nCan you ensure that there is only one version of uuid in your Cargo.lock?\n\nIf I am not mistaken, there is one version of uuid in my project :\nconsole\n$ grep uuid     \n \"uuid 0.4.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"uuid 0.4.0 (registry+https://github.com/rust-lang/crates.io-index)\",\nname = \"uuid\"\n\"checksum uuid 0.4.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"7cfec50b0842181ba6e713151b72f4ec84a6a7e2c9c8a8a3ffc37bb1cd16b231\"\nI use the same version requirement as diesel (I copied it from Diesel's Cargo.toml):\ntoml\nuuid = \">= 0.2.0, < 0.5.0\"\n. >Remove the use uuid::Uuid; lines from your table! invocations. That should fix your problem.\nIt works ! Thanks for your help :-). ",
    "TruputiGalvotas": "Well, for example own/next-cloud allows to use either sqlite or mysql. In other words, I'd like wirte an application which is database agnostic - meaning user could choose which backend to use. Although I don't know if this makes any sense..\nAnother example could be - if I wanted to write a framework for writing applications - a struct field would hold a generic database connection which I would use over load() function.\nYou can just say that it's stupid or impossible with diesel... ",
    "markcatley": "Attempting to fix #795. Not 100% sure this will completely solve the problem, but it has it's a good shot at it.. ",
    "Nukesor": "Ok. cargo update -p chrono --precise 0.3.0 temporarily fixes this issue.. ",
    "fluffysquirrels": "Arc<Mutex<T: Send>> already implements Sync automagically (Mutex docs) and Connection requires Send. So can you just wrap transactions in Arc<Mutex<T>> in your app?. ",
    "Nemo157": "Ok, I think I understand, there's actually sort of two parallel worlds of Rust values and SQL expressions which use either Option or Nullable for wrapping non-nullable entities into nullable ones. It would be great if the API docs could mention this somehow, but I guess putting something on the impl<T, ST> AsExpression<Nullable<ST>> for Option<T> where ST: NotNull needs https://github.com/rust-lang/rust/issues/18701 still.. ",
    "behos": "I've created something along these lines for the new structure here\nhttps://github.com/behos/models-derive\nUsed like https://github.com/behos/models-derive/blob/master/tests/default_insertable.rs#L20\nbut i haven't published this as a crate since I'm not 100% sure it's complete. I'd be happy to get some feedback and ideas/contributions around that. ",
    "jaroslaw-weber": "Error messages in diesel look too much like tokio errors - if you mistype or make a mistake it tends to throw out very long errors. although it is scary at first, fixing wasn't that difficult (just start at the top)\nEven if you can still read through messages and fix the problem, I miss the simple error messages without diesel.. ",
    "berkus": "@willmurphyscode there's definitely more to be done:\nerror: proc-macro derive panicked\n  --> src/models.rs:68:10\n   |\n68 | #[derive(Insertable)]\n   |          ^^^^^^^^^^\n   |\n   = help: message: failed to parse type: failed to parse all tokens\nin the recent diesel 1.2.2 and I have no clue what it's talking about.\nthe struct in question for posterity:\n```\n[derive(Insertable)]\n[table_name = \"alerts\"]\npub struct NewAlert<'a> {\n    pub guid: &'a str,\n    pub title: &'a str,\n    #[column_name = \"type\"]\n    pub alert_type: &'a str,\n    #[column_name = \"startdate\"]\n    pub start_date: NaiveDateTime,\n    #[column_name = \"expirydate\"]\n    pub expiry_date: Option,\n    pub faction: Option,\n    pub flavor: Option,\n}\n```\nUpd: it apparently blows on\n#[column_name = \"type\"]\n    pub alert_type: &'a str,\nI changed it to use #[column_name = \"type_\"] but not sure if this is correct - it's not documented anywhere.. I will send you full project repo in a bit.. Here's the repo: https://github.com/berkus/diesel-belongs-to-bug/blob/master/README.md\nsteps to reproduce:\n1. git clone https://github.com/berkus/diesel-belongs-to-bug\n2. cd diesel-belongs-to-bug\n3. cargo run\n(i'm using nightly jfyi). Thanks!. Ok, will add this to my codebase.. And probably many more will..\nIs it possible to add this simple function in diesel just once instead?. ",
    "mcgoo": "Added a commit to generate an import library to fix the msvc tests also.. It should be there as long as the AppVeyor build machine doesn't change radically. It's the version from Visual Studio 2013, but any of the 10-odd tool chains on the image would be fine. I somewhat arbitrarily chose the version from VS2103 since mysql also requires VS2013 at this point (although I have an incoming PR that allows 2015 and 2017 to work with mysql also.)\nThe other alternative I was able to think of was to put the VS tools in the path, but that is a global change that will indirectly affect rustc and this way will not.. Failed due to a network error - could someone please retry?. Great, thanks a lot! Would you like me to add the one step install script and/or some documentation to diesel itself? If so, where should it go, bin/install_windows.cmd?. Hmm, maybe just make the appveyor script delete it before it does anything then?. ",
    "king6cong": "yeah, this deals with multiple concurrent sqlite writers.\nthere are some discussions like here:\nhttps://github.com/mattn/go-sqlite3/issues/274\nand also these documentations:\n\nhttp://www.sqlite.org/cvstrac/wiki?p=MultiThreading\nhttps://www.sqlite.org/c3ref/busy_timeout.html\n\ntldr:\n\nSQLITE_BUSY will occur inevitably when there are multiple thread writers and we need to handle this\nadd busy timeout will reduce the SQLITE_BUSY situation\nat the moment, diesel will panic in step when SQLITE_BUSY occurred, I think log it maybe better for users at the moment. Better error handling should be saved for another commit :)\n\nreference: https://github.com/jgallagher/rusqlite/blob/master/src/row.rs#L43\n. Updated :). @sgrif @killercup These changes turn out working well in our project, any ideas? . I also think it is helpful to have a more powerful migration method, considering sometimes sql alone is not enough.\n  . ",
    "seanmonstar": "I recently just had the exercise in the reqwest crate. I also considered error_chain, but only briefly. I considering a public facing enum to be the wrong design, because it's impossible to add new variants, and it exposes the exact representation of how you store the errors. For reference, here's the reqwest error: https://github.com/seanmonstar/reqwest/blob/master/src/error.rs. Yea, and while shame on anyone actually matching on such a variant, it is possible, and it would break crates or apps that did it when you add a new variant.\nHowever, enum fields are all public, so if you were to, say, decide to stop storing some errors as boxes and instead of the normal values, you can't do so with a public enum. You could if it were in a private struct field.. ",
    "steverob": "@sgrif it makes sense to go for a through association for this. But, would it not be nice to let the developers choose the appropriate approach here and diesel giving them all options? :). ",
    "juliusdelta": "@Eijebong I'll take this if that's cool. Should have put skip-ci in the commit. Whoops.. Would love to work on this @sgrif if that's cool.. Awesome. i'll try to submit a PR tomorrow afternoon. Ty. So there's a few ways to accomplish this, but the most apparent but \"not so elegant\" way to do it is wrapping an if statement before the writeln!() function that outputs Running Migration 00000000000000.\nSomething like:\n/diesel/src/migrations/mod.rs#L267-L277\nrust\nfn run_migration<Conn>(conn: &Conn, migration: &Migration, output: &mut Write)\n    -> Result<(), RunMigrationsError> where\n        Conn: MigrationConnection,\n{\n    conn.transaction(|| {\n        if migration.version() !== \"00000000000000\" {\n            try!(writeln!(output, \"Running migration {}\", migration.version()));\n        }\n        try!(migration.run(conn));\n        try!(conn.insert_new_migration(migration.version()));\n        Ok(())\n    })\n}\nIt definitely seems like it could be cleaner but I didn't want to over think it. \nThe thought hole I went down was: at this point the version field is already defined on the migration at this point right? So just checking if it exists isn't possible in this scenario.\nI suppose I could also check if the first version equals the last version which might look nicer imo but it's not as clear if you're reading it -> If I'm understanding the architecture correctly that is.\nThoughts? @sgrif @Eijebong . Sounds good! \ud83d\udc4d  I'll get that done. Thanks for the direction!. Done @Eijebong \ud83d\udcaa . Ty guys. That was my first non-documentation PR to an open source project. Thanks for being so helpful. @Eijebong @sgrif . Should this issue be closed per #1094 ?. @killercup I Can take this since I'm pretty familiar with that code if that's cool!. So the first way I can think to do this would be:\n\nI could just print & parse the migration.file_path() which returns something like: \"/path/diesel_cli_test/migrations/20170924041631_create_posts\". Then parse it to just print 20170924041631 -> Create Posts (or something similar) and use that to replace https://github.com/diesel-rs/diesel/blob/master/diesel/src/migrations/mod.rs#L313 and corresponding revert output.\n\nIt'd have to be it's own method for sure. I'd probably call it migration_output_information() or something.\nThoughts?. Actually std::Path might have what I need to parse the path https://doc.rust-lang.org/std/path/enum.Component.html. Nice. Is the best way to get started to just review and add comments/questions to PRs?. Sure that\u2019d be great!. I've updated the commits after some help from @sgrif this should be good to go. If I need to add to changelog.md just let me know and I'll rebase and get that done.\nI was able to use file_name() to get the name instead of that weird chain of manipulation turning the path components into a collection then pulling the last one in that collection. Sean pointed me towards the std::path docs to use that. \nFor manual testing, just checkout this branch and run/revert a migration. You should see the output of the filename instead of just the SQL date stamp.. I managed to change CI's mind.. Sorry just got back from a vacation of sorts. Checking into these changes now.. I rebased on master to handle conflicts.. Ok will take a look. I only got moderately fancy. I called bankruptcy and archived the old branch and made a new one after rebasing on master and copied my changes over to the new files. I didn't have the brain power to figure out the \"proper git solution\" lol. Hopefully this is good now. Shall I add to the changelog as well @sgrif?. Ok Implemented Copy on the MigrationName struct.. Done. Maybe a configuration section would be good with different config options and supported DB's? Rocket has a brief one on their docs.\nLike:\ndiesel = { version = \"0.15.0\", features = [\"postgres\"] }\ndiesel_codegen = { version = \"0.15.0\", features = [\"postgres\"] }. @killercup I'm confident it wont.. It hit me after the fact that the good-first-issue label is on the issue and it's definitely not my first issue. Feel free to close this PR if necessary. \ud83d\ude05 . Will do. Sorry about that.. \ud83d\udc4d I'll fix that and squash the commits. Sure thing!. Done. Fixed. Rocket uses 'Libraries' which I think is what I would suggest here. Super stoked for this to be done btw.. Good point. Hm. I'd almost suggest Crates & Libraries but there's only 3 things. . Now that I re-read these, I'd probably change this to the inverse and 2 sentences.  \"A type that doesn't implement this trait means that it doesn't have a return type. It doesn't mean that it isn't a complete SQL query. For example,...\". Tbh I'm no1 100% sure if it should as I'm unfamiliar with the case in which it's necessary. If you think it should I can add it as well.. @sgrif I had but changed it back for some reason, and I can't quite remember why. Anyway, since an embedded migration would return None for file_path() I can just add an else like:\nrust\nimpl <'a> fmt::Display for MigrationName<'a> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let file_name = self.migration.file_path()\n            .and_then(|file| file_path.file_name())\n            .and_then(|file| file.to_str());\n        if let Some(name) = file_name {\n            f.write_str(name)?;\n        } else {\n            f.write_str(self.migration.version())?;\n        }\n        Ok(())\n    }\n}\nto handle that case. Right?. ",
    "hobofan": "Duplicate of https://github.com/diesel-rs/diesel/issues/588. @notryanb Sorry, I got tied up in a fulltime freelancing contract the last two months. I'll be free again beginning next week, and this is one of the first things I'll work on!. I'm so sorry everyone that I was holding up this important part of the documentation for so long. I'm sadly constantly finding myself busy with other stuff and also haven't used Diesel since writing my last comment here, so I don't think I can write the documentation at the level it deserves.\nIt's probably best if someone else who is using this project more takes on this issue.. ",
    "NoraCodes": "OK, gotchya, thanks! Good to know that this is done, I'll close :). ",
    "Measter": "Apologies for missing this issue; apparently my google-foo isn't as good as I'd hoped.\nIn terms of re-name syntax, I'm not massively familiar with writing macros, but is it possible to do something like this:\ntable! {\n    users {\n        id -> Integer,\n        name as username -> Text\n    }\n}\n. ",
    "elliotekj": "\nDiesel 0.13.0 does not support chrono 0.4\n\nAh, that's probably what the problem is then! I saw this line and assumed it did.\n\nCan you try using diesel master instead?\n\nI wasn't expecting such a quick reply, I'll try it out as soon as I'm back at my work machine and let you know.\n\nVery nice issue description! (We should steal this and make it a template!)\n\nThanks! I can't take credit for it though, I just filled in the details you ask for :). Right. So Diesel's master gets me past the original issue but I now have a different \"this error originates in a macro outside of the current crate\" error:\nerror[E0277]: the trait bound `diesel::pg::PgConnection: diesel::connection::Connection` is not satisfied\n  --> src/database.rs:6:1\n   |\n6  | / lazy_static! {\n7  | |     static ref CONNECTION: r2d2::Pool<ConnectionManager<PgConnection>> = {\n8  | |         let config = r2d2::Config::default();\n9  | |         let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n...  |\n12 | |     };\n13 | | }\n   | |_^ the trait `diesel::connection::Connection` is not implemented for `diesel::pg::PgConnection`\n   |\n   = note: required because of the requirements on the impl of `r2d2::ManageConnection` for `r2d2_diesel::ConnectionManager<diesel::pg::PgConnection>`\n   = note: required by `r2d2::Pool`\n   = note: this error originates in a macro outside of the current crate\nThings I've tried:\n\nGetting diesel_codegen from master too\nGetting r2d2-diesel from master (though I wasn't expecting that to change anything since there hasn't been a commit to it since the last release)\nMade sure I'm using the latest versions of r2d2 and r2d2-diesel.\n\ndatabase.rs:\n```rust\nuse diesel::pg::PgConnection;\nuse r2d2;\nuse r2d2_diesel::ConnectionManager;\nuse std::env;\nlazy_static! {\n    static ref CONNECTION: r2d2::Pool> = {\n        let config = r2d2::Config::default();\n        let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n        let manager = ConnectionManager::::new(database_url);\n        r2d2::Pool::new(config, manager).expect(\"Failed to create pool.\")\n    };\n}\npub fn connection() -> r2d2::Pool> {\n    CONNECTION.clone()\n}\n```\nFeel free to close this when it gets too off topic from the original issue /  becomes too specific to just how I'm using it.. @killercup You're a gentleman and a scholar! Thanks so much for taking the time to help!\n\nFor anyone else who finds themselves here:\nAdd Diesel and co. as you would usually:\ndiesel = { version = \"0.13.0\", features = [\"postgres\", \"chrono\"] }\ndiesel_codegen = { version = \"0.13.0\", features = [\"postgres\"] }\nr2d2 = \"0.7\"\nr2d2-diesel = \"0.13.0\"\nAs @killercup said, replace the version of Diesel you're using like so:\n[replace]\n\"diesel:0.13.0\" = { git = \"https://github.com/diesel-rs/diesel\" }\nRun cargo update to make sure r2d2-diesel is using the latest version of Diesel it can.\nBuild.\n\nThanks again @killercup \ud83d\ude04. Just confirming that Diesel 0.14 does indeed resolve the above issues. Good work folks \ud83d\udc4d. ",
    "greenpdx": "I have read this and I still do not understand the fix. \nI am tried both diesel 0.16.0 and master  c5fa99574673e09e6e5029cda517802a82f66933\nI have a postgress table with a TIMESTAMP column.\nerror[E0277]: the trait bound models::chrono::NaiveDateTime: diesel::types::FromSqlRow<diesel::types::Nullable<diesel::types::Timestamp>, diesel::pg::Pg> is not satisfied\n  --> src/main.rs:98:10\n   |\n98 |         .get_result(conn)\n   |          ^^^^^^^^^^ the trait diesel::types::FromSqlRow<diesel::types::Nullable<diesel::types::Timestamp>, diesel::pg::Pg> is not implemented for models::chrono::NaiveDateTime\n   |\n   = help: the following implementations were found:\n             >\n             >\n   = note: required because of the requirements on the impl of diesel::types::FromSqlRow<(diesel::types::Integer, diesel::types::Nullable<diesel::types::Timestamp>, diesel::types::Text), diesel::pg::Pg> for (i32, models::chrono::NaiveDateTime, std::string::String)\n   = note: required because of the requirements on the impl of diesel::Queryable<(diesel::types::Integer, diesel::types::Nullable<diesel::types::Timestamp>, diesel::types::Text), diesel::pg::Pg> for models::Tst1\n   = note: required because of the requirements on the impl of diesel::LoadQuery<diesel::PgConnection, models::Tst1> for diesel::query_builder::insert_statement::InsertStatement<schema::__diesel_infer_schema::infer_tst1::tst1::table, (diesel::insertable::ColumnInsertValue<schema::__diesel_infer_schema::infer_tst1::tst1::columns::methd, diesel::expression::bound::Bound<diesel::types::Text, &std::string::String>>,)>\nerror: aborting due to previous error\n. I have been dealing with MS breaking things for 40 years. If it is not a MS product, the functioning is always just a little broken. Since they broke skype and linkedin, now they own github, I assume they broke it.. ",
    "GopherJ": "I know It's a closed issue but I encountered another similiar error: *const str: diesel::deserialize::FromSql<diesel::sql_types::Timestamp, diesel::pg::Pg, anyone knows how to fix it?. I know this is a closed issue but I still get this warning after addding  #[allow(proc_macro_derive_resolution_fallback)] in src/schema.rs and models.. @weiznich  Thank you so much for saving my day! Sorry for my mistake, I didn't notice that.. ",
    "kieraneglin": "Thank you!\nThat did it.  Now it's giving me an error saying that it can't parse Datetime, but I'll try and sort that one out on my own ;)\n. Hmmm. Good point.  But honestly, I'm willing to bet it's a \"me problem\" ;). I'll try to flesh out the issue and I'll add a comment here if it turns out to be at all related to this.  Just in case it helps out another beginner in the future.\nUnrelated, but would a PR for an issue template be welcomed? \nThat aside, I'm happy with this solution and I'll close the issue. Thank you again for your help!. Update: The issue was because I had a raw-SQL seed file.  Like you said, if I entered the data through Diesel, everything worked as expected.. I've updated the template per your suggestions!  I also remove the *Description* lines.  They didn't provide anything meaningful, so I added spaces instead.. If you're using Chrono as a diesel feature, what version are you using?\nI thought it'd be good to add the versions of any diesel \"plug-ins\" they may be using. . Ah!  Good point!  My internal Rust novice is showing.  Will fix . ",
    "Fuckoffee": "@adwhit  Thank you so much, it works!. ",
    "chenshuiluke": "Thanks! I can't believe I spent hours trying to figure out why it wasn't working when the fix was so simple.. Yeah, just adding NOT NULL to the attributes in the up.sql file fixed it for me. ",
    "ohmountain": "@sgrif :joy_cat::joy_cat::joy_cat::joy_cat::joy_cat:\uff0cthank you !. ",
    "carols10cents": "\nworkflow cockroach \n\nwait wut\n\ud83d\udc1c\ud83d\udc1b\ud83d\udc1e\ud83d\udd77. > Hey, thanks for the awesome bug report with a repository and everything \u2764\ufe0f\n\nYou're welcome! I try :)\n\nYou need to add a enable_multi_table_joins!(crates, readme_rendering); to your code as those are not inferred by diesel.\n\nI read the docs for that, but I didn't think that applied because i'm not trying to do crates.inner_join(readme_rendering) at all :-/ Why do I need that if I'm only trying to join each of those to version but not to each other?\nThe docs say:\n// This would be required to do `users.inner_join(posts.inner_join(comments))`\n// if there were an association between users and posts, and an association\n// between posts and comments, but no association between users and comments\nbut that's not the join i'm trying to do, i'm trying to do the equivalent of users.inner_join(posts).inner_join(comments), which I thought was a different situation according to the inner_join docs..... Ok, I just tried it and the code compiles and runs the query i'm expecting... I think this is a documentation bug then :) The comment on the enable_multi_table_joins! macro made me think it didn't apply to my situation :-/. Then I have to either delete the column for schema.rs every time I run diesel print-schema, or I have to add use Ltree every time i run diesel print-schema, and everyone who adds a migration to diesel and runs print-schema has to know this.... Thank you for the workaround!. ",
    "Undin": "Workaround works perfectly:)\nThanks a lot!. ",
    "skade": "Would it also be possible to also ship diesel cli as a binary? For example, half of my hefty heroku build times are just building the CLI.. The example is minimal, this also happens if the schema is in scope.\nThis is documented nowhere and came up in an innocuous attempt to extend this (working) module by following your guides, by inserting NewCampaign.\nhttps://github.com/rust-community/rust-campaigns-server/blob/master/src/main.rs#L47-L112\nIt is at least surprising and the error message is terribly unhelpful.\nI find it confusing that diesel needs very tight hygienic control of the surrounding namespace or otherwise falls flat on its nose.. The recommended way of sharing a database on many SaaS and multiuser systems where you get one database assigned (such as Heroku) is assigning a schema to each deployed application.\nThis name cannot (reasonably) be picked ahead of time, but can easily be configured as a runtime property.\nThe use case is currently indeed this: sharing a low-tier Heroku database (which costs 50$/month) to multiple mid-traffic applications. In this case, I'd like the user to be able to pick the schema name.\nTo my current understanding, Diesel mostly supports this through the URL trick and could better support it if it did what Rails does (SET search_path on connection). There main roadbump is that database setup doesn't work, as it ignores the schema.. ",
    "Lukazoid": "Should this not be reopened now support for citext has been removed?. ",
    "agersant": "Thanks!. Sorry if I didn't explain this right.\nThere are two User structs in this story. One of them has many fields and matches the layout of the users table closely. That struct is not exposed to this module and does not appear in the snippets above.\nThe second User struct (let's call it SlimUser) only has the id field. The issue is that diesel refuses to put the result of a SELECT id FROM users [\u2026] into a SlimUser.. Oh that makes sense. I had not realized that without the trailing comma, the select argument was a lone value and not a 1-item tuple (even with the extra parenthesis around the field name). Sorry for the false bug report \ud83d\ude4f.\nEverything does work as expected without a select call.\n. Thank you very much for taking the time to investigate! Sorry it was a false alarm.. ",
    "mmrath": "@vityafx In case you have not found a solution yet.\nin my db module I have \nno_arg_sql_function!(last_insert_id, types::Bigint);\nI use it as below\nlet generated_id: i64 = select(db::last_insert_id).first(conn).unwrap();\n. ",
    "haruhinoshana": "@mmrath sir do you have a sample to implement this get last_insert_id im new at diesel and rust itself it will be a big help . is there a work around to get the last_insert_id or let new_user = statement.get_result::(&**connection); in mysql diesel sir.. . ",
    "kevinmichaelchen": "@sgrif What's your recommended way of getting the ID of the last inserted record?. @weiznich The downsides of LAST_INSERT_ID are enumerated here. If you don't use LAST_INSERT_ID in a transaction, then it just returns the last ID of an inserted record in any table.\nGenerating the ID in Rust code seems fine if the primary key is a UUID.\nOverall, I think I'm leaning toward Postgres, since it has the RETURNING keyword and natively supports UUID.. ",
    "natboehm": "Yup, done. ",
    "lthms": "\nThere main roadbump is that database setup doesn't work, as it ignores the schema.\n\nI ran into that exact problem today. Hence, I am wondering: is there any workaround to have src/schema.rs generated when using a dedicate schema and the search_path URL trick?. ",
    "nottxy": "@Eijebong The test has been added. Guys, Is there any update about this PR?. @sgrif updated. Thanks, make sense, updated. Sure, updated. updated. ",
    "qmx": "confirmed that it fixes #871 . good call, any suggestion on how to make this more obvious at the docs? Happy to put a PR together, as I've read it a handful times and couldn't see.. ",
    "alexander-alvarez": "I'm new to Rust and Diesel so if you feel the above is better, I have no problem doing it.. ",
    "valeriansaliou": "Yeah it's backwards, because otherwise I get:\nerror[E0275]: overflow evaluating the requirement `<child::table as diesel::JoinTo<grandchild::table>>::OnClause`\n   --> src/lib.rs:141:34\n    |\n141 |         .inner_join(child::table.inner_join(grandchild::table)). Thanks a ton @sgrif \ud83d\udc4d . ",
    "dhbradshaw": "https://blog.github.com/2018-05-01-github-pages-custom-domains-https/. ",
    "alanpoon": "The trait diesel::Expression is not implemented for diesel::types::Datetime, when I try to derive Insertable a Row struct that has field of type diesel::mysql::types::Datetime. \n. ",
    "drager": "Seems like it! When can it be released?. ",
    "Diggsey": "I think that's fine for it to be handled in application code, or via a library, but this was more around having a story for that: maybe that means implementing a demo application that shows how one might achieve that, and endorsing that particular technique.\nThe reason for this is that when choosing a technology stack, it's important to have confidence that these kind of things are doable, even if it requires additional work.\nHere are some difficulties that I ran into when attempting to do the above:\n1) I couldn't find out if it's possible to access a different column when deserializing a field, which would be required to read the version number.\n2) The migration infrastructure provided by diesel is not extensible in a way that would allow including data migrations.\nIn light of these difficulties, I changed my strategy:\n- Only support data migrations on JSON fields (there are alternative approaches for simpler columns)\n- Store the version number in JSON fields\n- Handle the data migration as part of the deserialization step, and require the codebase to handle all historical versions\n- Either never bother eagerly migrating all of the older rows, or implementing an application-level post-deploy hook which fetches and migrates all of the rows\n- Use a macro to prevent the upgrade logic from growing out of control as the number of versions increases\nYou can see my experiments here: https://github.com/Diggsey/rust-crud-example\n. > Quick thought: How about having a view for each table version? Like,\nThat's an interesting idea, but I'm not sure how it would work in practice. If my data migration is \"add 10 to value\", there's no way postgres could figure out that values inserted into the old view should be modified accordingly.\n\nHuh? We allow arbitrary SQL? With embed_migrations! you can include the migration process in your app.\n\nEach migration is run in a transaction, which is unsuitable for large data migrations. That said, I do like the simplicity of diesel's migrations system, which avoids certain problems that eg. alembic has, by being pure SQL. You could embed the migration process in your app, although I'm not sure how you would keep structural and data migrations in the same history.. I'm not aware of any which make these categorisations explicit. However, with most ORMs/database connectors you can simply catch an exception of the appropriate type.\nThe closest might be sqlalchemy, which has an \"invalidates_connection\" flag which is set for exceptions wrapping database errors: http://docs.sqlalchemy.org/en/latest/core/exceptions.html#sqlalchemy.exc.DBAPIError\nFor detecting deadlocks, etc. you have to look at the inner exception raised by the database connector, or just catch all OperationalErrors and InternalErrors and accept that there will extra retries, neither of which is a good solution.. I think changing transaction in the future to call-back multiple times would be too much of a breaking change, and FnMut is much more restrictive that FnOnce. If you want automatic retries, I think just adding a second method would be the way to go.. This is also very important when using a connection pool: currently r2d2_diesel implements the has_broken method on connections to always return false \ud83d\ude22 \nSomething like an invalidates_connection property on errors is really needed, and for diesel to use that to set a broken flag on connections. It can then implement has_broken using that flag, and there should also be a method to manually mark a connection as broken.\nFor example, if rollback fails on a transaction, then the connection really needs to be marked as broken, or else it will be returned to the connection pool!. @sgrif I am worried about transactions not being closed properly, ie. if a connection is returned to the pool with an open transaction, then SELECT 1 will still succeed. This can be fixed by the other issue I opened re: rolling back transactions on panic.\nAnother issue is if the \"transaction rollback\" call fails, then even if the is_valid check catches it, the connection will sit indefinitely in the connection pool, holding onto any locks acquired during the transaction.\nA better option would be to immediately close the connection any time an unrecoverable error occurs: then has_broken can be implemented to just check whether the connection is still open. Any errors from rolling back the transaction should be counted as unrecoverable.\nIf this is combined with the changes to r2d2 to discard connections dropped during a panic, then I think that covers all the edge cases?\n. I added some tests which verify that the \"no wait\" and \"skip locked\" behaviours work as intended and added the compile fail tests.\nI also added a new database error kind for use with .no_wait(), which makes it possible to detect whether a query failed for this reason.. > we should go with the API .for_update_skip_locked(), which overrides the previous FOR UPDATE clause if there was one. \nThat's not going to extend well with other modifiers - FOR UPDATE is a complex clause and NOWAIT/SKIP LOCKED are only one of the ways that its behaviour can be modified.. @sgrif tests are passing, good to go?. Bump \ud83d\ude1b . @sgrif we recently started actually using this at work (on our fork of diesel) and discovered we also needed for_no_key_update. I'm starting to wonder if the cases I considered rare enough to not worry about are actually quite common.\nWhat about an API like this:\nrust\nfoo::table\n    .locking(foo::for_update())\nThis better matches how the query is parsed, and allows us to handle the more complicated cases:\nrust\n<some query involving foo and bar>\n    .locking(foo::for_no_key_update().skip_locked())\n    .locking(bar::for_share())\nMentioning the same table multiple times is allowed, so we don't have to prevent that. What do you think?\nWe would probably need to add global methods, so you could do:\nrust\n<some query involving foo and bar>\n    .locking(for_no_key_update().skip_locked())\nAnd it would affect both mentioned tables, as this is the only form allowed in mysql, although personally I like being explicit about which tables are locked (and we actually had a production issue caused by a joined table being unexpectedly locked...). We would of course need to keep around for_update() for backwards compatibility but it can easily be implemented on top of the above model.. @sgrif I'm not quite sure how that would look? As it stands, the API does not allow you to specify which tables are locked in a multi-table query, or to specify different locking behaviours for different tables.. It has the advantage of not cluttering the top-level DSL. I also think having a bit of structure is preferable to just a flat namespace - do you disagree? The closer the DSL is to the way the query is parsed, the simpler and less magical it feels to use.\nIt's obvious from looking at the nested form what the skip_locked() modifier actually applies to, even if you are not already familiar with it: nested better matches the reality of how the query is executed, which is why it's a bit of a pain to pull those methods up onto the root QueryDsl.. Let's say we implement these as flat methods, we run into the problem you brought up earlier about implementing a LockClauseBuilder.\nImplementing all the DSL traits for each builder doesn't really scale very well... The nested version of the API solves this because the \"closing\" of the locking clause is explicit. \nDocumentation wise, the \"locking(...)\" method is the perfect place to document what all the different modifiers are that can be used.\n. @sgrif let's forget about the \"per table\" locking modes for now? I've updated the PR to include the other basic locking modes (FOR SHARE/FOR KEY SHARE) which I ended up needing.. Hm, bit confused about the compile-fail tests - it seems to be complaining that E0277 is unexpected, but that's exactly the error that's annotated in the test.... @sgrif Tests are passing now (rustfmt failure is rustfmt itself failing to build). @sgrif it is. I think a couple of improvements could be made in the process: the names of some of the functions are a little odd (for example, the function to find all the migrations is called mark_migrations_in_directory) and a lot of the design seems to be quite heavily based on the implementation (for example, name() not being a method on the Migration trait, but a standalone function).\nThis would be a good opportunity to refactor some of this: for example creating a MigrationSet trait instead of passing around a raw PathBuf, which has methods to list Migrations.\n. I strongly disagree with this decision: the transaction function creates a scope for the transaction, and it is fully expected that the transaction not be open after the end of that scope, regardless of how the scope is left. That's not a problem that's specific to connection pooling.. > Your argument is like saying that Vec should have special behavior on panics because it can get left in an inconsistent state when using Mutex. Exception safety is the responsibility of the types that cause values to outlive an exception, not the types that have internal invariants.\nNo, a Vec does not manage internally mutable state. The appropriate comparison would be to a Mutex, which does unlock the mutex (and poisons it) in the event of a panic.\nIf you look in the standard libary, or on crates.io, you will find that types with internally mutable state, do have special behaviour regarding panics. This includes RefCell, Mutex, Rwlock.\n\nAdditionally, continuing to re-open an issue after it's closed is not acceptable behavior.\n\nThis is a PR, not an issue.. > Panics are not exceptions. You should not be catching them in general.\nIt's considered bad practice to use panics for fine-grained exception handling, however catching panics is still completely legitimate, hence the stabilisation of catch_unwind.\n\nThere is no reason that normal usage would result in a database connection continuing to be open when a panic occurs, unless you are using connection pooling. I have laid this out in #1646.\n\nYou've asserted it without any basis: you can't know there's no other reason, there could be any number of reasons why that might be desirable: connection pooling is just the example we've encountered.\nFor example, here's another issue: even if the calling code does drop the connection after a panic, it is not required to do so promptly. Destructors may block: many web frameworks wait for the server to finish in a destructor, scoped thread locals \"join\" on their child threads before returning, even in the event of a panic. In all these cases, the transaction should not be held open during that time.\n\nException safety is the responsibility of the types that cause values to outlive an exception, not the types that have internal invariants.\n\nThis is not about exception safety, it's about clean up. If a connection was smart enough to \"poison\" (disconnect) itself whenever there was a panic from within the connection implementation, then that would be an example of exception safety, and that would be how you could implement UnwindSafe for a connection.\nHowever, even for types that are not UnwindSafe, that doesn't mean they can just leak resources when there's a panic. Vec still frees its memory when dropped, RefCells are still unlocked, even though they are not UnwindSafe, etc. etc.. > Destructors being run is very different from general exception safety.\nThat's my point: this issue is about destructors running, not exception safety: an open transaction is a resource, no different than an open file handle, and that resource should be dropped when it goes out of scope. It's a completely separate issue from making the connection itself unwind-safe.\nThis API from the standard library has an identical contract to the transaction method:\nhttps://doc.rust-lang.org/std/cell/struct.RefCell.html#method.replace_with\nAs you can see, it unlocks the RefCell even in the event of a panic. Please give one reason why this should have different semantics from those implemented by diesel?. > When a connection is dropped, the transaction is rolled back. This is the behavior of every database server out there.\nAnd the behaviour of every other database library or ORM providing a scoped transaction is to rollback the transaction in the event of a panic/unchecked exception/etc. Diesel is the odd one out here. You can look at java's @Transactional decorator, sqlalchemy's or django ORM's context managers for transactions, ruby's ActiveRecord, I've yet to find one that didn't do this.\n\nI'm not sure what you mean by \"contract\". You're referring to undocumented behavior, which could incidentally change in the future.\n\nThe fact that it doesn't \"leak\" a ref-guard is a pretty important part of RefCell's API. I doubt if you speak to any of the rust core team that they will agree with you on this.\n\nChanging how transactions behave does not make us UnwindSafe.\n\nI never said it would. In fact I specifically pointed out previously what it would take for that to be the case, and am not currently advocating for that.\n\nYou should not be using a diesel connection across panic boundaries.\n\nI'm not, and yet this is still a problem. A transaction being held open any longer than the scope of the transaction method call is a bug. Even if I don't use it again, and do not use a connection pool, the fact that the transaction is still open while destructors are running for types used outside that transaction can result in interference with other connections to the database.. Is that because it would require breaking changes? AFAICT, the only part of diesel currently using knowledge of the primary key is the find() method. Everything else works equally well without a primary key.. Not calling it a Table seems confusing - whether or not something has a primary key is incidental to whether it's a table.\nI currently have a table which implements a \"set\" data structure - the \"value\" is not the primary key because for reasons relating to locking, it is preferable to allow transient duplicate items than to enforce uniqueness (which could cause \"insert\" operations to have to wait on \"remove\" transactions, which are slow).. Might be worth adding a comment to the struct where field order is important so that it doesn't get re-ordered by accident?. Is there a previous discussion about this? I saw the message in this commit: https://github.com/diesel-rs/diesel/commit/ae22270600aeddeb8b95e6b88f48060bd514ab9a but the issue number seems incorrect as that links to my PR?\nThis seems to make some sense for the \"single developer\" workflow - however, I'm not sure about how well it will work with a team, or when running migrations on production via the CLI.\nPresumably, schema.rs will be checked into version control, so when you pull the latest version and run the migrations, you don't necessarily want it to modify your schema. Likewise, on production it may not even be possible to modify the schema file if it's running off a read-only file-system.. AIUI, whenever you run migrations via the CLI tool now, it will regenerate and overwrite your schema.rs file, correct?\nAre you saying that it should rewrite it exactly the same because the database state should be the same? It's mostly just a bit of a red flag for me whenever there's something in version control which is transparently updated like this.\nI think I would be less concerned if there was a --validate-only option for use in CI/CD pipelines, which runs the migrations, infers the schema, and then instead of overwriting the schema file, simply compares the two and returns an error if they don't match?. Sure, that's why I wanted to know if there was a previous discussion of the broader feature \ud83d\ude1b . @sgrif given that this previously caused an error, my view is that it should be introduced as a point release. If you consider the number of applications which are inadvertently broken today and would be fixed by this change vs programs which would be broken by introducing this change, the former is likely to be quite large, and the latter is likely to be zero.\nThat is, unless it is possible today to round-trip a value through the database without an error, and get a different result from what you'd get with this change applied?. Makes sense \ud83d\udc4d . @ivanovaleksey the change in this PR doesn't change the behaviour - unwrap_or and unwrap_or_else are identical if the closure doesn't have side effects.\nI'm not sure what you were testing, but this change did not fix your problem.. Will do. OK. Yep. How do you handle that right now? Should I just enable it outright for the MySQL back-end, or is there a way to specify the minimum supported MySQL version at compile time?. When using FOR UPDATE NOWAIT it's important to know whether the query failed due to the lock having been taken, or for some other reason. See the tests I added for a concrete example. I don't know how you'd use NOWAIT without that ability.. That's not true, there is at least one other way a select could fail: timing out. In fact I use this in the test by setting a 1 second timeout to determine if NOWAIT is working correctly. (I deliberately set up a deadlock, and then if it times out instead of returning LockNotAvailable then it didn't work correctly).\nI imagine there are also various encoding-related things that could go wrong in a select statement.. Also if the schema as defined in rust doesn't match the database schema, that could also cause issues, or if permissions are not correct. There are many ways select could fail.. What should I do about the test? I can't test NOWAIT without that error.. OK, but that will always pass \ud83d\ude26 . Can't ForUpdateDsl extend, and be implemented for all, LockingDsl<ForUpdate> avoiding the need for two definitions of this method?. Was it intentional to allow setting the modifier multiple times here?\neg. for_update().skip_locked().no_wait()\n. Hm, I suppose adding a super trait would be a breaking change. If only trait aliases were stable.... I'm concerned that this may be too limited an interface: I wished to store a list of previous revisions as part of the metadata for example, which means they've have to be double-encoded in the toml file.\nPerhaps this \"get\" method could use erased_serde to allow it to support structured data? That way I can specify the type when I access the metadata?. The metadata key that diesel understands should probably be exported as constants somewhere.. I meant publicly exported.. Alternatively, to keep things simpler we could just be more opinionated about what format metadata comes in, and have the migration supply a raw TOML/RON/JSON/whatever string.. Oh, I see, it's serialising back to TOML before returning if it's not a string \ud83d\ude41 \nWhat if barrel decides not to use TOML to store its metadata? Then I won't know how to deserialize an array without knowing where a migration came from?\n\nI'd prefer not to couple to any single serialization framework here.\n\nSerde is the de facto standard for serialization, and diesel already has it as an optional dependency, so this doesn't seem overly risky.\n\nEspecially since that assumes that metadata is serialized in a file, which may not be true for Rust migrations, or migrations which decide to use magic comments, etc.\n\nI don't follow this logic? The only assumption would be that the metadata could be converted to a format which is compatible with serde's object model. For embedding migrations, the internal format would not be exposed, we'd just pick any format which supports the whole of that object model (eg. RON).\nOverall I'd rather diesel picked a standardised object model (either serde/RON or JSON) and expected migrations to convert their metadata to that format. Given one of those object models, there's a choice of exposing an API based on serde, or exposing the raw RON or JSON, depending on which you'd rather be coupled to (the latter would allow you to entirely avoid coupling to serde).. So that if someone else wants to look at the same metadata they don't have to duplicate the strings, they can import the constant from diesel, and for someone reading the code it's obvious how everything fits together. The constant would also serve as a convenient place to put the documentation.\nAlso, for someone working on diesel, it's more obvious that the constant is part of the public API (ie. it can't just be changed without breaking stuff) if it is actually part of the public API.. ",
    "vandenoever": "I'd very much appreciate the convenience of ORM without the memory allocation overhead. An iterator that returns shallow items that use &str instead of String would be good in low-memory use-cases.\n. ",
    "bradleybeddoes": "Can't argue with a response as quick as that!\nThanks folks :).. ",
    "katrinabrock": "For a guide to installing dependencies, do we need to cover windows or just Mac and common Linux flavors?. @killercup thanks for your suggestions. I have made those edits.. So I'm closing this w/o merging now based on @sgrif 's  comment. I'm going to write a little burb about rustup in contributing.md instead. fixed spacing :-). Merp. I need to start running that locally, huh? Thanks @killercup.. 4 character PR. yeah, I'd like to do that but still don't know enough to know what to write.. @sgrif now ready for review. Still needs examples, of course.\nI don't think query_dsl is for query level and expression_dsl is for expression level really adds much, but it would be nice to have something about why methods might be in one place or another. . So...I'm thinking the main thing is PR still needs is an example. Any thought as to what should be in it? What should a mod-level doc have as an example that's distinct from the examples in trait-level docs?. I'm working my way through the query_dsl mod. I know \"one PR per file\", but some of these are just adding a couple lines. . merging as is would be fine with me. oops! should have caught that.. I checked the cargo man page and it's listed under Options:. I always think of a \"CLI flag\" as an option that doesn't take an argument. How about:\n\nUse cargo's --features option . Not sure this is the best heading, but this list needs a heading. Suggestions?. \"Libraries\" sounds nicer, but is a CLI tool really a library? . My concern with that is it might be a little too magical / hidden. Maybe there's a -v option? . Is there a way to just automate this, ie have travis just run rustfmt and then add a commit fixing everything?. that would explain it.... It's a placeholder, this push was mainly to debug my rendering issue.. This example is copy pasta from the associations mod. This didn't jump out at me due to rendering issue.. Existing mods don't have a blank line here. https://github.com/diesel-rs/diesel/blob/master/diesel/src/expression_methods/mod.rs  \u00af_(\u30c4)_/\u00af . \n",
    "maghoff": "@Boscop Did you end up doing anything with this?\n@killercup Would you care to mentor me a bit on this issue if I pick it up now?. Status update: I have gotten started by translating crate_scalar_function from rusqlite. Application-defined functions can return values of different types, but can not read arguments yet.\nWork in progress here: https://github.com/diesel-rs/diesel/compare/master...maghoff:sqlite_custom_function?expand=1. @killercup Thank you for having a look!\n\nCould this work as a separate crate that uses an extension crate to SqliteConnection?\n\nYou tell me \ud83d\ude04 I need access to internal_connection in RawConnection from the raw_connection field of SqliteConnection. If I could access that from an external crate, I think everything could be external, yes.. At present, the application-defined functions cannot accept arguments. My plan was to implement support for that, and then push for more discussion. Maybe a WIP PR would be appropriate then?. Right. I'll definitely do a pass of clean-up/refactoring before making a PR, but there are some things I need a little bit of input on how to design properly. For example, this branch contains my first unsafe rust code :). FWIW I agree with all of @sgrif's and @killercup's points about what needs improvement. This is a work in progress that I posted as a PR for discussion, as recommended by @killercup \ud83d\ude42. @sgrif I was planning on refactoring to unify FromSql and FromSqliteValue. I think I have enough to go on to succeed with that. And then we could get me in touch with someone on the team?. Thanks for this feature, and sorry for disappearing.\nI've been able to make use of this in sausagewiki and Diesel 1.3 solves my problem nicely! \ud83d\ude42 . The sqlite3_create_function_v2 gives us sqlite3_value pointers to work with. As far as I can tell, the only way to get the actual values out of these pointers is with the sqlite3_value_* functions. FromSql seems to use (via SqliteValue) the functions named sqlite3_column_*.\nIt might very well be that I have misunderstood something, but it seems to me that we need this in addition to FromSql.. I'm not sure. I feel that I don't know ToSql well enough to give a really decisive response. Again, the point here is to be able to use the correct sqlite API calls, in this case sqlite3_result_*. These functions are not called anywhere else in the code base.\nNow I'm thinking that you might be mainly concerned about the additional trait, not the implementation. I started out trying to make it work with FromSql and ToSql and couldn't make it. I think they are the slightly wrong abstraction. However, it might be that somebody more familiar with the Diesel code base could be able to make it work.. Barring any hidden dragons, I think it would be possible. It would, however, require an extra copy, via sqlite3_value_dup because the given sqlite3_value is \"unprotected\". The documentation of sqlite3_column_value seems to recommend against this design:\n\nWarning: The object returned by sqlite3_column_value() is an unprotected sqlite3_value object. In a multithreaded environment, an unprotected sqlite3_value object may only be used safely with sqlite3_bind_value() and sqlite3_result_value(). If the unprotected sqlite3_value object returned by sqlite3_column_value() is used in any other way, including calls to routines like sqlite3_value_int(), sqlite3_value_text(), or sqlite3_value_bytes(), the behavior is not threadsafe. Hence, the sqlite3_column_value() interface is normally only useful within the implementation of application-defined SQL functions or virtual tables, not within top-level application code.. In that case, I'm partial to impl Index, since Context is essentially a wrapper around an array.. Fixed with rustfmt, which took some other style issues as well. Yeah, the message could be improved. This assert can only cause a panic in case of logic errors in diesel or sqlite, but it still makes sense to have a descriptive error message.\n\nI like your step back. I think catch_unwind-ing could be the correct way to go here.. >Isn't that exactly what we're doing?\nOf course it is. The question I am trying to address is whether or not it is a good idea to change the preexisting FromSql code for handling the column values from normal database reads.\n\nunprotected just means that there's no mutex around the value\n\nOk. The way I read the documentation it seemed to me that the only safe way to access the value of an unprotected sqlite3_value would be via sqlite3_value_dup. I see now that the documentation is not as strict, it seems we can handle the thread safety ourselves. Good.\nI'll look into refactoring to using sqlite3_values for columns as well, so we can get rid of the duplication.. Yeah, the SQLite documentation is confusing at best, contradictory at worst.\nhttps://www.sqlite.org/c3ref/column_blob.html says:\n\nThe safest policy is to invoke these routines in one of the following ways:\n\nsqlite3_column_text() followed by sqlite3_column_bytes()\nsqlite3_column_blob() followed by sqlite3_column_bytes()\nsqlite3_column_text16() followed by sqlite3_column_bytes16()\n\nIn other words, you should call sqlite3_column_text(), sqlite3_column_blob(), or sqlite3_column_text16() first to force the result into the desired format, then invoke sqlite3_column_bytes() or sqlite3_column_bytes16() to find the size of the result. Do not mix calls to sqlite3_column_text() or sqlite3_column_blob() with calls to sqlite3_column_bytes16(), and do not mix calls to sqlite3_column_text16() with calls to sqlite3_column_bytes().\n\nhttps://www.sqlite.org/c3ref/value_blob.html says:\n\nPlease pay particular attention to the fact that the pointer returned from sqlite3_value_blob(), sqlite3_value_text(), or sqlite3_value_text16() can be invalidated by a subsequent call to sqlite3_value_bytes(), sqlite3_value_bytes16(), sqlite3_value_text(), or sqlite3_value_text16().\n\nIt seems that the documentation is imprecise and that the current implementation is recommended. It looks like the problems would only appear if we cause SQLite to transform a data representation, but they stop short of actually promising that in the documentation.\nPerhaps we could add a comment explaining that while the documentation looks contradictory, we trust this implementation because it is clearly recommended by the documentation in https://www.sqlite.org/c3ref/column_blob.html ?. ",
    "bovee": "A guide would be great, but even a table of SQL <-> Diesel would be super helpful. For example, I had difficulty finding out how to emit IN query statements without grepping the source (I think it's column.eq_any()?) and a list of column methods would have been incredibly useful.. ",
    "hbobenicio": "I miss guides and docs about queries too.\nThere is a \"All About Updates\" guide. There is also a \"All About Inserts\" guide. But no \"All About Queries\"...  :(\nIn my case (newcomer here) I'm struggling to make dynamic queries (for a paginated listing use case).\nMining help and basic usage directly from docs.diesel.rs is kind of cumbersome.... ",
    "estelendur": "I'm sorry, I'm very new to Rust and don't have the first idea how to fix it.. ",
    "pocket7878": "Any updates on this? Currently I'm trying to rewrite my API server from Rails to Rust.\nBut I can't use infer_schema! since rails using schema_migrations table to hold migration history, and it has no primary key.. ",
    "red-avtovo": "Anyone?. ",
    "bbqsrc": "This just broke my mind for a while, as I changed computers and couldn't understand the error that diesel-cli was giving me. Trying to connect to a postgres db with only the sqlite feature enabled provides the following:\n$ diesel migration run\nthread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: ConnectionError(BadConnection(\"Unable to open the database file\"))', libcore/result.rs:945:5\nSo yeah, this is still less than ideal. :)\n. ",
    "christiansakai": "I literally just encountered this problem and went on for 2 days.... Glad I found this issue.. ",
    "Kazakuri": "So basically my understanding of it is that the recursion limit is hit when expanding the table! macro that is generated from the diesel print-schema/!infer_schema(\"dotenv:DATABASE_URL\", \"foo\") commands.\nLike killercup said, the way the table! macro expands is the older(?) recursive style macros instead of a procedural style, so that every line inside the macro body is a recursively parsed.\nSo unless the macro gets re-written which has a lot of problems in itself, the only real solution is increasing the recursion limit of your program.. ",
    "krircc": "I have the same problme,  when i do with  inner_join . ",
    "alexeyzab": "Hi there! I'd like to do this one.. > That would be awesome. Do you want to do that here, or in another PR?\nI can do that here, just wanted to make sure I was on the right track. :). After looking at the code again, it seems that all the other calls to from_ymd involve specific dates that won't fail, like pg_epoch or all the unit tests. I've fixed the sqlite error message I linked to earlier, but not sure what else I could do here.\nUPD: I've rebased on master and squashed my commits but it seems that the build is failing on CI. The test passes locally though. If anyone could point me in the right direction here, that'd be much appreciated.. @sgrif Ohh, I see, thank you for pointing it out! Is there anything I can help with here?. Yep, I saw it, wanted to make sure.. Thanks for pointing this out!. Sure thing! I copied the error message from over here. I am guessing it would be a good idea to add something like this everywhere from_ymd is used.. ",
    "konstin": "Thanks for fix! \nIs it right that the current solution still means that the query will fail by returning an Error? That would imply that it is not possible to query fields with that value, which is kind of bad in a real world scenario like the one I had where the db contains those values.. Thanks for the detailed answer, I see the point now.\nUsing PG isn't an option here as I use data from a different program that is tied to mysql.. I got that it was joke, but sometimes jokes become solutions (though maybe not the one you want), and I've got nothing against giving PG a shot. Thanks!. ",
    "frol": "This is my take on getting this weird MySQL 0000-00-00 date handled as None on the Rust side.\nI have created a custom field MysqlNaiveDate:\n```rust\nuse chrono;\nuse mysqlclient_sys;\nuse diesel::mysql::Mysql;\nuse diesel::sql_types::Date;\nuse diesel::deserialize::{self, FromSql};\n[derive(Debug, FromSqlRow)]\npub struct MysqlNaiveDate(Option);\nimpl FromSql for MysqlNaiveDate {\n    fn from_sql(bytes: Option<&[u8]>) -> deserialize::Result {\n        let mysql_time = >::from_sql(bytes)?;\n        Ok(MysqlNaiveDate(\n            if mysql_time.day == 0 && mysql_time.month == 0 && mysql_time.year == 0 {\n                None\n            } else {\n                Some(\n                    chrono::NaiveDate::from_ymd_opt(\n                        mysql_time.year as i32,\n                        mysql_time.month as u32,\n                        mysql_time.day as u32,\n                    ).ok_or_else(|| format!(\"Unable to convert {:?} to chrono\", mysql_time))?\n                )\n            }\n        ))\n    }\n}\n```\nand use it like this:\n```rust\n[derive(Debug, Queryable)]\npub struct User {\n    pub user_id: u32,\n    pub email: String,\n    pub birthday: MysqlNaiveDate,\n}\n```\nHere is the schema.rs (generated for the existing DB, so I don't need to implement ToSql for MysqlNaiveDate):\nrust\ntable! {\n    users (user_id) {\n        user_id -> Unsigned<Integer>,\n        email -> Varchar,\n        birthday -> Date,\n    }\n}. ",
    "yyolf117": "yes, with cargo install.. ```\n$ ls ~/.cargo/bin/\ndiesel\n```\nbut \n```\n$ diesel\nbash: diesel: command not found\n```\nand one more thing:\nwhat if I gave it a different name? MY_DATABASE_URL\n``\n$ diesel setup\n[.................................]\nThe --database-url argument must be passed, or the DATABASE_URL environment variable must be set.`\n``. ok, how about my last question?. thx.  but I can't use the env. variable calledDATABASE_URL` in each project I have because, of course, each connection string in each proejct is different.. I didn't find anything related to \"--database-url\" being passed as an argument to diesel in the command line in the guides, where is it? . yeah, thanks.. with 0.16 the exception becomes this:\nerror: recursion limit reached while expanding the macro `table_body`\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = help: consider adding a `#![recursion_limit=\"128\"]` attribute to your crate\n  = note: this error originates in a macro outside of the current crate\n. I've put #![recursion_limit=\"128\"]  to the main file of my crate - src/main.rs - but the error remained.. yes, yes.\nis it possible to use diesel without  infer_schema!(\"dotenv:DATABASE_URL\") by writing code manually?. Now there're several errors:\nthe trait bound `(......)` is not satisfied\n\n^ the trait `diesel::Expression` is not implemented for .....\n= note: required by `diesel::query_builder::AsQuery`\n= note: this error originates in a macro outside of the current crate\n\n\n^ the trait `diesel::SelectableExpression<schema .....` is not implemented for .....\n^ the trait `diesel::expression::NonAggregate` is not implemented for .....\n\n. I have a model with many fields:\n# models.rs\npub struct Table123<'a> {\n    pub id: i32,\n    pub var1: &'a str,\n    pub var2: &'a str,\n    pub var3: &'a str,\n    pub var4: &'a str,\n    pub var5: &'a str,\n    pub var6: &'a str,\n    pub var7: &'a str,\n    pub var8: &'a str,\n    pub var9: &'a str,\n    pub var10: &'a str,\n    pub var11: &'a str,\n    pub var12: &'a str,\n    pub var13: &'a str,\n    pub var14: &'a str,\n    pub var15: &'a str,\n    pub var16: &'a str,\n    pub var17: &'a str,\n    pub var18: &'a str,\n    pub var19: &'a str,\n    pub var20: &'a str,\n}\n\n\n# schema.rs\ntable! {\n    table123 (id) {\n        id -> Int4,\n        var1 -> Nullable<Varchar>,\n        var2 -> Nullable<Text>,\n        var3 -> Nullable<Varchar>,\n        var4 -> Nullable<Varchar>,\n        var5 -> Nullable<Varchar>,\n        var6 -> Nullable<Varchar>,\n        var7 -> Nullable<Varchar>,\n        var8 -> Nullable<Varchar>,\n        var9 -> Nullable<Varchar>,\n        var10 -> Nullable<Varchar>,\n        var11 -> Nullable<Varchar>,\n        var12 -> Nullable<Varchar>,\n        var13 -> Nullable<Varchar>,\n        var14 -> Nullable<Varchar>,\n        var15 -> Nullable<Varchar>,\n        var16 -> Nullable<Varchar>,\n        var17 -> Nullable<Varchar>,\n        var18 -> Nullable<Varchar>,\n        var19 -> Nullable<Varchar>,\n        var20 -> Nullable<Varchar>,\n    }\n}\n\nExceptions:\n  error[E0277]: the trait bound `(schema::table123::columns::id, schema::table123::columns::var1, schema::table123::columns::var2, schema::table123::columns::var3, schema::table123::columns::var4, schema::table123::columns::var5, schema::table123::columns::var6, schema::table123::columns::var7, schema::table123::columns::var8, schema::table123::columns::var9, schema::table123::columns::var10, schema::table123::columns::var11, schema::table123::columns::var12, schema::table123::columns::var13, schema::table123::columns::var14, schema::table123::columns::var15, schema::table123::columns::var16, schema::table123::columns::var17, schema::table123::columns::var18, schema::table123::columns::var19, schema::table123::columns::var20): diesel::Expression` is not satisfied\n    --> src/schema.rs:30:1\n     |\n  30 | / table! {\n  31 | |     table123 (id) {\n  32 | |         id -> Int4,\n  33 | |         var1 -> Nullable<Varchar>,\n  ...  |\n  53 | |     }\n  54 | | }\n     | |_^ the trait `diesel::Expression` is not implemented for `(schema::table123::columns::id, schema::table123::columns::var1, schema::table123::columns::var2, schema::table123::columns::var3, schema::table123::columns::var4, schema::table123::columns::var5, schema::table123::columns::var6, schema::table123::columns::var7, schema::table123::columns::var8, schema::table123::columns::var9, schema::table123::columns::var10, schema::table123::columns::var11, schema::table123::columns::var12, schema::table123::columns::var13, schema::table123::columns::var14, schema::table123::columns::var15, schema::table123::columns::var16, schema::table123::columns::var17, schema::table123::columns::var18, schema::table123::columns::var19, schema::table123::columns::var20)`\n     |\n     = note: required by `diesel::query_builder::AsQuery`\n     = note: this error originates in a macro outside of the current crate\n\n  error[E0277]: the trait bound `(schema::table123::columns::id, schema::table123::columns::var1, schema::table123::columns::var2, schema::table123::columns::var3, schema::table123::columns::var4, schema::table123::columns::var5, schema::table123::columns::var6, schema::table123::columns::var7, schema::table123::columns::var8, schema::table123::columns::var9, schema::table123::columns::var10, schema::table123::columns::var11, schema::table123::columns::var12, schema::table123::columns::var13, schema::table123::columns::var14, schema::table123::columns::var15, schema::table123::columns::var16, schema::table123::columns::var17, schema::table123::columns::var18, schema::table123::columns::var19, schema::table123::columns::var20): diesel::SelectableExpression<schema::table123::table>` is not satisfied\n    --> src/schema.rs:30:1\n     |\n  30 | / table! {\n  31 | |     table123 (id) {\n  32 | |         id -> Int4,\n  33 | |         var1 -> Nullable<Varchar>,\n  ...  |\n  53 | |     }\n  54 | | }\n     | |_^ the trait `diesel::SelectableExpression<schema::table123::table>` is not implemented for `(schema::table123::columns::id, schema::table123::columns::var1, schema::table123::columns::var2, schema::table123::columns::var3, schema::table123::columns::var4, schema::table123::columns::var5, schema::table123::columns::var6, schema::table123::columns::var7, schema::table123::columns::var8, schema::table123::columns::var9, schema::table123::columns::var10, schema::table123::columns::var11, schema::table123::columns::var12, schema::table123::columns::var13, schema::table123::columns::var14, schema::table123::columns::var15, schema::table123::columns::var16, schema::table123::columns::var17, schema::table123::columns::var18, schema::table123::columns::var19, schema::table123::columns::var20)`\n     |\n     = note: required by `diesel::Table`\n     = note: this error originates in a macro outside of the current crate\n\n  error[E0277]: the trait bound `(schema::table123::columns::id, schema::table123::columns::var1, schema::table123::columns::var2, schema::table123::columns::var3, schema::table123::columns::var4, schema::table123::columns::var5, schema::table123::columns::var6, schema::table123::columns::var7, schema::table123::columns::var8, schema::table123::columns::var9, schema::table123::columns::var10, schema::table123::columns::var11, schema::table123::columns::var12, schema::table123::columns::var13, schema::table123::columns::var14, schema::table123::columns::var15, schema::table123::columns::var16, schema::table123::columns::var17, schema::table123::columns::var18, schema::table123::columns::var19, schema::table123::columns::var20): diesel::expression::NonAggregate` is not satisfied\n    --> src/schema.rs:30:1\n     |\n  30 | / table! {\n  31 | |     table123 (id) {\n  32 | |         id -> Int4,\n  33 | |         var1 -> Nullable<Varchar>,\n  ...  |\n  53 | |     }\n  54 | | }\n     | |_^ the trait `diesel::expression::NonAggregate` is not implemented for `(schema::table123::columns::id, schema::table123::columns::var1, schema::table123::columns::var2, schema::table123::columns::var3, schema::table123::columns::var4, schema::table123::columns::var5, schema::table123::columns::var6, schema::table123::columns::var7, schema::table123::columns::var8, schema::table123::columns::var9, schema::table123::columns::var10, schema::table123::columns::var11, schema::table123::columns::var12, schema::table123::columns::var13, schema::table123::columns::var14, schema::table123::columns::var15, schema::table123::columns::var16, schema::table123::columns::var17, schema::table123::columns::var18, schema::table123::columns::var19, schema::table123::columns::var20)`\n     |\n     = note: required by `diesel::Table`\n     = note: this error originates in a macro outside of the current crate\n\n  error[E0277]: the trait bound `(schema::table123::columns::id, schema::table123::columns::var1, schema::table123::columns::var2, schema::table123::columns::var3, schema::table123::columns::var4, schema::table123::columns::var5, schema::table123::columns::var6, schema::table123::columns::var7, schema::table123::columns::var8, schema::table123::columns::var9, schema::table123::columns::var10, schema::table123::columns::var11, schema::table123::columns::var12, schema::table123::columns::var13, schema::table123::columns::var14, schema::table123::columns::var15, schema::table123::columns::var16, schema::table123::columns::var17, schema::table123::columns::var18, schema::table123::columns::var19, schema::table123::columns::var20): diesel::SelectableExpression<schema::table123::table>` is not satisfied\n    --> src/schema.rs:30:1\n     |\n  30 | / table! {\n  31 | |     table123 (id) {\n  32 | |         id -> Int4,\n  33 | |         var1 -> Nullable<Varchar>,\n  ...  |\n  53 | |     }\n  54 | | }\n     | |_^ the trait `diesel::SelectableExpression<schema::table123::table>` is not implemented for `(schema::table123::columns::id, schema::table123::columns::var1, schema::table123::columns::var2, schema::table123::columns::var3, schema::table123::columns::var4, schema::table123::columns::var5, schema::table123::columns::var6, schema::table123::columns::var7, schema::table123::columns::var8, schema::table123::columns::var9, schema::table123::columns::var10, schema::table123::columns::var11, schema::table123::columns::var12, schema::table123::columns::var13, schema::table123::columns::var14, schema::table123::columns::var15, schema::table123::columns::var16, schema::table123::columns::var17, schema::table123::columns::var18, schema::table123::columns::var19, schema::table123::columns::var20)`\n     |\n     = note: required by `diesel::QuerySource`\n     = note: this error originates in a macro outside of the current crate\n\n  error: aborting due to 4 previous errors\n\n. ",
    "ghost": "@killercup \nI got a error \nerror: recursion limit reached while expanding the macro `numeric_expr`\n --> src/schema.rs:1:1\n  |\n1 | infer_schema!(\"dotenv:DATABASE_URL\");\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\n  = help: consider adding a `#![recursion_limit=\"128\"]` attribute to your crate\n  = note: this error originates in a macro outside of the current crate. table! {\n    level (id) {\n        id -> Integer,\n        name -> Varchar,\n        level -> Tinyint,\n        limits -> Integer,\n        limite -> Integer,\n    }\n}\nMaybe it's the problem here?. can't both use infer_schema!(\"dotenv:DATABASE_URL\") and table! ?. Thanks,. ",
    "dvberkel": "I experienced the same problem while walking through the tutorial. I cranked the recursion limit up all the way to 4096 to no avail. My model is small:\n```rust\n[derive(Serialize, Deserialize, Debug, PartialEq, Queryable)]\npub struct Event {\n    id: i32,\n    origin: String,\n    message: String,\n}\n```\nbut it doesn't residue in models.rs. When I use diesel print-schema it returns \ntable! {\n    events (id) {\n        id -> Int4,\n        origin -> Varchar,\n        message -> Varchar,\n    }\n}\nPutting this in schema.rs results in a similar error: cannot find macro 'table!' in this scope.\nDoes anyone have a clue?. I asked help on the diesel-rs/diesel and @weiznich came to the rescue. \n@weiznich quickly found out that I was missing a macro_use annotation on the extern crate diesel import. In fact, I was missing the entire import. Adding it in, made my problems go away, even without the altered recursion limit.. ",
    "mmstick": "What was your solution?. ",
    "nvanbenschoten": "This specific issue should be solved now. \nThat said, there are still a few other blockers listed in cockroachdb/cockroach#13787. CockroachDB has issues filled for each of the necessary changes: support for savepoints, the ability to drop and create the same table in a txn, and support for stored procedures. However, none of these are actually planned to be addressed in the near-future. I'm curious how many of these are hard requirements of Diesel and how many are artifacts of implementation decisions that could potentially be changed. For instance, it sounds like the stored procedures aren't actually strictly necessary. @killercup do you have an estimate for how much effort it would be to address each of these three limitations on Diesel's side?. EDIT: it looks like the ability to drop and create the same table in a txn may actually be addressed sometime soon. The other's are still longer-term tasks though.. Got it, thanks @sgrif. From this line, it looks like Diesel requires support for arbitrarily nested savepoints. Is this correct?\nI'll look into whether we can prioritize https://github.com/cockroachdb/cockroach/issues/10735 on our end.. ",
    "brandur": "I took a stab at adding a little more documentation in #1548 (as suggested).\nIMO though, the original reporter here has a point in that this goes a little beyond a documentation problem. I've been using Diesel fairly seriously for a few weeks now and it's quite a common pattern to have a compiler protect you from misuse, but to do so in a way that doesn't help give you much of an idea as to what's actually wrong.\nYou'll probably eventually solve the problem, but you do so by changing things until you accidentally get it right, investing lots of time reading documentation, or by cloning Diesel's source code and examining its source and examples in the test suite (I've resorted to this last technique about a hundred times). Compiler errors are often of minimal help.\nI don't really have a suggestion on how to fix this, but I wanted to second the fact that it's a fairly major problem, especially for newcomers to Rust and Diesel who may not be as practiced at unwinding these types of error messages.. Another data point: #1551. Diesel is doing something useful by not allowing a BIGINT to be loaded into an i32, but a new user is quite confused by the error message that's produced.. Ah, I just found this section on Insertable in a draft guide.\n\nWhen implementing Insertable, you probably won't be setting the auto-incremented id field of the row. Usually you will also ignore fields such as created_at and updated_at. For this reason, it's not advisable to use Queryable and Insertable on the same struct due to the field number constraints of Queryable. Create another struct that you may use for database insertions that will have all the fields you would like to set. This section will not cover nullable fields (we'll cover that in AsChangeset), so we will assume every field must have data in our example. When making a separate struct for database inserts, Diesel needs to know the corresponding table name, so the struct must also be annotated with the #[table_name=\"some_table_name\"] attribute. If your new struct has different field names, each of them may be annotated with #[column_name(some_column_name)].\n\nI'll do this for now, but this is a little suboptimal given the amount of overlap you're going to have between the insertable and queryable versions for most models \u2014 models tend to balloon to lots and lots of fields given enough time, and all of them will need to be written twice (although I suppose the approach has some advantages as well).. I'm not a maintainer, but I was looking at how this might be solved just out of curiosity. I think that the root of the problem is that the now struct is foremost fundamentally a Timestamp rather than a Timestamptz:\n`` rust\n/// Represents the SQLCURRENT_TIMESTAMPconstant. This is equivalent to the\n///NOW()` function on backends that support it.\n[allow(non_camel_case_types)]\n[derive(Debug, Copy, Clone, QueryId)]\npub struct now;\nimpl Expression for now {\n    type SqlType = Timestamp;\n}\n```\nWhen you subtract an Interval from a Timestamp, you end up with another Timestamp, which is what's producing the error you're seeing:\nrust\nimpl Sub for super::Timestamp {\n    type Rhs = super::Interval;\n    type Output = super::Timestamp;\n}\n(And an off-handed comment: I found it helpful to read the obtuse error produced by the compiler backwards. When it says expected struct `diesel::sql_types::Timestamp`, found struct `diesel::sql_types::Timestamptz`, what it really means is that it wanted a Timestamptz based off your schema definition, and found Timestamp.)\nCoerce is implemented for now so that it can become a Timestamptz:\n``` rust\n[cfg(feature = \"postgres\")]\nimpl AsExpression for now {\n    type Expression = Coerce;\nfn as_expression(self) -> Self::Expression {\n    Coerce::new(self)\n}\n\n}\n[cfg(feature = \"postgres\")]\nimpl AsExpression> for now {\n    type Expression = Coerce>;\nfn as_expression(self) -> Self::Expression {\n    Coerce::new(self)\n}\n\n}\n```\nBut it doesn't seem to happen soon enough. I would think that even after the interval subtraction, it should be able to coerce the resulting Timestamp to a Timestamptz, but it apparently doesn't, and even after reading the code for some time I still don't understand how exactly coerce is supposed to work. There's a little documentation explaining what it's for, but neither it nor its implementation provide much in the way of hints as to what it's doing.\nI was able to fix the problem by introducing a new struct nowtz for Postgres (and appropriate add/sub implementations):\n`` patch\ndiff --git a/diesel/src/expression/functions/date_and_time.rs b/diesel/src/expression/functions/date_and_time.rs\nindex 1461b8e7..d931bce9 100644\n--- a/diesel/src/expression/functions/date_and_time.rs\n+++ b/diesel/src/expression/functions/date_and_time.rs\n@@ -46,6 +46,35 @@ let today: chrono::NaiveDate = diesel::select(date(now)).first(&connection).unwr\n \",\n \"The return type of [date(expr)`](../dsl/fn.date.html)\");\n+#[allow(non_camel_case_types)]\n+#[cfg(feature = \"postgres\")]\n+#[derive(Debug, Copy, Clone, QueryId)]\n+pub struct nowtz;\n+\n+#[cfg(feature = \"postgres\")]\n+impl Expression for nowtz {\n+    type SqlType = Timestamptz;\n+}\n+\n+#[cfg(feature = \"postgres\")]\n+impl NonAggregate for nowtz {}\n+\n+#[cfg(feature = \"postgres\")]\n+impl QueryFragment for nowtz {\n+    fn walk_ast(&self, mut out: AstPass) -> QueryResult<()> {\n+        out.push_sql(\"CURRENT_TIMESTAMP\");\n+        Ok(())\n+    }\n+}\n+\n+#[cfg(feature = \"postgres\")]\n+impl_selectable_expression!(nowtz);\n+\n+#[cfg(feature = \"postgres\")]\n+operator_allowed!(nowtz, Add, add);\n+#[cfg(feature = \"postgres\")]\n+operator_allowed!(nowtz, Sub, sub);\n+\n #[cfg(feature = \"postgres\")]\n use expression::AsExpression;\n #[cfg(feature = \"postgres\")]\ndiff --git a/diesel/src/sql_types/ops.rs b/diesel/src/sql_types/ops.rs\nindex afb35d67..46f53678 100644\n--- a/diesel/src/sql_types/ops.rs\n+++ b/diesel/src/sql_types/ops.rs\n@@ -170,3 +170,27 @@ impl Sub for super::Nullable {\n     type Rhs = super::Nullable;\n     type Output = super::Nullable;\n }\n+\n+#[cfg(feature = \"postgres\")]\n+impl Add for super::Timestamptz {\n+    type Rhs = super::Interval;\n+    type Output = super::Timestamptz;\n+}\n+\n+#[cfg(feature = \"postgres\")]\n+impl Add for super::Nullable {\n+    type Rhs = super::Nullable;\n+    type Output = super::Nullable;\n+}\n+\n+#[cfg(feature = \"postgres\")]\n+impl Sub for super::Timestamptz {\n+    type Rhs = super::Interval;\n+    type Output = super::Timestamptz;\n+}\n+\n+#[cfg(feature = \"postgres\")]\n+impl Sub for super::Nullable {\n+    type Rhs = super::Nullable;\n+    type Output = super::Nullable;\n+}\n```\nAnd then changing your line above to use nowtz instead of now:\nrust\n    let foo2 = test_table::table\n        .filter(test_table::foo.lt((nowtz - 30.days()).nullable()))\n... but I assume that there's a much more elegant way to go about this which is a little beyond my grasp. If anyone more familiar with the type system could give me a high level explanation for how this might be generally solved, I could try my hand at sending over a patch.. > I suppose you could introduce a new SQL type (perhaps Now) which can be coerced to either Timestamp or Timestamptz, and then implement interval addition/subtraction for that type. \nSo the idea there would be that Now - Interval = Now so that you could then safely coerce to either Timestamp or Timestamptz right? I couldn't say for sure whether that would work, but it sounds like a reasonable idea. The way Diesel seems modeled today though is that SQL types are modeled after actual types in SQL, so the abstraction might still be a bit leaky.\n\nThat seems like the most \"correct\" way to do it, in the sense that the Postgres server is probably doing something vaguely similar.\n\nI took a quick look at the datetime docs in Postgres and interestingly, now() is stated to unequivocally return a timestamp with time zone. It must be coerced back to a regular timestamp as needed.\n\nI'm not sure how we'd feel about adding a new SQL type for what might be a fairly simple case, but I think it's better than nowtz since, to the user, the extra Now type should be totally transparent.\n\nYeah, I tried my current solution to verify that I had at least a partial understanding of the problem, but it's not very good.. diesel::sql_types::BigInt is representative of the BIGINT SQL type. You can see from the MySQL documentation on integer types here that BIGINT is an 8-byte integer. That's inherently incompatible with an i32 which is 32 bits (or 4 bytes), and Diesel is smart enough to understand that there's a potentially unsafe condition when you try to load a BIGINT that's too large into an i32, and won't let your program compile.\nSolution: try i64 (64 bits, or 8 bytes) instead.\n(Disclaimer: I'm not a maintainer of this project, but hopefully this is helpful.). For what it's worth, I ran into the same problem while trying to build an app, and embedded migrations turned out to be an adequate solution for me.\nHere's my code in case it's helpful:\n``` rust\n// Migrations get pulled into the final binary. This makes it quite a bit\n// easier to run them on remote clusters without trouble.\nembed_migrations!(\"./migrations\");\n...\nfn subcommand_migrate(log: &Logger, matches: &ArgMatches, options: &GlobalOptions) -> Result<()> {\n    let _matches = matches.subcommand_matches(\"migration\").unwrap();\n    let conn = connection(log)?;\ninfo!(log, \"Running migrations\");\n\nif options.quiet {\n    embedded_migrations::run(&*conn)\n} else {\n    embedded_migrations::run_with_output(&*conn, &mut std::io::stdout())\n}.chain_err(|| \"Error running migrations\")?;\n\ninfo!(log, \"Finished migrations\");\nOk(())\n\n}\n```\nIt has an advantage compared to containerizing diesel-cli in that because I just run them as a subcommand of my main program, I don't need to maintain a separate Docker image, and can run my migrations by attaching to any existing container.\nThe downside is that down migrations, or any kind of finer migration operations (rolling back/forward by steps or anything else) aren't supported. This is usually fine given that my migrations are well-vetted before going to prod and in case of an emergency I still have a psql console, but having the option would probably be better.. @vityafx Mine seems to work well. Maybe make sure that you follow all the caveats in the project's README. For example, it's suggested that this be added to Cargo.toml to make Diesel work:\n``` toml\n[dependencies]\nThis is needed to make sure that Cargo statically links against\nlibssl. This should happen automatically, but it doesn't.\nopenssl-sys = \"0.9\"\n[patch.crates-io]\nThis is needed to handle cross-compilation of libpq.\npq-sys = { git = 'https://github.com/golddranks/pq-sys' }\n```\nIf it helps, here's my completed Dockerfile, but as you'll see, there's nothing special going on in there.\n\nYou did literally link to the documentation for it one comment ago. ;)\n\n@sgrif I'm going to second that although it's really nice that some of this documentation does turn out to exist, it's not very discoverable. I almost always find things by ag'ing the source code and then using that path to go back to docs.rs to look at rendered docs.. @vityafx Based on your compilation error, it seems that somehow OpenSSL might be absent from the image or something. Unfortunately I'm cargo culting to a large degree myself and not really an expert, but if you're really stuck, I'd suggest going back to the beginning and trying to get it configured again from scratch. If you'd like, you can use by Dockerfile and .dockerignore as a template.. Thanks for the detailed response @weiznich. I think as you suggested, serde_json::from_value / serde_json::to_value will indeed be sufficient for my use case here.. Hi @retep007, thanks for the review!\nCan you take another look? I integrated your feedback here, and also tightened up the phrasing to be a little more prescriptive: \"load should probably be used instead\" instead of \"load might be useful instead\".. ",
    "DmitriK": "Removed joinable! line and it works perfectly. Thank you!. ",
    "xinghun92": "I have no idea how to use users table in tests/insert/batch_insert_with_defaults and tests/insert/insert_with_defaults, so I create a new table named users_with_default.. Although there is no round trip time for SQLite, the performance is quite different for batch insert by one query or multiple queries.\nthis is my test code\n```\nlib.rs\n![recursion_limit=\"128\"]\n![allow(unused_features)]\n![feature(test)]\n[macro_use]\nextern crate diesel;\nextern crate dotenv;\n[macro_use]\nextern crate diesel_codegen;\nuse std::env;\nuse diesel::Connection;\nuse diesel::sqlite::SqliteConnection;\nuse dotenv::dotenv;\ninfer_schema!(\"dotenv:DATABASE_URL\");\n[derive(Queryable, Clone, Debug)]\npub struct User {\n    pub id: i64,\n    pub name: String,\n    pub type_: i32,\n    pub avatar_key: String,\n    pub update_time: i64,\n    pub name_pinyin: String,\n    pub creator_id: Option,\n    pub is_resigned: Option\n}\n[derive(Insertable, Debug)]\n[table_name = \"users\"]\npub struct NewUser<'a> {\n    pub id: i64,\n    pub name: &'a str,\n    pub type_: i32,\n    pub avatar_key: &'a str,\n    pub update_time: i64,\n    pub name_pinyin: &'a str,\n    pub creator_id: Option,\n    pub is_resigned: Option\n}\n[allow(dead_code)]\nfn establish_connection() ->  SqliteConnection {\n    dotenv().ok();\nlet database_url = env::var(\"DATABASE_URL\")\n    .expect(\"DATABASE_URL must be set\");\n SqliteConnection::establish(&database_url).unwrap()\n\n}\n[allow(dead_code)]\nfn create_new_users<'a>(num: i64) -> Vec> {\n    let mut users = Vec::new();\n    for i in 0..num {\n        let user = NewUser {\n            id: i,\n            name: \"name\",\n            type_: 1,\n            avatar_key: \"avatar_key\",\n            update_time: 1,\n            name_pinyin: \"name\",\n            creator_id: Some(0),\n            is_resigned: Some(true)\n        };\n        users.push(user);\n    }\n    users\n}\n[cfg(test)]\nmod tests {\n    extern crate test;\n    use ::diesel::ExecuteDsl;\n    use self::test::Bencher;\n#[bench]\nfn bench_batch_insert_users(b: &mut Bencher) {\n    let test_num = 1;\n    let conn = ::establish_connection();\n    let new_users = ::create_new_users(test_num);\n    b.iter(|| {\n        let num = ::diesel::insert_or_replace(&new_users)\n            .into(::users::table)\n            .execute(&conn).unwrap();\n        assert_eq!(test_num, num as i64);\n    });\n}\n\n}\nmigrations/20170620103016_users/up.sql\nCREATE TABLE users (\n  id BIGINT NOT NULL PRIMARY KEY,\n  name TEXT NOT NULL,\n  type_ INTEGER NOT NULL,\n  avatar_key TEXT NOT NUll DEFAULT '',\n  update_time BIGINT NOT NULL DEFAULT 0,\n  name_pinyin TEXT NOT NULL,\n  creator_id BIGINT,\n  is_resigned BOOLEAN\n);\nmigrations/20170620103016_users/down.sql\ndrop table users;\n.env\nDATABASE_URL=test.db\n```\nand the time cost goes here:\n```\nbatch insert by one query:\n1 row ----> 0.45ms\n10 rows ----> 0.76ms\n100 rows ---> 2.55ms\nbatch insert by multiple queries:\n1 row ----> 0.42ms\n10 rows ----> 10.20ms\n100 rows ---> 47.38ms\nBatch insert by one query is faster than multiple queries. And I think support batch insert by single query for SQLite may be better.. Why not implement the batch insert of sqlite in a transaction like this? Or add a new batch_insert with transaction. I think there are some needs for faster insert, and add a transaction in ever insert statement out of diesel seems bad.\n[cfg(feature=\"sqlite\")]\nimpl<'a, T, U, Op, Ret> ExecuteDsl<::sqlite::SqliteConnection>\n    for BatchInsertStatement where\n        InsertStatement: ExecuteDsl<::sqlite::SqliteConnection>,\n        T: Copy,\n        Op: Copy,\n        Ret: Copy,\n{\n    fn execute(self, conn: &::sqlite::SqliteConnection) -> QueryResult {\n        if self.records.is_empty() {\n            Ok(0)\n        } else {\n            conn.transaction:: (|| {\n                let mut result = 0;\n                for record in self.records {\n                    result += InsertStatement::new(self.target, record, self.operator, self.returning)\n                        .execute(conn)?;\n                }\n                Ok(result)\n            })\n        }\n    }\n}. How can I use it dynamically? \nlet mut Initial = ...\nfor sub_case in cases {\n    Initial = Initial.or(sub_case)\n}\nand what the Initial should be?. I think there is no need to create a new transaction and do nothing. Does create a transaction in sqlite is zero cost?. But the one-off task is triggered by a specific migration. If I change the schema from A to B and need to do some data conversion, I need check whether B is in pending migrations, and do my conversion after all migrations finish in current diesel version. And this check is also in embed_migrations::run(), so I add a callback for each migration in which user can do some additional task. Is there a more elegant way to solve this problem? thanks.. Is there a more elegant way to do this work with functions supported by current diesel version? Thanks.. @sgrif Are there other problems? Please review this commit once more.. You can do this via CustomizeConnection \n in r2d2. ",
    "antab": "Take 3, I added a test and removed the stray file from the last one.. ",
    "joshleeb": "I'd like to take this one on as a first issue :smile:\nI attempted to rebase #782 with git, but I think it'll be easier to reapply it manually instead. . @sgrif it seems as though, for the u32_to_sql_integer tests that the newly defined ToSql<Unsigned<Integer>>... implementation isn't being called and I'm not really sure why. . So far the added tests for unsigned types are passing but some documentation still needs to be added.. @sgrif I'm not sure what's causing the compile-fail tests to fail here.. @sgrif WDYT about renaming Tinyint to TinyInt for consistency with the other *Int types?. @sgrif updated the language for the changelog entry and added #[doc(hidden)] to the type alias.. Yep, is it just SmallInt, Integer, and BigInt?. @weiznich would it be better to have a HasSqlType for SmallInt, Integer, and BigInt, instead of this more generic version?. I'll add similar structs to /diesel/src/type_impls/primitives.rs for u16 and u64. I imagine that's better than implementing the traits manually here.. Would it be best to provide a type alias? Something like \nrust\npub type Tinyint = TinyInt. ",
    "toddWannaCode": "I am really interested in this but I am just getting started with diesel.. Hey I would be like to be a member of the Reviewers team. Thanks. @killercup  . Sorry it was my mistake.. ",
    "ecasilla": "Count me in also. I would love to help anyway I can. . @killercup How will the mentoring work exactly is there a gitter for the core team?. ",
    "jbcden": "I'm a bit late to the party and I haven't really gotten a chance to use diesel, but I'm trying to get into Rust more and would love to help with reviews! . >  FYI, we usually avoid the \"Request changes\" button unless the changes are substantial enough that you think a second review will be needed after the changes are addressed.\n@sgrif good to know! . @sgrif I'm not sure if this would be any better but what do you think of or_filter_by?. @sgrif I looked into this a little bit and it looks like the users table may not exist for these tests. It could be my local setup but everything seems to pass except these two tests and the Err returned says that the users relation doesn't exist. I'm trying to debug now but perhaps you know what to do already.. It looks like adding\nrust\n            let connection = PgConnection::establish(&connection_url).unwrap();\n            connection.execute(\"CREATE TABLE IF NOT EXISTS users (\n                id SERIAL PRIMARY KEY,\n                name VARCHAR NOT NULL\n            )\").unwrap();\nto the connection_no_transaction helper function seems to fix this. Not sure if that's ideal or not though.. @sgrif Looks like a nice refactoring to me!. @sgrif Sorry about that I'm still pretty new to Rust. I just added 7dd2853. If this still isn't quite right I can drop into Gitter and perhaps we can talk it over a bit.. @weiznich I just saw your comment, how do you feel about --no-clippy? I also wasn't sure if 1acc79212ff4647ee677b7ac7bc829515843ab30 should be pulled into a separate PR or if it was ok to lump it into this one. Thoughts?. > This two lines should be removed.\n\ud83e\udd26\u200d\u2642\ufe0f removed in df38cf5c8fe88e238e59a9c2ed712891d74f5820. > This needs to be removed too ^_^\n\ud83e\udd26\u200d\u2642\ufe0f I think I got all the echos this time.. I might be misunderstanding this but should this be (old OR new)?. ",
    "retep007": "Hi, count me in. I think the previous error was slightly better, however what about explicitly saying Cannot derive Insertable for empty Structs. How does this help me when my structure fields are missing? What is the use case?. Could you move When asking... on a new line?\nAlso what you say on When asking the database to return data from query.\n\nInformation is also a number of the affected rows\nOperation feels to me a bit too much agnostic\n. \n",
    "logotie": "Hello all, is there any chance I could please be added also?  I am however very much a beginner with Rust :). ",
    "dlukes": "Doesn't seem to help :( I also tried using an env variable and the .env file, but the result is the same.. That was my thinking as well initially :) To be more precise, I didn't know specifically I needed to percent encode them (thanks for the info!) but I figured special characters might be a problem, so I changed my password and still no dice... And even when I put a wrong password in there with just ASCII letters, the error is still the same (i.e. it doesn't seem to even get to the stage where it tries to connect to the database cluster).\nIf it's relevant somehow, this is a PostgreSQL server installed from source, running under my user on a server I don't have root on. Connecting to databases with the psql command line tool works fine.. I wanted both sqlite and postgres support, so what I did was cargo install diesel_cli --no-default-features --features 'sqlite postgres'. Maybe I'll try reinstalling with just postgres then?. > Does your username or password contain any special characters?\nUsername is plain ASCII letters, the password I originally tried it with contains also numbers and a period, but I changed it and the behavior remained the same (see previous comment).\nFWIW, when I try to use a sqlite database instead of postgres, the database is successfully created but running the initial migration fails with a syntax error, which is weird because when I feed the migration script to the command line sqlite3 client, it doesn't choke on it.\nSo maybe something went wrong during compilation? As I mentioned, both the sqlite and postgres libraries are installed in nonstandard locations, I had to set LIBRARY_PATH for cargo to find them, but once I'd done that, the compilation seemingly went fine and no errors were reported.. > Also just to confirm, you're seeing this error message when using exactly the URL postgres://myuser:mypassword@localhost/mydb?\nyes\n\nCan you provide the output of otool -L $(which diesel) or the equivalent command on your OS to show the shared libraries used in the diesel binary?\n\nThis was good thinking, thank you very much! I did ldd $(which diesel) and it dawned on me based on the output that I'd compiled diesel against my custom-installed version of various libraries sitting alongside the sqlite and postgres libraries, but at runtime, diesel was finding the system versions of those :)\nSo thanks again, after setting LD_LIBRARY_PATH, everything works as expected. The error must have been the result of some weird interaction with the older versions of the libraries. Closing.. > I suspect that you're loading some older versions of libpq (possibly system libraries), and need to set your LD_LIBRARY_PATH before running it\nYes you're exactly right :) Thanks again!. Having slept on it, the compile-time option doesn't make sense: I'm using the SQLite library as provided by my OS, which is already compiled (with the option enabled, I've checked), and diesel just links against that, right? So either JSON support has to be explicitly enabled at the diesel level as well (via a --feature perhaps?) or I'm out of luck :). After some more exploration, it turns out that the JSON manipulation functions do work from diesel, the only thing that doesn't work is specifying JSON as the datatype of a column (one has to use TEXT instead). The best I could come up with is this: given the following table...\n```sql\n-- up.sql\nCREATE TABLE docs (\n  id INTEGER PRIMARY KEY NOT NULL,\n  meta TEXT NOT NULL\n)\nINSERT INTO docs (meta) VALUES ('{\"foo\": 1}');\n```\n... and model...\n```rust\n// models.rs\n[derive(Queryable, Debug)]\npub struct Doc {\n    pub id: i32,\n    pub meta: String,\n    pub foo: i32,\n}\n```\n... one can formulate queries like these:\n```rust\nuse schema::docs::dsl::*;\nuse diesel::{\n    dsl::sql, sql_types::{Integer, Text},\n};\nlet query = docs.select(sql::<(Integer, Text, Integer)>(\n    \"id, meta, json_extract(meta, '$.foo') as foo\",\n));\n```\nIf anyone knows of a better / less verbose way, please share, but I'm going to close this since diesel clearly is compiled with SQLite JSON support (since json_extract above works) as long as the SQLite library is, it just doesn't support the JSON datatype :). ",
    "samrayleung": "Even though I have changed the return type from Date to Timestamp, I still get error as below:\n``\nerror[E0277]: the trait boundstd::vec::Vec<(chrono::NaiveDateTime, i32)>: diesel::Queryable<(diesel::types::Timestamp, diesel::types::Integer), diesel::pg::Pg>is not satisfied\n  --> src/dal/models/visitor_log.rs:34:18\n   |\n34 |                 .get_result(conn)\n   |                  ^^^^^^^^^^ the traitdiesel::Queryable<(diesel::types::Timestamp, diesel::types::Integer), diesel::pg::Pg>is not implemented forstd::vec::Vec<(chrono::NaiveDateTime, i32)>|\n   = help: the following implementations were found:\n             <std::vec::Vec<T> as diesel::Queryable<diesel::types::Array<ST>, diesel::pg::Pg>>\n             <std::vec::Vec<u8> as diesel::Queryable<diesel::types::Binary, DB>>\n   = note: required because of the requirements on the impl ofdiesel::LoadQuery>fordiesel::expression::SqlLiteral<(diesel::types::Timestamp, diesel::types::Integer)>`\nerror: aborting due to previous error\nerror: Could not compile blog.\n. I get another error as below:\nthread '' panicked at 'Received more than 4 bytes decoding i32. Was a BigInteger expression accidentally identified as Integer?', /home/samray/.cargo/registry/src/mirrors.ustc.edu.cn-61ef6e0cd06fb9b8/diesel-0.14.1/src/types/impls/integers.rs:31:8\nnote: Run with RUST_BACKTRACE=1 for a backtrace.\nand after I change `Integer` to `BigInt`, everything works fine. Thanks soooo much for help me out, you save my day !\n    pub fn count_daily_page_view(conn: &PgConnection) -> Vec<(NaiveDateTime, i64)> {\n        sql::<(Timestamp, BigInt)>(\"SELECT date_trunc('day', access_time) ,\n    count(*) FROM visitor_log\n            WHERE access_time> now() - interval '30 days'  GROUP BY 1  ORDER BY 1\")\n                .get_results(conn)\n                .expect(\"Error executing raw SQL\")\n    }\n```. ",
    "stevepentland": "In an effort to learn more about diesel, I'd like to take this one on @sgrif. I'm just looking through what I believe is the code you referenced in your previous comment.. ",
    "jhpratt": "@sgrif I presume this would be related to the bug I'm running into with a column named columns?. @weiznich Is there a tracking issue for proc macros? I'm unable to find any.. ",
    "fmartini": "All public modules declared in the query_builder module clash with column names in the table macro, e.g. functions.. ",
    "alexanderbanks": "@ghotiphud thanks for the response. I actually took the seemingly simpler approach of running diesel print-schema on each DB change and then modifying the schema.rs file with its output.\nWe can close this, I apologize for not responding to @sgrif . All is well.. ",
    "bippityboppity": "I'd like to give this a try :slightly_smiling_face: . ",
    "blazern": "@sgrif, is there a way to see the full query used by Diesel though?\nIf one can't see the full query used by Diesel, it can be hard to debug wrong behaviour. . ",
    "ponyloop": "Okay, thank you!. ",
    "NotBad4U": "@Bobo1239 So I used the master branch in my Cargo.toml \n[dependencies]\ndiesel = { git=\"https://github.com/diesel-rs/diesel.git\", features = [\"large-tables\", \"sqlite\", \"chrono\"] }\ndiesel_codegen = { version=\"0.16.0\", features = [\"sqlite\"] }\nAnd when I compile with the feature large-tables. I get this errors:  \n``\nerror[E0194]: type parameterRshadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build<R: NamedRow<DB>>(row: &R) -> Result<Self, Box<Error + Send + Sync>> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n470 | |         (17) -> R, SR, TR,\n    | |                 - firstR` declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror[E0194]: type parameter R shadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build>(row: &R) -> Result> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n490 | |         (17) -> R, SR, TR,\n    | |                 - first R declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror[E0194]: type parameter R shadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build>(row: &R) -> Result> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n511 | |         (17) -> R, SR, TR,\n    | |                 - first R declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror[E0194]: type parameter R shadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build>(row: &R) -> Result> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n533 | |         (17) -> R, SR, TR,\n    | |                 - first R declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror[E0194]: type parameter R shadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build>(row: &R) -> Result> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n556 | |         (17) -> R, SR, TR,\n    | |                 - first R declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror[E0194]: type parameter R shadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build>(row: &R) -> Result> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n580 | |         (17) -> R, SR, TR,\n    | |                 - first R declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror[E0194]: type parameter R shadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build>(row: &R) -> Result> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n605 | |         (17) -> R, SR, TR,\n    | |                 - first R declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror[E0194]: type parameter R shadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build>(row: &R) -> Result> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n631 | |         (17) -> R, SR, TR,\n    | |                 - first R declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror[E0194]: type parameter R shadows another type parameter of the same name\n   --> /home/alessio/.cargo/git/checkouts/diesel-6e3331fb3b9331ec/98d0e98/diesel/src/types/impls/tuples.rs:69:26\n    |\n69  |                   fn build>(row: &R) -> Result> {\n    |                            ^ shadows another type parameter\n...\n432 | / tuple_impls! {\n433 | |     17 {\n434 | |         (0) -> A, SA, TA,\n435 | |         (1) -> B, SB, TB,\n...   |\n658 | |         (17) -> R, SR, TR,\n    | |                 - first R declared here\n...   |\n667 | |     }\n668 | | }\n    | |_- in this macro invocation\nerror: aborting due to 9 previous errors\nerror: Could not compile diesel.\n``. Maybe we should add the featurelarge-tableto [diesel_tests/Cargo.toml](https://github.com/diesel-rs/diesel/blob/master/diesel_tests/Cargo.toml) and add a test with astruct` that use this feature to avoid to encounter this bug again ?. ",
    "kivikakk": "https://github.com/diesel-rs/diesel/blob/a0fce398cfc2338564e6c7fa9225d7e92ec38489/diesel_tests/tests/expressions/mod.rs#L364\nThis is an eyesore, but I'm not sure how to convince the compiler to infer r as equal(ish?!) to the $arg_struct_name idents \u2026. I'd be curious on anyone's comments before I proceed with trying to clean this up!. I absolutely agree! Hence asking for comments. :) I'll work on that shortly.. This is now looking better. Thanks for your impeccable guidance there; it slotted right in with few changes.\nDoes the current positioning of the traits and structs for supporting this look OK?. Good call! Done.. Good point, thank you! Added in bb35442.. :+1:. \ud83d\udc4d . Not in this context? types isn't imported here.. Yep.. Good question! Dropping it.. Now that IntoSingleTypeExpressionList is in that module, yes.. Yep, done.. Yeah, good point. Fixed.. :+1:. I noticed behaviour where it wasn't, but I think that was in a previous iteration. I'll drop the excess.. Understood.. :+1:. :+1:. :+1:. They're like this:\nunexpected errors (from JSON output): [\n    Error {\n        line_num: 10,\n        kind: Some(\n            Error\n        ),\n        msg: \"10:5: 10:11: the trait bound `f64: diesel::SelectableExpression<()>` is not satisfied [E0277]\"\n    },\n    Error {\n        line_num: 10,\n        kind: Some(\n            Error\n        ),\n        msg: \"10:33: 10:43: the trait bound `f64: diesel::expression::NonAggregate` is not satisfied [E0277]\"\n    },\n    Error {\n        line_num: 10,\n        kind: Some(\n            Error\n        ),\n        msg: \"10:33: 10:43: the trait bound `f64: diesel::SelectableExpression<()>` is not satisfied [E0277]\"\n    },\n    Error {\n        line_num: 10,\n        kind: Some(\n            Error\n        ),\n        msg: \"10:33: 10:43: the trait bound `f64: diesel::query_builder::QueryId` is not satisfied [E0277]\"\n    },\n    Error {\n        line_num: 10,\n        kind: Some(\n            Error\n        ),\n        msg: \"10:12: 10:17: the trait bound `f64: diesel::Expression` is not satisfied [E0277]\"\n    },\n    Error {\n        line_num: 10,\n        kind: Some(\n            Error\n        ),\n        msg: \"10:33: 10:43: the trait bound `f64: diesel::query_builder::QueryFragment<_>` is not satisfied [E0277]\"\n    },\n    Error {\n        line_num: 10,\n        kind: Some(\n            Error\n        ),\n        msg: \"10:12: 10:31: the trait bound `f64: diesel::Expression` is not satisfied [E0277]\"\n    }\n]\nI'll add some specifics.. I'm not exactly sure what shape this should take, having tried a few ways. I've tried something in 99783c00, but it feels janky and wrong. Some documentation added too.. Got it.. ",
    "kochmaxence": "It takes me about 15 minutes to compile diesel with the feature.\nFifteen. Minutes.\n\nI can cope with \"humongous-tables\", instead of \"insane-tables\", \"probably-a-bad-idea-tables\", \"intern-tables\", \"unreadable-tables\", \"anti-compile-tables\" & others.\nUnfortunately I have a table with 80 columns.. I'm closing this for several reasons:\n\nBumping the allowed table size is a bad idea that originates from a bad idea, which will cause more drama in the long term: issues with \"I need to support 150 columns\". Large tables are a bad design choice.\nThe increased compile time is subject to drama in issues.\nThe drama around how to name things is driving me insane (pun intended).\nI opened this in Oct. and kept it open until now because I still don't feel like it's the correct approach.\n\n-> 5. If anyone needs to arbitrarily increase the maximum size, it's better to let them fork & modify to their needs. Maybe we should just document it somewhere, I might just open a new PR with some documentation and snippets I used to auto-generate it.\nThat said, I feel like @nsrsr had a point (in his deleted comment) about the issues we bring into our open-source community from society. But it's not the place to discuss this.. ",
    "leodasvacas": "We should not use \"insane\" in a name because that may be perceived as ableist.. @sgrif thanks for the review! Does it look correct now?. The latest bigdecimal upgraded to 0.2, I don't know how we could be compatible with both 0.1 and 0.2.. This could just be left at 0.1.32 since it's semver compat with 0.1.39. ",
    "nsrsr": "no, we should not. Please let's all work together on software instead of polluting it with so called \"social issues\" and politics of any kind. Please spare my area of work from left-wing ideas. Thanks.. ",
    "icefoxen": "My mistake for not seeing it then, thanks!. Sorry for reviving this, but I thought with Rust 2018 #[macro_use] and extern crate ...; were supposed to not be needed anymore.  I can't come up with the right combination of use decl's to get all the right bits of the macro in the same scope though.  Is there a good way to do this yet, or should we just stick with #[macro_use]?\nThanks a lot.. Will do, thanks a lot!. Give me a poke when #1923 gets merged, if I don't notice already, and I'll rebase this thing off of this branch.. Done!  New version is in #1937.  Thank you!. Any particular reason this wasn't merged when I first made it?. Well thank you for the confirmation that I'm not crazy at least!  :D\nIs there a way to, instead of having each individual column being nullable, have the entire sub-struct be nullable?  So instead of having:\nrust\nstruct Analysis {\n    size: Option<...>,\n    valid: Option<...>,\n    checksum_matches: Option<...>,\n}\nstruct CrateWithAnalysis {\n    a: QueryA,\n    b: Analysis,\n}\nI could do:\nrust\nstruct Analysis {\n    size: ...,\n    valid: ...,\n    checksum_matches: ...,\n}\nstruct CrateWithAnalysis {\n    a: QueryA,\n    b: Option<Analysis>,\n}. Oh nice, got it.  Can do (ac::size, ac::valid, ac::checksum_matches).nullable() and it appears to work.  \nThank you!  You may close this as necessary.. ",
    "abhikp": "That worked. Thanks!. ",
    "forbjok": "I'm having the same issue on Windows 10 x64.\nI don't have MySQL in any shape or form installed, and I have no intention of using it.\nThis seems like it should be an optional component only required if you are actually using MySQL.\nUPDATE:\nI tried installing the MySQL C connector from mysql.com, pointing MYSQLCLIENT_LIB_DIR to it, and even renaming the libmysql.dll and .lib files to libmysqlclient.* like the package seems to expect, but it did not work.\nHowever, it's possible to disable building the MySQL support by specifing \"--no-default-features --features postgres\" on the cargo commandline, so if you aren't using MySQL that would solve this particular issue. Now I'm getting a linking error on libpq.lib instead. (presumably unrelated to this issue)\nUPDATE 2:\nFixed that last problem by setting the PQ_LIB_DIR environment variable to Postgresql's lib directory.. ",
    "eastuto": "for anyone wanting to actually use MySQL and who is having issues running cargo install, just to clarify adding the location of mysqlclient.lib to your environment variables will fix this.\nE.g.\nMYSQLCLIENT_LIB_DIR=C:\\Program Files\\MySQL\\MySQL Connector C 6.1\\lib\\vs14\n. ",
    "sbwtw": "Tips:\nif you build failed and follow this issue to change your environment variable, you should execute cargo clean before next build.\nseems cargo not re-run build script if you continue last build, and it will always get an error.. ",
    "shijunti19": "Windows 10 can't solve this problem.\n\n\n\n. Officials give you a solution. Windows 10 can't use MySQL. ",
    "vemoo": "What's the status of this PR?\nI'm interested because I want to be able to create a readonly connection, and I think this is the only way to achieve it.. Awesome, thank you! . ",
    "joelgallant": "@euclio did you want to rebase and finish this? I could also try to finish it off. For anybody who stumbles on this like I did, it's fairly easy to make a macro that deals with it.\n```rust\nmacro_rules! check_nullable {\n    ($query:expr, $val:expr, $table_field:expr, $check_null:expr) => {\n        match $val {\n            // there's a value, no need to check is_null\n            Some(ref val) => $query.filter($table_field.eq(val)),\n            None => match $check_null {\n                // there was no value, and we want to check IS NULL\n                true => $query.filter($table_field.is_null()),\n                // there was no value, but we won't check IS NULL\n                false => $query,\n            },\n        }\n    };\n($query:expr, $val:expr, $table_field:expr) => {\n    check_nullable!($query, $val, $table_field, false)\n};\n\n}\n```\nthe query needs to be boxed (because of the conditional), but this simplifies\nrust\nif let Some(ref foo) = self.foo {\n    query = query.filter(table::foo.eq(foo));\n} else {\n    query = query.filter(table::foo.is_null());\n}\ninto\nrust\nquery = check_nullable!(query, self.foo, table::foo, true);\nProbably also possible to do with generics, but the trait constraints are quite hairy.. If this was changed, could it also remove the old .gitkeep file?. @rajcspsg did you end up creating anything for this?. This also happens on master using cargo +beta doc -p diesel (stable fails in a different way).. Question - does hg even require a .keep file like git does? I believe svn doesn't (it tracks directories), not sure about other vcs's.. Is there any documentation about what versions of DBs that diesel targets? I know it would be non-trivial to enforce, but maybe just a version range listed in a README or website? Maybe there is and I couldn't find it.. Can it not just be [chrono::Duration] with backticks? (eg). ",
    "Ppjet6": "So many READMEs, more commits coming!. I haven't converted the link to www.apache.org in LICENSE-APACHE, not sure what to do here. If it's fine I'll push one more.\nFor the rest I checked and they don't support yet.\nPS: It would also be nice to have an http->https redirection on (docs.)?diesel.rs!. ",
    "driftluo": "Oh, thanks, However, at the moment crates' docs and readme's docs both point to the wrong address, which has a negative effect on the work. However, when I write it like this, my project is working properly:\n```toml\n[dependencies.uuid]\nfeatures = [\"serde\", \"v4\"]\nversion = \"^0.6.0\"\n[dependencies.diesel]\nfeatures = [\"postgres\", \"chrono\", \"uuid\", \"r2d2\"]\nversion = \"^1.1.1\"\n```\nOn Cargo.lock , only a 0.6.3 version of the uuid library.\nI think diesel features add the following:\n[features]\nv4 = [\"uuid/v4\"]\nI will be able to use this instead of reimport the uuid library just to turn on an features\uff1a\ntoml\n[dependencies.diesel]\nfeatures = [\"postgres\", \"chrono\", \"uuid\", \"r2d2\", \"v4\"]\nversion = \"^1.1.1\". Ok,  I looked at the source code, uuid is converted from trait FromSql IntoSql, not the corresponding type in the uuid crate, there seems to be no way to inherit the feature, this is my idealization, I underestimated the complexity of the problem, but this is not something that cannot be achieved. ",
    "attdona": "Ok, it make sense for me to try the latest diesel.\nI've pointed diesel to master-branch, but now this code stop compiling:\n```\n[macro_use]\nextern crate diesel_codegen;\n[macro_use]\nextern crate diesel;\nextern crate dotenv;\nextern crate r2d2;\nextern crate r2d2_diesel;\npub mod schema;\npub mod models;\nuse diesel::pg::PgConnection;\nuse r2d2::{ Pool, Config };\nuse r2d2_diesel::ConnectionManager;\nuse dotenv::dotenv;\nuse std::env;\npub fn create_db_pool() -> Pool> {\n    dotenv().ok();\nlet database_url = env::var(\"DATABASE_URL\")\n    .expect(\"DATABASE_URL must be set\");\nlet config = Config::default();\nlet manager = ConnectionManager::<PgConnection>::new(database_url);\nPool::new(config, manager).expect(\"Failed to create pool.\")\n\n}\n```\nrustc output:\n``\nerror[E0277]: the trait bounddiesel::PgConnection: diesel::connection::Connectionis not satisfied\n  --> src/lib.rs:18:1\n   |\n18 | / pub fn create_db_pool() -> Pool<ConnectionManager<PgConnection>> {\n19 | |     dotenv().ok();\n20 | |\n21 | |     let database_url = env::var(\"DATABASE_URL\")\n...  |\n25 | |     Pool::new(config, manager).expect(\"Failed to create pool.\")\n26 | | }\n   | |_^ the traitdiesel::connection::Connectionis not implemented fordiesel::PgConnection|\n   = note: required because of the requirements on the impl ofr2d2::ManageConnectionforr2d2_diesel::ConnectionManager= note: required byr2d2::Pool`\n```\nThe online docs http://docs.diesel.rs/diesel/pg/struct.PgConnection.html states that the Connection trait is implemented by PgConnection.\nI probably missing something.\nMy only Cargo.toml change (original line commented):\n    diesel = { git=\"https://github.com/diesel-rs/diesel\", features = [\"postgres\"] }\n    #diesel = { version = \"0.16.0\", features = [\"postgres\"] }\n. I tried, but clearly I'm doing it in a wrong way ...\nCargo.toml:\n[dependencies]\ndiesel = { version = \"0.16.0\", features = [\"postgres\"] }\n...\n[replace]\n\"diesel:0.16.0\" = {git=\"https://github.com/diesel-rs/diesel\"}\n\nrustc output:\nerror[E0599]: no method named `load` found for type `diesel::query_builder::SelectStatement<information_schema::information_schema::key_column_usage::table, diesel::query_builder::select_clause::SelectClause<information_schema::information_schema::key_column_usage::columns::column_name>, diesel::query_builder::distinct_clause::NoDistinctClause, diesel::query_builder::where_clause::WhereClause<diesel::expression::operators::And<diesel::expression::operators::And<diesel::expression::array_comparison::In<information_schema::information_schema::key_column_usage::columns::constraint_name, diesel::expression::array_comparison::Subselect<diesel::query_builder::SelectStatement<information_schema::information_schema::table_constraints::table, diesel::query_builder::select_clause::SelectClause<information_schema::information_schema::table_constraints::columns::constraint_name>, diesel::query_builder::distinct_clause::NoDistinctClause, diesel::query_builder::where_clause::WhereClause<diesel::expression::operators::Eq<information_schema::information_schema::table_constraints::columns::constraint_type, diesel::expression::bound::Bound<diesel::types::Text, &str>>>>, diesel::types::Text>>, diesel::expression::operators::Eq<information_schema::information_schema::key_column_usage::columns::table_name, diesel::expression::bound::Bound<diesel::types::Text, &std::string::String>>>, diesel::expression::operators::Eq<information_schema::information_schema::key_column_usage::columns::table_schema, diesel::expression::bound::Bound<diesel::types::Text, std::string::String>>>>, diesel::query_builder::order_clause::OrderClause<information_schema::information_schema::key_column_usage::columns::ordinal_position>>` in the current scope\n   --> /home/adona/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel_infer_schema-0.16.0/src/information_schema.rs:156:10\n    |\n156 |         .load(conn)\n    |          ^^^^\n    |\n    = note: the method `load` exists but the following trait bounds were not satisfied:\n....\n. Ok, pointing at master also diesel_codegen and diesel_infer_schema it works as expected:\nJust in case could help someone this is my setup (../diesel directory is the root of diesel github clone):\n```\n[dependencies]\ndiesel = {path = \"../diesel/diesel\", features = [\"postgres\"]}\ndiesel_infer_schema = {path = \"../diesel/diesel_infer_schema\", features = [\"postgres\"]}\ndiesel_codegen = {path = \"../diesel/diesel_codegen\", features = [\"postgres\"]}\n[replace]\n\"diesel:0.16.0\" = {path = \"../diesel/diesel\"}\n\"diesel_infer_schema:0.16.0\" = {path = \"../diesel/diesel_infer_schema\"}\n\"diesel_codegen:0.16.0\" = {path = \"../diesel/diesel_codegen\"}\n```\n@sgrif Thanks for your suggestions! . ",
    "SamWhited": "That makes sense, and documentation would make this less confusing.\nMaybe it could also search for a .git or .hg directory? Or if it doesn't find something just use the working directory? I'd still like to not have to create an empty Cargo.toml which I'm just going to remove after initializing the database for new projects.. It just occured to me that there might be an easy fix for this: if you don't have a Cargo.toml and are in the root of the project you can tell you're in the root because the migrations directory exists. If you're not in the root you can't tell where the root is, so for non rust projects it could just only work if you're in the root already instead of complaining about missing Cargo.toml every time I delete my development database and want to run migrations over again.. > Except the command you're complaining about is diesel setup, which is responsible for creating the migrations directory.\nIt's also used to create the database initially, so if we're spinning up the database for the first time (eg. on a new devvm) and the migrations are already created it will currently complain that cargo.toml doesn't exist even though it has a way to detect the root directory and the project doesn't need a cargo.toml.\nMaybe it could look for the migrations directory and cargo.toml? Then it could still be used to create the database and wouldn't panic every time with a confusing error message.\ndiesel database setup is a good workaround though, I can live with that, but when you look in the help \"setup\" appears the obvious command to run, and having that panic and spit out a confusing error message still doesn't feel ideal.. ",
    "simonhdickson": "Is this better? Also should I add this to the appveyor script?. Yes will rebase, should just add it to Travis then?. ",
    "nickbabcock": "What needs to get this PR over the hump and merged? \ud83d\ude04 . After applying the following patch:\n```diff\n--- a/diesel_cli/Cargo.toml\n+++ b/diesel_cli/Cargo.toml\n@@ -23,7 +23,7 @@ infer_schema_internals = { version = \"1.1.0\" }\n clippy = { optional = true, version = \"=0.0.185\" }\n migrations_internals = { version = \"1.1.0\" }\n url = { version = \"1.4.0\", optional = true }\n-libsqlite3-sys = { version = \">=0.8.0, <0.9.0\", default-features = false, optional = true, features = [\"bundled\"] }\n+libsqlite3-sys = { version = \">=0.8.0, <0.10.0\", optional = true, features = [\"min_sqlite_version_3_7_16\"] }\n[dev-dependencies]\n difference = \"1.0\"\n```\nI can confirm that I was able to install diesel_cli on a clean windows machine with --no-default-features --features \"sqlite-bundled\" and my projects using sqlite and diesel migrated fine. Btw, I copied the libsqlite3-sys from diesel's Cargo.toml for consistency, but I'm not sure if this is the desired form.. Applying the diff I posted earlier to this PR, as far as I know, addresses the last outstanding comment (the environment var looks to be already taken care of). If desired, I can simply open a new PR with applied diff to this PR.. Rebased onto master, so tests pass.\nI've also updated the travis file so that running the bundle isn't a one off that is ran on nightly and allowed to fail. It also contains the SQLITE_BUNDLED env as \"sqlite-bundled\" so that it can be used in features and allows for more tests on the bundled functionality. The downside of this is that it does add two full fledged builds in .travis so now mysql, psql, sqlite, and sqlite bundled are ran on stable and beta.\nI can understand how this would not be desirable, so I can switch it back to the one off (but run it on stable instead of nightly). Ah, I've been ninja'd! \ud83d\ude04 . Phew, should be in a state for review \ud83d\ude0c . ",
    "kjeremy": "This is a killer on windows.  What needs to be done?. I forgot to mention my .env contains DATABASE_URL=test.db.  I also tried setting the environment variable and it still fails.. I can cargo build from that directory but cargo install --path . still fails with the same error.. ",
    "bgeron": "It seems that at least one maintainer says that it's a mistake that your program compiles, until someone has the time to put a lot of work in making this work properly. (Although I think your program is fine.)\nI can see two workarounds to allow sub-selects in queries. I'm personally using the second.\nWorkaround 1\nWrite your SQL by hand. I believe you can still use Diesel to convert the results into Rust structs.\nWorkaround 2\nWrap your now in parentheses manually. For instance, you can use the following code\n```rust\nuse diesel::{Expression, AppearsOnTable, QueryResult};\nuse diesel::backend::Backend;\nuse diesel::query_builder::{AstPass, QueryFragment};\npub fn parens(e: T) -> Parens {\n    Parens(e)\n}\n[derive(Debug, Copy, Clone)]\npub struct Parens(T);\nimpl Expression for Parens {\n    type SqlType = T::SqlType;\n}\nimpl> AppearsOnTable for Parens {}\nimpl> QueryFragment for Parens {\n    fn walk_ast(&self, mut out: AstPass) -> QueryResult<()> {\n        out.push_sql(\"(\");\n        self.0.walk_ast(out.reborrow())?;\n        out.push_sql(\")\");\n        Ok(())\n    }\n}  \n```\nafter which you can simply write my_query.filter(my_field.eq(parens(now))). . If the maintainers agree that this bug should not be fixed, then they should probably close it as WONTFIX or something. . Sean, I'm a user who had the same problem, I managed to solve it for myself, and so I thought I'd share it with @mfr-itr. And I thought this 2 month old ticket could use an update.\nI have to admit I didn't fully understand what you said on Gitter, even after reading it multiple times, so perhaps my summary is wrong. How about you write one and I remove mine?\n. ",
    "nrc": "I'm not really sure. In theory, there is not much work to do before we can start stabilisation (mostly making sure libraries can work, especially around hygiene). But there's no one signed up for this, so I'm not sure when it'll ever get done. I'd guess end of 2018, but it is just a guess - could be much sooner if someone jumps on it, or much longer if nobody does.. ",
    "Zsarl": "Thanks for the response.\nThe first thing I tried was actually multiple table_name statements - maybe this is more intuitive:\n[derive(Insertable)]\n[table_name=\"table1\"]\n[table_name=\"table2\"].",
    "virome": "With 1.0 released, I'd like to take a stab at this one.. Hmm, looks like a module compile failure, investigating.\nI also see that master is failing because of a rustfmt diff, so I'll try again after that is fixed.. This appears to be a known regression in beta and nightly rust, I believe this is the same issue that was encountered on Diesel's nightly ci builds.\nhttps://github.com/rust-lang/rust/issues/47139\n. Spoke with weiznich on gitter and I'll be working on this one. @ian-p-cooke Unfortunately, I ended up not having much time to work on this. If no one else wants to take it, I still would like to finish it at some point.\nIf you're ready to go with your work, I wouldn't wait for me.. Sorry, this was meant to be to my personal fork. I'm closing it now.. So I think (?) this is wrong and I should be using a file in in https://github.com/diesel-rs/diesel/tree/master/migrations/postgresql\nBut what is the format for naming those folders?\nEDIT: Whoops, this is done with 'diesel migration'. So I have everything except this one...\nI've been trying various approaches for bit now, but I can't seem to get these array entries inserted via rust...\ninsert_into(number_arrays)\n        .values(mystery_type)\n        .execute(&connection)\n        .unwrap();\nWhat should the type of mystery_type be and how do I actually constuct that type? I've tried variations on &[[1, 20, 300], [0, 2], [500],] but they all give compiler errors revolving around diesel::query_builder::UndecoratedInsertRecord not being implemented.. This is the test that I just moved up from below, which is why I didn't change it when you said to use the api for new tests.\nBut I'll go ahead and migrate to diesel public api for both the test_min and test_max functions since they're related.\nEDIT: Sorry, I just saw your comment below. Sounds good. Rust is so cool. I'm surprised this self referential trait relationship even compiled. ",
    "kregoslup": "I would like to work on that issue, although I think I need some guidance. I'm not sure what do you mean by binary type name. I checked with SQLite reference here https://www.sqlite.org/datatype3.html point 3.1.1 and there is no binary type except for BLOB. Did you mean binary collating sequences? . ",
    "MarcManiez": "It's been a while since this there hasn't been activity on this issue so I went and submitted a PR for it. I hope that's ok, @kregoslup!. This conversation is very thoughtful. I believe this issue has been addressed in 443f43ae and can be closed \ud83d\ude42 .. @juliusdelta, you might also want to update the mention of .gitkeep to .keep on line 220 \ud83d\ude42 .. @weiznich I think I might be confused: don't we already have something like it in the same file, a few lines down?. I didn't see any other recent additions to the changelog, so I added an \"Unreleased\" section. Please do let me know if you had something more specific in mind!. ",
    "Libbum": "Oh, I see! Thanks for the reasoning and suggested changes -- can confirm they do indeed work as expected.. ",
    "bitemyapp": "I've tried stable and nightly, same result.. No, I have migrations and I ran them.\nsql\nCREATE TABLE tweets (\n  id INTEGER PRIMARY KEY,\n  coordinates_x REAL,\n  coordinates_y REAL,\n  created_at INTEGER NOT NULL,\n  current_user_retweet INTEGER,\n  -- display_text_range_start\n  -- display_text_range_end\n  tweet_id INTEGER NOT NULL,\n  in_reply_to_status_id INTEGER,\n  text TEXT NOT NULL,\n  user TEXT\n)\nRe-running diesel migration run yields:\n$ diesel migration run                         \n[ callen@chalcis ~/work/twook master \u2717 ]\n$\nbecause I'd run them earlier.. On a lark, I tried setting the DATABASE_URL to nonsense and got the same result,\n$ DATABASE_URL=\"blah\" make build-verbose\nSo I think it was looking in the wrong file location, pretty surprising to get this sort of error for that mistake.\nNew error now is:\n``\nerror: proc-macro derive panicked\n --> <infer_table_from_schema macros>:2:14\n  |\n2 | # [ derive ( InferTableFromSchema ) ] # [\n  |              ^^^^^^^^^^^^^^^^^^^^\nsrc/main.rs:18:1: 18:38 note: in this expansion of infer_schema! (defined in <infer_schema macros>)\n<infer_schema macros>:3:14: 3:25 note: in this expansion of #[derive(InferSchema)]\n<infer_schema macros>:3:14: 3:25 note: in this expansion of infer_table_from_schema! (defined in <infer_table_from_schema macros>)\n<infer_table_from_schema macros>:2:14: 2:34 note: in this expansion of #[derive(InferTableFromSchema)]\n  |\n  = help: message: Could not load credentials from databasetwook.db`: StringError(\"Unsupported type: serial\")\nerror: Could not compile twook.\n```. Schema in the sqlite3 database:\nsqlite> .schema tweets\nCREATE TABLE tweets (\n  id INTEGER PRIMARY KEY,\n  coordinates_x REAL,\n  coordinates_y REAL,\n  created_at INTEGER NOT NULL,\n  current_user_retweet INTEGER,\n  -- display_text_range_start\n  -- display_text_range_end\n  tweet_id INTEGER NOT NULL,\n  in_reply_to_status_id INTEGER,\n  text TEXT NOT NULL,\n  user TEXT\n);. Fixed an erroneous (earlier) migration that included SERIAL to be INTEGER, then got this:\nerror: recursion limit reached while expanding the macro `table_body`\n  --> src/main.rs:18:1\n   |\n18 | infer_schema!(\"dotenv:DATABASE_URL\");\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n   |\n   = help: consider adding a `#![recursion_limit=\"128\"]` attribute to your crate\n   = note: this error originates in a macro outside of the current crate (in Nightly builds, run with -Z external-macro-backtrace for more info). Added recursion limit 128, then got:\n``\nerror[E0277]: the trait boundf64: std::hash::Hashis not satisfied\n  --> src/main.rs:73:5\n   |\n73 |     pub coordinates: Option<(f64, f64)>,\n   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the traitstd::hash::Hashis not implemented forf64|\n   = note: required because of the requirements on the impl ofstd::hash::Hashfor(f64, f64)= note: required because of the requirements on the impl ofstd::hash::Hashforstd::option::Option<(f64, f64)>= note: required bystd::hash::Hash::hash`\nerror[E0277]: the trait bound f64: std::cmp::Eq is not satisfied\n  --> src/main.rs:73:5\n   |\n73 |     pub coordinates: Option<(f64, f64)>,\n   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait std::cmp::Eq is not implemented for f64\n   |\n   = note: required because of the requirements on the impl of std::cmp::Eq for (f64, f64)\n   = note: required because of the requirements on the impl of std::cmp::Eq for std::option::Option<(f64, f64)>\n   = note: required by std::cmp::AssertParamIsEq\nerror[E0277]: the trait bound &NewTweet: diesel::Insertable<__diesel_infer_schema::infer_tweets::tweets::table> is not satisfied\n   --> src/main.rs:142:10\n    |\n142 |         .values(&new_tweet)\n    |          ^^^^^^ the trait diesel::Insertable<__diesel_infer_schema::infer_tweets::tweets::table> is not implemented for &NewTweet\nerror[E0275]: overflow evaluating the requirement <_ as diesel::Column>::Table\n   --> src/main.rs:143:10\n    |\n143 |         .execute(conn)\n    |          ^^^^^^^\n    |\n    = help: consider adding a #![recursion_limit=\"256\"] attribute to your crate\n``. After adding recursion limit 256 it seems like my problems are now narrowed down tof64not beingEq`, so I think I'm good to go now.. @sgrif almost:\n```rust\n[derive(Queryable)]\n[derive(Debug, Hash, PartialEq)]\npub struct DbTweet {\n    pub id: i32,\n    pub coordinates_x: Option,\n    pub coordinates_y: Option,\n    pub created_at: DateTime,\n    pub current_user_retweet: Option,\n    pub tweet_id: i32,\n    pub in_reply_to_status_id: Option,\n    pub text: String,\n    pub user: Option,\n}\n[derive(Insertable)]\n[table_name=\"tweets\"]\npub struct NewTweet {\n    pub coordinates_x: Option,\n    pub coordinates_y: Option,\n    pub created_at: DateTime,\n    pub current_user_retweet: Option,\n    pub tweet_id: i32,\n    pub in_reply_to_status_id: Option,\n    pub text: String,\n    pub user: Option,\n}\n```\nResults in the following errors:\n`^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `diesel::types::Double`\nThis seems wrong. I'm trying to harmonize my model struct with the REAL column in my schema. The documentation said to use Double with sqlite as well. What did I do wrong?\nThen for a similar but different error:\n86 | #[derive(Insertable)]\n   |          ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `chrono::DateTime<chrono::Utc>`\nDo I:\n\nFork Chrono, add diesel as a dependency and add this trait in Chrono to the datatype\nFork Diesel, add a Chrono dependency, add the trait instance to the trait module \nNewtype DateTime, reimplement the diesel instances (does Rust have generic newtype deriving like Haskell?), then add the Expression instance for that newtype?. I think I missed: https://docs.diesel.rs/diesel/types/struct.Timestamp.html but I suspect if I try to put that in my model type I'll run into the same problem I'm experiencing with the floating point type.\n\nChanging the types from Double to f64 netted me this, which is why I went spelunking in the docs, found Double, tried that.\n86 | #[derive(Insertable)]\n   |          ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `f64`\nEdit:\nI tried Timestamp and chrono::NaiveDateTime, got roughly this error for both:\n87 | #[derive(Insertable)]\n   |          ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `chrono::NaiveDateTime`. I had to use i32 and f32 in the model types to get those to pass. That did seem wrong to me earlier, but using a signed int for what should be an unsigned database id seems wrong to me too. SQLite's Integer can do up to 8 bytes. Are you intentionally restricting it to ANSI rather than what SQLite can do?\nI didn't say I was using f64 because of the docs, I said I was trying to use Double in my model type because of the docs. I was in whack-a-mole mode.\nThe last one appeared to be SQLite's somewhat unfortunate handling of dates requiring that I use Integer for the column type, meaning i32 for the model type.. For posterity's sake, here are the final models and migration (schema):\n```rust\n[derive(Queryable)]\n[derive(Debug, PartialEq)]\npub struct DbTweet {\n    pub id: i32,\n    pub coordinates_x: Option,\n    pub coordinates_y: Option,\n    pub created_at: i32,\n    pub current_user_retweet: Option,\n    pub tweet_id: i32,\n    pub in_reply_to_status_id: Option,\n    pub text: String,\n    pub user: Option,\n}\n[derive(Insertable)]\n[table_name=\"tweets\"]\npub struct NewTweet {\n    pub coordinates_x: Option,\n    pub coordinates_y: Option,\n    pub created_at: i32,\n    pub current_user_retweet: Option,\n    pub tweet_id: i32,\n    pub in_reply_to_status_id: Option,\n    pub text: String,\n    pub user: Option,\n}\nsql\nCREATE TABLE tweets (\n  id INTEGER PRIMARY KEY,\n  coordinates_x REAL,\n  coordinates_y REAL,\n  created_at INTEGER NOT NULL,\n  current_user_retweet INTEGER,\n  -- display_text_range_start\n  -- display_text_range_end\n  tweet_id INTEGER NOT NULL,\n  in_reply_to_status_id INTEGER,\n  text TEXT NOT NULL,\n  user TEXT\n)\n```. >If you'd like to submit a PR that makes IDs unsigned on all the backends we support, I'd be happy to make that change. However, as it stands right now, they are signed.\nOK\n\nSQLite does not have any requirement that you use Integer to store dates\n\nI mean, you can also use TEXT or REAL too but that's not much of a choice.\n\nSQLite does not support built-in date and/or time storage class. Instead, it leverages some built-in date and time functions to use other storage classes such as TEXT, REAL, or INTEGER for storing the date and time values.\n\nMy point is it's not a real date or timestamp column type.\n\nCan you be more specific about what you read that implied that you should do that? I'd like to improve the documentation to fix that error.\n\nI'm more exhausted now than I was when I was reading it. Maybe another time.. @sgrif not on your end, SQLite's. Alternative is newtyping and wrapping one of the supported representations.\nPostgreSQL has more completely supported date and datetime column types\nI double-checked, it turns out, only MySQL has real support for unsigned numbers, save for SQL Server's tinyint, so making the primary keys unsigned, while more faithful to how they get used in practice, is likely to cause some impedance. Unfortunate.\nI'm going to see how uniform the support for 64-bit numerics is meanwhile. Should be possible to do better than the ANSI spec.. I'll leave it be and just assume something's missing on my end then.\nFWIW, when you say:\n\nJust to be clear, you can call your column DOUBLE, DECIMAL, or NUMERIC to make infer_schema!\n\nI have no earthly idea where you're proposing I put that text.\nBut please don't tell me, put it in the docs if you're motivated. I'll keep-on with keeping-on with my thing rather than trying to fix the size for now.. Integer by itself is guaranteed to support up to 8 bytes by SQLite's documentation.\nYour suggested column types don't neatly fit an i64. Numeric can contain any of the five storage classes, so that isn't narrowly or clearly i64. Double is f64, not i64. Decimal falls under Numeric affinity and isn't a 64-bit signed integral number, but rather, a decimal value for which you can specify precision.\nThe actual column type that maps unambiguously onto i64 in SQLite and is in common use for that purpose is Integer, per the SQLite documentation:\n\nINTEGER. The value is a signed integer, stored in 1, 2, 3, 4, 6, or 8 bytes depending on the magnitude of the value.. >I think you may be confused about how SQLite's storage works. SQLite is dynamically typed. \n\nI'm not confused at all. My point is that i64 captures all possible sizes and values of Integer and is the most obvious native representation of SQLite's Integer unless you'd like to have an enum that separates them by size. But that would be silly and I don't think you're suggesting that.\nInstead, Diesel infers a type which cannot correctly or validly represent all possible values of an Integer column, i32.\nDecimal(5, 2) is definitely a valid column type in SQLite, it just doesn't mean a lot representationally because of SQLite's weird dynamic thing.\nI don't think this is steering in a direction that'll do anything useful, but thank you for taking the time so far. Have a good day!. Is \"empty database\" inclusive of \"wrong filepath?\" That was what happened in my case.. ",
    "sanmai-NL": "@weiznich: https://docs.rs/migrations_internals/1.0.0-beta1/macro.embed_migrations.html on https://docs.rs/migrations_internals/1.0.0-beta1/migrations_internals/ does not work. https://docs.diesel.rs/diesel/macro.embed_migrations.html, found on Google, also doesn\u2019t. Do you know the correct docs link?. It should be possible to close this one quickly \ud83d\ude42 . ",
    "dbkaplun": "This is the one feature I look for that weaker ORMs do not implement: programmatic migrations.. No problem @sgrif \ud83d\udc4d This works great for my use case. I'll leave the branch up for now in case others find it useful.. ",
    "ocamlmycaml": "I\u2019d like to take a stab at this issue. This would be my first rust project contribution here so i\u2019m hoping this will be ok for that as well. > If this was changed, could it also remove the old .gitkeep file?\nhmm is that a good idea? it'll be dead code after you use diesel_cli once (in the newer release). I guess it's ok if I can add a TODO or issue to clean it up in a much later release. Hg doesnt track directories: https://superuser.com/questions/81204/how-to-add-an-empty-folder-in-a-mercurial-project\nHmmm this might be scope creep but would it be more useful to have a readme about how to manage migrations in that directory by default instead of a .keep?. Hello!\nNot sure if I missed something on the contrib guide, but do I need to do something else to get approval and merge?. > You don't missed something, it's just that nobody currently has time to review PR's \ud83d\ude48\n\n(More reviewers would be great \u2026)\n\nI see :(. Oh well, i'll just pick up other tickets then B-). ",
    "dev10": "Looks like the PostgreSQL DatabaseError output was misleading. It was connected to the wrong database. ",
    "alatiera": "@sgrif Yes sorry. I guess I missed a review and the callback was not triggered?\nSorry, still getting used to github's Pull request mechanism.. @sgrif It seems that https://github.com/diesel-rs/diesel/pull/1414#discussion_r157878831 still isn't marked as resolved and I am not sure how do it. Can I request a manual review?. Yes that sound better, and less confusing. I took a look at the associations docs, do you think we could link or use those definitions of User and Post tables?. That's way better worded and informative, I will go ahead and replace it, thanks!. I think the SQL terms would help people map diesel syntax to something they already know, where the other way would already require a familiarity with diesel. Though both could probably be mentioned.. Sorry for the late response, I missed that.\nAs of 4695673e434127b20deb2e4a05d179052c6e4321 it was fixed  but seems like git  didn't picked it up as changed. Sorry for that.\nHere's how it renders on the latest commit (2f1575e4d6affea2844cf0b756e578127d202285):\n\n. ",
    "cpick": "Does it look like any more changes are needed?  I think I got everything so far.. ",
    "anilanar": "@sgrif What do you mean by:\n\nIf you really want to share these structs, Queryable composes with other structs that are Queryable.\n\nWhen I have the following: \n```\n[derive(Queryable)]\nstruct UserWithId {\n    id: i32,\n    user: User,\n}\n[derive(Queryable)]\nstruct User {\n    age: i32,\n}\n```\nusers::table.load::<UserWithId>(&conn)?; emits an error:\nerror[E0277]: the trait bound `(i32, User): diesel::Queryable<(diesel::sql_types::Integer, diesel::sql_types::Integer), _>` is not satisfied. It does work, but then it doesn't generate BelongsToDsl implementation for XWithId struct when foreign key field is defined in X struct. You can work around it by defining it in both XWithId and X and then do .select((x::id, x::user_id, (x::user_id, x::others)). Duplication again. Far from ideal \ud83d\ude15.  . ",
    "chillcaw": "Cargo.toml:\ntoml\ndiesel = { version = \"1.0.0-rc1\", features = [\"postgres\"] }\ndotenv = \"0.9.0\"\ndiesel_codegen = { version = \"0.16.0\", features = [\"postgres\"] }\nr2d2-diesel = \"1.0.0-rc1\"\nr2d2 = \"0.8.2\". Ah cool, I will have to look through diesels docs, I have been going by rocket's docs. They must be slightly out of date.\nnew Cargo.toml for people with the same problem:\ntoml\ndiesel = { version = \"1.0.0-rc1\", features = [\"postgres\"] }\ndotenv = \"0.9.0\"\nr2d2-diesel = \"1.0.0-rc1\"\nr2d2 = \"0.8.2\". I have it working with my Rocket project: Rocket Template.. ",
    "Martin1887": "Thanks, the issue can be closed then.. ",
    "martinlindhe": "The CI failures seems to be unrelated to this PR, as master is failing on the same issue (https://travis-ci.org/diesel-rs/diesel/builds/324571562)\nerror: `Queryable` is ambiguous\n --> tests/queryable.rs:9:49\n  |\n9 |     #[derive(Debug, Clone, Copy, PartialEq, Eq, Queryable)]\n  |                                                 ^^^^^^^^^\n  |. Sure, I will update this PR. PR rebased, and the new guide included too.\nhttps://github.com/diesel-rs/diesel/pull/1446/commits/8eb63c88f83f1a73eaf778d965247bd806332b15#diff-89e098c28236db73cf3b06cb8bcb7ebb\n  . I felt the wording here should be changed after reading https://github.com/diesel-rs/diesel/blob/master/code_of_conduct.md#our-standards. Not sure what this comment brings to the table, so I removed it.. ",
    "AyushyaChitransh": "It would be very useful to mention here which version of rust solves the issue.\nFrom the link to comments, it seems that the problem was solved by this commit, but am unable to install diesel_cli using following versions:\n\nnightly-x86_64-apple-darwin unchanged - rustc 1.26.0-nightly (80785a547 2018-03-30)\nstable-x86_64-apple-darwin unchanged - rustc 1.25.0 (84203cac6 2018-03-25). My build was failing but not due to the reasons mentioned in this issue. I was getting following error:\n\nerror: linking with `cc` failed: exit code: 1\n |\n  = note: \"cc\" \"-m64\" \"-L\" ...\n  ...\n  = note: ld: library not found for -lmysqlclient\nAnd I was able to resolve it by using:\ncargo install diesel_cli --no-default-features --features postgres\nThanks to the comment. ",
    "EloD10": "Thank you a lot for your very fast response ! \nBut me, i was long because i have do some test whitout succefull solution until I install PostgreSQL with EnterpriseDB installer (not BigSQL as i did). And finally with your instructions it works ! Thank you a lot ! <3\nI think we should add these instructions in documentation, it can help some people =). ",
    "top1st": "@sgrif that backend_installation.md worked me for compile but not working well.\ndiesel setup  \ud83d\udc4d  works\ndiesel migration generate create_posts \ud83d\udc4d  works\ndiesel migration run  \ud83d\udc4e  not works\ndiesel migration list \ud83d\udc4e not works\nI follwed this link\nhttps://diesel.rs/guides/getting-started/ \nwhy not works in windows?\n. copy C:/PostgreSQL/pg10/lib/libpq.dll & libpq.a to $(HOME)/.rustup/toolchains/[stable--msvc,gun]/lib/rustlib/x86/64-pc-windows.../lib\nrename libpq.a -> libpq.lib \nnext compile works\n. Here is one issue diesel migration run not works well.. ",
    "KingOfThePirates": "I'm not a candidate, but I care about the rust community so I'd like to offer unsolicited advice. I like the idea. But one thing that always makes me turn away is when people link broken links or outdated information. I haven't thought the solution through, but I wanted to share the idea, just in case it was easy for you to implement / add into your website: automate the check on the last updated date of the projects you link to. If they aren't active projects and they've become stale, don't use them as examples. If there aren't enough active projects using Diesel, work on getting more people to use it. Until you have more than a couple / several, then don't activate the page and hide the link to the page of live projects that use Diesel.\nI don't know how nitpicky this is, but I mean well. If it won't work to do it that way then don't do it. I haven't tested this out and don't know the implications :)\nHopefully I didn't overlook a simpler solution, but here's an idea that might be simplish: https://github.com/huginn/huginn. ",
    "pgab": "We are using Diesel and are going to ship it to customers within February.\nhttps://www.giga-infosystems.com\nhttps://gist.github.com/pgab/d1d23cd1d6fd1d5ac9e04760daba13c2. ",
    "jonathanstrong": "Wow, ok. Fwiw, as a user of diesel print-schema/infer_schema! this is a very sharp departure from how I expected it to work. I realize the docs of Queryable state it plainly but might be worth looking for other more visible places to note this. In many cases you'll end up triggering a type error but in the cases the misordered fields match up on type it could be pretty maddening to debug.. ",
    "tensor-programming": "thank you.  That confirms what I assumed happened.. It is on my path. that's is the problem; I'm not sure why you closed this issue when it hasn't been resolved at all.\nI did resolve this however by using vcpkg to install a new pqlib file and then pointed cargo towards it.  \nI understand that you probably are sick of listening to windows users complain about their terrible ecosystem but seriously... . ",
    "venkat125": "\nIt is on my path. that's is the problem; I'm not sure why you closed this issue when it hasn't been resolved at all.\nI did resolve this however by using vcpkg to install a new pqlib file and then pointed cargo towards it.\nI understand that you probably are sick of listening to windows users complain about their terrible ecosystem but seriously...\n\nhow to install pqlib file using vcpkg and point to cargo?. ",
    "lukesutton": "Totally fair! I imagined there was some constraint there. My approach at this point has been to synthesize a primary key for rows in views and manually add table! declarations for them, which is working pretty well.. ",
    "jjpe": "I completely missed that, you're absolutely right.\nOne too many late night coding sessions :). ",
    "rokob": "Alrighty, here it is using the url crate. The current function using pop().unwrap() led me to believe that the error handling here is to panic on bad input, so I just liberally used unwrap.. ",
    "SoniEx2": "I use CString as a form of NulString with unspecified encoding. This is extremely useful to me because I do a lot of interactions between embedded systems and they use C strings with \"unspecified\" encoding in their protocols, and some of those C strings are used when interacting with the DB and vice-versa. Validating that there are no nuls on the way in and on the way out would be nice, as well as avoiding any copies and conversions until the thing hits the Diesel or DB layer.. Actually, in this case CString has an \"unspecified\" encoding. It's basically a nul-terminated array of bytes for all intents and purposes. This has a slight (read: pretty big) difference compared to String.\nI'd either have to convert encoding at protocol boundary (fast, but may cause unnecessary/unused copies), or every time at DB/Diesel boundary (lots of redundant copies, but avoids the previous issue). I don't like either.. Ok. How do I put a Vec into a varchar while avoiding copies?. So what I should do is forget Diesel and use raw SQL?. Shouldn't you try to match wire protocol encoding with text column encoding to reduce conversions as much as possible?. ",
    "alleycat-at-git": "@sgrif  Yeah, that would solve the issue. ",
    "jeremybmerrill": "@searing : Were you able to find a solution to this? I have the same problem (minus the nullable stuff), so \"type mismatch resolving <diesel::expression::ops::Sub<diesel::dsl::now, diesel::expression::bound::Bound<diesel::sql_types::Interval, diesel::data_types::PgInterval>> as diesel::Expression>::SqlType == diesel::sql_types::Timestamptz\" for .filter(created_at.gt( now - 1.months() )). @searing Ah okay. Thanks!. ",
    "searing": "No, my temporary solution is to use diesel::dsl::sql until this is fixed, hopefully in the next major Diesel release.. I suppose you could introduce a new SQL type (perhaps Now) which can be coerced to either Timestamp or Timestamptz, and then implement interval addition/subtraction for that type. That seems like the most \"correct\" way to do it, in the sense that the Postgres server is probably doing something vaguely similar. I'm not sure how we'd feel about adding a new SQL type for what might be a fairly simple case, but I think it's better than nowtz since, to the user, the extra Now type should be totally transparent.. ",
    "RobertWHurst": "Exciting stuff. Thanks for this guys. \ud83d\ude04 . massive-tables?. ",
    "fafhrd91": "something like:\nUPDATE posts SET field='1' WHERE ..;\nUPDATE posts SET field='2' WHERE ..;\nUPDATE posts SET field='2' WHERE ..;. would it execute each update separately? \nsome background, I use diesel for TechEmpower framework benchmarks and it performs very well.\nbut result for \"db update\" benchmark is very weak. I see other frameworks do batch updates\nhttps://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Rust/actix. Thanks.. ",
    "thomasetter": "Another approach which also works with prepared statements is to chain the updates with WITH to create a single statement containing several updates:\nhttps://dba.stackexchange.com/questions/171123/use-same-postgres-with-in-multiple-queries. > I'm not sure I understand the use case of running our test suite in release mode\nThere is sometimes slightly different behavior in release and debug mode which can lead to bugs.\nIt makes sense to test all compile modes (also in the CI) to decrease the probability of introducing hard-to-debug issues.. ",
    "rajcspsg": "Hi - Can I work on this documentation issue and submit PR?. ",
    "cjen07": "Thanks, just solved my problem.. thanks a lot. ",
    "MattsSe": "Got it, thanks. Thought that diesel could omit the nullable field.\nGuess I'll use tuple types if I don't need the image data.. ",
    "sclarson": "Thanks for doing this.  Just started trying diesel out on our existing database today and ran into this almost immediately.\nAlso it looks like the tests are all passing now \ud83d\udc4d . The travis build appears to be breaking on compiling cargo metadata.  That seems like it should be unrelated to the change here.. I went to add this and doing so causes a compilation error. It looks like this implementation is already done by https://github.com/diesel-rs/diesel/blob/master/diesel/src/type_impls/primitives.rs#L38. ",
    "vjousse": "I'm also very interested in using the geometric types with diesel. @YetAnotherMinion would it be possible for you to publish your crate while we're waiting for a decision from the core team?. @YetAnotherMinion thanks a lot!. ",
    "spacekookie": "Yea, there is a problem with the code I don't know how to solve. I messaged you on gitter about it. \nAlso, looking at what's failing, it seems to be fine on one of the nightly branches. barrel does currently require nightly until rust#44490 is stabilised.. That's a fair point, I moved the MigrationName stuff back to migrations_internals. I don't really know what else to document about it. Considering that nothing else in that module is documented I think this should be alright.. @sgrif Sounds good :+1:\nI just published barrel v0.2.0 on crates.io and changed the dependencies. I'm gonna do the final round of cleanups tomorrow.\nThere is still an issue that's not caught by the CI which fails to compile diesel when using barrel. I'm wondering if it's some transient fault in diesel or in my own code. Would be nice to get that fixed before shipping the feature.. Eh, nevermind. Not sure what happened to the compile errors but they've gone away. I've cleaned up the code and adjusted some last things when calling barrel functions. The new feature seems to work and I hope I didn't break the CI again :smile: :crossed_fingers: \nEDIT: Actually, do we want to have an example how to use barrel in the example folder? Or just a comment in the README/ getting started section?. @sgrif @killercup Is there anything else that should be changed? Otherwise it would be great if we could get this merged :). Ping @sgrif it builds now! :tada: :smile: . There already is an issue. I doubt that it's actually the code in diesel that's causing the issue. But I'll have a look at it tomorrow.. That would be more elegant although rustc tells me attributes are not yet allowed on 'if' expressions. The stabilisation is being tracked here: rust-lang/rust#15701. \nI'd suggest we change the syntax when the feature becomes stable, as it is more elegant.. This needs to be public, it's re-exported from diesel_migrations. ",
    "tcmal": "It seems like this is already being done with nightly-2018-02-02, Just tried compiling with nightly-2018-02-01 and it failed with can't find crate for 'rustc_const_eval' (clippy-lints).. Ah, my bad.. Something like [printschema.whatever] with the usual properties could work if it inherited from the base printschema, I can't think of many other ways to do it & support filtering that isn't kinda messy imo.. ",
    "TethysSvensson": "The use_std flag was not enabled by default in 0.5.0.. Done.. Are there any plans to also do a new release for this?. Do you know an approximate timeframe for that? It is preventing us from upgrading our internal repos to uuid 0.6. I'd prefer not to have an internal fork of diesel.. ",
    "moore3071": "Thanks for the quick response. The extensible route of allowing other crates to provide new migration formats is probably the best route; I'll be sure to check out Barrel.. Instead of using two databases and dumping database info, it would make a lot more sense to use Diesel's ability to print the schema. This only gives table structure, but would be much easier to implement.\nAn obviously needed feature in a binary implementing this would be the ability to exclude the testing of specified migrations.. @weiznich, all problems from your review should be fixed now. It's just the Clippy part that's failing the build now (but it looks like the Diesel team already brought that up with the Clippy team).. I don't know much about macros 1.1 (yet), but I agree that that's the better approach for this issue. It's more concise, logical, and forward thinking. I'd love to help out with this; my main concern would be the support for macros 1.1. Are they supported in stable currently?\nIf so, would you mind, @sgrif, if I closed this PR and opened an issue for discussing this new sql_function macro?. If you mean having the docs above the macro call, I don't think that's possible at the moment. Nor would having them inside the arguments list now that I think of it. You could possibly hijack another unused token instead of /// or //!. Say:\nrust\nsql_function!(\n    @This is documentation for the\n    @sql function foo\n    fn foo(x: Integer, length: Integer) -> Text)\n);\nThis would probably pose other problems though.\n\nWe could potentially also change the API if you use the new syntax, but I'm not sure how I feel about that.\n\nI'd love to hear a little more elaboration on this. MySQL doesn't support function overloading. SQLite is an odd case. It doesn't have CREATE FUNCTION and functions are created through the C API. I Thought that it didn't support overloading, but after rereading the functions page it appears that they can be. I'll add a commit so that this works for SQLite.. ",
    "flip111": "\ndiesel print-schema does exactly that\n\nI see the table! macro printed with information about the columns ... how do i get the models from that ?. queryable and insertable ... it would be nice if this code can be generated. It's possible but with the caveat that is described in the symfony link\n\nDoctrine is able to convert approximately 70-80% of the necessary mapping information based on fields, indexes and foreign key constraints. Doctrine can't discover inverse associations, inheritance types, entities with foreign keys as primary keys or semantical operations on associations such as cascade or lifecycle events. Some additional work on the generated entities will be necessary afterwards to design each to fit your domain model specificities.\n\nSame for type mapping ... a best guess could be done. I think since already the schema can be printed it shouldn't be too hard to print the rust structs as well. I have no rust experience though, for me it will be hard in this point of time.\nI will close this because it's considered out of scope for diesel itself.. Hi, thanks for your response. With the discussion about down migrations and DSL's does your comment also apply to up  migrations based on generating SQL from queryable/insertable structs? I might be missing some background information, i couldn't tell.. What if you take the fields of all structs that related to a single table. Put them in a (single) unique list. Compare that with the database columns. When the database has an extra column or is missing a column write out the SQL migration for it?\nAre the facilities there to inspect the mapping (structs - tables)? Or would one have to write their own macros for it?. > Diesel doesn't assume or enforce that your structs are in anyway tied to table schema.\nAs far as i know that is the definition of Object-Relational Mapping to do just that. Now i'm utterly confused.. I understood the Queryable/Insertable structs to be the value containing \"objects\" (the O in ORM). Can table! hold values? I mean the values that go into and come from the database.\nIn the docs i see #[table_name = \"posts\"] i think this annotation does tie the struct below it to the posts table. Or is nothing assumed/enforced here? No check with the schema (table!)? If not, what is the posts string used for?\nI'm just trying to understand this by the background of another (non-rust) ORM i used to work with .... The library looks well made, thanks for writing it. However i must conclude this is not an ORM. As far as i understood the insertable are based on the names of fields and the queryable on the order of fields. This does not give the user the freedom to create a mapping.\nFor relations i read in https://docs.diesel.rs/diesel/associations/index.html\n\nAssociated data is typically loaded in multiple queries (one query per table). This is usually more efficient than using a join, especially if 3 or more tables are involved. For most datasets, using a join to load in a single query transmits so much duplicate data that it costs more time than the extra round trip would have.\n\nI like to see some numbers with the claim of efficient. Traditional database wisdom says to use joins for maximum query performance and a single roundtrip. It is expensive to deduplicate the data for sure. But it also gives you the possibility to construct an object graph and manage relations.\nFrom that point many ORM's introduce the concept of Unit of Work where changes are made to the objects and then once committed update the database in the least amount of changes. This isn't necessary though but it gives you the opportunity to decouple your data changes with your database inserts.\nORM's have their own problems though, so this query-first approach is excellent in many cases. Again  diesel looks like a very good library ... i just went in with the wrong expectations i think after seeing \"ORM\".. ",
    "dereckson": "If someone is looking for such feature,\nsee https://crates.io/crates/diesel_cli_ext. This crate provides a feature to generate model structs.. ",
    "taktoa": "Ah, then there are two conceivable bugs here:\n1. Why is diesel database drop marked as hidden? If it's not intended to be used, why does it exist?\n2. Perhaps clap's bash completion generation should not emit hidden subcommands.. ",
    "gasabr": "I would like to try to implement this issue. ",
    "jneumann": "If I'm understanding the documentation correctly, establish_connection() returns a struct that implements diesel::prelude::Connection, correct?. I kind of forgot I opened this issues. Thanks for the help, you guys rock!. ",
    "meven": "I would like to claim this issue.\nI understand the issue at stake is that in print_schema.rs:250 the outputed foreign_key column does not pass through the RESERVED_NAMES filter in inference.rs.\nSo I wonder which way to go from there, the simplest way I can come up with is to swap in\nwriteln!(f, \"{}\", Joinable(foreign_key))?;\nthe foreign_key with the rust_name using tables: Vec<TableData> to find the ColumnDefinition and the rust_name.\nOr in inference.rs there could be a post process in load_foreign_key_constraints to apply the RESERVED_NAMES filter or foreign keys as it is done on primary keys line 147.. ping @Eijebong does my take make sense ?\nShould I propose a fix, right away ?. ping @Eijebong \nI would like to claim this issue, does this mentoring offer still stands ?\nI'd like to discuss a little design, but after that I should be able to make a pull request with tests.. I am having a hard time setting up locally diesel to be able to test my changes.\nWhen running bin/test I end up with a bunch compilation error like :\nerror[E0412]: cannot find type `Nullable` in this scope\n  --> /home/meven/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-1.3.2/src/type_impls/primitives.rs:64:26\n   |\n64 |     #[derive(FromSqlRow, AsExpression)]\n   |                          ^^^^^^^^^^^^ not found in this scope\nI find it weird that a dev repo should rely on stable version of the crate.\nAm I missing something ?. ",
    "kestred": "The error codes that I'm hoping to catch are:\n * 40001 | serialization_failure\n * 40P01 | deadlock_detected\nTypically one or the other depending on whether the transaction is constructed with build_transaction().serializable() or not.\n. This error occurs for my use case specifically when two different services were attempting to do something that conflicts, but I've not been successful building a simplified use case.\nNon-Working Test (for serialization_failure)\nSourced from the postgres documentation hoping to find a minimal test case --- I'd written this, but I must've gotten something a bit wrong \ud83d\ude13.\n```rust\n[test]\n[cfg(feature = \"postgres\")]\nfn isolation_error_is_detected() {\n    // we need custom and multiple transactions, so we can't use default transaction\n    let conn = connection_without_transaction();\n    conn.execute(\n            \"CREATE TABLE IF NOT EXISTS isolation_example (\n                id SERIAL PRIMARY KEY,\n                class INTEGER NOT NULL,\n                value INTEGER NOT NULL\n            );\",\n        )\n        .unwrap();\n    conn.execute(\n            \"INSERT INTO isolation_example (class, value) VALUES\n                (1, 10),\n                (1, 20),\n                (2, 100),\n                (2, 200)\n             ;\",\n        ).unwrap();\nlet other_process = ::std::thread::spawn(|| {\n    let other_conn = connection_without_transaction();\n    other_conn.build_transaction().serializable().run::<_, result::Error, _>(|| {\n        other_conn\n            .execute(\"SELECT SUM(value) AS sum FROM isolation_example WHERE class = 1);\")\n            .unwrap();\n\n        ::std::thread::sleep(::std::time::Duration::from_millis(5));\n\n        other_conn\n            .execute(\"INSERT INTO isolation_example (class, value) VALUES (2, 30);\")\n            .unwrap();\n        Ok(())\n    }).ok();\n});\n\nlet failure = conn.build_transaction().serializable().run::<_, result::Error, _>(|| {\n    ::std::thread::sleep(::std::time::Duration::from_millis(2));\n\n    conn.execute(\"SELECT SUM(value) FROM isolation_example WHERE class = 2;\")\n        .unwrap();\n\n    other_process.join().unwrap();\n\n    Ok(())\n});\nassert_matches!(failure, Err(DatabaseError(IsolationFailure, _)));\n\n// clean up because we aren't in a transaction\nconn.execute(\"DROP TABLE isolation_example;\").unwrap();\n\n}\n```\nI'll take another crack it at eventually.... I am interested in getting a change like this merged in; @sgrif, does this PR need changes (I'd be happy to make a new one if there is a preference on how to support a newer version).\nIs there any reason that these dependencies have an upper bound on version selection?. @weiznich: please see https://github.com/diesel-rs/diesel/pull/1837 (tests finished successfully). @sgrif: now using allow rather than changing the syntax.\nI'd intuitively guess that newer versions of clippy would not have a fix for this ? (unless they've removed the lint entirely). The allow change is related to code affected by the version bump, so I'd strongly prefer merging this PR as is over blocking on another clippy-related PR. . @xrl: which version of BigDecimal do you depend on?\nI think I've had that error when I've used two different versions of BigDecimal.  The current stable release series 1.3.X depends on bigdecimal = { version = \">= 0.0.10, < 0.0.12\", optional = true }.\n(Support for the most recent version of bigdecimal has been added to the 1.4 milestone: https://github.com/diesel-rs/diesel/pull/1837). ",
    "tgturner": "I would love to take a look at this one!. @sgrif @weiznich \nThanks for the feedback! I thought it seemed like on heck of a change but figured it was best to just get something out there.\nSo from what I am hearing, the only change that needs to be made is to update lib.rs to look like this?\n``` rust\npub mod dsl {\n    //! Includes various helper types and bare functions which are named too\n    //! generically to be included in prelude, but are often used when using Diesel.\n#[doc(inline)]\npub use helper_types::*;\n\n#[doc(inline)]\npub use expression::dsl::*;\n\n#[doc(inline)]\npub use query_builder::functions::{delete, insert_into, insert_or_ignore_into, replace_into,\n                                   select, sql_query, update};\n\n}\n```\nDoes it make sense to add new tests for these methods somewhere?. Will do! Thanks for the guidance!\nSent from my iPhone\n\nOn Apr 19, 2018, at 4:40 PM, Georg Semmler notifications@github.com wrote:\nSo from what I am hearing, the only change that needs to be made is to update lib.rs to look like this?\n\ud83d\udc4d\nDoes it make sense to add new tests for these methods somewhere?\nMaybe change one or two tests to the newly added methods. Just in case somebody tries to remove them for whatever reason.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @weiznich I made the requested changes and squashed the commits (no one needs to see that giant commit I made). Let me know if there are any other changes I can make! \n\nI also updated some tests to use the newly exported methods.\nThanks again for all the help!. @sgrif Removed the tests! Thanks for working with me on this.. ",
    "alexfedoseev": "@sgrif Yeah, Text is a temporary workaround only to compile the app. Can you give some hints how it should be handled the right way?. Gotcha, thanks!. Recent activity reminded me about this task so I tried to implement it on the weekend.\nAFAIU from the history, the issue w/ this type is that citext_column.eq() performs a case-sensitive comparison. So I implemented  ToSql/FromSql using Text type and then tried to impl ExpressionMethods for Citext which gave me an error I couldn't resolve.\n@sgrif Can you take a look if what I did makes sense (just requires some adjustments) or I did something stupid and it should be implemented differently? Thanks in advance!\n```rust\nuse std::io::Write;\nuse diesel::deserialize::{self, FromSql};\nuse diesel::expression::operators::Eq;\nuse diesel::expression::{AsExpression, Expression};\nuse diesel::expression_methods::ExpressionMethods;\nuse diesel::pg::Pg;\nuse diesel::serialize::{self, Output, ToSql};\nuse diesel::sql_types::Text;\n[derive(Debug, Clone, Copy, SqlType)]\n[postgres(type_name = \"citext\")]\npub struct Citext;\nimpl ToSql for String {\n  fn to_sql(&self, out: &mut Output) -> serialize::Result {\n    ToSql::::to_sql(self, out)\n  }\n}\nimpl ToSql for str {\n  fn to_sql(&self, out: &mut Output) -> serialize::Result {\n    ToSql::::to_sql(self, out)\n  }\n}\nimpl FromSql for String {\n  fn from_sql(bytes: Option<&[u8]>) -> deserialize::Result {\n    FromSql::::from_sql(bytes)\n  }\n}\nimpl Expression for Citext {\n  type SqlType = Text;\n}\nimpl ExpressionMethods for Citext {\n  // default implementation from current source\n  fn eq>(self, other: T) -> Eq {\n    Eq::new(self, other.as_expression())\n  }\n}\n```\nBut it gives me the following error:\nerror[E0119]: conflicting implementations of trait `diesel::ExpressionMethods` for type `db::types::Citext`:\n  --> server/src/db/types.rs:37:1\n   |\n37 | impl ExpressionMethods for Citext {}\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n   |\n   = note: conflicting implementation in crate `diesel`:\n           - impl<T> diesel::ExpressionMethods for T\n             where T: diesel::Expression, <T as diesel::Expression>::SqlType: diesel::sql_types::SingleValue;\nI'm not sure why it conflicts since Expression is implemented for Citext and SingleValue should be derived for T:SqlType.\nMy guess is that diesel internally implements ExpressionMethods somehow but then I'm not sure how I can re-implement it for custom type.. > There's no reason that you'd need to do anything related to ExpressionMethods or expressions, just adding a Citext SQL type is sufficient.\nThe reason why I get there is that in https://github.com/diesel-rs/diesel/pull/1215 you said that citext_column.eq method is problematic and I assumed that this method should be re-defined for Citext. Apparently, I was wrong and I need dig into problem (and diesel domain) deeper to understand why.\n\nI wouldn't couple to any concrete types for ToSql/FromSql impls, just allow anything that impls for Text\n\nI'm not sure I understand this part either. In all examples I've seen (1, 2) there is re-implementation using some base diesel type, e.g.:\nrust\nimpl FromSql<Citext, Pg> for String {\n  fn from_sql(bytes: Option<&[u8]>) -> deserialize::Result<Self> {\n    FromSql::<Text, Pg>::from_sql(bytes)\n  }\n}\nBut you're saying to allow anything that impls for Text and I'm not sure how to do this.\nSorry for lots of questions!. SQL that I'm attempting to express via DSL:\nsql\nINSERT INTO data (title, project_id)\nSELECT $1, $2\nWHERE EXISTS(\n  SELECT * FROM projects\n  WHERE id = $2 AND user_id = $3\n)\nRETURNING *\nNot sure yet if it's possible to express such SELECT.. Thanks! One more question: is it possible w/ DSL perform such SELECT?\nsql\nSELECT $1, $2\nWHERE EXISTS(\n  SELECT * FROM projects\n  WHERE id = $2 AND user_id = $3\n)\nMy naive implementation doesn't work:\nrust\n// `foo` & `bar` are dynamic values\ndiesel::select((&foo, &bar)).filter(diesel::select(exists(\n  projects::table\n    .filter(projects::id.eq(&project_id))\n    .filter(projects::user_id.eq(&user_id)),\n)));\n. Eh, nope, this doesn't work either. I'll move to forums w/ this one. Thanks for help!. ",
    "OKINGWNER": "sorry for my foolish, :)  I should double-click to run rather than through the console\uff0cso I can see the exact cause of the error. sorry\uff0cplease close this issue :). ",
    "akatechis": "Running into similar issues on windows. I managed to get diesel_cli to install, after using lib.exe to convert the sqlite3.dll into sqlite3.lib, put it in rust's lib path, and get started. However, I then face issue where running diesel setup breaks looking for api-ms-win-crt-heap-l1-1-0.dll. A bundled feature would be great, especially since I'm planning to package sqlite along with my app.. ",
    "stahlstift": "It would be nice if this feature will be added to diesel (especially diesel_cli) for windows users... \nThe workaround from @spease works for diesel as a dep but not for diesel_cli because it's not possible to install a lib (as far as I know) system wide. So it should be easy to implement and it will have a huge benefit for windows users!. Well I am not an expert with the rust ecosystem - but why not add a feature for it (e.G. sqlite-bundle)? \nThis should prevent us for version conflicts in Cargo and my app will use the version of libsqlite3-sys diesel wants to use.\nUpdate: ok #1302  has the same idea with sqlite-bundle. ",
    "trsh": "Anything new on this?. Same here on Ubuntu. I like to keep my structure like /models/table1/model.rs, schema.rs, /models/table2/model.rs,schema.rs. So yes I would also appreciate some scenario, where I can split Large single schema.rs in to multiple ones.. ",
    "hweom": "Ugh, found the reason. diesel::sql_types::Numeric cannot be converted into f64, only into BigDecimal.\nThe error is quite misleading tho.. ",
    "hodgesds": "I'm going to open an issue for now to track this as that seems to be the right place for continuing what needs to be discussed.. ",
    "philip-alldredge": "Okay. Thanks! It's only a minor inconvenience. Everything else works great.. ",
    "leoank": "Is this pull request going to be merged any time soon? Or there are any other workarounds for running commands such as CREATE INDEX CONCURRENTLY and ALTER TYPE. . ",
    "dreid": "only-tables And except-tables?. I might have confused the git rename detection?. If we remove the default behavior would it make more sense to have --only-tables and --except-tables take a comma separated list of arguments instead of relying on the positional arguments to the command? (This was confusing when I first encountered it, from glancing at the help I really expected --blacklist=foo,bar,baz instead of --blacklist foo bar baz). ",
    "limira": "I reported this to dotenv. It is not an issue in diesel itself, but I think it is useful to leave this open, because infer_schema does not actually work as expected. \nWe will update the version of dotenv in [dependencies] and close this when the issue in dotenv get fixed.. @weiznich, @sgrif, what do you think?\nI actually can put the DATABASE_URL into .env at the workspace root. But it is very nice if we can put it into .env at the crate/project root, because it is only use for that specific crate.\nEdit:\nI noticed that you are deprecated infer_schema, so, just ignore this.. Personally, I never install the diesel-cli because infer_schema is enough for me. \ndiesel.rs/guides/configuring-diesel-cli is not available right now so the only thing I can say is that I wish/hope it is as easy as using infer_schema. . ",
    "daboross": "I believe this is an issue in diesel - it uses dotenv, but the error is in how diesel is using dotenv.\nThe method it's using, dotenv(), uses the current working directory to find .env files. However, it's being used here inside a procedural macro (in infer_schema_macros), and procedural macros are always run in the workspace root, rather than the crate root.\nIf this is deemed a real issue, the only way to fix this will be to have diesel change the working directory or use a different function from dotenv to load the file.. ",
    "huangjj27": "Same error in same environment.. ",
    "vi-n": "Same error on Linux. ",
    "jtescher": "For anyone looking for a workaround, you should be able to compile with 2018-05-14 for now. \n$ rustup toolchain install nightly-2018-05-14. ",
    "oli-obk": "Citing @sgrif in https://github.com/rust-lang-nursery/rust-clippy/pull/2712#issuecomment-391057884\n\ncargo clippy is a separate command that requires recompiling all the crates again (adding minutes to the feedback cycle), and that I have to remember to run in the first place. Running it as a separate step makes sense for CI, but hurts the work flow for local development.\n\nThat is a serious downside. But I think I have a solution. Do a cargo install clippy and set RUSTC_WRAPPER to clippy-driver (e.g. via an .env file) or change the appropriate setting in .cargo/config to clippy-driver. This should replace all compilation with clippy. It might require some adjustments on our side, but technically cargo check should then \"just work\"^TM\nedit: We will find a solution to the rebuilding problem prior to removing the plugin interface (unless rustc removes it first that is of course).. ",
    "iamcharleschege": "I can't build any project that depends on diesel due to this bug. Any help?\n. ",
    "xianghx": "I like it. We can write a very useful tools. Something like this:\nxdiesel print-struct\n  ```\n    #[derive(Identifiable, Queryable)]\n    pub struct User {\n        pub id: i32,\n        pub name: String,\n        pub favorite_color: Option,\n        pub created_at: NaiveDateTime,\n    }\n#[derive(Insertable)]\n#[table_name=\"users\"]\npub struct NewUser<'a> {\n    pub name: &'a str,\n    pub favorite_color: Option<&'a str>,\n    pub created_at: NaiveDateTime,\n}\n\n#[derive(AsChangeset)]\n#[table_name=\"users\"]\npub struct UpdateUser<'a> {\n    pub name: &'a str,\n    pub favorite_color: Option<&'a str>,\n    pub created_at: NaiveDateTime,\n}\n\nNewUser {\n    name,\n    favorite_color,\n    created_at,\n}\n\nUpdateUser {\n    name,\n    favorite_color,\n    created_at,\n}\n\nor  xdiesel print-html\nid\ntitle\nbody\npublished\n```\n. I'm ok. Just give me a new crate.. https://github.com/purpliminal/rust-dotenv\npage not found.\nwhat happen?. ",
    "Deedasmi": "diesel is broken on nightlies 05-15->(likely) 05-23 due to a regression in rustc. rustup run nightly-2018-05-14 cargo install diesel_cli. Or compile with stable. See #1700. The errors changes in 1.3, but the cause appears to be the same.. Why would it work on the previous version then? I downgraded to 1.2 and it worked fine.\nI've tracked the error down to https://github.com/diesel-rs/diesel/blob/master/diesel_cli/src/print_schema.rs#L57, but haven't figured out why its failing yet. . ```\nextern crate tempfile;\nuse tempfile::NamedTempFile;\nuse std::fs::File;\nuse std::io;\nfn main() -> Result<(), io::Error> {\n    let tempfile = NamedTempFile::new()?;\n    let mut out = File::create(tempfile)?;\n    Ok(())\n}\n```\nFails on my system. Seems like this is an issue with tempfile.. ~Opened https://github.com/Stebalien/tempfile/issues/56.~\n~Made a better test where I can write a PathBuf file, but not a NamedTempFile. This one looks... fun lol.~. I actually think diesel is using tempfile incorrectly. https://docs.rs/tempfile/3.0.2/src/tempfile/file/mod.rs.html#371-374\nNamedTempFile already creates a File. By passing the path to File::create() we're trying to create a new file on top of an open file handle.. Confirmed it works! Thanks!. Good call, edited. Trying to set up tests/patch test now.\nEDIT: Reopen doesn't do what I thought it did. Can confirm all tests pass on Windows!. Duplicate of #1700 , #1701, #1705, #1711, #1722. It's a regression in rustc that will likely be fixed on the next nightly from https://github.com/rust-lang/rust/pull/50876\nEDIT: Still broken on 05-23. Due to proc-macro2 this time.. @WillSquire This error is due to a change in the rust compiler. You can't fix it directly, as its a warning that diesel would break in the future. I think it's fixed on the repo, just not released yet.. Just \u2018#[allow\u2019 or \u2018#![allow\u2019? They do different things (this definition vs module level)\nAlso, I think this was also fixed on 1.4? Could be wrong. . @weiznich Just wanted to say thanks! The uuid fix works great!. ",
    "KodrAus": "@Deedasmi that's right, NamedTempFile::new will create the temporary file it wraps before it returns.. ",
    "JohnDoneth": "@sgrif @weiznich It would be much appreciated if we could get this out soon. \ud83d\udc4d . ",
    "huhlig": "Something like the following would likely be beneficial\n```toml\nFor documentation on how to configure this file,\nsee diesel.rs/guides/configuring-diesel-cli\n[print_schema]\ninclude_schemas = [\"schema1\", \"schema2\", \"schema3\"]\nexclude_schemas = [\"pg_catalog\", \"information_schema\"] # Implicit defaults include xor exclude\npatch_file = \"\"\n[print_schema.schema1]\nfile = \"src/models/schema1.rs\"\nfilter = { except_tables = [\"spatial_ref_sys\"] }\n[print_schema.schema2]\nfile = \"src/models/schema2.rs\"\nfilter = { except_tables = [\"ignored_system_table\"] }\n```. ",
    "theom": "Since I was using rocket as well, the following solved the issue for me:\n$ rustup install nightly-2018-05-05.\n",
    "bboyadao": "@theom \nhave you get it now ?\nError: Rocket codegen requires a more recent version of rustc.\nUse rustup update or your preferred method to update Rust.\nInstalled version is: 1.27.0-nightly (2018-05-04). Minimum required: 1.28.0-nightly (2018-05-30).. ",
    "BartMassey": "Looks like a change to rustc was pushed about 4 hours ago that is reported to resolve this issue. This would be a good time to close it, if it hadn't been closed 14 days ago. :-)  rust-lang/rust/pull/#51042. Indeed. So maybe we should wait to have closed the issue a little longer. :-). ",
    "ebkalderon": "EDIT: Sorry, I had to edit the example to make sure it was correct and showcased the problem more visibly. I decided to use a more complex composite type to demonstrate the problem.. These are some excellent responses! Thank you both so much. I will look further into how the libpg internal representation for composite types' works. I still have two more questions, though.  I might just join your Gitter channel for further assistance, to avoid clogging the issue tracker.. Referencing #1735 and #1738, should future readers want to see the solution.. Looks like the failing rustfmt checks in CI have been fixed. Is this ready to merge?. @sgrif Sure. In the same file still, I presume? Also, should I split the current database schema into two separate schemas as well (one with custom_enum and the other with custom_struct)?\nEDIT: Done.. You're welcome! Thanks for all the ongoing work on Diesel. I'll continue opening more PRs like this one, should I find more. \ud83d\ude04 . ",
    "xpe": "This looks potentially useful. I've got some many-to-many tables that use composite primary keys. I would like to be able to write .find((foo_id, bar_id)) for example. I'm not sure if this change is meant to enable that syntax -- or if it should work already.\n@sgrif Could you write a quick summary of what syntax this enables?. Ah, I think this is the write up: http://docs.diesel.rs/diesel/serialize/trait.WriteTuple.html. Here is a good way to mute the warning on a per-file basis:\n```rs\n![allow(proc_macro_derive_resolution_fallback)]\n```. ",
    "apiraino": "To add to the previous comment, I've kind of worked around this compilation error setting a previous nightly version:\nrustup override set nightly-2018-05-15. @WillSquire you may want to mute that warning. No big deal, AFAICS.\nShows up also with latest Rust nightly (1.30.0 as I write). ",
    "pjenvey": "Minimal crate: https://github.com/pjenvey/diesel1739\nNot sure the external-macro-backtrace is too helpful here:\n``\nwarning: unused import:EmbedMigrations--> <embed_migrations macros>:3:14\n   |\n1  | / (  ) => {\n2  | | # [ allow ( dead_code ) ] mod embedded_migrations {\n3  | | # [ derive ( EmbedMigrations ) ] struct _Dummy ; } } ; (\n   | |              ^^^^^^^^^^^^^^^\n4  | | $ migrations_path : expr ) => {\n...  |\n7  | | embed_migrations_options ( migrations_path = $ migrations_path ) ] struct\n8  | | _Dummy ; } }\n   | |____________- in this expansion ofembed_migrations!`\n   | \n  ::: src/main.rs:10:1\n   |\n10 |   embed_migrations!();\n   |   -------------------- in this macro invocation\n   |\n   = note: #[warn(unused_imports)] on by default\nFinished dev [unoptimized + debuginfo] target(s) in 47.02s\n\n```. Can we leave this open until this fix is brought into the 1.3 branch?. ",
    "rockstar": "Can we cut a release of diesel_migrations so that this change is in a released version?. ",
    "joshgev": "@weiznich Fantastic!  Thanks a ton.  I will check it out right now.. Yeah, that worked; I will close this issue.  Thanks again, @weiznich. . ",
    "rizakrko": "There is no particular reason, just a routine update. Failure is related to changes in nightly compiler, so #51042 has to be merged, and then clippy and related nightly needs to be updated.. ",
    "xfix": "If somebody needs a reason, this reduces amount of compilation if using diesel with another crate which has newest version of those dependencies (a specific example - serde).. ",
    "loothood": "Thank you!. ",
    "fundon": "thank you. fixed. ",
    "gwihlidal": "I'm having this same problem now too. ",
    "mathroc": "@weiznich it might be interesting to keep one of these issue open until this is resolved. it would avoid people opening the same issue again and again . and give them an issue to subscribe to to be notified when this is resolved\nI guess this is not something that can be solved on diesel side but it's still a in issue to its usage worth tracking imho (eg: I'm waiting for this to upgrade some dependencies that require a newer rustc because there is no rustc version that works with the newer version of those libs and diesel). ",
    "ondj": "Hi, but docs.rs doesnt work too, because there is error durring building latest version: https://docs.rs/crate/diesel/1.3.0/builds. ",
    "erlend-sh": "If you've got some Issues you'd like to move over, we have a tool for that:\nhttps://meta.discourse.org/t/introducing-github-issues-to-discourse/46671\np.s. looks like someone forgot to close this ;). ",
    "galuhsahid": "Does the specific version change often? \nIf so, I think we can write something like:\n\nThe line rust: x.x.x above rustup component add rustfmt-preview in travis.yml is the specific version we run rustfmt against\n\nto avoid updating this file often.\nOtherwise we can just mention the specific version. What do you think?. I'm not sure why it's failing, is there anything I should change?. ",
    "rakenodiax": "I'm using edition = \"2018\" which will be hitting Stable Rust in 2 days (6 December, 2018). The current version of diesel_cli prints a schema.rs file without the necessary macros used, meaning I have to add it manually on each migration.\nsh\n$ diesel --version\ndiesel 1.3.1\nI think this merits fixing, as builds will start failing once people start migrating to Edition 2018. Thank you.. @kamirr It's my understanding that the contributors' stance on issues like this is that, if there is an \"easy enough\" resolution, it should not be prioritized. This is similar with deprecation warnings with the Queryable derive macro. In my opinion, this does make the project feel less idiomatic and \"hacky\" compared to e.g. serde where you can just use serde::{Deserialize, Serialize}; in the modern way. This crate will come with the caveats of \"don't forget to set this crate attribute and import all of its macros, unlike all of your other dependencies\", which may not be a hard thing to accommodate as a user, but will negatively impact the image of the crate's polish and maintenance.\nI personally don't care to discuss these issues if the maintainers don't care about it, but there are only so many times a project can brush off these requests before it builds up to a serious issue.. ",
    "kamirr": "\nIf someone is willing to work on this feel free to submit a PR, but I've currently other priorities than \"fixing\" something that's already working.\n\nUsing macros from parent modules now results in a warning and will cause a hard error in the future, so you can't really call using #[macro_use] extern crate diesel a solution.\nAlso, I attempted to patch the schema file as you suggested, but I failed to get it working. I'd be grateful if you told me what exactly should I put in the schema.rs to get it to compile.. @technetos Seems like a good idea. There's this tiny problem that the master branch doesn't build ATM, but I guess I can wait.. ",
    "technetos": "@rakenodiax @kamirr AFAIK all of the diesel warnings are fixed in master and will at some point be found in a future release.  If you want a solution now, please use the diesel master branch.  . This would be really cool integrated into diesel.  In the meantime I happen to do exactly this in a macro I wrote and your welcome to come check it out.   link-to-macro. ",
    "raintears": "It's not missing. I installed it. The error happens when compiling diesel_cli\nprocess didn't exit successfully:rustc --crate-name diesel src/main.rs --crate-type bin --emit=dep-info,link -C opt-level=3 --cfg feature=\"diesel\" --cfg feature=\"infer_schema_internals\" --cfg feature=\"mysql\" --cfg feature=\"url\" -C metadata=bd285b008eff2313 -C extra-filename=-bd285b008eff2313 --out-dir C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps -L dependency=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps --extern chrono=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libchrono-f54516ef2a593f2a.rlib --extern clap=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libclap-ffeb0d5cc824d05e.rlib --extern diesel=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libdiesel-8e2a4e63564e5e36.rlib --extern dotenv=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libdotenv-465a041bb598e52f.rlib --extern infer_schema_internals=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libinfer_schema_internals-66920efbc5fb48bd.rlib --extern migrations_internals=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libmigrations_internals-b921a11ae77a4dc7.rlib --extern serde=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libserde-875d5ac5f162a2ac.rlib --extern tempfile=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libtempfile-6ad149e0e7ddb7cb.rlib --extern toml=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\libtoml-48cd27bfc099e7e9.rlib --extern url=C:\\Users\\user\\AppData\\Local\\Temp\\cargo-installFKeB7q\\release\\deps\\liburl-2f98437d64aca106.rlib --cap-lints allow -L native=C:\\Program Files (x86)\\MySQL\\MySQL Connector C 6.1\\lib\\vs14(exit code: 101). 1st case: I installed MySQL Connector/C 8.0 via Windows Installer.\n2nd case: It found my libmysqlclient -> linking with C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.14.26428\\bin\\HostX64\\x64\\link.exe failed: exit code: 1181\n3rd case: Ok I gave up. Nothing helps in mysqlclient-sys. I use 32 bit and 64 bit both gives me the same error. \nThis entire process is not even found in the docs.\nI went with postgres instead and it gives me yet another fatal error LNK1181: cannot open input file 'libpq.lib'\nThis was working fine with mac but now on windows is like a whack. Nothing works. The getting started guide only works for mac, it breaks in windows.. Thanks for the clarification! So how then if we're using mysql, do an upsert?\nWe should be able to do something like:\nINSERT INTO `item`\n(`item_id`, items_in_stock)\nVALUES( 'A', 27)\nON DUPLICATE KEY UPDATE\n`items_in_stock` = `items_in_stock` + 27. ",
    "9034725985": "sudo dnf install mariadb-devel libsq3-devel fixed it . Anyone know if this is intentional? \nWhat if someone just wants to use diesel with postgresql? Does everyone need all the dependencies? \n```zsh \n\u279c  ~ dnf info mariadb-devel libsq3-devel\nLast metadata expiration check: 29 days, 11:57:20 ago on Tue 29 May 2018 07:44:41 PM EDT.\nAvailable Packages\nName         : libsq3-devel\nVersion      : 20071018\nRelease      : 23.fc28\nArch         : i686\nSize         : 181 k\nSource       : libsqlite3x-20071018-23.fc28.src.rpm\nRepo         : fedora\nSummary      : Development files for libsqlite3x\nURL          : http://www.wanderinghorse.net/computing/sqlite/\nLicense      : zlib\nDescription  : The libsq3-devel package contains libraries and header files for\n             : developing applications that use libsq3.\nName         : libsq3-devel\nVersion      : 20071018\nRelease      : 23.fc28\nArch         : x86_64\nSize         : 181 k\nSource       : libsqlite3x-20071018-23.fc28.src.rpm\nRepo         : fedora\nSummary      : Development files for libsqlite3x\nURL          : http://www.wanderinghorse.net/computing/sqlite/\nLicense      : zlib\nDescription  : The libsq3-devel package contains libraries and header files for\n             : developing applications that use libsq3.\nName         : mariadb-devel\nEpoch        : 3\nVersion      : 10.2.14\nRelease      : 1.fc28\nArch         : i686\nSize         : 976 k\nSource       : mariadb-10.2.14-1.fc28.src.rpm\nRepo         : fedora\nSummary      : Files for development of MariaDB/MySQL applications\nURL          : http://mariadb.org\nLicense      : GPLv2 with exceptions and LGPLv2 and BSD\nDescription  : MariaDB is a multi-user, multi-threaded SQL database server.\n             : MariaDB is a community developed branch of MySQL.\n             : \n             : \n             : \n             : \n             : This package contains everything needed for developing MariaDB/MySQL server\n             : applications. For developing client applications, use mariadb-connector-c\n             : package.\nName         : mariadb-devel\nEpoch        : 3\nVersion      : 10.2.14\nRelease      : 1.fc28\nArch         : x86_64\nSize         : 976 k\nSource       : mariadb-10.2.14-1.fc28.src.rpm\nRepo         : fedora\nSummary      : Files for development of MariaDB/MySQL applications\nURL          : http://mariadb.org\nLicense      : GPLv2 with exceptions and LGPLv2 and BSD\nDescription  : MariaDB is a multi-user, multi-threaded SQL database server.\n             : MariaDB is a community developed branch of MySQL.\n             : \n             : \n             : \n             : \n             : This package contains everything needed for developing MariaDB/MySQL server\n             : applications. For developing client applications, use mariadb-connector-c\n             : package.\n\u279c  ~ sudo dnf install mariadb-devel libsq3-devel\n[sudo] password for kus: \nLast metadata expiration check: 1:10:36 ago on Thu 28 Jun 2018 06:31:44 AM EDT.\nDependencies resolved.\n===============================================================================================================================================================================================================================================================================\n Package                                                                      Arch                                                      Version                                                               Repository                                                  Size\n===============================================================================================================================================================================================================================================================================\nInstalling:\n libsq3-devel                                                                 x86_64                                                    20071018-23.fc28                                                      fedora                                                     181 k\n mariadb-devel                                                                x86_64                                                    3:10.2.15-2.fc28                                                      updates                                                    977 k\nInstalling dependencies:\n keyutils-libs-devel                                                          x86_64                                                    1.5.10-6.fc28                                                         fedora                                                      47 k\n krb5-devel                                                                   x86_64                                                    1.16.1-7.fc28                                                         updates                                                    544 k\n libcom_err-devel                                                             x86_64                                                    1.43.8-2.fc28                                                         fedora                                                      36 k\n libkadm5                                                                     x86_64                                                    1.16.1-7.fc28                                                         updates                                                    181 k\n libselinux-devel                                                             x86_64                                                    2.8-1.fc28                                                            updates                                                    197 k\n libsepol-devel                                                               x86_64                                                    2.8-1.fc28                                                            updates                                                     84 k\n libsq3                                                                       x86_64                                                    20071018-23.fc28                                                      fedora                                                      44 k\n libverto-devel                                                               x86_64                                                    0.3.0-5.fc28                                                          fedora                                                      17 k\n mariadb-connector-c-devel                                                    x86_64                                                    3.0.5-1.fc28                                                          updates                                                     61 k\n openssl-devel                                                                x86_64                                                    1:1.1.0h-3.fc28                                                       fedora                                                     1.9 M\n pcre2-devel                                                                  x86_64                                                    10.31-4.fc28                                                          fedora                                                     588 k\n pcre2-utf32                                                                  x86_64                                                    10.31-4.fc28                                                          fedora                                                     212 k\n sqlite-devel                                                                 x86_64                                                    3.22.0-4.fc28                                                         fedora                                                     153 k\n zlib-devel                                                                   x86_64                                                    1.2.11-8.fc28                                                         updates                                                     55 k\nTransaction Summary\nInstall  16 Packages\nTotal download size: 5.2 M\nInstalled size: 14 M\nIs this ok [y/N]: y\nDownloading Packages:\n(1/16): libsq3-20071018-23.fc28.x86_64.rpm                                                                                                                                                                                                     216 kB/s |  44 kB     00:00  \n(2/16): libsq3-devel-20071018-23.fc28.x86_64.rpm                                                                                                                                                                                               719 kB/s | 181 kB     00:00  \n(3/16): sqlite-devel-3.22.0-4.fc28.x86_64.rpm                                                                                                                                                                                                  1.0 MB/s | 153 kB     00:00  \n(4/16): openssl-devel-1.1.0h-3.fc28.x86_64.rpm                                                                                                                                                                                                 3.4 MB/s | 1.9 MB     00:00  \n(5/16): mariadb-connector-c-devel-3.0.5-1.fc28.x86_64.rpm                                                                                                                                                                                       81 kB/s |  61 kB     00:00  \n(6/16): zlib-devel-1.2.11-8.fc28.x86_64.rpm                                                                                                                                                                                                    513 kB/s |  55 kB     00:00  \n(7/16): mariadb-devel-10.2.15-2.fc28.x86_64.rpm                                                                                                                                                                                                852 kB/s | 977 kB     00:01  \n(8/16): libselinux-devel-2.8-1.fc28.x86_64.rpm                                                                                                                                                                                                 1.5 MB/s | 197 kB     00:00  \n(9/16): libkadm5-1.16.1-7.fc28.x86_64.rpm                                                                                                                                                                                                      699 kB/s | 181 kB     00:00  \n(10/16): libsepol-devel-2.8-1.fc28.x86_64.rpm                                                                                                                                                                                                  766 kB/s |  84 kB     00:00  \n(11/16): keyutils-libs-devel-1.5.10-6.fc28.x86_64.rpm                                                                                                                                                                                          1.0 MB/s |  47 kB     00:00  \n(12/16): libcom_err-devel-1.43.8-2.fc28.x86_64.rpm                                                                                                                                                                                             816 kB/s |  36 kB     00:00  \n(13/16): libverto-devel-0.3.0-5.fc28.x86_64.rpm                                                                                                                                                                                                429 kB/s |  17 kB     00:00  \n(14/16): pcre2-utf32-10.31-4.fc28.x86_64.rpm                                                                                                                                                                                                   2.3 MB/s | 212 kB     00:00  \n(15/16): pcre2-devel-10.31-4.fc28.x86_64.rpm                                                                                                                                                                                                   2.3 MB/s | 588 kB     00:00  \n(16/16): krb5-devel-1.16.1-7.fc28.x86_64.rpm                                                                                                                                                                                                   571 kB/s | 544 kB     00:00    \n\nTotal                                                                                                                                                                                                                                          2.1 MB/s | 5.2 MB     00:02   \nRunning transaction check\nTransaction check succeeded.\nRunning transaction test\nTransaction test succeeded.\nRunning transaction\n  Preparing        :                                                                                                                                                                                                                                                       1/1 \n  Installing       : pcre2-utf32-10.31-4.fc28.x86_64                                                                                                                                                                                                                      1/16 \n  Installing       : pcre2-devel-10.31-4.fc28.x86_64                                                                                                                                                                                                                      2/16 \n  Installing       : libverto-devel-0.3.0-5.fc28.x86_64                                                                                                                                                                                                                   3/16 \n  Installing       : libcom_err-devel-1.43.8-2.fc28.x86_64                                                                                                                                                                                                                4/16 \n  Installing       : keyutils-libs-devel-1.5.10-6.fc28.x86_64                                                                                                                                                                                                             5/16 \n  Installing       : libsepol-devel-2.8-1.fc28.x86_64                                                                                                                                                                                                                     6/16 \n  Installing       : libselinux-devel-2.8-1.fc28.x86_64                                                                                                                                                                                                                   7/16 \n  Installing       : libkadm5-1.16.1-7.fc28.x86_64                                                                                                                                                                                                                        8/16 \n  Installing       : krb5-devel-1.16.1-7.fc28.x86_64                                                                                                                                                                                                                      9/16 \n  Installing       : zlib-devel-1.2.11-8.fc28.x86_64                                                                                                                                                                                                                     10/16 \n  Installing       : openssl-devel-1:1.1.0h-3.fc28.x86_64                                                                                                                                                                                                                11/16 \n  Installing       : mariadb-connector-c-devel-3.0.5-1.fc28.x86_64                                                                                                                                                                                                       12/16 \n  Installing       : sqlite-devel-3.22.0-4.fc28.x86_64                                                                                                                                                                                                                   13/16 \n  Installing       : libsq3-20071018-23.fc28.x86_64                                                                                                                                                                                                                      14/16 \n  Running scriptlet: libsq3-20071018-23.fc28.x86_64                                                                                                                                                                                                                      14/16 \n  Installing       : libsq3-devel-20071018-23.fc28.x86_64                                                                                                                                                                                                                15/16 \n  Installing       : mariadb-devel-3:10.2.15-2.fc28.x86_64                                                                                                                                                                                                               16/16 \n  Running scriptlet: mariadb-devel-3:10.2.15-2.fc28.x86_64                                                                                                                                                                                                               16/16 \n  Verifying        : mariadb-devel-3:10.2.15-2.fc28.x86_64                                                                                                                                                                                                                1/16 \n  Verifying        : libsq3-devel-20071018-23.fc28.x86_64                                                                                                                                                                                                                 2/16 \n  Verifying        : libsq3-20071018-23.fc28.x86_64                                                                                                                                                                                                                       3/16 \n  Verifying        : sqlite-devel-3.22.0-4.fc28.x86_64                                                                                                                                                                                                                    4/16 \n  Verifying        : mariadb-connector-c-devel-3.0.5-1.fc28.x86_64                                                                                                                                                                                                        5/16 \n  Verifying        : openssl-devel-1:1.1.0h-3.fc28.x86_64                                                                                                                                                                                                                 6/16 \n  Verifying        : krb5-devel-1.16.1-7.fc28.x86_64                                                                                                                                                                                                                      7/16 \n  Verifying        : zlib-devel-1.2.11-8.fc28.x86_64                                                                                                                                                                                                                      8/16 \n  Verifying        : libkadm5-1.16.1-7.fc28.x86_64                                                                                                                                                                                                                        9/16 \n  Verifying        : libselinux-devel-2.8-1.fc28.x86_64                                                                                                                                                                                                                  10/16 \n  Verifying        : libsepol-devel-2.8-1.fc28.x86_64                                                                                                                                                                                                                    11/16 \n  Verifying        : keyutils-libs-devel-1.5.10-6.fc28.x86_64                                                                                                                                                                                                            12/16 \n  Verifying        : libcom_err-devel-1.43.8-2.fc28.x86_64                                                                                                                                                                                                               13/16 \n  Verifying        : libverto-devel-0.3.0-5.fc28.x86_64                                                                                                                                                                                                                  14/16 \n  Verifying        : pcre2-devel-10.31-4.fc28.x86_64                                                                                                                                                                                                                     15/16 \n  Verifying        : pcre2-utf32-10.31-4.fc28.x86_64                                                                                                                                                                                                                     16/16 \nInstalled:\n  libsq3-devel.x86_64 20071018-23.fc28 mariadb-devel.x86_64 3:10.2.15-2.fc28 keyutils-libs-devel.x86_64 1.5.10-6.fc28 krb5-devel.x86_64 1.16.1-7.fc28               libcom_err-devel.x86_64 1.43.8-2.fc28 libkadm5.x86_64 1.16.1-7.fc28   libselinux-devel.x86_64 2.8-1.fc28\n  libsepol-devel.x86_64 2.8-1.fc28     libsq3.x86_64 20071018-23.fc28        libverto-devel.x86_64 0.3.0-5.fc28       mariadb-connector-c-devel.x86_64 3.0.5-1.fc28 openssl-devel.x86_64 1:1.1.0h-3.fc28  pcre2-devel.x86_64 10.31-4.fc28 pcre2-utf32.x86_64 10.31-4.fc28 \n  sqlite-devel.x86_64 3.22.0-4.fc28    zlib-devel.x86_64 1.2.11-8.fc28      \nComplete!\n\u279c  ~ cargo install diesel_cli --verbose     \n    Updating registry https://github.com/rust-lang/crates.io-index\n  Installing diesel_cli v1.3.1                                                \n   Compiling cc v1.0.17\n   Compiling unicode-xid v0.1.0\n   Compiling pkg-config v0.3.11\n   Compiling matches v0.1.6\n   Compiling void v1.0.2\n   Compiling unicode-normalization v0.1.7\n   Compiling libc v0.2.42\n   Compiling unicode-xid v0.0.4\n     Running rustc --crate-name cc /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/cc-1.0.17/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=2494f437ec9205c7 -C extra-filename=-2494f437ec9205c7 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name unicode_xid /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode-xid-0.1.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=91dcf6c630d8b674 -C extra-filename=-91dcf6c630d8b674 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name pkg_config /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/pkg-config-0.3.11/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=d118bd48cb6004a9 -C extra-filename=-d118bd48cb6004a9 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name void /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/void-1.0.2/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=caecde666eaf88ec -C extra-filename=-caecde666eaf88ec --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name matches /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/matches-0.1.6/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=3e21c544cb7c996b -C extra-filename=-3e21c544cb7c996b --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name unicode_normalization /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode-normalization-0.1.7/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=5aa755380e525e3a -C extra-filename=-5aa755380e525e3a --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name libc /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/libc-0.2.42/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"use_std\"' -C metadata=cd9c0a92dfbde993 -C extra-filename=-cd9c0a92dfbde993 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name unicode_xid /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode-xid-0.0.4/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=78d05d44e850227b -C extra-filename=-78d05d44e850227b --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling pq-sys v0.4.5\n     Running rustc --crate-name build_script_build /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/pq-sys-0.4.5/build.rs --crate-type bin --emit=dep-info,link -C opt-level=3 -C metadata=340faea08fb0d477 -C extra-filename=-340faea08fb0d477 --out-dir /tmp/cargo-installdxfBoN/release/build/pq-sys-340faea08fb0d477 -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling num-traits v0.2.5\n     Running rustc --crate-name build_script_build /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/num-traits-0.2.5/build.rs --crate-type bin --emit=dep-info,link -C opt-level=3 -C metadata=f0de473f7a78c0f9 -C extra-filename=-f0de473f7a78c0f9 --out-dir /tmp/cargo-installdxfBoN/release/build/num-traits-f0de473f7a78c0f9 -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling regex v0.2.11\n     Running rustc --crate-name build_script_build /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-0.2.11/build.rs --crate-type bin --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=d0e097cc18effb5c -C extra-filename=-d0e097cc18effb5c --out-dir /tmp/cargo-installdxfBoN/release/build/regex-d0e097cc18effb5c -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling num-integer v0.1.39\n     Running rustc --crate-name build_script_build /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/num-integer-0.1.39/build.rs --crate-type bin --emit=dep-info,link -C opt-level=3 -C metadata=5492b76593543ee2 -C extra-filename=-5492b76593543ee2 --out-dir /tmp/cargo-installdxfBoN/release/build/num-integer-5492b76593543ee2 -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling ucd-util v0.1.1\n     Running rustc --crate-name ucd_util /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/ucd-util-0.1.1/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=262bf6f116a73cad -C extra-filename=-262bf6f116a73cad --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling rustc-demangle v0.1.8\n     Running rustc --crate-name rustc_demangle /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/rustc-demangle-0.1.8/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=68ef64f4f8baf8f5 -C extra-filename=-68ef64f4f8baf8f5 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling quote v0.3.15\n   Compiling lazy_static v1.0.1\n     Running rustc --crate-name quote /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/quote-0.3.15/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=7531a65df1fc6d63 -C extra-filename=-7531a65df1fc6d63 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name lazy_static /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/lazy_static-1.0.1/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=13d3d5636b3ae515 -C extra-filename=-13d3d5636b3ae515 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling cfg-if v0.1.4\n   Compiling serde v1.0.67\n     Running rustc --crate-name build_script_build /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/serde-1.0.67/build.rs --crate-type bin --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"derive\"' --cfg 'feature=\"serde_derive\"' --cfg 'feature=\"std\"' -C metadata=20418b2cd81aaac2 -C extra-filename=-20418b2cd81aaac2 --out-dir /tmp/cargo-installdxfBoN/release/build/serde-20418b2cd81aaac2 -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name cfg_if /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/cfg-if-0.1.4/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=f372f1afa1bbf981 -C extra-filename=-f372f1afa1bbf981 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling percent-encoding v1.0.1\n     Running rustc --crate-name percent_encoding /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/percent-encoding-1.0.1/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=4091d5da07ac45fd -C extra-filename=-4091d5da07ac45fd --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling bitflags v1.0.3\n     Running rustc --crate-name bitflags /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/bitflags-1.0.3/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=71282bd87c17fec5 -C extra-filename=-71282bd87c17fec5 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling byteorder v1.2.3\n     Running rustc --crate-name byteorder /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/byteorder-1.2.3/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=7ddb8085dbc25068 -C extra-filename=-7ddb8085dbc25068 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling utf8-ranges v1.0.0\n     Running rustc --crate-name utf8_ranges /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/utf8-ranges-1.0.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=7153fdfdde9acf5a -C extra-filename=-7153fdfdde9acf5a --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling unicode-width v0.1.5\n   Compiling strsim v0.7.0\n     Running rustc --crate-name unicode_width /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode-width-0.1.5/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=55470b249822e939 -C extra-filename=-55470b249822e939 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n     Running rustc --crate-name strsim /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/strsim-0.7.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=6251f76ab3616c54 -C extra-filename=-6251f76ab3616c54 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling remove_dir_all v0.5.1\n     Running rustc --crate-name remove_dir_all /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/remove_dir_all-0.5.1/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=54ca297a931213d9 -C extra-filename=-54ca297a931213d9 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling ansi_term v0.11.0\n     Running rustc --crate-name ansi_term /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/ansi_term-0.11.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=db41b2a9728108f8 -C extra-filename=-db41b2a9728108f8 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling vec_map v0.8.1\n     Running rustc --crate-name vec_map /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/vec_map-0.8.1/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=54c8ba97b679707a -C extra-filename=-54c8ba97b679707a --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow\n   Compiling unicode-bidi v0.3.4\n     Running rustc --crate-name unicode_bidi /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode-bidi-0.3.4/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=17dbd4acb7086505 -C extra-filename=-17dbd4acb7086505 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern matches=/tmp/cargo-installdxfBoN/release/deps/libmatches-3e21c544cb7c996b.rlib --cap-lints allow\n   Compiling unreachable v1.0.0\n     Running rustc --crate-name unreachable /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/unreachable-1.0.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=e24d499ca6920b30 -C extra-filename=-e24d499ca6920b30 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern void=/tmp/cargo-installdxfBoN/release/deps/libvoid-caecde666eaf88ec.rlib --cap-lints allow\n   Compiling proc-macro2 v0.4.6\n     Running rustc --crate-name proc_macro2 /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/proc-macro2-0.4.6/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"proc-macro\"' -C metadata=9a8b1995c153f609 -C extra-filename=-9a8b1995c153f609 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern unicode_xid=/tmp/cargo-installdxfBoN/release/deps/libunicode_xid-91dcf6c630d8b674.rlib --cap-lints allow\n   Compiling proc-macro2 v0.3.8\n     Running rustc --crate-name proc_macro2 /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/proc-macro2-0.3.8/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"proc-macro\"' -C metadata=b6e7f381465868e6 -C extra-filename=-b6e7f381465868e6 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern unicode_xid=/tmp/cargo-installdxfBoN/release/deps/libunicode_xid-91dcf6c630d8b674.rlib --cap-lints allow\n   Compiling synom v0.11.3\n     Running rustc --crate-name synom /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/synom-0.11.3/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=697dcad0a97a181e -C extra-filename=-697dcad0a97a181e --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern unicode_xid=/tmp/cargo-installdxfBoN/release/deps/libunicode_xid-78d05d44e850227b.rlib --cap-lints allow\n   Compiling memchr v2.0.1\n     Running rustc --crate-name memchr /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/memchr-2.0.1/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"libc\"' --cfg 'feature=\"use_std\"' -C metadata=12a113d5634908fb -C extra-filename=-12a113d5634908fb --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern libc=/tmp/cargo-installdxfBoN/release/deps/liblibc-cd9c0a92dfbde993.rlib --cap-lints allow\n   Compiling time v0.1.40\n     Running rustc --crate-name time /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/time-0.1.40/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=5b4cb43446967bd8 -C extra-filename=-5b4cb43446967bd8 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern libc=/tmp/cargo-installdxfBoN/release/deps/liblibc-cd9c0a92dfbde993.rlib --cap-lints allow\n   Compiling atty v0.2.10\n     Running rustc --crate-name atty /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/atty-0.2.10/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=6de45a38f81927fa -C extra-filename=-6de45a38f81927fa --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern libc=/tmp/cargo-installdxfBoN/release/deps/liblibc-cd9c0a92dfbde993.rlib --cap-lints allow\n   Compiling rand v0.4.2\n     Running rustc --crate-name rand /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/rand-0.4.2/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"libc\"' --cfg 'feature=\"std\"' -C metadata=81a089c0245327b8 -C extra-filename=-81a089c0245327b8 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern libc=/tmp/cargo-installdxfBoN/release/deps/liblibc-cd9c0a92dfbde993.rlib --cap-lints allow\n     Running /tmp/cargo-installdxfBoN/release/build/num-traits-f0de473f7a78c0f9/build-script-build\n     Running /tmp/cargo-installdxfBoN/release/build/num-integer-5492b76593543ee2/build-script-build\n     Running /tmp/cargo-installdxfBoN/release/build/regex-d0e097cc18effb5c/build-script-build\n     Running /tmp/cargo-installdxfBoN/release/build/pq-sys-340faea08fb0d477/build-script-build\n   Compiling regex-syntax v0.5.6\n     Running rustc --crate-name regex_syntax /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-syntax-0.5.6/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=ec2e61d25f6dc7c7 -C extra-filename=-ec2e61d25f6dc7c7 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern ucd_util=/tmp/cargo-installdxfBoN/release/deps/libucd_util-262bf6f116a73cad.rlib --cap-lints allow\n   Compiling libsqlite3-sys v0.9.1\n     Running rustc --crate-name build_script_build /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/libsqlite3-sys-0.9.1/build.rs --crate-type bin --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"min_sqlite_version_3_6_8\"' --cfg 'feature=\"min_sqlite_version_3_7_16\"' --cfg 'feature=\"pkg-config\"' --cfg 'feature=\"vcpkg\"' -C metadata=e907748d8658c71b -C extra-filename=-e907748d8658c71b --out-dir /tmp/cargo-installdxfBoN/release/build/libsqlite3-sys-e907748d8658c71b -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern pkg_config=/tmp/cargo-installdxfBoN/release/deps/libpkg_config-d118bd48cb6004a9.rlib --cap-lints allow\n   Compiling mysqlclient-sys v0.2.3\n     Running rustc --crate-name build_script_build /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/mysqlclient-sys-0.2.3/build.rs --crate-type bin --emit=dep-info,link -C opt-level=3 -C metadata=355e0c00c2f5cc0e -C extra-filename=-355e0c00c2f5cc0e --out-dir /tmp/cargo-installdxfBoN/release/build/mysqlclient-sys-355e0c00c2f5cc0e -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern pkg_config=/tmp/cargo-installdxfBoN/release/deps/libpkg_config-d118bd48cb6004a9.rlib --cap-lints allow\n     Running /tmp/cargo-installdxfBoN/release/build/serde-20418b2cd81aaac2/build-script-build\n   Compiling textwrap v0.10.0\n     Running rustc --crate-name textwrap /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/textwrap-0.10.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=3e3a996c0b539eab -C extra-filename=-3e3a996c0b539eab --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern unicode_width=/tmp/cargo-installdxfBoN/release/deps/libunicode_width-55470b249822e939.rlib --cap-lints allow\n   Compiling thread_local v0.3.5\n     Running rustc --crate-name thread_local /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/thread_local-0.3.5/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=8e649d381e273623 -C extra-filename=-8e649d381e273623 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern lazy_static=/tmp/cargo-installdxfBoN/release/deps/liblazy_static-13d3d5636b3ae515.rlib --extern unreachable=/tmp/cargo-installdxfBoN/release/deps/libunreachable-e24d499ca6920b30.rlib --cap-lints allow\n   Compiling aho-corasick v0.6.5\n     Running rustc --crate-name aho_corasick /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/aho-corasick-0.6.5/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=1cd80a98554391b1 -C extra-filename=-1cd80a98554391b1 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern memchr=/tmp/cargo-installdxfBoN/release/deps/libmemchr-12a113d5634908fb.rlib --cap-lints allow\n   Compiling syn v0.11.11\n     Running rustc --crate-name syn /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/syn-0.11.11/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"full\"' --cfg 'feature=\"parsing\"' --cfg 'feature=\"printing\"' --cfg 'feature=\"quote\"' --cfg 'feature=\"synom\"' --cfg 'feature=\"unicode-xid\"' -C metadata=02dd1fd2b79051c2 -C extra-filename=-02dd1fd2b79051c2 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern quote=/tmp/cargo-installdxfBoN/release/deps/libquote-7531a65df1fc6d63.rlib --extern synom=/tmp/cargo-installdxfBoN/release/deps/libsynom-697dcad0a97a181e.rlib --extern unicode_xid=/tmp/cargo-installdxfBoN/release/deps/libunicode_xid-78d05d44e850227b.rlib --cap-lints allow\n   Compiling backtrace-sys v0.1.23\n     Running rustc --crate-name build_script_build /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-sys-0.1.23/build.rs --crate-type bin --emit=dep-info,link -C opt-level=3 -C metadata=42779d8a8e8a1156 -C extra-filename=-42779d8a8e8a1156 --out-dir /tmp/cargo-installdxfBoN/release/build/backtrace-sys-42779d8a8e8a1156 -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern cc=/tmp/cargo-installdxfBoN/release/deps/libcc-2494f437ec9205c7.rlib --cap-lints allow\n     Running rustc --crate-name num_traits /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/num-traits-0.2.5/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=8b477d649a8b06e5 -C extra-filename=-8b477d649a8b06e5 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow --cfg has_i128\n     Running rustc --crate-name pq_sys /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/pq-sys-0.4.5/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=724a7349eb6f41a8 -C extra-filename=-724a7349eb6f41a8 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow -L native=/usr/lib64 -l pq\n   Compiling quote v0.6.3\n     Running rustc --crate-name quote /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/quote-0.6.3/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"proc-macro\"' --cfg 'feature=\"proc-macro2\"' -C metadata=d82dbe1af23b7444 -C extra-filename=-d82dbe1af23b7444 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern proc_macro2=/tmp/cargo-installdxfBoN/release/deps/libproc_macro2-9a8b1995c153f609.rlib --cap-lints allow\n     Running /tmp/cargo-installdxfBoN/release/build/libsqlite3-sys-e907748d8658c71b/build-script-build\n   Compiling quote v0.5.2\n     Running rustc --crate-name quote /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/quote-0.5.2/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"proc-macro\"' --cfg 'feature=\"proc-macro2\"' -C metadata=8d01b381e60fcd45 -C extra-filename=-8d01b381e60fcd45 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern proc_macro2=/tmp/cargo-installdxfBoN/release/deps/libproc_macro2-b6e7f381465868e6.rlib --cap-lints allow\n     Running /tmp/cargo-installdxfBoN/release/build/mysqlclient-sys-355e0c00c2f5cc0e/build-script-build\n   Compiling tempfile v3.0.2\n     Running rustc --crate-name tempfile /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/tempfile-3.0.2/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=dce3ea134b2df0be -C extra-filename=-dce3ea134b2df0be --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern libc=/tmp/cargo-installdxfBoN/release/deps/liblibc-cd9c0a92dfbde993.rlib --extern rand=/tmp/cargo-installdxfBoN/release/deps/librand-81a089c0245327b8.rlib --extern remove_dir_all=/tmp/cargo-installdxfBoN/release/deps/libremove_dir_all-54ca297a931213d9.rlib --cap-lints allow\n   Compiling clap v2.32.0\n     Running rustc --crate-name clap /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/clap-2.32.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"ansi_term\"' --cfg 'feature=\"atty\"' --cfg 'feature=\"color\"' --cfg 'feature=\"default\"' --cfg 'feature=\"strsim\"' --cfg 'feature=\"suggestions\"' --cfg 'feature=\"vec_map\"' -C metadata=c34afbbafb7dd8de -C extra-filename=-c34afbbafb7dd8de --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern ansi_term=/tmp/cargo-installdxfBoN/release/deps/libansi_term-db41b2a9728108f8.rlib --extern atty=/tmp/cargo-installdxfBoN/release/deps/libatty-6de45a38f81927fa.rlib --extern bitflags=/tmp/cargo-installdxfBoN/release/deps/libbitflags-71282bd87c17fec5.rlib --extern strsim=/tmp/cargo-installdxfBoN/release/deps/libstrsim-6251f76ab3616c54.rlib --extern textwrap=/tmp/cargo-installdxfBoN/release/deps/libtextwrap-3e3a996c0b539eab.rlib --extern unicode_width=/tmp/cargo-installdxfBoN/release/deps/libunicode_width-55470b249822e939.rlib --extern vec_map=/tmp/cargo-installdxfBoN/release/deps/libvec_map-54c8ba97b679707a.rlib --cap-lints allow\n     Running rustc --crate-name libsqlite3_sys /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/libsqlite3-sys-0.9.1/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"min_sqlite_version_3_6_8\"' --cfg 'feature=\"min_sqlite_version_3_7_16\"' --cfg 'feature=\"pkg-config\"' --cfg 'feature=\"vcpkg\"' -C metadata=f501687d11ee1b8c -C extra-filename=-f501687d11ee1b8c --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow -l sqlite3\n     Running rustc --crate-name mysqlclient_sys /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/mysqlclient-sys-0.2.3/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=5c6e2528db2f849f -C extra-filename=-5c6e2528db2f849f --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --cap-lints allow -l mysqlclient\n     Running /tmp/cargo-installdxfBoN/release/build/backtrace-sys-42779d8a8e8a1156/build-script-build\n   Compiling syn v0.14.2\n     Running rustc --crate-name syn /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/syn-0.14.2/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"clone-impls\"' --cfg 'feature=\"default\"' --cfg 'feature=\"derive\"' --cfg 'feature=\"parsing\"' --cfg 'feature=\"printing\"' --cfg 'feature=\"proc-macro\"' --cfg 'feature=\"proc-macro2\"' --cfg 'feature=\"quote\"' --cfg 'feature=\"visit\"' -C metadata=f0d120e95f694b46 -C extra-filename=-f0d120e95f694b46 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern proc_macro2=/tmp/cargo-installdxfBoN/release/deps/libproc_macro2-9a8b1995c153f609.rlib --extern quote=/tmp/cargo-installdxfBoN/release/deps/libquote-d82dbe1af23b7444.rlib --extern unicode_xid=/tmp/cargo-installdxfBoN/release/deps/libunicode_xid-91dcf6c630d8b674.rlib --cap-lints allow\n   Compiling syn v0.13.11\n     Running rustc --crate-name syn /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/syn-0.13.11/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"clone-impls\"' --cfg 'feature=\"default\"' --cfg 'feature=\"derive\"' --cfg 'feature=\"fold\"' --cfg 'feature=\"full\"' --cfg 'feature=\"parsing\"' --cfg 'feature=\"printing\"' --cfg 'feature=\"proc-macro\"' --cfg 'feature=\"proc-macro2\"' --cfg 'feature=\"quote\"' -C metadata=8bbc216ab693dccf -C extra-filename=-8bbc216ab693dccf --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern proc_macro2=/tmp/cargo-installdxfBoN/release/deps/libproc_macro2-b6e7f381465868e6.rlib --extern quote=/tmp/cargo-installdxfBoN/release/deps/libquote-8d01b381e60fcd45.rlib --extern unicode_xid=/tmp/cargo-installdxfBoN/release/deps/libunicode_xid-91dcf6c630d8b674.rlib --cap-lints allow\n     Running rustc --crate-name num_integer /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/num-integer-0.1.39/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=9f3add00dfa6e085 -C extra-filename=-9f3add00dfa6e085 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern num_traits=/tmp/cargo-installdxfBoN/release/deps/libnum_traits-8b477d649a8b06e5.rlib --cap-lints allow --cfg has_i128\n     Running rustc --crate-name backtrace_sys /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-sys-0.1.23/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=528df36d3a8b9d6b -C extra-filename=-528df36d3a8b9d6b --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern libc=/tmp/cargo-installdxfBoN/release/deps/liblibc-cd9c0a92dfbde993.rlib --cap-lints allow -L native=/tmp/cargo-installdxfBoN/release/build/backtrace-sys-1ebdce5b82263101/out -l static=backtrace\n     Running rustc --crate-name regex /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-0.2.11/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=2cefa1d7127abf28 -C extra-filename=-2cefa1d7127abf28 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern aho_corasick=/tmp/cargo-installdxfBoN/release/deps/libaho_corasick-1cd80a98554391b1.rlib --extern memchr=/tmp/cargo-installdxfBoN/release/deps/libmemchr-12a113d5634908fb.rlib --extern regex_syntax=/tmp/cargo-installdxfBoN/release/deps/libregex_syntax-ec2e61d25f6dc7c7.rlib --extern thread_local=/tmp/cargo-installdxfBoN/release/deps/libthread_local-8e649d381e273623.rlib --extern utf8_ranges=/tmp/cargo-installdxfBoN/release/deps/libutf8_ranges-7153fdfdde9acf5a.rlib --cap-lints allow --cfg regex_runtime_teddy_ssse3 --cfg regex_runtime_teddy_avx2\n   Compiling derive-error-chain v0.10.1\n     Running rustc --crate-name derive_error_chain /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/derive-error-chain-0.10.1/src/lib.rs --crate-type proc-macro --emit=dep-info,link -C prefer-dynamic -C opt-level=3 -C metadata=a240ea3a18fa2dac -C extra-filename=-a240ea3a18fa2dac --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern quote=/tmp/cargo-installdxfBoN/release/deps/libquote-7531a65df1fc6d63.rlib --extern syn=/tmp/cargo-installdxfBoN/release/deps/libsyn-02dd1fd2b79051c2.rlib --cap-lints allow\n   Compiling backtrace v0.3.9\n     Running rustc --crate-name backtrace /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-0.3.9/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"backtrace-sys\"' --cfg 'feature=\"coresymbolication\"' --cfg 'feature=\"dbghelp\"' --cfg 'feature=\"default\"' --cfg 'feature=\"dladdr\"' --cfg 'feature=\"libbacktrace\"' --cfg 'feature=\"libunwind\"' --cfg 'feature=\"winapi\"' -C metadata=07590466927f6b6c -C extra-filename=-07590466927f6b6c --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern backtrace_sys=/tmp/cargo-installdxfBoN/release/deps/libbacktrace_sys-528df36d3a8b9d6b.rlib --extern cfg_if=/tmp/cargo-installdxfBoN/release/deps/libcfg_if-f372f1afa1bbf981.rlib --extern libc=/tmp/cargo-installdxfBoN/release/deps/liblibc-cd9c0a92dfbde993.rlib --extern rustc_demangle=/tmp/cargo-installdxfBoN/release/deps/librustc_demangle-68ef64f4f8baf8f5.rlib --cap-lints allow -L native=/tmp/cargo-installdxfBoN/release/build/backtrace-sys-1ebdce5b82263101/out\n   Compiling serde_derive v1.0.67\n     Running rustc --crate-name serde_derive /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/serde_derive-1.0.67/src/lib.rs --crate-type proc-macro --emit=dep-info,link -C prefer-dynamic -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=8d339e57dff2a54f -C extra-filename=-8d339e57dff2a54f --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern proc_macro2=/tmp/cargo-installdxfBoN/release/deps/libproc_macro2-9a8b1995c153f609.rlib --extern quote=/tmp/cargo-installdxfBoN/release/deps/libquote-d82dbe1af23b7444.rlib --extern syn=/tmp/cargo-installdxfBoN/release/deps/libsyn-f0d120e95f694b46.rlib --cap-lints allow\n   Compiling error-chain v0.10.0\n     Running rustc --crate-name error_chain /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/error-chain-0.10.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"backtrace\"' -C metadata=f968ac73d8ad24f4 -C extra-filename=-f968ac73d8ad24f4 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern backtrace=/tmp/cargo-installdxfBoN/release/deps/libbacktrace-07590466927f6b6c.rlib --cap-lints allow -L native=/tmp/cargo-installdxfBoN/release/build/backtrace-sys-1ebdce5b82263101/out\n   Compiling chrono v0.4.4\n     Running rustc --crate-name chrono /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/chrono-0.4.4/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"clock\"' --cfg 'feature=\"default\"' --cfg 'feature=\"time\"' -C metadata=578e8dcfc27ce377 -C extra-filename=-578e8dcfc27ce377 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern num_integer=/tmp/cargo-installdxfBoN/release/deps/libnum_integer-9f3add00dfa6e085.rlib --extern num_traits=/tmp/cargo-installdxfBoN/release/deps/libnum_traits-8b477d649a8b06e5.rlib --extern time=/tmp/cargo-installdxfBoN/release/deps/libtime-5b4cb43446967bd8.rlib --cap-lints allow\n   Compiling idna v0.1.4\n     Running rustc --crate-name idna /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/idna-0.1.4/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=9aa3912cf6cc6aab -C extra-filename=-9aa3912cf6cc6aab --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern matches=/tmp/cargo-installdxfBoN/release/deps/libmatches-3e21c544cb7c996b.rlib --extern unicode_bidi=/tmp/cargo-installdxfBoN/release/deps/libunicode_bidi-17dbd4acb7086505.rlib --extern unicode_normalization=/tmp/cargo-installdxfBoN/release/deps/libunicode_normalization-5aa755380e525e3a.rlib --cap-lints allow\n   Compiling dotenv v0.10.1\n     Running rustc --crate-name dotenv /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/dotenv-0.10.1/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"backtrace\"' --cfg 'feature=\"default\"' --cfg 'feature=\"error-chain\"' -C metadata=3f3b5e76a7e761b6 -C extra-filename=-3f3b5e76a7e761b6 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern derive_error_chain=/tmp/cargo-installdxfBoN/release/deps/libderive_error_chain-a240ea3a18fa2dac.so --extern error_chain=/tmp/cargo-installdxfBoN/release/deps/liberror_chain-f968ac73d8ad24f4.rlib --extern regex=/tmp/cargo-installdxfBoN/release/deps/libregex-2cefa1d7127abf28.rlib --cap-lints allow -L native=/tmp/cargo-installdxfBoN/release/build/backtrace-sys-1ebdce5b82263101/out\n   Compiling url v1.7.0\n     Running rustc --crate-name url /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/url-1.7.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=f099343eeb9b1ab0 -C extra-filename=-f099343eeb9b1ab0 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern idna=/tmp/cargo-installdxfBoN/release/deps/libidna-9aa3912cf6cc6aab.rlib --extern matches=/tmp/cargo-installdxfBoN/release/deps/libmatches-3e21c544cb7c996b.rlib --extern percent_encoding=/tmp/cargo-installdxfBoN/release/deps/libpercent_encoding-4091d5da07ac45fd.rlib --cap-lints allow\n   Compiling diesel_derives v1.3.0\n     Running rustc --crate-name diesel_derives /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel_derives-1.3.0/src/lib.rs --crate-type proc-macro --emit=dep-info,link -C prefer-dynamic -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"mysql\"' --cfg 'feature=\"postgres\"' --cfg 'feature=\"sqlite\"' -C metadata=12b8ef71b2c5f439 -C extra-filename=-12b8ef71b2c5f439 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern proc_macro2=/tmp/cargo-installdxfBoN/release/deps/libproc_macro2-b6e7f381465868e6.rlib --extern quote=/tmp/cargo-installdxfBoN/release/deps/libquote-8d01b381e60fcd45.rlib --extern syn=/tmp/cargo-installdxfBoN/release/deps/libsyn-8bbc216ab693dccf.rlib --cap-lints allow\n     Running rustc --crate-name serde /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/serde-1.0.67/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"derive\"' --cfg 'feature=\"serde_derive\"' --cfg 'feature=\"std\"' -C metadata=0910a26d8c4a29ec -C extra-filename=-0910a26d8c4a29ec --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern serde_derive=/tmp/cargo-installdxfBoN/release/deps/libserde_derive-8d339e57dff2a54f.so --cap-lints allow --cfg de_boxed_c_str --cfg de_rc_dst --cfg core_duration --cfg integer128 --cfg num_nonzero\n   Compiling diesel v1.3.2\n     Running rustc --crate-name diesel /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-1.3.2/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"bitflags\"' --cfg 'feature=\"diesel_derives\"' --cfg 'feature=\"libsqlite3-sys\"' --cfg 'feature=\"mysql\"' --cfg 'feature=\"mysqlclient-sys\"' --cfg 'feature=\"postgres\"' --cfg 'feature=\"pq-sys\"' --cfg 'feature=\"sqlite\"' --cfg 'feature=\"url\"' -C metadata=8b8613945b65b829 -C extra-filename=-8b8613945b65b829 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern bitflags=/tmp/cargo-installdxfBoN/release/deps/libbitflags-71282bd87c17fec5.rlib --extern byteorder=/tmp/cargo-installdxfBoN/release/deps/libbyteorder-7ddb8085dbc25068.rlib --extern diesel_derives=/tmp/cargo-installdxfBoN/release/deps/libdiesel_derives-12b8ef71b2c5f439.so --extern libsqlite3_sys=/tmp/cargo-installdxfBoN/release/deps/liblibsqlite3_sys-f501687d11ee1b8c.rlib --extern mysqlclient_sys=/tmp/cargo-installdxfBoN/release/deps/libmysqlclient_sys-5c6e2528db2f849f.rlib --extern pq_sys=/tmp/cargo-installdxfBoN/release/deps/libpq_sys-724a7349eb6f41a8.rlib --extern url=/tmp/cargo-installdxfBoN/release/deps/liburl-f099343eeb9b1ab0.rlib --cap-lints allow -L native=/usr/lib64\n   Compiling toml v0.4.6\n     Running rustc --crate-name toml /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/toml-0.4.6/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 -C metadata=668c8f975b1580d6 -C extra-filename=-668c8f975b1580d6 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern serde=/tmp/cargo-installdxfBoN/release/deps/libserde-0910a26d8c4a29ec.rlib --cap-lints allow\n   Compiling infer_schema_internals v1.3.0\n   Compiling migrations_internals v1.3.0\n     Running rustc --crate-name infer_schema_internals /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/infer_schema_internals-1.3.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"diesel\"' --cfg 'feature=\"mysql\"' --cfg 'feature=\"postgres\"' --cfg 'feature=\"serde\"' --cfg 'feature=\"sqlite\"' --cfg 'feature=\"uses_information_schema\"' -C metadata=e68cd17a19c48dd9 -C extra-filename=-e68cd17a19c48dd9 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern diesel=/tmp/cargo-installdxfBoN/release/deps/libdiesel-8b8613945b65b829.rlib --extern serde=/tmp/cargo-installdxfBoN/release/deps/libserde-0910a26d8c4a29ec.rlib --cap-lints allow -L native=/usr/lib64\n     Running rustc --crate-name migrations_internals /home/kus/.cargo/registry/src/github.com-1ecc6299db9ec823/migrations_internals-1.3.0/src/lib.rs --crate-type lib --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' -C metadata=6deefc0726ea646d -C extra-filename=-6deefc0726ea646d --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern diesel=/tmp/cargo-installdxfBoN/release/deps/libdiesel-8b8613945b65b829.rlib --cap-lints allow -L native=/usr/lib64\n   Compiling diesel_cli v1.3.1\n     Running rustc --crate-name diesel src/main.rs --crate-type bin --emit=dep-info,link -C opt-level=3 --cfg 'feature=\"default\"' --cfg 'feature=\"diesel\"' --cfg 'feature=\"infer_schema_internals\"' --cfg 'feature=\"mysql\"' --cfg 'feature=\"postgres\"' --cfg 'feature=\"sqlite\"' --cfg 'feature=\"url\"' -C metadata=05c8d76c700b4fa1 -C extra-filename=-05c8d76c700b4fa1 --out-dir /tmp/cargo-installdxfBoN/release/deps -L dependency=/tmp/cargo-installdxfBoN/release/deps --extern chrono=/tmp/cargo-installdxfBoN/release/deps/libchrono-578e8dcfc27ce377.rlib --extern clap=/tmp/cargo-installdxfBoN/release/deps/libclap-c34afbbafb7dd8de.rlib --extern diesel=/tmp/cargo-installdxfBoN/release/deps/libdiesel-8b8613945b65b829.rlib --extern dotenv=/tmp/cargo-installdxfBoN/release/deps/libdotenv-3f3b5e76a7e761b6.rlib --extern infer_schema_internals=/tmp/cargo-installdxfBoN/release/deps/libinfer_schema_internals-e68cd17a19c48dd9.rlib --extern migrations_internals=/tmp/cargo-installdxfBoN/release/deps/libmigrations_internals-6deefc0726ea646d.rlib --extern serde=/tmp/cargo-installdxfBoN/release/deps/libserde-0910a26d8c4a29ec.rlib --extern tempfile=/tmp/cargo-installdxfBoN/release/deps/libtempfile-dce3ea134b2df0be.rlib --extern toml=/tmp/cargo-installdxfBoN/release/deps/libtoml-668c8f975b1580d6.rlib --extern url=/tmp/cargo-installdxfBoN/release/deps/liburl-f099343eeb9b1ab0.rlib --cap-lints allow -L native=/usr/lib64 -L native=/tmp/cargo-installdxfBoN/release/build/backtrace-sys-1ebdce5b82263101/out\n    Finished release [optimized] target(s) in 1m 48s\n  Installing /home/kus/.cargo/bin/diesel\n```. ",
    "RazrFalcon": "Yes. I've mistaken. Updated the post.. @Eijebong Looks like it is postgres only. I'm using mysql.. @weiznich but the example uses CREATE TYPE SQL pragma, which MySql doesn't support.. @weiznich I don't need an MySql enum. I simply want to represent a random Sql type with my own. . \n\nJust use #[mysql(typename = ...)]\n\nerror[E0658]: The attribute `mysql` is currently unknown to the compiler and may have meaning added to it in the future (see issue #29642)\n  --> src/db/changes.rs:30:1\n   |\n30 | #[mysql(type_name = \"my_type\")]\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. It doesn't work either. Do you have a complete example?. Finally!\nHere is a complete example:\n```rust\n[macro_use] extern crate diesel;\nuse diesel::*;\nuse diesel::deserialize::{self, FromSql};\nuse diesel::serialize::{self, Output, ToSql};\nuse diesel::mysql::{Mysql, MysqlConnection};\nuse diesel::sql_types::{Unsigned, Smallint};\nuse std::io::Write;\ntable! {\n    custom_types {\n        id -> Integer,\n        action -> Unsigned,\n    }\n}\n[derive(AsExpression, FromSqlRow, PartialEq, Debug, Clone)]\n[sql_type = \"Unsigned\"]\npub enum Action {\n    Added = 0,\n    Updated = 1,\n    Removed = 2,\n}\nimpl ToSql, Mysql> for Action {\n    fn to_sql(&self, out: &mut Output) -> serialize::Result {\n        let t = match *self {\n            Action::Added   => 0,\n            Action::Updated => 1,\n            Action::Removed => 2,\n        };\n        , Mysql>>::to_sql(&t, out)\n    }\n}\nimpl FromSql, Mysql> for Action {\n    fn from_sql(bytes: Option<&[u8]>) -> deserialize::Result {\n        match , Mysql>>::from_sql(bytes)? {\n            0 => Ok(Action::Added),\n            1 => Ok(Action::Updated),\n            2 => Ok(Action::Removed),\n            _ => Err(\"Unrecognized enum variant\".into()),\n        }\n    }\n}\n[derive(Insertable, Queryable, Identifiable, Debug, PartialEq)]\n[table_name = \"custom_types\"]\nstruct HasCustomTypes {\n    id: i32,\n    action: Action,\n}\npub fn select() {\n    let conn = MysqlConnection::establish(\"test\").unwrap();\nlet rows: Vec<HasCustomTypes> = custom_types::table.load(&conn).unwrap();\n\n}\n```. Thanks.\nI've tried this:\n```rust\ndiesel_infix_operator!(MyLike, \" LIKE \");\npub trait MyLikeMethods: Expression + Sized {\n    fn my_like>(self, rhs: T) -> MyLike {\n        MyLike::new(self, rhs.as_expression())\n    }\n}\nimpl MyLikeMethods for T {}\n{\n    let some_text = \"some text\".to_string();\n    let list: Vec = table::my_table\n        .filter(columns::my_table::price.my_like(format!(\"%{}%\", some_text)))\n        .load(conn)?;\n}\n```\nBut I'm getting:\nerror[E0277]: the trait bound `std::string::String: diesel::Expression` is not satisfied\n   --> src/db/invoices.rs:253:48\n    |\n253 |         .filter(columns::invoices::total_price.my_like(format!(\"%{}%\", some_text)))\n    |                                                ^^^^^^^ the trait `diesel::Expression` is not implemented for `std::string::String`\n    |\n    = note: required because of the requirements on the impl of `diesel::expression::AsExpression<diesel::sql_types::Numeric>` for `std::string::String`\nThe price column is Decimal.. Thanks! It worked.. ",
    "belsonheng": "I'm using replace_into but you can also use sql_query if you prefer.. ",
    "orangesoup": "I understand ON DUPLICATE KEY UPDATE won't be supported, but... people who actually need the performance vs REPLACE when using MySQL would still want to use it. I'm trying to convert my app from using the \"basic\" mysql crate to use diesel, and this one is kind of a blocker atm.\nIn my case I would like to batch insert or update thousands of rows every second, how can I do that with diesel? The guide only says it's not supported. Well... I would gladly use raw SQL, but even then I can't really see a way to provide it a huge Vec and just run it. The documentation is really lacking tbf. Would any of you be so kind and provide an example how to do this?\nAn example query is something like this (simplified):\nINSERT INTO table (x, y, z) VALUES (?, ?, ?), (?, ?, ?), ...\nON DUPLICATE KEY UPDATE x = x + VALUES(x). ",
    "sunlightboy": "@weiznich  ok   https://github.com/sgrif/diesel.rs-website/issues/66. ",
    "nocduro": "I had this problem as well, here's how to reproduce:\n\ntry to run migration on table without primary key:\n\nsql\ncreate table vehicle_movements (\n  vehicle_id varchar not null,\n  stop_id varchar not null,\n  arrived_at int,\n  departed_at int\n)\n\nget error message\nedit up.sql to include composite key:\n\nsql\ncreate table vehicle_movements (\n  vehicle_id varchar not null,\n  stop_id varchar not null,\n  arrived_at int,\n  departed_at int,\n  primary key (vehicle_id, stop_id)\n)\n\ndiesel migration run then fails with the same error\n\nI fixed it by running diesel migration revert which dropped the tables, and then re-running diesel migration run. ",
    "BlakeGilstrap": "EDIT: I learned a lot from this guide. https://github.com/diesel-rs/diesel/blob/master/guide_drafts/trait_derives.md\nApologies for necro.\n@sgrif Do you mind explaining why #[table_name] was not required in this case and/or when it should be used?  I'm seemingly running into this error but my pattern doesn't match above exactly.\nschema.rs\n```rust\ntable! {\n    my_metadata_table {...}\n}\n```\nmetadata.rs\n```rust\nuse schema::my_metadata_table;\n[table_name = \"my_metadata_table\"]\n[derive(Deserialize, Queryable, Serialize)]\npub struct Metadata { ... } \n```\nAnd I get same error as mentioned here. \n. ",
    "mbilker": "~Replace Pg with Mysql and you have an example that works with MySQL. You could also use the generic DB: Backend, but I wouldn't bother with the generics if you are only going to use your project with MySQL.~\nDisregard my comment. I didn't notice the #[postgres(type_name = ...)] when I looked at this earlier.. ",
    "steveklabnik": "This broke semver's CI as well.. ^ is already the default with Cargo, so this and the others should just be \"0.5.0\"\n. ... this raises the question, when is it a good idea not not make sure something is correct?\n. I wonder if there's any better name here, even though it is just an implementation detail.\n. do you do trailing commas in diesel? this one is missing one\n. I think this can just be unwrap_or_else(bug)? \n. imho, match with _ if is a code smell, but maybe it's easier to do the cfgs this way?\n. :+1: \n. seems reasonable then\n. ",
    "WillSquire": "Following the tutorial here I keep getting names from parent modules are not accessible without an explicit import for Queryable and Insertable too, but #[macro_use] extern crate diesel; is present in main.rs? Am I missing something? Did read the merge report and tried changing to extern crate diesel; but unsure if this is correct as I got a bunch of other errors?. @Deedasmi Ah ok, thanks. I'll ignore for now. Yeah sure, I'm easy :) . The most important part for me is a quick example just in case they're not 'au fait' with tuples. Would having something under the select documentation also be useful? (This was the first place I looked). ",
    "gmjosack": "Now that 1.29 is out is there a plan to cut a release for this fix?. I appreciate the update. We tend to have warnings as errors in our CI. I have this silenced for now but doing a blanket silence is problematic as it could mask other issues that crop up which is why I'd like resolution here.\nThanks again for the update and context.. ",
    "kushwahashiv": "rust is so unstable. I must consider not to move my tech stack to it and I should postpone for at least a year or so... ",
    "djc": "So these warnings are now also triggered on stable Rust with 1.29.0, with the result that my little Diesel (1.3.3) project on stable Rust now generates pages and pages of warnings on every compile. Could this be backported to an 1.3.x release, or will be 1.4.0 be released soon?. Ping, please take another look as this makes for very surprising UX.. @dsander sorry, my previous comment was badly worded. I meant that the current behavior of the Diesel CLI (without this change) is very surprising, and that your fix should be accepted.. BTW, I also ran cargo expand on my test module and could not find any mention of EmbedMigrations. So perhaps this is part of an intermediate macro output?. @sgrif -- with all due respect, without any rationale given, your response to the backporting request comes off as rather curt.\nIs there some policy against backporting? Is backporting excessively hard/expensive for this project? It seems like low-hanging fruit for users who get a false positive compiler warning, to me.. ",
    "sergeysova": "Does it already release?. ",
    "qrilka": "@weiznich is there any issue tracking this rustdoc problem?. ",
    "r-arias": "@weiznich that issue should be resolved in stable 1.30.1 (cargo doc works for me on this version); is there anything else blocking a release?. Thanks for the response. Looks like only sqlite causes trouble?. Could it be that sqlite is wrongly configured in the win environment? Just a guess, I am not familiar with how the test stage is set up.... Hmm, I thought maybe the schema is wrongly generated:\n2018-11-08T16:12:12.5030063Z error[E0433]: failed to resolve. Could not find `users` in `schema`\n2018-11-08T16:12:12.5053093Z  --> diesel_tests\\tests\\select.rs:8:17\n2018-11-08T16:12:12.5055022Z   |\n2018-11-08T16:12:12.5055296Z 8 |     use schema::users::dsl::*;\n2018-11-08T16:12:12.5059000Z   |                 ^^^^^ Could not find `users` in `schema`\n(here). Can't say, I'm just not familiar enough with this :/. Looks like it's building on azure, now?\nhttps://dev.azure.com/diesel-rs/diesel/_build/results?buildId=10\nI can't look at appveyor, where it is still failing. . ",
    "rrichardson": "Found the problem.  Since I'm providing the binary format, I need to prefix the value with 1 as is done in the ToSql impl for serde_json::Value. . ",
    "nabijaczleweli": "Does this also fix the docs not building on latest nightly?. Well, FTR, this is what the error looks like (can you cfg() on is-doc?, seems like simplest solution).. Whoops! I based this project off an another, older one, and there seemed to not be any kind of (migration, deprecation?) notice on diesel_codegen, so I matched diesel version to diesel_codegen's. Will explore that.\nHowever, the error still occurs on latest diesel (CI link):\nnote: lint level defined here\n   --> D:\\Users\\nabijaczleweli\\.cargo\\registry\\src\\github.com-1ecc6299db9ec823\\diesel-1.3.2\\src\\lib.rs:131:9\n    |\n131 | #![deny(warnings, missing_debug_implementations, missing_copy_implementations, missing_docs)]\n    |         ^^^^^^^^\n    = note: #[deny(intra_doc_link_resolution_failure)] implied by #[deny(warnings)]\n    = help: to escape `[` and `]` characters, just add '\\' before them like `\\[` or `\\]`. Okay, so I've the simple solution for the aforementioned problem; that is to change srd/lib.rs#L131 to:\n```rust\n![cfg_attr(feature = \"dox\", deny(warnings, missing_debug_implementations, missing_copy_implementations, missing_docs))]\n```\nThis will only disallow warnings on non-doc builds, meaning that docs, while still warninging like hell (I'll probably PR that), do actually build.. ",
    "kennytm": "A dependency currently breaks downstream crates because rustdoc has not stabilized --cap-lints yet, which prevents Cargo from utilizing it. Stabilization is underway (rust-lang/rust#52354) but it will likely take several days.\ncc rust-lang/rust#51468.. ",
    "jesskfullwood": "I assume this is the reason that the 'latest release' docs (linked in the README) on docs.rs are broken - https://docs.rs/diesel/1.3.2/diesel/ - because as I recall docs.rs uses nightly for its builds. ",
    "bnewbold": "Splunking around some more, I see previous discussion of some other compile-time messages, notably in #151 (\"Examine our compiler errors, and see if we can improve them\") and #573 (\"See if we can catch common errors with a lint\").. FWIW, I ran in to this exact problem, and an additional warning was added to the PostgreSQL wiki's \"Don't Do This\" list: https://wiki.postgresql.org/wiki/Don%27t_Do_This#Why_not.3F_12\nI switched to TEXT with a constraint. I suppose it's still the right thing for diesel to send bpchar in this case.. ",
    "dsander": "@djc Would to expect diesel database reset not to update schema.rs if it changed?. @sgrif Done. You are correct, I changed the indentation in migration_run_updates_schema_if_config_present as well.. ",
    "marioidival": "god. ",
    "sorccu": "This issue can be closed since #1837 is the exact same thing and it's been merged.. This is a real error that occurs if anything whatsoever goes wrong during a migration run. For example, the following migration:\nup.sql\nSELECT 1 FROM does_not_exist;\nExecuted with:\nrust\nembedded_migrations::run_with_output(&conn, &mut std::io::stdout()).expect(\"unable to migrate\");\nWill result in the following output:\n\nRunning migration 20190221123919\nthread 'main' panicked at 'unable to migrate: MigrationError(IoError(Custom { kind: Other, error: StringError(\"formatter error\") }))', src/libcore/result.rs:997:5\nnote: Run with RUST_BACKTRACE=1 environment variable to display a backtrace.\nExecuting migration script\n\nWhat SHOULD be shown is something along the lines of:\n\nthread 'main' panicked at 'unable to migrate: QueryError(DatabaseError(__Unknown, \"relation \\\"does_not_exist\\\" does not exist\"))', src/libcore/result.rs:997:5\n\nIt turns out that the reason is very simple. Upon encountering an error, diesel attempts to display the filename of the failed migration:\nhttps://github.com/diesel-rs/diesel/blob/03ec1d96ffa8a4f957ba6dc9bd5ab5b556a96d12/diesel_migrations/migrations_internals/src/lib.rs#L337-L344\nSince the embedded migration's impl Migration is left without a file_path() implementation:\nhttps://github.com/diesel-rs/diesel/blob/03ec1d96ffa8a4f957ba6dc9bd5ab5b556a96d12/diesel_migrations/migrations_macros/src/embed_migrations.rs#L37-L49\n...  it returns the default None, which then triggers the formatting error here:\nhttps://github.com/diesel-rs/diesel/blob/03ec1d96ffa8a4f957ba6dc9bd5ab5b556a96d12/diesel_migrations/migrations_internals/src/migration.rs#L49-L52\nAnd since the writeln!() for the error message uses ?, the formatting error from above ends up replacing the original error entirely.. I believe that Travis simply timed out instead of actually reporting an error. Closing and opening the PR once hoping to trigger the build again.. Same thing again. Trying once more.. ",
    "biot023": "Oh good grief. Yes, it was precisely that -- thank you!. ",
    "BlockCat": "I have the exact same issue, is this being worked on?. ",
    "Kibouo": "At the time of asking this question, json operators are not implemented yet. A work-around is using sql() to write raw SQL code.. ",
    "Beamed": "This is apparently an issue with the schema of the database; I was using a bit when I should have been using a boolean (too much time in MSSQL land). However, I think the error handling here could be improved. I've updated the title to reflect that. Is there anything I can do to assist with that?. Thanks for digging further into the issue; I was unable to find information on the error itself at all.\nIt looks like you're able to get an appropriate error; was it maybe an issue of the nightly on Aug 22nd? \nAgreed it is probably an issue of libpq.dll, especially since I cannot replicate it on Linux. \nI'll update my libpq.dll (somehow) and try to replicate with my test program later this weekend and follow up on this issue. Thank you for responding and taking care to ensure the error handling story is good! :) . ",
    "onesk": "Can confirm this regression as of 1.3.2. Seems like a similar problem to #728 and is at least partially mitigated by commenting the health check in ConnectionManager.. ",
    "moulins": "\nWe 100% need the lifetime declared in belongs_to, but I'm wondering if just belongs_to(\"Foo<'a>\") makes more sense\n\nWell, I was thinking \"What if you want to specify constraints on your lifetimes?\"; but when thinking more about it, all diesel objects you'll get back via belongs_to should be 100% owned, so all lifetime parameters can be unconstrained.\nUsing belongs_to(\"Foo<'a>\") still seems wierd to me, because the 'a isn't defined anywhere, and I'm not sure what belongs_to(\"Foo<'a, 'a>\") should mean:\n  - impl<'a> ... for Foo<'a, 'a>, or\n  - impl<'a, 'b> ... for Foo<'a, 'b>?\nInstead, I would propose belongs_to(\"Foo<'_>\"): the elided lifetime makes it clear that any lifetime is acceptable.. Nice, thanks for the work!. ",
    "RaleighHokie": "You would still use your GitHub org, no need to migrate that, in that step you are creating an organization in Azure DevOps (our top level container is also called an organization) that you would then use to build your existing GitHub org with Azure Pipelines.. ",
    "jeremyepling": "@sgrif / @weiznich , I updated our docs to clarify that an Azure DevOps organization is different than a GitHub organization. People often use the same name for both so there's alignment between then.. ",
    "jgraef": "Just so that other people know how to fix this:\nIt looks like feature bigdecimal needs crate num_bigint, which is not put into the dependencies, if feature num-bigint is not enabled. Thus enabling feature numeric (which includes num-bigint) fixed that issue for me.. ",
    "kpcyrd": "@weiznich I've changed this to a subcommand so diesel completions $x accepts bash, fish and zsh.. @weiznich I've pushed a commit to correct the rustfmt issue.. @dmcguire81 I somehow missed that, thanks for pointing it out. rustfmt should pass with the patch I just pushed.. My example, was probably confusing, I'm more interested in the println! part:\nrust\nif embedded_migrations::any_pending_migrations()? {\n    println!(\"executing migrations);\n}\nembedded_migrations::run(&db)?;\nHaving access to these things allows me to write a better user interface. @Boscop may have a similar usecase.. I was able to work around this with embed_migrations!(\"migrations\"), if I recall correctly I had to provide a path explicitly because foo uses diesel as well and it would pick up foo/migrations from foo/bar otherwise.. @weiznich thanks, I've updated my pr. I'm basically trying to do something like this:\n```bash\nbuild() {\n  cd \"diesel-${pkgver}/${pkgname}\"\n  cargo build --release\n}\ncheck() {\n  cd \"diesel-${pkgver}/${pkgname}\"\n  DIESEL_TEST_BIN=../target/release/diesel_cli cargo test --release --no-default-features --features sqlite\n}\npackage() {\n  cd \"diesel-${pkgver}\"\n  install -Dm755 \"target/release/diesel\" \"${pkgdir}/usr/bin/diesel\"\ninstall -d \"${pkgdir}/usr/share/bash-completion/completions\" \\\n             \"${pkgdir}/usr/share/zsh/site-functions\" \\\n             \"${pkgdir}/usr/share/fish/vendor_completions.d\"\n  \"${pkgdir}/usr/bin/diesel\" completions bash > \"${pkgdir}/usr/share/bash-completion/completions/diesel\"\n  \"${pkgdir}/usr/bin/diesel\" completions zsh > \"${pkgdir}/usr/share/zsh/site-functions/_diesel\"\n  \"${pkgdir}/usr/bin/diesel\" completions fish > \"${pkgdir}/usr/share/fish/vendor_completions.d/diesel.fish\"\ninstall -Dm644 LICENSE-MIT -t \"${pkgdir}/usr/share/licenses/${pkgname}\"\n}\n```\nWhen the package is built, build(), check() and package() are executed in that order. Running cargo build in release mode and cargo test in debug mode means the whole dependency tree is built twice. Since I already built everything in release mode, building the tests in release mode as well would significantly speedup the build.. I somehow missed that function, I'm now using your snippet and also found the value_t! macro, this removes every reference to bash and zsh and generates completions for everything supported in clap.. @sgrif I've re-introduced the command and also added a deprecation warning to stderr.. Good catch, updated my PR.. I've moved the comment to the commit message.. ",
    "dmcguire81": "@kpcyrd doesn't look like your rustfmt patch succeeded:\n$ cargo fmt --all -- --write-mode=diff\nDiff in /home/travis/build/diesel-rs/diesel/diesel_migrations/migrations_internals/src/lib.rs at line 183:\n /// structured, and where Diesel will look for them by default.\n pub fn any_pending_migrations_from<Conn, List>(\n     conn: &Conn,\n-    migrations: List\n+    migrations: List,\n ) -> Result<bool, RunMigrationsError>\n where\n     Conn: MigrationConnection,\nThe command \"cargo fmt --all -- --write-mode=diff\" exited with 4.\nI'm assuming that's why there are no takers on reviewing it.. @weiznich can you confirm that a review isn't picked up until the build shows passing?. ",
    "bobtwinkles": "For what it's worth, I'm willing to take a stab at fixing this if nobody else is working on it.. Awesome, thanks!. ",
    "igalic": "Thank you very much for this reply \u2014 it does help put things into perspective.. ",
    "h-michael": "@sgrif\nHave you started implementing it?\nIf not, may I start implementing ?. @sgrif\nThanks to your reply.\nBTW, both of Postgress and Sqlite have same query syntax for upsert.\nHow do you think how to pg and sqlite share query builder mdule?\nIf you have any ideas, please tell me your thought.\npostgres https://www.postgresql.org/docs/10/static/sql-insert.html\nsqlite https://www.sqlite.org/lang_UPSERT.html. @weiznich\nThanks to your advide.\nI'll implement this weekend!. @weiznich @sgrif \nDo you know what is version of sqlite on travis ?\nI think that that sqlite version is not support upsert.. @weiznich \n\nDo not remove unrelated tests and remove that impls for SupportsDefaultKeyword and SupportsReturningClause for sqlite because both are not supported on sqlite and may lead to invalid sql.\n\nI'm sorry, I was variously misunderstanding.\nI've fixed it.. @weiznich \nFailed tests with Sqlite3 on travis are success on my desktop.\nI think that sqlite3 running on the travis is not support upsert version.. @weiznich \nThank you so match for your polite review!\nI'll fix that today or tomorrow.\nAfter fix it, should I rebase and clean commit logs ?. @sgrif Would you review this PR?. [memo]\nin travisci\n$ sqlite3 --version\n3.8.2 2013-12-06 14:53:30 27392118af4c38c5203a04b8013e1afdb1cebd0d. @weiznich @sgrif \nPython depends on libsqlite3-0, so we should build python from source in order to using latest sqlite3. :( (We use python for travis-cargo.). @pascalw Thanks for your reply.\nI think libsqlite3-sys is only c binding library, so we can't run with only libsqlite3-sys.\nNow, I resolve test environment issue!\nI think that best way is running test on container image like Docker.\nBut TravisCI can run only Docker as one of script process, not as an integration.\nSo, if we use Docker with TravisCI, we get hard to see the output of the test.. @weiznich @sgrif\nI've pass the CI.\nWould you review this PR?. @weiznich I've fixed. \nCan I ignore azure pipelines failure?. @Eijebong @killercup\nWould you review this PR?. @weiznich \nFix and update CHANGELOG.md.. @weiznich\nTravis has passed.\nBut azzure has not passed yet.\nHow can I debug azzure pipelines?. @weiznich cc: @sgrif \nNow, CI has passed except nightly rust issue.\nPlease please review this PR.. @weiznich Now all passed :tada: . @weiznich \n\nI've just noticed that the current implementation does not work for insert statements based on select statements. (See the tests in diesel_tests/tests/insert_from_select.rs. In such cases invalid sql is generated for sqlite.\n\nWhat case you said? Now all test cases passed.\nDese you said is I should adding more test case?\nIf that's, could you show me tha case?. @weiznich \nI see. \n\n\nSomehow add a default where clause like suggested by the sqlite docs for the sqlite insert statement with select statements and conflict clause\n\n\nI think query builder should not automatically insert query that the user unintended.\nI think it should be fail build.\nBut I don't know diesel team policy.\nHow do you think about that?\n\n(I must say that I've totally missed that case for too long, so sorry for that\u2026)\n\nNever mind! Every your advices are good for me.. > Inserting a additional WHERE true does not alter the query, but only works around a bug in sqlites query parser. (They even state that in their docs\u2026)\nThis is just my personal opinion.\nThat is either parser bug or spec, we can't guarantee that it remains the same in the future version.\nIf that behavior changed, we should add version specific codes.\nThat is not good.. @weiznich \nOk, I try to implement adding WHERE true when SELECT clause that does not contain WHERE clause.. @weiznich \n\nChanged Milestone to 2.0 because this needs a solution for the insert by select case. (2.0 is just a placeholder for the next release after 1.4)\n\nThen, shall we merge this as 1.4 after adding fail test.. @weiznich \nOk, now I've rebased.\nAnd I'm going to add fail test soon.. @weiznich \nI added some fail test cases.\nAnd CI will passed soon.. @weiznich CI has passed.. @weiznich Oh, sorry.\nI'm trying implement now.\nDoes diesel have predicate which express TRUE or 1=1 ? . @weiznich Sorry, I don't think I can make it on time.\nIt's a little complex.. @weiznich \nSorry for late reply.\nI've see all insert statement codebase. But I don't know how to implement add WHERE true in such case.\nWould you help me?. @weiznich \nAt #1884, I need sqlite3 that is over v3.24.0, but Ubuntu trusty has 3.8.2.\nWe have two ways to use sqlite3 v3.24.0.\nFirst, we manually build sqlite3 on Travisci, but that makes build speed slow.\nSecond, when sqlite3 test runs, we use Ubuntu cosmic(18.10) that has sqlite3 v3.24.0 on Azure pipeline.\nCould you try to use Ubuntu cosmic on sqlite3 test?. Sorry, We are available only Ubuntu 16.04 on Azure pipelines.\nhttps://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=vsts&tabs=yaml#use-a-microsoft-hosted-agent. @weiznich \nFirst of all, thank you for maintaining this project.\nAre you going to merge this PR in a few days?\nThere are too many PR which is in review and wait for being reviewed for a log time.\nIf you merge this PR with leaving those PR, almost all those PR face conflict.\nI think that you and @diesel-rs/reviewers review and merge those PR before merging this PR.. @weiznich \nI understand your thought.\nThank you for explaining me!\nI'll rebase later.. This pr may help you. #1913. nightly build has failed, but this may be rust issue.. @weiznich \nBTW, may we specify the nightly version or ignore nightly building failed ?. @weiznich \n\nUnfortunately I'm not aware of anything like this\n\nI try thinking the way that resolves this.\nNow, CI passed, would you merge this?. @weiznich \nSorry, I don't know how to implement you said.\nPlease tell me in detail, if you could.. I think that these how to use cfg attr is bad, but I don't know how to write better especially features documentation test.. It changes it's owner ship to root:root.\nI think this is a bug by TravisCI or git.. Fixed.. Fixed. ",
    "tyrylu": "This is unfortunately not enough, because at least for the windows builds it is necessary to call the enable_load_extension c function which has no sql function counterpart, without it you end up with an unauthorized error (tried a few hours ago with the bundled 3.24 version in sqlite3-sys).. ",
    "alamminsalo": "This would be great feature, currently I have to use a separate sqlite lib to load and query with extensions.. changed to return QueryResult instead. removed this line. ",
    "behnam": "Actually, I later realized that it's optional. So, feel free to Close if you think the current way is preferred.. ",
    "NachoGotaki": "thank you too much.. ",
    "xrl": "@kestred I did hit that problem initial, now I've made sure to sync up the library versions. the error still happens when versions are synced:\n```\n$ cargo tree | grep bigdecimal\n\u251c\u2500\u2500 bigdecimal v0.0.11\n\u2502   \u251c\u2500\u2500 bigdecimal v0.0.11 (*)\n``. OK, turns out my reproduction wasn't fair. Looks like the ordering of properties in the target struct must match the order in thetable!` definition. Whoops \ud83d\ude26 \nClosing!. ",
    "inferiorhumanorgans": "In case anyone else misses this: you'll need to set the serde feature on bigdecimal for all of this to work.. ",
    "ian-p-cooke": "@virome are you still working on this?  I might want to do something similar to support TiDB and would like to see how you refactor things.. i\u2019m asking for changes to the MySQL backend and diesel_cli so that it supports both native MySQL and TiDB.  I\u2019ve opened issues with TiDB for places where I\u2019m finding incompatible behavior but I think we could tweak Diesel\u2019s MySQL backend in the mean time without negatively affecting native MySQL users.\nFor example, after I got past the above issues I found that diesel setup was still failing, this time because TiDB doesn\u2019t support DDL in prepared statements.  I modified diesel_cli so that it didn\u2019t use prepared statements for create and then finally I could diesel setup without errors.  I\u2019d rather not maintain a fork of diesel_cli and since my change should work equally well with MySQL I was hoping you\u2019d accept a pull request for that.\nI just wanted to check with you before putting in the work for any pull requests.. Ok, for now I'll keep track of the changes I need and then when the mariadb backend progresses I can follow suit with a TiDB backend if my experiments turn out the way I want them to.  \nI found #1882 but it looks like it got stuck somewhere along the way.  I'll inquire over there to see if that's still being worked on.\nThanks!. ",
    "samal84": "Thank you so much @top1st \nThat fixed my issue with it not finding libpq.lib.\nMy console output if anyone is curious\n\n```\n>cargo install diesel_cli --no-default-features --features postgres\n    Updating crates.io index\n  Installing diesel_cli v1.3.1\n   Compiling proc-macro2 v0.4.24\n   Compiling semver-parser v0.7.0\n   Compiling libc v0.2.46\n   Compiling unicode-xid v0.1.0\n   Compiling version_check v0.1.5\nwarning: not embedding natvis: lld-link may not support the flag\n\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling winapi v0.3.6\n   Compiling vcpkg v0.2.6\n   Compiling autocfg v0.1.1\n   Compiling num-traits v0.2.6\nwarning: not embedding natvis: lld-link may not support the flag\n\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling unicode-xid v0.0.4\n   Compiling cfg-if v0.1.6\n   Compiling rustc-demangle v0.1.13\n   Compiling num-integer v0.1.39\n   Compiling serde v1.0.84\nwarning: not embedding natvis: lld-link may not support the flag\n\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling ucd-util v0.1.3\n   Compiling matches v0.1.8\n   Compiling lazy_static v1.2.0\n   Compiling regex v0.2.11\n   Compiling rand_core v0.3.0\n   Compiling quote v0.3.15\n   Compiling unicode-width v0.1.5\n   Compiling unicode-normalization v0.1.7\n   Compiling byteorder v1.2.7\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling utf8-ranges v1.0.2\n   Compiling bitflags v1.0.4\n   Compiling percent-encoding v1.0.1\n   Compiling strsim v0.7.0\n   Compiling vec_map v0.8.1\n   Compiling proc-macro2 v0.3.8\n   Compiling semver v0.9.0\n   Compiling memchr v2.1.2\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling synom v0.11.3\n   Compiling rand_chacha v0.1.1\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling backtrace v0.3.13\n   Compiling rand v0.6.3\nwarning: not embedding natvis: lld-link may not support the flag\n\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling pq-sys v0.4.6\n   Compiling regex-syntax v0.5.6\n   Compiling unicode-bidi v0.3.4\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling thread_local v0.3.6\n   Compiling textwrap v0.10.0\n   Compiling rand_isaac v0.1.1\n   Compiling rand_xorshift v0.1.1\n   Compiling rand_hc v0.1.0\n   Compiling syn v0.11.11\n   Compiling rustc_version v0.2.3\n   Compiling quote v0.5.2\n   Compiling quote v0.6.10\n   Compiling rand_pcg v0.1.1\n   Compiling rand_os v0.1.0\n   Compiling atty v0.2.11\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling remove_dir_all v0.5.1\n   Compiling time v0.1.41\n   Compiling idna v0.1.5\n   Compiling aho-corasick v0.6.9\n   Compiling syn v0.13.11\n   Compiling syn v0.15.23\n   Compiling derive-error-chain v0.10.1\n   Compiling clap v2.32.0\n   Compiling chrono v0.4.6\n   Compiling error-chain v0.10.0\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling url v1.7.2\n   Compiling serde_derive v1.0.84\n   Compiling diesel_derives v1.3.0\n   Compiling dotenv v0.10.1\n   Compiling tempfile v3.0.5\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling diesel v1.3.3\nwarning: not embedding natvis: lld-link may not support the flag\n\n   Compiling toml v0.4.10\n   Compiling migrations_internals v1.3.0\n   Compiling infer_schema_internals v1.3.0\n   Compiling diesel_cli v1.3.1\nwarning: not embedding natvis: lld-link may not support the flag\n\nerror: linking with `lld-link.exe` failed: exit code: 1\n  |\n  = note: \"lld-link.exe\" \"/NOLOGO\" \"/NXCOMPAT\" \"/LIBPATH:C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.0.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.1.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.10.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.11.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.12.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.13.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.14.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.15.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.2.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.3.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.4.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.5.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.6.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.7.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.8.rcgu.o\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.diesel.5t9v60oe-cgu.9.rcgu.o\" \"/OUT:C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.exe\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\diesel-2ec5483bb11140fd.3t4brw9uu7e5917u.rcgu.o\" \"/OPT:REF,ICF\" \"/DEBUG\" \"/LIBPATH:C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\" \"/LIBPATH:C:/POSTGR~1/pg10/lib\" \"/LIBPATH:C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\liburl-311c27da7eda9b23.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libpercent_encoding-d39a8d4ccfb1689f.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libidna-cdf2ec7486fe2e53.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libunicode_normalization-1a689ddddc68742d.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libunicode_bidi-160075525a9af67b.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libmatches-306296e784ed2044.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libtoml-8ee757ed99fca180.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libtempfile-3f98137ca5a85f7f.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libremove_dir_all-5fb2054af2954367.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librand-20483952681cad83.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librand_xorshift-41d22a5c6587e3c1.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librand_pcg-403e4bb408bac56d.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librand_hc-856cdff7fee9f885.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librand_chacha-280ed9c94d9aa648.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librand_isaac-aff980eaa2e0b273.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librand_os-57c37edc1b30e732.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librand_core-c040c4bf6472128b.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libmigrations_internals-ad2660e9fb7ba3f6.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libinfer_schema_internals-0d77d3a21f991c8d.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libserde-0d476c92670d8967.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libdotenv-0d3ead47f2570ed8.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libregex-acc245407c006e45.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libutf8_ranges-393296c4e8921f2c.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libregex_syntax-52eab5ca3b3686b5.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libucd_util-3c34df3112141dbd.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libthread_local-d3320e4ca07141d2.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\liblazy_static-20b942af9413d46b.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libaho_corasick-5da8f3908f994d1e.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libmemchr-d3c2e3c742714911.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\liblibc-bda5ca0b3894b92c.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\liberror_chain-1da36336b39b2121.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libbacktrace-231589ff58f8134d.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\librustc_demangle-b967d08354ab3dea.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libcfg_if-05001ce65ae1165a.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libdiesel-b57f0a81e4f45a60.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libpq_sys-cb1af1c68ac17cd1.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libbyteorder-313da54f4620eb8e.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libclap-d2e3a7b7ff09e083.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libvec_map-50919a2d955cade3.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libtextwrap-42379df4d8ac8cb9.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libunicode_width-a6babce11606c624.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libstrsim-7761fa99b130e50d.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libbitflags-c3dfa588d6509e21.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libatty-5280a780c491ec6b.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libchrono-b2358e26e0fe0d54.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libnum_integer-271a4b863db8e4ef.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libnum_traits-1c9772dbd4a3fc65.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libtime-d06c3c96718bd16e.rlib\" \"C:\\\\Users\\\\Sammi\\\\AppData\\\\Local\\\\Temp\\\\cargo-install576IYL\\\\release\\\\deps\\\\libwinapi-06e1bccb79deb7a0.rlib\" \"C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\\\\libstd-5b27a62c9f67f3de.rlib\" \"C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\\\\libpanic_unwind-4369007c1114ae91.rlib\" \"C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\\\\libunwind-717cd1192a64e0a2.rlib\" \"C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\\\\liblibc-b468418b9b4dfb1b.rlib\" \"C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\\\\liballoc_system-31879fae3e218342.rlib\" \"C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\\\\liballoc-396b96b15f25c29e.rlib\" \"C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\\\\libcore-df063db6a7606a04.rlib\" \"C:\\\\Users\\\\Sammi\\\\.rustup\\\\toolchains\\\\stable-x86_64-pc-windows-msvc\\\\lib\\\\rustlib\\\\x86_64-pc-windows-msvc\\\\lib\\\\libcompiler_builtins-df8513470b3bc4f5.rlib\" \"libpq.lib\" \"advapi32.lib\" \"credui.lib\" \"dbghelp.lib\" \"gdi32.lib\" \"kernel32.lib\" \"msimg32.lib\" \"opengl32.lib\" \"secur32.lib\" \"setupapi.lib\" \"user32.lib\" \"winspool.lib\" \"advapi32.lib\" \"ws2_32.lib\" \"userenv.lib\" \"shell32.lib\" \"msvcrt.lib\"\n  = note: lld-link.exe: error: could not open libpq.lib: no such file or directory\n\n\nerror: aborting due to previous error\n\nerror: failed to compile `diesel_cli v1.3.1`, intermediate artifacts can be found at `C:\\Users\\Sammi\\AppData\\Local\\Temp\\cargo-install576IYL`\n\nCaused by:\n  Could not compile `diesel_cli`.\n\n```\n\n. ",
    "Swoorup": "This is all easier with vcpkg.\nInstall vcpkg and then install libpq using \nvcpkg.exe install libpq:x64-windows\n\u03bb  .\\vcpkg.exe list\nlibpq:x64-windows                                  9.6.1-5          The official database access API of postgresql\nlibpq:x86-windows                                  9.6.1-5          The official database access API of postgresql\nopenssl-windows:x64-windows                        1.0.2q           OpenSSL is an open source project that provides ...\nopenssl-windows:x86-windows                        1.0.2q           OpenSSL is an open source project that provides ...\nopenssl:x64-windows                                0                OpenSSL is an open source project that provides ...\nopenssl:x86-windows                                0                OpenSSL is an open source project that provides ...\nUse vcpkg-rs cli to ensure it detects the dependency:\nvcpkg_cli.exe probe libpq\nFound library libpq\nInclude paths:\n  D:\\Thirdparty\\vcpkg\\installed\\x64-windows\\include\nLibrary paths:\n  D:\\Thirdparty\\vcpkg\\installed\\x64-windows\\lib\nRuntime Library paths:\n  D:\\Thirdparty\\vcpkg\\installed\\x64-windows\\bin\nCargo metadata:\n  cargo:rustc-link-search=native=D:\\Thirdparty\\vcpkg\\installed\\x64-windows\\lib\n  cargo:rustc-link-search=native=D:\\Thirdparty\\vcpkg\\installed\\x64-windows\\bin\n  cargo:rustc-link-lib=libpq\n  cargo:rustc-link-lib=libeay32\n  cargo:rustc-link-lib=ssleay32\nFound DLLs:\n  D:\\Thirdparty\\vcpkg\\installed\\x64-windows\\bin\\libpq.dll\n  D:\\Thirdparty\\vcpkg\\installed\\x64-windows\\bin\\libeay32.dll\n  D:\\Thirdparty\\vcpkg\\installed\\x64-windows\\bin\\ssleay32.dll\nset VCPKGRS_DYNAMIC=1 to enable dynamic linking and then also export the vcpkg dll bin folder to PATH. It is much streamlined than copying dlls manually.. ",
    "Lynss": "thx, I met the same problem and solve it with your method adding the bin directory under PostgreSQL in Program Files to my path. ",
    "pascalw": "Wouldn't it be easier to run tests with libsqlite3-sys? I'm not familiar with Diesels Travis setup, so perhaps there's a good reason not to, but just throwing it out there?. Thanks for keeping at this @h-michael! \ud83d\udc4d . ",
    "lukaslueg": "The record will show that the board of directors was informed of shenanigans regarding Diesel tests since October 2018.. ",
    "jkcclemens": "No, master does not. That's why I made this issue.\nmaster explicitly will not use uuid 0.7, since uuid 0.7 misses the feature that master requests.. Perhaps you should revert #1861 to explicitly show that you won't support uuid 0.7, then.\nFor what it's worth, use_std was deprecated in uuid 0.6.. ",
    "terry90": "If I understand it correctly, uuid won't be updated unless a major version is coming out ? :cry: \nIs it better to support older versions instead of newer ? It prevents people to update lot of things\nEdit: if you want, you can temporarily use:\ntoml\n[patch.crates-io]\ndiesel = { git = \"https://github.com/terry90/diesel.git\" }. @fairingrey Sorry I didn't mentioned, you should cargo update or remove your Cargo.lock\n@DoumanAsh I agree too, I think I'm not the only one to use Rocket and Diesel, which seems close to a full web framework like Rails with Activerecord, and this issue unfortunately makes the latest diesel incompatible with rocket. The moving parts in the Rust ecosystem - I think - should not be ignored.\nIf you don't want to make this a breaking change until a minor or major version, another solution would be to maintain a parallel branch, and adds this to the README.md. While I don't think this is the best option, this is something.\nEdit: Great, I just saw you started a PR. @weiznich I see your point and I agree. Thanks for digging through\nEdit: As @weiznich said, I guess it should look like that https://github.com/terry90/uuid_diesel_0_7_pg so not a big deal. Feel free to use it in your project if you don't want to write it.\nThis is not usable with the master branch of diesel until #1916 is merged though, I'm using 1.3.3. @SergioBenitez I don't see the problem, what is the use of Rocket's Uuid aside FromParam ?\nOnce you have uuid::Uuid, what forbid you to use it like you want ? Here a simple newtype wrapper fixes this issue.\nI don't think it's Rocket's responsibility to fix this btw.. Oh yes, sorry I misunderstood. Then, would it be acceptable to create an additional wrapper type ?. ",
    "DoumanAsh": "If you have unstable crate as part of public API, it is already wrong to consider diesel stable.  Being part of feature though, I don't see big problem to update in next patch version with mention of need to upgrade uuid, not a big deal. >That means if you decided to use them you should except breaking things here\nThat's actually also argument on upgrading your public dependencies until their reach 1.0 (though only as minor version, not patch as user might need to perform actions to ensure compatibility, i.e. upgrading uuid)\nThough it is not critical as you say.. ",
    "fairingrey": "@terry90 I tried using your patch, but I'm getting a ton of errors now and I'm not sure what happened. I've attached the error output here: error.txt\nPerhaps this might be related to https://github.com/rust-lang/rust/issues/50504, but I'm not sure why your patch in particular breaks it when it builds just fine without it included.\nIn regards to the issue, maybe this could be patched in diesel 1.4.x if it's a breaking change? Kind of agree with @DoumanAsh.. ",
    "julien1619": "Hi! Is there any plan to upgrade uuid despite the strong arguments given here? I would really benefit from this update.\nCurrently uuid is activated using a feature flag, so, is it possible to add a new feature flag, like uuid-next that will expose an uuid implemented in Diesel code and internally depending on the new version of the uuid crate? It could avoid breaking compatibility, or I misunderstood something?. ",
    "0xpr03": "I'm not fully sure whether this is a standard, but at least the DB I use has a \"integerunsigned\" field and the sqlite browser I use seems to find this normal ?. Ah thanks, that explains my confusion when I tried to look up uInt in the sqlite docs. I guess that's what you get for trying to read 3rd party sqlite DBs.\nEdit: It seems like the rate limiting doesn't apply that hard for renewals, opposed to what I read in the FAQ. Had a change to retry now.. ",
    "ivan": "Interesting, thanks for that SqlType workaround. I was using .filter(sql(&format!(\"id = '{}'\", id))), which required me to deal with SQL injection.. ",
    "VictorKoenders": "Rust 1.31 released so this is waiting on #1936 . ",
    "jonas-schievink": "1936 is now merged :tada: . Hmm, this might be a broader issue than that: If the column is renamed to something that contains a space, the generated schema.rs is similarly broken.. My usecase was for running a test suite on a different database, without having the user deal with migrations. The test runner would run all needed migrations automatically and execute each test in a test transaction that is never committed.. Ah yeah, I just checked the code again and I'm calling any_pending_migrations before run_pending_migrations to log a message when migrations need to be run, and that fails if the migrations table doesn't exist. setup_database will fix that.\nI could live without this though, so feel free to close if you think this doesn't make sense. Or maybe the better fix would be to call setup_migrations from any_pending_migrations.. ",
    "Rio": "Also don't forget to add the appropriate label to indicate that it's synthetic diesel to be EU compliant.\n\nDiesel-type fuels: square. B7, B10, XTL, etc. (\u201cB\u201d stands for specific biodiesel components present in diesel, the XTL stands for synthetic diesel and indicates that it is not derived from crude oil);\n\n\n. ",
    "drozdziak1": "Full context\nClone this and checkout at diesel-bug-reproduction. cd into bounty_hunter and run reproduce_no_retrieve.sh. See test.json and you'll observe how the record that comes back from the DB is different and causes deserialization to fail on a field with not enough bytes that came from another field (channel_id).. ",
    "kevlarr": "@weiznich Thanks for linking to the Queryable docs - makes sense as intended behavior, though it was easy to miss that last line describing field order. This is definitely a hang-up for new people, especially when following the \"Getting Started\" guide - it shows migration and Post struct but does not make explicit mention that field order matters when using the #derive.\nWould adding a disclaimer that field order matters rather than field names to the intro guide make sense?. ",
    "RalfJung": "Turns out Debian considers it normal to change the psql DB port during a DB upgrade.  Hence my DB now listens on port 5433, where it previously listened on 5432.  I find that rather startling, but it's not diesel's problem.. ",
    "ZeGentzy": "I'm struggling to think of reasons that this is happening. The most relevant I can think of is my use of llvm-svn, however, I don't think that could lead to path resolution failure. The master version of diesel is the only thing which fails for me.\nI've tried doing rustup self uninstall, then wiping ~/.cargo and ~/.rustup, then reinstalling to no avail. I've reproduced this on both stable and nightly. I haven't tested beta, but I'm guessing it would happen on it too.. Apparently the Cargo.toml above is not enough, instead you need to clone diesel manually and do the following if you want your program to compile:\n```\n[package]\nname = \"diesel_test\"\nversion = \"0.1.0\"\nauthors = [\"Hal Gentz zegentzy@protonmail.com\"]\nedition = \"2018\"\n[dependencies]\ndiesel = { path = \"diesel/diesel\" }\n[replace]\n\"diesel_derives:1.3.0\" = { path = \"diesel/diesel_derives\" }\n```\nHopefully this gets documented somewhere or diesel_derives gets a version bump or something.. @weiznich Have I addressed all your concerns?. Done changes.\n. Say, what's this waiting on?. Rebased against master. Pleeeeeeeeease can we get this merged?. It isn't, I guess. Was copied over from UncheckedBind mindlessly.. I did not realize SqlQuery has no sql function, however, normally you can add extra sql via sql.\nAs far as I can tell, an sql function in BoxedSqlQuery is necessary for doing things like this in a loop (small example from my codebase):\n``\n            type BSQ<'f> = diesel::query_builder::BoxedSqlQuery<'f, DbBack, diesel::query_builder::SqlQuery>;\n            fn assemble_attribs_join<'f>(id: &str, sql: BSQ<'f>) -> BSQ<'f> {\n                sql\n                    .sql(\"INNER JOINddb_replay_attribs\")\n                    .sql(id)\n                    .sql(\"ONddb_replays.ddb_id=\")\n                    .sql(id)\n                    .sql(\".ddb_replay_idAND\")\n                    .sql(id)\n                    .sql(\".ddb_name`=? \")\n            }\n        replays_query = match sort_method {\n            ReplayPart::Attrib(name) => assemble_attribs_join(\"sm0\", replays_query)\n                .bind::<sql_types::Text, _>(name),\n            ReplayPart::SubmitterUsername => replays_query\n                .sql(\"INNER JOIN `ddb_users` `sm0` ON `ddb_replays`.`ddb_submitter_id`=`sm0`.`ddb_id` \"),\n            _ => replays_query,\n        };\n\n```\nI guess users could loop twice, once for compiling the sql query, and another for adding the binds, however, that strikes me as unergonomic.. This example does work, however, with BoxedSqlQuery.. Should be noted that users can also do things like diesel::dsl::sql::<sql_types::Integer>(\"Hello \").sql(\"World!\");. Made it symmetrical.. Removed. No reason, fixed.. ",
    "toplinuxsir": "I have already enabled the network-address, But the error still exist\n```\ndiesel={version=\"1.3\", features=[\"postgres\", \"chrono\", \"r2d2\", \"network-address\"]}\nipnetwork=\"0.13\"\n```. Thanks , I got it!. ",
    "Munksgaard": "In fact, it seems that I don't even need bar.date to be non-null. diesel print-schema fails on this schema as well:\n```sql\nBEGIN;\nCREATE SCHEMA diesel_error\nCREATE TABLE diesel_error.foo (\n  id SERIAL PRIMARY KEY,\n  date DATE NOT NULL\n);\nCREATE UNIQUE INDEX foo_id_date ON diesel_error.foo (id, date);\nCREATE TABLE diesel_error.bar (\n  id SERIAL PRIMARY KEY,\n  foo_id INTEGER NOT NULL REFERENCES diesel_error.foo(id),\n  date DATE NOT NULL,\n  FOREIGN KEY (foo_id, date) REFERENCES diesel_error.foo(id, date)\n);\nCOMMIT;\n```. For reference, the following schema works:\n```sql\nBEGIN;\nCREATE SCHEMA diesel_error\nCREATE TABLE diesel_error.foo (\n  id SERIAL PRIMARY KEY,\n  date DATE NOT NULL\n);\nCREATE UNIQUE INDEX foo_id_date ON diesel_error.foo (id, date);\nCREATE TABLE diesel_error.bar (\n  id SERIAL PRIMARY KEY,\n  foo_id INTEGER NOT NULL REFERENCES diesel_error.foo(id),\n  date DATE NOT NULL\n);\nCOMMIT;\n```\nand results in this output:\n```rust\npub mod diesel_error {\n    table! {\n        diesel_error.bar (id) {\n            id -> Int4,\n            foo_id -> Int4,\n            date -> Date,\n        }\n    }\ntable! {\n    diesel_error.foo (id) {\n        id -> Int4,\n        date -> Date,\n    }\n}\n\njoinable!(bar -> foo (foo_id));\n\nallow_tables_to_appear_in_same_query!(\n    bar,\n    foo,\n);\n\n}\n```. ",
    "z0mbie42": "I acknowledge and understand your objection but isn't there a way to find a compromise ?\nLet say I want to use diesel in an app with ~50 (to start) tables, each one having 1 to 3 JSONB fields, it's waaaay too much handwritten boilerplate don't you think ?. Thank you for the explanation and the example, I'll try to implement this macro.. ",
    "kswope": "This is badly needed.  I just spent a few hours figuring out that I have to add r2d2 to the \"features\" in Cargo.toml.  If I hadn't found some something about it on the forums I would have never figured it out.\nMaybe a small section in http://diesel.rs/guides/. ",
    "damody": "587 can not fix my problem.",
    "grinapo": "Correction, I cannot cheat the rename-dependency:\n```\ngetting_started_step_1$ cargo build\n    Updating crates.io index\n Downloading dotenv v0.10.1                                                                                                                                                                                                                                                   \n Downloading diesel v1.4.0                                                                                                                                                                                                                                                    \nerror: unable to get packages from source                                                                                                                                                                                                                                       \nCaused by:\n  failed to parse manifest at /home/grin/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-1.4.0/Cargo.toml\nCaused by:\n  feature rename-dependency is required\nconsider adding cargo-features = [\"rename-dependency\"] to the manifest\n```. I don't get the second part, my rustc is 1.31.0. \nThe first part cannot be fixed since it's in the cargo-pulled config from diesel upstream:\n\nfailed to parse manifest at /home/grin/.cargo/registry/src/github.com-1ecc6299db9ec823/diesel-1.4.0/Cargo.toml\n. Turned out that debian uses a funky versioning: 0.31 contains 1.30.x, 0.32 contains 1.31.x cargo. Upgrading to 0.32 in fact upgraded cargo to 1.31 which in turn is able to build the sample. \nStill, it won't work unless I move it out of the directory structure.\nThanks.. \n",
    "magj2006": "\nOracle is no supported back end therefore it is not possible to connect to a oracle database using diesel. Also we do not have any plans to add support for this to diesel.\nThat said there is diesel-oci that implements such an back end outside of diesel. It does work but is not finished yet. Also it requires a nightly compiler and a patched diesel version. What is planed is to upstream those changes.\nClosed as Won't fix.\n\nI got it, Thank you!!!. ",
    "0nkery": "RangeInclusive and RangeToInclusive seem to fail in the tests because the inferred Bound is always Excluded.. Seems like it's good to have precise Rust type to represent ranges with specific bounds. But I could remove some (redundant maybe) types like RangeInclusive and RangeToInclusive.\nIf I leave out FromSql these types cannot be Queryable, I guess?. > That means adding the ToSql implementations and related stuff is fine, but adding FromSql is against that policy.\nI see these types as kind of validation. What is validation policy? Maybe FromSql-like impls (maybe for completely separate trait) should be added to another crate?. ",
    "stevensonmt": "Does not compile with rustc 1.31.1.\n. > > Does not compile with rustc 1.31.1.\n\nI cannot reproduce that with rustc 1.31.1. (It builds fine for me...)\nCan you provide detailed steps to reproduce this?\n\nWeird. Here's the code I'm using: https://github.com/stevensonmt/diesel_pg_demo\nThe error returned is \n\nerror[E0658]: imports can only refer to extern crate names passed with --extern on stable channel (see issue #53130)                                                                      \n  --> src/lib.rs:22:9                                                                                                                                                                       \n   |                                                                                                                                                                                        \n10 | pub mod schema;                                                                                                                                                                        \n   | --------------- not an extern crate passed with --extern \n...                                                                                                                                                                                         \n22 |     use schema::posts;                                                                                                                                                                 \n   |         ^^^^^^                                                                                                                                                                         \n   |                                                                                                                                                                                        \nnote: this import refers to the module defined here                                                                                                                                         \n  --> src/lib.rs:10:1                                                                                                                                                                       \n   |                                                                                                                                                                                        \n10 | pub mod schema;                                                                                                                                                                        \n   | ^^^^^^^^^^^^^^^        \n\n$ rustc -V\nrustc 1.31.1 (b6c32da9b 2018-12-18)\nManjaro Linux box.. The problem is not that I did not clone the repo, but that I followed the tutorial. The tutorial does not mention anything about that flag. So the tutorial should be updated to reflect one of:\n\nAn upper bound of rust version\nInstructions to remove that flag from Cargo.toml if the rust version is a 2018 edition\nInstructions to add the same-crate syntax where appropriate for rust versions that are 2018 editions.\n\nI am happy to make edits and PRs for all the examples, but I'd like to know which of these three strategies is preferred.. ",
    "iptq": "I'm having the exact same problem trying to run a SQLite migration.\nsql\nCREATE TABLE `chals` (\n    `id` INTEGER PRIMARY KEY AUTO_INCREMENT,\n);\nThis is the full contents of the up.sql in question. Here's some parts of the code:\nrs\nmod sqlite {\n    #[derive(EmbedMigrations)]\n    #[embed_migrations_options(migrations_path = \"migrations/sqlite\")]\n    struct _Dummy;\n}\n...\nsqlite::run_with_output(conn, out) // fails. nvm my syntax is wrong, trailing comma. ",
    "paullgdc": "Also according to sqlite documentation\n\"Unless the column is an INTEGER PRIMARY KEY or the table is a WITHOUT ROWID table or the column is declared NOT NULL, SQLite allows NULL values in a PRIMARY KEY column. \" https://www.sqlite.org/syntax/table-constraint.html\nSo in the the case of non INTEGER primary key, it is right to make the column Nullable . Ok then, I'll just add NOT NULL to the field then. It seems to do the trick.. ",
    "davidarmstronglewis": "@weiznich okay, that makes a lot of sense. I'm sorry that it's not currently possible - I'll look into the custom backend implementation option, but I'm not sure I could make that fly on my project due to a lack of expertise on my end and a lack of community support if I were to build such a thing. Thank you for the reference to #1676, I'll check that out.\nCheers. ",
    "kiljacken": "FWIW, I'm using a bigint primary key for a table, and I've encountered no issues so far. Perhaps you could provide a code sample and the cargo checkoutput? :). I can recommend using heck instead of a homebrew solution.. Including this looks like a mistake, you might want to remove it :). ",
    "gpit2286": "For anyone who is looking to do the same thing, Below is my code. \n```rust \nuse diesel::deserialize::{self, FromSql};\nuse diesel::mysql::Mysql;\nuse diesel::serialize::{self, IsNull, Output, ToSql};\nuse diesel::sql_types::Binary;\nuse diesel::*;\nuse std::io::Write;\nuse serde::{Serialize};\n[derive(Debug, PartialEq, FromSqlRow, AsExpression, Serialize)]\n[sql_type = \"Binary\"]\npub struct BitBool(bool);\nimpl ToSql for BitBool {\n    fn to_sql(&self, out: &mut Output) -> serialize::Result {\n        match *self {\n            BitBool(true) => out.write_all(&[1])?,\n            BitBool(_) => out.write_all(&[0])?\n        };\n        Ok(IsNull::No)\n    }\n}\nimpl FromSql for BitBool {\n    fn from_sql(bytes: Option<&[u8]>) -> deserialize::Result {\n        let r = not_none!(bytes).iter().any(|x| *x != 0);\n        Ok(BitBool(r))\n    }\n}\ntable! {\n    test (id) {\n        id -> Integer,\n        active -> Bit\n    }\n}\nstruct TextRow {\n    id: i32, \n    active: BitBool\n}\n```\n . ",
    "torkleyy": "Okay, thank you for the thorough explanation!. ",
    "walter211": "Subscribed this issue\uff01. ",
    "mocsy": "Last I checked enums weren't supported by diesel.\nHere is what I'd use instead:\naction TEXT NOT NULL CHECK(action IN ('create', 'read', 'update', 'delete')),\nI haven't seen this Camel_casing issue yet.. ",
    "NicholasLYang": "They actually are! I'm using diesel-derive-enum. It's fairly decent except I need to add an import_types and then suppress the unused import warnings in schema.rs.. Sounds like a good idea!. Oops. Will do. ",
    "akrantz01": "I'm not sure, how do I check?. I got -107374151. It doesn't seem right, but it stayed consistent through multiple runs from echo $LASTEXITCODE. I didn't get it from powershell, but when I ran it in command prompt, I got the error message:\n\nThe code execution cannot proceed because SSLEAY32.dll was not found. Reinstalling the program may fix this problem.. \n",
    "Ryman": "Sadly, macros (which try! is) can't be called like methods, so the entire expression needs to be wrapped. You can try...\nrust\ntry!(insert(..).into(..).execute(..));\n. Slightly different problem with these, as main doesn't expect to return a Result, so the try! will fail. Not sure if there's any benefit to switching to try! here as this line is hidden from the output (It's prefixed with '#')\n. ",
    "Stebalien": "I'm not sure this is the right change. It's might be cx.call_site() or even something else (I'm not familiar with rust syntax extensions). This was broken by https://github.com/rust-lang/rust/commit/4259fba7e6b87966099a2df04e75b678e26e0811, FYI.\n. ",
    "tshepang": "indeed\n. ok, I might have a look at some point\n. ",
    "jashank": "The C interface defines, in server/catalog/pg_type.h, the macros JSONOID and JSONBOID as 114 and 3802, respectively. Not sure why there's no better documentation than that.. Seconded. This seems like something that should be added in the pq-sys bindings, too.. ",
    "daschl": "is this still needed?. \ud83d\udc4d . ",
    "PeterW-LWL": "any any?. Please include as much of your codebase as needed.... This error message is not correct, is it?. whitelist -> blacklist. ",
    "iterion": "We should probably implement a BigDecimal::NaN value to handle this. NaN isn't really an exceptional value, so an error seems wrong. That said, we'll need to figure out on the BigDecimal side of things how to make the API tolerable.. ",
    "abaumhauer": "Adding a cockroach feature would be ideal.  But in this case having a feature the enables the use of triggers in the database is also a good idea. This is business logic being defined in the database. It violates the rules of clean architecture by creating coupling between the app and the db. It's also not portable to the sqlite3 and mysql/mariadb back ends.. ",
    "klieth": "using \"substitute\" seems to me to be exposing the internals of how the library works a little too much, although I admittedly haven't looked at much of the code and don't know what the standard is. How about \"to correctly interpret strings starting with\" or \"to allow passing strings starting with\"? I'm also happy to go with your suggestion if you think it's best.. I went with the \"interpreting\" one; if it still reads poorly when you first read it I'll change it to your suggestion.. ",
    "cuviper": "Hmm, yeah, we now have scalar ops, but not for a combined div_rem. I could see adding something like div_rem_scalar, maybe generic or just for u32.. You're right that the output of Rem could have matched the divisor type. I guess we were just thinking to use consistent output for all ops. That could be reconsidered in a breaking change.\nYou do need all digits for computing Rem though, unless the divisor shares all prime factors with the base. (In this case just powers of 2.). ",
    "LappleApple": "Oh wow, thanks for that catch!. +1. ",
    "kulshrax": "Unfortunately it can't because host has different types in the two match arms (std::net::Ipv6Addr vs url::Host). \nI can change it to use the ? operator instead of the try! macro -- I only chose to use the latter to maintain consistency with the surrounding code.. ",
    "Darksonn": "Hmm, when I read the initial code, I remember seeing links that were already duplicated, and thus assumed the style was to put the links after each paragraph where they're used, to keep them close to the actual link. However when I look at the source again, it seems this isn't actually what happened.. "
}