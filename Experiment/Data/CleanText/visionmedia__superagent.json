{
    "Filirom1": "+1\n. ",
    "kapouer": "This gist from @shigeki looks like it ?\nhttps://gist.github.com/shigeki/2921169\nif he's all right with using it.\n. A second thought about this : it would be easier to have a superagent-proxy module that declares \"tunnel\" as a dependency, instead of having superagent depend on it directly.\n. This is related to #19\n. fine by me - i now understand that res being present means the server answered something and we have a status code, while no contact with server populates err or emits an error.\nMaybe that should be stated more obviously in documention ? Else feel free to close.\n. This also implies there should be some copyright statement somewhere.\n. ",
    "anthonyshort": "^ :+1:\n. ",
    "shigeki": "I'm very surprised that my gist was founded in this issue thread. This patch is for the man who was in trouble to use tower.js inside his proxy. As described in the gist, it needs node-tunnel module for SSL proxy. \nPlease free to use or modify this as you like.\n. ",
    "gjohnson": "Checkout superagent-proxy\n. As mentioned it passes both these days: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L623\n. Not until after 1.0\n. This exists now.\n. yeppp! thanks @tjconcept \n. Checkout superagent-retry for now.\n. It's not in the core,  but the plugin system exists so you could certainly write something.\n. Probably not... In most cases when you need jsonp, you don't need 99% of the API superagent has since there is no headers, etc. If all your looking for is the syntax surgar superagent uses, you could steal some code from this thing -> https://github.com/redventures/pixel\n. @tomasdev thats odd... superagent supports the browser and node, not sure what node-webkit could be doing to mess up the node or webkit side of things.\n. Closing this for now because people are using superagent fine in the browser via the download file, component or even browserify. \n@tomasdev I am certain that's going to be node-webkit's problem, but feel free to open a newer issue if you feel differently.\n. @rogerwang @jduncanator @tomasdev I am interested in this conversation, but for the sake of other watchers/maintainers on here, let's move this to a thread on node-webkit. Please paste the issue link. Thanks!\n. No more 0.6.x support.. Please re-open if this is still an issue.\n. Fixed in d7c9d017645d0f6589169636f30f9da5b018e620\n. Closing due to more recent duplicate #294 \n. For your use cases, can you get around your local tests by setting NODE_TLS_REJECT_UNAUTHORIZED=0? Defiantly do not want to do that in production but it works for local testing and removes the headache of multiple certs.\n. @RGBboy make sense\n. It defaults to json, try something like\nagent\n  .post('/data')\n  .type('text')\n  .send('hello')\n  .end(fn)\n. Formdata it is!\n. I'm -1 in core and maybe adding a little cleaner way to define new parsers. XML is a good example actually...  some people will want/need a certain XML parser for various legit reasons (e.g libxml vs xml-parser vx xyz) and then on top of that some people will want the XML to be parsed into JSON and others will want the XML document and so on.\n. Perhaps something like:\n``` js\nvar request = require('superagent');\nvar parse = require('xml-parser');\nrequest.parsers.set('text/xml', parse);\nrequest.get('/', function (res){\n  res.body // << whatever xml-parser gives you (an object I think)\n});\n```\nor\n``` js\nvar request = require('superagent');\nvar libxml = require('libxmljs');\nrequest.parsers.set('text/xml', libxml.parseXmlString);\nrequest.get('/', function (res){\n  res.body // << instanceof XmlDocument\n});\n```\n. Actually there is already a way... otherwise I think I am confusing the feature request here.\njs\nsuperagent.parse['application/xml'] = function(res, fn){\n   fn(null, customParserHere(res.text));\n};\nhttps://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L102-L104\n. Closing since we expose https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L102-L104\n. LGTM.... just need to get it to apply cleanly.\n. Nevermind, there we go!\n. Good plan. We will need to make sure browserify stays happy too.\n. Taking care of this manually, thanks though!\n. IMO it should throw. Errors from the callback stack should be connection and server errors only.\n. @visionmedia you have any thoughts on this?\n. @lbdremy try now, re-opened... \nAs for piping errors... node doesn't do that.\n. Things have changed a bit since this was opened and it will not apply cleanly. Parse errors are handled now though, so it's all good.\n. Note to self: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L428\n. @jonathanong started messing with this, it's my first go around with generators so still figuring out some things. Feel free to fix this branch: https://github.com/visionmedia/superagent/tree/thunkify\n. If their media types are json, why do they keep making up new silly media-types and not just use application/json? What is to prevent them from doing application/json+vnd+seferral-v1+hal or something next and then we would have to support that too?\nI am personally thinking this is way to edge case and will just open up a can of worms in regards to the future. :-(\n. Is there a spec for how these media-types are being crafted?\n. @jxson Thanks for the great explanation. I will review the changes sometime so we can pull it in (as long as we only just for /json$).\n@nathanhoel @amarandon try .agent() in supertest. https://github.com/visionmedia/supertest/blob/master/test/supertest.js#L588\n. Added in d7c9d017645d0f6589169636f30f9da5b018e620\n. What version of node?\n. @vtloc does @mintrigue's suggestion work for you?\n. Closing for now, please re-open if the middleware does not fix it.\n. Should be addressed in 5553d0e5583975b2d9a0202f6f094fa07978af38\n. Oh we fixed this haha\n. Have you tried https://github.com/TooTallNate/superagent-proxy?\n. Thanks for pointing that out. I believe all the documentation in the gh-pages (which is what the website uses) is up to  correct though. Perhaps @visionmedia has some thoughts on just removing the docs in master to avoid confusion on which docs to rely on.\n. I am going to remove the docs folder to avoid this confusion.\n. Yep, you need to have the content-type set, otherwise you need to force the request to buffer via .buffer().\nSee: http://visionmedia.github.io/superagent/#buffering-responses\n. @ayanamist yep, if you switch your example (the one include .buffer(true)) from res.body to res.text it works fine.\n. Strange, I'll check it out.\n. What version of npm?\n. Fixed in #272 \n. Side note: this should fix the random travis-ci failures and other npm issues.\n. I have never used browserify but I do not see how that is possible since the change was only to package.json, it was not actually being used anywhere in the lib/node.\n. Okay, so I guess browserify does some really strange shit (https://github.com/visionmedia/superagent/pull/259). I'll look into reverting, but then we start breaking node again... yay... @visionmedia @hallas any thoughts?\n. I own reduce so we can try whatever (just let me know)... I assume the issue in node-land is that older versions of npm don't like username/package? Perhaps, we just inline reduce as a function inside client.js and make everyone happy?\n. @visionmedia shit like this: https://github.com/visionmedia/superagent/issues/271\n. since it use to be supported via #259, I feel like we should fix it. Pushing up the fix in a minute...\n. Alright, here we go: c30313f7a4ef8f7ab631cee2f7332839be35683f\n. Make sense, I will check try it out tonight. Thanks!\n. Fixed in a566c88f9ca2056107f96d511f7d5e585e8ad83b\n. Going through all of this, you have a few things committed. :-)\n. Also, unless I am missing something, a rebase should have removed the need for that first commit. \n. ah yeah! Keep forgetting about squash.\n. @nickl- there ya go! Merged in 7ff4afa5e780b8b2a72b896e37aeb77619b448f3. I will do an actual release after work or sometime tomorrow. Thanks again for the additions and for fixing up the nit picky stuff. \n. Get it! https://github.com/visionmedia/superagent/blob/master/History.md#0160--2014-01-07\n. This is for the gh-pages branch though... I need to just remove the \"docs\" directory from master.\n. Yeah, I am kinda thinking we wrap up some outstanding bugs and tag 1.0 and then start 2.0 which would include things like this and other breaking changes.\n. I am +1 on doing this now rather than later, more benefits by having this change than keeping what we have now.\n. Yep, gonna check it out on Saturday morning!\n. I noticed @MatthewMueller ran into some charset issues in https://github.com/modella/ajax/commit/3ab6b5db1006394b689acb0aa9467690f97a57de... Wondering if he can shed any light on any repercussions to adding this.\n. Sorry, been a little too busy to double check everything! It looks good though and makes sense.\n. Merged in 543388fa4abe483a9b313f657cf9e719b3c78dda\n@bengourley want to make another PR for the browser in lib/client?\n. We could prevent the empty cookie header from being sent, however anyone can send whatever headers they want (not limited to superagent of course) and if your sever crashes because of an empty string value, I would say the issue is actually in your server.\n. No problem!\n. Yeah, sorry... Just been too busy this past couple weeks (middle of moving jobs)... I should have some time on Sunday though.\n. Looks like this made it's way in via #310. Please re-open if you still have problems.\n. I don't think we need something that elaborate included. Checkout making a plugin or just a function that looks up the auth by a key.\n. I don't believe there is a typo here, the function is performing a http HEAD request.\n. Ha, I read it backwards :-)\nSent from my iPhone\n\nOn Nov 16, 2013, at 2:14 PM, Matteo Figus notifications@github.com wrote:\nExactly, thanks @jdan\n\u2014\nReply to this email directly or view it on GitHub.\n. Spec was updated. https://code.google.com/p/v8/issues/detail?id=789#c3\n. Check out the comment I linked to, I believe they updated the update you are refereeing to.\n. Hmm. It looks like most browsers ignore it (for whatever reason), with phantomjs being the exception I guess. Re-opening but I need to run some tests on IE before merging.\n. Resolved in aa55815bdb041b78b8831225c697cb5b9b05bff1\n. The issue actually appears to be in how you have crafted your test case(s). You can't call done() until after ALL the iterations have completed. Might want to read up: http://book.mixu.net/node/ch7.html\n. Yep, thats what I plan on setting up.\n. Thanks!\n. @johntron  Can you add it to the node client too?\n. @johntron for the time being they don't actually share code... you can just add it somewhere on here https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L116.\n. @johntron yeah thanks for clarifying the two different types of plugins, make sense!\n. pong\n. I'll tag it later today.\n. Probably your local git settings. Not really an issue w/ superagent though.\n. Thats not good! One of the reason I am going to setup sauce labs!\n. We should keep 0.11 open until 0.12 comes out.\n. Closed in 5553d0e5583975b2d9a0202f6f094fa07978af38\n. Agree with everything @nickl- said here.\n. Yes, please add more info with a gist or PR.\n. Thanks a bunch.\n. I am still messing around with the testing setup. Will keep this open for now once some other things are in place. Thanks.\n. @defunctzombie yep, got some time slotted to finish it up this weekend.\n\nAlso, the build is failing because of some strange shit going on in 0.11.x, it's as if proto is acting like an own-property and causing object comparisons within should.js to fail.\n. Working on this over at https://github.com/visionmedia/superagent/tree/zuul\n. @visionmedia I could just change it to debug() for now.\n. @stephenmathieson can you please add a snippet/gist of the code you have that causes it?\n. Hmm... I have not really messed with the agent additions much. Maybe @hunterloftis would have a thought or two before I dig in.\n. Can we simplify this down to just the bare minimum so we don't have to keep so many fields up to date? Kinda like this: https://github.com/segmentio/analytics.js/blob/master/bower.json\nI've never used bower, so not sure the downsides of that.\n. Yeah, we should probably handle that. I am thinking we attach it to res.error instead of passing the error to the callback, as the callback error is presumed to be connection errors. So basically:\njs\nrequest('/')\n.accept('json')\n.end(function (err, res) {\n  if (err) return done(err); // connection error\n  if (res.error) {\n    // possible parse error\n  }\n});\n. @hallas this is different I think, this is the response failing to parse here, which you can't really handle your self. With #226 they were failing to serialize, which can easily be handled on the user's side.\n. Well, if something fails to serialize, the request never went out, so there shouldn't even be a response instance to attach it to yet. If we were convinced to not throw, then it should probably be caught to end up on the callback(err) or emitted error just like connection issues. But even then, I think people rely on that err from the callback only being from connection errors.\n. Let's move this convo back to #226 so we don't confuse them. :-)\n. @janesconference I was referring to a different issue. There are a couple tiny things we can do differently from that snippet though, so please open a PR and we can work through them.\n. Fixed in latest.\n. Fixed via #432. Thanks though!\n. I never mess with the multipart stuff and it's rather fragile. I'd rather not touch it. I do see what your trying to accomplish and maybe it's something to keep in mind for v2.\n. I feel like we already did this for HEAD requests, be nice to consolidate the logic somewhere.\n. I actually like this better than the HEAD fix.\n. It's too easy to just append a random value to query(...). Don't think it warrants another method added to the API.\n. You probably did not create an instance yet via get, post, put, etc...\nThis does not work:\njs\nvar request = require('superagent');\nrequest.redirects(1); // Uncaught TypeError: Object #<Request> has no method 'redirects'\nThis is what you want:\njs\nvar request = require('superagent');\nrequest.get('/url').redirects(1);\n. Thanks for keeping them short and sweet, makes life lot easier!\n. Sounds good.\n. Cool, if you want to be extra awesome, you can figure out why they fail  on node 0.11.x :-)\n. Nice!\n. Thanks, not sure why they are published two different ways...\n. Extend is fine. Thanks tho!\n. That used to be the behavior of the native querystring module, that way we can send nested data and/or arrays over querystrings. They removed it back in the day, so @visionmedia wrote qs as a replacement I believe.\nAs far as removing it, I'd be a :-1: on that, mainly because I am sure a lot of people rely on the nesting behavior. I know some of my apps do.\n. My apps requirements have changed these days, I need this feature now. :stuck_out_tongue_closed_eyes:\n. @whitlockjc @slifszyc can either of you provide a snippet that reproduces this everytime?\n. Think @yields made that last change, any thoughts?\n. Hmmmmm I am meh on this one... we'll see if anyone wants to chime in and tip the scale. :-)\n. There's a lot of extra stuff here besides XHR2 file stuff :-)\n. Check out the last few merges to master. Sorry, they were more straight forward to merge. Please open an issue if what's there doesn't work for you.\n. @defunctzombie see #314\nI don't feel this fix is how we should address the issue either. Thanks though.\n. Hmm... looks like it would work, just not sure about mucking around with the listeners like that is ideal. What about just next-ticking the internal callback.\nMaybe like:\njs\nself._callback = function(){\n  fn && process.nextTick(fn);\n};\nNot sure which one is less hacky.\n. What do you mean by \"can't open it\"? How are you trying?\n. Yeah, superagent has no timeout by default... if you need to set something, use .timeout(ms)\njs\nrequest\n.get('/')\n.timeout(30000)\n.end(callback);\n. I think that is something we would do for 2.0 (global plugins, NOT promises lol) but monkey-patching has basically been adopted for 1.0 and I don't want to confuse things. \nExample: https://github.com/segmentio/superagent-retry\n. But for adding it to the plugin list, just send a PR!\n. Please add a test, thanks!\n. Don't mind the browser tests... I am an idiot and have them half working right now on master.\n. Nice, thanks.\n. Can you just delete 0.9? We don't need to test it since 0.8 and 0.10 are out and stable.\n. Removed in 08ca866bb5a975bbacac116e53bfbced924fed06\n. This seems like more of a plugin thing. When I have time, I'll try and put up an example of how that could/should work.\n. @TooTallNate looks to be intentional - https://github.com/visionmedia/superagent/commit/b05f1984e1e352b3cad6ca372dafabc89310b140#diff-2de4b4329fc30ad75f3a88b650a1f577\n. Will do before all this attachment() stuff get's tagged. Leaving this PR open as a reminder.\n. Cool, make sense... Given how delicate the streaming is in superagent, I need to try this out for a bit. Can you make the 0.10.x test happy on travis-ci, looks upset about writing to /tmp or something?\n@visionmedia might have some more immediate thoughts since this problem has been around for a while.\n. @TooTallNate since you have had streaming + superagent on the brain more so than I have.... do you have any thoughts on this?\n. Nice\n. Nice. Wondering if @visionmedia will have a panic attack if you use util.inherits instead of __proto__? :-) \n. @TooTallNate tagged and published.\n. We can add it later. Thanks though!\n. After I finish this drink (okay and another). :beers: \n. Well... it was never added to the client implementation now that I look twice. :-/ \n. ... and I probably will not add it until we merge the two codebases a bit more now that component has grown up... so if you need it now, please send a PR.\n. LGTM... @jdesboeufs an empty string is a false value, so it covers that too.\n. Nice, is this where the browserify vs component debate starts? haha :-)\n. Yeah, if it's the one I think it is, it's because of the home brewed test framework in here and not the actual code. I started scraping all that for mocha a while back after you added the zuul stuff but then got busy and busier... I'll just update it for for this branch instead.\n. It's back!\n. Make sense, I'll test it out some more. Thanks!\n. I mean I guess that's what the RFC says... I am trying to consider how many people rely on this now... Decisions!\n. Going with the RFC (http://tools.ietf.org/html/rfc6265#section-8.5) as @prasunsultania thoughtfully included. Won't get a release for a couple days, but it will be in master.\n. Yeah, we already have a tough time keeping everything in sync with node + browser and component + browserify. I don't want to throw bower into the mix at that level. There is an open PR for adding a bower file, but the author has not addressed my concerns for keeping it as simple as possible, feel free to address those if you want bower support. https://github.com/visionmedia/superagent/pull/315\nI'll cherry pick the .use() fix.\nThanks!\n. mehhhhhhhhh seems like something a plugin should be able to do.\n. thanks\n. Hmm... If the site says it is redirecting but never sends the location header, there is not a lot we can do but I guess we could bubble up a better error rather than hitting the uncaught exception.\n. @katcipis sorry :-( I need to catch up on xhr2 again before deciding anything.\n. Ehhhhh, I don't think that is a good idea to add it. Browsers are really trying to limit usage of that option and hopefully one day it will be gone. Sorry!\n. Thanks, will go out later this week.\n. Need to this this fixed before next release -- https://github.com/bmeck/node-cookiejar/pull/17\n. We have to do this to prevent parsing of the empty response (e.g JSON.parse('')). See #280 \n. It's used as a getter for the agent after it's assigned. I agree with you, but I'm not personally up for breaking the feature as it's meant to be used today. \nWe can re-visit after the refactor and we have some more time on our hands to break things :-)\n. Yeah, let's do that to be on the safe side.\n. LGTM\n. I'll fix travis, not related to this PR.\n. Tonight :-)\n. Sorry! Had to fix the cookie issue breaking in master.\n. Alright, 0.18.1 is out now.\n. Couldn't you just do .redirects(0) as a way to not trust it?\n. This happens in node?\n. Release in 0.19.0\n. Sounds more like a nock bug no?\n. Think the underlying issue here is a little more involved. I need to look a little more.\n. Yeah, that or something like https://www.npmjs.org/package/superagent-promise. Defiantly not adding them into the library anytime soon (or at all).\n. cc: @aheckmann\n. yeah, that makes sense. It should be checked first. Let's also stop ignoring the error.\n. There are a couple issues regarding the handling of parse errors, let's make sure we address them.\n. 10-4, good point.\n. Yeah, this came up before in #307 and we decided to not include it for all those reasons mentioned above. Revert Revert :-)\n. @naman34 I'd like to tag some changes that have been merged to master but I do not want to personally release this particular change yet (really never). Even if we were to keep it, it needs a lot more work to even work somewhat predictably (doesn't support non-200 responses, doesn't support readyState so \"end\" won't even fire here, etc).\nLet's revisit later, work for you? I'll revert it if your cool with that.\n. Decision made... reverted for now. I'll drop a comment in this thread if/when it's added back.\n. Soooooon, probably this evening.\n. I don't mind supporting bower via simple the json file, but I just don't see the point and don't want to support bowerifying just to debowerify so it can work with something else. Sorry.\n. Were gonna remove XDomainRequest support. Thanks though!\n. @naomik it was fixed in https://github.com/visionmedia/superagent/pull/416\n. I suck... just realized 416 was browser only :-/\n. I'll add it tomorrow sometime, but if someone wants to send over a PR, I'll check it out first thing.\n. Give 0.20.0 a whirl. Had to bump it again for some other new changes, but the fix was here: https://github.com/visionmedia/superagent/commit/1aa99be27791ff25948630da8b56b7815466e9c4 \n. err - 0.21.0\n. Fixed by #416. Thanks though!\n. @jacwright that is true. However I feel like if we just swallow the error, then you might not know the server is returning something you did not expect.\n. Mehhhh not really a fan of typing \"thunkify\" all over. Maybe we should just have .end() return a promise and then the promise gang can be happy and the generator gang will be happy too since co works fine with generators.\n. Thanks for providing the links to the changes!\n. Makes sense, we'll leave it hanging out here until streams works a bit better.\n. Fixed in 473b957db6073705830b27a6ddda487c8ebd18e2\n. Blocked until we decide to revert XDomainRequests.\n. LGTM\n. Thanks for the heads up!\n. Hmm I don't think it's possible for fn to be undefined because we default it to noop here https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L762.\nCan you comment with a gist/snippet that reproduces?\n. Re-open if this is still an issue.\n. Thanks!\n. @timaschew Hmm... thinking it should actually be something like this so that we don't call self.callback(...) multiple times.\njs\nthis.on('end', function(){\n  var err, res;\n  try {\n    res = new Response(self);\n  } catch(e) {\n    err = new Error('Parser is unable to parse the response');\n    err.parse = true;\n    err.original = e;\n  }\n  self.callback(err, res);\n});\nAlso, since the HEAD check is already done here, we don't need to do it again: https://github.com/visionmedia/superagent/blob/master/lib/client.js#L305\nMeh?\n. Fixed in #480 - Thanks!\n. Already exists. Try the latest version. :-)\nhttps://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L655-L658\n. Fixed in #480 - Thanks!\n. Available in 0.20.0!\n. Sweet!\n. Available in 0.20.0!\n. You can use .agent(...) to set your own custom agent. \n. Give 0.21.0 a try - It addressed similar issues. Added a test to master just to make sure - https://github.com/visionmedia/superagent/commit/3238d7a2580f80a3a92415c023e641e59c95d3f2\n. Fixed in #480 - Thanks!\n. Thanks!\n. Thanks - should all be updated now. \n. That's up to how you implement your code. Not up to superagent... There are lots of modules that can assist with that, such as async.js as you mentioned.\n. Thanks - want to take a stab at fixing the node client too? (https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L902-L912)\n. @defunctzombie oh yeah that would be awesome... TBH I'm really just playing issue/pr cop lately, not using superagent enough right now to safely tear things about. Feel free too though :-)\n@pgn-vole good point.\n. But then self is undefined for the rest of the world?\n. @defunctzombie I think it was an old component thing.\n. 1.4.28? Were still on 0.20's :-) Maybe you have the wrong module? Please re-open if your still having problems.\n. Try 0.21.0 - reopen if it's still a problem. Thanks!\n. Fixed in d7c9d017645d0f6589169636f30f9da5b018e620\n. Thanks @hopkinsth!\n. I don't contribute enough to debate much. As long as the output is duo friendly, works for me. cc: @yields\n. As long as it's consumable with duo, merge away!\n. I think we are actually headed the direction of always passing err and res.\n. Nice, I can't remember how the emitter is implemented that were using but is there any chance a response listener could trigger an exception that will get tangled up with that catch there? Perhaps we should move it down where the callback is called? \n. LGTM!\n. Meh, IMO it's easy enough to use util.format.\n``` js\nvar fmt = require('util').format;\nvar url = '/posts/%s/comments/%s';\nrequest\n.get(fmt(baseURL, 11, 1))\n.end(callback);\n```\nOr, if that is not enough sugar for you... Write a plugin.\n``` js\nrequest\n.get('/posts/:post/comments/:comment')\n.use(params({ post: 11, comment: 1 })\n.end(callback);\nfunction params(data){\n  return function(request){\n    for (var key in data) {\n      request.url.replace(new RegExp(':' + key), data[key]);\n    }\n    return request;\n  };\n}\n``\n. [Yeppp](https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L524-L535).\n. Wow, thats crazy haha\n. Thanks for including the links. Makes PR's for the browser (which I have not been messing with lately) wayyyy easier!\n. +1 I think this makes the most sense. We have some breaking changes in master anyways. The fancy querystrings are too unusable by default when working with other services.\n. @defunctzombie you cool w/ this? Gonna cut a 1.0.0-something release if you are.\n. Agree w/ @defunctzombie. At this level I think it makes the most sense and is what most users expect, maybe make it more pluggable later like you mentioned.\n. @pornel I just added you and on that note, I think I'll stop pretending to contribute anymore, so can you remove me from the package? Thanks! :-)\n. Up to @hallas but I would personally like.certmethod over.camethod.\n. Can you move this require up with the rest of the module dependencies?\n. nitpick:new Error(\"Parse error\"). Do we really need this here?\n. We don't need this here anymore after #323 \n. why/index?\n. nitpick: maybe set error message fromhttp.STATUS_CODES` ( https://github.com/joyent/node/blob/master/lib/_http_server.js#L40)\n. Yup, code -> message.\n. ",
    "PeterDaveHello": "hmmm ... sorry to comment on an old issue, but I have a question, no offense, can't we just respect the environment variable http_proxy but can only rely on another package? Thanks.\n. ",
    "kornelski": "AFAIK node's own http request handling doesn't automagically pick the proxy, and superagent behaving differently could surprising, so an explicit superagent-proxy call seems like an OK solution to me. \n. By default there is no timeout (superagent will wait for the response forever). You set timeout with .timeout method, e.g. to wait up to 5 seconds: request.post('/foo').timeout(5000).end();\n. I've updated the docs. We do have Digest in browsers that support it http://visionmedia.github.io/superagent/#authentication\nIt's missing in Node though.\n. Somehow these commits are not in master. History of the current master branch looks like it was never added to component.json.\nIf you make a PR I don't mind adding necessary dependency to component.json, but keep in mind that we (the current maintainers) don't use component.json and don't have it as part of tests, so it's likely to rot again.\n. I don't recommend disabling HTTPS security. If you can't get a trusted certificate, then try creating your own CA and set it as trusted in superagent using .ca().\nhttp://stackoverflow.com/a/24749608/27009\n. Semi-serious, but you could put the broken-SSL endpoint behind CloudFlare CDN. They don't care about enforcing end-to-end security, but do enough to make superagent, etc. to believe it's secure.\nI feel your frustration, but you should be pressuring the broken-SSL-2-week-cert people to fix their security, rather than expecting superagent to weaken its. These days proper TLS certificates are free, can be obtained in minutes, and renewed entirely automatically. I'm not relenting, so that all people failing to make their TLS work are under pressure to fix their TLS rather than disable it so they can keep their broken implementations and outdated processes.. We don't have a solution to this yet. \n- The general idea is to have .tls() method with TLS-related options, but the current pull requests simply allow setting of any agent option, and I'm not comfortable with having an \"anything goes\" unlimited API. It'd help if someone came up with a whitelist of useful options.\n- rejectUnauthorized is not scary enough. It should be THIS_IS_TOTALLY_INSECURE_AND_WILL_EAT_BABIES = true or such.\n. Please never use NODE_TLS_REJECT_UNAUTHORIZED for anything, ever. It's a dangerous option that ruins security of all requests made by node.\nPlease either get a free certificate from Letsencrypt, or create your own certificate and CA.\n. The issue fixed previously was that progress event handler forces options request.\nBrowsers will also force options request if you set custom headers.\n. That is very surprising. Can you share code to reproduce this problem?\n. As mentioned in #236 the HTTP RFC doesn't require DELETE request to have a Content-Length, so I think nginx is being too picky here.\nHas anybody reported the issue to nginx? If the bug can be fixed in nginx I'd rather avoid adding a workaround superagent.\n. This is intentional and IMHO correct. \nThe brackets [] are only an informal convention used by some frameworks/servers, but not all environments use it. There are web servers that expect repeated keys without brackets:\nhttp://example.com/service?value=1&value=2&value=3\nIf superagent always added [] to arrays, then it would not be able to create a URL like the one above.\nThe current implementation supports both cases. If you'd like an array with [] in the name, then put [] in the name explicitly:\njs\nrequest.get('/').query({'interests[]': [300, 400]});\n. Can you provide a complete example with a publicly accessible URL that reproduces this problem? . WebSockets are a completely different protocol (the HTTP-like handshake is just a decoy). Handling WebSockets well, with logic that handles reconnections, stalled connections, bufferbloat, etc. requires amount of effort enough for a library on its own.\nI don't plan to add support for WebSockets (not even Server-Sent events which would be technically more compatible with HTTP).\n. This is intentional. You can use the new .ok(status => true) function to ignore errors.. Superagent 2.0 fixes handling of .then()\n. I can't reproduce this issue with any of the code posted in the thread.\nI suspect the double callback issue depends on specific HTTP headers and possibly timing of server response, so if you're reporting the issue, please include real, working public URLs that I can investigate.\n. We know 1.8 is buggy \u2014 we've already fixed those bugs in later versions. Especially 2.2 and later removed many double callback problems. Please upgrade.\n. Superagent 2.0.0 has this bug. The fix is in Superagent 2.2 or later.\nSupertest changes quite a lot about behavior of superagent, so if you have a bug that happens when running supertest, please report it to the supertest project.\n. Sorry, I can't reproduce this (superagent 3.3, Node 7.2 osx). Timeout is in our test suite.. If you run into this problem, please change:\nif (this.called) return console.warn('superagent: double callback bug');\n  this.called = true;\nto\njs  \n  if (this.called) return console.trace('superagent: double callback bug', this.called);\n  this.called = Error(\"previous trace\");\nand report the stack traces.. Yes, that looks like an important fix. This will not be added.\nSynchronous XHR is an awful mistake in the DOM API. We shouldn't be getting in the way of its deprecation and eventual removal.\n. I know sendBeacon is bad, but I still don't think it's a reason to allow sync XHR. No, no no. If you want to use a deprecated API, then use it directly.\n. That seems like a good idea for a plugin. I don't think it needs to be in core superagent.. You have to add fields one by one.. Agreed that this is misleading and unnecessarily jumping to conclusion.\nAs mentioned in https://github.com/visionmedia/superagent/pull/653#issuecomment-126088770 fixing this could be a breaking change. As bad as it is, there are applications that check for this particular error.\nI suggest keeping API backwards compatible, but extending the message to add something like \"or it could be aborted connection, user-agent offline, etc.\"\n. For 1.x I'm going to change the message - #802\nFor 2.x I'm happy to change it to \"transport error\". What should the error message say?\n. Since I've changed the error message I haven't got any complaints, so I'm not going to change implementation details further to avoid unnecessary churn.. Unparseable input is now returned as a property of the error.\n. I have some concerns about the PR in its current state, and I'm waiting for a response from @olalonde, but in general I agree that's a good thing to implement.\n. Agreed.\n. I'm OK with switching to query for the shorthand function (I'm assuming explicit .get().send() would continue to work for those who really want a body).. I think that's fixed in #1228. Options requests are fully supported as far as superagent is concerned.\nNote however that browsers intentionally have a lot of restrictions regarding HTTP features, and may not permit you to make OPTIONS request unless you make your server explicitly allow it in preflight request.\n. qs almost doubles size of superagent.js, so it's not so good for the browser version. Currently we still use our own thing in the browser, but since v1.5 it's closer to what Node does.\n. Now on master the response event should give you this information, and you can call req.abort() in that callback if needed.\n. .pipe() does not return a superagent request. Save the superagent reference before calling .pipe().\n. You get the abort event, and no more. It stops downloading further data.. @misaunde The filename is sent as part of content-disposition header inside multipart body. Whether it's used on the server or not depends entirely on the library you use to parse multipart requests.. npm version contains a pre-compiled superagent.js file.\nWe don't have a package for bower, so bower only gets link to the repository, which does not have any precompiled files by design.\n. In #1302 request.agent() creates a reusable copy of superagent and sets default settings.. That's an old issue. It's probably been fixed (we have mapping of extensions to mime types, plus we now support options object for attach).. That's an old issue. Parsing has been refactored again. It's still a bit wonky, but there's .buffer(false) and req.pipe().. No, end is the end.. It does the latter.\nBTW: you can use whatever serialization you want using your own code/library, and then set the query as a string.\n. This is no longer compatible, so I'm going to close this.. I agree that it's useful to be able to set a default set of plugins once for all requests in an application.\nHowever, I'm not fond of mutating a globally shared superagent module, as it could cause problems for 3rd party libraries that expected to use a vanilla module, and it creates state that can leak across unit tests.\nSo I think a good solution would be if superagent supported some sort of subclassing where a \"global\" .use()/.extend() creates a new instance of superagent module preconfigured with the plugin.\nSo you'd create: my_superagent.js:\nmodule.exports = require('superagent').use(require('plugin'));\nand require('superagent') would remain unmodified, but require('./my_superagent') would give you superagent with the plugin.\nWDYT?\n. Done in #1302 . This issue has been closed, because it's not a bug in superagent. Have you tried reporting this bug to react-native authors?\n. @mienaikoe Sorry, this bug is about react-native only.\nBut in your comment you say \"the response is text/json, and I'm using a plain get request.\" \u2014 try application/json?\n. This has been fixed by another PR.\n. Try this:\njs\nrequire('superagent').parse['put the wrong type here'] = JSON.parse;\n. @scsper is there a consensus what the error message should say?\n. The reworded message has been in superagent for a while now. I haven't renamed  crossDomainError, but since the message is generic I think it's not causing confusion any more.. The tests are failing: Error: InvalidStateError: DOM Exception 11: An attempt was made to use an object that is not, or is no longer, usable. (https://jmxihwatjo.localtunnel.me/__zuul/test-bundle.js:509)\n. These tests have failed:\nhttps://travis-ci.org/visionmedia/superagent/jobs/96181019#L377\nhttps://travis-ci.org/visionmedia/superagent/jobs/96181019#L384\nhttps://travis-ci.org/visionmedia/superagent/jobs/96181019#L389\nhttps://travis-ci.org/visionmedia/superagent/jobs/96181019#L405\nhttps://travis-ci.org/visionmedia/superagent/jobs/96181019#L414\nhttps://travis-ci.org/visionmedia/superagent/jobs/96181019#L441\nThis code passes in some browsers, so it may be browser-specific.\n. Mixing of .send() and .attach() doesn't work. The current version warns about it.. I think they should. Right now it's a coded as it was a feature, but probably not a good one.\n. 1. If you need to, you can have the hello[] keys by using exactly that name in the input, but it wouldn't work the other way \u2014 if superagent always added [] then it wouldn't be compatible with servers that require []-less arguments.\n2. Node already does it this way, and superagent aims to be identical in browser and node.\n. This brings client-side implementation in line with the server-side one (which supports arrays already). LGTM @focusaurus?\n. I like this implementation better (node impl is recursive as well). I'm going to take this code, and tests from the other PR. OK?\n.  #716 added rawResponse to the error. Does that solve your problem?\n. I'll be released soon\n. Agreed this is a problem. Duplicate of  #484\n. No, superagent is not best suited for this. Most of the functionality it adds is based on assumption that resources have a finite size.\n. It allows arbitrary options, and tls options can override all other properties, e.g. tls({host:'xxx'}), which doesn't seem right. I'd prefer an API that is limited to only specific useful whitelisted options.\n. This will not be merged in the current state, because it allows change of arbitrary options on the agent, and we don't want to support everything, just properties we know are useful and have tests for.\n- Please make it only accept whitelist of properties (without rejectUnauthorized #832)\n- Please add tests for the properties accepted\n- Please add a dummy function in browser implementation\n. Closed in favor of #1057\nIf you'd like to add more options, see https://github.com/visionmedia/superagent/pull/681#issuecomment-209345788\n. The .end() callback is called after piping has ended and is no longer possible.\nYou can't use both .end() and .pipe(). Only one of them is possible at a time.\n. When you call .end() then superagent takes over response stream pipe, collects all of its data in res.body, and waits for the pipe to finish sending data.\nThe callback in .end() is called after response stream pipe has finished and closed. At this point it's guaranteed that it's not possible to pipe anything anymore, because all pipes have ended and closed.\nIf you want to send data from the end callback, you must use expressJsResponse.end(superagentResponse.body), because at this point in time res.body is the only place where the data exists.\n. cc #1188. We've fixed a lot of these. We do have statusCode now, too. Please file bugs if you find more undocumented differences.. Yes, if you run:\njs\nconst agent = new https.Agent(options);\n^ with https in there, you're saying you want HTTPS-only agent and you refuse to handle unsafe HTTP.\nSo, just don't do that. Use superagent.agent().\n. If you're making request in the browser, the OPTIONS request (called preflight) is done by the browser, not by superagent. Superagent can't do anything about it. Superagent can't even detect when it's happening, and that's by design.  See CORS:\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS\nWhen you make a request to another origin (URL with a different host/port/protocol than the page, i.e. generally absolute URL instead of a relative path) you have to deal with CORS. This is mandatory for security, and you'll most likely need to implement appropriate response on the server. There are exceptions for \"simple\" GET requests, but POSTing or GET with custom HTTP headers will make browser send another OPTIONS request first to check if these extra features are allowed by the server.\n. I think we've added that a while go.\n. Sorry, I did not realize it's was a breaking change (IIRC arrays weren't supported previously and you'd get various accidental results). superagent intends to follow semver. \nThe current supported version is 3, so we're past a couple of semver bumps already, so this change became permanent and I recommend updating your code to work with it. You can stringify your arrays before passing them to superagent if you want to keep the old behavior.\nIt's intentional that [] is not added automatically. This syntax is an informal convention used by some server-side frameworks, but not all. Adding [] would prevent superagent from being able to send ?a=1&a=2&a=3. OTOH you can use \njs\nreq.query({\n   \"a[]\": [1,2,3]\n}) \nto have the a[] syntax, so this way superagent supports both ways.\n. This bug is about running examples/simple-get.js, not post requests, and not Redis.\n\"Not Found\" error is very generic and can correctly happen in lots of situations. You should check whether you're calling correct URL and whether your server allows POST for that url. \n. Thanks\n. As far as I know HTTP RFC does not forbid DELETE requests to have a body (even GET requests can have one!), so forcing 0-length body wouldn't be appropriate.\nSorry @soyuka. That's a well-written pull request, but I think it's not a behavior the library should have.\n. That clause is for OPTIONS (in that case I wouldn't be opposed to setting content-length if nodejs doesn't do that already).\nFor DELETE I see:\n\nA payload within a DELETE request message has no defined semantics;\n   sending a payload body on a DELETE request might cause some existing\n   implementations to reject the request.\n. The code looks fine. Can you be very specific about the problem and supply diagnostic information?. That JSON is not from superagent, so you need to file a bug with whoever manages the service you're connecting to.. Well done. Thank you.\n. I've suggested using global Promise constructor.\n- It's only few lines of code, so I think it's not bloating superagent.\n- It doesn't require superagent to ship with a promise library.\n\nIs that not satisfactory?\n. It would not require node 0.12, but it would require a polyfill (e.g. you'd need babel or require('es6-promise').polyfill() on the IE6 of node versions).\n. @matthewmueller Where do you take that 17KB from? I think superagent bundling promises implementation would be a mistake, and a serious downside. Where necessary, I already have a promise polyfill in my code, and I don't want a second one. It's wasteful and could cause bugs (I've ran into such problems when libraries had their own copies of the Q library, but Q breaks in subtle ways if there's more than one copy).\nI'm assuming that nobody would be interested in using the .then() method without using promises in their code, so it's safe to assume they must have a promise library already.\n. es6-promise currently overwrites native promise implementation due to (IMHO tiny and irrelevant) bugs in v8, so bundling of it in superagent would cause negative side-effects.\nco is an interesting example, but not a good example of a case where promises are not available \u2014 yield and Promise are both part of ES6. Babel and Traceur compilers have Promise polyfills. Also versions of node that support yield also support Promises.\n. I think you're wrongly assuming that you need to implement promises. The way I see it it's something you integrate with, not something you provide.\nBundling promises with superagent would be like bundling v8 with superagent, in case somebody wants to use the JavaScript library, but doesn't want to install a JavaScript VM.\n. @kahnjw I think the concept of thenables exists primary for interoperability between Promise-compliant libraries.\nIt is possible to convert thenable to a fully-functional Promise, but it isn't convenient, and superagent's implementation is not functional enough to start a promise chain without explicit conversion.\nI try to avoid thenables as much as I can, because they don't give guarantees that Promises have (e.g. that callbacks are run on the next tick) and can cause bugs. \nIn Superagent 0.13 case this happens to work thanks to casting:\ndoSomethingAsync().then(() => request.get()).then(res => nextStep());\nbut if you refactor the code to swap the first two functions, it'll unexpectedly break in a weird way:\nrequest.get().then(res => doSomethingAsync()).then(()=> nextStep());\nand while it's possible to fix it with an explicit Promise.resolve(), this isn't a usual thing to do in Promise-based code, and extra parenthesis are undesirable around fluent interfaces.\n. The global Promise is now part of ES6, so it isn't any worse than relying on global Array in ES5.\nAnd the desire for it is to have a robust API without footguns. The faux promise stopgap thing:\n- fails to support chaining\n- fails to handle exceptions thrown from callbacks\n- fails to defer execution to the next tick\n- fails to handle optional callbacks\n- etc etc.\nI suppose you're not \"sold\" on Promises, but please understand that for somebody who's using them heavily Superagent's faux solution is not only insufficient, but even harmful. \nv0.12 used without some glue code would clearly fail with \"then is undefined\", but v0.13 is now worst of the both worlds: without diligent wrapping in Promise.resolve() it may appear to work, but won't: exceptions will escape, callbacks won't be called in the right tick, and values won't be passed down the chain.\n. It doesn't have to break compatibility if the faux solution is used as a fallback.\n. This is fixed in 2.0.0\n. No, .end() is the old world. Don't use it. .then() is a replacement for .end().\n. I agree returning promise from end() would be better.\nI also think it should cache the promise, so that var tmp = superagent.get(); tmp.then(); tmp.then() doesn't try to launch the request again.\n. BTW: the code for both node and browser happens to be identical. Do you have a preferred way for sharing/reusing it?\n. We have .set('foo','bar') and .set({foo:'bar'}), so I think .field could be changed to behave the same.\n. Correct, we don't have that option. In the browser version we use a custom minimal serialization instead of the full qs library, so to support customization we'd have to bundle qs in the browser as well. Perhaps the overhead is not too big, but I'm not sure if it's common enough use-case.\nCurrently you can convert object to string in your own code, using your own rules, and set query as a string.\n. Thank you for the PR. The functionality is useful, but I'm worried about exposing a shared global field. I think it's better handled by https://www.npmjs.com/package/superagent-defaults\n. The code is a bit hacky :/\nHas this bug been reported to Cordova? Is that a problem they can't fix on their end?\n. Would this help? #681 \n. Thanks for the PR. Sorry for the late response. The change looks OK. Could you rebase it?\n. Thank you.\n. We don't support IE8, and ES5 allows reserved words as property names, so it's all good.\n. No longer there\n. I think the solution is to never set content-type manually for multipart.\n. js\nsuperagent.post(url)\n   .attach('field_name', file_object) // file_object can be File or Blob\n   .then(result => {}) // .end() works too\n. What about v2.2?\n. Can you provide more information? The attach functions don't set up any callbacks, so there may be other options/server response headers that cause it.. Only if you can reproduce the bug without supertest involved. Otherwise report the problem to supertest.. I think the buffering situation was fixed in 2.3. We've decided to rename the other function to serialize()\n. We use new form-data now\n. In 2.0.0. It uses form-data 1.0.0-rc4\n. Thank you\n. If reading XHR from global rather than window is all that's needed then I don't mind supporting tvOS. If it's more involved then we'd need to figure out how to test it.\n. Thank you for the PR. It's a useful change.\n1. I think the code could be simplified by checking parts.length from parts = split('=').\n2. The change from \"undefined\" to undefined is good, but it may be a breaking change, so it'll need a major version bump.\n. It's an interesting bug, and potentially very annoying gotcha, so we definitely should fix it. I'm not familiar with the code enough myself to be sure what would be an ideal solution.\nHowever, flags like that are a shared mutable state, and code that modifies query string is now duplicated. So while this fixes this particular bug, I'm afraid it could be easily broken later (e.g. if qs serialization is updated in end() but not in write()).\n. OK, it's better to fix this. We'll worry about a stateful property later.\n. I'm not sure if that's something that was ever intended to work. There are lots of stateful properties within the request object that could go wrong like that.\nYou'll be better off writing a function that configures a new request from scratch each time (the cost of doing this is small).\n. .then is fixed in 2.0\n. Agreed we shouldn't be causing any TypeErrors. Some callback-related bugs were fixed recently. Can you re-test with the latest version?\n. Sorry, that's an old issue. From the log I don't see a problem, and I don't know about OcrEio API.. I'm assuming this was due to browsers not allowing it. Please re-open if it affects node.\n. Ah, ok. Supertest is a separate codebase. Can you report it in that project?\n. Thanks for the pull request. That's a useful functionality to have.\nHow do you distinguish between upload and download progress? Won't it confuse existing code that posts something and then expects to track download progress?\nI don't see lengthComputable changed anywhere. \nAre you certain Content-Length is always available?\n. Great, thank you!\n. They are now, if you use promises. Thank you. This is very well done pull request!\nThis workaround, in a slightly different version, has been merged in already.\n. The webapp team at Financial Times is using superagent heavily, and we already maintain our own extensions to it. We're interested in maintaining this project.\n. :ok_hand: \n. I'm not a fan of bower, but if that's all that's needed for it then I don't mind. @focusaurus?\n. OK, let's give Bower a chance\n. Sorry, I haven't noticed you've updated history, so I've made a conflicting commit.\n. (I've used git log --format='%s (%an)')\n. @focusaurus by bundled files do you mean superagent.js built with the Makefile?\n. @defunctzombie I've tagged v1.5.0. If you're happy with it, could you npm publish it?\n. Can we get npm access, or assistance in publishing this release? @defunctzombie @gjohnson @travisjeffery?\n. Thanks! I'm kornel on npm.\n. Done! Thanks everyone :)\n. I'm noticing a pattern of errors with implicit expectations of state change on end(), so eventually we should look into making it an explicit state machine to solve all such cases.\nBut this as a quick fix seems sensible.\n. Did you try v1.5.0? \n. Please try 1.5.0 or master to see if the problem has been fixed already. \n. Yes, we support progress (now in node too #771).\nThe documentation needs an update.\n. ev.type sounds good to me. It'll be great if you make a PR.\n. booleans don't make good APIs, so let's go for direction:'upload'/direction:'download'.\n. I'm not sure, but it looks like unintentional inconsistency. The guiding principle is that superagent should have the same API on client and server.\n. I'd rather avoid breaking if possible. How about adding parseRequest, parseResponse accordingly?\n. Yes, that's what I had in mind: create new unambiguous methods for parsing that work the same client- and server-side, and leave the old confusing one for backwards compatibility and eventually remove the old one in 2.x.\nI'm not entirely sure about parseRequest and parseResponse names though.\nAnother approach could be to add arguments to the existing parse to disambiguate? req.parse({response:fn, request:fn})? i.e. parse(fn) used with only a callback would continue behave as it does currently (with deprecation notice?), but when used with an options object, it would configure parsing of request body or response body according to the options.\n. The term serialize is used in Superagent's codebase, so for 2.0 I suggest:\n- parse(fn) for parsing response body only (this is a breaking change)\n- serialize(fn) for generating data to send in the request\n. Done, ekhm, twice :)\nhttps://github.com/visionmedia/superagent/blob/master/package.json#L6\nThanks everyone!\n. into master? Eek. I'm not sure about that.\n. My impression is that the gh-pages branch is messier and has auto-generated files. That's fine when it's used to power the website behind the scenes, but not so good in the visible part of the repository.\nI think it'd be better to cherry-pick or even copy&paste the few changes to files that are already on master, and only keep merging master to gh-pages.\n. edit: hmm, tests pass :)\n. Can you show response from you backend, e.g. via curl -i?\n. application/x-json is not JSON, but a made-up non-standard type. Please use application/json or application/something+json only.\n. Try \nsuperagent.get(url)\n  .parse(superagent.parse['application/json'])\n  .then(response => \u2026)\n. This has been fixed around version 1.8. I've restarted tests (you can do that by clicking details, then failed test, and a refresh button in top right)\n. See https://www.npmjs.com/package/superagent-defaults\n. superagent-defaults is still the best solution.\nI assume that when people want global, they mean configuring truly globally that every require('superagent') gives you pre-configured instance, but I'm not planning to add anything like this, because it would break libraries (if superagent is a dependency of your dependency, you'd be unexpectedly changing someone else's requests).\n. Does it work apart from this?\n. I've updated the readme that it's required https://github.com/visionmedia/superagent/commit/11abecbe7272181b7c4f3b4a2f749caaee7631b1\n. I'm going to close it as wontfix:\nWe require FormData polyfill for IE9, as noted in the README. This requirement won't change. \nIf you still need reliable IE9 support and FormData polyfills aren't good enough, then use JSON or real  HTML forms instead.\n. Blobs are used to upload files via JS, which IE9 does not support. If you get errors about Blob being undefined, it means your polyfill is not compatible with IE9.. I don't think octet-stream is appropriate, because the default encoding varies by MIME type, e.g. JSON is utf8 by default. To make things worse some MIME specs are out of touch with reality (e.g. latin1 for text/* IIRC), and in the browser world anything but utf8 is asking for trouble.\nSo I think it should be limited to using encoding that is explicitly specified, and utf8 otherwise. PR welcome.\n. I see that in general there could be different approaches to handling files without any encoding specified, but the example URL you've mentioned clearly specifies that it's a UTF-8 file:\ncurl -I http://i1.theportalwiki.net/img/6/6b/Portal2_japanese.txt\nHTTP/1.1 200 OK\nDate: Wed, 30 Dec 2015 14:06:38 GMT\nContent-Type: text/plain; charset=utf-8\nSo handling it as UTF-8 is perfectly correct in that case. If that file is not really a UTF-8 plain text file, it's the fault of the server for sending wrong information.\n. I'm going to leave this bug open to add support for encoding=\"\" argument in MIME types.\nAs for working around incorrect server response for that that URL, I don't think it's possible in node version of superagent. In the browser version you could set xhr.responseType to arraybuffer and convert encoding yourself.\n. You can do this, or you can rely on the closure and use the file variable directly. Another option is to use .bind() on a function if the function was defined elsewhere.\n. I'm not sure what's going on, because webpack should have picked the client-side version that doesn't try to require a JSON file. \nIt seems to be compiling the nodejs version. Were you intending to build a file for nodejs?\n. @adambro it looks like you're building node-only version for web target. You should compile lib/client.js, which doesn't use mime-db.\nedit: ah, nope. That's the old form version in 1.8b1. Fixed in 1.8b2\n. Thanks for the PR @vicanso. \nLGTM. @focusaurus?\n. Agreed we should reduce duplication. \n. Good job on that!\n. Thank you for the PR.\nWhat kind of problem are you trying to solve? If the server has a self-signed certificate, wouldn't it be safer to have an option whitelist that certificate or its self-signed CA?\nIf it's aimed for testing on localhost, should it be limited to local domains only? Or work only if NODE_ENV=development?\nIs the name consistent with any existing node API? \"SSL\" is an old name for TLS, and I'd prefer a more dramatic name for this option, as it's not just disabling \"strictness\", but completely disables all protection against MITM attackers decrypting and manipulating the content.\nThere were other requests for generic TLS options, #681 #737 #685 #197. Do you have suggestion how API for other TLS options should look like?\n. Note that with rejectUnauthorized:false in Node allows MITM attacks, which means an attacker can decrypt and maliciously modify your traffic. \nSo if you have hosts that need confidentiality of communication you must not use rejectUnauthorized:false.\nIt's not \"just a bit less secure\". It's plainly insecure. The security is analogous to a tank with a hatch open. Still feels super secure having so much armor, but actually anybody can enter and blow it up from the inside.\nCurrently in superagent you can secure communication with a host that has a self-signed certificate by using the .ca() method. Create your own CA and issue your own certificates using it (e.g. Charles proxy can do it for you. In OS X keychain app has a \"wizard\" to generate these as well), and set that CA's cert as trusted in superagent.\n. If you say PKI is rubbish, you still need to distinguish between two very different scenarios:\n1. You don't verify identity at all, and you're happy to send the data to an attacker presenting any certificate whatsoever. This is what rejectUnauthorized does, and it kills confidentiality, because you allow attackers to intercept and decrypt the traffic.\n2. You verify identity using your own CA certificate to ensure you reject attackers' unauthorized certificates, so that you allow decryption only by parties you trust. This is what .ca() option does.\nCurrently superagent supports option 2, but does not allow the insecure and irresponsible option 1.\n. MITM attacks are not very difficult, e.g. can be done on public Wi-Fi (or by spoofing a public Wi-Fi hotspot your computer has remembered).\nSSH does not behave like rejectUnauthorized:false. It verifies identity after first connection (and on the first connection it is insecure unless you verify the server identity yourself).\nYou've mentioned localhost. This is an exception \u2014 I've asked about it in https://github.com/visionmedia/superagent/pull/832#issuecomment-169758461 but you haven't answered my questions, and argued about PKI/MITM in general.\n. Your concern may be \"I need this, and here's the shortest path to get my stuff done\", but my concern is that I'll have to maintain that code. I'm worried that exposing all agent options will allow somebody to use options we didn't intend to support, and we don't have tests for. If we break someone's app, we'll be blamed for it.\nProposed names of options for disabling certificate validation IMHO don't make it clear enough that they allow the traffic to be decrypted and modified by attackers. I do think that having a poorly named option that disables TLS security for all connections to all hosts, even in production, is irresponsible. Even if you know not to use it outside localhost, others may not and think that some \"non-strct SSL\" is still secure enough to go through public networks. \nI need to understand motivations behind this to decide whether that's a quick hack or feature I want to support, and see whether maybe we can come up with an alternative better solution that still solves your problem.\nCurrently I think I'd be OK with having an option that disables SSL security for localhost only (or hosts on local network, but that's a bit trickier to implement), and/or an option with a scary name that disables certificate validation only if NODE_ENV=development, so that if it's accidentally left in it won't make real connections vulnerable.\n. Agreed that's a protocol violation and superagent definitely shouldn't be doing this. Could you help by writing a test or maybe fixing the issue?\n. I've checked this. Superagent doesn't re-send POST, but changes request method to GET on 301, 302 and 303. I think that's fine, and follows the current HTTP RFC:\n\nNote: For historical reasons, a user agent MAY change the request\n  method from POST to GET for the subsequent request.  If this\n  behavior is undesired, the 307 (Temporary Redirect) status code\n  can be used instead.\n. RFC 2616 has been obsoleted and should not be used as a reference any more. The current HTTP RFC clarified this, and we follow the current recommended behavior for HTTP.\n. Use .on('redirect', callback). Bodies of redirect responses are supposed to be only a fallback for clients that don't support redirects, so we don't parse them.. Superagent doesn't have raw bytes of the response. It uses Node's request, which is higher-level than that. For that I'd recommend wireshark, tcpdump, etc.\n\nI don't remember off top of my head whether we set headers object, but it might be there.. Thanks\n. I'm unable to reproduce. You get an error when server responds with status 401. If the server rejects the password, but only prints a message without setting status code, then superagent won't know that it's an error.\n. I think it's useful to sort query string, but there are problems with this implementation:\n- AFAIK it doesn't give any option to have a custom non-sorted order. If someone has settled on another order already, or has a server sensitive to the order, it may be problematic.\n- It relies on browser sorting being stable. There's a convention of setting ?foo[]=1&foo[]=2 to represent an array, and order of these identical keys has to be preserved.\nI suggest limiting sort by default to a case of using JSON to set the qs, on the basis that order of keys in JSON is not supposed to matter, i.e. sort on .query({foo:1,bar:2}), but not .query(\"foo=1&bar=2\").\nFull sorting of all query strings could perhaps be done in a plugin?\n. Closing in favor of sortQuery PR\n. I think it's been fixed in 2.3.0\n. It might be a flaky VM or an actual incompatibility caught by the test. I'm going to restart the test later to see.\n. It has worked with Zuul 3.\n. Yeah, we could be smarter about this. Would you like to make a PR for it?\n. You can run node tests with make test and browser tests locally with make test-browser-local\n. @jisaacks if IE doesn't support it, it's IE's problem. You can skip the test there (see FormData check few lines above)\n. Thank you\n. You can run tests without saucelabs with make test-browser-local\n. Yeah, travis tests are sometimes a bit flaky and need restarting.\n. The build passes now (travis is flaky)\n. LGTM. @focusaurus\n. Superagent supports only one level of nesting, so you'll have to create flattened keys yourself, e.g.\njs\n.query({\n    a: '1',\n    'b[innerA]': '2',\n    'b[innerB]': '3',\n})\n. I agree this does change behavior indeed. I'm not sure if we can do anything about this? Reverting this change now will be another backwards-compatibility break.\n. If we bump major semver #854, we could as well upgrade thenable to a native Promise API.\n. You must start with request[http_method], so nothing works until you do request.get() for example.\n. I agree with @focusaurus on Babel. Right now it feels unnecessary complication to me. I do like ES6, so perhaps we can revisit that decision later (e.g. when non-transpiled ES6 becomes viable in browsers and/or node).\n. If you mean complete removal of .then(), then I'm against it. While the current implementation is bad, complete removal is an unnecessary compatibility break. If we add promisification to .end(), we can make .then() call .end(). for backwards compatibility.\n. @jpodwys speaking of breaking, I've just released 1.8.0 as beta. It has some internal changes to reduce code duplication, and we hope it won't break anything, but we'd like feedback on that.\n. 1.8 changes headers again, but the good news is that it makes it consistent in browser and node. #891 \n. Last time I've looked at version stats, there still was a lot (like 1/3rd IIRC) of users on 0.x. I expect move from 1.x to 2.x to take a long time. \nOTOH we're not planning any major rewrites (the sharing of code mostly moves existing functions to one file), and the backwards compatibility API breaks we currently have in the pipeline are mostly around edge cases.\n. AFAIK toLowerCase is correct, because header names are case insensitive https://tools.ietf.org/html/rfc7230#section-3.2 (and in HTTP/2 they're not even case-preserving).\nIt may be a common pattern that we compute some data lazily in .end(). Perhaps for plugins we could add a method to precompute-data-as-if-end-happened?\n. @focusaurus should we start merging in breaking changes?\n. I haven't used component. AFAIK it's currently broken, so I wouldn't mind dropping it.\nI'm OK with supporting bower in a minimal fashion - i.e. just bower.json without precompiled files polluting the repository. \n. Ouch. I it was not supposed to be latest, I forgot to tag it as next.\nOTOH we haven't added anything unstable recently and haven't got reports of sky falling, so maybe we should just release it as stable?\n. And it's done!\nBig thanks to everyone who contributed.\n. Since #1302 you can set a plugin for all requests from an agent.. I can't fix this without more information. Please don't +1, as this does not help at all.\nPlease submit unit tests or a full dump of server and client HTTP headers.\n. Thanks for the test case with dfzq.com.cn. That helped me diagnose and fix the problem.\n. Published!\n. That sounds like a sensible usage. Perhaps we can make it work by translating such .send() into .field() calls?\n. Fixed in 1.7.1\n. Thank you. We've got this fixed now.\n. Error is special in JS\u2014it's not a usual constructor, but a function returning an object, so it can't be truly subclassed.\nIf detecting of all superagent errors is needed, I'd suggest adding a property consistently.\n. Good idea!\nI think it'd also be valuable to distinguish between programmer errors and network errors, i.e. cases where the library is used incorrectly (and the error is in the code), and cases where the error is due to runtime conditions (server down, device offline, etc.).\n. Yes, please\n. Superagent by itself doesn't have such specific functionality. Our recommendation is to wrap creation of Request into something higher-level, e.g.\n``js\nfunction _requestForOffset(path, offset) {\n     return superagent.get(https://api.example.com/${path}`).query({offset});\n}\nasync function getAllPages() {\n    const limit = 50;\n    let offset = 0, total;\n    do {\n        const response = await _requestForOffset(\"listings/active\", offset);\n        total = response.body.total;\n        offset += limit;\n    } \n    while(offset < total);\n}\n``. @fabien can you check which version exactly breaks it? 1.7.2 or 1.8 beta?\n. Thanks\n. We've changed a few things around this functionality, so it could have been fixed. Please reopen if you find this happening.\n. We've added Blob support on the client #888 \n. I don't see it as related to content type at all. You could ask fortext/plainin aBufferif you wanted bytes instead of a string. And on client-side you may wantimage/pngasBloborArrayBuffer` \u2014 and there's nothing PNG-specific in an ArrayBuffer.\n. To get binary data in Node:\njs\nrequest.get(\u2026)\n    .buffer(true).parse(superagent.parse.image)\n    .then(res => res.body). In the latest version you can use superagent.parse['application/octet-stream'], but .image is shorter to write, and both do the same thing :). This should be fixed in 3.1+. Great! Maybe this will help with the travis flakyness.\n. This is a breaking change, and it has inconsistent behaviour between client and the server.\n. Returning of unparsed string is dangerous, e.g. let's say the server used to return {accessDenied: false} or Forbidden!\njs\n.end(err, res) {\n   if (err || res.body.accessDenied) return;\n   allowAccess();\n}\nwith this change res.body would be \"Forbidden!\" and res.body.accessDenied would be undefined and evaluate to falsy value, causing a security issue.\n. @yunda you can from the error object, that's what rawResponse was for. Other properties can be added to the error.\n. @yunda now there's err.statusCode. Do you need to read other properties during an error?\n. I'm closing in favor of err.rawResponse and err.statusCode, which I think are safer and more backwards-compatible.\n. Should be fixed now\n. Thank you! \n. I'm going to rebase it to remove unnecessary commits.\n. Perfect. \nI've given travis a kick to ensure tests pass.\n. res.successful is much longer and typo-prone than res.ok. \nI'm not sure other statuses are checked commonly enough to need sugar. Redirects are simply followed most of the time. In the browser the 304 is handled transparently. Usually if you get 400, your app, or its user, can't do anything more about it than about 500 or 503. \n. For testing, perhaps it could be added to https://www.npmjs.com/package/should-http? \nI'm not convinced it's important for superagent, so I'm closing this issue.\n. Can Firefox extensions solve that problem by setting global XHR before including superagent?\n. Thanks for the solution\n. Great!\n. As far as HTTP is concerned DELETE can contain a body, but the request is for the URI, and the body is not supposed to be semantically meaningful.\n. The tests are failing. You can run them locally with make test-browser-local\n. I'm little worried that you had to change a test to make it work. What was missing before? Do I understand correctly that now the server has to respond with 401 status first to make the browser to send the authorization header?\n. Supporting other auth schemes is useful, but OTOH:\n- it's a performance regression \u2014\u00a0it's common to have HTTP APIs that just expect the basic auth header to be there, and can be called in one request\n-  this is a breaking change \u2014 if someone implemented basic auth API lazily (like our tests) just by checking the authorization header, it'll stop working\nCould a hybrid approach work? e.g. if you set Basic auth header and give username/pass to the browser, will the browser switch to a more advanced scheme if needed?\n. Yes, sounds like a good idea. Let's go for just {type:'auto'} and {type:'basic'}, as booleans make calls harder to read.\n. :+1: \n. Thank you for the pull request. That's a useful functionality.\nHowever, the API for this is a hack. The .set method is for HTTP request headers, but this isn't a header, and isn't a property of the request.\nWe try to keep browser and nodejs API as close as possible, and some users have asked for Buffer support as well. Perhaps there could be a single API for enabling Buffer/ArrayBuffer?\n. Yes, definitely a different method has to be used. I don't have an idea for a good method name for it right now (and if/how it should support Blob as well). \nMaybe someone else can suggest?\n. Setting this.responseType, which is same as the method name, will break. Please change it to _responseType. Please also add a test.\n. Yeah, that doesn't look like a successful rebase. Try git rebase -i origin/master and squash/fixup unnecessary commits.\nAlternatively pull and checkout master, git merge --squash your branch, and make PR from that instead.\n. Great! Thank you @iambumblehead \n. It's resolved in dbc5d6f8590056c745e0ad9671c7ed6878362e60\nPlease always use the latest version (currently 2.2)\n. neat\n. Good stuff!\n. BTW, I've noticed a bug (that was there before) \u2014 .set('Foo').unset('fOO') will remove the header from ._header, but not .header.\n. We've had some reports of Webpack picking incompatible type of module when building #672 #827 \nAre you using Webpack as well?\n. Right, so we don't know what the risk may be. I believe in release early and often.\nI think the fact sharing is only 20% done is good, because if it turns out to be breaking, we'll know before 80% of the work is done (and we can change the course of action).\n. I think we're ready to release 1.8.\n- we've learned that we've broken plugins in 1.7 too, so it's a problem not specific to request base refactorings (we'll need to provide a stable plugin api)\n- there are known problems with header lowercasing in 1.7 that are fixed in 1.8\nAfter that, should we start merging PRs for 2.0?\n. Done\n. We don't have buffer output yet: #871\n. Sorry, correction. We do have buffer output if Content-Type of the response is image/-something. In that case response.body will be a buffer.\nIf MIME type is not right, it gets complicated: #950 \n. Thank you for the PR. I've merged it, but also allowed content-length header to be missing in order to support gzipped chunked encoding.\n. Thanks\n. We specify in package.json:\njs\n \"browser\": {\n    \"./lib/node/index.js\": \"./lib/client.js\",\n    \"emitter\": \"component-emitter\",\n    \"reduce\": \"reduce-component\",\n    \"./test/support/server.js\": \"./test/support/blank.js\"\n  },\nwhich should tell WebPack to use the browser-compatible ./lib/client.js instead of ./lib/node/index.js, but it looks like Webpack is ignoring this.\nI think it should work. I don't know if there's anything else that we can do, so I won't be able to fix this.\nPlease file a bug in Webpack instead.\n. As far as I can tell there is nothing to fix on our side and this is entirely a problem of WebPack configuration, so please file bugs in WebPack repo or ask in WebPack forums about this, not here.. Tests are always good :)\n. :+1: \n. Not in the core library, but there are some plugins that let you set global configuration: \nhttps://github.com/visionmedia/superagent#plugins\n. This is now built in in .agent() #1302 . I wasn't aware it's that bad. Our tests expect qs to handle UTF-16, and the version we use did it better than the latest.\n. This changes which url's query string is visible in the event, so it may be a break.\n. I wanted to correct URL some site is redirecting to\nrequest.get('/this will redirect/')\n .on('redirect', () => req.url = req.url.replace(foo,bar))\nand have the correct url in response.redirects.\n. Does this require us to bump major semver?\n. LGTM\n. maybe this is an actual bug? Do we have to wait for some kind of end/close event?\n. Thank you. Docs improvements are always welcome!\n. - 'function' == typeof this._sort is overengineered. \n- .sortQuery(false) doesn't disable sorting.\n- needs documentation\n. Regarding git, instead of committing, you need to run git rebase --continue to preserve authorship (and git rebase --abort now if git is still waiting). You can fix existing commits with git commit --amend --author=\"user <email>\".\nAs for the code, I don't see the point of using is-function module instead of 'function' === typeof. From what I gather it's a workaround for old browsers confusing regexes with functions, none of which applies here.\nOther than that it's good :)\n. rebased as 07147ce74ccc4a87388593c68b2d8a94d3d0bc41. Try npm i superagent@1. I didn't expect npm to pick a beta version by default :/\n. We have a stable 1.8 now. I'll keep beta tag in mind next time.\n. It's private. Methods with @api private in the doccomment are private and not supposed to be used outside superagent's own code (since they're subject to change and can disappear at any time).\nWe should probably rename them to have _ prefix.\n. #922\n. I many cases we're adding properties to the error object. Check for err.response.\n. We don't have such option currently. There have been some proposals for exposing tls options #681, but nobody has implemented it well yet.\n. As discussed in #681, a .tls({}) function that takes an object and only allows options that are necessary (which AFAIK would be key, cert and something to disable security).\nAs for disabling security, see https://github.com/visionmedia/superagent/pull/832\n- rejectunauthorized:false is a bad name, as it doesn't clearly state that it disables all TLS security, and allows decryption and malicious modification of requests.\n- having a setting that completely disables security for all domains, in production seems like a very bad idea if all you need is e.g. load HTTPS from localhost in development. I'd like to hear specific use-cases for disabling TLS security and add specific options for them.\n. No, please don't make all of node's requests insecure. \nPlease either use letsencrypt, or set your own ca using .ca() call.\n. We pass these to the agent, so details are documented here: https://nodejs.org/api/https.html#https_https_request_options_callback\nit'd be great if someone made a PR adding reference to these to superagent's docs.. I strongly believe that Node's own rejectUnauthorized is a mistake, which should be contained, and not propagated further.\nI've written about it before, but mainly:\n\nIt's horribly named. Apart from being a sort-of double negation, it is easy to interpret it as a small convenience tweak to TLS configuration. But in fact it's a complete disaster that makes all of HTTPS pointless for all practical purposes. False sense of security is worse than explicitly no security.\nAdding it as a method in superagent would make it very easy to accidentally commit code that disables all security for all connections in production.\nWith Let's Encrypt certificates are free, and in many setups can be obtained automatically, even for test servers.\n\nIf you want to make connections without any real security or privacy, then own it, and use HTTP.\n. I see it as \"We need to remove a spider. We could have just set doNotBurnDownTheBedroom = false, but we're forced to set DONT_BURN_DOWN_THE_HOUSE=0 setting instead!\"\nI'm not opposed to solving the problem. I'm opposed to solving it in the misguided way that makes it look easy, and has more serious consequences than it seems.\nIf you'd like to solve the problem, I'm happy to accept solutions that are less likely to be a footgun. For example:\n\nallow broken HTTPS on localhost/127.0.0.1. There's no need to secure that \"network\".\nallow disabling HTTPS security for a specific hostname, and only when NODE_ENV=development is set. This way even if you were using a real hostname, but with /etc/hosts override in dev, and committed code that disables security, it won't get disabled in production.\n\nFor the current superagent version, if you're connecting to some API, I'd suggest making base URL of that API configurable:\njs\nconst base = prod ? 'https://api.example.com' : 'http://localhost/api';\n\u2026\nrequest.post(`${base}/do/something`);\nso that in dev you can use HTTP, and HTTPS in prod. This is no more secure than rejectUnauthorized = false, but it does not give false sense of security.\nIt may be worthwhile to improve .agent() to make setting base URL easier.\n. >  After-all, superagent will work with HTTP requests\nI'm happy to add an option to superagent that completely blocks HTTP. I know it may seem radical: we've had HTTP forever, and HTTPS has been such a pain. However, things have changed rapidly and HTTPS-only world is already a reality for new client-side web applications and many macOS/iOS apps. \nIn web apps you need to be HTTPS-only to be able to use modern browser features, and that blocks all HTTP requests. Apple has deprecated HTTP. For real, system-wide. It's blocked it by default for all new macOS and iOS apps (you can add exceptions for now). \nSo allowing HTTP by default in superagent is pretty lax in that context.\n. @julien-f I hope you'd join me in pushing for proper HTTPS everywhere, and nudge your clients to fix their HTTPS instead of disabling it.. @stefanotorresi For testing in controlled environment that may be useful indeed, but I'm concerned about a for-testing-only option being accidentally left enabled in production. How would you design that option to prevent accidental misuse?\nSo far that's still what I'd recommend: https://github.com/visionmedia/superagent/issues/926#issuecomment-296444305. I appreciate you're bringing data to this discussion. Options to disable security are common indeed, but misuse of these options is also common. There are numerous CVEs for this vulnerable major bank apps, vulnerable mail clients, etc, etc, etc. In non-browser software misuse of these options is a widespread problem.\nSo I think the status quo needs to be improved. I'm OK to have such option in superagent, but only if it's clearly labelled as dangerous and hard to accidentally leave on in production. Could we focus the discussion on achieving these goals?\nMost of APIs you quote IMHO fall short (though having insecure in the name is a good dierction). For example CURLOPT_SSL_VERIFY* is famous for being a footgun. In PHP-related QAs it's easy to find comments such as \"if you get an error about invalid hostname, just set CURLOPT_SSL_VERIFYHOST to 0\". \nUnfortunately, completely broken and useless SSL appears to be working just as well as secure one. It's not a bug you can notice, so I think it really needs extra help to prevent such mistakes.\nPeople tend to go for the quickest \"fix\", so I'd like to make secure connections easier than insecure ones. \nHow about pinning specific certificate(s)?\nSomething vaguely similar to SSH's host key verification. You could specifically list certain certificates as trusted. That would allow self-signed and \"3rd party failed to maintain TLS and need two weeks to fix it\" cases, but will not trust just any random certs, so it still protects against MITM.\nAre there use-cases it won't solve?\nWhat would syntax for this be? Can somebody help with the implementation?\n. Can you check v1.8.2?\n. To fix this issue I need to see HTTP headers from server response and request body, if there was any.\n. if the body is empty, but the server is saying Content-Length: 15544, then it's the server's fault it doesn't work. The response is invalid, and gzip is right to complain that an empty body is not the 15KB of gzip data promised by the server.\n. Oh, OK, so in that case it should work. The other thing that stands out in the headers you've posted is encoding deflate rather than the more common gzip, so maybe we have a bug in there \u2014 I'd have to set up a test case for it.\n. If you'd like to help, it'd be super helpful if you wrote a unit test that exposes the bug.\n. LGTM. We'll merge it after releasing 1.8.1, since we've got a small fix to release first\n. Agreed\n. Looks like we're up to date now\n. I can add labels, but I think we don't need this one. When I update the changelog it's clear when the minor version needs to be bumped.. Oh, probably bower has the same problem. I forgot we have non-npm manifests.\n. I haven't used component before. Can it install npm packages? Could you make a pull request with dependency declaration it needs?\n. I think we can fix component support for 1.9.0 (we can avoid using form-data client-side #941), but we'll drop component support in 2.0.\n. 1.8.2 makes form-data optional on client-side, so should work again\n. This also allows downgrade of existing dependencies where major version hasn't changed. Could you use ^x.y.z syntax for these? \n. Great.\nYeah, looks like a saucelabs having problems launching IE.\n. I've restarted the build a few times, and IE9 fails consistently. Maybe it's the FormData issue? Or some other dependency? \nCan you rebase on master? And/or try updating only half of the depencies at a time?\n. In 1.8 we use form-data module that seems to require a browser that supports FormData\nif ('undefined' === typeof FormData) window.FormData = false may be a workaround.\nFiled: https://github.com/form-data/form-data/pull/176\n. I don't think this is a problem with webpack\u2014it compiled browser version OK this time. It's a problem that form-data assumes FormData exists in the browser.\nI don't know how our tests passed in IE9 with that though :)\n. In the current version .then is a bit of a hack #722, and depends on the generator being used by a Promise-wrapping library that will call .then() on it exactly only once. We're planning to fix it #925.\nDoes the following work for you?\njs\nvar res = yield Promise.resolve(request\n  .get('http://local')\n  .auth('tobi', 'learnboost'))\n. Sorry, our Bower support is minimal.\nWe don't check in autogenreated files into git repository, because they tend to cause merge conflicts, and I think it's generally a bad practice to use source control for derived files that aren't source files. \nFor npm we generate superagent.js that is included in the archive, but I don't know if that is possible for Bower without polluting our github repo.\nWithout the precompiled file, we assume you'd use something like WebPack or Browserify and require('superagent') in your code.\n. done\n. AFAIK Bower doesn't support bundling of pre-compiled files (apart from working around it by polluting source code repository with generated files), so with Bower you have no choice but use Webpack or Browserify or such.\nHowever, if you use npm instead, you can get a pre-compiled standalone browser version of superagent. It'll be installed in node_modules/superagent/superagent.js.\n. git repository shouldn't contain derived files, especially when they're unmergeable. I'd prefer not to add such files just because Bower is confuses source code with a built product.\nMy suggestions:\n\n\nConsider abandoning Bower. NPM 3 has a flat directory structure. Yarn has --flat switch that enforces Bower-like version resolution.\n\n\nIf you have to use Bower, use build tools like Gulp and Webpack that will build and minify superagent's source for you. \n\n\nIf you really have to use Bower and can't have a build step, fork this repository and add and maintain the derived files yourself.\n. You mean there's an uncaught exception? We definitely should catch and pass these on.\n. Sorry, I don't follow. Could you give an example what would you use it for?\n\n\nEvery HTTP request needs to have a URL, so something like request.post() wouldn't know where to send data to. \nThe fact that request.post('') works is an accident, and ends up being same as request.post('http://localhost/') (at least in node version).\n. Sorry, I still don't understand usefulness of this. Why should there be special convenient shortcut for posting to http://127.0.0.1/? Who does that?\n. Are you sure you mean superagent, and not supertest? \nSuperagent is a library for making real HTTP calls over the Internet, not a test mock, so it absolutely doesn't make sense for it to ignore the path.\n. Good to have this clarified! Thanks\n. Is your server sending Content-Encoding: gzip/Transfer-Encoding: gzip and does not return any bytes?\n. It should be fixed in 1.8.2\n. Please submit tcpdump or a unit test that reproduces the problem.\n. Thanks @afanasy for the suggestion.\nIt hasn't crossed my mind to use Content-Encoding for upload. Is that allowed by the HTTP RFC? Do servers support it? \nIn the browser it'd be tricky to do it, since it probably isn't supported natively. If it's commonly supported by servers, we could do it in node version. Otherwise it's probably best to implement it as a plugin.\n. I think buffered responses should be the default, and unbuffered responses should be only opt-in. \nHaving buffering mime-dependent is weird, especially that unknown types get unbuffered behavior. \nBTW, currently node and browser have different interfaces for parsers. There may be a possibility of unifying them, while sorting out buffering in the new parser API.. Gaah, bad JSON, bad.\n. thanks\n. Please reopen if it still happens in the latest version.. In 2.0 we support real promises in .then(), so there's no need to wrap .end():\njs\nconst response = await request.post('/foo');\nshould just work. I don't mind adding that to the documentation.\n. Let's wait for superagent 2.0 and es7 finalizing the feature.\n. I can't help the fact that Google likes to dig out closed issues instead of showing actual docs. I've edited the description to redirect lost googlers.. We use encodeURIComponent  https://github.com/visionmedia/superagent/blob/d4fb001df6ce6862e3dbdb4999c1ff82b54a4bad/lib/client.js#L99\nbut XHR in the browser does not allow unencoded '. xhr.open('GET', \"/'\") will send GET /%27 HTTP/1.1 on the wire. It works in Node.\n. Thanks for the PR, but that is a hack.\nI think it's inappropriate to use http: URL scheme for something that is not true HTTP over TCP/IP. unix is not a special, reserved hostname.\nPython uses http+unix scheme for this: https://pypi.python.org/pypi/requests-unixsocket/ which seems more appropriate and avoids ambiguity.\n. That's better. Thanks! Can you add tests to ensure we don't break it?\n. I've restarted the build\n. Have you checked node 0.10? If there's no simple fix for it I don't mind disabling the feature in node 0.10 (i.e. detect node 0.10 in tests and skip the tests). 0.10 is the IE6 of nodes.\n. Since 0.10 life ends this month we can go ahead and merge this.\n. Thanks. Consistency between node and client is definitely a good idea.\nI'm unusure about the sneaky .query() getter, especially that it isn't consistent. \n. The code looks OK now, but for some reason the tests are failing. I've restarted the build.\n. It keeps timing out, and not only due to the tunnelling. Suspicious. I'm going to check if it passes otherwise #967\n. Sorry about the delay. Looks like our tests are broken #972, so I'm merging without the tests (code looks ok)\n. \ud83d\udc4d \n. It should be in err.response.body. We also have .ok(() => true) now to catch all error pages.. We fire an abort event when the request is aborted due to a timeout. If I remember correctly, you should also see the end event with an error.\n. What information do you need from err?\n. The abort event already tells you that. You can do:\njs\n.on('abort', () => {throw Error(\"abort\")})\n. PhantomJS 1 is stuck with a very old and oddly incomplete JS engine. If you have to use it, then polyfill .bind(), but I suggest switching to anything else.\n. @defunctzombie is localtunnel.me overloaded or having some connectivity issues? We're seeing denied connections and data timing out so frequently, that the tests almost always fail.\nShould we host our own localtunnel server?\n. Works well now!\n. Included in #976 \n. The progress event gives an object as an argument which includes information like amount downloaded and total size.\n. js\nsuperagent.get('https://example')\n.on('progress', function(e){\n   console.log(e.direction,\"is done\",e.percent,\"%\");\n})\n.end();\nNote that we support download progress only in browser, and upload progress only in node (it's weird, I know).\n. Documentation for it is missing. I'd be helpful if you made a pull request adding it!\nUpload progress in browsers is just not implemented. I think with XHR2 it should be possible to add it.\n. Please note that for small files you may not get any events or get nonsense progress. That's simply due to how TCP/IP and buffering works \u2014 until all buffers in your browser/os/router are full, the sending appears to be instant, but it's not known how much reached the other end until there's a response from the other side.\n. Interesting question. If the API supports basic auth, you could use it on both client and server. \nIf the API uses cookies, then unfortunately there's a different behavior in node and the browser \u2014 browser will manage cookies for you, and forbids .set('Cookie','\u2026') call. Nodejs doesn't manage cookies and requires you to handle them, via .set('Cookie',\u2026') :/\n. To make it prettier, maybe write a superagent plugin? request.use(cookieJar)\n. Related: #1014 \n. It hasn't been on my radar.\nWith request-base we've done some work to make code more reusable between browser and node, so this approach could be used to write a node-http2-based version as well.\nAlternatively, if you had a node module that has the same interface as the built in require('https') module, you could swap these.\n. A new dependency for node is OK.\nHTTP/2 didn't add a new URL scheme, so it can't be just dropped in as a new type of URL.\nI'd prefer it to work in node the same way it works in browsers \u2014 transparently via ALPN when HTTPS is used. \n. I'm afraid that it'd be architecturally quite difficult to add this to superagent in a reliable way, e.g.\njs\n.use(req => wait().then(() => req.set('Foo',1)))\n.set('Foo',2)\nCurrently .use() returns this immediately, and all setters are synchronous, so it'd require a lot of magic in superagent's internals to wait for async use to finish.\nI suggest moving the async to before or after creation of request:\njs\nApi.createRequest('/api/users').then(req => req.end(\u2026));\nor\njs\nApi.sendRequest(req.get('/api/users')).then(res => \u2026)\n. Is it possible that your API sends a HTTP redirect?\n. No problem\n. Usually it should be enough to just wait for the end event.\nDoes it consistently get stuck in some specific situation?\n. By the spec it must change to 4 when the connection ends. Does network inspector in devtools show the connection is still running?\n. BTW: if you're finding this problem in production, it may be caused by network/browser issues, e.g. I've seen users with data caps on 3G connections have their connections throttled down to 0, so they never finish, but never fail either. Setting something like .timeout(30000) on all requests helps.\n. I presume it's been fixed in #985 \n. It may be access denied to the response, because 404 page doesn't include CORS headers.\n. Oh, the Samsung 4.3 browser is awful. Sorry, we can't support it. It doesn't even have remote debugging, so it's very hard to check what's going on.\n. self.callback(null, {}); reports it was a success, so this is wrong to do that when an error happened. It will break other people's code.\nCan you quote what error did you get exactly? Is res undefined? Is res an object, but res.status throws?\n. Thanks @RajeshSivanesan. Please try superagent 2.0.0-alpha.3\n. There is no date datatype in JSON, so I think superagent's behavior is correct. Your solution is fine.\n. How big is the delay?\nSome delay is expected, as setTimeout in JS isn't exact, especially if there are many other things happening on the main event loop.\n. I don't see what I can do about it. Please make a pull request if you think it needs a fix. \n. The text parser sets only .text.\nFor custom parsers it's sort-of broken. The end callback doesn't wait for the parser to finish - #950, so you need .buffer(true).\n. res.body is populated depending on Content-Type header in the response. If the server is (mis)configured to send the response as e.g. text/plain, then the response won't be parsed as anything else.\n. Yes, a fix is welcome.. This error means the response sent by the server wasn't valid HTTP. It could be caused by making http:// request to port 443 (HTTPS) or some other non-HTTP port. \n. Do you use proxies? Does the server have any clever load balancing/protocol detection?\nMaybe wireshark/tcpdump will let you see what response it gets. \n. Yes, because 300 is not a redirect, but application-specific list of available choices to choose from manually.\n. No, sorry, there isn't. You'll have to read the location header and make another request yourself.\n. This is added by Emitter(Request.prototype);\n. Good point\n. That was done for #985 I think we can shuffle things around a bit\n. Yes. node_modules/superagent/superagent.js works in the browser as-is.\n. @anonym24 npm i superagent; ls -l node_modules/superagent/superagent.js works for me. You definitely should have that after successful install.. We already have a check that prevents callback from being called twice:\nhttps://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L575\nwhich is exactly what prints \"double callback\", because the message is not a bug, but a diagnostic that warns about presence of other logic bugs.\nSo bypassing \"double callback\" check doesn't fix multiple callbacks, it just hides them.\n. I'm afraid nock changes behavior here significantly, and the proper fix would be for nock not to start the request in this case.\nIn superagent this situation can't happen, because the request is made after _appendQueryString, so it can't fire an error, because it's not started yet until end of the function: https://github.com/visionmedia/superagent/blob/86921996137a40b6fa12d343ca0d32daa2993fc6/lib/node/index.js#L844\n. You're correct.\nAnd yes, it sounds like a good idea to remove listeners (or maybe not even add them at that point yet) if something goes wrong in the setup.\n. I think moving appendQueryString (but not its catch) to inside .request() before handlers are attached would solve the problem, and remove some duplication.\n. We did some refactoring since, and this change is still not what we want, so I'm closing this.\n. Superagent is a \"thenable\" object, so you never need new Promise() when interacting with it.\nThis works:\njs\nrequest.post(\u2026)\n.then(postResult => {\n    return request.get(\u2026);\n})\n.then(getResult => {\n});\n. It is a real Promise, and it works with generators. As of superagent 2.0, you can consider .end() obsolete.\n. Thank you for the pull request.\nConsistency with set is a good idea.\nWe're having problems with localtunnel.me, so I'm going to give Travis a few kicks and merge it when tests pass.\n. Thanks\n. When you bundle superagent for node, you must specify target: \"node\".\n. To help diagnose these surprises, maybe we should add something like:\njs\nif ('undefined' === typeof window) throw Error(\"You've using browser version in node\")\n@focusaurus ?\n. I agree that the behavior is weird.\nI think the original issue was that we didn't want to needlessly re-parse existing query, as conversion to an object and back could change its escaping and reorder the elements.\nWe also support setting the query as string, and the string allows any syntax. If we'll parse it in the URL, then we should probably parse in such case too:\njs\nreq.query(`foo=bar`).query({foo:'baz'})\nbut OTOH somebody could have used string to set query in a weird format .query('foo:bar;baz$quz'), and parsing of that shouldn't be supported.\n. Yes, this was a private function and was never supported.\nHow did you run into this problem?\n. It worked, but working doesn't mean it's supported. This API was not documented in 1.0 manual, and in the source it was marked as @api private, meaning it was not for use.\nRemoval of all such private function is one of the breaking changes in 2.0.\nThe function has been renamed to _attachCookies, but this is private too, and sooner or later it will break too.\n. Try this:\n``` js\nconst jar = new CookieJar;\njar.setCookies(res.headers['set-cookie']);\n\u2026\nconst access = CookieAccess(url.hostname, url.pathname, 'https:' == url.protocol);\nreq.set('cookie', jar.getCookies(access).toValueString());\n```\nThis should work for simple requests, if there are no other cookies or redirects.\n. It depends what do you need it for. Do you only need to fake cookies in supertest tests?\n. Setting cookies for tests sounds like a strong use-case. Can you open a feature request for it in supertest project? I think it's better to create a unit-test-specific API there.\n. That should be tracked in supertest.\n. Is react-native loading superagent from lib/client.js or lib/node/index.js?\n. In that case we don't build the line with the filename, the \"browser\" does \u2014 we use native FormData object. Perhaps React doesn't emulate the third argument?\n. I don't see the bug. Can you reduce it to a more specific case?\nBTW: as of superagent 2.0 you don't need to use .end(). superagent.then() returns a Promise.\n. Does it work without supertest?\nI don't see anything special about this code, and .send() with objects works in general.\n. OK\n. Ouch. That's a gotcha. Thanks for sharing the solution.\n. BTW: buffer() should still be available in superagent. It was always only available in the Node version, not in the browser version (since we can't control how browser buffers).\n. We don't handle multipart ourselves. In browser we use XHR2 native FormData. In Node we use form-data module.\n. Since superagent 2 do not use .end(). Use .then() instead.\n. Superagent 1.2 is quite old. It has known bugs, which we have fixed \u2014 in later versions.\n. Should it be header or headers?\n. In node it's headers, so I suggest going with that: https://nodejs.org/api/http.html#http_message_headers\nAlso, could you add a basic unit test for it?\n. Thank you\n. Thanks\n. Indeed, and this is a typical behavior for asynchronous code in Javascript. There is no short simple solution for this. \nThis is the way most \"long\" operations work in JavaScript. You will have to restructure your code to accommodate that. The function that needs the result will have to use callbacks itself (be called from inside of the end callback).\nManagement of callbacks is a little bit simplified with Promises, and then with async/await, but none of these things really remove callbacks, they just hide them, so you'll have to embrace callback-style programming.\n. Thanks. We've updated jQuery on our documentation pages.\n. Done\n. Please try version 2.1, it includes a fix for doubled callbacks.\n. Thanks. Consistency is definitely desirable. However, maybe we should adjust browser to match node instead?\nJSON.stringify keeps nulls:\njs\nJSON.stringify({n:null,u:undefined})\n'{\"n\":null}'\n. Query string taking JSON isn't meant to preserve it 100% (for that you'd use actual JSON post type), it's just a convenience. I think it's fine as long as it's consistent and seems sensible.\nPerhaps we could serialize {a:null,b:1} as ?a&b=1.\n. @focusaurus what do you think about it? \n. Thank you @Gerhut!\n. I think in recent versions we have support for all types ending with +json. If not, could you write a unit test that demonstrates the failure?\n. If you want to pipe the response, then don't use end().\nResponse given in the end() callback is already complete and finished, so there's nothing to pipe - the piping process has already ended.\n. In the .end() callback _res.pipe() causes errors, nothing else. You can't use .pipe() if you call .end(). It's either one or the other, never both.. This is a common problem, and it never ends. I suggest that you add custom properties on Object prototype as non-enumerable (or don't modify Object prototype at all).\n. I think that would be a good addition.\nWe currently don't have an API to expose this functionality. The browser version doesn't support streaming at all. OTOH in Node we have .pipe() and node's streams.\nSince ReadableByteStream is the standard, I think it should be used in the browser version. Is it possible to emulate ReadableByteStream in browsers that don't support it natively yet?\nI wonder how to have first-class support for node's streams, and first-class support for the Streams Standard without confusing and duplicated APIs. Do you have any proposal for the API?\n. Yes, I think a minimal polyfill is a good way to go. With XHR we don't even have ability to do proper backrpessure.\n. If the polyfill is heavy I see a couple of possible workarounds:\n- don't bundle the polyfill with superagent, and inform users that they should polyfill the global ReadableByteStream (and other objects) if they want backwards-compatibility. Users could choose which implementation they want.\n  or\n- in superagent provide only hooks for plugins for streaming, and leave streams implementation up to plugins.\n. Currently superagent, in node version, has a rather ad-hoc mechanism for \"parsers\"\nhttps://github.com/visionmedia/superagent/blob/master/lib/node/parsers/text.js\nwhich boils down to \"data\" and \"end\" events. Is that equivalent of .write/.end methods you've had in mind?\n. Depends what you mean by chunks. If you mean chunked HTTP/1.1, then you can, but superagent will wait until the whole response is received.\n. Streaming in the browser will not solve your problem, as the error is due to your web server cutting the connection server-side.\n. Try using raw XmlHTTPRequest or curl to verify whether the server sends data fully.\n. If you get error in XmlHTTPRequest then there's nothing we can do. The browser would report the same error via streaming API too, and stop streaming early.\nIt's most likely that it's a problem outside of browser, e.g. in your CDN, your reverse proxy, your web server, or middleware managing node.\n. fetch() is a thing now and it works well with streaming, so if you need streams, use fetch().. I guess you've managed to solve it?\n. No problem\n. Does it work with actual superagent request?\nThis project doesn't handle simulated requests done by supertest.\n. So when super_test_ is not used:\n- in the browser, superagent uses native FormData object. Do request from the browser work? Do you have the same problem with native XHR?\n- in node superagent uses form-data module. If your request works from browser, but not from node, please file a bug for form-data.\n. I'm not sure if it'll work if you set Content-Type - you may be overwriting the correct one.\n. as for FormData, we don't support it set that way, we only use it internally via .attach(), .field(), etc.\n. Please don't confuse supertest with superagent. These are separate projects.\nIf something works with superagent (making real requests to real servers), but not in test with superagent, then please file a bug in supertest project.\n. Sorry, it's still unclear to me whether you have a bug with superagent or supertest. Previously we've had both issues with superagent's multipart handling as well as incompatibilities with supertest.\nIf you have a reproducible code that fails, please add it as a unit test in superagent and I'll try to make it work.\n. In my previous comment I specifically mentioned superagent's test suite, because superagent's test suite makes real requests, and does not use supertest.\nIf you're seeing a bug while using supertest (fake requests, not real ones going over the network), then please file the bug in the supertest project.\n. Sorry it's frustrating.\nI've only tested superagent with webpack with target: \"browser\". I've never tried to build it as part of a compiled bundle for node only. The node version is meant to be used directly, without compilation.\n. It's possible that the mime module, which we use for node only, is not compatible with webpack.\n. Nothing will be done about this in superagent, because as far as I understand, the problem is not in superagent. The problem is that the mime module does not support non-browser Webpack targets.\n. I'm wondering, instead of making it fail, can we make it just work instead?\nI guess it'd require using this._data for .field and .attach, and then \"serializing\" it as FormData before sending.\n. Technically superagent is a \"thenable\" and doesn't require to have catch, but I see your point, and since the implementation only takes 1 line, I think it's fine to add it.\nThanks for the PR.\n. Thanks!\nCan you remove the second commit? Seems accidental.\n. Thanks for the PR! I've merged in the first commit:\nhttps://github.com/visionmedia/superagent/commit/77fbca276146c2a7fd47520dc9227f4e0f68d1a7\n. Can you share the code that reproduces the error?\n. IIRC .response is an XHR2 feature, which IE9 does not support. Maybe try/catch would be a safer alternative?\n. Thanks. What's your reason for staying on 1.8?\n. You console.log looks correct, as if it printed an Error object, not a string, so err.status should still be possible.\nNote that err.status is available only if the server responded. If server didn't respond (e.g. client is offline, or server is down), then there will be no HTTP status to report.\n. Existence of err should be enough. The browser does not report why connection failed (we only get status = 0).\n. In case of a timeout the error has .timeout property, and we fire an abort event.\n. OMG, I didn't know npm was that dumb. I've pushed 1.8.4 bugfix from #1042\n. Pushed 2.2.0 to npm\n. That's not a message from superagent. It looks like an error from express.js. Are you sure you're calling it on superagent, and not express' request?\n. If you're running it under supertest, please file a bug there. Supertest changes/bypasses superagent, so I can't help you here.\n. supertest has to prevent requests actually going to the network, so it patches/replaces superagent's request-making logic with its own.\nOTOH if you can reproduce the error without supertest involved, then it's definitely a superagent bug.\n. Thanks\n. it makes sense. What about the null check?\n. As far as I know, the XHR interface does not expose existence of preflight checks in any way, and a failed preflight gives us a generic error with status = 0, which we can't distinguish from DNS, TCP connection or offline errors.\nDo you know how a better error could be implemented?\n. You should be getting the end() callback on CORS failure. \n. @ratiotile do you know if this message is exposed to JS somehow?\n. I can't change when end is fired \u2013 apparently we have tests that check it's not fired on CORS error.\nI've added an error event, so if you catch error, abort and end you should be covered.\n. You could avoid base64 overhead by using a Blob created from an ArrayBuffer.\nAFAIK XHR can't stream uploads. If you wanted to avoid having whole object in memory at the same time you would need to upload it using multiple requests and reassemble on the server.\n. We have attach() for sending Blobs (as multipart).\n.  I see. I think it'd make sense to support it as superagent.send(blob). Would you like to make a pull request for this?\n. @jedwards1211 are you using htmlparser in the browser? If so, then there's no way, because we don't support the whatwg stream standard yet.\n. In node request.pipe(htmlparser) should work.\n. Yes, we accept buffer in .attach(). Yeah, that works too.. Neither buffering, nor response body parsing are available in the browser. These things are handled natively by XHR.\nIn Node parser is expected to listen to events on response stream, but in the browser we don't have a stream (we could #1033)\n. This could only happen here, in Node-JS-only bit of code:\njs\n    this._formData = new FormData();\n    this._formData.on('error', function(err) {\nwhich would happen if FormData was incorrectly imported. Are you perhaps using Webpack or something similar that could accidentally create a mix of Node-only and browser-only modules?\n. We now have a getter that creates this object automatically. Hopefully it'll work. \n. Webpack has a target setting, which has to be \"browser\" or \"node\" accordingly to the environment the code is going to run in. Unfortunately I don't know Meteor's specifics.. We have only very basic support for mapping of JSON to form-data. If you want to send complex data I suggest sending it as JSON.\n. Efficiency of both encodings is similar. Mostly it's a matter of compatibility with your server, and most servers accept form data out of the box. \n. Thank you!\n. Thanks\n. Good catch.\n. Thank you. I appreciate the attention to detail.\n. That makes sense. Yes, please make a pull request.\n. I think calling .attach() multiple times should work already.\n. Superagent can only fetch things of finite size. The documentation says \"Continuous video stream.\", which I assume means a stream that never ends, so you'll never get the end() callback in superagent.\nYou must use a different library for this.\n. Search for tools for dealing with multipart/x-mixed-replace. The format is quite obscure.\n. That looks like a bug in FormData (I don't see what we can do about it in superagent). Can you report the problem there?\n. .set('header',undefined) throws, .query('field',undefined) sets query string to ?field, so it could go either way.\nThrowing may be easier, but making undefined remove fields from the form could be more useful.\n. We're not using assert module in the client code. Can you use regular if/throw instead?\n. Superb. Thanks!\n. I think we could make the logic configurable by allowing user to supply a callback to judge whether the response is OK.\nhttps://github.com/visionmedia/superagent/blob/v2.2.0/lib/node/index.js#L590\njs\nrequest.get().ok(res => res.status < 500).then(\u2026)\n. This feature is in superagent. Are you using supertest perhaps?. Then request.post(url).ok(cb) should work. chai.request(app) doesn't look like a  call to superagent, so maybe chai has a wrapper that doesn't expose it yet?. Can you provide a URL that shows the error?\n. Yup\n. There is a .response field already\n. Oops! Thanks\n. js\n.catch(error => error.response.body)\nshould work\n. In the fallback, does err.response exist? Did you test it in situation that actually gets response from the server?\n. The success/error returned by .then()/.catch() is generally in line with how promises work. But if you think the docs can be improved here, then a PR is very welcome.\nBTW: error.response only exists when we received a response. There are some edge cases when request fails even before we get any response from the server, and in such case there's no response at all (equivalent to .end(error, undefined)).\n. @kromit CORS error is very different from all other errors, because in this case the browser deliberately tries to pretend that the response does not exist! We don't get any information at all. No headers. No status. This is intentional by design of the HTML Standard to prevent information leak across origins. Until you fix CORS headers you won't get any information from the server at all.\n. Still, .catch(error => error.response.body) (and .catch(function(error) {error.response.body})) should work whenever response exists (i.e. on 404, but not on DNS errors, CORS, timeouts, offline, etc).\n. I think it is documented. Feel free to add to it:\nhttp://visionmedia.github.io/superagent/#error-handling. Its fine. As far as superagent is concerned, err.response is there for you to inspect it. The body may be potentially megabytes large, so include it in the message at your own risk.. This is a bug in Chrome. The second argument must not be null and must be a string or Blob.\nIf you don't have a file to send, then don't call .attach()\n. The code looks correct. Do you get different server response depending on browser?\n. Ahh, I see. Without any fields you're not getting multipart request.\n. This is a bit weird. Rollup's requirement doesn't make sense in CommonJS world. Could such transformation be done by Rollup instead?\n. OK, that makes more sense. Unfortunately exports.clearTimeout is a public interface in superagent, so I can't rename it. \n. Please provide HTTP request headers and the response so we can investigate the problem\n. I've found this is because Facebook is sensitive to the Accept header, and browsers and curl force their own default one, but superagent doesn't.\nAdding .accept('json') to the request happens to do exactly what it should, and makes FB send JSON.\n. So given this, I wonder what should we do:\n- add more documentation/warnings/hints about use of .accept('json')?\n- try to parse text/javascript as JSON? What if it's actually JS (e.g. jsonp) and fails to parse?\n. That's a good idea. It may need some care to keep compatibility with the browser. \nWould you make a PR for this?\n. AFAIK in browser there's no control beyond filename, so it'd be fine to ignore extra parameters. As long as you don't break \nsh\nmake test-browser-local\nit's fine :)\n. I feel your pain, but I think it's not the right solution. The problem is that as soon as you use this promise, it'll lose the added methods, e.g. req.get().then().then().abort() wouldn't work, neither would Promise.all([req.get()]).\nPersonally I use workaround of return {promise: req.then(), abort() {req.abort()}}.\nThere is a proposal for cancellable promises, so when it lands, it'll be possible to add it to superagent.\n. Thanks\n. 1. The secret is already out.\n2. Last time I checked this it would break checks on pull requests from other people's repos. This is a dealbreaker.\n. Nice catch. Thanks!\n. Can you show example code? Are you using it in Node or browser? Is it a CORS request?\n. Thanks.\n. Thank you for the PR. That looks like a good way to solve it.\nI wonder if we need to bump semver-major for this? (will this impact supertest, plugins or mocking?) WDYT @focusaurus?\n. Cool. Let's do that as semver-major. It's now (unrelated to this issue) also a good time to drop Node 0.10 support (official support has ended), which might be seen as semver-major too.\n. Thanks for the pull request, but I think it's a bit too specific functionality to be included in a general library like superagent. That may be useful as a standalone module or maybe a function in supertest.\n. Most failures I've seen are either timeouts or connection refused by localtunnel. This makes me suspect that flakiness is mainly because localtunnel.me is slow/unreliable: #972 (although it could also be connectivity issue between saucelabs<>localtunnel or travis<>localtunnel) \n. I don't have that information. I vaguely remember that there was a 3rd party project which allowed you to download and query a massive data dump of npm stats, but I forgot how it was called.\n. Potential memory leak. Nobody complained about leaks before, so I think it's more of a good practice than a fix for a nefarious problem.\n. npm i superagent@next\n. Please try overriding the dependency version (or better, as dep author to upgrade) and see if the warning still appears. There's ~90% of chance that the warning comes from the old version and that we've already fixed the bug. \n. I've added more info in 1.8.5 and 3.2.0. if there are no objections I'm going to release today \n. AFAIK this behavior did not change since 1.7. Only 2xx responses are treated as success. We treat 304 as an error, because it does not contain response body, and is not guaranteed to have all the usual HTTP headers of the response, so the usual properties of the response object would be useless (with no response.body, response.text, etc.).\n. The 304 response is sent by the server when it sees matching If-Modified-Since or If-None-Match headers in the request. It's likely to happen when you request URL that is cached by the browser.\nYou should still see the same error in 1.7.1, because that change has been made in 1.0.0:\n1.0.0 / 2015-03-08\n\nAll non-200 responses are treated as errors now. (The callback is called with an error when the response has a status < 200 or >= 300 now. In previous versions this would not have raised an error and the client would have to check the res object. See #283.\n. It's possible that some other change caused the server to start returning 304 (e.g. maybe we were lowercasing HTTP headers and your server doesn't like that \u2014 I'm totally guessing here), but I'm 100% sure that once the server sends 304, all versions past 1.0 will behave the same.\n\nIf you try other versions (e.g. does 1.7.2 work? does 1.8 work?) and narrow the change to specific version, it'll be easier for me to find out why it behaves differently.\n. I agree there's a bug. Superagent should be copying given objects instead of mutating them.\nUnfortunately this particular workaround is breaking things:\n\nUncaught AssertionError: expected '{\"0\":1,\"1\":2,\"2\":3}' to be '[1,2,3]' \n\nPlease check\nsh\nmake test-browser-local\n. 1. There's Array.isArray\n2. Why || {} and || [] if you know the object won't be falsy?\n. 1. Constructor check is weird. Correctness is more important, so if you check for isArray first, and then for typeof, it'll work the best\n2. Sorry, I've misread the code!\n. Oops, sorry. My suggestion with typeof object was wrong. The input can also be a Buffer/Blob, etc.\nTest failure: https://travis-ci.org/visionmedia/superagent/jobs/173242438\nYou can use npm test to check these locally.\n. OK, now it all works. Thank you.\n. sh\nnpm i superagent@next\n. Thank you for the PR, with the tests \ud83d\udc4d \n. That's great. Thank you.\n. And it's cool that there are still .com domains available :)\n. This is not unique to superagent. JavaScript in general can't handle integers larger than 2^52, so we can't fix it. You will have to use another solution, e.g. send the number a string.\n. Query example seems like a good thing to add.\nWhile we're at it, could we have an example with some realistic values, not \"foo\" and \"some-url\"?\n. Great! thank you\n. withCredentials exists only because of CORS, which is a limitation that only exists in browsers (for very good reasons). \nWe have absolutely no control over this. You can control these restrictions by supporting appropriate OPTION requests on your server. See docs I linked above.\nIt doesn't exist in the Node version, because Node doesn't run untrusted code from multiple sources, like browsers do.\n. I see. Well, then withCredentials() is certainly completely unrelated and won't help you at all.\nTo preserve cookies, you need to create an agent:\n``` js\nconst agent = superagent.agent();\nagent.get('/url1').then(() => {\n    agent.get('/url2').then(etc); \n});\n```\nThe agent object will remember the cookies between requests.\n. Is it still a problem in superagent 3?\nBTW: files are only allowed in .attach() method. .field() is for strings, .send() is for JSON.. I've just realised that next tag in npm is annoying, because it's not the very latest version, but the last unstable/experimental version, so don't use superagent@next unless you want broken code :). I've changed .once to .on and published it as superagent@next to make the next tag less outdated.. Superagent doesn't add the semicolon. Maybe you have a proxy that does it?\nedit: semicolon without a parameter is not valid syntax\n. No, it's that .send() never ever worked together with .attach(). It was either silently dropping data or sending garbage, so the only change is that now you'll know about it.\n.attach() can only work with .field().\n. In superagent 3 the error event works in more situations. Please test it.\n. By overloading, do you mean .timeout(Number) vs .timeout({connect:\u2026, chunk:\u2026})?. Also, should we have any defaults?. The MVP of response timeout seems to work well enough, so I'll leave it at that.. Does it work without supertest? (i.e. if you make a real request over the network with superagent only).\n. Cool, thanks :)\nBTW: all supported node versions have native promises now, and current node warns about unhandled rejections.. Thank you very much. This is good stuff!. You can't use end() if you're using promises. End is for non-promise callbacks only.\n await request.get(). It will be returned, so\n\njs\nconst res = await request.get(\u2026);\nconsole.log(res.text);\n. We deliberately don't do this, because it increases size of superagent.js (for all browsers, even those which have btoa).\nIn browsers it's needed only for IE9. React native is a new problem, but the solution is the same as we recommend for IE9: you should fix it yourself, in your code:\njs\nwindow.btoa = require('Base64').btoa;\nI think you could file a bug with react native, because btoa is now a standard.. I think it's a bug in supertest only. See #1117\nCan you reproduce the problem with superagent, without supertest?. Thanks . This is MVP for #1115. It is compatible. We use promises in our test suite.\nThe common error is to use .end() with promises, but these are mutually exclusive.. I think we could add more cross-request customizability via superagent.agent() methods. That creates an instance that an app could safely change.\nI'd rather not have any global superagent.on, because then libraries couldn't safely use superagent without risking interfering with each other.. It's done! .agent() now supports .set(), etc. #1302. As for the original question:\njs\nconst superagent = request('superagent').agent(myAgent);\nit will create a copy of superagent that uses myAgent for all requests.. You can do agent().use(yourCallback) and the callback will be called with the request object every time a new request is created. From there you can set headers and listen to redirects and responses.\n. The agent is strictly for Node's HTTP agent. It's a different API with a different level of abstraction than express.\nI can't help with supertest, unfortunately. It's a weird situation that it's a separate project implemented by other people.\n. Oh, we don't have a stable api for the cookie jar. You'd need to keep track of them yourself (see how agent does it). Passing the agent (result of superagent.agent()) around is the right solution. It's like dependency injection. \nIf you expect to modify behavior of superagent straight from require('superagent'), then that's a no-no, because this is a global variable, and it would create a shared mutable state.\n```js\nconst csrfAgent = require('superagent').agent().use(req => req.set('Token', token));\n````\nand you won't need to pass the token separately.. Done in #1302 . I wouldn't call it inventing. By default superagent treats status 2xx as success, and everything else as error. That's mostly in line with intentions of the http spec.\nNote that in most cases there's err.response if you want to read content of error pages.\nIn the latest version there's .ok() function for customizing which responses are treated as errors.. That line of code is pointless indeed. In case of CORS error we don't get any status.. It looks like you're using Node-only version of Superagent in a web browser. This won't work. In browser you can only use browser version of superagent.\nThe correct version is automatically picked by browserify and webpack (in webpack target:\"browser\"   (default) in config controls this).\n. We do have a test for PUT, so I think it works in general.\nIf you're sending from browser, make sure you implement CORS.\nThat 2 looks suspicious. Try \"2\" or {id:2}.\n. This library doesn't handle this level of detail. Actual request and setting of ports is delegated to Node.js (or the browser in browser version), so the answer is \"whatever Node.js usually does\".\n. Since you're talking about the test suite, in browser version it's the same \u2014 test server is still runs in node.. Socket hang up means the server closed the connection, which could be caused either by a hard crash of the server or a serious syntax error in the request. \nSo you see any errors on server side? Is it possible that you have some non-ASCII characters or unexpected newlines in your headers?\nTry running nc -l 3000 instead of your server and see what superagent sends.. is the \"(compatible with 1.x)\" comment intentional? Does it mean it's compatible with 1 or later, or that it's not compatible with the current version? (3.x)?. Good catch. Thanks!. Yeah, but staying on an old version of Appium doesn't seem like a proper (long-term) solution.. Now Saucelabs fails with \"Appium 1.7.2 does not support Mac 10.13. \". No, there's no way. Setting it will break things.\nIn the browser version the boundary is set automatically by FormData element and we have no control over it.. You can't use attach() and send() at the same time. You can either use your own content-type and your own payload with .send().set() OR you can let all of it being 100% auto-generated by the browser by using .attach().field(). They don't mix.. The hard way. Generate boundary, content-type header, and append image's binary data. You'll need to get Uint8Array from image Blob (using FileReader).\nI'd rather do it the other way \u2014 why do you use your raw, custom payload? Can you send it as files or form fields instead?. What do you use .send() for?\nUsually you only need\njs\nrequest\n    .post('http://website.com/upload')\n    .attach(\"image\", image, \"2684337397.jpg\")\n    .then(\u2026)\nand nothing else. The boundary is supposed to be random, so needing it to match anything is very unusual.\n. You can add other data using .field() - it does the same thing as .send(), but uses form-data instead of JSON that can't send files.\nthe only limitation of .field and .attach is that it sends the form the same way as browser would send <form>, so you can set the fields, but you don't control byte-for-byte details on the network level.. Please make a new issue for the other problem. I have no strong opinion either way. I went withconsole.error, because it may become an error.. I think that would be a useful addition.\nAs you've noted, superagent has a quite a bit of internal state. Do you have a plan how to deal with that nicely?. I suspect it may be necessary to change .end() and split it into 2 phases (2 functions): things done once only (e.g. append query string), and things done to launch the request (the latter call being repeated when retrying).\nAlso care needs to be taken with redirects. Node version handles them explicitly.. Answering your questions:\n\n\nIf you split and reuse part of end() that sets these timeouts, you won't need it\n\n\nDoesn't seem needed. Does it break any tests?\n\n\nI'd use retries, but attempts is fine too. \n. > I'm a little hesitant to mess with anything in there if it's not absolutely necessary.\n\n\nI could try to do that refactoring first if you want. Thank you. \nThe failures were only due to short timeouts in the test.. In browsers, in general the Web platform supports only UTF-8 well, and the rest is legacy and broken. On a UTF-8 encoded page I don't think it's possible to send a string via XHR and have it latin1-encoded, and it's definitely impossible to do that if you're sending files (using .field() and .attach(), since the browser does string to binary conversion.\nYou could try:\n\nchange encoding of your entire page to ISO-8859-1 encoding\napply your own URL-encoding and use request.post().type('form').send('text=%e5')\nSend a binary buffer (construct Blob or ArrayBuffer)\ntell the recipient that UTF-8 is 25 years old and it's time to upgrade. I think .send() with string will always use UTF-8, or at least the same encoding as the page. I forgot how '90s encodings work...\n\nI think your best bet is to use Uint8Array for building the payload. If you need legacy encoding, then you probably shouldn't use superagent, and use raw XHR instead. superagent doesn't support any encodings other than UTF-8 and it will only get in your way here.. Yes, you'd update state and re-render the view. For advanced uses there are also libraries that help manage events/state in React.\nThere's nothing React-specific in superagent, so you can look for guides that describe asynchronous changes in React in general.\n. That must be a very old WebKit. . Run make test-browser-local and open that URL on your TV to see if it's compatible.. Thank you. Yes, it's unfortunate that our default for res.body is {}. It should probably be undefined, but it's a breaking change :(. Could you help with it and make a PR?. cc #1188. sh\nmake docs. You can't directly. You have to call either .pipe() or .then/.end() first to make the request.\nThere's response event which lets you inspect the headers as soon as they arrive. Then you can unpipe?\nAlso with the pipe you should get error event on the pipe.\n. Thanks for the suggestion. It's a cool idea.\nUnfortunately, in superagent's case the examples shown happen to be very basic 1-liners that don't tell much about the library.. This is still showing usage in a misleading way that looks incorrect:\nsuperagent = require('superagent')\nagent.get('localhost:3000/multi')\nagent.get('localhost:3000/raw?test=/api/countries')\nagent.get('localhost:3000/multi?country=/api/countries')\nagent.get('localhost:3000/multi?user=/api/customers/23&country=/api/countries')\nagent.get('localhost:3000/multi?foo=/api/foo/&country=/api/bar')\nagent.get('localhost:3000/multi?headers=/return-header')\nIt's not possible to have good 1-line example of superagent, becuase it has a fluent interface and at very least you must have a call to .get() and .end() or .then(). Limiting examples to just 1 function makes them invalid.\nInstead of cutting examples down to one line/one function call, you should display at least one complete JS statement.\nSo this:\njs\n        agent.get('localhost:3000/multi')\nis invalid.\nBut the expanded version:\n```\n        agent.get('localhost:3000/multi').end(function(err, res) {\n            assert.equal(res.statusCode, 200);\n            // an empty object is returned if no parameters has been passed in\n            assert.deepEqual(res.body, {});\n        done();\n    });\n\n```\nis OK-ish.. As for the ranking: the first result request-curator - request-curator-test.js is from a unit test, so it's a bit artificial. The second result farm-budgets-sdk - materials.js - is much nicer. It shows actual usage.\nBut it seems like half of the results are from unit tests, and even 3 in the row are indentical:\n\n...\nrequest = require('superagent')\nrequest.get('http://localhost:1234/foo.js')\nrequest.get('http://localhost:1234/bad.js')\nrequest.get('http://localhost:1234/coffee.js')\nrequest.get('http://localhost:1234/moobar.js')\n...\nbrowserify-dev-middleware - index.jsOpen full file\n...\nrequest = require('superagent')\nrequest.get('http://localhost:1234/foo.js')\nrequest.get('http://localhost:1234/bad.js')\nrequest.get('http://localhost:1234/coffee.js')\nrequest.get('http://localhost:1234/moobar.js')\n...\nkoa-less-middleware - index.jsOpen full file\n...\nrequest = require('superagent')\nrequest.get('http://localhost:1234/foo.js')\nrequest.get('http://localhost:1234/bad.js')\nrequest.get('http://localhost:1234/coffee.js')\nrequest.get('http://localhost:1234/moobar.js')\n. Node wants you to add .catch(err => {\u2026}) to the Promise. Using .then(successCallback, errorCallback) works too. It's not specific to superagent.\n\nYou only need to catch errors on the last promise in a promise chain. If you're using superagent in a function that shouldn't be handling the error itself, then return the promise and let caller handle it.\nBTW, I've found node --trace-deprecation --trace-warnings is helpful in finding where the warnings come from.. We have tests for it and they pass:\nhttps://github.com/visionmedia/superagent/blob/36ce8782842c2fee402013ff0650d7f8b310e3a7/test/node/agency.js#L82,L109\nDo you do something differently from these tests? (e.g. check contents of the header to see if domains/paths/secure flags make sense). I'm unable to reproduce it with the latest version of superagent\n\nCookie Test\n    \u2713 test1 (1775ms)\n    \u2713 test2 (1465ms)\n2 passing (3s). Yes, request and response HTTP headers would clear things up. This looks correct. Yahoo does not set any cookies, it removes one: expires=Thu, 01-Jan-1970. I've checked. This is because superagent doesn't know what the domain name is. You're requesting .get('/'), so the domain is undefined, but the cookie requires match on a specific domain.\n\nagent.get('https://www.mavericklabel.com/reskin/xml/headers.php') works.\nI guess superagent-prefix is a leaky abstraction. You could report the problem there.. In browsers it's not possible to send GET body. However, it works fine in Node version.. Does it work if you JSON.stringify() it first? \nI've added this test:\nhttps://github.com/visionmedia/superagent/commit/aa8f1aef80a376b89c379957eb36951b910cdaf2. Thanks. The HTTP RFC says http://httpwg.org/specs/rfc7231.html#DELETE\n\nA payload within a DELETE request message has no defined semantics; \n\nso I think it's not appropriate to support it.\n. OK, the spec says the same for GET and we already support that as a precedent.. Thanks for the PR. Validating and setting to 0 is generally a good idea.\nHowever, interpreting negative values as 1 doesn't seem right to me. Can you change it so that:\n\nretry() == retry(true) == retry(1)\nretry(number) sets retries if number > 0\notherwise retries are set to 0 (null, undefined, false, -20, etc.)\n. I think arguments.length == 0 is a more common pattern.\n. I've tweaked that and made a release. Thank you!. Oops. This is fixed now.. AFAIK finally isn't in the standard yet. And superagent's Request is deliberately designed to be a thenable object, not an instance of the Promise class.\n\nPromise methods only wait, they don't start any actions. So when you call .then() on superagent, you call our wrapper around .end(), not a method of a promise. \nIf you need an actual Promise instance (e.g. because you've patched the prototype to add your own finally), then you'll need Promise.resolve(request).finally(\u2026).. js\nPromise.resolve(request.get('url')).finally(\u2026).\nbut more realistic would be\njs\nrequest.get('url').then(res => res.text).finally(\u2026). .finally() is kind-of obsolete now, since in the async functions you can use the real finally{} block.\njs\ntry {\n   const res = await superagent.get(url);\n} finally {\n   finally_works();\n}. That's logical, because in case of an error, there could be no res. And if you need a different behavior for success and error case, that's what try/catch are for.\n. Superagent doens't have its type definitions. Someone else wrote them incorrectly.\nSuperagent's request is a thenable, it only guarantees to have .then.. It's used by default. Use GET requests. On your server add \"Cache-Control: max-age=999\" (number of seconds) to make responses cacheable.. Looks like you're bundling code using webpack or browserify that are configured to produce browser-only code, but you're not running this code in a real browser.\nEither change your build system to build for nodejs, or change environment to be a real browser.. Add \"target\":\"node\", to your webpack config.. Yes, that was much needed. Thanks!. Thank you for the pull request.\nI'm worried that it might have other side effects, like replacing user's request.set('Cookie',\u2026). Maybe it should attempt to merge the header?\n. Instead of using the library you can concatenate both headers with ; as the separator. The cookie-jar is needed only to parse paths, domains, expiry dates from Set-Cookie header, but the Cookie header does not contain any of this.. You're right. This is a bit more correct.\nI'll merge it when I write a test for it.. Thanks! \nIt differs in how buffering is handled, but fortunately the rule was a bit redundant and there's a second place where it's fixed-up: https://github.com/visionmedia/superagent/pull/1176/files#diff-c24ce7e3da4c0e4ff811a2b6a76f8bd9R844. Thanks for the pull request.\n@focusaurus what do you think about adding this?. There's err.retries. I suppose we could add res.retries too. Would just the number of retries be enough for you?. I'm not sure where to take design of this feature. \nRight now it's a bare minimum, but retries overall can get very complex. Should superagent try to handle them all? For example, you may want to retry after a delay, and the delay should probably grow exponentially or with an s-curve (unless there's an online event, which should interrupt the wait). You might want to retry some errors, but not others. Maybe retries caused by timeouts should increase the timeouts.\nI think the callback could control more of this (e.g. return a promise to delay retry or fail immediately).. OK, so let's try this:\nSync MVP:\n\nthe callback should receive only one argument - the error that has happened (so it can check the error code)\nif the callback returns exactly boolean false, then the request isn't retried and fails with the error\nif the callback throws, the request fails with the thrown error\nif the callback returns true or undefined then continue as usual\n\nAnd an extra feature:\n\nif the callback returns an object with a .then property, then it's resolved using Promise.resolve(obj), and the request waits for the promise:\nwhen the promise resolves successfully, interpret it as a result from the callback (so give up if it's false, continue otherwise)\nwhen the promise rejects, then fail the request with the error from the promise\n\n\n\nI think it could be used as:\n```js\n// Retry only connection errors\nreq.retry(err => err.code != 'ECONNREFUSED'); \n// Retry after a delay, increasing with number of failures\nreq.retry(err => new Promise(cb => setTimeout(cb, 1000 * err.retries)));\n// Just log\nreq.retry(console.warn); \n``\n. I guess it's not needed.. That's done on master now. Looks likeTestAgentdoesn't have a prototype. That's not a type used in Superagent. It looks like you're trying to subclass it? But that assigning the prototype without copying is not the right way to do it.. Please supply complete code that I can run to diagnose the problem. Yes, for unbuffered request this works as intended, because superagent firesendevent as soon as response arrives, and then it considers the response done, doesn't wait for the body to arrive.. Unbuffered responses are unfortunately generally weird in superagent: #950 ..then()pipes the response to a parser, so at the point when *you* get tho seeres` it's already been finished and there is no more data to pipe anywhere.\nYou can't use .then() or .end() anywhere at all if you want piping.. It is in a weird place that only your parser sees. #950 . cc #1188. Are you sure that all of it is required? Did you find the root cause of the increased memory usage? I would prefer not to do a major refactoring of the whole library on a hunch.\nI'm especially concerned about changes to closures. Avoidance of cycles caused by closures looks like the workaround that used to be needed for IE6, but it was a problem very specific to IE's DOM, and it doesn't apply to V8.\nI see a potential for unbounded memory growth in image-resolver:\nhttps://github.com/mauricesvay/ImageResolver/blob/023ee8944ec4ca69932781f2282c53b38c6d9665/src/Utils.js#L33,L35\nso I think that's where your leak is, not in superagent. Thinning of superagent's objects just makes the stored-forever response objects smaller.. Thank you. The closure uses reference to the Request, which stays the same for lifetime of the request, so I don't see anything wrong with this code.\nWe have a test for the basic functionality, so it seems to work.. Sorry, I don't follow. \nIt's not always undefined. .abort() sets this._aborted = true;, so it can be true in the XHR callback if one is fired after the abort.\n. Good catch, thank you.\n. Superagent doesn't have any control over CORS. It's 100% internal browser thing, so if you get a CORS error, the browser thinks that CORS headers are incorrect. Please check the headers using devtools.\nThere's never any CORS in Node, so it's normal that it's not affected.\n. BTW: your FormData isn't going to work. Please use .field and .attach, and not your own object. Superagent has its own copy of FormData and can't merge two of them, so half of your form will be dropped.\nAlso you probably shouldn't set Content-Type, unless you want to expose unparsed internals of HTTP request body.. Hm, it may be possible. On non-HTTP failure XHR reports status == 0, which we guess is a CORS error, since that's the most common cause. If devtools console reports some other problem, then it is that problem.\nI don't know if we can get more detailed error information from the browser.. #144 #1154. Thanks.\nThat's a good idea. True CORS failure will be blocked quickly, so there's no harm retrying.. Thank you. You're calling request.get(\u2026).then(\u2026), and you need request.get(\u2026).then(\u2026).catch(\u2026).\n. Please note that await syntax is a different thing, and it's not related to the original question about \"unhandledRejection\".\nYou don't need .then() if you're using async/await.\njs\nconst response = await request\n        .get(url)\n        .set(headers);\nt.is(response.status, 404);\n. The code is OK. It says not found, because the url in your case is not found on the server that the URL points to. That's not a bug in superagent.\n. BTW: You never need to use new Promise when interacting with libraries that support promises (including superagent). new Promise is only for legacy callback-based libraries. This code is the same as your exaple:\njs\nrequest\n        .post(url)\n        .set({'Content-Type': 'application/json', 'X-Authorization': key})\n        .send({ k: v })\n        .then(res => {\n            return res.body;\n        }). OK ef9af6c85b2b1a0cf5f350bece2f7e33d89b888a. Right. Field name is always required.. Do you have an example code showing the bug that happens with retry?\nThis is supported:\njs\nrequest.get().query('arr[]=1').query('arr[]=1')\nSo this is a breaking change, and the fix must be different.\n. Thanks. I've made a fix for the root cause in #1200 . We define the dependency as ^6.1.0, which allows 6.4.0, so if you do npm update, you'll get the safe version.. Never set Content-Type with multipart, as it erases the boundary argument that has to be set by the browser.. Try adding .attach('_wahtever_', new Blob([], {type:'blah/blah'})\nThe reason is we use browser's own FormData to build the form, but it doesn't give any control over the format. Adding a fake file may force it to use multipart format.. Superagent doesn't know whether the problem is really caused by cross-domain communication. It can be any problem caused by the browser or the system.\nUnfortunately I don't know specifics of RN, so I can't help.. I can't fix this. Please report the problem to the author of \"superagent-no-cache\" plugin or the \"component-ie\" module.\n. this.qs is going to be misleading and inaccurate, since superagent stores stringified and non-stringified versions of query string separately.\nSimilarly with _data, which will be nonsense when _formData is used.. We've refactored query strings a bit since then, so it may be possible to reopen this. Anybody wants to make a PR? \nI suggest looking at _end() how full string is made there.. Is there a cross-domain redirect involved? (see res.redirects)\nThe offending commit is here: 68bc8c2e9615b5d577397f701f18c2ca7ab6f748\n. No, sorry. That option disables all security of HTTPS, and it's poorly named for such a dangerous option.\n. My concern here is that if there's an option in code that disables all security, then it's likely to be accidentally committed and left enabled in production.\nIf your test server is visible on the internet, then you can get a real cert from certbot/let's encrypt for free. \nIf your test server is localhost or some other private domain, then I suggest making the server URL configurable in your application and use HTTP URL in dev (and a domain that isn't accessible from production servers, so erroneous use of dev URL in production will be noticed quickly).\nAnd finally, you can create your own CA and sign your cert with it, and set the CA with .ca() option, although it is a bit of a hassle.. @rusekr Mozilla gives certificates freely as in \"for $0\", but not freely as in \"any cert to anyone\", so they still maintain strong chain of trust that self-signed/unverified certificates don't.. All DV certs are vulnerable to hijacking of authoritative DNS (i.e. not user's Wi-Fi, but networks at ISPs/hosting), regardless whether you pay for them or not. \nLet's Encrypt is on par or more secure than other CAs thanks to using ACME challenges (rather than e.g. SMTP), and they are adding even stronger protections against BGP-based attacks. (not that it matters given overall design of CA PKI, but I'm just correcting a rumor you're spreading).\nThere's Certificate Transparency which is another method of detecting successful impersonations.\nAnd if by \"hacking my DNS\" you mean DNS queries made by my browser, then this is exactly what verification of chain of trust protects against. So no, you definitely can't get a green bar this way (unless I foolishly made my browser behave like rejectUnauthorized=false).\nAlso, this is getting very off-topic. I find security nihilism arguments entirely unconvincing, so please don't continue this argument.. No, you're technically incorrect about this.. No, SSH's TOFU model is different than CA PKI and has different security trade-offs.\n\nIf i spoof your dns requests your browser will be checking my certificate chain, not yours (;\n\nAnd it will check it and find it's not authorized by any CA, and reject it. That's exactly what needs to happen, yet you still seem to be advocating for removal of this check that is critical for security.\nI'm locking this topic so you have time to cool down and not flood everyone in this thread with notifications.. This happens when there were too many redirects.. Are you using superagent, or supertest in your tests?. You can't call .send() more than once. Use .field or .send('foo=bar&baz=quz').. It looks like you're trying to build a form yourself. Are you sure you need this? To do this you'll also need to set the content type.\n. Chrome developer tools is logging XHR failures automatically.. We've had some reports that React native packages wrong version of the library (we have two versions: one for the web platform only (web browsers) and one for Node.js only.) \n. I'm not using react-native, so I won't be able to answer this. Try it, and report bugs you find to either react-native or here.. We've done this in ce2f27d5 . Unfortunately I don't know why this is happening. We're just passing the argument straight to Node's request:\nhttps://github.com/visionmedia/superagent/blob/8f1a90cbcc9aac066bfe58b4ad38ff2b3092bb46/lib/node/agent.js#L79\nso if it works with Node, it should work with Superagent too.. We use https://github.com/form-data/form-data so its {contentType:\u2026} option should work in Node. In the browser you'll need new Buffer([data], {type:\u2026}).. If you're making a request to a specific server that you control, then I think you can achieve a similar effect by using the .ca() setting.\nBefore having pinning in general I think we first should have HSTS support. \nBoth also depend on persisting the information, and we don't have a solution for this yet.. I don't know what React-Native is complaining about. We don't use Object.assign. Is it about implementation of FormData.append()?. Yes, does it happen only when you call .attach()?\nDoes it happen when you use form-data package without superagent?. I'm trying to diagnose the problem. I need to know which line of code is misbehaving. Is it a problem inside FormData or superagent?. The old whole-browser-locking sync XHR request is deprecated and won't be supported ever again.\nYou should give async/await syntax a try (you'll need Babel to compile for older browsers). It gives code as clear as sync code, but doesn't have the nasty side effects of the deprecated methods.\n. Fixed, thanks. It should work. I don't know why it doesn't. Duplicate of #1213. I don't quite understand your description. Can you post a minimal code sample that shows the problem?. So you're sending request to /foo?query=1, which redirects to /bar, but you want this to be redirected to /bar?query=1 instead?. I'm afraid this won't work. The server should be adding query when redirecting (so the /foo server should be taught to forward the query). \nIn HTTP there is no such thing as re-sending of the query string. There is re-sending of POST body in some cases, but it's mostly a legacy bug, so you shouldn't rely on it either.\nIn superagent you can set .redirects(0) and handle redirects yourself.. This is intentional. It's not incorrect, since interpretation of query stings is up to the server, and the query string format is older than JSON, so it doesn't give any guarantee that JSON will losslessly round-trip as query string.\nSuperagent specifically doesn't automatically add [] to query strings, because it supports query strings such as test?a=1&a=2, which are valid and used by some servers.\nIf you'd like URL test?a[]=1&a[]=2, then use .query({'a[]': [1,2]). You can also use the qs module directly, and pass serialized string to superagent.\n. If you want global, then you can patch or replace superagent.Request with a query method that you want.\nFor local behaviour, a .use(plugin) would work, the plugin could similarly patch the .query method (serialize using your settings, pass a string to super method).. But that wasn't the reason for gh-pages branch. The reason was it contains large auto-generated files that cause repo bloat and merge conflicts.. No, because it's OK to force-push a fresh version gh-pages branch and erase its history, which removes the bloat. But we can't do that with the master branch, as that'd break all hashes/tags/etc.. The test.html is a bit of a mess. I don't know, maybe someone is using it? It does provide a lot of code, so maybe it comes up in searches sometimes?. Ah, sorry for confusion. They way I currently work with it is:\n\nchanges to documentation sources (index.md, Makefile) are in master\nthe branch with result of make docs is pushed to gh-pages (git checkout gh-pages; git merge origin/master; make docs; git commit -a;)\n\nso in that way gh-pages is disposable.  I've copied your PR to master branch.. Great. Thank you. That probably fixes #1213 . It looks like this has stopped working again. \nhttps://travis-ci.org/visionmedia/superagent/jobs/331565966#L2282\nDoes it work for you? Could you take a look?. Superagent doesn't track the upload progress, it only forwards events from the browser.\nThis is probably bufferbloat: https://en.wikipedia.org/wiki/Bufferbloat. We don't support piping of uploads. You must use .attach() to upload a file.. Still the case, and unlikely to change.. You can use streams to upload files, just not with .pipe(), but with .attach(). We use FormData to handle this. That's just our API \u2014 multipart forms are handled via .field() & .attach().\n.pipe() is a special case in superagent. Waiting and error handling in Node is different for streams and doesn't play well with callbacks/promises, so it's problematic for us on implementation side, and confusing for users.. What about this example is wrong?. Thanks. Try configuring your server to allow that header via CORS: \nhttps://developer.mozilla.org/en/docs/Web/HTTP/Access_control_CORS#Access-Control-Allow-Headers. I don't see a reason to add buffering delay for requests. Why do you need this?. 1. In Node Nagle's algorithm is off by default, so without this change it's always off (good). With this change it's on or off.\n\nI don't see default set for this._noDelay anywhere, so it's undefined, and !!this._noDelay makes false, so your change makes it slow by default.\n\n. > https://nodejs.org/api/net.html#net_socket_setnodelay_nodelay\n\nnoDelay defaults to true.\n\nSo if true is the default used by node, and therefore used by superagent, the only use for this function is to set it to false. Why would you need to set nodelay to false?. Ah! I see. I'm sorry I misread that documentation page.\nI've tried this change and I tried to see how much it affects the speed, but I'm not seeing any effect:\njs\ndescribe('benchmark', function(){\n    it('nodelay', function(){\n      this.timeout(1000000);\n      const https = require('https');\n      return Array.from(Array(100)).reduce(prev => prev.then(() => {\n        return request\n          .head('https://geekhood.net/robots.txt') // remote serv in case localhost is special\n          .agent(new https.Agent({ keepAlive: false }))\n          .set('connection', 'close')\n      }), Promise.resolve());\n    });\n  });\nWith and without nodelay I'm seeing about the same speed (tested on macOS). \n. Yes, since I didn't see any negative side effect, I've enabled it all the time just in case.\nAs far as I understand cost/benefit of Nagle's algorithm depends on how the data is sent \u2014 whether it's sent all at once, or sent bit by bit.\nIn case of superagent user has absolutely no control over this. All of the sending happens in Node's underlying HTTP request library. Since nodelay doesn't seem to affect anything, I presume Node already sends all headers at once.\nSo I don't see why user would need to have control over this, since it doesn't depend on the user, but depends on Node's implementation. In case of superagent there should clearly exist a right and wrong setting, and there shouldn't be a need to let user set it to a wrong value.\n. Is that a superagent bug, or browser just doing its thing?\nDo you get different headers when using XHR?. The promise .then(res => {}) callback has only one argument. It never has any error. \nFor errors there's a second callback in .then(undefined, err => {}) or .catch(err => {}) callback.. We don't measure progress. We only pass back what your browser reports, so misreporting of 100% is a browser/Android problem.\nAs for the error, check whether your server allows large files. Most servers and environments like PHP by default reject files larger than 20MB or so.. That's a tricky one. \nWe certainly can't represent files this way. FormData is more flexible than a typical JSON, e.g. it allows duplicate keys.\nWhat do you use toJSON for?. You can do it already:\njs\n.ok(() => {if (!res.ok) throw CustomError(); else {return true;}});. Oh, that's a bug. We should be catching this and passing it on.. @caicai0 Try using constructs like Promise.all() or use async/await.\nHowever, please do not post in these comments, as they are about a pull request, which is totally unrelated to your problem.. Can you specify what error do you get exactly? Can you provide a test case?. Hmm, UTF-8 BOM is 0xEF,0xBB,0xBF. If you're getting 0xFEFF that's a big endian UTF-16. It's an awful encoding that has no good reason to be used, so it would be best if you could ask server operator to use UTF-8 instead.\nI'm surprised that UTF-16 has ever worked with superagent. Node generally defaults to interpreting all text-like streams as UTF-8.\n. We don't support piping to the request. You have to use .attach(). Oh, sorry. I wasn't aware of that :D If there's a test for it then I guess it should work, but obviously I'm not any better informed about what's going on than you.\n.attach() is indeed for multipart. If you just want raw bytes sent, you can use .send() with a Buffer.. fixed. Unfortunately this is a breaking change. Thank you for the PR. It's very useful. The code looks good, but there are some failures in CI. Can you check it?. This hasn't been a problem previously, so I think it's not a cause of caching/clearing, but difference in what these browsers were told to do.\nFor example, browsers' auth is different from superagent's auth - 620beaac\n. Ahh, I see :)\n. Sorry for the delay. I've cherry-picked your changes in 06d7865d5ab90cf0a84c914fd63e7a5e7be96b8f. I think that's intended here, sporting meaning \"to have as a notable feature.\". In the browser it's forbidden on purpose (C:\\fakepath\\ is hardcoded).\nIn Node I think we're just passing filename as-is, so it should be work.\nIf the path is important, it may be better to send it as a separate form field.. I haven't seen this particular problem. I have seen modules randomly missing with npm 5 in versions older than 5.3.0. Make sure you have the latest npm, or try yarn.. Could you help by making a pull request?. Fixed in v3.7.0. Thank you. Yes, you can keep the agent from request.agent(). You can store it in a global variable, or in an object that persists in your application \u2014 it depends on how you designed your program.\nKeep in mind that you still need to create a new request object for every request (i.e. call .get()/.post() and set options each time). The requests are strictly one-time-use-only.. The server is probably sending the response as text. It is essential that the server is configured to send the correct Content-Type header (with image/something MIME type). Without this superagent doesn't know that you've wanted to load an image.. Make sure it actually worked. Verify with curl -I <url>. \nYou'll get Buffer or Blob in res.body if this content-type is set.. Eww, you should never need base64 here.\nPlease show me response headers from your server. I'm 99% sure that you just didn't set the content-type header properly (perhaps different endpoint needs it, perhaps it's proxied through something that breaks it).\nIn case your server can't be fixed, then use this:\njs\n            .buffer(true)\n            .parse(superagent.parse.image)\nto force every response, even text or JSON, to be interpreted as an image.. Well, there you go: your server says it's sending JSON (\"application/json; charset=utf-8\"), not an image. If you fix that, then reading of images will work without a workaround.. .on('response',\u2026) will let you peek the response before body arrives.. Sorry, I can't help with this. This doesn't seem like problem caused by superagent.. Yes, superagent is a \"thenable\", so:\njs\nconst [foo, bar] = await Promise.all([\n  superagent.get('foo'),\n  superagent.get('bar'),\n]);\nwill wait for both foo and bar requests to finish.\n. I don't have any recommended CDN. Personally, I prefer bundling with webpack. When you use webpack it's also clear what is the name of the import and there aren't any globals to worry about.. We provide superagent.js compiled for web browsers in the npm package, so you can use it without having webpack or browserify yourself.\n. This was changed in #1066, because FormData doesn't allow empty values: #1065\nI see this can be annoying, and we've had a few reports about this already. Perhaps we should redesign how we build FormData (i.e. not use it directly, but create a filtered version when you call .end()). We already support this: https://visionmedia.github.io/superagent/#attaching-files. I see.  \nFor now, make it a Buffer or Blob and attach.\nSo far we haven't been paying attention to encoding of non-file fields. It probably be changed to default to text/plain;charset=utf-8.\nI'm not sure if we should be adding options to .field(), as it would make it almost the same as .attach().\n. It's not a bug. That's an ES6 iterator. It looks like you're passing iterable instead of a concrete object. Use Array.from(iter) on it before passing it to superagent.. Superagent already has no caching at all, so your problem is server-side/in the proxy.. Like the message says, you're using web-browser-only version of superagent and you're trying to use .ca() feature which can only work in node.js environment.\nRemove .ca() or run it in Node.js.\n. You can't use both. These are mutually exclusive features and can't work together.. Ah, sorry, I assumed you've meant pipe for downloading the request.\nSo this may work, although I have concerns:\n\n\ncan there be race conditions? Is it guaranteed that pipe event is called immediately and sychronously? It'd be a nasty bug if piping started after call to .then().\n\n\npeople often try req.get(url).pipe(output).end() expecting this to work. I'm worried about creating confusion where pipe() + end() works in one way, but not the other. And I'm worried that supporting piping and buffering at the same time will be hard (it's already hairy with gzip and async parsers).. I mean pipe client->server is OK, but pipe server->client is hard.. Yes. There are two kinds of pipes in superagent, and supporting end/then with only one of them creates inconsistency. Currently superagent doesn't support combination of any pipe with end/then, which may not be very useful, but at least it's a simple rule and is consistent.. The potential for race condition is worrying, so I'm going to close this.. Closing \u2014 https://github.com/visionmedia/superagent/issues/1277#issuecomment-332242818. Thanks. Superagent doesn't have this functionality. Mainly because it's not a common need, and it doesn't have equivalent on the browser side (we try to maintain parity).\n\n\nI'm not sure what to do about this. The use-case is valid, but probably rare.\nOn browser side we expose the XHR object. Maybe we can just expose the Node's request object too? (as a \"use on your own risk\" API for such rare cases). @focusaurus WDYT?. Unfortunately we only support UTF-8 for all text and JSON. You can't change it with any declaration.\nThe only way to send anything else is to create a Buffer or Blob manually with appropriately encoded bytes, but superagent doesn't have any functionality to help with this.\nYou probably should switch the server to UTF-8 or use another library.\n. Fixed in v3.7.0. Fixed. We've dropped support for Node 0.12 last year when it was EOL-ed and stopped getting any security updates. If you're still using Node 0.12 your first priority should be to upgrade to Node 6 ASAP.\nSee #1286. I don't see such require anywhere in superagent. Which file is requiring this?. The browser version of mime doesn't seem to be affected. Our tests pass in IE, and we don't use any ES6 transpiler.\nSuperagent 3.x doesn't support Node 0.x. All ES5 versions of Node are officially dead since the end of 2016.. It didn't change interface of superagent, and didn't change Node versions we support, so I don't think it's a breaking change.\nNode 0.x it not supported, neither by us nor by Node developers, so it absolutely doesn't matter what happens to it. People using Node irresponsibly long after the end maintenance period are now on their own with all the consequences of their failure to keep software even minimally up to date.. Superagent 2.x works on Node 0.10.\nSuperagent 3.x was never meant to work on Node 0.10. We've stopped testing on it, and intentionally bumped semver-major for this exact reason. It's clearly documented. \nAny Node module that uses Superagent 3.x requires Node 4 or later, and that's fine, because there is no older version of Node that is fit for use today.\n. ^2.0.0 is not compatible with 3.x (it means 2.0.0 to 2.999\u2026), so swagger should be fine. \nIt's possible that 3.x is pulled by another dependency (that requires ^3.0.0), because npm allows multiple copies of the same library to exist.\nSee \nsh\nnpm ls. npm ls will tell you why (search the output looking for superagent@3). There's also yarn why superagent.. Try .responseType('blob'). . Yes, it's a shortcut for responseType.. Thank you. Fixed in 3.6.3. That's very useful. Thank you.. Listen to redirect event and log what's happening. Try the same request using curl.. Sorry, this is very unlikely to be a problem with superagent. Superagent does not even require crypto. It's probably problem with webpack, its config, or some corrupted/incorrectly installed node module.\n. Thanks. Can you help by making a pull request that only pops the line if it's empty?. Thank you!. That is not quite accurate. 3xx by default are considered redirects and don't cause errors. They become errors only in non-default case where you disable/limit number of redirects.. Oh, I've forgotten about that one. Yes, it is an error indeed (we're unable to get its body). \nPerhaps clarify with \"non-redirecting 3xx\". That's good. Thank you.. Try .field('attributes', JSON.stringify({foo:'bar'}))\nYou can send strings as files with .attach('file', new Buffer('string')).\n. For browsers the major blocker is IE and a bit of iOS9 and Android 4. We have IE in CI, so hopefully this will catch any \"leakage\" of ES6 to the browser version.. Since retries are opt-in, I'm going to leave configuring details of them up to #1178. \nRetrying of 501 does not make much sense, but 500 does IMO: you may have flaky app severs behind a load-balancer and hit a working app server on the next request.\n. If your code is getting mysteriously stuck, it may be because it fails to call a callback somewhere. I recommend using Promise-based async handling instead (ideally with async/await syntax), which eliminates these types of problems.\n. If your code has function(err, result) and if (err) cb(err) then it's callback-based, not promise-based. Library called \"async\" (require('async')) is an old callback-based one. It's the old world in Node, and it has manual error handling and continuation.\nThe new stuff is async function() and await request() which is Promise-based.\nBluebird and other libraries are from the era of Node 0.x, which didn't have promises built in. These days you don't need any library for promises, they are built into the language like String, Array, and Object.\n. I think it's because the form-data library isn't passing this error to superagent. I've filed an issue with them.. I can't reproduce it. Works for me. Try HTTPS link  https://visionmedia.github.io/superagent/. It must be something on your side. In any case, that's a github-hosted page and I can't do anything about it.\n. Thank you for the pull request.\nUnfortunately we're not ready to upgrade this yet. Mime 2 supports only Node 6+, and we still have users on Node 4.\nI'm going to leave that pull request open until next major update of superagent when we'll be able to bump requirements to Node 6.. Thanks for the report. It'll be fixed in the next release. Can you reproduce it without supertest?. That's a tough one. It looks like cookies have to be based on the URL and can't use the Host header.\nTo support the Host header cookie setting would have to be moved to the .end() callback, but then you wouldn't be able to read cookies from the request object and overriding agent's cookies would need special handling.. Related one is #938 for TLS/SNI hostname.\nSo maybe it'd require an alternative solution:\njs\nsupeagent.get('http://cookie-hostname').ip('127.0.0.1')\nto override target IP explicitly this way.. That test passes, because it's a response. Client-side cookie handling only affects requests.. Thank you. 1. You're using superagent as a promise (request.then() or await request)\n2. You're not handling all errors. In Node.js you have to call a .catch() (or then() with 2nd arg, or await) on every single promise created.\nError: Unauthorized probably means HTTP response status 401\n. It's now possible with superagent (note that supertest is a separate codebase, so I'm not sure if has it yet):\n```js\nconst myAgent = require('superagent').agent().use(req => req.query(etc));\nmyAgent.post(url).end(cb); // posts with the query\n``. Fortunately you can't get an infinite loop here, since it only catches on success path.. Thanks. There's.ok()callback which lets you decide which responses are considered sucessful.. Can you verify it happens with other servers? It looks like a connection closed by the server, so the problem may be servers-side, and not in superagent.. Your server may not be expecting to receive unstructured POST. Try usingrequest.post().attach('file', stream).end()instead.. If it's put then it should work. Are you setting content-length?. Thank you for the PR, but I think it's not an appropriate modification.JSON.parse` defines what JSON is, so if it doesn't parse, it's not a valid JSON.\nsuperagent supports replacing parsers (globally via supeagent.parse[mime] or per request .parse()) so I'd recommend using that instead.. Can you help narrow this problem down? Does it work in 3.8.0? 3.7.0?. So the problem is caused redirects to another domain. (you can use .on('redirect', cb) to inspect them).\nChange in 3.8.1 is considered a security fix, because previously the Authorization would have been sent to every domain redirected to.\nSuperagent doesn't have a way to know which domains are supposed to get Authorization, so it plays safe and allows it only on the original request.. Thank you. superagent doesn't have any special abilities to affect express beyond what a regular http request can do, so it's entirely up to you to set things up in express the way you want.. The superagentPromise thing looks very suspicious. It's probably incompatible with superagent since version 2.x, which has promise support built-in.. Thanks. This is indeed a problem with \"thenable\" objects. The workaround is to return them wrapped in an object:\njs\nreturn {request};\nwhich will prevent promises/async from automatically calling .then on the returned value.. Thank you. Thank you!. It looks like browser limitation? Are you able to send body in options request using plain XHR API?. Can you verify whether the \"raw\" XMLHttpRequest API can make this request?. That's surprising and I don't see from the code how could it happen, unless something patched superagent in a broken way:\n```js\n// initiate request\n  const mod = exports.protocols[url.protocol]; // it's require('http') or require('https')\n// request\n  const req = (this.req = mod.request(options));\n// set tcp no delay\n  req.setNoDelay(true); // Node supports this since forever\n```\n. req.setNoDelay() is used only in the Node-only version of superagent. Perhaps instead of packaging the browser-compatible version of superagent, your build system bundles the Node version and then tries to emulate Node.js in the browser?. See if there's a string \"This is not supported in browser version of superagent\" in the compiled bundle. That message is present only in the browser bundle.\nThe node version contains node-superagent in the bundle.. From linked issues it seems this was a bug in jspm, and it has been fixed in jspm 0.17. Make sure you have an up-to-date version of jspm.\n. Thanks. If you'd like, make a PR to add it to the list of plugins in the readme.. Thank you. Fixed. Technically it is a breaking change (#950). Your case didn't fail tests only because we don't use that MIME type in tests. . Thank you for adding the tests.. In 4.1.0-beta I've added:\nhttp://visionmedia.github.io/superagent/#testing-on-localhost\nrust\nrequest.get(url)\n.connect(\"127.0.0.1\")\n.trustLocalhost()\nwhich allows you to force any HTTPS URL to connect to localhost (.connect(override IP)), and since the loopback connection is always safe by itself, HTTPS security on it can be safely broken (.trustLocalhost(true)).\nI know this doesn't solve all cases yet, but hopefully helps some, and still doesn't create a footgun.\n. You can listen to the redirect event, .on('redirect', cb). I'd rather not publish two versions/one version with two implementations. That adds overhead to publishing, documentation and bug reporting.\nDuring development a usual concern is to have source code readable in order to be able to use breakpoints, step through in debugger, etc.\nIf you need smaller packages during development, I suggest enabling minification in your dev builds.. We could minify the browser build we make and bundle in the nodejs package. However, that build is only for the front-end <script>, and not for common JS usage.\nHowever, if you're building a front-end JS app it's best if you bundle all your code together yourself (using webpack or such), so it can de-duplicate all dependencies.\nIn dev you don't need source of 3rd party packages every day, but when you need it, it's very helpful. It's also helpful for us to get bug reports with stack traces with correct line numbers.\n. I don't understand why do you set response headers. These headers are set by the server, and are supposed to be read-only for superagent. \nThe event handler is not supposed to allow setting response headers either. You're just abusing Node API.\n. The lack of rejection when the request is aborted is annoying. We should probably fix it by generating an error on abort.\nYou're right that Promises can defer calling then, so the effective order of things is .abort(), then .end(). \nHowever, I'm not sure if we should try to hide that and effectively support calling things out of order. Another approach could be to throw an error when .abort() is called before the request is started.\n. After all it turned out to be useful, so I've added it in v4. If you already have jQuery, then you can use jQuery.html() (if I recall correctly) to take advantage of its script magic.. You're right, and this is exactly to simplify such uses.\nIn the current version:\njs\nconst req = request.get(\u2026);\nreturn new Promise((resolve, reject) => {\n  req.on('abort', reject);\n  req.then(resolve, reject);\n});\nPromises always resolve only once.. Done in v4. Yup, that's ES6 sneaking in.\n. Our code is\njs\nthis._defaults.push({fn:fn, arguments:arguments});\nso probably your minfier is not IE-compatible.. By default all server-set cookies are thrown away.\nCookies are preserved only by a copy of an agent (.agent()) so create and use a copy of an agent for as long as you need its cookies.. Each instance of an agent has separate cookies. If you make two agents, they will be like two users.. Nope, it was meant to be field :). Thanks. It's a quirk. We have response.body = {} as the default value.. I'm not sure. It's different between Node and browser version as well -- that's a bit of tech debt that we have. . Thank you. Works. Thanks.. Piping and promises are mutually exclusive. .then() waits for all piping to be permanently finished.\nYou either only pipe or only use then/end callbacks, never both.. Fixed. Superagent doesn't emulate any browser. The Node.js version sends request using regular Node.js module, and the version for browsers makes XMLHttpRequest of the browser it's running in.. We specify \"marked\": \"^0.3.6\",, so npm update fixes it.. The message refers to your package-lock, so I think still npm update and committing the newer lock should solve this.\n. You will need .set(await myAsyncFunction()). Yes, .attach(\"multipart field name\", new Blob([xmlPayload], {type:\"text/xml\"}). If it's the Multipart/Related format you're after, then it's not possible unless you build the whole MIME message from scratch the hard way.. Superagent is not a replacement for supertest. Superagent makes actual, non-emulated, requests on the real internet.. Thanks. First version sends query in the URL, the second in POST body, so they are different.. That's a good use case. We have unset(), which currently only unsets headers you've set() yourself, but it would make sense to keep note which headers have been unset and avoid setting default ones.. Could you try implementing it? I think it could go like this:\n\nin unset save all header names that have been unset, something like `this._unsetHeaders[name] = true (keep in mind case-insensitivity, so lowercase names)\nin places where we set our own headers (lots in end() and friends) check for _unsetHeaders headers and don't set defauts if the name is set\nwrite a test for it.\nI'm not sure what should happen for .unset(foo).set(foo) combo. maybe it doesn't need special handling?\n. This is a typical CORS error. \n\nThe withCredentials response header looks like a read flag, because that's an option, not a header, so something is set in a wrong place.. I only see encodeURIComponent in superagent source. Can you give more information about the bug?. If you use browserify or webpack, it just works. You don't have to do anything.. Thanks\n. We depend on encodeURIComponent(\"`\") which returns '%60'. We still support IE, so we can't easily switch to the URL API.\nIt's not clear to me whether WHATWG URL recommends unescaped \"`\" or merely tolerates it as a recoverable error. The path encode set contains fragment set, which contains backtick.\nIn superagent you can set query as a string req.query(\"foo=`\"), and IIRC it won't escape it in the Node version (in the browser version it depends on what the browser enforces).\nBut in general I've got a feeling your server depends on a problematic feature. Given decades-old mess of fragmented specs for URL/URI/IRI the server should be prepared to support the lowest common denominator.. You're effectively making quotes a new special character, and creating your own new syntax for the query string. Consider using something else, e.g. double URL-encode the values or make your own escaping within query string values. Maybe use \\t as a delimiter? Or if you're adventurous, NUL (%00).\n. I've checked superagent's code. As far as superagent's own code goes, and it carefully preserves encoding of both ' and ` when you use .query(\"\"). It all breaks due to Node's url.parse(). Node's http module requires parsed URL, so that's hard to avoid. The WHATWG parser was added in 7.0, so we won't be able to use it until April 2019 (6.0 EOL). I'm reluctant to add another 3rd party parser just to support such an edge case.\n. I've used `` ` ``. Is it allowed to have unescaped '/` in the path? path.replace(/%60/g,'`') may be an OK solution.. Eh, I hoped for a quick fix :(. It seems that url.parse() is guilty here, so it should be changed. You should probably raise this issue with the Node core, but since it's a stable API they probably won't like the idea of changing it.\nI'd be OK with moving to the WHATWG parser, except for the pain of Node 6 compatibility. I'm worried that conditional require() will have nasty side effects in bundlers (we already get super weird bug reports about them).\nThe workaround you proposed is narrow (requires query as a string) and little bit on the convoluted side. It feels like tech debt for a solution that you will be the only person in the world to ever use.. OK, if you maintain it, I can accept the change :). I've just bumped major, which I plan to release on April 30th. Yes. IE9+. Please use our documentation and not some random website: https://github.com/visionmedia/superagent#supported-browsers-and-node-versions. This sounds familiar. I think we've fixed such error once already. Are you using the latest version?. Good catch! Thanks.. This is bizarre. We use regular setTimeout for this, which can't be that broken. Are you sure you're measuring correctly? and the request doesn't finish sooner by itself?. This error comes from Node.js. We can't do anything about it.. Thank you for the PR. However, I don't think that's appropriate. \nI see what you want \u2014 monitoring whether connection is still alive and timing out only after data stops flowing. That would be useful. But that's not what current timers are supposed to do. The deadline's main purpose is to kill slow connections, even if they're still going. \nIf you can accept the upload taking half an hour, then you can't set the deadline (or you have to set it to half an hour).\nThe _responseTimeoutTimer is cleared in readyState change >= 2, which is fired when headers are received. Its not set again, so doesn't need to be cleared later.\nSo if you'd like to implement watchdog timer for connection stalling, then you need to add a third timer. Don't cancel the existing ones.. No, don't touch the other options. They are independent.. The current options are:\n\n\ndeadline timer: kill the request if it doesn't fully finish entire upload and entire download before the time passes. Kills no matter what.\n\n\nresponse timer: kill the request if it doesn't fully finish entire upload and start some download before the time passes. Allows inifinite download time.\n\n\nBoth current options always limit upload time \u2014 on purpose. It's not a bug that these timers stop long uploads. That's their purpose. If you don't want uploads interrupted by a timeout, don't set these timeouts.\n. From what I understand, you are setting the deadline timer, which sole purpose is to unconditionally abort the request, and then you don't like that the timer fires and unconditionally aborts the request.\nThere's nothing wrong with the deadline timer, it does exactly what it's supposed to do. It's just not a feature for you, so don't use it. Don't call .timeout({deadline:\u2026}). \n\nHow can I avoid the deadline timeout to happen if I don't clear it?\n\nBy design, the deadline timer is supposed to be unconditional and intentionally impossible to avoid. If you change the implementation to clear the timer in some circumstances, then you just break that feature.\nWhat I'm suggesting is that you add a third kind of timer, completely separate from the other two, and then:\n\nDo not set the deadline, at all. Never. Just forget it ever existed. The default behavior is no deadline, which allows infinitely long uploads.\nUse the third kind of timer instead.\n\nIn that situation you don't need to clear the deadline timer.. Yes, this functionality (timeout since last bit of data was sent or received) would be useful in superagent. Here's previous discussion of that feature: #1115\nI've just remembered we've had reports that the upload events are buggy in some browsers: #1236 #1244 \nSo this is going to be a serious problem for uploads, and will require special handling (e.g. find a way to detect when the browser fires events for buffering rather than actual sending, or support the timeout only in browsers tested and verified to work).\n. Sure! I'm happy to help.. UNABLE_TO_VERIFY_LEAF_SIGNATURE means you haven't called .ca() to specify public certificate of your CA that did the signing.. Are you making request to https://192.168.10.103?\n. It'd still be great to have tests for it, otherwise it's easy to break it accidentally.. Have you verified it using other sources? I think devtools just don't display the content.. Please test with 4.0.0\nsh\nnpm i superagent@next. You seem to be using supertest. This project is superagent. They're quite different.\nPlease try to reproduce the problem without supertest involved at all, or file the bug in the other project.. Just as an aside, new Promise is only for converting non-promise libraries to promises. You shouldn't use it otherwise. In your case misuse of new Promise makes program hang forever on error. .then() returns a new promise already, so just return it.\nWhen the response is JSON, superagent puts it in res.body.. Thanks for the report, but that's a false positive. The domain is legitimate, so Malwarebytes needs to fix their mistake.. GitHub has proxied all images for privacy for a while now, so it's not a response to that particular failure.. Just FYI this isn't necessary. You can run npm update to achieve the same effect.. Could you help fixing that, e.g. by writing a unit test that catches this behavior?. Hi. Thanks for your response. I've been travelling and only now I've had a chance to have a look at it.\nI don't quite understand why there's stringFromCharCode. Is there a problem only if certain non-printable character is used?\nCould you do the test the format that can be used in https://github.com/visionmedia/superagent/tree/master/test/node ? Having it checked automatically in the test suite will help writing a fix and ensuring it won't be broken again in the next release.. In node it should work. In the browser it's just not possible at all.. It depends if you need it in Node or browser:\nhttps://visionmedia.github.io/superagent/#parsing-response-bodies\nhttps://visionmedia.github.io/superagent/#binary. .parser() and .responseType() are per request.. It is in the section I've linked to:\n\nYou can set a custom parser (that takes precedence over built-in parsers) with the .buffer(true).parse(fn) method.. No, that's node specific. For browser there's responseType. We're aware of the problem. Maybe you could help with this issue? #1362 . This looks like a message from your browser, and if the browser says CORS is not sent by the server correctly, then it's not sent by the server correctly. Inspect the headers.\n. ?. In general, we do not have any known problems with Chrome. 100% of our 198 tests pass in Chrome.\n\nThe code looks like from a test, not from actual superagent use. As it stands, this test is meaingless \u2014 it has no assertion, and doesn't even wait for the result.\nAlso you haven't provided any specific information about how chrome fails, what was expected and acutal result, and relevant information such as http headers from the client and the server.. So for purpose of printing the code looks fine. I can't help you without specific description of what doesn't work, what should work, and what HTTP headers superagent has sent and received (from Chrome's network inspector or tcp dump).. No, superagent is supposed to be for performing requests, not for representing them. \nIf you're trying to write a test/assertion to catch potential bugs, then I guess there's no better way. Otherwise you should ensure in your application logic that you don't set unwanted request data in the first place.\n. __proto__ is a non-standard hack. While it has some uses, I don't see why would it be useful for sending JSON. Behavior of JSON.stringify seems sensible here.\nSo I think current behavior is fine, and I'd rather pretend __proto__ doesn't exist and not support any objects hacked that way.. It's best if the server decides what to do, not the client. Make the server send Connection: close HTTP response header and most frameworks will handle that for you.. So, we have this huge dilemma between perfectly preserving formatting of existing query string, and updating it (some people are very picky about their query strings and want them exactly as set, byte-identical, in the right order, with the specific encoding of specific characters).\nTo keep everyone happy, superagent keeps query string both as a whole string, and also as a separate object with keys/values, and then tries to merge them. And we used to have separate implementations for browsers and Node, because they use different libraries.\nThe behavior you're expecting seems reasonable. I suppose we did something wrong with merging the strings?. You get 404, because your path on localhost:3000 doesn't exist. Probably you need to add routes to the server or ensure your URL is correct.. Your problem has nothing to do with superagent. Delete all superagent-related code and it will be 100% the same. You haven't defined routes for your server.. If you see status == 0 that's a CORS (security) violation from browser's perspective. The response contains data that the browser wants to keep secret. This cannot be fixed in superagent. The browser refuses to expose information about this error.. @rhae Thanks for looking into this. Can you capture HTTP request headers from superagent's request, and from yours? I suspect there's a difference in them that makes superagent require CORS.. 1. Superagent uses ^3.0.0 so it picks up the fixed version of extend whenever available. If you run npm update you'll get the fixed version.\n\nIt is very unlikely to be a problem, because extend is only used for merging of the query string, and we don't do anything interesting with query string's prototype.\n\nI know auditing tools will keep complaining until we bump the version. I'm not a fan of such tools, since they require changes for sake of changes, and raise alarm over a non-issue.\n. Thank you! That's a very useful functionality.. Does EXPOSE_HTTP2 affect ability to make HTTP/1 requests? Is Node going to fall back automatically? I wonder if we need to give more runtime control over this.\n. @focusaurus do you have a preference how HTTP/1 vs 2 API should look like?. Thanks. If the server has responded, and the page is allowed to see the response, there will be e.response. \nPlease note that in many cases, especially cross-origin errors, browsers deliberately hide all details of errors and intentionally make it impossible to learn what happened, as network errors are a privacy leak.. JS is unfortunately deeply broken when it comes to mixing OOP and errors. Due to a bug in the definition of the language Error can't be a base class, and preserving sensible backtrace is a mix of impossible and non-standard.\nI think \"duck typed\" errors are good enough for superagent, and it's valuable to pass underlying errors (mostly) unmodified.. In Node .redirects(0). In browser \u2014\u00a0not supported at all.. There's .ok() callback that decides which status is an error.. https://visionmedia.github.io/superagent/#error-handling. Because it's not success (2xx). Bodies of 30x responses tend to be garbage.\nYou usually don't see 30x, because we follow redirects.  If there are too many redirects and we stop following them, then you get 30x. That's probably not what you expected, so we default to erring. \n. Unfortunately, we don't have a good solution here.\nDo you know if the cookiejar library has support for matching cookies by domain? I'm not sure if we're using the library properly.\n. That .expect() looks like supertest, which is a different project. Can you reproduce the bug with pure superagent?. We don't maintain the TS interface. Please report it to DefinitelyTyped or author of the ts file.. No, we don't support streaming.. You haven't set the URL to fetch, so there's nothing to do, there's nothing to wait for.. That's a very good point. Would you like to help documenting them?\nSearch the code for uses of emit function. There's also response event in addition to the ones you've listed.. I assume you're worried about text being presented as \\\\x63 and not an actual character.\nThis seems fine to me. It's just presented this way, because you've printed it from an object (presumably using console.log or similar).\nIf characters aren't correct, it may be because they use a different encoding than UTF-8. We only support UTF-8 and do not plan to support anything else.. .send() is only for sending plain text or JSON.\nUse .field() for setting form fields.. There's no BOM in UTF-8. That's a made-up hack for Windows Notepad. The JSON spec explicitly forbids use of the BOM in UTF-8, so superagent's behavior is correct.\nSuperagent only tries to parse response as JSON when the server tells it to parse it as JSON by setting application/json Content-Type. If the Content-Type was something else, like text/plain, then it wouldn't be parsed, and the non-JSON data would be allowed.\n. BTW, we support overriding of parsers. The API is a bit tricky to use, but you could try copying code of our existing JSON parser, set it as parser for the request, and make it skip over the problematic character.. Thanks!\n. Thanks for the fix!\nDo you know if express plans to release HTTP/2 soon? I'd rather use a dependency from npm than git.. Thanks! . root is not a reserved keyword. The code works in es5 and es6-compliant browsers without any warnings about this. \nPlease file a bug in the uglify project. . It's not a module. It's a stand alone copy to include in web browsers like it's 1999. . ``js\nconst req = \u2026;\nconst res = await req;. Req isn't a promise. It's \"thenable\", which means it's converted to a promise when needed. . I think we're not using promises at the core yet, so if you use end() callback it should work without promise polyfill. . Did you call.then()`? That one case requires promises, but non-promise interface shouldn't.. Requirement is documented here:\nhttps://visionmedia.github.io/superagent/#promise-and-generator-support\nand here\nhttps://github.com/visionmedia/superagent#upgrading-from-previous-versions. I suspect it may be tricky, because we share files between Node and browser. For browsers compiling/copying is a necessary evil, but we only support ES6-capable Node versions, so it's desirable to serve ES6 files directly to Node.\n. That's a huge PR with many unrelated changes. It'll take me a while to review it. . Hi! \nSorry, there are too many unrelated changes. I can't accept this PR. I don't have time to review 20000 lines of changes.\nIt doesn't matter that the changes are just from a code formatter, I can't accept code changes I haven't reviewed, and basically everything everywhere has changed. \nI'm still keen to improve compilation for browsers, but just that. Please leave out changes of quoting style or moving commas and semicolons around.. Indeed, in superagent v4 we've dropped support for ES5. If you need ES5 compatibility, you have to either stay with superagent v3 or transpile.\n. Thanks for the suggestion. I'm not sure if that change is appropriate. It's an indirection, but not abstraction.\nUsers would still need to understand mapping between .range() microsyntax and HTTP semantics. If header syntax errors are an issue, superagent could handle the problem directly by checking the syntax of the header.\nProper support would need more changes. For example, response with multiple ranges should probably have body as an array of Buffers, and we should be smart enough not to try to parse fragments using parsers designed for parsing a full response (e.g. fragments of JSON are not parsable as JSON). But I'm not sure if ranges are used often enough to justify all the changes to have good range support, and just a minimal one doesn't seem that interesting.\n. Resilient downloads sound cool, but in non-piping case we keep the result in memory, which limits how large the large file can be. So it may be better left to a higher-level downloader that also manages on-disk storage.. Thanks for the PR.\nI agree it's better to have some consistent style, but such changes for sake of changes are just going to cause merge conflicts with other PRs.\n. Did you intentionally enable HTTP2? Does it work over HTTP1?. OK, I've checked the code:\nIgnore the HTTP2 line. It's always printed on Node 10 and later. It's not an error, and it doesn't mean anything.\nThe error is about lack of .catch() in your code.\nYour problem is only later \"UnhandledPromiseRejectionWarning: Error: Unauthorized\". That means you have made HTTP request to a server, but the server returned status 403, and you've ignored that error by not having .catch() in your code.\nEvery time you use .then(), you must also catch Promise errors (i.e. have .catch() somewhere later, or 2-argument version of .then(), or use async/await syntax instead of then()).\nWhen you launch node, add --trace-warnings, e.g.\nnode --trace-warnings index.js\nand it will show you where you must add .catch() calls.. Yes, you can ignore everything that mentions http2.\n. It's disabled on master\n. It looks like your server is paying attention to MIME type of the attached file, but the browser doesn't know/can't know what the right value is expected.\n. This shouldn't be possible. Are you using some compiler/transpiler/packaging tool that breaks it?. The major breaking change in v4 is use of ES6 in the source code.\nhttps://github.com/visionmedia/superagent/releases. Indeed, there is no support for async plugins. You have to wrap superagent in your own async function.. I totally agree it'd be useful. Go for it!\n. Please report it to the author of index.d.ts. We don't maintain this file.. Is it even possible at all to upload something without a length?. Thanks. I don't use Electron, and it's not a supported platform for superagent, so I'd rather not maintain workarounds for it. It's a bug they should fix.. That's most likely about non-ASCII characters in HTTP headers. \nDoes the filename contain any non-ASCII characters by any chance? Alternatively, are you setting any other headers that could contain non-ASCII characters?. Mutable state is already quite problematic for superagent, so I'd rather not add anything more in that direction.\nYou can build the features you want as a higher level on top of superagent. Building of request objects isn't expensive, so it's perfectly fine to make new request object every time you want to send a new request.. It's meant to be \"to sport\", as in exhibit, parade, flaunt.. Fixed in 4.1.0. > SyntaxError: Unexpected token \ufeff in JSON\nThis is not a bug. It means the server has sent some garbage instead or in addition to the JSON. It may also be caused by use of non-UTF-8 encoding.\n. If JSON.parse() doesn't parse your data, then the data is not JSON.. No, that's not how this works. You must fix your WordPress to send valid data, rather than break everything touching the broken WordPress.\n. I don't have admin rights, so @defunctzombie needs to do that.. Sure, make a PR.. Since you're using regex anyway, you could reduce the code to /[\\\\+]json\\b/.test(mime), and it'd be parsing a bit stricter.\n. Right, I've got slashes backwards.\n\\b to support foo/bar+json;charset=x. Stricter version would be json\\s*(?:$|;), but I was trying to find a compromise between correct parsing and a simple regex.\n. if that endpoint echoes, then the file is downloaded as well. It's a bit worrying that there's no download event after the upload.\n. Can you change the test to be forwards-compatible, e.g set a flag that a desired event has been seen?\n. Should emitter be called on the base only?\n. Oh, I didn't realize the Stream complication.\nWhat confused me was that RequestBase is called in constructor, which looks like \"single inheritance\" pattern to me. I'd expect JS classes to either emulate single inheritance, or patch prototypes at will, but not both.\nWe can't fully use single inheritance pattern (with full prototype chain, Object.create, etc.), so in that case I'd go all the way the other way and make it clear RequestBase isn't a class, but only a bunch of functions to copy.\nSo my suggestion is to remove call to RequestBase in constructor. Perhaps even instead of using function.prototype, just assign functions to plain object module.exports = {method: function(){}}, so it's clear it's not a real base class.\n. How does it behave when compiled for the browser? Will it cause an unused module to be bundled?\n. what about chunked transfer encoding? (that does have a body, but no content-length)\n. I'm using Mocha's Promise support here: https://mochajs.org/#working-with-promises\n. This may not work in the browser, where we use native FormData without on methods\n. Looks like we don't have a browser test that covers this method. Could you add a shared test that calls \njs\nrequest.post('/upload')\n     .field('foo', 'bar')\n     .end(callback);\nand see if that works? (with make test-browser-local)\n. Yup\n. That doesn't look right. What if {filename:\"foo\"} is passed? Wouldn't it call the file something like [Object object] instead?\n. That looks odd.\n\nYou shouldn't need to read the timeout from the error. Read request's properties set by the timeout() function directly\nif you needed to identify error thrown by superagent, add a property to it, don't touch the message. Maybe err.retries?. I don't understand why it skips errors here. \n\nAlso note that all these handlers are .once(), so they should have been re-attached again on retry. That's why I've mentioned earlier that .end() may need to be split up into once-ever and once-per-retry functions.. That is set in end(), so you shouldn't need to change that. Doesn't this break things? e.g. append query string twice?. Please make sure that .abort() called by the user stops all retries. This may require creating a private abort for superagent's timeouts.. In CI we have multiple browsers running the test at the same time, and I think they're sharing the server, so they could interfere with each other's attempts.\nIt may be more robust to take a random ID from the client as an argument, and count retries per that ID (/error/ok/:id, attempts[req.params.id]++). Oh, yes, delete it there.. Sorry, I've meant it's set in https://github.com/visionmedia/superagent/pull/1155/files#diff-c24ce7e3da4c0e4ff811a2b6a76f8bd9R145\nIt's not an error, but it's redundant. _retries are never increased before .retry() is called, so there's no point zeroing something that's zero anyway.. I don't understand why these fields are deleted here. The timers are probably cancelled when the error happens (they should\u2026), and should be irrelevant later.. That looks good!. Ah, I see. In that case it's OK. \nHowever, have you considered https://visionmedia.github.io/superagent/#agents-for-global-state agent.buffer(true)?. You're not resetting the timer, so it allows infinitely long upload time after first event (so if e.g. 1% is uploaded quickly, nothing will stop remaining 99% taking forever). I suggest assigning that callback to a property and using the property when resetting the timer to avoid recreating the closure frequently.. You must write unit tests for it, because you've written non-working code second time in a row. \nThis is not a comparison, but an assignment (the condition is always true in this case).\nTotal is not a percentage, but amount of data to be transferred, so a comparison with a 100 byte file size doesn't make any sense.\nIf you're only clearing the timer without resetting, it doesn't add much value beyond response timeout. You could just add upload time to response timeout.. If you set timer once, and clear it once, then it's a one fixed length of time from start to finish. It doesn't change the timeout if there's one progress event or 100 progress events in the meantime.\nThe response timeout timer has the same inflexible behavior - it's set once, and cleared once. The only difference is that it's cleared in readystate rather than progress event, but that's not a major difference most of the time. So effectively your approach doesn't bring anything new.\nThe adaptive approach would clear timer and set a new one after every single progress event. (that's why I've suggested using a bound method, btw). That would make it adaptive to rate of events.\n. For the \"lint\", we use unit tests as the lint. See existing tests. Write an endpoint for our built-in server, and then write code for success and failure case you expect.\n. Is it necessary here? In normal implementation we allow options.host to be different than host header, because it's useful to do request.get('http://[ip address]').host('example.com') to force request to connect to a particular IP address.. AFAIK browsers also send http/1 here. Do we support a fallback?. Why is such conditional parsing needed?. Why is this needed?. \ud83d\udc40 . Can you explain this change?. Maybe this should translate the header to HTTP/1 header, or allow both in the test using it?. So it would be better to improve the check, otherwise host like httparchive.org would be misparsed :)\njs\n/^https?:\\/\\//.test(value)\n. I see. If there's no fallback, then that's OK.\n. ",
    "tj": "could probably do that if we nextTick() the request, sounds good to me\n. looks better too IMO, and that way we can have .headers() and the regular .setHeader() etc working as well\n. totally, I do agree. it gets very unwieldy trying to pass all this stuff as an argument, which was the main reason I started this mod haha. I'll try and get that in soon\n. the api was revamped to match the client-side one more closely\n. we would just have something like this (agent is really SuperAgent, the constructor):\nvar myagent = agent('whatever.com');\n myagent.get();\netc, similar to what you want but I think we should keep the host as the initializer, at least for now so that we can map the agents from that call\n. closing for now\n. yeah you shouldnt use 0.5.x yet, tons of mods will break\n. when 0.5.0 is out I'll support it\n. When it's released\n. hehe :D superagent was originally a SS node thing but I'll rewrite it to make the APIs more similar\n. it doesnt work with node yet :p. It used to be node-only (which is in npm) the API was a bit different and I needed a name for this client-side one so I scrapped it but I'll be adding it back\n. wahoo! thanks man, I knew someone would do this haha :D appreciate it\n. cool cool. I just never care enough about IE to bother wasting space on my machine haha :D but I dont do much client-side stuff\n. ah im done this, forgot to close it :D\n. build up my friend! up!\n. the high level stuff like piping files etc can be layered on top easily\n. minus .data() since that is now .send(), and should be .pipe() for multipart streams\n. then you end up with inflexible APIs like request, obviously you have the high level API in mind, but that's definitely not the place to start building\n. that's probably what mikeal had in mind for request haha and look at it now, it's just one big function. just takes a bit of time that's all\n. nope: https://github.com/mikeal/request/blob/master/main.js#L100\n. haha :D this is why I started superagent, didn't want a rushed lame api\n. im just saying there is more to an API than the highest-level. If you need to set a header field then you need a method for that, if you set a content-type then you need a method for that, if you set a content-type based on a filename the you need a method/mime lookup for that. These lower level APIs would be great for testing node apps, crafting multipart requests that reside in memory (node-canvas etc), and they're basically required by the higher level API anyway\n. you could say the same thing about node's setHeader() vs writeHead() which much more flexible\n. stream.pipe(part) would stream the raw contents to the Part, so you still set the header fields. part.pipe(stream) would use the stream.path to determine the content-type etc, and perhaps part.pipe(path) would create the fs.ReadStream for example. That's more what I would call \"proper\" abstraction, it's all things you need anyway\n. nope nope\n. \"A multipart/related is used to indicate that each message part is a component of an aggregate whole. It is for compound objects consisting of several inter-related components - proper display cannot be achieved by individually displaying the constituent parts.\" - http://tools.ietf.org/html/rfc2387\n. not sure why im not using multipart/form-data in part.js haha... wth\n. one of those sleepy nights i guess\n. my example isnt even right \"mixed/related\" it's \"multipart/related\" hahaha\n. just ignore me haha\n. haha yup :) make wont do anything unless the files are modified, but yup it's node + browser (node stuff isnt finished yet)\n. i havent finished up the node stuff yet\n. plus qs should be a dep not a devDep in this case, I'll add that\n. i added the client-side API so I'm remodeling the server-side api to match, it should be done soon\n. i think so\n. I would definitely prefer .timeout(ms) personally\n. ah yah i'll have to come up with some better docs\n. may end up changing it anyway so the tests can run on node and the browser\n. actually yeah i'll change this. though the typical errors for the CS will be parse errors etc, pretty rare I'd think. I'll be adding global error handlers so it's less redundant to deal with\n. on the client/server-side that would be for things that are truly exceptions like parse errors etc, not just responses. I got really frustrated with all the special-casing that jQuery had, a request is a request, and a response is a response, so they are not currently treated differently. That being said I do plan on adding optional global support for error handling so you can opt-in to that\n. though on the client-side we could just ignore parse errors and leave the res.text as the invalid json or whatever. the inconsistency would just have to be properly documented, or we could do the same for the node end, and emit error events\n. the only issue I have with it is that it gets rid of the typical (err, result) signature that everything in node uses, but it'll be nicer to use for sure\n. i like the idea but at the same time i dislike it haha, but since it's stream-like I think we should be fine to just emit errors, and then if no listeners are present for that stream we can have the global handler superagent.on('error'.. or whatever\n. yeah it's a bit tough since on the client-side, errors will be pretty infrequent and you'll ideally want to handle them globally quite often, though not always. The server-side is slightly different, but core does this actually with http.get(options, callback(res)), there's no error signature there. We could simply emit the error, but with node if you emit \"error\" and do not have a listener it'll throw, so it's a tough call \n. haha yeah we could. it's definitely annoying, you already usually will be checking if (res.ok){ blah blah so checking an error too is annoying\n. I decided what I'm going to do is both, but you can opt-in for the error otherwise you can handle it at the globally:\n```\n.end(function(err, res\nvs\n.end(function(res\n. yeah it's nice when you need it, but on the client it's not uncommon at all to just have a global handler and show some kind of notification etc, we really need both\n. @alexeypetrushin nope that should be fine. I'll be doing similar, a way to handle errors \"globally\" would be nice too for some cases\n. damn lol i'll try and get a test suite going since my node/browser one isn't ready yet, or i'll just try and get that done soon\n. oh wow haha... not sure what I was thinking there\n. I dont think I'm passing the error yet for the CS version, even though it'll be a lot more rare \n. ahahahaha you're drunk? nice man haha. yeah that inconsistency has to go\n. ahahaha niiice\n. thankya\n. related to another issue\n. hmm... something is definitely up there. what is assignSocket?\n. ah :) I use netcat's server feature `nc -l 3000`\n. I'll try and get some tests for superagent soon \n. this can be a plugin\n. the callback signature is `(err, res)` not `(req, res)` :p but nope, there wont be a sync api, in fact with node you cannot have a sync api\n. np!\n. weird, i marked it as a bug i'll have look when i can\n. these shouldn't be globals, mocha's not reporting anything\n. this is a formidable bug\n. formidable doesn't support preambles currently, but I had to change this in master since I'm using formidable to test things anyway\n.\nmultipart-body := preamble 1*encapsulation \n               close-delimiter epilogue \nencapsulation := delimiter CRLF body-part \ndelimiter := CRLF \"--\" boundary   ; taken from  Content-Type \n```\nas you can see \"technically\" it should start with CRLF\n. hmm?\n. done a while back\n. +1\n. i'll close for now cuz i'll be revamping them a bit when i doc the node stuff\n. global usage:\njs\nrequest\n  .use(request.gzip())\n  .use(request.retry())\nsingle usage:\njs\n request\n  .get('/something')\n  .use(request.gzip())\n  .end(...)\n. with pull-requests :p haha\n. +100\n. closed by 8bcac5f\n. node or the browser? I may have forgotten to port it to the browser\n. hmm strange. you can always do nc -l 3000 and request against port 3000 to see the request\n. yup\n. i'll try and update the docs soon\n. boom merged\n. merged we'll have to port it to the CS i'll open an issue for that\n.  what's the motivation for having the strings vs obj?\n. oh weird I have support for this already in the browser sorta \n. DELETE can have a body as well, maybe what we should do is have an explicit .query() method, and for GET .send() can use .query() but others can use it so you can still say POST json but also use the querystring\n. https://github.com/visionmedia/superagent/issues/59\n. 57531c3\n. yeah i need to go through and redo the docs, lots of stuff missing, we have an issue for this already i think\n. my bad, yeah i'll have to clean that up a bit haha. it doesn't really have a name, not sure what I like best\n. .query() is there for both the browser and node\n. request.get('/users').query({ sort: 'desc' }).end(fn) blah blah\n. if it's not in the latest npm release I'll release soon\n. maybe I just didn't release yet, can't remember when I added .query() it could be in the history.md file\n. nc -l 3000 and request against port :3000\n. those are not booleans, those are just integers, true / false are booleans, but yeah there was a bug in the qs module I need to update it\n. updated, next release will allow that properly\n. @simukis what?\n. oh haha nvm I get it, yeah, if you dont mind opening another issue for that so i remember\n. needs a rebase but other than the style related stuff I'll merge, thanks!\n. just realized you dont have any tests for this new code\n. if we're going to do the coercion thing we should do it in node-querystring, but I think it still might surprise people, tough call, both helpful and potentially confusing\n. ah. yeah fair enough. feel free to open an issue for node-querystring, maybe we can get some feedback from other people and see what they think, im impartial, I think it would be nice but either way is fine with me\n. doesn't jQuery.param take some gross array?\n. nvm im thinking of serializeArray\n. well anyway node-querystring supports the client now so it should be easy to integrate \n. doh, thanks! we should add Buffer support too as well actually, I'll add an issue\n. yup\n. @noisebeuter cool thanks man. In general? or related to this buffer stuff? we should definitely add a few tests for this in ./test/node/*\n. hmm did you try res.text?\n. node doesn't give you a string of the header but you could just log out console.log(res.headers), and in many cases you dont dont want a string representation laying around, if it's a large multipart response etc\n. my bad, yeah that's not right at all\n. yup: https://github.com/visionmedia/superagent/issues/27\n. you could use toJSON()  one way, but yeah we would need something the other direction. we would like to add some kind of plugin system eventually as well\n. there's nothing yet but we could have something\n. we can do this via plugin once we have https://github.com/visionmedia/superagent/issues/44\n. haha my bad, habit of not caring for shitty browsers. we dont need to use reduce, a simple for loop will do\n. 3xx are all redirects, that's what 3 == (res.statusCode / 100 | 0) was for\n. ah ok I see what you're saying. Nah I think it's fine in here\n. awesome tahnks man\n. pipe() invokes end() unless you do req.pipe(out, { end: false }), kind of a lame API but that's a node thing\n. oh nvm i'm overriding .pipe() to get the \"raw\" streamable response. it should be a pretty simple fix\njs\nRequest.prototype.pipe = function(stream, options){\n  this.preventBuffer();\n  return this.end().req.on('response', function(res){\n    res.pipe(stream, options);\n  });\n};\n. i have a different module for the client called \"emitter\" for something I'm working on, but maybe we can add support for \"events\" since browserify will use this too\n. well the thing is that it's detecting exports for a thing I have in the works, which just happens to use \"emitter\" instead of node's one because it has a slightly different API and removes the require('events').EventEmitter fluff. We would need a way to tell which environment this thing is in even with both module and exports is present \n. gah haha fragmentationnnn..\n. +1\n. disabled agent\n. i get a few with master for 0.8.0 i'll take a look\n. definitely some kind of weird regression for 0.8.x im seeing a couple double .end() calls\n. yeah i'd like to add a cookie jar, it'll be a bit sloppy unless we add an agent concept kinda like node has to tie the requests together\n. needs a rebase as well the diff is all weird\n. woah something is going on here haha a rebase issue maybe\n. i'll fix the markdown\n. fixed\n. hahahaaha shit\n. merged + test added + 0.7.0 released\n. node or the client one? it should be reasonable to propagate for the same host at least\n. fixed\n. yeah should be a pretty straight-forward fix we just have to re-.set(headers)\n. oh shit, thought i updated that\n. fixed the docs\n. why don't they supply a regular XMLHttpRequest? :s seems odd if the rest of the api is similar\n. i'd love to have both superagent.parse(mime, callback) and request-level request.parse(mime, callback), but I think they should stay async like they are currently\n. it should be this signature https://github.com/visionmedia/superagent/blob/master/lib/node/parsers/json.js\n. squashed / merged\n. I must have forgot to build, I'll retag\n. https://github.com/component/url/commit/e04a3e6dda3074e99d688222c93ec1325a1a3791 :)\nneed to get superagent going as a component, we have a query-string parsing component as well so there's quite a bit superagent could ditch\n. i dont have an IE vm right now so i can't verify the hostname portion, and location var shouldn't matter since it's already global\n. we should be able to refactor this more now that it's a component, needs a rebase anyway, sorry for the delay\n. thanks! for some reason I was waiting on \"main\" to point straight to lib/ but this works!\n. why not use the express.compress() middleware? it'll do all this for you\n. your request doesn't make sense because you're saying the response is a gzipped gzip file\n. hmm odd, works 100% fine to me:\n``` js\nvar request = require('./');\nrequest\n  .get('http://a248.e.akamai.net/assets.github.com/assets/github-6f9ac9220676fa355e8b13e0403cf7972fdabbfb.js')\n  .set('Accept-Encoding', 'gzip')\n  .end(function(res){\n    console.log(res.text);\n  })\n. nvm that seems to not even be responding with gzipped data\n. js\nvar request = require('./');\nrequest\n  .get('https://github.com')\n  .set('Accept-Encoding', 'gzip')\n  .end(function(res){\n    console.log(res.header['content-encoding']);\n    console.log(res.text);\n  })\n```\n. ah that did it for me, ill take a look\n. hmm can you paste your code? it should be fine:\n``` js\n\nrequire('qs').stringify({ a: 1, b: 2, c: 3 })\n'a=1&b=2&c=3'\n``\n. closing until we can reproduce\n. oh i didn't realize it was the same name each time, my bad. Our current behaviour in node-querystring is to make it array-like with[]when it sees duplicates, but there's a discussion in one of the issues about changing that\n. yeah im sure we can change that, i'll reopen\n. in later superagents you have to do.buffer()if the response is nottext/*orapplication/json. sounds good, do you mind adding a test?\n. I'll pull for now, hopefully we can get a test in there soon\n. hmm which version of component? make sure you're on the latest\n. cant read coffeescript :(\n. ah i see, yeah superagent is not a server so you dont get(req, res)like that, there's no direct access to the session\n. nope, sessions are never exposed to clients\n. success callback is redundant since that's what you give to.end(), it could still be useful for pluggin in other things so im not against it but I wouldn't use it as the primary way to handle the response. \"error\" we already emit though not forres.status\"errors\", only for real errors at the moment but that needs some refactoring, I'd like to make it so you opt-in to http errors\n. ill update the docs soon, they're definitely lacking in some areas\n. hawt\n. 0.9.8\n. hmm a little hacky. I'd prefer https://github.com/visionmedia/superagent/issues/136\n. yeah you have to use.field()for multipart, send() could possibly utilize this if it knows it's multipart\n. well there's the site: http://visionmedia.github.com/superagent/\n. closing for now\n. we only do multipart/form-data at the moment, so we can't put json in, we could eventually do multipart/mixed or something but then things like formidable will fail\n. but it would be nice to have.fields(object)or something similar that invokes .field() a bunch\n. you can.concat()Buffers, that'll be more efficient than the binary string encoding, though ideally you just .pipe() to disc with an fs.WriteStream, likereq.get('/something').pipe(out). yup ill update, it's changed a few times\n. +1\n. it would be more difficult to express a list that way, unless we went crazy and started splitting on commas etc\n. since the client is a component now we can use https://github.com/RedVentures/reduce\n. well actually the entire querystring parser thing exists already as a component, ill use that\n. woah hmm, any idea how big the average response is? You can opt-out of buffering with.buffer(false), hopefully later we'll have a lot of these settings at the agent-level instead of per request\n. hmm interesting, I just remembered that I set this already in .pipe(): https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L383, if it's not working there's definitely a bug, I'll label this issue and check it out later\n. +1 I forgot they're all bools anyway so it might as well be something useful\n. we could adderr.request = this` though potentially leaking memory pretty bad\n. we've disabled the agent in the latest versions, but other issues are cropping up due to that :(\n. the client one doesn't even have this api yet\n. closing this for now since it doesn't exist \n. yes this is true, and this is has nearly every user-agent out there behaves. If the server thinks you need to know something, it'll send it, that's not really up to superagent, though there is a \"redirect\" event you could potentially use, merging them would be extremely odd\n. I've never seen this behaviour..\n\n```\ncurl -L -i http://localhost:8888/\n/\nHTTP/1.1 302 Moved Temporarily\nFoo: bar\nLocation: /foo\nDate: Fri, 07 Dec 2012 20:43:51 GMT\nConnection: keep-alive\nTransfer-Encoding: chunked\n/foo\nHTTP/1.1 200 OK\nDate: Fri, 07 Dec 2012 20:43:51 GMT\nConnection: keep-alive\nTransfer-Encoding: chunked\nHello \n```\nnote that Foo is not carried along\n. ./build is a pretty obvious dir I would think, but I'll add something to the readme\n. next release right away will have the reduce component\n. oh weird, that's messed, FF is always doing weird shit like this, node should be dropping the response body though I'll have a look thanks for the report\n. im guessing that since test.request.js is loaded FF is serving it straight from cache or something\n. great! thanks for the clean PR merged\n. added: f4c0e02\nmay be a nicer way to detect that but it works for now\n. if you have time to add a test that would be great!\n. thanks!\n. doh, yeah we should fix that, I never use the shorthands so I must have missed that\n. hmm im getting:\n```\n  \u2024\u2024\n\u2716 2 of 1 test failed:\n1) response should act as a readable stream:\n     Error: Parse Error\n      at Socket.socketOnData (http.js:1447:20)\n      at TCP.onread (net.js:404:27)\n2) response should act as a readable stream:\n     Error: Parse Error\n      at Socket.socketOnData (http.js:1447:20)\n      at TCP.onread (net.js:404:27)\n``\n. nvm that was just shouldjs apparently\n. if this is an issue we need to fix it in component https://github.com/component/component\notherwise this build will be clobbered next time\n. oh wow lame.. thanks man I'll release right away\n. @carlituxman typically you add it as a dep to one of your app components and then require('superagent')\n. @carlituxman could you gist the build.js? I can take a look\n. @carlituxman it sets up the alias properly for\"webadmin/deps/superagent/index.js` so you should be able to require it fine in the webadmin component\n. 304 only maybe to delegate the cache store...?A>SDF>ASDF\n. this component.json is for http://component.io/ not bower\n. it should use transfer-encoding: chunked\n. not currently nope\n. it's generated from the markdown, I'll grab this\n. i've been using form-data the last few days and im pretty happy with it, I would kind of rather remove my multipart stuff and use that, less for me to maintain\n. or integrating it in superagent, but so far I haven't really needed that\n. needs a rebase but looks good to me otherwise! \n. this is for http://github.com/component/component not bower\n. hahah wtf, someone must have published it, i didnt\n. done\n. did you guys update npm for GH style support?\n. it's \"emitter-component\" in npm, I forget why someone needed to change it to GH-style, but it's the same project\n. wonder why npm doesn't grab the tarball instead\n. that dep is only for the client version anyway, this is kind of why npm sucks for both server and client side code, that dep is completely useless for the server end. im going to revert that commit, browserify people will just have to suffer\n. 0.14.4\n. \"text\" is flagged via:\n``` js\nfunction isText(mime) {\n  var parts = mime.split('/');\n  var type = parts[0];\n  var subtype = parts[1];\nreturn 'text' == type\n    || 'json' == subtype\n    || 'x-www-form-urlencoded' == subtype;\n}\n```\nso you'd have to pass the \"text\" parser (which just buffers) in. Right now we dont allow req.parse('text') but that would be nice as an alias of req.parse(superagent.parser.text)\n. I usually don't bother with nextTicks for errors personally, I think if your app is dependent on the tick you're probably doing something wrong, but otherwise the patch LGTM\n. yeah, it's legacy behaviour, and even worse is that the browser/client are slightly different right now :s need to redo a bunch of that\n. but we have issues open for those\n. no clue what node replay is\n. yeah go nuts! \n. yeah I'm not a fan of promises, not going to go that route, this is a nice one line change\n. plus .query() doesn't actually initiate the request so that would be sketchy\n. I just don't really like that amount of \"cruft\" as a base, especially when a perfectly good alternative is to just return a function: https://github.com/visionmedia/co-exec/blob/master/index.js#L12\nno fighting over which implementation to use or duplicate implementations etc. Even if there was one particular method to use I dont think .then() is a great one personally but it is what it is!\n. yeah seems like too much boilerplate for something effectively every library would require, at least with thunks there's only one way you can do it haha\n. not really, impartial once they're actually implemented in browsers, but IMO it's a really silly thing to add to the language, easier to just return a function\n. who knows :D \n. should be fine now\n. added\n. hmm sounds odd to me but I guess we could\n. damn, thanks man\n. i get a different error in each version of node :( checking it out\n. I almost think we should just get rid if .pipe() it's pretty horrid trying to get things to work properly\n. formidable is super unhappy too for whatever reason, used to work fine :s might have to revert to an older version\n. just disabling multipart for now it's so broken, i'll try and check the rest of this out soon\n. yeah haha I stay as far away from them as possible, especially after seeing how broken the streams 2 implementation is, we'd be rewriting things left and right. I haven't had tons of time to look into it but it seems like it may be a node bug: https://github.com/felixge/node-formidable/issues/240\nreally hard to follow core's code though, but the removal of agent and keep-alive is what screws over all the multipart tests, which is kind of interesting because that means there is probably a race regardless, just one that is intermittent when agent is enabled. \n. im getting\n```\n1) zlib with pipe should deflate during pipe:\n     Uncaught Error: incorrect header check\n      at Zlib._binding.onerror (zlib.js:286:17)\n``\n. oh nvm you said it breaks 0.8.x\n. definitely need to rework this lib, even when we get this working .pipe() is still super half-assed, won't follow redirects or anything \n. fixed that but now one of the stream tests fails :S haha.. woot\n. nope just node ATM\n. we need to keep that in there to prevent the double unzipping, fixes one thing, breaks another\n. simple fix, my bad\n. oops, it's ./superagent.js\n. I think we support that, I forget now since it's usually not all that useful in practice, you still want to check status codes / errors etc. I was planning on removing .pipe() since it has race conditions in later nodes \n. oh nvm sorry we supportstream.pipe(superagent.post(stuff))but it doesn't copyreqheaders or do anything request-specific like that\n. .end is a bit of a node idiom but tons of libs use .end() so no point changing it now, you can use.send(stuff, fn)if you want though that works fine. send doesn't really make sense either for streaming though\n. thanks man\n. they all pass for me, the version should be locked down\n. weiiird.. \n. +1\n. eww :( \n. Y U FENCE haha, is there a way we could skip inlining the reduce stuff?\n. https://github.com/RedVentures/reduce/blob/master/index.js doesn't do much\n. -1 from me since this is more of a user-error, we can't protect against everything that _could_ be used wrong\n. woah no, why not just addnpm test`, don't need all the grunt stuff\n. make is designed for builds, grunt is just verbose and awkward\n. @djechlin hmm we actually have accept-encoding by default: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L584\nso we must not be handling that correctly\n. hmm maybe it's time to move this to https://github.com/yields/xhr/blob/master/index.js and add that as a dep\n. we should try and stuff both in there I think, pass an option or two so it can figure out what to return\n. wait so user/repo doesn't work with browserify? I'm confused haha. @gjohnson having your reduce was breaking the node side of things?\n. ohhh right, npm uses git, duh, damn.. yeah that's lame, npm's user/repo will never be useful if git is required\n. LGTM as well\n. yeah i think it's component:component haha\n. nope it's ./superagent.js, I swear we used to have it in the readme\n. any luck with res.text? res.body is the \"parsed\" content for json etc so we're not switching the value from object to string (though I wouldn't really be against that)\n. hmm interesting, what's the content-type?\n. huge anti-pattern, services should use Accept\n. it's a bug in superagent, that's why it's a warn, crashing your entire proc is definitely less ideal\n. oh wait actually now i forget, i dont think it was a superagent bug, ignoring it is no good, but throwing is also no good\n. it should pass the error but at the time when we had this we couldn't afford crashing node processes over and over so I added a warning\n. @jonasfj in that snippet you're piping to req which should already call .end(), you'll get an end event (or should at least)\n. no worries, streams are like that they don't really make sense in their current state\n. I'm kinda impartial on it personally, it's useful for toy things and demos but not really for real work where you'd want to act on the response code etc anyway\n. OMG hahah jk\n. Yea it's definitely a little annoying to handle two cases. I think the distinction between network error and transport error is important but we could hide that in the err. I'm pretty impartial, I think reserving (err to network related stuff is cleaner but usage-wise definitely annoying, so I think I'm +1 in general.\nSimilarly in Go the transport-level errors are just part of the response:\n```\nres, err := request..\nif err != nil {\n  // network related\n}\nres.Status\n```\n\u00af\\_(\u30c4)_/\u00af\n. It gets weird though, because for example say we make superagent a Promise, do you really want:\n``` js\ntry {\n  var res = request.get(stuff)\n} catch (err) {\n}\n```\nwhen it could just be a check for res.status. It only really helps the callback use-case, but hinders the promise/async/await case. Similar issue to JSON.parse() throwing, when returning null or something would really be a nicer solution.\nMaybe it's time to start going the promise route and pretty much disregard the old stuff haha\n. Oh yeah, forgot about browsers sucking. I guess I'm just meh in general then, whichever sounds fine to me\n. changed my mind, I'm +1. It's hard to rationalize either since callbacks are stupid in the first place\n. the utf8 ones could break depending on the chunk:\n- https://github.com/joyent/node/blob/master/lib/http.js#L308\n- https://github.com/joyent/node/blob/master/lib/string_decoder.js#L50\n. aren't they keeping setEncoding? i remember there being a little debate about it somewhere in one of the node issues\n. I think it's private\n. oh maybe not: http://nodejs.org/docs/latest/api/string_decoder.html\nhaha. but still the method is there in 0.6.x anyway\n. maybe that's what people were battling about, it had something to do with pipe(). we should definitely find a way to allow gzip/deflate for any response\n. nvm the diff made it look like you put it in the json parser hahaha, makes more sense now\n. I didn't even know this was a word haha, what's the reasoning behind this part? JSON values remain as bools etc\n. nvm I see\n. I wonder if we should just port visionmedia/node-querystring to the client so both can be consistent\n. these should match the rest of the lib (/* style)\n. no need for parens hurrr\n. maybe req.on('response', this.saveCookies.bind(this))\n. these we can maybe move out to the constructor just to keep a bit of bloat out if this method.\njs\nthis.redirects = [];\nthis.on('redirect', this.redirects.push.bind(this.redirects));\nor something\n. -1\n. the style I go with is:\njs\nreturn Array.isArray(header)\n  ? header.map(Cookie.parse)\n  : [Cookie.parse(header)];\n. why all the returns here? we can remove all of those\n. these too\n. this is nice test cov thanks :D\n. yup that too \n. I need to do that a lot more in .end() too it's a crazy mess right now haha\n. yeah it gets pretty confusing, it could definitely use with a nice refactor, anything in there that isn't declarative\n. ah haha yeah this one maybe not, I have weird rules for those things. If it's inline I try to use // but if it's a function I'll use the jsdoc style\n. nvm i forgot that we have a method called .redirects\n. this line is really long, i'd rather have something like var seeOther = 303 == res.statusCode;\\n var idempotent = 'HEAD' == this.method || 'GET' == this.method etc then followed by conditional. Also add a space if (... like the rest of the source\n. } else {\n. if (this._redirectAuth && ~url.indexOf(host)) {\n. , auth\n. just noticed this, we shouldn't ever do this I dont wan't to buffer data and this will not support streams etc\n. and this patch should have been more focused, this is a completely separate thing, I just didn't read very well :D\n. this would make a good component/*, so we can eventually move this sort of x-browser junk out of superagent\n. shouldn't the scheme be compared on its own? not sure why it's assigned to the port here\n. should be more, mocha currently inlines a bunch of xbrowser stuff as well but I really need to rewrite them with component(1)\n. if (self._parse) parse = self._parse would be fine here, or || self._parse above\n. two spaces\n. newline\n. two spaces in this file as well\n. just noticed this we should label it something like \".parse(fn)\" to reflect the feature\n. we should probably make this optional, otherwise you get \"Cannot use wildcard in Access-Control-Allow-Origin when credentials flag is true\"\n. I'll have to double check that this wont break our legacy component thingy, we had some issues with npm not following bundledDependencies so we had to implement a thing on top of npm but I dont think we support the GH style stuff ATM\n. nvm good to go\n. this'll globber itself this._agent =\n. clobber* hahaha..\n. tiny nitpick but null != obj[key] would be good here, might as well include null as well\n. :D \n. spacing } catch (err) {\n. try { and if ( below etc\n. +1\n. something like '<code> \"<status code string>\"'might help clarify that it's an http response error, for some of the terse ones like \"Conflict\"\n. ",
    "lexer": "I've made a mistake in title. I mean:\nt would be more clear to put qs parameters as method like -->JSON<-- and form\n. great!\n. Agree, putting ssl, host and port option to constructor would be fine too.\n. ",
    "srour": "Nevermind\n. ",
    "snsparrish": "I haven't had any troubles with other mods yet including:\nconnect\ncradle\nredis\nAny eta on a superagent update for it?\nThanks again,\nShawn\n. ",
    "suhoparov": "when ?\n. ",
    "weepy": "ah just found \"finish node port\" at the bottom of the README\n... seem's you're always one step ahead ^_^\n. ",
    "alexyoung": "VirtualBox + IETester is how I usually research/test/fix IE issues\n. FYI\n. ",
    "c4milo": "+1 for this\n. excellent, tks :D\n. do you want to go still with this API? I think it's too low level.\n. hehe, meh, I'm so user centric now. I usually design top down.\nOn Wed, Jan 4, 2012 at 1:03 PM, TJ Holowaychuk <\nreply@reply.github.com\n\nwrote:\nbuild up my friend! up!\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/visionmedia/superagent/issues/11#issuecomment-3358324\n\n\nCamilo Aguilar\nSoftware Engineer\n. I agree, but then if you want to be pragmatic. I'd suggest you to release a simple and functional multipart support since it's pretty straight forward to do. Then, you can continue working on a better and more flexible implementation aka low level api and high level api on top. It's fine if you decide to go straight with the latter since I can use my fork in the mean time.\nJust putting my 2 cents here.\n. @visionmedia I'll be nice also to have the high level API like you envisioned it.\n. it was improve in node 0.6.x wasn't it?\n. hug\n. I was giving it more thought to the need of a low level API and I honestly think that we are over engineering the solution. RFC 1867 is really simple and I don't think it will change in the near future. For instance I don't see the value of allowing users to specify custom headers for every part. Also content-type can be determine by superagent, either by the file extension or using libmagic. The only thing that makes sense to me, so far, is allowing to do piping when downloading binary data. \nI'm still open to discussion though :) \nBTW, the API that I'm proposing would look like: \njavascript\nrequest.post('/upload')\n  .set('x-mycustomheader', 'value')\n  .part('field1', 'value1') //once it finds the first part it assumes content-type: multipart/form-data defining the boundary\n  .part('field2', 'value2') //a plain field\n  .part('file', filePath) //a file path, this could be also an array of file paths\n  .end(function(res) {\n    //boo\n  });\n. hehe, I got it now, I thought you were proposing the API that most users will ultimately be using...\n. how did you come up with content-type mixed/related?. It isn't mentioned in RFC 1867. \n. oh boy hehe, are you serious? the scope of most rest libraries for file uploads is only rfc1867. If you want to support the whole mime standard I'd suggest to create a new project hehe.\n. or write bindings for http://spruce.sourceforge.net/gmime/\n. nah, no problem. I'm going to review what we have so far and try to make rfc1867 work with your current design, given that you didn't like my big function ^^. I'd say that it's a fair scope for superagent for now.\n. or if you want to do it yourself and want to save time just grab pieces from https://github.com/c4milo/superagent/blob/master/lib/node/part.js. It is working and tested with node-formidable \n. any update TJ?\n. duplicates @santiago pull requests\n. human beings TJ, we make mistakes when we're tired ;D\n. heh it's okay you can ignore this pull request, I'm drunk and hit a wall using superagent and then figured out that the response object comes as the second parameter \n. sort of ;D , finishing up some things at the office http://goo.gl/827Wy\n. :+1:\n. @defunctzombie ? was this implemented? \n. @visionmedia is this because you switched data to send?\n. any reason why this issue was closed?\n. ",
    "JonDum": "Herp, I didn't realize you already included a build. \n. ",
    "TooTallNate": "close?\n. Looks like it's simple as:\n`` diff\ndiff --git a/lib/node/index.js b/lib/node/index.js\nindex 4d21f1c..c8689a7 100644\n--- a/lib/node/index.js\n+++ b/lib/node/index.js\n@@ -375,15 +375,16 @@ Request.prototype.write = function(data, encoding){\n  *\n  * @param {Stream} stream\n  * @param {Object} options\n- * @return {Request} for chaining\n+ * @return {Stream} thestream` argument, for chaining\n  * @api public\n  */\nRequest.prototype.pipe = function(stream, options){\n   this.buffer(false);\n-  return this.end().req.on('response', function(res){\n+  this.end().req.on('response', function(res){\n     res.pipe(stream, options);\n   });\n+  return stream;\n };\n/**\n``\n. @visionmedia Fixed'd'd'd'd''d!\n. Oh interesting... well perhaps that comment should be updated? :p\n. And also yes, I confirmed thatcurlsends its file upload with \"form-data\", not \"attachment\", so rejecting this patch was indeed the correct thing to do. Thanks for keeping me on my toes!\n. I think with #374 in place, this is no longer necessary (thePartmodule has been essentially rewritten).\n. > Wondering if @visionmedia will have a panic attack if you useutil.inheritsinstead ofproto`?\nI bet he's used to me pulling that one on him by now ;)\n. Repo was moved to visionmedia org, so this is no longer relevant.\n. wat?\n. Oh good catch, haha\n. ",
    "runeh": "I might use superagent for a mobile project, so I need interrupts to deal with shoddy mobile networks.\nExperimented a bit over the weekend. I have some working code in my fork that works like this:\n``` javascript\nrequest('GET', '/slow')\n    .interruptAfter(\"1.5s\")\n    .end(function(res){\n        if (req.interrupted) { do stuff  and return }\n        else { whatever }\n    })\n```\nThere's also a interruptEvery. The time argument can be a number of millis or a string of the form \"300ms\" or \"1.5s\".\nAny opinons. Not entirely sure about the API. I'd be happy to fix up my branch and submit pull request if we could come up with a reasonable API.\n. As an alternative to .interruptAfter presumably? I kinda hate the term \"timeout\" as it's so generic, but in this context it makes sense I suppose. Would align with the naming of window.setTimeout. \nHow about interruptEvery is it needed? Could rename to .interval(ms), which soulds a bit weird, but would work.\n. ",
    "OlgaKozlova": "And what is default timeout for requesr? Can't find this info!\n. ",
    "jazoom": "I also can't find it. I want to create a longer timeout for a particular request.\n. Okay, thanks. That's good to know.\n. Ah right. So req is a promise and you can call abort directly on the promise? Interesting.. Gotcha. That makes more sense. Thanks.. ",
    "drypot": "+1\n. +1\n. It was not string method, but array method. ;)\nand I found this work around.\nhttps://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/array/reduce#Browser_compatibility\n. It was OS X problem.\nhttps://groups.google.com/forum/?fromgroups#!topic/nodejs/3KNosjnfTks\n. +1\n. Ah, I found workaround. :)\n```\nrequire('superagent');\nbefore(function () {\n    require('superagent');\n});\ndescribe('myfunc', function () {\n    it('should success', function () {\n    });\n});\n```\n. agree on (err, res).\ndisagree 4xx err. \n4xx is not err.\nIt's parts of meaningful formal procotol.\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html\n. @defunctzombie \nSorry for my poor english.\nOk. I think I have to start modifying thousands of my broken tests. :(\nNext time it wil be good if there are more mild migration path.\n. @defunctzombie I can accept new style. Understood it. Style A, style b, It's not problem. but it's worring how many projects will be broken. Fortunatly I have tests.\n. Relaxed, \ndroped my mind, \nsome coffee, \nmodified 300+ test cases.\nNew style pros: in most cases simpler code.\ncons: some side effects, some broken tests. for me 3% broken. not bad.\n. ",
    "defunctzombie": "I think this commit fixes this:\nhttps://github.com/visionmedia/superagent/commit/639b2d0a246397b1d2b37ac923273ed0d64808bb\n. Closing. I think this could be done via plugins. We may think about something better down the road. Wrapper seems like a reasonable solution for now.\n. @c4milo I have no idea what this issue is about. I am guessing some sort of cookies support but I have no clue. If cookies feature is desired, then I will review a PR if there is nothing that is currently offering a cookiejar.\n. I am gonna do this using zuul. Some of the work is already in place.\n. It was closed because there is no issue description saying what behavior is desired or why. I can't act on something that has no example use case even.\n. This is the superagent library not the supertest library.\nOn Wednesday, January 14, 2015, Daniele Bellavista notifications@github.com\nwrote:\n\nOk, I will expand the original issue.\nI have some express API protected by HTTP Digest Access Authentication\n(using passportjs http://passportjs.org/guide/basic-digest/, for\ninstance) and I'd like to test them using supertest, without spawning a\nserver.\nvar app = express();\n// ... express setup and protection using Digest Access Authentication\nsupertest(app)\n.digestAuthentication('user', 'secretkey') // Desiderata\n.get('/my/protected/api')\n.expect(200)\n.end()\nI didn't try superagent.auth(user,pass), because the documentation\nhttp://visionmedia.github.io/superagent/#basic-authentication states\nthat Basic authentication is supported, but there's no mention to digest.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/51#issuecomment-69945037\n.\n. No idea what this means.\n. Is this still an issue? This is really old.\n. Closing. Let me know if I need to re-open.\n. better handled as a plugin since we can't really support client and server with this.\n\nFWIW the request module is a behemoth and I don't think supporting everything it supports is useful.\n. I think this was fixed, if not open a new issue.\n. Yea. I too find it strange that the behavior is different. One downside to using qs in the browser is that it increases the size of the lib (pretty substantially). Maybe I can use just the serialization part without the other parts.\n. Will create a new issue to just use qs on client as well for consistency.\n. Makes sense to me.\n. Closing this old issue. If something similar comes up we can revisit. The pipe logic is less than ideal at the moment anyway.\n. Error handling will be revamped in the next release. Arity has been removed, it is too confusing.\n. While it may be nice, I think it is better to handle this at the app level or build something on top of this lib that integrates with your app.\n. Closing due to age and not understanding what this issue is about.\n. Don't know what this means or which lib (client or server) this is targeting.\n. :thumbsup: \n. Yes, I will be doing this in the new error handling refactoring. I have already removed arity, this is the next piece. Basically, anything that is not 2xx will be an error and response object will also be provided.\n. Closing issue since there is an ENV var workaround. I don't think we have specific node options.\n. Memory will keep rising until garbage collector needs to reclaim it. Please try the test again with the --expose-gc option for node and put gc() state calls in your interval.\nA script showing the memory leak would also be helpful.\n. I don't see superagent sending empty cookie headers in the latest version.\n. PR with tests would go a long way here. We just have limited time to get to all the issues. :)\n. @rexxars is this the only thing blocking IE9 use? I am wondering if it is even worth the trouble for IE9.\n. https://github.com/visionmedia/superagent/blob/8d1c04e3aa29aa6d7da122de584593214f9242f4/lib/client.js#L656-L660\n. We should document that you need the polyfill for btoa for auth to work. I do not think native support for old IE warrants including such a large polyfill by default for everyone.\nWe should have a supported browsers section in the readme that covers these topics.\n. The main issue would be around streaming data. I don't think getting parts of responses is really a common thing in browsers.\n. Dislike promises. Right now they are not widely supported enough and I don't see a reason to use them for this since a request is a one shot deal.\n. I don't care for thunks or promises right now in this lib. This is a one shot callback lib. Once people rally around the way async will be done going forward, then might revisit. My comment is not meant to be about one being better than the other, only about having more dependencies for this lib right now for no reason. Functions are simple and easy to understand.\n. @damianb Can you provide a simple example to show the problem please.\n. @soyuka can you make a PR with appropriate tests for this?\n. @soyuka make test-node should would. For browser tests you will need to setup zuul for cloud testing. Just steps 1 & 2 should be enough.\n. Going to close this due to age.\n. :) for those of us on the other side of the fence.\nOn Aug 1, 2013 9:50 AM, \"TJ Holowaychuk\" notifications@github.com wrote:\n\neww :(\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/visionmedia/superagent/pull/256#issuecomment-21950912\n.\n. Yea. If we update the reduce module to not shim object crap which bloats\nthe built bundle. I inclined only cause of that.\nOn Aug 1, 2013 10:20 AM, \"TJ Holowaychuk\" notifications@github.com wrote:\nY U FENCE haha, is there a way we could skip inlining the reduce stuff?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/visionmedia/superagent/pull/256#issuecomment-21953929\n.\n. Maybe I was looking at some other version. I deff saw something with a\nshim. I'll double check my craziness and resubmit with use of the reduce\nmodule.\nOn Aug 1, 2013 10:36 AM, \"TJ Holowaychuk\" notifications@github.com wrote:\nhttps://github.com/RedVentures/reduce/blob/master/index.js doesn't do much\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/visionmedia/superagent/pull/256#issuecomment-21955191\n.\n. I will open a new pull request that uses the reduce component directly.\n. Closing due to age. I think zlib issues have been resolved in newer versions.\n. Closing this. @eivindfjeldstad I would review a PR if it contains tests.\n. You can use .pipe()\n. Feasible yes (it is just code). But I don't like it. The function(err, res){} syntax is nice and terse and you can expand on that do emit events into whatever else you want. It also creates a leaner testing surface for us since this module is not about many opinions but more fundamentals.\n. @jamlen only if that is how you handle errors. Maybe a person's app handles them some other way :)\n. @jamlen depends what you are trying to accomplish :) Feel free to hop in the #express IRC channel on freenode and share what you are doing.\n. I thought about this more and see the following error setup.\n- anything that is not a 2xx status will result in Error\n- successful non 2xx responses will result in the error instance having a statusCode or status field\n- unsuccessful responses (network issues, like the current behavior) will result in error instance with no statusCode or status field\n\nThe goal was to prevent the loss of information (network error or not) but maybe it doesn't really matter to an end user and the status could be set to some 5xx code for network errors.\n. @gjohnson any more thoughts on this one? I am happy to make the code changes. I think they would be pretty small. It would be a breaking change.\n. This has been merged into master.\n. You could also make the claim that a non-successful http response is also\nan error.\nI am not married to the new api so could push out a revert it is really not\nuseful but there was not much pushback before and I provided lots of time.\nUntil something is released people don't try it.\nOn Wednesday, March 11, 2015, Kevin Malakoff notifications@github.com\nwrote:\n\nFollowing up #554 https://github.com/visionmedia/superagent/pull/554\nand #580 https://github.com/visionmedia/superagent/issues/580....\nThe new API is non-standard for Node.js callbacks. The request was\nsuccessful so there should not be an error (eg. you can check the response\nstatus code). Only if the response cannot be returned should there be an\nerror, eg. failed to parse the body.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/283#issuecomment-78401506\n.\n. Missing entry in changelog is an oversight on my part. I will add that.\n\nAs for the change, I can see where it is confusing because the method is\ncalled 'end' and maybe making assumptions about the response is too high\nlevel.\nI will add tho that parsing errors can also have responses so the issue\nwith error having been only for network or when no response is not quite\naccurate. To avoid passing two arts to the callback I can simply change to\nerr.res and remove res arg.\nThe idea behind this change was to make it easier to consume success\nresponses and ignore everything else. While it is true that a response is\nstill available for 4xx etc, I find that I always treat those completely\ndifferently than success responses and this change was meant to make it\neasier to avoid accidentally forgetting to check status. Whether this is\ngood or bad honestly depends on how high level you view this library. Yes,\nthe library makes requests, but so does node core. This library presents\nsome opinions about how to code up a request and consume it. Maybe this\nchange breaks the assumptions most people have about the library.\nI will add that breaking existing code is in my mind insufficient to say\nthis change is \"bad\". I am aware it is a breaking change and knew it would\ncause breakage. I even added a wiki page for migrating from 0.x to 1.x\nHearing more yay or nay here will help me identify of this should be\nreverted. Obviously until released no one cared so happy to have the\ndiscussion now.\nOn Thursday, March 12, 2015, Bastian Krol notifications@github.com wrote:\n\nThis is a major breaking change, yet, as far as I can see there is no\nmention of it in the change log for 1.0.0 (\nhttps://github.com/visionmedia/superagent/blob/master/History.md is the\nchangelog, or is there something else that I have overlooked?).\nI think this change should be there in big bold letters. The way it is\nnow, I had to find out about this change the hard way (my tests failed,\ndebug them, find the piece of code that changed in superagent, check the\ngit history of the lib/client.js until finally arriving at this issue).\nPS: I really don't like the change, for my feeling, a successful HTTP\nrequest with a non-200 error code is fine in some situations. but that's\ncertainly a matter of taste and I can see why people have different\nopinions.\nPPS: That said, superagent is an awesome library, so thanks for this.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/283#issuecomment-78533352\n.\n. Yep, that is a bug. status should exist and so should err.res so that we\ncan follow node style callbacks as mentioned above.\n\nOn Friday, March 13, 2015, Jonny Buchanan notifications@github.com wrote:\n\nErrors returned as a result of a successful response's HTTP status code\ndon't have a .status as discussed above - is this a bug?\nWith 1.0.0, I have to check 'err' and check if 'res' is null or not when\ndetermining if I want to deal with client errors myself but pass off\nrequest errors or server error responses to an error handler.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/283#issuecomment-79033090\n.\n. @kmalakoff to follow nodejs style callbacks, I can simply remove the response object from the callback when there is an error. I have already added the err.response field and err.status fields so the extra response arg would not be needed.\n\nObviously there is still the larger opinionated API concern, but as far as callback style, that can easily be resolved.\n. @kmalakoff \nI don't know if I am sold yet. I don't 100% agree that all errors are things that need a stacktrace. It is absolutely valid to produce an error for business logic. Even things like the parsing error produce meaningless stack traces because the actual error is that the response body could not be parsed but the stacktrace is where the parsing tried to happen. Here the server sent back a response, just not a valid/parsable one and we error. Technically in that case we too should not have the error object because the server sent you a response?\nI can simply remove the second response arg and leave error.response and now are are following nodejs style conventions so that argument doesn't sway me.\nThe only argument that might sway me is that this library is meant to be lower level and not make such a judgement call about the \"success\" of a response in the end callback. But honestly, I am not 100% sure that is the case.\n\nIt is subjective on whether the 404 is an error or an expected response status code so it feels like it is the application's responsibility to classify not the library's. An error in Node-callback conventions is a very serious proposition\n\nI totally understand this point and agree, however I also think that it is not wrong to check the error for codes and other things if you want to take certain actions on said errors. I realize that handing this now is different code than before but that is why the change is a breaking one.\nLooking at the status codes page here\n\nThe 4xx class of status code is intended for cases in which the client seems to have erred.\n\nIn the context of http responses and higher level libraries, it would not be that crazy to consider non 2xx (success) responses to be errors.\nMaybe people don't like this assumption for any level of http request library and that is the core issue, but I have yet to hear enough votes to really make that call right now.\n@mdebruijne \n\ncookie-parser generates an error, because it doesn't like the cookie content\n\nsuperagent parser will generate an error if it cannot parse the response body, yet there is a response\n. @kmalakoff I really wanted more people to weigh in on it :/\n\nIf I HEAD an endpoint with the purpose to check if a resource exists, I check the response's status code for a 404. I doesn't feel like the request failed but just a successful request/response cycle to check if a resource exists so (null, res) feels correct\n\nI am learning towards undoing the change as I think the confusion lies with using end() and having pre-existing expectations around that always returning a response if one was available. The other thing that pushes me towards undoing this change is all of the existing superagent stuff that expects err, res and is unlikely to all be updated appropriately.\nI will add tho that the cases like you describe I find far fewer instances of than the case of having to write a check for response status 2xx in handlers before trying to use the response.\n. @drypot at the danger of being too pedantic, it quite literally says\nThe 4xx class of status code is intended for cases in which the client seems to have erred\n. I have thought about this some more and I think the new behavior is better for the 90% case. If sometime later I feel that this is an incorrect choice or there are other maintainers with different opinions, we can revisit. I am not going to revert this in the near term.\nI think this change, while controversial, is good. Maybe my thinking will change over time. Maybe this library is too popular and I should have not made any breaking changes. Well, in some ways that ship sailed. I asked for opinions on this early on, people weighed in and it seemed like a reasonable change.\n. The changes for this were merged. Still need to enable the travis part with whatever saucelabs credentials you wish to use.\n. Probably outside of the scope of superagent.\n. @gjohnson zuul is ready to go once you add the saucelabs credentials to the travis config.\n. Still in the works for which browsers to test. IE 11 is supported but saucelabs is broken. IE 9 might work for some stuff.\nWhich other browsers do you want to see tested?\n. I personally have no desire or wish to support IE8. It is a useless endeavor. Time better spent elsewhere :) I will however review PRs for IE 8 support as long as they don't involve a complete refactor of the codebase.\nI think some stuff will work in IE8 without much fuss.\n. Please rebase these changes on latest master if still applicable and I will be able to merge. Otherwise LTGTM.\n. @gjohnson you need to setup the sauce credentials as encrypted vars in .travis.yml for zuul to work against sauce on travis.\n. I don't think it has. I will take a look this week.\n. The PR needs to be reworked. I think we need a cleaner way to do it than the way the PR is doing it.\n. Fixed by 04a04e2\n. I don't see a point. This can be closed or @gjohnson concerns should be addressed and merged.\n. There is a PR out to fix this.\n. Will give an error now: https://github.com/visionmedia/superagent/commit/ecd32cb0d15d291c4262852c369c318ff30a9bf9\nYou can't redirect with no header\n. Says merged, can be closed.\n. Can be closed. Seems irrelevant?\n. Docs are incorrect/misleading, if you want to test in browser you wouldn't point zuul at test/server.js since that just sets up the express test server. Zuul should be pointed at the client test files which I believe is test/index.js\n. I think this can be closed.\n. @mindjuice please open a new issue with a failing example so we can take a closer look.\n. -1, this seems wrong. why?\n. Closing this due to age and lack of repo to reproduce.\n. This has been fixed.\n. Needs a new clean PR if this issue is to be reviewed further.\n. In general I am not against this. I would however prefer to see the API be more along the lines of:\nrequest.query('string', { raw: true });\nOr similar in thought.\nAnother consideration is what happens on the client?\n. @dpolivy The client library and the server library need to support this feature. (lib/client.js not just lib/node/index.js)\n. Thinking about it more, is there a downside to detecting when a string is specified and just using that as the query? That way we don't need an options argument.\n. I will make a new PR for this for server and client versions.\n. Submit a PR and that can just be accepted or rejected. This issue can be closed.\n. Why was using\nself._callback = function(){\n  fn && process.nextTick(fn);\n};\ndeemed worse than this listener re-arrangement?\n. This PR is out of date and build fails. If this is still a desired feature, I can review a new clean PR or discuss the issue.\n. What is the issue here?\n. What should it do? No error? Should it emit the abort event?\n. Also, is this an issue with server side lib or client side lib?\n. Maybe something is killing the connection? If you can provide a sample repo showing the failure it would make it easier to help you debug this. Or a failing test in the test suite.\n. The browser handles redirects for you.\n. hahaha. I think component can still build these changes (I did not change the makefile) and all the new requires are relative paths. But yes.. I bet the debate will start before too long.\nBTW, there is a failing client test (was failing before my changes too). Something about headers.\n. btw. I run the client tests with \u201czuul \u2014local \u2014 test/index.js\u201d but maybe that is wrong. That only tests a few things but does use mocha.\nOn May 16, 2014 at 3:43:10 PM, Garrett Johnson (notifications@github.com) wrote:\nYeah, if it's the one I think it is, it's because of the home brewed test framework in here and not the actual code. I started scraping all that for mocha a while back after you added the zuul stuff but then got busy and busier... I'll just update it for for this branch instead.\n\u2014\nReply to this email directly or view it on GitHub.\n. Looks good to me. What about the node side of the library? This isn't relevant for that I guess?\n@vstirbu Does this PR need refreshing or is it good to go?\n. I believe fixed in master.\n. Buffer is not available on the client right now. Should I make it a no-op? What behavior would help here?\n. Not worth the bloat in the final code bundle.\n. I am going to close this. Browser side just doesn't support .buffer(). If someone submits a PR I will review but this is not a feature that is blocking usage or something high on my priority list.\n. I set aside some time next week to go through the issue backlog on this\nrepo. If you make a PR I will review it then.\nOn Friday, December 19, 2014, Michael Schoonmaker notifications@github.com\nwrote:\n\n@gjohnson https://github.com/gjohnson and @defunctzombie\nhttps://github.com/defunctzombie - I just lost a couple hours to this\nyesterday, and this looks like the Right Way(tm) to fix it. I'd like to go\nthe options route, as that gives users a lot more flexibility.\nCan you think of any other ways to improve this, or should I fire away\nwith a PR to this effect?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/403#issuecomment-67671046\n.\n. I think this is fixed in master.\n. @gjohnson did you have any thoughts on this?\n. @jonasfj Says I can't auto merge this anymore. Can you rebase it please. Seems to me that we want these changes.\n. I think your approach with the plugin is the right one. I view IE 8 and 9 and legacy and not worth core lib support :/ At least I don't have the cycles to deal with the pains right now.\n. If you have a reproducible example I can take a look. Going to close due to age of issue.\n. Is there an issue here? Is this about the client version or the node version?\n. Closing this for no response. If this is still broken (sounds likely) can we make a simple explanation of the issue and failing test. The current issue is hard to follow :)\n. Closing due to age. If a simple example is provided I can run to reproduce, happy to take a closer look.\n. Closing due to age.\n. Seems like a nock issue.\n. Middleware for responses might be an interesting idea for v2\n. Who wrote the streams code for this module?\n. Closing for no response. If streaming is still broken we need a failing example. Age of bug might indicate things have been fixed up in other ways.\n. Unless there is a way to do this on the client, I think this is better suited for plugin land. Let me know if that is not the case and I will happily reconsider. We need to be thoughtful of API support for client and server where we can.\n. 1. This PR edits the wrong file.\n2. What is the issue here? Please open a ticket for discussion.\n. Seems that FF won't fix this. I think we should only set progress if you actually are uploading something to avoid this issue.\n. This PR needs to remove the rebuild of the dist files and also update package.json accordingly.\n. This has been fixed in master. The callback is not in the try/catch anymore.\n. Yea, I am trying to blow through the issue backlog today and tomorrow and want to try to get an RC out tomorrow but can't promise anything.\n\nIf you want to use master today you can certainly just reference git commits directly.\n. Related:\nhttp://stackoverflow.com/questions/19325314/how-to-detect-cross-origin-cors-error-vs-other-types-of-errors-for-xmlhttpreq\n. Closing in favor of: https://github.com/visionmedia/superagent/issues/484\n. Not that I am aware of.\n. Please cleanup the commit history and make sure code style matches existing files.\n. Which change broke this? Was there a reason? Are there tests to catch this?\n. Here is a test that reproduces double callback. It tries to use the request as a duplex stream.\nhttps://gist.github.com/defunctzombie/c3d3aaa3e1ee3e15537e\n. No. You can only know in each request callback if they are done. Use a module like after or async to wait on multiple things. There are no globals for this for good reason.\n. I think the best bet here is to create a plugin that will populate whatever\nglobal you want.\nOn Sunday, February 22, 2015, Sebastian Porto notifications@github.com\nwrote:\n\n@defunctzombie https://github.com/defunctzombie is not about waiting\nfor several things in the application itself, this can be done with\ncallbacks or async as you say.\nIt is about writing end to end test that depend on an ajax response to be\nfinished. For example:\n- I write end to end test using a tool like\n  https://github.com/jnicklas/capybara (which uses Selinium or PhantomJS)\n- capybara clicks on things that triggers ajax request\n- then I want to assert that something is shown for example, but I\n  need to wait for all ajax request to be finished first\nThe capybara has no way to ask superagent if there are ajax request going\non.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/465#issuecomment-75428359\n.\n. I would argue that what nodejs does is unexpected. If you want pooling or other agent features you should set that yourself.\n. I don't see ArrayObject in that list.\n. LGTM\n. @gjohnson any way we can share more code there?\n. Why does this line of code exist anyway? Why not just get the window variable?\n. I am open to suggestions on how to detect this better.\n. Related reading:\nhttp://stackoverflow.com/questions/19325314/how-to-detect-cross-origin-cors-error-vs-other-types-of-errors-for-xmlhttpreq\n. node version or client version?\n. I take it you think that the parameters should not be added to the request of the second redirect? Is that standard behavior?\n. :+1: \n. Is there an equivalent issue on the client.js code?\n. Go ahead and throw them in a gist and I will take a look today. I recently\nreworked the client tests and will merge my changes which will make it\neasier to test in browsers.\n\nOn Saturday, November 15, 2014, Thomas Hopkins notifications@github.com\nwrote:\n\nThere should not be. The browser handles redirection for you in that case,\nwhere node does not. I just pushed up a similar test for client.js that\nshould verify that case.\nI had trouble running the browser tests on my machine \u2013 looks like Express\n4.0 compat stuff. I got the tests running locally but left those changes\nout of this PR. Still, beware.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/491#issuecomment-63193174\n.\n. It will work once I add the browser field to package.json to do the mapping. I will make a PR for review.\n. Added PR #495 \n. On node you already have mitm or nock libraries. In the browser you can just monkey patch XHR. I do not think this library needs to do anything special for request mocking.\n. @MatthewMueller not worth it for this lib, we don't have many require calls. The space savings would be nothing. Are there other benefits other than dereq being minified?\n. I am wrapping up some things at work and will have time to do the new error refactor in a few weeks if no one gets to it before then.\n. Closing this PR. This issue is on the list for v1 in a slightly larger form.\n. Does the server side emit response events?\n. @Schoonology sounds good. If you could add a test it would be appreciated :)\n. @gjohnson thoughts?\n. Yes, we should not have this inside of the try/catch to avoid mis-representing the error as one of ours. Good catch @gjohnson .\n. Yea, this looks better.\n. You cannot. If the browser decides to prelight a request you have no choice. The only way your request won't be preflighted is if it is considered a \"Simple\" request. See here for simple requests:\n\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS\n. Superagent makes request with content type application/Json IIRC and this\nwill be preflighted.\nOn Thursday, November 27, 2014, Colorfully.Me notifications@github.com\nwrote:\n\n@defunctzombie https://github.com/defunctzombie OK. Thanks!\nI know that \"If the browser decides to prelight a request you have no\nchoice\"\nBUT it looks that the browser decides to upgrade the request because\nsuperagent is sending some additional headers or does not handle\nmultipart/form-data correctly in the browser.\nWanted just to report it because I solved the problem via using the\nXMLHttpRequest and FormData objects and it works for the same request I\nwas trying to make with superagent...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/501#issuecomment-64763305\n.\n. Out of scope for the base module. I would prefer to keep it lean since it also gets client side use.\n. Is this for timeouts that happen as a result of user option for timeout\nperiod?\n\nOn Friday, November 28, 2014, Garrett Johnson notifications@github.com\nwrote:\n\nI don't like relying on err.timeout as an error code of some sort, so\nfigured I'd tack on an error code for timeouts. Which error code is\ndebatable and I'm open to changing... I saw that request/request\nhttps://github.com/request/request/blob/master/request.js#L920 uses\nETIMEDOUT but I kinda felt like that should be more representative of\nconnection timeouts. Meh?\nCC: @defunctzombie https://github.com/defunctzombie\nYou can merge this Pull Request by running\ngit pull https://github.com/visionmedia/superagent add/econnaborted\nOr view, comment on, or merge it at:\nhttps://github.com/visionmedia/superagent/pull/503\nCommit Summary\n- Add error code for timeouts\nFile Changes\n- M lib/node/index.js\n  https://github.com/visionmedia/superagent/pull/503/files#diff-0 (1)\n- M test/node/timeout.js\n  https://github.com/visionmedia/superagent/pull/503/files#diff-1 (1)\nPatch Links:\n- https://github.com/visionmedia/superagent/pull/503.patch\n- https://github.com/visionmedia/superagent/pull/503.diff\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/503.\n. LGTM\n\nhttp://lxr.free-electrons.com/source/include/uapi/asm-generic/errno.h#L76\nLegit.\n. I'll remember this for the error refactor since I think it might be nice for the frontend as well.\n. Not sure it belongs in the readme. Maybe wiki pages.\n. Needs tests so we avoid breaking this again plz.\n. This was fixed by another PR.\n. Personally I would prefer this done either via the plugin system or via options when making the request. I kind of dislike these magical global settings.\nThoughts @gjohnson?\n. Yea, I guess why not.\n. Sounds like your server is sending a content type that the parser can't handle. I don't think application/json-patch is a thing that is automatically handled if you are sending that as the response. Just use json?\n. Needs tests, then will merge.\n. We should comment them back in and make them work.\n. More complicated? The PR needs the tests because with tests we would have caught this. Tests are worth the added code in the PR.\n. Can you just add a new test then for this feature and leave the commented out tests as they are? I would prefer not to merge this until it has a test added otherwise we will just ignore the tests. Now is the ideal time to add even a simple test for it.\n. @xaka lgtm\n. oh yea, I added an abort test recently\n. I think this question is better suited for StackOverflow or a similar support forum. Please keep issues focused on technical problems with just this module.\n. I like the fix here better: https://github.com/visionmedia/superagent/pull/511\nIt has a smaller impact on the code and I believe achieves the same result. I asked for some tests so we don't break this in the future; then will merge.\n. /cc @MatthewMueller @gjohnson\n. I think this is now fixed in master.\n. Closing this since it seems you resolved your own issue.\n. Please format the issue so we can read it. Also a PR or failing test would help explain more what is wrong here and what we should be doing. I can't tell from the code snipped what actually changed.\n. Not sure what this is suppose to show but sending x-www-form-urlencoded content type but actually sending json can't be too good. I bet php is refusing to decode invalid content type most likely. I would make sure you are sending valid requests first.\n. Is your request being preflighted? You should look into CORS preflight and\nhandle that in your php code if that is the case.\nOn Tuesday, January 13, 2015, lborgman notifications@github.com wrote:\n\nI getting a bit closer to understand what is going on. The PHP code is\nsomehow getting run 2 times when application/json is used, but not when\napplicaiton/x-www-form-urlencode is used.\nPlease take a look here:\nhttp://stackoverflow.com/questions/27924902/why-do-an-ajax-application-json-run-php-code-twice\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/522#issuecomment-69757665\n.\n. If you read the preflight rules it talks about certain content types being\npreflighted and others not.\n\nOn Tuesday, January 13, 2015, lborgman notifications@github.com wrote:\n\nIt could perhaps be something with CORS preflight, but why should that be\ndifferent with the two headers?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/522#issuecomment-69774106\n.\n. Is this on the client or the server?\n. no. sorry.\n. sounds like a bug with the superagent-prefix module. I would try there first.\n. This is not going to be supported.\n. javascript is required\n. why?\n. What type of changes are needed?\n. Sorry I am really busy at work. Have not had a chance to review yet but\nwill try to next week.\n\nApologies and I do appreciate the detailed explanation!\nOn Thursday, January 22, 2015, Pier Paolo Ramon notifications@github.com\nwrote:\n\nSo, what\u2019s your opinion on this, @defunctzombie\nhttps://github.com/defunctzombie?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/529#issuecomment-71006241\n.\n. getXHR() is not exposed on the request object (no release yet but that code is in master)\n. parseHeader(str) and splitting .end() into smaller pieces could use PRs.\n\nI think making you life for ti-superagent easier should be the first goal (we can do that with relative ease).\nI am also onboard with most of the items in Make superagent itself compatible with Titanium APIs but some of them will need to be tweaked.\n. Please provide a full failing example and note which superagent and node version you are using.\n. req.on('end') should work\n. It would be better to just check if the user has added any progress listeners. If they have not, then we would not attempt to attach to upload.\n. Overlapping issues with https://github.com/visionmedia/superagent/pull/538. Will track there.\n. This may have the downside of triggering a CORS preflight in some browsers.\nhttps://bugzilla.mozilla.org/show_bug.cgi?id=727412\nI think we should only connect progress handler if the user adds a progress listener in their app. Otherwise we should avoid using the upload listeners.\n. Cannot merge because it will trigger CORS in browsers and users may not want that.\n. @gjohnson yea, I am cool with it.\nI don't remember if I merged in the first part of the error refactor (remove arity) but that would be nice to merge for 1.0.0-something.\nThe rest of the error stuff I have not tackled yet. I want to get close to the success/error behavior of jquery so that it is very clear that no error is a successful response and everything else is an error.\n. Please add a test so this doesn't break in the future.\n. Sounds like a bug to me. Can you look into making a fix with failing tests?\n. Please make a simpler test case that uses just superagent and not supertest or other libs on top.\n. I don't understand this issue.\n. I don't see it supported in the current codebase. Would review a PR that adds support on the client and server as well as tests.\n. There is no way to do this currently that I am aware of.\n. I think this is actually fixed in master, but there hasn't been a release in a while. I will try to cut a 1.0.0 RC for folks to try out.\n. @johnHackworth I closed it because I think it is a duplicate of another open issue.\nI think the PR was doing too much. Basically, we can do what @mdawaffe said and just check if there are progress listeners and only then connect progress. We should also document that this has adverse effects so users are aware.\n. IMO the xml2js module parser method is deceiving you into thinking it is async. That method can do all the work it needs to in one go. It is not an async method and should expose an API that is also sync.\nThe question of changing the superagent API for parsers to support async parsing is potentially useful but I don't think it is something to get into at this time.\n. I am not sure the browser affords supplying such an interface. What is your proposed API that the server can do but the browser does not? Do you want us to support pipe on the browser? In the browser we have the full response body, you can do with that what you wish without relying on superagent.\n. I will re-open, but I don't see this happening anytime soon. If you provide a working concept for what you propose, it might make things clearer.\n. request.parse is what you want\nrequest.parse['application/vnd.github.repo.v1+json'] = JSON.parse\n. It should be fixed but I think a 201 should be sending back something. A 204 is the one that can send back no body.\n. Is this a browser or client issue?\n. What content type is being sent in the response? Likely we could handle no body a bit better. If you can make a failing example or test case that would help.\n. I checked the test suite and we have tests for 204 no content responses. For those hitting this error, please provide a failing example, otherwise there may be other things going on with your request/response that is not clear here.\n. I am not sure the error event is a thing on the browser build tho we certainly could add it. Sounds like it could be a bug for the error event not to occur.\nAlso, I would strongly recommend that your end callback use function(err, res) since future versions will have the arity magic removed.\n. This will be changed in the next version. Any non success code will be an\nerror. I too agree that the current behavior is confusing.\nOn Saturday, February 21, 2015, Jeff Waugh notifications@github.com wrote:\n\nOh! Perhaps this is why\u2026 in this case, no error is passed to the end\ncallback. It's null. That's a pretty good reason to not raise an error\nevent, really.\nIs it because the status code is 409? Thus recognised as a client error,\nnot a server error? I wasn't expecting only certain categories of errors to\nbe emitted. [image: :innocent:]\nSelect bits from the Response object:\n{\n  clientError: true,\n  error: {\n    message: \"cannot POST http://localhost/bananas (409)\",\n  },\n  serverError: false,\n  status: 409,\n  text: \"this server says you are bananas\",\n  type: \"text/html\"\n}\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/553#issuecomment-75423927\n.\n. /cc @tj @gjohnson @rauchg @TooTallNate \n\nLooking for feedback on this idea and general thinking here. How are other libraries doing it. Would you like this approach? Would you prefer the current behavior and handle identifying res.status yourself.\n. The current implementation (in this PR) implies the following to determine the \"cause\" of the error:\n- err argument but not res -> network error\n- err argument, with res -> user's responsibility, we provide generic error message\n- no err argument, res -> successful response\n. My personal feelings on this are that lowlevel core libs should do what node does and what go does (errors are network things). But higher level libs can start to blur the lines about what is a \"successful\" response versus one that isn't. We just have to determine how high level this lib is.\nFor me, I would prefer code like this:\n``` js\n.end(function(err, res) {\n   if (err) {\n       //.. handle errors here, or res.status == 400, etc\n       return;\n   }\n// good response\n}\n```\nFor some reason I find that less error prone than the current alternative:\n``` js\n.end(function(err, res) {\n    if (err) {\n       return;\n   }\n// oops forgot to handle res.status = 400\n}\n```\nAlternatively, maybe this behavior could be punted to a plugin or function wrapper around the function you provide as a callback leaving the current behavior of error is network event intact and not making assumptions about what a successful response is (counter argument).\n. I don't follow the promise try/catch issue but maybe I don't know how promises behave in this respect enough.\nPromises are not available in browsers natively and I am not sure I want to bloat by including some promise library. Requiring that users shim their browser also seems not so nice.\n. The PR has been updated to use http.STATUS_CODES on the server and xhr.statusText on the client for the error message if available. This provides the nice default error messages we want.\n. @kmalakoff please also see https://github.com/visionmedia/superagent/issues/283 as I posted in the original comments above\n. LGTM\n. I merged this in for parity with the client side for now. However we should just remove this way of making requests in favor of the separate function call approach which is clearer at the callsite about what happens anyway.\n. We don't support cookies currently (that I am aware of) and this this feature is left to the user.\n. @rase- thoughts?\n. beautiful!\n. Don't see the benefit in this over existing tools that read what is already in package.json.\n. @u9520107 yes. I think that all of the relevant metadata is already in package.json and other package managers make use of that information. It would be unwise to throw every custom package manager tidbit into the package file since everyone has their favorite. As far as I am aware webpack and browserify work with the format we are using.\n. yep, seems pretty reasonable to expose that out.\nDoes the browser generate the statusText for us? or is that something the library is populating and we just want to expose it better?\n. added res.statusMessage in commit 77aa6c0 for error handling revamp.\n. Seems like your module handles exactly what you want. If that is not the case, please describe more specifically what you are looking for.\n. Not to my knowledge. I think plugins are the way to go for that stuff.\nOn Sunday, March 8, 2015, Neri Marschik notifications@github.com wrote:\n\nSorry, I just wondered if there is a more official way. I didn't make that\nclear above.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/571#issuecomment-77787733\n.\n. We should start throwing these up on the wiki or even the docs pages.\n. Does it work fine in other browsers?\n. @dlockhart \n\nhttps://github.com/visionmedia/superagent/blob/master/lib/client.js#L929-L930\nNew versions of superagent don't register the onprogress handler unless you have progress listeners.\n. amazing, I had not gotten around to doing the docs yet!\n. BTW. I think you need to edit this file (https://github.com/visionmedia/superagent/blob/gh-pages/docs/index.md) otherwise your changes will be overwritten next time docs are generated.\n. :+1: \n. any chance you would be interested in writing a test that uses web workers :)\n. This is indeed an expected breaking API changed that was discussed in an issue as well as this PR\nhttps://github.com/visionmedia/superagent/pull/554\nThe thinking, to summarize, is that any non success http response is an error. If you want to know if it is a network error or something else, you can use err.status or see if there is a response object as well as an error.\nThis is documented in the changelog and the reason for the 1.x release to indicate API change was breaking.\n. Why do you feel like that is not a good API change?\n/cc @gjohnson\n. Which version of superagent?\n. Can you describe a bit about when this would be used and what this is for?\n. I specifically removed it from the repo because it isn't something I want to keep building and storing in version control. If anyone knows of a CDN that will accept files we can look into that.\nBower is not a package manager we support.\n. People using npm can use browserify. There is also a browserify CDN (I\nforget the link) but I should add that to the readme and it can provide the\nprebuilt file.\nOn Thursday, April 2, 2015, Zsolt Lattmann notifications@github.com wrote:\n\n@defunctzombie https://github.com/defunctzombie: I completely agree\nwith you on not checking the built artifacts into the git repository. We do\nthe same in our projects.\nIs it possible that you would still pre-build superagent.js for browsers\nas part of the npm prepublish script? At least people using npm will get\nit and you will not need to check it into the repository.\nhttps://docs.npmjs.com/misc/scripts\nThanks.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/587#issuecomment-88967551\n.\n. For reference:\nhttps://wzrd.in/standalone/superagent@latest or https://wzrd.in/standalone/superagent@1.1.0\n\nvia https://github.com/jfhbrook/browserify-cdn Which you can use for any npm module that can build via browserify.\n. please see\nhttps://github.com/visionmedia/superagent/wiki/Migrating-0.x-to-1.x\n. Overall I am +1 on the idea. The global parsers are one of the places where the lines between module and global ajax like library are blurred.\nI will say that I think that the instances should have some sane defaults as they do today with the option to override those defaults.\n. Can't this middleware approach be implemented today with no changes to the codebase?\n. Agreed on pre/post flight not being hook-able currently. Maybe use could be extended to accept options or a when value that would hook the used function into various predefined locations in the lifecycle.\n. How do you expect these to be serialized?\nThis opens the larger issue of using the qs module on the client which increases the client size (non trivially I think).\nNot against this overall, just want to make sure that we benefit wisely from a larger library size.\n. BTW, you can get around this by using qs yourself and passing the result string to .query.\njs\nsuperagent.get('/foo').query(qs.stringify({foo: {bar: {baz: 100}}}));\n. I am not against making this better but we have trade offs.\nOn Monday, March 23, 2015, AlekZonder notifications@github.com wrote:\n\nIf i just start using superagent and don't know about qs module, this is a\nhidden bug\nsuperagent.get('/test').query({foo: {bar: {baz: 100}}).end(...);\n// GET /test?foo=[object Object]// WTF!?\nWe can do recursive serialize and parse for GET-params.\nBut if qs module do same better and has no dependencies, why not use it?\nOkay, you win :)\nIf you don't want use qs for browser, add example to documenatation and\nclose this pull request\nsuperagent.get('/foo').query(qs.stringify({foo: {bar: {baz: 100}}}));\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/593#issuecomment-85325970\n.\n. @kmalakoff I think you are correct in that nested queries are not a standardized thing and both the parser and serializer need to match.\n\nThe node side of this library already uses qs because size is not an issue but the client size version doesn't obviously. I am inclined to lean the behavior as is and add documentation indicating what to do when this happens. The throw could also work but I am less inclined to do that because those tend to break other js execution.\n. Dude, seriously please stop spamming issues like this.\n\nLet's make the superagent community happy by doing the right thing\n\nYou are the one that is unhappy so do not assume everyone is unhappy. There are others who are happy with the API change and new users won't care, hell they may even find it makes their code simpler for the 90% case.\nMaybe the change turns out to be disliked but we don't know that yet. You have spammed enough of the posts about the topic that anyone who is looking for it will find your repo and desire to have responses all the time.\n. fixed\n. look at result.headers and then pull out the cookie header. You will need a cookie module to parse it I believe.\n. Without a failing example it could really be anything or nothing.\n. Build it using browserify\n. Not sure what the issue is, but we would need a failing test showing the POST failing. It is likely your php code is not processing the POST params correctly (I don't know PHP). Try stackoverflow.\n. I have been bitten by this a few times but the moment we change it, I am almost 100% certain someone will complain and say it doesn't work in use strict or something. As long as it works under use strict then I have no problem with making an alias.\n. Would review a PR for this.\n. .send won't result in a querystring, so not sure what that test is trying to show.\n. That is tragic. I think being explicit is better. Did this behavior ever\nwork?\nOn Sunday, April 12, 2015, Charlie DeTar notifications@github.com wrote:\n\nAs mentioned in #606\nhttps://github.com/visionmedia/superagent/issues/606, the documentation\nindicates that it does\nhttps://visionmedia.github.io/superagent/#query-strings:\nWhen issuing a GET request the res.send(obj) method will invoke\nres.query(obj),\nThis test shows the described behavior. If that's not what is\ndesired/expected, the docs need to be changed.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/607#issuecomment-92201830\n.\n. Are you having this issue with the client or browser versions or both?\n. IE. rofl.\n. I would be down for reverting it. This seems a bit too assuming especially if we have streaming.\n\nAs an aside, can we detect streaming and support both?\n. I think configurable range is something that would be nice. I would entertain adding such an API.\n. This would not be global but per instance. We already have Apis for per\ninstance so this is not hard at all.\nOn Friday, April 3, 2015, Kevin Malakoff notifications@github.com wrote:\n\nThis change would need to handled very carefully.\nIf any user of superagent can re-define the range globally, they may\nunintentionally break libraries they use that also have expectations on\nrange. That could lead to library writers having to query the range to\nprogram defensibly against uncertain configuration.\nTo properly implement this, changing the range could necessitate the\nability to create instances of superagent each with their own\nconfigurations (#591\nhttps://github.com/visionmedia/superagent/issues/591).\nAlternatively, the range could be set on individual requests, but that\ncould be cumbersome.\nFinally, we could just go back to the 0.x API and more strictly limit\nsuperagent to the transport layer instead of mixing in logic that is best\nleft in the application/user-land.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/613#issuecomment-89258576\n.\n. @aaronshaf @kmalakoff take a look at https://github.com/visionmedia/superagent/pull/617 and share your thoughts.\n\n@kmalakoff we could think about doing something global but I think your factory approach is better for the cases of creating custom request instances.\nMy general thoughts on this honestly are that you shouldn't be making agent instances all over your codebase anyway and requests (whether for APIs or whatnot) typically funnel through request methods you setup yourself scoped for the requirements. Obviously not everyone does that but the things I have written that end up doing http requests tend towards all calling a single \"request\" point eventually to avoid hunting down request code all over the app.\n. If request works I would use request. I believe the pipe in this module is for data only.\n. Needs to depend on an exact version down to the patch level.\nWhat effect does this have on the bundle size?\n. I think acceptedStatus or acceptStatus are both good. acceptStatus is maybe better in that it is more \"active\" and maybe fits with existing API calls better? Think: .send, .end, .set.\n. I still think we shouldn't monkey patch this inside of the acceptedStatus function call.\n. I still don't like the this.statusFilter patching going on.\n. I am not a fan of this approach:\njs\nthis.statusFilter = function(status) {\nAs for the regexp feature. I thought it would be nice but maybe the implementation complexity doesn't justify it? The implementation could maybe be simpler. I do think it is kinda nice to be able to specify 2xx or something similar.\n@kmalakoff do you favor any array functionality or just the function argument approach? I think some sort of array is nice to keep things simple for basic use cases.\n. LGTM\n. Critical fix! Thank you.\n. @amasad this weekend\n. Superagent is not designed for reverse proxying. You can do it, but it isn't ideal IMO. Maybe you need { end: false} on the first pipe.\n. Commented in the PR.\n. Not sure this is all that useful. Seems like a separate function can easily be created with the plugin system (based on your original use case description).\n. tests fail\n. please squash the commits\n. what does this do?\n. What about the client version?\n. Not sure what that last comment has to do with this. I was asking about the browser side version of the library.\n. While that may be the case, we still need to keep parity between the two versions if we can. Is this feature relevant for the client version?\n. I think these are issues with react-native.\n. What is the behavior on the server for the equivalent?\n. sounds like react-native is at fault here? headers are not case sensitive as far as I am aware\n. IMO the best solution is for the engine to the fixed. This has not been a\nproblem in any other browser to this point. If it was not in the spec I\nmight feel differently but given that all the other browsers behave\ncorrectly I am hesitant to fix this since it seems like a bug in\nJavascriptCore (not exactly sure what that is by sounds relatively new and\nlikely to fix this bug)\nOn Monday, May 4, 2015, Dan Horrigan notifications@github.com wrote:\n\n@slooker https://github.com/slooker @defunctzombie\nhttps://github.com/defunctzombie It is true that getResponseHeader\nshould be case-insensitive. However, this is probably an issue with\nJavascriptCore (which is the engine that ReactNative uses), thus cannot be\nfixed by the Facebook team (without an upstream fix). I think the best\nsolution here is just to use the correct case.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/638#issuecomment-98702913\n.\n. I would at least file an issue there and see how receptive they are. If for\nsome reason they are not receptive then we can revisit.\n\nOn Monday, May 4, 2015, Dan Horrigan notifications@github.com wrote:\n\n@slooker https://github.com/slooker @defunctzombie\nhttps://github.com/defunctzombie It is true that getResponseHeader\nshould be case-insensitive. However, this is probably an issue with\nJavascriptCore (which is the engine that ReactNative uses), thus cannot be\nfixed by the Facebook team (without an upstream fix). I think the best\nsolution here is just to use the correct case.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/638#issuecomment-98702913\n.\n. :+1: \n. Not working how?\n. fixed\n. This is really vague. Examples or a PR with your ideas would go a long way.\n. Because this library doesn't use promises for the API.\n. Superagent doesn't support passing in an app. That is supertest.\n. PR for docs update is most welcome. I don't know much about the current multipart support or the limitations. Nothing is perfect so this is an oversight likely in docs or regression.\n. This would be a breaking API change but also likely to lead to less confusion. outBoundError doesn't sound like the best terminology for this tho. In general I like solving this confusing part of the code better.\n. @scsper sounds good to me. I think your plan in having a better message for 1.x and a different error type for 2.x would work. Run it by others via a PR when you are ready.\n. Does using node's builtin http library also incur such a delay? I am tempted to think this is either an issue on your system or something with node's dns lookup. I highly doubt it is anything to do with this library.\n. Can you make a PR if there isn't one already? Also please add tests.\n. sounds like some webpack issue. Maybe ask them to help\n. has this been tested in non-worker environment?\n. please follow existing coding style (use braces)\n\nWhat is the consensus around the changeset now? Is this is correct version?\n. I am not increasing the size of the library for everyone just because someone wants a function with a different name. If you want promises, just use what is available.\n. I will accept a PR for the readme to point to any relevant module/use for promises if you want to show users how that can be accomplished.\n. You shouldn't need to. Have you been able to track this down anymore?\n. @GDreyV This is related/duplicate of https://github.com/visionmedia/superagent/issues/714. See my explanation there on why this happens.\n. No, agent is only available in the nodejs version.\n. Or just send a PR with a patch if this is an issue with this library.\n. I believe you can disable encoding by passing a full query string to .query instead of an object.\n. Please make a self contained test that we can actually run. How do you expect reproduction of your error if the steps to reproduce are not provided. What debugging have you done to try and identify the error? This about if I came to you with the error report you just posted above (and no other information), are you able to fix the problem based on that info?\n. why? is this a commonly used standard?\n. Website doesn't make it a commonly used standard, just makes it a website :) Adding media types is easy since superagent exposes this for the user. I think I would like more how the request module does it by letting you specify json: true option to force decoding of the response as json. Maybe adding a json(true/false) or similar API to force/unforce automatic decoding. Otherwise we are in a constant battle to \"intelligently\" detect all the various mime types for json.\n. seems mostly rails/ember specific for now. I am not against having a way to force json parsing, but as I said I think the better approach is to hint to the instance that the response should be handled as json.\n. Why is this different from: https://github.com/visionmedia/superagent/pull/673\nAnd neither have tests.\n. Browserify is a simple tool you can use to build the bundle. It does not require you to \"use node\".\nAlternatively, you can download a pre-built version from this awesome site:\nhttps://wzrd.in/standalone/superagent@latest\nAll it does is run the module through browserify for you and give you a standalone you can use.\nPowered by:\nhttps://github.com/jfhbrook/browserify-cdn\n. please follow existing coding style\n. Travis will fail because of saucelab keys being encrypted for the repo.\n. please squash the commits :)\n. Looking at this pr a bit more. I like that it handles the charset part of content-type but I don't like that it hard codes the regex check. There is already an object for the different serializers. Why not just add the content-type you want to serialize to that? Alternatively, if there is a convention/standard around having mime-type followed by +more stuff I would be open to separating the core mime type from the other stuff and checking serializers for that. This seems more general purpose.\n. Bug with react-native not this library. I would urge react-native devs to fix this up.\n. Is this still not fixed in react-native? I just don't follow that this is broken behavior. The function call has a definition on what it should return. Is this a case-sensitivity issue?\nIt seems the opposite was applicable to other vendors (and it doesn't seem like anything other than react-native suffers from this). My only reason for pushing back against this is that react-native is the newer project and is prone to bugs and poor behavior compared to the \"spec\" other browsers follow.\nThere is no bad idea in overriding the header value since by all accounts it should be the same.\nThe goal of this module is not to patch up implementation issues with react-native (which this seems to be). If you can give me a good case for this not being a react-native issue then I would gladly include the check but everything I have read about how the function is suppose to behave seems to point to it returning a value if the header is present.\n. don't understand the issue here. If the content-type header is null then the null value will be set to this.headers[content-type]. Alternatively you just don't set the value. Both seem like essentially the same behavior, no?\n. #696 sounds like a react-native bug to me. Why does it not return the correct value for getResponseHeader? Seems like if it worked as expected for that method then there would be no issue.\n. Kinda since one would reasonable expect that function to return the header value or null based on the docs: https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest#getResponseHeader()\n. The reason I have been hesitant to do this is because qs is a large module and now everyone has to bear the cost of increased file size. I know this is an annoyance but also have to balance with file size :/\n. please prefix commit message with docs:\n. thanks!\n. This is not needed. You can just build the bundle you need. This just bloats the repo and we will never keep it up-to-date.\n. err.status (or err.statusCode I forget) will have the specific status.\nAlternatively, you can check for if (res) before checking the status on res.\n``` js\n.end(function(err, res) {\n    if (err) {\n       if (err.status === 403) {\n       }\n    }\n// non error code\n\n});\n```\n. You can still use those of you check that red exists first. The new error\nhandling is based around the idea that it is better to have non success\nstatus codes be errors and force you to deal with them.\nOn Wednesday, July 22, 2015, Simone Busoli notifications@github.com wrote:\n\nDoesn't this make res.forbidden and the like (which would be quite handy)\nbasically useless?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/706#issuecomment-123780623\n.\n. Discussion already had in other issues :)\n\nYou can write the if statements however you want :)\nOn Wednesday, July 22, 2015, Simone Busoli notifications@github.com wrote:\n\nWhich means I should write this:\n.end(function(err, res) {\n  if(res) {\n    if(res.forbidden) return handleForbidden();\n    if(!res.ok) return handleNon200Response();\n  }\n  if(err) return handleGenericError(err);\n});\nIt's certainly not a big deal but not very readable either in my opinion.\nWhy are non 2xx/3xx status codes errors in the first place? Probably too\nlate to change this, but I think it would be much more consistent with\nother node APIs if the first line in a callback was always:\nif(err) return callback(err);\nwhich it is in all other libraries that I commonly use.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/706#issuecomment-123786971\n.\n. No idea without a failing example script with file.\n. I like this compared to the alternative since it doesn't increase the file size :).\n\nPlease add tests and it can be merged.\nAlso need a docs update PR.\n. Something about how this works via the .then function would help folks if they run into issues.\n. @soyuka the client aka browser version of this library\n. I don't think you can call end twice like that on the same request. That is likely undefined behavior.\n. I took a quick look at the code and can't find any place where we would be triggering the request to fire just for setting headers. But I can reproduce the exact behavior you are seeing.\n. I looked into this some more and it has to do with how superagent is behaving and using the built-in node request instances. When you call methods like set, get, unset, superagent calls the .request() method on itself (your superagent request instance). This initializes the node request object and prepares the request (via the node api). Due to the nodejs api behavior, you can still call setHeader on this request object if you are in the same tick (no IO work has been done) since the request will actually go out on the next tick it seems.\nThis is a tricky one to make a call on since the easy thing to do is to say that superagent should cache headers internally and not do anything until you 'end' your request. That might work for headers, but this same problem seems to plague the .send() call as well (and possibly others).\nI am going to say that I think superagent calls need to happen in the same tick and thus you can't pre-create a request with the intention of ending it later. Creating a request means you will be sending if off in that same tick (or at least the headers).\n. @mpjura it was closed because of my explanation above. I have not run into this error myself because I always initiate the request when it is created. I think the superagent API misleads the user into thinking they can create the request and then send it later but that is not really the case. Creating the request will send it off at the end of that tick.\n. yea, no worries\n. How would a dev use the API now versus before to do this?\n. Please clean up the commit message to just say which feature was added\n. index.html is generated with from index.md file in the docs folder so editing it directly will just get your changes destroyed on next rebuild. You want to look at head.html\nAlso not against moving to a new system for docs like slate or something else.\n. Don't like printing to the console directly. This spams the stdout. We could either throw or just let undefined is not a function error do what it is doing.\n. Yes, we did not actually intend to add full promise because I don't want to bloat the library for everyone for what I perceive to be a marginally (if not worse) api. We know this is not full promises and is not meant to be. If there is a solution you have that works better but is not requiring full promises to be present.\nping @matthewmueller \n. I like it. LGTM\n. @alex94puchades can you please make a test for this\n. I am gonna say it again. I do not care about supporting promises in this library. The .then hack was to make it a simple thenable and I was fine with that. If you want a promise then use a wrapper.\nYes, we need to document the .then call better.\n. Yes, I know. I welcome PRs that that consolidate the source code. I did not write it this way and have not had the time to allocate to re-writing it since it works.\nSeparately, some methods you will find are simply not available in the client (like .agent) because the node version can do things differently. The reality is that while same api in client and browser is a nice idea, there will always be subtle differences and that is ok.\n. Please search for other issues around this topic\n. Where is it documented that we use statusCode?\n. Gotcha, yea I can see in the changelog and code that it was added to mirror the node response object. Don't want to undo that change so this seems like a reasonable patch-up. It will remain undocumented but can be something that is there for use since the node version already had it.\n. Better to ask open ended question like this on stack overflow. In the browser it really depends on your request if cookies are sent or not. Read more about requests with cookies in browsers.\n. What is the issue? Please make a better commit message. Was the previous commit not tested? Please add tests for this now, clearly the previous commit was bad and I should have been more thorough in reviewing it.\n. Can you add a client test for these changes so it doesn't break in the\nfuture and we know it works plz :)\nOn Tuesday, September 15, 2015, Alejandro Caravaca Puchades \nnotifications@github.com wrote:\n\n@defunctzombie https://github.com/defunctzombie Sorry, really, it was\nmy bad. This is what happens when \"fast\" gets in the place of \"good\". I am\nreally sorry. The issue with the last commit was that it added the ability\nto override a parser for the Response, when what I wanted to was to add\nthat ability to Request. It WAS tested, it was tested not to break anything\nthat wasn't broken, and I was adding unit tests sometime in the future.\nEverything I said still applies: no backward-incompatible changes, no\nbroken tests, it was just a typo.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/742#issuecomment-140530726\n.\n. please remove the dummy commit and squash remaining commits into a single one with a commit message describing the change\n. @alex94puchades what's with the \"fix detection of root object\" commit?\n. :+1: \n. Seems reasonable. PR would go a long way to getting the conversation going :)\n. Are there any existing issues that talk about doing the same thing?\n. closing in favor of #742\n. What is the bug? Can you make a PR and tests for this please?\n. you need to check if there is an error\n. @pornel great, I'm gonna give this a few days and then add some folks as collaborators for get stuff going again\n. I have added all three of you as collaborators. Please work together (gets +1s from one another on issues and other things that are non trivial (like basic readme updates, obvious typo fixes etc).\n\nRemember that the original intent of this project was/is to have a library that exposes the same (similar) API on client and server so keeping parity is usually an important thing when reviewing PRs and fixing issues.\nFeel free to ping me on any specific issues if they come up or you want another vote.\nI'd start with going through the PR and issue backlogs to close out anything that is stale or super old with no responses.\nPlease avoid making sweeping changes right out of the gate, stability of the API and users is arguably more important than any particular philosophical issue.\nThank you so much for stepping up and helping out! This module is really popular and your work will be really appreciated for all the of the folks filing issues :+1: \n. I'm out for the next few days but when I get back I'll add you to npm.\nPlease leave your npm username in this issue.\nOn Thursday, December 3, 2015, Kornel notifications@github.com wrote:\n\nCan we get npm access, or assistance in publishing this release?\n@defunctzombie https://github.com/defunctzombie @gjohnson\nhttps://github.com/gjohnson @travisjeffery\nhttps://github.com/travisjeffery?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/797#issuecomment-161643812\n.\n. This seems weird to me in the sense that you are waiting for a finished even on the stream you are piping to when usually that stream is what would wait on your end event no?\n. Makes sense. In that case tho I would expect that listening to \"end\" on the response is the right thing to be doing with respect to the response being done (unless that isn't actually indicative of the response being done).\n\nDoes changing the test to wait for the end even on stream make it work reliably?\n. @niftylettuce What is your npm username?. @niftylettuce I've added you as a collaborator here and an owner on npm.\n@kornelski I've made you admin on the repo for future needs.. What specific string do you have in mind? Or just the single name corresponding to the error code?\n. Should the same thing happen on the client where this list is not available? Would require shipping this list. Or I can just change it to Request failed.\n. They are errors for ajax requests because they don't have bodies themselves or tell you much about the success of the request.\n. Why? You know if it is a network error or not based on if there is a response object in the callback.\nWe could add a flag to the error object to let you know more but my thinking was that just checking if you have a response (after error) would let you know more about the situation.\n. I think doing this in node is a no brainer, but on the client I am less sure mostly cause of the giant string dump.\n. What if total < 0 ? We won't have e.percent. Do we want to have a default value or stick with undefined?\n. We should be setting this on prototype like everything else\n. I think just saving the status filter and invoking it later is better than doing the monkey patch on this within this function\n. If the code for the two is the same, can we start to do some more code sharing? I know we don't do that now but this could be a nice time to re-use common code. Not a blocker tho.\n. please follow existing style for source files/vars\n. does the client side need to be updated accordingly?\n. this._parser || can just prefix this to avoid the lookup if we have a parser\n. Nope, just a suggestion.\nOn Tuesday, September 15, 2015, Alejandro Caravaca Puchades \nnotifications@github.com wrote:\n\nIn lib/client.js\nhttps://github.com/visionmedia/superagent/pull/742#discussion_r39561996:\n\n@@ -980,7 +980,8 @@ Request.prototype.end = function(fn){\n   if ('GET' != this.method && 'HEAD' != this.method && 'string' != typeof data && !isHost(data)) {\n     // serialize stuff\n     var contentType = this.getHeader('Content-Type');\n-    var serialize = request.serialize[contentType ? contentType.split(';')[0] : ''];\n-    var contentParser = request.serialize[contentType ? contentType.split(';')[0] : ''];\n\nIs that a real issue? Sorry, I was just trying to keep within the 80\ncharacter line width\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/742/files#r39561996.\n. \n",
    "rfadams": "I'm a little new to nodejs, so forgive me if this is painfully obvious.\nBut what type of error would need to occur in order to make the err, in the callback fn(err, res), return something other than null? For the response, I return 400 etc and err still comes back as null.\n. Thanks for the reply.\nI like the idea of emitting error events on the node side and making the .end callback have the same signature as on the client-side. \nI think I'll have some time tonight, I'll see if I can't add this. Like I said, I'm new to node, but I was looking through your code quite a bit to figure out why the first argument was always returning null. I think I can do it. I'll give it a try and make a pull request.  Thanks again.\n. Oh, maybe I misunderstood. I thought you had accepted that result. \nOn the node-side, am I missing some use for err if we change it to emit error events?\nOn Oct 17, 2011, at 3:52 PM, TJ Holowaychuk wrote:\n\nthe only issue I have with it is that it gets rid of the typical (err, result) signature that everything in node uses, but it'll be nicer to use for sure\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/visionmedia/superagent/issues/19#issuecomment-2435841\n. Yea, I understand what you mean. In talking to you, I've kind of started to reverse my position and starting to think that we should keep the standard node signature of (err, result). Originally, I liked the idea of using the same library on both the client and node side of things (since my project will use both) and having everything act the same, but now....I'm wavering since it would brake convention. I'll look at it some more...\n\nHonestly, I think alot of my (the) confusion could be alleviated simply by changing this example on http://visionmedia.github.com/superagent/ :\n```\nThe node client may also provide absolute urls:\nrequest\n   .get('http://example.com/search')\n   .end(function(err, res){\n});\n```\nIn the example online atm, it reads .end(function(res){... which is what confused me for so long. \nWant a pull request to just fix that in the meantime?\n. ",
    "stagas": "Check fn.length and support both :)\n. I'd go with the fn.length check :)\n. ",
    "jprichardson": "Cool, I really like the consistency between Node and the client. That is .end(function(err,res){ .... code .... });.\n. Ooops, sorry, didn't see that.\n. And, while you're at it... please fix the form/form-data inconsistency between client and server. This would close #63 ;) \n. TJ, looks like you can close this one... the docs seem updated.\n. I support going back to the 0.x API. Returning an error for non-2xx status codes seems silly IMHO. \n. ",
    "alexeypetrushin": "I tried to create temporary fix, can You please tell - such fix can be used, or there maybe some hidden problems with such approach?\nJavaScript\nsuperagent.Request.prototype.endWithoutErr = superagent.Request.prototype.end;\nsuperagent.Request.prototype.end = function(fn){\n  this.endWithoutErr(function(res){\n    if(fn.length < 2) return fn(res);\n    if(res.ok){              \n      fn(null, res);\n    } else {\n      fn(response.text);\n    }\n  });  \n};\n. ",
    "hkjels": "Perhaps add setBaseurl and auth or sign?\nI've just now created a little hack on superagent to work with API\u00b4s myself.\nhkjels/superapi\n. Superapi works, it's just hacky. I'd prefere something like.\nJavaScript\nvar Superapi = require('superagent');\nvar request = new Superagent(options)\nBut that's a breaking change.\nI guess something like:\nJavaScript\nrequest.setDefaultHeader('name', 'content');\nwould be a saner way of going about it at this point.\n. ",
    "hallas": "what about a notion of \"arch requests\" or \"prototype requests\"?\njavascript\nvar req = request.get(...).header(...);\nreq.clone().header(a).end();\nreq.clone().header(b).end();\n. Nope, not yet\n. @whitlockjc what exactly are you looking for?\n. closed by #333 \n. gonna look at the pull request later\n. @RGBboy we need an update on the PR to be able to merge it in\n. @riston PR is pull request, the one in question is: https://github.com/visionmedia/superagent/pull/198\n. Merge back with our master branch and let me know when, so we can merge it in\n. @visionmedia you still want this?\n. why not as a plugin instead? lets do this right.\nWould it be possible on the form request.use(parser) ? Maybe like var agent = request.agent(); agent.use(parser); and then only use that agent for the XML requests\n. won't fix this, just parse the header manually or use a library, there are plenty out there\n. i think this is a bit irrelevant now? closing to clean up the issues\n. but tell me what is your actual problem with super agent? I don't quite understand\n. so you want to properly bubble the error through the callback stack?\n. i agree with you, also the case where this can throw is when someone tries to send bad json (circular even), not really what super agent is intended for anyway ;)\n. @gjohnson lets add some tests for the thunk branch\n. @cheddar yes its being worked on\n. @cristiandouce are you still looking into this?\n. I don't see a reason for this. You are welcome to re-open with an explanation :)\n. We're not gonna merge this is, as we can't maintain changes to those docs when we release new versions. Why not host your own chinese docs?\n. for now, use the https://github.com/TooTallNate/superagent-proxy module, we're not gonna merge this in.\n. You don't leave much information about your situation. But to answer your questions. First some basics, ECONNRESET is a TCP level error, and it means the other end of the pipe was closed.\nTo catch thrown errors (ie handling them) you wrap your executing code in a try {\u00a0} catch { } clause (http://www.w3schools.com/js/js_errors.asp)\n. you can try stream.on('error', function (err) {});\n. Hey. Are you deadset on using the 201 created status code? You could use a redirect instead. The agent will follow those, and you can control that behavior with .redirects(n) when doing your request, it will by default follow up to 5 redirects.\nBut I can see you are in a browser so that's probably not relevant. What you are currently doing seems like the best way.\nYou could write it as:\n.end(function (res) {\n  if (!res.ok || !res.headers.location) {\n    log.error('failed');\n    return;\n  }\n  window.location.replace(res.headers.location);\n});\n. body is not for plain text, its for objects parsed from content-types like application/json, url encoded and so on.\n. I've been having this issue with node versions 0.6.x, not any other. I think it's fine moving this out.\n. pull the latest changes and try again :-)\n. we could try and fix it so reduce doesn't break node\n. @fgnass how does it not work, any errors? something... ?\n. well, we don't use reduce in superagent, so why should it be a dependency for us, if it fails in browserify?\n. It's hard for us to support two environments that use the same packaging information. Naturally our first and foremost priority is to support Node and the browser via component.\n. :+1: you gonna add it to the node api?\n. haha \"forgot to add it to the node version\" :-)\nI'll do it, sometime soon, both superagent and mocha needs spring cleaning!\n. whats up with the way he uses . notation in the README file, weird\n. :+1: for this as well, what about other events?\n. Alright. Follow the other issue #80 for updates.\n. What @defunctzombie said\n. Can you supply some more information please?\n. Awesome :)\n. this describes what we can do for you right now http://visionmedia.github.io/superagent/#following-redirects\n. let me look into it tonight\n. You can install it as a component as well, but yeah, include the library and you can use it.\n. Yeah exactly\n. Could you also provide what the actual use case would be for this? It's always a good idea to do so. Leaving your changes up to interpretation can create some confusion.\n. @sintaxi any news on your issue?\n. can you provide a runnable example where it fails?\n. would be really great if it was something I could just copy paste and run with node :) nvm ill fix it my self\n. @OliverJAsh an update please? \n. and bower support would be pretty cool as well\n. you can see here #226 why we rejected this suggestion before\n. ah looks like I was a bit fast, sorry\n. yeah so, but should superagent throw anything then? should we pass it all on the response?\n. How does this make anything easier when it comes to reading the content of the attachment from the fs? To me this is just sugar and we're not a a place where it makes sense to change the api significantly.\n. I don't think we need this. :-1: \n. @gjohnson what about you?\n. Sorry for now @xaka we really do appreciate your work and interest. We'll keep this in mind.\n. :-1: I don't want to add complexity when you can set the content type via the header api.\n. Yep\n. It's still here. Show us some code please.\n. I can see why this functionality could be useful. :+1: \n. :+1: \n. No plans so far but we appreciate the request and the reminder. We're working hard : )\n. Thanks, but no thanks, please contribute with issues, fixes and features.\n. I figured. I just wish it was standardized or one was a subset of the other. \n. Which version are you using?\n. ok\n. lgtm\n. not sure but try to add .buffer() to your request chain like so:\nrequest.get(...).buffer().end(fn)\n. Maybe the image your trying to send doesn't work? Maybe it's the thing thats just black?\n. Cool. Closing this. @Nascotix if you still have the problem return here\n. What @alsotang said\n. @shesek you found something that needed to be fixed and that wasn't caught in previous tests, therefor, write a test that fails, implement code to fix that test whilst previous tests still complete.\n. Ok. Use the second example but make sure your data is properly encoded. Don't use filePath, read the data into something your API can understand, either a buffer or base 64 encoded PNG string.\n. Yep.\n. Can you post what you're trying to do :) ?\n. What the content type on the response that is supposed to read the text type?\n. :-1: im sorry but big no from me on this one - I believe using the body on GET requests to start with is a big anti pattern..\n. why reference this? it isn't used anywhere\n. Fair enough, but as you can see you save parts[1] into subtypeand then ever use subtype - that sort of stuff should be cleaned up as we go\n. ",
    "smeijer": "Any progress on this? I really need some defaults. Like authentication headers and request retry on token-expiry.\n. ",
    "anthonator": ":+1: being able to set a base url and default headers would be awesome.\n. Here's a wrapper I'm using on a project for managing defaults. This specific example is used for setting a base URL. You can chain other defaults as well. I typically use this as a default and then create another wrapper around this for my app or endpoint specific defaults.\nhttps://gist.github.com/anthonator/0dc0310a931398490fab\n. ",
    "cgarvis": "+1\n. ",
    "Nican": "assignSockets overwrites the output from the \"socket\" to the file stream, so when node start writing the request, instead of opening a new socket, it will notice it already has an output and use the file stream.\nIt is more of a debugging method that I found while poking around with the library.\nWhat you see at both the file outputs is the request HTTP headers. \n. Awesome! Thanks. \n. ",
    "hunterloftis": ":+1:\n. Also getting errors on a 302 response, but getting:\nError: connect ECONNREFUSED\n      at errnoException (net.js:670:11)\n      at Object.afterConnect [as oncomplete] (net.js:661:19)\nHowever, the connection is definitely not refused as the server logger registers the request.\n. :+1:\nrelated: https://github.com/visionmedia/supertest/issues/14\n. https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L692 :smirk:\n. some things I do just for scan-ability. can drop.\n. sure, would you prefer binds on attachCookies too and drop the self?\n. makes sense.\n. k\n. I like returns in exit points because they glow bright red in my editor. can drop for superagent.\n. npm link'd to a real project, amazing how much better the tests become...\n. haha .end() took a while to grok, partly because there are native 'req' and 'res' and also Request and Response and it's easy to forget which one you're working on. I'd love to split out some of those callbacks in .end() to named functions somewhere else.\n. ",
    "OliverJAsh": ":+1: \n. ",
    "quangv": "oh really? boo, thanks hah, I guess I'll have to figure out another way to do it then...\nthanks for the correction, and all your diligence TJ ;)\n. ",
    "jackyz": "But the same sever-side code could process post-data properly that posted by CURL tool.\nAnd I had tried to dump the raw post data, there is an extra \\r\\n different from that CURL does.\n. I see, thanks for clarify.\n. ",
    "eshao": "Would like to bump this, as it would be much appreciated in the browser build. Is there any easier way of getting the browser build to be more highly in sync to the node build?\n. +1\n. https://github.com/defunctzombie/zuul/ is a good repo for auto running sauce tests\n. ",
    "tjconcept": "I guess this could be closed as of c9632bac1cb81e20c5e2e30dcc67d30cf95a6966?\n. I can't make the title fit with the changes.. Aren't you sending more cases into the ActiveXObject clause, which are bound to fail since their ActiveXObject is undefined?\n. Sorry, but it frustrates me, that I can't see this..\n\nThat means, the only time XMLHttpRequest is used when there is no ActiveXObject at root.\n\nNo, it's also used if we are not using the File protocol, regardless of the existence ActiveXObject?\nOriginal: (root.XMLHttpRequest && ('file:' != root.location.protocol || !root.ActiveXObject))\nThis is true in all instances where we have a XMLHttpRequest and we aren't using the File protocol, exactly as you new is, but is also valid if there is no ActiveXObject regardless of the protocol.\nNew: (root.XMLHttpRequest && 'file:' != root.location.protocol)\nThis is false in all instances of the protocol being File.\n. Okay, so do we agree that with this change less cases are using XMLHttpRequest?\nNamely those cases where the protocol is file: and ActiveXObject does not exist - they were previously sent to XMLHttpRequest but are now sent to ActiveXObject.\nSo the impact of this change is \"Prefer ActiveXObject when the protocol is file: even if XMLHttpRequest does not exist\".\n. > And, now it sends non-file requests to XMLHttpRequest regardless of whatever ActiveXObject is there or not.\nIt did so before as well.\nThere are only less cases sent to XMLHttpRequest. No additional cases will go there, that didn't go there before. The if clause has been made more restrictive.\nYou can write out all eight (2^3) combinations of the three variables in play here, and only one of the cases has a new outcome:\nXMLHttpRequest exists  y\nActiveXObject exists   n\nProtocol is \"file:\"    y\nThis one used to go to XMLHttpRequest but now goes to ActiveXObject - all other cases are unchanged.\nIf you're right - that a file: will never work with XMLHttpRequest - this change has no impact. But now you have guaranteed that it won't succeed, as you're sending it to use ActiveXObject even though it is not supported.\nIt breaks the scenario where my shim for XMLHttpRequest actually does support file: and I have no ActiveXObject.. Try this:\njs\nreq.on('response', function( res ) {\n  console.log(res.status);\n});\n. I don't think so in Node (because of some state not exposed before v0.12), but it should work in the browser.\n. ",
    "ghost": "I looked at the tests and it looks like it's supporting array conversion already.\nSomething else is wrong with my request. Is there a way to see what the request sent looked like?\n. Node :)\n. Never mind, it was a bug in Neo4j, not in Superagent :)\n. There is also no handling of function signatures that follow:\nfunction (url, data, callback);\nfor put/post under node.\n. GitHub was not working properly yesterday so I made a lot of dups :)\n. I used the latest git repo instead and having ?foo=bar at the end of the url worked now.\nquery() was there but it didn't work. The params weren't sent.\n. I am using the latest through git but query() isn't working.\nIt works when I am attaching ?limit=2 to the url.\nWhen using query({limit: 2}) it doesn't work as expected.\nHere's the code:\nsuperagent\n  .get(config['x-storage-url'])\n  .query({limit: 2})\n  .set('X-Auth-Token', config['x-auth-token'])\n  .set('Accept', 'application/json')\n  .set('Content-Type', 'application/json')\n  .end(function (res) {\n    if (res.ok) {\n      ....\n    }\n  });\nI don't get the same result as:\nsuperagent\n  .get(config['x-storage-url'] + '?limit=2')\n  .set('X-Auth-Token', config['x-auth-token'])\n  .set('Accept', 'application/json')\n  .set('Content-Type', 'application/json')\n  .end(function (res) {\n    if (res.ok) {\n      ....\n    }\n  });\nAny clue why that is?\n. The query() method is added to master but it's definitely not giving me the same results.\n(It would be great if there was a way to debug the actual HTTP request created by superagent).\n. Ahhh, the problem is that it doesn't work with a boolean value. It has to be a string.\nquery({limit: '2'})\nfixed the problem.\nThanks for the netcat tip!\n. Although it kinda looks strange that I have to put a boolean value within quotes.\nPerhaps allowing boolean values is a good feature?\nIt looks cleaner\nquery({offset: 10, limit: 10})\n. Must have been somewhere else in my mind when writing that post.\nThanks!\n. Thanks!\n. Closing this for now.\n. Yeah, I added it in because, in the tests - originally, at least - I sent an object as - \n{\n  date: {\n    day: 21,\n    month: 2,\n    year: 2101,\n    era: \"AD\"\n  }\n}\nand had the server spit it back out as a query string, and was surprised when the tests started failing; then realized the ints were coming back as strings.\n. Sure thing.\nhttps://github.com/visionmedia/node-querystring/issues/34\n. Hate to necro, but is this supported yet? request.options doesn't seem to be working. @defunctzombie\n. Yeah, it happen me too.\n. Was using an older version on npm, query works perfectly. \n. @pornel It is using the standard port 80 actually, I just checked\n. ",
    "barberdt": "Likewise. I believe this just needs to be changed to '.send(...' from '.data(...'\n. ",
    "nijikokun": "It's still not fixed?\n. ",
    "firstdoit": "Apparently superagent-retry is not actively maintained and still depends on \"superagent\": \"~0.20.0\".\n. ",
    "szarouski": "If anyone else will look at this issue - retry is already a part of superagent: http://visionmedia.github.io/superagent/#retrying-requests. If you're looking for more details: https://github.com/visionmedia/superagent/pull/1155. Is there a reason why it was closed? Adding timing information would be great - https://blog.risingstack.com/measuring-http-timings-node-js/. Got it, thank you.. ",
    "dbellavista": "Was it closed because it's now supported or because it's unimplementable?\n. Ok, I will expand the original issue.\nI have some express API protected by HTTP Digest Access Authentication (using passportjs, for instance) and I'd like to test them using supertest, without spawning a server.\nvar app = express();\n// ... express setup and protection using Digest Access Authentication\nsupertest(app)\n.digestAuthentication('user', 'secretkey') // Desiderata\n.get('/my/protected/api')\n.expect(200)\n.end()\nI didn't try superagent.auth(user,pass), because the documentation states that Basic authentication is supported, but there's no mention to digest.\n. Uh... right (sorry)!\nStill, it would be a useful feature to have in superagent and libraries such as supertest will get the benefits too.\nrequest\n.get('/my/protected/api')\n.digestAuthentication('user', 'secretkey') // Desiderata\n.end(callback)\n. ",
    "taylordowns2000": "Been using Superagent for about 6 months now and absolutely love it. Thanks to all involved. Are there any plans to implement a digest auth feature?\n. OK, thanks for the swift response, @focusaurus ! At the moment I may try to get the job at hand done with \"request\" but when I can pick my head up I'll do my best to take a look. By the way, I really appreciate what you've built here. It's been a big part of our open-source \"adaptors\" at www.openfn.org. Thanks again.\n. ",
    "focusaurus": "I don't think it's on any of the maintainers' roadmaps to proactively code this. If someone submit's a pull request with solid code, tests, and docs, I don't think we'd hesitate to merge it though.\n. Even passing {end: false} I still see the callback invoked twice. Do I need to use req.on(\"end\", ... instead? Yes, req.on(\"end\", .... seems to work, but it doesn't give me the res object as a parameter. Maybe you can post an example in the docs of how to have a callback at the end of a piped request and get access to the response?\n. +1 to removing arity check. Have to provide a wrapper function with arity 2 in order to make superagent play nice with async.js.\n. Can anyone interested confirm whether or not https://github.com/camshaft/superagent-defaults allows a default .end callback and whether that facilitates any of these use cases? I think in general we are pointing to superagent-default for global stuff, but will still consider things here if a compelling case can be made.\n@apsavin thank you for the workaround snippet.\n. AFAIK there is no synchronous networking available in regular node whatsoever. It's not possible to make a synchronous HTTP request in node. Maybe meteor is doing it via fibers but superagent only supports official node and browsers.. I think this has been fixed already in v1.6.1. I am unable to reproduce there and I don't see any calls to this.request() during req.set() or req.send(). @themaarten if you could confirm that would be great. Please re-open if this is still an issue on the latest release.\n. God I wish our APIs would just consistently do the same thing instead of overloading generic methods like send and trying to be clever. That said, if we behave that way and document it for GET, I'd agree to at least make it consistent for HEAD, although ultimately I'd rather not have a method that does 2 totally different things depending on the state of the request built up in the method chaining DSL so far.. OK so we're all on the same page, here's the current behavior and some options for changes we could make\n\nBrowser .get(url, payload, cb)\nCurrently puts payload in the query string\nBrowser .head(url, payload, cb)\nCurrently puts payload in the body\nProposed change to put payload in the query string\nNode .get(url, payload, cb)\nCurrently puts payload in the body\nProposed change to put payload in the query string\nBrowser .head(url, payload, cb)\nCurrently puts payload in the body\nProposed change to put payload in the query string\n\nI think whatever we choose, if technically possible, we should be consistent across the full matrix above. I'm OK with either of the below choices.\nOption A: make them all use the query string. I think this would match what I believe was probably TJ's intent when he coded the .get() implementation in f3955101 back in 2012. We'd need another commit on the node side and probably some test updates to get here.\nOption B: make them all use the body. I believe technically GET and HEAD requests are permitted to have bodies although they typically do not. This would be a breaking semantic change for 1/4 of the API surface above, and a blessing of the existing behavior as the intended for the other 3/4.\n. I believe this is addressed in the v2.0.0 release as per the comment above. Closing.\n. Do we just need a no-op function on the node side or some particular behavior?\n. Fixed by #743\n. Docs updated to no longer indicate this API. Thanks for finding this issue!\n. The only instance of .send() I see in the README is for a POST request, which defines the request body to be sent as always. This particular issue pertains specifically to GET requests.\n. OK, I have updated the docs to no longer lead users to believe request().get().send() will populate the query string. I agree that behavior was confusing and inconsistent and crossed the border from smart/convenient into magic and surprising. So .query() is for query strings and .send() is for bodies.\n. Thanks all for the effort here. I'm going to close this due to stalling without enough energy to merge over many months.\n@kmalakoff if you are still motivated to try to get this functionality in, we can re-open this (or a new one given the request-base.js refactoring I have been doing) and discuss with the current collaborators.\nPersonally, I would be inclined to reject this just based on disagreeing with the basic idea that interpretation of HTTP status codes should be configurable. I think if you want \"soft error\" behavior for certain responses, handling them in your application code outside of superagent is OK. I believe the raw data you need from the response (headers, body) is still available so I don't think there's technical barrier to \"soft errors\" in your application code, but if so I'd be supportive of a PR to ensure that.\nI think it's important for a developer who knows superagent to be able to predict the code behavior given the details of an HTTP response without having to scan your entire application code base to find a .acceptedStatus somewhere that alters behavior in a surprising way.\n. @DylanPiercey +1 on superagent-defaults being a preferable solution. I would be OK with a doc update to point folks at that library in the plugin section of the superagent docs, but I think we should close this issue and the associated PR without merging.\n. @pornel This looks OK to me and several users are keen to get it merged. OK to merge?\n. @tnrich could you provide your browser version details and what specifically happens when it doesn't work?\n. Trying to push this along. I think we need:\n- [ ] update PR to name this TransportError\n- [ ] finalize the error message\nI'm OK with the existing error message \"Request has been terminated\\nPossible causes: the network is offline, Origin is not allowed by Access-Control-Allow-Origin, the page is being unloaded, etc.\"\nIf I had to tweak it, I'd try to order the example reasons by likelihood (no data to support this beyond intuition)\n\"Request has been terminated and may not have been sent at all.\\nPossible causes: the page is being unloaded due to navigation or reload, the network is offline, Origin is not allowed by Access-Control-Allow-Origin (CORS), etc.\"\n. This shipped in 1.8 and I'm adding it to the docs now.\n. Not sure the exact history of things here, but a responseType(name) method has made it into superagent releases. OK to close this out as resolved/duplicate?\n. There seems to be several issues and PRs about this issue. I need some time to review and come up to speed before I can confidently make a recommendation. In particular, #699 includes tests.\n. Sure. I haven't looked at these in detail yet so if you have, go for it.\n. I'm going to close this as #696 has been closed and the maintainers have not been compelled to merge after almost 8 months. If this is still an issue for you with the latest react-native, maybe follow up with that project. Thanks for your effort, though!\n. LGTM. Should be OK to merge. No release needed.\n. @olalonde @pornel another one we should be able to quickly review and merge.\n. EDIT: OK, my first analysis was off (I was probably looking at the browser code by mistake). This defunctzombie comment is still an accurate summary of the fundamental problem here.\nThus I don't think near-term avoiding initializing the node request until the very end is probably not feasible, and if we did it, it would probably warrant a semver major and be a big deal.\nHowever, in the case bminer is describing, we should indeed provide a fix to capture the early DNS lookup error and call the callback if .end(cb) is later called.\nI'll have to do some more thinking to fix the cases, including DNS lookup failures, timeout expiring before send, etc.\nPRs welcome, but I'll try to circle back and make a concrete suggestion after some more focused analysis.\n. OK thanks for posting that snippet. Let me reproduce locally and try to understand what's going on.\n. @reinaldo13 this looks good on the client side. Could you add another commit making the corresponding change to the server side code with a test as well?\n. @eligolding can you rework this change to reflect this conversation and re-submit? If not I'll recommend closing this as minor and stale.\n. OK, this looks good to me now. I tested locally. @pornel recommend merge on this one.\n. Not convinced this in an improvement. I recommend closing.\n. LGTM. Recommend merge. Doc-only update so no semver bump necessary. @pornel @olalonde please review and merge if you agree. @reinaldo13 thank you for your contribution!\n. This is just a doc update for a plugin. LGTM. Recommend merge. Does not need a release.\n. I'd like to see both client.js and node/index.js updated to maintain API parity. I'd also like so see this implemented just by looping over object properties and dispatching to this.field(name, value). Not sure silently ignoring any non-object arguments is good behavior, but whatever you propose I'd like to see the API docs clearly explain what happens if you pass a non-object argument.\n. Still would like the docs to explain how non-objects are handled and think ignoring them is bad, fail-silently behavior likely to make debugging take much longer than necessary.\nNeeds at least a basic unit test to be seriously considered for merging.\n@pornel what are your thoughts on this?\n. LGTM. API addition so semver minor bump. @pornel @olalonde please review and merge if you approve. @aaroncrows thanks for your good work on this one!\n. Some minor nit picks:\n- jsdoc has wrong type for parse method argument\n- I'd suggest just a literal copy/paste of the node/index.js parse method code and jsdoc to keep the variable name this._parser the same\nI'd be +1 to merge this with that bit of cleanup.\n. LGTM. @pornel can you review please?\n. LGTM. Bugfix so semver patch. @vadimgoncharov if you feel inclined to add a unit test, we'd love that. @pornel @olalonde please review and merge if you agree.\n. Seems reasonable to me, but also probably worth some detailed review. @pornel @olalonde thoughts?\n. Closing as #753 has been resolved by #756. @sescobb27 if you want to PR in any additional unit tests to make sure your specific use cases work, please do so.\n. I tried to reproduce your issue with superagent v1.4.0 but was able to set a custom User-Agent header without any issue. Can you try to create a Minimal, Complete, and Verifiable example on the latest superagent release and post your results?\n. LGTM. Recommend merge. Semver patch vs minor is debatable but I guess the conservative path would be to consider this a semver minor change.\n. @olalonde see #785 for updates on transitions to new maintainers.\nLGTM. Recommend merge and semver minor bump.\n. LGTM. Fixes the only failing test in master on node v4. Test-only fix so no release needed. Recommend merge.\n. @olalonde @pornel this is an easy candidate to merge. Can you review and +/-1 please?\n. Yes it would be good to get io v3 and node v4 in travis. I'll file and issue and assign to you :-)\n. I reviewed this PR. LGTM. Recommend merge and bump semver patch.\n. LGTM. For those scanning PRs, this is a doc fix that just changes URLs that currently cause HTTP redirects to the new correct/canonical URL. Doc-only fix so no release needed. Once the new maintainers get things stabilized with tests passing etc should be OK to get the git conflicts resolved then merge this in.\n. Merged in via #786 after rebase and conflict resolve. Thanks for the contribution!\n. I believe that may be technically possible but reviewing the current code I'm pretty sure it does not currently work. This would create another feature disparity between the browser and node, so there may be some objection to adding this based on that. My thought would be getting the basic mechanics working over a unix socket would be pretty straightforward but then it would get complex dealing with redirects and facets of HTTP coupled to the host:port origin like cookies etc.\n. LGTM. doc-only fix so no release needed. Recommend merge.\n. I'm interested in helping out. I'm doing some PR review and issue triage now.\n. Also not a fan of bower. I'm also not sure this will in fact work when installed via bower but I have no strong objections to merging this, especially if others in the community will shoulder the maintenance burden.\n. I vastly prefer npm for both node and browser development (with browserify). I resort to bower only when some library I need is bower-only and I can find no suitable alternative on npm, which is trending toward never on a steep trajectory.\n. We can certainly use a weirder port to make this less likely.\n. I'm +1 on more tooling, but down the road after we clear the backlog of PRs/issues. For the next few weeks/months as we work the backlog, I think it's more important to work PRs/issues and not get bogged down with \"hey can you resubmit this PR with a comment in this magic format?\".\n. Yes I would definitely consider merging. Give it a shot and let us know if you have any questions.. I added a few more todos to that. It would be good to document the release process for the new collaborators. Not sure who holds the npm keys etc.\n. Oh and it should be v1.5.0 I think because 42e897d1fc0df6828762a03935ed227b5c1fe3c5 adds a new API.\n. Yes.\n. I like adding an extra property to the event. My only reservation is the word type is so broad and users could expect to see HTTP method names there, \"XHR\" or many things. How about something more specific like 'transferDirection' or 'transfer' or 'direction'?\n. Sadly, it looks like request.parse indeed sets a request body serializer and then this._parse in the browser request instance is indeed a function used for serializing request bodies. Thus I don't think the confusion is request vs. response but rather parse vs. serialize. I'd like to see a PR for the following changes:\n- rename the private var this._parser to something more clear like this._serializeBody in the browser client code\n- Add a new clear public API to set the request body serializer. Perhaps req.serializeBody() (open to more concise suggestions for the name). This can be an alias of the current req.parse in the client code.\n- I don't see any functionality in the node code to provide a custom body serializer. It seems to all just be hard coded in exports.serialize which presumably can be overridden in a straightforward way if a user has read the source, but maybe we should make an explicit API to keep parity with the browser code.\n- deprecate existing request.parse with corresponding doc updates\n. Thanks, @andyburke !\n. :shipit: \n. OK let me rework my changes and PR them directly into master then, and from them we can merge into gh-pages.\n. I'm getting CORS access denied errors, but is res.body populated for you? If so, it's because your response Content-Type header isn't prefixed with text/ and side note is probably incorrect.\n. Great. I've similarly been thinking about whether a BaseRequest common prototype should be extracted that extends EventEmitter and has all the copypasta between node/client code. May need some tooling updates to keep the jsdoc convenient when we generate the HTML docs. I'll wait until we get the test passing to merge this change, but otherwise +1.\n. LGTM\n. LGTM\n. At first glance, this seems like a webpack issue to me. superagent's use of the browser field seems correct from a glance at this version of the browser field spec. Maybe retry with the latest webpack and if it is still not working, report an issue with them?\n. @rbardini Thanks for the detailed analysis. I suspect you are right and a polyfill is necessary. PR would be welcome, especially with tests as without automated tests IE9 support could easily rot over time.\n. If I'm reading the latest code in the v1.6.1 branch correctly, response parsing should be disabled entirely once req.pipe() is called.\nCould you confirm what version you are running and retry with the latest release?\n. The other issue in react-redux-starter-kit has been closed. I don't think this is a superagent issue. Closing. Re-open if my cursory analysis is wrong.\n. Note I was concerned about needing to accommodate some of the jsdoc moving around in the code, but it seems our website API docs are entirely separate in docs/index.md so no need to retool any of the documentation.\n. @pornel there's a bunch of code (at least .type(), .auth(), and .accept()) that could be made consistent/shared except for the wrinkle that in node we use the mime package (which contains a huge .json data file far too large to send to the browser) whereas on the client we have a small hard-coded list of html, json, xml, and urlencoded mime types and shorthand names. Maybe that list could be extracted out via package.json \"browser\" field such that the rest of the code could be unified? Any suggestions?\n. Also .auth() has a Buffer in node vs btoa in browser issue that I think using browserify's Buffer might work OK, but not sure if that would make the client bundle bigger (if so how much) or if there's a more clever way.\n. OK, I'm going to close this as complete for the near-term. The remaining candidates to refactor to request-base.js have enough complications to warrant their own issue/PR.\n. This sounds like a general question about node callback control flow. Yes, you can get the data outside of a callback, but not until it arrives and the callback executes. Once the callback gets the data you can assign it to a variable, add it to an array, or whatever else you need to do with it. It sounds like you want to do this.\njs\nvar body;\nrequest.get('/data').end(function (error, res) {\n  body = res.body\n})\nconsole.log(body)\nIn which case, no you cannot do it that way.\n. LGTM. Thanks @markdalgleish. @pornel please review and merge if you agree.\n. @vicanso would you be willing to review and unify query string handling comprehensively now that we have the request-base.js file for common code. I believe we could have the same code running in node and the browser, but currently both the behavior and implementations are different. It would take some analysis to describe the differences, choose the most correct behavior, code that into request-base.js, update tests and docs. That would be part of #830.\nMy initial thought was the query string should respect the order values are added across several .query() calls, but if there are real caching benefits to be had by sorting, I'd definitely consider it. Generally more deterministic behavior is desirable but I couldn't say with confidence whether there would be negative consequences of sorting by default.\n. These are failing due to saucelabs not being able to start up one of the environments:\nError: [init({\"build\":\"724\",\"name\":\"superagent\",\"tags\":\n[],\"browserName\":\"iphone\",\"version\":\"9.2\",\"platform\":\"Mac 10.10\",\"appium-version\":\"1.3.6\"})] The \nenvironment you requested was unavailable.: {\"status\": 13, \"sessionId\": \n\"7421609f14fa4e0c9fcc88e67c6383e2\", \"value\": {\"message\": \"The Sauce VMs failed to start the \nbrowser or device\\nFor more info, please check https://docs.saucelabs.com/reference/troubleshooting-\ncommon-error-messages\"}}\nCan we disable that environment or somehow get a more reliable process?\n. The way I read the error message seems to mean \"we couldn't get an environment started at all\" thus I don't think they even ran any code in this case.\n. I would prefer not to add more API surface for this. Is this not reasonably achievable already with request.parse['application/json'] = stripPrefixes?\nIn either case this would need consistency in the node/client code before merging.\n. Yeah this is unfortunate. If we do anything, I'd vote to remove the fake promise API entirely and bump semver major. I'd personally rather stick with a callback API that follows node core conventions and let folks do something like Promise.promisifyAll(request.prototype) (with bluebird) if they want Promises.\n. I can't weigh in from tons of experience on libraries of this popularity, but my gut says the substack/hammer approach of shipping semver major as often as we need is better. I think browserify has gone from v9 to v13 and I've never had to change my code. Ditto for joi.\nGiven this library still has a pretty big backlog of PRs and issues and a fairly small allocation of contributor attention, I don't think we're in a position to offer \"long term/maintenance\" releases on prior major versions. I think for the most part, stuff that's broken in v1 has probably been broken a while.\nI'm OK with batching up a few issues into a single semver release if we already know about them and have a fix plan at the same time, but other than that I don't think we should hold code back more than say 2-3 weeks.\n. I'm -1 on babel for the node code base. I guess I'm OK with it for the browser, but I'd rather build the client via browserify sticking with ES5 as we currently do. I find needing a babel preprocessor before running code on node a major development hassle and I'd rather say this works on node directly.\n. It's not that simple. You need to transpile before you can run tests or debug. You need sourcemaps. Many existing tools for debugging, linting, code coverage, etc are not babel aware yet and everything becomes slower and more complicated and confusing. All this makes babel painful for me and ES5 simple and fast. I don't think there's much in the ~3000 LoC superagent codebase that would hugely benefit from ES2015 features. Anyway, end of my opinion on that one.\n. I'd vote to deprecate .then() in 2.0 and remove in 3.0 in favor of user-choice promisification method applied to req.end(cb)\n. OK if we can easily fix up .then() to have good behavior without too much\nhassle, sounds good to me.\nOn Sun, Jan 17, 2016 at 7:32 AM Kornel notifications@github.com wrote:\n\nIf you mean complete removal of .then(), then I'm against it. While the\ncurrent implementation is bad, complete removal is an unnecessary\ncompatibility break. If we add promisification to .end(), we can make\n.then() call .end(). for backwards compatibility.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/854#issuecomment-172329710\n.\n. So prior to the change, the behavior was different in node and the browser. Now it's the same. We store both as-provided (req.header) and lowercased (req._header). When passing headers on to the underlying node/browser APIs, we use the as-provided values.\n\nThe articles and RFCs you link to, and node core's behavior indicate HTTP header names are case-insensitive.\n. Looks like you already did, but yeah. Any thoughts on deprecating either component and/or bower support as of 2.0 so we could consider removing in some subsequent major release? I don't mind maintaining them (especially if others who are actively using them help out), but AFAIK component is pretty much abandoned/forgotten now and bower had a spike of much more popularity, but clearly is being abandoned in favor of npm going forward.\n. I've had some projects update to it via npm-check-updates. That was a bit surprising, but no issues so far but my usage is pretty basic. I'm OK releasing it as stable. I'm not aware of any users actively installing the betas and doing explicit testing so I'm not sure we're going to get any additional feedback on the pre-releases.\n. Thank you!\n. Perhaps we can sanity check Content-Length header before unzipping? In node I think we just .pipe() into a zlib stream but perhaps that doesn't handle zero-size payload properly. Anyone care to code a unit test and a fix and submit a pull request?\n. :shipit: \n. In current superagent, the equivalent functionality would be:\n1. listen for the 'request' event in place of ajaxStart\n2. Use the .end() callback in place of ajaxStop\nI would consider a PR to have superagent emit an end event (for responses, aborts, and errors) in the same place we invoke the .end() callback so there's a consistent event model without having to mix event handler and callbacks.\n. LGTM\n. Could you use curl --verbose or the chrome dev tools network tab to post the full raw text of the HTTP response including the headers and body? \n. The curl output looks OK. The devtools output indicates the 2nd payload has been stringified twice and is thus no longer valid JSON, just a regular string. Hard to debug this remotely. It could be a superagent bug, but I think we'd need you to do some more work on a minimal reproducible case.\n. LGTM. I think the build failing is travis flakiness getting one particular environment running.\n. Agree. I will tackle this as part of #830.\nPersonally I think names like get, set, data, field while concise, are unclear and if I were to design this library from scratch I would replace generic works with correct and specific http words (header, body, etc) and opt for obviousness vs conciseness (so getHeader instead of get). However this library and a lot of TJ's libraries (express, mongoose) do use the super-concise ones, so it seems best to maybe maintain that consistently.\nSo I'd probably vote to just go with get and set being the consistent superagent API for headers, leave getHeader implemented as an alias for backward compatibility, but perhaps deprecate it in the next semver major.\n. Also according to the API javadoc, getHeader is a private API and get/set are the public APIs your code should be using.\n. From the few times I've looked into travis flakiness details, it seems to be travis themselves cannot allocate a Win/IE10 (IIRC) environment for the browser tests, so they never even run. I'm not aware of flakiness with the node tests. But there could be other issues I'm not aware of.\nThe funny bit was that we had zuul running on port 4000 and some node tests also trying to start a temporary express server on 4000 so if you ran zuul to run the browser tests then tried to run the node tests, they'd always fail, which is pretty facepalmy.\n. Could you add a unit test, please? Otherwise seems reasonable to me.\n. LGTM, thanks!\n. I believe all the HTTP verbs from WebDAV are supported as they are included in the methods module that is our full list of supported methods. Is there anything specifically beyond that you had in mind?\n. Try this:\nrequest.move('http://10.184.19.243:4502/content/dam/phase1/publish/11ss/abdcd')\n  .auth('user', 'pass')\n  .set('Destination', 'http://10.184.19.243:4502/content/dam/phase1/publish/22ss')\n  .end(yourCallback)\n. I think we'd surely consider a pull request with some documentation around WebDAV. The file to edit is docs/index.md. I'd just want to be sure it was clear what can be expected to work in browsers (to my knowledge mostly GET and POST only) vs what works in node.\nI don't know if any of the collaborators are actively working with WebDAV so I'd think we are probably not in a good position to document the details of the situation accurately.\n. I'm hesitant about this. Is there any way we can properly automate tests for this?\nAre you using destructuring syntax there? Is that supported in all of our target node and browser environments?\n. If the collaborators merge this into master, I'll follow up with a series of smaller PRs for each of the methods that have small discrepancies between browser and node code. Just wanted to get the basic structure in place and all tests passing and agreement from collaborators before tackling those.\n. OK, I'll start working through the longer list in #830 and submit individual PRs for each of those methods.\n. I don't believe REST addresses bulk delete (or really bulk operations of any kind), at least I'm not aware of any convention. In practice I have seen RPC style endpoints like DELETE /api/books/bulk sending an array of ids as the request body.\n. I'd vote for the API req.responseType(string) and the implementation just later does xhr.responseType = whatever without any  explicit validation of the string value (which might make new valid values \"just work\" in the future, and allow the error handling to be left up to the browsers). I think exactly matching the official property name responseType from the spec is the most obvious thing, just made into a chainable method call because that's the overall pattern of superagent.\nIf later we want to design some single API for managing binary bodies that is consistent across node and browsers, we could attempt to do that, but it'd be a nontrivial undertaking and we'd need a complete table of all the combinations and design an expressive API. If anyone is anxious to attempt to design that near-term, I'd be OK to postpone this new API until that's ready, but I suspect that pragmatically we should merge this and create a new browser-only API (perhaps with a no-op in node) to make this work for the browser near-term.\n. Thanks!\n. Here's the build failure. I think this is a temporary environment issue. Rerunning.\n- waiting: <firefox 44 on Mac 10.10>\nevents.js:141\n      throw er; // Unhandled 'error' event\n      ^\nError: connection refused: localtunnel.me:42359 (check your firewall settings)\n    at Socket.<anonymous> (/home/travis/build/visionmedia/superagent/node_modules/zuul/node_modules/zuul-localtunnel/node_modules/localtunnel/client.js:84:32)\n    at emitOne (events.js:77:13)\n    at Socket.emit (events.js:169:7)\n    at emitErrorNT (net.js:1256:8)\n    at nextTickCallbackWith2Args (node.js:441:9)\n    at process._tickCallback (node.js:355:17)\nmake[1]: *** [test-browser] Error 1\nmake[1]: Leaving directory `/home/travis/build/visionmedia/superagent'\nmake: *** [test] Error 2\nnpm ERR! Test failed.  See above for more details.\n. Some notes I took while planning/coding this FYI for anyone who may do archaeology on this later:\nthe header situation\n- client\n  - this._header stores lowercase names and values\n  - this.header stores mixed case names and values\n  - .set(name, value) sets both\n  - .unset(name) deletes both\n  - .getHeader() gets from _header (lower, private API)\n  - .end() sets them into the real XHR from .header (preserves case)\n  - no req.get() currently, although there is a res.get() on the response\n- node\n  - this.header stores lowercase names and values (except User-Agent)\n  - .request() sets them on the native OutgoingMessage from this.header (uses lowercase names)\n  - no .getHeader(), just directly this.header['lower-case-name'] for internal api\n  - .get(field) public api is case-insensitve\n  - .redirect() deletes them all except 'User-Agent' and sets them again via .set() for second request\n- proposed refactorings to unify\n  - \u2713 this._header stores lowercase names and values\n  - \u2713 this.header stores mixed case names and values\n  - \u2713 .set(name, value) sets both\n  - \u2713 .unset(name) deletes both\n  - \u2713 .get(name) gets from _header, case-insensitive\n  - \u2713 .getHeader is an alias for .get, marked as deprecated in next semver major\n  - \u2713 internal code just does this._header['lower-case-name'] as internal api, don't use .get or .getHeader\n  - \u2713 internal code when setting headers on native request, use this.header to preserve case of names \n. Yeah I suspect it's been there a while but no one has encountered/noticed\nit. I guess the fix would be to loop through the keys in .header and\ndelete in case-insensitive manner. I can code that up.\nOn Thu, Feb 18, 2016 at 5:00 AM Kornel notifications@github.com wrote:\n\nBTW, I've noticed a bug (that was there before) \u2014 .set('Foo').unset('fOO')\nwill remove the header from ._header, but not .header.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/891#issuecomment-185682912\n.\n. dreamhost is sending an incorrect Content-Type header. Should be application/json but it's Content-Type: application/javascript\n. To workaround, try: superagent.parse['application/javascript'] = JSON.parse. If they are sending real JSON (which is not the same as javascript), this hack/workaround should get you going. If they are really sending javascript, you'll need to come up with an alternative way of parsing or evaluating it to extract the payload you need.\n. Also, be sure to report this to dreamhost as a bug. They are a technical company and should not be providing a broken API like this.\n. Closing as not a superagent bug and workaround provided. @willin don't hesitate to re-open if you still need help.\n. Are you building via make? This is a browserify-compatible module that will use all the above deps when run in node, but when built for the browser will just do module.exports = FormData; which means it just uses the FormData global the browser provides, and none of other dependencies are bundled either.\n. You might consider coding this as a superagent plugin that works with request.use(absoluteUrlPlugin) and then submitting a PR to add your plugin to the superagent README.\n\nAside: I think your module might need to support the obscure HTML <base> tag to correctly handle the (rare) pages that make use of it.\nAside: Your repo has misspelled \"examples\" in the directory name.\nLooks like a neat plugin!\n. Well the only facts we have easy access to are that it passes the tests. I'm in no particular rush to release it as it's not delivering high value to end users and subjecting them to some small risk, but we can if you think smaller releases are more manageable. If it does break things, I'll keep an eye out for opportunities to improve the tests.\nGiven I'm probably only about 20% through my goal of code refactored to shared, I'm hesitant to do a bunch of beta releases.\n. OK, sounds good.\nOn Mon, Feb 22, 2016 at 2:28 PM Kornel notifications@github.com wrote:\n\nRight, so we don't know what the risk may be. I believe in release early\nand often.\nI think the fact sharing is only 20% done is good, because if it turns out\nto be breaking, we'll know before 80% of the work is done (and we can\nchange the course of action).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/896#issuecomment-187391320\n.\n. I reviewed the diff between 1.7.0 and master. Looks good. Ship it! :shipit: \n. :cake: \n. LGTM. :+1: \n. Nice catch!\n. Trying to confirm with the tests that .abort() is chainable but getting some unexpected failures where the .end callback is firing in browsers. Give me some time to investigate. May need to revert this.\n\nI think zuul is loading old code somehow for me locally. Investigating...\nVery confusing. zuul depends on superagent and loads version 0.15.7 so there is a version of client.js loaded into the browser devtools other than the one I was expecting.\n. Code change is pretty obviously not problematic, so LGTM. Could you explain a bit further the before and after behavior driving this change?\n. LGTM. Thanks!\n. Sounds plausible to me. Maybe we should wait until stream fires \"end\" before we emit \"end\" here?\n. If this gets merged, #912 can be closed without merge.\n. I think it's confusing here. I don't think our implementation of pipe is really part of the node stream API. It's just sugar for piping the response to a file, but you call req.pipe and listen for req to emit end. So yeah, if we had exposed the res to the caller and let the caller do res.pipe(writable), the caller could listen for end or finish etc according to the node streaming API. However, I think the end fired off req is not really the same thing, so with this change I'm making the semantic \"when the response has been fully streamed to its destination stream and that stream is finished, we are clear to indicate via end to our callers that the IO is done and they can proceed.\nDoes that make sense? Again, I could be completely misunderstanding this, but like I said I think it's confusing because there's real streams here and even though Request subclasses Stream I'm not sure it's going to actually behave like a stream with all the required methods and events. For example, is req.pause() going to do anything useful?\n. Maybe it's the unit test that is broken then? Maybe the unit test needs to do stream.on('finish') before trying to read the file instead of binding reading the file to then req emits end?\n. I just rewrote this and rebased as just a fix to the test logic leaving the superagent logic unchanged. We'll see if it resolves the TravisCI reliability problems. I would say this has a fair shot of fixing the issue for good but would definitely welcome anyone else to review the problem and offer their own analysis. @defunctzombie thanks for your input!\n. OK my git/github/rebase kung fu failed me repeatedly, so closing #912 and this one in favor of #914 \n. Whew...it actually passed the first time. Had fingers crossed for that one.\n. Would sortQuery be a better name in terms of English grammar verb object?\n. LGTM. Semver-Minor. @pornel thoughts?\n. I rebased this code and addressed Pornel's comments. The tests now pass and there's documentation. It's in my fork here: https://github.com/focusaurus/superagent/tree/sort-query\n@vicanso The rebase lost your commit author metadata. You may want to take the final diff between my sort-query branch and master, make a single new feature commit, and then PR that in. I think we should be able to accept the PR then unless @pornel has any further reservations.\n. I suspect you are misunderstanding the mechanics of CORS. These headers you are talking about are HTTP response headers that the server must send. The do not go on HTTP requests and thus you would not set them via superagent. You would set them in your server application, which might be running express or some other server software.\n. LGTM\n. I don't see .then() mentioned anywhere in docs/index.md. Let's document this while we're at it. Other than docs and my comment above about done() this looks good to me.\n. Could you grab the tests I added from this commit on my fork and rebase your PR including the test code?\nFrom a feature perspective, this looks good to me. I confirmed at least in Chrome the browser happily sends OPTIONS requests and includes the body.\n@greensk I'd be curious to hear your specific use case and motivation for adding this feature.\n. @pornel I think we could merge this and roll into a semver minor 1.9 release or for 2.0 which it seems like we are getting close to ready to release.\n. OK, I started testing. The tests pass with the latest versions of most things, with the following exceptions:\n- should.js need to refactor res.should.have.status(200) to res.should.have.property('status', 200) as of should v4 (I think. Latest is v8)\n- form-data needs to ship 1.0.0 without release candidate\n. Requesting help from anyone more familiar with componentjs. How does this interact with browserify/npm? Should we be building a superagent.js file with browserify and checking that into the master branch and referencing that from component.json? Do we need to roll back this change and make sure the browser implementation uses only in-repo deps or deps that have component support?\n@airportyh @jongleberry-bot @matthewmueller ?\n. Done.\nWhen the travis browser test fails with failed: <internet explorer 9 on Windows 2008> (0 failed, 0 passed) is that a travis issue allocating a worker to run that OS/browser?\n. I rebased but still seeing failed: <internet explorer 9 on Windows 2008> (0 failed, 0 passed). That seems like saucelabs isn't even running the code, but I will start bisecting the changes.\n. Now the tests are passing in CI. I don't think it's flakiness in the superagent code, I think it was just an operational issue with saucelab spinning up IE9 workers.\n. LGTM. Maybe we can add a webpack build to superagent's CI build/test process to catch similar errors in the future?\n. Other than my one comment about the unit test filenames, this seems like good functionality to merge. Thanks!\n. LGTM!\n. LGTM\n. LGTM\n. This is likely a networking issue on your server. Try from your server's command line: curl -v https://eksisozluk.com/debe. If that also fails, it's a networking issue, most likely an outbound firewall dropping outbound traffic resulting in ETIMEOUT. If the curl version does work, we can look further into node/superagent.\n. Thanks for the fix!\n. How about posting the code snippet that is generating the error?\n. Listen for the 'request' event. \n. If we just need a daemon I have Ubuntu x64 droplets in digital ocean SFO1 I can easily run something (docker or debian/ubuntu package) and could set up a DNS name for it.\n. For a while now it seems like our CI stack is unable to consistently pass test builds. I'm filing this issue to try to figure out exactly what the issue(s) are and see if it can be fixed.\nFirst, some notes on how things work as I understand them:\n- Key files are Makefile, .travis.yml, .zuul.yml\n- Automated CI test builds are run by Travis CI whenever a pull request is created or updated\n- Travis runs the same test suite in several environments including node versions 0.12, 4.6, and 6.7\n- The node tests on Travis seem stable and consistently pass\n- One configuration travis runs sets BROWSER=1 to trigger saucelabs automated browser testing\n  - This is handled via zuul and amounts to\n  - starting up a local express server on the travis worker instance\n  - using zuul to open up a port on localtunnel.me so that local express instance is Internet-accessible\n  - launching a suite of saucelabs headless/automated browser tests running the superagent client tests pointing at the localtunnel URL\n  - In Travis, I think we experience 3 types of failures\n  - Some saucelabs OS/browser combos fail by exceeding a 2s timeout\n  - Some saucelabs OS/browser combos fail by exceeding a 10s timeout\n  - Some saucelabs fail with connection refused from travis worker out to localtunnel\nLocal Behavior\n\nTrying to run make test-browser from my laptop seems to start/wait/restart saucelabs instances for a very very long (forever?) time. Many many minutes go by without seeing any successful runs.\n\nOpen Questions\n\nWhy don't the zuul/saucelabs tests work when run locally?\nWhy do the zuul/saucelabs tests fail when run within Travis?\nShould we consider switching to the Travis Sauce Connect Addon?\nShould we switch to a saucelabs alternative?\n. I deployed my own localtunnel server today, verified it worked for a normal express app, then tried to run the superagent browser tests through it. Still hanging waiting for saucelabs to actually start running any browser tests. I think I'm going to open up a support case with saucelabs and see if they are willing and able to help troubleshoot this.\n. Will keep an eye on travis runs as new PRs come in to see if GH-1103 makes things reliable enough.\n. LGTM.\n. You need to configure CORS properly on your server and browser code. Closing this issue as it is not a superagent bug.\n. No. Most client side CORS behavior is implemented in the browser itself.\n\nOn Thu, Jun 2, 2016 at 2:24 AM lioralt notifications@github.com wrote:\n\nOnce configuring CORS on my server side, do i need to change something on\nmy superagent side for it to work ?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/996#issuecomment-223227165,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AAdcSV56aXpQedbDvVkEqvP8vey3Z8kOks5qHpNEgaJpZM4Iril4\n.\n. Isn't this going to fail here: https://github.com/lmk123/superagent/blob/81c979d43f32c5016917475a8e58a1ecfc40ff49/lib/client.js#L755 ? You removed a function without updating the places that call that function.\n. How about reproducing the issue in a unit test and thus verifying the fix?\n. .pipe() is a node-only API. Streaming is not supported in the browser. Are you using webpack to bundle your code for the browser? If you are actually running your code in node, there is no need for webpack, so don't use it on node code.\n. Just to clarify, you are using webpack to build a bundle, and then running\nthat bundle in node.js on a desktop via node-webkit? If so, my guess is\nwebpack is reading the superagent package.json browser field and bundling\nthe browser code instead of the node code. Could you try loading superagent\ninto node-webkit without browserify to test that theory? You may be able to\nwork around it by removing the index client line\nhttps://github.com/visionmedia/superagent/blob/164585fc55ca0186ad052f8f23a49f3387353599/package.json#L54\nfrom\nsuperagent's package.json before bundling as well.\n\nOn Wed, Jun 22, 2016 at 11:11 PM StMarcusDE notifications@github.com\nwrote:\n\nHi,\nwe\u2019re using webpack for both, a mobile version of our app and a\nnode-webkit version as desktop app. We bundle the sources to get a better\nloading time. We need to download hugh packages in our app, so that is why\nwe preferred to pipe() the request. And we choose superagent, because it\nworks on mobile and desktop. Can you point me to a solution on how to\nrealize a download with superagent without the pipe function? Or is there a\nworkaround?\nThank you so much\nVon: Peter Lyons [mailto:notifications@github.com]\nGesendet: Mittwoch, 22. Juni 2016 15:59\nAn: visionmedia/superagent superagent@noreply.github.com\nCc: StMarcusDE marcus.ziegelmeier@gmail.com; Author \nauthor@noreply.github.com\nBetreff: Re: [visionmedia/superagent] request.get(url).pipe(stream)\ndoesn't work for me - pipe is undefined (#1010)\n.pipe() is a node-only API. Streaming is not supported in the browser. Are\nyou using webpack to bundle your code for the browser? If you are actually\nrunning your code in node, there is no need for webpack, so don't use it on\nnode code.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub <\nhttps://github.com/visionmedia/superagent/issues/1010#issuecomment-227752101>\n, or mute the thread <\nhttps://github.com/notifications/unsubscribe/AIpuiNCFsGz6GdAwiQsMYNKxBLdUXNhFks5qOT-1gaJpZM4I7yTC>\n.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1010#issuecomment-227951474,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AAdcSfj2XHWtEO2T5nIjYoe4De4yJ2UNks5qOhV0gaJpZM4I7yTC\n.\n. Well I'd say first step would just be to document this. Throwing an error doesn't immediately strike me as a great thing to do, but I don't have any better suggestions beyond either console.log a warning or throw an error as you have above.\n. @bendman request.get(url).end(callback) should work fine in both the browser and node. If you are seeing reproducible issues with that maybe file a separate bug. \n. @bendman If you want to update the docs, this issue goes through all the APIs and talks about which are node only etc. That would be a good starting point for a PR to update docs/index.md.\n. Lgtm\n. This is a browser standard behavior for security around cross-origin AJAX requests. Check this stackoverflow answer for some details and search online. This is not something superagent can change/fix.\n. Ha you're too fast! I was trying to replace jquery-ui with the latest in the repo but their custom package builder server is throwing 504s at the moment. This looks good to me and getting the libs from CDN should be nice.\n. I like your suggestion of {a:null,b:1} encodes to ?a&b=1. That seems reasonable.\n\nMore broadly, I dislike informal serialization schemes that try to map nested objects and arrays into a query string since they tend to be poorly-defined and have broken edge cases. If I were to rethink the superagent API I might explicitly limit .query(foo) to a single non-nested object of names and scalar values.\n. So the superagent API returns the request instance you are building up, not a promise, from most of the API methods. This is because the superagent API is based on the chaining paradigm. In order to get a promise, you must call .then() which deviates from the main pattern in that it returns a promise, not the request instance. Once you have the promise, you can call its .catch() method.\nWe need the API to work this way so we can tell when you are done configuring the request and thus we should actually send it vs you plan to further chain calls to set headers, etc.\n. LGTM. @pornel should we merge this?\n. This is probably a publishing script mistake. @pornel can you fix please?\n. Have at look at the stream.pipe(req) docs: http://visionmedia.github.io/superagent/#piping-data\n. Thanks!\n. Nicely done!\n. A forEach should work fine:\n```\nconst request = require('superagent')\nconst req = request.post('http://localhost:3000')\nconst files = ['1.txt', '2.txt', '3.txt']\nfiles.forEach((file) => req.attach(file, file))\nreq.end((error, res) => {\n  console.log(error, res)\n})\n```\n. I think this is one of those API decisions that could go either way. Either you write application code like that to treat responses with error status codes as successful responses or you change the superagent API to treat them as success, but then you have to write application code to look at the status code in the application and respond accordingly. For example, detecting a 404 with HTML in the body when you were expecting a 200 with JSON.\nI personally wish the original superagent API was \"any HTTP response is success\" semantics, but it's not. This is something that would be such a breaking change I'd hesitate to change it without something as drastic as forking and renaming the project. I believe that has been discussed on github issues in the past so you might get some insight searching through closed issues for discussion.\nI know of at least request-promise which has this behavior configurable:\n\nBy default, http response codes other than 2xx will cause the promise to be rejected. This can be overwritten by setting options.simple = false.\n\nI would hesitate to make the core API configurable in this way, but I do understand your frustration.\n. Well, if we do it, I'd rather do it with a different API like adding a\nreq.getResponse() method.\nOn Fri, Sep 16, 2016 at 8:37 AM Tao notifications@github.com wrote:\n\nSo since request-promise add configuration to this, how about superagent\n\ud83c\udf89\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1069#issuecomment-247617098,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAdcSWMICCSs4_mdiiGXpj2Ud6o_nYSkks5qqqmlgaJpZM4J-1Q4\n.\n. I believe the chai-http plugin is in use here. That has superagent 3.7 which should have .ok I believe so not sure what's wrong.. Test failures look like legitimate issues that should be addressed, not saucelabs flakiness.\n. Use request.post('/').send(sendToServerData).type('json').then(handleSuccess).catch((error) => {console.log(error.response.body)})\n. Please send the full HTTP request and response headers if you can. That will help us troubleshoot. Auto-parsing of response bodies is primarily based on the Content-Type header in the response.\n. +1 on documentation. -1 on presumptive parsing \n. Superagent itself should have no problems sending the Authorization header. We do often find issues with supertest specifically. Can you change your code to a straight node app working directly with superagent (not supertest) to send a request to your express app which is separately running and listening? That would confirm whether the issue is really superagent as opposed to something with supertest.\n. It might be worth getting some explicit coordination from the supertest maintainers on this branch before merging. I believe their mechanism to integrate with superagent will continue to work but I think it would be worthwhile to test. Looks like @mikelax is the most recent active maintainer. Perhaps I could try to pull down the supertest repo, integrate it with this branch of superagent, and see if their unit tests still pass.\n. I was able to:\n- clone supertest\n- npm install, run tests, they pass\n- rm -rf ./node_modules/superagent && npm i 'ahelmberger/superagent.git#mixin-requestbase-prototype'\n- supertest unit tests still pass\n\nSo that's a good sign.\n. Pragmatically I don't think there's much harm done in treating this as semver major even if in retrospect we find out nothing important broke. That's probably better than semver minor that unexpectedly breaks some integration, so I wouldn't sweat it too much.\n. Nice! I think this might be more appropriate as a superagent plugin instead of in the core module. \n. Closing. Will comment on 972.\n. I believe the Set-Cookie response header is explicitly not exposed to javascript on the page by the browser itself. There's mention of this in the MDN getAllResponseHeaders documentation but I couldn't quickly find any additional detail.\n. If you can reproduce on demand, it would be great to get a stack trace. Edit the node_modules/superagent/lib/node.js file and replace this line:\nif (this.called) return console.warn('superagent: double callback bug');\nwith this line:\nif (this.called) throw new Error('superagent: double callback bug');\nThen reproduce it and post the stack trace here.\n. Well, most of the sauce browser tests actually passed. The one that failed has:\n<internet explorer 10 on Windows 2012> request :: on 303 :: should redirect with same method\nError: Unable to get property 'text' of undefined or null reference (http://jhpwkkjpxw.localtunnel.me/__zuul/test-bundle.js:10232)\nWhich I would think means localtunnel failed to serve the test-bundle properly. Edit I'm actually not sure exactly what failed because we don't log the error properly. I fixed that in another commit.\n. Maybe let's try focusaurus.com (a domain I bought just to run localtunnel-server in a docker container after realizing localtunnel-server only works on top-level hostnames), at least for a while to see if there really are reliability problems with localtunnel.me\n. It's not clear to me why the plugin example needs updating this way. Perhaps you did not encounter docs/index.md which powers the main superagent website and documentation?\n. \ud83d\udc4e for clever API interpretations and overloading. My first thought would be leave .timeout(2000) as an alias for the entire request completing including the full body, and introduce APIs like .resolveTimeout(500), .connectTimeout(1000), .headerTimeout(3000), .chunkTimeout(4000).. Yes, overloading meaning a single API function call that has multiple meanings or behaviors depending on arguments provided. I think in general that's an antipattern and having distinct API functions that do 1 clear thing is preferable, even if it means the API surface is bigger (it's just being honest about the actual API surface).\nI don't mind .timeout({connect: 42, chunk: 97}) that much though. It's not terrible. It just requires good validation and I think it's easier to document and more obvious when you typo .conectTimeout(42) and get an obvious exception vs calling .timeout({conect: 42}) and maybe having to debug why the timeout seems to not be taking effect as expected. If the code detects unexpected option names and throws an exception immediately, it's close enough I think.\nI think we should have no defaults and do what the runtimes/node/oses do by default.\n. One way that is pretty simple in my opinion is just use an alternate initial request function in your application:\n```js\nconst request = require('superagent')\nfunction appRequest (method, url) {\n  return request(method, url).agent(myAgent)\n}\n```\nUse that throughout your application instead of directly calling the superagent request function. The code throughout your application can then use the full superagent API to configure requests before sending them.. Maybe you'd prefer monkey patching like this:\n```js\nconst superagent = require('./')\nconst http = require('http')\nconst myAgent = new http.Agent()\nconst OrigRequest = superagent.Request\nsuperagent.Request = function RequestWithAgent (method, url) {\n  const req = new OrigRequest(method, url)\n  return req.agent(myAgent)\n}\nconst b = superagent.get('/')\nconsole.log(b._agent)\n```\nKeep in mind someone reading your code, seeing what looks like unmodified superagent use but getting different behavior may feel that a monkey patch in some other file in the code base is \"not very clean\" and causes surprise in the bad sense.\n@pornel What do you think about emitting an event when a new request is initialized so folks could do superagent.on('init', customize)?. It looks to me like the issue is probably with sending a compressed response body but manually setting the Content-Length header based on the uncompressed body size, thus resulting in there being less data than declared due to compression. In both your client and server code, it is usually best to let your libraries handle Content-Length automatically as they will calculate it correctly. I doubt this has anything to do with the actual content of the request body in terms of pound sign.. LGTM. Restarting travis to handle saucelabs browser test flakiness.. You can extend parsing with request.parse['application/jwt'] = function (text) { return text }. Similarly you could decode the JWT into a javascript object if that makes sense for your application.. The firefox windows 10 tests are failing and it doesn't look like sauce flakiness. Do you want to have a look?. Your server is probably crashing due to an uncaught exception in your auth related code. Perhaps there's a JSON.parse call not wrapped in try/catch? But the problem is not in your superagent client code, it's in your express server.. Thank you!. I think the issue is the appium version. Using the saucelabs platform\nconfigurator, it looks like if we want to test Android 5.1 that only works\non Appium 1.5 and 1.4.\nOn Tue, Jan 10, 2017 at 6:53 AM Kornel notifications@github.com wrote:\n\nThe tests failed due to:\nAndroid@5.1:\n[init({\"build\":\"1265\",\"name\":\"superagent\",\"tags\":[],\"browserName\":\"android\",\"version\":\"5.1\",\"platform\":\"Linux\",\"appium-version\":\"1.6\"})]\nThe environment you requested was unavailable.: Appium 1.6.3 does not\nsupport Linux. Please check our platform configurator (\nhttps://saucelabs.com/docs/platforms)\nI'm not sure if we need to specify something like \"Android on Windows\"\n(dunno how) or something else entirely. The linked page doesn't explain\nanything in detail.\nFor now I've removed Android from tests d7d2839\nhttps://github.com/visionmedia/superagent/commit/d7d2839437e74feb7a500fcb9b2a40b825c18725\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1151, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AAdcSTpdz79oy5Xsr4RLn-XGHS4g8Hqaks5rQ41VgaJpZM4LfbxY\n.\n. I have no real opinion on this but would console.warn be slightly more semantically correct if we consider these \"warnings\"? I think ultimately this is going to cause misbehavior so they usually do represent actual errors in the application needing a code change to fix. (In which case console.error seems like the best choice). OK I merged the warning version.. superagent (and all other browser HTTP client libraries) is ultimately built upon the functionality provided by XMLHttpRequest which does make use of the browser cache, but the specifics of how and when it is used are complex and may vary between browsers. You as a developer don't have any mechanism to explicitly opt in or out of the cache, other than using URLs with cachebust parameters in them.. I'm OK with it, as long as people don't interpret it to mean some kind of deep OAuth 2 support.. Thanks for this great effort! I'll watch for additional commits addressing the unit test failures.. Should we make the corresponding change to the node side as well?. Thank you!. Thanks!. FYI my tests were passing locally but this failed in Travis. I wiped  node_modules and re-installed clean and I can reproduce the test failure, which is unrelated to this PR code change but probably due to some dependency changing behavior in our test web app. Investigating.... Looks like mime 1.3.4 had xml as application/xml and by 1.3.6 it switched to text/xml. I don't know the backstory behind that nor am I sure of what the semver/breakage implication is for end users of superagent.. @pornel Thoughts on this? \n\nI confirmed it was mime 1.3.6 that introduced this change.\n```sh\n/tmp/20170524-100433 -> npm i mime@1.3.5\nmime@1.3.5 node_modules/mime\n/tmp/20170524-100433 -> node\n\nrequire('mime').types.xml\n'application/xml'\n\n/tmp/20170524-100433 -> npm i mime@1.3.6\nmime@1.3.6 node_modules/mime\n/tmp/20170524-100433 -> node\n\nrequire('mime').types.xml\n'text/xml'\n```\n\nI did some github research trying to understand the back story for this change but the rabbit hole got the best of me.. Also FYI I asked for help here: https://github.com/broofa/node-mime/issues/158\nI see no mention of this change in the mime-db history file: https://github.com/jshttp/mime-db/blob/master/HISTORY.md\nI'm a bit perplexed at this point. Hopefully someone closer to the issue might shed some light so we can merge this and get the tests passing again.. Note 2 mime xml test failures are expected. There's a separate open PR that fixes those. All other tests should be passing for both node and the browser.. Well either branch the repo bloat is the same. I'd be ok deleting the test.html file which I believe to be entirely useless then the only auto-generated file would be docs/index.html.. OK I'll open a new PR targeting gh-pages.. I did request.get('http://poj.org/problem?id=1002', function(error, res) {console.log(error, res && res.text)}); with the latest version of superagent from node v6.10.3 and I see HTML all the way to the close html tag so it looks complete to me. How are you determining the HTML is not complete?. Thanks!. Can you elaborate specifically on \"better\"? Better how? What use cases would it enable?. Probably more precise to log _.text with the superagent callback. The body property is used when we parse response JSON into an object. In your case you test service is probably just sending text/plain with Hello World which will be available via superagent in _.text (_ being the response object, more typically named res).\nI don't think ports have anything to do with this - just understanding the superagent response API property semantics.. My initial thought is the browser is actually doing a multipart form upload which requires a corresponding Content-Type. See https://msdn.microsoft.com/en-us/library/ms527355(v=exchg.10).aspx for more details. Try removing your js/superagent code that overrides the Content-Type header. I think that will allow the browser and server to process the content correctly.. Ah no this looks very suspect to me and you are most likely confused. They are node style error first callbacks. What specifically makes you think differently?. You should be able to simplify the server code even further with:\njs\nres.type('image/png');\nreadstream.pipe(res);\nYou don't need bufs and the associated code. .pipe() will do that for\nyou.\n. The response for non-2XX responses is available on the error object: err.response.text will have the value your express server sent as the response body.. Which version of superagent?. OK can you look at node_modules/superagent/package.json for the version field please? Your stack trace is not current master.\nFor your error, the problem is your are explicitly setting text/plain content type then passing in an object for the body. You need to pass a string or buffer, or stringify your object explicitly.. OK so yeah the TypeError is when your request body object gets passed unmodified to the node OutgoingMessage.end method, which expects a String or Buffer.  Superagent auto-serialization only handles application/json and application/x-www-form-urlencoded content types. Other than that, you have to serialize your request body manually. . As far as the node core http API is concerned, this basic type checking and throwing an exception is their \"graceful\" error code. I'm OK with this as it's consistent with the node core behavior, although I'll grant you it may not score that many points for grace.. I agree it's a rare but valid use case so a tough call. If we expose the\nrequest object can you configure localAddress on it after it's already been\nconstructed?\nOn Fri, Sep 22, 2017 at 4:46 PM Kornel notifications@github.com wrote:\n\nSuperagent doesn't have this functionality. Mainly because it's not a\ncommon need, and it doesn't have equivalent on the browser side (we try to\nmaintain parity).\nI'm not sure what to do about this. The use-case is valid, but probably\nrare.\nOn browser side we expose the XHR object. Maybe we can just expose the\nNode's request object too? (as a \"use on your own risk\" API for such rare\ncases). @focusaurus https://github.com/focusaurus WDYT?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1280#issuecomment-331577563,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAdcSScaw3xEGU09KnHrcIF184N_8yClks5slDjWgaJpZM4PhQUt\n.\n. I'm investigating. I switched DNS from namecheap to digitalocean but things should have kept working.. I think it's working now. I think the issue was I didn't have a wildcard DNS A record for *.focusaurus.com configured, but while troubleshooting I also updated to the latest defunctzombie/localtunnel-server:latest docker image as well. Can you confirm?. Hmm. Am I interpreting the discussion correctly? So if a user sets EXPOSE_HTTP2=true they can only connect to http2 servers from that entire node process and connections to http/1 servers will fail? That sounds untenable. I think I'd prefer leaving HTTP/1 as the default and exposing an API to use http/2 on a per-request basis. For that I think the .http2() method name is a good API.. Awesome contribution @sogaani !. app.all should be OK here to keep code minimal.\n. Does this need to be made case insensitive to be correct?\n. These lines duplicated code already in .field and should be removed.\n. This syntax is incorrect. You need a colon here instead of a comma.\n. Maybe. The complication is the node class inherits from Stream, which inherits from EventEmitter so that's where the event emitter methods come from on the node side, vs the client side which uses component-emitter.\n\nI was planning to just use events.EventEmitter and util.inherits and let browserify deal with that in the client, but not sure if that would be cleaner. Any idea if we really need the \"browser: {\"emitter\": \"component-emitter\"} bit from package.json anymore? I'm not sure our test coverage regarding emitted events is that thorough though so I'm a bit cautious.\n. OK added a commit along those lines.\n. I'm definitely not familiar with this aspect of XMLHttpRequest, so I could be way off base here, but this line seems dubious. The Content-Type header is describing the body format for the outgoing request and the responseType is indicating how the response body is to be represented to the application JS code. Can you explain how/why Content-Type and responseType need to interact like this?\n. Good point. I checked and it looks like form-data is properly browserified to use the built-in FormData on the browser:\nhttps://github.com/form-data/form-data/blob/master/lib/browser.js (their package.json file has the proper \"browser\" property as well).\nI'm OK with this approach overall in dealing with node/browser discrepancies. We'll have a few others to address soon enough like btoa, Buffer, etc.\n. And actually, based on this it's probably OK to just do a direct var FormData = require('form-data'); and let browserify do it's thing.\n. I think you need to take a done() parameter here or mocha will consider the test passed before all the assert calls are reached. (And same pattern in a few other places below)\n. Ah, I haven't seen that before. Looks good then.\nOn Tue, Mar 8, 2016 at 9:17 AM Kornel notifications@github.com wrote:\n\nIn test/basic.js\nhttps://github.com/visionmedia/superagent/pull/925#discussion_r55382858:\n\n@@ -64,6 +64,36 @@ describe('request', function(){\n         done();\n       });\n     })\n+\n-    it('is optional with a promise', function() {\n\nI'm using Mocha's Promise support here:\nhttps://mochajs.org/#working-with-promises\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/pull/925/files#r55382858.\n. If this is supposed to be a non-existent file, let's make it simple and obvious and just use 'test/node/fixtures/non-existent-file.ext'. The timestamp implies something about uniqueness that I don't think is really at play here.\n. Using node core http, not the npm request module, right?\n. Would it be marginally more efficient to do Object.prototype.hasOwnProperty here instead of declaring a new object literal each turn of the for loop?\n. At a glance this looks like it will emit the error event even on successes when error is null. Am I missing something?\n. I'd prefer curly braces for all if statements, but with or without is OK but let's make all 3 instances use the same syntax. The other 2 don't use curlies.. Otherwise LGTM.. Is this missing a typeof?. \n",
    "rauchg": "See https://github.com/visionmedia/superagent/pull/53\n. -1\n. I'd be interested in adding a Node version for:\nhttps://github.com/webmodules/jsonp/blob/master/index.js\nWe can use teh browserify browser field in package.json to point to the\ncurrent implementation, and add a Node-specific one.\n\u2014\nGuillermo Rauch \u2013 @rauchg https://twitter.com/rauchg\nOn Wed, Oct 15, 2014 at 9:06 AM, Garrett Johnson notifications@github.com\nwrote:\n\nProbably not... In most cases when you need jsonp, you don't need 99% of\nthe API superagent has since there is no headers, etc. If all your looking\nfor is the syntax surgar superagent uses, you could steal some code from\nthis thing -> https://github.com/redventures/pixel\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/89#issuecomment-59230679\n.\n. I get this pretty often as well\n. Yes. Who sends XML anyways.\n. Duplicate\n. +1\n. I think we also don't have error at all for status?\n. (I only find occurrences of .error in client.js but not in node/index)\n. +1\n. Errors are a problem in the logic. An unexpected outcome. A 404 can be perfectly expected. The example I usually give is: \n\nhttps://twitter.com/rauchg/status/556153308168323072\n. They simply are not errors. They're data. That's why you're always gonna have edge cases or debates about whether X status code was an error or not. The data got from end to end successfully. It was a success case, not an error case.\nThink about it this way. The goal of the request function is to get the Response object, which has properties like status and text. Anything that gets in the way of producing that Response object is an error. Anything else is not.\nThat's why the signature is err, res. There are two possibilities: we got err, or we got res. We are proposing an in-between scenario where we got res, but it's also an err.\n. It's a really bad idea to consider HTTP-level error codes actual errors. Maybe a better way to think about it is, is a stack trace helpful at all for a 404? That's certainly not an Error.\n. Oh, good point, I'll switch it to end\n. Or I'll leverage that StringDecoder provided it's not private API?\n. The thing is, it's there for HTTP, but it's not there for regular Streams. Which means the parsers are not interoperable with streams returned by zlib.createUnzip for example.\n. I just added deflate/gzip support to demonstrate this.\n. The other thing we can do, which is kind of a hack, is a method unzip(res) that returns a glorified Stream with setEncoding, that leverages the StringDecoder\n. Check this one out\nhttps://github.com/visionmedia/superagent/pull/53\n. ",
    "DamonOehlman": "Figured that might be the case... Good call on the query method, might have a look at doing something with that now.\n. Awesome, that saved me some time :)\n. ",
    "strk": "+1 -- this is needed for Windshaft tests \n. I think it takes express 3.x for node-0.8 support, so package.json should be updated to reflect that.\nBeing the master branch it may make sense to require express 3.x (and hoping it will work with older node ...)\n. actually express 3.x requires connect 2.3.6 which in turn requires node >= 0.5 :(\n. npm cache clean fixed this\n. This is with current master (0b3e3733 aka 0.5.0-3-g0b3e373)\n. ",
    "lundin": "I tried to use the restler api with the 0.2.x library and got the same result as the posted code above (i.e the server never gets the data) However i updated restler to the new version where a postJson method exists. I will look into the source what it do differently other than setting the content-type and what is different to superagent but that method works.\nrest.postJson(url,json,option) with the parms supplied in my first post.\n. ",
    "alfredwesterveld": "+1. I also tripped over this.\n. ",
    "nagisa": "What about HEAD support for browser version?\n. ",
    "plessbd": "I submitted pull #76 as a fix\n. Didnt know a pull request opened an issue\n. I would really like to see this merged.\nIs there anything else that I need to do to get this merged?\n. I think I did what I needed to...not sure about the rebasing\n. Added tests.  Thank you for having me do this.  It helped me find a few issues and taught me a lot.\n. Pull request #76 adds this functionality\n. I am doing this on pull #76 for the Auth header.\nWe just need to make sure not to send information to another host if it shouldnt be.\n. ",
    "lancejpollard": "I am having this same issue and this pull request fixes it, please merge.\n. Awesome, thanks!\n. Lol, I think it's just the api is request.query now for GET, and request.send for POST/PUT/DELETE, different from the site docs.\n. nice, thanks!\n. For whatever reason, doing it exactly like this works:\n``` javascript\nagent.parse['binary'] = function(res, fn) {\n  res.text = ''\n  res.setEncoding('binary');\n  res.on('data', function(chunk) {\n    res.text += chunk.toString('binary');\n  });\n  res.on('end', fn);\n}\nexports.download = function(url, callback) {\n  var nodes = url.split('/')\n    , ext = nodes[nodes.length - 1].toLowerCase()\n    , type = mime.lookup(ext)\n    , name = nodes[nodes.length - 2]\n    , path = 'data.gov/downloads/' + name + '.' + ext;\nif (!agent.parse.hasOwnProperty(type)) {\n    agent.parse[type] = agent.parse['binary'];//agent.parse['text'];\n  }\nagent.get(url).buffer(true).end(function(response) {\n    var encoding = 'utf-8'\n      , text = new Buffer(response.text, 'binary');\nfs.writeFile(path, text, encoding, function(error) {\n  console.log(path);\n\n  if (callback) {\n    process.nextTick(function() {\n      callback(null, path);\n    });\n  }\n});\n\n});\n}\n```\n. ",
    "KyleAMathews": "It'd be nice to get complex objects -> query strings supported. I ran into a problem with this today.\n. For now I replaced the code in the serialize function with jQuery.param\n. ",
    "msuess": "Yes, it will break. Actually, it won't work for anything but strings. buffer.length reports the correct size, though. Maybe something along the lines of:\njs\n      // content-length\n      if (data && !req.getHeader('Content-Length')) {\n        this.set('Content-Length', typeof data === 'string' ? Buffer.byteLength(data) : data.length);\n      }\nThis should work for both buffers and strings.\n. Content-Length is fixed. I won't have time to look into this any further for today, but do you have some pointers to code that needs adaption off the bat?\n. ",
    "srohde": "I was looking for something similar to the output of for instance Charles like:\nPOST /test HTTP/1.1\nHost: localhost:4000\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:11.0) Gecko/20100101 Firefox/11.0\nAccept: application/json, text/javascript, /; q=0.01\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip, deflate\nContent-Type: application/x-www-form-urlencoded; charset=UTF-8\nX-Requested-With: XMLHttpRequest\nReferer: http://localhost:4000/\nContent-Length: 14\nCookie: some.sid=OdS3YHpTdsadsadr32423asd\nPragma: no-cache\nCache-Control: no-cache\n{\"body\":\"Foo\"}\n. makes sense, thanks!\n. ",
    "christiaanwesterbeek": "I don't get it. Case is closed by showing how to debug res.headers where the question was about the debugging the request. Oh well.\n. +1\n. ",
    "robotlovesyou": "In case anybody else ends up here you can use\n.end(function (error, result) {\n   console.log(result.req);\n});\nAlthough the request is a pretty big graph so you'll probably just want to look at one or two properties\n. ",
    "davidhq": "Thank you @robotlovesyou, that was useful!\n. ",
    "kennethklee": "closest i could get was\nconsole.log(result.req._header + JSON.stringify(json))\nwhere json was the body I sent.. ",
    "inadarei": "That would be great. Thanks.\n. My bad. I closed it since TJ responded, but I guess this ticket could be open so JSONP support is in the backlog as a request? Reopening.\n. ",
    "ingro": "I know this issue is pretty old, but there is actually a way to handle JSONP request with Superagent?\n. ",
    "balsamiqstefano": "Is anyone actually working on writing a JSONP plugin yet?\n. ",
    "stresslimit": "There is a simple project based on superagent that does just this: https://github.com/code42day/jsonp\nI had this same problem with the Instagram API and using the above jsonp library instead of superagent it \"just works\".\n. ",
    "ntucker": "I couldn't find any plugin for JSONP, so I wrote one here: https://ntucker.true.io/ntucker/jsonp-plugin-for-superagent/ @balsamiqstefano\n. ",
    "enyo": "Any update on that?\n. Fixes #90\n. I just thought that it's such basic and trivial code, that barely\njustifies it's own function. And TJ said to replace it with just a for\nloop, so I did that.\nBut I can create a function for it instead if wanted.\n. @visionmedia your thoughts?\n. ",
    "impronunciable": "did you try\njavascript\nrequest.post(url).set('port', your_port)\n?\n. I solved using a noop custom parser. buffer(false) is not working, that's the problem. The sample method of the Streaming API send ~1MB data per second so res.text grows at the same level. \nAgain, I solved for the library using .parse(function(){}) but .buffer(false) seems to fail on this situation, I think is an edge case (I'm receiving json data but the connection will persist \"forever\") but we'll have more cases like this in the near future.\n. I tried using .buffer(false) and .pipe() (and both together), none of this work. I think the problem is with the response type signature.\n. It would be nice but meanwhile you can check the /test folder\n. Please try using var request = require('superagent')\n. ",
    "slaskis": "Hmm. probably should add 303, 305 and 307 to that redirects-array as well as they also should contain location headers...\n. That's true, but they don't all require a location header or imply try-again-at-this-url. \nIf requesting with an \"if-modified-since\"-header now it throws an exception whenever there's a 304 and this.url is undefined.\nOr do you mean this stuff should be handled in Request#redirect() instead?\n. I rebased this pull request on your master and added the other redirect status codes.\n. @gjohnson why did you close this issue without merge? What the PR does is adjust to match that of the updated spec.\n. Yes the comment you linked to points to the spec where it says that if you set withCredentials before xhr is in the OPENED state (i.e. before xhr.open() has been called) it will throw an INVALID_STATE_ERR exception. And this is what happens right now when I use superagent in something like phantomjs. But this PR fixes it (and doesn't break any tests).\n. Thanks, I appreciate it\n. ",
    "rase-": "@defunctzombie I think this can be closed as .pipe now returns a stream.\n. Looks like it was addressed recently: https://github.com/visionmedia/superagent/pull/558\ncc @defunctzombie \n. Perhaps related to https://github.com/visionmedia/superagent/pull/567\n@contra could you try with latest master and see if that helps?\n. Auth works fine with a polyfill according to the test suite: https://github.com/visionmedia/superagent/blob/master/test/client/request.js#L565\nI'm wondering if we should just document it somewhere (like in the README after the plugins section?) that IE9 use requires a polyfill for auth instead baking it into superagent. Thoughts?\ncc @defunctzombie \n. If we're just going to document the need for a polyfill, I think this can be closed after merging in #564.\ncc @defunctzombie \n. It could be useful to introduce another API for this and revert the current behaviour of .end().\nWe could have something like a .success() and .error() handler that are mutually exclusive (in a way) with .end(), where any response that qualifies as a valid response currently would end up in .success(), and any errors plus error status codes would end up in the .error() callback.\nDiscussed this briefly with @defunctzombie and @rauchg (ping for some more thoughts/discussion).\n. :+1: LGTM as well\n@vstirbu looks like it needs a rebase.\n. Is this still an issue?\nA piece of sample code could be useful.\n. What qualifies as \"large\" here?\n. Should work as demonstrated in this test case (on node): https://github.com/visionmedia/superagent/blob/master/test/node/pipe.js#L25\n. Indeed I think this can be closed.\nIn future versions there is no arity checks for the end cb, so the error will always be passed there.\ncc @defunctzombie \n. @defunctzombie: Looks like there already is an abort test and some timeout tests that are already failing without the patch:\n```\n req.timeout(ms)\nError: Could not complete the operation due to error c00c023f. (https://flyyywknnz.localtunnel.me/__zuul:1)\n req.timeout(ms) with redirect\nError: Could not complete the operation due to error c00c023f. (https://flyyywknnz.localtunnel.me/__zuul:1)\n request :: .abort() :: should abort the request\nError: Could not complete the operation due to error c00c023f. (https://flyyywknnz.localtunnel.me/__zuul:1)\n\nfailed:  (3 failed, 85 passed)\n```\n. Here's the stacktrace for the failing test:\n\n1) request on redirect should follow Location even when the host changes:\n     Uncaught TypeError: Cannot call method 'send' of undefined\n      at null.<anonymous> (/home/rase/OSS/superagent/test/node/redirects.js:35:9)\n      at timer._onTimeout (timers.js:219:16)\n      at Timer.listOnTimeout [as ontimeout] (timers.js:112:15)\nHappens on both 0.10 and 0.12.\n. Though it seems fine on travis.\n. https://github.com/visionmedia/superagent/pull/556 fixes that aforementioned test for me.\n. @defunctzombie completely agreed. I figured for now it's good to have parity, but using the builder API for setting things up is so much more composable and clean that we might as well eventually drop this.\n. LGTM\ncc @defunctzombie \n. Seems like a good idea to me. Thoughts @defunctzombie?\n. LGTM. Thanks!\n. I do think parity with express would make a lot of sense, not to mention consistency of verb method names, and would be in favor of this. \ncc @defunctzombie for an opinion\nI wonder if there is another reason for missing .delete other than reserved names being generally considered bad practice for property names.\n. Thanks!\n. Can switch to .acceptStatus\n. @kmalakoff I figured the API is a bit too primitive with the function filter alone, but I'm open to create a separate module for that. Thoughts on this @defunctzombie?\nRegarding your point in 2), this is how I had coded things up before I rebased, since it seemed like a better fit conventions-wise for the file. \"Unsetting\" the filter seems like a good idea, though. I'd vote for changing things back. Thoughts on this @defunctzombie?\n. For sure. It is the same yeah. Maybe in a separate PR right away after merging this in?\n. Didn't we want to set the range per instance?\n. The idea here was to save it to the object property, and it's actually called later in the range check when the response is received, so I'm unsure what you're referring to by saving.\n. ",
    "lwille": "Okay, I think I messed up something. You're checking for an \"exports\" variable which should only exist when running on node. But stitch is supplying module, exports and all that stuff in the client.\nAlso, the events.js is only working when prepended to superagent.js - not when required via the CommonJS interface (it's missing a module.exports). I'll make a pull request if you like.\n. ",
    "clux": "Yeah, it would be nice to be able to use this with browserify as well.\nOne alternative I can see is to set a different main with browserify, i.e. specify \"browserify\" : \"browserifyEntry.js\" in package.json. Then move the eventEmitter stuff to the two entry points, and injected the right one in those. This should make the packaged code slimmer as well.\n. ",
    "tomasdev": ":+1: having this issue while using superagent inside node-webkit (and I don't know why it doesn't find EventEmitter - @rogerwang maybe?)\n. I've just found out it's because of superagent index.js file:\njavascript\nif (typeof window != 'undefined') {\n  module.exports = require('./lib/superagent');\n} else if (process.env.SUPERAGENT_COV) {\n  module.exports = require('./lib-cov/node');\n} else {\n  module.exports = require('./lib/node');\n}\n:| I don't know if this is node-webkit responsibility or superagent's.\n. ",
    "jduncanator": "@tomasdev It's super agents. However things could get complicated and messy when detecting node-webkit over browsers. I'd suggest something like:\njs\nif((typeof process != 'undefined' && process.versions['node-webkit']))\n    // This is node-webkit!\n. @gjohnson The issue is that node-webkit exposes a global window variable which causes superagent to think its running in a browser, even tho node-webkit supports the full Node.js APIs. \n. @rogerwang What exactly do you mean?\n. @rogerwang But would that not affect all the other applications built to use window? I'm not sure I understand what you mean by \"Node Context\"\n. ",
    "rogerwang": "@tomasdev I'm considering removing the window reference from Node context in node-webkit. I'm not sure whether other developers would need it.\n. I mean the global window variable which causes superagent to think its running in a browser. Some other JS libraries use this way too. In order not to confuse them I'm thinking to remove it from the Node context of node-webkit, so JS libraries would run smoothly.\n. Please discuss here in future: https://github.com/rogerwang/node-webkit/issues/1588\n. ",
    "jhnlsn": "+1\n. ",
    "nickdima": "Is this still an issue?\nMy node app makes a lot of outbound requests via superagent with a high percentage of them timing out... Any ideas?\n. This seems to still be an issue or maybe a regression.\n. When can we get this in NPM? Thanks!\n. ",
    "timoxley": "oh shit. my bad\n. I did the PR via the github interface and the silly thing doesn't default to the branch you just forked from, instead tries to merge with master. Let's blame github.\n. Bump. I almost solely use superagent for cors requests and this keeps biting me.\n. Why not just shim instead of changing the code?\n. ugh, this breaks on node 0.8. Investigating.\n. @visionmedia help :(\n. ah, yeah, multipart is borked, even without my changes. I have a feeling, at least in theory, a more streams-oriented approach will actually help straighten the code out here, but you're likely to disagree with that haha\n. ",
    "cleercode": "node, same host\n. ",
    "mattaddy": "Woops. Meant for this to be an issue on the supertest library.\nSorry about that!\n. ",
    "ElHacker": "This feature would be really helpful\n. ",
    "nylen": "FYI, mikeal/request has digest support.\n. ",
    "LinusU": "Would be great to get this merged!\n. ",
    "jmarca": "should be, but I couldn't figure out the right incantation in a reasonable time --- I'm not sure where headers are stored at that point in the redirect cycle, and my hacking attempts didn't work.  \nI could be way off base, but I think the \njs\ndelete this.req;\nline in the Request.prototype.redirect function isn't quite right.  I think some things need to be copied over to a new request object after that one is deleted, because in the test I made I get a loop without ever establishing a proper session.\n. I pulled #76 and looked at it.  I tried simply copying all old headers, but that failed my test and the existing agency tests.  But if I deleted .host and .cookie from oldheaders, as so, then tests pass:\n``` js\n    var oldheaders = this.req._headers\n    delete oldheaders.host\n    delete oldheaders.cookie\n...\nthis.url = url;\nthis.set(oldheaders)\n\nthis._redirectList.push(url);\n```\nThis seems a bit too hacky for me to submit as a patch however.\n. I got it working with this super hacktastic kludge:\n``` javascript\nfunction make_piper(resp){\n    return function(r, fn){\n        r.pipe(resp)\n        r.on('end', function(a,b){\n            resp.end()\n            fn(a,b) // ?? cargo cult callback invocation\n        })\n       // do I need to listen to other events??\n    }\n}\n...\n// in handler:\nfunction(req,res,next){\n   res.setHeader(\"Content-Type\", \"application/json\");\n    var to = couch + '/my%2fcouchdb/_all_docs';\n    var query = req.query\n    if(query)\n        to += \"?\" + toQuery(query)\n    superagent.get(to)\n    .parse(make_piper(res))\n    .end()\n    return null\n}\n```\nIn other words, use .end() to trigger the GET request, but I've slotted in a piping parser.  I had to set the return header, as apparently the pipe won't copy the headers?\nI don't really know what I am doing with streams...this is very cargo-culty, but it works and perhaps is a start to a real solution\n. Hmm,  I'm still having this problem.  I will make a proper test case and link to it here.\n. Okay, I take that back.. I am not having this problem, at least not with a super short response.\ntest repository here:  https://github.com/jmarca/sa_pipe_test\nif you have couchdb running on a local host you can set a few env. vars to get the test to work properly.\nI will try again with my real data (much longer docs) and if there is a problem I'll report.\nThe key I was missing was I needed to set the response header prior to piping for some reason:\njavascript\nfunction pipetest(req,res,next){\n    // source is some known doc in couchdb, which will come back json\n    res.setHeader(\"Content-Type\", \"application/json\");\n    var from = cdb + '/mydocid';\n    var cdb_req = superagent.get(from)\n                  .accept('application/json')\n    cdb_req.pipe(res);\n    return null\n}\n(ah, and just realized I'm playing with iojs 1.0.1 on my laptop, so this is for that, not node.js)\n. this is cool, but buried!  Needs documentation, needs  tests\n. Perhaps my issue is related.\nI'm trying to stream an image into CouchDB.  It works fine with Request, but fails with superagent.\nI wrote a test and put it into node/pipe.js as follows:\n``\n  it('should act as a writable stream for images', function(done){\n    var req = request.post(base);\n    var stream = fs.createReadStream('test/node/fixtures/plot.png');\n      stream.on('data',(chunk)=>{\n          console.log(Received ${chunk.length} bytes of data.`);\n      })\n      req.type('png');\n      req.accept('png');\n      req.on('response', function(res){\n          console.log('got response');\n          done();\n    });\nstream.pipe(req);\n\n})\n```\nIt hangs after reading just two chunks.  Same behavior on my app (reads two chunks and hangs)\n```\njames@emma superagent[bug/stream_image]$ ./node_modules/.bin/mocha  test/node/pipe.js  --timeout 5000\nrequest pipe\n    1) should act as a writable stream\nReceived 65536 bytes of data.\nReceived 65536 bytes of data.\n    2) should act as a writable stream for images\n    3) should act as a readable stream\n```\nnode version 7.10.0\nattached is the plot file I'm using \n\n. my fork with the test case details: https://github.com/jmarca/superagent/tree/bug/stream_image\n. ",
    "seishun": "Same with Steam. Accessing a link such as http://steamcommunity.com/my/inventory/json/1/2 redirects to http://steamcommunity.com/id/your_id/inventory/json/1/2. However, the headers will be lost and it will fail if the inventory is private.\n. ",
    "blopker": "I'm running into this bug using SuperTest. I'm trying to test for a flash message on a login screen. \nManually setting the Cookie header seems to work though:\njavascript\ndescribe('Bad Login', function() {\n    var tommy = request.agent(app);\n    it('should redirect to login and show message.', function(done) {\n        tommy.post('/login')\n            .send({username:'tommy', password: 'not the right one'})\n            .expect(302)\n            .expect('Location', '/login')\n            .end(function(err, res) {\n                if (err) {throw err;}\n                tommy.get('/login')\n                    .set('Cookie', res.header['set-cookie'])\n                    .expect(/Invalid/)\n                    .end(function(err) {\n                        if (err) {throw err;}\n                        done();\n                    });\n            });\n    });\n});\nKinda hacky though, will this be fixed?\nThanks!\nEdit:\nSuperTest@0.7.1\nSuperAgent@0.15.1\n. ",
    "rhodri": "Still broken in SuperTest@0.13.0\n. ",
    "euforic": "All the APIs are under the Ti namespace. Im not a big fan of the structure either.\n. Titanium API needs to conform to standard.\n. There is no need to add titanium support to superagent. All you have to do is polyfill Xhr in your TI project. Especially since the Titanium Xhr lib only deviates a little.\nTi-xhrfix.js\n``` js\nvar Emitter = require('emitter');\n// Global Context\nvar globalCTX = Function('return this')();\n// Patch global scope\nglobalCTX.XMLHttpRequest = XMLHttpRequest;\n// sub for browser global location property.\nglobalCTX.location = {};\n// expose XMLHttpRequest\nmodule.exports = XMLHttpRequest;\n/*\n * XMLHttpRequest\n /\nfunction XMLHttpRequest() {\n  var self = this;\n  // titanium xhr client\n  this._proxy =  Ti.Network.createHTTPClient();\n  this.upload = {\n    onprogress: function(){}\n  }\n  this._proxy.onsendstream = function(e){\n    self.upload.onprogress({loaded:e.progress, total:1});\n  }\n}\nXMLHttpRequest.prototype.proto = Emitter.prototype;\nXMLHttpRequest.prototype.abort = function() {\n  this._proxy.abort();\n};\nXMLHttpRequest.prototype.open = function(method, url, async) {\n  this._proxy.open(method, url, async);\n};\nXMLHttpRequest.prototype.getResponseHeader = function(name) {\n  return this._proxy.getResponseHeader(name);\n};\nXMLHttpRequest.prototype.send = function(data) {\n  this._proxy.send(data);\n};\nXMLHttpRequest.prototype.setRequestHeader = function(key, val) {\n  this._proxy.setRequestHeader(key, val);\n};\nObject.defineProperties(XMLHttpRequest.prototype, {\n   'onreadystatechange' : {\n      set: function (val) {\n        return this._proxy.onreadystatechange = val\n      }\n    },\n    'readyState': {\n      get: function () {\n        return this._proxy.readyState;\n      }\n    },\n    'responseText': {\n      get: function () {\n        return this._proxy.responseText;\n      }\n    },\n    'responseXML': {\n      get: function () {\n        return this._proxy.responseXML;\n      }\n    },\n    'status': {\n      get: function () {\n        return this._proxy.status;\n      }\n    }\n});\nXMLHttpRequest.prototype.getAllResponseHeaders = function() {\n  return '';\n};\n```\nThen you can just wrap it all\nti-superagent.js\njs\nrequire('./TI-xhrfix');\nmodule.exports = require('superagent');\n. I wrote it over a year ago. Had it on github but i no longer use titanium so it got dropped on accident. It was MIT though so go nuts , :-) I have a better version with timeouts and multipart I just have to dig it up. I will put it back up on github when I find it.\n. ",
    "yields": "+1\n. +1\n. ping @gjohnson ;)\n. not sure this is something superagent should handle, in any case i patched superagent-retry to re-add headers so i think this should work ?\n. @gjohnson consider merging this one too :)\n. ah, damn i added extend because it's recursive :) so we might loose some data like ?baz[foo][bar]=baz\n. -1 from me too, since a lot of apis expect this behavior, and if someone doesn't want it you can always request.query(nodeQS.stringify(obj))...\n. hmm yeah, didn't really know this was supported haha, and there was no tests backing it up, so i broke it :P\nLGTM!\n. -1 unless there's .remove('User-Agent').\nwe can provide construct event, and then anyone wanting to add something would just use it.\n``` js\nvar superagent = require('superagent');\nsuperagent.on('construct', function(req){\n  req.set('User-Agent', 'whatever');\n});\n``\n. yeah, but that would still sendUser-Agentin the request text, unlessOutgoingMessageignoresnullor\"\"` ?\n. what happens when you\njs\nrequest(url)\n  .post('/invite')\n  .query({ mode: ... })\n  .field('..', '..');\n?\n. +1 @nrako \ni tried working with XDomainRequest too, thought it was what i was looking for, turns out it's dumb and incomplete like you said.\n. meh, req.res is fine too.\n. yeah, i think duo loads lib/client.js, so shouldn't matter which package manager we use here.\n. actually don't know if this would work, since browserify might expect require('emitter') to be require('component-emitter') etc.., so it might break on Duo.\n. this breaks compatibility with component/duo i think.\nIMHO bower should consider adding index.js to it's main list, like any other pkg manager.\n. Just realized you are adding superagent.js as bower's main.\ni think this should work without /index, since superagent.js is \"compiled\" already ?\n. ",
    "jxson": "I am using supertest/ superagent for a test suite of a hypermedia API I am building that uses application/json+hal and was having a few issues with the request.parse() method introduced in this pull request. I added a better check for json documents and some tests to make sure parsing happens as expected with media types that are json variants.\nIt would be really great to eventually get a nice API for adding media types and their parsers/ serializers, I dont mind contributing/ writing it should I open a feature request?\n. This is how I was using it:\n```\nrequest(server)\n.get(href)\n.parse(JSON.parse)\n.set('accept', 'application/json+hal')\n.expect(200)\n.end(function(err, res){\n  if (err) return done(err)\n// res.body and res.text is not set, the _parse method was not called\ndone()\n})\n```\nThe server responds with a json document with content-type: application/json+hal. Because of the way the check for a json document was happening in the response handler the sub type json+hal was not passing the check for text that should be buffered so the parse function was not getting called.\nExcept for the addition of the tests, the change I made is pretty minor: 12844a2b6cbc3a874250e3221fae87bc21edaac9\n. @ericmedem your right, I can back out your changes and send a pull request to make sure the default json parser gets used on json variants.\n. Good job man! I hope this makes it in, its been pretty useful for working with content-types that are related to json like hal and collection+json\n. @gjohnson that's kinda like saying rss is just xml ;) While true, the difference between the two is very important to consuming clients.\nThe +json media types are a superset of json with specific and semantic differences that are important to the consuming clients which care about the added features. If the client doesn't care about the superset then it should just treat the resource as application/json.\nIdeally when a developer is knowingly consuming a vendor specific or custom media type they should provide a parser to superagent. Sometimes you don't know ahead of making the request or you just don't care about the superset so providing a valid fallback to application/json when a custom parser isn't provided is a good thing to do.\nLike @nathanhoel mentioned, supporting the fallback means only supporting the +json suffix so there isn't that much complexity as a result. Take a look at the diff, it's mostly tests.\nFor background on REST and Hypermedia:\n- Fielding's Thesis, Chapter 5\n- Building Hypermedia APIs with HTML5 and Node\n- Haters gonna HATEOAS\n- Designing Hypermedia APIs\nVendor APIs which care about guiding their consumers will often extend an existing media type like aplication/json to say \"the resources are based on JSON but have some extra vendor specific semantics added which you should care about\". When creating APIs as well as consuming them this becomes important. A few well known companies that provide custom media types as part of thier APIs include:\n- Amazon: http://docs.aws.amazon.com/appstream/latest/developerguide/rest-api.html#rest-api-hal\n- Github: http://developer.github.com/v3/media/\nHere are some specs for the more common +json types\n- application/hal+json - http://tools.ietf.org/html/draft-kelly-json-hal-06\n- application/vnd.collection+json - http://amundsen.com/media-types/collection/\nI kinda nerded out on this stuff not that long ago so sorry for the length. If you want to learn more about Hypermedia and why the media types are important I highly recommend the hypermedia mailing list.\n. ",
    "ericedem": "Thats exactly what I had in mind for a long term solution. It would be great to be able to add custom media types. This actually isn't hard to do right now if you just manipulate the parse / serialize objects in the superagent module. Of course you need to have access to the module, so if it is imported through supertest you are out of luck. I actually logged an issue for this problem in supertest.\nFor this pull request however, I simply wanted a stone knife way of overriding _parse and _serialize so that I could proceed with writing unit tests, as I am also using a cusom 'application/json' format.\nI feel that the changes in this pull request are orthogonal to specifying media type. Are you saying that when you specify a parser with this API, it is defaulting to something else instead of the parser you specified? Can you be more specific about what is going wrong? Code snippets would help.\n. Ok \"Close & Comment\" didn't do what I thought it would do :-).\n. Alright I see what you are saying. The way I have been using this is to not specify a content type, so it will always default to text. Though, it sounds like you really don't need the stuff I added, you just need superagent to recognize that your content type is actually json, so that it will use the default JSON parser.\nI actually am using my own custom parser that has extended json to understand some more complicated MongoDB primitives. In express, I can override the parser used for 'application/json'.\nIt might be good if this library eventually had support for reaching into the express / connect server instance you give it and extracting the parser from there, that is probably a pipe dream though :-).\n. Sounds good, it'll be easier for TJ to validate the pull requests without too many things lumped together :-D\n. I'm not sure what you mean by async in this case. The request.parse(callback) method I implemented follows the chaining paradigm that is currently in place. I didn't provide a mime argument for the request-level method because whatever parser you specify would just override the any mime default parser for that request.\nLet me know what I can do to get this pull request by you. I'm currently relying on this parsing behavior for my unit tests so I'd like to make it into official build. The main reason I did the request level first is because setting a module level parser won't work unless it is also exposed through supertest.\nI can implement superagent.parse(mime,callback) if we can agree on the expected behavior, and can expose it through supertest.\n. Alright I've shifted the pull request. Now all I add is the parsing handler that accepts parsers with this signature https://github.com/visionmedia/superagent/blob/master/lib/node/parsers/json.js\nI have removed the serialize handler. \nI have added a test case for parse.\nI want to add support for superagent.parse(mime,callback), but I think that is better as a supplementary task after this one.\n. Completed all the requested formatting changes. Test cases pass.\n. Yikes how embarrassing... :-(\n. ",
    "matthewmueller": "ooo.. looks like superagent.js / superagent.min.js wasn't updated with the latest release, was that intentional?\n. Can you try the latest push? The img tag causes a GET request that doesn't seem preventable. I'm using another technique to resolve the URL. \n. Yah that makes sense. Cool, I didn't know about the error event. And yah, the http error events would be a really nice  feature, something like: request.on('401', fn) or even request.on('unauthorized', fn).\nI'll close this for now, emitting error is my primary use case. Thanks!\n. +1 for @visionmedia's original API. Not a huge fan of .thunkify(), you can just do:\njs\nvar thunkify = require('node-thunkify');\nrequest.get = thunkify(request.get);\nyield request.get('http://google.com')\nIf you need it on the shorthand.\n. oh really? Okay that's fine. It's pretty nice when you just want to forward the entire request to another endpoint and have that endpoint do all the status code checking and whatnot. But its fairly trivial to write it out anyway. Closing for now\n. Ohhh nice. didn't notice this PR, this would have fixed the problem. I had to remove the charset because superagent didn't pick up on it and serialize the object, resulting in [Object object] being passed in the body.\nThere was probably a reason @alexmingoia added the charset to modella/ajax, but I'm not sure what it was.\n. I think we should add the _dereq_ stuff that socket.io does:\nhttps://github.com/Automattic/socket.io-client/blob/master/socket.io.js#L11-L14\n. just that you can consume again it via browserify or duo without breakage. not a huge deal either way.\n. +1 to remove arity altogether, it breaks most function wrappers.\n. <3\n. oops, using an old version, my bad.\n. lgtm!\n. +1 to this change as well. \nI thought post was hookable via .parse(fn). I guess pre could be hooked in via .use(fn), maybe. Maybe I'm misunderstanding what you mean though.\n. Alrighty, this should be ready for review. I'll open a PR updating the docs as well.\n. I think that makes sense if people will find this as a useful compromise for promises. I don't really know, because I'm not going to be using it that way. catch is not useful in the co generator environment though, so that's why I didn't include it.\n. Yep, for additional context, the most recent PR aims to resolve #230. That was the only intent of the PR. It was not to add promise support.\nPersonally, if what you suggested works properly, all existing tests pass and you include a small catch implementation, I think that would be better that what was implemented in 1.3.\nAlso, if I'm not mistaken, your solution would require everyone to be running node 0.12 or io, right?\n. Yep, so it would require Node 0.12 or a polyfill. And the polyfill would need to be present on the browser implementation as well (for IE).\nI tend to agree with @defunctzombie on this that it's a marginal API improvement for a non-trivial increase in file size (17.952 kB minified). Though I do agree and sympathize that the .then() implementation here may confuse folks coming from the promise world, so I'd be open to revisiting it with the constraints described above.\n. > Where do you take that 17KB from? I think superagent bundling promises would be a mistake, and a serious downside.\nHere: https://github.com/jakearchibald/es6-promise/blob/master/dist/es6-promise.min.js\n\nI'm assuming that nobody would be interested in using the .then() method without using promises in their code.\n\nThis is an example of where a .then() implementation is extremely useful: https://github.com/visionmedia/superagent/pull/709. Also resolves the discussion here: #230\n. > co is an interesting example, but not a good example of a case where promises are not available\nYep, the point isn't about compatibility though, it's about file size. We wouldn't be having this discussion if either, Promises were implemented everywhere or we can implement an extremely light-weight version of promises that weighs in at like 1-3Kb minified. The PR implemented added 4kb unminified and since a lot of it is repeated, I suspect gzipped with the rest of the file, it basically goes away.\n. Okay, so if I'm understanding what you're saying correctly, you're suggesting something along the lines of... \njs\nif ('undefined' != typeof Promise) {\n  Request.prototype.then = function(resolve, reject) {\n    var self = this;\n    return new Promise(function(resolve, reject){\n      self.end(function(err, res){\n        if (err) reject(err); else resolve(res);\n      });\n    })\n    .then(resolve, reject);\n  };\n}\nIf that's the case, then I don't really care much either way since it doesn't add much bulk and yield will work in environments that promises work. Not sure how @defunctzombie feels about that, but I'd welcome your PR.\n. I actually grabbed this piece from socket.io-client:\nhttps://github.com/LearnBoost/socket.io-client/blob/master/lib/socket.js#L385\nBut yah, that makes sense, something like:a.protocol !== window.location.protocol\n. Ah yah, I was surprised to see superagent was pretty much two separate libraries.\n. Also, this causes the tests to run \"slightly\" slower (or maybe just because I'm on slow internet). I saw an abort command somewhere in the code, but I'm not sure if that would be useful here.\n. ahh shit, yah.. gotta love minute CORS details\n. ",
    "blakeembrey": "@visionmedia Could you rebuild the superagent(.min).js files for this repo?\nI gave the superagent.js file in your fork a quick test (having trouble in the browser with the one here, query strings keep serializing like \"test=true\" -> \"1=t&2=e&3=s\"...). \nThe img.src checking mechanism is faulty. It will causes requests to URLs that should fail in the browser (E.g. http://google.com) and superagent returns no data. Looks like it starts directly on Line: 298 where you have img.src = url;. Is there any reason you can't just use a link to get the hostname and check if it's cross domain?\n. About to give it a go. However, couldn't you just use something like this?\n``` javascript\nfunction isCrossDomain (url) {\n  var link = function (href) {\n    var a = window.document.createElement('a');\n    a.href = href;\n    return a;\n  };\nurl = link(url);\nvar host     = url.hostname,\n      port     = url.port,\n      protocol = url.protocol,\n      location = window.location;\nreturn !(host == location.hostname || host == null || host == '') || port != location.port || protocol !== location.protocol;\n}\n```\nProbably rearrange the check so if the host == null || host == '' it avoids the next checks, and that should work on IE.\n. @visionmedia I will have to look into the component then. However, it looks like it would have an issue with the IE issue described in this PR. Should you check against something like?\nreturn !((url.hostname == location.hostname && url.port == location.port && url.protocol == location.protocol) || url.hostname == null || url.hostname == '')\nAlso, should you var location = window.location?\n. I double checked it, and it does appear IE7 is returning relative URLs. Just made a PR against component/url to patch this.\n. I noticed I was crashing the process at the same spot when I ask for gzipped pages via the Accept-Encoding: gzip header.\n. Here is how I can replicate the bug:\n```\nvar request = require('superagent');\nrequest('GET', 'http://a248.e.akamai.net/assets.github.com/assets/github-6f9ac9220676fa355e8b13e0403cf7972fdabbfb.js')\n  .set({\n    'Accept-Encoding': 'gzip'\n  })\n  .end(function (res) {\n    console.log(res);\n  });\n```\nThat snippet is just using the JS file from github. I can also replicate the bug on other CDNs.\n. Okay, can't replicate it with that url anymore. But this causes an error (for me at least):\n``` javascript\nvar request = require('superagent');\nrequest\n  .get('http://othstatic.propertycdn.com/clean/js/load.v5.6.4.js')\n  .set('Accept-Encoding', 'gzip')\n  .end(function (res) {\n    console.log(res.header['content-encoding'], !!res.text);\n  });\n```\n```\ngzip false\n/Users/blakeembrey/Dropbox/Projects/requestmaker/node_modules/superagent/lib/node/utils.js:111\n    var str = decoder.write(buf);\n                      ^\nTypeError: Cannot call method 'write' of undefined\n    at Unzip.exports.unzip._on (/Users/blakeembrey/Dropbox/Projects/requestmaker/node_modules/superagent/lib/node/utils.js:111:23)\n    at Unzip.EventEmitter.emit (events.js:93:17)\n    at Zlib.callback (zlib.js:405:12)\n```\nFor some reason I am not even getting any response text?\n. ",
    "coen-hyde": "yes please\n. ",
    "dokipen": "It's because you do the equivalent of this:\n```\n\nqs.stringify(qs.parse('a=1&a=2'))\n'a[]=1&a[]=2'\n```\n\nin node/index.js#request()::\nurl = parse(url, true)\nin node/index.js#query()::\nvar query = qs.stringify(obj)  // which is url.query\n. It would be nice if the URL wasn't parsed and put back together. I can imagine situations where you need to send something that isn't quite right.\n. Thanks! Can we get a release with this fix in it?\n. ",
    "vkadam": "I see there is no discussion on this issue over a year, is there any substitute.\n. ",
    "dougwilson": "Yea, the forced use of qs is pretty crappy :( here is my work-around for now:\njs\nreq = request.get('/')\nreq.request().path += '?opt=a&opt=b'\n. The server is likely closing the connection; if you are using node.js on the server-side, it will close the connection after 2 minutes of inactivity, even if no response had been sent yet. I don't believe superagent has any timeouts.\n. I think you may be able to do res.socket.setTimeout(0) in your route to remove the timeout, but don't quote me on that one :) You'll also want to close the connection after you respond or restore the timeout to the socket when you're done (because a socket and handle multiple requests/responses with keep-alive):\njavascript\nreq.socket.setTimeout(0); // req.socket === res.socket, by the way :)\n// Setting your outgoing connection header to close is recorded by node.js\n// core and the socket is closed after the request is sent.\nres.setHeader('connection', 'close');\n. @binarykitchen can you update this issue with your most recent findings?\n. @sogaani is actively working to get Express.js working with HTTP/2. Of course, Express tests itself with supertest (which uses superagent) and thus why getting superagent working with HTTP/2 is important to us in order to actually get HTTP/2 test suite.\nAnd yes, we've been slowing grinding through Node.js bugs as we uncover them, as Express.js exercises a lot of the HTTP server implementation.. I don't know why superagent's express dependneyes needs to be your fork @sogaani . Can you ellaborate on why that is necessary?\nIf express needs to have HTTP/2 support in order to hand HTTP/2 support in superagent and Express needs superagent to have HTTP/2 support in order to land the support, I think we're in a catch 22 situation here.\n. ",
    "u9520107": "@dougwilson \nThat only works in node I believe. In browser, I tried to assign to the url directly, but that url is still parsed by qs.\nUpdate: nvm.. setting the url does work... I just forgot to update the component.\nFYI, in browsers: \nreq = request.get('/')\nreq.url += 'extra querystring...';\n. @defunctzombie So if I use jspm as client-side package manager, I have no other choice than to fork the project and add those properties in my fork?\n. @defunctzombie Ok, thx. I suspect that jspm should support the \"browser\" property. Might be a bug that it's not currently working. I'll go probe around jspm's issues.\n. ",
    "ikokostya": "Maybe add some option for disabling recursive serialization like jQuery.ajaxSettings.traditional = true?\n. See https://github.com/visionmedia/superagent/issues/345\n. Before commit https://github.com/visionmedia/superagent/commit/629bf9b10d26e2e6b44aea11b197ef8fea99a9c5 any string passed in Request#query just appends to querystring without encoding.\n. Ping! This also fixes encoding arrays.\n. I think this test should be removed to favor component/querystring tests.\n. ",
    "cithukyaw": "I'm encountering the same problem. Is there any fix for this since 2012 when the issue was started?\n. I found that Unirest works perfectly for this purpose:\n```\nvar unirest = require(\"unirest\");\nunirest.get('/')\n.query({a: 1})\n.query({a: 2})\n.query({a: 3})\n.end(function(res) {\n    console.log(res.body);\n});\n```\n. ",
    "englercj": "It is also pretty strange that the browser version works differently than the node version currently:\nnode:\njs\nqs.stringify({ a: ['b', 'c', 'd'] }, { indices: false })\n// => 'a=b&a=c&a=d'\nbrowser:\njs\nserialize({ a: ['b', 'c', 'd'] });\n// => 'a=b%2Cc%2Cd' which decodes as 'a=b,c,d'\nI would expect them to work/act the same way. Can you not use qs with browserify in the browser version?\n. I am seeing this issue on 1.2.0 I think it is due to error handling again in the response parsing:\nhttps://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L955\nIt calls the callback and processing continues, which means that later an end listener is registered and that calls the callback again.\n. I also don't think this is true for the browser version, which seems to operate differently. I find I have to actually call query instead of send for the browser version.\n. I too encountered this issue recently, I have to branch for gets and do the exact same code block but replacing \"send\" with \"query\". Was there ever any movement on this?\nI use both the node and the browser versions of this library.\n. @blented No, the logic to do what I mentioned is in my application code. I didn't change this lib.\n. https://github.com/visionmedia/superagent/issues/464#issuecomment-111522076\nI am experiencing the same issue. If there is a parse error, then you see the double callback error. I think it is due to error handling again in the response parsing:\nhttps://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L955\nIt calls the callback and processing continues, which means that later an end listener is registered and that calls the callback again.\n. ",
    "cheryly279": "I see the commit above states that \"Strings passed to request.query() will be used in the final querystring\nunaltered,\" but is there a way to pass an option like we would in jQuery with {traditional : true}? So for instance we could pass something like:\nrequest.query({a : [1,2]}, {traditional : true})\nresult in a url like ...?a=1&a=2...\n. ",
    "dead-horse": "Oh. The render module forgot to add content-type. Thx\n. ",
    "enoyhs": "Would love to add test, but can you help me out on how to test secure cookies? I'm not sure if it is good to add some third party website as target of test...\n. ",
    "esundahl": "Ahh NPM wasn't updating. Fixes quite a few issues I was having now that its updated. Thanks\n. ",
    "zedd45": "I see I have confused my SuperAgent and Express syntax with agent1, but I would still love to know if there is a way to achieve this?\n. no problem.  how about this: \n```\nvar token = null, \n    agent1 = superagent.agent(), \n    agent2 = superagent.agent(), \nloginUser = function(agent) {\n  return function(done) {\n\n    var onResponse = function(err, res) {\n      res.should.have.status(200);\n      return done();\n    };\n\n    // obviously wrong (Express JS) syntax; how do I get at the response in SuperAgent / Test?\n    agent1.get(\"http://localhost:3000/\", function(req, res) {\n      return token = req.session._csrf;\n    });\n\n    agent2.post(\"http://localhost:3000/login\").send({\n      // other login creds here\n      _csrf: token\n    }).end(onResponse);\n};\n\n};\n```\n. yeah, I realize I borked the syntax (confused it with Express).  So there is no method that exposes req.session?\n. makes perfect sense.  I'll see what other tools I can utilize to write this test.  Thanks for your time.\n. closing\n. I realize, in retrospect, it's much easier simply to disable CSRF middleware in the test environment.  \njavascript\napp.configure 'development', 'staging', 'production', ->\n    app.use express.csrf()\nThen I use @NODE_ENV=test like in Express JS's Makefile\nfigured this might help someone else down the line\n. ",
    "chuyeow": "The docs are confusing but the Node and browser versions of SuperAgent are different. To actually get the timeout, you'll need to either use a 2-arity callback or add an error callback, like so:\nrequest.get(url).timeout(100).end(function(err, res) {\n  // err.timeout will be available here if the request times out\n});\nor\n```\nrequest.get(url).timeout(100).end(function(res) {\n}).on('error', function(err) {\n  // err.timeout will be available here if the request times out\n});\n```\n. ",
    "jvanalst": "Thanks. I'll play with field the next time I'm in that project. Is there a better source for documentation then the README.MD or should I be writing a patch to improve it?\n. ",
    "jaketrent": "Request.field() only accepts string values.  What's the recommended method for including json in a multipart request and Request.attach() for images?\n. ",
    "jchan172": "I combined .field and .attach in my test in order to test sending json with an image. Here's an example:\nvar should = require('should'),\n    supertest = require('supertest');\nvar request = supertest('localhost:3000');\ndescribe('upload', function() {\n    it('a file', function(done) {\n       api.post('/your/endpoint')\n           .field('extra_info', '{\"in\":\"case you want to send json along with your file\"}')\n           .attach('image', 'path/to/file.jpg')\n           .end(function(err, res) {\n               res.should.have.status(200) // 'success' status\n               done()\n           });\n    });\n});\nTake a look at http://stackoverflow.com/questions/10120866/how-to-unit-test-with-a-file-upload-in-mocha\n. ",
    "skskumbharkar": "I want to access 'extra_info' data (based on above example) in my expressJS app.\nHow to access it?\nBecause I am not getting any 'extra_info' field in 'req.body'.\n. ",
    "jonathanong": "well i personally only either request json or html, so i'm not sure how handle lists. right now i'm just doing:\nRequest.prototype.accept = function(type) {\n  this.set('Accept', request.types[type] || type)\n  return this\n}\n. would you accept a PR for an accept with a single type? ie no lists \n. totally forgot about the node API\n. @sebs bower now uses bower.json instead of component.json, so you can't assume anything with a component.json is consumable by bower.\n. oh woops. sorry :)\n. can we get this in? are there any blockers?\n. i don't know, man. a part of me doesn't want to touch node superagent because i know it's half broken. lol\n. what node superagent needs is a streams2 rewrite. you can use http-duplex-client as a basis, but i think i'm just going to use request for nontrivial stuff\n. he's an anarchist\n. don't know of any events other than what node typically uses\n. you should add the same API to the node version.\nalso, it should be 0.16.0 since you're adding a new feature\n. @gjohnson he should squash anyways when he's done :P\n. @nickl- you don't necessarily need to squash the entire thing, but you should squash until its appropriate. ex, you should squash/remove the first commit. if you change history.md again, you should squash all changes to it into a single commit. for the most part, the commits are fine right now.\nhere's the entire node folder: https://github.com/visionmedia/superagent/tree/master/lib/node\n. you should just merge this PR to the other one. no need to have two\n. O crap\n. this is weird. i'm using superagent and all my requests work fine. i don't even think you're allowed to set the content length via xhr. i think something else is going on.\n. naw, i use koa, but koa uses type-is as well\n. oh my god i hope not. you aren't using yahoo shit, are you? i think one of their libraries intercepts req.on('data') events, does stuff to it, removes the content-length header, and reemits the events. \n. best thing to do right now is create a really small repo that demonstrates this bug.\n. ",
    "maxbeatty": ":+1: better late than never?\nCame across an issue today using step where its callback to continue didn't report arity correctly to get both arguments. Async has the same issue which causes the code to go from:\ncoffee\nStep(\n  -> request.get('/path').end @\n  (err, res) -> # err is res :(\n)\nTo:\ncoffee\nStep(\n  -> request.get('/path').end (err, res) -> @ err, res\n  (err, res) -> # err and res are as expected\n)\nIt's not the end of the world, but all future contributors are probably going to do a double take and ask, \"why not just pass this like normal?\"\n. ",
    "clocklear": "+1 to this.  Just had this bite me in the ass using async.waterfall().\n. ",
    "TedTrela": "Any detail on this issue?  I'm seeing some peculiar behavior where a node app is handling a lot of requests in a short time and while processing those requests makes an http request via superagent with a .timeout() set.  The requests get queued up in node's agent due to the agent.maxsockets setting (default 5) and the timeout is triggered for some.   The superagent .end() callback receives the proper timeout err.  However - the request still gets sent even after the the timeout is raised.  Looking into the superagent code - req.abort() is called - but doesn't seem to have any effect, or at least not any that I know to look for.    Is what I'm seeing related to this labeled 'Node' issue, or is there something I'm not understanding?\n. ",
    "livedata": "well, any (for example) curl or web browser implementation of 'follow location' passes these informations... to which 'http agent' are You refering to? \n. Okey, more investigation, and problem wasn't related with headers that were set at the beginning but with headers that curl/web browsers have set by default, such as 'user-agent'. Some websites are trying to find out which user agent is connecting to them, and when 'ua' header is missing website drops connection with (ie.) 403 code...\n. ",
    "jescalan": "It looks like this has been known since #90 and fixed in https://github.com/visionmedia/superagent/pull/151 - is there any chance we could get this merged in? Although shitty browsers are not fun to develop for, having code break in IE8 really can't happen - it's still very heavily used.\n. ",
    "conradz": "Actually res.text is supposed to be undefined, but it appears that in Firefox res.text is a string containing the source of test.request.js. In the built-in Firefox JS debugger it shows [longString undefined] as the value of res.text, but printing to the console and also Firebug shows that typeof res.text === \"string\" and it is a string containing the source code.\n. So it appears that the server is sending back the file contents that the test is requesting, even when using the HEAD request. Most browsers will discard the body when using HEAD, but Firefox 18 beta is not. It is preserving the response body even for HEAD requests. The tests appear to be expecting the browser to discard the body of a HEAD request.\nShould superagent force the response text to be empty on HEAD requests, or should the tests be changed to allow response text? The only way to make it be the same cross-browser seems to be to clear the response text, since other browsers won't give the response text.\n. ",
    "Mouvedia": "What happened to this? It's not in the component.json.\n. ",
    "bsenyk": "A great use case for this in-browser would be global handling of 401 errors to force the user to sign in again.\n. ",
    "Arsenalist": "This really needs to be part of the library.  It satisfies too many use cases not to.\n. ",
    "wokejacqueline": "Agreed.\n. ",
    "liubko": "Could someone share a workaround?\n. ",
    "xpepermint": "Status?\n. ",
    "syropian": "Anyone have a solution for this?\n. ",
    "mikestopcontinues": "Important.\n. ",
    "apsavin": "An example of quick and dirty workaround:\njs\nconst end = superagent.Request.prototype.end;\nsuperagent.Request.prototype.end = function (callback) {\n  return end.call(this, (error, response) => {\n    if (response.unauthorized) {\n      // handle the error here, for example:\n      // window.location = '/login'\n    } else {\n      callback(error, response);\n    }\n  });\n};\n. ",
    "boucher": "I believe .end is not supported by superagent-defaults.\n. ",
    "buschtoens": "Great! Thank you. :)\n. Fixes #178.\n. ",
    "lbdremy": "Hello @visionmedia,\nI added the test. Let me know what you think about it.\nThanks\n. how did you fix it?\n. Actually it looks like this issue is still relevant, no try/catch around the serialize method here https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L699\n. For example if you pass in an object that is going to be in your body as JSON, when JSON.stringify is called with this object as argument if the object contains circular reference JSON.stringify will throw an error. You can pull in  the changes locally if you like and run the test that I have added for this case and see by yourself.\n. Exactly\n. Ok like you want guys, it just makes superagent more robust. Also now I will probably do that\njs\nnextTick(function(){ self.callback(err) }); // like that the error is emitted async like network, server errors\ninstead of\njs\nself.callback(err);\n. ok @visionmedia , I just pushed a commit with that in the same branch here https://github.com/lbdremy/superagent/commit/38ba912aaf002ef3cc3e9e1271135f661fa7c538 but it does not seem to find its way here, maybe because the pull request is closed?\nAlso there is still this strange error in the second test for the pipe method, where it seems I cannot attached an event handler on('error', fn). https://github.com/lbdremy/superagent/commit/c36e1f746a9c126c55ff514567e8a748e4dde2b5\n. thanks @gjohnson \n. Great thanks @visionmedia that was fast! Yeah for the cleanup on error event no one really know you think? At least we can consider that when one error event emitted the stream won't be readable anymore right?\n. ",
    "btknorr": "This just stumped me as well...I had to dig through the superagent code to figure it out.  Please fix...thanks!\n. ",
    "pgn-vole": "Is there any updates on this issue ?\n. Is this going to be merged at some point ?\nCurrently responses with hal+json as media type are broken when requested with superagent.\n. +1\n. I made a PR that fixes this issue. I would appreciate a maintainer can have a look.\n. @gjohnson  Regarind the node client issue - the parsing is asynchronous so I would suggest to not try it and just rely in the callback error value. A function should not be able to delivers error in both way (asynchronous and synchronous).\n. ",
    "shiwano": "@whyyk7\nIt might be good using request.parse method.\nExample:\n``` javascript\nvar encoding = require('encoding'),\n    request = require('superagent');\nvar parser = function(res, done) {\n  res.text = '';\n  res.setEncoding('binary');\n  res.on('data', function(chunk) { res.text += chunk });\n  res.on('end', function() {\n    res.text = encoding.convert(res.text, 'UTF8', 'GBK').toString();\n    done();\n  };)\n};\nrequest.get('http://example.com/').parse(parser).end(function(error, res) {\n  // do something.\n});\n```\n. ",
    "whyyk7": "I trid yours but can't be ok.\nI wrote it to make it ok.\nrequest.parse.text = function(res, done) {\n  res.text = '';\n  res.setEncoding('binary');\n  res.on('data', function(chunk){ res.text += chunk; });\n  res.on('end', function() {\n    var str = iconv.decode(new Buffer(res.text,'binary'), 'gbk');\n    done();\n  })\n};\n. ",
    "missinglink": "Hey @defunctzombie, this should be resolved by: https://github.com/visionmedia/superagent/pull/369\nYou can probably close this issue now\n. It appears that the url I am hitting returns a 307 redirect which does not contain the expected location header, that's what's triggering the error for me. This is obviously broken HTTP.\nref: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L585\n``` bash\npeter@manta:~$ curl -v http://london.spareroom.co.uk/flatshare/london/leytonstone/964123\n Hostname was NOT found in DNS cache\n   Trying 62.128.194.100...\n* Connected to london.spareroom.co.uk (62.128.194.100) port 80 (#0)\n\nGET /flatshare/london/leytonstone/964123 HTTP/1.1\nUser-Agent: curl/7.35.0\nHost: london.spareroom.co.uk\nAccept: /\n< HTTP/1.1 307 Temporary Redirect\n* Server Apache is not blacklisted\n< Server: Apache\n< Set-Cookie: moreinfocount=1; domain=.spareroom.co.uk; path=/;\n< Vary: Accept-Encoding\n< P3P: CP=\"CAO DSP COR ADM DEV TAI PSA PSD IVD CON HIS OUR BUS LOC\"\n< Content-Type: text/html; charset=UTF-8\n< Transfer-Encoding: chunked\n< Date: Tue, 03 Jun 2014 10:24:49 GMT\n< X-Varnish: 581722849\n< Age: 0\n< Connection: keep-alive\n< Via: web5\n< \netc...\n``\n. yep, there are 4 issues:\n- type checking variables that are out of our control before calling methods on them\n- dealing with websites that speak invalidHTTP` in an elegant way\n- not crashing when something bad happens\n- returning an error back up to the caller\n. \n",
    "camshaft": "If #176 get's pulled it would be really easy to do that\n. @visionmedia hey have you had a chance to take a look?\n. ",
    "whitlockjc": "Anyone got an example of this?  It seems in the browser, the OPTIONS prior to the AJAX calls do not include authorization stuff setup.\n. Disregard.  I was running into an improperly implemented REST API with CORS.  What was going on is the initial OPTIONS request in the browser didn't have authorization information in it and the server required auth so I was getting a 401.  Fixing the server's CORS implementation fixed the issue for me personally.\n. I've got the same problem, using ~0.18.0.  If I find something important, I'll let you know.\n. Mine would only happen when running Karma tests and it seems to have remedied itself.  I think I had some weird Karma issue.\n. ",
    "little-big-h": "while this is a horrible bug report, I have the same problem: redirects aren't followed when using the pipe function\n. ",
    "bernardeli": "Seems to be a problem for me as well. I can't find pipe redirections.\nWould love to see some traction on this at some point. :) \n. ",
    "thanpolas": "Stumbled on this too, using pipe() redirects will not be followed\n. mmm indeed, this looks promising\n. 400 is an expected response, new behavior returning an error broke tests, downgraded to 0.21.0\nOn top of that, the res object was attached on the error object vs as the second argument.\n. Would you entertain a rejectStatus()?\nOnce a server returns a response, that's a response, I need to handle it.\nAn error would be anything happening in between me sending a request and up until I receive a response.\n. @kmalakoff :+1: \n. ",
    "andrewrk": "Related to this maybe? https://bugzilla.mozilla.org/show_bug.cgi?id=608735\n. xhr.getAllResponseHeaders() is returning \"\" but xhr.getResponseHeader(\"Content-Type\") returns application/json.\n. Thanks, really appreciate the turnaround time.\n. I think both options should be exposed..\n. @dpolivy as a workaround, you can do this:\njs\nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = \"0\";\n. ",
    "alinz": "OK, it seems this bug returns when I use it with react-native 0.6 and above. What I found that xhr.getResponseHeader('content-type') starts to return null which isn't right. \nCalling to this.xhr.getAllResponseHeaders() returns the correct sets of headers which also includes content-type. \nSo here's my humble solution:\njs\nvar tryAnotherContentType = this.xhr.getResponseHeader('content-type');\nif (tryAnotherContentType && tryAnotherContentType.length > 0) {\n    this.header['content-type'] = tryAnotherContentType;\n}\n. @nilgradisnik I'm having a same problem with my PR! All the tests pass but Travis fails.\n. @defunctzombie I was the early adaptor of superagent. However, I still believe that overriding the header blindly is not a good idea. What I have done with this PR is checking the header value and if there is something, then override it. It might applicable to other venders as well. \nI'm not pushing this but I would like you to think about it one more times and give me a good reason why it is ok to override the header in your own way?\nthanks\n. @defunctzombie thank you for clarify it. I will try to find a use case for it. \n. hmm, what I found was, parseHeader parses the header correctly which contains application/json for content-type in my use case and we are blindly trusted this.xhr.getResponseHeader('content-type'); and overriding the content-type. So in my PR, I check the return value of this.xhr.getResponseHeader('content-type') first, before overriding the content-type.\n. Agreed, however, do you think it's a good idea to overriding header's content-type without checking the xhr.getResponseHeader's value?\n. ",
    "carlituxman": "I do script src build.js\nand then use\nrequire('superagent')\nthen the browser log:\nUncaught Error: failed to require \"superagent\" from \"root\" build.js:17\n. is here\nhttps://gist.github.com/carlituxman/4997328\n. at my js used in browser I do it:\n(jade) script(type='text/javascript', src='/javascripts/build/build.js')\nand then\n var request = superagent;\n        request\n            .get(....\nIt works\n. ",
    "vendethiel": "\nfrom \"root\"\n\nYou're not supposed to require it from root, but from your own index.js.\n. > You're not supposed to require it from root, but from your own index.js.\n. ",
    "redbugz": "We are hitting an API with superagent that makes heavy use of caching headers and ETags. If we were to implement something like https://github.com/kevinswiber/request-caching in concert with superagent, would that seem like a good solution? Is there method of integration the best, or would you recommend some other way to integrate with superagent?\n. ",
    "jpodwys": "I know this is old, but I recently published a superagent extension that adds transparent caching. You can see it here: https://github.com/jpodwys/superagent-cache.\n. Were these tests already failing? All I changed was the readme file.\n. @defunctzombie Thanks!\n. A couple of thoughts:\n1- I agree with both staying with ES5 for now and with keeping .then() in place. I don't want the extra trouble of dealing with preprocessors and removing .then() just seems unnecessary at this point.\n2- I know this issue mainly focuses on breaking API changes for end users and it seems there's a consensus among the few commenters here that breaking changes and therefore major releases should not be avoided. In the interest of progress, I agree. However, I would just like to say that, as the author of superagent-cache, I have greatly appreciated the complete lack of internally breaking code changes in the year since my initial release. I know that a breaking change for an end user does not necessarily mean a breaking change for a superagent extension, but it would be nice if internal consistency was on people's minds when making any changes.\nPerhaps release candidates for breaking changes, even just internal ones, could help extension maintainers keep up. I would just hate superagent-cache's potential incompatibility with the latest major superagent release to force coders to choose between the latest superagent release and superagent-cache or any other extension that wants to keep up.\nThanks for your time and hard work!\n. Thanks for the heads up! I'll try it out today. My test suite is not yet comprehensive, but I'll pin to your release and run my tests and let you know what happens.\nIf we discover that there is a set of common internals all extensions rely on, perhaps we can indicate that changes to those portions should be taken more seriously somehow. \n. It seems I spoke too soon--since 1.7.0, my tests no longer pass. Since my library depends heavily on the inner workings of precisely how query params, headers, and other such data is stored, it can be a brittle relationship. Honestly, I'm surprised it didn't break sooner!\nIt appears that the changes made to how headers are stored and read in 1.7.0 are breaking superagent-cache. Below is the code I'm currently using to retrieve headers:\njavascript\ngetHeaderOptions: function(req){\n  if(req && req.req && req.req._headers){\n    return req.req._headers;\n  }\n  else if(req && req._header){\n    return req._header;\n  }\n  return null;\n},\nBefore 1.7.0, this function returned the headers, but since 1.7.0, it does not. I cannot comment on the 1.8.0 beta until I resolve the incompatibilities in earlier versions. If anyone knows, please inform me what changes. If not, I can look into the code myself.\n. OK, it appears that a change with redirects in a post-1.7.0 release is also incompatible.\n. I respect the fact that superagent may need to make a number of internally breaking changes in the near future. If the superagent team is able to come up with a reasonable plan for maintaining internal consistency (perhaps starting with 2.x) while still not avoiding publicly breaking changes, I can move superagent-cache to 2.x at the same time superagent goes to 2.x and consider no longer supporting 1.x.\nI just don't see myself having enough time to maintain two versions of superagent-cache, much less backwards compatibility spanning numerous internally breaking changes. I'm also not thrilled with the idea of making superagent-cache compatible with > 1.6.1 until some agreement on consistency can be reached. \nAm I way off here, or does this seem reasonable? Any thoughts on a consistency strategy?\n. Ok thanks, that's comforting. Surprising so much of the user base is on 0.x. I don't support earlier than 1.1, I believe. At least that's where superagent was when I initially released. \n. I've identified a rather troubling internally breaking change introduced in 1.7.0. Previous to 1.7.0, headers are stored in lower case whereas in 1.7.0, headers are stored in whatever case they were passed. I'm basing this off of the data returned from the function I pasted above titled getHeaderOptions.\nAs a result, I'm unable to support both 1.7.0 and previous versions from the same code base because there is no version attribute within superagent. Perhaps there should be. Additionally, it's troubling that headers undergo a .toLowerCase() since headers are case-sensitive.\n. In 1.7.0, req._header is never populated until after .end() is called. Because I'm patching superagent to be capable of not executing an http request if data exists in the cache, this breaks me--I need to generate a cache key to perform a lookup prior to query execution. And, because I need to be backwards compatible with versions that only store lower-case headers, I need the lower-case headers before .end() is called.\n. Also, it appears that before .end() is called, \"User-Agent\":\"node-superagent/1.7.0\" is present in the headers object but not after. This is really frustrating. What was the reasoning for changing the behavior so that request headers are not finalized until after the http call is made?\n. OK, I was able to get everything working with 1.6.1, 1.7.0, 1.7.1, 1.7.2, and the 1.8.0 beta release. It's currently just in a branch but I plan to merge it tomorrow. Sorry for my frustration.\n. @pornel I finally got around to testing superagent-cache with superagent 1.8.0, 1.8.1, and 1.8.2 and all my tests pass! Quite relieving since you mentioned a bit ago that 1.8.0 changed how headers were handled again.\nI see that a 2.x alpha has been released. Any new thoughts on how to approach a potential developer API? If you'd still like to do it, do you know if it will make it into 2.0.0?\n. Thanks!\n. Thanks for doing this!\n. OK thanks for the fast response. \n. Perhaps I should reword it as \"Tested against 1.x\". It basically means that I don't guarantee it works with 2.x or 3.x, although a couple of people have told me they use it with 2.x and haven't had issues. \nWe can probably just remove that text from the Plugins section. They'll see it in my docs if they look at my repos. . ",
    "RGBboy": "This might be a better option:\nhttps://github.com/visionmedia/superagent/issues/197\n. If you want to use my version with the fix you can add the following in your package.json dependencies, and re run npm install:\njavascript\n\"superagent\": \"git://github.com/RGBboy/superagent.git\"\n. Updated #198 and ready to be merged.\n. I have merged back with the visionmedia/master and fixed a certificate problem that was causing tests to fail with the latest stable version of node (0.10.18). All the tests pass for me now. Please let me know if there is anything else I can do to get this merged.\n. .ca is used to keep inline with the node http and https apis. I thought it best to use those to avoid confusion.\n. ",
    "dpolivy": "Agree with @superjoe30; the ability to set the rejectUnauthorized option would be preferred in some circumstances (such as mine). My use of superagent is against a local developer's machine with self-signed certificates, and the self-signed cert would be different per-host. It's far easier to just set rejectUnauthorized to false, than to have to get the proper cert for the machine and add it to the trusted CA list.\n. @superjoe30 That works great, thanks for the tip!\n. Sure, I'm happy to revisit the API to use a parameter instead of a separate method. I don't have any strong preferences here -- are you OK if I revamp this to match what you proposed?\nAlso, not sure I understand the client concern you're asking about?\n. @pornel Is there a better solution for more complex cases, including redirects and adding incremental cookies?\n. @pornel Yes; before doing certain tests I need to have the agent \"login\", which saves a cookie from the server that is used by subsequent tests. Sometimes the cookies are set or cleared through the use of redirects. And sometimes they are changed by the tests, and need to be propagated through subsequent tests.\n. I found an existing issue that captured the scenario pretty well. Let's use that to track the feature request.\n. ",
    "thaihau": "Yes, Thanks for the tips!\n. ",
    "bryanlarsen": "An example of where this would be useful and the environment variable workaround is with webhooks.\nI'm setting up webhooks in my app, and I'm copying the github API.   They have a configuration flag called 'insecure_ssl'.\n. ",
    "yuyudhan": "@defunctzombie \nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = \"0\"\nThis sets SSL off for all http requests in the process. Shutting off all together would be drastic in production use.\nDo you know how to set it off for one particular request. Anyone??\n. ",
    "rusekr": "@pornel \nWe have system in production that communicates with many external systems on production and test basises (we integrating with people, other people integriate and test integration with us). Recently maintainers of one of this external systems forgot to update certificate and now part of important for us API do not work. While they requesting new cert (2-3 weeks) we set temporary  rejectUnauthorized: false for only requests to this API with checking while it is updated to revert option to true. \nBut some tests with requests to this API written with chai-http which uses superagent and while i can  suppress errors for native nodejs request with rejectUnauthorized, for chai-http i can`t.\nSetting process.env.NODE_TLS_REJECT_UNAUTHORIZED = \"0\" kills security of many other requests even if i will be reverted in in response callback.\nWhat to do? Change testing framework because of this small but important in real life option? . Big companies have big bureaucracy. Frustration because maintainer of lib used in popular testing(!) framework rejects to have basic nodejs simple configurability in its wrapper and i cant simply fork it because i need to fork chai-http too. It's even already pull requests. No need to do anything.\nIt's like some linux distro which disallows users to have simple passwords because it's insecure but creators of that distro cant think about how wide it can be used for example for tests in virtual environment or as demo short-ttl containers.. @pornel  You are rejecting configurability. Let people decide themself how to use this basic options. It's basic nodejs functionality. I mentioned here https://github.com/visionmedia/superagent/issues/188#issuecomment-336725716 real life use of this option.\nThere are not always YOUR systems with bad certificates in real life and you must integrate with them anyway (responsibility for potential mitm - another question). \np.s. Meanwhile you can make checking cert not only required but require to save and check it's fingerprint because now MITM can be made with green certificates which any breacher can get from mozilla freely. And no default rejectUnauthorized: true can say the differece. Security is configured by means, not for all.. This company staff uses only paid certificates. Its decision of big management.\nAbout strong chain i wrote in p.s. - if i can hack your dns - mozilla gives me plenty space to have green browser bar for my fake servier for you without you notice (except fingerprint saving/checking enabled on your client). Mobile browsers dont even allow you to see which cert is actually on server you connected to if its green. (;. >> verification of chain of trust protects against\nVerification chain is for the convenience of certificate authorities. No need for them to revoke root cert if just one of its children (or child of children) compromised. It's simple delegation of trust.\nIf i spoof your dns requests your browser will be checking my certificate chain, not yours (;\nmeanwhile nodejs is not a browser. it's server to server communication and i can check even fingerprint of my expired certificate and it will be proof that it is not switched with fake.\nAnd its went to nowhere. Got it. Your locked freedom in your lib for no reason.. You are using ssh - its same as non-browser to server ssl. There is no green-mafia in it for all good. Here only known or unknown key fingerprints as i want with rejectUnauthorized: true in that case.. ",
    "Swatinem": "Oh yes please.\nThis breaks CORS since a server would have to explicitly allow the header via Access-Control-Allow-Headers.\nAnd since there is no api method to remove a header, i need to resort so req.headers = {} which is not really clean.\n. ",
    "mako-taco": "This would be helpful to me as well\n. ",
    "timaschew": "+1\n. @gjohnson \nwhy the try block wraps the callback as well?\nIsn't it enough to catch just the var res = new Response(self); ?\nhttps://github.com/visionmedia/superagent/blob/f106c7226758a22f633d0cf1607b5bb6a3ce264e/lib/client.js#L454\n. maybe something like that:\njs\n  this.on('end', function(){\n    var res;\n    try {\n     res = new Response(self);\n    } catch(e) {\n      var err = new Error('Parser is unable to parse the response');\n      err.parse = true;\n      err.original = e;\n      self.callback(err);\n    }\n    if ('HEAD' == method) res.text = null;\n    try {\n      self.callback(null, res);\n    } catch(e) {\n      self.callback(e);\n    }\n  });\n}\n. ",
    "sebastianhoitz": "I noticed the same problem.\nnginx responds to all POST requests without Content-Length header with a 411 response.\nWhat would be a good way to add this functionality?\n. Is there anything else you want me to do in order to accept this pull request @visionmedia ?\n. @johnaschroeder do you mind sharing your solution?\n. ",
    "tinganho": "Is there a way you can make it support content-length?\nOn Thu, Jul 4, 2013 at 11:02 PM, TJ Holowaychuk notifications@github.comwrote:\n\nit should use transfer-encoding: chunked\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/visionmedia/superagent/issues/196#issuecomment-20481583\n.\n\n\nSincerely,\nTingan Ho\n. ",
    "robraux": ":+1: , I can't run SSL paged local oriented tests until this is resolved.\n. ",
    "wridgers": "I'd be great to see this merged asap. :+1: \n. ",
    "jkutianski": ":+1:\n. ",
    "arthurdarcet": ":+1: \n. ",
    "riston": "Waiting for new package, this feature would be great !\n. PR means what ? Yes I think this is must have feature, @RGBboy thank you for your version.\n. ",
    "nparsons08": "Any update on this? We could really use a merge on this one.\n. ",
    "djechlin": "+1, this is needed - using @RGBboy's fork for now.\n. In browser response headers indicate encoding is deflate.  When I add this to my request:\n.set({\"Accept-Encoding\" : \"gzip,sdch\"})\nRequest succeeds. So problem seems to be in unencoding deflate-encoded streams. (I guess.)\n. ",
    "jonathanrdelgado": "@gjohnson I think the better option is passing rejectUnauthorized to the request rather than ignoring security for the entire process with NODE_TLS_REJECT_UNAUTHORIZED=0.\nAdding the CA works in some cases, and should be kept as a feature, but if you are trying to secure an IP, node will always throw a match error, even if you pass the cert as a ca.\nI'll throw in a PR if you agree.\n. ",
    "scull7": "When is it anticipated to have this into the super agent release?\n. ",
    "nguyenchr": "any update on this pull request?\n. ",
    "stephenmathieson": "bump\n. hmm.. ok.  workaround?\n. +1 for debug :)\n. @visionmedia superagent is ignoring it.  it's just returning and writing stuff to stderr.\n@nickl- yeah, as it's an implementation issue, it sounds like throwing is exactly what should happen..\n. @gjohnson i don't have it anymore.  i had not committed, as it was broken :p  if i come across it again, i'll post it\n. Wow. You're incredibly fast.\nThanks dude!. Looks like CI failed for unrelated reasons: https://travis-ci.org/visionmedia/superagent/jobs/190088001. ",
    "rubenv": "Sorry, github screwed me over here.\n. Oh, didn't notice that, would've fixed it in the right place if I had.\nAnyway, as long as it gets fixed, I'm happy :-)\n. Oh what a crappy bug, lost a lot of time on this one. While I don't have a patch for it, here's a way to work around it:\njs\nagent\n    .post('/queue/4/status')                                                                                                                  \n    .expect(200, status)\n    .end(function (err) {\n        process.nextTick(function () {                                                                                                        \n            cb(err);                                                                                                                          \n        });                                                                                                                                   \n    });\nRunning the callback in the next tick ensures that the next request will only happen once the cookies are set.\n. ",
    "mlegenhausen": "Have the same problem!\n+1\n. ",
    "jozsi": "``` javascript\nvar superagent = require('superagent')\n  , host = 'github.com'\n  , path = '/visionmedia/superagent/issues/204'\n  , proxy = 'http://address:port'; // replace this\nsuperagent\n  .agent()\n  .get(proxy + path)\n  .set('Host', host)\n  .end(function(r) {\n    // parse result\n  });\n```\n. A workaround would be to delete the fields manually before executing the request:\n``` javascript\nvar superagent = require('superagent');\nvar agent = superagent.agent().get('https://github.com/visionmedia/superagent/issues/206');\ndelete agent.req._headers.cookie;\ndelete agent.req._headerNames.cookie;\nagent.end(function(res) {\n  // Do something with the results\n});\n```\n. ",
    "angelochen960": "i tried above with Charles Web Debugging Proxy, does not work, any solution? Thanks\n. ",
    "georgesnelling": "That works.  Closing...\n. In general I agree with you.  In our particular case it worked OK because we use server modes: dev, test, prod, and we set that flag only for dev and test.  However, it is at best a blunt instrument, and in general, I think that API wrappers should expose some way to twiddle all the knobs of their underlying lower-level APIs.  I don't want to reopen because we've worked around it, but feel free to reopen if it is important to you.  Cheers!\n. We see a blocking install problem with 0.14.3 on windows only.  Osx is fine.  on windows, npm cannot find emitter and chokes. \n. we're running \nnode 0.10.4\nnpm 1.2.18\non both windows and osx.  npm install superagent works on osx,  chokes on windows complaining it can't find both the dependencies mentioned in the top-line report.   haven't had time to grovel the npm commit logs.  If its a general npm / windows problem I'm sure the Dear Leader will hear about it soon.\n. ",
    "MartyGentillon": "I am inclined to think that that is a lousy solution.  One of the reasons to use SSL is that you get to authenticate the server.  This shuts off that authentication application wide.  I am likely talking to many different HTTPS systems.  Only a handfull of these uses a self signed certificate.  What happens when someone tries to spoof one of the other services that I am talking to?  Because I have \"avoided the issue altogether\" I now have a new issue, where I am vulnerable to spoofing in general.\n. ",
    "doublerebel": "I believe this is duplicate of #188 ?\n. ",
    "devangpaliwal": "process.env.NODE_TLS_REJECT_UNAUTHORIZED = 0; Worked!!\n. ",
    "mikemaccana": "Is it currently possible to pass rejectUnauthorized in options? Reading some of the linked comments suggests it is, but there's nothing mentioned in the documentation and it doesn't seem to work when I try.\nFor my own use case  process.env.NODE_TLS_REJECT_UNAUTHORIZED = 0; is dangerous. \n. Thanks for the quick answer. Good point, node itself doesn't name the option very well, I've asked what people think about renaming it: https://github.com/nodejs/node/issues/5258  \nIn my case (I want to check an existing TLS setup so I can recommend how to fix it) I ended up just checking for err.code === 'UNABLE_TO_VERIFY_LEAF_SIGNATURE' which was sufficient for my needs.\n. \ud83d\udc4d using .buffer(true) and using response.text worked for me too, thanks @gechols! I suspect a whole bunch of users will end up on this page from bad API vendors who just use JSON but have unnecessary custom mime types like application/vnd.somecompany.rest-v1+json. \ud83d\udca9\n. Please close this. The issue seems to have been timing related! The code works successfully on 3.5.x with some timing parameters adjusted. Thanks for your patience & help.. Any chance we could get the message disabled (at least on node 10)? . ",
    "harshithjv": "@devangpaliwal @mikemaccana \nI am not able to make make it work by setting process.env.NODE_TLS_REJECT_UNAUTHORIZED = 0;. Where should I set it?\nI am using React with Router. I tried manually setting environment variable on windows command prompt. Even that did not work.\n. ",
    "guersam": "+1, it results in errors with some servers parsing headers strictly.\n. ",
    "damianb": "Ping - heartbeat check.\n. Also, \"the server shouldn't error on an empty cookie string\" isn't an excuse to ignore the issue. Superagent shouldn't be sending an empty string either.\n. digging deeper, agent.js within lib/node/ seems to handle this, but it's very problematic.\n. Okay, a few problems that need fixed here within superagent to properly support cookies across redirects (even while using agent.js).\nOne - lib/node/utils.js, method cleanHeaders dropping the cookie header is a problem (see #207).\nTwo - in lib/node/index.js, within Request.prototype.redirect, the this.set(header); call should come before the redirect emit.\nThree - I'm not sure about this one (it might have helped, I can't remember because this was about 1am)...but I added res.set('Cookie') into lib/node/agent.js, within Agent.prototype.attachCookies. Goes alongside req.cookies.\n. Heartbeat check.\n. Similar problem to #206, though different context.\n. I'd appreciate that. I've had to monkey-patch it in on my own for the time being, and setting content-length to 0 for DELETE operations has managed to fix the problem.  The transfer-encoding=chunked just ends up messing quite a bit up.\n. a client workaround will still likely be necessary due to propagation of that patch/update across the web.  even if nginx patches it today, it wouldn't land anytime soon in rhel, deb, ubuntu, so handling nginx's edge case would be necessary in the meantime.\n. ",
    "tommystanton": "(Sorry for the long-winded comment, but I feel that it's worthwhile in explaining the issue.)\n\nI couldn't get the fix that @tracid suggested to work, but I was able to pinpoint the problem with the following code.\nThis script shows how using SuperAgent would result in an HTTP 500 whereas using Request would result in HTTP 200.  The assumption here is that http://example.com is an HTTP endpoint that strictly parses cookie headers:\n``` js\nvar async = require('async');\nvar _ = require('lodash');\nvar superagent = require('superagent');\nvar request = require('request');\nvar attrs = {\n  url: 'http://example.com',\n  method: 'GET'\n};\nasync.parallel([\n  function(cb) {\n    var r = superagentattrs.method.toLowerCase();\n    //r.set('Cookie', 'cook=ie'); // XXX The \"fix\"\n    r.end(function(err, res) {\n      cb(err, res);\n    });\n  },\n  function(cb) {\n    var options = _.merge({}, attrs, {\n      // XXX Add headers that SuperAgent is automatically adding\n      headers: {\n        'Accept-Encoding': 'gzip, deflate',\n        //'cookie': '' // XXX This would break Request as well!\n      }\n    });\nrequest(options, function(err, res, body) {\n  cb(err, res);\n});\n\n}\n], function done(err, results) {\n  if (err) {\n    console.log(err);\n  } else {\n    console.log('SuperAgent', {\n      statusCode: results[0].statusCode,\n      headers: results[0].req._headers\n    });\nconsole.log('Request', {\n  statusCode: results[1].statusCode,\n  headers: results[1].req._headers\n});\n\n}\n});\n```\nRunning this script as is would output:\nSuperAgent { statusCode: 500,\n  headers:\n   { host: 'example.com',\n     'accept-encoding': 'gzip, deflate',\n     cookie: '' } }\nRequest { statusCode: 200,\n  headers:\n   { 'accept-encoding': 'gzip, deflate',\n     host: 'example.com' } }\nNotice that the empty cookie header sent by SuperAgent is the only real difference in between its HTTP request and Request's HTTP request.\nUncommenting line 24 ('cookie': ...) and running it again will cause Request to be given an HTTP 500, just as SuperAgent was being given:\nSuperAgent { statusCode: 500,\n  headers:\n   { host: 'example.com',\n     'accept-encoding': 'gzip, deflate',\n     cookie: '' } }\nRequest { statusCode: 500,\n  headers:\n   { 'accept-encoding': 'gzip, deflate',\n     cookie: '',\n     host: 'example.com' } }\n...whereas uncommenting line 14 (r.set(...), while having line 24 commented out, would give both SuperAgent and Request HTTP 200 responses:\nSuperAgent { statusCode: 200,\n  headers: \n   { host: 'example.com',\n     'accept-encoding': 'gzip, deflate',\n     cookie: 'cook=ie' } }\nRequest { statusCode: 200,\n  headers: \n   { 'accept-encoding': 'gzip, deflate',\n     host: 'example.com' } }\nSo adding the bogus cookie header to SuperAgent (cook=ie, as mentioned in #285) is the short-term fix that I'm using.\n. ",
    "jnak": "FYI, I still get weird behavior with the soundcloud api. The same request will sometimes fail for no reason. I don't think it does send an OPTIONS request though (at least request.method is 'GET'). \n@contra did you find what the issue was? Though I realize it was a long time ago ;) \n. This is happening when running in node 4.2.1\n. ",
    "johnaschroeder": "It would be great to have this merged, we've hit the same issue.\n. Yup, seems reasonable.  Just implemented form-data here and working fine, thanks.\n. We are uploading to s3 for production, and a local db in development. For uploads we get the id and s3 signature if required from the server first, which is uploadResponse.  Here's the relevant snippet, hope it helps.\n``` javascript\nvar FormData = require('form-data');\nvar upload = uploadResponse;\n  var form = new FormData();\n  var path = \"./test/files/\" + testFile.name;\n  var write_multipart = function(key) {\n      if (upload.form && upload.form[key]) {\n          form.append(key, upload.form[key]);\n      } else {\n          //console.log('skipping key' + key);\n      }\n  }\n  // The order of parts matters\n  write_multipart('key');\n  write_multipart('policy');\n  write_multipart('Content-Type');\n  write_multipart('acl');\n  write_multipart('signature');\n  write_multipart('AWSAccessKeyId');\n  form.append('file', fs.createReadStream(path));\n  form.submit(upload.url, function (err, res) {\n      if (upload.form) {\n          res.statusCode.should.equal(204);\n      }\n  });\n```\n. ",
    "dominicbarnes": "Just rebased against the latest master\n. This branch does include the changes to superagent.js itself. Since it is a generated file, I can rebase this branch to include only my actual source code changes to lib/client.js.\n. I guess that component would replace my getIEXHR() function?\n. +1\n. I was thinking that perhaps a request that was specifically aborted should not emit an error. Either way, I don't think it should be treated the same as a timeout.\n. +1\nI remember this working at some point, but as long as the documentation is consistent/accurate I don't care which way this goes.\n. ",
    "jkroso": "fixed\n. not that it makes much difference when using them with generators but it might be worth a look at making the request instances also promise instances.\n``` js\n  var res = yield request\n    .get('http://google.com')\n    .set('Accept', 'application/json')\n    .query({ search: 'sloths' })\nconsole.log(res.status);\n```\npromises are just a little nicer for other abstractions which are usable now. whatever though thunks do the job in any case.\n. no the generator thing would call then and that would start the request (or pipe, lol, if it preferred). if you like to minimize implicit stuff you can add .then() with no args after .query and nothing changes. I would love to hear a proper explanation of why you dislike promises, but fair enough if you just wan't to get on with it ;)\n. > no fighting over which implementation to use or duplicate implementations etc\ngood point people still disagree a lot on how to implement them.\nI really wish this was the standard https://gist.github.com/jkroso/5689012#file-promise-js but instead most people use stuff like q which makes me cringe :(. I guess without agreement on what a promise should be thunks are a pretty good alternative\n. superagent requests pretty much already are promises so I think they may aswell become yieldable ones. The new ES6 promises won't help though since they aren't sub-classable :(.\nBTW: I rewrote superagent to use promises and here is an example of which demonstrates why some people go for promises over thunks. Promises are more a type than mechanism. If you could distinguish thunks from other functions cleanly then I'd prefer them too.\n. that makes sense :) LGTM\n. ",
    "PWani": "In an attempt to use superagent with an XML datasource (and have res.body reflect the XML content response), I was using xml2js as shown below.  Although the parser seems to be working and myParse outputs the correct result, the callback on the request seems to be getting called before the parser 'end's. i.e. request.get outputs undefined (since parser is still at work) and then the parser outputs the correct result.  Any ideas on what might be happening here?  Thank you.\n```\nvar parser = new xml2js.Parser();\nfunction myParse (res, fn) {\n  res.text = '';\n  res.setEncoding('utf8');\n  res.on('data', function(chunk){ \n      res.text += chunk; });\n  res.on('end', function ()\n    {\n    parser.parseString(res.text, function (err, result) {\n      if (err)\n        fn(err);\n      else\n      {\n            fn(null, JSON.stringify(result));\n      }\n      });\n});\n\n}\nrequest.get(url)\n    .set('Content-Type', 'application/xml; charset=utf8') \n    .parse(myParse)\n    .end(function(err, res){\n          if (err) console.log(\"Could not access database.\");\n         else console.log(\"Output :\", res.data);\n                });\n```\n. What I'm noticing may be related to: https://github.com/visionmedia/superagent/issues/244\n. ",
    "laurilarjo": "I got it working with this, so I guess it's already supported.\nvar request = superagent.get(url);\nrequest.buffer();\nrequest.type('xml');\nrequest.end(function(res) {    \n    console.log(res.text);\n});\n. ",
    "toddgeist": "I need to work with some XML APIs :-( \nI would like to help get this done. I just need some direction. My skills are intermediate at best, I need more practice.  This looks like a good problem to solve. What can I do to help?  Is there a plan for this?\nThanks\nTodd\n. I just published a tiny module that converts xml in res.text to JSON in res.body\nhttps://github.com/toddgeist/superagent-xml2jsparser\n. ",
    "stephy": "I was able to use the solution from @laurilarjo, so Thanks!\nFor those who want to use that solution as well, there's a little typo in his code. Don't forget the error comes first in the parameter list for the callback function on end.\nvar request = superagent.get(url);\nrequest.buffer();\nrequest.type('xml');\nrequest.end(function(err, res) {    \n    console.log(res.text);\n});\nor the 'shorter' version:\nconst request = superagent.get(url)\n .buffer()\n .type('xml')\n .end((err, res) => {    \n    console.log(res.text);\n});. ",
    "susumuasaga": "I was able to use solution from @laurilarjo, @PWani and @gjohnson, thx all!\nThe key point is enable buffering with .buffer(), the .type() refers to the request body and useless if you are only interested on the response body:\n```var url = 'http://localhost:3000';\nvar superagent = require('superagent');\nvar xml2js = require('xml2js');\nfunction myParse (res, cb) {\n   res.text = '';\n   res.on('data', chunk => res.text += chunk);\n   res.on('end', () => xml2js.parseString(res.text, cb));\n}\nsuperagent.parse['application/xml'] = myParse;\nsuperagent.get(url).buffer().end((err, res) => console.dir(res.body, {depth: null});. ",
    "AdamT213": "@susumuasaga, your solution worked for me!\n. ",
    "cristiandouce": "@visionmedia thoughts?\n. @visionmedia ok. Now should work!\nSorry about the missing console.log back there. I messed a little with the code to catch it.\nWhat do you think about a make test-client command?\n. @visionmedia news?\n. @gjohnson What do you mean? Anything I should do?\n. Cool! :dancers: \n. @visionmedia I wouldn't mind to work out a fix.\nThe thing is I can't decide where or how the check should be...\nMaybe messing around with the request.parse. Provide a parseJSON func to check if empty before calling JSON.parse, or something like that.\n. lol, I never really dig much more into this...\nI think I just forked, patched and used my fork.\n. :trollface: \n. Nice: https://github.com/visionmedia/superagent/blob/master/lib/client.js#L357\n. nooooooooooooooooooo\nshame on me! :'(\nI should have used debug... ;) hahaha\n. ",
    "KenanY": "RedVentures/reduce isn't a registered Bower component.\n. @jonathanong I think you mean to be mentioning @sebs? I made no such assumption.\n. ",
    "sebs": "Oh, but bower tells me for a bower search superagent \nclu-2:distributedcms Admin$ bower search superagent\nSearch results:\n- superagent git://github.com/visionmedia/superagent.git\nSo somehow it seems to be supported (and I like it) \n. Hmm, that would be one library that need to be published to bower and one bower config file that is distinguishable from the component.json in order to make it work?\n. awesome: This discussion goers for multiple tickets now. What about you let the tester decide  how to test and not be to anal about everything. Thing is: You give me the choice: Test all without ssl or deactivate it for ALL. I want my ssl stuff tested\n. ",
    "rexxars": "@defunctzombie Since you added IE9 to the test matrix, tests have been failing because (among others) this issue. Any ideas on how you want to proceed? Don't support IE9? Use a base64-module to support it? I'd be happy to contribute with a PR if you have any feedback on how you want it solved.\n. Yes. superagent fires progress events through it's eventemitter.\nBasically:\njs\nrequest\n   .post('/api/file')\n   .send(someFile)\n   .on('progress', function(e) {\n      console.log('Percentage done: ', e.percent);\n   }\n   .end(function(res){\n     if (res.ok) {\n       alert('yay got ' + JSON.stringify(res.body));\n     } else {\n       alert('Oh no! error ' + res.text);\n     }\n   });\nSee https://github.com/visionmedia/superagent/blob/master/lib/client.js#L756-L770\n. Not using superagent anymore, but based on the previous comments you're probably right. Updated my example.\n. ",
    "pwldp": "According to the https://gemnasium.com/visionmedia/superagent \"emitter\" latest version is 0.0.2.\nIn package.json is 1.0.0.\nIt should be \"emitter\" or \"component/emitter\"?\n. My problem exists on LInux.\nWhat does it mean: npm in GH-style? It is different npm manager?\n. ",
    "jdesboeufs": "It happens when git is not available.\n. Any DELETE request through nginx without body :(\nHopefully it's easy to fix with req.set('content-length', 0).\ncurl seems to do this by default.\n. :+1: \nAnother problem with the current implementation is that you must use agent before headers methods like set. If you call it after, it's a no-op.\n. You should also check that cookies is not an empty string, which causes request rejection on legacy servers.\n. ",
    "ericelliott": "@visionmedia I'm seeing this issue as well. It can't find a compatible version of component/emitter. \nI worked around it by locking superagent at 0.14.2. It's saying it can't find a compatible version.\nInterestingly, this works just fine:\n$ npm install emitter-component\nnpm http GET https://registry.npmjs.org/emitter-component\nnpm http 200 https://registry.npmjs.org/emitter-component\nnpm http GET https://registry.npmjs.org/emitter-component/-/emitter-component-1.0.0.tgz\nnpm http 200 https://registry.npmjs.org/emitter-component/-/emitter-component-1.0.0.tgz\nemitter-component@1.0.0 node_modules/emitter-component\n. Working like a charm for me in Node again. Thanks.\n. ",
    "pyrostrex": "+1, I really need this.\n. ",
    "cyjake": "or we can just use .buffer() to force buffer, right?\nbash\n$ node -e \"require('superagent').get('https://github.com/bevry/feedr/commits/for-testing.atom').buffer().end(console.log)\"\n. Regarding the .tls() or .ca() method, where is the documentation? I can't find it at http://visionmedia.github.io/superagent/. ",
    "lingo": "I'm getting what seems to be a similar/the same problem.\nDespite a 200 status and the response seems correctly completed, I'm getting res.body == {} and res.text as undefined. \nOutput here (with secrets removed): https://gist.github.com/lingo/e4cd297cd05e77f55806\nSadly I can't find references to .parse() in the documentation, but I'm reading through the code now.\nShouldn't XML at very least be returned in res.text by default?   This may be an error with the external service, but testing with curl using same headers gives a valid response.\nEdit I do get it working with .buffer().  I see the documentation talks a bit about this, but maybe it could be clarified a little that for XML res.text will be undefined?\n. Okay, it appears I'm generating a lot of noise today.\nThe problem (of course!) is that the tests expect a port of 5000 to be free.  Perhaps this could be altered in the testing, or a test could be added at the beginning that will show an error if this is wrong.\nExcuse the noise, please.\n. ",
    "shesek": "Looks like its for superagent to work with co? (which looks awesome, @visionmedia!).\nIf co were to support promises (which is basically ~~just~~ [1] replacing ret.value(next) with (ret.value.then||ret.value)(next)) its just a matter of aliasing the end method with then... but it looks like co is pretty opinionated about not using promises.\nEdit: [1] actually, its not quite right - promises don't follow the (err, res) callback convention and use two callbacks instead. It would also be wrong to alias end as then for that reason.\n. Should I create a new file for Response tests or put this someplace else? Also, this piece of code is quite trivial, and I just fixed a typo... I can test that toError() works properly, but I'm not sure if its needed.\n. I added the test, but was unable to run the browser tests locally. Just added it here for the record, this shouldn't be merged until tested. I'll open a separate ticket about the errors I'm getting with the browser tests and try to get this working.\n. Sure thing! Thanks for merging :)\n. It should be fine with strict mode as long as obj['delete'] is used rather than obj.delete. Users of superagent can choose which one they prefer.\n. @iMerica This issue is still opened, the \"closed\" you're seeing is from the referenced issue at borisyankov/DefinitelyTyped.\n. ",
    "spikebrehm": "Curious if @visionmedia has any renewed interest in supporting promises now that it's a sure thing for ES6?\n. ",
    "drojas": "I use this\n``` js\nvar co = require('co');\nvar request = require('superagent');\nco(function *(){\n  var a = yield request.get('http://google.com').thunkify();\n  var b = yield request.get('http://yahoo.com').thunkify();\n  var c = yield request.get('http://cloudup.com').thunkify();\n  console.log(a.statusCode);\n  console.log(b.statusCode);\n  console.log(c.statusCode);\n})()\nco(function *(){\n  var a = request.get('http://google.com').thunkify();\n  var b = request.get('http://yahoo.com').thunkify();\n  var c = request.get('http://cloudup.com').thunkify();\n  var res = yield [a, b, c];\n  console.log(res);\n})()\n```\n. I'm sorry, no automated tests added.\n. yes... no prob. I don't like promises but I don't really need this pr to be merged. regards!\n. ",
    "ianstormtaylor": "+1 for thunks\n. ",
    "kof": "\nPromises have a way bigger value proposition than thunks. \nPerformance overhead can be ignored in superagent use case.\nWe don't need to introduce a dependency to some particular implementation. We can let user pass  the implementation once or use the global one.\nWe can still have the .end method which returns a promise, which is more explicit and backwards compatible.\n. I suppose because it doesn't play well with redirects? I have tried to pipe a request, but in case of redirect it stays piped and receiver gets empty body.\n. I am getting it also very often, we need to identify reasons and fix it finally. Probably in some cases it is ok when its double called and there is no need for the warning. Just ensure not calling users callback twice.\n. Oh its not because I didn't pass the callback fn, its because this.request() within .end gets an error and calls .callback, but  this._callback = fn happens after that.\n. so basically this._callback = fn || noop; should happen before this.request()\n. ohh figured out this error would never happen if .agent method would return this, I was chaining .agent with .end call.\n\n.agent should really return this, there is no usability value in returning Agent I just passed. But returning this gives me possibility to build a nice chain.\n```\nrequest\n    .get(url)\n    .set('user-agent', conf.request.agent)\n    .set('accept', conf.request.accept)\n    .timeout(conf.request.timeout)\n    .buffer(false)\n    .parse(noop)\n    .agent(new http.Agent())\n    .on('error', done)\n    .on('response', function(res) {\n})\n.end()\n\n```\n. Will somebody accept pull with changed return value of .agent method?\n. I see, and because of this behavior we can distinguish between setter and getter\nundefined (default): use global Agent for this host and port.\nAgent object: explicitly use the passed in Agent.\nfalse: opts out of connection pooling with an Agent, defaults request to Connection: close.\nbecause undefined should set global agent.\n. Oh just read the documentation, there is NO SINGLE mention about .agent method. Therefore we can change it for sure. Not much people will have broken code. Its almost unrealistic case that I need to get the agent out of req object passed somewhere else, normally if you want to access the agent you have its reference already in that function.\nSo we can change this without to break someonce code!\n. And also we can actually distinguish between passed undefined and not passed anything, by checking arguments.length.\nI will send you a  patch.\n. If you agree on checking arguments.length > 0 ? setter : getter I willl send a pull\n. Pull request done \nhttps://github.com/visionmedia/superagent/pull/406\nThere are also 3 tests added.\n. Yeah, there are 2 other tests failing\n. what about publishing? :)\n. ;(\n. I start piping within 'response' event.\n. Oh its not possible even if I do request with  buffering and end callback ....\n. If I change pathname to path, it breaks 3 tests.\n.  1) req.query(String) should work with url query-string:\n```\n  Uncaught AssertionError: expected { name: [ 'tobi', 'tobi' ], age: '2' } to equal { name: 'tobi', age: '2' }\n  + expected - actual\n{\n     \"age\": \"2\",\n  +  \"name\": \"tobi\"\n  -  \"name\": [\n  -    \"tobi\",\n  -    \"tobi\"\n  -  ]\n   }\n```\n2) req.query(Object) should append to the original query-string:\n```\n  Uncaught AssertionError: expected { name: [ 'tobi', 'tobi' ], order: 'asc' } to equal { name: 'tobi', order: 'asc' }\n  + expected - actual\n{\n  +  \"name\": \"tobi\",\n  -  \"name\": [\n  -    \"tobi\",\n  -    \"tobi\"\n  -  ],\n     \"order\": \"asc\"\n   }\n```\n3) req.query(Object) should retain the original query-string:\n```\n  Uncaught AssertionError: expected { name: [ 'tobi', 'tobi' ] } to equal { name: 'tobi' }\n  + expected - actual\n{\n  +  \"name\": \"tobi\"\n  -  \"name\": [\n  -    \"tobi\",\n  -    \"tobi\"\n  -  ]\n   }\n```\n. Oh thats complicated to track down. So at the end the path looks  like \n/?p=yaboot.git%3Ba%3Drss%3Bf%3Dsecond%2Ffile.c%3Bopt%3D--no-merges\n. Finally understood the problem.\nqs.stringify encodes the url and in this case it breaks things, here:\ntry {\n    var querystring = qs.stringify(this.qs);\n    req.path += querystring.length\n      ? (~req.path.indexOf('?') ? '&' : '?') + querystring\n      : '';\n  } catch (e) {\n    return this.callback(e);\n  }\n. No idea where to fix that correctly\n. Yet another example: http://s228.photobucket.com/albums/ee39/BillyG1591/?action=view&current=untitled.jpg\nsuperagent max redirects 5 +0ms\nsuperagent GET http://s228.photobucket.com/albums/ee39/BillyG1591/?action=view&current=untitled.jpg +9ms\nsuperagent GET http://s228.photobucket.com/albums/ee39/BillyG1591/?action=view&current=untitled.jpg -> 301 +382ms\nsuperagent redirect http://s228.photobucket.com/albums/ee39/BillyG1591/?action=view&current=untitled.jpg -> http://s228.photobucket.com/user/BillyG1591/media/untitled.jpg.html +1ms\nsuperagent clear timeout GET http://s228.photobucket.com/user/BillyG1591/media/untitled.jpg.html +0ms\nsuperagent set accept-encoding \"gzip, deflate\" +1ms\nsuperagent set user-agent \"node-superagent/0.18.1\" +2ms\nsuperagent GET http://s228.photobucket.com/user/BillyG1591/media/untitled.jpg.html +0ms\nsuperagent GET http://s228.photobucket.com/user/BillyG1591/media/untitled.jpg.html -> 404 +1s\nsuperagent end GET http://s228.photobucket.com/user/BillyG1591/media/untitled.jpg.html +84ms\nsuperagent clear timeout GET http://s228.photobucket.com/user/BillyG1591/media/untitled.jpg.html +1ms\nhowever browser resolves it correctly, accessing the redirected url directly with superagent works as expected too\nCan somebody look at it whats going on under the hood?\n. @gjohnson ?\n.  @naman34 wdyt?\n. yes sure, also probably good to mention node -v v0.11.13\n. Here another example, this one redirects correctly, but then no data and no end events fired\nhttp://www.tvcatalunya.com/rss/videos/tots_multimedies_182564611_rss.xml\nor\nhttp://blog.maartenballiauw.be/category/feed/C.aspx\n.  @naman34 wdyt?\n. node v0.11.13 didn't test the older one\n. same on node 0.10\n. @gjohnson if you agree I will implement it now.\n. Just read the tests for parser, it looks like there is already even a test \"'should take precedence over default parsers'\". So its a bug, test doesn't ensure this works for all mime types. \nNow I am sure it has to be fixed.\n. yes error should be emitted on the main Request instance.\n. probably a separate issue though\n. In this issue I will ensure no default parser is running when user defined one exists.\n. fixed by #422\n. shold component.json and package.json versions increment always in parallel?\n. merged.\n. it would be actually a way nicer not to have this code in superagent, but in a separate XMLHTTP shim which most probably exist already.\n. because lots of us don't need it anyways. Its  a throw away compatibility thing.\n. @gjohnson me too. The question is how to achieve this without to trap into the promises implementation war. \nMy suggestion is to use window.Promise if there is one. So its up to user which implementation to use.\n. ",
    "cncolder": "i have a new idea:\nwe can extend the prototype of superagent.Request as thenable.\njs\nRequest.prototype.then = function(fulfilled, rejected) {\n  return new Promise(function(resolve, reject) {\n    this.end(function(err, res) {\n      if (err) reject(err);\n      else resolve(res);\n    });\n  }.bind(this)).then(fulfilled, rejected);\n};\nnow we can get promise after then or yield.\n``` js\nrequest.get('localhost:3000')\n.then(function(res) {\n  assert(res.ok);\n  return res;\n})\n.then(function(res) {\n  assert.equal(res.text, 'Hello World');\n});\nco(function * () {\n  var res = yield request.get('localhost:3000');\n  assert(res.ok);\n})();\n```\n. ",
    "nmn": "This has been a long and unproductive argument, which is mostly a thunks vs promises debate.\nSome things to consider now:\n1) Co now prefers promises over thunks\n2) superagent-promise already provides a simple wrapper for superagent to return promises\n3) Choosing one does not mean the other is bad.\nPossible resolutions:\n1) support thunks in the main lib, and support the development of superagent-promise to support both approaches.\n2) Leave the main lib alone, and create a separate repo to wrap superagent and make it support thunks, and support superagent-promise\n3) Add Support for both thunks and promises into the main lib, possibly with an extra method (toThunk/toPromise?)\n4) Choose one approach as the only approach and keep arguing about it for eternity\n. If this only happens in Node, there might be a bug in the underlying node implementation. I'll try to test it soon.\n. Node or browser, or both? Sound like a bug similar to the redirect bug.\n. Could you test in a stable node? this could be a bug in Node core.\n. Alright. I'll try to find the bug. In the mean time, let me know if you find anything interesting.\n. We should look into code refactor where the API largely remains the same. Otherwise a fork may the correct route.\n. It's one failing test. Maybe you can fix it and re-submit?\n```\n111 passing (604ms)\n  1 failing\n1) request pipe should act as a readable stream:\n     Uncaught Error: ENOENT, no such file or directory 'test/node/fixtures/tmp.json'\n      at Object.fs.openSync (fs.js:427:18)\n      at Object.fs.readFileSync (fs.js:284:15)\n      at Request. (/home/travis/build/visionmedia/superagent/test/node/pipe.js:39:21)\n      at Request.EventEmitter.emit (events.js:117:20)\n      at IncomingMessage. (/home/travis/build/visionmedia/superagent/lib/node/index.js:808:14)\n      at IncomingMessage.EventEmitter.emit (events.js:117:20)\n      at _stream_readable.js:920:16\n      at process._tickCallback (node.js:415:13)\n```\n. I think just a file needs to be added in the fixtures folder.\n. hmm... It's debatable. But I see your point.\n. ",
    "lostinpatterns": "Added for the browser too so the defaults are the same.\n. ",
    "nathanhoel": "This is exactly what we need. Does the maintainer need this to be updated before considering the pull request at this time?\n. This is what we do in each test for now\nvar superagent = require('superagent');\nsuperagent.parse['application/vnd.seferral-v1+json'] = superagent.parse['application/json'];\nsuperagent.serialize['application/vnd.seferral-v1+json'] = superagent.serialize['application/json'];\n. +json is standard.\nThere is precedent for it, see the list of registered media types IANA lists (notice +XML, +JSON etc)\nhttp://www.iana.org/assignments/media-types/media-types.xhtml\nRFC 6839 (http://tools.ietf.org/html/rfc6839) suggests these should be registered suffixes.\nNotice in RFC 3023 (http://tools.ietf.org/html/rfc3023) the +XML suffix has been around since 2001.\nThere are not a lot of suffixes that are registered and used as widely as these. \nI agree with you though that there is a danger of accepting other suffixes as aliases for JSON. If HAL wants to put +HAL at the end and have libraries accept it as JSON they should just make it +JSON. Hal is actually using hal+json. Some groups may start making their own suffixes but I would not expect those to be supported. If other media types wish to be recognized as xml/json parseable they should use the appropriate suffix instead of inventing their own.\nAs for the content type you saw above that is actually the vendor content type for my specific project. That is how you are supposed to form your media types. application/vnd.SOMETHING+json or + whatever supported suffix it is.\n. Using just application/json is far less description than a specific media type such as application/hal+json or whatever it may be. Using the (admittedly prevalent) vanilla \"application/json\" should not be considered the \"proper\" way. It is simply the media type of choice in very simple cases or cases where people do not realize the full potential of media types.\nAfter re-reading I realize you might have thought that the whole \"application/vnd.seferral-v1+json\" would have to be supported. But to support suffixes you simply split the string on the + and read the suffix. If it's a recognized type, then parse it.\nHopefully that all makes sense.\n. @amarandon Yes, actually we do the same thing, I just changed it to superagent specific.\nThe actual line is \nvar superagent = require('supertest/node_modules/superagent');\nI dislike monkey patching as it is, but the fact I have to do it in every test is even worse.\n. ",
    "amarandon": "+1 Yes please. \nIn the meantime, is there a way to add this behavior from our code (ie. add our own custom parsers)?\n. @nathanhoel Thanks. Actually I'm using supertest and can't find a way to access the superagent instance from my code.\n```\n\nconsole.dir(supertest.agent)\n< [Function: TestAgent]\nconsole.dir(supertest.agent.TestAgent)\n< undefined\ntypeof supertest.agent.parse\n'undefined'\n``\n. I see, was hoping for a more elegant way to do it but ... oh well :)\nHere doing the monkey patching once in mytest/index.js` file seems to work fine though.\n. \n",
    "abrkn": ":+1:\n. I'm very interested in this feature. There are certain errors returned from the API I consume which mean I should retry.. ",
    "shahzaibyounis": "+1 SuperAgent should default to json-parser for media-types ending with '+json'.\n. ",
    "juliangruber": "ping\n. ",
    "soyuka": "@defunctzombie DELETE requires a content-length, at least with nginx (seems I had no issues with apache). If I try to curl DELETE it will send a 411 Length Required status. \nSolution here is to set a Content-length header:\nif(this.method == 'DELETE') {\n      this.set('Content-length', 0)\n    }\natm I have a hack like this one to override the Request.prototype.request method.\n. @defunctzombie are there specific instructions to run tests? I did make test or make test-node but a lot is failing. Thanks.\n. @defunctzombie sorry made a lot of mistakes in my first commit it's late here ^^. \n. @damianb  I see no client workaround here. How can you set the Content-Length header from the client (aka web browser)? See in the list of forbidden header name.\n@pornel agreed, but it then say in OPTIONS that a request with an empty body MUST provide a Content-Length of 0. I'll search on the nginx side if there are mention of this particular issue.\n. Continuing the discusison from the #711 PR here:\nOPTIONS:\n\nA server MUST generate a Content-Length field with a value of \"0\" if no payload body is to be sent in the response.\n\nDELETE:\n\nA payload within a DELETE request message has no defined semantics;\nsending a payload body on a DELETE request might cause some existing\nimplementations to reject the request.\n\n\nYes indeed, I read both, but the OPTIONS paragraph was a more logical explanation to why does nginx sends 411 when DELETE happens without Content-Length.\nIf you mix both parts, you could deduce that DELETE should not have any body, and so, should set the Content-Length to 0, like OPTIONS expects.\nI can't find any relevent issues on the nginx Trac, I'll try to dig deeper.\n. @defunctzombie nope, the browser should set the Content-Length header automatically. XMLHttpRequest isn't allowed to set it anyway. \nCould you check out my last comment : https://github.com/visionmedia/superagent/pull/711#issuecomment-126117830 ? Thanks.\n. Bump\n. @pornel maybe that was the cause:\n\nA server MUST generate a Content-Length field with a value of \"0\" if no payload body is to be sent in the response.\n\nhttps://tools.ietf.org/html/rfc7231\nThanks for the answer. Anyway, I'm almost always extending supertest/superagent for my needs. I can provide an example if someone wants.\nYou may want to close https://github.com/visionmedia/superagent/issues/236 too.\n. Do you have a better way to check the header that has been sent? \n. What are you meaning by client? The client can sent the header he wants (see last test). Some web servers (like nginx) will deny a DELETE request when Content-Length is not set to 0. \n. ",
    "suparngp": "Okay, here is what I have done to take care of this error. I don't know if this will work out in future.\nI added a on error event listener on req object in superagent index.js module. So far, it is working okay. I still need to test it out further.\nIf anybody has any suggestions, please let me know. Thanks.\n. I understand what you are saying. I think I should try to resolve this with\nthe glassfish community. Because The server doesnt crash. What it does is\nif it cookie header string is empty it throws an exception and sends a 200\nok response.\nSorry for the trouble!\nOn Thursday, November 7, 2013, Garrett Johnson wrote:\n\nWe could prevent the empty cookie header from being sent, however anyone\ncan send whatever headers they want (not limited to superagent of course)\nand if your sever crashes because of an empty string value, I would say the\nissue is actually in your server.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/visionmedia/superagent/issues/285#issuecomment-27974153\n.\n. @gjohnson I have opened an issue with GlassFish. Hopefully it will get resolved.\n\nhttps://java.net/jira/browse/GLASSFISH-20887\n. Just an update, this issue has been fixed in the current build (4.0.1) of GlassFish.\n. ",
    "gebrits": "@suparngp is this still your go-to solution? I'm experiencing the same thing. @wonnage: Any luck in resolving this? \nWe're seeing something similar: \n```\nevents.js:141\n      throw er; // Unhandled 'error' event\n      ^\nError: unexpected end of file\n    at Zlib._handle.onerror (zlib.js:363:17)\n```\nThis crashes our node-process entirely without an apparent way to catch??\n. Possibly related to #410 \n. ",
    "brighthas": "very good ! :+1: \n. ",
    "topkara": "Is part() supported on the browser? It doesn't come up in the signature of a post request.\n. ",
    "meaku": "@visionmedia it would be great if the documentation would state that multipart is not working atm. Agree?\n. ",
    "adriancooney": "+1 for documentation note. :(\n. ",
    "cheddar": "Looks like this is fixed in #310 \nAny chance the fix might make it into npm soon?  @visionmedia \n. ",
    "ARAtlas": "Still seeing this with the latest superagent. Am I the only one?\n. I tried various versions of superagent. This bug was introduced in 0.14.8.\n. Node 0.8.22.\n. ",
    "mindjuice": "Not sure if I am seeing the same issue, but it seems similar.\nThe res.body field is never set for my GET request when running superagent in a node app.  My res.text is very small (about 120 characters), and the content-type is set as shown:\n\"content-type\": \"application/json; charset=utf-8\",\nI am running the same code in the browser to send requests to my REST API and it sets res.body properly in that environment, but running under node, res.body is never set.\nI'm running superagent 0.21.0 and node 0.10.31.\n. I tried putting your patch into superagent 0.21.0, but my res.body is still undefined even though my res.text is set and content-type is \"application/json; charset=utf-8\".\n. ",
    "mintrigue": "I was seeing a similar issue but it ended up being a bug in my code.  I had not setup express to handle multi-part forms-\napp.use(express.multipart());\n. ",
    "chrisabrams": "I went ahead and made jQuery's $.param standalone with just Javascript so I could use it on Node without requiring jQuery. Still curious though if there is a built in option for this with superagent? Here's what I did: https://github.com/chrisabrams/param\n. ",
    "mathieuruellan": "If you want to avoid jquery, the querystring module does the job!\n. ",
    "davis": "this is important!!\n. wasn't this fixed in https://github.com/visionmedia/superagent/releases/tag/v1.5.0?\n. could we also have an option for both forms:\n// GET \"/things?thing[]=a&thing[]=b&thing[]=c\"\n// GET \"/things?thing=a&thing=b&thing=c\"\n. @longlho the issue is that the node version of superagent and the client lib have different behaviors\nnode outputs a=1&a=2\nclient outputs a=1,2\n. my issue originally came up because i wrote a library that is supposed to work on both node and client and has superagent as a dependency. a user reported an issue when using the client lib which i could not reproduce with my mocha tests (node). that's why i reported it.\nclient and node libs have different behaviors -- i don't think that should be the case.\n. can be merged with #629 \n. sweet! thanks guys\n. @tdeheurles do you mind sharing the rest of your config? I'm still running into this issue\n. I got around it by removing some lines from the bundle after building. Inconvenient, but works for now. Thanks though!\n. ",
    "vs4vijay": "How can I send post data as Array?\nI am using .type('form')\n. How to make this work?\n. ",
    "tjdavenport": "I just stumbled into this problem today. Going to try to get a PR up sometime this week \n. ",
    "badunk": "\nwhen it should be\ninterests[]: 300\n   interests[]: 400\n\nI'm trying to find the spec that backs up this claim - why should it be that way?  I'm also running into the same issue.  Closest thing I've found is:\n\nRFC 2388                  multipart/form-data                August 1998\n5.5 Ordered fields and duplicated field names\nThe relationship of the ordering of fields within a form and the\n   ordering of returned values within \"multipart/form-data\" is not\n   defined by this specification, nor is the handling of the case where\n   a form has multiple fields with the same name. While HTML-based forms\n   may send back results in the order received, and intermediaries\n   should not reorder the results, there are some systems which might\n   not define a natural order for form fields.\n\nWhich implies there's no specification for a duplicate interests[] field\n. Small update, I tested a bit with express's multer and it does in fact parse multipart as @chrisabrams suggests, regardless of the spec.\nIn fact, despite superagent's refusal to parse these more complex multipart requests, you can build up a much more complicated structure where for example attach(\"interests[name]\", \"myname\") gets parsed into the interests object {name: \"myname\"} and attach(\"interests[0][name]\", \"myname\") serializes into [{name: \"myname\"}]\n. +1\n. I would love this.  Specifically, I'm trying to figure out whether the codebase supports file uploads in ie9 (which does not support xhr2).\n. If you're referring to #280, then the fix there was simply about not parsing HEAD requests.  This PR is checking for the length of the response body.  I don't see all that much duplication of logic.\nDo the tests need fixing from this PR?\n. I suppose the code would look like this if consolidated:\nthis.body = this.req.method != 'HEAD' && this.text\n  ? this.parseBody(this.text)\n  : null;\nI can submit a new PR if that's what you want\n. ",
    "J-F-Liu": "Please note that jQuery.param() also has special treatment for object data.\n. ",
    "mdp": "Yeah, so Express 3.3.1 should be sending back formatted JSON by default, not a single line as the tests specify.\nI added it to Travis and it's failing there as well - https://travis-ci.org/mdp/superagent/builds/9441920\n. ",
    "prycec": "+1\n. Not sure why this was closed? it's still an issue in 1.18.2\n. ",
    "gaearon": "This seems to have been merged on July 16th, but 0.18.2 was on July 12th.\nSo it's fixed in master but not in NPM.\n. ",
    "akatov": "I was going to use grunt-mocha-cov to also generate test coverage reports. Also thought that having everything done in one language (including the build process) might be useful. But I now know that you don't like grunt.. Will make another PR without it I guess.\n. well, my above branch is still alive in my fork, but I haven't touched this since July 2013, so this is hopelessly behind master. You're welcome to browse it though:\nhttps://github.com/akatov/superagent/tree/grunt\n. ",
    "guillaume86": "@akatov do you still have a pure JS build/tests fork? \nI'd like to look into chunked response support but I'm currently on windows which is not really make friendly.\n. To add a little bit of info: if you res.end() you'll receive the last chunk in res.text.\nI found this that could help implementing it: \nhttps://github.com/pk11/streaming-with-chunked-responses/blob/master/public/xhr.html\n. ",
    "jayceekay": "@defunctzombie i'm still seeing this. newer versions of what? superagent, zlib?\n. ",
    "landonpoch": "Should be re-opened.  I'm seeing this also.  I believe there are a couple of other bugs related to zlib not working: https://github.com/visionmedia/superagent/issues/927, https://github.com/danwrong/restler/issues/96\nI did notice that I had to change my headers from:\n{ \"Accept-Encoding\": \"gzip, deflate\" }\nto this:\n{ \"Accept-Encoding\": \"gzip\" }\nThat seemed to fix it.. ",
    "nickl-": "The appropriate way to request the type of content you wish to be returned is by issuing an Accept header in your case you want \nhttp\nGET /something.js HTTP/1.1\nHost: www.example.com\nAccept: text/plain\nThe server may disagree with you and reply with a 406 Not Acceptable which should include a list of the available types. \nYou can always view the Response.text to get to the raw text which is the \"non-exception\" you are referring to instead.\nThis should be closed as Won't Fix.\n. JQuery went with first duck typing the ActiveXObject: see jQuery.ajaxSettings.xhr\nThen it could simply be:\njs\nfunction getXHR() {\n       try { return new ActiveXObject( \"Microsoft.XMLHTTP\" ); } catch( e ) {}\n       return new XMLHttpRequest(); \n}\nDo those other ActiveX references still appear in the wild? ie 6.0 has been canned afaik. But if you insist then keep those others for sentiment I believe it will still be more efficient/reliable to try and fail then doing lookups, assignments and string comparisons;\nComparing the method here seems odd...\n. The first \"Build superagent.js\" 19cc24e should not be considered \"mine\" it was as a result from running make on a fresh head and committed to cleanly separate current state from the new state after my proposed changes were applied and build. As seen in the second \"Build superagent.js\" 1250dbb which only shows my changes. If that helps you with the task at hand. =)\nShout if I can help with anything.\n. @gjohnson are you serious about the rebase? This was a fresh fork I deleted my old one so never once considered it might be out of sync.\n@jonathanong You don't prefer cherry pickable to bulk commit. I made an effort to keep them each self contained unless you disagree. Screw squash I'll just add -A next time much less effort. Does this mean you also want one commit even if it covers multiple changes? I'm confused... usually have trouble getting people to make contained commits. I am getting uncomfortable just thinking about it. \nWhere is the node part I missed?... and I will add that too. \nWill redo the release tags too...\n. Ahh I see index.js I thought they were all using client.js\nNow to find where to apply the tests, it's not as obvious as one would hope.\n. @jonathanong I use interactive add (add -p) to selectively create the commits.\nThe worst is commits including whitespace fixes especially tabs converted or trailing whitespace. Find myself staring character for character and then repeat that several times as I am obviously missing something but nothing changed. Simply adding all whitespace in a single commit makes life so much simpler.\n. All requested changes have been applied, ready for your review.\nQuick breakdown:\n- Outstanding project maintenance\n  - 3fe86a2 is the result from running make superagent.js on fresh HEAD - no codes were harmed in the making of this commit.\n- Pre-existing functionality\n  - b31b4ca increase timeout duration for node tests - 2s would timeout frequently.\n  - 908ba98 change the basic tests echo endpoint to accept all HTTP methods not only POST.\n- Newly added functionality \n  - 321e621 add xml to application/xml mime type mapping for the types lookup table, browser only.\n  - ade4087 add .accept(type) method for node and browser versions.\n  - 8cf5055 add comprehensive unit tests for both node and browser versions - all tests pass.\n- Project maintenance\n  - a5eceeb Re-build superagent.js which now only adds the new additions.\n  - 6175164 Update History.md, changes since last release (0.15.7) also included and tagged for release 0.16.0\nAll commits squashed to incorporate the node.js additions and rebased on fresh upstream HEAD.\nTrust this is to your satisfaction but should further impediments remain feel free to raise your complaints.\n. Any remaining issues? While I still have this project folder at hand please...\n. Yeah \\o/\n. lol =)\n. There will probably be impediments raised for the absence of tests and you will likely be asked to include the node.js counterparts too. \n@chris-rock You may reference #281 for the same exercise and location of the relevant files to update.\n. JQuery (referencing them is almost as good as testing on ie yourself) seems to make special provision for ie9 by using ActiveX:\njs\n  new ActiveXObject( \"Microsoft.XMLHTTP\" );\nInstead of simply:\njs\n new XMLHttpRequest();\nThey check if property withCredentials is present in  either of these instances.\nsee https://github.com/jquery/jquery/blob/master/src/ajax/xhr.js#L7\nHope that helps... \n. You can see #281 for reference to where both browser and node.js functionality and tests can be modified. They unfortunately don't share the same code.\nYou should also build superagent.js IMO...\n$ make -B superagent.js\nShould do the trick =)\n. @johntron tip of the :tophat: =)\n. @bminer any reason not to simply adopt the improved mechanisms by default? Do they require additional dependencies? What exactly are the tangible benefits (ie compared benchmarks) of adopting dns.resolve? It begs the question: If there really are substantial improvements would node not adopt the new functionality eventually? Raising the final and ultimate question: Is this not out of scope for superagent? \n. @bminer Just a thought... would something like this not accomplish the same.\njs\ndns = require('dns');\ndns.lookup = function (domain, family, callback) {\n    if (family = 6)\n       return dns.resolve(domain, 'AAAA', callback);\n    else\n       return dns.resolve(domain, 'A', callback);\n}\nAfter doing some quick tests against the above it appears that dns.resolve4 (which superagent uses) does infact use dns.resolve as far as I can tell.\ndns.lookup appears to benefit from one or other caching mechanism and subsequent queries are instantaneous whereas dns.resolve dns.resolve4 seems to be deprived of this enhancement which makes dns.lookup much quicker than dns.resolve in repetition. \n. Benchmarking the dns.resolve vs dns.lookup\nMeasuring both the synchronous lock time and the time it takes until we've received the last result;\nEnvironment:\nMacBook Pro 2.66 GHz i7 8G\nOS X: 10.8.5\nnode: v0.10.24\nresults looking up github.com for 100 000 iterations:\n\nmethodlocktotal\nlookup0.6s18.3s\nresolve3.9s5min 49s\nresolve43.7s5min 57s\n\nConclusion:\nIt is clear that resolve4 uses resolve and not lookup and that the latter responds quicker both in retrieving the results and synchronous lock time. \nChanging the superagent implementation to dns.lookup instead of dns.resolv4 should yield a large performance increase.\nNode console output by which results were retrieved if you would like to reproduce or audit these findings.\n``` js\n\ndns = require('dns');\nfunction resolve_bench(d) {\n... console.time('resolve-lock');\n... console.time('resolve');\n... a=0;\n... for (i=0;i<=100000;i++) \n...    dns.resolve(d,'A',function () {if (++a == 100000) console.timeEnd('resolve'); });\n... console.timeEnd('resolve-lock');\n... }\nresolve_bench('github.com')\nresolve-lock: 3946ms\nresolve: 349471ms\nfunction lookup_bench(d) {\n... console.time('lookup-lock');\n... console.time('lookup');\n... a=0;\n... for (i=0;i<=100000;i++) \n...   dns.lookup(d,4,function () {if (++a == 100000) console.timeEnd('lookup'); });\n... console.timeEnd('lookup-lock');\n... }\nlookup_bench('github.com')\nlookup-lock: 619ms\nlookup: 18256ms\nfunction resolve4_bench(d) {\n... console.time('resolve4-lock');\n... console.time('resolve4');\n... a=0;\n... for (i=0;i<=100000;i++)\n...   dns.resolve4(d,function () {if (++a == 100000) console.timeEnd('resolve4'); });\n... console.timeEnd('resolve4');\n... }\nresolve4_bench('github.com');\nresolve4: 3688ms\nresolve4: 357464ms\n```\n. @bminer ahh yes I was looking at the link you posted for the fetch library I see =)\n. tl;dr ie <10 does not support CORS, XDomainRequest is cross-origin perhaps but is not CORS, use JSONP instead or insist on non defunct browsers.\n\nI find the suggested implementation odd because CORS is not something of free choice that we need to specify in a client as this crossDomain method would subsequently suggest. It is particular to ajax requests made for resources on a destination that differs from the origin to which browsers would historically refuse to comply.  CORS is a mechanism by which the cross-origin server may instruct the user agent to lift the restriction and Allow the request when a particular Origin match was found.\nIt is not ours to modify the restrictions imposed by user agents, it is not possible to specify the value to an Origin request header nor instruct the browser to acknowledge Allow response headers (if you did manage to specify the former).  XDomainRequest does not follow the CORS specification and is therefor not compatible with CORS and even if we attempted futility the result is not compatible with the CORS compliant alternatives.\nJQuery did not adopt XDomainRequest and provide a list of compelling arguments. They conclude, I concede, that if you are prepared and really-really-really up for the torment then XDR is best implemented as an extension.\nAdvise mark as \"won't implement\" and close issue.\n. @jldec it is not clear what action you are proposing, perhaps a PR will shed more light.\n. @jldec ahh yes that makes perfect sense.\nImplementation and tests look good but I have a suspicion this will be required for the node.js as well.\nSee lib/node/index.js and test/node/toError.js perhaps.\nUnless this was only a problem in the browser version... please advise.\n. The node.js implementation also makes reference to req.path and will suffer the same consequences your patch is attempting to resolve for the browser version.\nUnless... is path not perhaps the desired functionality and the problem is that it is not populated in a 404 and we should address that instead of changing to url? \nIf these two implementations get out of sync however it will rapidly turn into a maintenance nightmare. \n. @jldec I think those differences are imposed by the difference in environments or am I mistaken.\nTwo wrongs doesn't make a right though and I would still encourage us to keep the two implementations as close as possible. Returning url in the one implementation and path in the other will surely result in confusion, would you agree?\nPlease don't get despondent, you found a valid bug and your solution resolves the problem. My aim is not to demotivate but instead encouraging us to look at every angle and find the optimum resolve. By raising the issue alone, don't underestimate the value in this, you have brought this functionality under the spotlight and who knows how long it would've remained unattended, did you never mention it. Kudos! We now have the unique opportunity to scrutinise and see what else comes to light.\nIf you found yet another discrepancy between the implementations then bonus! Lets address that as well =)\n. @jldec I am not sure what the original intentions were, perhaps the @visionmedia devs can elaborate, but if I had to guess I would imagine that:\n- url = the full schema + host + path, and\n- path = what remains when schema and host is removed from url\nOtherwise referred to as the Uniform Resource Identifier as defined in RFC3986 \nI am not sure which reference is preferable to use in the 404 message but I do believe that both should be populated and perhaps that is the root of the problem. I am not convinced that assigning both url and path to the same value is the desired conclusion though.\nThoughts? Suggestions? Discourse?\n. Agree that this should not be de-facto and can be added manually if required. The fact that chrome does the same should already be an indication.\nX-type headers are not specification services that rely on it are not specification.\nSuggest mark issue as \"Won't implement\" and close.\n. @jldec please note your PR is failing on the CI\n. :thumbsup: \n. @stephenmathieson this warning is implemented to avoid double callbacks and you should not be getting the warning.\nWithout any clue as to how your implementation is triggering this warning I will not attempt to thumb suck a cause. Can you try and isolate and produce an example (in the least amount of code) which causes this warning to appear? \nAnother related issue #290 which may provide additional clues but please don't refrain from providing the example snippet for future reference and aiding others.\n. In absence of the much needed cause of the problem as silver lining at least we can celebrate @stephenmathieson's issue resolved \\o/\nAdvise mark \"Works as intended\" and close.\n. Tx @jonasfj this will definitely help to narrow it down. You rock!\n. From the code it is obvious that the double callback was prevented, the warning however raises alarm that this is a problem but we already circumvented the problem when the warning was raised.\nThe questions that remain:\n- is this a problem or does the raised exception sufficiently solve the problem?\n- is double callback the only problem and no other concerns remain?\n- do we have to raise exception or would simply avoid on condition with an if and return suffice?\n- do we have to raise a warning or would console.info or console.log suffice?\n- if message is desired can we come up with better wording to address these questions?\n. ",
    "eivindfjeldstad": "hmm. It's fairly easy to detect. If I remember correctly, IE8 throws when you do req.open('PATCH' ...); so we could do something like\njs\ntry {\n  var req = new window.XMLHttpRequest();\n  req.open('PATCH', '/', true);\n  req.abort();\n} catch (err) {\n  brokenPatch = true;\n}\nand just use ActiveXObject instead. @gjohnson, would you accept a PR?\n. The issue is how Component does the lookup. Should probably be fixed in the Component repo anyways, but this was the only thing i had time to do ATM\n. ",
    "thomaspons": "I've found this fix mayber merge it ?\nThese lines must be put under :  var mod = exports.protocols[url.protocol]; (line 580)\nif(process.env.http_proxy) {\n    var proxy = parse(process.env.http_proxy);\n    options.port = proxy.port;\n    options.path = this.url;\n    options.host = proxy.hostname;\n    mod = exports.protocols[proxy.protocol];\n}\nBut now i've got another issue my corporate proxy block the post method and send me a 501 ! I don't know why.\nHere the original patch for superagent : https://gist.github.com/shigeki/2921169\n. It works as well as the code above. The 501 error is normal my proxy SQUID is too old and doesn't support HTTP 1.1\nBut what about have a proxy method in superagent wihout passing by another module ?\n. ",
    "zhangjunmin": "did you solve your problem?\nnow I  have the same problem.\ncan you share your answer with me, thanks?\n. ",
    "rufuspollock": "@gjohnson quite right - and I noticed that too soon afterwards. Options here are remove or update (back-integrate gh-pages branch docs?)\n. ",
    "binarykitchen": "PS: currently I have something like this:\n.end(function(res) {\n                    if (res.ok)\n                        if (res.headers.location)\n                            // do not use window.location.href when coming from a post,\n                            // this to avoid a never ending back-button fiasco, see:\n                            // http://stackoverflow.com/questions/503093/how-can-i-make-a-redirect-page-in-jquery-javascript\n                            window.location.replace(res.headers.location);\n                        else\n                            log.error('New video created but new location is missing!');\n                    else\n                        log.error(res.text);\n                });\nbut not sure if this looks good. To me, it looks kind of ugly ...\n. thanks man. yeah, i use that snippet on the client-side.\nok, good to know you said my code is ok. but i was thinking of something new like location in the chain:\n```\nrequest\n  .post('/api/pet')\n  .send({ name: 'Manny', species: 'cat' })\n  .location()\n  .end(function(error, res){\n});\n```\nprobably one pitfall: end() is never called after a location.replace ... just a thought. Ignore my comment if you think it is not necessary to add more stuff for the superagent.\n. Any news on this one? This error is bugging me ...\n. I understand what you did @jldec but I think this should be sorted out among superagent's core developers. Since I do not know the internals, it would take me too long to submit a PR.\n. Right. I reckon I have to solve this the other way around with a couple of changes in my application logic. Ticket closed for now.\n. Very interesting, thanks! I wont quote you ;)\n. Do you use the latest ExpressJS version on the server side?\n. Well it could be possible that an ExpressJS middleware is modifying a header ... any chance you could give it a try?\n. Correction: There are zero contents in my case. I am doing a simple GET request to retrieve a list of videos for my single page app. Hence I think type-is should also work for that case.\n. Sure @dougwilson, ticket closed! My comment here explains why https://github.com/expressjs/type-is/issues/5#issuecomment-40073471\n. ",
    "ayanamist": "@gjohnson Have you test buffer method?\n``` js\nvar http = require(\"http\");\nvar agent = require(\"superagent\").agent();\nvar mockServer = http.createServer();\nmockServer.on(\"request\", function (req, res) {\n  res.end(\"asdfasdf\");\n});\n// port 0 let operation system choose port\nmockServer.listen(0, function () {\n  var mockPort = mockServer.address().port;\n  agent.get(\"http://127.0.0.1:\" + mockPort + \"/\").buffer(true).end(function (res) {\n    console.log(res.body);\n  });\n});\n```\nstill got {}, nothing changed.\n. OK, i just debug it by myself.\nThe problem is:\nlib/node/index.js#L744 calls lib/node/parsers/text.js\nAll text data are collected to res.text, however, callback fn are called without any arguments, and lib/node/index.js#L747 makes res.body become undefined\nThen in lib/node/response.js#L36 this.body = res.body || {}; makes body become {}\nNow what i get is {}\nThe problem is that, lib/node/parsers/text.js is too simple to handle anything.\n. @hallas OK, i misunderstand them.\n. @gjohnson I got it, thx.\n. ",
    "fernandopasik": "Thanks!\n. ",
    "Jaymassena": "Cool.\n. ",
    "fgnass": "@hallas the error is:\nError: Cannot find module 'reduce'\n    at module.exports.cb (.../node_modules/browserify/node_modules/browser-resolve/node_modules/resolve/lib/async.js:45:17)\n. Why don't we just use the npm version of reduce instead of downloading it from GitHub via user/repo? My guess would be that the failing Travis builds occurred when it couldn't reach the GitHub server. Pulling all dependencies from the same place sounds like a good idea to me.\n. Because it is a dependency of client.js which is part of this package. We either have to include it or we have to split it into two separate modules (one for node and one for browsers).\nBTW, whrere does component.js get the dependency from? I assume it's broken there too?\n. Ah I see, it's in component.json\n. ... so the third option would be to drop the browserify support, I guess. \n. Well in that case you should probably revert #259 too and update History.md so that others don't step into the same trap as me and think browserify was actually supported.\n. @visionmedia user/repo works just fine with browserify. If I understand the old issues correctly there were some random test failures on Travis CI.\n. ",
    "ben-crowhurst": "Was a solution found for this issue?\n. ",
    "kamikat": "The point is that  HTTP streaming feature is not supported by an Nginx server configuration.\nThe solution is to add a custom Content-Length header to the request (which may requires a dirty code calculating the size of request body) or, just enable HTTP streaming on the Nginx (which may significantly limit the performance of Nginx proxying).\n. ",
    "wejendorp": "+1.\nNot a superagent fix, but here is a workaround I am using in my tests:\nvar req = http.request({\n  hostname: '127.0.0.1',\n  port: server.address().port,\n  method: 'POST',\n  path: '/test'\n}, function(res) {\n  assert(res.statusCode == 200);\n  done();\n})\nreq.write(buffer);\nreq.end();\n. ",
    "jamlen": "I'd like to see something like:\njavascript\n    request\n      .post(config.endpoint)\n      .set('Authorization', 'Bearer ' + token.secret)\n      .send(json)\n      .on(403, function(error){ self.emit('forbidden', error); }); \n      .on(404, function(error){ self.emit('notFound', error); }); \n      .on(418, function(){ makeABrew(); }); \n      .on(500, function(error){ self.emit('serverNotAvailable', error); }); \n      .on('error', function(error){ self.emit('dataTransmitError', error); }); \n      .end(function(res) {\n         // ...\n       });\nWould this be feasible? Any comments?\n. Appreciated, but it does lead to a large if..else block, which I dislike more ;)\n. @defunctzombie Fair point, I've only been using SuperAgent for about 3 weeks...and node for about 4 so I'm rather green! What is a better approach then?\n. ",
    "dcousens": "100% agree on this.  That magic around the function arity is a real pain.\n. Although I agree with @kmalakoff that only in the event of an actual exception should the err argument be not null,   I can't help but recognize ow much I personally rely on an error for things like a 404 intuitively which, obviously, is a valid response. \nThat said, I guess I'd just quickly adjust to that and enforce the expected status code everywhere.\n. +1\n. Any word on a publish?\nOn 22 Feb 2015 6:01 pm, \"Roman Shtylman\" notifications@github.com wrote:\n\nClosed #450 https://github.com/visionmedia/superagent/issues/450.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/450#event-239719766.\n. \n",
    "kmalakoff": "Following up https://github.com/visionmedia/superagent/pull/554 and https://github.com/visionmedia/superagent/issues/580....\nThe new API is non-standard for Node.js callbacks. The request was successful so there should not be an error (eg. you can check the response status code). Only if the response cannot be returned should there be an error, eg. failed to parse the body.\n. Thank you for discussing this. I see your perspective about non-successful http responses. \nMy arguments would be:\n1) if there is a response then I'm not convinced this is an error but a successful response with a non-success status. There's potentially data with it in addition to the status code that may be handled (for example, besides the status code, we also parse XML from S3 to check for request retry-ability: http://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html). \n2) superagent provides a res.ok helper specifically for this purpose.\n3) as a minor point around conventions/API design, I wouldn't expect a Node.js callback to return both an error and a value in the second parameter that needs to also be optionally checked. The new API is non-conventional and a bit messier now since it requires more validation logic to check the optional second parameter.\nWe would have to change 50+ calls because of this change to upgrade to 1.0.0 so let's get it right. What do other people think?\n. > I will add tho that parsing errors can also have responses so the issue with error having been only for network or when no response is not quite accurate.\nThis is a good subtle point to mention since there would be a response. In this case, I think a property on the error makes sense since there was not an error in the request, but an error processing the body of the response. Personally, I would treat this as a different case to a response with a non-successful status code, where I would still expect the arguments to be (null, res) since the request was successful even if the response status code indicates non-success, e.g. error are only for actual error control flow not non-success statuses. \n. @defunctzombie understood. I'm not sure if the subtlety was clear.\nWhat my recommended approach is that only in the case of there being an actual error would the response be put on the error. So for all successful requests regardless of status code: (null, response) and for errors (_.extend(err, {response})). \nBasically, I agree with the single parameter principle for Node-style callbacks and prefer error argument only when there is an actual error like a parsing error.\n. @basti1302 I think your argument is a false equivalence argument using an old-fashioned/jQuery-like success/error pattern.\nWe use Node-style callback as our preferred pattern for browser and server code, and we follow that convention strictly. This is what partially drew us to superagent in the first place...a cross-platform API based on Node.js conventions.\nIf superagent provides a node style callback pattern, it should follow the Node convention. If superagent provided an old-fashioned/jQuery-like success/error API, it would make sense to follow those conventions. Same if it provided a promises-based API, it should follow those conventions.\n. @dcousens it's funny, but I feel exactly the opposite. I totally see that people coming from a jQuery background would have different expectations since they are using a different convention. \nI bet it is that when I found superagent, the Node convention made much more sense to me than the way jQuery did this determination for you in a forced branching code flow between success/error. If I HEAD an endpoint with the purpose to check if a resource exists, I check the response's status code for a 404. I doesn't feel like the request failed but just a successful request/response cycle to check if a resource exists so (null, res) feels correct. It is subjective on whether the 404 is an error or an expected response status code so it feels like it is the application's responsibility to classify not the library's. An error in Node-callback conventions is a very serious proposition....\nIn https://github.com/visionmedia/superagent/pull/554, @rauchg wrote:\n\nIt's a really bad idea to consider HTTP-level error codes actual errors. Maybe a better way to think about it is, is a stack trace helpful at all for a 404? That's certainly not an Error.\n\nI wish the 1.0.0 change wasn't made in the first place because it makes it harder to switch back if people are now in the process of changing their code. We're still locked at 0.x awaiting the final call. \n@defunctzombie are you staying the course, reverting, needing more input, or still considering?\n. @defunctzombie I'll explain a little further using @rauchg's unexpected outcome refinement......\n\nHere the server sent back a response, just not a valid/parsable one and we error. Technically in that case we too should not have the error object because the server sent you a response?\n\nIf you receive a response, you should use the (null, res) signature because you expect a response to the request regardless of the status code. But because superagent has an helper API layer for parsing those response bodies, you also expect a parsable response but if you did not get one, it is an error and so in this case returning an error makes total sense (eg. an actual error due to malformed JSON, XML, cookies, etc) so the (_.extend(err, {response})) signature is right in this case because it is an actual error with the response because it is invalid. \nThe first case is expected whereas the second case is unexpected and would require investigation (eg. stack trace, looking into the parser, looking into the server that sent the response). \nI think using this sort of rationale keeps the responsibility of the two superagent API layers much cleaner and more intuitive. I do agree with and like the error with a response property solution for actual errors.\nIs this more clear in explaining the differences on when a user of superagent would expect to receive a response vs an error signature? \n. @defunctzombie just wondering if you have an update on this? It is totally fine if you disagree or need more input. \nI just want to know so I can decide about forking superagent or not to get the benefits of the latest fixes and features.\n. > We could have something like a .success() and .error() handler that are mutually exclusive (in a way) with .end(), where any response that qualifies as a valid response currently would end up in .success(), and any errors plus error status codes would end up in the .error() callback.\n@rase- I really like that solution. :+1:\nIt's in alignment with what I wrote before about expectations against conventions:\n\nIf superagent provides a node style callback pattern, it should follow the Node convention. If superagent provided an old-fashioned/jQuery-like success/error API, it would make sense to follow those conventions. Same if it provided a promises-based API, it should follow those conventions.\n\nWe don't use anything but the .end (err, res) signature since we use Node's callback pattern across all of our client and server code. We never use .on 'error'or the .end (res) signature. We'll never use the .success/.error signature, but those people who come from a jQuery background would find it the most familiar and in alignment with their expectations.\n. @landau obviously someone thought the same way in the past. Must have been someone with a Node background...maybe who maybe no longer likes callbacks or Node... :sweat_smile: \n. @drypot I wouldn't modify thousands of tests if I were you. \nI'm happy to fork superagent to put back the old functionality. It there is enough interest, I'll even do it this weekend.\nI just need a name...I'm thinking superagent-ls  ...'ls' for less suck ;-)\n. @defunctzombie totally disagreed, but it is your choice. The problem isn't that there is a breaking change, the problem is:\n1) that the change breaks the Node callback conventions\n2) is against the original design philosophy of superagent \n\nNote that a 4xx or 5xx response with super agent is not considered an error by default. For example if you get a 500 or 403 response, this status information will be available via res.error, res.status and the others mentioned in \"Response properties\", however no Error object is passed for these responses. An error includes network failures, parsing errors, etcetera.\n\nForked: https://github.com/kmalakoff/superagent-ls and https://www.npmjs.com/package/superagent-ls. I'll aim for a first release the weekend.\nI'm happy to accept for issues and pull requests for this fork. \nPlease star and use the superagent-ls repo to show your support for reverting the 1.x API  :smirk: \n. @defunctzombie imagine the amount of work that has been created for the 3500+ users of superagent (not only developer time to update all calls and tests, but QA time to test our applications and libraries) and how many of us who do not agree with the change in the first place.\nI think the better option is to revert the API change and introduce the success/error pattern. \nI will spend my personal time this weekend updating superagent-ls and make a pull request to make the revert easier.\n. superagent-ls has been released on npm: https://www.npmjs.com/package/superagent-ls and component.io\nPlease star and use the superagent-ls repo to show your support for reverting the 1.x API  :smirk: \n. @aseemk I think you are right that Superagent is at a lower transport level, but unfortunately, there are legacy decisions that make it hard to use as a transport level. Superagent would really need a better API without globals and a more well-defined middleware API so that library writers could configure it without stomping all over one another.\nIdeally, this sort of setting would be configurable in isolation so if I develop libraries that adhere to Node.js callback conventions, but other people are more familiar with browser interpretations of status codes we could do as we prefer. \n. I'm still maintaining superagent-ls for the day sanity rules again :wink:\n. We are also encountering this...streaming is broken in 0.18.1. The response has all of the image data.\n. I used the xml2js example to give you something concrete to think about. \nThere is a critical difference between the server and browser responses, one is stream based and the other is not. This means one is async and the other is synchronous. That means that because I am writing a cross-platform parser, I have this weird situation where the parser methods have the same names, but have different functional signatures and like in this case where I want to use an open source module that only supplies an asynchronous API, I have no way to make it work except to override the superagent end method.\nBy closing this, does this mean you are unwilling to track this API inconsistency problem for future consideration? I would prefer if superagent kept things consistent and simple by supplying a single asynchronous interface across browser and server.\n. I don't think this is the right way to look at it....\nThe browser can provide asynchronous interfaces and streams are coming. Today, we are using streams with pipe on the client through browserify/webpack, but I do not believe that is right for everyone so it should not be pushed onto them. Asynchronous APIs should be considered differently than streams. \nOf course, there are some differences like you mention that won't make sense because of cost/benefit (eg. pulling in a client side stream),  adding additional/unnecessary complexity, etc.\nWhat I am saying is that superagent should aim to minimize the differences since besides its awesome API, one of superagent's main value propositions is around creating consistency across the client and server.\n. That's totally OK I appreciate you leaving this open.\nThe concept is simple: review the API and tests for differences between the browser and node version of superagent, try to remove as many of the differences that a user or hooks for library author would encounter, and document the rest with the reasons (like your streams argument where because of the cost/benefit, it isn't the right thing to do). \nI would probably add this principle of \"striving for sensible API parity\" to your contributing guide as well and you accept/reject contributions based on it\n. I don't think this is a good API change. We are totally happy checking the res.status and leaving errors for actual errors like a body parsing error.\nWhat do other people think?\n. @defunctzombie has chosen to stay the course on this change despite:\n1) that the change breaks the Node callback conventions\n2) is against the original design philosophy of superagent \nForked: https://github.com/kmalakoff/superagent-ls and https://www.npmjs.com/package/superagent-ls. I'll aim for a first release the weekend.\nI'm happy to accept for issues and pull requests for this fork. \nPlease star and use the superagent-ls repo to show your support for reverting the 1.x API  :smirk: \n. superagent-ls has been released on npm: https://www.npmjs.com/package/superagent-ls and component.io\nPlease star and use the superagent-ls repo to show your support for reverting the 1.x API  :smirk: \n. Wow! This is not a good API change.\nDown-vote. We'll stick with 0.x.\n. I've added a comment on https://github.com/visionmedia/superagent/pull/554\n. @defunctzombie has chosen to stay the course on this change despite:\n1) that the change breaks the Node callback conventions\n2) is against the original design philosophy of superagent \nForked: https://github.com/kmalakoff/superagent-ls and https://www.npmjs.com/package/superagent-ls. I'll aim for a first release the weekend.\nI'm happy to accept for issues and pull requests for this fork. \nPlease star and use the superagent-ls repo to show your support for reverting the 1.x API  :smirk: \n. superagent-ls has been released on npm: https://www.npmjs.com/package/superagent-ls and component.io\nPlease star and use the superagent-ls repo to show your support for reverting the 1.x API  :smirk: \n. There is the middleware approach that also might work:\nrequest.post('/url')\n  .use(parser)\n  .end (err, res) ->\nOr even specialized functions:\nrequest.post('/url')\n  .parser('application/xml', xmlParser)\n  .end (err, res) ->\nIn either case, by default superagent could first register the defaults and then overrides or new parsers could be added by the caller.\nI think the question comes down to whether having globals for superagent makes sense in a world where it it used inside libraries who cannot control what others set.\nFinally, we have created what we call a superagent factory which abstracts out the get, post, put, head, del functions (plus default signature variants) so that we can derive and create defaults from request.Request. This could be a way to allow library writers to define their own base Request class with their own defaults.\nLot's of ideas...it would be great to agree a direction for library writers. Personally, I avoid globals so I would even support a proposal that went as far as deprecating them.\n. Sure, with monkey patching, keeping the global settings problems unaddressed, etc.\nI'd like to see what people think is the best API for safe usage of superagent across libraries and modules. \nWe have created a superagent factory for subclassing Requests which could be part of one approach if they get their own configuration settings. Maybe exposing the parsers and serializers on the Request with chaining helper methods could be another approach. I think either of these are preferable to using middleware to monkey patch superagent\nAlso, some of the problem with the current middleware design is that it often requires monkey patching because there is not a clear flow for modifying requests pre-flight vs responses post-flight. If you were to suggest a middleware-based solution to modifying parsers and serializers, you should consider these two paths for library writers in addition to the use of global settings. If you find considerations to both these problems, it could also work.\n. We have implemented a way to serialize and deserialize nested query parameters in BackboneORM with little code, but we also force a strict JSON interpretation of query parameters to allow for couch-like query syntax by URL.\nserialize: https://github.com/vidigami/backbone-orm/blob/master/src/lib/json_utils.coffee#L75\ndeserialize: https://github.com/vidigami/backbone-orm/blob/master/src/lib/json_utils.coffee#L61\nI could be wrong, but are nested queries not a standard meaning wouldn't developers need to find/implement and include custom query parsers on the backend of their choice to match the query-string implementation? eg. maybe this better left to user-land\n. It's tough because of the current asymmetric behaviour between browser and server. People expect consistency (https://github.com/visionmedia/superagent/issues/549).\nOne could argue that this should be treated at the middleware or user-land level both for node and the browser to enforce consistency. If superagent is easy to configure at a library level (https://github.com/visionmedia/superagent/issues/591), it shouldn't be a problem for someone to register query-string once on browser and once on the server for all the instances they control (or whatever their case use may be) and then match the parsing with the backend of their choice.\nAlternatively, instead of throw, you could log a warning with an explanation of the inconsistency for the reason of bloat-control along with a solution.\n. @defunctzombie I am not the only one who is unhappy with the change. You have now heard from others in the issues.\nLike many others, we have chosen the superagent library as our go-to solution for HTTP on client and server. You made a significant change to the API which affects us deeply and that like myself, many people do not agree with because it breaks the Node callback convention that all users would expect regardless of being new or not.\nI let you know as soon as I found out about this change, I engaged your arguments in the issues (https://github.com/visionmedia/superagent/pull/554, https://github.com/visionmedia/superagent/issues/283), I was not convinced by your arguments, and I was forced to fork the repo. \nObviously, this is a tough decision to reverse because it means people who upgraded to the new API need to again revert chose changes. I get that. Unfortunately, it is also the right thing to do.\nHey, the benefit of open source is that we can all help make things better. I'm just trying to help. \n. Great!\nNot sure if streaming can be detected because we pipe the stream in the end function after the parsers have been applied and status codes have been checked.\nDisabling parsers or forcing streaming (server only) could be selected via an option or chained function, but this brings back to the question of whether there should be global parsers or isolated instances of superagent with their own settings as alternative API change options. \n. OK. I've reviewed the code and wanted to run a few ideas by you...\n1) should the image parser still be bundled with superagent? For example, I could move it into a module like superagent-parser-image. I think the parser is quite simple so this might be overkill, but depending on 2), it might still be best to keep superagent lean.\n2) it looks like there is some custom type checking logic (https://github.com/nebulade/superagent/commit/c65b7758bced00c656bf6ae6734cc39c3e7007a0#diff-c24ce7e3da4c0e4ff811a2b6a76f8bd9R728) which if it is moved to a library, will need a way to be hooked up. The logic is basically extracting the major type (image) before the slash and using that as the check. A few options:\na) allow parsers to be registered by major type, eg. image. Of course, it doesn't make a lot of sense for 'application/*' lookups. This would be quick and dirty, but probably handle most cases.\nb) expand and generalize the \"type to parser key\" lookup API. Unfortunately, this would require people to know that they may need to register in two places (one for the parser name and another for the parser itself). For example, isText and isImage would register custom typeToParserKey functions and the parser key would end up being a name for the parser instead of a mix of types and keys.\nc) move away from the object/key lookup and add API that either takes a function or key, and the parser (stored in an array). It could work both at the global level and the Request instance level:\nGlobal API\nrequest = require 'superagent'\nrequest.parser(isImage, parseImage) # only this format would be supported for non-string keys\nrequest.parser('application/xml, parseXML) # or request.parser({'application/xml: parseXML})\nand/or\nLocal API\n```\nrequest = require 'superagent'\nrequest.get('/images/1234')\n  .parser(isImage, parseImage)\n  .end (err, res) ->\nrequest.get('/xmls/1234')\n  .parser('application/xml', parseXML)\n  .end (err, res) ->\n```\nI kind of think 2 is the worst API, but either 1 or 3 could be acceptable.\nThoughts? I'm happy to implement this, but if 2 or 3 is chosen, it could bump superagent's major release number.\n. This change would need to handled very carefully. \nIf any user of superagent can re-define the range globally, they may unintentionally break libraries they use that also have expectations on range. That could lead to library writers having to query the range to program defensibly against uncertain configuration.\nTo properly implement this, changing the range could necessitate the ability to create instances of superagent each with their own configurations (https://github.com/visionmedia/superagent/issues/591). \nAlternatively, the range could be set on individual requests, but that could be cumbersome.\nFinally, we could just go back to the 0.x API and more strictly limit superagent to the transport layer instead of mixing in logic that is best left in the application/user-land.\n. Interesting. Maybe this should be the answer for range mapping in general. \nIf you could have people who want it add it to their request instances using existing mechanisms (add it to their instances) or those of us who don't want it, to be able to ignore the setting (skip it) or those who want it differently, set a different mapping (add It with a different range), that might make everyone happy rather than making the decision for users of superagent.\nOr you have the current default range mapper added to each instance and provide a mechanism to clear it or set a different rangeMap function per instance.\nIf instance-based configuration is the way forward, we could create our own factory function for requests that set up instance defaults like disabling range mapping. \nWould you consider rather than using an existing monkey-patching API, adding a specific API for range mapping?\n. Reviewed https://github.com/visionmedia/superagent/pull/617 and it looks good.\nWe internally have an agent factory that takes a Request class and some options and we have started to use it more (three concrete cases: retry, file uploader with retries, multi-step image uploader with retries). I'd probably add one more for superagent with the acceptedStatus default off.\nWe haven't tackled the global settings problem since it would require monkey-patching suepragent so probably instances work just fine if we use our own factory.\n. Good stuff. \nWe should probably try to keep the code to a minimum. Some feedback:\n1) Perhaps the regex code should be an optional, user-land thing that should just be wrapped in a function that can be set using the same api. My guess is that will be rarely used.\n```\nstatusRange = require('accepted-status-range')\nreq.get('/')\n  .set({ Accept: 'application/json', 'X-API-Key': 'foobar' })\n  .acceptedStatus(statusRange(['2xx', '4xx', 500]))\n  .end(callback);\n```\n2) Maybe you could set the default in the constructor and make it easy to clear:\n```\n// By default 2xx status codes may pass\nthis.statusFilter = function (status) {return status >= 200 && status < 300;}\n// no need to a helper method\nif (!this.statusFilter || this.statusFilter(res.status)) {return self.callback(err, res);}\n```\nreq.get('/')\n  .set({ Accept: 'application/json', 'X-API-Key': 'foobar' })\n  .acceptedStatus(-> return true) # or .acceptedStatus(null) or .acceptedStatus() all work\n  .end(callback);\n3) Not sure about whether the naming could be improved? Some ideas:\n- errorStatus\n- isError\n- isStatusError\n- statusError\n- acceptStatus\nNone of these are great, but just some thoughts in case it spurs some better ones or increases the convictions for the current one....\n4) We could make a global setting so that people can set things globally if they know they are the only instance running.\n// By default 2xx status codes may pass\nrequest.statusFilter = function (status) {return status >= 200 && status < 300;}\nrequire('superagent').statusFilter = null # disable status filtering globally\nthis.statusFilter = request.statusFilter\n. @rase- I wouldn't look at a simpler API as primitive. It provides a good API that matches most user's use cases with little customization boilerplate (just set a function, usually a conditional expression) and that has the necessary hooks for more advanced functionality like your regex approach. If there was a lot of boilerplate involved or specific needs couldn't be met with the simpler API, I would agree with you. \n@thanpolas there's many discussions on this topic already, but the decision has been made so we are now into workaround territory. I'm maintaining superagent-ls  for people who believe interpreting status codes should not be part of core, superagent is more of a transport layer, and that the node callback conventions should be adhered to.\n. @defunctzombie there are a multiple recommendations. Can you clarify?\nAre you saying that you do not like the regex status range implementation which changes an array to a function? If so, I'm proposing that that functionality not be included in superagent since it is unlikely to be used and can be provided in a user land module.\n. I think superagent core should be light and provide the hooks needed to customize behavior, but not bundle seldomly used behavior that is better implemented in user land. It just adds library bulk that must be tested and maintained moving forward.\nAccordingly, I believe the regex is unnecessary and unlikely to be used since it is very easy with a simple function containing a conditional to provide similar functionality.\nAs for the:\nthis.statusFilter = function(status) {\nComing from a CoffeeScript background, it just looks like setting an instance/member variable with a function and I wouldn't classify it as a (monkey) patch since it doesn't add to the external API. Maybe you would prefer naming of instance variables with underscores to indicate their internal scope and not extending the API?\nthis._statusFilter = function(status) {\n. It looks like from https://github.com/visionmedia/superagent/issues/647 that there is already a module to add promises.\nWhat is the best way to give superagent users choice?\n. ",
    "basti1302": "This is a major breaking change, yet, as far as I can see there is no mention of it in the change log for 1.0.0 (https://github.com/visionmedia/superagent/blob/master/History.md is the changelog, or is there something else that I have overlooked?).\nI think this change should be there in big bold letters. The way it is now, I had to find out about this change the hard way (my tests failed, debug them, find the piece of code that changed in superagent, check the git history of the lib/client.js until finally arriving at this issue).\nPS: I really don't like the change, for my feeling, a successful HTTP request with a non-200 error code is fine in some situations. but that's certainly a matter of taste and I can see why people have different opinions.\nPPS: That said, superagent is an awesome library, so thanks for this.\n. Wow, thanks for this detailed answer.\nOn second thought, what you say makes sense. I use superagent more like a tool doing the raw HTTP business for me. In that context, I personally would have preferred that superagent handles all HTTP status codes transparently and leaves me to interpret them. But superagent advertises itself as an Ajax library (Ajax with less suck, right?) and this gives things a slightly different perspective. Probably for most use cases this change is for the better. \n\nI will add that breaking existing code is in my mind insufficient to say this change is \"bad\".\n\nI never inteded to say that it's bad because it's a breaking change. I'm all for breaking changes. You upped the major version first digit, so that's totally fine.\n\nMissing entry in changelog is an oversight on my part. I will add that.\n\nI kind of did that already, see #584 . Feel free to ignore this and use your own wording if you prefer, though. Also, #583 seems to kind of duplicate this but also brings up a good point about updating  http://visionmedia.github.io/\n\nI even added a wiki page for migrating from 0.x to 1.x\n\nMaybe adding a link to that wiki page directly to the Readme in a prominent place would be a good idea.\n. > change to treat non 2xx codes as errors; this change doesn't make sense to me, because it is very uncommon for a library [...] Personally I don't know another library that behaves this way.\nMaybe it's better to compare this with how other http libs handle this cases than comparing it to DNS or cookie parsing libs.\n- jQuery Ajax distinguishes between success and error callbacks. The success callback is only called for http status 200-299, other http statuses end up in the error callback. So that's very similar to superagent@1.0.0's behaviour (also technically the callback style is different, judging what is an error and what not is the same).\n- AngularJS' $http: https://docs.angularjs.org/api/ng/service/$http also uses success and error callbacks. Same as jQuery, same as superagent@1.0.0.\n- request/request: Handles http status codes like superagent@0.21.0, that is, no http status codes creates an error.\nSo obviously both ways are well known patterns. Actually, I think superagent is closer to jQuery.ajax and AngularJS' $http than to request/request.\nAlso, all your examples of use cases for 3xx/4xx status codes are about tests...\n. FWIW, there is already an upgrade guide. It's just not linked to or advertised anywhere, so nobody will see it.\nhttps://github.com/visionmedia/superagent/wiki/Migrating-0.x-to-1.x\n. Stumbled upon the same issue just now: Location header in response visible in network tab but not in the response object. I think the answer given by @roshanraj is not quite correct. The location header is indeed stripped away by the browser if this is a CORS request and the CORS headers of the response do not allow the location header to be exposed. The CORS header in question is Access-Control-Expose-Headers. If the response has Access-Control-Expose-Headers:Location, then the browser exposes the Location header just fine and superagent yields its value happily.\nSo, if you have control over the server side, you just need to set this header. If you are for example using express with the cors middleware you could do something like:\napp.use(cors({                                                                 \n  exposedHeaders:['Location'],                                                                                                                         \n}));\nHope this helps the next person which googles for \"superagent response location header\" ;-)\nSee also: http://www.w3.org/TR/cors/#access-control-expose-headers-response-header\n. ",
    "insin": "Errors returned as a result of a successful response's error status code don't have a .status as discussed above - is this a bug?\nWith 1.0.0, I have to check err and check if res is null or not when determining if I want to deal with client errors myself but pass off request errors or server error responses to an error handler.\n. Having used 1.* for a bit, I think removing the pre-1.0 sugar which let you pass a callback to end() with only a res argument was worth making a breaking change for, for the sake of consistency with errback-style APIs..\nNode-style callbacks and having the same API on both sides of the HTTP divide are what drew me to superagent in the first place over other libraries which use success/error style callbacks.\nForcing an (err, res) callback is consistent with that, but I think the change to populate err on 4xx and 5xx response codes introduces a new inconsistency - it makes err part of the normal flow for handling bad user input, which is a common scenario if you're doing things like navigation and form submission using superagent.\nThe pre-1.0 behaviour was clearly a design decision rather than an accident, since it was explicitly called out in the docs, and I now don't think it's worth breaking code where people were already using (err, res) callbacks and were expecting to handle a 4xx error by inspecting res.\n. An upgrade guide .md would be useful. I'd be willing to contribute to it, but I'm still trying to divine the correct way to deal with 1.0.0 changes from commit notes and issue discussions.\ne.g. if I can deal with a client error, but not a server error, and I used to be using a single argument callback which only took res, is this now the pattern that's required for error handling in the callback?\njavascript\n(err, res) => {\n  if (err && (!err.status || res.serverError)) {\n    return cb(err)\n  }\n  // ...\n}\n. Sweet, thanks!\n. ",
    "mdebruijne": "Hi @defunctzombie,\nI was also bitten by this API change without a warning in the release notes. These things can happen and your work on SuperAgent is really appreciated!\n\nHearing more yay or nay here will help me identify of this should be reverted. Obviously until released no one cared so happy to have the discussion now.\n\nMy two cents;\n- change to mandatory error object in the callback; with a big warning of this API change in the release notes it is easy to sed over codebase to add the error object to the callback. If it makes your life easier then go for it.   ;-) \n- change to treat non 2xx codes as errors; this change doesn't make sense to me, because it is very uncommon for a library to generate an error object based on the content outside of its own scope. Personally I don't know another library that behaves this way.\nAnalogies to different libraries;\n- DNS library generates an error on a successful DNS A-record query, because it doesn't like the returned IP address\n- cookie-parser generates an error, because it doesn't like the cookie content\n- mongoose generates an error, because it doesn't like the contents of a document\nTo me, these analogies are the same as a \"raw\" HTTP library that generates an error, because it doesn't like the content (response) on a successful HTTP request.\nThe library does a request and can receive a response, doesn't it make sense to put the response in the response object instead of putting the response in the error object? Only if it doesn't receive a response then return an error object.\nAlso, non 2xx codes like, 301/302, 401 and even 404 can be desirable/mandatory in a lot of situations;\n301/302; test the redirect from http to https\n401; test if data is not accessible without authentication\n404; test if data is not accessible outside of the organisation network\nIf any of these tests return a 2xx code then security is broken in the application or infrastructure, but now the SuperAgent HTTP library considers everything is working as expected. If the application is not broken and all security rules function as expected the SuperAgent HTTP library now considers this an error.\n\nI even added a wiki page for migrating from 0.x to 1.x\n\nIs it possible to add the link to this wiki page in the release notes? I was not able to find it.\nAgain, many thanks for your work on SuperAgent!\n. Thanks for sharing your valuable insights, it is really appreciated.\nI guess the different expectations are based on comparing SuperAgent with backend/testing libraries versus comparing SuperAgent with frontend libraries.\nIf you look at SuperAgent from a frontend perspective then it makes more sense to make it behave like other frontend libraries like AngularJS and jQuery. You still need to look very closely to the details. For example AngularJS doesn't use the error object with redirects, but SuperAgent does.\nIn the end, it really doesn't matter that much as long as (changes to) the behavior is well documented.\nFor the people who use SuperAgent as a backend/testing library;\nafter a sed from .end(function (res) to .end(function (err, res) all tests work as expected with SuperAgent version 1.1.0 (we test for almost all HTTP scenarios/return codes).\n. ",
    "nw": "FWIW.\nDojo, Prototype, Mootools, YUI (io) all follow the same pattern as well.\nTreating anything above 2xx as an error.\nThings I found interesting:\n- Prototype allows one to register on2xx, on3xx, on4xx and on5xx\n  listeners that when set override the simplified success and error\n  listeners.\n- Mootools allows passing your own custom isSuccessful function to\n  override behavior.\nOn Fri, Mar 13, 2015 at 4:52 PM, mdebruijne notifications@github.com\nwrote:\n\nThanks for sharing your valuable insights, it is really appreciated.\nI guess the different expectations are based on comparing SuperAgent with\nbackend/testing libraries versus comparing SuperAgent with frontend\nlibraries.\nIf you look at SuperAgent from a frontend perspective then it makes more\nsense to make it behave like other frontend libraries like AngularJS and\njQuery. You still need to look very closely to the details. For example\nAngularJS doesn't use the error object with redirects, but SuperAgent does.\nIn the end, it really doesn't matter that much as long as (changes to) the\nbehavior is well documented.\nFor the people who use SuperAgent as a backend/testing library;\nafter a sed from .end(function (res) to .end(function (err, res) all\ntests work as expected (we test for almost all HTTP scenarios/return codes).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/283#issuecomment-79514517\n.\n. It does! I believe this change hasn't been published on npm yet.\n. I think the change is a tad unintuitive and mixing layers. My mental mapping has been error is when something bad happened with the communication itself. Sure a 500 is bad but the server responded and the response is well formed. It is up to my app to handle. This for example could be throttling requests when getting a 420 from twitter, its not that my request was bad. It is a state \"above\" the TCP layer that needs to be resolved.\n\nI would be more inclined to agree with this change if every server used status codes appropriately, they don't. \n. ",
    "marcello3d": "What's easier to debug?\n1. You're expecting a normal response object when you get a 4xx response, but instead you get an Error('HTTP Status Error 400 Bad Request') w/ stack trace\n2. You're get a 4xx response with no error which causes a ripple effect elsewhere in the app. (Maybe you're posting to an API, get a 403, but the app carries on because you forgot to check the status code)\n   - And if you forget to check the error, hopefully the undefined 'response' will trip you up\nMy feeling is more time would be wasted on the latter scenario than the former.\n. 4xx and 5xx are totally errors. The majority of the time you don't want them.\n. ",
    "landau": "Docs appear to be out of date. http://visionmedia.github.io/superagent/#error-handling\n\nNote that a 4xx or 5xx response with super agent is not considered an error by default. For example if you get a 500 or 403 response, this status information will be available via res.error, res.status and the others mentioned in \"Response properties\", however no Error object is passed for these responses. An error includes network failures, parsing errors, etcetera.\nWhen an HTTP error occurs (4xx or 5xx response) the res.error property is an Error object, this allows you to perform checks such as:\n. \n",
    "aseemk": "I'm late to this party, but just want to say I'm impressed all-around by the thoughtful and reasonable discussion, and particularly @defunctzombie's open-mindedness. Great to see. =)\nMy 2\u00a2:\nI completely sympathize with @defunctzombie's logic. I myself have requested this change in behavior for request.js: https://github.com/request/request/issues/606. There also, people were generally +1 to the idea, but the issue was ultimately closed with no PR to move forward with.\nIndeed, in every place we use both request.js and Superagent, we have a helper function that does:\njs\nif (res.statusCode >= 400) {\n    return callback(new Error(res.statusCode + ' response for ...'));\n}\nI majorly agree with @defunctzombie @marcello3d and others that this is the 90% common case, and it's much easier to work around and debug bugs with this than the opposite.\n\u2014\nHowever, I also agree with @rauchg and others that there are legit cases of 4xx. The domain name lookup is a good example. Another is GitHub's API for querying stars/follows/etc.:\nhttps://developer.github.com/v3/activity/starring/#check-if-you-are-starring-a-repository\nhttps://developer.github.com/v3/users/followers/#check-if-you-are-following-a-user\nhttps://developer.github.com/v3/gists/#check-if-a-gist-is-starred\nAll of those return empty 204 for \"yes\", or empty 404 for \"no\".\nSo it might be useful if this could be configurable. But maybe others have better ideas.\nEither way, I'm overall +1 to this change, but understand others. Thanks @defunctzombie.\n. One thing I'm not sure about is treating 3xx as errors. I understand browsers do this, but on Node, 3xx is a legit response more often than not, in my experience. E.g. 304 Not Modified.\nPlus redirects obviously. Does Superagent still follow redirects, rather than treat e.g. 302 as an error?\n. That's a legit view @rauchg. I'd like to offer another view: my common use case for making requests is to talk to REST APIs. And with REST/HTTP, 4xx and 5xx are errors; 2xx and 3xx are not.\nWith this view, the goal of making requests is not to get a response so much as to get (or put or ...) a resource. And if the server responds with 4xx or 5xx, I didn't get the resource; I got an error.\nHowever, my argument doesn't quite hold water with a library that indeed returns Responses as you mention. And I think this is what the debate boils down to: what layer this library lives at.\nPerhaps the conclusion is that Superagent is at a lower transport level, not a higher application level.\n. I should have left versions:\n```\nclient:\n\u2514\u2500\u252c superagent@0.18.0\n  \u2514\u2500\u2500 formidable@1.0.14\nserver:\n\u251c\u2500\u252c express@3.2.6\n  \u2514\u2500\u252c connect@2.7.11\n    \u2514\u2500\u2500 formidable@1.0.14 \n```\n. ",
    "ggoodman": "I've tried to parse through all of this to figure out what the conclusion is.\nFrom what I can see in practice: status >= 300 is now an 'error' and triggers that behaviour accordingly.\nA major problem that I see with this approach and the Request#then adapter for Promise support is that all response metadata for non 2xx responses is lost.\nWhat can we, as users of this lib, do to get around this?\n. ",
    "bengourley": "Hi @gjohnson, it looks to me like you're the maintainer of this project now. What can I do to get this merged? Sorry for the spam if you're not responsible.\n. Great stuff, thanks!\n\nOn 7 Nov 2013, at 15:18, Garrett Johnson notifications@github.com wrote:\nYep, gonna check it out on Saturday morning!\n\u2014\nReply to this email directly or view it on GitHub.\n. Any word on how we can get this resolved?\n. No worries. Sorry to pester, just trying to prevent it from going stale.\n. Thanks. Sure.\n. Correct me if I'm wrong, but I can't see a problem with the client.\n\nI tries to use the content type header as a key here, but if that's undefined it just uses the header as is:\nhttps://github.com/visionmedia/superagent/blob/master/lib/client.js#L571\nSince the client doesn't do any response body parsing, I don't think there's an issue.\n. ",
    "chris-rock": "and updates on this? Any reason, why this is not merged?\n. @gjohnson cool and I cross the fingers for your new job. \n. ",
    "Zulunko": "I can't see a way that an HTTP redirect to a different authorization can be handled by a plugin or a separate function without intentionally hacking to avoid an automatic redirect and manually handling it myself outside of superagent. This solution gives a way for someone to allow redirects to external servers which have different authorization. In my specific usage, I am using a pipe to request data from a server which requires authorization which redirects me to a server (where the data is contained) which explicitly requires that no authorization be present, and superagent by default simply uses the same authorization that was set for every request, regardless of redirect location, so it fails every request without my authorization mapping. I believe this is an issue others may be harmed by, albeit infrequently. Is there a way I can solve this problem with superagent that isn't considered elaborate?\nIf you believe solutions to the redirect authorization problem simply can't exist for superagent, would you like me to submit a different pull request with only the pipe redirection fix?\n. I created pull request #372 with only the pipe redirection fix.\n. I ran the tests with node version 0.10.25 (the same that Travis used) on a clean repository a few dozen times with my changes applied and they didn't fail. I'm not sure what else I can do to try to reproduce this failure, and without reproducing it I won't be able to fix it. If you happen to reproduce the error, let me know how and I'll work on it.\n. ",
    "garthk": "@Zulunko, could you submit a PR for just the fix for redirection breaking simple piping? \n. Confirmed. \nvar stream = require('superagent')\n    .get('https://github.com/twbs/bootstrap/archive/v3.1.1.zip')\n    .pipe(fs.createWriteStream('v3.1.1.zip'));\n\u2026 results in this:\n\n<html><body>You are being <a href=\"https://codeload.github.com/twbs/bootstrap/zip/v3.1.1\">redirected</a>.</body></html>\n\nSee also: #287, which rolls a patch for #298 in with an unrelated authentication feature. \n. ",
    "jdan": "@gjohnson Correct, currently (in master) the JSDoc for request.head says it performs a GET. His change fixes that string to say HEAD.\n. ",
    "matteofigus": "Exactly, thanks @jdan \n. Hi, any news about this? It would be a good feature to add for me. Thanks for the great work.\n. ",
    "jas-": "@gjohnson Thanks, I am an idiot\n. ",
    "therebelrobot": "Was this PR just closed, or was it implemented in another way? I'm assuming it was implemented in another way given the docs talk about plugins, but I wasn't sure. \n. Thanks @defunctzombie!\n. :+1: I, for one, am excited for this release :)\n. ",
    "ericgj": "Yes pls!\n. it's actually lib/client.js you want I think\n. oops of course and it says it right there in the readme... sorry.\n. ",
    "johntron": "FYI - the wiki already includes plugins that extend the functionality of superagent, but they extend ALL requests. This PR adds the ability to extend a single request object at multiple stages of the request lifecycle.\n. @gjohnson - I don't use the node client, but I believe the node client shares the code this PR modifies, so Node should benefit without further modifications. Care to test?\n. My latest commit adds Node support. Thanks @nickl-!\n. ",
    "elimisteve": "@defunctzombie No plans for superagent to support WebSockets?\n. ",
    "esnunes": "By default it should follow 5 redirects (as it mentions on the documentation you've pointed out) although in case you pipe it the redirects don't work, the request for the first server will be piped and \"end\" event will be fired before follow the redirect.\nHave you tried the source code mentioned on issue description?\nEven if you can't fix it now, I believe it would be interesting not to close this issue.\nKind regards,\n. Did you have time to take a look on it yesterday?\n. ",
    "thulka": "\"the library\" is just superagent.js ?\n. cool, thx. nice api btw.\n. ",
    "nebulade": "Useful when the server returns an image, which would have a content-type of image/* The retrieved data blob can further be used in \"\" or \"css:backgorund-image\" within the browser or like in my case in nodejs for simply downloading an image file.\n. Not quite sure what you meant by 'referencing it', it's part of the change. It is used by the other code paths of this change. I followed the other code's convention like 'isText(..)' just above. Otherwise I could have just inlined it.\n. ",
    "sunfuze": "why i cant see this feature in the newest version\n. ",
    "jeffchan": ":+1:  would love this too. Trying to figure out if IE8 is supported\n. ",
    "omeid": "446 could possibly have fixed the issue for IE11 in compatibility mode.\nWaiting for the Sauce Labs regardless. :+1: \n. Bump. I need this issue to be resolved before I can use superagent.\nAlso, perhaps a PostMessage Proxy based solution could be baked into SuperAgent for IE users? Something like these:\nhttps://github.com/eligrey/pmxdr/\nhttps://github.com/oyvindkinsey/easyXDM\n. @nrako I did. By resolved, I didn't mean to be merged but rather a decision made. So I can go ahead accordingly.\nPerhaps I should create the \"proxy\" as extension but even then there is a bug in superagent that holds me back. It prefers ActiveXObject over XMLHttpRequest which is bad.\n. No, the original is that \njavascript\nif (root.XMLHttpRequest\n    && ('file:' != root.location.protocol || !root.ActiveXObject)) {\n    return new XMLHttpRequest;\n  }\nLets ignore the file case for a minute. We will have \njavascript\nif (root.XMLHttpRequest && !root.ActiveXObject)) {\n    return new XMLHttpRequest;\n}\nThat means, the only time XMLHttpRequest is used when there is no ActiveXObject at root.\nWhile the new code is \njavascript\n if (root.XMLHttpRequest && 'file:' != root.location.protocol) {\n    return new XMLHttpRequest;\n  }\nWhich insists on using XMLHttpRequest whenever it is defined unless we are using the File protocol;  regardless of ActiveXObject.\n. @tjconcept That is right. XMLHttpRequest will fail for files anyways. Only ActiveXObject, and that too in very limited instances support file protocol.. And, now it sends non-file requests to XMLHttpRequest regardless of whatever ActiveXObject is there or not.. ",
    "davidtheclark": "This is essential.\n. I see on the current Readme saucelabs-documented support for an extremely limited number of browsers. Is that really it, or is this documentation still in the works?\n. IE8, or just clear acknowledgement that it is not supported, I suppose. Thanks.\n\nOn Dec 24, 2014, at 11:01 AM, Roman Shtylman notifications@github.com wrote:\nStill in the works for which browsers to test. IE 11 is supported but saucelabs is broken. IE 9 might work for some stuff.\nWhich other browsers do you want to see tested?\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "sintaxi": "hmm, text is working in this example but returning undefined in my application.\n. ",
    "noah79": "I have the same problem:\n\n.content and .body are both undefined.. ",
    "bminer": "@nickl - Good points.  I think you're right -- this is outside of the scope for the Superagent project and is solely a Node.js issue.  If you don't mind, I'd like to close this issue.\nThanks!\nEDIT: Just to add on... dns.resolve is certainly much faster than its dns.lookup counterpart... problem is that dns.lookup is more consistent with how other network applications perform DNS resolution.  dns.lookup, for example, will keep track of changes to /etc/resolv.conf; whereas, dns.resolve only looks at /etc/resolv.conf when Node starts up.\nShould Node provide a nice API in the future to change which resolver is used for an HTTP request, perhaps it would be appropriate to expose that option via Superagent.  Until then, I vote to close this issue.\n. @nickl- Superagent is already using dns.lookup.  HTTP requests use dns.lookup by default.\n. Just to be clear, it appears that this bug is caused when an \"error\" event is emitted from Node's request Object, which is captured by Superagent; however, since .end(cb) was not yet called on the Superagent request Object, there is no _callback property set yet, and the error is not reported to the user.  By the time .end(cb) is called, the error is gone, and cb will never be called (as of Superagent v1.6.1).  This bug will only occur if .end(cb) is NOT called in the same tick as the request was created (i.e. you created the request, do some async stuff, then call .end(cb)... and in the meantime an error occurred -- like a connection error or whatever).  The end result under these circumstances is that your cb is never called, and the error is not reported to the outside world.\nIn this case, why not just save any request errors that occur before .end(cb) is called on the Superagent request?  Then, when .end(cb) is called, you check if an error has already occurred on the request Object.  If so, you call cb, passing the saved error.  If not, you continue as normal.\nA workaround to this bug is to set _callback on the Superagent request with your desired cb before doing any async work.  This is what I decided to do until this bug is corrected.\nThoughts?\n. I can always submit a PR of my suggestion if you want?  I assume this change would be a minor version bump?\n. Sorry for the delayed response.  Here's some code you can use to replicate the bug:\njavascript\nvar request = require(\"superagent\");\nfunction callback(err, res) {\n    if(err) {\n        console.log(\"Error:\", err.stack);\n    } else {\n        console.log(\"Success:\", res.status);\n    }\n}\nvar req = request.get(\"http://www.fjkldfjkdjf.com/\");\nreq.set(\"User-Agent\", \"Superagent... duh!\");\n//req._callback = callback; // Workaround: Uncomment this line to \"fix\" the problem\nsetTimeout(function() {\n    req.end(callback);\n}, 1000);\nIn superagent v1.6.1, callback is never called.  EDIT: Actually, it would be called if www.fjkldfjkdjf.com was a valid DNS host, which it currently is not.  As mentioned above, the bug only occurs when an \"error\" event is emitted from the Node HTTP request Object before Superagent's .end(cb) method is called.\nIf you uncomment the line as noted, callback is called once with the proper Error:\nError: Error: getaddrinfo ENOTFOUND www.fjkldfjkdjf.com www.fjkldfjkdjf.com:80\n    at errnoException (dns.js:26:10)\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (dns.js:77:26)\nEDIT: However... even though callback is called with the correct Error when setting the _callback property, the callback is called as soon as the Error occurs, NOT when the 1000 ms. timer expires, producing unexpected behavior.  Therefore, this workaround is not a perfect solution.\nFor comparison, in superagent v0.21.0, a message like this occurs:\nTypeError: Cannot read property 'length' of undefined\n    at Request.callback (/home/blake/Repositories/machine/node_modules/superagent/lib/node/index.js:746:14)\n    at ClientRequest.<anonymous> (/home/blake/Repositories/machine/node_modules/superagent/lib/node/index.js:711:10)\n    at emitOne (events.js:77:13)\n    at ClientRequest.emit (events.js:169:7)\n    at Socket.socketErrorListener (_http_client.js:264:9)\n    at emitOne (events.js:77:13)\n    at Socket.emit (events.js:169:7)\n    at connectErrorNT (net.js:998:8)\n    at nextTickCallbackWith2Args (node.js:478:9)\n    at process._tickDomainCallback (node.js:433:17)\nEDIT: For the record, this bug definitely occurs on Node 4.x and 5.x, but it probably also pertains to other versions, as well.\n. I think that this bug was fixed in Superagent v1.7.  I'll double check to confirm.... Setting this.headers instead of this.request().setHeaders(...) is what ultimately fixes this bug.  The key is to avoid calling this.request() and then doing async operations.  Now this.set(...) avoids calling this.request(), so everything is all good.\nhttps://github.com/visionmedia/superagent/compare/v1.6.1...v1.7.0#diff-c24ce7e3da4c0e4ff811a2b6a76f8bd9R279\nThis issue should probably be closed.. ",
    "jldec": "converted this issue into a PR and used a branch to include just the changes for this bug.\ncurl -d \"{ \\\"base\\\": \\\"visionmedia:master\\\", \\\"head\\\": \\\"jldec:issue308\\\", \\\"issue\\\": \\\"308\\\"}\" -u \"jldec@ciaosoft.com:***\" https://api.github.com/repos/visionmedia/superagent/pulls\nhth\n. I think this was only a problem in the browser version.\nThe code in the commit passes tests for node (i have v0.10.24) and in browsers (recent OSX chrome / firefox / safari). I did not test with older browsers or older versions of node though.\n. @nickl unfortunately it seems that the implementations are already out of sync.\nthe client code calls var res = new Response(self); from the on('end' handler in new Request()\nthe node code calls var response = new Response(self.req, self.res); from the on('end' handler in Request.end\nThis means that the client Response has access to Request (which has a url property), but the node Response is working with node's ClientRequest object (which has a path property)\nPerhaps the better solution would be to adjust implementation of Request to match node's ClientRequest ?\n. Per previous comment, this alternative (change Request to have both .url and .path) would fix it too:\nhttps://github.com/jldec/superagent/commit/8e4bacb2ce1d14d5bf34bd60bf2e31b41db5102a\n. no worries @nickl - it's awesome to see someone being so assiduous with the code!\nSince this issue was a minor annoyance (just affecting an error message on clients,) i was proposing fixes with minimal impact. \nIf you're looking for the deeper underlying problem, a good place to start may be to tackle the divergence between the client side tests and the node tests. E.g. If the node toError test had also been run against the client code, then the issue would have surfaced earlier.\nMy vote for this fix still goes to the first toError change in client.js (to use req.url for the error message instead of req.path.)\nA more substantial/consistent fix would be to change the node.js implementation so that toError() has access to to the full Request.url. This would result in a more informative error message on both sides.\n. fwiw: see also 42251f9\n(perhaps @TooTallNate would chime in with a suggestion/fix)\n. @binarykitchen  - not sure what to do myself.\nI just rebased my original PR to bring it up to date with master and re-ran local browser and node tests (part of the PR is a change to the client tests so that this issue is exposed)\nhttps://github.com/jldec/superagent/commit/44d958693687b36dc0d34eb10e0c64822a3c7963\nhappy to do more work if anyone needs further testing etc. to move this along\nj.\nps - i think the deeper issue here is the divergence between client and server code (both runtime and tests)\n. @defunctzombie\nThis bug was fixed (sortof) with 3ed4472 and c267c3b which changed the error object to include a .url property - so the error .message is correct now. My PR is no longer relevant - thanks.\nFWIW the fix introduced a small inconsistency between the node and client code - in the node code the error only has .path and in the client code the error only has .url\n. ok - sorry - didn't want to send PR without tests - which led to figuring out zuul etc. (the existing instructions in the Readme didn't work on the master head).\nanyway, just committed a change to client.js and adjusted tests to fix the error.path and error message issue.\n. @nickl, afaik @gjohnson is working on the CI testing setup (per his earlier comment on this issue)\ni suspect that the CI fails across the board because of the zuul changes\nj.\n. ",
    "jessefulton": "+1 would love to see this get into supertest. ~~Any suggestions on a temporary workaround? (I tried forking supertest to use the latest master of superagent, but it doesn't seem to be firing the Busboy events in my API routes...)~~\nEdit: I had another issue in my route... looks like my fork is working fine. Thanks!\n. ",
    "lepture": "Example here: https://github.com/mitsuhiko/werkzeug/blob/master/werkzeug/wrappers.py#L613\n. ",
    "lencioni": "Additional context: it looks like this header used to be set, but that was removed by #189.\n. It would be nice to at least maintain the ignore list, which will prevent those files from being downloaded when you bower install.\n. ",
    "jonasfj": "I might be doing something wrong, but I had the double callbacks warning with this:\njs\n        var req = request\n                    .put(someUrl)\n                    .set('Content-Type', contentType);\n        var stream = fs.createReadStream(file);\n        stream.pipe(req);\n        req.end(function(res) {....});\n. Yeah, it was probably just me doing it wrong... I got it working by using stream.pipe(req, {end: false}). But I guess the alternative is to listen for an end event, perhaps end I tried a couple of different events like response, etc. The type of event seemed undocumented, so...\nAnyways, this is more likely a case of me being confused by the documentation.\n. Try piping the stream with options end as false.\nIe. stream.pipe(req, {end: false});\nand then do req.end() manually...\nIt sounds like a bug that you can just rely on end from stream...\n. @gjohnson,\nI didn't implement trustRedirect. So the only way not to trust 307 redirects with this PR is .redirect(0).\nBut if we wanted to follow the spec as much as possible, that is not good enough. Because the spec says to automatically redirect GET and HEAD requests, but only redirect other methods, if the user confirms this. Using .redirect(0) sort of assumes that you already know if it's a 307 or 303 redirect, you're going to get, because 303 should redirect with a GET to regardless of original method.\nEither way, it's very convenient to just trust all 307 redirects. For better syntax it could also be .redirects(5, {trustLocation: true). But IMO, it's okay to diverge at bit from the spec, as this \"user-agent\" is more geared towards REST APIs. And if a server sends a 307 redirect, you probably want to follow it. After all the server must sort of trust the server it redirects to... It certainly could choose to just forward your request to the other server.\nI suspect the reasoning in the spec is that you might not want to forward your authentication credentials to the server you are redirected to.\n. @defunctzombie rebased on current master.\n. For the record, I've been looking through the history and it was probably me who broke this in #408.\nI'm not entirely sure what is the desired behaviour for headers. Since 303 force redirects with a GET request, it's probably sane to clean the content related headers.\nFor 307 which preserves content, it's probably bad to clear the content related headers.\n. ",
    "MattCain": "I'm getting the double callback message when testing (with mocha) the GET routes of my API:\nit('should get the account metadata', function(done) {\n    request.get('https://***/api/user/1')\n    .end(function(e, res) {\n        expect(res.body).to.have.property('_id');\n        expect(res.body).to.have.property('created');\n        done();\n    });\n});\nNone of my POST/PUT/DELETE requests are getting it and they're in the same format. What's causing it in this case?\n. ",
    "joerx": "Why am I getting this for something as simple as piping a stream? It's basically done like in the docs, so going by the docs is causing warning? Or am I missing something?\n``` js\nvar s = http.createServer(app);\ns.listen(0);\nvar addr = s.address();\nvar host = addr.address;\nvar port = addr.port;\nvar req = agent.put('http://' + host + ':' + port + '/documents/' + id).type('application/pdf');\nvar stream = fs.createReadStream(__dirname + '/data/sample.pdf');\nstream.pipe(req);\n// results in 'double callback'....\n```\n. ",
    "cedric-b": "Getting the same entering every superagent .end() cb but this happens only when using gulp watch... Manual CLI mocha or gulp \"test\" (task piping gulp-mocha) work allright. Only in gulp watch mode surveying test/*.js and triggering \"test\" task. \nCode sample (though pretty much like some others samples here):\n\nit('No status is provided. Returns [500: ' + errmsg.noStatus + ']', function(done) {\n  agent.put('http://localhost:3000/api/invoice')\n    .send(fixt.invoices.no_status)\n    .end(function(err, res) {\n      // double callback\n      should.not.exist(err);\n      res.status.should.eql(500);\n      res.type.should.eql('text/plain');\n      res.text.should.eql(errmsg.noStatus);\n      done();\n    });\n});\n---------\n// gulpfile part\ngulp.task('test', function() {\n  gulp.src('test/*.js')\n    .pipe(mocha({reporter: 'spec'}));\n});\ngulp.task('watch-test', function() {\n  gulp.watch('test/*.js', ['test']);\n});\n\nNothing new since last comment on July ?\n. ",
    "cesarandreu": "Having same issue, not sure why :(. \n. ",
    "kfng7": "I also got the same issue when the remote server is down. I expect that error message should be passed via callback instead.\n. ",
    "lukebayes": "Also experiencing this issue using gulp watch with mocha.\n``` javascript\nvar request = require('supertest'),\n      worker = require('../src/worker');\ndescribe('POST /message', function() {\n  var app;\nbeforeEach(function() {\n    app = worker(); \n  });\nit('handles valid request', function(done) {\n    request(app)\n      .post('/message')\n      .send({version: 10, docId: 'blah'})\n     .expect(200, function(err, response) {\n        assert.equal(resonse.body, 'some content');\n     })\n     .end(done);\n  });\n});\n```\nThis test passes the first time every time. Then after about 3 file saves it will fail for the next few file saves, and eventually pass again intermittently going back and forth with the double callback error.\nTypeError: Cannot read property 'length' of undefined\n    at Test.Request.callback ([project]/node_modules/supertest/node_modules/superagent/lib/node/index.js:746:14)\n    at ClientRequest.<anonymous> ([project]/node_modules/supertest/node_modules/superagent/lib/node/index.js:711:10)\n    at ClientRequest.EventEmitter.emit (events.js:95:17)\n    at Socket.socketOnEnd [as onend] (http.js:1568:9)\n    at Socket.g (events.js:180:16)\n    at Socket.EventEmitter.emit (events.js:117:20)\n    at _stream_readable.js:919:16\n    at process._tickDomainCallback (node.js:463:13)\n. I may have found the root cause and a workaround.\nIt looks like providing a callback handler to expect and adding an end handler may intermittently trigger this multiple callback warning.\nI have changed our test code to always pass a callback to expect, never call end() and the provided handler calls done() directly.\nHaven't seen a recurrence for an hour or so.\n. ",
    "JohnTigue": "I found my way here because of \"double callback!\" messages while running Mocha tests with Nock. I am leaving this message mostly to cross-link to more info at #417.\nAnd in Nock's issues: https://github.com/pgte/nock/issues/211\nOne small trick for checking to see if the SuperAgent-to-Nock interaction is your problem is to call nock.enableNetConnect() right before firing off a request with SuperAgent. Toggle that on and off with comments while running Mocha and you might just have found where your prey is hiding.\n. ",
    "SGrondin": "I have found a workaround for my particular case.\nIn a mocha test file, I was doing:\njavascript\nrequest.post(\"http://127.0.0.1/\")\n.send(new Buffer(1024*1025))\n.end(function(err, result) {\n    // Some asserts go here\n    done()\n})\nI changed it to\njavascript\nvar buf = new Buffer(1025*1024).toString(\"utf8\")\nrequest.post(\"http://127.0.0.1/\")\n.send(buf)\n.end(function(err, result) {\n    // Some asserts go here\n    done()\n})\nand the problem disappeared\n. ",
    "asperling": "Same here but with a slightly different environment. I use supertest-as-promised and therefore my tests are promise based.\nBut my solution might be of interest anyway, since I figured that the double callback issue disappeared when I re-instantiated the agent in the beforeEach() hook.\n```\nvar expect = require('chai').expect,\n    q = require('q'),\n    sap = require('supertest-as-promised'),\n    app = require('../../server')\n    agent,\n    request;\n// ...\ndescribe('Some Service Tests', function() {\n  beforeEach(function() {\n    // reinitialize agent to prevent \"double callback\"s\n    request = sap(q.Promise);\n    agent = request.agent(app);\n    // ...\n  }\n  // Tests go here... and so on\n}\n```\nNow... I never saw the double callback error since. \n. ",
    "JMacLulich": "I'm seeing this problem as well, it happens only sporadically but my end handler is being called twice on some fairly simple code.\njavascript\nrequest\n      .post(url)\n      .send(postBody)\n      .type('application/json')\n      .timeout(TIMEOUT)\n      .end(function(err, res) {  ... some stuff gets executed twice for some weird reason... };\nI'll try the suggestion about using expect instead of end but not sure why that should matter.\n. ",
    "matthiasg": "@ORESoftware i dont quite follow your code there. Your change should not have corrected this issue as i understand it. \n@JMacLulich writes that end is called at least twice, that means in your example you either call the if(err) branch once or twice or the else branch once or twice. In all cases you would call done exactly as often as end was called. \nSo why does that fix anything ?\n. I had this issue again today after doing some extensive unrelated updates in my codebase. In my case the culprit turned out to be the 'faux promise support'.\nbasically i did something like this (abbreviated): \n```\nfunction send(something,callback){\n  return request.post('http://foo.io/invalid').send(something).end(callback);\n }\nfunction main(){\n   send(something, function(){ console.log(done) }).then(function(){})\n}\n```\nthe then was added because i used promises in my main code base and the call to send was inside a promise then handler.\nPromise.all([...]).then( ()=>send(somedata, function(){...}) )\nthis happens in ES6 with the above syntax or with e.g coffeescript or with ES5 when its function(){return send(...)} \nthe return value of my send function is interpreted as a promise thus the faux promise support of Request is called causing end to be called twice.\nin the 2nd call this._headerSent is already set to true which means the data is not serialized in the second call causing the  req.end(data); to complain about having the wrong format when the send call is given an object.\nTL;DR: had the request hooked up with 'end callback' AND '.then callback' causing double request.\n. ",
    "rcrichton": "I'm also seeing the 'double callback!' message and my end() callback doesn't seem to be called (the test times out in mocha). For me it was introduced with supertest 1.1.0 and the same code works fine on 1.0.1. I'm also using mocha for testing and this occurs in a few of our test.\nHere is a snippet of code. Is there anything we are doing wrong to cause this?\ncoffeescript\ndescribe \"with no credentials\", ->\n  it \"should `throw` 401\", (done) ->\n    server.start httpPort: 5001, ->\n      request(\"http://localhost:5001\")\n        .get(\"/test/mock\")\n        .expect(401)\n        .end (err, res) ->\n          if err\n            done err\n          else\n            done()\n. ",
    "vizath": "I'm having this issue also, when making requests with small timeouts (timeouts that are near the response time).\nI can reproduce it by executing this snippet.\nvar request = require('superagent');\nrequest.get('http://google.com').timeout(140).end(function(err, res) { console.log(err); });\nrequest.get('http://google.com').timeout(140).end(function(err, res) { console.log(err); });\nrequest.get('http://google.com').timeout(140).end(function(err, res) { console.log(err); });\nrequest.get('http://google.com').timeout(140).end(function(err, res) { console.log(err); });\nrequest.get('http://google.com').timeout(140).end(function(err, res) { console.log(err); });\nrequest.get('http://google.com').timeout(140).end(function(err, res) { console.log(err); });\nrequest.get('http://google.com').timeout(140).end(function(err, res) { console.log(err); });\nYou can make the request only once, but you have more chances to see it if you execute it often.\n$ node index.js\nnull\nnull\nnull\nnull\n{ [Error: timeout of 140ms exceeded] timeout: 140, code: 'ECONNABORTED', response: undefined }\n{ [Error: timeout of 140ms exceeded] timeout: 140, code: 'ECONNABORTED', response: undefined }\n{ [Error: timeout of 140ms exceeded] timeout: 140, code: 'ECONNABORTED', response: undefined }\ndouble callback!\ndouble callback!\ndouble callback!\n. As of 1.8.3 and 2.0.0-alpha1, my test case higher still outputs double callback!.\n. I can still reproduce https://github.com/visionmedia/superagent/issues/313#issuecomment-141326537 in 3.3 using .timeout(180). \nThe warning is now superagent: double callback bug.\nNote that .timeout({ response:60 }) (introduced in 3.2) works fine with no warnings, but it is not the behavior that I'm looking for (I don't want to wait more than 180ms total including downloading the body).\nCould that mean that the warning is shown when there is an error between the moment the connection is established and the body is completely received ?. ```\n$ node superagent.js\nnull\nnull\n{ [Error: Timeout of 450ms exceeded] timeout: 450, code: 'ECONNABORTED', response: undefined }\n{ [Error: Timeout of 450ms exceeded] timeout: 450, code: 'ECONNABORTED', response: undefined }\n{ [Error: Timeout of 450ms exceeded] timeout: 450, code: 'ECONNABORTED', response: undefined }\n{ [Error: Timeout of 450ms exceeded] timeout: 450, code: 'ECONNABORTED', response: undefined }\n{ [Error: Timeout of 450ms exceeded] timeout: 450, code: 'ECONNABORTED', response: undefined }\nTrace: superagent: double callback bug [Error: previous trace]\n    at Request.callback ([...]\\node_modules\\superagent\\lib\\node\\index.js:637:35)\n    at Stream. ([...]\\node_modules\\superagent\\lib\\node\\index.js:849:18)\n    at emitNone (events.js:67:13)\n    at Stream.emit (events.js:166:7)\n    at Unzip. ([...]\\node_modules\\superagent\\lib\\node\\unzip.js:63:12)\n    at emitNone (events.js:72:20)\n    at Unzip.emit (events.js:166:7)\n    at endReadableNT (_stream_readable.js:905:12)\n    at nextTickCallbackWith2Args (node.js:441:9)\n    at process._tickCallback (node.js:355:17)\n```\nThe previous trace:\nError: previous trace\n    at Error (native)\n    at Request.callback ([...]\\node_modules\\superagent\\lib\\node\\index.js:642:17)\n    at RequestBase._timeoutError ([...]\\node_modules\\superagent\\lib\\request-base.js:516:8)\n    at null.<anonymous> ([...]\\node_modules\\superagent\\lib\\request-base.js:525:12)\n    at Timer.listOnTimeout (timers.js:92:15)\nYou need to play with the timeout values until you get the sweet spot where half of them are timeouts and half of them are success.\nAlso, having the timeout error doesn't always trigger the trace.\nUsing a mobile network makes it very hard to reproduce.\n. I cannot reproduce my use case on 3.3.1 :tada: . ",
    "alexaivars": "Why is this issue closed ? Im still having problems with double callback, the following simple situation causes a double callback. It might be related to JSON.parse throwing an error further down the chain.\n```\n        require('nock')('http://foo.io')\n            .get('/invalid')\n            .reply(200, 'not valid json', {'Content-Type': 'application/json'})\n    require('superagent')\n        .get('http://foo.io/invalid')\n        .end(function (err, res) {\n\n        });\n\n```\n. ",
    "psypersky": "Same problem here\n. ",
    "tribou": "I was seeing the 'double callback!' message along with a fn is not a function error when mocking superagent with sinon.  After visionmedia/superagent@454eeb2, the error and double callback message are gone.  Did that commit resolve the issue for anyone else?\n. ",
    "ybian": "I had the same issue. The first case of the following works well but the second prints \"double callback\" message and the done() callback was not called so timeout error occurred.  \nIt seems that supertest inside a promise then block can easily reproduce the problem.\n``` coffeescript\n  it '# success', (done) ->\n    supertest(dbServerUrl)\n      .get('/_all_dbs')\n      .expect(200)\n      .end (err) ->\n        if err\n          done.fail(err)\n        else\n          done()\nit '# failed', (done) ->\n    Q('5')\n    .then ->\n      supertest(dbServerUrl)\n        .get('/_all_dbs')\n        .expect(200)\n        .end (err) ->\n          if err\n            done.fail(err)\n          else\n            done()\n```\n. ",
    "gstamp": "@ybian I also get the same issue when I use promises although in my case I was using bluebird.\n. ",
    "hustcer": "I got the double callback! warning too.\n. +1\n. @pornel Sorry, I will add more info later.\n. Just run the following code:\n```\nconst request = require('superagent');\nrequest\n    .get('http://www.dfzq.com.cn/dfzq/dfyw/rzrqbdzq.jsp')\n    .buffer()\n    .end((err, res) => {\n    console.log(err, res);\n});\n\n```\nand you will get the error:\n{ Error: unexpected end of file\n    at Zlib._handle.onerror (zlib.js:370:17) errno: -5, code: 'Z_BUF_ERROR', response: null } null\n. @pornel Great !\n. I got the same error in 2.2.0\n. ",
    "cdutson": "I'm on 2.0.0-alpha3, and I'm getting double callback\nexample code:\n```\nexport const performRequest = function performRequest(url, method='GET') {\n return request(method, url);\n};\nexport const getResource = function getResource(resource, id = null) {\n    return performRequest(${baseUrl}/${resource}/${id});\n};\nexport const _doFetch = function _doFetch(id, resolve, reject) {\n  // Right here it's double callbacking the .end() causes it.\n  // I can even run getResource('sample', id).end() to generate the warning, no resolve/reject needed\n  return getResource('sample', id).end((err, res) => { \n    if (res && res.ok) {\n     resolve(res.body);\n    }\n    else {\n      reject(err.response);\n    }\n  });\n};\n```\nfurther info: I'm using es6 (not everywhere mind you) that's translated via babel.\n. @pornel further information that may prove helpful, I only see these warnings when running the code through mocha. so some additional code:\n```\n/ import nock, expect, etc /\ndescribe('api code', () => {\n   it('Should return values for api call', () => {\n    nock('http://33.0.0.16:8000')\n      .get('/foo')\n      .reply(200, [\n        {\n          foo: 'bar'\n        }\n      ]);\nconst expectedResults = [\n    {\n        foo: 'bar'\n    }\n]\n\nreturn _doFetch().then((results) => {\n  expect(results).toEqual(expectedResults);\n},\n() => { /* swallow error */ });\n\n});\n}\n```\nrunning the code posted above within the test suite causes ... 3 warnings to show up.\n```\ncli> node_modules/mocha/bin/_mocha --compilers js:babel-register --recursive --grep \"api code\"\ndouble callback!\ndouble callback!\ndouble callback!\n    \u2713 Should return values for api call\n```\nthe local api server I'm running is a vanilla django rest framework setup. no custom headers or anything.\n. ",
    "romaleev": "Same issue with 'double callback!' with version 1.8.4.\nI use PM2 with node.js.\nWhen superagent's timeout exceeded I log the error and run process.exit after which PM2 successfully restarts the node.\nHowever sometimes superagent sends 'double callback!' warning right after I call process.exit which makes my node hang up forever and not being restarted by PM2.\nAfter some investigation I figured out that request callback executes twice:\n1) superagent.callback with error -> which resolves it as expected\n2) calling process.exit (but it is still running afterwards)\n3) then callback executes the second time !!! with a result and no error (result is with content as if request succeeded)\n4) superagent returns 'double callback!' warning within neither callback fn execution nor error.\n5) node.js is still running\nAs a conclusion for some reason superagent executes callback twice with no resolving the second one which leads the process to hang up.\n. ",
    "djabraham": "I was getting double callback because I had the port forwarded via nat using virtual box (boot2docker). I was running a containerized app locally and forgot the same port was used for both. \nFunny thing is the server starts and I am able to browse to it with no warnings. But when I run supertest, I encounter the double callback error. Once I changed the port, it worked fine. \nI don't consider this a problem, just posting it here for future reference. This was occurring under the latest versions (2.0.0 SA & 2.3.0 ST). \n. ",
    "vsuhanov": "just put this file in a test/node folder. Or how want me to do it? \nhttps://gist.github.com/vsuhanov/8665978\n. I made a pull request https://github.com/visionmedia/superagent/pull/354 with a possible solution. \nBut it fails travis build on node version 0.8 which appears to be a general issue right now I notice\u0432 that all latest builds crash on it. \n. I agree that rearranging event listeners looks like a dirty hack, and I don't like that solution either but I would rather not change Request. \nnext-ticking callback interferes with .buffer(false) option. I tried putting nextTick in the callback \u2014 lots of red tests. \nP.S. do I need to create a new pull request if I squashed commits? \n. ",
    "veeti": "Ping. Just spent a hour trying to figure out why this wasn't working just to find this issue.\n. You might want to squash these into a single commit for clarity.\n. ",
    "madhums": "any updates on this?\n. @alsotang the tests are failing #366.\n. Oh nevermind, its in node 0.8\n. ",
    "alsotang": "seems no. I think my fix is ok:\nhttps://github.com/alsotang/superagent/commit/bb47cd45a594a2c2b43cf51af29b0833c06d1980\n. @madhums okok, forget 0.8\n. This merge request is too dirty.\n. what about \njs\nrequest.post(API.uris.createAccount)\n      .send({account: this.user})\n. sea.js \u7528\u53cc\u95ee\u53f7\u4e0d\u6015\u8ddf http \u539f\u751f\u7684\u90a3\u5957\u51b2\u7a81\u5417\n. I dont know if this project need 0.9. I just fix 0.90 to 0.9 assume it need.\nIf not, just delete 0.9.\n. if merged, please help update the docs.\n. I wanna fix this issue myself. but I think all things about protocol is accurate work. Though I can solve problem about mine, I dont know the right solution. \n. ",
    "chovy": "it still doesn't work for me.\n. ",
    "mocheng": "Hit by this bug. \nIt looks there is already quite a few PR available. Not merged yet?\n. ",
    "themaarten": "+1\nThis bug is still present in v0.21.0.\n. To those who are experiencing problems after this issue closed: perhaps you're running into issue #509.\n. To reproduce the problem:\n``` javascript\nvar superagent = require('superagent');\nvar r = superagent.get('http://example.com');\nr.set('user-agent', 'superduperagent'); // indirectly trigger a call to r.request()\nsetTimeout(function (){}, 5 * 60e3); // prevent the process from ending for 5 minutes\n// Wait for some time\n```\n. I just did a test with v1.6.1. The issue seems to have been fixed indeed!\n. For the case described above, the superagent-charset middleware is a great solution. However, receiving binary data instead of (utf-8 decoded) strings is a very generic feature. See issues #825 and #824.\nI'd love to have a method like this\njavascript\nreq.binary(true)\nthat would cause res.body to be the binary response. The type of this value would be a Buffer for Node.js and a Uint8Array, Blob or ArrayBuffer in the browser.\n. I didn't know about the undocumented responseType('blob') feature from #888.\nThe value 'blob' wouldn't make sense for Node, though, since it doesn't have (native) support for Blobs. Wouldn't a more generic and versatile API be to use req.responseType to override the HTTP Content-Type header of the response? Then, the argument would have to be a mime-type.\nWith such an API you can force binary output with responseType('application/octet-stream') (or responseType('binary') for short). Calling responseType('application/json') would force parsing JSON even when the server is not sending the right Content-Type.\nIt would even make it possible to force a certain character encoding, for instance by calling responseType('text/html; charset=utf-16le'). This feature would be useful because the response character encoding is often omitted, this feature would be useful. Supporting the GBK encoding (see the start of this thread) and many others would require an extra library though.\n. ",
    "Dynasty9": "+1 I've lost days to this.\n. :+1: \n. ",
    "ilanbiala": "Has this been merged in and released?\n. ",
    "alexanderlperez": "+1\n. ",
    "alexhung": "Just lost like 4 hours on this. +1 on merging and release soon.\n. ",
    "elbuo8": ":+1: to this. \n. ",
    "livin": "How it's possible that such an import bug is not yet fixed. Why this testing library is needed if it can't handle cookies at all. Struggled with it for enough time. Now thinking about replacing controller testing with something else. Perhaps e2e testing instead.\n. ",
    "cristiano-belloni": "I just wrote a naive workaround:\nif (this.req.method != 'HEAD') {\n  try {\n    this.body = this.parseBody(this.text);\n  }\n  catch (e) {\n    this.ok = false;\n    this.body = this.text;\n    var msg = 'Malformed JSON';\n    var err = new Error(msg);\n    this.error = err;\n  }\n}\nelse {\n  this.body = null;\n}\nbut @gjohnson said he would write it differently, so I won't submit the pull request.\n. Sent!\n. ",
    "xaka": "@hallas oh uh? It has nothing to do with reading or writing. The idea behind this PR is exactly to not read anything from filesystem, but be able to pass a data instead, in an easier way, which means you're no longer forced to use fs module or create temporarily files in your tests.\nAs i mentioned in the description, there is a way to do so by \nrequest(...).post(...).part().attachment(...).write(...)\nwhich is ugly and could be shorten to \nrequest(...).post(...).attach('upload', 'my_file.txt', 'Some content')\nThere are other APIs which provide similar syntax sugar already to bypass calls to .part() so adding one more doesn't look like a significant API change.\n. +1\n. @defunctzombie That's the question. There are tests for form-data requests, but those are commented out for unknown reason. Should we add another tests on top of those or what's the deal?\n. It'll make this PR a little bit more complicated that it's suppose to be. Is there a better way or workaround?\n. That's right, we're not against the tests, but let's be clear - this PR fixes one issue so it requires one test while at least 10 are commented out at this moment. If you're willing to uncomment those as part of this PR, we're fine with it, but IMHO it's more than required here. What I would suggest is to uncomment those as part of another PR (or commit if you're the maintainer) and get back to this one right after. It's your call after all, we're glad to help in either way.\n. Now we're talking :) Will do. Thanks!\n. @defunctzombie As I don't have access to @dmartinezg repo and he is on vacation, I had to create another repo. Could you please take a look at this diff https://github.com/mulesoft-labs/superagent/compare/bugs/attach-with-custom-filename and let me know whether it's fine (I turned on the test case for change we made). If you think it's good to go, I'll open another PR and we close this one.\n. The new PR is https://github.com/visionmedia/superagent/pull/520. We can close this one. Thanks!\n. ",
    "mrjoelkemp": "You should be able to just do:\njavascript\nrequest.get('/shoes')\n  .query({ '_': new Date().getTime() })\n  ...\nTo get it more like jQuery, we'd have to always bust the cache and then force the user to turn it off like:\njavascript\n request.get('/shoes')\n    .cache(true)\n    ....\nTo keep the existing functionality, we'd have to assume that cache is always on and allow the user to turn it off (busting) like:\njavascript\n request.get('/shoes')\n    .cache(false)\n    ....\nThat would add the random string automatically to the request's url.\n. ",
    "ddo": "380\n. ",
    "innerdaze": "Damn, I pushed the wrong commit. Ignore this ;)\n. ",
    "yuchi": "Thank you for this! (I\u2019m the main author of ti-superagent)\nCould you please reopen this issue?\n. Hi @lsdriscoll, are you still working in proposing a change to superagent for this?\n. First of all something that was not explicitly stated, but it\u2019s really important. By now Titanium SDK has no compatibility with Node.js builtins, and as a de-facto philosophy is more oriented towards reducing the learning gap for  web devs rather than node devs. For that reason we\u2019re extending and using the browser version of superagent.\nWe have three different kind of changes that can be made:\nChanges to simplify ti-superagent maintenance\n\nmake the utils monkey-patchable by having them in the Request/exports obj, in particular\ngetXHR(), in Titanium you need to do Titanium.Network.createHTTPClient({ ... }),\nparseHeader(str), to support old less xhr-complaint Titanium versions where a non-custom getResponseHeaders() returned a parsed object instead of a string;\nsplit the Request#end() function body into smaller pieces so that we can (eventually) overload just specific parts of it.\n\nMake superagent itself compatible with Titanium APIs\n\nredirects(num) can be implemented in Titanium, but only as a true/false;\nuse xhr.timeout property instead of a setTimeout, so we can actually get connection timeouts but longer requests work (on mobile network this is an actual issue);\nuse xhr.onerror to catch timeouts and other kind of issues, but also check for some wrong behaviour happening on Android which fires onerror for non-2xx;\nuse xhr.onload because xhr.onreadystatechange doesn\u2019t always fire;\nmake sure that callbacks are not fired twice, we needed to check this in ti-superagent to prevent xhr.onreadystatechange and xhr.onload collisions;\nuse xhr.send({ obj:here }) to pass Ti.Filesystem.File or Blob as attachment.\n\nThese are the most evident changes. I know that some of them are ominous, and we can (should) actually create a good test-suite and solve this from Titanium APIs standpoint. But we have many, many, many applications that are still locked to older Titanium SDK versions.\nMake superagent installable as a Ti module\n\nuse titaniumifier to build the module zipfile that should be attached to the relative GitHub release,\nadd a \"guid\" property in the package.json which is required metadata,\nadd a build step for every release.\n\nYou don\u2019t need to explicitly publish your module somewhere, gitTio (which is the module manager for Titanium) does it for you every time you push a new version and git tag.\n. So, what\u2019s your opinion on this, @defunctzombie?\n. Great. I\u2019ll try to transform every task in a relative PR.\n. This is in fact a great solution, but you\u2019re not dealing with timeouts and Android \u22602xx issue.\nCould be nonetheless the right direction.\n. BTW, where does that code comes from? Could add a small CC license to it or refer to the original author? I\u2019d like to use it in the future.\n. ",
    "kirankashalkar": "Thank you for the good work. Please carry it forward.\nStill want this feature (wink)\n. Why was this closed?\n. ",
    "jamielinux": "It would be great if you could include a copy of the license, either in README.md or in a separate LICENSE file. It's actually a requirement of the license itself to include a copy of the license text.\nIt's also actually pretty standard across the visionmedia repositories to include a LICENSE file. Please reconsider?\n. Damn, still 8 failing tests. I thought I had it for a second.\n. Ah got it. connect needs to have qs updated to 0.6.6 too.\n. ",
    "travisjeffery": "_go_ figure :stuck_out_tongue_winking_eye: \n. https://github.com/visionmedia/superagent/pull/539\n. sweet. lgtm!\n. ",
    "noducks": "I ran into the same error running a test with mocha -w\n```\nTest\n  \u2713 should validate no input \n1 passing (2ms)\n/Users/username/project/node_modules/supertest/node_modules/superagent/lib/node/index.js:728\n      if (2 == fn.length) return fn(err, res);\n                 ^\n    TypeError: Cannot read property 'length' of undefined\n        at Test.Request.callback (/Users/username/project/node_modules/supertest/node_modules/superagent/lib/node/index.js:728:14)\n        at ClientRequest. (/Users/username/project/node_modules/supertest/node_modules/superagent/lib/node/index.js:693:10)\n        at ClientRequest.emit (events.js:95:17)\n        at Socket.socketOnEnd [as onend] (http.js:1568:9)\n        at Socket.g (events.js:180:16)\n        at Socket.emit (events.js:117:20)\n        at _stream_readable.js:929:16\n        at process._tickCallback (node.js:419:13)\n```\nRun with mocha -w , this test file reproduces it for me after a delay of 20 seconds or so.\n```\n    var request = require('supertest')('http://www.github.com');\ndescribe('Test', function(done) {\n        it('should validate no input', function() {\n            request\n                .post('/test')\n                .send({})\n                .expect(500, 'Invalid input.', done);\n        });\n});\n\n```\nIt turned out to be a typo, I had the done callback parameter in the wrong place. It appears as though the test is passing before the error pops up, which made it much harder to know which test was causing the problem.\n. ",
    "tripu": "Same error here using v0.17.0.\n. ",
    "craigspaeth": "I'm running into this error as well in 0.21.0. It's really hard to track down where this is happening and reproduce it, but in my case I'm getting a ECONNRESET at this point. This is caught properly, moves on and reaches this line and by then I find out this._callback is undefined and I get the can't call .length of undefined.\nThis is happening sporadically in my production app right now (FWIW seems to appear when blasting out a lot of requests... which is probably why there's a ECONNRESET being thrown from when the endpoint the superagent request is hitting probably closes off).\nAny insights would be helpful.\n. So far I think I've found a solution to my problem, but it seems like something that could be overlooked by others. Essentially I was instantiating request objects via var req = request.get('/foo/bar') and sometimes not closing them via req.end(function(){}). After enough of that I started to see the ECONNRESET and missing this._callback. More details in this PR https://github.com/artsy/backbone-super-sync/pull/29\n. :+1: this is exactly what I ran into in https://github.com/visionmedia/superagent/issues/339\n. Thanks for the quick response! I actually think I can do without this feature for now, but I'll reopen if I come back to it.. ",
    "theganyo": "Yup. Guess it can. Figured it would have been by the merger. Thanks.\n. Thanks, guys!\n. ",
    "bevacqua": "Lots of server-side HTTP libraries do this too, but I guess it's not my call! Hope it gets pulled in, though.\n. @yields if you wanted to change it, or remove it, you could just use .set()\n``` js\nvar superagent = require('superagent');\nsuperagent\n  .get('http://localhost:3345/ua')\n  .set('User-Agent', null) // or some string\n  .end(cb);\n```\nThe idea behind setting one by default is that you get a user-agent string no matter if you are on the client-side (browsers always set one, and you generally can't change it), or in Node, where it can be manufactured.\nIt's always useful to let the receiving end know where the request is coming from.\n. You are correct. setHeader won't remove them with null, void 0, false, nor ''. I think a .remove method would make sense. I could add it.\n. @yields Added!\n. Definitely makes more sense. I can roll back if @yields doesn't agree, though :-)\n. Done https://github.com/bevacqua/superagent/commit/71aaf225639ff978584a06962e965a93e3c713b3\n. ",
    "gasi": "+1\n. @yields Cool! How about naming it unset for API symmetry, e.g. get/set/unset?\n. :+1: \n. Ooooh, thanks, let me try that. If that works, I\u2019m happy to update the docs as well :+1: \n. Are the docs up to date now?\n. @gjohnson: Yes, there is the build change to have consistent component builds (documented in the changelog). The rest is just a side-effect of recompiling with the latest component version. Let me know if you need me to explain anything.\nI\u2019d like to build add some tests but had no luck running the existing ones locally. Would you mind helping me get up and running? See #345.\n. @gjohnson Sounds good, thanks. I\u2019ll check it out.\n. Alternatively, we could simply reintroduce debug using var debug = require('debug')('superagent');. Any preference? Happy to do the work.\n. Sounds good, thanks. What\u2019s the plan around releasing 0.18.0?\n. :smile: \n. It\u2019s been a while, but I believe aborting a request results in timeout error, although it shouldn\u2019t.\n. Frankly, it\u2019s been too long to remember all the details but I have the following. This issue occurred in the client-side library and I have this comment in this snippet:\njavascript\n// TODO: `err.timeout` is incorrectly reported:\n// https://github.com/visionmedia/superagent/issues/376\nif (err.timeout != null) {\n  error = new Error('Settings change event timed out.');\n  error.code = 'Timeout';\n  return callback(error);\n} else {\n  return callback(err);\n}\n. :+1: \n. ",
    "Redsandro": "I think I figured it out.\nThe superagent returns a value, which holds the actual request.\nsuperagent.req.output then contains the text after the full chain of commands is complete (and before any callbacks are made).\n. @igorescobar did you ever figure out what the problem was? I am running into the same.\n. @igorescobar you are right. I figured right about now that I was doing a request on a proxy, but the SSL certificate was for the end server.\nThis message is (probably) about mismatching SSL certificates. In node (0.12) you can opt to ignore the certificate, but I don't think SuperAgent uses this.\nThank you for getting back so soon.\n. @pornel (How) can I log the redirects happening?. @pornel the response.text in the callback is undefined for redirect events.\nDo you know how I can log the exact http response?. @pornel sorry, I don't mean the body, but the actual reply in http format.\nFor example (I made this up):\nHTTP/1.1 301\nDate: Mon, 22 May 2017 12:25:30 GMT\nServer: Apache\nLocation: http://www.foo.bar\nContent-Length: 100\nConnection: close\nContent-Type: text/html; charset=utf-8\nCan we retrieve this, or is superagent skipping this when status is 30x?. @pornel I can indeed get close using headers or rawHeaders. Also status works. I can't seem to find the protocol declaration though, e.g. HTTP/1.1 or HTTP/2.0.\nI understand this is not superagent specific but could be in the Node serverResponse object.\nThank you for the quick reponse. :+1: . ",
    "chrisbuttery": "+1 to using FormData!\n. Not sure what I was doing wrong, but this is working now. </newb>\n. ",
    "dkimdon": "I was thinking I'd be able to attach the tar.gz to the issue.  I don't see how to, here is a link to it:\nhttps://drive.google.com/file/d/0B1bDujiBV5HUblFmQ1h5V3JHZEk/edit?usp=sharing\n. ",
    "Silverwolf90": "Any success fixing this? I think I'm running into this same issue. The file size (not that it's particularly large) seems to be the trigger. If I send an empty file it works, if I send an xml document with 2000 lines, I get this warning and an ECONNRESET error.\n. ",
    "seriousben": "Getting this as well.\njs\nt('upload png too large', function(done) {\n       request.post('/api/files')\n      .attach('file', path.join(__dirname, './fixtures/largeImage.png'))\n      .set('Accept', 'application/json')\n      .expect(400)\n      .send(function(err, res) {\n        done();\n      });\n  });\n. I've had lots of socket hangup recently while using multipart requests... I wish there would be good alternatives..\n. ",
    "mjomble": "I ran into a similar problem. It seems like it's not that attachCookies is interfering with setting the JSON, but the other way around - using send() breaks subsequent attachCookies() calls.\nIf you look at https://github.com/visionmedia/superagent/blob/master/lib/node/index.js, you can see that Request.prototype.send calls this.request() which adds the cookies to the header, but also caches its result:\njavascript\nRequest.prototype.request = function(){\n  if (this.req) return this.req;\n...\n  // add cookies\n  if (this.cookies) req.setHeader('Cookie', this.cookies);\nWhich explains why attachCookies() must be called before send() or in fact before anything else that internally calls this.request(), otherwise a version of the headers without the cookies will be cached and returned on all subsequent calls.\n. Perhaps the issue should remain open as it's fairly unexpected and undocumented behavior. Ideally it should work regardless of the order of send() and attachCookies() or at least throw an error if you're using them in an unsupported order, rather than discarding the cookies silently.\n. ",
    "ihinsdale": "@mjomble Thanks for that clear explanation!\n. ",
    "waltonseymour": "+1\n. ",
    "stuartpb": "Where is any of this saveCookies/attachCookies stuff documented? I don't see any of it in https://github.com/visionmedia/superagent/blob/master/test/node/agency.js\nFurthermore, depending on its behavior to be used externally at all is a defect, since these functions are specifically marked \"private\" in the comments preceding their definition.\n. Also, this means that agent.get(url).end(cb) doesn't get its cookies set while agent.get(url,cb) does, which is completely bonkers. I'm assuming this is a regression?\n. ",
    "Nascotix": "It doesn't work.\n. I mean that I want to see the image by myself. But it's like the file is corrupted because the only thing I see is just black image.\n. I tried with several working image.\n. ",
    "aweijnitz": "I had the same problem, but not using streams, just getting and writing the res.body to a file. I looks like there is a bug in the image parser.\nTo fix it, go in and change the file lib/node/parsers/image.js to \n``` javascript\nmodule.exports = function(res, fn){\n    // broken: var data = '';\n    var data = []; // Binary data needs binary storage\nres.on('data', function(chunk){\n      //broken:    data += chunk;\n      data.push(chunk); // Append Buffer object\n  });\n  res.on('end', function () {\n      // broken: fn(null, data);\n      fn(null, Buffer.concat(data)); // Merge the chunks and return\n  });\n};\n```\nThe corresponding test case unfortunately does a 'utf8' encoded comparision and therefore this has gone unchecked. I am hoping to submit a fix and hopefully they'll take it.\nThere is a useful write-up here How to read binary data in the browser or under node.js?\n. FYI. Fixed the test and the parser and sent a pull request.\n. ",
    "mikegleasonjr": "+1\n. ",
    "RamIdeas": "Being able to accept a given query string - as is - would be helpful.\nPlease see #581\n. Sorry, I somehow had 0.21.0 installed. Only started this project last week, so not sure how/why npm did that.\nI've got 1.1.0 now and it works just fine :)\nFWIW, I did search before creating this issue. But somehow I didn't see #128\n. ",
    "jqsjqs": "Also... I'm actually using supertest but figured out it was the upgrade to superagent that was giving me a problem.\n. looks like the same problem.\n. ",
    "limelights": "@jqsjqs Can you confirm same bug on 0.18.2? I'm trying to post data using superagent but failing.\n. ",
    "bisrael8191": "For anyone else who finds this issue, 0.18.2 works but the documentation appears to be wrong:\npost/put requests\nI had to use the following to send query params instead of '.send()':\nrequest.post(url)\n  .type('form')\n  .query({fieldName: \"value\"})\n  .end(callback)\n. ",
    "popomore": "@alsotang \u6069\uff0c\u611f\u89c9\u8fd9\u4e2a\u6ca1\u5fc5\u8981\uff0c\u6211\u4e4b\u524d\u5904\u7406\u7684\u601d\u8def\u6709\u95ee\u9898\nThis PR is not necessary, I will close it.\n. ",
    "contra": "@defunctzombie Interested in merging a PR for this? Pretty major issue that pipes don't work with redirects, would def send one if you OK it.. @pornel It looks like this was fixed by TJ already a while back. Should be reclosed.\nMy issue was different, attaching 'data' listeners to a streaming request doesn't work so it isn't a real stream, it just has the pipe function. Threw me off, may need clarifying in the docs that pipe is just a sugar fn and it isn't a real stream.. @pornel Yeah, I get that a=1&a=2 is a perfectly fine way to serialize an array with more than one item and the server will parse it just fine. If I'm understanding you right, this is a wontfix because you don't want to break servers that don't understand [], which is more important than fixing single item or 0 item arrays.\nIs there any way to override the qs function globally on superagent (either via config, exposed prototype, or a plugin) instead of doing it for every request? I'll happily make a plugin if it's possible to override it.\nMight be worth putting a note somewhere that superagent serializes querystrings in a lossy way, this was a confusing bug to track down a few levels up in the stack.. @kornelski Yep, the code in the issue is just a starting point to the discussion around putting better support for ranges in superagent.\nConcretely I need to use this for downloading files in a resilient way - right now superagent is not suited to do that. If you're downloading a 16GB file to disk and the network hiccups somewhere you have to start over from the beginning. I'll probably end up making a plugin to handle this case really well, but it's worth having a conversation about how much of this should go into core (I think downloading a file is a pretty common case IMO).\nMy dream API (figured this was probably too much) would be:\njs\n// will detect range support, and in the event of any connection issue\n// it will continue the request where it left off\nrequest.get('largefile')\n  .resilient()\n  .pipe(transform)\n\nnot sure if ranges are used often enough to justify all the changes to have good range support\n\nServers support range headers - I can't think of any that doesn't. Usually request libraries is where the gap is, so they probably aren't being used as much as they should be.. @kornelski     That's already the case, I don't follow how adding the resilient functionality would make the problem any worse?. ",
    "ianwalter": ":+1: \n. Yea if you're intentionally aborting a request there shouldn't be an error.\n. ",
    "jasonkuhrt": "Confirmed. Just ran into this.\n. ",
    "jeromegn": "I believe there's no redirects in the browser since an AJAX request does not have the opportunity to act on a redirect. It's not aware of that fact.\nMore info: http://stackoverflow.com/questions/282429/returning-redirect-as-response-to-xhr-request/2573589#2573589\n. ",
    "gollygeewizard": "creating a stream and sending fails too. in Ruby or curl you can just pass -data-binary and be done with it which makes me think super agent is sorely missing a .data() to easily facilitate going beyond strings and json POST.\n```\nvar fs = require('fs');\nvar stream = fs.createReadStream(filePath, [options]);\nrequest(apiUri)\n    .post('/api/v1/assets')\n    .set('Content-Type', 'image/png)\n    .set('Content-Disposition', 'attachment; filename='+fileName)\n    .set('Content-Length', size)\n    .send(stream)\n    .end()\nresult: FATAL TypeError: Argument must be a string\n```\n```\nvar fs = require('fs');\nvar stream = fs.createReadStream(filePath, [options]);\nrequest(apiUri)\n    .post('/api/v1/assets')\n    .set('Content-Type', 'image/png)\n    .set('Content-Disposition', 'attachment; filename='+fileName)\n    .set('Content-Length', size)\n    .pipe(stream)\n    .end()\nresult: FATAL TypeError: Property 'end' of object # is not a function\n```\n```\nvar fs = require('fs');\nvar stream = fs.createReadStream(filePath, [options]);\nrequest(apiUri)\n    .post('/api/v1/assets')\n    .set('Content-Type', 'image/png)\n    .set('Content-Disposition', 'attachment; filename='+fileName)\n    .set('Content-Length', size)\n    .write(stream)\n    .end()\nresult: FATAL TypeError: first argument must be a string or Buffer\n```\n. Found the secret sauce... Posting as I am sure others may run into this at some point. Adding an example to the docs would help too.\n```\nvar fs = require('fs');\nvar data = fs.readFileSync(filePath);\nrequest(apiUri)\n    .post('/api/assets')\n    .set('Content-Type', 'image/png)\n    .set('Content-Disposition', 'attachment; filename='+fileName)\n    .set('Content-Length', data.length)\n    .send(data)\n    .end()\n```\n. ",
    "undoZen": "When will new version on npm roll out? It have been almost 3 months since I open this pr.\n. I strongly support this. There are bug fixs I need in master but npm module\nhave not been updated for months, I have to maintain it in my own registry.\nOn 9 Sep, 2014 3:58 am, \"Alberto Pose\" notifications@github.com wrote:\n\nCould it be possible to release to npm a new version with all the updates\nin master? Thanks!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/449.\n. +1\n. @davis have a look at promisingagent\n. \n",
    "pilerou": "+1 same needs with bearer....\n. ",
    "markuso": "We are having the same issue as well where the app we are testing sets the session cookie domain like this .example.dev and the route urls of the app are mixed like sub1.example.dev:3000 or sub2.example.dev:3000.\nAll this works fine in the browser session and cookies are applied properly given that they apply for the entire domain and all its subdomains. In our Express routes and API tests, the change @prasunsultania is proposing did indeed fix our issue. Hoping to see the fix in the next release.\nThe question though, what if people are setting their cookie domain with a port? I guess the fix might then cause a problem for them. Unless the best practices is not to usually include the port in the cookie domain.\n. ",
    "prasunsultania": "@markuso \nAs per RFC#6265 Section 8.5 - \"Cookies do not provide isolation by port.  If a cookie is readable by a service running on one port, the cookie is also readable by a service running on another port of the same server.  If a cookie is writable by a service on one port, the cookie is also writable by a service running on another port of the same server.  For this reason, servers SHOULD NOT both run mutually distrusting services on different ports of the same host and use cookies to store security-sensitive information.\". \nAlso, I tried using cookie domain as .localhost.io:5000 in an express app using app.use(express.session({cookie:{domain:\".localhost.io:5000\"}})) , it fails to set any session cookies on browser.\n. @gjohnson any update on this? We are using superagent for all HTTPs.\n. ",
    "henryoswald": "Thanks for fixing this. Is it possible to get this released to NPM soon? Its currently blocking one of our feature releases.\n. ",
    "mbelshe": "Yeah, I don't think this is great either.\n. ",
    "katcipis": "@vstirbu  how can i help to make this happen ? :-) I'm really interested on having this feature.\n. i have seen the broken build and supposed that something was missing, but it seems that it is broken only on nodejs 0.8, is it acceptable ?\nI want to fix supertest by implementing octet-stream support on superagent, it seems to me that your pull request can make it happen. But until now it seems no one is merging it, that's why i asked if there is something missing :-)\n. Now i understand, i probably need to implement the support for this on the node side. As for support, both supertest and superagent are kinda slow :-)\n. ",
    "vstirbu": "The pull request adds the feature for the browser side of supperagent. I've also updated the first comment to add a bit more detail on what you have to do in the application to use it.\n. I have made changes only on the browser side, so I do not know why the node side fails the test on node v0.8.\nIt would be nice to get some feedback from maintainers if this is the right approach. :)\n. @defunctzombie I've made another PR on the same topic #566 .\nNot the walk in the park as initially expected as the library API changed a bit. This feature is only against the client side. Node side does not have this limitation.\n. The library does not support out of the box this feature. #393 allows you to get blobs or array buffers from a server.\n. ",
    "jwerle": "what is keeping this from being merged in ?\n. ",
    "twoBoots": "Would be great to see this merged in!\n. ",
    "SanderSpies": "Still needed when doing a request inside onunload and related events. Please re-consider adding it :-)\n. ",
    "danieljoppi": "+1\n. ",
    "psanders": "+1\n. ",
    "blackbing": "+1\n. Same reason with @SanderSpies which is onunload event. While Navigator.sendBeacon can only send POST and can not set custom header in spec. I know it will be deprecate in the future, but this is an option variable in XMLHttpRequest spec. I think library should not limit the usage, developer have to know what they are doing. \n. ",
    "krismeister": "Our use case is we're trying to get off MeteorJS onto a new api. Alot of meteor runs sync due to keeping the DB connection open in the node side. Our api calls need to run sync at the node level similarly.\nI know it's might be an edge case,  but it's what we're facing.. @focusaurus I didn't realize this about node, likely due to my confusion about the yield and async/await syntaxes. You're exactly right Meteor does this through fibers and their own implementation to do async promises Promise.await(superagent.get(...)), for which Superagent worked beautifully.. ",
    "barroudjo": "Any way around it ?\n. I try to share a module between our server app and our client app, and this module requires a downloader.\nCurrently we use superagent as the downloader on the server side via this code:\n```\nvar getUrl = function (options, callback) {\n    var range;\n    var query = request.get(options.url);\nif (options.range) {\n    range = make_range(options.range.start, options.range.end);\n    query = query.set('range', range);\n} else if(options.responseType.toLowerCase() === 'text'){\n    query = query.buffer();\n}\n\nquery.end( function (err, res) {\n    var result, bufferSize, error, index, response;\n    if (err) {\n        callback(err);\n    } else if (res.error) {\n        error = new Error(\"GET query failed. Verify your URL\");\n        callback(error);\n    } else if (options.responseType !== 'text') {\n        bufferSize = res.header['content-length'];\n        console.log(bufferSize);\n        res.on('data', function(chunk) {\n            if (!result) {\n                result = new Buffer(chunk);\n            } else {\n                result = Buffer.concat([result, chunk]);\n            }\n            if(options.responseType.toLowerCase() === 'arraybuffer') {\n                response = (new Uint8Array(result)).buffer;\n            }\n            else if(options.responseType.toLowerCase() === 'buffer'){\n                response = result;\n            }\n        });\n        res.on('end', function (err) {\n            callback(null, {response: response, pptes:options.pptes});\n        });\n    } else {\n        callback(null, {response: res.text, pptes:options.pptes});\n    }\n});\n\n};\n```\n(pardon the ugly code, this is due for a good cleaning :-) )\nAnd when we use this bit of code on the client, it bugs at the line:\nquery = query.buffer();\nThe reason we need this line, at least on the server, is because in some cases we need the text of the response, not the binary data. If we don't do that, we don't get the res.text field.\nThanks for the help !\n. The content type is 'application/octet-stream'. Which makes sense, what we're doing is downloading a file. But that file is text (xml), and instead of decoding the binary data, we'd rather get the text directly, as we do with buffer().\nCurrently we do this on the client by setting xhr.responseType to 'text'.\n. ",
    "bryancallahan": "@barroudjo I'm using https://www.npmjs.com/package/superagent-browserify (v0.0.2) and it's working great w/ superagent v0.11.0 (also using browserify v7.1.0).\n. ",
    "adam-lynch": "@bryancallahan FYI the version of superagent that superagent-browserify installs looks out of date\n. ",
    "mjhasbach": "@defunctzombie You could perhaps leverage bops to add buffer support to the client.\n. Perhaps ArrayBuffer, then.\n. ",
    "MitchK": "Solved: Forgot app.use(require('body-parser')());\n. ",
    "pablolmiranda": "A node-cookiejar version 2.0.0 was deployed on npm registry.\n. ",
    "ghemingway": "Actually, this really would be nice to get included.\n. ",
    "cedx": "This worked for me using a stream:\n``` javascript\nvar fs = require('fs');\nvar request = require('superagent');\nvar output = fs.createWriteStream('path/to/file.zip');\nrequest.get('http://domain.com/path/to/file.zip').pipe(output);\n// \"output\" contains the raw data.\n```\nUse a module like memorystream if you don't want to store the output on the file system.\n. ",
    "chollier": "I feel like there's also an issue on the client-side part https://github.com/visionmedia/superagent/blob/master/lib/client.js#L686-L690 \nI'm getting Signature errors from chrome when trying to use .attach\n. ",
    "Schoonology": "@gjohnson and @defunctzombie - I just lost a couple hours to this yesterday, and this looks like the Right Way(tm) to fix it. I'd like to go the options route, as that gives users a lot more flexibility.\nCan you think of any other ways to improve this, or should I fire away with a PR to this effect?\n. It does, and they're quite handy: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L938\n. @defunctzombie - I added three previously-missing tests:\n1. Browser-side response event\n2. Browser-side request event\n3. Server-side response event\nI tried to match the paint already on the walls; please let me know how this could be better.\n. Does that mean you'd rather that block look like the following? (Sorry for the delay, but I just now realized your last comment meant I needed to change something! I misinterpreted \"we\" the first time around.)\n``` javascript\nthis.on('end', function(){\n  var err = null;\n  var res = null;\ntry {\n    res = new Response(self); \n  } catch(e) {\n    err = new Error('Parser is unable to parse the response');\n    err.parse = true;\n    err.original = e;\n  }\nif (res) {\n    self.emit('response', res);\n  }\nself.callback(err, res);\n});\n```\n. Sweet. Updated.\n. @defunctzombie - Is there anything else needed here? Trying to make sure I'm not holding this up.\n. ",
    "couchand": "Or maybe I'm wrong.  Looking into the code I've discovered it uses fn.length to determine intent.  That seems like a nice feature, so perhaps the documentation here could be made more obvious.\n. ",
    "vvo": "Support for XDR, was added and then removed https://github.com/visionmedia/superagent/search?q=xdr&type=Issues&utf8=%E2%9C%93\nXDR has lots of limitations as you said, that's why it may not fit this more advanced library.\n. ",
    "trevorreeves": "Sounds good to me.  Hopefully people like me on projects like mine will soon enough not be given requirements to support IE 8 and 9 - they're slowly but surely dying.\n. ",
    "knownasilya": "Still an issue, see https://travis-ci.org/Strider-CD/strider-github/jobs/104789778#L299\nCode is here: https://github.com/Strider-CD/strider-github/blob/master/lib/api.js#L134\nWorks in > 0.10 of node, but 0.10 is broken.\n. ",
    "igorescobar": "@Redsandro sorry bro but it's been awhile since I got this error... I don't remember what I did to solve it. But it was probrably something in my local network or my machine. This is not a superagent bug.\n. @Redsandro I'm glad to hear good news from you! I'm under an authenticated proxy too, maybe this is what we have in common :+1: \n. ",
    "ggoodale": "Is 0.18.3 going to be released with this fix anytime soon?\n. ",
    "buildmaster": "That's what I'm unsure of, all nock is doing is throwing an exception pre connect: https://github.com/pgte/nock/blob/master/lib/intercept.js#L223 Not sure if anything else would do this but it seems odd that that results in a \"Double Callback!\" message and a TypeError rather than the original exception bubbling up. this seems to be the simpler fix which is why I submit it but understand if it's not something you want to fix here. \n. ",
    "samouri": "Hey all,\n1. I think that the improper error bubbling is a nock issue\n2. The double callback is a superagent issue.\nThe way most clients are probably utilizing superagent:\n1. The end function is invoking the callback after trouble setting the query args: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L642-L659 \n2. The Nock overriden request emits an error causing the superagent error handler to invoke the callback a second time: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L531-L540\nWould this be a good/generic solution? \n1005\n. @pornel, what is the desired behavior in this situation:\n1. client of request library creates a new request with various params\n2. client calls .end()\n2.1 within .end(), there is an error adding the query params in _appendQueryString.  This causes the callback to be invoked: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L642-L659\n   2.2 The http request created in end() throws an error.  As things are now this will cause the callback to be invoked again: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L531-L540 \nUnit test that would replicate this:\n``` javascript\n  it('should not invoke the callback twice when an error is thrown by both the request and adding query args', function(done){\n    var req = request\n    .get(base);\nreq._appendQueryString = function() { throw new Error('error adding querystring') };\nreq.end(function(err, res){\n  req.req.emit('error', 'error thrown in request');\n});\n\n})\n``\n. So let me make sure I understand this correctly: \nSuperagent would never run into this normally because _Node.js_'s [Http.ClientRequest](https://nodejs.org/api/http.html#http_class_http_clientrequest) does _not_ emit errors until the request has been started (flushHeaders,write,end`, etc. has been called).\nFor this I agree that nock should not emit errors until one of the request-starting functions have been called. I'll open up a thread with them on the topic.\nEDIT: relevant nock thread\nBut in terms of superagent handling requests -- wouldn't it make sense to protect against this sort of issue (clients directly accessing the request object or tampering with it somehow like in the case of nock) by clearing listeners to req any time superagent.end aborts mid-way (like in this case of errors adding query string)\n. I looked into it and moving appendQueryString would break superagent functionality.  Usually people can call .query multiple times before sending out a request and each new query gets appended.    The way appendQueryString is right now, it is meant to be a final mutator.  It will only append if there is no querystring yet.\n. ",
    "wavded": "Since this API is chainable, this wouldn't work but maybe a chain closer that returns a promise, like exec() or make end() return a promise instead of itself (not sure that the use case is for that)?:\njs\nPromise.all([\n    request.get('http://example.com').end(),\n    request.get('http://example.biz').end()\n]).then(function(){\n});\n. Turns out you can extend superagent fairly easily to provide this functionality:\njs\nrequest.Request.prototype.exec = function () {\n  var req = this\n  return new Promise (function (resolve, reject) {\n    req.end(function (er, res) {\n      if (er) return reject(er)\n      resolve(res)\n    })\n  })\n}\nThen run:\njs\nPromise.all([\n    request.get('http://example.com').exec(),\n    request.get('http://example.biz').exec()\n]).then(function(responses){\n    // handle data\n});\n. @defunctzombie any chance we can get a release with this?\n. Just got bitten by this in an isomorphic React app.  Used Qs.stringify on the browser side as well to get around it but would love to see it fixed.  To recap, browser-side was producing the grievous a=1,2,3 and server was producing the proper a[1]=1&a[2]=2&a[3]=3\n. ",
    "lapo-luchini": "Just for the records, I noticed it has been added in the meantime and the opening post example is now perfectly working as is.\n. I'm very willing to PR for the node version (as that's what I'm currently using), but I'm not sure when I'd be able to check it in the browser too.\n. Oh, I noticed that in the browser code while the third field is called filename the example it's already using it as an object to specify the content type (though it seems strange that it's using type instead of contentType as accepted by the library; maybe there is a conversion somewhere in the code path, but I didn't find it).\nAlso, the browser tests won't break, as the only test doesn't cover the third parameter.\n. (I'm not sure about travis, but it didn't break make test-browser-local)\n. @martinbooth you're right, that should be a o.filename.. I suggest the following fix:\ndiff\n--- node_modules/superagent/lib/request-base.js.orig    2018-04-20 11:32:08.960725000 +0200\n+++ node_modules/superagent/lib/request-base.js 2018-04-20 11:40:19.227878000 +0200\n@@ -235,6 +235,7 @@\n       console.warn(\"Warning: superagent request was sent twice, because both .end() and .then() were called. Never call .end() if you use promises\");\n     }\n     this._fullfilledPromise = new Promise(function(innerResolve, innerReject) {\n+      self.on('error', innerReject);\n       self.end(function(err, res) {\n         if (err) innerReject(err);\n         else innerResolve(res);\nwhich removes the Unhandled 'error' event by making explicit that Promises are managing the error.\n(even though they were doing it already, by .end first parameter, really\u2026)\nIf you think it makes sense, I can create a PR (with tests).. Latest NPM, v3.8.2.\nOn Windows (where I am now) the output is slightly different (but the same idea):\n```\nPS C:\\Users\\lapo\\t> npm install superagent\n+ superagent@3.8.2\nadded 24 packages in 1.349s\nPS C:\\Users\\lapo\\t> node test\nevents.js:137\n      throw er; // Unhandled 'error' event\n      ^\nError: ENOENT: no such file or directory, open 'C:\\Users\\lapo\\t\\does-not-exists.txt'\nwith patch:\nPS C:\\Users\\lapo\\t> node test\nCATCH ENOENT: no such file or directory, open 'C:\\Users\\lapo\\t\\does-not-exists.txt'\n```. No, as the third parameter is an object, even though a string is accepted.. ",
    "aheckmann": ":)\n. ",
    "roland-vachter": "No idea why the travis CI build failed, it passed on my machine. It seems it is something to do with some configuration on the initial set of tests, and not an assertion actually failing.\n. I would be good if travis would have a retest button. It passes on my machine, I will try to trigger another test.\n. I created another one where the build passed: https://github.com/visionmedia/superagent/pull/425\n. Hi guys,\nFirst of all thanks for including this.\nI think it is actually helpful because:\n1. It adds just a few bytes weight to the whole project\n2. IE9 is considered a quite modern browser, but this module couldn't be used without this enhancement in IE9 which is a drawback to consider.\n3. An XMLHttp shim would probably redefine that object and it could affect other frameworks (like jQuery). This way of integration actually isolates the shim from other frameworks which is a best practice in my opinion.\n. Bower would be nice to be supported, it's kind of a standard nowadays.\n. ",
    "ryanseddon": "What's the timeline for this to be tagged and published onto npm? \n. ",
    "nrako": "IMO I don't think it's a good idea to include XDomainRequest support in superagent. At first I was happy to see this PR, I quickly tried as I thought it would solve some of my needs. I was wrong!\nI forgot how XDomainRequest is a big pile of :shit: and pain in the ass, incomplete and buggy. It bring more problems that it solves. Anyone that has to surrender to xdr must fully understand the cons and develop from start with that in mind. It involves so much quirk handling (header, methods, http code) that you don't add support for CORS in IE<10, but you develop for IE<10 XDomainRequest limitation.\nIf someone has to go down the road of XDomainRequest it should just extend superagent with something that suit his need (i.e always respond 200 and pass the code in the body response, send header in query etc.). On my case I was able to use a proxy and quickly made a superagent extension for that https://github.com/nrako/superagent-cors-proxy. I don't have time to polish it right now but it works perfectly for my use.\nXDR :gun: is destined to die anyway.\nSo please don't add this cranky shit in superagent, this will only lead to a huge wave of stupid issues.\n. Oh no please revert! Don't publish this to npm! @naman34?\n@singh1469 have a try with my extension https://github.com/nrako/superagent-cors-proxy see if it's suits your need you'll be in a way better situation without XDR!  If something is missing (i.e requests to multiple domains) let me know or do a PR and we'll work out something together.\n. ? @omeid did you read the latests comments? :neutral_face: \nAnd maybe if superagent doesn't do what you need, take a look at the existing extensions... or make your own.\n. ",
    "singh1469": "I agree IE9 is (unfortunately) considered to be a modern browser. Please publish this to NPM as I could do with this feature.\n. @nrako I'll take a look.\n. ",
    "jkimbo": ":+1: any update on this?\n. Thanks!\n. ",
    "tarjei": "This also happens to POST requests recieving 201. Empty responses should not be parsed. \n. @jacwright if an API returns null and there is an error in the request, then this should be indecated in the HTTP status code.\nAnyhow, another solution is to add thorough documentation on the subject and how it may be avoided by changing parsers.\n. @pornel when was this bug fixed?\n. ",
    "naomik": "Why is this issue closed ?\nHow can we do a HEAD request to a json resource ?\n. @gjohnson has it been rolled into a versioned patch yet? I just installed the latest version 0.19.0 and I'm still getting the same problem.\n. If I actually knew how to fix this, I happily would.\nFor now, I'm using\n``` js\nvar request = require(\"superagent\");\n// remove the problematic parser\ndelete request.parse[\"application/json\"];\n// HEAD request\nvar req = request.head(\"http://ip.jsontest.com\").end(function(head) {\n  console.log(head.type); //=> application/json\n});\n```\n. ",
    "dzucconi": "Bump\n. @tarjei Indeed, some documentation would be appreciated as HEAD requests for JSON resources just don't work out of the box.\n. ",
    "jacwright": "416 will actually return a parse error for empty responses rather than a null. This may still be applicable.\n. That's a good point. To the API @tarjei is using, an empty string may mean a null, to another API it may mean there was an error in the request.\n. I used a more verbose error message to be consistent with other errors in the library. Shouldn't we be consistent?\n. Again, this is consistent with other errors in the file. E.g.\nvar err = new Error('Origin is not allowed by Access-Control-Allow-Origin');\n  err.crossDomain = true;\n  this.callback(err);\n. Perhaps not. However I did not want to include updates for other tickets in this one. If you think we should take it out I can update the PR.\n. ",
    "pdehaan": "This fixes #436\n. link to majorleaguesoccer/restify-url-version#1\n. Updated qs module was fixed by #435.\nI'll leave this open in case you want to update any of the other dependencies, or you want me to rerun nsp shrinkwrap or npm outdated.\n. ",
    "roark31337": ":+1: \n. ",
    "bahtou": ":thumbsup: \n. ",
    "pkaminski": "Have you made a decision yet @gjohnson?  I guess I also don't understand why a simple compatibility fix that prevents a hard crash needs to wait on a design decision.\n. I opened https://github.com/segmentio/analytics-node/issues/72 but it's not clear how well that project is maintained.  I still think improving the warning message would be a good thing to do since right now it takes a fair bit of Googling (and luck) to find the source.\n. Actually, I think the double callback warnings are coming from superagent 2.3.0.  Take a look at the log histograms below, the first for request timeouts that I know were made through superagent 2.3.0, and the second for double callback! warnings:\n\n\nNot an exact match, but definitely a strong correlation that's exceedingly unlikely to be coincidental.\n. ",
    "mdawaffe": "See also #548.\n. This will prevent CORS requests from using progress events completely.  What about only adding the XHR listener if  . hasListeners( 'progress' ) is true?\n. ",
    "nschurmann": "Solved, npm install ms. Also for every package that requires.\n. ",
    "stephanebachelier": "@gjohnson I think this issue can be closed as the 0.20.0 is out.\n. @ilyaigpetrov Since this is an issue since 0.21.0, I've published superagent-dist on bower, that just bundle and release the new version with the same semver.\n. @ccapndave it seems related to #484 \n. @pornel Thanks! \nI've some legacy code and I don't have the time to upgrade to 2.x.x (for now!)\n. ",
    "joanniclaborde": "+1\n. ",
    "constantx": ":+1: \n. ",
    "magalhas": "No one?\n. ",
    "huang-xiao-jian": "Actually, I don't understand the description quite well, but code below may be helpful for you.\nbackend data resolve first.\n``` javascript\nvar express = require('express');\nvar multer = require('multer');\nvar app = express();\napp.post('/',  multer({\n    inMemory: true,\n    includeEmptyFields: true\n}), function(req, res) {\n    /\n     req.files contains file information\n     req.body contains other non-file information\n     /\n    res.json(req.body);\n});\napp.listen(1337);\n```\nsuperagent with multipart\n``` javascript\nvar request = require('superagent');\nvar should = require('should');\ndescribe('superagent', function () {\n    it('with multi part', function (done) {\n        request\n            .post('http://localhost:1337')\n            .field('name', 'born')\n            .field('age', 23)\n            .attach('package', 'package.json')\n            .attach('index', 'index.js')\n            .end(function(res) {\n                try {\n                    res.body.should.eql({\n                        \"name\": \"born\",\n                        \"age\": \"23\"\n                    });\n                    done();\n                } catch (err) {\n                    done(err);\n                }\n            });\n    });\n});\n```\nIn theory, supertagent support  both part lower-level and field, attach higher-level api . @magalhas \n. ",
    "zbyte64": "Okay two things,\nIs part really deprecated? If so shouldn't it be removed from the docs?\nCan attach accept a file stream or a blob of text isntead of reading from a filename?\n. ",
    "formula1": "It appears this was not answered\nHeres what I have found if it helps anyone\n- superagent basically is just a wrapper around the form-data module when it comes to multipart post calls. The wrapper transforms strings into readable streams so your best to expect that a normal stream should work as well\n- form-data's append method is a wrapper around combined-stream's append. \n- combined-stream's converts all streams into a delayed stream then pushes the value (regardless of whether its a stream or not) on the list of streams\n- combined-stream's way of handling its list of streams is pretty straight forward. If its a stream, it pipes. If it isn't it just writes the values.\nIn other words passing a blob or a readableStream seems to be fine.\nIf you want to pass a content type, you must provide a exstension that will qualify as the type you want. This seems straightforward however it is not in all cases since if you want to send a file as application/x-patch that will not be possible as it is not in the mime-db\nUpdate - I was wrong on the arbitrary readable stream.\n. Multipart has not been working for me either. However my situation may be unique(ish) https://github.com/felixge/node-form-data/issues/90\nhttps://gist.github.com/formula1/582b2acb8c1e6513fe1a\n. ",
    "misha-slyusarev": "I'm using superagent with React and Rails and trying to compose a multipart request for the backend.\nIs there a way to add a JS object to the request without adding it field by field? For instance, I would like to have {'invoice' => {'recipient_attributes' => {'name' => 'myname', 'last_name' => 'mylastname'}, 'attachment' => ... } as my params in Rails backend part. And that's how I'm trying to do it:\nrequest.post('v1/invoices')\n      .field('invoice[recipient_attributes]', this.state.recipient)\n      .attach('invoice[attachment]', this.state.invoiceFile)\n      .end(function(err, res){\n        console.log('invoiceInfo submitted')\n      });\nBut recipient_attributes is saved as '[object Object]' instead of expected. Is there a way to add the whole object, or I have to add fields one by one like this:\n.field('invoice[recipient_attributes][name]', 'myname')\n.field('invoice[recipient_attributes][last_name]', 'mylastname')\nThank you in advance!. ",
    "redonkulus": "I've done some debugging and think it could be a bug with the parse function completing after the response has already been finished.  I found that the parser code does not finish before the logic continues.\nI produced this by outputting a console message in the parser function and one here. The one in index.js displayed before the one in the parse function.\nModified text parse function:\nmodule.exports = function(res, fn){\n  res.text = '';\n  res.setEncoding('utf8');\n  res.on('data', function(chunk){ res.text += chunk; });\n  res.on('end', function(err){\n      console.log('parser end');\n      fn(err, res.text);\n  });\n};\nI could just be doing things wrong...\n. ",
    "gechols": "I found this thread when I was trying to do the same thing. I found that setting superagent.buffer(true) and then using the response.text worked.\nOf course, in my case the content was actually JSON by another name so it was safe to treat it as a string. This may not be the case for binary data.\n. ",
    "jonathankeebler": "Looks like the Travis CI build kicked off twice and annihilated itself :)\n. +1\n. ",
    "cayter": "+1\n. ",
    "der-On": "Yes please fix this. It's happening for me too.\n. ",
    "mwq27": "+1\n. ",
    "rooftopsparrow": "Starting at 0.18.2, I get a [SyntaxError: Unexpected end of input] and console output \"double callback!\" when receiving a 408 response from a server.\n0.18.1 seems unaffected.\n. ",
    "thedersen": "+1\n. I need this as well. It works fine on the client, but the behavior should be the same on the server.\n. Looks like it works just fine now :) Thanks!\n. ",
    "sporto": "@defunctzombie is not about waiting for several things in the application itself, this can be done with callbacks or async as you say.\nIt is about writing end to end test that depend on an ajax response to be finished. For example:\n- I write end to end test using a tool like https://github.com/jnicklas/capybara (which uses Selinium or PhantomJS)\n- capybara clicks on things that triggers ajax request\n- then I want to assert that something is shown for example, but I need to wait for all ajax request to be finished first\nThe capybara has no way to ask superagent if there are ajax request going on. \n. ",
    "hellboy81": "This event can not be handled\n. ",
    "juancoen": "I've tried this and the 'response' callback do not work with get requests.\nI'm not sure if this is the 'proper way' to do this, but if you really need it, you can access the response status code in the 'end' callback doing\nthis.res.statusCode;\nThis breaks encapsulation, so be aware that it might change in future superagent versions.\n. Hi!\nI'm not sure if this is the 'proper way' to do this, but if you really need it, you can access the response status code in the 'end' callback doing\nthis.res.statusCode;\nThis breaks encapsulation, so be aware that it might change in future superagent versions.\n. ",
    "HenryGau": "+1 I think it should be mapped to a response.error and let the callback handler to handle the error\n. @brugnara this error handling is already taken care of in the API\nhttp://visionmedia.github.io/superagent/#error-handling\nrequest\n  .post('/upload')\n  .attach('image', 'path/to/tobi.png')\n  .on('error', handle)\n  .end(function(res){\n  #handle ENOTFOUND error here\n  });\nI think you can close the ticket.\n. ",
    "tentonaxe": "the HEAD fix didn't fix the issue for POST and DELETE requests that return 204.\n. ",
    "codeHatcher": "Thanks for posting that alt address. Was getting this and was just about to post something similar. \n\n. ",
    "utatti": "\nThis part should be updated as well :)\n. ",
    "tgohn": "+1\nsimilar pull requests for this same issue:\nhttps://github.com/visionmedia/superagent/pull/473\nhttps://github.com/visionmedia/superagent/pull/456\n. ",
    "fetmar": "I'm also getting this error in the browser when a request is made and there's no connection to the internet.\n. ",
    "Fishrock123": "Likewise. I think I also get incorrect cross-domain errors when the URI has no handler, maybe.\n. ",
    "palamccc": "+1, One of my xhr request takes 5 seconds to complete, and if page is refreshed before completion, i am getting cross domain violation error. All of my requests are sent to same origin domain only. From stack trace, it looks like the error is generated at https://github.com/visionmedia/superagent/blob/0.21.0/superagent.js#L1280 (Win7, Chrome 40).\nIt looks like this exception is generated, when page load is aborted by browser. You can see this exception in console only if you enable preserve log in developer console.\n. From what i understand,\nWhen a request is aborted, it may be user interruption (user leaving the page) or due to cross domain violation error. since there is no foolproof way to detect the reason, I think its better to throw generic \"Page Aborted\" exception. (Developer can anyway find out about cross domain violation from web console.)\nAs of now code throws self.crossDomainError() for all abort cases.  https://github.com/visionmedia/superagent/blob/0.21.0/superagent.js#L1280\n. ",
    "zackify": "this is still happening to me. The request goes through, then this error gets thrown. Really weird.\n. This has been a problem for so long. I've moved on to using fetch since\nit's going to be the new standard for doing Ajax requests.\nOn Mon, Nov 30, 2015 at 18:10 Kornel notifications@github.com wrote:\n\nAgreed that this is misleading and unnecessarily jumping to conclusion.\nAs mentioned in #653 (comment)\nhttps://github.com/visionmedia/superagent/pull/653#issuecomment-126088770\nfixing this could be a breaking change. As bad as it is, there are\napplications that check for this particular error.\nI suggest keeping API backwards compatible, but extending the message to\nadd something like \"or it could be aborted connection, user-agent offline,\netc.\"\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/484#issuecomment-160791372\n.\n. \n",
    "grrowl": "+1 if this is the case it really should be documented. We're capturing many error.crossDomain = true errors in Sentry but we've been diagnosing them as if we have a server issue; in fact, it might be regular run-of-the-mill connection aborted during navigation.\nAs it stands, I don't think we're able to tell at all (and neither is superagent?)\n. I think \"Transport Error\" might be more obvious and descriptive than \"Outbound Error\" (I read it as \"out of bounds error\" for a while)\n. > I suggest keeping API backwards compatible, but extending the message to add something like \"or it could be aborted connection, user-agent offline, etc.\"\nKeep the API backwards compatible, but deploy the changes as a new major version. This is too misleading to keep around in the name of not breaking older apps, and semver exists for a reason.\n. ",
    "kahnvex": "I am running into this issue as well.\n\nI am open to suggestions on how to detect this better.\n\n@defunctzombie I think detection is going to be difficult. Right now superagent is gobbling the xhr and naively assuming CORs error. That seems wrong. The responsibility of knowing what happened can at least be offloaded to the user, if we give them the xhr with status = 0. Right now the user has to catch the error and string match on it to do anything about it.\n. It should also be trivial to attach some information to the error informing users that it could be a CORs error.\n. I'm pretty sure the intent was not to add a full on promise implementation. Promises A+ spec documents the use of thenables, objects with then functions. These can be used by libraries like Q to map the async task to a real promise. With Q you can do:\njavascript\nQ(thenable).then(...).fail(...).done();\nhttps://promisesaplus.com/\n. Yeah, please don't roll a Promise polyfill. I'd have to consider moving all my projects away from superagent at that point. It's a good amount of bloat, and we already have big projects using Q and superagent together. I'm sure a lot of other users would echo this sentiment. Thenables are fine, they should simply be documented as such.\n. > I'm assuming that nobody would be interested in using the .then() method without using promises in their code.\nAre you assuming that when people use promise libraries, they add them to the global namespace? If so, that is sort of a silly assumption.\n. > I think you're wrongly assuming that you need to implement promises. The way I see it it's something you integrate with, not something you provide.\nI think you are wrongly assuming that everyone who wants to use promises exposes a Promise global for other things to integrate with. Why is it necessary to break compatibility with users who don't make a Promise global? MDNs Promise documentation even shows you how to use a thenable to create a real promise. https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/resolve\nWhat are your reasons for pushing this? Is there some upside I'm missing that isn't already easily achievable? I can only think of down sides.\n. I think this is sacrificing compatibility for convenience. Doing this would break thenable coercion methods in most promise libraries on environments like Node 10, and on browsers like IE10, IE11 and Safari 6. I agree that your suggestion is cleaner, better, and preferable, but only marginally and if you assume everyone uses FireFox or Chrome. The downside is pretty bad for consumers relying on Promise libraries that don't polyfill Promise.\nA thenable is a thing. It is in Promise A+ spec. Yes it is a stopgap solution until ES6 Promises are used everywhere. The javascript community is simply not there yet.\n. This addresses my compatibility concerns by adding a thenable fallback, but is weird/unexpected from a behavioral standpoint.\nAlso, I'd suggest returning a promise from the .end() method if there is community support for it. Having the then method fire the request is arbitrary and weird. If the goal is to use real promises, we should use promises as they were intended - then methods should not perform actions other than to return a new promise. You could also add a new function .endPromise(), or something like that to address backward compatibility concerns.\n. ",
    "ahoym": "+1, got this false CORS error when redirecting to another page while requests were in flight.\nAccording to the wc3 spec, The causes of an xhr.status of 0 can also be \"some type of network error or fetch termination\" -  the latter of which applies to my case. As @kahnjw pointed out, we can't assume that a xhr.status === 0 will be a CORS.\nI think a general blanket that covers all these cases is that something went wrong with the outbound request. I'll make a PR that implements that, as well as attaching information on the possible causes. Discussion and suggestions are more than welcome.\n. To avoid string matching, we can probably also attach the xhr as a property of err, or simply throw the xhr itself. This way, the user can catch and handle the xhr status 0 in the way they see fit\n. ",
    "lazreg87": "+1 Where are we on this?\n. ",
    "deregtd": "Latest superagent still throws the same error. :(  I vote for \"unknown transport error\" or something like that.  Maybe try to be really fancy and detect if the request was a CORS-based request or not (check the url of the source and the target for matching host), and set the crossDomain flag then, but making that the message seems bad.\n. ",
    "oluckyman": "As said in #679 that error occurs also if there is no internet connection.\n. ",
    "rohitlodha": "+1 @grrowl for transport error. superagent should just pass the error to user.\n. Same here. Can you suggest the best way to deal with error?\n. ",
    "magicdawn": "Since we can't tell what status=0 means, we should not swallow the error.\n+1 on Transport Error & err.status = 0\n. js\nrequire('superagent').get('http://libs.baidu.com/jquery/1.8.3/jquery.min.js').pipe(process.stdout);\nwe can see the correct result.\nSince the return mime type as application/x-javascript. so it's not buffered. use .buffer(true) to explicit buffer text.\n``` js\n\nvoid request.get('http://libs.baidu.com/jquery/1.8.3/jquery.min.js').buffer(true).end(function(err,res){ console.log(res.text.length) })\nundefined\n93637\n```\n\nPS: consider to use ['js','css','txt'....].indexOf(path.extname(url).slice(1)) to reimplement isText function.\nhttps://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L1047\nPPS: \u767e\u5ea6!\u5c45\u7136\u8fd8 x- ,Obsolete\nhttp://stackoverflow.com/questions/9664282/difference-between-application-x-javascript-and-text-javascript-content-types\n. use agentkeepalive\nhttp://stackoverflow.com/a/26324362\n. @pornel That's a question ...\n. Oops ...\n. value.length <- the exception\n. I'm sorry, Just found that error happens when the value is empty. \nAnd can be reproduced by code below: \n.field('key'), value is undefined\n``` js\n'use strict';\nconst request = require('superagent');\nconst co = require('co');\nconst main = co.wrap(function*() {\n  const res = yield request\n    .post('http://localhost')\n    .field('x');\n});\nif (module === process.mainModule) {\n  main().catch(e => console.error(e.stack || e));\n}\n```\nSo should we add a assert(value, 'value can not be empty') here or the form-data repo ?\n. what does an empty field means in a multipart/form-data ?\nLooks there already got some clues\n- form-data/form-data#147\n- request/request#2208\n. Since form-data is going to fix this in v2, and current this will throw a unknown error\nTypeError: Cannot read property 'path' of null, and I found a hidden bug in my bussiness code after figuring out what really happens. \ud83d\ude02 \n. I guess it's better to close solved issues to let the opening issues number down. \ud83d\ude02 \n. I noticed that the test code style are not consistent in semi ; http://eslint.org/docs/rules/semi\n. Actually I'm talking about this: https://github.com/visionmedia/superagent/blob/v2.2.0/lib/node/index.js#L594-L601\n. So since request-promise add configuration to this, how about superagent \ud83c\udf89 \n. ping\n. ## idea: global staticProperty\nadd a static property superagent.detectStatusCode\n- defaults to true, so we treat 4xx & 5xx response as error\n- when set to false, wo do not care the statusCode\n. ## idea: per req config\nadd a property or method to the superagent.Request class\ne.g add Request.prototype.config\njs\nrequest\n  .get('https://www.google.com.hk')\n  .config({ detectStatusCode: false }) //  <- turn off detectStatusCode here\n  .end((err, res) => {\n    // ... blabla\n  });\nI'm \ud83d\udc4d  on this too\n. .ok is also ok\nbut add support short version like .ok(true) would be more nice\n. ping\n. ",
    "jsheetzati": "+1 \n. ",
    "scsper": "I agree with @grrowl.\n. @defunctzombie @pornel I think https://github.com/visionmedia/superagent/issues/484 says that we should call it a TransportError, not an outBoundError, and that we should bump the major version.  If we made those two changes, would we be able to merge?\n. @defunctzombie https://github.com/visionmedia/superagent/pull/802 contains the change for a better message.  \n@pornel Are you planning on making the 2.0 change as well?  If not, I can do it.\n. +1 \n. @defunctzombie Any guidance on what to do?  I'm willing to open the pull request, but I'd like some community support before putting in the work.\n. this doesn't sound like a superagent issue.  sounds like your action is not getting called correctly in your server-side code.\n. ",
    "niftylettuce": "@zackify @grrowl @scsper @lazreg87 @deregtd @ahoym @kahnjw  @defunctzombie @palamccc @Fishrock123 @rickharrison \nTry out Frisbee... it's a replacement I made for this issue we're all having with superagent.\nI've documented how to use it specifically with React Native.  See this React Native pull request I've filed to change the default recommended package to use frisbee instead of superagent (mainly since frisbee uses fetch and superagent results in the Origin is not allowed by Access-Control-Allow-Origin error). \n. Same issue here\n. Did anyone get this working?  I've tried doing request.set('Accept', 'application/json') using superagent-defaults for example and it still doesn't work.  iOS works fine.\n. @icefoggy Can you share insight if you got it fixed?\n. Has anyone figured this out yet?\n. Use my package in NPM called Frisbee\nOn Dec 9, 2015 12:49 PM, \"Jesse\" notifications@github.com wrote:\n\nI'm having the same issue now.\nUsing superagent version 1.5.0\nres.body is null.\nres.text is full.\nthe response is text/json, and I'm using a plain get request.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/636#issuecomment-163337609\n.\n. Here's a promise implementation (uses ES6/ES7 async/await too, with ES6's new fetch() method) https://github.com/glazedio/frisbee.\n. For anyone that wants to go bleeding edge and not use stable releases of Superagent... here's a promise implementation (uses ES6/ES7 async/await too, with WHATWG's fetch() method) https://github.com/glazedio/frisbee\n. similar issue but I'm using common-shakeify and it's erroring #1418 . As soon I removed the -p tinyify flag with browserify it went away.  Seems like a weird parsing issue with tinyify.. I've narrowed the issue down to https://github.com/visionmedia/superagent/blob/master/lib/utils.js:\n\n```sh\n\ncross-env NODE_ENV=production browserify src/index.js -o dist/beep.min.js -s Beep -d -t babelify -p tinyify\n\nloc Position { line: 1, column: 684 }\nthis.input \"use strict\";exports.type=(str=>str.split(/ ; /).shift()),exports.params=(str=>str.split(/ ; /).reduce((obj,str)=>{const parts=str.split(/ = /),key=parts.shift(),val=parts.shift();return key&&val&&(obj[key]=val),obj},{})),exports.parseLinks=(str=>str.split(/ , /).reduce((obj,str)=>{const parts=str.split(/ ; /),url=parts[0].slice(1,-1);return obj[parts[1].split(/ = /)[1].slice(1,-1)]=url,obj},{})),/ common-shake removed: exports.cleanHeader = / void 0, (header,changesOrigin)=>(delete header[\"content-type\"],delete header[\"content-length\"],delete header[\"transfer-encoding\"],delete header.host,changesOrigin&&(delete header.authorization,delete header.cookie),header));\npos 684\nthis.pos 685\nSyntaxError: Unexpected token (1:684)\n    at Parser.pp$4.raise (/Users/user/Projects/my-project/node_modules/acorn/dist/acorn.js:2761:13)\n    at Parser.pp.unexpected (/Users/user/Projects/my-project/node_modules/acorn/dist/acorn.js:647:8)\n    at Parser.pp.semicolon (/Users/user/Projects/my-project/node_modules/acorn/dist/acorn.js:624:64)\n    at Parser.pp$1.parseExpressionStatement (/Users/user/Projects/my-project/node_modules/acorn/dist/acorn.js:1093:8)\n    at Parser.pp$1.parseStatement (/Users/user/Projects/my-project/node_modules/acorn/dist/acorn.js:818:24)\n    at Parser.parseStatement (/Users/user/Projects/my-project/node_modules/acorn-dynamic-import/lib/inject.js:47:31)\n    at Parser.parseStatement (/Users/user/Projects/my-project/node_modules/acorn-node/lib/import-meta/index.js:40:55)\n    at Parser.pp$1.parseTopLevel (/Users/user/Projects/my-project/node_modules/acorn/dist/acorn.js:706:23)\n    at Parser.parse (/Users/user/Projects/my-project/node_modules/acorn/dist/acorn.js:551:15)\n    at Object.parse (/Users/user/Projects/my-project/node_modules/acorn/dist/acorn.js:5292:37)\n``..babelrc`:\njson\n{\n  \"presets\": [\n    [\"@babel/env\", {\n      \"targets\": {\n        \"node\": \"6.4.0\",\n        \"browsers\": [ \"> 1%\", \"last 2 versions\", \"ie >= 9\" ]\n      }\n    }]\n  ],\n  \"sourceMaps\": \"inline\"\n}. seems to be an issue with common-shakeify so opening an issue there https://github.com/browserify/common-shakeify/issues/18. Preset env is used so arrow functions get converted\nOn Wed, Oct 3, 2018, 11:51 AM Kevin Smith notifications@github.com wrote:\n\nNote that for babel 7.x .babelrc will no longer apply to sub projects. You\nneed to create a babel.config.js file for global (configuration)[\nhttps://babeljs.io/docs/en/next/config-files]. You can see that you still\nhave arrow functions in your output which is obviously not going to work\nwith IE\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1418#issuecomment-426712099,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAf7hVczXV49H6PZtbrRn5-DXxa0aMxrks5uhOsCgaJpZM4W76FK\n.\n. see my PR opened which resolves this\n\nOn Wed, Oct 3, 2018, 12:29 PM Nick Baugh niftylettuce@gmail.com wrote:\n\nPreset env is used so arrow functions get converted\nOn Wed, Oct 3, 2018, 11:51 AM Kevin Smith notifications@github.com\nwrote:\n\nNote that for babel 7.x .babelrc will no longer apply to sub projects.\nYou need to create a babel.config.js file for global (configuration)[\nhttps://babeljs.io/docs/en/next/config-files]. You can see that you\nstill have arrow functions in your output which is obviously not going to\nwork with IE\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1418#issuecomment-426712099,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAf7hVczXV49H6PZtbrRn5-DXxa0aMxrks5uhOsCgaJpZM4W76FK\n.\n\n\n. the main benefits to this is that we can use @babel/preset-env to target node versions we want to support, and take advantage of a .browserslistrc file for both babel targeting and eslint (with added support for eslint-plugin-compat which uses caniuse database for linting).. once Lass has babel support I could tackle this https://github.com/lassjs/lass/issues/40. @kornelski I've submitted PR #1423 to fix this.  Please accept/test \ud83d\udc4d !. @kornelski I also suggest that we use np and release to publish new versions moving forward. There's an issue right now with eslint-config-xo-lass requiring Node v8.3+, I am fixing this, one moment.. As an aside, if you use np, be sure to use it with np --no-yarn since yarn publish does not have OTP (two-factor auth) support yet.. Tests should pass now, I think.. I doubt that we can use this package, but I made it anyways https://github.com/niftylettuce/spdy-or-http2.  Not sure of the differences or if there'd be a conflict.  The only reason why tests fail is because http2 is not available in Node v6.x.  The package I linked spdy-or-http2 may fix this issue, but again, I'm uncertain.  In the meanwhile I've removed Node v6.x from being supported.. \u2705 all tests are now passing btw. I also had updated the docs too, you can view a preview at https://github.com/niftylettuce/superagent.. Thanks @kornelski, if I can answer any questions please let me know.  This is blocking for me right now and I published @ladjs/superagent@5.0.0 in the meanwhile (you could also use this package for testing or to see what the NPM node_modules folder would look like, e.g. mkdir test && npm init && npm install @ladjs/superagent && cd node_modules/@ladjs/superagent && ls).\n\nI didn't change any core code other than running it through the linter / xo / prettier with --fix command.  I also just tested it in the browser myself using the jsdelivr package and it works great https://jsfiddle.net/t82ysrh7/4/.\nCurrently there are a ton of code quality issues with the existing codebase, such as using != vs !== and not using Object.hasOwnProperty.call.  I did not want to make these changes without first getting this PR resolved.  If you look at my branch you'll notice an extensive list of eslint rules that I've turned off due so that the linting tests will pass for now.  See https://github.com/niftylettuce/superagent/blob/master/package.json#L205-L250 for this list.\nThe reason the PR is so huge is because I used https://lass.js.org, and therefore moved everything from lib to src folder (src folder gets built to lib using Babel with .babelrc Node/Browser targets thanks to @babel/preset-env.. This will also fix #1437\nI will release this soon, thank you folks for adding me as a contributor!. Ill double check this before I publish. Thank you for your review. Super super helpful to have extra set of eyes.\nOn January 11, 2019 12:47:21 AM UTC, Matthew Herbst notifications@github.com wrote:\n\nMatthewHerbst commented on this pull request.\n\n\n},\n\"prettier\": {\n\"singleQuote\": true,\n\"bracketSpacing\": true,\n\"trailingComma\": \"none\"\n},\n\"remarkConfig\": {\n\"plugins\": [\n\"preset-github\"\n]\n},\n\"repository\": {\n\"type\": \"git\",\n\"url\": \"https://github.com/visionmedia/superagent\"\n},\n\"scripts\": {\n\n\nIt seems like what I'm looking for should be the default behavior: From\nthe fixpack docs:\n\nIt will re-write your package.json file as follows:\n\nname first\ndescription second\nversion third\nauthor fourth\nall other keys in alphabetical order\ndependencies and devDependencies sorted alphabetically\nnewline at the end of the file\n\n\nIt seems you could create a .fixpackrc file to manage the\nconfiguration.\nPersonally I just manage package.json files manually (save for npm\ninstall runs)\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/visionmedia/superagent/pull/1423#discussion_r246972944\n. @suprMax I am releasing superagent@5.0.0 soon with support for this.  You can see my PR is already done here https://github.com/visionmedia/superagent/pull/1423, now I am a maintainer/contributor to this package and will have this released soon!\n\nYou can use @ladjs/superagent in the meanwhile until superagent@5.0.0 is released.. Can you please add me as collaborator/NPM? cc @kornelski @tj . @defunctzombie it's \"niftylettuce\", thank you. @smulesoft I've added to .npmignore the test folder.  This will go out in the 5.0.0 major release soon.. There is not. I had a scenario which happened multiple times (and I reported to NPM) where despite files and being in .gitignore, NPM tarball contained these folders, so it was just a safe guard.. I left most of the core logic as-is, this was from prior code.  If you see I turned a TON of ESLint rules off so the tests would pass... there were so many existing issues with the old codebase.. Same as https://github.com/visionmedia/superagent/pull/1423#discussion_r246971213, what we have to do is fix this everywhere by turning off the rules one by one and fixing lint errors.  I didn't want to do a daunting commit with tons of changes everywhere, my first step was getting browser support done.. I use fixpack which organizes them differently, I think there might be a way to configure the order somehow with fixpack.  Is there a better alternative than using fixpack?. It is now using it (via my PR), I have to update the contributors block still, it's pretty cool - gets read from contributors in package.json and automatically added to README.md in the # Contributors section.. ",
    "DonutEspresso": "Thanks for quick response! Should have been the first thing I checked, will give it a whirl. \n. ",
    "Zenwolf": "This fails for me in 0.21.0. I only get back error object and a null res. Error message is \"Parser is unable to parse the response\", when a 400 is returned. So I cannot even check to see if it was a 400 error and do anything about it.\n. I am running in browser via Browserify, superagent version 0.21.0.\nChrome browser version 39.0.2171.95 (64-bit).\nI think the problem is that a http 400 is not required to return content, so it can be empty, even when the 200 resp would return JSON. However, the JSON.parse tries to parse an empty content, which is invalid JSON.\n. I understand that the http status codes state:\n\"The 4xx class of status code is intended for cases in which the client seems to have erred. Except when responding to a HEAD request, the server SHOULD include an entity containing an explanation of the error situation, and whether it is a temporary or permanent condition. These status codes are applicable to any request method. User agents SHOULD display any included entity to the user....\"\nHowever, of course, some services do not return any content in these cases in response to application/json. Should this be considered a bug or a scenario superagent should address?\n. As an update to this, for some reason removing one of the custom headers will cause superagent to work (removing either will work, as both are valid headers for my app), but adding both breaks superagent. I can add both headers using curl and HTTPie just fine, and the server handles them both. Not sure why adding both would cause a problem in superagent and cause a \"double callback!\" message.\n. As a final update, I can verify that the syntax error was due to a null value, but the double callback still is a problem when an error occurs. I believe it is happening when non-JSON content is returned and it tries to parse the expected JSON response. Not sure if this double callback warning is important or not...\n. ",
    "badeball": "I am also having this issue. Personally, I absolutely consider it to be a bug. Even if a requests returns a response that doesn't conform to the standard, I still want to be able to see the status code.\n. ",
    "hilkeheremans": "I agree. No one can really guarantee all server APIs they communicate with behave as they \"should\". Superagent should be robust enough to handle these cases.\n. ",
    "adriaanbalt": "+1\n. ",
    "dcurletti": "+1\n. ",
    "castrolem": "+1\n. ",
    "ivan-novakov": "@defunctzombie Of course. You send a request to http://some/url and get a response like this:\n302 Found\nLocation: http://other/url\nThen you need to follow the redirect by sending a request to http://other/url as is. With no modification.\n. And there is potentially a security or privacy issue with this behaviour. For example, if you make request to site A with some private query parameters and site A returns a redirect to site B, then if the query parameters from the first request are copied to the new request, they will be revealed to site B.\n. ",
    "hopkinsth": "There shouldn't be. The browser handles redirection for you in that case, where node does not. I just pushed up a similar test for client.js that should verify that case.\nI had trouble running the browser tests on my machine \u2013 looks like Express 4.0 compat stuff. I got the tests running locally but left those changes out of this PR. Still, beware.\n. Changes should all be in here:\nhttps://gist.github.com/hopkinsth/652c26191115f3bc687a\nI can run browser tests with zuul --local after applying that patch\n. ",
    "ryanzec": "@defunctzombie Can you give an example of a library to does general XHR mocking as all the mocking libraries I can find for the browser are tied to a specific library?\n. ",
    "zertosh": "@gjohnson: any chance of quick publish to npm for this? thanks in advanced!\n. ",
    "kkartunov": "Looks like the answer to 2 is Yes.\nThe POST request gets \"Preflighted\".\nWhat are the ways to workaround this ugly situation?\n. @defunctzombie OK. Thanks!\nI know that \"If the browser decides to prelight a request you have no choice\"\nBUT it looks that the browser decides to upgrade the request because superagent is sending some additional headers or does not handle multipart/form-data correctly in the browser.\nWanted just to report it because I solved the problem via using the XMLHttpRequest and FormData objects and it works for the same request I was trying to make with superagent...\n. ",
    "fiatjaf": "For anyone with this problem, here's a fork that does not add application/json unless you ask for it: https://github.com/fiatjaf/superagent-cors\n. ",
    "gaastonsr": "@gjohnson I'm actually using your second solution. I didn't know I could write a plugin for that. It's bad it doesn't offer a way to extend the object and don't have to use .use(plugin) every time.\n. ",
    "nodu": "OK cool, added it there. Cheers!\n. I was having a similiar issue with content-type: application/json and a lowercase patch, uppercase PATCH has fixed the issue.  Go figure.\n. ",
    "kellyrmilligan": "is it not possible to have a request stored in a var and then executing it when you call .end with superagent?  I'm trying to build up the headers and params in separate methods for a wrapper i'm creating....\n. ",
    "lucastschmidt": "Humm, I am having this error in my app, using this exact same version 0.21.0. \nIn my case, I was override the end method, and doing some extra checks when the user session expired with an API. If the checks took too long, it would break the app.\nBut I am just posting to document this, since I just encountered as well.\n. ",
    "sescobb27": "I have the same issue but with application/vnd.api+json which is the content type for JSON API http://jsonapi.org/format/#conventions, but it only happens with PATCH request, not with POST or GET\n. I have the same issue but with application/vnd.api+json which is the content type for JSON API http://jsonapi.org/format/#conventions, but it only happens with PATCH request, not with POST or GET\n. Test are failing due to lack of support of PATCH request in BROWSER mode. any hint on this?\n. @digitalsadhu basically yes :disappointed: due to lack of support for PATCH request in some of them\n. @digitalsadhu I made something similar\njs\nreturn request\n  .post('/customers')\n  .send(this.data)\n  .expect(201)\n  .expect('Content-Type', /application\\/(vnd\\.api\\+)?json/) // match application/vnd.api+json or application/json)\n. Test are failing due to lack of support of PATCH request in BROWSER mode. any hint on this?\n. ",
    "dmartinezg": "A question for the mantainers, is there a reason why the multipart tests are disabled?\n. ",
    "olalonde": "+1. Has this been implemented yet?\n. I started implementing this (file upload progress event) but got stuck here because writable streams don't have a 'data' event:\njavascript\n  // See http://dev.w3.org/2006/webapi/progress/Progress.html\n  req.on('data', function () {\n    var length = req.getHeader('Content-Length');\n    var lengthComputable = !!length;\n    var loaded = 0;\n    var total = lengthComputable ? length : 0;\n    return function (data) {\n      loaded += data.length;\n      self.emit('progress', {\n        lengthComputable: lengthComputable,\n        loaded: loaded,\n        total: total\n      });\n    };\n  }());\nI tried googling around but couldn't find any helpful info on tracking upload progress with nodejs' http module.\n. Ok, so I implemented this on form-data uploads only (e.g. when using .attach() or .field()).\n. PR merged though it would still be nice to have \n1) progress events on the incoming side (when downloading). (and a way to distinguish them)\n2) currently, the progress event only works when using the attach() or field() APIs (anything that uses form data). It would be nice to also have it on regular requests or requests that are piped to from a readable stream.\nI might work on that when I have time but until then, PRs welcomed.\n. Yep.\n. #690 wasn't my issue. I was just curious why it wasn't documented as I was using it in my Node.js app IIRC and wasn't sure if it was a safe thing to do.\n. FWIW, if you are running your tests in a browser, setting the user-agent header won't work because web browsers don't allow overriding the user-agent header (otherwise, I'm pretty sure it works in Node.js as @focusaurus mentioned)..\n. Hmmm any feedback? Is this project still maintained?\n. > How do you distinguish between upload and download progress? Won't it confuse existing code that posts something and then expects to track download progress?\nCuriously, the browser implementation doesn't seem to distinguish between upload/download: https://github.com/visionmedia/superagent/blob/master/lib/client.js#L974 \nMaybe we should address this first?\n\nI don't see lengthComputable changed anywhere.\n\nYes it's not changed. I just put it there so that the event object somewhat resembles what browser progress events: http://dev.w3.org/2006/webapi/progress/Progress.html\nAFAIK, Content-Length is always available when using form data. There is actually a TODO which explicitly states that \"unknown length\" uploads aren't supported yet.\n. LGTM :+1: \nPS: we should probably add io..js 3.0 to travis?\n. Personally, I wouldn't be opposed to supporting that if it's just a few lines of code.\n. LGTM\n. Interested in helping out but only have one PR as far as I know: https://github.com/visionmedia/superagent/pull/771 \nCan't promise I will keep promises away though :smiley: \n. :+1: thanks\n. LGTM :+1: \n. I can't reproduce this bug locally with node 4.1.2, tests pass fine. I'm starting to suspect that this might be a race issue caused by having all the tests run in parallel? Do all travis builds run in the same directory? \nI just manually restarted the 4.1 build and tests pass now.\n. @defunctzombie have you had that localtunnel.me / zuul issue before? https://travis-ci.org/visionmedia/superagent/jobs/92531224\n. Well seems all tests are passing now. @pornel @focusaurus \n. Yeah, I usually do something like that:\njavascript\nconst httpServer = http.createServer(app).listen(process.env.PORT);\nconst httpPort = httpServer.address().port;\nconst url = `http://localhost:${httpPort}`;\nWhich lets me use a specific port if I need to (e.g. I want to use curl on the server - in which case I also need to comment out the server shutdown procedure).\n. Might be too big of a change right now but if we used a standardised format for commit messages, we could use conventional-recommended-bump to do semantic versioning for us and conventional-changelog to generate History.md.\nI use the following scripts in my own projects:\njavascript\n{ \"scripts\": {\n    \"preversion\": \"npm test && npm run changelog\",\n    \"version:auto\": \"npm version $(conventional-recommended-bump --preset=angular)\",\n    \"postversion\": \"git push && git push --tags\",\n    \"release\": \"npm run version:auto && npm publish\",\n    \"prepublish\": \"npm run build\",\n    \"changelog:generate\": \"conventional-changelog -p angular -i CHANGELOG.md -w\",\n    \"changelog:commit\": \"git add CHANGELOG.md && git commit -m \\\"chore(changelog): auto generate changelog\\\"\",\n    \"changelog\": \"npm run changelog:generate && npm run changelog:commit\"\n}}\nhttps://github.com/semantic-release/semantic-release might be worth looking into as well.\n. Agreed.\n\n\"hey can you resubmit this PR with a comment in this magic format?\"\n\nHaha yeah, that's one downside of this approach.\n. Sorry, I'm a bit out of the loop here as I've been busy with other projects but I also vote for releasing major versions more often (as needed) and only consider long term maintenance if it becomes a real issue to library users.\nOn a related note, I'd like to propose we use babel as part of the build so we can safely start using es2015 features.\n. I was also initially skeptic at first but I have been using babel for the last few months in other projects and I now find going back to es5 projects kind of painful. Also babel comes with babel-node which is a drop in replacement for node when developing. We would just need a prepublish script that runs babel before publishing to npm.\n. ",
    "shishirx34": "This is exactly what I was looking for, @olalonde is there an ETA on when #771 PR would be merged?\n. This is great. Thank you for getting this merged in. @pornel, any idea when the next npm update will be available for these changes on superagent?\n. ",
    "edward32tnt": "when i read module form-data, i found this at\nsuperagent/node_modules/form-data/lib/form_data.js\n```\n    // fs- and request- streams have path property\n    // or use custom filename and/or contentType\n    // TODO: Use request's response mime-type\n    if (options.filename || value.path) {\n      header +=\n        '; filename=\"' + path.basename(options.filename || value.path) + '\"' + FormData.LINE_BREAK +\n        'Content-Type: ' +  (options.contentType || mime.lookup(options.filename || value.path));\n// http response has not\n} else if (value.readable && value.hasOwnProperty('httpVersion')) {\n  header +=\n    '; filename=\"' + path.basename(value.client._httpMessage.path) + '\"' + FormData.LINE_BREAK +\n    'Content-Type: ' + value.headers['content-type'];\n}\n\n```\nthen .attach(field, buffer, {filename: 'need a filename'}) \nits worked!\n. ",
    "SystemParadox": "Yes, .attach(field, buffer, {filename: 'need a filename'}) does work, but that is to do with #403 (it shouldn't need an object wrapper).\nThis issue is about what happens when you don't provide a third argument at all. Superagent should either make this work correctly, or throw a useful error message.\n. ",
    "lborgman": "It seems like it is xhr.upload.onprogress that spoils it. No idea why.\n. Seems to be something with the format of the onprogress function. Switching to the supported addEventListener instead makes things work as I expected.\nEh: This is tested in Chrome.\n. Thanks @defunctzombie, but that is a misunderstanding. I changed the code in Superagent to make it work. Maybe this could work in all browsers, I am not sure:\njavascript\n    // progress\n    /// Fix for Chrome\n    if (xhr.addEventListener) {\n        xhr.addEventListener(\"progress\", function(e){\n            e.percent = e.loaded / e.total * 100;\n            self.emit('progress', e);\n        });\n    } else if (xhr.upload) {\n        xhr.upload.onprogress = function(e){\n            e.percent = e.loaded / e.total * 100;\n            self.emit('progress', e);\n        };\n    }\n. Sorry, I added the markdown to format the code.\n. I took a look again. I works with my patch ($entityBody in PHP above contains what I expect), but not without it ($entityBody is NULL).\nWhen I look at the event it looks ok in addEventlistener, but in onprogress e.total == 0 and e.lengthComputable == false.\nSo it might be considered kind of a bug in Chrome, but does onprogress exist in the standards?\n. And please reopen this, of course. ;-)\n. Here is my test case, on browser side:\njavascript\n    superagent.post(\"http://localhost:7000/test.php\")\n        .type(\"application/x-www-form-urlencoded\")\n        .send('{\"a\":\"b\"}').end()\nOn the PHP side it is just the one line code I mentioned above, test.php:\nphp\n    <?php\n     function writeStdErr($msg) { $fh = fopen('php://stderr','a'); fwrite($fh, $msg); fclose($fh); }\n     $entityBody = file_get_contents('php://input');\n     writeStdErr(\"entityBody:\\n\".$entityBody.\"\\n\\n\");\nJust run it with php -S localhost:7000\n. I would really like to agree with you, but ... ;-)\nA lot of people seem to think x-www-form-urlencode is the right way, however (when posting to PHP). And when I tested first I could not get it to work with application/json. \nBut - hm, the example PHP code i sent is not what I have been testing with. Just what I though was the essential part of it. I should have known. You should test with the actual code, of course. \nI do not see the problem with the PHP code I posted here. Sigh.\nAt the moment I have no idea why and when it fails. But it does. (I.e. $entityBody == NULL sometimes.) Coming back. :-(\n. This was a really hard one. It looks like a PHP bug so far, but I am not quite sure. The problem occurs when I POST from PHP to another URL (this is a proxy server), but I have a hard time to understand how.\nThe missing input is fetched at the beginning of the PHP file and the offending code comes much later in the PHP file.\nAnd it is working code. Except for the problem I see here. I looks like the PHP code (in HTTP/Request2.php) is doing some quess-work in a first parsing pass and tries to help me. A very bad idea if that is the case.\n. I am beginning to understand what is happening. The request is sent two times when it is POST.\nSo there is no PHP bug. However the problem I saw above in Superagent exists, but is a bit hard to nail down. It seems to show up when application/json is used and 500 is sent back.\nBut at least this should be fixed, I think:\n- Check the e.lengthComputable value. If it is not true, then just do return in onprogress.\nAnd maybe replace onprogress. But that one is harder to show. \nFor anyone wanting to test more, here is my PHP testing script. Run it with php -S localhost:7000 for example:\n``` php\n<?php\nrequire_once 'HTTP/Request2.php';\nheader(\"Access-Control-Allow-Origin: *\");\nheader(\"Access-Control-Allow-Headers: Content-Type\");\nini_set('display_errors', 1); \nerror_reporting(E_ALL);\nini_set('default_charset', \"UTF-8\"); \nfunction writeStdErr($msg) { $fh = fopen('php://stderr','a'); fwrite($fh, $msg); fclose($fh); }\nwriteStdErr(\"\\n=====================================\\n\");\nforeach (getallheaders() as $name => $value) { writeStdErr(\"IN: $name: $value\\n\"); }\nwriteStdErr(\"GET:\\n\".var_export($_GET, true) . \"\\n\");\nwriteStdErr(\"POST:\\n\".var_export($_POST, true) . \"\\n\");\n$entityBody = file_get_contents('php://input');\nwriteStdErr(\"entityBody:\\n\".$entityBody.\"\\n\");\n$postedJson = json_decode($entityBody, true);\nwriteStdErr(\"POSTed json:\\n\".var_export($postedJson, true) . \"\\n\");\n$status = \"500\";\nif (array_key_exists(\"status\", $_GET)) { $status = htmlspecialchars($_GET[\"status\"]); }\nheader(\"HTTP/1.0 \".$status.\" Just testing, look at status value here\");\nwriteStdErr(\"Sent back \".$status.\"\\n\");\necho \"Sent back \".$status.\"\\n\";\n```\nAnd test it with something like the below in the web browser console. Test status 200 and 500 (default).\njavascript\nsuperagent.post(\"http://localhost:7000/test.php?status=200\").send('{\"a\":\"b\"}').end()\n. I getting a bit closer to understand what is going on. The PHP code is somehow getting run 2 times when application/json is used, but not when applicaiton/x-www-form-urlencode is used.\nPlease take a look here:\nhttp://stackoverflow.com/questions/27924902/why-do-an-ajax-application-json-run-php-code-twice\n. It could perhaps be something with CORS preflight, but why should that be different with the two headers?\n. Ah, you are right. Thanks. :-)\nI have no idea why the rules looks like that, though. It looks to me that due to this it might be better to send JSON with application/x-www-form-urlencoded.\nSince that would make it one round-trip less, I mean. Or am I missing something else?\n. I posted an answer based on your advice to my own question on StackOverflow (linked above).\n. Thanks for finding the explanation, @doesnotexist! So in principle other browsers should do this too.\nAll I can say now is that I really wonder how the CORS rules got through the standard committees.\n. ",
    "doesnotexist": "I have the same issue, when sending a post request to a webservice (that I do not control) which does not implement a handler for the preflight OPTIONS request. So the OPTIONS preflights always fail. The request I'm sending meets all the criteria for not needing a preflight, it is a simple POST request with no special headers and the content-type is application/x-www-form-urlencoded. Yet the way superagent binds xhr.upload.onprogress causes chrome to send a preflight.     However, the preflight can be avoided in the latest versions of chrome as long as xhr.upload.onprogress is not directly bound.  \nSo the code provided in the comment above  as a patch to superagent fixes the issue for me by avoiding the preflight.  It appears that chrome is ok with code that addsEventListners to the xhr but requires a preflight if any javascript code touches the xhr.upload.onprogress property.\nIt should be noted that jquery.ajax does not have this issue as they never bind the onprogress property.\n. from the chrome source code:\n\" // The presence of upload event listeners forces us to use preflighting because POSTing to an URL that does not // permit cross origin requests should look exactly like POSTing to an URL that does not respond at all.\"\nSo perhaps a better patch would be to check if the request is cross origin or not.  If it is not bind the progress listener, otherwise don't if it is cross origin.  Alternatively, perhaps make the progress listener an option, so users can turn it off when they want to make CORS requests with no preflight.\n. @sonicsnes is really to thank.  He helped me track this down as I was porting my app from using jquery ajax to superagent.\n. ",
    "zackwoo": "on the server\n. thank you\n. ",
    "tbo": "\nsuperagent-prefix never claimed to offer this functionality. Only the superagent documentation is stating this: \"Prefixes all requests\"\nsuperagent-prefix doesn't seem to be maintained anymore\nI don't think that this is a superagent-prefix bug. It consists of only 9 lines of code and seems to do exactly, what it is supposed to do: Add a prefix to a single request:\n\n```\nmodule.exports = function (prefix) {\n    return function (request) {\n        if (request.url[0] === '/') {\n            request.url = prefix + request.url;\n        }\n    return request;\n};\n\n}\n```\nThis is why I am asking, how this could be achieved just by using vanilla superagent. \n. ",
    "morlay": "@tbo recently I use superagent to do the same thing.  \nFortunely, I find https://www.npmjs.com/package/superagent-defaults to solve my problem.\nvar superagent = require('superagent-defaults')();\nsuperagent.on('request', function (request) {\n  if (request.url[0] === '/') {\n    request.url = 'http://127.0.0.1:3001' + request.url;\n  }\n});\nGood luck\n. ",
    "BenLorantfy": "Even if there's a plugin that addresses this issue, isn't this a common use case and a good feature to have in the core library?. ",
    "lazdmx": "Any comments... Just closed or already implemented and closed\n. ",
    "mpociot": "+1\n. ",
    "rborn": "+1\n. ",
    "FokkeZB": "+1 (excellent speech)\n. ",
    "emilioicai": "+1\n. ",
    "acontreras89": "What's the status on this? \nPerhaps this line of code should be changed to:\njs\nif (data) req.query(data); // rather than req.send\nAs described by the HTTP spec (credits to this SO answer):\n\nThe HEAD method is identical to GET except that the server MUST NOT return a message-body in the response.\n\nIt would be nice to have both functions (.get and .head) behave the same way.. @focusaurus I'm not familiar with the node implementation of this. I took a look but it seems it's already treating GET and HEAD requests the same way, even though they are not treated as in the browser version.. :clap: . ",
    "omarfouad": "Oh didn't notice the 'on()' method. \nThanks! \ud83d\udc4d \n. @pbc Thanks for the note, but why? Isn't that supposed to be promise? \n. ",
    "pbc": "it's worth mentioning here that the snippet above won't work because \"on()\" method is after the \"end()\" call.\n. I think it's by design. This is what you have in the readme:\n\n. ",
    "koenpunt": "@rexxars your example doesn't work. Or at least not in my case. I have to call on('progress') before end(), otherwise the handler isn't triggered.\nSo\njs\nrequest\n   .post('/api/file')\n   .send(someFile)\n   .on('progress', function(e) {\n     console.log('Percentage done: ', e.percent);\n   })\n   .end(function(res){\n     if (res.ok) {\n       alert('yay got ' + JSON.stringify(res.body));\n     } else {\n       alert('Oh no! error ' + res.text);\n     }\n   });\n. As fas as I know there are no (reliable) polyfills for FormData. If someone can recommend one that works in IE9, please tell! \n. Using my addon superagent-use (also mentioned in the readme) you can do:\njs\nsuperagent\n  .use(function(request) {\n    request.url = request.url + (request.url.indexOf('?') > -1 ? '&' : '?') + 'access_token=' + accessToken;\n    return request;\n  })\n  .use(function(request) {\n    request.on('response', function(response) {\n      if(response.status == 401) {\n        login();\n      }\n      return request;\n    });\n  });\nAnd every request done with superagent after that will apply both functions\n. ",
    "alexsasharegan": "If anyone else comes across this thread (it's the default thread for superagent progress tracking on google), here's the updated section where the progress event is emitted:\nhttps://github.com/visionmedia/superagent/blob/master/lib/client.js#L780-L799\n\nupdated: now found at https://github.com/visionmedia/superagent/blob/master/lib/client.js#L738-L757. @similityman Alternative to @teonik's solution, you can use a bound function (arrow function) when attach the superagent onprogress handler. This can also give you a chance to bind extra params to your onprogress handler if you need references to anything.\n\n```js\n// without extra params\nreq.on( 'progress', event => this.onProgress( event ) );\n// with extra reference to the files array\nreq.on( 'progress', event => this.onProgress( event, files ) );\n```\nI personally chose to fire off individual requests for each file upload in my own app so I could render progress per file. I used the second method to bind a uuid to each file so I could map the progress emitted to the correct file in the uploading queue. Not sure how valuable copy/pasting that example will be, but hey... sharing is caring!\n```js\n// from inside my Uploader component wrapping DropZone...\n/\n * Proxied handler function for the DropZone's native 'onDrop' method.\n * Called with an array of files uploaded.\n * Sets up component state to handle progress bars,\n * and uses uuid's to make unique keys on potential\n * files with identical names.\n \n * @param files\n /\nuploadFiles( files ) {\n    const filesToUpload = files.map( ( file ) => {\n        return { name: file.name, percent: 0, uuid: uuid.v4(), timestamp: Date.now(), data: file };\n    } );\nthis.setState( {\n    isUploading: true,\n    files: [ ...this.state.files, ...filesToUpload ],\n} );\n\nlet promises = filesToUpload.map( file => this.uploadFile( file ) );\n\nPromise.all( promises ).then( () => {\n    this.setState( { isUploading: false } );\n    this.onUploadComplete();\n} );\n\n}\n/\n * By attaching each file to an individual ajax call,\n * we are able to bind our unique keys to the progress events\n * and render progress on each individual file.\n \n * @param file\n * @returns {Promise}\n /\nuploadFile( file ) {\n    return (\n        request.post( this.props.uploadURI )\n               .attach( file.name, file.data )\n               .on( 'progress', ( event ) => this.onUploadProgress( file.uuid, event.percent ) )\n    );\n}\n```. ",
    "similityman": "My question is not directly the same as the question in this thread but how do I pass a different class function as a callback handler for progress? Basically I want to pass a progress function of my React component as a handler for request.on('progress',..) Here is my code:\n``progress(obj) {\n  var percent = obj.percent;\n  console.log('[progress] Percentage done: ', percent);\n  if (percent > 100) {\n    this.setState({completed: 100});\n  } else {\n    this.setState({completed: percent});\n  }\n}  \nonDrop(files) {\n  console.log('Received files: ', files);\n  this.state.completed = 0;\n  var data = new FormData();\n  var req = request.post('/nltools/v1/files/upload');\n  files.forEach((file)=> {\n      data.append('files[]', file, file.name);\n  });\nreq.on('progress', this.progress);\nreq.send(data);\n  req.end(function(err, res){\n      console.log(\"Successfully uploaded\");\n  });\n}`\n```\nHowever, I am constantly getting an error: Uncaught TypeError: Cannot read property 'apply' of undefined\n. ",
    "umidbekkarimov": "@similityman I think that you're digging in to the wrong direction: see. ",
    "teonik": "@similityman Have you added this.progress = this.progress.bind(this); to your component's constructor?. ",
    "grigoryvp": "Thanks for update! Actually, it will trigger CORS in all browsers since this behavior is required by specs. If some browser doesn't trigger CORS it's probably something very old or not standard-compliant\n. ",
    "Autarc": "The main issue was the missing handler for emitting progress updates on GET request to resources. Although you omit the one for uploads, perhaps you could still add this one for larger downloads.\n. ",
    "nousacademy": "I cant nevermind..\n. ",
    "mleanos": "I have described an issue I'm having that's very similar to this\nhttps://github.com/visionmedia/superagent/issues/747\nThere's definitely something going on here, in the form of a bug. Not yet sure if it's with superagent or supertest.\n. I'm experiencing the same behavior. I've described it here, https://github.com/visionmedia/supertest/issues/230, and it may be related to this as well, https://github.com/visionmedia/supertest/issues/258\nIn my case, I am using .attach with a request, and this particular test checks to make sure a User is logged in, before attempting to upload the file; this properly send back a 400 response in the form of res.status(400).send(... This is what I want my API method to do. However, it does appear that since the response is sent back so quickly, the attached file isn't loaded into memory (shooting from the hip here, as I don't know much about how the attach feature works), thus causing the ECONNRESET error.\nI have tested this with varying file sizes. A file size of somewhere between 44 KB & 50 KB will exhibit this behavior. A file size of 44 KB never has this issue. Thus, my conclusion is that superagent's .attach method hasn't completed what it is doing, due to the file size, before I send back the response to my test.\nI hope this helps in determining the issue. I realize that I have no need to use the .attach method with this use case, and I have since removed it from the test in question. However, I think this is definitely a bug somewhere in superagent's attach method, or somewhere else down the line as it gets propagated through the assertion process.\n. ",
    "jcristovao": "Does superagent support the OPTIONS HTTP Method?\nIt seems to not support it, but perhaps I'm missing something...\n. ",
    "fletchowns": "This would be great for use with Django Rest Framework.\n. ",
    "asadovsky": "The tests are still all commented out, so I don't understand why this issue was closed.\nHas anyone verified that this actually is fixed in master?\n. ",
    "johnHackworth": "@defunctzombie is the pull request closed because you already are working on this? If not, what's the reason? I could send a fix if I know what are the prerequisites for it...\n. oh, ok! makes sense... thank you for the explanation!\n. ",
    "jphastings": "Ha! Awesome - thanks so much :)\n. ",
    "gabrielecirulli": "Browser, sorry. So not all responses can contain empty bodies?\n. ",
    "magnuskjellen": "I've got the same problem... I my world, the response of for example an delete-request, is perfectly fine without an body (just 200OK as response code). \n. ",
    "rodsouto": "Same issue here, sending a DELETE request that returns 204 I get \"Uncaught SyntaxError: Unexpected end of input\"\n. ",
    "rps": "npm install superagent gives a dependency of \"qs\": \"1.2.0\" instead of 2.3.3 which has some issues\n. ",
    "jeffreywescott": "Now it gives \"qs:\" : \"^3.1.0\" ... should be okay, right? Consistent behavior across the node and client versions seems essential to me ... (see again #128)\n. ",
    "esperancaJS": "still 1.2.0 ..\n. ",
    "DylanPiercey": "What about just using the native node querystring?\n. This would be extremely useful for things like prefixing, intercepts and more. I personally find single request plugins somewhat useless.\n. @pornel I totally agree that adding global middleware should create a new constructor.\n. @pornel I think https://github.com/camshaft/superagent-defaults is the right approach.\n. ",
    "jdub": "OK, in that case I'll do without for the time being. Thanks! :smiley:\n. Oh! Perhaps this is why\u2026 in this case, no error is passed to the end callback. It's null. That's a pretty good reason to not raise an error event, really.\nIs it because the status code is 409? Thus recognised as a client error, not a server error? I wasn't expecting only certain categories of errors to be emitted. :innocent: \nSelect bits from the Response object:\njs\n{\n  clientError: true,\n  error: {\n    message: \"cannot POST http://localhost/bananas (409)\",\n  },\n  serverError: false,\n  status: 409,\n  text: \"this server says you are bananas\",\n  type: \"text/html\"\n}\n. By the way, I'm still not seeing events in the browser, be it response, error (for server errors), etc. I would still regard that as a bug. Prefer a new issue opened?\n. ",
    "amishshah": "This is still happening for me... Any updates?\n. ",
    "miklschmidt": "Just ran into the same problem, i'd be happy to send a pull request? The server version does a bunch of stuff in the Request.prototype.callback method that you'd expect would happen in the client aswell. The 'error' event being one of them.\nThe following line would fix the problem in the client:\nif (err && this.listeners('error').length > 0) this.emit('error', err);\n. ",
    "warrenseine": "Yes, that's what I ended up doing.\nHowever, I don't think I should close this issue because it's a bug IMHO.\n. I've moved to the native HTTP module for that specific case anyway.\n. Thanks for the feedback. I'll try that.\nIn case this worked by swapping the modules, would a PR adding a protocol and a new dependency would be considered?\n. ",
    "jdavisclark": "I've got the same problem. Handling errors when piping is really cryptic\n. ",
    "joewestcott": "Is this still the suggested way to handle errors when downloading/streaming to file?\nI get request.abort is not a function running this.\nvar stream = fs.createWriteStream('path/to/file')\nvar request = superagent\n    .get('http://httpbin.org/image/png')\n    .on('response', function(response) {\n        if (response.status !== 200) {\n            request.abort();\n        }\n    })\n    .pipe(stream);\n. ",
    "sebastialonso": "@kornelski I don't quite fully understand.\nWhat exactly means aborting a request? What do I get?  Do I get anything?\nDocumentation only shows\n~~~\nAborting requests\nTo abort requests simply invoke the req.abort() method.\n~~~. Any ideas on how to check if the request failed before piping (say 401, or 404)?. Thanks for your reply @kornelski \nYesterday I lost all my afternoon trying to trigger the error event on the pipe, forcing a 401 on my request, so I can say with a very high degree of confidence that the event it's either not being fired by the request error, or it's not working.\n~~~javascript\nreturn new Promise((resolve, reject) => {\n    stream.on(\"finish\", () => {\n      console.log(\"File saved\")\n      resolve(stream.path);\n    });\n    stream.on(\"error\", (err) => {\n      console.log(\"error in request\")\n    })\n  });\n~~~. ",
    "RileyTomasek": "@vstirbu thanks for doing this! might be worth adding to the docs somewhere @defunctzombie?\nIs there an easy way to do this in node? I'm writing an SDK that works in both node and the browser and I'm struggling with the node part here.\n. ",
    "Noxalus": "This issue has been fixed on master, I used the last version available on npm (https://www.npmjs.com/package/superagent) without the changes from the last 4 months.\n. ",
    "misaunde": "I was following this tutorial: https://developer.atlassian.com/blog/2015/11/scripting-with-node/#packaging-shell-commands \nand experienced the same results (was ignoring filename).\nNeither this:\n.attach('file', file, 'my-title')\nor this:\n.attach('file', file, {filename: 'my-title'})\nworked for me...\nThe file would make it, but not the filename.\nUsing \"superagent\": \"^3.6.3\" in my package.json.... ",
    "codesuki": "Sorry, I just wondered if there is a more official way. I didn't make that clear above. \n. Ok thanks!\n. ",
    "dncrews": "A friend of mine wrote https://github.com/camshaft/superagent-defaults. It allows you to set defaults for all of your calls, e.g.\n1. If on every request you set the same accept headers;\n2. If on every request you check for the same errors (using .on('response', fn) or .on('error', fn))\n3. If on every request you do the same authentication\n4. Or if you need to define your own request methods\nIt's more DRY than using a .use for every superagent call. Might be more like what you're looking for...\nCaveat: Just make sure if you use the .on() methods for error checking in your defaults, you always use the .on() methods in your superagent calls. If you do a .end(err, resp), superagent doesn't emit the errors. It only passes them to your callback. Though .end(resp) (no err) will emit them.\n. ",
    "nguyenxuantuong": "Yes. From what i test, the error only occur in firefox.\n. ",
    "rdy": "I believe this is the same issue as #484, there is an onprogress callback which is added to the xhr. Doing this on a cross domain request causes a security exception only in firefox.\nI've modified this on my own fork and removed the callback to work around the issue 9b1e68e4036f12d01b7172141f0c6a2c44d546bf, it looks like firefox is not going to change this. Instead it needs detect the cross origin and not bind the callback in that case.\n. ",
    "cdekok": "Am having the same problem :(\n. ",
    "dlockhart": "I also ran into this issue. Following the trail @rdy suggested, I found this ominous defect on Bugzilla: Unnecessary CORS preflight when using upload progress.\nMozilla claims it's not a defect at all, specifically referencing the XmlHttpRequest spec which states that it will it will use \"CORS-with-forced-preflight if one or more event listeners are registered on the associated XMLHttpRequestUpload object...\".\nSo it appears as though when superagent registers for the onprogress event:\njavascript\n// client.js\nif (xhr.upload) {\n  xhr.upload.onprogress = function(e){\n    e.percent = e.loaded / e.total * 100;\n    self.emit('progress', e);\n  };\n}\nThis is causing Firefox to do a preflight OPTIONS request, which in our case is getting blocked by cloudfront (not your problem). Chrome, IE and Safari seem to have a different interpretation of the spec, and aren't doing the prelight.\n@defunctzombie, is there maybe a way to not register for the onprogress event if it's not needed (e.g. no event listeners have been added)? Because even if we configure cloudfront to allow the OPTIONS requests through, there will still be one for every request we make through superagent (on Firefox), even just simple GET requests that shouldn't require a preflight.\n. Awesome, you read my mind. :)\nConfirmed that this fixes the issue, I vote you can close it.\n. ",
    "gagoman": "mime package still uses readFileSync, so this PR is useless.\n. ",
    "danharper": "Ah of course! - I'll do that now.\n. ",
    "jeffkole": "Sure.  The way we are using it is to show a progress meter as we download files (PDFs, Word docs, etc) from S3 for display in the browser.\n. I was looking to prevent the potential divide by zero error, though the result would just be Infinity.  Perhaps that is sufficient safety for the API.\n. ",
    "mferraco": "Can you give an example here as to what has changed and how you fixed it?  I am having issues as well.\n. ",
    "menelaos": "The issue I am referring to is that previously superagent checked the number of arguments of the callback passed to .end() and took actions accordingly. Now (as discussed in #283), it expects a function (err, res) {}. \nThus\n``` javascript\nrequest('/search', function(res){\n});\n```\nwill need to be changed to\n``` javascript\nrequest('/search', function(err, res){\n});\n```\nWhile I support this change, I think it should be mentioned somewhere that this can break existing code. Currently, it is not clear to me which of the changes in history.md are breaking changes.\n. ",
    "Keepcase": "+1\nI'm running into the same issue as well.\n. ",
    "arielschiavoni": "+1\n. ",
    "Lucas-Gluchowski": "+1\n. ",
    "alex94cp": "Related to #690\n. I can confirm this, what @englercj says completely makes sense\n. The example works as-is for me, could you please indicate package versions used?\n. Ok, now I get this error too. According to c279f59, superagent-prefix does not support global usage. The correct usage would be per-request request.use(prefix). Global plugin registration is only possible atm for methods patching the superagent api, like superagent-mock does. I'll probably make a PR adding support.\n. Why? The Accept header should be used by the server to send the response in a format that is understandable by the client, and set its Content-Type accordingly. In my opinion, superagent should honor the Content-Type header, no matter what Accept says. If your Accept header says 'application/json', your server response should be marked as JSON. That's what the Content-Type header is for.\n. It's not documented because it is not available on the client build (see #729). Agents are used by the http module available on the server build. AFAIK, an equivalent does not exist for XHR, which is used on the client build, and adding a shim has not been discussed yet (I wouldn't have high hopes given browserland module size paranoia) xdd\nAnyway, could you please describe your issue at #690? Reducing Superagent server-browser differences is on our after-summer purpose list (and as always PR's are welcome and strongly appreciated)\n. It appears so (see #729). The long-term goal will be to eventually diminish the differences (PR's welcome!)\n. Yep, what you are describing seems like CORS preflight requests, not related to Superagent. @eeskov could you please provide with full request/response headers so we can help? Are you using cors on the server?\n. Hi @MaxSvargal, sorry for the late response. Could you please write about your issue in #690? We'd want to join all efforts into addressing this important issue in the best way possible. Thanks for your understanding\n. The correct behaviour seems not easy to implement in a standard-compliant way (see here). However, you could make a plugin: the superagent plugin API is quite flexible and easy to work with. Good luck and don't hesitate to ask for help if you need it!\n. Thanks for your involvement. However, sending a request (as request.end does) not subscribing to the response (that is, with no callback) seems like a legit use case.\n. +1\n. Addressed by PR #725\n. In addition to that (which is not the end of the world), the expected signature of the parsers also varies! How am I supposed to write an isomorphic parser for superagent then?! (this is the end of the world). (cc @defunctzombie)\n. I'm closing this, since #690 seems like a better place to keep track of differences between the client and server builds\n. Hi @defunctzombie, I'm sorry to cc you but I need this PR merged soon to continue one of my projects. This PR adds a feature already present in Node builds. It is short, it's backward-compatible and all tests pass. Thanks for your comprehension\n. @defunctzombie Sorry, really, it was my bad. This is what happens when \"fast\" gets in the place of \"good\". I am really sorry. The issue with the last commit was that it added the ability to override the body parser for the Response, when what I wanted to was to add that ability to Request. It WAS tested, it was tested not to break anything that wasn't broken, and I was adding unit tests sometime in the future. Everything I said still applies: no backward-incompatible changes, no broken tests, it was just a typo.\n. @defunctzombie Ready to be merged at last! ^^\n. Done\n. Sorry, I think it got included by mistake while squashing commits, I hope everything is fine now\n. There was already #742 which also included unit tests for this\n. Is that a real issue? Sorry, I was just trying to keep within the 80 character line width\n. ",
    "scags9876": "+1\n. ",
    "markdalgleish": "Not sure why this issue has so many +1s when it was a 5 minute fix. I've just issued a PR with a fix for this, including a test case, so hopefully it's satisfactory :)\n. The browser build is failing, but it seems flakey as an earlier build succeeded and my failing build was a whitespace change. I'll try to trigger another build.\n. Finally got the build to pass, just force-pushing non-code changes to my PR branch.\nIf you weren't already aware, you might want to look into your flakey tests. You can see the failures for this PR here: https://travis-ci.org/visionmedia/superagent/pull_requests\n. ",
    "novabyte": "I agree with @basti1302 it'd be nice to continue to easily grab a pre-built browser build of superagent.js from Bower.\n. ",
    "lattmann": "@defunctzombie: I completely agree with you on not checking the built artifacts into the git repository. We do the same in our projects.\nIs it possible that you would still pre-build superagent.js for browsers as part of the npm prepublish script? At least people using npm will get it and you will not need to check it into the repository.\nhttps://docs.npmjs.com/misc/scripts\nThanks.\n. Understood, thanks.\n. ",
    "pmeijer": "From the current readme \"npm (for browser standalone) When we publish versions to npm, we run make superagent.js which generates the standalone superagent.js file via browserify, and this file is included in the package published to npm...\"\nSo this issue is implemented from npm, correct?\n. ",
    "koistya": "Ah, it's already fixed in https://github.com/visionmedia/superagent/commit/2b56be701d3d511b72883aa93eaee6ea711d1f06\nPlease, publish the new version, ASAP.\n. ",
    "mikemcgowan": "Thanks, I am aware arity for errors has been removed in 1.0.0.\nI'm pretty sure that's not the problem though.\nIf you look at the Jasmine spec, you'll see the callback already has both (error, response) parameters, and that the expectation that the first parameter (the error) is null succeeds on both 0.21.0 and 1.0.0.\nThe regression is caused by something in this block of code in the Response constructor (line 309+ in 1.0.0):\n@@ -42678,9 +42678,11 @@ function Response(req, options) {\n   options = options || {};\n   this.req = req;\n   this.xhr = this.req.xhr;\n-  this.text = this.req.method !='HEAD' \n-     ? this.xhr.responseText \n+  // responseText is accessible only if responseType is '' or 'text'\n+  this.text = (this.req.method !='HEAD' && (this.xhr.responseType === '' || this.xhr.responseType === 'text'))\n+     ? this.xhr.responseText\n      : null;\n+  this.statusText = this.req.xhr.statusText;\n   this.setStatusProperties(this.xhr.status);\n   this.header = this.headers = parseHeader(this.xhr.getAllResponseHeaders());\n   // getAllResponseHeaders sometimes falsely returns \"\" for CORS requests, but\n@@ -42689,7 +42691,7 @@ function Response(req, options) {\n   this.header['content-type'] = this.xhr.getResponseHeader('content-type');\n   this.setHeaderProperties(this.header);\n   this.body = this.req.method != 'HEAD'\n-    ? this.parseBody(this.text)\n+    ? this.parseBody(this.text ? this.text : this.xhr.response)\n     : null;\n }\nIn 1.0.0 the assignment to this.body can be to this.xhr.response whereas in 0.21.0 it could not.\nIf I change:\njavascript\n  this.body = this.req.method != 'HEAD'\n    ? this.parseBody(this.text ? this.text : this.xhr.response)\n    : null;\nto:\njavascript\n  this.body = this.req.method != 'HEAD'\n    ? this.parseBody(this.text ? this.text : this.xhr.responseText)\n    : null;\nNote: this.xhr.responseText not this.xhr.response then my tests continue to pass on 1.0.0.\n. This Jasmine spec now passes in 1.1.0 so closing.\nThank you!\n. ",
    "zerok": "From what I can see there is no easy way to inject a custom XMLHttpRequest object into a single request. You should get there to some degree by monkey-patching the exposed getXHR method, but that would change it globally (and be rather ugly):\n```\nimport Superagent from 'superagent';\nSuperagent.getXHR = function() {\n    return new XMLHttpRequest({mozAnon: true, mozSystem: true});\n};\nSuperagent.get('/some/path').end((err, res) => {\n    ...\n});\n```\nIf the Request.prototype.get method would only fetch a new xhr object if one wasn't really available locally, it would be much easier. I'm not sure, though, how high the demand for custom XHR objects outside of your use-case actually is \ud83d\ude42\n. Do you get that after cloning superagent and executing npm install superagent inside the superagent directory? Why would you do that? \nYou normally run npm install superagent inside a project you'd like to use superagent in if you're using for instance browserify or webpack there \ud83d\ude42\n. ",
    "alekzonder": "I check size with webpack\nvar request = require('superagent');\nwithout uglify\n27.9 KB for version 1.1.0 without qs module\n36.4 KB with qs module\nwith uglify plugin\n9 KB for version 1.1.0 without qs module\n12.3 KB with qs module\n. If i just start using superagent and don't know about qs module, this is a hidden bug\n``` javascript\nsuperagent.get('/test').query({foo: {bar: {baz: 100}}).end(...);\n// GET /test?foo=[object Object]\n// WTF!?\n```\nWe can do recursive serialize and parse for GET-params.\nBut if qs module do same better and has no dependencies, why not use it?\nOkay, you win :)\nIf you don't want use qs for browser, add example to documenatation and close this pull request\nsuperagent.get('/foo').query(qs.stringify({foo: {bar: {baz: 100}}}));\nThanks\n. We can develop our stringify and parse in superagent, but why?\nIf qs module works good, covered by tests and has no large dependencies.\nWe can develop same functional, but without tests.\nOR we can detect: if query object is nested, throw error 'use qs module for nested objects in query' :)\n. ",
    "leedut": "I've got it.\nThe homepage will jump into another page when it receives email&psw.\nSo result.headers i got is the header of next page. Second page doesn't include the cookies infor.\nI use redirects(0)  and it works~\nTHX~\n. ",
    "RaasAhsan": "I wasn't really sure if pasting code or config would work, there was a lot of space where it could've been. But I just figured out that apparently cookies and those additional headers won't come in if I'm on a localhost domain, so there has to be at least 2 levels, a custom dns name like www.localhost or 127.0.0.1 will have to be used.\nThanks!\n. ",
    "ilyaigpetrov": "echo \"window.request = require('superagent')\" | browserify - > superagent.js, but I wish I could get a prebilt bundle from visionmedia/superagent/dist/superagent.js.\n. ",
    "fdubost": ":+1: \n. ",
    "James1x0": "Bump\n. ",
    "dennishall1": "Shouldn't be anything wrong with obj.delete.  Strict mode should only disallow an attempt to set a value to a global variable named delete, but this is not a global variable, it is an object's method name.\nSeems fine:\n(function(){ \"use strict\";  var o = {};  o.delete = \"hello\"; return o; })();\n...\"Use strict\" does not appear to prevent setting an Object property named delete.\nThe only potential gotchya would be if the language ever decided to add an un-overridable delete method or property to the Object prototype.  Object :: deleteProperty is in the ES6 draft.\n. ",
    "iMerica": "This has been closed, yet .delete() is still not supported. What was the final resolution?\n. ",
    "vmasto": "Greetings, this also appears as an example on the README of the repo (under installation). Took me a while to figure out why the query wasn't working :dancer: \nhttps://github.com/visionmedia/superagent#installation\n. Ahh, my apologies, I naively assumed it was an all-in-one like jQuery's data on $.ajax. \n. ",
    "yourcelf": "As mentioned in #606, the documentation indicates that it does:\n\nWhen issuing a GET request the res.send(obj) method will invoke res.query(obj),\n\nThis test shows the described behavior.  If that's not what is desired/expected, the docs need to be changed.\n. I don't know if it ever worked. But I know I tried it, when implementing a polymorphic function that handled both getting and posting, and the docs said I could -- something like:\nfunction sendIt(method, data) {\n    request[method]\n        .send(data)\n        .set(\"Authorization\", ...)\n        ... other stuff ...\n       .end()        \n}\nHaving to branch \"send\" to \"query\" when using a different verb makes that a fair shake less elegant to implement.  But I recognize that conflating query/body could constrain you from exercising edge cases in the HTTP spec like sending a body along with a get request.  I'd personally be happy with a docs fix instead.\n. Uh -- client version, I guess?  I'm using superagent in unit tests under node, and browserify-packed version in the browser.  Invoked like this in both cases:\nvar request = require(\"superagent\");\nrequest.get...\n. ",
    "blented": "+1 on this, couldn't figure out why send() wasn't working with get().  Forcing .query() instead makes code harder for no reason.  @englercj is your version up on NPM?\n. ",
    "richardaday": "+1.  Ran into this same issue.  Docs and test case says it's supported.  Turns out, it's not.  I was also creating a polymorphic function like @yourcelf explained above.\n. ",
    "ludovicofischer": "Looks like the build failed because Firefox did not start in the build environment.\n. ",
    "elmigranto": "\nAPI. Returning an error for non-2xx status codes seems silly\n\nUnless someone uses HTTP as a transport and always returns 200.\n. ",
    "wali-s": "Fixed the version issue.\nIf you mean my webpack bundle, in my particular case, the bundle size is unchanged. I believe because both node-mime and mime-types were already included as dependencies for other libraries.\nDetails on a related issue that may be fixed by this PR (browserify support): https://github.com/felixge/node-form-data/pull/95\n. ",
    "vjeux": "Thanks for merging it in that quickly :)\n. ",
    "amasad": "A new version on npm would be awesome!\n. ",
    "brentvatne": ":+1: nice\n. ",
    "prayerslayer": "Bumpy!\nIt\u2019s been two weeks and I\u2019ll need this in production probably as soon as next week. Depending on a forked superagent is nothing that excites me though, so would you mind sharing your opinion on whether this is a desirable functionality (=> you would accept the PR) in the first place? If not I\u2019d be very interested in an alternate solution where I don\u2019t need to patch superagent.\nReasons putting clone into superagent:\n- From the outside I don\u2019t know whether I\u2019m using the Node or browser request and as a library user I don\u2019t care, actually.\n- State needed for cloning might not be available from the outside.\n(An alternative to clone might be something like reset, after which it\u2019d be possible to call end on the same request again. I don\u2019t know if this is technically possible/feasible using http on Node and XMLHttpRequest in the browser though.)\nThanks for your time and consideration!\n. How do you debug superagent when a test fails on Android 5 on Linux and IE whatever on Windows 2012?\n. ",
    "tmathews": "Ripadipdip :skull: . ",
    "UYEONG": "This issue happend only in an old version, i'll close this issue\n. ",
    "dwieeb": "Wishing this small, useful PR was in superagent right now.\nIf the modifier functions (.query(), .set(), etc) don't return new immutable request objects and .clone() doesn't exist, then there's no built-in way to construct a request from an existing request. . ",
    "edazdarevic": "I'll make a PR for this.\n. ",
    "longlho": "I actually gotta :-1: this since I'm not a big fan of polluting the API. There's also a[0]=1&a[1]=2&a[2]=3 (this maintains the order of the array since key=value is by nature unordered. Some API takes in a=1,2,3 also. If you want to serialize an array, just serialize it and pass it in as the string. This works:\njs\nsuperagent()\n  .get('/things')\n  // String as query\n  .query('a=1&a=2&a=3')\n  // Object as query\n  .query({ foo: bar })\nIt will concat things properly.\nThere's querystring libs like qs that handle a slew of diff serialization schemes.\n. yup client basically shims that. Again, you can pass in a serialized string to ensure proper serialization IMO.\n. ",
    "ropez": "Well, qs can format query strings from arrays with no sweat.\n``` javascript\n\nvar qs = require('qs')\nqs.stringify({foo: 10, things: [1,2,3]})\n'foo=10&things%5B0%5D=1&things%5B1%5D=2&things%5B2%5D=3'\nqs.stringify({foo: 10, things: [1,2,3]}, {arrayFormat: 'repeat'})\n'foo=10&things=1&things=2&things=3'\nqs.stringify({foo: 10, things: [1,2,3]}, {arrayFormat: 'brackets'})\n'foo=10&things%5B%5D=1&things%5B%5D=2&things%5B%5D=3'\n```\n\nCan be used with superagent easily:\njavascript\nsuperagent.get('/things').query(qs.stringify({thing: things}))\nHowever, I decided to use it with plain XMLHttpRequest in our project.\n. ",
    "psirenny": "My apologies, I fixed the tests.\n. done\n. ",
    "jtwebman": "I am having this same issue using the supertest which uses this library!\nI am writing a test where I want to pass multiple values into the same query string item to make it an array. I am using the connects library that likes me add [] to the end and makes sure it is an array on the server side. If I pass just one like this:\njavascript\nrequest(app)\n    .get('/balance_records/?types[]=BalanceCredit')\nSupertest does the correct thing and doesn't add anything to the url:\n/api/v1/accounts/1-VzLqGc7vJK/balance_records/?types%5B%5D=BalanceCredit\nBut if I pass mutiple like this:\n``` javascript\nrequest(app)\n    .get('/balance_records/?types[]=BalanceCredit&types[]=BalanceDebit')\n//or\nrequest(app)\n    .get('/balance_records/')\n    .query({ 'types[]': ['BalanceCredit', 'BalanceDebit'] })\n```\nSupertest injects array elements like so:\n/api/v1/accounts/1-VzLqGc7vJK/balance_records/?types%5B%5D[0]=BalanceCredit&types%5B%5D[1]=BalanceDebit\nWhat I need is:\n/api/v1/accounts/1-VzLqGc7vJK/balance_records/?types%5B%5D=BalanceCredit&types%5B%5D=BalanceDebit\nIs there a way to turn this off or remove it. At least adding an option to override the default and allow for this way of handling arrays would be nice.\nI'll fork and send a merge request adding in an option as a second parameter on query function. This way it doesn't break anything else.\n. I just did like below and it seem to work.\njavascript\nrequest(app)\n.get('/balance_records/')\n.query({ types: ['FlashDisplayCreative', 'ImageDisplayCreative'] })\n. ",
    "xogeny": "I have also run into this.  Was there any resolution to this?\n. What query string did it generate?  Does it produce:\n?types[0]=FlashDisplayCreative&types[1]=ImageDisplayCreative\nor\n?types=FlashDisplayCreative&types=ImageDisplayCreative\nI'm using the version bundled with traverson right now (which is, presumably, an older version).\n. ",
    "whistlerbrk": "I'm still running into this and I can't seem to just pass a string..... ",
    "tux4": "I can reproduce this issue on IE 11 on Windows 8 too. My request is:\njs\nsuperagent\n  .post('example.com')\n  .end(/* ... */)\nSame as you, the request body for IE11 is 'undefined' with Content-Length: 9.\n. ",
    "amarnus": "Workaround:\njavascript\nrequest.post('/foo')\n.send(null)\n.end()\nUseful at least until the pull request above gets accepted.\n. ",
    "chrisbroome": "Also, a quick glance at the various parsers shows that they never throw and instead always return errors via the callback. Custom parsers should conform to this behavior as well.\n. ",
    "snackycracky": "for me this is a blocker atm. It happens randomly once a day.\nmy node backend is requesting some information from a service via superagent. In this call to the service I use just one header entry .set('Authorization', 'Bearer ' + access_token). \nThe final result from this service is logged as a nice JS object like this: {name: \"mr.x\", roles: [\"user\"]} just before resolve(user) is called with that object.\nMy frontend is requesting my node backend without any header set and the response in the frontend is a broken json.\nsee the missing closing brace in the rawResponse.\ndouble callback!\nLOGIN_FAIL { [SyntaxError: Unexpected end of input]\n                        rawResponse: '{\"name\":\"mr.x\",\"roles\":[\"user\"]',\n                        response: undefined }\nany update on this ? \n. could you send something to reproduce this very simple get? What versions do you have of superagent, node, express ? I cant reproduce this behavior deterministically. In our case this happens after like 48h of heavy load. Also in our case we COULD have problems with the header entry \"content-lenth\" but thats not verified yet.\nLooking forward to your \"simple get\".\n\nOn 20.03.2016, at 08:44, Maxime Gir notifications@github.com wrote:\nExperimenting the same problem on a very basic GET.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\n. \n",
    "MaximeGir": "Experimenting the same problem on a very basic GET. \n. ",
    "9662": "javascript\n    chai.request(server)\n    .get('/')\n    .set('Accept', 'application/json')\n    .end( (err, res) => {\n        res.should.be.json;\n        done();\n    });\nUncaught AssertionError: expected 'text/html; charset=utf-8' to include 'application/json'. \"devDependencies\": {\n    \"chai\": \"^4.1.1\",\n    \"chai-as-promised\": \"^7.1.1\",\n    \"chai-http\": \"^3.0.0\",\n    \"chai-url\": \"^1.0.4\",\n    \"mocha\": \"^3.5.0\",\n    \"nyc\": \"^11.1.0\"\n  }. Ignore. Looking at the wrong terminal.\n. ",
    "muddydixon": "by this p-r, we can control ssl/tsl version to request.\n(now I want to connect a server only accepting tls1 protocol.)\n. i forked from v1.2.0 (exactly 94afa3ae189267a8d352d72b20edb9900148959e).\n. Sorry, I use superagent in node (ServerSide).\n. I don't know it, but I will check it. \n. ",
    "jeffcharles": "Still getting the same error with 1.3.0 of superagent and 0.0.2 of superagent-prefix. I did notice that the problematic example that my code copies was removed in https://github.com/visionmedia/superagent/commit/c279f59bd4a5485a05cefca167a2d318e5591591. If that's the case, how am I supposed to apply a plugin across all uses of request without including it in each call?\n. ",
    "mnaughto": "So I actually think adding a constructor might make more sense, as superagent-defaults looks like it only works in node and not on the client side. \n. ",
    "rpastorelle": "Same for me. The res.header['content-type'] is null & res.type is an empty string.\n. @slooker @jonaswindey You can make the change in the PR above & see if that fixes for you as well. It was the cause of my problems.\n. I don't see the harm in using the typical case for this header. It adds no extra code and still fixes the issue.\n. I found & fixed the root cause in React Native \u2014\u00a0https://github.com/facebook/react-native/pull/1138\n. ",
    "slooker": "I'm having the same error as well.\n. This solved the problem for me.  Nice work. :)\n. This solved the problem for me.\n. I'm not sure if it's react-native's fault or not, but according to https://tools.ietf.org/html/rfc7230#appendix-A.2 section 3.2, headers definitely should be case-insensitive.\n. I agree, we should absolutely post it as an issue there.  Getting it fixed where it's actually broken is a better option than applying a bandaid further down.\n. ",
    "isair": "I'm having this issue as well using the latest version of react-native and superagent. When I do console.log(res) I see that content-type header is null, but when I do the request using a browser and log the response I can see that Content-Type header exists and is application/json.\nHowever, there is no problem when I do a request to https://api.github.com/users/isair/repos. I'm going to check and see what the server I'm using does different.\n. ",
    "jsergiu": "I'm still getting this error on firefox with latest version of react and superagent. After long debugging my work around is to add request.set('Accept', 'application/json') or whatever type you expect. This way the browser will treat the response as json even the response content type is something different.\n. ",
    "icefoggy": "I'm still getting this on react native android. It works fine for iOS, but the res.body is null and res.type is an empty string.\n. ",
    "mienaikoe": "I'm having the same issue now.\nUsing superagent version 1.5.0\nres.body is null.\nres.text is full.\nthe response is text/json, and I'm using a plain get request.\n. I'm not using React Native\n. A thenable without chaining is no different than supplying a callback as an argument to the method. It serves no purpose other than to fool the developer into thinking it's a fully-implemented thenable. If you don't want to adhere to the promises/A+ spec, then remove the then function.\n. ",
    "vandernoud": "@jsergiu Your solution worked for me, used it in react static starter app. Thanks.\n. ",
    "MathieuDoyon": "same here, if my API return content-type header application/vnd.profiles+json instead of application/json res.body is null and res.text has content.\n. ",
    "NICK-DUAN": "i have a problem probably like this\u3002\nHttp.post('/auth_manage/auth/change_auth/')\n                .send({name: values.name})\n                .send({op: this.state.value})\n                .set({'X-CSRFToken': Cookie.getItem('csrftoken')})\n                .type('application/x-www-form-urlencoded')\n                .end((err, res) => {\n                    console.log(res)\n                })\nthis is my code\uff0c when i use console.log print res, i got a html file which is my static file, i don't know why, anybody can help me?. ",
    "adnanh": ":+1: \n. ",
    "AdnanHidic": ":+1:\n. ",
    "dhrrgn": "@slooker @defunctzombie It is true that getResponseHeader should be case-insensitive.  However, this is probably an issue with JavascriptCore (which is the engine that ReactNative uses), thus cannot be fixed by the Facebook team (without an upstream fix).  I think the best solution here is just to use the correct case (per the spec).\n. ",
    "Semigradsky": "Looks like fixed in c279f59bd4a5485a05cefca167a2d318e5591591 and 21216bcaebee3c0258935501266a4bc0b5d1eed3\n. ",
    "is": "+1\nIn our project, the simple static server is written in node.js basic http server mode. It don't set correct content-type for json data. \n. ",
    "teebot": "@alex94puchades it can very well happen that for a reason or another the backend does not return a proper application/json . In my case superagent does not recognize this content type as a json type: application/app-v5+json;charset=UTF-8. \nMy backend colleague told me it's pretty standard but I could not find a proper spec confirming this.\nIn the meantime I had to fix this with\nvar responseBody = response.body || JSON.parse(response.text)\nbut it's kind of dirty\n. ",
    "eburi": "Did anything happen regarding this issue? The workaround proposed by @teebot is not working, as in my case response.body contains an empty object {}.\nrequest('GET', 'https://<misconfigured-server>/test.json')\n            .query({ format: 'json' })\n            .set('Accept', 'application/json')\n            .end((err, response) => {\n                console.log('Result:', response.body);\n                done();\n            });\nThe output is:\nResult: {}\nThe problem is, that the server does not send a Content-Type header. But I think, that there should be an option to tell superagent to parse the response, no matter what the server sends. \n. ",
    "clemens-tolboom": "I ran into this with GET too and https://github.com/visionmedia/superagent/issues/644#issuecomment-214772130 did not work. So I switched using https://www.npmjs.com/package/node-fetch for GET.. ",
    "tomconroy": "Related to #208 #207 \n. ",
    "DullReferenceException": "Any reason why this has not been merged? The cookie behavior really needs to be fixed.\n. ",
    "facultymatt": "+1 would love to see this merged and released. \nTesting sessions with redirects is fundamental to many websites, making this bug a major blocker in my opinion. \n. ",
    "nchase": "Hi folks, I had this problem too. It took me over a day to figure out, lots of time spent dissecting code that wasn't broken and reading through headers that were ultimately reasonable. cURL does what I expected, so I spent time poring over the differences between the behavior there, here, and in other libraries. Found no differences.\nUntil the behavior is changed (if it is ever changed), it would be great to call this behavior out loudly so that other people can find the issue easily.\nLooks like node-fetch has this same behavior, I might open an issue there too.\n. ",
    "sayanee": ":+1: \n. ",
    "chetverikov": "+1\n. +1\n. +1\n. ",
    "dominiksteiner": "+1\n. ",
    "mewben": "+1 to this....\n. ",
    "bbirand": "It is clear that you are very keen on not having anything to do with Promises, seeing as you locked a previous conversation over a pull request, and answered this one in a very blunt and uninformative fashion.\nAt 4000+ stars, you certainly do have the luxury of not caring at all what other members of the community think, and I appreciate that. But perhaps showing a bit more humility and providing an explanation (justification?) as to this derision against promises would be a grander goal? Like it or not, Promises are a very prevalent part of JS...\n. ",
    "screendriver": "+1 for supporting Promises\n. ",
    "ianshea": "Just went through this. You can use the plugin - https://www.npmjs.com/package/superagent-jsonp\n. ",
    "gwuhaolin": "nice~\n. ",
    "swiftone": "As a specific item, the docs say:\n \"Multipart requests\nSuper Agent is also great for building multipart requests for which it provides methods .attach() and .field().\"\nWhat isn't stated is that it appears to only support multipart/form-data, not multipart/mixed.  Saying as much would have saved me a day and seems pretty simple.  Unless I'm wrong? (he says with great hope and anticipation)\n. ",
    "tnrich": "This isn't working for me. Anyone else having this issue?\n. Sorry this was an issue with express not handling file uploads by default.\nI used the multer package to get them to come in. Thanks for the response\n:)\nOn Fri, Dec 11, 2015 at 5:06 PM Peter Lyons notifications@github.com\nwrote:\n\n@tnrich https://github.com/tnrich could you provide your browser\nversion details and what specifically happens when it doesn't work?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/652#issuecomment-164092268\n.\n. Hey there, is anything stopping these changes being merged in? I need them to use superagent in a webworker. \n. \n",
    "rylan": "+1, having this feature would be super handy\n. ",
    "deltaidea": ":+1: \n. ",
    "ponelat": "+1\n. @pornel thanks for filing the form-data issue (and creating a PR I see).\n. I updated the issue title, to be something more useful.\n. thanks for the fix !\n. ",
    "jbq": "Works great, thanks!  I had to manually resolve conflicts however, this pull request has to be updated.  See https://github.com/jbq/superagent/commit/7a8ddf4ac193573b608e592ab3a6a436eb144f0d\n. ",
    "brianswisher": ":+1: \n. ",
    "mwildehahn": "@pornel just rebased\n. hm, they're passing locally for me\n. is there a way i can repro that locally? i can't even see which test failed\n. to reference the response you should do: response.xhr.response\n. ",
    "fraczak": "I hit the same problem. Any news of that one?\n. ",
    "seanmadhaven": "me too have same problem with 1.2.0\n. I had to use field function instead and that worked.\n. ",
    "Donaira": "Same here with 1.2.0:\n\"request.part is not a function\"\n. ",
    "dgellow": "I have the same problem.\nRequest#part seems deprecated since Apr 29, 2014, cf commit https://github.com/visionmedia/superagent/commit/9afb6dfe703d6efe2155be98b2f9fb32a6ee7629\nSo, is the documentation out of date ?\n. @defunctzombie done \n. ",
    "dprentis": "yes, field works fine\nrequest.field(key, data);\n. ",
    "subdesign": "Partly true. Request::ajax() for some reason doesn't work, but except that SuperAgent works, example:\n<script src=\"js/vendor/superagent.js\"></script>\n<script>\n$(function(){\n    var request = window.superagent;\n    request\n        .post('/testapi')\n        .send({ name: 'Tom', '_token': $('meta[name=\"_token\"]').attr('content') })\n        .end(function(err, response) {              \n            console.log(response.body.greeting);                \n        });\n});\n</script>\nin routes.php:\nRoute::post('testapi', function(){\n    $name = \\Input::get('name');\n    return Response::json(array('greeting' => 'Hello, '.$name));\n});\nonly thing, you have to pass the csrf token with the request, but that's all.\n. ",
    "jmp909": "(note: csrf does not get processed on GET routes)\nthere are some functions in Laravel that use eg\nif ($request->ajax() || $request->wantsJson()) {\nthat first function checks headers for X-Requested-With = 'XMLHttpRequest'\nthe second function checks header for Accept = 'application/json'\nas far as superagent is concerned I have to set one of these 2 to pass that initial test:\n.set('X-Requested-With', 'XMLHttpRequest')\n.set('Accept', 'application/json')\nto answer the original queston then, it appears superagent is not setting the X-Requested-With value in order for laravel to see it as Ajax?\nregards\nJ\n. ",
    "bi-kai": "you can use async module.. here is the testing result:\n1 in parallel, setTimeout <1s, blocked.\n1 in parallel, setTimeout 1.5s+, run finished(the results are not verified).\n3 in parallel, setTimeout <3s , blocked.\n3 in parallel, setTimeout 5s+, still blocked.\n100 in parallel, always blocked, the async's final callback cannot be triggered anywhy.\nIf I set the total task num is 20 and 100 in parallel, it blocks at about 17(+-).\nIf I set the total task num is 200 and 100 in parallel, it blocks at about 183(+-).\n\n\nI donot really understand why this happened. Why they cannot run fluently in parallel?. @pornel Hi, thanks for your reply. Isn't async module Promise-based inside or it's just a syntax sugar of callback? \nI'm not sure the difference between async module and async in async/await. I regard them as the same thing -_-!!! I want to use async for reliable result all the time. \nIs promise module like bluebird will be helpful? I'm not quite familiar with async/await. . @pornel Thx!. ",
    "importjake": "@mtando how did you solve this?\n. ",
    "91ranjan": "@mtando how did you solve this?\n. @schmittyjd Where you able to solve this?\n. ",
    "bmf-san": "I want to know about this solution.\n. I have same problem.\n. ",
    "ganna-shmatova": "After a lot of research I found an alternative that works:\njs\nrequest.post('/upload').expect(200)\n    .field('uploadTo', './test/dir/nonbinary.txt')\n    .attach('file', fs.createReadStream('./test/nonbinary.txt'))\n    .end(assert('upload'));\nturns out you need to attach a read stream to be able to upload\nthe correct headers were automatically sent after this\n(the call must also have been post, and i had to use fields method to send in extra data -- send(obj) was not being caught anymore by express)\n. ",
    "jonhester": "Just ran into this issue. I think that this is a bug.\n. ",
    "juanmaia": "+1\n. ",
    "wenzowski": "Superb, thanks @pornel \n. ",
    "aalpern": ":+1: \nI just ran into this problem as well, in a REST API client I wrote that's intended for both node.js and browser usage. It means avoiding superagent's built-in query string encoding altogether, which really defeats the purpose of having it at all. \n. I'll see what I can do. Although I'm currently getting 35 test failures under node.js (in node 0.12.2 and 0.12.5) from a fresh clone of master, so that doesn't give me a lot of confidence in testing my own changes.\nEdit: ah, I see - the node tests require port 5000 be available. That'd be a good thing to add to the README (or find a random available port for the tests)\n. ~~Digging in, it looks like the bug is actually in the qs module, which handles all query string formatting: https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L823 , which has had 6 releases since the one in user here.~~\nWhoops, misread that entirely. The browser version just uses encodeURIComponent(), which is what's formatting arrays as comma-delimited values. \n. Just submitted a PR - if it could be packaged in a 1.2.1 release that would be :sparkles: :guitar: :tada: \n. Is it possible to structure a plugin to replace the built-in serialization? That way people who need it can opt for it, and those who don't need any more than basic key/value serialization can use the default. \nFor anyone who actually needs node/browser compatibility though, they're going to have to pay the cost anyway (2.4K minified and gzip'd isn't bad for my use cases). \n. OK, I've create a new PR (#699) which addresses the array-vaued parameter case without requiring qs. \n. Hi - any chance this will ever get addressed?\n. ",
    "ianks": "Why was this syntax (?hello=a&hello=b&hello=c) decided on over:\n?hello[]=a&hello[]=b&hello[]=c\nIt seems to me that the latter is the most common syntax for representing arrays in a query string.\n. I experience the same issues with superagent ^1.8.0\n. ",
    "carlos09": "I'm having this same issue. Seeing this when i try using superagent.  Any luck with this issue? @vlinder \n. ",
    "tdeheurles": "You can try to fix that issue by adding \nplugins: [\n    new webpack.DefinePlugin({ \"global.GENTLY\": false })\n],\nto your webpack config\n. I'll try to find... I\u2019m not sure the project is fine. I can\u2019t remind but maybe it\u2019s the one where I finished with babel-cli ...\n. @davis sorry, have looked to my commit and I can\u2019t find ... Do you run targeting node ?\n. ",
    "vlinder": "That is what solved my problem.\n. ",
    "targos": "Yes, I'm using it in usual window environment as well.\nCI seems to be run in browsers and passed without any error : https://travis-ci.org/visionmedia/superagent/jobs/65554746\n. @oleics I cannot reproduce a situation where self is not equal to window with browserify. When does that happen ?\n. @oleics \nI agree with your explanation, and my PR is here exactly to fix the fact that this is defined in browserify builds but not with the expected value.\nI can add a check for window first if that feels safer, but it should not be needed because self is a reference to window in the browser and to the worker global scope in web workers (see link in the OP).\n. I pushed a change to safely check for window first, PTAL\n. @defunctzombie braces added.\nThis is a correct, more conservative version than the first one. I think both behave exactly the same, but this one has the advantage to be explicit about about browser and web worker compatibility.\n. ",
    "oleics": "The PR will not work for code in browserify-bundles, as somehow self is not window inside a module.\nFollowing should cover pretty much all environments:\njs\nvar root;\nif(typeof window !== 'undefined') root = window;      // Browser\nelse if(typeof self !== 'undefined') root = self;     // Web Worker\nelse if(typeof global !== 'undefined') root = global; // Web Worker, but in a module (browserify)\nelse root = this;                                     // everything else\n. Just checked the issue again:\nThe reason that using superagent in browserify-bundles running in web-worker-env fails, is not that self is undefined. Instead, this is defined. So, this does the trick:\njs\nvar root;\nif(typeof window !== 'undefined') root = window;      // Browser\nelse if(typeof self !== 'undefined') root = self;     // Web Worker\nelse root = this;                                     // everything else\nCould be rewritten as a one-liner, but I would not do so for readability.\n. @targos \nIn web-worker-env, self is not window, as code running in a web-worker does not have access to window. self in web-workers is - simply put - a new context. See https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers\nBut that is not the problem here. Let me refer to this:\njs\nvar root = 'undefined' == typeof self\n  ? this\n  : self;\nthis might not always be window, especially when it comes to module-systems like nodejs/browserify or whatever-module-system. It is unsave to rely on this beeing always window. I think it is better to be explicit here and test for window first, then self, and then (as the last resort) this.\n. @targos \nThe check for self alone makes me a little nervous, as we all do var self = this. But this should really only be the last resort. I would throw an error if neither window nor self is defined. \n. @targos Thanks.\n@defunctzombie What do you think, merge?\n. thanks a lot, just in time.\n. ",
    "taish": ":+1: :+1: \nI am facing same problem using webpack & webworker.\n. ",
    "mohsen1": "+1\nPlease merge this. This module needs Web Worker support. It's deep in my dependency chain, I can't just use a fork. \nThanks!\n. ",
    "darxtrix": "Yeah, I am having the same problem. Actually superagent checks the Content-Type of the returned response. If the content is text itself but if the content type is wrong like application/json , it tries to parse it. If an error occurs during parsing, double callback error is thrown and res is not set.\n. There should be some option to get the raw response text in case the JSON parsing fails ?\n. @reinaldo13  Great !\n. ",
    "catc": "Same issue here. Response from API is plain text but the header is text/json which causes superagent to throw the double callback error.\n. ",
    "reicolina": "I added a .rawResponse property to the err object if the parsing fails. The code is pending approval in pull request https://github.com/visionmedia/superagent/pull/716\n. Fixed and awaiting approval for PR https://github.com/visionmedia/superagent/pull/723\n. @focusaurus: sure! Not a problem. I can get this done within the next couple of days.\n. @focusaurus: i just added the corresponding change to the server side code + test. Feel free to review when you get a chance. Thanks!\n. ",
    "FoghostCn": "I had the same problem, content-type is application/json but failed to parse,then it warned double callback!\n. no no\uff0cI mean .field method, not .attach method \nwhen I use .field method I can't set content-type to application/json, it default's to application/octet-stream. > For now, make it a Buffer or Blob and attach.\nYeah ,this is what I use now.\nOK, thank you for your time. ",
    "anthonyhastings": "Same here; I'm purposefully sending back malformed JSON (as that's what numerous Google scripts do to stop people injecting the resource directly onto a apage in a script tag). \nA way to either disable the auto-parsing, or, somehow get the response in the error would allow me to skirt around this problem.\n. It'll certainly give a workaround for examining the error and seeing if it \"really\" is an error. Having some way to disable the auto-parsing sounds like it'd be pretty useful but perhaps the use cases for this functionality are too small.\nDo you know when this PR will be included into a release or SuperAgent that could be pulled over NPM? When's your next release?\n. ",
    "Jpunt": "No, I can't for the life of me figure out why this is happening. The exception is still thrown a lot and I'll try to make time to take another look at it. Any hints of what direction I should be looking?\n. Thanks, I'll take a look at that one ASAP.\n. ",
    "GDreyV": "Hi, not sure if it's the same issue but I managed to reproduce this exception. I just created request and didn't call end(). I thought that request just shouldn't be issued but it causes exception instead. The point was that I was writing the test and I didn't want to send real HTTP request. I thought not calling end() should do the trick.\nSo I have to call abort() and now tests hangs for a moment. It looks like request is really sent and aborting takes some time.\n. ",
    "GantMan": "So this doesn't work in React Native either :(. ",
    "xcatliu": "+1\n. ",
    "nalwayaabhishek": "+1 I am getting the same error when no internet connection \n. ",
    "crcn": "+1\n. ",
    "benjdezi": "+1\n. ",
    "WenXuanYuan": "The same error occured with me !\n. ",
    "askucher": "+1. ",
    "timon": "This PR works for me, \nand I also find it concerning that current implementation will happily override any options.\nAt least cert and key should be exposed (I believe they could be made separate arguments), maybe some tis peer checking callbacks could be exported as well.\nThis is sample na\u00efve code I have used (that's basis upon which I'm building up now):\n``` javascript\nvar fs = require('fs');\nvar request = require('superagent');\nvar url = 'https://server.local/client_auth';\nvar myCA = fs.readFileSync('server-ca.crt');\nvar myCert = fs.readFileSync('client.crt');\nvar myKey = fs.readFileSync('client.key');\nrequest.get(url).\n  ca(myCA). // <-- already present\n  tls({ key: myKey, cert: myCert }). // <-- required to  work\n  end(function(err, res) {\n  if (err) {\n    console.log(\"Err: \", err);\n    return;\n  }\n  console.log(res);\n});\n```\n. Hello,\nsame question here.\n. @pornel Thanks, looks promising!\nI'll give it a try.\n. @pornel exactly what I looked for.\n. ",
    "Whoaa512": "This approach seems most amicable and forward thinking in the case that the options for tls.connect() change.\nI agree that overriding the other options is troublesome, however this could easily be avoided by simply moving the loop above the property assignments which should not be overridden.\nThe only other suggestion would be to add a comment above the method for documentation purposes and maybe a test. \n@cgx9, you could adapt my test from https://github.com/visionmedia/superagent/pull/832 \n. The problem in question is for making a request to an internal service with a self-signed cert, which unfortunately my IT department won't grant me access. This also rules out the dev only restriction.\nI actually like the design from #681 more than my own and will continue my comments there and close this PR.\n. ",
    "ericnewton76": "ca(...) and tls(...) shouldn't be on the returned object from get(...) but should be on request(...) so that wasteful redundancy in testing code is reduced\n```\nvar fs = require('fs');\nvar request = require('superagent');\nvar url = 'https://server.local/client_auth';\nvar myCA = fs.readFileSync('server-ca.crt');\nvar myCert = fs.readFileSync('client.crt');\nvar myKey = fs.readFileSync('client.key');\nrequest\n  .ca(myCA) // <-- already present\n  .tls({ key: myKey, cert: myCert }) // <-- required to  work\n  .get(url)\n  .end(function(err, res) {\n  if (err) {\n    console.log(\"Err: \", err);\n    return;\n  }\n  console.log(res);\n});\n```\nso that potentially (what i do in my test files)\n```\nvar fs = require('fs');\nvar request = require('superagent');\nvar url = 'https://server.local/client_auth';\nvar myCA = fs.readFileSync('server-ca.crt');\nvar myCert = fs.readFileSync('client.crt');\nvar myKey = fs.readFileSync('client.key');\nrequest = request\n  .ca(myCA) // <-- already present\n  .tls({ key: myKey, cert: myCert }) // <-- required to  work\n//now the request object is setup same for all subsequent GETs POSTs, etc\nit('test1',function() {\nrequest\n  .get(url)\n  .end(function(err, res) {\n  if (err) { done(err); }\n  console.log(res);\n});\n})\nit('test2',function() {\nrequest\n  .post(url)\n  .end(function(err, res) {\n  if (err) { done(err); }\n  console.log(res);\n});\n```\n. ",
    "borispovod": "Why closed?\n. I can't catch it. It's crash in different places all time, i can try to debug it again and maybe make pull request.\n. ",
    "ajnisbet": "I'm guessing it's because you didn't provide any information about your issue.\nIf you want to help, reduce your code to the minimum amount that still produces an error. Then post that code, the command you used to run it, the version of superagent you used, and the complete stacktrace.\nIn doing so, you'll probably find your issue has nothing to do with superagent.\n. You're right, this works as expected:\njavascript\nrequest\n  .get('http://localhost/id')\n  .query('key=val1,val2')\n  .end(function(err, res) {\n    console.log(res.text);\n});\nThanks for the workaround.\n. ",
    "mijie1023": "req.end(function(err, res) {\n   // console.log(res.body);\nfs.writeFile('test.png', res.body, function(err) {\n      console.log('Error: ' + err);\n   });\n});\n. ",
    "Enet4": "Bumping this dormant issue because an SO question emerged with the same problem. I've just answered it too. Basically, right now one should pipe the request object instead of the obtained response.\nUnless you wish to consider improving the documentation on how a response object should not be treated as a readable stream or actually making that part of the public API, this issue can be closed.\n. > The .end() callback is called after piping has ended and is no longer possible.\n\nYou can't use both .end() and .pipe(). Only one of them is possible at a time.\n\nNote that neither I nor the questions suggest doing both end() and pipe() on the request, but rather end the request and pipe the response, which is actually not that far out to assume the possibility. A small statement in this section on the subject would be nice to have.\n. ",
    "Harishgolla": "Any idea why this PR is closed?\n We want to send pfx and passphrase  to superagent. Let us know how we could do this in superagent.\n. ",
    "topaxi": "Yes, yes it is: http://jsonapi.org/\n. Sure, but there seems to be a movement in a lot of web frameworks in using this jsonapi.\nEmber.js is going to use the jsonapi as default: http://emberjs.com/blog/2015/06/18/ember-data-1-13-released.html\nThe Django REST Framework has an implementation: http://drf-json-api.readthedocs.org/en/latest/\nRuby on Rails is going to use it too, as rails-api is going to follow the jsonapi by default: http://wyeworks.com/blog/2015/4/20/rails-api-is-going-to-be-included-in-rails-5/\nIt would be nice if superagent, especially because it is used in browsers too, could support this, imho very small, feature.\n. ",
    "sbrunot": "I got the exact same issue when the HTTPS URL that I'm calling redirect to an HTTP url (with a 307 status code).\n. ",
    "olivierto": "I'm facing the exact same issue.... how did you manage to solve this?. ",
    "davidtom": "Has anyone solved this issue??. Okay, thank you!\nThe strange thing is that I'm seeing this error while trying to make a request to an API url that does use https. My requests to other https urls go through fine, so I'm a bit confused why the one doesn't work.\nI'm wondering if its a certificate issue on the part of the API owner? I'll keep looking into it and will circle back here with an update.. ",
    "fertrig": "Getting the same issue.\n. ",
    "tonyalaribe": "same here. CORS issue\n. ",
    "neekey": "@alex94puchades  I think actually superagent always send Content-Type: 'application/json caused the problem\nAnyway to disable this behavior?\n. sorry, I doubled checked, not an issue with superagent, just the browser's CORS strategy.\n. ",
    "tadjik1": "Yep, merge it please.\n. ",
    "lucidNTR": "both are the same, i did not see the other pull request due to its generic description.\nthe other version is probably better because using self can be better handled by linters.\n. ",
    "twincle": "maybe you're looking for this: https://github.com/twincle/superagent/tree/master/client\nhope this could help you.\nhave fun~\n. ",
    "jugimaster": "Thanks, that is roughly what I was looking for!\nWell, it's easier for me to fire off a couple of comments here than to set up a local repo and scrape together a pull request, so.. :)\nYou might want to adjust the isObject method a bit, because the current version returns true for Arrays too. \nInstead, you could do something like: \njavascript\nfunction isObject(obj) {\n  return obj === Object(obj) && !(obj instanceof Array) && !(obj instanceof Node);\n}\nYou could also start using strict equality comparisons: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Equality_comparisons_and_sameness\n. Thanks for the tip :) \nI'm using Babel now, and reasonably happy so far.\n. ",
    "nilgradisnik": "I assume you were referring to the if and else if style. I fixed that.\nAlso I'm not sure why Travis CI tests are failing, all the tests pass on my machine.\n. Done.\n. I agree with you. I was struggling to somehow incorporate this regex to the serialize map because it's a map, so we would need to add all the possible type variations in there which seems bad, where this regex solved this problem more elegantly.\nPerhaps changing that serialize to a function that takes the content-type value and returns a serializer function seems like a better solution? This would require a bigger change that's why I decided not to do it.\nI am all for having a more generic solution, if you look at the IANA list there are a bunch of +xml types which can be parsed by an XML parser.\nThis pull request was an effort to solve the JSON type variations but I can have another go at this and come up with a generic solution.\n. @defunctzombie I took another pass at this pull request. I added the serializeSubtypes function that takes care of this. This is where we can handle serialization of any other types such as XML etc.\n. ",
    "artnez": "+1\n. ",
    "js62789": "+1\n. ",
    "pho3nixf1re": "This is a critical capability rendering this lib just about unusable in the browser. What is holding it up from merging? I would be fine with a peer dependency on 'qs' as I'm already using that library elsewhere in our app.\n. ",
    "paranoidjk": "This is a break change, why it been released in a minor version  1.5.0? \nDoes superagent do not obey semver?. PS. Why not use ?cars[]=Saab&cars[]=Audi, It's more safe.\nref https://stackoverflow.com/questions/6243051/how-to-pass-an-array-within-a-query-string. ",
    "heguofeng": "oh i have the same problem\u3002\u3002\u3002. ",
    "natarajanmca11": "I am getting the same error in post request. Details are given below.\n\"superagent\": \"^1.8.3\",\n\n. ",
    "simoneb": "Doesn't this make res.forbidden and the like (which would be quite handy) basically useless?\n. Which means I should write this:\n.end(function(err, res) {\n  if(res) {\n    if(res.forbidden) return handleForbidden();\n    if(!res.ok) return handleNon200Response();\n  }\n  if(err) return handleGenericError(err);\n});\nIt's certainly not a big deal but not very readable either in my opinion. Why are non 2xx/3xx status codes errors in the first place? Probably too late to change this, but I think it would be much more consistent with other node APIs if the first line in a callback was always:\nif(err) return callback(err);\nwhich it is in all other libraries that I commonly use.\n. I looked up those issues and PR and understand why you're not willing to discuss this further. I strongly disagree with this decision though, as others did already, very counter-intuitive.\n. ",
    "asaf-romano": "@defunctzombie Would you also accept an implementation of catch (in-spec sugar for `then(null, func)``)?\n. ",
    "mattdell": "It must be related to this: http://jaketrent.com/post/expose-http-headers-in-cors/\nWe are using CORS requests so this explains it.\n. Thanks @pornel, that would be greatly appreciated!\n. I was curious how to do that @pornel and have figured it out. Another PR raised here with just the single commit: https://github.com/visionmedia/superagent/pull/878\n. +1 thanks for that\nHad to kick it a few times before but I have run them locally and they do pass. Seems to be the last test in Travis regularly stalls testing iphone 9.2 on Mac 10.10.\n. @pornel Thanks for merging!\nHow often do you publish to npm as I'm keen to get this into my solution as soon as possible.\n. ",
    "harry1989": "I took a quick look at the code and realized that, this is happening due to the typo at https://github.com/harry1989/superagent/blob/master/lib/node/index.js#L708. It should be \nif (0 != url.indexOf('http')) url = 'http://' + url.\n\ncan't find any place where we would be triggering the request to fire just for setting headers.\n\nContrary to belief we are actually triggering a http request even for setting the headers. \nhttps://github.com/harry1989/superagent/blob/master/lib/node/index.js#L274, this is the cause of the error. I even verified this by monitoring the traffic while set() method is called using tcpdump. Clearly it is triggering the http call.\n. ",
    "wonnage": "The (awful) node docs suggest that the request is considered in-flight already as soon as you create it:\n\nThis object is created internally and returned from http.request(). It represents an in-progress request whose header has already been queued. The header is still mutable using the setHeader(name, value), getHeader(name), removeHeader(name) API. The actual header will be sent along with the first data chunk or when closing the connection.\n\nSo maybe touching the header is making node attempt to send things? That's terrible. :(\n. ",
    "samyhrer": "This errors occurs in my application alot. I've had no success in reproducing the error as is seem to trigger randomly. Are we guaranteed that a\nrequest.get(..)\n           .set(..)\n           .end(..)\noperation will happen within the same tick?\n. ",
    "mpjura": "@defunctzombie I'm confused as to why this issue was closed. As @samyhrer noted above even if you initialize the request in the same statement chain, results are spotty.\nRunning mocha tests with superagent-mocker on this code fails around 20% of the time:\n```\nvar Service = {\n    request = require( \"superagent\" ),\nedit: function( id, params, callback ) {\n    this.request.put( this.formUrl( id ) )\n        .set( { \"Content-Type\" : \"application/json\" } )\n        .send( params )\n        .end( callback );\n}\n\n};\n```\n. @defunctzombie maybe I'm confused about when the request gets \"created\" then. I'm getting errors using the same patterns in the superagent docs. Opened a new issue with all the code to reproduce here: https://github.com/visionmedia/superagent/issues/741\n. Similar issue: https://github.com/visionmedia/superagent/issues/687\n. ",
    "gabzim": "I think I am hitting this bug, annoying, any updates?\n. ",
    "eexit": "Hello,\nI'm still having this issue with version 3.8.3. Could you advise?\nThanks,\nCode:\njs\nrequest\n    .post(url)\n    .accept('application/json')\n    .type('application/json')\n    .redirects(0)\n    .send(data)\n    .timeout({\n        response: 3000, // Waits 5s for the server to start sending\n        deadline: 30000, // Allows 30s for the response to load\n    })\n    .retry(2, function (err, res) {\n        // Don't retry on client errors\n        if (res && res.clientError) {\n            return false;\n        }\n        // Retry on all other kind of errors\n        return err || res.error;\n    })\n    .end(function (err, res) {\n        if (err) {\n            if (err.response && (err.response.clientError || err.response.redirect)) {\n                return callback();\n            }\n            return callback(err);\n        }\n        callback();\n    });. On inexistent domains, I get this error:\njson\n{\n  \"name\": \"router\",\n  \"version\": \"x.y.z\",\n  \"hostname\": \"bdb34863fa90\",\n  \"pid\": 17,\n  \"req_id\": \"1faeda99-cdc0-4ff3-be2d-d6d859fa62c2\",\n  \"level\": 60,\n  \"err\": {\n    \"message\": \"getaddrinfo ENOTFOUND example.com example.com:443\",\n    \"name\": \"Error\",\n    \"stack\": \"Error: getaddrinfo ENOTFOUND example.com example.com:443\\n    at errnoException (dns.js:28:10)\\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (dns.js:76:26)\",\n    \"code\": \"ENOTFOUND\"\n  },\n  \"msg\": \"getaddrinfo ENOTFOUND example.com example.com:443\",\n  \"time\": \"2018-05-31T14:13:36.736Z\",\n  \"v\": 0\n}\nI would like these to be handled by end() error but apparently not.. > That JSON is not from superagent, so you need to file a bug with whoever manages the service you're connecting to.\nError was just wrapped into bunyan, no big deal.\n\n:white_check_mark: Anyway, I found my answer by doing some more testings and I could avoid it by adding an extra condition:\n```js\nrequest\n    .post(url)\n    .accept('application/json')\n    .type('application/json')\n    .redirects(0)\n    .send(data)\n    .timeout({\n        response: 3000, // Waits 5s for the server to start sending\n        deadline: 30000, // Allows 30s for the response to load\n    })\n    .retry(2, function (err, res) {\n        // Don't retry on client errors\n        if (res && res.clientError) {\n            return false;\n        }\n        // Retry on all other kind of errors\n        return err || res.error;\n    })\n    .end(function (err, res) {\n        if (err) {\n            // Handles cases when host no longer exist: DNS errors\n            if (err.code && err.code == 'ENOTFOUND') {\n                return callback();\n            }\n        if (err.response && (err.response.clientError || err.response.redirect)) {\n            return callback();\n        }\n        return callback(err);\n    }\n    callback();\n});\n\n```\nThanks for your help though =). ",
    "yeatszhang": "I will use querystring~~\n. ",
    "eligolding": "Thanks. Didn't realize it worked like that.\n. Sorry been meaning to get back to this for while. I'll try to work on this asap. If I can't get something working soon I'll close this.\n. I just push a new commit. This one uses the tocify jquery plugin to generate the documentation menu. It includes scroll highlighting and animations.\nI made the proper changes to head.html.\nI also needed to include the widget component from jqueryui.\n. Thank you!\n. ",
    "dj": "@alex94puchades, ah, this seems obvious to me now but I wasn't thinking of that before. I just had an idea though.\nWhat if you raised the error if ( arguments.length == 1 ) && ( typeof fn == 'undefined' )?\nHowever, after typing this out, I guess I could see code where you pass end a callback that only is only defined sometimes and depend on it to noop? Feel free to close this if you're convinced that passing end() an undefined argument is a valid use case as well.\nI'm probably too tired to be thinking about this right now, so sorry if this is a dumb idea for some obvious reason. \n. ",
    "ptz0n": "Browser or Node/IO? Please provide example request.\n. ",
    "h1bomb": "maybe you can do like this\njavascript\nrequest\n    .get('http://someaudio')\n    .parse(request.parse.image) //I think audio parse like image\n    .end(function function_name(err, res) {\n        if (err) throw err;\n        console.log(res.body);\n    });\nbut body is {}\uff0cI don't known why?\n. ",
    "oleynikd": "I used it in node! I could'n figure out hot fix this so I switched to https://github.com/request/request\n. ",
    "rsolomo": ":+1: \n. ",
    "aredridel": "Heh. Definitely document the heck out of this. But at this point I'm moving away from projects that are using just thenables in favor of ones that use promises.\n. Oh, I think this is well handled!\n. ",
    "euwest": "I thought the original intent was to turn the request object into a \"thenable\" so any promise library with coercive functionality could turn it into a promise. So for native promises, it would look like:\njs\nvar reqPromise = Promise.resolve(superagent.get('/whatever'))\n  .then(something, otherThing)\n  .then(null, blahBlah)\n  ...\nis this not the original intent? why force usage of native promises in browsers that support them?\n. I just don't understand the desire to make this function reliant on a global Promise, simply to hide a Promise.resolve inside. There's so much room for pain, and the benefit seems so trivial.\n. > I also think it should cache the promise, so that var tmp = superagent.get(); tmp.then(); tmp.then() doesn't try to launch the request again.\nYeah, which is further reason for end returning the promise and it(i.e. end) not being a part of then(maybe that's what you were saying?). That way you'd have:\n``` js\nvar tmp = superagent.get().end();\ntmp.then(); \ntmp.then();\n```\n. > It's a pity indeed to not be comlpaint with some standard approach.\nSuperagent is not a promises implementation, though. Request objects just have a then method to make it a little easier to coerce into a promise, given an actual implementation.\n. ",
    "oncletom": "Interesting discussion: I don't think there is any negative impact on using es6-promise server side.\nThe question is rather client-side, where we might want to include the Promise polyfill for convenience but as @pornel stated, we don't want to overbloat if people already rely on external polyfills.\nWhy not having two artefacts, one with and one without polyfills?\nUsage wise, I think we are at a stage people are familiar with promises, especially since the rise of Node 4.x.\n. ",
    "WickyNilliams": "If people are averse to depending on a global Promise (I don't think that's a big deal since it's part of the language - not DOM - spec now), what about adding a mechanism for users to supply some factory function for producing promises? That way superagent has no implementation of promises itself (or half an implementation as it stands), and consumers can use their favourite promise implementation or the global Promise type.\nCurrently I find the then provided by superagent to not be useful. It gets painful/annoying having to wrap in a real promise every time, so instead I do the simple/lazy/bad/convenient (delete as appropriate) thing of monkeypatching Request.prototype.then to return a real promise. I suspect a lot of users do this also, or use one of the many libs which add in real promises.\n. ",
    "FuzzySockets": "@pornel I've been reading your comments throughout.  I'm with you all the way.  These guys must not use Promises.  I'm battling to get my superagent stuff promisified so to not manually wrap all of my api methods in promises.  I don't see how anyone can argue against using global Promise either;  It's an ECMA standard and the previous superagent implementation was pointless. Might as well use the callback.\n. Looks like version 2.0 is the answer. \n. ",
    "gaboesquivel": "so is it now possible to this ?\nrequest\n  .post('/api/pet')\n  .send({ name: 'Manny', species: 'cat' })\n  .set('X-API-Key', 'foobar')\n  .set('Accept', 'application/json')\n  .end()  \n  .then(handleSuccess)\n  .catch(handleError);\n. thanks\n. ",
    "vire": "What's the status please, there is an closed PR, but in the latest version of superagent (v1.4.0 and node v0.12.7) is not working as expected (see #722). \n. @FoxxMD thanks for clarification. It's a pity indeed to not be complaint with some standard approach.\n. ```\nHTTP/1.1 200 OK\nContent-type: application/hal+json\nAccess-control-allow-origin: *\nCache-control: no-store\n{\n  \"_embedded\" : {\n    \"users\" : [ {\n      \"username\" : \"admin\",\n      \"userId\" : 1,\n      \"created\" : \"2015-09-11T11:00:34.204Z\",\n      \"firstName\" : \"John\",\n      \"lastName\" : \"Doe\",\n      \"email\" : \"jdoe@somedomain.com\",\n      \"state\" : \"ACTIVE\",\n      \"_links\" : {\n        \"self\" : {\n          \"href\" : \"http://localhost:4000/users/1\"\n        },\n        \"user\" : {\n          \"href\" : \"http://localhost:4000/users/1{?projection}\",\n          \"templated\" : true\n        }\n      }\n    }]\n  },\n  \"_links\" : {\n    \"self\" : {\n      \"href\" : \"http://localhost:4000/users\"\n    },\n    \"profile\" : {\n      \"href\" : \"http://localhost:4000/profile/users\"\n    },\n    \"search\" : {\n      \"href\" : \"http://localhost:4000/users/search\"\n    }\n  },\n  \"page\" : {\n    \"size\" : 20,\n    \"totalElements\" : 1,\n    \"totalPages\" : 1,\n    \"number\" : 0\n  }\n}\n```\nres.body is null res.text is okay\nrequest.parse looks like this\napplication/json: parse()\napplication/x-www-form-urlencoded:\nso Response.prototype.parseBody returns null for the body\n. ",
    "FoxxMD": "@vire It was closed but not merged. @defunctzombie said above that he will not support A+ promises\n. ",
    "tarikakyol": "commit modified as requested @focusaurus \n. ",
    "garrows": "Without looking deeply, I think this is out of date as superagent now requires qs \nhttps://github.com/visionmedia/superagent/commit/dc18679a7c5ccfc6046d882015e5126888973bc8#diff-b9cfc7f2cdf78a7f4b91a753d10865a2R35\n. ",
    "linxixuan": "searching for this\n. ",
    "ccapndave": "P.S. looking at the network panel shows that the file is getting loaded, even though superagent reports an error.\n. The cause of this seems to be that phonegap/cordova webviews sometimes return 0 instead of 200 for the status.  http://simonmacdonald.blogspot.ch/2011/12/on-third-day-of-phonegapping-getting.html\n. ",
    "ertrzyiks": "We use superagent in isomorphic app and we experienced inconsistency in client and server response object. I don't see any documenation about statusCode indeed and I even tried to remove it, but testsuite failed without this property. \nI've added this field to introduce consistency, but similar effect can be done by removing statusCode from node version.\n. ",
    "patrickberkeley": "The issue was params needed to be stringified JSON.stringify(params), so nothing to do with superagent.\n. ",
    "steve-taylor": "Sorry, it wasn't clear, but this question is actually about cookies as they relate to superagent. My understanding, in general, was that if a browser has a cookie associated with a specific origin then that cookie will be sent in requests to that origin. But this is not working with superagent, and there is nothing in the documentation to explain why this is the case. Please re-open.\n. Oops - damn cookie was set to secure on localhost.\n. ",
    "RubenVerborgh": "@pornel Rebased and ready to merge.\n. This actually was a bug in the original implementation of redirection: only the key/value part of the query string was cleared (qs), but not the raw query string parts (qsRaw). This behavior surfaced because this commit now stores the original query string in qsRaw, and an existing unit test verifies whether the query string is cleared on redirect.\n. We don't need to parse the URL's query string anymore, as we use it unmodified.\n. If there is a query string, pass it unmodified (skipping the leading ? character).\n. ",
    "dafortune": "Hey Guys, I am having a similar issue, not only with \"PUT\" request but also with \"GET\" requests, I traced it back up to https://github.com/visionmedia/superagent/blob/master/lib/node/index.js#L736. #set and other methods internally calls #request() to create a request to work on. _callback attribute is set on #end, so _callback is not defined at that point. It seems that sometimes node emits an error before #end gets called and so we get this exception.\nrequest.put( url + \"/1\" )\n        // request() is called by `set` which creates the http request object and \n        // attaches `error` event handler, `#_callback` is not defined at this point. \n        // Sometimes node seems to emit an error at this point, before \"end\", which \n        // seems to be causing the problem.\n        .set( { \"Content-Type\": \"application/json\" } )\n        .send( { foo: \"bar\" } )\n        .end( function( err, res ) {\n            expect( res ).to.equal( \"put 1\" );\n            done();\n        });\nA workaround this issue that worked for me:\n```\n    var req = request.put( url );\n// WORKAROUND: https://github.com/visionmedia/superagent/issues/741\nreq._callback = function() {};\n\nreq.set(...)\n\n```\nI could create a PR to fix this if you want.\n. ",
    "jackspaniel": "Ok well a little further research shows all err objects looking similar: \n```\ncall.end(function(err, response) {\nconsole.log(err); // { [Error: getaddrinfo ENOTFOUND xxxhttp] code: 'ENOTFOUND', errno: 'ENOTFOUND',  syscall: 'getaddrinfo',  hostname: 'xxxhttp' }\n\nconsole.log(JSON.stringify(err)); // {\"code\":\"ENOTFOUND\",\"errno\":\"ENOTFOUND\",\"syscall\":\"getaddrinfo\",\"hostname\":\"xxxhttp\"}\n\nconsole.log(typeof err); // object\n\n```\nBasically I am trying to isolate timeout errors. Can I trust that if the timeout property exists in the error object, that means timeout error and nothing else? I don't really feel comfortable matching on err.toString() or something weird like that. And timeout is the only property in the err object. \nIdeally it would be nice to have an error code like code; \"TIMEOUT\".\n. Ok well now I'm guessing you just overloaded the toString() method. Although I don't see that in the source code anywhere.\n. Hey it looks like this actually works!\n.set({\"Content-Type\":\"application/json\",\"Accept\":\"application/json\",\"Margle\":\"Bargle\"})\nProblem solved! Would be good to add to the docs I guess.. ",
    "codeviking": "I ran into this as well, but if you check this out...\nhttps://github.com/visionmedia/superagent/blob/master/lib/client.js#L881\n...depending on the existence of err.timeout appears to be reliable, I'm going with that for now. \n. ",
    "bdefore": "A similar discussion ongoing for POSTman here: https://github.com/postmanlabs/postman-app-support/issues/576\n. As a workaround, I got this to work, with the proper Content-Type set, using FormData:\n``\n    const req = request.post(https://api.cloudinary.com/v1_1/${settings.CLOUDINARY_ACCOUNT_NAME}/image/upload`);\nconst data = new FormData();\nfiles.forEach((file) => {\n  data.append('file', file);\n});\ndata.append('api_key', settings.CLOUDINARY_API_KEY);\ndata.append('timestamp', Date.now() / 1000);\ndata.append('upload_preset', settings.CLOUDINARY_UPLOAD_PRESET);\n\nreq.send(data);\nreq.end((err, res) => {\n  if (err) {\n    console.log('error', err);\n  } else {\n    console.log('success', res);\n  }\n});\n\n```\n. @pharno still using that workaround \n. ",
    "philippTheCat": "@bdefore can you explain how you got it to work? In your example you're not setting the proper Content-Type which you said was needed for it to work correctly.\n. ",
    "jsdario": "@bdefore +1. Same problem here.\n. ",
    "marcuswhit": "+1 Same problem\n. @meenalt Why can't you use FormData in React?  I ended up getting this working using the following:\n```\nlet data = new FormData();\ndata.append('file', file, file.name);\nsuperagent\n    .post('url')\n    .send(data)\n    .end((ex, result) => {\n});\n\n```\n. ",
    "meenalt": "+1 on this issue.\nI can't use FormData in React, so the workaround solution doesn't work either :(. Anybody have any other suggestions?\n. I found that uploading files without specifying the Content-Type worked for me. In the request, I saw that  Superagent was able to determine that the Content-Type was multipart/form-data and appended the correct boundary. It worked successfully. \n. ",
    "athlite": "You should probably use field for non-file data. Like req.field('name', 'John Doe')\n. ",
    "Webbrother": "The same problem.\nI use @athlite approach. Not sure which one is right.\nCan anybody explain what is right way to set 'multipart/form-data' manually to request? Thanks.\n. @pornel thank you! Could you please explain in details what is the correct way to upload file with using 'superagent' and without manual setting of 'content-type'?\n. ",
    "cvkkumar": "@pornel Wow!! Thank YOU! I was totally dumbstruck for a few hours. . ",
    "melkishengue": "Thank you so much @pornel You saved my day!!. ",
    "pjisha": "Thank you so much @pornel, wow !!. ",
    "ymma": "req.set('enctype', 'multipart/form-data'). ",
    "Evgeniy-Mamaev": "@ymma Thank you so much. Once I've added req.set('enctype', 'multipart/form-data') to my request, it started to define correct boundaries of the file. . ",
    "rip3rs": "@ymma that worked perfectly.\nI am not very savvy with headers and stuff, would you mind explaining why this works like this?\nBest,\nJoe. ",
    "patrickleemsantos": "I tried setting content type to undefined and it works\n.set('Content-Type', undefined). ",
    "sherodtaylor": "This is still happening when I use attach. It calls back twice one with res defined and then another with undefined res.\nsuperagent\n      .post(`${domain}/api/bitcoinaddresses`)\n      .attach('bitcoin_addresses', files, filename)\n      .end(function(err, res) {\n        cb(err, res, res.body);\n      });\n. ",
    "fractalawareness": "I get the same exact behavior as mleanos described even in the v.2.0.0\n. ",
    "timendez": "I am still experiencing this problem in v3.0.0, notably, I am using two .attach functions. Oh, woops, I am using supertest, not superagent. Do you still want to see my code?. ",
    "timmolendijk": "It looks like this issue has already been successfully addressed by #670. As far as I understand a PR is awaiting to be approved and to go downstream.\n. ",
    "Cwallice": "I faced this problem while doing proxy responses with \"application\\yaml\" content type\nSince  our proxy engine is very generic it really doesn't care about possible return content type before response is actually received, since that I can't set parse function and while buffer option set to true is really a solution it still bring confusing because it doesn't come along with parsing settings logic\n. ",
    "limscoder": "+1\n. ",
    "jakepearson": "I didn't see anything like this. I'll take a crack at the PR.\n. @defunctzombie I attached some code. It turns out this facility is already on the node side of the library. I tried to make it similar for the client.\n. ",
    "dignifiedquire": "Any chance of this getting merged? This is currently blocking our usage of superagent\n. ",
    "digitalsadhu": "@sescobb27 so your fix works on the server but not on the browser?\n. @sescobb27 I ended up setting my tests Content-Type to application/json to avoid the issue and then added a single test using nodes http module to verify that setting Content-Type to application/vnd.api+json to verify that it works. Would be nice to be able to just stick with superagent/supertest but works for now.\n. ",
    "Eiryyy": "Does this duplicate with #695 ?\n. @pornel Thank you. Rereview please\n. The collect is not /[\\\\+]json\\b/.test(mime) but /[\\/+]json\\b/.test(mime), I suppose. And, why \\b (not$)?\n. ",
    "listepo": "+1\n. @defunctzombie review this PR please\n. ",
    "flipxfx": "+1\n. ",
    "heathprovost": "+1\n. ",
    "hc2p": "i had the same issue while using webpack instead of browserify. I solved it by using the imports-loader to inject a fake window object: superagent = require('imports?window=>{XMLHttpRequest:XMLHttpRequest}!superagent')\n. ",
    "CezaryDanielNowak": "I had similar issue, when using webpack code on server side.\nThe solution was:\nFront-end:\n// HACK: Allow to user different versions of superagent in browser and in node\nlet superagent;\nif (global.superagent) {\n  // node superagent\n  superagent = global.superagent;\n} else {\n  superagent = require('superagent');\n}\nBack-end:\nglobal.superagent = require('superagent');\n. Workaround:\nconst tmpField = superagent.prototype.constructor.Request.prototype.field;\nsuperagent.prototype.constructor.Request.prototype.field = function (name, val) {\n  return tmpField.call(this, name, val == null ? '' : val);\n};. ",
    "vadimgoncharov": "@focusaurus done.\n. ",
    "dandybreath": "ok, i re-read the doc about error handling.\nfortunately i wrapped it on a single function so i just need to change that.\nit's hard to check error since it occured after the apps running more than 12 hr iirc.\n. ",
    "detj": "Okay.\n. ",
    "mattfysh": "1.8.3 + .then causes this also... req.then(fn).then(fn) results in the request being sent once per .then\n. ",
    "hmeerlo": "Sorry, yelled too soon once again. I see that the latest and greatest version does support this. Mea culpa.\n. ",
    "ixtli": "I'm also having this issue when doing\njavascript\n            request\n                .get(url)\n                .set('User-Agent', uaString)\n                .end((err, resp) => {\n                    console.log(resp.body);\n                    done();\n                });\nwith node 6.2.1. \nI think it's clear that OP was not trying to override this request from a browser, otherwise it would not have identified itself as node-superagent/1.3.0.\nEDIT: I can also confirm that the object that is being returned by .end() has a top level key called _headers which does contain 'user-agent' (lowercase) with a value of uaString.\n. Ok so apparently I had failed at isolating the code and I now believe that it's actually some interaction i don't understand with https://github.com/visionmedia/supertest because when i require superagent directly and make a get request with the full URL it passes the user-agent correctly.\nFor what it's worth, what I'm doing with supertest is\njavascript\nconst supertest = require('supertest');\nconst request = supertest(config.serverAddress());\nrequest\n     .get(url + '&platform=WEB&type=start')\n     .set('User-Agent', macUAString)\n     .end((err, resp) => {\n    console.log(resp.body.data);\n    done();\n});\n. ",
    "ChrisCinelli": "+1\n. For request #2 err.response is undefined. I f you look at the stack trace it is clear that there is something wrong.. I installed with superagent:'*' in the package.json.. \"version\": \"3.5.2\". I get it. I wonder if it should have a more graceful way to fail. . ",
    "roshanraj": "Location headers received as xhr response is pre-processed (and stripped) by browser before response is passed to calling JS part (superagent in this case). The same issue has been asked on SO for jQuery.\n. Oh thats cool. Thank you for correcting me. \n. ",
    "Rambobafet": "Oh ok :(\nI change the way to pass the information by using the body.\nThanks for your answer :)\n. Oh that's nice to know :)\nThanks for your feedback <3\n. ",
    "astraw": "Something like this\nsuperagent\n        .get(request_href)\n        .set('Accept', 'application/json')\n        .end(\n          function(err,res) {\n            if (err || !res.ok) {\n              alert('Oh no! error');\n            } else {\n              alert('yay got ' + JSON.stringify(res.body));\n            }\n          });\n. ",
    "jordansexton": "FWIW I use node 4.2.1 with superagent 1.4.0 on both the client and server without apparent issue. I don't know about the tests, however.\n. ",
    "jbellenger": "@pornel would you mind publishing an updated package?\n. ",
    "ReadmeCritic": ":+1: \n. ",
    "kanreisa": "@enricostano\nHello! I've implemented it on https://github.com/kanreisa/superagent/commit/9e57664dc130d46fcc17a47301cf8756da339a55 .\nIf you sure, try it and feedback please.\nUsage:\nhttp://unix:/absolute/path/to/unix.socket:/request/path\n. @enricostano np ;)\n. @pornel Thanks review, I've fixed.\n. @pornel yes, added :cake: \n. retry build please\n. Oops, Node.js 0.10 has failed. I'll check it later.\n. ",
    "enricostano": "hi @kanreisa thanks! But I finally decided to create 2 different and separate API clients, one for server side (using request) and another for browser side (using XHR, until fetch doesn't get stable enough).\n. ",
    "mikefrancis": "Fixed this using .query(params), closing.\n. ",
    "honger05": "Thanks for your reply.  I did not execute npm install superagent inside the superagent directory. \nIt's amazing, It's ok for me to execute npm install superagent@1.4.0\uff0c but It's not ok without version '@1.4.0' . \nBut it can normally run npm i superagent in another directory, not the case-superagent that I use.\nI test many times. \nIt's over!  I don't want to turn from side to side.\n. ",
    "enginoid": "Is there a contributor who can re-run the tests on Travis?\nI've been experiencing the same flakiness/slowness locally as caused this test to fail (on <iphone 9.1 on Mac 10.10>), both on master and on this branch.\nI think there might be a Sauce Labs issue with this platform right now (although I notice that a similar thing has happened in a recent build that eventually passed).\n```\n- starting: \n- waiting: \n- waiting: \n- restarting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- starting: \n- waiting: \n- waiting: \n- restarting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- starting: \n- waiting: \n- waiting: \n- restarting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- waiting: \n- starting: \n- waiting: \n- waiting: \nError: Timeout opening url\n    at null. (/home/travis/build/visionmedia/superagent/node_modules/zuul/lib/SauceBrowser.js:144:35)\n    at Timer.listOnTimeout [as ontimeout] (timers.js:121:15)\nmake[1]:  [test-browser] Error 8\nmake[1]: Leaving directory `/home/travis/build/visionmedia/superagent'\nmake:  [test] Error 2\nnpm ERR! Test failed.  See above for more details.\nnpm ERR! not ok code 0\nThe command \"npm test\" exited with 1.\nDone. Your build exited with 1.\n```\n. Thank you! We'll stop using our fork and update to the latest version to get the fix in #758.\n. ",
    "MarkHerhold": ":clap: Thank you all!\n. ",
    "tejasmanohar": "@defunctzombie Responded via Twitter and then saw the issue... so thought this is a better place. I'm also up for helping maintain this. I use Superagent (and its unofficial bluebird/promise wrappers) most always on client and server :)\nalso helping out with koa, node-schedule, and boris right now (as well as personal and other small repos, of course)\n. ",
    "johnnyfreeman": "Out of curiosity, what do you use instead of Bower? I'm hearing this comment more and more and know there must be a reason even though it's worked well for me (so far).\n. ",
    "chrisbartley": "[sigh] The failing test is making a request to localhost:8888, assuming nothing is already listening on that port. But! I happen to have a server listening on localhost:8888, so the test \"fails\". I'd suggest documenting this assumption in the test description.\n. A solution, sure, but wouldn't it be better to just trap the error thrown when attempting to listen on a port that's already in use?  For example, this...\n``` javascript\nvar request = require('../..')\n      , express = require('express')\n      , assert = require('better-assert')\n      , app = express()\n      , url = require('url');\napp.get('/', function(req, res) {\n   res.status(400).send('invalid json');\n});\ndescribe('res.toError()', function() {\n   it('should return an Error', function(done) {\n      var server = app.listen(8888, function() {\n         request\n               .get('http://localhost:8888/')\n               .end(function(err, res) {\n                  var err = res.toError();\n                  assert(err.status == 400);\n                  assert(err.method == 'GET');\n                  assert(err.path == '/');\n                  assert(err.message == 'cannot GET / (400)');\n                  assert(err.text == 'invalid json');\n                  done();\n               });\n      });\n      server.on(\"error\", function(e) {\n         done(new Error(\"Test failed because something else is already listening on port 8888. Please shut it down and try running the tests again: \" + e));\n      })\n   })\n})\n```\n...fails like this if there's something already listening on port 8888 (and this version tells you so, too!):\n1) res.toError() should return an Error:\n     Error: Test failed because something else is already listening on port 8888. Please shut it down and try running the tests again: Error: listen EADDRINUSE\n      at Server.<anonymous> (/Users/chris/Downloads/superagent-latest/superagent/test/node/toError.js:28:15)\n      at Server.emit (events.js:107:17)\n      at net.js:1160:12\n      at process._tickCallback (node.js:355:11)\n. ",
    "samkelleher": "It seems that if buffer is enabled and the response compressed, those events are not fired. When buffer is disabled, the file is written to and only the end event is called. It's still buggy but meets my current needs.\n. ",
    "edmundoa": "I stumbled into this issue while debugging an error I'm seeing with superagent (v. 3.5.2) and I want to add a comment on it:\nDue to the inconsistency described in the issue, the code handling request.auth() in node also throws an error if the user given as a first argument is undefined, while in the browser it works fine.\nI'm willing to do a PR for this, would you consider merging it? I know the issue said it would be a good first contribution, but it's also fairly old...\nThank you in advance!. I will take a look, thank you for your review!. It looks like Safari and IE send cached passwords, when the HTTP basic auth password is empty, as it is in a couple of the tests I added on this PR. That makes the test server return a 401 challenge, and browsers show a prompt to ask for new credentials, causing the test to time out and fail.\nI have been looking for a while, but I don't know how can I clear those cached credentials, any ideas or suggestions?. You didn't see the error before because there were no tests for this in the browser, they got added in this PR 7a822362148983ef6e47cfedaf0e31139dda6178.\nJust to verify the issue existed before, I ran the new tests locally in Safari against the old code, and they showed the same behaviour as the CI reported. That of course doesn't mean I didn't do something wrong on the tests, but I can't see where \ud83d\ude04 \nYesterday I didn't have that much time to write more details on why I think the error we see is cache-related, but here they are now.\nTo debug the issue I added logs into the code doing the basic auth in the browser (via superagent) and the express middleware that is doing the basic auth on the test server side.\nThis is what I get in the browser console when running the tests in Chrome 60 (or Firefox 55):\nbasic auth with \"foo\", \"bar\"\nbasic auth with \"foo\", \"bar\"\nbasic auth with \"foo\", \"bar\"\nbasic auth with \"foo\", \"\"\nbasic auth with \"foo\", \"\"\nThis is what the server is logging:\nauth attempt  user: \"foo\"  pass: \"bar\"  successful?  true\nauth attempt  user: \"foo\"  pass: \"bar\"  successful?  true\nauth attempt  user: \"foo\"  pass: \"bar\"  successful?  true\nauth attempt  user: \"foo\"  pass: \"\"  successful?  true\nauth attempt  user: \"foo\"  pass: \"\"  successful?  true\nThis is what I get in the browser console when running the tests in Safari 10.1.2 (or IE 11):\n[Log] basic auth with \"foo\", \"bar\" (test-bundle.js, line 1307)\n[Log] basic auth with \"foo\", \"bar\" (test-bundle.js, line 1307)\n[Log] basic auth with \"foo\", \"bar\" (test-bundle.js, line 1307)\n[Log] basic auth with \"foo\", \"\" (test-bundle.js, line 1307)\n[Log] basic auth with \"foo\", \"\" (test-bundle.js, line 1307)\nThis is what the server is logging:\nauth attempt  user: \"foo\"  pass: \"bar\"  successful?  true\nauth attempt  user: \"foo\"  pass: \"bar\"  successful?  true\nauth attempt  user: \"foo\"  pass: \"bar\"  successful?  true\nauth attempt  user: \"foo\"  pass: \"bar\"  successful?  false\nauth attempt  user: \"foo\"  pass: \"bar\"  successful?  false\nauth attempt  user: \"foo\"  pass: \"\"  successful?  true\nAs you can see, in Safari/IE there are two extra attempts to authenticate with foo and password bar, even when it should use foo and an empty password. The browser is logging the right credentials and they also appear correctly in the network request in the browser's developer tools:\n\nYou can see that the request includes an Authorization header with Zm9vOg== as encoded credentials, which is exactly what I get when running btoa('foo:') in the browser console.\nIt is at that point when the browser displays a prompt asking for new credentials, and also when the tests time out if the prompt is not closed.\nI'll try to further debug the request being sent by the browsers with Wireshark or something similar, to see if the request is actually wrong or something else is going on, but maybe someone has a better idea on how to fix this, or at least what is wrong with it.\nIn case it wasn't clear before, I am not saying there's nothing wrong with the code I submitted, just that the only explanation I could find so far after looking into the issue is not pointing at the changes in the PR \ud83d\ude42 . ",
    "calebmer": "1.5.0 hasn't been published to npm so no.\n. Any updates on this? Do you recommend I specify this repository for the 1.5.x version?\n. Sorry for taking so long, but I can confirm it fails in 1.5.0 and the master branch.\n. It seems like the request is being made successfully, but the response is failing to decompress.\n. ",
    "pobed2": "Awesome. Thanks for the response.\n. ",
    "ArtskydJ": "I think this is going to be an issue for me, so I'd be willing to contribute to solve this.\nPerhaps instead of this\njs\n.on('progress', function (ev) {\n    console.log(ev) // { loaded: 1234, total: 2468 }\n})\nit could be\njs\n.on('progress', function (ev, type) {\n    console.log(ev) // { loaded: 1234, total: 2468 }\n    console.log(type) // 'download'\n})\nor it could be\njs\n.on('progress', function (ev) {\n    console.log(ev) // { loaded: 1234, total: 2468, type: 'upload' }\n})\nAny thoughts?\n. Yeah, more specific than type would be good. Maybe upload: true for uploads, and upload: false for downloads?\nI'll probably use direction, as it fits quite nicely. Hopefully I can make the PR tonight.\n. From lib/node/index.js:\njs\nself.emit('progress', {\n  lengthComputable: lengthComputable,\n  loaded: loaded,\n  total: total\n});\nFrom lib/client.js:\njs\nvar handleProgress = function(e){\n  if (e.total > 0) {\n    e.percent = e.loaded / e.total * 100;\n  }\n  self.emit('progress', e);\n};\n. Wow, thanks for putting your time into this!\nI would like the node and browser code bases to be shared (as much as possible). When they're separate, it only leads to confusion/discrepancies between them.\nI don't think the shared code should be placed in an entirely separate module, just a separate file for now. There is a lot of cost in creating a separate module.\nRefactoring a node/client method to use shared code is probably up to the situation. If it can be cleanly merged, I am all for it, since it reduces the amount of duplicated code. If it is impossible to cleanly merge them, then it probably means there really isn't much duplication of code.\n. It looks like node only emits 'progress' on uploads. Perhaps the 'progress' event should be added to node downloads as well.\n. Done.\n. ",
    "gavacho": "Yeah, the node tests predate the client tests and are also much more robust.  If I prepare a PR which changes the client library to be consistent with the node library, would that breaking change be accepted?\n. Sounds reasonable.  Add those methods to both libs and deprecate the current parse?\n. ",
    "huguangju": "@focusaurus I didn't encounter CORS error, and my res.body is {}\n. ",
    "chrischjh": "I got the same error after upgraded to 1.6.1 today. It works at version 1.5.0\n. ",
    "clemf": "I am having this same issue. res.body is null, while res.text works. Here is curl -i for the resource I am testing:\nsh\nHTTP/1.1 200 OK\nServer: nginx/1.7.6\nDate: Tue, 29 Dec 2015 13:29:54 GMT\nContent-Type: application/hal+json\nTransfer-Encoding: chunked\nConnection: keep-alive\nX-Powered-By: PHP/5.6.0\nSet-Cookie: PHPSESSID=o067841oqm79jvsoqjjsjdh356; path=/\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\nCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nPragma: no-cache. ",
    "niieani": "Same problem with Content-Type:  application/x-json.\n. I don't control the server in this instance. \nIn that case could there be a way to force superagent to treat the output as if it's some Content-Type, essentially overriding the Content-Type that the server returns?\nAlso, Firefox's Firebug seems to recognize application/x-json as JSON:\njs\n // List of JSON content types.\n var contentTypes =\n {\n     \"text/plain\": 1,\n     \"text/javascript\": 1,\n     \"text/x-javascript\": 1,\n     \"text/json\": 1,\n     \"text/x-json\": 1,\n     \"application/json\": 1,\n     \"application/x-json\": 1,\n     \"application/javascript\": 1,\n     \"application/x-javascript\": 1,\n     \"application/json-rpc\": 1\n };\n. ",
    "craigrich": "This worked for me (FF-47)\nsuperagent.get(url)\n  .set('Accept', 'application/hal+json')\n  .then(response => \u2026). ",
    "clayreimann": "How can I kick off the Sauce tests again? (and why are they always so flakey?)\n. Version 2.x of qs doesn't percent encode ' per RFC 3986. And as far as I can tell your tests just expect qs to fail in a very specific way when you provide UTF-16 strings as input.\n. It might if you think that no longer returning an error when UTF-16 characters will be encoded in the query string constitutes a breaking change\n. ",
    "MovingGifts": "@pornel Is this still the recommended way or is there something baked in the library now to allow that out of the box?. Awesome, thanks for the quick response :). ",
    "kenjiokabe": "@pornel \nYes, it works!\ncf. \nhttp://stackoverflow.com/questions/26479123/angularjs-http-delete-breaks-on-ie8\n. @pornel \nThank you for merging!\nCould you please update npm ver. 1.6.1 -> 1.6.2 ?\n. ",
    "lbeschastny": ":+1: It would be very nice to have this PR released\n. ",
    "rafaferreira": "+1\n. ",
    "bratva": "+1 \n. ",
    "notflip": "Is this fixed or still open?. @pornel Is it possible to merge this? the ['catch'] is forward compatible! I tested it in non IE9 browsers. Thank you!. ",
    "jimmywarting": "Here is a reliable FormData polyfill: https://github.com/jimmywarting/FormData. ",
    "823844596": "@jimmywarting   i use your polyfill in my code, and run it in IE9, but the console show error like:\nSCRIPT5009: 'Blob' undefined\nand i found Blob support IE10 from https://developer.mozilla.org/en-US/docs/Web/API/Blob\nhow to solve it? thx~. okays... thanks for your apply~ i will try to use other polyfill.. ",
    "cmawhorter": "i've moved on from the lib so i might not be the best for a pr but here's an example of why assuming utf8 is a bad idea.  \njavascript\n// superagent (i couldn't get res.body to populate no matter what i did by my point remains valid)\nvar Encoding = require('encoding-japanese');\nrequire('superagent').get('http://i1.theportalwiki.net/img/6/6b/Portal2_japanese.txt').end(function(err, res) { \n  console.log('as-is; incorrect output', res.text); \n});\nrequire('superagent').get('http://i1.theportalwiki.net/img/6/6b/Portal2_japanese.txt').end(function(err, res) { \n  console.log('correct conversion; incorrect output', Encoding.convert(res.text, { from: 'UTF16', to: 'UNICODE', type: 'string' })); \n});\nrequire('superagent').get('http://i1.theportalwiki.net/img/6/6b/Portal2_japanese.txt').end(function(err, res) { \n  console.log('this shouldnt work and it doesnt', Encoding.convert(res.text, { from: 'UTF8', to: 'UNICODE', type: 'string' })); \n});\njavascript\n// wreck returns Buffer, which is the correct way to store data of unknown encoding i.e. everything on the web\nvar Encoding = require('encoding-japanese');\nrequire('wreck').get('http://i1.theportalwiki.net/img/6/6b/Portal2_japanese.txt', function(err, res, payload) { console.log('correct conversion; correct output', Encoding.convert(payload, { from: 'UTF16', to: 'UNICODE', type: 'string' })); });\nrequire('wreck').get('http://i1.theportalwiki.net/img/6/6b/Portal2_japanese.txt', function(err, res, payload) { console.log('equiv to what superagent does; incorrect output', payload.toString('utf8')); });\nThere is no reason to setEncoding on the response stream.  You can just concat buffers (as image parser does) and then call toString('utf8') on the resulting buffer if that's what you really want to do.  \nAnd FWIW JSON.parse works on Buffers:\njavascript\nvar buf = new Buffer('{\"blah\":\"i am a buffer\"}')\nJSON.parse(buf);\n. Yes, you're correct.  And I can't come up with a way to retrieve that page using superagent and get correct output.  any ideas?\nany chance this behavior could get a mention in the docs?\n. ",
    "jitchavan": "i am closing this issue as i got the solution.\njust add any parameter to object as normal property.\nfiles.forEach((file)=> {\nvar req = request.post(ajax_url);\nreq.attach('file', file);\n//adding property to object\nreq.filename= value;//any value you want to add\nreq.on('progress', function(e) {\nconsole.log('Percentage done: ', e.percent);\nconsole.log(e);\n//get the property value\nconsole.log(this.filename); //this object holds the property\n});\nreq.end(this.callback);\n}); \n. ",
    "adambro": "I've got simialar error with 1.8-beta.1 version when using webpack. After downgrade to 1.7.2 everything works. The error was:\nERROR in ./~/mime-db/db.json\nModule parse failed: /home/adam/www/openfootball/node_modules/mime-db/db.json Line 2: Unexpected token :\nYou may need an appropriate loader to handle this file type.\n| {\n|   \"application/1d-interleaved-parityfec\": {\n|     \"source\": \"iana\"\n|   },\n @ ./~/mime-db/index.js 13:17-37\nThat was after adding \"json-loader\": \"0.5.4\" dependency.\n. Thanks @pornel for the fix!\n. ",
    "vicanso": "fixed\n. request.parse, the code path lib/node/parsers\n. You can use like this:\n``` js\nvar unauthorizedRedirect = function(req) {\n  req.on('response', function (res) {\n    if (res.status === 401) {\n      console.dir('redirects')\n      // redirect to login\n    }\n  });\n};\nrequest\n  .get('/some/end/point')\n  .use(unauthorizedRedirect)\n  .end(function(err, res) {\n    // do something with res.body\n  });\n```\n. @allces \njs\nfunction authorizedGet(url) {\n    return request.get(url)\n        .use(unauthorizedRedirect);\n}\n. @littlee \nuse method is used in superagent Plugins. I learnt response event from source code, so response event may be changed without notice.\n. http://visionmedia.github.io/superagent/#aborting-requests\nYou may read the api first.\n. I am sorry. I made a mistake.\n``` js\nfunction stats(req) {\n  req.once('request', function(){\n    // ajaxstart\n    req._startedAt = Date.now();\n  });\n  req.once('error', function(){\n    // an error\uff0cthe request fail\n  });\n  req.once('end', function(){\n    // ajaxstop\n    var use = Date.now() - req._startedAt;\n  });\n}\nfunction get(url) {\n  return request.get(url)\n    .use(stats);\n}\nRequest.prototype._end = Request.prototype.end;\nRequest.prototype.end = function(fn) {\n  this.emit('request');\n  this._end(fn);\n}\n``\n. @focusaurus I have changedquerySorttosortQuery`\n. ",
    "GBeauny": "Thanks a lot, but yes it's not good to do it.\n. ",
    "lgreenlee": "I have this problem as well. I really like your library but it is unusable without this option. I have an environment where the hosts are trusted but I need confidentiality for their communications. The lack of this option prevents me from securing my environment at all. I also think that you don't really need to worry about screening the options. Anyone looking to set TLS options probably has some idea of what they are up to. These options are also well documented for Node.js. As Patrick Bruel once said, \"Let the people do what they want\"! So I'd rather see the .tls style implemented. #681 #926 \n. My comments here are limited to securing service to service communication on a \"quasi-private\" e.g. Cloud network or Corporate network. External User to System communications should avail themselves of the full set of features of the CA infrastructure.\nThe underlying issue is that we use certificates to provide confidentiality and identity. These actually need to be two distinct mechanisms which they are not always today. In my opinion, ensuring confidentiality is the most important aspect of securing endpoints followed by establishing identity. There are also a range of methods for identity management that go beyond the features embedded in the certificate and the CA system.\nI'd also suggest that the identity management aspect of certificates for any important application is basically a failure. See the Lenovo superfish example (arstechnica.com) (which is basically a man in the middle attack) and  Google for example (google.com).\nFundamentally, the use of rejectUnauthorized does not compromise the channel's ability to provide confidential communication. It does defeat the identity management aspects of the certificate infrastructure and in some scenarios this is perfectly fine.\nEasy RSA (github.com) is an easy way to setup a CA that can be used in a number of different environments.\n. Thank you for your input. PKI is still evolving and is not perfect, but it is hardly \"rubbish\".\nWhat you describe in 1. is very difficult in practice to execute. Unless you are doing something of great value it is basically a thought exercise.\nThe amount of time wasted during development due to certificate errors is non-trivial and the ability to ensure that SSL works is pretty important. Most important though is that we don't waste our time on tasks that are unimportant at a given time e.g. having a DNS server, CA and well configured network just to test a simple SSL based service on localhost.\nIf what you say is true, then everyone should make sure that all of the SSH keys they use are issued by a CA too! I mean, we wouldn't want to make any irresponsible and insecure connections to our servers!\n. Good Sir, \nLet us reflect on what has just transpired. I provided my support for a feature request but instead received an (unwanted) lecture on MITM attacks and an accusation that I might act \"irresponsibly\" by using an option that is available in many Linux utilities and applications that deal with SSL based connections. Perhaps openssl, openssh, git, curl svn, firefox and chrome are all \"irresponsible\" as well for allowing their users to actually get what they need done.\nI tried to take the time to explain that there are scenarios where this is OK, however your previous comment would indicate that you did not completely grok my comments. I appreciate that you'd like to better understand my use case, but it is frankly none of your business.\nI just need the feature added. Apparently others do as well since they have taken the time to prepare PR's. These PR's, most especially the .tls implementation is the most flexible and would be just what the doctor ordered.\nWe are your users - your work is popular because you have users but being belligerent and treating them as if they have no clue what they are doing is a good way to alienate them.\n. ",
    "wubzz": "Got caught offguard on this after first having rewritten ~900 tests to use superagent instead of restler. Honestly baffled how such a simple configuration is being blocked due to a fear of being blamed of something that would obviously be the endusers fault.\nWithout taking your argument out of context, I would say it is the same as saying a database client library should not allow DELETE queries because the lib collaborators could be blamed for accidental DELETE queries.\nI don't mean to sound disrespectful or to necro this old issue, just need to get my dissapointment out there... git reset --hard we go!. ",
    "Sakaza": "To use the tank analogy mentioned earlier ...\nThe rejection of this pull request is like manufacturing tanks without hatches, due to the hatch being seen as a security risk. Sometimes, someone needs to get in or out of the tank, man!. ",
    "jamiesonbecker": "One valid use-case where you might want to ignore invalid certs is in spidering or scraping. There are more, of course, but that's a particularly big one. It seems like Superagent would probably be a good tool to use for that.. ",
    "MieszkoGulinski": "Would be useful for me too - for requests in internal network not having control over other servers' certificates.. ",
    "mstn": "I do not agree with your conclusions and this issue should be reopened imo. My reference is this https://tools.ietf.org/html/rfc2616#section-10.3.3.\nRFC addresses two distinct problems:\n- automatic redirect when 302 is received;\n- change from GET to POST on second request.\nAs far I understood, as a response to POST requests, 302 says that \n- the user agent MUST NOT automatically redirect the request unless it can be confirmed by the user;\n- but it is up to the user agent to decide to perform a GET instead of the original POST the second time;\n- if you do not like this ambiguity, please return 303 or 307 instead.\nHence, superagent must not redirect automatically, but, if redirect is confirmed by the user, it can resend the request using GET instead of POST.\nEDIT\nApparently it depends on XHR implementation/specification. One of the reasons why ajax sucks. :-P\n. ",
    "kasbah": "Though the function is now there on .post() it still doesn't seem possible to stop redirect with .redirects(0). Is that intended?\nEDIT: Sorry, I just realised it's probably not possible to stop redirects within the browser version. . ",
    "catamphetamine": "I confirm that this has been fixed and is working for file upload in Chrome. @fisch0920 So, does browser file upload progress work?\nIt's surely supported in all browsers, and has been around for a long time.. Ok, I found a workaround for the issue.\nOn a client:\njs\nvar request = require('superagent')\nrequest.parse['application/json'] = text => JSON.parse(text, JSON.date_parser)\nOn a server:\njs\nvar request = require('superagent')\nrequest.parse['application/json'] = function parseJSON(res, fn){\n  res.text = '';\n  res.setEncoding('utf8');\n  res.on('data', function(chunk){ res.text += chunk;});\n  res.on('end', function(){\n    try {\n      var body = res.text && JSON.parse(res.text, JSON.date_parser);\n    } catch (e) {\n      var err = e;\n      // issue #675: return the raw response if the response parsing fails\n      err.rawResponse = res.text || null;\n      // issue #876: return the http status code if the response parsing fails\n      err.statusCode = res.statusCode;\n    } finally {\n      fn(err, body);\n    }\n  });\n};\nJSON.date_parser:\njs\nif (!JSON.date_parser)\n{\n    var ISO = /^(\\d{4})-(\\d{2})-(\\d{2})T(\\d{2}):(\\d{2}):(\\d{2}(?:\\.\\d*))(?:Z|(\\+|-)([\\d|:]*))?$/;\n    JSON.date_parser = function(key, value)\n    {\n        if (typeof value === 'string' && ISO.test(value))\n        {\n            return new Date(value)\n        }\n        return value\n    }\n}\n. ",
    "jisaacks": "@pornel sure, I put one together. I had an issue with adding tests though, take a look and let me know if you need it adjusted.\n. > browser tests locally with make test-browser-local\n@pornel that worked thanks.\nFor the tests, I needed a way to check that the name was being sent correctly in the request. The only thing I was able to get back though was a content disposition string.\nI tried parsing that string with this library but was unsuccessful.\nI was able to get it to work with a simple regex though. previously the string would have contained filename=\"undefined\" and now it contains filename=\"image.jpg\" (the actual file name.) I don't have a ton of time to throw at this though but I think this is Good Enough\u2122.\nPlease let me know.\n. Hmmm IE11 seems to be failing at this line in the test.\n. OK So it seems IE11 doe snot support the File constructor which would explain the failure on that line.\nI am not aware of a good workaround. Any ideas?\n. @pornel cool. I skipped the test if File cannot be used as a constructor. Note, I could not just check for the existence of File as in some cases it will exist but not be allowed to be used as a constructor resulting in an error of:\n\nError: FileConstructor is not a constructor \n\nLet me know if there is anything else.\n. ",
    "tquetano-r7": "Apologies again, I have no easy way to produce a test for this locally as I don't have saucelabs credentials and therefore cannot do the BROWSER=1 test. Based on another client test, I modified to see if this would work. I promise I have tested it in the real world ...\n. @pornel Thanks, that is some badassery. I ran that locally and all my tests passed, and I know my travis build failed but I don't think it was due to my test.\n. Ah sweet, noticed the browser test was kicked off again and passed, I assume that was you. :)\n. Going about it in the way you recommended appears to solve my issue. Thanks!\n. ",
    "heategn": "Closing due to the build error. I'll open an issue for this and investigate the build error when I get the chance.\n. ",
    "aniss": "Same issue here.\n. ",
    "littlee": "dang it, my fault\n. thanks for replying,\nBut I got an question:\nhow do you know there is a 'response' event on req\nand there is a use method?\nseems they do not exist on the doc :pig: \n. great, learning from source code. :+1: \n. Seems I did not make myself clear.\nthe link you show me is just a sentence.\n\nwhat can this .abort method do with ajaxStar/Stop?\n\nYou may read the api first.\n\nafter read all the api, I still can not find any api I can use to implement my goal. :cry: \ncan you look this question in stackoverflow?\nhttp://stackoverflow.com/questions/33219794/superagent-equivalent-of-jquerys-ajaxstart-ajaxstop\nthe question author is faced with the same problem with me.\n. wow~\n. ",
    "PMByrne": "Was alpha 3 suppose to be marked as latest in npm @pornel ?\nWas a bit surprised when npm i superagent grabbed an alpha release this morning\n. ",
    "Spy-Seth": "I use the alpha from some time now, and no issue on my side. \n:+1: for release.\n. ",
    "fanjunzhi": "still need add repeat code(use....) in every request\n. .on('abort', (err) => {\n                console.log('error');\n            })\nis work, thanks.\nbut err is undefined\n. distinguish abort type. (timeout or unknown reason)\n. ",
    "didxga": "@littlee since you want to avoid repetitive code, here you go:\n1. Define this somewhere in a module file\nimport superagent from \"superagent\";\nexport const request = superagent.agent()\n    .use(function(req) {\n        req.on('response', function (res) {\n            if (res.status === 401) {\n                console.dir('redirects')\n            }\n        });\n    });\n2, import from this module to use the request,  instead of importing from superagent\nimport {request} from '../your/local/module';\nrequest.get('/some/end/point')\n           .end(function(err, res) {\n              // do something with res.body\n           });. ",
    "yourcontainer": "+1\n. ",
    "sheltonial": "+1\n. Actually.. I think it needs a little more work. There's pipe function which also attempts to unzip.\n. ",
    "seangarner": "I doubt this is the cause, but just in case....\nA number of conditionals aren't triggered if instantiating the Request class directly with a lowercase method.  See visionmedia/supertest/pull/371 for an example of how superagent is doing just this and ending up with the same zlib error as in this issue.\n@pornel I'm not sure if you'd consider this a superagent bug or not.  Personally I think it is because the  Request class is exported and documented yet methods are only uppercased when calling the function.  If you agree I can open a PR for that.\n. ",
    "vcanales": "What @pornel suggests would be ideal, I think. I ran into this problem by not reading deep enough into the docs and I'm convinced that I can't be the only one.\nBut at least reporting the proper error would be enough. In my case what happened and what made it so hard to find the error was that the message I was receiving was related to the size of the payload, since the PNG was being interpreted as JSON data by nginx, thus exceeding the max body size.\n. Also closes #859. ",
    "joepie91": "To clarify - the message that @devjunkORG was seeing was being sent by either NGINX or their body-parsing middleware, and not by superagent.\n@pornel That seems like a better solution. I was assuming that the split between field and send was intentional for some reason, hence suggesting the error approach.\n. ",
    "cmordue": "We've run into the same issue.\n. ",
    "mrsharpoblunto": "I've posted a pull request which fixes the issue - but for now a workaround is to require() superagent before express. The problem occurs in express because the methods list changes between the time the handler functions are created and then enumerated over - if superagent is required before express, the del method is on the list the whole time and there is no mismatch between the list of handler functions created and the list to enumerate over\n. Looks like this should fix https://github.com/visionmedia/superagent/issues/862\n. ",
    "cappslock": "Good point... I was a little off on my understanding of best practices, anyways.\nWhat about using the name property instead? This seems to be a pretty standard way of doing things, it's what Joyent recommends in their guide: https://www.joyent.com/developers/node/design/errors\n. Absolutely. Would you welcome a pull request for this functionality?\n. ",
    "lancedikson": "Run into this bug. Waiting for a new version ASAP. Thank you :+1: \n. ",
    "plonko": "@bonesoul Hey I'm doing a similar thing, what did you go with in the end? ty. ",
    "anomaly44": "Devtools:\n```\n1st:\n[{\"id\":3,\"tree_item_id\":24,\"name\":\"Vaste airconditioning start niet\",\"description\":\"Start niet\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"appliance\"},{\"id\":4,\"tree_item_id\":24,\"name\":\"Vaste airconditioning lekt\",\"description\":\"Lekt\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"appliance\"},{\"id\":5,\"tree_item_id\":24,\"name\":\"Vaste airconditioning maakt vreemd geluid\",\"description\":\"Maakt vreemd geluid\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"tiles\"},{\"id\":6,\"tree_item_id\":24,\"name\":\"Vaste airconditioning\",\"description\":\"Andere\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"standard\"}]\n2nd: \n\"[{\\\"id\\\":11,\\\"tree_item_id\\\":26,\\\"name\\\":\\\"Raamairconditioning start niet\\\",\\\"description\\\":\\\"Start niet\\\",\\\"message_title\\\":\\\"\\\",\\\"message\\\":\\\"\\\",\\\"form_type\\\":\\\"appliance\\\"},{\\\"id\\\":12,\\\"tree_item_id\\\":26,\\\"name\\\":\\\"Raamairconditioning lekt\\\",\\\"description\\\":\\\"Lekt\\\",\\\"message_title\\\":\\\"\\\",\\\"message\\\":\\\"\\\",\\\"form_type\\\":\\\"appliance\\\"},{\\\"id\\\":13,\\\"tree_item_id\\\":26,\\\"name\\\":\\\"Raamairconditioning maakt vreemd geluid\\\",\\\"description\\\":\\\"Maakt vreemd geluid\\\",\\\"message_title\\\":\\\"\\\",\\\"message\\\":\\\"\\\",\\\"form_type\\\":\\\"appliance\\\"},{\\\"id\\\":14,\\\"tree_item_id\\\":26,\\\"name\\\":\\\"Raamairconditioning\\\",\\\"description\\\":\\\"Andere\\\",\\\"message_title\\\":\\\"\\\",\\\"message\\\":\\\"\\\",\\\"form_type\\\":\\\"standard\\\"}]\"\n```\ncurl:\n```\ncurl --verbose http://localhost:3000/api/report/loadProblems/24\n Hostname was NOT found in DNS cache\n   Trying 127.0.0.1...\n* Connected to localhost (127.0.0.1) port 3000 (#0)\n\nGET /api/report/loadProblems/24 HTTP/1.1\nUser-Agent: curl/7.35.0\nHost: localhost:3000\nAccept: /\n< HTTP/1.1 200 OK\n< x-powered-by: Express\n< Content-Type: application/json; charset=utf-8\n< Content-Length: 595\n< etag: W/\"253-IsqWIlD9wlD+UtcTb1aUow\"\n< date: Fri, 22 Jan 2016 15:47:11 GMT\n< connection: close\n< Vary: Accept-Encoding\n< \n* Closing connection 0\n[{\"id\":3,\"tree_item_id\":24,\"name\":\"Vaste airconditioning start niet\",\"description\":\"Start niet\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"appliance\"},{\"id\":4,\"tree_item_id\":24,\"name\":\"Vaste airconditioning lekt\",\"description\":\"Lekt\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"appliance\"},{\"id\":5,\"tree_item_id\":24,\"name\":\"Vaste airconditioning maakt vreemd geluid\",\"description\":\"Maakt vreemd geluid\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"tiles\"},{\"id\":6,\"tree_item_id\":24,\"name\":\"Vaste airconditioning\",\"description\":\"Andere\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"standard\"}]\n\ncurl --verbose http://localhost:3000/api/report/loadProblems/26\n Hostname was NOT found in DNS cache\n   Trying 127.0.0.1...\n* Connected to localhost (127.0.0.1) port 3000 (#0)\n\nGET /api/report/loadProblems/26 HTTP/1.1\nUser-Agent: curl/7.35.0\nHost: localhost:3000\nAccept: /\n< HTTP/1.1 200 OK\n< x-powered-by: Express\n< Content-Type: application/json; charset=utf-8\n< Content-Length: 595\n< etag: W/\"253-FC+pM2d7gqB1E9t5NwGepQ\"\n< date: Fri, 22 Jan 2016 15:44:55 GMT\n< connection: close\n< Vary: Accept-Encoding\n< \n* Closing connection 0\n[{\"id\":11,\"tree_item_id\":26,\"name\":\"Raamairconditioning start niet\",\"description\":\"Start niet\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"appliance\"},{\"id\":12,\"tree_item_id\":26,\"name\":\"Raamairconditioning lekt\",\"description\":\"Lekt\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"appliance\"},{\"id\":13,\"tree_item_id\":26,\"name\":\"Raamairconditioning maakt vreemd geluid\",\"description\":\"Maakt vreemd geluid\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"appliance\"},{\"id\":14,\"tree_item_id\":26,\"name\":\"Raamairconditioning\",\"description\":\"Andere\",\"message_title\":\"\",\"message\":\"\",\"form_type\":\"standard\"}]\n```\n. Ok, so after some further testing, it does not happen in firefox, only in chrome. Am on linux, so I can't really check other browsers. Does that help ?\n\nedit it gets better, when inspecting the response that fails in chrome, in firefox, it says: SyntaxError: JSON.parse: unexpected end of data at line 1 column 1 of the JSON data.\neven though it gets parsed in firefox ... \n. ",
    "fabien": "I've ran into an issue this week and I suspect this PR to be at the cause of it. When running the following code, I consistently get a 401 error from a third-party API that used to work fine:\nvar req = request.get(url);\nreq.set('Content-Type', 'application/json');\nreq.set('Accept', 'application/json');\nreq.set('Authorization', 'Bearer ' + key);\nreq.send(data);\nreq.end(function(err, res) {\n    console.log(res.body);\n});\nThe issue started appearing with ^1.7.2 for me, so for now I downgraded to a fixed 1.7.1 dependency.\nSince I have no control over the remote API, I cannot provide any details regarding the wellformedness of the request or particular issues. The problem seems subtle enough to stay under the radar for most SuperAgent users, so I'm curious if others have ever experienced something like this.\n. @pornel apparently 1.7.2 is the latest version I tried, and it had issues. For now, it appears that 1.8.0-beta.2 works fine though! I will have to check more thoroughly.\n. ",
    "leipert": "@pornel Even with credentials travis fails :+1:\nI ran the exact tests locally with node 5.4 and npm 3.3.12 and they did not fail.\n. Thanks :+1: \n. Sorry. Stardog did handle Header fields not correctly\n. ",
    "efegurkan": "Is this still happening, I couldn't reproduce it locally on master. Maybe it fixed since the issue opened?\n. ",
    "brickyang": "@pornel Sorry I just come back from London to Beijing so I haven't tested it yet. Will report after my test. Thanks\n. ",
    "timneutkens": "This middleware might help you:\nhttps://github.com/magicdawn/superagent-charset\n. ",
    "shaunc": "I'm receiving an xlsx spreadsheet which I want to pass as a buffer to js-xlsx. The following works in parse:\n(NB wrapped in new Promise((resolve)=>...rest of request...) )\n.parse((res)=>{\n  let buffer = [];\n  res.on('data', (chunk)=>{\n    buffer.push(chunk);\n  });\n  res.on('end', ()=>\n    resolve(Buffer.concat(buffer)));\n  });\n\n. Nice @pornel ... I thought that superagent.parse.image must have something to do with images... :). ",
    "yunda": "This pull-request supposed to fix #675\n. @pornel The idea is to return a response even if it fails to parse body. Otherwise we cannot read status codes or any other necessary information form the response object.\n. ",
    "Risto-Stevcev": "@pornel I use superagent to test my API, and so I think it's pretty normal to add a test to check that if a resource is moved that my server will send a 301. \nThe validation check request is sent by modern browsers automatically (using If-Match and/or If-Modified-Since headers), but the server is supposed to correctly respond with 304 if the resource isn't modified, and I'm using superagent to test my API. But I agree with you about 500 though, it might not be common enough.\n. ",
    "kenichi-shibata": "Can you teach me how to use MOVE method? with basic auth 'user' 'pass'\nSince this is not documented\nThank you!\n. curl --user 'user:pass' -X MOVE --header 'Destination: http://127.0.0.1:4502/content/1' http://127.0.0.1:4502/content/dam/ --verbose\n. Works like magic thanks! @focusaurus \n. Sorry to reopen this but I think it would be helpful to add a documentation for web dav as well. \nAlso how do we send delete request using webdav? (not to be confused by del)\n. ",
    "gonzazoid": "\nCan Firefox extensions solve that problem by setting global XHR before including superagent?\n\nI've tried import XMLHttpRequest by using Components.utils.importGlobalProperties but this did't solve problem. I'll prepare gist reproducing error (it will take some time)\n. Hi, guys!\nI feel so ashamed!\nAs I said earlier - Components.utils.importGlobalProperties does not work properly and it is not possible to import XMLHttpRequest into global scope. This is not true. importGlobalProperties works as expected, the problem is that we do not have variable windows into backround process in firefox extension. This variable is used when checking and not found. This code solves the problem (maybe it will help someone):\n``` javascript\nif(typeof window === \"undefined\"){\nvar viewFor = require(\"sdk/view/core\").viewFor;\nvar window = viewFor(require(\"sdk/windows\").browserWindows[0]);\n\nlet {Cu} = require(\"chrome\");\nCu.importGlobalProperties([\"XMLHttpRequest\"]);\nwindow.XMLHttpRequest = XMLHttpRequest;\n\n}\n// we can call superagent here\n```\ntopic can be closed (I'm so sorry I wasted your time)\n. ",
    "marcbachmann": "That was most likely an npm issue. It works again.\n. ",
    "pyoner": "If we use native xhr a chrome browser send username and passwor in url (http://username:password@localhost/) not in HTTP header\nI don't know how in Express js get username and password from url to fix test\n. Added basic auth to server side test\n. Yes, you correctly understand\n. I have better solution:\nreq.auth(user, pass, options)\nwhere options is true or object\nif no options the library use basic auth (a default behavior)\nif options is true then the library use native auth\nif options is object then look at options.type\noptions.type maybe basic or auto or digest (or other auth type need implement)\nauto means native auth by browser (but I don't know how to implement this on node side, may be we can copy behavior from the browser)\nWhat do you think about it?\n. Done!\nPlease check!\n. ",
    "iambumblehead": "@pornel Are you suggesting blob and buffer specific set methods? I'll push a different update to this branch which does not use the set('Content-Type', 'blob').\n. for reference here is mdn arraybuffer and blob --i think these are the only two which need to be handled.\n@pornel what would you think of this set('responseType', 'blob') // blob|arraybuffer?\nor maybe setResponseType('blob')?\n. It looks like there is a conflict that must be resolved but with the changes I made in the last few minutes, I'm able to make a successful request with this\njavascript\nrequest\n  .get('http://d8d913s460fub.cloudfront.net/videoserver/cat-test-video-320x240.mp4')\n  .setResponseType('blob')\n  .end(function (err, res) {\n    console.log(err, res);\n  });\n. I have run $ make test-browser-local as well as $ make test --I have 0 failing tests locally and do not understand why the CI build fails. @pornel could you tell me what I'm doing wrong?\n. @focusaurus per your request setResponseType is changed to responseType\njavascript\nrequest\n  .get('http://d8d913s460fub.cloudfront.net/videoserver/cat-test-video-320x240.mp4')\n  .responseType('blob')\n  .end(function (err, res) {\n    console.log(err, res);\n  });\n. It looks like there may be a problem with the way I rebased. lib/node/index.js is not a file I modified and I do not see the change which appears here in the master branch.\n. finally!\n. This change breaks superagent for me\nI'm not using this form-data object --simply commenting out this line from lib/request-base.js makes everything work again,\n//var FormData = require('form-data'); // browserify compatible\n. I'm using this tool I wrote https://github.com/iambumblehead/scroungejs\nIf 'form-data' defined a browser index exporting window.FormData this would work. Maybe I should update my build tool. It looks like I need to update my build tool. \n. Thanks for pointing this out. This condition exists somewhat inadvertently as it prevents cycle-http-driver (which I am using) from using a default \"json\" Content-Type when responseType is defined. I'll remove the condition before committing again.\nhttps://github.com/cyclejs/cycle-http-driver/blob/master/src/http-driver.js#L16\n. ",
    "rohanprasad": "@pornel @iambumblehead Is this issue resolved? If yes, in which version can I use responseType?\n. ",
    "jomaxx": "thanks @focusaurus \n. ",
    "acolchado": "Setting .accept('application/json') usually does the job for me.\n. @willin .accept('application/json') usually forces them to respond in the type that you are looking for.\n. ",
    "willin": "@focusaurus \nyes, then how to fix this\n. @acolchado \n``` js\nlet request = require('superagent');\nrequest.get('https://api.dreamhost.com/')\n  .accept('application/json')\n  .query({key: '6SHU5P2HLDAYECUM', cmd: 'user-list_users_no_pw', format: 'json'})\n  .end(function (err, res) {\n    if (err || !res.ok) {\n      console.log(err);\n    }\n    console.log(res.text);\n    console.log(res.body);\n  });\n```\ntried, but no use. the content type is always application/javascript\nundefined\n{}\n. server side i use superagent to request remote api. timeout 5s\nclient(browser) side i use superagent to request local api \u2b06\ufe0f. timeout 10s\nclient side exceed timeout several times, and i have no idea about why it goes like this.\n. ",
    "zxyah": "will add the feature?\n. Thanks, I Have Solve The Problem By Other Way, Not Get The base64 Of Image\n. ",
    "p4bloch": "Actually my version constraint was in latest. Specifying superagent@1.7.2 solved this.\n. ",
    "qingemeng": "Is it fixed in the latest version? It still happens in 3.0.0. ",
    "sinkcup": "maybe you need this:\nhttps://coderwall.com/p/l_7acq/publish-beta-versions-of-npm-modules\n. ",
    "jifeon": "ok thx\n. :+1: \n. ",
    "ewnd9": "Is it possible to access a response body in the catch method (e.g. server is responding with a 500 status code, but an error reason is in a body)? \n. ",
    "rkostrab": "Can you give me any hint how to implement that? I may make PR.\n. ",
    "denishowe": "Temporary hack:\nprocess.env['NODE_TLS_REJECT_UNAUTHORIZED'] = 0;\n. Pornel, please (re)read Kris's comment.. ",
    "krisdahl": "This is silly.  We're forced to choosing between completely disabling certificate authentication across the entire node process, or not using SSL at all.\nIt should be allowed to be disabled on a per-request basis, just like you could do on any other browser, http utility or request library (Firefox, Chrome, curl, wget, IE, etc.)\nNot everyone can create their own CA, or has control of the server (which may be totally internal even, and on a trusted network).\nWe all understand the risks of a MITM attack, but it isn't always that big of a deal.  After-all, superagent will work with HTTP requests as well as HTTPS, right?  By the logic of rejecting all self-signed certificates, should't superagent also just reject any non HTTPS requests as well?\n. ",
    "andineck": "I don't get it. node's own https.request has got the option to allow rejectUnauthorized. curl has --insecure and other tools have their option to disable the ssl check per request.\n\nThere are 7 issues regarding this: https://github.com/visionmedia/superagent/search?q=rejectUnauthorized&type=Issues&utf8=%E2%9C%93\nAn three PR's have been closed ...\n\nI really don't think that the world becomes a safer place with rejecting the need to reject unauthorized ssl certificates.. ",
    "julien-f": "@pornel I understand your point very well, but unfortunately I do not control my clients environment in which my code is executed.\nSo my choices currently are:\n\nuse another library instead of superagent (probably what I'm going to do)\ndisabling completely certificate validation \ud83d\ude16 \n\nWhat I want is to allow my clients to explicitly disable certificate validation if they need to and understand the risks.. @pornel indeed I want to promote proper use of HTTPS, but I have to support the self-signed certificates of my clients (adding the CA for all servers is not an option either) \ud83d\ude15 . And where is the data if I set .buffer(false)?. ",
    "stefanotorresi": "@pornel are you open to reconsider this? Every http client that I know of has a way to disable SSL verification on a per-request basis, which is a completely valid use case for self-signed certificates, and the existence of LetsEncrypt doesn't mean that these should no longer exist.\nI wanted to use SuperAgent in a CI setup for e2e tests, and using actual SSL certificates doesn't even make sense in such an environment.\nIMHO you're not making anything more secure with your decision, because we're not talking about defaults here.\nYou're enforcing an arbitrary limitation that makes this library unusable in development and testing environments.. Using the host field or unspecific environment variables (like a generic and arbitrary development mode) to change the behaviour of the client is far from what I'd expect as a consumer, and I'd strongly advise against it anyway because this line of thought involves dangerous assumptions and is a slippery slope.\nIf I were to choose, I'd apply the so called principle of least astonishment and just follow the common practice among HTTP clients in the wild.\nNode options have already been pointed out, so here are a few examples from other ecosystems:\n\ncURL exposes -k/--insecure flag in the CLI and CURLOPT_SSL_VERIFYPEER in the programmatic api. [[1]]\nWget exposes --no-check-certificate flag in the CLI. [[2]]\nlibwww-perl exposes verify_hostname in the programmatic api. [[3]]\nssl.py module exposes SSLContext.verify_mode in the programmatic api. [[4]] [[5]]\nGuzzle exposes verify in the programmatic api. [[6]]\nnet/http exposes verify_mode in the programmatic api. [[7]]\ncrypto/tls exposes Config.InsecureSkipVerify in the programmatic api. [[8]]\nhttpie exposes --verify flag in the CLI. [[9]]\n\nI could continue and list every major programming language and every major HTTP tool ever made, to be honest; my point is that this is not an isolated opinion of few, it's the industry de-facto standard.\nTo be completely frank, I find a bit naive to think that providing an opt-in insecure mode is a bad practice.\nIt's not; providing insecure defaults is.\nIMHO any other approach would result to be unexpected at best, and totally wonky at worst.\nJust my 2 cents, though.\n[[1]]: https://curl.haxx.se/docs/sslcerts.html\n[[2]]: https://www.gnu.org/software/wget/manual/html_node/HTTPS-_0028SSL_002fTLS_0029-Options.html#HTTPS-_0028SSL_002fTLS_0029-Options\n[[3]]: https://github.com/libwww-perl/libwww-perl#ssl_opts\n[[4]]: https://docs.python.org/3/library/ssl.html#ssl.SSLContext.verify_mode\n[[5]]: https://docs.python.org/2/library/ssl.html#ssl.SSLContext.verify_mode\n[[6]]: http://docs.guzzlephp.org/en/stable/request-options.html#verify\n[[7]]: http://ruby-doc.org/stdlib-2.4.2/libdoc/net/http/rdoc/Net/HTTP.html#verify_mode-attribute-method\n[[8]]: https://golang.org/pkg/crypto/tls/#Config.InsecureSkipVerify\n[[9]]: https://httpie.org/doc#server-ssl-certificate-verification. By all means, using a custom Certificate Authority key pair can be a way to verify only a subset of certificates, even self signed ones, and as you can see from the examples above, this is something that goes very well along with the ability to turn verification off entirely.\nBut hey, I still don't agree with your \"it's a footgun\" argument. Everything can be a footgun, even forgetting debugging enabled can become problem, but that's not a reason to make it a PITA to enable.\nIn fact, I'd argue that a well designed API should rather not expose a function, rather than make it very inconvenient just to protect people from their own mistakes. Safe defaults, that's all I'd expect, and I also expect people to know what their doing when they turn safeties off.\nThen again, it's your library, so I'll leave you at that. ;). ",
    "pimterry": "\nHow about pinning specific certificate(s)?\n\nThis is notably similar to Chrome's approach: https://codereview.webrtc.org/2753123002/.\nThey recently added an ignore-certificate-errors-spki-list flag, which lets you specify specific certificates that should not be validated, as part of moving towards removing their current ignore-certificate-errors option entirely. ",
    "fergadipa": "So...\nIs there any options to skip/ignore/ ssl certificates? . ",
    "gwely": "I'm having this issue with superagent (v1.8.3) and supertest (v1.2.0).\nHere is my request code:\n```\nvar api = supertest(config.get('baseUrl'));\n// var api = require('superagent');\napi.post('/api/token')\n    .set('Accept', 'application/json')\n    .type('form')\n    .send(loginData)\n    .expect('Content-Type', /json/)\n    .expect(200)\n    .end(function (postErr, postResponse) {\n        if (postErr) {\n            console.log(postErr);\n            return done(postErr);\n        }\n    access_token = postResponse.body.access_token;\n    token = 'Bearer ' + access_token;\n\n    api.get('/swagger/docs/v1')\n    // with superagent - api.get(config.get('baseUrl') + '/swagger/docs/v1')\n        .set({\n            'accept': 'application/json;charset=utf-8,*/*',\n            'Accept-Encoding': 'gzip,deflate,sdch',\n            'Accept-Language': 'en-US,en;q=0.8',\n            'Authorization': token\n        })\n        .end(function (getErr, getResponse) {\n            if (getErr) {\n                console.log(getErr);\n                return done(getErr);\n            }\n\n            var filename = path.resolve(__dirname, 'schema', 'v1.json');\n            jsonfile.writeFile(filename, getResponse.body, function (writeError) {\n                if (writeError) {\n                    console.log(writeError);\n                    return done(writeError);\n                }\n\n                done();\n            });\n\n        });\n});\n\n```\nI've tried the get request without any headers set other than Authorization and various combinations of what's above.\nI get the same error:\n{ [Error: incorrect header check] errno: -3, code: 'Z_DATA_ERROR', response: null }\nError: incorrect header check\n  at Zlib._handle.onerror (zlib.js:363:17)\nThe same request works perfectly fine in postman\n\n. Also works fine with request\n```\nvar options = {\n    url: config.get('baseUrl') + '/swagger/docs/v1',\n    headers : {\n        'Authorization': token\n    }\n};\nrequest(options, function (getErr, getResponse, body) {\n    if (getErr) {\n        console.log(getErr);\n        done(getErr);\n    }\nconsole.log(JSON.parse(body).info.version); // v1\ndone();\n\n});\n```\n. The request body is empty.\nI got the following HTTP headers from the response from a successful request via Postman. \nCache-Control \u2192private\nContent-Encoding \u2192deflate\nContent-Length \u219215544\nContent-Type \u2192application/json; charset=utf-8\nDate \u2192Tue, 03 May 2016 14:04:54 GMT\nServer \u2192Microsoft-IIS/7.5\nX-AspNet-Version \u21924.0.30319\nX-Powered-By \u2192ASP.NET\n. Oh sorry the request body is empty. The response body is quite large and also something I can't really post publicly. Is there something I can check for you?\n. ",
    "lcgg110": "superagent.get('http://www.test.com').set('Accept-Encoding','gzip, deflate').end(callback())\nthis test case is not support\nerror:\nincorrect header check\nError: incorrect header check\n    at Zlib._handle.onerror (zlib.js:366:17)\n. ",
    "futpib": "In case anybody is looking for a workaround:\njs\n    const res = await agent\n        .get(url)\n        .set('Accept-Encoding', 'identity'). ",
    "DavidTPate": "Thanks for the workaround @futpib that definitely addresses the issue.\nAlso, you can change the encoding to something that superagent can handle such as gzip instead of identity as well.. ",
    "rafaelugolini": ":+1: \n. @focusaurus I also use OPTIONS method to fetch data schema. The forms of the application I'm working on are generated through calls using the OPTIONS method.\n. ",
    "greensk": "\nCould you grab the tests I added from this commit on my fork and rebase your PR including the test code?\n\n@focusaurus, done.\n\nI'd be curious to hear your specific use case and motivation for adding this feature\n\nOPTIONS queries are used to fetch data schema from REST API. Sorry, I am not able to show you my code example, it is proprietary.\n. ",
    "OmgImAlexis": "This really should have changes to the docs included in the PR.. Supertest but I get the same result with superagent so I'm assuming it's an underlying issues with superagent that's just showing because of the dependancy.. ",
    "airportyh": "As I understand it, each componentjs dep and transitive deps need to be proper componentjs projects. My feeling is if you want to use form-data or any other module that doesn't support componentjs (quick check is to see if it has a component.json), it will not be worth the trouble to support componentjs, because\n1. componentjs is a deprecated project\n2. the amount of work to get all deps and transitive deps working with componentjs and the resistance you'll get trying to convince the authors to support a deprecated project\n. ",
    "bmatto": "I'm seeing this issue as well in IE9 - Was particularly confusing because we have a module elsewhere called FormData :8ball: \n:+1: \n. ",
    "tremendus": "Yeah, for my application this does work. Right now I'm wrapping it as a promise, but your passing it to resolve directly is more concise ... though there is no error handling here of course. But I can work with it anyway, thanks. \n. ",
    "chrisdchristo": "Also in general with the releases here, where are the final production files? I would expect a superagent.js and a superagent.min.js file included in the artifacts in the github releases. But alas all I see is source code zips and tars. Seriously?\n. ",
    "zallek": "Hi could you release with the fix on bower.json pls ?\nhttps://github.com/visionmedia/superagent/commit/47b44ac55a960136b23e4b3baca054365adb7ee3\n. thx :)\n. ",
    "Eiskis": "Could you elaborate the intended and non-intended usage in the readme? I'm also running into this, as my project does not use WebPack or Browserify. I saw in another discussion you suggested using wzrd.in, so maybe you could add that to the readme?\nI understand that moving to a pipeline that supports using superagent as in your current examples is the preferred way of using the library, but in real life this is not always possible when considering using the library in an existing project. It doesn't make sense to simply not provide any information on the subject to the users in my opinion.\n. ",
    "sajalrustagi": "Without bower support, the libraries using superagent as their hard dependency cannot resolve dependencies only using bower. They would have to use other ways to resolve these dependencies. Like every other JS based library providing a folder containing superagent.js and a superagent.min.js on bower and git would have been really helpful. ",
    "jotto": "\nIs it secure?\n\nIsn't this the purpose of SNI? (multiple hosts, 1 IP) - this just seems like an alternative API to what would could easily be achieved with DNS or merely calling the lower Node APIs manually.\nIf there's still paranoia, maybe start by limiting to localhost only (testing environments).\nOr maybe I'm misinterpreting what you mean by \"is it secure?\".\n\nHow to test it?\n\ninspiration from https://github.com/visionmedia/superagent/blob/eafc6583dcac73f04754f2aabc8bce6ea65d00ef/test/node/https.js#L30-L58\n```javascript\nserver = https.createServer({\n  SNICallback: function(hostname, cb) {\n    if (hostname === 'example.com') cb(null, tls.createSecureContext({ cert, key }));\n  }\n}, app);\nbefore(function listen(done) {\n  server.listen(0, function listening() {\n    base += ':' + server.address().port;\n    done();\n  });\n});\ndescribe('https', function(){\n  describe('request', function(){\n    it('should give a good response', function(done){\n      request\n      .get(base)\n      .set('Host', 'example.com')\n      .ca(cert)\n      .end(function(err, res){\n        assert(res.ok);\n        assert('Safe and secure!' === res.text);\n        done();\n      });\n    });\n  });\n});\n```\n. ",
    "scriptype": "Yes. There are no error handlers for formData, which happens to handle fs-level read.\n. @pornel This is actually completely node-side. In browser, users will probably handle producing buffer themselves, or most likely, file will be selected through a file input, thus it's all OS's job.\nWe must make sure calling on method will not break browser though.\nI wasn't sure which references should I modify in a node-only case. Maybe request-base shouldn't include this change.\n. I've tried adding shared test for field but regardless of my changes, it was failing. And adding listener to request-base was breaking the browser. So I've removed the listener from request-base and the shared test of field method.\nCurrently it catches error on node, doesn't behave differently on browser.\n. Good point. I've thought something similar later on. Let me clear that.\n. ",
    "piranna": "\nThe fact that request.post('') works is an accident, and ends up being same as request.post('http://localhost/') (at least in node version).\n\nThat's the point, what I'm asking for is that request.post() to have the same behaviour than request.post(''), it's said, that the empty string to be the default value. Don't know if it's an accident, but I think it's a good default value to have...\n. > Sorry, I still don't understand usefulness of this. Why should there be special convenient shortcut for posting to http://127.0.0.1/? Who does that?\nI'm not interested on testing the URL path, since I know before hand the exact location where the middleware will be listening for, so whatever path you put on .post() it doesn't matter. That's just why the empty string is a valid case the same way it does not setting it at all: I don't care (in the test) where I'm posting to, only that I'm receiving a POST request.\n. Ok... maybe you are right, it's supertest :-P Since it uses superagent as dependency and the names are a bit similar, probably when following the code to see why it was not working for me I wrong the repo when opening the issue :-P\n. You are welcome :-) I've open a new issue on supertest for this :-)\n. ",
    "harshu108": "Yes server sends content-encoding: gzip and does not return any content\n. ",
    "fatso83": "Yes, it's possible\n\nBut seriously, adding full compression supports adds something like 20KB to the library. This is not something most people want. Try creating a plugin and just wrap the inflate-part of js-deflate.\n. It's common to do compression for server-to-server communication, but there is no general native support in browsers.\n. ",
    "afanasy": "@pornel looks like it's a part of the standard and Express body-parser middleware https://github.com/expressjs/body-parser#inflate supports it out of the box. @fatso83 thanks for the tip, how about we just add it for the node client for the start (since it's most common to use for server-to-server anyway, and it's my use case too)? Then we can just use zlib, and several lines of code. \n. ",
    "hajoxx": "```\n$ curl -v https://eksisozluk.com/debe\n Hostname was NOT found in DNS cache\n   Trying 176.53.43.6...\n connect to 176.53.43.6 port 443 failed: Connection timed out\n   Trying 176.53.43.11...\n...\n...\n* Closing connection 0\n```\nIt got stuck like that. Also the server is a digitalocean droplet. (Thanks for your help)\nAs you say it can be the server's problem because I tried with php's curl too but still same.\nWhat would you advice in this case? \nRegards.\n. I resolved the issue by creating three more droplets in digitalocean. Third one worked.\n. ",
    "crookedneighbor": "That doesn't seem like something inherent to superagent. You're using bluebird to promisify the callback, and any promise can be used with async/await. Following that logic, you'd include a note about using async/await in any callback based library, which seems unnecessary. \n. May I ask what the point of adding the documentation would be? If you're using async/await, you should see that superagent can return a promise and know that you can use async/await on it. If you're not using it, and aren't familiar with async/await, the documentation would be confusing unless you also mention that you need to transpile code from es7 to use it. Seems like more trouble than it is worth IMO.\n. IMO, that doesn't seem like a concern of this module. \n. Sorry to convey being upset. Not upset, just have strong opinions :smile: \nIt just seems out of scope to me. Especially for a language feature that is still stage 3, not stage 4. (If it has transitioned to stage 4, please share a link, cause that's very exciting news!)\n. Looks like this has been added to the docs:\n\n. I'm curious why your server needs a null value for myFlag. Can you explain the use case?\nDoes jQuery automatically convert null to '' (empty string)? \nPersonally, I prefer superagent's method, to ignore the key if the value is null or undefined. That makes more sense to me than sending along an empty value. \n. :+1:\n. I verified that this link still works with the capital letter.\n. ",
    "taoeffect": "\nMay I ask what the point of adding the documentation would be?\n\nThe point would be to help and encourage people to switch their codebases over to await/async syntax. EDIT: and of course to introduce those who are unfamiliar with it to it and its possibilities.\n. Providing examples at all isn't a concern of this module, but it's a good thing to do. I'm surprised at how this small (and helpful, I thought) suggestion seems to be upsetting you @crookedneighbor. It was not my intent to upset you. If you feel strongly this small example usage is an existential threat of some sort, by all means let me know and I can close this issue, I wouldn't want to cause you harm through it.\n. FWIW, @pornel's example is great too, it's just that until 2.0 I think superagent doesn't support it, so this could work in its place in the meantime.\n. @kornelski I looked at the docs you linked to, and I don't see a single example of using async/await. :-\\\nEdit: there's one hidden under \"using http/2\", but that's not what the link that was inserted into my comment points to.. FWIW I no longer use superagent and now use the native fetch API.. ",
    "dschinkel": "example is here..it's another framework but still a good example;  I know his this is an old post..just wanna say II agree @taoeffect , always assume the lowest common denominator with developers and if you're showing examples for everything else you should also show async/await.  Anyway for anyone who might come across this thread just wanted to pass this along: \nhttps://github.com/thenables/requisition\nhttps://honeycomb.io/blog/2017/04/es7-await/async-and-superagent\nIs it possible to contribute to the docs?  I'd like to.\nAll the examples use then() via promises.  It's not obvious that you'd get a response object back because it lacks in the docs.  Because most the examples are using sueprtest's built-in assertions which the examples only show being called within then().  So the documentation is totally lacking.. ",
    "reyou": "I came here by google searching \"superagent async/await example\", and I would rather to land in documentation, rather than this issue page. Well thought @taoeffect . ",
    "kadishmal": "Currently I have to do:\n('/alerts?filter=' + encodeURIComponent(filter).replace(\"'\", '%27'));\n. ",
    "philpill": "Sorry, I added the comment about the failing build a bit earlier, but removed it as I'm not sure if this PR (or the work for this PR) was the cause. Thanks for looking into it.\n. ",
    "vkarpov15": "Ah oops, my mistake re: the query() getter, thought about adding that but decided against it since what I really wanted was a way to consistently apply the query string between client and server.\n. @pornel quick reminder to take a look at this when you get a chance :+1: \n. Looks like the build is breaking because of some tunneling issue. Travis being flakey?\n. ",
    "thunderkid": "Use case is pretty boring. The server call includes an id parameter for additional action to be taken on that particular id. If it's null, no extra action's taken on any id. In this case I have access to the rest of the code, so I can store '' instead of null. However, in larger projects it might not be so easy to make that sort of change.\nYes, I suppose jQuery just converts null to ''. And so does the npm request library. And so does direct use of XMLHttpRequest. Because of this I actually spent quite a while hunting down this bug - I thought there was some sort of CORS problem since I was assuming the parsing would be the same across libraries. \n. So right now I'm just using a simple hack that makes superagent behave like jQuery:\nfunction nullsToEmptyStrings(origObj: any) : any {\n        return JSON.parse(JSON.stringify(origObj, (k, v) => (v === null) ? '' : v));\n    }\nWhich is used as:\nrequest.post(uri)\n               .set('Content-Type', 'application/x-www-form-urlencoded')\n               .send(nullsAsEmptyStrings(myParams))\n               .end((err, result) => { ....\n. ",
    "shreychaturvedi123": "can you show me a snippet?\n. ",
    "transitive-bullshit": "@pornel where in the world is this documented?? I've been looking through docs for the past few hours and just happened to stumble on this issue which is the only place I've clearly found this distinction.\nWhy isn't upload progress supported in the browser?\n. Okay; I'd be glad to look into adding support, but I'm not sure I understand why it doesn't work as-is, given that lib/client.js includes a progress handler and bindings for xhr.onprogress and xhr.upload.onprogress.\nDo you have any insight or resources that would explain why this approach isn't currently working?\nThanks!\n. Also, it looks like the progress handler is called several times on Chrome in a few tests I've run, but only at like 98% and 100% and never consistently.\n. Awesome -- thanks @pornel!\n. ",
    "idw111": "@pornel \nThank you for your comment.\nI'm currently using the cookie,\nbut I should dig for the basic auth.\n. I managed to inject cookies by tweaking redux action creators.\njavascript\nconst actionCreator = (a, b, c) => (injectCookie) => (dispatch) => {\n   injectCookie(AjaxClient).fetchData().then(..)\n}\nand wrote some injectCookies function which does similar things with bindActionCreators\nnow the code looks much more uglier than before.\nI have to find a way to make it prettier,\nor maybe I'll be using it as it is...\n. ",
    "leaves4j": "http2 is ready, is there a plan to support it?. ",
    "alexilyaev": "Had the same exact issue, spent several hours trying workarounds without success.\nWould really love to see built in support for this.\n. ",
    "maxence-lefebvre": "Hi,\nIn fact, you can patch req.end in order to have the desired effect : \n```js\nimport { getToken } from './auth.service';\nexport const withToken = (req) => {\n  const _end = req.end;\n  const promise = getToken();\n  req.end = (...args) => {\n    promise.then((token) => {\n      req.set('Authorization', Bearer ${token});\n      _end.apply(req, args);\n    });\n  };\n  return req;\n};\nAnd then, use it for all your authenticated requests by importing the following file :js\nimport superagent from 'superagent';\nimport { withToken } from 'services/auth/auth.middleware';\nconst agent = superagent.agent();\n// add Authorization header with auth token in all requests made by this agent :\nagent.use(withToken);\nexport default agent;\n```. ",
    "hallettj": "Yes, the problem was on my end. I'm very sorry to open a frivolous ticket!\n. ",
    "RajeshSivanesan": "// state change\n xhr.onreadystatechange = function () {\n    if (4 != xhr.readyState) return;\n```\n// In IE9, reads to any property (e.g. status) off of an aborted XHR will\n// result in the error \"Could not complete the operation due to error c00c023f\"\nvar status;\ntry { status = xhr.status; } catch(e) { status = 0; }\nif (0 == status) {\n  if (self.timedout) return self.timeoutError();\n  if (self.aborted) return;\n  return self.crossDomainError();\n}\nself.emit('end');\n```\n};\nif(4 != xhr.readyState) return;\nif the readyState in any case will not change to 4 ? Status still staying on 3.\nI will confirm if Iam able to reproduce this always. I just wanna understand, are there any cases in which this can happen ?\n. I tried different ways of reproducing this, but always the readyState changes to 4 always. If i find the exact steps to reproduce, will let you know.\n. This issue is happening only in Stock Browser (4.3 Android) Samsung GT-i9300 phone S |||.\nIts working properly in Android 4.4+ mobiles & chrome browser.\n. I found out where it was exactly crashing with this error by adding try / catch block, in the 'end' event of Request function.\nAccessing status / statusText properties in the end event could have caused this problem.\nAs of now i wrapped the block with try / catch and invoked callback with error as empty and data as empty object.\nCode Snippet:\n```\n     try {\n    if (err) {\n        return self.callback(err, res);\n    }\nif (res.status >= 200 && res.status < 300) {\n    return self.callback(err, res);\n}\n\nvar new_err = new Error(res.statusText || 'Unsuccessful HTTP response');\nnew_err.original = err;\nnew_err.response = res;\nnew_err.status = res.status;\n\nself.callback(err || new_err, res);\n\n} catch (e) {\n    self.callback(null, {});\n}\n```\nPlease have a look and let me know if there are any issues. Can you also think about adding this to master code base ?\n. when i try to access res in the catch block to know the value, I am getting the same exception \"Internal State Err: DOM Exception\".\nI think accessing the variable drives this problem. To get rid of this problem i thought of changing the library from superagent to x. Can you please identify the problem and add the same in the latest version ?\n. Thanks pornel. \n. ",
    "TobyEalden": "I'm seeing this too - with a basic post:\nrequest\n        .post(url)\n        .send(postData)\n        .set({ authorization: \"Bearer \" + this._accessToken })\n        .end(function(err, res) {\n          if (err) {\n            cb(err);\n          } else {\n            log(\"RESPONSE >>>>>>> %j\", res);\n            cb(null, res.body);\n          }\n        })\nres.body is always missing, even though the response I want is in string form in res.text.\nAm I missing some configuration? Surely a basic json request/response works out of the box?\nThanks in advance.\n. ",
    "lesterzone": "Should be documented, or perhaps as FAQ.\nThanks @pornel now response.body is not null  :+1:\n. ",
    "jeremy-linchao": "thanks, @pornel \n. ",
    "likino": "req.on('error', function (err) {\n    if (err) {  \n        // do something  \n    }  \n }). ",
    "gautaz": "@likino This is in fact a working way to circumvent the issue.\nNonetheless I would still expect timeout to operate in such a case, don't you agree?. ",
    "chakradeb": "Hey I am ready to fix this issue.\nWould you consider If I submit PR?\n. ",
    "haocs": "@pornel - I see, thank you for the clarification. Is there a way to config super agent to follow 300 redirect? \n. ",
    "jcramer": "i have this same issue.  Its a problem for me because I receive an error from the server if I submit \"true\" \nI used something like require('superagent').post('/').send('{\"key\": true}').end() as a work around\n. ",
    "lmk123": "@focusaurus I'm not removed this function request.getXHR(). It is strange that when I run make test-browser-local, everything is ok. I will take a look.\n. I can't figure out why it's failed on Travis CI.\n. ",
    "AlexZeitler": "For me var request = superagent; instead of var request = new superagent(); did the trick.. ",
    "anonym24": "@pornel I installed superagent with npm but I don't have such fodler. ",
    "cancerberoSgx": "So I'm doing it like this, but I think the syntax would be more clear if superagent calls manage promises automatically. .end() could return a promise. \n```\nnew Promise(function(resolve, reject)\n{\n    //first obtain the token\n    request\n    .post('http://localhost:3000/api/authenticate')\n    .send({name: 'sg', password: 'test123'})\n    .end(function(err, res)\n    {\n        err ? reject(err) : resolve(res.body.token);\n    })\n})\n.then(function(token)\n{\n    //now make the api call passing the token\n    return new Promise(function(resolve, reject)\n    {\n        request\n        .get('http://localhost:3000/api/utility1')\n        .set('x-access-token', token)\n        .end(function(err, res)\n        {\n            err ? reject(err) : resolve(res.body.result);\n        });\n    });\n})\n.then(function(result)\n{\n    //we have the api call result :)\n    // console.log('operation result is: ', result);\n    cb()\n})\n.catch(function(err)\n{\n    console.log('ERROR', err.toString())\n    cb()\n})\n```\n. Thanks, I understand, but unfortunately it is not a promise. For example, If I would like to use generators, yield, co etc, this works: \n```\nco(function*() \n{\n    var token = yield new Promise(function(resolve, reject)\n    {\n        request\n            .post('http://localhost:3000/api/authenticate')\n            .send({name: 'sgurin', password: 'test123'})\n            .end(function(err, res)\n            {\n                err ? reject(err) : resolve(res.body.token);\n            })\n    });\nconsole.log('token obtained', token);\n\nvar result = yield new Promise(function(resolve, reject)\n{\n    request\n    .get('http://localhost:3000/api/utility1')\n    .set('x-access-token', token)\n    .end(function(err, res)\n    {\n        err ? reject(err) : resolve(res.body.result);\n    });\n});\n\nconsole.log('result obtained', result);\n\nexpect(result).toBe(123123)\n\ncb();\n\n})\n.catch(function(err) \n{\n    expect(err).toBe(undefined); \n    console.log(err.stack);\n});\n```\nbut unfortunately \nvar result = yield request.get(..).end(..)\nwon't work - that's kind of the point of this issue. \n. ",
    "hengbenkeji": "It seems that it is an CORS issue.\nActually, you got two responses - one is in response to OPTIONS command, with the other responding to your POST request.\nYou can set up an Express server for your own, and use the Morgan logger on the server side. Then, you will see for every POST command, the browser automatically preflight your POST command with a proceeding OPTIONS command, which causes problems on your client side.\nThe server just returns an empty body {} to the OPTIONS command.\nsee here for details\nhttps://github.com/visionmedia/superagent/issues/501\n. ",
    "StMarcusDE": "Hi, \nwe\u2019re using webpack for both, a mobile version of our app and a node-webkit version as desktop app. We bundle the sources to get a better loading time. We need to download hugh packages in our app, so that is why we preferred to pipe() the request. And we choose superagent, because it works on mobile and desktop. Can you point me to a solution on how to realize a download with superagent without the pipe function? Or is there a workaround?\nThank you so much\n. ",
    "bendman": "It would be nice to have documentation of the difference between the browser/standalone version and the node version.  Even something as simple as request.get(url).end is undefined in the browser standalone version.\n. ",
    "samzilverberg": "I looked into the code and got some better understanding of qsRaw and qs usage.\nI think i understand now the parsing problem you wanted to avoid and the feature you wanted to have with qsRaw .query(string).\nif your'e interested I'd be happy to create a PR with some extra tests and docu that explains the interaction (well, no-interaction...) between query(string) and query(object).\nso if i understand it correctly:\nreq('/?foo=1')\n   .query(`foo=2`)\n   .query(`foo=3`)\n   .query({foo: 'bar'})\n   .query({foo: 'boom'})\n => ?foo=boom&foo=1&foo=2&foo=3\n. ",
    "sharique123": "Version 1 works \nagent.saveCookies(res);\n. http://jaketrent.com/post/authenticated-supertest-tests/\n. ",
    "jadidian": "Versions: superagent: 2.0.0, superagent-promise-plugin: 3.2.0, iOS: 9.3, react-native: 0.28.0\n. UPDATE:\nI attached a file.name = 'avatar.jpg' to the file object I'm passing to .attach() and now it shows up in the request, which is weird, I was guessing .attach([fieldname], [data], [filename]) should have set (or overrided) the filename in content disposition...\n```\n...\nContent-Length: 93108\n--dj/YL9pno2_FjeGb10D.VWrTo_serRiSPD3KneuZvWESgt2_LKp2EOiPFD2ulKG9aVUluo\ncontent-disposition: form-data; name=\"avatar\"; filename=\"avatar.jpg\"\ncontent-type: image/jpeg\n\ufffd\ufffd\ufffd\ufffd\u0000\u0010JFIF\u0000\u0001\u0001\u0000\u0000H\u0000H\u0000\u0000\ufffd\ufffd\u0000XExif\u0000\u0000MM\u0000*\u0000\u0000\u0000\b\u0000\u0001\n...\n``\n. I'm not sure, I didnpm install superagent --save` and then imported the npm module in my project\njs\nimport superagent from 'superagent';\n. OK, it seems that its loading the lib/client.js... added a console.log() in both files and the lib/client.js one showed up in console\n. You're right, I also did:\njs\nvar formData = new FormData();\nformData.append('avatar', file, 'avatar.jpg');\nthen tried to send it either with fetch() or superagent.post().attach()... Neither would set a filename, so the workaround for having a filename in content-disposition on iOS react-native (Safari or WebView or whatever react-native uses to run the JS under the hood) is to explicitly set file.name = 'something.jpg' then pass it to superagent or fetch...\nBtw, thanks for the awesome job on superagent, its one of my most favourite JS libraries.\n. ",
    "sidhijakpat": "Hi @jadidian , how did you load the file? I try to upload image file to server using superagent.attach but always failed, can you help me?\nI submit the issue here: https://github.com/visionmedia/superagent/issues/1444\nI hope you still remember it \ud83d\ude04 \nThank you. sorry didn't realise that I repost the same issue twice\nplease check https://github.com/visionmedia/superagent/issues/1444 instead. We try to load the file using react-native-fs before sending the file, like this:\n  rnfs.readFile(file.uri, 'base64').then(result => {\n    superagent.post(full_url)\n      .field('type', 'image_type')\n      .attach('file', result, {contentType: 'image/png'})\n      .then(response => {\n        console.log(`response ${JSON.stringify(response.body)}`)\n        callback(response.body)\n      })\n      .catch(error => {\n        console.log(`error body json stringify ${JSON.stringify(error)}`)\n        errorCallback(error)\n      })\n  })\n\nstill got the same error. I got it, so the file must be in JSON object in the following format to make it work:\nconst file = {\n  fileUri,\n  name: 'image_name.png',\n  type: `image/png`\n}\n\nThank you. Sorry, the issue still exist, \nthe server did find file key, but the uploaded file is empty\nstill need help \ud83d\ude04  . Once again, it was our mistake, the JSON Object should be:\nconst file = {\n  uri: fileUri,\n  name: 'image_name.png',\n  type: `image/png`\n}\nThank you again. ",
    "happyvig": "@focusaurus : Thanks.\n. ",
    "blindbox": "I see the issue now. server.send() is sending the data as JSON, while my POST api accepts form-data.\n@pornel : I think this issue can be closed. Adding .type('form') fixed everything.\n. ",
    "viktorlarsson": "Well, I figured out one of the issues. I've only spent like a total of 8 hours trying to wrap my head around this. Hope this helps someone else. You have to use trailing slash \n'.get(${config.apiUrl}endpoint)' // wrong\n'.get(${config.apiUrl}endpoint/)' // right\n. ",
    "furkanmustafa": "This turned out to be a problem on my side, when evaluating the request stream on the receiving end.\nI could confirm that superagent and form-data does not mess with the order of delivery and delivers multi-part data stream as-is. (in node)\nSorry for the inconvinience.\n. ",
    "loretoparisi": "[UPDATE]\nI came out with this possible solution:\n``` coffeescript\nHTTPClient = \n  # http get\n  # support https and http\n  # @return Promise\n  get: (url) -> new Promise (resolve, reject) ->\nheaders=\n  'Accept': 'application/json'\n\nreq = request.get url\nreq\n.set headers\n.timeout(3000)\n.end (err, res) ->\n  if res?.ok\n    console.log res.header\n    try\n      data = JSON.parse(res.text)\n      resolve data\n    catch\n        reject new Error \"request malformed\"\n  else\n    #console.log req\n    reject new Error err\nreq.on 'error', (error) ->\n  reject error\n\n```\nSo that I therefore handle it in the catch\ncoffeescript\nHTTPClient.get(url)\n      .then (res) ->\n        console.log res\n      .catch (error) ->\n        console.log 'error:%s', error\ncatching the original timeout error: error:Error: timeout of 1000ms exceeded\n. [UPDATE]\nInvestigating the callbacks fired by the library, it seems that both the\ncoffeescript\nreq.on 'error', (error) ->\n      reject error\nand the\ncoffeescript\n.end (err, res) ->\nwill be fired in case of errors, so the solution will be to avoid to handle both.\n. @pornel thank you I'm using superagent@1.2.0 due to other dependencies requirements.\n. ",
    "vinnymac": "This is just how javascript works right now. But the future is bright async and await should make this a bit easier for us. You can do this today if you use babel with some transforms.\nThen you could write something along the lines of\n``` javascript\nimport request from 'superagent';\nlet id = 'empty';\nconst res = await request.post('http://URL/getjson');\nid = res.body.id;\nconsole.log('id is- ' + id); // prints \"id is- XXX\"\n```\n. ",
    "DSigmund": "Many Thanks. But seams not to be updated in the npm package yet...\n. Thank you again :-) :+1: \n. ",
    "timbuckley": "FYI you can drag/drop the image into this github issue to make it show up.\n\n. ",
    "thanhthang20": "\n. \n. ",
    "Gerhut": "I prefer ignoring them because {\"a\": null} compiles a=, which may not be decided with {\"a\": \"\"}.\nSometimes it will be used as a result of an expression.\njs\n{\n  \"userId\": config.userId > 100 ? config.userId : null // or undefined\n}\nIn these cases, I think using null is better than using undefined as a specific value.\n. ",
    "leesiongchan": "Sorry, the library I use is using the older version. Closing this as it is not an issue.\n. ",
    "kharandziuk": "Thanks! It works.\nBut what does _res.pipe function do in the case?\n. It will give me an ability to separate SuperAgent-level errors from all the other.\ntry {\n        const a = await request.get('example.com/absent')\n    } catch(e) {\n        if(e instanceof SuperAgentError) {\n            // do some specific handling for 404 or 500 and ? \n        } else {\n            throw e // I don't want to handle e.g.:Error: getaddrinfo ENOTFOUND\n        }\n    }\nWhy is it better? With a typed error you don't need to figure out how to catch the only one specific type of the error. . ",
    "ariutta": "That's a tough question. I love superagent's clean API and minimal file size. And I also support building on standards. But I'm not sure how to join the two.\nEmulating/polyfilling Node streams or ReadableByteStream definitely is possible, but wouldn't this option eliminate superagent's file size advantage?\nThis issue for stream-http has a comment suggesting it would be possible to create a minimal stream library to replace the Node stream dependency to reduce file size. But, yes, creating yet another stream library would pollute superagent's clean API. \n. I ran some quick tests on the minified, bundled sizes of the latest versions of related modules for comparison:\n| module | size |\n| --- | --- |\n| axios | 16K |\n| chunked-request | 7.2K |\n| fetch | 435K |\n| fetch-stream | 91K |\n| whatwg-fetch | 7.1K |\n| grab-http | 8.1K |\n| hyperquest | 134K |\n| nets | 32K |\n| request | 1.0M |\n| requests | 12K |\n| simple-get | 90K |\n| stream-http | 87K |\n| superagent | 13K |\n| xhr | 6.1K |\n| xhr-request | 9.8K |\nHere was the bundle command:\nbrowserify -g uglifyify ./size.js --standalone size | uglifyjs -c -o ./size.bundle.js\n. Maybe the best option would be to minimally polyfill the stream standard with a notice that the full stream standard will be used when it lands in most major browsers. The minimal polyfill would be limited to event emitters (data, error, end) and basic functions (.write, .end). Polyfilling the entire stream standard, including backpressure, etc., would drastically increase the size of the library.\n. Hmm... WHAT-WG streams actually remove data events and also split the Node pipe method into pipeTo(writable) and pipeThrough(transform). I'm hesitant to try creating a minimal polyfill of the streams standard when it's not yet in production anywhere (didn't see it on icanuse.com) and is significantly different from Node streams.\n. Also, there is the observable standard, which is probably less suited for the purpose of this library, but it does offer yet another way of working with multiple chunks over time. If for some reason the observable standard gets traction and the stream standard doesn't, then it would make sense to use the observable standard here.\n. But if we continue with the web streams standard, the web-streams-polyfill could serve as a start. It basically just turns the reference implementation into an npm package. I got it down to a minified size of 47K by using uglifyify and unassert. To reduce size further, we could look at dropping code from readable-stream.js.\n. I like the second idea. Would the hooks be event emitters and .write/.end methods? If so, pull-through and pull-stream might be useful. 9.8K bundled together and minified.\nIn this issue, there's some interesting discussion on lightweight transforms for web streams. Would the hooks be easy to use with transducers?\n. Yes, that sounds perfect.\n. ",
    "XeniaSiskaki": "So, currently if the server is sending the response in chunks, there is no way to receive it accordingly on the browser?\n. Well, on the server I subscribe to a stream which is emitting data when they are available (that's what I mean by chunks). But because sending the whole response takes long (fetching one year's data), the client is always throwing a ERR_INCOMPLETE_CHUNKED_ENCODING, even though the server didn't finish sending the data.\n. Is there any way to verify that? The server seems to be sending data normally, without any errors. \n. I tried using an XmlHTTPRequest but still get the error. Even after getting the error on the browser, the server continues to send data and at some point ends (res.end()) with no error. So I'm not sure if the problem is on the server side. \n. ",
    "alexanderbanks": "Yes, my own relentless stupidity. I forgot to add:\nif ('OPTIONS' == req.method) {\n    res.send(200);\n  }\n  else {\n    next();\n  }\nTo my node app. It was failing on the options preflight. Thanks for responding and I apologize for the illegitimate issue raising.\n. ",
    "jwingo1015": "@pornel  No it doesnt i want to know how to make it work\n. I tried the following but get an error message:'TypeError: first argument must be a string or Buffer' \nvar form = new FormData();\n      form.append('json', '{\"categoryId\":1}')\n        api.post('/1_0/callrequests')\n        .set({\n          'Authorization': token\n          'Content-Type': 'multipart/form-data; boundary=----WebKitFormBoundaryKPzoKfSfBvBzfvZa'\n        })\n        .send(form)\n. @pornel \n. @pornel  ok so i need to do this:\napi.post('/1_0/callrequests')\n        .set({\n          'Authorization': token\n        })\n        .field('json','{\"categoryId\":1}')\n        .expect(200)\n        .end(function(err, res) {\n. @pornel b/c this way doesnt work either. I was able to get this call to work in postman but no luck with supertest\n. @pornel Not that deep sir. I just mispoke\n. describe('post_callrequest', function() {\n      it('should respond with 201 201 response', function(done) {\n        api.post('/test/callrequests')\n        .set({\n          'Authorization': token,\n          'Content-Type': 'multipart/form-data'\n        })\n        .field('json','{\"categoryId\":1}')\n        .expect(201)\n        .end(function(err, res) {\n          callId = res.body.id\n          console.log(res.status+'   '+res.body.id)\n          if (err) return done(err);\n          done();\n        });\n      });\nThis still is not working for me @pornel \n. ",
    "mrsum": "Any news?\n. ",
    "Nitive": "Thanks!\n. ",
    "popeindustries": "oops, sorry...\n. \"Nicely\" will definitely be the challenge ;)\nI don't yet have a full picture, but it looks like callback() would be the best place to trigger a reset (_aborted, timedout, called, _endCalled, etc) and re-execution of end(). I think the real challenge will be dealing with the event handlers for the internal req instance. On timeout, for instance, after abort() is called and an err passed to callback, if we reset _aborted, the error handler here will not return early and we'd end up with a double callback. Maybe req.removeAllListeners() will be enough?. Ok, thanks. I'll start with some tests and start poking around. . @pornel I think things are looking pretty good so far. I just have a couple questions if you have time to look things over:\n\ndo you have any suggestions on how to avoid this mess when resetting _timeout or _responseTimeout after they have been cleared in clearTimeout?\nis it necessary to reset headers here?\nI've added an attempts property to err as a kind of flag for exposing retries (similar to err.timeout. I'm not sure if this is the best terminology or not.\n\nI've so far avoided touching end(). I can see how it would be more efficient to avoid initial parsing on each retry, but I'm a little hesitant to mess with anything in there if it's not absolutely necessary.. I've split end() into public/private methods as you suggested. Seems to work fine. I'm not sure if there is anything else I've forgotten. \nUnfortunately, some of the browser tests are still failing. I've added a (pseudo) unique id to the requests to work around the parallelisation problem you raised, but there still seems to be something wrong with the tests that require different responses from the same endpoint.. That's great! Thanks for your help and patience . A little funky to tell the difference between retry() and retry(undefined), but I think this should do it:\njs\n  if (!('0' in arguments) || count === true) count = 1;\n  if (count == null || count <= 0) count = 0;. Yeah, this is really ugly because _timeout and _responseTimeout are zeroed out in clearTimeout, before callback is called. Any reason we can't just delete L45-L46 in request-base?. This is also a little strange. After aborting req (timeout -> abort()), I delete the old req, but if I also req.removeAllListeners(), an unhandled \"socket hang up\" error is thrown from the old instance. If I don't remove listeners on the old req instance, then I have to skip somehow. \nI think the best approach would be to memoize the current retry index and return early if they are not the same.. I'm not sure I follow. This is the main api for enabling retry (like timeout). I tried to follow the same logic as for redirects.. Good point. I'll write a test for this. Of course! I was wondering why the tests worked locally but not remotely.. I can confirm that this works fine (via test). Calling abort() never triggers callback(), so no more retries are attempted.. Yes, I can see how this would be a problem. I'll take a look at refactoring end() next. . In _setTimeouts() there is the following check, so if they are not removed, the new timers for retry can't be set:\njs\nif (this._timeout && !this._timer) {\nProbably better to delete or zero out in clearTimeout()?. ",
    "kolodoz": "Sorry, forgot about our old friend. Fixed and added a test.\n. Missed the button\n. ",
    "joekrump": "Was a matter of having 'Authorization' in 'Access-Control-Expose-Headers' in CORS settings for my API\n. ",
    "bs-thomas": "@pornel Wow that was some quick response.  Thank you so much!!\nHope you don't mind me asking one more question.  If there is network connection errors such as timeout, how should I detect that then?\nThanks again!\n. @pornel Understood.  So may I confirm there is currently no way of knowing the callback is triggered by timeout / abort?\nThe reason why I'm asking is because it would be great to know what type of error was called back, for logging purposes.\nI noticed that jQuery's $.ajax actually has some non-response related errors:\n\"error\", \"timeout\", \"abort\", or \"parsererror\"\nhttp://api.jquery.com/jquery.ajax/\nThe first 3 errors are related to network connection I believe, and the 4th one is a parseerror.\nThanks!\n. ",
    "mattcodez": "Thanks for the reply. I believe it's actually deeper than express even, going down to Node's native http.serverResponse. I'm running it on SuperTest which claims   I can make any SuperAgent call with it.\nagent = request.agent(sails.hooks.http.app);\ndescribe('index - ajax', function(){\n    it('should return JSON for XHR request', function(done){\n      agent\n        .get('/survey')\n        .set('X-Requested-With', 'XMLHttpRequest')\n        .set('Accept', 'application/json')\n        //         .expect(200)         .expect('Content-Type', /json/)\n        .expect(function(res){\n          if (Array.isArray(res.body.questions)){\n            return;\n          }\n          else{\n            return 'questions property is not an array';\n          }\n        })\n        .end(function(err, res){\n          if(err) return done(err);\n          done();\n        });\n    });\n  });\nNote I've tried changing the order of and even removing the .set('Accept'... and it doesn't help. There's something about setting that X-Requested-With header specifically that something doesn't like.\n. Have done so, I know superagent is being used but didn't realize it's also being bypassed by supertest? \n. ",
    "juandopazo": "Awesome! Thank you!\n. ",
    "stonerworx": "I closed the pull request as it was actually not the reason for our problem. Still it would make sense to implement. Yes, the null check should be kept. \n. ",
    "nickclaw": "I guess don't really care whether or not I know exactly why the request didn't complete. It's more that I can't tell the request is \"over\" strictly using events.\n. Indeed I am. And that's fine when you're the originator of the request. My use case is a higher order react component that manages and keeps track of one-off requests. I could always overwrite the end function with my own hook, but that seems like a bad solution -- and I think any module that needs to keep track of requests could benefit from more thorough events.\n. @pornel that's fantastic thanks\n. Hey @pornel, I see this fix is still sitting in a branch. Is there any reason it hasn't been merged yet?\n. ",
    "ratiotile": "I would like to get better error messages. For example, Chrome prints out in the console: XMLHttpRequest cannot load http://192.168.1.192:23297/submit_registration. Response to preflight request doesn't pass access control check: The 'Access-Control-Allow-Origin' header has a value 'http://localhost:8080' that is not equal to the supplied origin. Origin 'http://192.168.1.192:8080' is therefore not allowed access.\nbut the error supplied in end is only Request has been terminated\nPossible causes: the network is offline, Origin is not allowed by Access-Control-Allow-Origin, the page is being unloaded, etc.\n    at Request.crossDomainError (http://192.168.1.192:8080/build/bundle.js:80988:14)\n    at XMLHttpRequest.xhr.onreadystatechange (http://192.168.1.192:8080/build/bundle.js:81058:20)\n. @pornel, If I knew, I would have provided a solution. Chrome unhelpfully points to my index.html as the source for that log statement, so I have been unable to trace its origin.\n. ",
    "acgourley": "I'll look into that now, thanks. \nI want to clarify that there is no problem having the object in memory before the request, but once the request starts the crash is likely to occur. So something about my approach increases the memory usage of the app - maybe a serialization of the object occurs? \n. ",
    "acrazing": "But, how to handle Blob in browser?\n. Maybe add a method like req.bin(blob|buffer|stream|path) is more friendly? And then we can call as follow:\n``` js\n// node buffer\nconst file = fs.readFileSync('./example.png')\n// node stream\nconst file = fs.createReadStream('./example.png')\n// file path\nconst file = './example.png'\n// browser blob file\nconst file = document.querySelector('input[type=file]').files[0]\nrequest\n  .post('/proxy')\n  .bin(file)\n  .end()\n```\n. @pornel But sometimes we need to deal with this situation:\njs\nconst file = document.querySelector('input[type=file]').files[0]\nconst xhr = new XMLHttpRequest\nxhr.open('POST', '/file')\nxhr.send(file)\nThe XMLHttpRequest support send a Blob/Document/ArrayBuffer directly, rather than wrap to FormData. See https://www.w3.org/TR/2012/WD-XMLHttpRequest-20120117/#the-send-method.\n. ",
    "jedwards1211": "Is there any way to pipe only the response body?  I'm trying to parse it as a stream with htmlparser.\n. No, I'm using it in node.  Just using it to slurp tabular data out of html pages.  It works in some cases (I assume because nothing looks like a tag until the parser reaches the body) but not in others.\nOn the other hand, the case where I've seen it fail is a ucs2-encoded gzipped response.  Does .pipe() send the data without expanding it?  If not, I guess superagent-charset isn't intercepting .pipe() to decode the body before it reaches the destination stream.\n. @pornel oh...you know what I think my problem was?  I just noticed that the headers of the response I'm consuming include X-UA-Compatible:IE=EmulateIE9.  I didn't realize it was lacking the usual compression and encoding headers.  I didn't notice because, well, Chrome does do the emulation.\nRequest URL:http://hydromet.lcra.org/data/datafull.xml?9:20\nRequest Method:GET\nStatus Code:304 Not Modified\nRemote Address:198.214.246.3:80\nResponse Headers\nAccept-Ranges:bytes\nDate:Tue, 13 Dec 2016 15:20:16 GMT\nETag:\"80a6335f5455d21:0\"\nLast-Modified:Tue, 13 Dec 2016 15:20:01 GMT\nSet-Cookie:(redacted)\nX-UA-Compatible:IE=EmulateIE9. @kornelski is there any way (/plugin) to make superagent automatically include the response body in its error message for certain status codes?  I think I'll always want to see the body for 400 responses, and it would be nice not to have to add .catch(error => error.response.body) every place I'm making a request.. @kornelski I haven't found anything, so I'm thinking of making a plugin that works something like this:\njs\n  superagent.use((req: Superagent) => {\n    req.on('error', (err: Error) => {\n      if (err.response) {\n        if (err.response.body instanceof Object) {\n          err.message += '\\n' + JSON.stringify(err.response.body, null, 2)\n        } else {\n          err.message += '\\n' + err.response.text\n        }\n      }\n    })\n    return req\n  }). @kornelski true, though an error response that large would be pretty unusual. @pornel is there some technical reason that code like the following would be impossible?\njs\nconstructor() {\n  this.once('pipe', () => this.isPiping = true)\n}\nthen(resolve, reject) {\n  if (this.isPiping) {\n    this.once('response', resolve)\n    if (reject) this.once('error', reject)\n  } else {\n    this.end(resolve, reject)\n  }\n}. @pornel it is indeed possible, I have made a PR complete with tests.. @pornel in fact, if you ask me, it would be better if we could also call .end() after .pipe() and it would merely register the callbacks instead of complaining that it was ended twice.  I don't see why the API for getting a response or error should be so different in the .pipe() case.. @pornel \n\nIs it guaranteed that pipe event is called immediately and sychronously?\n\nI haven't found official documentation but it seems to?\n```js\nvar PassThrough = require('stream').PassThrough\nvar a = new PassThrough()\nvar b = new PassThrough()\nb.on('pipe', () => console.log('pipe'))\nconsole.log('before')\na.pipe(b)\nconsole.log('after')\n\n$ node temp.js\nbefore\npipe\nafter\n```\nAll I see in the docs is\n\nThe 'pipe' event is emitted when the stream.pipe() method is called on a readable stream\n\nDoesn't say when the event is emitted...\nI don't know much about how the buffering works.  Are you saying that's only a concern if we support .pipe().end(), or is that a problem with .pipe().then() as well?. @pornel I'm a bit confused what you mean, are you saying if we support awaiting a request that we've piped something into, you want to support awaiting a response we've piped into something as well?. @pornel I have noticed intermittent failures with awaiting a request that I piped data into now...maybe the pipe event isn't synchronous.. okay.  is there any way to determine if superagent parsed the response without building a big list of content types?. ",
    "bigman73": "I'm using node with a a 3rd party web service that expects a application/octet in its body. I don't have a local file but a base64 string (which I converted to a memory Buffer)\nIs there a way to send the binary buffer with the POST request?\nSaving the Buffer to a local file won't work (by attaching or piping it) since the web service doesn't support files/attachments.. Thanks. I couldn't get attach() to work, and actually ended up using send(), which to my surprise worked fine\nThe buffer was created with:\nconst buffer = Buffer.from(base64Data, 'base64'); \nconst response = await request\n        .post('<URL>')\n        .send(buffer)\n        .set('SubscriptionKey', '<XYZ>')\n        .set('Content-Type', 'application/octet-stream')\n        .set('Accept', 'application/json');\n. ",
    "benmosher": "Ah, so makes sense that buffer(...) would be unavailable within browser.\nIt still seems like providing a parser via #parse should be used within _parseBody as an override for the global request.parse map?\nCurrent code:\njs\n// lib/client.js:375\nResponse.prototype._parseBody = function(str){\n  var parse = request.parse[this.type];\n  if (!parse && isJSON(this.type)) {\n    parse = request.parse['application/json'];\n  }\n  return parse && str && (str.length || str instanceof Object)\n    ? parse(str)\n    : null;\n};\nWhat I thought I'd find based on #parse docs:\njs\n// lib/client.js:375\nResponse.prototype._parseBody = function(str){\n  var parse = this._parser || request.parse[this.type]; // only changed this line\n  if (!parse && isJSON(this.type)) {\n    parse = request.parse['application/json'];\n  }\n  return parse && str && (str.length || str instanceof Object)\n    ? parse(str)\n    : null;\n};\n. relevant commit (AFAICT): https://github.com/visionmedia/superagent/commit/18ea25afef3b87a927018bf221f36ca0b7f11e22\njust making this note for myself. thanks!. ",
    "sean-stanley": "@pornel \nHaving this exact same issue on both 3.5.3-beta.1 and 3.5.2\nI'm on the v1.4 meteor framework so using Meteor's webpack build compiler. Do you have any suggestions on tweaking an image upload request like in acomito's example for when this._formData is undefined?\nThanks for your help.. ",
    "cristian-sima": "Is the length the only disadvantage of using JSON instand of FormData?\n. Or in other words why is the FormData a standard rather than using JSON?\n. ",
    "terusus": "I have no idea why one of the jobs is failing (browser=1). Any ideas?\nevents.js:141\n      throw er; // Unhandled 'error' event\n      ^\nError: connection refused: localtunnel.me:35378 (check your firewall settings)\n    at Socket.<anonymous> (/home/travis/build/visionmedia/superagent/node_modules/zuul/node_modules/zuul-localtunnel/node_modules/localtunnel/client.js:84:32)\n    at emitOne (events.js:77:13)\n    at Socket.emit (events.js:169:7)\n    at emitErrorNT (net.js:1269:8)\n    at nextTickCallbackWith2Args (node.js:442:9)\n    at process._tickCallback (node.js:356:17)\nmake[1]: *** [test-browser] Error 1\nmake[1]: Leaving directory `/home/travis/build/visionmedia/superagent'\nmake: *** [test] Error 2\nnpm ERR! Test failed.  See above for more details.\n. My pleasure. Waiting for the next release.\n. Also, I believe it's safe to decline this PR: https://github.com/visionmedia/superagent/pull/681\nWith the TLS options provided as an object one can override all options in the request.\n. ",
    "nathanbrock": "Hey! This pull request is incredibly useful, many thanks @terusus. Appreciate there's a lot on, but is there by any chance a time frame for the release of these additions into NPM @pornel?\n. ",
    "xinghengwang": "never mind. I think there is something else. \n. ",
    "theDanielK": "Not working being called out of the chain. How would you call that function dynamically?\nie. call it (n) number of times.\n. ",
    "rares-lupascu": "thanks @pornel \ni can officially say i am lost :/\n. doing that for the past 3 days and counting :)\n. ",
    "keithamus": "request.get().ok(res => res.status < 500).then(\u2026)\nVery much works for me. I think if you want all to pass, request.get().ok(_ => true) is very succinct.\n. (chai-http maintainer here) We've yet to add support for this feature in a released version of chai-http. We'll be making a release soon. Thanks for everyone's input here.. @svicalifornia we should take this off of the superagent tracker. Please track https://github.com/chaijs/chai-http/pull/202 for updates.. As someone interested in this issue, this gets a \ud83d\udc4d from me (reviewed the code, it looks good). ",
    "Joshua-Swain": "I'm trying to use this function for to test an invalid post request. The function goes like this: chai.request(app).post(...).set(...).send(...).end((err, res) => {...});\nI tried putting .ok(...) at every point in that chain, but I always received the error TypeError: chai.request(...).post(...).set(...).send(...).end(...).ok is not a function\nI am expecting this to cause validation errors. Any advice on how to use this ok() feature?. I'm pretty sure I'm using superagent, because I'm using chai out of the box.. ",
    "svicalifornia": "@keithamus Any update? What should we be doing until ok is added to chai-http?. ",
    "g7r": "Sorry, false alert.\n. ",
    "DavidTanner": "https://github.com/visionmedia/superagent/blob/v2.2.0/lib/client.js#L503\nCool, I didn't see that.  Thanks\n. ",
    "kroko": "I just tried dropping ES6 promises for this \njavascript\n    request\n    .post('/')\n    .send(sendToServerData)\n    .set('Accept', 'application/json')\n    .end((err, res) => {\n      console.log(err, res);\n    });\nand it works - res body contains payload.\nSo to rephrase the question - how to get error payload when using ES6 promises? I am using React with native promises + Babel.\n. javascript\n    request\n    .post('/')\n    .send(sendToServerData)\n    .type('json')\n    .set('Accept', 'application/json')\n    .then((sucess) => {\n      console.log('we have sucsess', sucess);\n    })\n    .catch((error) => {\n      console.log('we have error', error);\n    });\nsame,  the catched object does not contain payload, only Bad Request(\u2026)\n. but it does not. :)\ncurrently falling back to\njavascript\n.end((err, res) => {})\n. yes, I always tested in a situation where there is response from the server.\njavascript\nrequest\n    .post('/')\n    .send(sendToServerData)\n    .type('json')\n    .set('Accept', 'application/json')\n    .then((sucess) => {\n      console.log('we have sucsess', sucess);\n    })\n    .catch((error) => {\n      console.log('we have error', Object.keys(error), error.response, error);\n    });\nerror.response exists!\npreviously i just tested error that seemed not to contain any keys (and i just assumed it will behave same as success as on the server side both responses 200 & 400 are constructed the same way).\ni did not test error.response.\npardon for my laziness. :(\nthis is probably due to different object enumerability for sucess and error (isn't it?).\nso note to myself, when using promise, use catch for non 200 statuses and callback object will contain keys original, response, status.\n. should i clone, change, commit and pullrequest correction to https://github.com/visionmedia/superagent/blob/master/docs/index.md ES6 promises are supported... block, reflecting that .catch() should be used; or maybe it is at someones fingertips already :) ?\n. ",
    "kromit": "I can confirm this behavior. When promises are used error.response is not there. \nIn my case I am getting 401 response from the server, but not even the status code is there.\nIn .catch(function (err){  I am getting\nerr={\ncrossDomain:true\nmessage:\"Request has been terminated\u21b5Possible causes: the network is offline, Origin is not allowed by Access-Control-Allow-Origin, the page is being unloaded, etc.\"\nmethod:\"GET\"\nstack:(...)\nget stack:stack()\nset stack:stack()\nstatus:undefined\nurl:\"http://....\"\n}\nThe corresponding preflight OPTIONS was returned with 200.\nThe second GET got 401 but no error.response.\nEvtl CORS is the problem cause here.\n. ",
    "pmcavoy89": "I can confirmed that .catch(error => error.response.body) works for me. I'm using ES6 and Babel. But I am using the superagent library. Not sure if that makes a difference or not.. Ah gotcha. I see the difference that you all are talking about now. I appreciate this GitHub issue. It actually helped me solve the issue I was facing. Can we update the documentation on both the error handling and generators to include information along these lines?\nYea, that code was working fine on the HTTP statuses of 400-500.. ",
    "subhamagr": "@pornel How do I do that? I mean conditionally attach a file?\n``` javascript\nvar req = request.post(url)\nif(image) {\n  req.attach('file', image, 'file')\n}\nreq\n  .end(function(err, res) { ... })\n```\nI tried this, but even this doesn't work. The API returns 415 invalid media type.\n. The case may be the API is expecting multipart/formdata and when the file is null, its is simple a POST request, that's why its returning 415 invalid media type. As you pointed out that there's a bug in Chrome that's why it works fine.\nIf I do not send a file, the API just creates a new entry with default image and when I send a file, it just updates the image of the particular entry.\nSo should the back-end be changed to solve the issue? I mean different APIs for creating and updating?\n. yes.\nrequest is something like /add/ and file is optional\nso if i don't send a file, a new entry is created and when i send a file, the entry with the given name is updated with new file.\n. ",
    "ntilwalli": "I agree, a bit weird to workaround ES6 module semantics in a CommonJS package... ideally this would be handled with some sort of exception in rollup or some smarter parsing, but it was such a simple change I submitted the PR to have discussion/get your perspective.  The issue I posted in rollup is here: https://github.com/rollup/rollup/issues/1007\n. I discovered this PR fixes the rollup-bundling issue but not because this was being overrwritten to undefined as I first thought.  The clearTimeout function in the request-base.js module ends up shadowing the global/window clearTimeout due to the way rollup transforms commonjs modules to es6... I've submitted an issue to rollup-plugin-commonjs to better understand how to approach. https://github.com/rollup/rollup-plugin-commonjs/issues/127\n. ",
    "MingYe-dz": "sorry, i find this problem is  due to react-native`s bug.\n. ",
    "sunhjie": "How did you solve the problem, I have the same question. \u5f88\u6025\n. @MingYe-dz \n. ",
    "tkesgar": "Node requests seems to set the wrong content-type.\ncurl-ing the request (to Facebook Graph API) returns the correct content-type:\n```\ncurl -i -X GET \"https://graph.facebook.com/v2.7/335148063288907?access_token=\"\nHTTP/2 200\naccess-control-allow-origin: *\netag: \"ea63bae8487b4f133cb3877b366e553a01fd2e35\"\npragma: no-cache\ncache-control: private, no-cache, no-store, must-revalidate\nfacebook-api-version: v2.7\nexpires: Sat, 01 Jan 2000 00:00:00 GMT\ncontent-type: application/json; charset=UTF-8\nx-fb-trace-id: Bfie5260Olg\nx-fb-rev: 2602612\nx-fb-debug: /J4vr6vfR2BJdlDT1tr6SSDYSciqKO+KEONMWkUfYUoZg/TS3uQkmA4y5PHNZeY1pq9CMhKUj7e26oSZQps6yg==\ndate: Wed, 05 Oct 2016 00:29:01 GMT\ncontent-length: 66\n{\"created_time\":\"2013-10-01T18:01:15+0000\",\"id\":\"335148063288907\"}\n```\nI run both this on Node and browser (result is attached):\njs\nrequest.get('https://graph.facebook.com/v2.7/335148063288907')\n.buffer(true)\n.query({ access_token : <token> })\n.then((success, failure) => {\n  console.log(JSON.stringify(success, null, 2))\n})\ncontent-type is application/json; charset=UTF-8 in browser, but text/javascript; charset=UTF-8 in Node.\nOn an unrelated note, I can't use .buffer(true) in browser, but I removed it and it still works.\nbrowser.txt\nserver.txt\n. I think adding docs should be enough.\n. ",
    "willmorgan": "@pornel That's a pretty good workaround and I see the rationale - thought that augmenting Promise objects might not be the best thing to do (like extending built-ins \ud83d\ude04 )\nI will close this for now. Thanks!\n. ",
    "martinbooth": "Hey. What is filename in https://github.com/visionmedia/superagent/blob/b179a6b3766b8f322b1d3bd91469c4755e190dc9/lib/node/index.js#L185 ? Doesn't seem to be defined anywhere is it?. ",
    "nicolelovecoding": "I think I found the problem, it is not related to superagent. Thanks!. ",
    "imalik8088": "@focusaurus thanks for the hint.\nIt was easy, the problem was in the code!\nHere is what i've done:\n``` js\ndescribe('----- ACCESSING PROTECTED PATH', () => {\n    let token;\nbefore((done)=> {\n    request(app)\n        .post('/api/auth/register')\n        .set('X-Real-IP', URI)\n        .type('form')\n        .send(validNormalUser)\n        .expect(201)\n        .end((err, res)=> {\n            if (err) done(err);\n            token = res.body.token;\n            done();\n        });\n});\n\nafter((done)=> {\n    const colls = 'users';\n    mongoose.connection.collections[colls].drop(err=> done());\n});\n\n\nit('should 401 without invalid login as guest', (done) => {\n    request(app)\n        .get('/api/protected')\n        .set('X-Real-IP', URI)\n        .expect(401, done);\n});\n\nit('should get [200] content from a protected path with valid token', (done) => {\n\n    request(app)\n        .get('/api/protected')\n        .set('Accept', 'application/json')\n        .set('Authorization', token)\n        .expect(200)\n        .end((err, res)=> {\n            if (err) done(err);\n            assert(res.body.content === 'The protected test route is functional!');\n            done();\n        });\n});\n\n});\n```\n. ",
    "ahelmberger": "Red build on TravisCI doesn't seem to be a code issue.\n. ",
    "mindrones": "Hi, this patch is in master but not in the latest release: would it be possible to release so that superagent can be used in projects built with Rollup? Thanks!\n. ",
    "jknight12882": "\ud83d\udc4d  on this, looks like it fixed a fairly nefarious memory leak\n. ",
    "DWboutin": "I got the double callback too, is it possible to get rid of this?\n. Ok, i'll try it this evening!\n. Why it doesn't trigger the error with the 1.7.1 version? Is it possible the treat 304 as a 2xx response? What can cause an http code 304 with superagent? I poke my server-side which is in the same port of my website, first request gives me a 200, when reloading it gives me a 304 but it works...\n. > You should still see the same error in 1.7.1, because that change has been made in 1.0.0:\nIf i don't see it!? Cause i really don't. And if i'm with the latest version, it stop the request, not with the 1.7.1. I'll try to update it to the latest version when i'm back home, but it didn't throw any errors.\n. ",
    "killedWithFire9001": "bringBack Node 0.10\njkjk, nice update :D\n. ",
    "justmendes": "Well, my fix was based on the wrong assumption that _data would be an object every time. Instead it should only be initialized to {} when the data variable on RequestBase.prototype.send is an actual object. It should also account for Arrays, which I believe lead to a similar situation.\nI have the following workaround:\n``` javascript\nRequestBase.prototype.send = function(data){\n  var obj = isObject(data);\n  var type = this._header['content-type'];\nif (obj && data.constructor === Object) {\n    this._data = this._data || {}\n  } else if (obj && data.constructor === Array) {\n    this._data = this._data || []\n  }\n// ...\n```\nobj is true for Arrays which leads to the error you mentioned. So I had to add data.constructor part. I'm on the fence with putting this logic here. What do you think?\n. 1. I wanted to keep consistency because of data.constructor === Object but I can switch it to Array.isArray\n2. I'm not sure I'm getting your question but obj refers to data not being falsy, not this._data. There are times where this._data is initialized and it avoids overriding it.\n. I agree with you with the constructor check. I pushed a version following your suggestion but it's failing for buffer object data.\nI can check for the content-type, since it's only really an issue with JSON, right? Or use the uglier constructor check which doesn't seem to cause these issues.\n. I updated to explicitly look for an object. Not sure if it's the correct way, but seems better than to use a constructor check.\n. ",
    "a-ludi": "It would be nice to have some way of providing the passphrase for the cert/key file. ATM I can't prepare a PR myself, so I am writing at this place, hoping one of you guys can do that.. ",
    "oprogramador": "I think it's an essential example and it should be in README.md (at least query).\n. @pornel I updated this PR.\n. ",
    "delenius": "Hmm, as I understand it, my problem has nothing to do with CORS. I just want to return cookies that I get from previous server responses.\nMy Java server uses J2EE @SessionScoped bean classes. This is supposed to automatically instantiate one bean per \"session\". The sessions are handled by the server sending the client a cookie (this is done automatically by the J2EE app server), and the client returning the same cookie in subsequent requests.\nSo, how can I return cookies from Node.js?\n. It is the same as the problem discussed here: http://stackoverflow.com/questions/15485073/how-to-use-cdi-sessionscoped-without-a-http-session\n. Interesting. Does Agent have all the methods that Request does, like setting accept headers, end(), and so on?\nAnd will this also work in a browser setting?\n. I got this to work. In the browser, I still use withCredentials, since the browser version of superagent does not have a .agent field.\n. ",
    "evgenosiptsov": "I have solved same in another way. \nFor ExpressJS if we use cookie-parser midlleware\nconst cookies = querystring.stringify(req.cookies, '; ', '=');, - cookies variable will contain value for passing it into superagent's setting header methods like a superagent.get('/userinfo').set('Cookie', cookies).then((res) => { ... }).\nSo i hope, it will be useful. \nUDT: In my case i'm sending session data via static methods for Redux architecture (look like a static componentWillFetchData(props, dispatch, cookies) {..}, you know ). Works great in universal apps.. ",
    "hovissimo": "In case it's not obvious, file in the first snippet is the object that comes out of a form, and it looks like \n\n. I went with a different technology and I no longer have the code to exercise this.  I'll update this ticket if I get another chance to try superagent.. ",
    "igghera": "I'm getting \"formData.once is not a function\"\nThis is the culprit:\nRequest.prototype._getFormData = function() {\n  if (!this._formData) {\n    this._formData = new FormData();\n    this._formData.once('error', function(err) {\n      this.emit('error', err);\n      this.abort();\n    }.bind(this));\n  }\n  return this._formData;\n};\nI'm using superagent@next.\nAny idea?. ",
    "DavidIAm": "...are you suggesting that the use case of sending a multipart response with some form feilds and some file attachments is one for which there is so little utility that the superagent should not allow it? I am confused because not only is this is a legal and supported by traditional user agents form of multipart message ( part as www form data, another part as a file content ) but some file put apis absolutely require this in order to work, sending metadata in the form fields along with the file. We will not be able to replicate the beahavior of a normal web browser file submit if we cannot include form fields in the upload!\n. Ah, very good then.\n. ",
    "AlexKvazos": "Oh okay thanks, I was using 2.3.0. I guess I can close the issue for now, because I am not using 3.x at the moment.\n. ",
    "dciccale": "OK i found the problem, and has nothing to do with superagent feel free to close. However after explaining it here I know it won't make any sense such weird behavior.\nThere is a module which I export a plain object.\nI was requiring this module and using an undefined key because of a typo. since I was passing this function (which is undefined because of the typo) to the catch promise chain of bluebird, there was no error at all anywhere, but somehow this was affecting receiving all the data in the request 'data' event (I logged every output of the chunk and it was coming cut by 1 char the last }). I do not have full understanding of the whole thing but I am 100% sure this was the problem because by just commenting this out I can reproduce the issue, just by commenting that one catch that looks like this\n.catch(loginErrors.AuthenticationError, errorHandlers.sendUnauthorized(res))\nwhere loginErrors.AuthenticationError is undefined.\nEDIT actually was not undefined, but loginErrors was undefined, so trying to access AuthenticationError property from undefined basically should have failed. I tried this again inside my controller, let something; something.whatever and it does not fail! (and it should) I think there must be some catch at ~~express router level which is hiding this error, or at~~ mocha level, because it does fail the test but is not showing why, but when trying it by starting the server and doing a POST request through Postman, it does fail TypeError: Cannot read property 'whatever' of undefined\njust commenting that line makes it work. of course now I fixed the typo and no need to comment it.\nthanks for driving me on a direction which allowed me to find this :)\nESLint basically have no way to know I was passing an undefined value into a catch promise chain which was not being called anyway.. but beneath the dungeons some check in bluebird would have thrown an error in the middle of the request, who knows ;). I know, I'm using node7, but was not getting the unhandled rejection because the error may happened outside the promise chain which I guess it should have failed also in some way or another but yeah I have no clue of what exactly happened a part from my previous description. And apart from the error I stated there was no other.. ",
    "Azard": "@pornel But how can I get the GET response data in async/await model ?. @pornel Thank you, it's OK \ud83d\ude03 . ",
    "manosim": "@pornel Agreed and thank you for your quick reply! For any future reference the way to fix this is:\nInstall Base64 (note the capital B) from npm:\nnpm install --save Base64\n\nThen in your code before requiring superagent do:\nwindow.btoa = require('Base64').btoa;\n\n. ",
    "nshahpazov": "I'm not using supertest. It's like it's slicing the last closing curly brace. This is what get as a stack.\n{ SyntaxError: Unexpected end of JSON input\n    at JSON.parse ()\n    at IncomingMessage. (/Users/nikolashahpazov/projects/volontime-api/node_modules/superagent/lib/node/parsers/json.js:8:35)\n    at emitNone (events.js:91:20)\n    at IncomingMessage.emit (events.js:185:7)\n    at endReadableNT (_stream_readable.js:974:12)\n    at _combinedTickCallback (internal/process/next_tick.js:74:11)\n    at process._tickCallback (internal/process/next_tick.js:98:9)\n  rawResponse: '{\"message\":\"Missing fields\",\"errors\":[{\"message\":\"name cannot be null\",\"path\":\"name\"},{\"message\":\"type cannot be null\",\"path\":\"type\"},{\"message\":\"overview cannot be null\",\"path\":\"overview\"}]',\n  statusCode: 400,\n  response: undefined }\n. I have tracked where the problem is. It seems to be in a dependency I'm using on the server - express-session which slices the length by 1.\nhttps://github.com/expressjs/session/issues/395\nFeel free to close the issue here :). ",
    "abhagupta": "Thanks @focusaurus . Above worked but we are using superagent extensively and using this code would require changes at multiple places with not very clean solution. Is there a way the http.agent  can be easily set on the underlying http object cleanly? Something that happens in request npm.  I can debug superagent myself and send a PR if you can give me some pointers. . Thanks @focusaurus . I will explore this as well.  However, what I am really trying to do is making use of http.globalAgent, override it with my proxy agent, and pass it to the superagent  something like this \n```\nvar http = require('http');\nvar HttpProxyAgent = require('http-proxy-agent');\nmodule.exports = myAgent = http.globalAgent =  new HttpProxyAgent('http://127.0.0.1:8442');\nvar options = {\n    host: 'www.google.com',\n    port: 80,\n    path: '/index.html',\n    agent: myAgent\n};\nhttp.get(options, function( res){\n    res.on(\"data\", function(chunk){\n        console.log('BODY: ' + chunk);\n})\n\n})\n```\nIf superagent has an option to pass along an agent object to request, I will have to do just one change. \nThe result that I am expecting is, if I encapsulate my application by an outer module which sets globalAgent and run both in same  process (like node index.js myapplication )  then all http requests going out in my application will have the myAgent which should make it go through the proxy running at http://127.0.0.1:8442. Is it something feasible at all?  . ",
    "pszabop": "@pornel cross-request customizability would be very nice.  For example, need to be able to add to every request a JWT header, an CSRF header, etc..  A hook in in superagent.agent() would be very nice for doing that.. well, one of the CSRF solutions involves copying a token from a  cookie (or local storage) to a header on every request.  Having to call .set() on every request and figuring out a place to store the token while I\"m passing around references to the agent to helper functions is proving problematic.  Have to support nodejs and browser.... 1.  have to use supertest because simply passing the expressjs app to your agent function doesn't work.  I'm not using supertest for any other feature except for that.\n1.  supertest won't accept your plugins.  Well, at least they won't accept supertest-use which is the one I want.\n1.  If I could get supertest-use to work, I don't know how to access the cookie jar in the agent. . leaving aside supertest, how would you access the agent's nodejs cookie jar inside of the use() callback?   Are the cookies on the request structure?. Yes, I saw the cookie code.  Was hoping to not have to rewrite it all.\nI'm kind of flummoxed.   CSRF is at least an 8 year old problem, yet AFAICT AngularJS is the only agent out there that has native support for putting a cookie into a header in a natural fashion.   (natural, meaning, as natural as cookies are added currently by superagent.agent() )\nEverything else appears to be extremely awkward.  I'm passing handles to a supergent.agent() around and the cookies currently go with them.  I'd have to modify all my functions to accept a cookie jar handle, or keep a global cookie jar around separately instead of in the agent, or ???.  That doesn't seem like the right way to do things.... agreed, I want to put the cookies into (result of superagent.agent() and then put those cookies into the headers Authorization or X-CSRF on all outbound HTTP requests.. > Superagent doesn't have any control over CORS.\nYet it works with XMLHttpAgent...   I cross checked the headers using devtools and I cannot tell the difference between the two.  The set of fields present is the same.  The contents of the fields are trivially different.\n\nand .attach\n\nattach works in a browser?\nI see the mistake above but that should not have affected the OPTIONS request.  The mistake is in the body, which would have gotten to if the OPTIONS request had not failed...   Maybe the error is actually the mistake in the creation of the body and I'm getting an inappropriate error message?. I have confirmed that generating headers or body that the browser doesn't like will generate the same CORS error.  You can close this bug unless you can figure out a better error message.  This is a useful thread to keep around as a programming mistake could result in the same confusing message.\n(example code above on how to generate a confusing error message :-)\nThe code below returns a 200/OK on the OPTIONS preflight.  Note I still get a 403 from minio on the POST but that's not a CORS issue, I probably still have a bug, and is unrelated to this issue.\nconst uploadForm = JSON.parse(uploadTicket.uploadForm);\nconst req        = httpAgent.post(uploadTicket.uploadLink);\n\n\nconst formData = new FormData();\n_.each(uploadForm, (value, key) => {      formData.append(key, value);\n}); \nformData.append(file.name, file);\n req\n.set('Content-Type', 'application/octet-stream')\n.send(formData)\n.then(res => {\n\n. Working code.  I should add that this link here is providing outdated information and needs to be corrected.  I suggest reporting in your documentation that .attach() works in a browser now.\nconst uploadForm = JSON.parse(uploadTicket.uploadForm);\nconst req        = httpAgent.post(uploadTicket.uploadLink);\n\n_.each(uploadForm, (value, key) => {\n  req.field(key, value);\n});\n\nreq\n.attach('file', file)\n.then(res => {\n\n. FYI, the host check is too strict because you are supposed to check for \"domain or subdomain\".  superagent just checks to see if the host is different, it doesn't check to see if it is a valid subdomain.\nI don't have anything that breaks because of this right now but FYI here to someone who this might break.\nSee supposedly more correct example here. ",
    "ilnurYalal": "Oh, I got it.\nThanks very much!! it works now. ",
    "hepiyellow": "Great. \nThe ok() function would work. \nToo bad though that chaiHttp uses superagent 2.x..x\n\nOn 2016. Dec 16., at 22:17, Kornel notifications@github.com wrote:\nI wouldn't call it inventing. By default superagent treats status 2xx as success, and everything else as error. That's mostly in line with intentions of the http spec.\nNote that in most cases there's err.response if you want to read content of error pages.\nIn the latest version there's .ok() function for customizing which responses are treated as errors.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "ORESoftware": "Ok hmmm, but somehow this library tells Node.js to use an emphemeral port instead of a specific designated port. Or is it simply that if no port is given that Node.js will by default find an emphemeral port?\nok I think I figured it out, if you don't specify a port, Node.js will find an ephemeral port\n```js\nconst net = require('net');\nconst server = net.createServer((c) => {\n    // 'connection' listener\n    console.log('client connected');\n    c.on('end', () => {\n        console.log('client disconnected');\n    });\n    c.write('hello\\r\\n');\n    c.pipe(c);\n});\nserver.on('error', (err) => {\n    throw err;\n});\nserver.listen((data) => {\n    console.log('server bound ', data);\n});\nserver.on('listening', function(data){\n    console.log('server address => ', server.address())\n});\n```\nthanks for the info!. well, actually, I should have asked, in the \"browser version\", how does this work with emphemeral ports?. alright :) thanks. ",
    "ttbarnes": "Thanks @pornel ,  \nThe JWT used in the header is definitely valid. No syntax errors on the server side. \nThis error only occurs in test environment. Other GET endpoints that do not require a Authorization header work fine.\nI've tried using axios instead and I get exactly the same issue. Therefore this must be something to do with my setup. I suspect i'm missing something silly/obvious - still learning some node things. Any help would be great, i'll update here regardless.\nI don't understand how simply adding an authorization header would cause the connection to close and not get any response.\nI've enabled the server logs and it doesn't even seem to be sending a request, just instant 'socket hang up', with superagent and axios. . You're right @focusaurus  :) The auth check for this particular endpoint uses node passport. Within my tests using superagent, the endpoint is not getting past the passport check part:\nThe code:\nrouter.route('/private')\n  .get(\n    passport.authenticate('jwt', { session: false }), (req, res, next) => {\n      res.json({ allTheThings: true });\n  })\nWorks fine in dev environment.  Still looking, will update.. Sorry guys - this is nothing to do with superagent. This seems to be a bug with passport-jwt (auth GET requests are not getting past passport auth) Thanks all the same! :). ",
    "Kufert": "to answer my own q - \ne.response #<-- response. ",
    "liesislukas": "it is undefined because response = await request.post(url) assigment never happens on error and in 1st line you have created response variable with value undefined, which is logged.. @pornel yep, that's what I proposed for my team, JSON.stringify is actually the only method I see here to attach object-like thing. . ",
    "Glutch": "@pornel So theres literally no way i can use the same boundary in my payload as my header?\nIf no, can i use some other framework to accomplish this?. @pornel Okey, so theres still a chance! Can you send images with .send()? :) (if so how?). @pornel I'm trying to upload a picture to a website (not mine), i've checked the network requests and i need to provide the image and a payload. \nThe payload consists of information regarding the image, like this\n------WebKitFormBoundaryKWf3FhTClwfaDpre\nContent-Disposition: form-data; name=\"image\"; filename=\"2684337397.jpg\"\nContent-Type: image/jpeg\nAnd the content-type (WebKitFormBoundaryKWf3FhTClwfaDpre) must match. I'm not sure how to do it. @pornel The payload also consists of eventvalidation and some viewstate string, so it seems to be required (using only attach doesn't work). Is the server expecting .attach(\"image\", image, \"2684337397.jpg\") to be something specific? If so, how can i figure that out?. @pornel I just got it working, thank you a lot!\nI've got a new, simpler problem. i'm sending some text via .send(), the site uses charset ISO-8859-1. I tried setting the charset with\nconst charset = require('superagent-charset')\ncharset(request)\n.charset('ISO-8859-1')\nThis has worked previously when reading the response. But when i'm sending, the text coming up on the site is encoded weirdly. \u00e5 showing up as \u00c3\u00a5 etc. Is there a specific method of setting the charset of .send()?\nShould i make a new issue for this?\nThanks a lot. @pornel Havent managed to solve it yet :(\nI'm sending a payload like this\n``\nconst payload =------WebKitFormBoundaryBkSiVoOiTVrsXXjp\nContent-Disposition: form-data; name=\"something\"\nHey!\n------WebKitFormBoundaryBkSiVoOiTVrsXXjp\nContent-Disposition: form-data; name=\"something else\"\nHow you doin? \u00c5\u00c4\u00d6\n------WebKitFormBoundaryBkSiVoOiTVrsXXjp--`\nuser\n    .post('http://url')\n    .send(payload)\n```\nAny new ideas or tips would be greatly appreciated. ",
    "lyykfi": "Yes )\nI am building smart TV project with webpack. ",
    "nwwells": "I would gladly help with a PR. Also, I'd like to suggest that using pipe on the response object from end should throw an error. Fail fast and all that.. @pornel how do I build the docs?. Should be closed by #1315. ",
    "libHive": ":ok: \nWe'll keep working on making the examples more useful - challenge accepted ;)\n:tophat: Thanks for the awesome feedback !. Hi @pornel \nI revised the scoring algo so the examples are a bit more \"lush\".\nMaybe you could reconsider ? :blush:\nThanks . Thanks ! This is some priceless feedback.\nI'll keep working on it :hammer_and_wrench: . ",
    "JeffML": "Here is a full test:\ncookieTest.js\n```\nvar login = require('./login2.js');\nvar chai = require('chai');\nvar should = chai.should();\nvar server = process.env.SERVER_UNDER_TEST;\nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = 0;\nvar prefix = require('superagent-prefix')(server);\nvar request = require('superagent').agent();\ndescribe(\"Cookie Test\", () => {\n    it(\"test1\", done => {\n        login.testSite(request, prefix, (res) => {\n            should.exist(res.headers['set-cookie']);\n            done();\n        });\n    });\nit(\"test2\", done => {\n    login.testSite(request, prefix, (res) => {\n        should.not.exist(res.headers['set-cookie']);\n        done();\n    });\n});\n\n});\nlogin2.js\nvar chai = require('chai');\nvar should = chai.should();\nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = 0;\nexports.testSite = (agent, prefix, done) => {\n    agent.get('/')\n        .use(prefix)\n        .type('json')\n        .end(function(err, res) {\n            if (err) {\n                throw err;\n            }\n        res.ok.should.be.ok;\n\n        done(res);\n    });\n\n};\ndependencies:\n  \"dependencies\": {\n    \"chai\": \"^3.5.0\",\n    \"lodash\": \"^4.17.4\",\n    \"supertest\": \"^2.0.1\"\n  },\n  \"devDependencies\": {\n    \"eslint\": \"^3.14.1\",\n    \"mochawesome\": \"^2.0.2\"\n  }\n```\nmocha installed globally\nRun: SERVER_UNDER_TEST=https://www.yahoo.com mocha cookieTest\n. Hmmm.  Rechecking my dependencies, I have:\n```\njeff.l@Jeffs-MacBook-Pro:~/Documents/workspace/unit-tests/mocha-chai_tests (master *=)$ npm ls -depth 0\nmocha-chai_tests@1.0.0 /Users/jeff.l/Documents/workspace/unit-tests/mocha-chai_tests\n\u251c\u2500\u2500 chai@3.5.0\n\u251c\u2500\u2500 eslint@3.14.1\n\u251c\u2500\u2500 lodash@4.17.4\n\u251c\u2500\u2500 mochawesome@2.0.2\n\u251c\u2500\u2500 shrinkwrap@0.4.0 extraneous\n\u251c\u2500\u2500 superagent@3.4.0 extraneous\n\u251c\u2500\u2500 superagent-prefix@0.0.2 extraneous\n\u2514\u2500\u2500 supertest@2.0.1\n```\n$ SERVER_UNDER_TEST=https://www.yahoo.com mocha cookieTest\nCookie Test\n    \u2713 test1 (701ms)\n    1) test2\n1 passing (1s)\n  1 failing\n. I can provide you with the network log. That might help.\n. ## First \nrequest:\nGET / HTTP/1.1\nHost: www.yahoo.com\nAccept-Encoding: gzip, deflate\nUser-Agent: node-superagent/3.4.0\nContent-Type: application/json\nConnection: close\nresponse:\nHTTP/1.1 200 OK\nExpires: -1\nCache-Control: no-store, no-cache, private, max-age=0\nServer: ATS\nVia: http/1.1 ir5.fp.gq1.yahoo.com (ApacheTrafficServer)\nConnection: close\nTransfer-Encoding: chunked\nAge: 0\nContent-Type: text/html; charset=UTF-8\nContent-Encoding: gzip\nVary: Accept-Encoding\nSet-Cookie: autorf=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT; path=/; domain=www.yahoo.com\nX-Frame-Options: DENY\nStrict-Transport-Security: max-age=2592000\nP3P: policyref=\"https://policies.yahoo.com/w3c/p3p.xml\", CP=\"CAO DSP COR CUR ADM DEV TAI PSA PSD IVAi IVDi CONi TELo OTPi OUR DELi SAMi OTRi UNRi PUBi IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC GOV\"\nDate: Fri, 27 Jan 2017 21:30:42 GMT\nsecond:\nrequest:\nGET / HTTP/1.1\nHost: www.yahoo.com\nAccept-Encoding: gzip, deflate\nUser-Agent: node-superagent/3.4.0\nContent-Type: application/json\nConnection: close\nresponse:\nHTTP/1.1 200 OK\nExpires: -1\nCache-Control: no-store, no-cache, private, max-age=0\nServer: ATS\nVia: http/1.1 ir12.fp.gq1.yahoo.com (ApacheTrafficServer)\nConnection: close\nTransfer-Encoding: chunked\nAge: 0\nContent-Type: text/html; charset=UTF-8\nContent-Encoding: gzip\nVary: Accept-Encoding\nSet-Cookie: autorf=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT; path=/; domain=www.yahoo.com\nX-Frame-Options: DENY\nStrict-Transport-Security: max-age=2592000\nP3P: policyref=\"https://policies.yahoo.com/w3c/p3p.xml\", CP=\"CAO DSP COR CUR ADM DEV TAI PSA PSD IVAi IVDi CONi TELo OTPi OUR DELi SAMi OTRi UNRi PUBi IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC GOV\"\nDate: Fri, 27 Jan 2017 21:36:35 GMT\n. Alright, trying again;  this time SERVER_UNDER_TEST=https://www.mavericklabel.com/reskin/xml/headers.php mocha cookieTest\nI'm wondering if the expires data (Nov. 19, 1981) is being interpreted as applying to the cookie as well as the rest of the response? I believe that should only apply to the response body (although the past date suggests a config issue).  There's no expires date on the cookie, so it should be maintained for the session....browsers are treating the cookie this way.\nfirst request:\nGET /reskin/xml/headers.php/ HTTP/1.1\nHost: www.mavericklabel.com\nAccept-Encoding: gzip, deflate\nUser-Agent: node-superagent/3.4.0\nContent-Type: application/json\nConnection: close\nfirst response:\nHTTP/1.1 200 OK\nConnection: close\nContent-Length: 145\nContent-Encoding: gzip\nVary: Accept-Encoding,User-Agent\nset-cookie: PHPSESSID=5a6857299af944ebc047e6d38efc4b25ee5f66f6; path=/; domain=.mavericklabel.com\ncontent-type: application/json\npragma: no-cache\ncache-control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nexpires: Thu, 19 Nov 1981 08:52:00 GMT\nAccess-Control-Allow-Methods: GET,POST,PUT,DELETE,OPTIONS\naccess-control-allow-origin: *\nX-Powered-By: Express\nServer: Apache/2.2.15\nDate: Fri, 27 Jan 2017 22:31:54 GMT\nsecond request:\nAccept-Encoding:gzip, deflate\nContent-Type:application/json\nHost:www.mavericklabel.com\nUser-Agent:node-superagent/3.4.0\nsecond response:\nHTTP/1.1 200 OK\nConnection: close\nContent-Length: 144\nContent-Encoding: gzip\nVary: Accept-Encoding,User-Agent\nset-cookie: PHPSESSID=08e8314d1e5eef0e67d002beb9230b136536f6eb; path=/; domain=.mavericklabel.com\ncontent-type: application/json\npragma: no-cache\ncache-control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nexpires: Thu, 19 Nov 1981 08:52:00 GMT\nAccess-Control-Allow-Methods: GET,POST,PUT,DELETE,OPTIONS\naccess-control-allow-origin: *\nX-Powered-By: Express\nServer: Apache/2.2.15\nDate: Fri, 27 Jan 2017 22:34:46 GMT\n. I'm using superagent-prefix, which I assumed prefixed the server name to the get path. However, if I don't use superagent-prefix and specify the full path (https://www.mavericklabel.com/reskin/xml/headers.php), then the test passes.  Alright, good enough.  Thanks.. ",
    "jdmswong": "works:\nconst request = superagent['post'](url);\nrequest.send({test: 'HELLO!'})\n....\napp.use(bodyParser.json());\napp.post(url, (req, res) => { console.log(req.body) }\ndoesn't work:\nconst request = superagent['get'](url);\nrequest.send({test: 'HELLO!'})\n....\napp.use(bodyParser.json());\napp.get(url, (req, res) => { console.log(req.body) }\nnode v6.9.4\nsuperagent@3.4.0 . Also works when I call \ncurl --header \"Content-Type: application/json\" -XGET <url> -d <json>\nso the error is not on the receiving side, it's on the sending side. ",
    "alphashuro": "But it is supported, and up to the server to define the semantics of the payload, so what is the harm in supporting it in superagent?. Thank you. ",
    "refaelos": "Oh... I didn't know that's possible.\nDo you have a full example with request.get(...)... ?. Thanks. ",
    "IlyaSemenov": "Is there anything that prevents finally to be implemented?\nOn client side, this is a very common use case to prevent double submit:\njs\nthis.submitting = true\nconst { text } = await agent.get(url).finally(() => { this.submitting = false })\naxios supports that, and having to type twice the code with superagent is frustrating.. All right, I came up with the ad hoc plugin:\njs\nconst agent = superagent\n  .agent()\n  .use(function(request) {\n    request.finally = function(fn) {\n      return Promise.resolve(this).finally(fn)\n    }\n    return request\n  })\nStill I don't see any harm in landing this in the core.. No, it's not. In your example, res is not accessible outside of the try block, and if the processing code goes inside try after await, then finally will be called too late.\nOf course it can avoided by using let res outside of try/finally but then res becomes mutable for no reason.\nThere is no decent alternative to promise.finally for this scenario.. No, that's not logical, because the original example intentionally does NOT handle errors, therefore, res will always exist:\njs\nthis.submitting = true\nconst res = await agent.get(url).finally(() => { this.submitting = false })\n// Further processing.\n// res is guaranteed to exist and it is immutable!\nYour supposed 'replacement' is invalid:\njs\ntry {\n   const res = await superagent.get(url);\n   // If processing goes here, finally will be called too late.\n} finally {\n   finally_works();\n}\n// If processing goes here, res is not be accessible.\nreplacing const with let makes the response mutable:\njs\nlet res\ntry {\n   res = await superagent.get(url);\n} finally {\n   finally_works();\n}\n// res is undesirably mutable. the developer may write:\n// res = 'bazinga'\nbesides, the code becomes twice as long.. In any case, the current implementation is plain wrong regarding its own type definitions. The return type is advertised to be Promise<Response>:\nhttps://github.com/DefinitelyTyped/DefinitelyTyped/blob/1e39558ee2231ad3df45859b81031da4d6425042/types/superagent/index.d.ts#L120\nts\n    interface Request extends Promise<Response> {\nand Promises are officially supposed to have then, catch, and finally:\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise#Methods_2. ",
    "romanlex": "why topic is closed? I can confirm this. Cannot set cookie from server. ",
    "indapublic": "@romanlex I'm using fetch now. ",
    "khayalan-mathew": "Sorry if i misunderstood anything, but im building it with webpack and run the result in a browser (Chrome to be exact). Can it be that the cross-env package is the \"fail\"?. Fixed it :) Deactivated ServerSide Rendering ^^ Thanks for the help. ",
    "foxpsd": "Hello :)\n@pornel  want to ask how to configure webpack to produce a code for Node?\nreally confused~\nThanks for the help in advance. ",
    "damoclark": "Hey @pornel \nThat's a good point.  Merging the headers makes sense if a Cookies header already exists.  \nI can change the PR to merge the headers.\nBut my knowledge of the complete superagent code-base is obviously lacking.  Is there code to parse stringified cookies request header back into an object that already exists in superagent?  I can't seem to find anything, but just checking.\nOtherwise, I have two suggestions for your input: \n1.  Add another library dependency to superagent that does this, or\n2. Use a regex to parse myself\nI'm thinking option 1 would be better, but are you guys happy with adding another dependency to the project?\nI did a search on npmjs and found strict-cookie-parser which looks like it will fit the bill nicely.  It doesn't have many downloads, but then I'm thinking this is an uncommon task.\nWould you like me to proceed with option 1 with this library?  Or is there a smarter way to go about it?\nBy the way, thanks to you and your team for superagent. :1st_place_medal: \nD.\n. Hi again @pornel \nNevermind about my last comment.  I found a way of merging the cookies using existing libraries.\nWhat do you think?\nD.. I understand.  But the reason I used the library was to merge any duplicate cookies names, so when a new Cookie request header was generated from the temporary cookiejar, there would be no duplicates.  \nDoes it not matter if a cookie name and value pair appear twice in the Cookie request header?\nIf this doesn't matter, which will override the other?  Cookies with a matching name that comes first, or last?\nD.. No worries.  Happy to do that.\nD.. ",
    "amurph491": "That's a good thought - ideally, i think it would be nice to see why the requests failed before retrying and potentially succeeding, but at least including the number of retries on the res object would allow some level of investigation/reporting on requests that are needing to be retried. Totally agree - I like the idea of having the option to add some finer control over the retries for certain requests and responses. To start at least, I think it'd be sufficient to leave this retry logic up to the user, but at least provide this callback option to allow aborting a sequence of retries, introducing delays, or any other logic that may suit specific uses. I'm happy to build this into this PR, there would need to be some consensus on what the passed in callback function should return (like you mention, a promise, a superagent request, or a boolean). ",
    "ryanhugh": "Any update on this? I would totally use the features @pornel is talking about if they were live right now :). ",
    "peebles": "me too. ",
    "gerhardsletten": "Have submitted a PR #1180 . ",
    "F-loat": "superagent-use. ",
    "niftynei": "Update: buffering the response with req.buffer(true) triggers using the text.js parser and works fine for my purposes.. huh. that's in contradiction to the stated purpose of the deadline timeout.  better documentation around MIME-type buffering and the impact of buffering on other flags would be really helpful.. closing this, as it's not really an issue.. ",
    "skeggse": "yes, please!. ",
    "andrija-hers": "@focusaurus , sorry for this, I wouldn't have sent the PR if I had recognized these failures. Obviously, I was unaware of how to run tests - simple mocha call succeeded on my side (node 6.5.0, 165 passing in 17s). If that's not a problem for you, when you find time, please let me know about the steps needed to run all the tests.. npm test, silly me...\nWe'll be back with all the issues covered :). @pornel , many thanks for spending your time on my case :)\nHowever, image-resolver is already taken care of (by me again :| ), and that particular line you're referring to is already covered (among several other \"leaky\" lines).\nOn the other side, regarding the very garbage manipulation, we learned a very important lesson. Here's the situation:\n\non our server we use a single process for the whole server\nour server does a lot of stuff, one of them being the image resolving\nthe whole result of image resolving is a single string; but, in order to produce a string that will be stored in memory, up to 1e4 temporary objects might be produced\n\nThe case described above stabilizes at around 300 MB.\nThen we \"split\" the server process into \n1. the main server process\n2. the image resolver child process\nThe important thing with this setup is that the child process stores nothing, just reports the resolved string back to the parent process.\nWe ended up in the parent process taking up <70MB and the child process swinging wildly in the (60, 250) MB range, but for most of the time taking under 100MB.\nThe reason is that frequently a small number of long-living objects might find themself in a memory chunk full of garbage. These useful objects keep the whole chunk from being free-d.\nMoral of the story: whenever possible, \"outsource\" a \"pollution-intensive\" job to a separate process that will produce no long-living objects.\nFinally, our tests have shown that superagent is working perfectly with no interventions, and the image-resolver really needed memleak cleaning + additional options for avoiding the cache-ing and utilizing the timeout feature of Response.\nGuys, many thanks for the great work on superagent! There will be no PRs from our side regarding memory handling :). ",
    "danielpgross": "\nThe closure uses reference to the Request, which stays the same for lifetime of the request\n\nThis is exactly my point -- why check the value of self._aborted if it will always be undefined/false? That looks to me like a bug. It seems that the intent was to return in case abort() was called and therefore request._aborted == true, but this is not the actual behaviour.\nIndeed the test validates the basic functionality, but it does not check whether crossDomainError() is invoked.. Never mind, I dove deeper into this and determined that it's actually being caused by my wrong usage. I am using it with React, storing the Request object in my component state. Between state changes, I was deep cloning the Request object. I was seeing this behaviour because self was referring to the original object (pre-cloning), while ._aborted = true was being set on the new/cloned object.\nLesson learned, deep clones of the Request object will not work properly.\nMy attempted reproduction here confirmed that this was my bug, not superagent's bug.\nSorry for the confusion and thanks for your help.. ",
    "mwolson": "Fixed in acaf84d. Added some docs for .retry() as well, since I noticed they were missing.. ",
    "selenium-tester": "May I ask why this is the case? I'm still learning how to use this, and I guess maybe the promise docs aren't super clear because with supertest we can, for example:\nawait request\n        .get(url)\n        .set(headers)\n        .then((response) =>\n        {\n            t.is(response.status, 404);\n        })\nI'm using Ava in my case for assertions within the .then(...). Errors and assertion failures will be caught and reported. I didn't realize this was a feature of supertest; I just switched to superagent since supertest dev seems to have stalled. Is it possible to use promises in this way directly with superagent?. ",
    "takao-akiyoshi": "hi! I use superagent 3.8.3, and I have same error...\nPlease correct me if I'm wrong.\nnew Promise((resolve, reject) => {\n    request\n        .post(url)\n        .set({'Content-Type': 'application/json', 'X-Authorization': key})\n        .send({ k: v })\n        .then(res => {\n            resolve(res.body);\n        })\n        .catch(error => {\n            reject(error);\n        });\n});. ",
    "bwidtmann": "request.get('http://www.google.com?bla=1&blup=1).retry(1)\nthe first request is ok, the second request would be:\nhttp://www.google.com?bla=1&blup=1&bla=1&blup=1\nyou know what I mean?. ",
    "dinkom": "@pornel When I try that, I get a 500.. Unfortunately, that didn't do it (tried both with content-type header and without it, getting same responses as without .attach(...)). There must be something missing in my request that is maybe related to the API itself. I'll investigate more today. In case you have other suggestion regarding what I can try with superagent, please share.. Finally solved this, my clients had an API error they were not aware of... sorry for the trouble.. Thanks!\ntodayilearned.",
    "WeIio": "@pornel   Thanks for your answer so quickly, i have figured out how made this.\nBecause ios security policy require  https  rather than http , so http will be prevented and this will cause superagent to show cross domain error.\nThanks anyway again. ",
    "shwanton": "\ud83d\udc4d \nWould be great to see all query params with DEBUG=superagent. ",
    "talaevlev": "And what should I do?\nI have only self-signed certificate for tests.\n. ",
    "Bluscream": "I would like to see such a option too. Some people route their SSL traffic to software like Adguard which uses it's own cert validation so node does not need to take care of that.. ",
    "runhwguo": "yeah\uff0ci get it\uff0cthank you. ",
    "FlorianWendelborn": "Same here. Have you found any workaround/fix @OmgImAlexis?\nEDIT: Turns out my issue is different. It was in a project that's basically a proxy-server and forwards all headers to the server. Turns out it also blindly forwarded Content-Length, which means that the server didn't understand that the request is over and therefore timed out waiting for the body.\nResolved by deleting headers['content-length'].. My issue was with superagent directly, but I suppose that doesn't matter anymore as it's arguably user-fault.. ",
    "qiangzi7723": "I have a same problem. I get a bug in my code and check for a long time. At last I found that superagent do not send my post body to the server. I don't know why and don't know how to solve it. I try to change to another library and it seems to be work. It is my code\nagent.post(url)\n    .send('encSecKey=xxx')\n    .send('params=xxx')\n    .end((err,res)=>{\n        console.log(res);\n    })\nIn the response, the body and text are all empty and I found that the request body did not send to the server.\n. @pornel I am so sorry to tell you it doesn't work. The response body and text still null.\n                    .send('encSecKey=2af4ca51b906def2e80755a34450db64e8a34f038ffa7ee66ae4c50fbaacc785eddcc1a63222928af3814c355f20b7f8d4e4b05f26879087acd1f8a4da79adaa4a59e3efb54c135017d7f94f7514603e208b0178f547f436c9ca11a3f45e27876c81c3f0a5d3a82854b9d39fdee0ac1b16ecd23503908595fc48359e0811f6d6&params=DQU/eyfHyqpTa40dLoNsxkRxCEmEsIgzAgKEYce7d5o78+o4DrdquhuTE5/h5PWqI027kSWd4Y1c9/h6mQFX8J9KiGI0zhV7hb6F7JzXjmg2wtky3SXDoXDn2IYKQnoF4mSXfjGtJdL9kA0KmJvNow==')\n. ",
    "ramsestom": "react-native doesn't package superagent by default. As any other package, you have to install it with npm -i superagent --save. (so it would be the node.js version of superagent that would be installed). Now the real question is: is the node.js version of superagent compatible with react-native? And this question remains open as it seems that many people have issue making them work together.... (but maybe these issues have been fixed now). ",
    "michaelroevievictoria": "any update with this ?. ",
    "danielfloyd": "That did it. Thanks!\nThat option that was not clear from the docs and I had supertest 2.x which pulled in superagent 2.x and so it wasn't actually an option. I upgraded to supertest 3.x and it worked.\nThanks again for the quick reply!. ",
    "enguerranws": "To be honest, I don't know :) If I can provide more information to debug this, let me know.. Hi,\nI'm not sure what you expect from me here? Switching from superagent to form-data package in node-wpapi?. ",
    "LuizSD": "thx i will fix my callback.. ",
    "meloseven": "javascript\n let req = agent.get('http:xxx/xxx');\n req.query(requestData);\n req.set('Cookie',cookie);\n req.end((err,res) => {\n       res.setEncoding('utf8');\n       response.writeHead(res.statusCode,res.statusMessage,res.headers);\n       response.write(res.text);\n       response.end();\n});\nwhen I send a request like this.The request will be redirected three times.The url of last time can not get the query string.Then I found  _data has been set null and qs has been set empty object in _redirect .So how can the last url  receive the query params?. Yes.. Thank you.. ",
    "yuanchuan": "You can  use Object.assign to merge headers conditionally.. ",
    "stoffern": "Not working as i am trying the same\n. ",
    "jameslongyoung": "Thank you for your helping and  maybe my npm and superagent version are not latest . After I update my npm and superagent version, I found the HTML of the page  is complete to me , Thank you very much!. ",
    "mikecousins": "I tried a plain XMLHttpRequest and tried Axios as well. All of them are identical.  Here is a gif that someone made to demonstrate it from: https://github.com/mzabriskie/axios/issues/593\n. ",
    "tkoenig89": "We are experiencing the same issue with XHR Progress. Just came here from google, searching for this issue.\nFrom our observations this seems like an issue with Windows (independent of browser or framework). All browsers we tested so far (Chrome, Firefox, Edge, IE 11) are jumping from 0% to 100% in a few seconds on a Windows host. The final response - upload request completed - takes until the upload is done, and the server responds. Showing 100% for a few minutes...\nOn Linux Mint we get the progress events representing the real network speed. Tested with Chrome and Firefox on Linux.\nA weird fact: The upload continues on windows, even if you close your browser. On Linux the upload stops as soon as the browser is closed.\nThis led us to conclude, that somehow Windows takes the files from the browser and handles the upload from there on. The browser thinks it has send the complete file, and waits for the response... (But we don't have any evidence for this conclusion at the moment).. ",
    "luck-zzb": "Thanks for the answer @pornel . ",
    "isaachinman": "@kornelski Is this still the case? There's no way to test stream uploads?. Do you mind explaining the reasoning behind that?. ",
    "ian-speers": "@kornelski if this is the case \u2014 would it be possible to update the documentation? I just burned an hour trying to get the Piping data example to work.. The code throws a write after end error:\n```js\nconst superagent = require('superagent');\nconst fs = require('fs');\nconst inStream = fs.createReadStream('in.json');\nconst outStream = fs.createWriteStream('out.json');\nconst request = superagent.post('https://postman-echo.com/post');\nrequest.type('json');\ninStream.pipe(request).pipe(outStream);\n```\nError: write after end\n    at write_ (_http_outgoing.js:622:15)\n    at ClientRequest.write (_http_outgoing.js:617:10)\n    at Request.write (.../node_modules/superagent/lib/node/index.js:384:14)\n    at ReadStream.ondata (_stream_readable.js:639:20)\n    at emitOne (events.js:116:13)\n    at ReadStream.emit (events.js:211:7)\n    at addChunk (_stream_readable.js:263:12)\n    at readableAddChunk (_stream_readable.js:250:11)\n    at ReadStream.Readable.push (_stream_readable.js:208:10)\n    at fs.read (fs.js:2058:12). ",
    "voiceofvega": "This was not enough. I included Access-Control-Allow-Headers=\"\" or the value of Access-Control-Request-Headers + \",X-Auth-Token\" but it failed:\n- With \"\", an error is shown in the console: content-type is not included in the response,\n- With the other (as shown below), the custom X-Auth-Token is simply not included in the request.\n`OPTIONS /myurl HTTP/1.1\nAccept: /\nOrigin: (myorigin)\nAccess-Control-Request-Method: POST\nAccess-Control-Request-Headers: content-type, accept\nAccept-Encoding: gzip, deflate\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; ASU2JS; rv:11.0) like Gecko\nHost: (myhost)\nContent-Length: 0\nConnection: Keep-Alive\nCache-Control: no-cache\nHTTP/1.1 200 OK\nDate: Fri, 16 Jun 2017 17:14:30 GMT\nServer: Apache\nAccess-Control-Allow-Origin: *\nAccess-Control-Allow-Headers: content-type, accept,X-Auth-Token\nAllow: GET, HEAD, POST, PUT, DELETE, TRACE, OPTIONS, PATCH\nContent-Length: 0\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\nPOST /myurl HTTP/1.1\nContent-Type: application/json\nAccept: application/json\nReferer: (myreferer)\nAccept-Language: fr-FR\nOrigin: (myorigin)\nAccept-Encoding: gzip, deflate\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; ASU2JS; rv:11.0) like Gecko\nHost: (myhost)\nContent-Length: 48\nConnection: Keep-Alive\nCache-Control: no-cache`. Responding with a full set of CORS headers, including Access-Control-Allow-Credentials (as described in https://www.webdavsystem.com/ajax/programming/cross_origin_requests) worked better but was not correct for all navigators.\nI stopped investigating this point, as I resorted to proxying the back-end requests (avoiding the CORS issue), so I close this issue.. ",
    "xiamengyu": "This is not add a delay for a request, this is support TCP_NODELAY  option to disable TCP Nagle algorithm.\nWe found some TCP packages are delayed  because of TCP Nagle algorithm.\nThis commit can support under layer TCP_NODELAY option to disable TCP Nagle algorithm.\n. > noDelay defaults to true \nThis means the param noDelay is true when you call setNoDelay without pass a param.\nThe same web page says 'By default TCP connections use the Nagle algorithm'. So I need a option to disable Nagle algorithm(enable TCP_NODELAY option).. Here is the source code of nodejs socket.setNoDelay():    lib/net.js\n```\nSocket.prototype.setNoDelay = function(enable) {\n  if (!this._handle) {\n    this.once('connect',\n              enable ? this.setNoDelay : () => this.setNoDelay(enable));\n    return this;\n  }\n// backwards compatibility: assume true when enable is omitted\n  if (this._handle.setNoDelay)\n    this._handle.setNoDelay(enable === undefined ? true : !!enable);\nreturn this;\n};\n. Thank you for you merged this commit and added benchmark for it. \nThe delay of  Nagle algorithm happens on some special situations,  that not always happen.\nHere is the Algorithm:\nif there is new data to send\n  if the window size >= MSS and available data is >= MSS\n    send complete MSS segment now\n  else\n    if there is unconfirmed data still in the pipe\n      enqueue data in the buffer until an acknowledge is received\n    else\n      send data immediately\n    end if\n  end if\nend if\n``\nBy the way, may be it's a good choice for user (who use **superagent**) to choose enableTCP_NODELAYor not.\nI seeTCP_NODELAYis enabled by default in **superagent** now, and user can not disable it. \nNagle's algorithm sometimes can save network resource, may be some situations need Nagle's algorithm, but user can not disableTCP_NODELAY` in superagent.. ",
    "eliprand": "@focusaurus thanks for taking the time to look at the post. You are correct. This was a very contrived example that was exhibiting the same symptoms as my more complex example and I thought I had found a smoking gun.\nMy symptoms were that the requests were getting a 404 response and not even hitting my handler (in express, debugger attached).\nAs it turns out, I had left a VM running last week that was handling the request instead. Now, why would requests made within NodeJS (using superagent or http or request) were being routed to the VM while Postman requests were being routed properly? I don't know. I turned off the VM and everything is working properly.. ",
    "oyeanuj": "@pornel @focusaurus Thank you for taking a look! I found the root issue, and the solution (in case anyone else runs into this). \nThe content boundary header added seems to be the default browser behavior whenever attaching files, or submitting a multi-part request (so, removing the content-headers above didn't matter).\nIt seems that typically webservers know how to strip that out when dealing with that upload, but not S3. S3 (and other object stores) requires the files to be uploaded as the main body/data. So, instead of the above method, the following works -\njs\nrequest.put(s3path)\n  .set('Content-Type', 'image/jpeg')\n  .set('Content-Disposition', 'inline')\n  .send(theFile)     // <--------------------------- THIS LINE instead of .attach()\n  .on('progress', updateCallback)\n  .end(success, failure)\nAt this point, the browser sends this as the main body of the request, rather than assuming it to be multipart/form-data request (which seems to be the default behavior).\nLet me know if you guys think this sort of case needs to be mentioned in the main superagent homepage somewhere as an example!. ",
    "bcepuran": "thank you @oyeanuj ! using .send is what I was missing.. ",
    "kingscott": "I was using this pattern:\n```javascript\nimport request from 'superagent';\nconst foobar = () => {\n   return request\n      .get(${URL})\n      .set({ Accept: 'application/json' })\n      .then((res, err) => {\n         if (err || !res.ok) {\n           return err;\n         }\n         return res.body.payload;\n      });\n};\n```\nThat gives me the proper payload back. When I switched the params, I would get the entire request response back (from the return err). . That'll do it. \nThanks. . ",
    "vuthuytrangfr": "video size: 326MB\n- upload 100%: \uff11\uff16m\uff1a\uff11\uff18s\n- after 14:31 s\nerror network\nprogressbar: back to 0%. thanks for the answer, I am using nginx server with ruby, react, and allow file larger than 150MB.\nDo you know what is the problem of browser/Android or how to find out the reason?. I have a problem something likes this \nhttps://github.com/rack/rack/issues/1075. ",
    "israelidanny": "I'm saving responses, which also contain the request output of toJSON(). In\nmy use case it's very useful to be able to replicate the request -\nincluding form data that was sent to it.\nWithout the FormData fields, the replayed request would not return the same response.. form-data guys have a .get() method planned (to match the browser API):\nhttps://github.com/form-data/form-data/issues/124\nHowever, it looks like that repo isn't very active nowadays. Multiple values per key isn't really that much of a problem. \nFiles are a bit of a bigger deal...\n. ",
    "p-p-m": "Found. https://github.com/visionmedia/superagent/pull/928.. ",
    "jeremyruppel": "That snippet actually results in an uncaught error; what I want is to be able to catch the error and handle it just like any other non-ok response. Here's an example using the Flickr API:\n``` js\nvar request = require('superagent');\nrequest('GET', 'https://api.flickr.com/services/rest')\n.query('method=flickr.test.echo')\n.query('nojsoncallback=1')\n.query('format=json')\n.ok(function (res) {\n  // the response will have stat: 'fail' because we haven't provided an API key\n  if (res.body.stat === 'fail') {\n    throw new Error(res.body.message);\n  }\n  return true;\n}).then(function (res) {\n  console.log('never gets called');\n}).catch(function (err) {\n  console.log('i would expect this to be called with my error');\n});\n```\n. ",
    "caicai0": "I used it for loading.\nvar loadingUrl = [];\nfunction load(url){\nloadingUrl.push(url);\n    superagent.get(url).end(function(err,res){\n        loadingUrl.remove(url);\n       //other code\n    });\n}\nwhen I used this load() function too many times for diffrent urls.I find that there are away some urls in loadingUrl.I do not know why. ",
    "rosyaniv": "Sure.\nI'm making a request to a WCF Web Service.\nThis is the error I get. The empty character after the word \"token\" is what causing all this - 0xFEFF (I replaced some specific project names and data with '...'):\n{ SyntaxError: Unexpected token \ufeff in JSON at position 0\n    at Object.parse (native)\n    at Stream.<anonymous> (/home/.../node_modules/superagent/lib/node/parsers/json.js:8:35)\n    at emitNone (events.js:86:13)\n    at Stream.emit (events.js:185:7)\n    at Unzip.<anonymous> (/home/.../node_modules/superagent/lib/node/unzip.js:53:12)\n    at emitNone (events.js:91:20)\n    at Unzip.emit (events.js:185:7)\n    at endReadableNT (_stream_readable.js:975:12)\n    at _combinedTickCallback (internal/process/next_tick.js:74:11)\n    at process._tickDomainCallback (internal/process/next_tick.js:122:9)\n  rawResponse: '\ufeff{\"Successful\":true,...\n  statusCode: 200,\n  response: undefined }. ",
    "jwgoh": "@pornel Are you say piping is an \"unsupported\" feature of superagent? ~~Yes, I don't see it in the main documentation but there are test case & test documentation for it here.~~ Edit: It is in the main documentation.\nUsing .attach() is not ideal because of the multipart form metadata that will be included as mentioned above, since I am not uploading to a web server. Is there a way around this?. > If you just want raw bytes sent, you can use .send() with a Buffer.\nYeap this would work.\nThe weird thing is that the piping works for node 0.12.7, superagent 1.2.0, but NOT for node 4.8.3, superagent 3.5.2 when the file is anything other than simple text or html files.\n```js\n// app.js\n'use strict';\nvar request = require('superagent');\nvar req = request\n  .post('https://requestb.in/example')\n  .on('response', function(res) {\n    console.log(res.status);\n    console.log(res.text);\n  })\n  .on('error', function(err) {\n    console.log(err);\n  });\nprocess.stdin.pipe(req);\n```\nbash\n$ node app.js < file.txt\n$ node app.js < example.png # Fails for node `4.8.3`, superagent `3.5.2`\nSomething must have changed in Node's Stream interface. Let me know if you can/can't reproduce the issue above.\n. ",
    "freitagbr": "Nevermind, the issue is not with superagent. The issue was that the Content-Length header was not being set correctly; bytes=10-20 is inclusive, so the Content-Length should be 11, not 10.. ",
    "cyrilchapon": "\nIn Node I think we're just passing filename as-is, so it should be work.\n\nNah in fact we're not, because of using form-data 2.1.1\nThis issue was resolved by this release(2.2.0).\nSame bug posted on request.js btw.\nA dependency update would resolve this I guess.. ",
    "MKrausSHC": "I also just ran into this problem. I'd very much appreciate a solution.\nI'm attaching multiple files and it seems they can get reordered until they are parsed on the server side (using express and formidable). Therefore i'm also having issues with supplying the path information with additional fields.. ",
    "edencorbin": "Good point, I want to say it did work on a different os/install without the extra install steps. I'll test a few more scenarios and post back when I figure out what is causing this.. ",
    "letsgolesco": "Heads up, this is blocking my company's CI builds - would appreciate a speedy fix if it's possible.\nEdit: see https://nodesecurity.io/advisories/479. This is related to https://github.com/visionmedia/superagent/issues/1259. ",
    "walshie4": "I'm in to help, breaking our builds as well (for the time being @letsgolesco you can use a .nsprc file to ignore this advisory). I'll report back with any progress.. ",
    "westy92": "To ignore for now, add the following to an .nsprc file:\njson\n{\n  \"exceptions\": [\"https://nodesecurity.io/advisories/479\"]\n}. ",
    "edmorley": "This is still showing on https://nodesecurity.io/advisories/479 as not fixed, so I've dropped them an email to update the advisory :-). ",
    "chrisfosterelli": "It's updated now \ud83c\udf89 . ",
    "quytang": "thanks @pornel . ",
    "arn-the-long-beard": "Hei.\nOkay. I added  res.set('content-type','image/png') into the server side\n```javascript\nrouter.get('/banner/admin/university/:id', (req, res) => {\n//TODO improve it\nconsole.log('--------------get the banner --------------')\nUniversity.findById(req.params.id, function (err, uni) {\nvar readstream = gfs.createReadStream({_id: uni.banner});\n\nreadstream.on(\"error\", function(err){\n  console.log(err)\n  res.send(\"No image found with that title\");\n});\n\nres.set('content-type', 'image/png')\nreadstream.pipe(res);\n\n})\n})\n```\nBut I still get the data into the res.text. How should I write superagent request to get the image ?\nBest regards,\nArn. Hey :)\nI read your answer after I succeed :\nFirst : I use server side\njavascript\n     readstream.on('close', function () {\n                 const fbuf = Buffer.concat(bufs);\n                 const base64 = fbuf.toString('base64');\n                 console.log(base64);\n                 return res.status(200).json({\n                   message: 'You have got the image',\n                   image: base64,\n                   file: file\n                 })\n               //  ss(socket).emit('file-uploaded',     base64,file);\n               });\nClient side\n```javascript\nfixBinary (bin) {\n    var length = bin.length;\n    var buf = new ArrayBuffer(length);\n    var arr = new Uint8Array(buf);\n    for (var i = 0; i < length; i++) {\n      arr[i] = bin.charCodeAt(i);\n    }\n    return buf;\n  }\n  loadImage(){\n    //TODO make a single component for loading single image\n    var file = null;\n  request.get('https://localhost:3000/' + 'api' +'/banner'+ this.props.path )\n    .set({'Authorization': 'Bearer ' + Auth.getToken()})\n      .then((res, err) => {\n        if (err) {\n          console.log(err)\n        }\n        console.log(res.status)\n        if (res) {\n          var binary = this.fixBinary(atob(res.body.image));\n          var blob = new Blob([binary], {type: res.body.file.contentType});\n          var url = URL.createObjectURL(blob);\n           file = res.body.file\n          file.preview = url\n          //  this.state.universities=\n    console.log(res)\n        //  this.state.file=res.body.file\n      this.setState({\n   file : res.body.file\n      })\n    }\n\n})\n  }\n```\nIt is working but think I can improve it a lot, can I ?\n. ok\nhere is the response \njson\nheaders\n:\nObject\ncontent-length\n:\n\"97541\"\ncontent-type\n:\n\"application/json; charset=utf-8\"\netag\n:\n\"W/\"17d05-99eV0mWYPfFRgmChfU8NAKdct0o\"\"\nstatus\n:\n\"200\"\nx-powered-by\n:\n\"Express\"\nOkay I try your solution.\nIt looks like it is changing nothing on the headers.. Okay, I will try to fix this. I will keep you updated.. Okay :\nI did this .\njavascript\nrequest.get('https://localhost:3000/public' + this.props.location.pathname+'/banner')\n        .buffer(true)\n        .set({'Content-Type': this.props.university.banner.contentType})\n        .parse(request.parse.image)\n        .then((res, err) => {\n          if (err) {\n            console.log(err)\n          }\n          console.log(res.status)\nHere is the request result :\njson\neq\n:\nRequest\nheader\n:\nObject\nContent-Type\n:\n\"image/jpeg\"\n__proto__\n:\nObject\nmethod\n:\n\"GET\"\nurl\n:\n\"https://localhost:3000/public/university/598ab55a694d261852bf6bab/banner\"\nxhr\n:\nXMLHttpRequest\nHere is the Response header(s)\njavascript\nheader\n:\nObject\ncontent-type\n:\nnull\nstatus\n:\n\"200\"\nx-powered-by\n:\n\"Express\"\n__proto__\n:\nObject\nheaders\n:\nObject\ncontent-type\n:\nnull\nstatus\n:\n\"200\"\nx-powered-by\n:\n\"Express\"\nHere is the server side express code :\n```javascript\n var readstream = gfs.createReadStream({'_id': uni.banner})\nreadstream.on('error', function (err) {\n  console.log(err)\n  res.send('No image found with that title')\n})\nreadstream.pipe(res)\n\n})\n```\nI think you are right and something is breaking the headers. I am using \nconst http2 = require('spdy') to run the server but I dont think it comes from this.\nBest regards\nArn. Hello.\nI added this on the server side \n```javascript\n  const fbuf = Buffer.concat(bufs)\n          res.setHeader(\"Content-Type\", file.contentType);\n          res.setHeader('Content-Length', file.chunkSize);\n          res.setHeader('Content-Disposition', 'attachment; filename='+file.filename+'');\n          res.write(fbuf,  'binary');\n          res.end();\n```\nThe headers is now \njson\nObject\ncontent-disposition\n:\n\"attachment; filename=moldeuniversity.jpg\"\ncontent-length\n:\n\"261120\"\ncontent-type\n:\n\"image/jpeg\"\nstatus\n:\n\"200\"\nx-powered-by\n:\n\"Express\"\nSo, how should I write the code with superagent to get the image as a file ?\n. Okay I solved everything. ( I wanted to do more complicated than necessary ... )\nhere is the explanation\nServerside :\n```javascript\nUniversity.findById(req.params.id, function (err, uni) {\n    if (err) {\n      return res.status(409).json({\n        success: false,\n        message: 'error on getting the university'\n      })\n    }\n    gfs.findOne({ _id: uni.banner}, function (err, file) {\n      console.log(file)\n      if (err) {\n      }\n      if (file) {\n        const readstream = gfs.createReadStream({\n          _id: uni.banner\n        })\n    const bufs = []\n    readstream.on('data', function (chunk) {\n      bufs.push(chunk)\n    })\n    readstream.on('error', function (err) {\n      console.log(err)\n      res.send('No image found with that title')\n    })\n\n\n\n    readstream.on('close', function () {\n      /*\n      const fbuf = Buffer.concat(bufs)\n      const base64 = fbuf.toString('base64')\n\n*/\n          const fbuf = Buffer.concat(bufs)\n      var img = new Buffer(fbuf, 'base64');\n\n      res.writeHead(200, {\n        'Content-Type': 'image/png',\n        'Content-Length': img.length\n      });\n      res.end(img);\n\n    })\n\n  }\n})\n\n```\nClient side\njavascript\n     file.url = 'https://localhost:3000/public' + this.props.location.pathname+'/banner'\n```\nI didnt need to use superagent to request the image. Just an Url. I do not know why I didnt think about this before.\nThank for helping me a lot with the header thing !. Haa thank you.\nit is working !! :+1: . ",
    "deeparora29": "Thanks I am using this in conjunction with redux saga now. This can be closed. ",
    "reviewher": "Does the library work without webpack, or is it an essential dependency?. That makes sense @pornel but when using the superagent.js script the library is exposed as superagent, not request.  That piece of information is not in the docs.  Try to use that superagent.js script in a page and follow the README and you'll see the confusion.\nIn retrospect there are actually 3 ways this could be resolved: mention that browser users have to add var request = window.superagent; in the code, redo the documentation samples with the superagent variable name, or just change the library to directly assign to window.request. ",
    "LoicUV": "FormData does allow empty values, you mean that the dependency form-data doesn't, right ?. ",
    "kamilsmuga": "+1 more report - yes it is annoying :) . ",
    "bfabec": "Note the following other issues:\nhttps://github.com/visionmedia/superagent/issues/410\nhttps://github.com/visionmedia/superagent/issues/776. ",
    "lamyat2005": "For your information, the data I have passed in is \n{access_token: null, action: \"date:get_date\", api_key: \u201ckey\u201d, args: undefined}\nHowever some devices toString it as [object Array Iterator] instead of [object Object]. Thanks.. Thanks!. ",
    "thomaschaaf": "It would need to be set somewhere around here https://github.com/visionmedia/superagent/blob/d55adf1a86623247ee19a8bb75024f5098ed42a2/lib/node/index.js#L595\nThe localAddress has to be set when initializing the request according to: https://nodejs.org/api/http.html#http_http_request_options_callback\nSo sadly it can not be set afterwards.. ",
    "wooliet": "https://github.com/broofa/node-mime/releases\nThey might have a fix for the 1.x version. The 2.x version will break in node 0.12.\nerror   28-Sep-2017 16:10:42    const Mime = require('./Mime');\nerror   28-Sep-2017 16:10:42    ^^^^^\nerror   28-Sep-2017 16:10:42    SyntaxError: Use of const in strict mode.. ",
    "dammo001": "superagent/node_modules/mime/index.js -- now that I look at the actual file structure, I guess I should be posting an issue for mime... . ",
    "evalphobia": "I got the same error when using jest and supertest@3.0.0.\n```bash\n    Cannot find module './types/standard' from 'index.js'\n  at Resolver.resolveModule (node_modules/jest-resolve/build/index.js:191:17)\n  at Object.<anonymous> (node_modules/superagent/node_modules/mime/index.js:4:27)\n\n```\nI removed that file and it worked.\nbash\n$ rm node_modules/superagent/node_modules/mime/index.js. ",
    "jota": "I also use jest and could solve it by simply adding \"json\" as a possible extension in the jest config. For example:\n\"moduleFileExtensions\": [\n      \"ts\",\n      \"tsx\",\n      \"js\",\n      \"json\"\n    ],\n\"json\" is in that list by default so it should only be an issue if you overwrite that config parameter and are missing \"json\".. ",
    "silentroach": "mime upgraded in major, but you don't. why? it is a breaking change, not patch. You are wrong, your package worked on node 0.10, but with upgrade to new mime it doesn't and it is a breaking change when your package is not compatible with old node any more. Why not just change a major version?\nSo now our project (big old project for 0.10) is broken cause of sway -> json-refs -> path-loader -> superagent deep dependency. They are just depend on each other as \"^x.x.x\", so why should I expect that something will be wrong this way?\nSo now, to support this change I have to fork every dependency in this chain or do something like this after npm i: \ncd node_modules/sway/node_modules/json-refs/node_modules/path-loader/node_modules && npm install superagent@3.6.0 --production\n\nDon't you think something is wrong with it? :). Didn't knew about 2->3 switch and its reason, my fault. Ok, thank you.. ",
    "com4": "\nSuperagent 2.x works on Node 0.10.\nSuperagent 3.x was never meant to work on Node 0.10. \n\n@pornel For what it's worth I'm actually having trouble with the swagger-tools project. I'm just using swagger to document an API. I'm not a node developer so forgive any ignorance.\nIn the swagger-tools package.json it lists superagent as a dependency with ^2.0.0[1]. The NPM docs say that using a ^ prefix indicates \"Compatible with version\"[2]. \nIs it possible for you to mark superagent v3 as not compatible with v2 so other packages don't upgrade to this incompatible version? This should help maintain stability for other packages which haven't done the leg work to upgrade while still giving you the freedom to make backward-incompatible changes.\n\nhttps://github.com/apigee-127/swagger-tools/blob/master/package.json#L82\nhttps://docs.npmjs.com/files/package.json#dependencies. Do you happen know why it would be pulling 3.0 versions?. looks like it was a few dependencies deep (https://github.com/whitlockjc/path-loader/blob/master/package.json#L62) \n\nThanks for your help.. ",
    "hellofantastic": "Before seeing this I figured out this , \nis it the same essentially? \nthen pass it to a function to convert the blob and force it to the browser\njavascript\nconst self = this;\n    this.setState({isLoading: true}, function() {   \n        request\n        .get('api/frontEnd/generatePDF')\n        .on('request', function () {\n            this.xhr.responseType = 'blob';\n        })\n        .then(function(res) {\n            fileDownload(res.xhr.response, 'infographic.pdf');\n            self.setState({isLoading: false});\n        });\n    });\nlike \njavascript\nthis.setState({isLoading: true}, function() {   \n        request\n        .get('api/frontEnd/generatePDF')\n        .responeType('blob')\n        .then(function(res) {\n            fileDownload(res.response, 'infographic.pdf');\n            self.setState({isLoading: false});\n        });\n    });\ntry it out on Monday\nThanks. ",
    "sdesalas": "Mime version 2.0.0 onwards provides a force=true flag to allow multiple calls to .define() for the same mime type, which in turn stops the error from being thrown.\nFix as follows:\n/lib/node/index.js L71\n```javascript\n/*\n * Define \"form\" mime type.\n /\nmime.define({\n  'application/x-www-form-urlencoded': ['form', 'urlencoded', 'form-data']\n}, true); // <--- add 'force=true' here \n```. :+1:. :man_dancing: ~~~~~~~. ",
    "cthuluhoop123": "I've listened to the redirect event and it does not trigger with cloudfare's redirect. hmmm any workarounds?. ",
    "wildermuthn": "@ebardajiz This can be solved by ensuring the offending module that depends on superagent is included in the externals of webpack. It might be worth making a note somewhere about troubleshooting this particular build problem.\nexternals: {\n    wpapi: 'commonjs wpapi'\n  },. ",
    "mickeyreiss-visor": "Ah. In that case, what would be a good way to document the behavior for 304 Not modified?. I pushed another version of the copy. Please take a look. \u270d\ufe0f \ud83d\udc40 . ",
    "tomasstrejcek": "after more investigation, it looks like newrelic fails to track more things than this and its not related to retry(), so this issue may be closed. ",
    "pmbanugo": "I still get the same thing. Says the server is not responding both for http and https.. ",
    "rickknowles-cognitant": "I have a concrete use case for this when accessing the docker registry v2's blobs API using superagent. When backed by an S3 bucket, the reigstry sends a 307 to a pre-signed S3 url, which of course 400's when it gets an unrecognised authorization header. \nNice easy case to reproduce. . ",
    "chrisveness": "I've only used superagent through mocha/supertest, I'm afraid I'm not sure how to reproduce on its own \u2013 I'll see if I can work it out.. I don't know how to reproduce without supertest, but I think I've located the issue.\nWhen superagent checks cookiejar's CookieAccessInfo() (lib/node/agent.js:65), for the 'domain to match', it passes url.hostname \u2013 apparently ignoring the .set({ Host: 'www.local.host:3000' }) passed to request.get().\nThis results in CookieAccessInfo() matching '127.0.0.1' against 'local.host' (and failing), instead of matching ''www.local.host' against 'local.host'.\nI haven't looked into how the .set() is handled, whether this need to be addressed in superagent or koa (or whether if falls between the two).. Actually, I may be wrong, I can't really follow what's happening. For the 1st, 2nd, and 4th tests, Cookie.collidesWith() (cookiejar.js:133) gets invoked with a CookieAccessInfo as an argument, but on the 3rd test, it gets invoked with a Cookie as an argument. All a bit beyond me, sorry!. I've had a look through the code further \u2013 though I can't say I can follow it particularly well!\nWhere Agent.prototype._attachCookies() invokes CookieAccessInfo() (lib/node/agent.js:65), if I replace url.hostname with the (hardwired) Host header I specify with request.get().set(), then the host is matched successfully. \nHowever, at this point req.url is http://127.0.0.1:<random-port>/<path>, and it occurs before the .set() has been processed, which means the Host header specified in the .set() is not available.\nI can't see any way around this, but I can't imagine I am the first to have encountered this issue. Is there something I am doing wrong?. Thanks for the reply.\nI'd be happy with any workable solution, but I'm struggling to get to grips with superagent's innards.\nI've been trying to pursue a superagent-only repro, and don't see why this node test passes:\nconst setup = require(\"../support/setup\");\nconst base = 'http://www.local.host:5000';\n\nconst request = require(\"../../\");\n\ndescribe(\"request\", () => {\n  it(\"should retain cookies\", done => {\n    request\n      .get(`${base}/header`)\n      .set(\"Host\", \"www.local.host:5000\")\n      .set(\"Cookie\", \"foo=bar; Domain=local.host\")\n      .end((err, res) => {\n        try {\n          res.body.should.have.property(\"cookie\", \"foo=bar; Domain=local.host\");\n          done();\n        } catch (err) {\n          done(err);\n        }\n      });\n  });\n});\n\nAgent.prototype._attachCookies() doesn't even get invoked.\nIf you have any solution that would get my initial post to pass, I'd be super glad! Let me know if there's anything I could do to help.. Of course, sorry \u2013 being slow!\nTo investigate further, I put together a test on the lines of SuperAgent's own 'node' tests (using Express) \u2013 which worked fine.\nSo looking into it, I think the culprit here is actually SuperTest: specifically, supertest/lib/test.js:62 hardwires the 127.0.0.1 IP address.\nI'll raise this over on the SuperTest side \u2013 sorry to have troubled you!\n. SuperTest PR #297 would fix this for me, but is SuperTest still active, or has it been abandoned?. ",
    "mpareja": "@pornel I have confirmed that the above commit rectifies the symptom I was experiencing. Thanks for the speedy fix.. ",
    "zfcheng": "Thank you very much for your answer.\nI check on the server, the server did not receive the next data of the client, Content-length and the received content of the length does not match, the server waiting for timeout to actively disconnect the link, and then the client throws an exception.\nI try to set highWaterMark larger than sending files, and like this, requests are successful\nlet stream = fs.createReadStream(file, {\n    highWaterMark: 300000\n})\nrequest = new Request(method, url);\nstream.pipe(request);\nThe server should not receive the complete stream, if I do not set highWaterMark, but use default values, can solve this problem?\nDo you have any ideas about this question?. But my interface is PUT. Is there any other way?. yes, I set up Content-Length, and it was right, but I didn't know why stream was interrupted.\nIf the upload file size is less than highWaterMark, the file can be uploaded.. When I upload stream, I use require ('http').request, and the upload is successful. I think what SuperAgent did when uploading stream, see the code has nothing to find, and I will continue to follow this problem.\ncode:\n```\nvar http = require('http');\nfunction stream (req, callback) {\n    var options = {\n        host: req.headers.Host,\n        port: req.port,\n        method: req.method,\n        headers: req.headers,\n        path: req.path\n    }\n    return http.request(options, function (httpResp) {\n        callback(httpResp);\n        httpResp.emit('headers', httpResp.statusCode, httpResp.headers);\n    });\n}\nmodule.exports = stream;\n\nreadStream.pipe(stream);\n```. ",
    "jon-cooke-rentalcars": "I had the same issue, solved in the same way - using http.request instead. I'm using node 10.6.0\n. ",
    "qwerty2323": "Yes, It works in 3.8.0 & older.. ",
    "workfel": "Okey, thank you ! \ni will follow your guide and use .auth. ",
    "alaorneto": "I removed the superagentPromise but it still logs errors to the console. The line 772 of client.js is given as the source of the logged error:\nxhr.send(typeof data !== 'undefined' ? data : null);. Well, I guess it's related to this question on stackoverflow:\nhttps://stackoverflow.com/questions/14337351/can-i-prevent-the-chrome-developer-tools-console-from-logging-image-404-errors\nSeems to be a issue with Chrome. Nevermind. I thank you for your attention.. ",
    "mpseidel": "I'm also currently debugging an issue with Edge. See that Edge is not listed as a supported browser in my case it looks like CORS is not working properly as in other browsers. Was going to open another issue but wasn't clear about general Edge support as tests currently seem to fail.. ",
    "pieterbeulque": "Hi @kornelski, this keeps popping up as an issue for us. Below are a few things that might help point in the right direction.\nSuperagent is being imported as a dependency for Auth0.js.\nThis particular project is intended for the browser and is bundled using JSPM 0.16.\nJSPM provides support for require('http') and require('https') using these packages.\n\nhttps://github.com/jspm/nodelibs-http\nhttps://github.com/jspm/nodelibs-https\nhttps://www.npmjs.com/package/http-browserify\n\nThese packages don't look 1:1 compatible with the native modules.\nDo you think this might be the issue? I don't see why Superagent would require('http') in a browser environment. I think this is accounted for in the package (the browser field in package.json)?. I was looking in that direction too, yes.\nHowever, in the JSPM docs I found this regarding Node.js usage:\n\nPackages with a browser field will always use that browser mapping even in Node (https://github.com/jspm/npm/issues/32), pending conditional loading support in SystemJS.\n\nSo instead of always picking up on the browser key, it looks like it doesn't pick up on it at all.\nAny advice on how I can test or verify this?. Hey, I verified & that string is present in the bundle.\nIt looks like our build tool is using the ./lib/client.js file as an entry point, as it should.\nHowever, the node-superagent string is also present in the same bundle. This is probably where things go wrong? \nI took a deep dive in the bundled code and found this:\njs\nSystem.registerDynamic(\"npm:superagent@3.8.2.js\", [\"npm:superagent@3.8.2/lib/node/index.js\"], true, function ($__require, exports, module) {\n  var global = this || self,\n      GLOBAL = global;\n  module.exports = $__require(\"npm:superagent@3.8.2/lib/node/index.js\");\n});\nSo it's effectively registering the Node.js entry point as the main entry point, preferring the main keyword from package.json over the browser one.\nIf I change lib/node/index.js in the part above with lib/client.js, everything works as expected in the browser.\nLooks like the JSPM issue tracker is where I'm headed \ud83e\udd15\nI'll be following it up here: https://github.com/systemjs/systemjs/issues/1792. ",
    "roy09": "Was there any resolution to this?\nAre we suppose to install with jspm install superagent -o \"{ main: null }\"? . ",
    "clarkttfu": "According to https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/HEAD, HEAD response should contain empty body... ",
    "itaditya": "Nice . ",
    "akoptelov": "@kornelski ~~Shoudn't buffering be turned on if a parser is defined? Otherwise I don't see any good in having a custom parser that has no means to set its result to the response...~~\nOk, I see some use-cases when it is useful. Then probably parser itself could give a clue on buffering? Function's property probably?. ",
    "shreyjain1994": "There should be no problems with agent.buffer(true) since it just calls the main request.buffer method internally.\nHowever, I've added all necessary tests, including ones that show that agent.buffer(true) remains unaffected... Are you sure it would be a breaking change? This block would only run if a user defined a mime type on exports.buffer, and since exports.buffer didn't exist until now, previously written code should run as normal. Also, this block still respects the fact that the buffer() method takes precedent over everything else.. ",
    "ashersaupingomez": "Any news on this @kornelski?. Hi guys, any progress on this issue? I'm having the same issue.. I think async plugins could make for great functionality. For example, I know of a few instances where async work needs to be done before the first request in order to authenticate a user.\nI'd be happy to work on this if you agree.. ",
    "windware": "It's pretty common that packages usually come with app.js and app.min.js. It's just a matter of creating a minified version of exactly the same file. What kind of overhead are you mentioning when using either of them yields completely same results?\nOf course I can minimize when it goes to production but development is all about speed and I'd rather want the packages come minified than, minify them every time I bundle it up during development and I'm assuming the libraries that I use are not too buggy and won't require for me to look at the human readable versions until necessary.\n. ",
    "NathanCH": "Here is the solution I came up with, but I can already see a number of issues with it such as the scripts appending multiple times.\n```\n.then((res) => {\n// Populate container with response.\n  const body = document.getElementById('containerToPopulate');\n  body.innerHTML = res.text;\n// Extract and evaluate scripts.\n  const scripts = body.getElementsByTagName('script');\n  for (let i = 0; i < scripts.length; i++) {\n    const scriptText = scripts[i].text;\n    const scriptTag = document.createElement('script');\n    scriptTag.text = scriptText;\n    const head = document.getElementsByTagName('head')[0];\n    head.appendChild(scriptTag);\n  }\n})\n```\nAll I'm doing here is looping through the response text (after it has been mounted to the DOM), and recreating the scripts to apply to the header. From what I can see, this is how jQuery does it too, but probably much better.\nEdit: Note that this will only handle inline scripts. If your view calls external scripts, you can use the same technique just check that it has a src attribute.. Whoops didn't mean to close the issue! But yes you are 100% right, sticking with jQuery would solve this problem. It sounds like you're saying the jQuery.html() method may be responsible for the script magic. \nThat's a good point, I'll take a look. And if that's the case, this issue should be closed as it's not the responsibility of superagent to mount.. ",
    "christian-dinh": "Perhaps this is the wrong place to ask this question (if so I apologize), but I'm working on an application in which we keep a count of in-flight superagent requests. When a request is created we increment the counter, and when a request resolves or rejects we decrement the counter in the promise then/catch. It is possible for a request to be aborted, in which case we have an abort event listener that decrements the counter.\nAs mentioned in https://github.com/visionmedia/superagent/pull/1342, the in-flight promise will still sometimes resolve and we'll end up decrementing the counter an extra time. It seems what you're proposing here would solve our problem (we could drop the abort listener and rely on the promise rejection instead), but in the meantime is there a workaround for this issue in the current implementation of superagent?. Clever, thank you!. ",
    "RiccardoMargiotta": "Thanks for the update. I'll see if there's anything weird going on in our Webpack setup. \ud83d\udc4d. For future reference, it looks like Webpacker changed the default Uglifier settings to target ecma: 8, which led to the issue I was seeing. https://github.com/rails/webpacker/issues/1235. ",
    "WesleyDRobinson": "As written, startDate and endDate are expressions that resolve to -2018 and -2027 in Chrome. Looks like IE11 coerces them to strings (and wraps with ?).\nWhat happens if startDate and endDate are wrapped in quotation marks?\nstartDate='2-2-2018'\nendDate='2-11-2018'. ",
    "JadyNews": "@kornelski , I am new here, could you please confirm that if I use superagent.agent(). After .end() will the session be closed. \nFor example, user1 uses superagent.agent() to call an API to get response SAML back and do something, after it, user2 uses superagent.agent() to call same API. Will the user1's session still preserved when user2 making the call ?\nThe code snippet is below:\njs\nvar request = require('superagent');\nvar agent = request.agent();\nagent\n    .get(`${config.oktaAppURL}`)\n    .query({ sessionToken: sessionToken })\n    .set('Accept',  '*/*')\n    .end(function(err, res) {\n      if (err) {\n        logger.error('Call okta app url to get SAML assertion: ' +\n        'can\\'t not query to this app url');\n        callback(err);\n      }\n      else {\n        // do something\n          return callback(null, data);\n        }\n        else {\n          // do something\n          return callback(err);\n        }\n      }\n    });. ",
    "altruisticsoftware": "@kornelski - Updated \ud83d\udc4d . ",
    "biot023": "Ah, that makes sense, I'll give something along those lines a try...\n...\n... and that did it. Thank you so much, @kornelski !. ",
    "cat5inthecradle": "Unfortunately it still makes github unhappy. I'm not completely sold on their vulnerability detection feature, but so long as the affected version is present in the package.json, github will flag it.\n\nhttps://help.github.com/articles/about-security-alerts-for-vulnerable-dependencies/. ",
    "flandrade": "@kornelski Thanks, this works if you attach the XML, but I'm trying to reproduce \"SwA\" or SOAP with Attachments, where you a body has a request payload in XML and an attached file. Is this possible? . Yes, it's not possible to do this. I'm not sure if this is common either. I'm closing this. Thanks! . ",
    "Exomnius": "Will do!. ",
    "videni": "@kornelski, it supposed to work , I have configured web and node for webpack , but none of them work, I don't know why , so I stop writing my own configurations , I use n8-make and the makefile from wpcom-xhr-request ,, it works now. . ",
    "ethanresnick": "To be clear, this happens even when I call request.query(String) with my unencoded string, and a bit of debugging reveals that the issue goes all the way down to node's built-in url.parse (i.e., url.parse(\"http://example.com/?test=`\") returns { ..., query: \"test=%60\" }).\nNode's solution to this issue is to offer both the RFC 3986-compliant url.parse and the WHATWG URL API in core, so perhaps superagent should simply surface both of those options? Note that using the built-in new (require('url').URL)(\"http://example.com/?test=`\").search does leave the backtick unescaped.. > We depend on encodeURIComponent(\"\") which returns '%60'. We still support IE, so we can't easily switch to the URL API.... In superagent you can set query as a string req.query(\"foo=\"), and IIRC it won't escape it in the Node version (in the browser version it depends on what the browser enforces).\nThe issue here isn't encodeURIComponent; even in the Node version of superagent with req.query(\"foo=`\"), the backtick gets escaped, because of superagent's internal use of url.parse. I'm pretty sure this is the problematic call/the spot where node's WHATWG API could be used instead.\n\nIt's not clear to me whether WHATWG URL recommends unescaped \"`\" or merely tolerates it as a recoverable error. The path encode set contains fragment set, which contains backtick.\n\nI agree that the spec's pretty hard to follow. I don't think the path encode set is relevant, though, as that seems to only be referenced in the path processing steps, not the query ones. My best reading is that the key bit is the query state of the parser, where the spec explicitly doesn't include backtick as one of the characters that gets percent encoded during parsing. (Normally, I'd expect encoding to be part of the serialization step, but that's not how the spec is structured; the serialization is just dumb concatenation, with the percent encoding having already happened during parsing/construction. Either way, the point is that, under WHATWG URL, serialize(parse(http://exmaple.com?t=`)) leaves the backtick as is.)\n\nBut in general I've got a feeling your server depends on a problematic feature. Given decades-old mess of fragmented specs for URL/URI/IRI the server should be prepared to support the lowest common denominator.\n\nI kind of agree with this, and I'm probably going to switch the server to a new delimiter. However, let me give a bit more context. In my use case, I need a way to delimit literal strings from other query param data, and I think a reasonable approach would be to allow the client to delimit the string with either literal single quotes (for RFC 3986-compliant clients, which should leave these unencoded) or by backticks (for WHATWG based clients, like browsers, that will encode the single quotes but not the backticks). However, even this scheme of allowing either delimiter doesn't work with superagent, because it unconditionally encodes both characters. To me, that seems pretty bad/frustrating. \nI think it's reasonable for new client libraries to correctly support at least one of RFC 3986 or WHATWG URL. Superagent, by encoding both backtick and single quote, is supporting neither. This isn't really it's fault \u2014\u00a0it all goes back to url.parse encoding single quotes in violation of RFC 3986, but that's probably good for security (that's why browsers do it), so I wouldn't suggest changing that in Node core even if it weren't a big breaking change. The upshot of all this, though, is that it's still impossible to make a bunch of useful requests from superagent. That's what I'd like to see some escape hatch for.. > You're effectively making quotes a new special character, and creating your own new syntax for the query string.\nNot sure I follow; single quotes already are a special character under RFC 3986 \u2014 they're part of the sub-delims set, which is for unencoded use in query strings precisely to enable custom DSL syntaxes like this. That's my point...\nIn the meantime, I am gonna use some other delimiter (most likely tilde or slash or similar), but I still think there's an underlying issue that it's just impossible to make certain requests with superagent that browsers can make and/or that are allowed under RFC 3986. > Node's http module requires parsed URL, so that's hard to avoid. \nAhh, I didn't know this. Definitely makes things trickier.\n\nThe WHATWG parser was added in 7.0, so we won't be able to use it until April 2019 (6.0 EOL). I'm reluctant to add another 3rd party parser just to support such an edge case.\n\nFair enough. Would it be possible to do some very minimal post-processing on the result of url.parse to add back the unescaped versions of any ' or ` that were present in the .query() arg?\nAnother possibility might be to have an option to opt-in to WHATWG parsing, but have that option throw on Node 6? (If it's explicit opt-in, and fails hard and fast, this doesn't really seem like a problem.). [Totally unrelated: How did you get Github to put a single backtick in a code block in your last comment? I can't figure out the escape sequence, which is perhaps ironic given the content of this thread.]. > Is it allowed to have unescaped ' /` in the path? path.replace(/%60/g,'`') may be an OK solution\nMy quick reading is that, for both RFC 3986 and WHAT WG, unescaped ` is not allowed in the path but unescaped ' is. How does that help us though? The issue is with the query string, not the path and, regardless, the user has to be able to send escaped characters too, i.e. req.query(\"test=%60%27\") should be left as-is.\nI think the logic is maybe something like:\n```js\nconst parsed = url.parse(url); \nif(rawQuery.indexOf('') > -1) {\n  // capture escaped and unescaped backticks, in order.\n  const backticks = rawQuery.match(/|(\\%60)/g);\n// calculate the final query by replacing the backticks that got escaped by url.parse\n  // with unescaped versions, while leaving those that came escaped as is\n  parsed.query = parsed.query.split(\"%60\").reduce((acc, piece, i) => {\n    return acc + backticks[i - 1] + piece;\n  });\n}\n```\nThe above would be a polyfill for WHATWG behavior on Node < 7, for users calling request.query(String). Yeah, the above obviously isn't as simple as a one-liner; that said, it doesn't seem too bad to me. Is there something in particular that bothers you about it?\nAlso, just to clarify, the above snippet could be used across the board, without superagent importing require(\"url\").URL at all. (That is, I didn't mean to suggest importing the WHATWG stuff conditionally and then falling back to the above; that would be needless complexity and open the door to bugs caused by WHATWG URL doing other subtle things that the non-WHATWG-superagent still wouldn't do.)\nIf something like the above snippet were implemented, it could get applied to all requests unconditionally (i.e., no need for a user facing option either) because applying it unconditionally doesn't actually take away any expressive power; a user who wants the escaping can still get it (by escaping the ` before passing it in). Also, in practice, applying it automatically is likely to actually increase interop, as it's what browsers do.\nThat said, applying this automatically would technically be a breaking change, so it probably should live behind a user opt-in option just until the next major version.. @kornelski Any more thoughts on this?. > It seems that url.parse() is guilty here, so it should be changed... I'd be OK with moving to the WHATWG parser, except for the pain of Node 6 compatibility. I'm worried that conditional require() will have nasty side effects in bundlers (we already get super weird bug reports about them).\nI don't think trying to change url.parse makes sense, since it actually is compliant with RFC 3986 re the backtick, and that's the spec it's (mostly) trying to match. I hear you about the pain of switching to WHATWG though.\n\nThe workaround you proposed is narrow (requires query as a string) and little bit on the convoluted side. \n\nTrue.\n\nIt feels like tech debt for a solution that you will be the only person in the world to ever use.\n\nI hope the DSL I'm developing will get somewhat wider use \u2014 I plan to ship it with my implementation of the JSON:API spec, and then publish its syntax as a public spec that other implementations could adopt. It's not gonna be huge, but I wouldn't be surprised if it ends up with dozens of users, and I don't really want to tell them \"you can't make requests from Node\", or that they have to use a custom fork. \nIf we merged the narrow fix for now, I'd gladly come back when Node 6 reaches EOL and make a PR to swap it out for the WHATWG parser. Would that work?. It's a deal :) I'll work up a PR tomorrow or Friday.\nAfter that, how do you want to me to handle maintenance? I imagine you'd just tag me if/when any relevant bugs come up?\nAlso, for the PR, how do you want to land it: as a major version bump, or by adding an opt-in option to request.query? Unless there's some big cost to releasing a new major, I'd strongly prefer to do that; an option would have no good reason to exist long-term and would be a big API kludge. (As I mentioned earlier, if a user wants the old behavior, they can get it with request.query(oldInput.replace(/`/g, '%60')) \u2014 no option needed.). Cool. So, I imagine that means that, if I get you the PR ASAP, it can go out with that release?. Closed by #1369.. ",
    "vasergen": "+1. ",
    "DenysVuika": "I see what you mean, thanks. Will try to increase timeout settings at the client side. . ",
    "eromano": "@kornelski also if we add a third timer the deadline timeout will be still active . \nShould I just disable the deadline timeout and other this third timeout? . Sorry still don't clear to me.  Basically we will have 3 timers:\n\nDeadline timer\nResponse timer\nUpload timer\n\nUpload timer :The upload timer should trigger  an error when between two progress chunk it last too much time. (is that right?)\nThe problem that I see that the deadline timer will still be triggered after 60 seconds (by default):\n```js\n// deadline, this timeout will always be triggered if we don't clear it\n  if (this._timeout && !this._timer) {\n    this._timer = setTimeout(function(){\n      self._timeoutError('Timeout of ', self._timeout, 'ETIME');\n    }, this._timeout);\n    ...\n    ...\n    ...\n    ...\n```\neven if we clear the upload timer :\n```js\n// progress\n  var handleProgress = function(direction, e) {\n    clearTimeout(self._uploadTimeoutTimer);\nif (e.total > 0) {\n  e.percent = e.loaded / e.total * 100;\n}\ne.direction = direction;\nself.emit('progress', e);\n\n};\n  if (this.hasListeners('progress')) {\n  try {\n  xhr.onprogress = handleProgress.bind(null, 'download');\n  if (xhr.upload) {\n    xhr.upload.onprogress = handleProgress.bind(null, 'upload');\n  }\n} catch(e) {\n  // Accessing xhr.upload fails in IE from a web worker, so just pretend it doesn't exist.\n  // Reported here:\n  // https://connect.microsoft.com/IE/feedback/details/837245/xmlhttprequest-upload-throws-invalid-argument-when-used-from-web-worker-context\n}\n\n}\n```\nHow can I avoid the deadline timeout to happen if I don't clear it?. Thanks for the explanation of the current options .\nMy questions are related to the third timer that you suggest to implement and I was trying to figure out which was your proposal.\n\"So if you'd like to implement watchdog timer for connection stalling, then you need to add a third timer. Don't cancel the existing ones.\"\n. Ok I got it, thanks.\nThis timer will works only if the deadline timer is not set or it's value is minor of the deadline.\nDo you would like to have this functionality in superagent or is better that we just overwrite it in our side?. Ok thanks , I guess I will try to create a PR but I will sure need your help. ok \ud83d\udc4d . Maybe I misunderstood should I clear only if is 100%?\n```javascript \n    if (e.total > 0) {\n      e.percent = e.loaded / e.total * 100;\n    } else if(e.total = 100){\n      clearTimeout(self._uploadTimeoutTimer);\n    }\n```. yep you right, sorry I was in rush ;), honestly I guess we could add some linter in the project to avoid those mistakes and add it before the build. What do you think?. I change it but is actually not clear to me the part :  \nIf you're only clearing the timer without resetting, it doesn't add much value beyond response timeout. You could just add upload time to response timeout.\nDo you have suggestions for the test?\n. the lint would be different, ti will promote a common style across all the files http://jshint.com/docs/ . Tests are great but they are not style related they only guarantee that the functionality respect the wanted behaviour. If you see in your codebase there are different case where you use somewhere single/double quote ==/=== and other similars. Have a linter will guarantee a common style across all the contributors. Another usefull file for the indentation could be have an .editorconfig file where is described where any kind of file is formatted  . @kornelski your idea is to add an adaptive timeout similar the TCP one? http://www.pcvr.nl/tcpip/tcp_time.htm#21_0 if yes we should understand which strategy apply. ",
    "budarin": "Thanks! It helped!. I'm sorry - I have anothe error:\nERR_TLS_CERT_ALTNAME_INVALID]: Hostname/IP does not match certificate's altnames: IP: 192.168.10.103 is not in the cert's list: \n[1]   app:server:request:error     at Object.checkServerIdentity (tls.js:229:17)\n[1]   app:server:request:error     at TLSSocket.onConnectSecure (_tls_wrap.js:1070:27)\n[1]   app:server:request:error     at TLSSocket.emit (events.js:182:13)\n[1]   app:server:request:error     at TLSSocket._finishInit (_tls_wrap.js:639:8)\nCA certificate has alternative name with ip of my local machine's IP: \nDNS Name=192.168.10.103\n\n\n\n\nCould you help me, please. I make a request to https://192.168.10.103:44300 - here is webpack-dev-server\nwebpack's config:\njs\ndevServer: {\n        host: `192.168.10.103`,\n        port: 44300,\n        historyApiFallback: true,\n        hot: false,\n        overlay: true,\n        headers: { 'Access-Control-Allow-Origin': '*' },\n        watchOptions: {\n            ignored: /node_modules/,\n        },\n        https: {\n            key: fs.readFileSync('certs/server.key'),\n            cert: fs.readFileSync('certs/server.crt'),\n            ca: fs.readFileSync('certs/cacert.crt'),\n        },\n    },\ncacert.crt.txt\nserver.crt.txt\nserver.key.txt\n. I'm sorry - I have found solution: instead of using IP it should be used machine name!\nThanks!. ",
    "apoguy": "Oops! Posted in the wrong project. Sorry.. ",
    "FinalFantafish": "@kornelski  oh i get it,thank you very much!. ",
    "talkquazi": "This image link is still found on https://www.npmjs.com/package/superagent. Well that is the debate online. I personally have never used that site I am just reporting the phishing warning. But obviously someone took notice because the github readme does not use the same url as the readme on npmjs.. I was just informing the superagent team about the issue. The site constantly allows the sharing of virus's, malware, trojans, ect. They do not respond to take down requests within 48 hours thus they are considered a phishing site. In the amount of time you have responded to this Issue you could have uploaded the offending image to another site and fixed this issue.. ",
    "danielmcq": "Thank you for approving and merging. I just wanted to make sure the dependency version was explicit because any projects using a package-lock.json or that use yarn.lock won't automatically get updated dependencies. This way with the next version of superagent any other project that updates to use that version will be certain that the fix done in the cookiejar project will be included.. ",
    "DragonCat1": "@kornelski \n```javascript\nimport Express from 'express'\nimport Superagent from 'superagent'\nconst app = Express()\nlet i = 99\napp.use('/', (req, res) => {\n  res.cookie(String.fromCharCode(i++), i).send(req.headers.cookie)\n})\napp.listen(8080, () => {\n  const header = { Cookie: 'a=1;b=2' }\n  const agent = Superagent.agent().set(header)\n  agent.get('http://localhost:8080/').then((data) => {\n    console.log(data.text)\n    return agent.get('http://localhost:8080/')\n  }).then((data) => {\n    console.log(data.text)\n    return agent.get('http://localhost:8080/')\n  }).then((data) => {\n    console.log(data.text)\n  })\n})\nrun this script,the result is\na=1;b=2\nc=100\nc=100;d=101\n```\nthe initialized cookies has been droped\nhttps://github.com/DragonCat1/superagent_cookie_issue\n. ",
    "d11wtq": "Oh, is that a limitation of XMLHttpRequest itself?. Just checked. Yeah it's a limitation of XMLHttpRequest. That's a shame. Seems like a pretty odd design choice but it is what it is. Will work around it, thanks.. ",
    "anasanzari": "This looks like application wide change. What if i only want to disable\nspecific requests.\nOn Wed, Jun 13, 2018, 7:46 PM Kornel notifications@github.com wrote:\n\nIt depends if you need it in Node or browser:\nhttps://visionmedia.github.io/superagent/#parsing-response-bodies\nhttps://visionmedia.github.io/superagent/#binary\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1386#issuecomment-396953384,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHBSJtOnMMPLz3_HkdQ-xByUMViipzuKks5t8R6-gaJpZM4UkpoN\n.\n. I guess this needs to be documented\n\nOn Wed, Jun 13, 2018, 8:59 PM Kornel notifications@github.com wrote:\n\n.parser() and .responseType() are per request.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1386#issuecomment-396980082,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHBSJvdRK6Xz42FcOh4VCwNst2gY1GNdks5t8S_MgaJpZM4UkpoN\n.\n. Does this work for browser?\n\nOn Wed, Jun 13, 2018, 10:01 PM Kornel notifications@github.com wrote:\n\nIt is in the section I've linked to:\nYou can set a custom parser (that takes precedence over built-in parsers)\nwith the .buffer(true).parse(fn) method.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1386#issuecomment-397002687,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHBSJtGN3FGM1ZCeP53DxXfF5eywy07cks5t8T5NgaJpZM4UkpoN\n.\n. \n",
    "palakdesai7": "@kornelski This test is an example. And as mentioned, I don't want to assert or do anything. Just want to print response. Test passes with no errors when browser is chrome. And superagent can be use in multiple ways. So here I want to use it to print response from api mentioned in post.  Plus end function will wait till console.log is executed so no additional waiting is required.\nThanks . @jonathansamines Thanks I will try that.. ",
    "jonathansamines": "@palakdesai7 From your test seems like it is not waiting for the response (super agent is completely async). If your are using mocha, you can return the whole expression as mocha is promise-aware and superagent returns promises.. ",
    "EvanHahn": "Makes sense.\nI was using Supertest to figure out whether my API server did anything weird with __proto__. For anyone else doing exactly what I was, I wrote a request like this to accomplish this:\njavascript\nsupertest(app)\n  .post('/my-route')\n  .set('Content-Type', 'application/json')\n  .send('{\"__proto__\": {}}')\n  .end(/* ... */). ",
    "Jordan4jc": "What does it merge on? The key names are the same but the values are different. Also is there a way to clear all query strings on an agent?. ",
    "yewenxiang23": "@kornelski \n\n. \n. ",
    "rhae": "I have the same situation.\nTrying to look what is really happening I wrote a little plain javascript and armed the XHR callbacks (see below).\nI tested Chrome beta,FF 52.6, FF 61.0.2, IE 11.0.9600.18537. They show the true xhr.status.\nI have also tried to debug superagent. However I have no clue, why the xhr.status is 0 here. Maybe you have some more insight. This would be helpful.\nHere are the files and the output. Somehow it didn't work to upload files.\nHTML\n-------8<---------8<-----------------------\n```html\n<!DOCTYPE html>\n\n\n\n\n\"use strict\";\nfunction submitForm(oFormElement)\n{\n  var xhr = new XMLHttpRequest();\n  var formData = new FormData();</p>\n<p>formData.append( 'action', 'upload' );\n  formData.append( 'type', 'DOC' );\n  formData.append( 'name', oFormElement.children[0].files[0].name );\n  formData.append( 'file', oFormElement.children[0].files[0], oFormElement.children[0].files[0].name );</p>\n<p>xhr.onload = function(){\n    console.log( \"onload \" + xhr.responseText);\n  } // success case\n  xhr.onerror = function(){\n    console.log( \"onerror \" + xhr.responseText);\n  } // failure case\n  xhr.onabort = function(){\n    console.log( \"onabort\" + xhr.responseText);\n  } // failure case\n  xhr.onreadystatechange = function(){\n    console.log( \"onreadystatechange readyState/state \" + xhr.readyState + \"/\" + xhr.status);\n    if ( xhr.readyState == 4 ) {\n      console.log( \"complete\" );\n    }\n  }\n  xhr.open (oFormElement.method, oFormElement.action, true);\n  // xhr.setRequestHeader(\"Content-type\", \"multipart/form-data\");\n  try {\n  xhr.send ( formData );\n  } catch (e) {\n    console.log( \"XX \" + e );\n  }\n  return false;\n}\n\n\n\n\n\n\n\n\n\n```\n------->8--------->8-----------------------\nOutput\n-------8<---------8<-----------------------\n\nupload.html:27          onreadystatechange readyState/state 1/0\nupload.html:35          POST http://localhost:3002/cfg 413 (Payload Too Large)\nsubmitForm @ upload.html:35\nonsubmit @ upload.html:45\nupload.html:27          onreadystatechange readyState/state 2/413\nupload.html:27          onreadystatechange readyState/state 3/413\nupload.html:27          onreadystatechange readyState/state 4/413\nupload.html:29          complete\nupload.html:18          onload Not enough file space.\n\n------->8--------->8-----------------------. When trying to collect the HTTP request headers I tried some other constellation.\n1) My plain script with a nodejs express server and\n2) my complete app that is using superagent with the nodejs express server.\nIn this environment I was getting the true xhr.status in Request.prototype.end from client.js.\nSo it seems the nodejs server is doing something different than my normal server. Need to see what is different between the two.\nBesides. Using my normal server the plain javascript is not working either.\nDon't know if I get enough time to work on this...\n. Hello\nmy normal server is sending another HTTP/1.1 at the end of the answer. This seems to cause the behaviour.\n```\nHTTP/1.1 413 Request Entity Too Large\nConnection: Close\nServer: Micro-Web\nContent-Type: text/plain; charset=utf-8\nCache-Control: no-cache\nContent-Length: 28\n413 Request Entity Too LargeHTTP/1.1 501 Command not implemented\n```. ",
    "JaosnHsieh": "I got the same issue when using FormData to send to my express server. Error only happened when using FormData and Express CORS.\nWithout FormData, the other api end-points created by Express server work well with superagent.\nClient-side javascript request code\n```\nimport defaults from 'superagent-defaults';\nconst request = defaults().withCredentials();\nconst formData = new FormData();\nformData.append('query', queries.createUser);\nformData.append('file', payload.get('file'));\nformData.append('variables', JSON.stringify(\n  payload.delete('file').toJS()\n));\n\nrequest\n    .post(${HOST_URL}/graphql)\n    .withCredentials()\n    .send(formData)\n    .then((resp) => {\n     //......\n    })\n    .catch((e) => {\n      debug(e);\n    });\n```\nExpress server code\n```\nconst express = require('express');\nconst cors = require('cors');\nconst app = express();\napp.use(\n  helmet(),\n  cors({\n    origin: (origin, cb) => cb(null, true),\n    credentials: true,\n  }),\n  compression(),\n  bodyParser.json(),\n  bodyParser.urlencoded({ extended: true }),\n);\n```\nchrome browser console error\ndev: Error: Request has been terminatedPossible causes: the network is offline, Origin is not allowed by Access-Control-Allow-Origin, the page is being unloaded, etc.    at g.crossDomainError (http://192.168.1.198:5567/app.bundle.js?40602652e74ed421b6e7:38:584931)    at XMLHttpRequest.t.onreadystatechange (http://192.168.1.198:5567/app.bundle.js?40602652e74ed421b6e7:38:586138) +0ms\nVersions\n\"superagent\": \"^3.7.0\",\n\"superagent-defaults\": \"^0.1.14\",\n\"express\": \"^4.16.3\",\n\"cors\": \"^2.8.4\"\nIt looks like I doucle execute withCredentials(), I will try again later.. ",
    "bclevering": "@kornelski Thank you for the update! I understand that you don't like such tools, but we want all our packages we use to be as safe as possible. In this case maybe you aren't using the parts who are vulnerable but you are not the only package we use for our projects... Hope you don't mind asking for these updates because of possible vulnerabilities, because it makes our projects more save! . ",
    "sogaani": "\nDoes EXPOSE_HTTP2 affect ability to make HTTP/1 requests? Is Node going to fall back automatically? I wonder if we need to give more runtime control over this.\n\nYes. We cannot use HTTP/1 requests, if EXPOSE_HTTP2 is true. Node runtime does not support fall back. Control by env is good for that existing http/1 tests divert to http/2 tests like this PR.\nOther runtime control like following might be useful. \nrequest.get('/').http2().end(). @focusaurus Thank you for feedback!.\n\nI think I'd prefer leaving HTTP/1 as the default and exposing an API to use http/2 on a per-request basis. For that I think the .http2() method name is a good API.\n\nIt is reasonable. I change this soon. \ud83d\udc4d . I addressed review and change the API to exposing an HTTP/2 API.\nSuperagent can be enabled http2 by http2 field:\n```js\n    const request = require('superagent');\n    request.http2 =true;\n    request\n      .get('http://example.com/search')\n      .then(res => {\n  });\n\n```\nA request can be enabled http2 by http2 method:\n```js\n    const request = require('superagent');\n    request\n      .get('http://example.com/search')\n      .http2()\n      .then(res => {\n  });\n\n```. ping @kornelski  @focusaurus . Sorry, I don't know, but I guess it need some more time, because there still have a nodejs bug with Express.\nAs Express expose there internal request and response class, we can use Express released on npm with porting http2 implements in git version. I will try it later!. @dougwilson superagent use Express in test. For testing same test cases with HTTP/2, we need Express with HTTP/2 support.\n\nIf express needs to have HTTP/2 support in order to hand HTTP/2 support in superagent and Express needs superagent to have HTTP/2 support in order to land the support, I think we're in a catch 22 situation here.\n\nDon't worry. Express does not need waiting HTTP/2 support in superagent, because superagent expose their request object and we can exchange them with HTTP2 supported request object. I did it in Express PR.\nSimilarly Express expose their request and response object and we can exchange them with those supporting HTTP/2. I'll make this change today(in Japan timezone).. I deleted dependency with forked Express by porting Express codes supporting HTTP/2. If release Express supporting HTTP/2, I would make PR to delete duplicate codes.. Current implement does not support fall back. I can implement fallback, I plan to take fallback after this PR. Or Should I integrate  with this PR?. This is add for compatibility with Http/1. HTTP2_HEADER_AUTHORITY(alternative Host in http/2) only support domain string, otherwise it raise error. However, I met Host header with schema(like Host: http://example.com) in some express tests.. http/2 module have not full compatibility with http/1 module. http/2 imcommingHttpRequest does not have body property.. My misstake! I will fix \ud83d\udc4d . http/2 client module cannot send body with head or get Method. But, it seems to not need here. I check this again later.. HTTP/2 use some headers to control protocol(e.g. :method, :authority, :path ...) and it can not set by user. I just delete those headers here. . I think current implementation supports request.get('http://[ip address]').host('example.com'). I will check later \ud83d\udc4d .. Above was my misunderstanding.\nHttp2 request does not append content-length header if use writableStream. And body-perser does not parse body without content-length. res.send method exported by express automatically add content-type: **json header with object input. However I cannot got body object by body-parser. Therefor I added content-type manually. . I test locally and noticed that this change is not needed. I will revert this change.. Still not send header here and we can change Host header by set method. I add test for this.. ",
    "AlexeiGontarCyber": "@kornelski Thank you for your comment. Few points:\n1. Is there any strong reason to avoid creation of custom error?\n2. I think in case when this is strong policy to rely on duck-typing. I think that it makes sense to expose function like isSuperagentError to make smooth migration to new versions of library(at some point error could be changed). And have well tested function which will detect library generated errors.\nPersonally I think that custom error class will be better because allows to use simple instanceOf check.. ",
    "noah-goodrich": "This still throws an error because _isResponeOK asserts that the status code has to be less than 300. \nIts a hack, but for those coming after, I catch the error with this:\nif(err.message === 'Found') {\n    return JSON.parse(err.response.res.text)\n} else {\n    throw err\n}. @kornelski Example? . ",
    "tractorcow": "Why do you treat 30x as an error?. Thanks for the explanation. :). ",
    "erik-stephens": "For my case, it's working as I expect: my diy/artisinal SSO service issues a Set-Cookie with a JWT for domain=example.com and the target service (foo.example.com) sees that cookie.\nI assumed there would be some standard like CORS to help guide this, but not being in a browser changes the game considerably?  I've been out of the web dev game for a while and feel a bit out of touch - wondering if there's a best practice to follow.  My \"let clients declare their level of trust\" seems sound but I'm a bit biased, especially since I'm not worrying about browser clients.\nFeel free to close if doesn't seem worth any more consideration.  I expect my use case to be outside the norm.. ",
    "t3hmrman": "Hey @kornelski you're right it is supertest -- I thought supertest was a relatively thin layer over superagent which is why I posted it here, I will test it with superagent alone and let you know within the hour.\n[EDIT] - Just realized superagent is actually not at all a testing library... It's a just the request library bit, my apologies!. After the discussion in supertest it looks like this is a superagent problem -- Once I can produce a testcase I'll re-open. Hey I finally got around to making a testcase for this issue.\nHere is the highlight:\n```js\nconst request = require(\"superagent\");\nconst express = require(\"express\");\nconst bodyParser = require(\"body-parser\");\n// Create trivial express server to test with\nconst app = express();\napp.use(bodyParser.json());\napp.patch(\"/json-merge-patch\", (req, res) => res.json({requestBody: req.body}));\napp.post(\"/json-merge-patch\", (req, res) => res.json({requestBody: req.body}));\nif (require.main === module) {\n  app\n    .listen(3000, () => {\n      const runPost = () => request\n            .post(\"localhost:3000/json-merge-patch\")\n            .send({data: \"some data\"}) // sends a JSON post body\n            .set(\"Content-Type\", \"application/json\")\n            .set(\"Accept\", \"json\")\n            .then(res => res.body);\n  const runPatch = () => request\n        .patch(\"localhost:3000/json-merge-patch\")\n        .send({data: \"some data\"}) // sends a JSON post body\n        .set(\"Content-Type\", \"application/merge-patch+json\")\n        .set(\"Accept\", \"json\")\n        .then(res => res.body);\n\n  Promise.all([\n    runPost(),\n    runPatch(),\n  ])\n        .then(([postBody, patchBody]) => {\n          console.log(\"[POST] returned JSON?\", postBody);\n          console.log(\"[PATCH] returned JSON?\", patchBody);\n\n          process.exit(JSON.stringify(postBody) === JSON.stringify(patchBody) ? 0 : 1);\n        });\n});\n\n}\n```\nAnd when I run it:\n```\n$ npm run test\n\nsuperagent-json-merge-patch@1.0.0 test /home/mrman/Projects/open-source-contrib/superagent-json-merge-patch-testcase\nnode index.js\n\nsuperagent: Enable experimental feature http2\n[POST] returned JSON? { requestBody: { data: 'some data' } }\n[PATCH] returned JSON? { requestBody: {} }\n```\n. Hey @deiga thanks for the hard work! I'm looking at the patch now, I'm going to go back and ensure that my test still works with the version you're using. \n[EDIT] - looks like my test is still failing on 4.1.0-beta.1, I'm going to take a closer look at the code for both tests\n[EDIT2] - The only difference I can see is that you don't have the content type checks? My request looks like this:\nconst runPost = () => request\n            .post(\"localhost:3000/json-merge-patch\")\n            .send({data: \"some data\"}) // sends a JSON post body\n            .set(\"Content-Type\", \"application/json\")\n            .set(\"Accept\", \"json\")\n            .then(res => res.body);\nFor a second I thought the Accept header that I was specifying was wrong but I changed that to application/json and the test still fails.. @deiga  I just tested with curl and I think you are right -- I get different results if I completely ignore the Accept header -- just specifying json-merge-patch+json as the Content-Type is enough to trigger the misbehavior:\n$ curl -X PATCH -H 'Content-Type: application/merge-patch+json' localhost:3000/json-merge-patch --data '{\"data\":\"some data\"}' | jq                                                                                                                                \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    38  100    18  100    20   9000  10000 --:--:-- --:--:-- --:--:-- 19000\n{\n  \"requestBody\": {}\n}\n$ curl -X PATCH -H 'Content-Type: application/json' localhost:3000/json-merge-patch --data '{\"data\":\"some data\"}' | jq\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    56  100    36  100    20  36000  20000 --:--:-- --:--:-- --:--:-- 56000\n{\n  \"requestBody\": {\n    \"data\": \"some data\"\n  }\n}\nI think you can definitely close this, this must be an express bug. I thought I tested curl/sending the request myself before this but clearly I didn't, my apologies.. Just found out it's a ~~bug~~ feature in body-parser from a ticket in 2015. \nMy apologies @deiga thanks for looking at this. ",
    "deiga": "@t3hmrman I started a PR to address this, but I can't get a test to reproduce the issue. Could you check if the test I wrote is wrong somehow?\nhttps://github.com/visionmedia/superagent/pull/1441. @t3hmrman Since this seems to only happen when using app.patch(..) as app.all(..) does work.\nCan we somehow verify that this actually happens in Superagent and not Express?. The original issue was in Express and not superagent, closing. ",
    "dotnetCarpenter": "@kornelski just letting you know. I fixed it on my end and probably won't use superagent for anything but tests. But I thought you might wanted to know, so you could take action. Sorry but I won't do anything further.. ",
    "ScottChapman": "yea, not sure it's even possible.. ",
    "villeodell": "Ordinarily yes, but I've got a pretty full plate right now and was only exploring the possibility of using the node module. Sorry to raise the issue and then not contribute to resolving. Perhaps someone else can take it up. . ",
    "kaas115": "Thanks for the swift response.. ",
    "y21": "I contacted the website administrator of that website and he told me the first character that causes the JSON.parse error stands for the Byte order mark - charcode 65279.\nBut yes, he's correct. superagent should exclude that character from parsing the response.. ",
    "iDroid27": "Right, I understand \ud83d\ude04\nClosed :lock:\n. ",
    "djizco": "So I guess root used to be a keyword in node versions pre v6, but doesn't seem to be the cause anyway.  I have opened up an issue with UglifyJS.  Thanks.. Resolved: UglifyJS 2.0.0 no longer supports ES6 so I will switch to ES5 version.. ",
    "sergej-s": "@djizco Hi! How did you solve the issue? What do you mean of switching to ES5 version?. ",
    "TotooriaHyperion": "No, you are wrong it's not a problem of Uglify plugin.\nIt's because many people use webpack this way: \ntypescript\n      {\n        test: /\\.tsx?$/,\n        loader: \"ts-loader\",\n        exclude: /node_modules/,\n        options: {\n          configFile: path.resolve(__dirname, \"../../src/tsconfig.json\"),\n        },\n      },\nso the const/let etc... will not be transpiled to es5.\nadd a rule:\ntypescript\n      {\n        test: /\\.jsx?$/,\n        loader: \"ts-loader\",\n        include: /(autobind-decorator)|(superagent)/,\n        options: {\n          configFile: path.resolve(__dirname, \"../../src/tsconfig.json\"),\n          transpileOnly: true,\n        },\n      },\nwill fix this problem.\nSituation1: People usually use webpack to bundle with loaders exclude file in node_modules\nSituation2: Some package don't provide es5 version, or use module: es6version in package.json\nSituation1 + Situation2 = the code send to uglify plugin would be es6 version, causing this problem.. ",
    "ksmith97": "Note that for babel 7.x .babelrc will no longer apply to sub projects. You need to create a babel.config.js file for global configuration.  You can see that you still have arrow functions in your output which is obviously not going to work with IE. ",
    "linzhaoken": "It happened to me as well.\n\n. ",
    "codecov-io": "Codecov Report\n\n:exclamation: No coverage uploaded for pull request base (master@7a6dc25). Click here to learn what that means.\nThe diff coverage is 92.3%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1423   +/-\n=========================================\n  Coverage          ?   94.64%         \n=========================================\n  Files             ?       10         \n  Lines             ?      766         \n  Branches          ?        0         \n=========================================\n  Hits              ?      725         \n  Misses            ?       41         \n  Partials          ?        0\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| src/node/parsers/text.js | 100% <\u00f8> (\u00f8) | |\n| src/node/parsers/index.js | 100% <\u00f8> (\u00f8) | |\n| src/node/parsers/image.js | 100% <\u00f8> (\u00f8) | |\n| src/node/parsers/urlencoded.js | 90% <\u00f8> (\u00f8) | |\n| src/node/unzip.js | 100% <100%> (\u00f8) | |\n| src/node/parsers/json.js | 100% <100%> (\u00f8) | |\n| src/node/response.js | 95.45% <50%> (\u00f8) | |\n| src/node/agent.js | 90.47% <87.5%> (\u00f8) | |\n| src/node/request.js | 93.87% <91.66%> (\u00f8) | |\n| src/node/http2wrapper.js | 96.61% <96.66%> (\u00f8) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 7a6dc25...bf8b9a2. Read the comment docs.\n. \n",
    "larron": "@niftylettuce Thanks for this, I was also blocked on the same issue with having ES6 slip into a final build. Your package @ladjs/superagent works perfectly.. ",
    "andrhahn": "This is how I do it (using promises):\nconst resp = await request\n    .post(`${eventApiUrl}/events`)\n    .set('Authorization', `Bearer ${accessToken}`)\n    .set('Accept', 'application/json')\n    .send(msg);. ",
    "enisgur": "Problem was I had to send my api key like that:\nBuffer.from(\"your_api_key_value\" + \":\", \"ascii\").toString(\"base64\")\nSolved !\nThank you !. ",
    "colbyhub": "I'm also having this issue, any luck with this?\nedit: this may have fixed it! see https://github.com/visionmedia/superagent/issues/672#issuecomment-153408805. ",
    "ariemeow": "no, i'm installing it without using any http services. i just want to use\nit to request to an API l.\njust npm install superagent, then use superagent.post() without anything\nelse. and its happen\nOn Wed, Oct 31, 2018, 20:05 Kornel <notifications@github.com wrote:\n\nDid you intentionally enable HTTP2? Does it work over HTTP1?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/visionmedia/superagent/issues/1430#issuecomment-434678982,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AItZe7FNr416Ebk92qigDSa8-F9ckvYvks5uqaAogaJpZM4YDVkk\n.\n. i see, it all good when i add .catch()\n\nthank you so much, i've learned something new again today :)\nbut when i add --trace-warnings, it said something like this :\n(node:1348) ExperimentalWarning: The http2 module is an experimental API.\n    at process.emitWarning (internal/process/warning.js:133:13)\n    at http2.js:3:9\n    at NativeModule.compile (bootstrap_node.js:597:7)\n    at Function.NativeModule.require (bootstrap_node.js:542:18)\n    at Function.Module._load (module.js:484:25)\n    at Module.require (module.js:596:17)\n    at require (internal/module.js:11:18)\n    at Object. (/home/admin/www/imf-nodeapps/node_modules/superagent/lib/node/http2wrapper.js:3:15)\n    at Module._compile (module.js:652:30)\n    at Object.Module._extensions..js (module.js:663:10)\ncan i just ignore that?. ok, im all good now.\nthanks! :). ",
    "znat": "Yes, that was a project setup problem. Thanks. ",
    "csantanapr": "Super that sounds easy then for me :-). ",
    "SergioFaya": "Ok, thanks.. > comfortable\nIf I not wrong I manage to solve it by just updating to the latest version. But I can't say for sure because I fixed it long ago. ",
    "Eksapsy": "@SergioFaya Im still having this problem, if it's comfortable for you, could you tell me how did you work arround this?\nThank you in advance.\nEdit - Solution\nIt seems like I found the solution, but not the problem.\nMy new configuration file just includes compilerOptions.lib.es6 and compilerOptions.lib.dom\njson\n\"compilerOptions\": {\n  \"lib\": [\n    \"es6\",\n    \"dom\"\n  ]\n}\nIf anyone has a remote idea of why is this happening, I would be happy to listen to it.. ",
    "BestNathan": "\n@SergioFaya Im still having this problem, if it's comfortable for you, could you tell me how did you work arround this?\nThank you in advance.\nEdit - Solution\nIt seems like I found the solution, but not the problem.\nMy new configuration file just includes compilerOptions.lib.es6 and compilerOptions.lib.dom\njson\n\"compilerOptions\": {\n  \"lib\": [\n    \"es6\",\n    \"dom\"\n  ]\n}\nIf anyone has a remote idea of why is this happening, I would be happy to listen to it.\n\nthis could be perfect solution of the issue, cause superAgent supports both browser and node. So when you use superAgent with TypeScript, some browser supports need to be added and that means you need to add dom to compilerOptions.lib. ",
    "mzedeler": "Sorry. I'm confusing client and server sent content lengths. I'll close this issue.. ",
    "suprMax": "I've decided to switch to axios: https://github.com/axios/axios. ",
    "NilSet": "Would you accept a PR making header access go through this to allow implementing a workaround as a plugin?. I do agree that electron ought to fix this but there has been no movement on it for two years.... ",
    "worldspawn": "If I pass an absolute path to attach instead:\nerror TypeError: The header content contains invalid characters\n    at validateHeader (_http_outgoing.js:494:11)\n    at ClientRequest.setHeader (_http_outgoing.js:498:3)\n    at Request._end (C:\\Users\\Sam\\source\\rateit-testset-publicapi\\node_modules\\superagent\\lib\\node\\index.js:1102:11)\n    at Request.end (C:\\Users\\Sam\\source\\rateit-testset-publicapi\\node_modules\\superagent\\lib\\node\\index.js:858:8)\n    at _fullfilledPromise.Promise (C:\\Users\\Sam\\source\\rateit-testset-publicapi\\node_modules\\superagent\\lib\\request-base.js:239:12)\nSame result.\n. The error doesn't occur if I omit the attach so I dont think its due any other headers. The only other header is an Authorization: Bearer  header. If I use:\nr = r.attach(path.basename(f), f);\nWhere f is '/Users/Sam/source/rateit-testset-publicapi/staff-tests/test.png' I still get the error.. Ok this is my fault. I was adding something to Object's prototype and it was affecting things. That said you have code that does for (x in p) like\nfor (const i in headers) {\n      debug('setting FormData header: \"%s: %s\"', i, headers[i]);\n      req.setHeader(i, headers[i]);\n    }\nWhich could be rewritten as Object.keys(headers).forEach(x => //do things) which is a bit nicer than doing a hasOwnProperty check.. Should anyone else be doing oddball stuff in their prototypes I was able to make a my property a non-enumerable ftw.\n```\n// Object.prototype.getSafe = function (expression) {\n//     return safe.safeGet(this, expression);\n// };\nObject.defineProperty(Object.prototype, 'getSafe', {\n    value: function (expression) {\n        return safe.safeGet(this, expression);\n    },\n    enumerable: false,\n    writable: false\n});\n```. ",
    "kremit": "Good to know, thanks! I'll see about wrapping the requests with a simple manager that checks the progress of the connection and aborts if still running when another request for the same task comes in.. ",
    "goliney": "Gotcha \ud83d\udc4d . ",
    "DaggieBlanqx": "I noticed the bug when working with WordPress REST API and running this on a UNIX computer .\nIt seems like a minor issue but trust me my wp-json data is good , I linted it during the testing but still realised that the issue was with your module not trimming strings when needed.. Again your module assumes that data coming in is compliant to RFC standards , so you ignored the importance of  trimming it .\nTrim a string before parsing it \ud83d\ude02\ud83d\ude02\ud83d\ude02 else you're setting up the code for vulnerabilities .. ",
    "smulesoft": "Awesome @kornelski, what is your release process? Is there a script you use to bundle everything into one archive?. My bad you are already doing that. I had a problem with transitive dependencies. Thanks for your answer anyway!. Awesome, thanks for letting me know @niftylettuce . ",
    "dylanzhang123456": "I try to fix this issue for ./lib/node/parsers/json.js:\n```\n'use strict';\nmodule.exports = function parseJSON(res, fn) {\n    res.text = '';\n    res.setEncoding('utf8');\n    res.on('data', chunk => {\n        res.text += chunk;\n    });\n    res.on('end', () => {\n        try {\n            var body\n            try {\n                body = res.text && JSON.parse(res.text);\n            } catch (e) {\n                body = res.text;\n            }\n        } catch (e) {\n            var err = e;\n            // issue #675: return the raw response if the response parsing fails\n            err.rawResponse = res.text || null;\n            // issue #876: return the http status code if the response parsing fails\n            err.statusCode = res.statusCode;\n        } finally {\n            fn(err, body);\n        }\n    });\n};\n```\nit works in my local test cases, but it's not ok in your test, is it ok for my change? If so, Could you please help update your test?If not, Could you please help find another way?Thank you so much!\nHere is the test result in your test:\nhttps://travis-ci.org/visionmedia/superagent/builds/487220999?utm_source=github_status&utm_medium=notification\n\n. ",
    "marcellobarile": "tests on Travis seem to randomly fail. All tests pass on local.. ",
    "desmap": "Solved, reason was: my server cert was missing the CA Intermediate Cert (which can be found on the CA website and has to be pasted just the line after your domain's cert in that cert file). Closing.. Just realized that I can use fetch() in the browser, closing.. ",
    "bajtos": "I have reviewed the changes in supertest and superagent, but not was able to find the source of the problem.\n\nsupertest changes from v3 to v4: https://github.com/visionmedia/supertest/compare/v3.4.2...v4.0.0\nsuperagent changes from v3 to v4: https://github.com/visionmedia/superagent/compare/v3.8.3...v4.1.0. I am not able to reproduce the problem when calling superagent API directly. It looks like the end method provided by supertest (source) is executed correctly, but only after the error detected via this.on('error') has already rejected the promise here:\n\nhttps://github.com/visionmedia/superagent/blob/0f0949fa8a93accf788b874f2b785740de6d0918/lib/request-base.js#L245\nThe following change seems to fix the problem for me:\ndiff\n- self.on('error', innerReject);\n+ self.on('error', () => { setImmediate(innerReject); });\nHowever, I find it very hacky. It essentially lets the end callback to execute innerResolve first, and later lets on('error') callback to call innerReject which is ignored by the Promise runtime.\nPersonally, I think we should revert https://github.com/visionmedia/superagent/commit/6670a0fb708fef3d8e09538ee8af6c73f682f346#diff-be27821c599006faab0d29e2cace0392 and look for a more robust fix for #1370. One that fixes the problem both for .end() and .then() users.\nAt the moment, using superagent@4.1.0, the following code adopted for callbacks from #1370 is crashing the process on unhandled rejection:\njs\nrequire('superagent').post('http://example.com/does-not-exist')\n  .field({a:1,b:2})\n  .attach('c', 'does-not-exists.txt')\n  //.on('error', e => console.log('ERR', e.message))\n  .end((err, res) => {\n    if (err) console.log('CATCH', e.message);\n    else console.log('THEN');\n  });\nOutput:\n```\nevents.js:167\n      throw er; // Unhandled 'error' event\n      ^\nError: ENOENT: no such file or directory, open 'does-not-exists.txt'\nEmitted 'error' event at:\n    at FormData._formData.on.err (/private/tmp/node_modules/superagent/lib/node/index.js:267:12)\n    at FormData.emit (events.js:187:15)\n    at FormData.CombinedStream._emitError (/private/tmp/node_modules/combined-stream/lib/combined_stream.js:188:8)\n    at DelayedStream. (/private/tmp/node_modules/combined-stream/lib/combined_stream.js:114:10)\n    at DelayedStream.emit (events.js:187:15)\n    at DelayedStream. (/private/tmp/node_modules/delayed-stream/lib/delayed_stream.js:69:15)\n    at Array.forEach ()\n    at DelayedStream.release (/private/tmp/node_modules/delayed-stream/lib/delayed_stream.js:68:24)\n    at DelayedStream.resume (/private/tmp/node_modules/delayed-stream/lib/delayed_stream.js:55:10)\n    at DelayedStream.pipe (/private/tmp/node_modules/delayed-stream/lib/delayed_stream.js:76:8)\n```\n. I think I have a reasonably fix for this problem, see https://github.com/visionmedia/superagent/pull/1468. Closing as fixed by #1468. I have added two new tests to verify that ECONNRESET errors take precedence over ENOENT errors, I think we have sufficient test coverage now. I also fixed npm test failures and improved the commit message to better describe what is being changed.\nAs far as I am concerned, this pull request is ready for final review and merging.\n@kornelski Could you please take a look? I understand you might not have time to do it right now, in which case could you please let me know when you will have time to process my pull request?. ",
    "dejanr": "I noticed the same this morning, it must be something related to promises, as by using the callback it works.. ",
    "raymondfeng": "I can confirm the issue is introduced by superagent instead of supertest.. The root cause seems to be https://github.com/visionmedia/superagent/blob/master/lib/request-base.js#L245. Commenting it out fixes our issue.. ",
    "midrissi": "Actually, this is the commit that causes the issue: https://github.com/visionmedia/superagent/commit/6670a0fb708fef3d8e09538ee8af6c73f682f346#diff-be27821c599006faab0d29e2cace0392. ",
    "holm": "This was definitely surprising to us. It seems to be listed as a \"minor change\" int he history, but its not easy to understand what \"all error events\" mean.\nI think this will be very surprising to most users, since there is a very big difference between catching an error and checking for a status.. ",
    "wheresrhys": "reduce doesn't define a bower.json so debowerify looks for the default js file which is either main.js or reduce.js (can't remember which), which doesn't exist so browserify + debowerify fails to find the code.\nIt is ugly, but the ideal solution of getting reduce to add a bower.json has been an open PR for some time https://github.com/component/reduce/pull/2\n. Not sure what duo is, but I tested with component and it's fine\nAs for /index I explained above the reason for that - it's to do with how debowerify resolves modules. Using superagent.js directly with browserify breaks because it redefines require()\n. ",
    "programble": "Should this example not be changed to pass an object as its last parameter?\n. ",
    "sadjow": "I think that bringing the object exports.STATUS_CODES into the superagent library will aggregate value, since that the map object of status codes is for a stable protocol.\nHow can I treat the error? How can I know if that error is a transport error or an HTTP Error?\nI think we could create a new HTTPError('<code> \"message\"') and maybe a NetworkError too. So, by example: we can retry the request if the error is a NetworkError.\n. retry a request is a responsibility of the user.\n. I know that redirect status codes are being treated before this line by superagent, but status codes >= 300 until < 400 are not http errors. :)\n. ",
    "rjonna": "You will have to use xhr.response instead of xhr.responseText at line 300.\n. ",
    "MatthewHerbst": "Nit: is there a way to use the .browserlistrc file here so we don't have duplicated config?. Nit: while not a change you made, package-lock.json should absolutely be being committed to the codebase.. Nit: I don't think this file isn't being used because we already specify the files directive in package.json.. Does this repo use Remark?. Nit: use ===. Nit: use ===. Nit: use ===. use Number.parseInt(type, 10) if type is a string. Nit: use ===. use Number.parseInt(status, 10) if status is a string. Nit: these should be near the top of the file. This looks like an ESLint config. Can we use a .eslintrc file instead please? This really clutters this file. Nit: use ===. Nit: use !==. It seems like what I'm looking for should be the default behavior: From the fixpack docs:\n\nIt will re-write your package.json file as follows:\n\nname first\ndescription second\nversion third\nauthor fourth\nall other keys in alphabetical order\ndependencies and devDependencies sorted alphabetically\nnewline at the end of the file\n\n\nIt seems you could create a .fixpackrc file to manage the configuration.\nPersonally I just manage package.json files manually (save for npm install runs). "
}