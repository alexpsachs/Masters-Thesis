{
    "davisking": "No problem :)\nYeah, oops, the file is missing.  I just added it and make test should work now.  Thanks for pointing this out.\nCheers,\nDavis\n. Thanks for finding this.  I just pushed the fix to github.\nCheers,\nDavis\n. The preprocessing and tokenization in ner_stream is pretty basic.  However, we are setting up python, R, and java APIs right now that will make it easy for you to use whatever kind of preprocessing and tokenization you want (e.g. like NLTK's tokenizer) since in general different applications require different sorts of preprocessing and tokenization.  But yeah, it's annoying that the default tokenizer doesn't handle a smartquote.  So I just updated it and if you pull and recompile it should work properly now.\nCheers,\nDavis\n. Very cool :)\nHowever, I already setup a python API that works on windows, linux, and mac os (see https://github.com/mit-nlp/MITIE/blob/master/examples/python/ner.py).  I forgot to push it into github though so it wasn't publicly viable until a few minutes ago.  Sorry I didn't post it earlier.\nCheers,\nDavis\n. Yeah, sorry :)\nThe example is documented reasonably well.  I still need to add python docs to the actual functions though, which I'll do soon.\n. Thanks, will do.\nIt doesn't have an interface for training document classifiers, but that's\non our todo list.\nOn Wed, Apr 16, 2014 at 1:44 PM, maksim2042 notifications@github.comwrote:\n\nI'll be test-driving it shortly :-) let me know if you need help debugging\nor documenting.\nAlso -- can mitie be trained for document classification?\nSent from my iPhone\n\nOn Apr 16, 2014, at 1:41 PM, \"Davis E. King\" notifications@github.com\nwrote:\nYeah, sorry :)\nThe example is documented reasonably well. I still need to add python\ndocs to the actual functions though, which I'll do soon.\n\u2014\nReply to this email directly or view it on GitHub.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mit-nlp/MITIE/pull/4?utm_campaign=website&utm_source=sendgrid.com&utm_medium=email#issuecomment-40629280\n.\n. Sweet, thanks for the fix.\n. Ah, that's right.  I forgot about the double _ rule.  I'll change the names. thanks for pointing this out.\n. Just fixed them.\n. No problem.  Thanks for pointing it out :)\n. Yeah, that's a bug :)  I just fixed it, if you pull from the git repo it should be fixed.\n. I think I just fixed the FFTW related error.  @myeesw, can you see what's up with the other issues?  I don't have access to an OS X machine :)\n. Cool.  I can't do much right now because I'm at a hotel and SSH is firewalled (WTF?).  But you should say in the ensures comment how to interpret the score.  Something like \"the larger the value the more likely the tag is to be correct.  Additionally, output with a score < 0 is probably incorrectly tagged.  That is, the canonical decision threshold is at 0.\"\n\nAlso, it's probably a good idea to output all the chunks rather than discarding the ones that are predicted as \"not a label\".  None of the multiclass linear decision function's methods do that, but it's a basic computation and the members of the df object are public.  You just have to ignore whatever row of the weights matrix corresponds to that tag.\n. It's all good.  I wouldn't use a branch.  Branching in git is a hassle and your own repo is effectively a branch anyway.\nYou can do it as multiple pulls.  Whatever you want.  Also, I just told someone who asked about it that it would be done shortly :)\n. Sweet, looks good.  I'm glad you didn't take my advice about ignoring the \"not a label\" part.  Now that I'm looking at the API I can't think of a way of doing that that doesn't severely complicate the API.  I guess there could be a switch on the ner extractor that enables or disables it, but don't add that until we can think of a really compelling use case for it.  \nAnyway, looks good.  I'll run the test and look it over in more detail when I get back in town on Monday.\n. Looks good.  I just merged it.  Sorry it took so long.  It's been hell with the weather and everyone in my house being sick.\n. Sure, I just incremented the version :)\n. Don't worry about it.  I think it's very unlikely that this change will\ntrouble any MITIE users very much, if at all.\n. Yeah, sorry about that.  Variations in how cmake deals with libjpeg have really been a pain lately.  Anyway, it should be fixed now.  Repull from github and it should work.\n. No problem :)\n. What happens when you run it?. That's just how the optimizer works.  To do the training with any non-trivial amount of data you need to compile in 64bit mode and use a 64bit OS.  Otherwise you can only use 2GB of ram which isn't very much.\n. 13GB is a lot for 198 samples.  How exactly did you run the trainer?\n. That doesn't look like it should run at all.  The trainer.add() method is\nsupposed to take a ner_training_instance object.  Is that what\nstrip_braces() returns?\nCan you post a complete program that reproduces the problem?  One that I\ncan run?\n. What about the RAM usage.  When I run the python trainer I don't get anything like 13GB of RAM usage.  What happens when you run our provided train_ner.py python program?  Does it use a lot of RAM or is only on your data that this happens?\n. Can you post the inputs you used to run this such that I can exactly reproduce this issue?\n. Sounds good. \nThe only reason I can think of that might cause this is if you use a very large number of labels.  How many different label strings did you use?  E.g. the example program uses just person and org so that's 2 different types of labels.  If you used 1000 then it's going to take a huge amount of RAM because it solves a big multiclass linear SVM in the last step that uses an amount of RAM linear in the number of distinct labels. \n. That amount should be fine.\n. Can you post your training data? :)\nWe (and a bunch of other groups) have been using MITIE to train models and\nhaven't had any issues.  So I need one of you guys to post a program that\nreproduces the issue you are having or it's going to be impossible to debug\n:)\n. Sounds good.  You can email me at davis@dlib.net\n. Thanks.  Please also include a working python program that when executed causes this large ram usage bug to appear so that I can debug it.\n. I've looked this over and the problem is in the training data given to MITIE.  However, before I explain the issue it's helpful to understand a little about how MITIE works.  In MITIE, each sentence is chunked into entities and then each chunk is labeled by a multiclass classifier (a multiclass support vector machine specifically).  To classify each chunk, MITIE creates a 501354 dimensional vector which is given to the multiclass classifier.  \nNow the way the multiclass classifier works is it learns one linear function for each label (and an addition one for the special 'not an entity' category).  So if you have N labels then the classifier has 501354(N+1) numbers it needs to learn.  Moreover, since we use a cutting plane solver there is an additional factor of RAM usage in the solver, let's call it Z.  The amount of RAM used by the multiclass trainer is 501354(N+1)Zsizeof(double) + (the amount of RAM needed to store the training data).  That means there are 501354(N+1)Z*sizeof(double) bytes of RAM usage no matter the size of your dataset.\nThe Z value is normally in the range 40-80.  However, if you give input data that is basically impossible to correctly classify then the solver needs to work harder to find a way to separate it so Z might go up to about 200.  It will also take a long time to train.  In your case, you gave data with these 18 labels: 'builder', 'project', ' builder', 'size', 'location', 'price', ' price ', 'Infra', 'time', 'price psf', 'loction', ' time', ' size', ' location', ' infra', ' price', ' project', 'infra'.\nNow what's happening is MITIE is trying to figure out, for example, how to separate the ' price', 'price', and 'price ' labels but this is probably impossible as I'm sure you meant to give all these things the same label.  But the MITIE solver still tries and it needs a large Z to build up a high accuracy solution that can do this.  So if Z=200 and N=18 then 501354(N+1)Z*sizeof(double)=14GB of RAM.\nSo the solution is to fix your training data so that the labels make sense.  If you do that then I would expect more like 2GB-4GB of RAM usage.  I have also updated the MITIE code to print the labels supplied by the user.  So if you pull from github and rerun it will show these labels and that should make this kind of error a lot easier to spot in the future.\n. You train the model using python or C++ and then load the model file in java.  Right now there isn't a training API for java.\nYes, MITIE is state-of-the-art (http://blog.dlib.net/2014/04/mitie-completely-free-and-state-of-art.html) and very fast.  The NER in OpenNLP is not very good.  There is a Stanford library that is just as accurate as MITIE but it's not free for commercial use.  \nAlso, running MITIE consumes basically just the amount of memory for loading the model file.\n. Sweet :)\nIt's on our list, but it's somewhat lower priority than other things since\nmost people are fine running the training in python and then using the\nmodel via whatever API they like.\n. Try running the example programs in the examples folder.  Those will definitely work.\n. There is now a MITIE Java API thanks to this PR https://github.com/mit-nlp/MITIE/pull/32\n. Thanks :)\nWe don't have any plans to update the models.  The general plan is to add some more features (e.g. document classification, part of speech tagging) rather than to keep tweaking models.  Moreover, an important feature of MITIE is the ability to train custom models.  So if there is some data you have that doesn't work the way you want with the included MITIE model then the idea is that you can train your own custom model.\n. The next thing we add to MITIE is going to be text classification.  It would be in there already but we have been unexpectedly busy with a bunch of other things.  In the meantime, you can easily make text classification tools using one of dlib's linear SVM classification tools (see http://dlib.net/ml.html).  You will have to write the code to convert the text into a feature vector but beyond that dlib has everything else.\n. Yeah yeah :)\n. sentencet_of_feats doesn't produce a feature vector, it produces a set of feature vectors, one for each word.  To do document classification you need create one feature vector (of fixed length) for the entire document.  \nAdding document classification to MITIE would require implementing multiple different \"document to feature vector\" representations from the academic literature.  Then when someone calls train in MITIE it should try all of them, checking the results with cross validation, and then returning the best classifier to the user so that the user doesn't need to think about anything.  So it's a little more complex than you imagine.  A reasonable implementation in MITIE would need to include a few different \"bag of words\" models as well as some word vector models and likely combinations of the two.\n. You could sum them and that might work fine for some applications.\nThe most common document to feature vector method is the \"bag of words\"\nmethod which isn't any kind of neural network.  The other thing that is\npopular is the \"word vector\" method which is sometimes done with a neural\nnetwork, but in MITIE we use the eigenword method (\nhttp://www.pdhillon.com/dhillon15a.pdf) which is a better way of estimating\nthese vectors.  I haven't seen any deep learning methods applied to\ndocument classification, aside from these \"word vector\" methods already\nused by MITIE.\n. Yeah, I know about paragraph vector.  We might add some kind of paragraph\nlevel vector representation to MITIE at some point.  But right now I'm busy\nfinishing the deep learning tooling in dlib :)\n. Now addressed by PR https://github.com/mit-nlp/MITIE/pull/49 \n. It should just be a matter of producing a good training dataset.  We would make the training datasets public to make retraining easier but their licenses prevent that.  If building or buying appropriate training data isn't going to be reasonable for you then the best thing to do is as you say just include some additional rules or post processing. \n. We used the CoNLL 2003 NER task data along with some of the ACE 2008 data.  The CoNLL data is the most useful though so that's what I would mainly focus on.\n. CoNLL and ACE :)\n. You would add whatever cases you personally care about to CoNLL and then train on the whole thing.\n. This is by design.  MITIE does everything using UTF-8 and those offsets are\nthe reported byte offsets into the UTF-8 strings.  If you want to know the\ncharacter offset then you need to use a routine that converts from UTF-8\nbyte positions into character counts.\nCheers,\nDavis\n. There isn't any paper specifically about MITIE.  However, since MITIE is basically just a thin wrapper around dlib I would cite dlib's JMLR paper: http://dlib.net/faq.html#HowcanIcitedlib\nThanks, I'm glad you like it :)\n. The train-ner script you found is in the same folder as the ner program.  Also, to train a german model you will have to use the wordrep program to train a german word model before doing any entity extraction training.\n. Thanks for the patch\n. This is offtopic for the MITIE project.  But you should use cmake to compile your project if you don't know how to use gcc.\n. You don't have X11 installed correctly.  Did you install XQuartz?\nAlso, where does cmake think X11 is?  Run this command and post the output:\ngrep X11 CMakeCache.txt\n. CMake is finding the anaconda copy of X11 which is missing files.\nIf you edit dlib/CMakeLists.txt at line 149 to say:\nfind_path(xlib_path NAMES Xlib.h Xlocale.h\ninstead of this:\nfind_path(xlib_path Xlib.h\nDoes it fix the problem?  You will probably have to delete the folder and\nrerun cmake.\n. It says \"Build files have been written to:\n/Users/davidlaxer/MITIE/mitielib/java\".\n ;-)\n. No, it is unrelated.  It's because you also ran cmake in the parent folder\nand generated files there.  Delete the entire source tree and try again to\nclear out any build files you have generated.\n. That didn't rerun cmake. Delete all the build files you generated and rerun\nit from scratch.  I would just reclone the repo and try from a fresh copy.\n. Hmm, try replacing that find_path statement with this:\nfind_path(xlib_path_hint X11/Xlocale.h )\n        find_path(xlib_path Xlib.h\n           HINTS ${xlib_path_hint}\n           PATHS\n           /Developer/SDKs/MacOSX10.4u.sdk/usr/X11R6/include\n           PATH_SUFFIXES X11\n           )\n. Yeah, that's what I mean.  What do you see when you grep your\nCMakeCache.txt file for xlib?  What path does it find?  Still the broken\nanaconda one?\n. What about grep xlib CMakeCache.txt?\n. Seems like it should have worked.  Is there a\n/opt/local/include/X11/Xlocale.h file on your machine?\n. Huh, well, you can change the CMakeLists.txt back to the way it was at the\nbeginning but tell it to look for Xlocale.h instead of Xlib.h and it should\nwork fine.  It would be preferable to make cmake check that both those\nfiles are there, especially since Xlib.h is the main header for X11, but\nfinding the folder based on the presence of Xlocale.h is probably robust\nenough.\n. Ha, sweet.\n. Yes, isn't everyone? :)\n. It comes with example programs that do this, look in the examples folder.\nThere are also the two release announcements on the dlib blog that explain\nit as well.\nhttp://blog.dlib.net/2014/04/mitie-completely-free-and-state-of-art.html\nhttp://blog.dlib.net/2014/07/mitie-v02-released-now-includes-python.html\n. No problem.\n. Yeah, I've moved all the dlib files over to another hosting provider because of this.  We will move the MITIE files over as well in a few days.\n. The files are now hosted on github.\n. It's the output of a support vector machine.  Positive values mean it's probably an entity and negative values mean it's probably not.  The larger the value the more confident it is. \n. No. Yes, that's what it is.  No, you will not see non-entities output.  . Thanks for the patch!\n. Try running the example programs in the examples folder. Those will definitely work.\n. It's possible to add one.  We would use SWIG to do it, just as the current\nJava MITIE API does.  However, why don't you want to use the existing\nPython training API?  You can load the trained models with the Java API\nonce training finishes.\n. The training process can take a fair amount of time to run and also must be\nrun on a beefy machine.  We generated the existing model files on a 12 core\nmachine with 128GB of RAM.  Depending on what part of the training process\nyou run, you could easily consume large fractions of the RAM of such a\nmachine.  So the training effectively consumes all the resources of a large\nserver.  It's not the sort of thing I would normally suggest being launched\nautomatically as part of a larger application.  You certainly could, but\nit's resource intensive.  Normally it's best to manually generate the\nmodels on some large workstation and then copy the generated files into\nyour production system and use the Java APIs.  You will also usually want\nto check the accuracy of the generated model and then adjust your training\ndata annotations or add more depending on the results.  So training is\nusually a manual and iterative process.\nGiven all that, do you still want a Java training API? :)\n. Thanks :)\nWe will add a Java API onto our todo list.\n. There is now a MITIE Java API thanks to this PR https://github.com/mit-nlp/MITIE/pull/32\n. If you want to train a custom model you can use the Python or C++ API's to\ngenerate the model file.   Then you can use that model file in Java with\nthe existing Java APIs.\n. There is now a MITIE Java API thanks to this PR https://github.com/mit-nlp/MITIE/pull/32\n. You need the large model to make it work.  Or are you asking about making\nmultiple extractors that all share the same word model file so they aren't\neach 330MB?\n. The current API assumes you have just one NER model, so it's not possible\nright now.  The underlying tooling can certainly handle it though.  I'll\nsee about adding something to the API that supports this use case.  Also,\nwhat language are you using to interact with MITIE?\n. There is now a MITIE Java API thanks to this PR https://github.com/mit-nlp/MITIE/pull/32\n. PR #33 was added recently to help with the model file size issue.  As for what's inside, yes, it's a variant of word2vec based on the two step CCA method from this paper: http://icml.cc/2012/papers/763.pdf.  I also upgraded it to include something that is similar to the CCA method but works on out of sample words by analyzing their morphology to produce a word vector.  This significantly improved the results on datasets containing lots of words not in the original dictionary. \n. Yes, that part of the model is generated by the wordrep tool.  You could\nrun it and ask it to output a smaller dictionary if you want a smaller\nmodel.  Note that you need access to a large text corpus such as the\ngigaword news dataset to generate a high quality model.\n. That's awesome.  I looked at it and it looks good, except for the following easily fixed things:\n- C++ has fully automatic resource management for all resources, unless you explicitly tell it to ignore an object by creating it with the new keyword.  So don't use new.  For example, in the code, don't say mitie::ner_trainer* impl;  do say mitie::ner_trainer impl;\n- It would be good to have some more comments in the example program (similar to https://github.com/mit-nlp/MITIE/blob/master/examples/cpp/train_ner/train_ner_example.cpp) that explain what is going on.  \nUpdate those two details and I'll merge the code in :)\n. You have to pass the arguments of those functions directly to the MITIE object's constructor.  I made the necessary code changes a moment ago.  You can see them in the MITIE repository history now.  \nThanks for the PR :)\n. Nice.  Looks good.  However, can you add the last check of classname for the feature extractor when it's being loaded back in?  Also add a little example code to the bottom of the new java training example program that shows how you use this feature.  \nOnce those things are in the PR will be ready :)\n. No worries and happy holidays to you too :)\nAfter thinking about this a little, I think it would be more user friendly\nif trainSeparateModels() wrote just one file instead of thee.  If it were\njust one file then the user couldn't accidentally mix parts from different\nand incompatible training runs when loading the ner object.  So unless\nthere is a compelling usecase for allowing this kind of model part mixing,\ncan you change it to output just one file rather than 3?\n. Awesome.  Thanks for another great PR :)\n. Take a look at the python example programs, they show how to do this.\n. MinGW is not a good windows compiler.  As the error says \"The C compiler\n\"C:/MinGW/bin/gcc.exe\" is not able to compile a simple test program.\".\nUse visual studio, it's freely available from Microsoft's web page.\n. No problem :)\n. Yeah I know what you mean.  However, why don't you train one big model that\npredicts all the labels you want to use at once?\n. I see what you mean.  I'm trying to think of an API that lets you do what\nyou want but doesn't introduce the opportunity for user error (e.g.\ncreating a NER object that doesn't have any feature extractor it can use\nand exploding when the user invokes it).  The best thing I can think of is\nmaking a new object, micro_ner say, that can be constructed from an\nexisting ner object.  micro_ner could copy everything in the original\nobject except for the large feature extractor.  Then when you want to use\nthe micro_ner instance you need to supply it with text and also with a full\nner object so it can use the feature extractor in it.  How does that\nsound?  Does that work for your usecases?\n. It's on my todo list.  It's a long list though :)\n. Right, further API changes are needed to support this.\n. This is already there.  Look in the examples folder.   Also, the front page\nin github tells you what to type to compile mitie.  Read the instructions.\n. Cool.  I'll look over this PR this weekend :)\n. I looked over the PR and there are a few issues.\n- The change should not break the existing API, and in particular, the existing examples should continue to work unchanged.\n- Don't put paths to your own files (e.g. /home/yichao/MITIE/examples/cpp/ner/sample_text.txt) in the example programs.\n- The new micro_ner object should look at the fingerprint of the total word feature extractor and make sure it matches the fingerprint of the total word feature extractor it was trained with.  This way it can give an error if the user supplies an incompatible total word feature extractor.  To implement this the micro_ner would need to save the expected fingerprint as a member variable.\n- Do not add auto generated files to git (i.e. the SWIG generated files)\n- It's not clear to me why a micro_trainer and ner_micro_training_instance are needed.  You can simply construct the micro_ner object from the existing named_entity_extractor object.  That would be much simpler and not disruptive to the existing API.\n. Thanks for the patch.\nThe MITIE models were trained for utf-8 text files.  However, the library works with files as streams of bytes so it doesn't care what format they are in.  So you should be able to train a model on any kind of file.\nMore PRs that make using MITIE with python3 are always welcome :)\n. Sweet, thanks for the PR :)\n. It's created by the wordrep program and basically contains word vectors for every English word.\n. No, you need to train a new model.\n. Did you try using the instructions in the README?\n. What happened in each case when it didn't work?\n. It's something we plan on adding.  There keep being more pressing problems\nto solve though so we haven't gotten to it yet :)\nThe same goes for the java example.\n. Now addressed by PR https://github.com/mit-nlp/MITIE/pull/49 \n. Currently, MITIE doesn't do coreference resolution.\n. I can't tell from what you posted.  However, the trainer does use a lot of\nRAM in general.  Especially if you have a lot of labels.\n. MITIE finds named entities and labels them.  For example, it finds\n\"locations\" and labels them as such.  The amount of RAM usage is linear in\nthe number of different label categories.\n. The outputs are from linear SVMs and have the usual interpretation for such models.\n. Yeah, I've been meaning to move the files over but forgot.  I'll do that in a second :)\n. Done\n. Cool.  I'll look at this and let you know.\nYou should also add a simple bag-of-words feature vector into it using feature hashing.  It's really easy to implement.  I've often used dlib's murmur_hash3_128bit function to implement the second version of the \"hashing_vectorizer\" function shown in that wikipeida page and it works quite well.  The cross validation code should also try just using the \"total word features\", the hashing features, and a combination concatenated together and pick whatever works best.  That would make this feature reasonably complete for a first version.\n. Yeah, it definitely won't work by itself for small datasets.\n. Cool.\nIt's been a while since I looked at this code.  So I forgot that MITIE\nalready uses these kinds of hashed features in the ner labeling code.  In\nparticular, make_feat() creates the features you need.  I see that you\nfound it but you shouldn't duplicate code by copying it into another file.\nCode should be shared by use of header files.  Also, the\nway extract_BoW_features works isn't quite right.  It should look\nlike extract_text_features except without the \"total word features\".  I\nalso expect BoW features to work a little better on largish training sets\nand 20 newsgroups seems big enough.  So this might be the reason.\n. Cool, that's more the F1 scores I would expect for those methods :)\nLooking through the code I see a few issues still remaining:\nThe name of the program isn't right here (https://github.com/mit-nlp/MITIE/pull/49/files#diff-5b16cbdea5f182df2cd1d6cf206784bbR68). \ntext_categorizer_extractor should be renamed to text_categorizer.  Especially since that matches the name in the Java API.\nIs this comment correct? https://github.com/mit-nlp/MITIE/pull/49/files#diff-5b16cbdea5f182df2cd1d6cf206784bbR85\nI see some cases of copy and pasted code that doesn't actually do anything. e.g. https://github.com/mit-nlp/MITIE/pull/49/files#diff-fd32f4cff3a5bcf0ef9f7a6bc66d05a7R17\nThe requires/ensures comments for this function don't make sense: https://github.com/mit-nlp/MITIE/pull/49/files#diff-3684754a9aae1aaf1ea650c305c64f89R41\nThe usage and behavior of the \"Unseen\" label should be clarified in the documentation.\nFix tabbing:https://github.com/mit-nlp/MITIE/pull/49/files#diff-2cbf13001db8c576b703ef9d81a735cdR124\nThere should also be an easy way to use just BoW features since that allows the user to use much smaller models.  The total word feature extractor is very large, I'm sure many users won't care about the additional accuracy it gives for text categorization considering the computational requirements it imposes.\n. Cool.  I'll look at this later this weekend.\n. Been crazy busy the last few days, so I didn't get to this.  I'll do it\nthis week at some point :)\n. I just pulled the code and ran make test at the top and got an error.  Can you make sure the tests run?\n. Cool.  Now make test works but make clean; make gives an error.\n. Super, this is looking pretty good.  There are just a few more minor things:\nIf operator() outputs just one argument then it should return it using the return keyword rather than via a named parameter: https://github.com/mit-nlp/MITIE/pull/49/files#diff-d8e0976856497c45f7a97bddbf09ab1bR83\nThe text_categorizer_BoW example should be renamed to something like train_text_categorizer_BoW so that it's name is cohesive with the other mode of training and other examples.  That is, this way it is clear that there are two ways to train a text categorizer and that this example is one of them.\nDon't put using namespace declarations in header files: https://github.com/mit-nlp/MITIE/pull/49/files#diff-eea8b6e1f1ecf0f8fe1b869bbed5f3c6R14\nI went to MITIE/mitielib/java/build and ran cmake ..; make install and got this error\nIn file included from /home/davis/MITIE/mitielib/java/build/lib/java_src/edu/mit/ll/mitie/swigJAVA_wrap.cxx:231:0:\n/home/davis/MITIE/mitielib/java/./swig_api.h:28:30: fatal error: text_categorizer.h: No such file or directory\n #include \"text_categorizer.h\"\nThis line should say 'document tag', not NER tag https://github.com/mit-nlp/MITIE/pull/49/files#diff-1d050bd526db4a845d0c51a9ff6a75aaR58\n. Cool.  Almost there :)\nI see a bunch of places that talk about the text_categorizer_extractor but that doesn't exist anymore.  Can you go through the comments and make sure everything is up to date?\nAlso, can you rename the train_categorizer example to train_text_categorizer so that it matches the naming scheme of the other examples i.e. some_example, train_some_example.\n. Cool.  However, looking over it again, I'm still finding problems.  For example.  in the cpp/train_text_categorizer, the message it prints when it is run is, \n\nYou must give the path to the MITIE English total_word_feature_extractor.dat file.\nSo run this program with a command like: \n./train_categorizer_example ../../../MITIE-models/english/total_word_feature_extractor.dat\n\nWhich is the wrong command.  \nI think the PR is about ready to go in terms of the code and features, but these little details need to be taken care of.  Can you read over the whole PR and make sure the documentation, comments, and so forth is correct?  That's what I'm doing each time I go over a PR and when I start to find these kinds of things I stop and send it back to you.  The fewer times I have to read over the PR the better, and the sooner it will be merged :)\n. Super, thanks for the PR.  I just merged it into the main repository and fixed few minor remaining details.\n. No problem :)\n. It creates a bunch of indicator features based on the presence of different substrings in each word.  What substrings are used is learned by the word feature extractor.  The substrings are just strings of bytes as far as MITIE is concerned.  So it should work with any language.\n. Well, different languages have different common sub-strings and combination patterns.  So no, you definitely can't reuse a feature extractor on different languages.. Even more generally, I wouldn't have made the feature extractor a trainable thing if there was One True Feature Extractor you just used for everything.  . You run the wordrep program on a folder of text files and wait.  That's all\nthere is to it.  There aren't any parameters or anything and one of the\nexamples tells you what to type even.\n. I'm not sure what to suggest other than to be careful about being\nconsistent in your use of utf8.  With utf8 there shouldn't be any problems.\n. Yes, the tokenizer does a little bit of normalization.  So that is the\nexpected behavior.\n. If the beginning of the next token doesn't work for what you are trying to\ndo then you can write your own tokenizer and use that with MITIE.  There\nisn't any reason you have to use the tokenizer that happens to come with\nMITIE.\n. The MITIE tokenizer isn't going to be all things to all people.  I almost\ndidn't include a tokenizer with MITIE because I know many people who do\ntokenization many different ways.  But a default one needs to be there so\nthe examples can run.  This is the default one, it isn't going to be the\none final tokenizer you can use for all tasks.  It is the tokenizer that\nmakes MITIE perform reasonably well on the examples and with a few\nlanguages and tasks.  For some tasks you will have to create your own\ntokenizer.  For example, maybe there is something inherent in the NLP\nproblem you are trying to solve that requires different notions of \"words\"\nor you are doing some additional non-NLP task like making some kind of GUI\nwhich needs some particular tokenization.  In those cases, make your own\ntokenizer because MITIE isn't going to be a tokenizer library.  It's an NLP\nlibrary.\nAs for this normalization.  It's in MITIE because some users complained\nabout the tokenizer not doing it.  Adding it also slightly improves NER\nperformance on English and it's a minor change so it went into MITIE.\nThere are other users who would like even more normalization.  Some want\nless. Tokenization is easy, if you want it done differently then do it some\nother way.  You can still use MITIE with tokens from some other tokenizer.\n. Ah, yes, this is a bug in the MITIE tokenizer :)   I just pushed the fix to github, so it should give the correct byte offsets now.  Sorry for being such a nazi about this :)\n. No problem.\nAs the error says, you gave two entities that overlap in the text.  You\ncan't do that.  I'm not sure how to say it in a clearer way :)\n. No worries :)\n. No, bad_alloc means you ran out of RAM.  This algorithm requires a lot of RAM, when I trained the existing model I used a machine with 128GB of RAM.\n. No problem :)\n. I forget the exact size, but it was the English Gigaword corpus, which is\n10s of gigabytes.\n. Don't compile with -fno-rtti.  \nAlso, I'm not familiar with any node.js MITIE tool.  You should probably post this question on that project's forums.\n. I didn't even know MITIE had node.js packages :)   \nI would suggest asking whoever made the node.js binding or NPM package.\n. I'm not going to create such models.  But you can train them yourself if you have the data using MITIE's training API.\n. The datasets are available for download here https://github.com/mit-nlp/MITIE/releases\n. No problem :)\n. The example programs show how to train MITIE models.  All you need is annotated data.  You will also need a chinese tokenizer.\n. You need to separate it into \"words\" with spaces between them. I'm not\nreally sure what the best kind of tokenization is for Chinese though.\n. Yes. That\u2019s all correct.  You need to train a word embedding as well. . The C++ API for doing this is already straightforward.  But if you wanted\nto contribute a Python API for it that would be cool.  :)\n. Sweet.\n. Cool, yeah, I just added some comments.\n. Cool.  Can you remove the editor artifacts so it's easier to review the changes?\n. No idea.  I would use print statements if gdb isn't working.  It's probably that you defined the C binding in python wrong.  The types need to match exactly to the C calls or it won't work.\n. If you want to output a string as an argument to a C function then the argument type must be char**, not char*.  The output is a pointer to some chars.  char* would only let the C function write data to some memory address.  But the C function needs to allocate a block of memory (of chars) and return it.  So a double pointer is needed.  That's why it isn't working.\n. Cool.  Some of the requires/ensures documentation is missing or wrong in\nmitie.h.  That needs to be correct before its merged into the mainline.\nAlso make sure all the comments and documentation elsewhere is correct.\nI'm seeing a lot of things that are obviously copied and pasted from other\nparts of the code and don't make sense where they appear.\n. Super.  Looking better.  I added more comments.  Looks like the memory leak\nis still there too.\n. Super, looks good.  I just merged the PR :+1: \n. The only model creation methods in MITIE are the ones documented in the example programs.  So you would need to create a new dataset that contained the union of all the entities you wanted to deal with and train on that. \nYou also seem to be asking if MITIE supports user generated features like \"is in my dictionary\".  There is no API for that since I found gazateers to not make much of a difference in accuracy and they complicate the user workflow.  Although the C++ code for running MITIE isn't that complicated so you could add your own additional features by editing it if you wanted to.  At the end of the day MITIE is just a simple application of this dlib tool, which is fully documented.  So it's easy to modify. \nBut I wouldn't worry about that.  The thing to do is make a single unified training dataset that captures what you want to do and train a model based on that dataset.\n. I wouldn't worry about it.  The word vectors MITIE uses dynamically\ngenerate word morphology features when you train wordrep, so the stemming\nisn't very important.  The main thing is to have a tokenizer that makes\nsense for your language.  You can also perform any kind of reasonable token\nnormalization at that processing stage as well.\n. Unfortunately, there isn't any POS tagger in MITIE.\n. No.  You should train a new model.\n. Sure, sounds like a good improvement :)\n. to_default_str_type has only been called on some of the the strings coming out of MITIE.  Shouldn't it be needed for all of them?\n. Sweet, thanks for the PR :+1: \n. Cool.  Can you submit a pull request for this?\n. How big is your training set?   Also, linking to a BLAS library will help with speed a bit as well. \n. That's too few samples to get any significant parallelism.  However, 2\nhours is extremely long for such a small dataset.  I've used that thing on\ndatasets with hundreds of thousands of samples.  Are you sure compiler\noptimizations are on?\n. Then optimizations are on.\nMaybe your data is impossible to classify and the optimizer is spending a\nhuge number of iterations trying to figure out how to do it.  That can\ncause issues sometimes.\n. No.  Those things are all removed by tokenization.\n. I'm not sure I understand what you are asking but the answer is probably no.\n. Any sort of cleanup you can do is usually helpful.  Removing invoice numbers and replacing them with some tag is a good example of that.  More generally, anything you can automate without machine learning is something you should automate.  Machine learning is only what you use when you have run out of normal coding techniques to solve part of a problem.\n. It's just showing you the models it is testing.  You can read about f-score on wikipdia\n. Super, thanks for the PR :)\n. The only way to know is to try it and see :)\n. I'm not sure I understand what you are talking about. Is this a question?\n. Cool, thanks :)\nYeah, C++ is viewed as being harder than Python but I don't think that's really the case. \n. Cool.   \nI added some comments.\n. Cool, looks good aside from a few documentation details, but I fixed those.  Thanks for the PR :)\n. No problem.\n. Is that a question?  People use python 3 with MITIE.\n. Cool, thanks for the PR.   I assume you noticed there are conflicts with the main MITIE codebase?\n. Cool, thanks for the PR.  I'll review this in a few days.\n. Cool, thanks for another PR :)\n. Did you follow the exact instructions?\ncd mitielib/java\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release --target install\n. Is there a jar file in the mitielib folder?  That cmake command runs an\ninstall operation that copies the jar to mitielib.  It sounds like that\ndidn't happen.\n. What happens when you try to run the install target on its own.  Do make install.  What happens?  It should copy the jar.\n. From the build folder\n. There is definitely an install target.  I don't know what's wrong on your\nsystem.  I would delete everything and try getting a fresh copy from github.\n. Sure, that's fine with me so long as it's clear that users are expected to not need to modify those parameters.  So such a PR would be welcome :)\n. I would call mitie functions using the Pyhton API.. Cool, thanks for the PR \ud83d\udc4d . There is example code in the examples folder that shows you how to use it.  See this example specifically: https://github.com/mit-nlp/MITIE/blob/master/examples/cpp/ner/ner_example.cpp. The code is wildly different.  You aren't even calling deserialize the same way, which is the source of the error.. No, this isn't part of the available model.. What warnings do you think it would fix?\n. Ok.  Well, I'll update it eventually.  However, the new versions of dlib require a C++11 compiler and I don't want to force that on MITIE users yet.  As I've learned from the switch to C++11 in dlib proper, there are still lots of people with broken/old compilers out there.  . @SakthivelAnand Stop posting comments at random in unrelated github threads.  . If it doesn't work even on the training data then you have probably done something wrong.  Maybe you aren't loading your data correctly, are putting the tags in the wrong places, or something like that.  . No, you don't need to have all possible tags on each instance.  \nIn any case, if it doesn't work on your training data something is almost certainly wrong with your code.  Consider the example programs, they have tiny training datasets but work fine.  Make sure you are really feeding the data back in the same way during testing.  Maybe you are tokenizing it differently when you go to test.  Beats me.. Did you follow the exact instructions on the mitie front page? https://github.com/mit-nlp/MITIE  It tells you what to type.. The java examples come with scripts like run_ner.sh.  Run that script, or look at it's contents.  It contains the java command that correctly adds MITIE to the classpath and library load path.. That doesn't look like the entire output from the build process. So it's impossible to say anything.\n. Just run cmake on it's own rather than python setup.py.  What does cmake say?. The cmake build instructions are shown here: https://github.com/mit-nlp/MITIE. The front page of MITIE shows how to use it with python.  Once you have it built you can run the python examples.   . I have no idea.  But if you follow the instructions on the front page exactly you can definitely get the MITIE examples working.. @abubakarsohail You ran the cmake commands exactly as shown on the MITIE front page, then you ran one of the python examples.  What happened?. Did you run these commands first?\ncd mitielib\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release --target install. Those commands output the mitie library that python opens.  They either work or they don't.  That error you are posing is a file not found for the mitie library file.  Look and see if it exists.   You either have the file or you don't.  This should be simple to debug.. If it built then there is a mitie.pyd file, just put it in your python path.\n. Did you type these commands?\ncd mitielib\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release --target install\n. Do the examples in the examples folder run?. The front page, https://github.com/mit-nlp/MITIE, tells you what to type.. Well, I don't know anything about rasa or any of the people who work on it.  So this isn't the right place to ask about rasa.. Cool, thanks for the PR.  I'll take a look at it this week.  \nOn first glance though, I see there is a mixture of tabs and spaces in the change.  Can you update it so it's only spaces, this way the code looks uniform and the github change view isn't messed up?. I still see a bunch of tabs and bad indenting. :(. No worries.\n. Super, I'll look it over in a few days.\n. Yeah, I should have paid more attention to this when the first PR about\npure models was submitted. :(\nAnyway, what you can do is add a different version string, the first string\nserialized, and use that to identify pure models that have a fingerprint.\nThis way you could preserve backward compatibility which is pretty\nimportant.\n. Awesome.  Thanks for the PR :). @kwkwvenusgod What's popular is not always the best.  When I compared spectral word embeddings to word2vec during MITIE development I found that word2vec wasn't better.  Moreover, the spectral word embeddings can be quickly and reliably estimated without any user fiddling.  The spectral technique also lends itself to an out of sample projection in a way that the deep learning methods didn't.  For example, if you give MITIE a word it hasn't seen before it is still able to produce a spectral word vector for it by mapping the set of all substrings of the word into the spectral word vector space.  I should emphasize that lots of people use MITIE in industry in situations where they have a very high out-of-dictionary word rate so this kind of thing makes a big difference to them.  However, you hardly see this kind of discussion in the ML literature because savvy researchers can just make a new dictionary with the appropriate words.  But MITIE is a tool for non-NLP experts who just want something that works.  My impression is that most users never retrain the word model and they get good performance regardless.\nIn any event, if you want to try the comparison yourself it's plenty easy to replace the spectral word vectors with any other word vectors and run MITIE and see what happens.  \n@korokokou This is a good first paper to read about it: http://icml.cc/2012/papers/763.pdf. I haven't tried GloVe.. No problem :)\nMake sure you install a good BLAS library like the Intel MKL.  That will make wordrep run much faster.  I trained the model that comes with MITIE on the gigaword dataset and it took a few hours or so using the Intel MKL.\nNo, it's not incremental.  . If you aren't getting errors about running out of RAM then you have enough.. Yes, using a multi-core BLAS library like openblas will make a big\ndifference in speed.\n. No, CMake should find it automatically.  The MITIE compilation will print a message to the effect of \"Hey, I found BLAS and I'm using it.\"   If it's using BLAS then it's using BLAS and the BLAS library does whatever it does.  However, maybe you have a copy of openblas that doesn't use multiple cores.  I don't know.. You need to get more ram. \n. There are no French models included with MITIE.  So if you want to do some NER with French then it's up to you to train whatever sort of tagging model is appropriate for your problems.  The examples folder contains example programs showing how to train MITIE.  However, what data you need for that depends entirely on what you want to do.  . Use the CMake based build instructions.. You could go into the code and print some progress statements if you want.  But yes, it will take a long time.   Although, it doesn't sound like you compiled it against a BLAS library, which you should definitely do if you want it to run fast.  I would recommend using the Intel MKL since it's the best.  OpenBLAS is also reasonable as well, but not quite as good.. OpenBLAS is normally multithreaded.  Maybe the version you have isn't\nconfigured that way.  But if you download a copy from the openblas web site\nyou can compile it easily and it will be multithreaded by default.\n. Is MITIE compiled to use it?  What did you do to compile MITIE?\n. Actually, the CCA step isn't going to make heavy use of the multi-core\naspects of BLAS since most of the computation happens inside the sparse\nvector code in dlib which isn't multi-threaded.  It's been a long time\nsince I ran wordrep so I forgot about this.   But in any case, it does take\na long time to run.  But you only run it once so it's not a big deal.  Just\nbe patient and it will finish.\n. Try it now.  I disabled those dlib modules since MITIE doesn't needed them.\n. Beats me, those errors look like your compiler is broken.  As an aside, the first errors you posted were also funny and shouldn't happen since they required non-standard copies of libjpeg.  All I did was disable trying to use libjpeg.  \nSo there is probably something wrong with your compiler install or system libraries.. Post a minimal python program that runs and reproduces this error.. Post a minimal python program that runs and reproduces this error.. I have no idea what rasa_nlu is.  As far as I know the bug is probably in this rasa_nlu thing and not at all related to mitie.. ner.py doesn't call any text categorizer functions. So I don't see how you could get that error by running that example.  Unless you modified the ner.py code.  Did you modify it?\n. Actually, maybe this is a python ctypes error.  Do you have an old MITIE shared library sitting around?  That could explain it.. Oops.  Looks like some functions were missing export statements.  Try it now.. No problem.  Thanks for reporting this bug :). It's just this tool from dlib: http://dlib.net/ml.html#structural_sequence_segmentation_trainer. Follow the instructions on this page: https://github.com/mit-nlp/MITIE. Use the CMake based instructions and it will work.. Try using the cmake install instructions. \n. Delete everything, then get a fresh copy of MITIE from github.  Then type these exact commands:\ncd mitielib\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release --target install\nWhat is the output?. You don't need visual studio 2010, 2015 is fine.  But something is obviously wrong with your computer if CMake can't find visual studio 2015.  It's not installed correctly.  So this doesn't have anything to do with MITIE.  \nTo clarify, you don't need to tell cmake the name of visual studio.  It will find it if it's installed correctly, but that doesn't seem to be the case.. That's how you do it.  You are looking at the second step right there.  This is explained in the original paper.. There are example programs in the examples folder that show how to train more models.  You can't \"retrain\" an existing model file though.. The CoNLL shared tasks we referenced don't have overlapping entities.  So I'm not sure what you are talking about.  The examples you give seem to just be labeling errors.. Are you using the latest code in github?\n. Actually, try it now.  Should be fixed.. There are example programs, in the examples folder, that explain how to train MITIE.. Thanks for the bug report. \nThere isn't any deep reason why it does what it does.  Although, it's too late to change since many people use MITIE and rely on it having consistent behavior, even if it might be more sensible to separate punctuation.  . No. No, it's not on pip.  You can get it from github.. Yes, the examples folder contains example programs that show how to retrain MITIE.. No, that's not really going to be practical.  It's best to retrain using\nthe existing API.  Online learning algorithms are a lot more difficult for\nthe user to get right.  You would find it much less reliable than what\nMITIE currently does.\n. No, there is no GPU computing code in MITIE.. People keep posting weird errors when using rasa nlu that only happen when using rasa nlu.  So I'm doubtful this has anything to do with MITIE.   Can you post a python script that reproduces this problem?  One that doesn't involve rasa nlu.. rasa nlu has no affiliation with MITIE.  You should post this question on a rasa nlu forum.. Post a minimal example program that illustrates the problem.. The command you pasted here isn't what the instructions say to do.  They say to type this, when using cmake:\ncd mitielib\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release --target install. Install visual studio and use that.  You will probably find that it's easier to install correctly than mingw.. Did you run these commands?  What happens when you run them?\ncd mitielib\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release --target install. Is there a mitie.dll in the mitielib folder?  The messages you posted indicated that it was built so it should be there.  So I don't see how you can still be getting the errors about not being able to find mitie.dll.. Yes. Good point. You definitely need to do that as well. . You can't touch the same object from multiple threads at the same time. \n. It goes to infinity. So that can happen. . That's not what happens when I run it.  Post a short program that\nillustrates the problem.\n. Not really.  Just the comments here on github.  It's basically just dlib's sequence segmenter with the addition of eigenword features, hash features, and some word morphology.  . I would read the code.  It's not as complicated as you would think since most of it simply uses dlib components which are very well do documented and include citations to the literature.  For instance, this is the fundamental sequence segmentation tool MITIE uses: http://dlib.net/ml.html#structural_sequence_labeling_trainer. Also, this is the paper on eigenwords: http://icml.cc/2012/papers/763.pdf. No, you have to retrain with the whole dataset at once.  You can't update an existing model.. Huh, yeah, that's not how cmake used to behave.  Thanks for pointing this out. I just pushed a fix to github so it should work properly now on both old and new versions of cmake.. No.  MITIE does all that stuff internally so you don't have to.  That's basically the main design principle of MITIE.. It takes a lot of data to learn.  Maybe you just didn't give it enough.  I have a feeling you are training it on just one sentence?\nIn addition, the total word feature extractor model that comes with MITIE knows a whole lot about English, both about many specific words as well as a lot about word morphology.  So it's almost certainly going to know that chicago is something special even before you give it any labeled NER data.. It includes a lot of word morphology in the construction of the word vector.  So it still does something useful. . Many things are possible.  I doubt what you are suggesting will make it better though.  I selected the eigenvectors MITIE uses because they were better than word2vec in multiple experiments.. It already builds and works on windows.  The front page mentions windows many times even.. No, there aren't any pretrained binary relation models for Spanish.. Thanks for the detailed bug report :)\nDo you want to submit the change as a PR (so you get github points for it :) ), or should I make the change?. Sweet, thanks for the PR :). Sweet, thanks for the PR :). How long it takes depends on your data.  For instance, if your labeling is somehow inconsistent then it will take longer to train because the optimizer is trying to do something impossible.  Ultimately, the only way to find out what will happen is to run it and see.  But normally training on a small dataset like that only takes a few minutes.  But it might take longer.  . Yes, MITIE is a CRF.. In general, you want to define things in a consistent way.  It doesn't necessarily matter how long the entities are.  However, the only way to know what is best is to try it and see what happens.. Having sentences without any entities is fine.   More generally, add more training data and you will probably get better results.. That's just how the algorithm works.  There is a large amount of RAM required, independent of the size of the dataset.  . Yeah, that doesn't work on windows.  Just use cmake instead as the instructions on the front page of MITIE show.. Because they give good results.   You can try changing them to see what happens though.  They aren't the only possibly settings that will give good results.. I should also point out that the functions being called there are in dlib and those functions are all fully documented.  The main one being dlib::cca().. That's not a bug, it's done on purpose.  If you want to tokenize things differently you should use a different tokenizer. . That's a long time.  It's likely due to your data being difficult to separate.  But it kinda is what it is.  Part of the reason MITIE takes a longish time to train is because it does a lot of internal validation so that you don't have to mess with anything.  You could instead use the machine learning tools in dlib directly if you wanted more control.. wordrep just takes a folder with a bunch of .txt files as input.  It doesn't matter what the format is so long as it's the same format use you use when you use MITIE in your application.  In general, I encourage people to use utf-8.  \nAs for what is 'in' the .dat file.  It's a whole bunch of data useful for modeling word morphology and notional relationships.  You don't need to know what's in the file to use MITIE.  But if you want a background in how MITIE works you should look at the sequence labeling tooling in dlib and the two step cca paper (https://arxiv.org/abs/1206.6403) as starting points.. Do you mean 30 million separate label categories?\n. Then MITIE should work fine for this task. . That's fine.  It will just require more RAM.\n. Yes, that's how it works.  \nIt's that way because adding those features to the segmentation didn't improve the accuracy on standard benchmarks.  . You have to train everything again if you want a combined model.. I haven't setup anything like that.  Personally, I'm not going to hang out in a chat room.. The point of MITIE is to be easy to use.  So it's easy to use.. Being difficult to use doesn't mean it's better.. Use the cmake instructions when installing windows.. http://dlib.net/faq.html#Itdoesn'twork. That could happen.  The running time is also dependent on how separable your data is.  If there are a lot of things in your dataset that aren't labeled consistently or are impossible to distinguish between each other or very difficult then training will take longer.  . Not sure what you mean by 'formats'.  You call the functions shown with those kinds of inputs.. Yes, the examples show you how to use the API.\nNo, you can't combine models.  . No, that's not a reasonable thing to do.  You can do exactly what you want without modifying MITIE.  You aren't getting answers to your questions here because you are asking basic python programming questions, rather than questions specific to MITIE.  You should find a good python tutorial, course, or internet forum about learning python generally if you want help learning to program in python.. Your code shows that you are reloading the model file on every call.  That's not a mistake someone conversant in programming should make.  Don't do that and it will run much faster.\nMITIE doesn't output any entity text at all.  Look at your code you posted.  The text is text you input to MITIE in the first place.  The only output of entity extraction is a class label (that the user defines as whatever they want), and a numeric range that tells you what tokens the ID applies to.  The \"not the right text\" you posted is text you made with your code, not from MITIE. . I think there is confusion about what MITIE does.  Getting \"the actual named entity it was trained with\" isn't a thing.  Each type of named entity is generally trained with hundreds or thousands of separate examples of that entity type.  There is no such thing as \"the one string for that entity during training\".  It could be any number of a huge variety of strings.  . Don't duplicate issues.. OS doesn't matter.  Also, so long as you have enough RAM that the OS isn't swapping pages to disk you are fine.  \nSome datasets take a long time for the solver to process.  . Post the entire output. That error is telling you that you don't have a C++ compiler.  You have to install visual studio to compile the code.. You have to add the mitie shared library into your python path.  Look at the example programs, they contain the code that does this.  Or google it, there are a lot of ways to add things to your pyhton path.. You have to compile in 64bit mode if you want to use it with a 64bit python.  You do this by telling cmake which visual studio you want to use, e.g. cmake -G \"Visual Studio 14 2015 Win64\" ... The important bit is saying Win64. Download the ner_model.dat file.  There are links on the MITIE front page.. There are a lot of ways to permanently add things to the pyhton path.  None of them are MITIE specific.  I would look up a few and pick one you like.. Some parts of MITIE aren't threaded.   How much you benefit from the threading varies from task to task and dataset to dataset.  Sometimes only 100% CPU utilization happens and that's normal.. I don't understand what you are trying to ask. . Yeah, it's been a while since I uploaded new precompiled binaries.  It's probably about time to refresh them :). I haven't updated anything yet.  Be patient.. No, you can't do that.  See\nhttps://github.com/mit-nlp/MITIE/blob/master/mitielib/include/mitie/total_word_feature_extractor.h#L28\n. It contains a dlib::total_word_feature_extractor object.. Read the error message.  It says you don't have g++ installed.  You need a compiler.. There isn't much to it. See https://github.com/mit-nlp/MITIE/issues/118. Yes, thanks for the PR :). I just added a tag on github.  :)\n. Follow the instructions on the front page: https://github.com/mit-nlp/MITIE\nIt doesn't look like you followed them.  Here is what they say:\n\nThere is an example Java program in the examples/java folder. Before you can run it you must compile MITIE's java interface which you can do like so:\ncd mitielib/java\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release --target install\n. The output you pasted shows that you ran the mitie build script, not the javamitie build script.  If you typed the commands I pasted you would have run the javamitie build, not mitie.. You must have accidentally invoked the cmake command on the mitielib folder rather than the mitielib/java folder.. No, there is just the one version.  . Lots of people use MITIE with python 3.  Are you having some issue?\n. You shouldn't have to do anything.  Like I said, MITIE works with python 3.  Is there some issue?. It\u2019s all the same license. So you can use the models any way you want. . You should also make sure that your labels are consistent.  Datasets that\nare harder to label take longer to train.  So if, for example, you have a\nhuge number of labeling mistakes training will take a long time.\n. It just means you are labeling your data with incorrect labels.  Like maybe\nsometimes you label references to the city of Boston as \"city\" and other\ntimes as \"place\".  Or maybe other times you don't label it at all.\n. Sometimes it takes a while.  Be patient.\n\nWhat's happening is MITIE is repeatedly training a classifier and doing\nhyper parameter selection to find the best one.  So MITIE training is\nalways going to take longer than other systems since it does a whole lot of\ninternal validation and retraining so that you never have to fiddle with\nany parameters.\n. You can break the data up into any chunk size you want.  It doesn't have to\nbe sentences.\n. It shouldn't matter much. \nThere is a certain fixed runtime that is a function of how difficult your data is.  This fixed runtime can be large if your dataset is labeled in an inconsistent or difficult way.  So adding more data shouldn't be a problem in terms of runtime.  This is all assuming your machine isn't using a 10 year old CPU and running out of RAM and constantly swapping to disk or something like that.  It's possible that your computer just sucks.  But other than that you shouldn't worry about it.. Give it words, not sentences.  That's why it's zero.\n. Yes, that would be a fine thing to do.\n. It should work just fine in python 3.\n. Did you get an error when trying to use MITIE with python 3.6?\n. Don't use setup.py.  Follow the instructions for us on windows as they appear in the README.. The readme contains instructions for installing on windows. Don\u2019t use setup.py. Use those instructions. . That's not what the instructions say to do.  But in any case, I just updated the setup.py so it supports windows.  So try running that same command you ran again, it should work now.. You don't have to setup the path to the mitie dll if you run setup.py.. The fix for this is live on github now.. Fill out the issue template.. It's basically this: https://arxiv.org/pdf/1206.6403.pdf but with the\naddition of word morphology.\n. Follow the instructions on the front page of MITIE.. Fill out the issue template. Be patient.  MITIE does a lot of rounds of training and the whole search is\nvery conservative.  That is, it errs on the side of running much longer to\nensure it finds a good solution.  The training time is linear in the\ndataset size and it can learn from very large datasets, much larger than\n30k sentences.  However, there can be very large fixed overhead due to the\nunderlying difficulty of your training data.  This has nothing to do with\nthe size of the dataset.  For instance, if your samples are mislabeled or\nthe labels are ambiguous then the hyperparameter search will often take\nmuch longer, regardless of the training set size.\n. Yes\n. You need to use a computer with more RAM.. The only solution is more ram. Use a machine with 64gb or 128gb. Ram is really cheap. . You have to compile the application in 64bit mode.  Visual studio compiles\nin 32bit mode by default which only gives you access to 2GB of RAM.  When\nusing cmake you have to say something like this to tell it to use 64bit\nmode: cmake -G \"Visual Studio 14 2015 Win64\".\n. Don't modify anything in the build project or how you run it. Just run it normally.  It should run just fine.. There are instructions here: https://github.com/mit-nlp/MITIE/blob/master/examples/python/train_ner.py . Your computer doesn't have the wordrep executable.  \"command not found\" means it's not on your computer.  You can't run a program if it's not on your computer.\nYou need to go into the wordrep folder and compile it.  Use cmake to do so.. Post the exact commands you used to compile wordrep.. That should work fine.  I don't know what is going on.  If you can post a small dataset that reproduces the error I'll take a look.  Give exact instructions for reproducing the problem.. Thanks, I'll take a look.\n. Try it now.  I just pushed a fix and it should all work as expected in\nVisual Studio now.\n. No problem. Thanks for reporting this.. Uh, you sure about that?\n. Well, there isn't any code in MITIE that pauses for user input.  . To compile MITIE on windows you are supposed to use CMake. The makefiles\nare only for unix systems.\n. No, you have to retrain every time.. Please post complete instructions to reproduce your error, starting with downloading a fresh MITIE copy from the official MITIE repository.. If you are hitting the page file then you need more ram. Also make sure you compiled with compiler optimizations enabled and against the intel mkl. That makes it faster. \nI don\u2019t know why you get that file error, but it doesn\u2019t have anything to do with MITIE. You need to ask in a rasa nlu form. I don\u2019t know anything about rasa nlu except that it\u2019s apparently hard to use since it\u2019s users frequently post questions about it in MITIE forms. . Good idea!  Done :). Isn't the token's number the offset?\n. Right, but you should know where you got the token. You have to feed the tokens into MITIE. It\u2019s not like it\u2019s internally doing some hidden tokenization. \nSo keep track of where you got the tokens from. . Or maybe you just don't see that the tokenizer is returning the offsets?  tokenizeWithOffsets() gives you the numbers. . There isn't much to the java API.  You can see the binding here https://github.com/mit-nlp/MITIE/blob/master/mitielib/java/swig_api.h.  For detailed API docs for MITIE you can refer to the C API.  \nMITIE hasn't changed in years, so any copy should be just as fast as any other.. No problem :). You need to install a working C++ compiler.  On windows I highly recommend using visual studio.. There is no API for this.  But you can easily edit the MITIE code to add whatever features you want.. Thanks, but MITIE is already licensed under the boost software license.  It says this on the front page and there is an additional copy in the mitielib folder.  It is also mentioned at the top of every source file.. Yes, that is likely to use less RAM.\n. Please ask such questions in a rasa nlu forum.  All the things you are asking about are not part of MITIE and no one involved in maintaining or creating MITIE knows anything about rasa nlu.. Thanks for reporting this.  I just pushed the fix to github.. MITIE is purposefully designed to have no parameters.  The thing that will make this work better is using more training data.  If you want to use lower level tooling that lets you design your own models then you should look at dlib, since MITIE is a thin wrapper around dlib.. It's based on this method: http://jmlr.csail.mit.edu/papers/volume16/dhillon15a/dhillon15a.pdf. It uses eigenword features for words it has seen before.  These are combined with a large set of morphological features designed to map onto the eigenword vectorspace.  So what happens if you get a word it hasn't seen before is it attempts to construct an eigenword vector from only morphology.  This works fine in general.  For instance, it might recognize that a word ending in ing is a verb via this method even if its never seen it before.. http://jmlr.csail.mit.edu/papers/volume16/dhillon15a/dhillon15a.pdf\n\n. Oops.  Sounds like it's time for v0.7 then :)\n\nThanks for reporting this.. No\n. why isn't this const?\n. This comment says something that's obviously not correct.\n. This documentation is wrong.\n. Why is this commented out?  Shouldn't this check be here?\nAlso, the following comment is wrong.\n. You can't call new.  All memory needs to be allocated like other mitie objects with mitie's allocation functions.  Then it needs to be freed with those functions as well.  If this isn't done then it will lead to program crashes, especially on windows where different DLLs have separate memory allocators.\nUse allocate_bytes() to get the memory since that function will work with mitie_free()\n. This code needs to ensure label is deallocated.  As this code stands it has a memory leak.\nYou should also do some testing to make sure there aren't memory leaks.\n. Why not have this assert (once fixed)?\n. *text_tag is a null terminated C string right?\nAlso, the caller should be responsible for freeing it with mitie_free()?\nAlso, what is the structure of tokens?  This must be documented.  I haven't gotten that far down the code yet but I bet it's similar to this: https://github.com/amn41/MITIE/blob/2cff1f769b362cd0ce634c4e932e9c8f33f3385e/mitielib/include/mitie.h#L481\n. fix TODO\n. What are tokens and label?  There are more requirements than just being not NULL\n. You should say something about what tokens is.  Like it's a sentence of words and that's the training example.  label should be mentioned in the text too.  Basically, what does this function do?  The complete answer to that needs to reference the arguments in some way.\n. Where is the memory allocated to label being freed?  It looks like it's leaked here.\nFor example, the tokenize API has a similar structure and you can see it freeing memory: https://github.com/amn41/MITIE/blob/2cff1f769b362cd0ce634c4e932e9c8f33f3385e/mitielib/mitie.py#L137\n. There must be other requirements to call this function, in particular on result.  Include the exact requirements that make a valid result.  What is needed to call this function and have it work?\n. Same here.  What are the requirements on result?\n. Also, say clearly what this function does.\n. How does this memory ever get freed?\n. What is an array?  C doesn't really have arrays.  The syntax float thing[] is just another way of writing float* thing.  So this should say something like result points to a block of memory.  How much memory?\n. Now it's even more wrong :)\nThis will probably segfault when you run it.  Although you might get lucky and avoid a crash sometimes.\n. You should look at how the mitie tokenize code does it since it faces the same problem, returning an array of strings.\n. Yeah, that code for making it work in the tokenizer is somewhat subtle too.  Definitely a good wheel to avoid remaking.\n. Don't forget to say the caller must free the returned array.  I would use very similar words as is used in the tokenizer documentation about freeing the results.\n. What is a pure_model?  The references to classes should use the full class name so it's clear what class is being referenced.\n. What is a pure_model?  The references to classes should use the full class name so it's clear what class is being referenced.\n. Shouldn't this refer to the pure version?   Also, it's probably a good idea if the pure load functions reference these functions so it's clear what it is the load functions are capable of loading.\n. Same here\n. This is a little confusing\n. Remove print call\n. This is also a little confusing.  The way it's worded makes it sound as if 'you must pass a feature extractor' when saving in pure mode.\n. What does this mean?\nMore generally, all the functions in this file should be properly documented.  e.g. what does this function do?  What are the requirements for calling it?. The user shouldn't have to supply None,True as an argument.  The code can figure out that the file on disk is a pure model so it should not require the user to supply this redundant information.. Why is this here?. Why is this here?. Why is this here?  \nThis is the third time I've seen variables like this added that just alias existing variables.  Please don't do this, unless there is some very good reason to do it (which is not apparent to me).. Try to use the same formatting as the rest of the code, i.e. put { on it's own line.. Why is fe being renamed to fe_?. I've looked over the PR and everything looks great, except for one more minor detail.  I noticed that if I call this without giving a feature extractor the code executes and silently does the wrong thing.  Can you make it throw an error if the user tries to make a prediction but forgets to supply the feature extractor?. The user should be required to use any model in the way it was trained.  If it was trained with a particular feature set then that feature set is definitely required when it is used or the results will be very inaccurate. . ",
    "geovedi": "Thanks for the update. Will definitely wait for the APIs.\n. ",
    "swadey": "@geovedi the simple ner_stream tokenizer doesn't handle the more general problem of unicode normalization.  We should probably do this.  If you can file an issue for posterity and discussion, we can keep track of this.\nAs @davisking mentioned, the solution may not be to put it in ner_stream but into the bindings.  The issue there is that it affects training.\n. ",
    "maksim2042": "Dude, you would have like saved me a day of hacking. Oh well, I learned something new. Hope yours is better documented then mine and runs on a Mac :-)\nSent from my iPhone\n\nOn Apr 16, 2014, at 1:31 PM, \"Davis E. King\" notifications@github.com wrote:\nVery cool :)\nHowever, I already setup a python API that works on windows, linux, and mac os (see https://github.com/mit-nlp/MITIE/blob/master/examples/python/ner.py). I forgot to push it into github though so it wasn't publicly viable until a few minutes ago. Sorry I didn't post it earlier.\nCheers,\nDavis\n\u2014\nReply to this email directly or view it on GitHub.\n. I'll be test-driving it shortly :-) let me know if you need help debugging or documenting.\n\nAlso -- can mitie be trained for document classification?\nSent from my iPhone\n\nOn Apr 16, 2014, at 1:41 PM, \"Davis E. King\" notifications@github.com wrote:\nYeah, sorry :)\nThe example is documented reasonably well. I still need to add python docs to the actual functions though, which I'll do soon.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "elfring": "Thanks for your small source code improvement.\n. ",
    "ahalterman": "Thanks! It's working for me now.\n. ",
    "arjunmajum": "@charlieg, thanks for pointing out the bug. It should be fixed now.\n. Argh, I should have made a branch on my end for this feature. Next time.\nI will add additional verbiage to the ensures clause. I had thought about that but it slipped my mind before committing.\nI'm changing the name of the pull request to represent exposing the scores through the api. We should probably wait until I have the c, python and java apis complete before closing it.\n. It will :)\n. All done take a look.\n. Yeah the \"not label\" part is a little messy. Also, the fire alarm went off so I had to check things in, haha.\n. Do you think we should increment the version number?\n. In the python interface, should we return a namedtuple? This would give the user the option of slightly more readable code, but it would not address backwards compatibility.\n. @KanwalSingh the way you are labeling your training data has a bug...\nsample.add_entity(xrange(0,1),\"builder\")\nwill label only \"india\" as builder, not \"india bulls\" as the line \"{india bulls :: builder}...\" would suggest. The correction is as follows:\nsample.add_entity(xrange(0,2),\"builder\")\nSee here for documentation on the xrange function and here for example usage.\nPlease fix this bug and let us know if the problem persists.\n. Andrew,\nLet me jump in here.\nI think what Davis is suggesting is that if you are able to purchase a\ndataset like CoNLL (preferably) or ACE. You could train a general purpose\nmodel. If you used both the model would be exactly the same as the free\nmodel we provide.\nNow if your particular situation require a special entity such as Amazon to\nbe recognized more reliably as an Organization, you would simply hand label\na bunch of training examples where that was the case. You would then add\nthose training examples to the dataset you purchased and train on the\ncombination of the two. You would then have a model that had good general\npurpose performance and the specific performance charecteristics you were\nlooking for.\nArjun\nOn Mon, Apr 27, 2015 at 10:12 PM, Andrew Nystrom notifications@github.com\nwrote:\n\nWas the free model not trained on the whole thing? I care about people,\norgs, and locations, so all but misc.\n\nOn Apr 27, 2015, at 9:10 PM, Davis E. King notifications@github.com\nwrote:\nYou would add whatever cases you personally care about to CoNLL and then\ntrain on the whole thing.\n\u2014\nReply to this email directly or view it on GitHub.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/15#issuecomment-96877743.\n. rp,\n\nCurrently, you will need to retrain the model using all the training data as you acquire new samples.\nIt also sounds like you are having trouble with serialization...\nTo train and save a model follow the approach taken in  'examples/cpp/train_ner/train_ner_example.cpp' through line 106 where the model is saved to disk.\nTo use a model that you have previously saved follow the approach taken in 'examples/cpp/ner/ner_example.cpp.' Line 60 shows how to read a model from disk.\ncheers,\nArjun\n. This sounds like a useful feature, but falls outside of scope for the MITIE project. The design goal is to provide a core functionality for named entity recognition. The user is responsible for managing the input text and translating the output.\n. Adding the Mac OS shared library to the set of precompiled binaries will be no problem. Deploying MITIE to maven central is more involved, but I will add that to the list of tasks on our TODO list.\n. ",
    "charlieg": "Sweet, thanks!\n. ",
    "AWNystrom": "The new extract_entities returns 3-tuples (where the last element is now\nthe score) as opposed to 2-tuples, which could break existing code\nutilizing MITIE, so as a consumer, I think it might be a good idea to\nincrement the version number.\nOn 3 February 2015 at 15:11, Arjun Majumdar notifications@github.com\nwrote:\n\nDo you think we should increment the version number?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/pull/9#issuecomment-72735515.\n. Thanks, Davis. Where would you recommend getting labeled data from? Paying\nfor it is an option.\n\nOn 27 April 2015 at 18:52, Davis E. King notifications@github.com wrote:\n\nClosed #15 https://github.com/mit-nlp/MITIE/issues/15.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/15#event-291449802.\n. What data was the free model trained on?\nOn Apr 27, 2015, at 8:43 PM, Davis E. King notifications@github.com wrote:\nWe used the CoNLL 2003 NER task data along with some of the ACE 2008 data. The CoNLL data is the most useful though so that's what I would mainly focus on.\n\u2014\nReply to this email directly or view it on GitHub.\n. Oh I thought you were saying that training on more data could improve performance and I should try CoNLL and ACE, but if that's what the free model was trained on, how will this improve performance? The results I showed were from the free model. I could be missing something though as I've been awake for 21 hrs.\nOn Apr 27, 2015, at 8:59 PM, Davis E. King notifications@github.com wrote:\nCoNLL and ACE :)\n\u2014\nReply to this email directly or view it on GitHub.\n. Was the free model not trained on the whole thing? I care about people, orgs, and locations, so all but misc.\nOn Apr 27, 2015, at 9:10 PM, Davis E. King notifications@github.com wrote:\nYou would add whatever cases you personally care about to CoNLL and then train on the whole thing.\n\u2014\nReply to this email directly or view it on GitHub.\n. Arjun, thanks for seeing past the confusion and clarifying that. So the\nlicense of the data doesn't restrict the distribution of a model trained on\nit, only the data itself. I'll probably go with your suggestion.\n\nOn 27 April 2015 at 21:20, Arjun Majumdar notifications@github.com wrote:\n\nAndrew,\nLet me jump in here.\nI think what Davis is suggesting is that if you are able to purchase a\ndataset like CoNLL (preferably) or ACE. You could train a general purpose\nmodel. If you used both the model would be exactly the same as the free\nmodel we provide.\nNow if your particular situation require a special entity such as Amazon to\nbe recognized more reliably as an Organization, you would simply hand label\na bunch of training examples where that was the case. You would then add\nthose training examples to the dataset you purchased and train on the\ncombination of the two. You would then have a model that had good general\npurpose performance and the specific performance charecteristics you were\nlooking for.\nArjun\nOn Mon, Apr 27, 2015 at 10:12 PM, Andrew Nystrom <notifications@github.com\n\nwrote:\nWas the free model not trained on the whole thing? I care about people,\norgs, and locations, so all but misc.\n\nOn Apr 27, 2015, at 9:10 PM, Davis E. King notifications@github.com\nwrote:\nYou would add whatever cases you personally care about to CoNLL and\nthen\ntrain on the whole thing.\n\u2014\nReply to this email directly or view it on GitHub.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/15#issuecomment-96877743.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/15#issuecomment-96881913.\n. \n",
    "SeanDunford": "Hey, thanks so much man. I really appreciate that. \n. ",
    "shubhamtalbar": "I am unable to run the command: wordrep -e /home/shubham/MITIE-wordprep\nAm I missing something out?\nPS: MITIE-wordprep contains all the text files of my interest\n. It says:  wordrep: command not found\nI would be really thankful if you help me get it running.. ",
    "KanwalSingh": "@davisking \nthe top command showed 13 GB memory usage, it got killed after that (safe to assume it was using the complete memory, hence got killed) \nThe config of my machine is 16gb memory , 64 bit , 2.1 ghz processor \n. @davisking I used the total_word_feature_extractor.dat for the vocab file \ntrainer = ner_trainer(vocabfile)\nfor line in input_lines:\n    sample = strip_braces(line)\n    trainer.add(sample)\ntrainer.num_threads = 16 \nner = trainer.train()\nhere the sample variable is of type ner_training_instance , this is how we are intitalising it \nline = \"{india bulls :: builder} panvel greens\"\nstrip_line = \"india bulls panvel greens\"\nsample = ner_training_instance(strip_line.split())\nsample.add_entity(xrange(0,1,\"builder\")\n. ya, thats exactly what it returns \n. Hi that's my bad in mentioning the label data , yes I am giving it as 0,2\nOn Monday, February 23, 2015, Arjun Majumdar notifications@github.com\nwrote:\n\n@KanwalSingh https://github.com/KanwalSingh the way you are labeling\nyour training data has a bug...\nsample.add_entity(xrange(0,1,\"builder\")\nwill label only \"india\" as builder, not \"india bull\" as the line \"{india\nbulls :: builder}...\" would suggest. The correction is as follows:\nsample.add_entity(xrange(0,2,\"builder\")\nSee here https://docs.python.org/2/library/functions.html#xrange for\ndocumentation on the xrange function and here\nhttp://www.pythoncentral.io/how-to-use-pythons-xrange-and-range/ for\nexample usage.\nPlease fix this bug and let us know if the problem persists.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/11#issuecomment-75545753.\n\n\nSent from My iPhone\n. I too had 10 labels max\nOn Fri, Feb 27, 2015 at 6:10 PM, Manal notifications@github.com wrote:\n\nThere are 8 different labels in the training data.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/11#issuecomment-76388618.\n\n\nKanwal Prakash Singh\n#Data\nHousing.com\n+919619281431\n. hey Davis, I understand that, will be sharing the training data by Monday,\nwill also see if we can share the code with you. Hope thats fine with you,\nalso share your personal email.\nOn Fri, Feb 27, 2015 at 6:22 PM, Davis E. King notifications@github.com\nwrote:\n\nCan you post your training data? :)\nWe (and a bunch of other groups) have been using MITIE to train models and\nhaven't had any issues. So I need one of you guys to post a program that\nreproduces the issue you are having or it's going to be impossible to debug\n:)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/11#issuecomment-76389933.\n\n\nKanwal Prakash Singh\n#Data\nHousing.com\n+919619281431\n. @davisking I have mailed you the training data \n. done, mailed it to you\nOn Mon, Mar 2, 2015 at 6:03 PM, Davis E. King notifications@github.com\nwrote:\n\nThanks. Please also include a working python program that when executed\ncauses this large ram usage bug to appear so that I can debug it.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/11#issuecomment-76704323.\n\n\nKanwal Prakash Singh\n#Data\nHousing.com\n+919619281431\n. ",
    "manalgandhi": "I am facing this problem too.\nWhen I run the train_ner.py python program, it uses about 718 MB of ram (value under RES - top command).\nWhen I run it on my data it uses 6.7 GB of ram (value under RES - top command).\nScreenshots attached.\nThe python program was faster than the c++ program in determining the best C. But after determining the best C, the python program started consuming lot of ram (it did not comsume lot of ram until then). (Best C was calculated to be 300.69)\nThe c++ program took about 2.5 hours to determine the best C where as the python program took about an hour. I had to force shutdown the system after an hour or so after best C was determined in both the cases.\nI've used the code under tools to build a custom total_word_feature_extractor.\nThis is the output from the python code before it starts determining the best C:\nwords in dictionary: 282\nnum features: 271\nnow do training\nC:           20\nepsilon:     0.01\nnum threads: 4\ncache size:  5\nloss per missed segment:  3\nC: 20   loss: 3     0.949386\nC: 35   loss: 3     0.949386\nC: 20   loss: 4.5   0.948403\nC: 5   loss: 3  0.944963\nC: 20   loss: 1.5   0.946437\nC: 27.5   loss: 3.375   0.948894\nC: 21.2605   loss: 3.35924  0.95086\nC: 19.135   loss: 3.2257    0.949877\nC: 22.119   loss: 3.19385   0.950369\nC: 21.9391   loss: 3.60092  0.949877\nC: 21.941   loss: 3.36495   0.95086\nbest C: 21.2605\nbest loss: 3.35924\nnum feats in chunker model: 4095\ntrain: precision, recall, f1-score: 0.996075 0.997543 0.996808 \nnow do training\nnum training samples: 2043\n...\nMachine Configuration:\n8GB ram\nIntel i5 2.7GHz\nUbuntu 12.04 64bit\nPlease let me know if I've made a mistake somewhere since this was the first time I've executed the program.\n\n\n. I'm not sure if I am allowed to share the training data. I'll post it here if I am allowed to, on monday.\n. There are 8 different labels in the training data.\nAnd the data contains about 600 sentences. Each sentence/phrase contains three to ten words.\n. @davisking , I won't be able to share the training data. Sorry!\n@KanwalSingh could you please share the training data you used with Davis.\n. ",
    "gagan-bansal": "@davisking Thanks for such detailed explanation about MITIE working. It solved my issue regarding the long training duration. \nI am using rasa_nlu with MITIE. There are few issues(160 and 260) in rasa_nlu and root cause may be the one you have explained here.. ",
    "kunalm3701": "gagan-bansal did you solve your issue?. I am also facing the same issue. I am not able to link MITIE with Python on windows machine.. I found out a way for installing MITIE NLP in Windows, here is the steps I followed: Steps for installing MITIE NLP in Windows. First clone the entire MITIE repository\nThen download Visual Studio 2015 Build Tools for C++from this link\nBuild all the directories in the ~\\MITIE-master\\tools first using developer command prompt VS2015:\ni) mkdir build\nii) cd /D build\niii) cmake -G \"Visual Studio 14 2015 Win64\" ..\niv) cmake --build . --config Release --target install \nNow use the appropriate exe which is located under train_ner > Build > Release > train_ner_example.exe folder to invoke it via Golang.. ",
    "techscientist": "This is like my dream come true! \nAlso, will you guys add a training api for java? \n\u2014\nSent from Mailbox\nOn Fri, Feb 27, 2015 at 6:13 PM, Davis E. King notifications@github.com\nwrote:\n\nYou train the model using python or C++ and then load the model file in java.  Right now there isn't a training API for java.\nYes, MITIE is state-of-the-art (http://blog.dlib.net/2014/04/mitie-completely-free-and-state-of-art.html) and very fast.  The NER in OpenNLP is not very good.  There is a Stanford library that is just as accurate as MITIE but it's not free for commercial use.  \nAlso, running MITIE consumes basically just the amount of memory for loading the model file.\nReply to this email directly or view it on GitHub:\nhttps://github.com/mit-nlp/MITIE/issues/12#issuecomment-76388879\n. \n",
    "d-kum": "hi. i am new to python and trying out MITIE Python API to train a named_entity_extractor. But i am getting Undefined variable: ner_training_instance error. How can i resolve that?\n. ",
    "TechnikEmpire": "+1 for this, would love to see. Not trying to be one of those github folks that just asks for more. :) Thanks for publishing this lib.\n. ",
    "jinyichao": "Hi, Davis. I am now trying to add the text classification (which would be also applied to sentiment analysis) to this repo. And in this process, may I ask you some questions? \n1. Is it applicable to directly use the output of sentence_to_feats(...) function as the feature vector for the text?\n2. If the answer is \"Yes\", then when I try to feed it into the \"svm_multiclass_linear_trainer\" as \"svm_multiclass_linear_trainer > >,unsigned long> trainer\", it gives me an error indicating somewhat \"the data type is not matched\". Is my way to revoke the trainer wrong?\n3. If the answer is \"No\", could you please give me more hints on how to get the text feature vector based on current implementation?\nThanks a lot for your kind and quick reply as always. \n. Thanks very much for your quick and insightful reply! \nIn this case, as the first step, is it a right direction to try some simple \"document to feature vector\" representations, such as getting the summation/average of all word vectors from sentence_to_feats, as the feature vector of the entire document? \nAnother question is that, because different \"document to feature vector\" relies on completely different scheme. While most of them makes use of deep learning network / neural network, which is not included in MITIE, if I am correct. So do you mean that MITIE need to inevitably include deep learning in the near future? \n. Yes, I do agree the eigenword based vector representation method is a better way to estimate the word feature vectors. That's also why I am so interested in MITIE. \nRegarding to the neural network based document classifications, there are actually a few attempts. This paper is one of them, https://cs.stanford.edu/~quocle/paragraph_vector.pdf. And basically, it uses almost the same way of word2vec to train the paragraph/document vector together with the word vectors. But I also believe such method might still perform no better than the MITIE, once the document vector method has been implemented. And frankly, I am not a fun of deep learning. :)\nAnyway, thank you so much for the extremely valuable explanations! I will start from the simple case by using the simple summation/average method from the code level. \n. Yeah, it is always glad to hear about new features are on the way! Thank you for all these great stuffs you shared here! :) :+1: \n. Is it possible to separate the extractor from the model? Because I find that even one line of train data may generate over 330 MB model, which is slightly larger than the extractor.\n. Exactly! Is it possible to have multiple models, with the size of each at no more than 100MB, and they share the same extractor, which is of 330MB? Because in this case, if I want multiple models, the total size can be significantly reduced.\n. I really appreciate your prompt reply! It would be better if this use case can be supported soon! \nJava is our first choice, but unfortunately, there is no Java APIs for model training. It would be even better if you can provide such Java APIs soon! \n. That's so sweet! Thanks a lot!\nAt the same time, I also look forward to the separation of extractor and models.\n. Hi Davis, it is so sweet that you have made another PR to make this use case available. And my final question about this issue is, what exactly inside the extractor, say, total_word_feature_extractor.dat? A clear understanding may help us to further reduce the file size. Thank you! \n. In my understanding, is it something like the one used in word2vec, say, \"vectors.bin\" in https://code.google.com/archive/p/word2vec/, that extracts the features of each chunk into a high dimensional space?\n. Thanks for your quick and clear explanation that perfectly addresses my concern! I am just curious that is there a way to customize such data model? Is wordrep in the tools folder the right one?\n. OK, thanks for your detailed instructions. Previously, I was afraid that using bag-of-words alone cannot efficiently use the \"word features\", thus is not expected to work well for a small set of test cases. But yeah, using a combination of them would be much better. Will try to add the implementation soon. \n. I tested both the \"total word feature\" and \"bag-of-words hashing features\" based text classification on a public 20newsgroups dataset. In particular, I simplify the task a bit by only focusing on the 4 coarse types (i.e., comp, rec, sci, and talk), as shown in the table, and uses exactly the train and test files inside the 20news-bydate.tar.gz download from that website without any text pre-processing.  \n\"total word features\" alone achieves 88.7% F1-score, while \"bag-of-words\" alone only achieves 72.7% F1-score. This result actually matches well with my expectation. Because intuitively, \"total word feature\" is trained from a large and high-quality corpus, making it able to properly represent the meaning of each word in some level. Whereas the \"bag-of-words\" only learns the word occurrence from the training data, although, its poor performance might be also attributed to the small hash vector size (e.g., 10000) in the code and other implementation issues. \nAnd for the combined solution, I simply append the \"bag-of-words\" hashing vectors to the \"total word features\", to make a larger feature_vector for the text. In this way, it gives almost the same F1-score (e.g., 88.8%) for the same task. \n. I guess you want to say, 20newsgroup is NOT big enough. :) if in this case, yes, I agree :)\nAnd thanks for pointing out the problems in the code. I will modify them accordingly and let you know later. \n. Hi Davis, I just realized that result.push_back(make_feat(shash(words[i],0))) and result.push_back(make_feat(shash(stem_word(words[i]),10))) actually achieves the bag-of-words features. So I made some modifications, and now, \"word features\" alone achieves 74.9% F1-score, BoW alone is 87.3%, and the combined solution is still 88.8%, for the 20newsgroups task.\n. Thanks for the detailed comments! According to them, I made two more commits, please kindly check them. :)\n. No hurry! Take your time. :)\n. Oops, I forgot to check \"make test\" command before, and there were some minor issues in the makefile. They should be fixed now, please check them one more time. :)\n. Err...... sorry. I forgot to include the text categorizer into the example list. It is there now. Eventually, I hope it works now...\n. Hi, Davis, Thanks for your careful check and detailed comments!\nI've changed the code accordingly, please spare some of your time to go through it again. :)\n. Ha, thanks~ I renamed them through the whole project. Just check it :)\n. Hi, Davis, I really appreciate your patient and careful review! It is really a good lesson for me to learn and practice how to contribute to a high-quality project! \nJust going through the PR again, and revised a few places. Please do not hesitate to point out if there is any further problem. :)\n. Really a great news for me! As I said, it is also a very good lesson for me! Thanks a lot!\n. ",
    "developer-rakeshpaul": "Hi Arjun,\nSorry for delaying in replying. Thanks for the inputs and it clarifies my question.\nKind Regards,\nrp\n. ",
    "dbl001": "David-Laxers-MacBook-Pro:java davidlaxer$ grep X11 CMakeCache.txt\ndlib_LIB_DEPENDS:STATIC=general;/usr/lib/libpthread.dylib;general;/opt/local/lib/libX11.dylib;general;/users/davidlaxer/anaconda/lib/libpng.dylib;general;/opt/local/lib/libopenblas.dylib;general;/usr/lib/liblapack.dylib;general;/users/davidlaxer/anaconda/lib/libsqlite3.dylib;\nxlib:FILEPATH=/opt/local/lib/libX11.dylib\nxlib_path:PATH=/users/davidlaxer/anaconda/include/X11\n\nOn Aug 25, 2015, at 3:44 AM, Davis E. King notifications@github.com wrote:\nYou don't have X11 installed correctly. Did you install XQuartz?\nAlso, where does cmake think X11 is? Run this command and post the output:\ngrep X11 CMakeCache.txt\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134552859.\n. I (re)installed XQuartz 2.7.7 from here:\n\nhttp://xquartz.macosforge.org/trac/wiki/X112.7.7 http://xquartz.macosforge.org/trac/wiki/X112.7.7\nLogged out, same error.\n\nOn Aug 25, 2015, at 3:50 AM, David Laxer davidl@softintel.com wrote:\nDavid-Laxers-MacBook-Pro:java davidlaxer$ grep X11 CMakeCache.txt\ndlib_LIB_DEPENDS:STATIC=general;/usr/lib/libpthread.dylib;general;/opt/local/lib/libX11.dylib;general;/users/davidlaxer/anaconda/lib/libpng.dylib;general;/opt/local/lib/libopenblas.dylib;general;/usr/lib/liblapack.dylib;general;/users/davidlaxer/anaconda/lib/libsqlite3.dylib;\nxlib:FILEPATH=/opt/local/lib/libX11.dylib\nxlib_path:PATH=/users/davidlaxer/anaconda/include/X11\n\nOn Aug 25, 2015, at 3:44 AM, Davis E. King notifications@github.com> wrote:\nYou don't have X11 installed correctly. Did you install XQuartz?\nAlso, where does cmake think X11 is? Run this command and post the output:\ngrep X11 CMakeCache.txt\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134552859.\n. I removed the build directory, recreated it, cd\u2019d to it, then ran cmake ..\nThis didn\u2019t happen before I edited dlib/dlib/CMakeLists.txt\n\n\nDavid-Laxers-MacBook-Pro:build davidlaxer$ cmake ..\n-- Searching for BLAS and LAPACK\n-- Found OpenBLAS library\n-- Found LAPACK library\n-- Configuring done\nCMake Warning (dev):\n  Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run \"cmake\n  --help-policy CMP0042\" for policy details.  Use the cmake_policy command to\n  set the policy and suppress this warning.\nMACOSX_RPATH is not specified for the following targets:\nmitie\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n-- Generating done\n-- Build files have been written to: /Users/davidlaxer/MITIE/mitielib/java\nThe build directory is empty:\nDavid-Laxers-MacBook-Pro:build davidlaxer$ pwd\n/Users/davidlaxer/MITIE/mitielib/java/build\nDavid-Laxers-MacBook-Pro:build davidlaxer$ ls -l\nDavid-Laxers-MacBook-Pro:build davidlaxer$ \n\nOn Aug 25, 2015, at 4:45 AM, Davis E. King notifications@github.com wrote:\nCMake is finding the anaconda copy of X11 which is missing files.\nIf you edit dlib/CMakeLists.txt at line 149 to say:\nfind_path(xlib_path NAMES Xlib.h Xlocale.h\ninstead of this:\nfind_path(xlib_path Xlib.h\nDoes it fix the problem? You will probably have to delete the folder and\nrerun cmake.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134561784.\n. I know.  But this didn\u2019t happen before I changed dlib/dlib/CMakeLists.txt.\nIs this expected?\nOn Aug 25, 2015, at 10:21 AM, Davis E. King notifications@github.com wrote:\nIt says \"Build files have been written to:\n/Users/davidlaxer/MITIE/mitielib/java\".\n;-)\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134676516.\n. David-Laxers-MacBook-Pro:java davidlaxer$ pwd\n/Users/davidlaxer/MITIE/mitielib/java\nDavid-Laxers-MacBook-Pro:java davidlaxer$  make clean\nDavid-Laxers-MacBook-Pro:java davidlaxer$ cmake --build . --config Release --target install\n[  0%] Building CXX object dlib_build/CMakeFiles/dlib.dir/base64/base64_kernel_1.o\n[  1%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bigint/bigint_kernel_1.o\n[  2%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bigint/bigint_kernel_2.o\n[  3%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bit_stream/bit_stream_kernel_1.o\n[  4%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_decoder/entropy_decoder_kernel_1.o\n[  5%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_decoder/entropy_decoder_kernel_2.o\n[  6%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_encoder/entropy_encoder_kernel_1.o\n[  7%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_encoder/entropy_encoder_kernel_2.o\n[  8%] Building CXX object dlib_build/CMakeFiles/dlib.dir/md5/md5_kernel_1.o\n[  9%] Building CXX object dlib_build/CMakeFiles/dlib.dir/tokenizer/tokenizer_kernel_1.o\n[ 10%] Building CXX object dlib_build/CMakeFiles/dlib.dir/unicode/unicode.o\n[ 11%] Building CXX object dlib_build/CMakeFiles/dlib.dir/data_io/image_dataset_metadata.o\n[ 12%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_kernel_1.o\n[ 13%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bsp/bsp.o\n[ 14%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_kernel_1.o\n[ 15%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_kernel_2.o\n[ 16%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_extensions.o\n[ 17%] Building CXX object dlib_build/CMakeFiles/dlib.dir/linker/linker_kernel_1.o\n[ 18%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/extra_logger_headers.o\n[ 19%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/logger_kernel_1.o\n[ 20%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/logger_config_file.o\n[ 20%] Building CXX object dlib_build/CMakeFiles/dlib.dir/misc_api/misc_api_kernel_1.o\n[ 21%] Building CXX object dlib_build/CMakeFiles/dlib.dir/misc_api/misc_api_kernel_2.o\n[ 22%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_extensions.o\n[ 23%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_kernel_2.o\n[ 24%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockstreambuf/sockstreambuf.o\n[ 25%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockstreambuf/sockstreambuf_unbuffered.o\n[ 26%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_kernel.o\n[ 27%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_iostream.o\n[ 28%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_http.o\n[ 29%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/multithreaded_object_extension.o\n[ 30%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threaded_object_extension.o\n[ 31%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_1.o\n[ 32%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_2.o\n[ 33%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_shared.o\n[ 34%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/thread_pool_extension.o\n[ 35%] Building CXX object dlib_build/CMakeFiles/dlib.dir/timer/timer.o\n[ 36%] Building CXX object dlib_build/CMakeFiles/dlib.dir/stack_trace.o\n[ 37%] Building CXX object dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o\nIn file included from /Users/davidlaxer/MITIE/dlib/dlib/gui_widgets/fonts.cpp:14:\n/Users/davidlaxer/MITIE/dlib/dlib/gui_widgets/nativefont.h:29:10: fatal error: \n      'X11/Xlocale.h' file not found\n\ninclude \n     ^\n\n1 error generated.\ndlib_build/CMakeFiles/dlib.dir/build.make:974: recipe for target 'dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o' failed\ngmake[2]: * [dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o] Error 1\nCMakeFiles/Makefile2:122: recipe for target 'dlib_build/CMakeFiles/dlib.dir/all' failed\ngmake[1]: * [dlib_build/CMakeFiles/dlib.dir/all] Error 2\nMakefile:127: recipe for target 'all' failed\ngmake: *** [all] Error 2\nDavid-Laxers-MacBook-Pro:java davidlaxer$ \n\nOn Aug 25, 2015, at 10:21 AM, Davis E. King notifications@github.com wrote:\nIt says \"Build files have been written to:\n/Users/davidlaxer/MITIE/mitielib/java\".\n;-)\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134676516.\n. Same error.  For Java and for C:\n\nDavid-Laxers-MacBook-Pro:dlib davidlaxer$ cd dlib/dlib\nDavid-Laxers-MacBook-Pro:dlib davidlaxer$ vi CMakeLists.txt \n        if (NOT DLIB_NO_GUI_SUPPORT)\n            find_library(xlib X11)\n            # make sure X11 is in the include path\n            find_path(xlib_path NAMES Xlib.h Xlocale.h\n               PATHS\n               /Developer/SDKs/MacOSX10.4u.sdk/usr/X11R6/include\n               PATH_SUFFIXES X11\n               )\nDavid-Laxers-MacBook-Pro:dlib davidlaxer$ cd ../..\nDavid-Laxers-MacBook-Pro:MITIE davidlaxer$ make MITIE-models\ncurl -LO http://sourceforge.net/projects/mitie/files/binaries/MITIE-models-v0.2.tar.bz2\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0   357    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0   447    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0   361    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100  415M  100  415M    0     0   128k      0  0:55:21  0:55:21 --:--:--  119k\ntar -xjf MITIE-models-v0.2.tar.bz2\nDavid-Laxers-MacBook-Pro:MITIE davidlaxer$ make\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C mitielib\nCompiling src/mitie.cpp\nCompiling src/named_entity_extractor.cpp\nCompiling src/ner_feature_extraction.cpp\nCompiling src/binary_relation_detector.cpp\nCompiling src/binary_relation_detector_trainer.cpp\nCompiling src/stem.c\nCompiling src/stemmer.cpp\nCompiling src/conll_parser.cpp\nCompiling src/ner_trainer.cpp\nCompiling ../dlib/dlib/threads/multithreaded_object_extension.cpp\nCompiling ../dlib/dlib/threads/threaded_object_extension.cpp\nCompiling ../dlib/dlib/threads/threads_kernel_1.cpp\nCompiling ../dlib/dlib/threads/threads_kernel_2.cpp\nCompiling ../dlib/dlib/threads/threads_kernel_shared.cpp\nCompiling ../dlib/dlib/threads/thread_pool_extension.cpp\nCompiling ../dlib/dlib/misc_api/misc_api_kernel_1.cpp\nCompiling ../dlib/dlib/misc_api/misc_api_kernel_2.cpp\nLinking libmitie.so\nMaking libmitie.a\n/opt/local/bin/ranlib: file: libmitie.a(threads_kernel_1.o) has no symbols\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C tools/ner_stream\nCompiling src/main.cpp\nmake[2]: Nothing to be done for all'.\nLinking ner_stream with flags: ../../mitielib/libmitie.a\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C examples/C/ner\nCompiling ner_example.c\nmake[2]: Nothing to be done forall'.\nLinking ner_example with flags: ../../../mitielib/libmitie.a -lpthread\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C examples/C/relation_extraction\nCompiling relation_extraction_example.c\nmake[2]: Nothing to be done for all'.\nLinking relation_extraction_example with flags: ../../../mitielib/libmitie.a -lpthread\nBuild Complete\ncp examples/C/ner/ner_example .\ncp examples/C/relation_extraction/relation_extraction_example .\ncp tools/ner_stream/ner_stream .\nDavid-Laxers-MacBook-Pro:MITIE davidlaxer$ cd mitielib/\nDavid-Laxers-MacBook-Pro:mitielib davidlaxer$ make\nmake: Nothing to be done forall'.\nDavid-Laxers-MacBook-Pro:mitielib davidlaxer$ cd ..\nDavid-Laxers-MacBook-Pro:MITIE davidlaxer$ cd examples/C/ner/\nDavid-Laxers-MacBook-Pro:ner davidlaxer$ mkdir build\nDavid-Laxers-MacBook-Pro:ner davidlaxer$ cd build\nDavid-Laxers-MacBook-Pro:build davidlaxer$ cmake ..\n-- The C compiler identification is AppleClang 6.1.0.6020053\n-- The CXX compiler identification is AppleClang 6.1.0.6020053\n-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc\n-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for png_create_read_struct\n-- Looking for png_create_read_struct - found\n-- Looking for jpeg_read_header\n-- Looking for jpeg_read_header - found\n-- Searching for BLAS and LAPACK\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void*\n-- Check size of void* - done\n-- Found OpenBLAS library\n-- Looking for sgetrf_single\n-- Looking for sgetrf_single - not found\n-- Found LAPACK library\n-- Looking for cblas_ddot\n-- Looking for cblas_ddot - found\n-- Check for STD namespace\n-- Check for STD namespace - found\n-- Looking for C++ include iostream\n-- Looking for C++ include iostream - found\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /Users/davidlaxer/MITIE/examples/C/ner/build\nDavid-Laxers-MacBook-Pro:build davidlaxer$ cmake --build . --config Release\nScanning dependencies of target dlib\n[  0%] Building CXX object dlib_build/CMakeFiles/dlib.dir/base64/base64_kernel_1.o\n[  1%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bigint/bigint_kernel_1.o\n[  2%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bigint/bigint_kernel_2.o\n[  3%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bit_stream/bit_stream_kernel_1.o\n[  4%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_decoder/entropy_decoder_kernel_1.o\n[  5%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_decoder/entropy_decoder_kernel_2.o\n[  6%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_encoder/entropy_encoder_kernel_1.o\n[  7%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_encoder/entropy_encoder_kernel_2.o\n[  8%] Building CXX object dlib_build/CMakeFiles/dlib.dir/md5/md5_kernel_1.o\n[  9%] Building CXX object dlib_build/CMakeFiles/dlib.dir/tokenizer/tokenizer_kernel_1.o\n[ 10%] Building CXX object dlib_build/CMakeFiles/dlib.dir/unicode/unicode.o\n[ 11%] Building CXX object dlib_build/CMakeFiles/dlib.dir/data_io/image_dataset_metadata.o\n[ 12%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_kernel_1.o\n[ 13%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bsp/bsp.o\n[ 14%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_kernel_1.o\n[ 14%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_kernel_2.o\n[ 15%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_extensions.o\n[ 16%] Building CXX object dlib_build/CMakeFiles/dlib.dir/linker/linker_kernel_1.o\n[ 17%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/extra_logger_headers.o\n[ 18%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/logger_kernel_1.o\n[ 19%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/logger_config_file.o\n[ 20%] Building CXX object dlib_build/CMakeFiles/dlib.dir/misc_api/misc_api_kernel_1.o\n[ 21%] Building CXX object dlib_build/CMakeFiles/dlib.dir/misc_api/misc_api_kernel_2.o\n[ 22%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_extensions.o\n[ 23%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_kernel_2.o\n[ 24%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockstreambuf/sockstreambuf.o\n[ 25%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockstreambuf/sockstreambuf_unbuffered.o\n[ 26%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_kernel.o\n[ 27%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_iostream.o\n[ 28%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_http.o\n[ 28%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/multithreaded_object_extension.o\n[ 29%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threaded_object_extension.o\n[ 30%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_1.o\n[ 31%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_2.o\n[ 32%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_shared.o\n[ 33%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/thread_pool_extension.o\n[ 34%] Building CXX object dlib_build/CMakeFiles/dlib.dir/timer/timer.o\n[ 35%] Building CXX object dlib_build/CMakeFiles/dlib.dir/stack_trace.o\n[ 36%] Building CXX object dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o\nIn file included from /Users/davidlaxer/MITIE/dlib/dlib/gui_widgets/fonts.cpp:14:\n/Users/davidlaxer/MITIE/dlib/dlib/gui_widgets/nativefont.h:29:10: fatal error: \n      'X11/Xlocale.h' file not found\ninclude \n     ^\n\n1 error generated.\ndlib_build/CMakeFiles/dlib.dir/build.make:974: recipe for target 'dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o' failed\ngmake[2]: * [dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o] Error 1\nCMakeFiles/Makefile2:123: recipe for target 'dlib_build/CMakeFiles/dlib.dir/all' failed\ngmake[1]: * [dlib_build/CMakeFiles/dlib.dir/all] Error 2\nMakefile:127: recipe for target 'all' failed\ngmake: ** [all] Error 2\nDavid-Laxers-MacBook-Pro:build davidlaxer$ cd ..\nDavid-Laxers-MacBook-Pro:ner davidlaxer$ cd ..\nDavid-Laxers-MacBook-Pro:C davidlaxer$ ls\nner         relation_extraction\nDavid-Laxers-MacBook-Pro:C davidlaxer$ cd ..\nDavid-Laxers-MacBook-Pro:examples davidlaxer$ ls\nC   cpp java    matlab  python\nDavid-Laxers-MacBook-Pro:examples davidlaxer$ cd pwd\n-bash: cd: pwd: No such file or directory\nDavid-Laxers-MacBook-Pro:examples davidlaxer$ pwd\n/Users/davidlaxer/MITIE/examples\nDavid-Laxers-MacBook-Pro:examples davidlaxer$ cd ..\nDavid-Laxers-MacBook-Pro:MITIE davidlaxer$ cd mitielib/java\nDavid-Laxers-MacBook-Pro:java davidlaxer$ mkdir build\nDavid-Laxers-MacBook-Pro:java davidlaxer$ cd build\nDavid-Laxers-MacBook-Pro:build davidlaxer$ cmake ..\n-- The C compiler identification is AppleClang 6.1.0.6020053\n-- The CXX compiler identification is AppleClang 6.1.0.6020053\n-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc\n-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for png_create_read_struct\n-- Looking for png_create_read_struct - found\n-- Looking for jpeg_read_header\n-- Looking for jpeg_read_header - found\n-- Searching for BLAS and LAPACK\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void\n-- Check size of void* - done\n-- Found OpenBLAS library\n-- Looking for sgetrf_single\n-- Looking for sgetrf_single - not found\n-- Found LAPACK library\n-- Looking for cblas_ddot\n-- Looking for cblas_ddot - found\n-- Check for STD namespace\n-- Check for STD namespace - found\n-- Looking for C++ include iostream\n-- Looking for C++ include iostream - found\n-- Found SWIG: /usr/local/bin/swig (found version \"2.0.1\") \n-- Found Java: /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/bin/java (found version \"1.8.0.05\") \n-- Found JNI: /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib/libjawt.dylib\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /Users/davidlaxer/MITIE/mitielib/java/build\nDavid-Laxers-MacBook-Pro:build davidlaxer$ cmake --build . --config Release --target install\nScanning dependencies of target dlib\n[  0%] Building CXX object dlib_build/CMakeFiles/dlib.dir/base64/base64_kernel_1.o\n[  1%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bigint/bigint_kernel_1.o\n[  2%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bigint/bigint_kernel_2.o\n[  3%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bit_stream/bit_stream_kernel_1.o\n[  4%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_decoder/entropy_decoder_kernel_1.o\n[  5%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_decoder/entropy_decoder_kernel_2.o\n[  6%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_encoder/entropy_encoder_kernel_1.o\n[  7%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_encoder/entropy_encoder_kernel_2.o\n[  8%] Building CXX object dlib_build/CMakeFiles/dlib.dir/md5/md5_kernel_1.o\n[  9%] Building CXX object dlib_build/CMakeFiles/dlib.dir/tokenizer/tokenizer_kernel_1.o\n[ 10%] Building CXX object dlib_build/CMakeFiles/dlib.dir/unicode/unicode.o\n[ 11%] Building CXX object dlib_build/CMakeFiles/dlib.dir/data_io/image_dataset_metadata.o\n[ 12%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_kernel_1.o\n[ 13%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bsp/bsp.o\n[ 14%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_kernel_1.o\n[ 14%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_kernel_2.o\n[ 15%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_extensions.o\n[ 16%] Building CXX object dlib_build/CMakeFiles/dlib.dir/linker/linker_kernel_1.o\n[ 17%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/extra_logger_headers.o\n[ 18%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/logger_kernel_1.o\n[ 19%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/logger_config_file.o\n[ 20%] Building CXX object dlib_build/CMakeFiles/dlib.dir/misc_api/misc_api_kernel_1.o\n[ 21%] Building CXX object dlib_build/CMakeFiles/dlib.dir/misc_api/misc_api_kernel_2.o\n[ 22%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_extensions.o\n[ 23%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_kernel_2.o\n[ 24%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockstreambuf/sockstreambuf.o\n[ 25%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockstreambuf/sockstreambuf_unbuffered.o\n[ 26%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_kernel.o\n[ 27%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_iostream.o\n[ 28%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_http.o\n[ 28%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/multithreaded_object_extension.o\n[ 29%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threaded_object_extension.o\n[ 30%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_1.o\n[ 31%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_2.o\n[ 32%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_shared.o\n[ 33%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/thread_pool_extension.o\n[ 34%] Building CXX object dlib_build/CMakeFiles/dlib.dir/timer/timer.o\n[ 35%] Building CXX object dlib_build/CMakeFiles/dlib.dir/stack_trace.o\n[ 36%] Building CXX object dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o\nIn file included from /Users/davidlaxer/MITIE/dlib/dlib/gui_widgets/fonts.cpp:14:\n/Users/davidlaxer/MITIE/dlib/dlib/gui_widgets/nativefont.h:29:10: fatal error: \n      'X11/Xlocale.h' file not found\ninclude \n     ^\n\n1 error generated.\ndlib_build/CMakeFiles/dlib.dir/build.make:974: recipe for target 'dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o' failed\ngmake[2]: * [dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o] Error 1\nCMakeFiles/Makefile2:122: recipe for target 'dlib_build/CMakeFiles/dlib.dir/all' failed\ngmake[1]: * [dlib_build/CMakeFiles/dlib.dir/all] Error 2\nMakefile:127: recipe for target 'all' failed\ngmake: *** [all] Error 2\nDavid-Laxers-MacBook-Pro:build davidlaxer$ \n\nOn Aug 25, 2015, at 10:31 AM, Davis E. King notifications@github.com wrote:\nThat didn't rerun cmake. Delete all the build files you generated and rerun\nit from scratch. I would just reclone the repo and try from a fresh copy.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134678800.\n. Same thing.  Is this what you meant?\nCMakeLists.txt:\n\nif (NOT DLIB_NO_GUI_SUPPORT)\n        find_library(xlib X11)\n        # make sure X11 is in the include path\n        find_path(xlib_path_hint X11/Xlocale.h )\n        find_path(xlib_path Xlib.h\n        HINTS ${xlib_path_hint}\n           PATHS\n           /Developer/SDKs/MacOSX10.4u.sdk/usr/X11R6/include\n           PATH_SUFFIXES X11\n           )\n        if (xlib AND xlib_path)\nDavid-Laxers-MacBook-Pro:dlib davidlaxer$ vi CMakeLists.txt \nDavid-Laxers-MacBook-Pro:dlib davidlaxer$ cd\nDavid-Laxers-MacBook-Pro:~ davidlaxer$ cd MITIE/mitielib/java/\nDavid-Laxers-MacBook-Pro:java davidlaxer$ rm -rf build\nDavid-Laxers-MacBook-Pro:java davidlaxer$ mkdir build\nDavid-Laxers-MacBook-Pro:java davidlaxer$ cd build\nDavid-Laxers-MacBook-Pro:build davidlaxer$ cmake ..\n-- The C compiler identification is AppleClang 6.1.0.6020053\n-- The CXX compiler identification is AppleClang 6.1.0.6020053\n-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc\n-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for png_create_read_struct\n-- Looking for png_create_read_struct - found\n-- Looking for jpeg_read_header\n-- Looking for jpeg_read_header - found\n-- Searching for BLAS and LAPACK\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void*\n-- Check size of void* - done\n-- Found OpenBLAS library\n-- Looking for sgetrf_single\n-- Looking for sgetrf_single - not found\n-- Found LAPACK library\n-- Looking for cblas_ddot\n-- Looking for cblas_ddot - found\n-- Check for STD namespace\n-- Check for STD namespace - found\n-- Looking for C++ include iostream\n-- Looking for C++ include iostream - found\n-- Found SWIG: /usr/local/bin/swig (found version \"2.0.1\") \n-- Found Java: /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/bin/java (found version \"1.8.0.05\") \n-- Found JNI: /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib/libjawt.dylib\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /Users/davidlaxer/MITIE/mitielib/java/build\nDavid-Laxers-MacBook-Pro:build davidlaxer$ cmake --build . --config Release --target install\nScanning dependencies of target dlib\n[  0%] Building CXX object dlib_build/CMakeFiles/dlib.dir/base64/base64_kernel_1.o\n[  1%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bigint/bigint_kernel_1.o\n[  2%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bigint/bigint_kernel_2.o\n[  3%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bit_stream/bit_stream_kernel_1.o\n[  4%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_decoder/entropy_decoder_kernel_1.o\n[  5%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_decoder/entropy_decoder_kernel_2.o\n[  6%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_encoder/entropy_encoder_kernel_1.o\n[  7%] Building CXX object dlib_build/CMakeFiles/dlib.dir/entropy_encoder/entropy_encoder_kernel_2.o\n[  8%] Building CXX object dlib_build/CMakeFiles/dlib.dir/md5/md5_kernel_1.o\n[  9%] Building CXX object dlib_build/CMakeFiles/dlib.dir/tokenizer/tokenizer_kernel_1.o\n[ 10%] Building CXX object dlib_build/CMakeFiles/dlib.dir/unicode/unicode.o\n[ 11%] Building CXX object dlib_build/CMakeFiles/dlib.dir/data_io/image_dataset_metadata.o\n[ 12%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_kernel_1.o\n[ 13%] Building CXX object dlib_build/CMakeFiles/dlib.dir/bsp/bsp.o\n[ 14%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_kernel_1.o\n[ 14%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_kernel_2.o\n[ 15%] Building CXX object dlib_build/CMakeFiles/dlib.dir/dir_nav/dir_nav_extensions.o\n[ 16%] Building CXX object dlib_build/CMakeFiles/dlib.dir/linker/linker_kernel_1.o\n[ 17%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/extra_logger_headers.o\n[ 18%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/logger_kernel_1.o\n[ 19%] Building CXX object dlib_build/CMakeFiles/dlib.dir/logger/logger_config_file.o\n[ 20%] Building CXX object dlib_build/CMakeFiles/dlib.dir/misc_api/misc_api_kernel_1.o\n[ 21%] Building CXX object dlib_build/CMakeFiles/dlib.dir/misc_api/misc_api_kernel_2.o\n[ 22%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_extensions.o\n[ 23%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockets/sockets_kernel_2.o\n[ 24%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockstreambuf/sockstreambuf.o\n[ 25%] Building CXX object dlib_build/CMakeFiles/dlib.dir/sockstreambuf/sockstreambuf_unbuffered.o\n[ 26%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_kernel.o\n[ 27%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_iostream.o\n[ 28%] Building CXX object dlib_build/CMakeFiles/dlib.dir/server/server_http.o\n[ 28%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/multithreaded_object_extension.o\n[ 29%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threaded_object_extension.o\n[ 30%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_1.o\n[ 31%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_2.o\n[ 32%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/threads_kernel_shared.o\n[ 33%] Building CXX object dlib_build/CMakeFiles/dlib.dir/threads/thread_pool_extension.o\n[ 34%] Building CXX object dlib_build/CMakeFiles/dlib.dir/timer/timer.o\n[ 35%] Building CXX object dlib_build/CMakeFiles/dlib.dir/stack_trace.o\n[ 36%] Building CXX object dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o\nIn file included from /Users/davidlaxer/MITIE/dlib/dlib/gui_widgets/fonts.cpp:14:\n/Users/davidlaxer/MITIE/dlib/dlib/gui_widgets/nativefont.h:29:10: fatal error: \n      'X11/Xlocale.h' file not found\ninclude \n     ^\n\n1 error generated.\ndlib_build/CMakeFiles/dlib.dir/build.make:974: recipe for target 'dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o' failed\ngmake[2]: * [dlib_build/CMakeFiles/dlib.dir/gui_widgets/fonts.o] Error 1\nCMakeFiles/Makefile2:122: recipe for target 'dlib_build/CMakeFiles/dlib.dir/all' failed\ngmake[1]: * [dlib_build/CMakeFiles/dlib.dir/all] Error 2\nMakefile:127: recipe for target 'all' failed\ngmake: *** [all] Error 2\nDavid-Laxers-MacBook-Pro:build davidlaxer$ \n\nOn Aug 25, 2015, at 2:07 PM, Davis E. King notifications@github.com wrote:\nHmm, try replacing that find_path statement with this:\nfind_path(xlib_path_hint X11/Xlocale.h )\nfind_path(xlib_path Xlib.h\nHINTS ${xlib_path_hint}\nPATHS\n/Developer/SDKs/MacOSX10.4u.sdk/usr/X11R6/include\nPATH_SUFFIXES X11\n)\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134742384.\n\n\nThis is a CMake makefile.  You can find the cmake utility and\ninformation about it at http://www.cmake.org\n\nsetting this makes CMake allow normal looking if else statements\nSET(CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS true)\ncmake_minimum_required(VERSION 2.4)\nset(CMAKE_LEGACY_CYGWIN_WIN32 0) # Remove when CMake >= 2.8.4 is required\nSuppress cmake warnings about changes in new versions.\nif(COMMAND cmake_policy) \n   cmake_policy(SET CMP0003 NEW) \n   if (POLICY CMP0054)\n      cmake_policy(SET CMP0054 NEW)\n   endif()\nendif()\nmake macros that can add #define directives to the entire project.  Not just\nto the dlib library itself.  I.e. to dlib and to any projects that depend\non dlib.\nmacro ( add_global_define def_name )\n   if (NOT CMAKE_CXX_FLAGS MATCHES \"-D${def_name}\")\n      set (CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -D${def_name}\" \n         CACHE STRING \"Flags used by the compiler during all C++ builds.\" \n         FORCE)\n   endif ()\nendmacro()\nmacro ( remove_global_define def_name )\n   if (CMAKE_CXX_FLAGS MATCHES \" -D${def_name}\")\n      string (REGEX REPLACE \" -D${def_name}\" \"\" temp_var ${CMAKE_CXX_FLAGS}) \n      set (CMAKE_CXX_FLAGS \"${temp_var}\" \n         CACHE STRING \"Flags used by the compiler during all C++ builds.\" \n         FORCE)\n   endif ()\nendmacro()\nMake sure ENABLE_ASSERTS is defined for debug builds\nif (NOT CMAKE_CXX_FLAGS_DEBUG MATCHES \"-DENABLE_ASSERTS\")\n   set (CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} -DENABLE_ASSERTS\" \n      CACHE STRING \"Flags used by the compiler during C++ debug builds.\" \n      FORCE)\nendif ()\nDon't try to call add_library(dlib) and setup dlib's stuff if it has already\nbeen done by some other part of the current cmake project.  We do this\nbecause it avoids getting warnings/errors about cmake policy CMP0002.  This\nhappens when a project tries to call add_subdirectory() on dlib more than\nonce.  This most often happens when the top level of a project depends on two\nor more other things which both depend on dlib.\nif (NOT TARGET dlib)\nset (DLIB_ISO_CPP_ONLY_STR \n   \"Enable this if you don't want to compile any non-ISO C++ code (i.e. you don't use any of the API Wrappers)\" )\n   set (DLIB_NO_GUI_SUPPORT_STR \n   \"Enable this if you don't want to compile any of the dlib GUI code\" )\n   set (DLIB_ENABLE_STACK_TRACE_STR \n   \"Enable this if you want to turn on the DLIB_STACK_TRACE macros\" )\n   set (DLIB_ENABLE_ASSERTS_STR \n   \"Enable this if you want to turn on the DLIB_ASSERT macro\" )\n   set (DLIB_USE_BLAS_STR\n   \"Disable this if you don't want to use a BLAS library\" )\n   set (DLIB_USE_LAPACK_STR\n   \"Disable this if you don't want to use a LAPACK library\" )\n   set (DLIB_LINK_WITH_LIBPNG_STR\n   \"Disable this if you don't want to link against libpng\" )\n   set (DLIB_LINK_WITH_LIBJPEG_STR\n   \"Disable this if you don't want to link against libjpeg\" )\n   set (DLIB_LINK_WITH_SQLITE3_STR\n   \"Disable this if you don't want to link against sqlite3\" )\n   #set (DLIB_LINK_WITH_FFTW_STR \"Disable this if you don't want to link against fftw\" )\noption(DLIB_ISO_CPP_ONLY ${DLIB_ISO_CPP_ONLY_STR} OFF)\n   option(DLIB_NO_GUI_SUPPORT ${DLIB_NO_GUI_SUPPORT_STR} OFF)\n   option(DLIB_ENABLE_STACK_TRACE ${DLIB_ENABLE_STACK_TRACE_STR} OFF)\n   option(DLIB_ENABLE_ASSERTS ${DLIB_ENABLE_ASSERTS_STR} OFF)\n   option(DLIB_USE_BLAS ${DLIB_USE_BLAS_STR} ON)\n   option(DLIB_USE_LAPACK ${DLIB_USE_LAPACK_STR} ON)\n   option(DLIB_LINK_WITH_LIBPNG ${DLIB_LINK_WITH_LIBPNG_STR} ON)\n   option(DLIB_LINK_WITH_LIBJPEG ${DLIB_LINK_WITH_LIBJPEG_STR} ON)\n   option(DLIB_LINK_WITH_SQLITE3 ${DLIB_LINK_WITH_SQLITE3_STR} ON)\n   #option(DLIB_LINK_WITH_FFTW ${DLIB_LINK_WITH_FFTW_STR} ON)\nset(source_files \n         base64/base64_kernel_1.cpp\n         bigint/bigint_kernel_1.cpp\n         bigint/bigint_kernel_2.cpp\n         bit_stream/bit_stream_kernel_1.cpp\n         entropy_decoder/entropy_decoder_kernel_1.cpp\n         entropy_decoder/entropy_decoder_kernel_2.cpp\n         entropy_encoder/entropy_encoder_kernel_1.cpp\n         entropy_encoder/entropy_encoder_kernel_2.cpp\n         md5/md5_kernel_1.cpp\n         tokenizer/tokenizer_kernel_1.cpp\n         unicode/unicode.cpp\n         data_io/image_dataset_metadata.cpp)\nif (DLIB_ISO_CPP_ONLY)\n      add_library(dlib STATIC ${source_files} )\n   else()\n```\n  set(source_files ${source_files}\n     sockets/sockets_kernel_1.cpp\n     bsp/bsp.cpp\n     dir_nav/dir_nav_kernel_1.cpp\n     dir_nav/dir_nav_kernel_2.cpp\n     dir_nav/dir_nav_extensions.cpp\n     linker/linker_kernel_1.cpp\n     logger/extra_logger_headers.cpp\n     logger/logger_kernel_1.cpp\n     logger/logger_config_file.cpp\n     misc_api/misc_api_kernel_1.cpp\n     misc_api/misc_api_kernel_2.cpp\n     sockets/sockets_extensions.cpp\n     sockets/sockets_kernel_2.cpp\n     sockstreambuf/sockstreambuf.cpp\n     sockstreambuf/sockstreambuf_unbuffered.cpp\n     server/server_kernel.cpp\n     server/server_iostream.cpp\n     server/server_http.cpp\n     threads/multithreaded_object_extension.cpp\n     threads/threaded_object_extension.cpp\n     threads/threads_kernel_1.cpp\n     threads/threads_kernel_2.cpp\n     threads/threads_kernel_shared.cpp\n     threads/thread_pool_extension.cpp\n     timer/timer.cpp\n     stack_trace.cpp\n     )\n# we want to link to the right stuff depending on our platform.\n  if (WIN32 AND NOT CYGWIN) ###############################################################################\n     if (DLIB_NO_GUI_SUPPORT)\n        set (dlib_needed_libraries ws2_32 winmm)\n     else()\n        set (dlib_needed_libraries ws2_32 winmm comctl32 gdi32 imm32)\n     endif()\n  elseif(APPLE) ############################################################################\n     find_library(pthreadlib pthread)\n     set (dlib_needed_libraries ${pthreadlib})\n if (NOT DLIB_NO_GUI_SUPPORT)\n    find_library(xlib X11)\n    # make sure X11 is in the include path\nfind_path(xlib_path_hint X11/Xlocale.h )\nfind_path(xlib_path Xlib.h\nHINTS ${xlib_path_hint}\n       PATHS \n       /Developer/SDKs/MacOSX10.4u.sdk/usr/X11R6/include\n       PATH_SUFFIXES X11\n       )\n    if (xlib AND xlib_path)\n       get_filename_component(x11_path ${xlib_path} PATH CACHE)\n       include_directories(${x11_path})\n       set(dlib_needed_libraries ${dlib_needed_libraries} ${xlib} )\n    else()\n       message(\" *****************************************************************************\")\n       message(\" *** DLIB GUI SUPPORT DISABLED BECAUSE X11 DEVELOPMENT LIBRARIES NOT FOUND ***\")\n       message(\" *** Make sure XQuartz is installed if you want GUI support.               ***\")\n       message(\" *** You can download XQuartz from: http://xquartz.macosforge.org/landing/ ***\")\n       message(\" *****************************************************************************\")\n       set(DLIB_NO_GUI_SUPPORT ON CACHE STRING ${DLIB_NO_GUI_SUPPORT_STR} FORCE )\n    endif()\n endif()\n\n mark_as_advanced(pthreadlib xlib xlib_path x11_path)\n\nelse () ##################################################################################\n     find_library(pthreadlib pthread)\n     set (dlib_needed_libraries ${pthreadlib})\n # link to the nsl library if it exists.  this is something you need sometimes \n find_library(nsllib nsl)\n if (nsllib)\n    set (dlib_needed_libraries ${dlib_needed_libraries} ${nsllib})\n endif ()\n\n # link to the socket library if it exists.  this is something you need on solaris\n find_library(socketlib socket)\n if (socketlib)\n    set (dlib_needed_libraries ${dlib_needed_libraries} ${socketlib})\n endif ()\n\n if (NOT DLIB_NO_GUI_SUPPORT)\n    include(FindX11)\n    if (X11_FOUND)\n       include_directories(${X11_INCLUDE_DIR})\n       set (dlib_needed_libraries ${dlib_needed_libraries} ${X11_LIBRARIES})\n    else()\n       message(\" *****************************************************************************\")\n       message(\" *** DLIB GUI SUPPORT DISABLED BECAUSE X11 DEVELOPMENT LIBRARIES NOT FOUND ***\")\n       message(\" *** Make sure libx11-dev is installed if you want GUI support.            ***\")\n       message(\" *** On Ubuntu run: sudo apt-get install libx11-dev                        ***\")\n       message(\" *****************************************************************************\")\n       set(DLIB_NO_GUI_SUPPORT ON CACHE STRING ${DLIB_NO_GUI_SUPPORT_STR} FORCE )\n    endif()\n endif()\n\n mark_as_advanced(nsllib pthreadlib socketlib)\n\nendif () ##################################################################################\nif (NOT DLIB_NO_GUI_SUPPORT)\n     set(source_files ${source_files}\n        gui_widgets/fonts.cpp\n        gui_widgets/widgets.cpp\n        gui_widgets/drawable.cpp\n        gui_widgets/canvas_drawing.cpp\n        gui_widgets/style.cpp\n        gui_widgets/base_widgets.cpp\n        gui_core/gui_core_kernel_1.cpp\n        gui_core/gui_core_kernel_2.cpp\n        )\n  endif()\nINCLUDE (CheckFunctionExists)\nif (DLIB_LINK_WITH_LIBPNG)\n     # try to find libpng \n     find_package(PNG QUIET)\n     # Make sure there isn't something wrong with the version of LIBPNG\n     # installed on this system.\n     if (PNG_FOUND)\n        set(CMAKE_REQUIRED_LIBRARIES ${PNG_LIBRARY})\n        CHECK_FUNCTION_EXISTS(png_create_read_struct LIBPNG_IS_GOOD)\n     endif()\n     if (PNG_FOUND AND LIBPNG_IS_GOOD)\n        include_directories(${PNG_INCLUDE_DIR})\n        set (dlib_needed_libraries ${dlib_needed_libraries} ${PNG_LIBRARY})\n     else()\n        # If we can't find libpng then statically compile it in.\n        include_directories(external/libpng external/zlib)\n        set(source_files ${source_files}\n           external/libpng/png.c\n           external/libpng/pngerror.c\n           external/libpng/pngget.c\n           external/libpng/pngmem.c\n           external/libpng/pngpread.c\n           external/libpng/pngread.c\n           external/libpng/pngrio.c\n           external/libpng/pngrtran.c\n           external/libpng/pngrutil.c\n           external/libpng/pngset.c\n           external/libpng/pngtrans.c\n           external/libpng/pngwio.c\n           external/libpng/pngwrite.c\n           external/libpng/pngwtran.c\n           external/libpng/pngwutil.c\n           external/zlib/adler32.c\n           external/zlib/compress.c\n           external/zlib/crc32.c\n           external/zlib/deflate.c\n           external/zlib/gzclose.c\n           external/zlib/gzlib.c\n           external/zlib/gzread.c\n           external/zlib/gzwrite.c\n           external/zlib/infback.c\n           external/zlib/inffast.c\n           external/zlib/inflate.c\n           external/zlib/inftrees.c\n           external/zlib/trees.c\n           external/zlib/uncompr.c\n           external/zlib/zutil.c\n           )\n     endif()\n     set(source_files ${source_files}\n        image_loader/png_loader.cpp\n        image_saver/save_png.cpp\n        )\n  endif()\nif (DLIB_LINK_WITH_LIBJPEG)\n     # try to find libjpeg \n     find_package(JPEG QUIET)\n     # Make sure there isn't something wrong with the version of libjpeg \n     # installed on this system.  Also don't use the installed libjpeg\n     # if this is an APPLE system because apparently it's broken (as of 2015/01/01).\n     if (JPEG_FOUND)\n        set(CMAKE_REQUIRED_LIBRARIES ${JPEG_LIBRARY})\n        CHECK_FUNCTION_EXISTS(jpeg_read_header LIBJPEG_IS_GOOD)\n     endif()\n     if (JPEG_FOUND AND LIBJPEG_IS_GOOD AND NOT APPLE)\n        include_directories(${JPEG_INCLUDE_DIR})\n        set (dlib_needed_libraries ${dlib_needed_libraries} ${JPEG_LIBRARY})\n     else()\n        # If we can't find libjpeg then statically compile it in.\n        add_definitions(-DDLIB_JPEG_STATIC)\n        set(source_files ${source_files}\n              external/libjpeg/jcomapi.cpp\n              external/libjpeg/jdapimin.cpp\n              external/libjpeg/jdapistd.cpp\n              external/libjpeg/jdatasrc.cpp\n              external/libjpeg/jdcoefct.cpp\n              external/libjpeg/jdcolor.cpp\n              external/libjpeg/jddctmgr.cpp\n              external/libjpeg/jdhuff.cpp\n              external/libjpeg/jdinput.cpp\n              external/libjpeg/jdmainct.cpp\n              external/libjpeg/jdmarker.cpp\n              external/libjpeg/jdmaster.cpp\n              external/libjpeg/jdmerge.cpp\n              external/libjpeg/jdphuff.cpp\n              external/libjpeg/jdpostct.cpp\n              external/libjpeg/jdsample.cpp\n              external/libjpeg/jerror.cpp\n              external/libjpeg/jidctflt.cpp\n              external/libjpeg/jidctfst.cpp\n              external/libjpeg/jidctint.cpp\n              external/libjpeg/jidctred.cpp\n              external/libjpeg/jmemmgr.cpp\n              external/libjpeg/jmemnobs.cpp\n              external/libjpeg/jquant1.cpp\n              external/libjpeg/jquant2.cpp\n              external/libjpeg/jutils.cpp\n              external/libjpeg/jcapimin.cpp\n              external/libjpeg/jdatadst.cpp\n              external/libjpeg/jcparam.cpp\n              external/libjpeg/jcapistd.cpp\n              external/libjpeg/jcmarker.cpp\n              external/libjpeg/jcinit.cpp\n              external/libjpeg/jcmaster.cpp\n              external/libjpeg/jcdctmgr.cpp\n              external/libjpeg/jccoefct.cpp\n              external/libjpeg/jccolor.cpp\n              external/libjpeg/jchuff.cpp\n              external/libjpeg/jcmainct.cpp\n              external/libjpeg/jcphuff.cpp\n              external/libjpeg/jcprepct.cpp\n              external/libjpeg/jcsample.cpp\n              external/libjpeg/jfdctint.cpp\n              external/libjpeg/jfdctflt.cpp\n              external/libjpeg/jfdctfst.cpp\n              )\n     endif()\n     set(source_files ${source_files}\n        image_loader/jpeg_loader.cpp\n        image_saver/save_jpeg.cpp\n        )\n  endif()\nif (DLIB_USE_BLAS OR DLIB_USE_LAPACK)\n     # Try to find BLAS and LAPACK \n     include(cmake_find_blas.txt)\n if (DLIB_USE_BLAS)\n    if (blas_found)\n       set (dlib_needed_libraries ${dlib_needed_libraries} ${blas_libraries})\n    else()\n       set(DLIB_USE_BLAS OFF CACHE STRING ${DLIB_USE_BLAS_STR} FORCE )\n    endif()\n endif()\n\n if (DLIB_USE_LAPACK)\n    if (lapack_found)\n       set (dlib_needed_libraries ${dlib_needed_libraries} ${lapack_libraries})\n    else()\n       set(DLIB_USE_LAPACK OFF CACHE STRING ${DLIB_USE_LAPACK_STR} FORCE )\n    endif()\n endif()\n\nendif()\nif (DLIB_LINK_WITH_SQLITE3)\n     find_library(sqlite sqlite3)\n     # make sure sqlite3.h is in the include path\n     find_path(sqlite_path sqlite3.h)\n     if (sqlite AND sqlite_path)\n        get_filename_component(sqlite_path2 ${sqlite_path} PATH CACHE)\n        include_directories(${sqlite_path2})\n        set(dlib_needed_libraries ${dlib_needed_libraries} ${sqlite} )\n     else()\n        set(DLIB_LINK_WITH_SQLITE3 OFF CACHE STRING ${DLIB_LINK_WITH_SQLITE3_STR} FORCE )\n     endif()\n     mark_as_advanced(sqlite sqlite_path sqlite_path2)\n  endif()\nif (DLIB_LINK_WITH_FFTW)\n     find_library(fftw fftw3)\n     # make sure fftw3.h is in the include path\n     find_path(fftw_path fftw3.h)\n     if (fftw AND fftw_path)\n        include_directories(${fftw_path})\n        set(dlib_needed_libraries ${dlib_needed_libraries} ${fftw} )\n     else()\n        set(DLIB_LINK_WITH_FFTW OFF CACHE STRING ${DLIB_LINK_WITH_SQLITE3_STR} FORCE )\n     endif()\n     mark_as_advanced(fftw fftw_path)\n  endif()\nadd_library(dlib STATIC ${source_files} )\n  target_link_libraries(dlib ${dlib_needed_libraries} )\n```\nendif ()  ##### end of if NOT DLIB_ISO_CPP_ONLY ##########################################################\n#test for some things that really should be true about the compiler\n   include(TestForSTDNamespace)\n   include(TestForANSIStreamHeaders)\nif (DLIB_LINK_WITH_LIBPNG AND NOT DLIB_ISO_CPP_ONLY)\n      add_global_define(DLIB_PNG_SUPPORT)\n   else()\n      remove_global_define(DLIB_PNG_SUPPORT)\n   endif()\nif (DLIB_LINK_WITH_LIBJPEG AND NOT DLIB_ISO_CPP_ONLY)\n      add_global_define(DLIB_JPEG_SUPPORT)\n   else()\n      remove_global_define(DLIB_JPEG_SUPPORT)\n   endif()\nif (DLIB_LINK_WITH_FFTW AND NOT DLIB_ISO_CPP_ONLY)\n      add_global_define(DLIB_USE_FFTW)\n   else()\n      remove_global_define(DLIB_USE_FFTW)\n   endif()\nif (DLIB_USE_BLAS AND blas_found)\n      add_global_define(DLIB_USE_BLAS)\n   else()\n      remove_global_define(DLIB_USE_BLAS)\n   endif()\nif (DLIB_USE_LAPACK AND lapack_found)\n      add_global_define(DLIB_USE_LAPACK)\n   else()\n      remove_global_define(DLIB_USE_LAPACK)\n   endif()\nif (DLIB_ISO_CPP_ONLY)\n      add_global_define(DLIB_ISO_CPP_ONLY)\n   else()\n      remove_global_define(DLIB_ISO_CPP_ONLY)\n   endif()\nif (DLIB_NO_GUI_SUPPORT)\n      add_global_define(DLIB_NO_GUI_SUPPORT)\n   else()\n      remove_global_define(DLIB_NO_GUI_SUPPORT)\n   endif()\nif (DLIB_ENABLE_STACK_TRACE)\n      add_global_define(DLIB_ENABLE_STACK_TRACE)\n   else()\n      remove_global_define(DLIB_ENABLE_STACK_TRACE)\n   endif()\nif (DLIB_ENABLE_ASSERTS)\n      add_global_define(ENABLE_ASSERTS)\n   else()\n      remove_global_define(ENABLE_ASSERTS)\n   endif()\nendif()\n. David-Laxers-MacBook-Pro:build davidlaxer$ grep X11 CMakeCache.txt\ndlib_LIB_DEPENDS:STATIC=general;/usr/lib/libpthread.dylib;general;/opt/local/lib/libX11.dylib;general;/users/davidlaxer/anaconda/lib/libpng.dylib;general;/opt/local/lib/libopenblas.dylib;general;/usr/lib/liblapack.dylib;general;/users/davidlaxer/anaconda/lib/libsqlite3.dylib;\nxlib:FILEPATH=/opt/local/lib/libX11.dylib\nxlib_path:PATH=/users/davidlaxer/anaconda/include/X11\n\nOn Aug 25, 2015, at 2:53 PM, Davis E. King notifications@github.com wrote:\nYeah, that's what I mean. What do you see when you grep your\nCMakeCache.txt file for xlib? What path does it find? Still the broken\nanaconda one?\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134753122.\n. David-Laxers-MacBook-Pro:build davidlaxer$ grep xlib CMakeCache.txt\nxlib:FILEPATH=/opt/local/lib/libX11.dylib\nxlib_path:PATH=/users/davidlaxer/anaconda/include/X11\nxlib_path_hint:PATH=/opt/local/include\n//ADVANCED property for variable: xlib\nxlib-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: xlib_path\nxlib_path-ADVANCED:INTERNAL=1\nOn Aug 25, 2015, at 3:23 PM, Davis E. King notifications@github.com wrote:\nWhat about grep xlib CMakeCache.txt?\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134759151.\n. David-Laxers-MacBook-Pro:build davidlaxer$ ls -l /opt/local/include/X11/Xlocale.h \n-rw-r--r--  1 root  admin  1297 Mar 20 08:17 /opt/local/include/X11/Xlocale.h\nDavid-Laxers-MacBook-Pro:build davidlaxer$ \nOn Aug 25, 2015, at 4:06 PM, Davis E. King notifications@github.com wrote:\nSeems like it should have worked. Is there a\n/opt/local/include/X11/Xlocale.h file on your machine?\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134766317.\n. :-)\n\n[100%] Linking CXX shared module lib/libjavamitie.jnilib\ncompiling Java files...\nMaking jar file...\nadded manifest\nadding: edu/(in = 0) (out= 0)(stored 0%)\nadding: edu/mit/(in = 0) (out= 0)(stored 0%)\nadding: edu/mit/ll/(in = 0) (out= 0)(stored 0%)\nadding: edu/mit/ll/mitie/(in = 0) (out= 0)(stored 0%)\nadding: edu/mit/ll/mitie/BinaryRelation.class(in = 1322) (out= 663)(deflated 49%)\nadding: edu/mit/ll/mitie/BinaryRelationDetector.class(in = 1569) (out= 703)(deflated 55%)\nadding: edu/mit/ll/mitie/EntityMention.class(in = 1959) (out= 864)(deflated 55%)\nadding: edu/mit/ll/mitie/EntityMentionVector.class(in = 2306) (out= 906)(deflated 60%)\nadding: edu/mit/ll/mitie/global.class(in = 734) (out= 370)(deflated 49%)\nadding: edu/mit/ll/mitie/globalJNI.class(in = 5531) (out= 1540)(deflated 72%)\nadding: edu/mit/ll/mitie/NamedEntityExtractor.class(in = 2591) (out= 948)(deflated 63%)\nadding: edu/mit/ll/mitie/StringVector.class(in = 1999) (out= 864)(deflated 56%)\nadding: edu/mit/ll/mitie/SWIGTYPE_p_mitie__binary_relation.class(in = 513) (out= 320)(deflated 37%)\nadding: edu/mit/ll/mitie/TokenIndexPair.class(in = 1428) (out= 689)(deflated 51%)\nadding: edu/mit/ll/mitie/TokenIndexVector.class(in = 2250) (out= 909)(deflated 59%)\n[100%] Built target javamitie\nInstall the project...\n-- Install configuration: \"Release\"\n-- Installing: /Users/davidlaxer/MITIE/mitielib/java/cmake_swig_jni../libjavamitie.jnilib\n-- Installing: /Users/davidlaxer/MITIE/mitielib/java/cmake_swig_jni../javamitie.jar\nsudo make test\nPassword:\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C mitielib\nmake[1]: Nothing to be done for all'.\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C tools/ner_stream\nmake[2]: Nothing to be done forall'.\nLinking ner_stream with flags: ../../mitielib/libmitie.a\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C examples/C/ner\nmake[2]: Nothing to be done for all'.\nLinking ner_example with flags: ../../../mitielib/libmitie.a -lpthread\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C examples/C/relation_extraction\nmake[2]: Nothing to be done forall'.\nLinking relation_extraction_example with flags: ../../../mitielib/libmitie.a -lpthread\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C examples/cpp/ner\nmake[2]: Nothing to be done for all'.\nLinking ner_example with flags: ../../../mitielib/libmitie.a -lpthread\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C examples/cpp/train_ner\nmake[2]: Nothing to be done forall'.\nLinking train_ner_example with flags: ../../../mitielib/libmitie.a -lpthread\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C examples/cpp/train_relation_extraction\nmake[2]: Nothing to be done for all'.\nLinking train_relation_extraction_example with flags: ../../../mitielib/libmitie.a -lpthread\nBuild Complete\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -C examples/cpp/relation_extraction\nmake[2]: Nothing to be done forall'.\nLinking relation_extraction_example with flags: ../../../mitielib/libmitie.a -lpthread\nBuild Complete\ncp examples/C/ner/ner_example .\ncp examples/C/relation_extraction/relation_extraction_example .\ncp tools/ner_stream/ner_stream .\ntar -xjf MITIE-models-v0.2.tar.bz2\n./ner_stream MITIE-models/english/ner_model.dat < sample_text.txt > /tmp/MITIE_test.out\nLoading MITIE NER model file...\ntime: 14.08sec\nNow running NER tool...\ndiff /tmp/MITIE_test.out sample_text.reference-output\n./relation_extraction_example MITIE-models/english/ner_model.dat MITIE-models/english/binary_relations/rel_classifier_location.location.contains.svm sample_text.txt > /tmp/MITIE_test_rel.out\ndiff /tmp/MITIE_test_rel.out sample_text.reference-output-relations\nTesting completed successfully\nDavid-Laxers-MacBook-Pro:MITIE davidlaxer$ \n\nOn Aug 25, 2015, at 4:32 PM, Davis E. King notifications@github.com wrote:\nHuh, well, you can change the CMakeLists.txt back to the way it was at the\nbeginning but tell it to look for Xlocale.h instead of Xlib.h and it should\nwork fine. It would be preferable to make cmake check that both those\nfiles are there, especially since Xlib.h is the main header for X11, but\nfinding the folder based on the presence of Xlocale.h is probably robust\nenough.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mit-nlp/MITIE/issues/22#issuecomment-134770332.\n. Are you on LinkedIn?\nOn Aug 25, 2015, at 3:44 AM, Davis E. King notifications@github.com wrote:\nYou don't have X11 installed correctly. Did you install XQuartz?\nAlso, where does cmake think X11 is? Run this command and post the output:\ngrep X11 CMakeCache.txt\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "holgerd77": "Ah, very cool, would be helpful if you link these two blog articles also in the GitHub README.md.\n. ",
    "rajesh-bhat": "Is there any way to get scores for all the entity or intents?\nExample:\nintent1 : confidence value\nintent 2 : confidence value. ",
    "sugampandey": "@davisking - is it possible to get scores for the other intents too, not just the best matching intent?. ",
    "nsanthanam": "Is the score returned the signed distance of the entity from the hyperplane? If so, should we expect to see negative scores for tokens that MITIE considers non-named-entities? We have not seen any so far across a large number of examples (in the 1000s).. ",
    "eamonnbell": "No problem. I look forward to exploring MITIE!\n. ",
    "wihoho": "Thanks for your reply.\nUnfortunately, we are only allowed to use Java in production. And we would like to train the model continuously with users' feedback.\nSo I saw the the issue regarding to Java api to train models in February. I really really appreciate that the API will be available soon. Thanks a lot.\n. Hi davisking,\nI totally agree with you.\nI have some experience with training SVM models using images. The process is slow and consumes a large amount of resources.\nBut we have very specific cases to deal with, and we are very likely to limit the amount of data to train the model. Still the restriction is that we are only allowed to use Java in production. And we really want to make the whole process automatically,.\nIf possible, thank you very much. :)\n. By the way, this is really the best named entity recognition package that I have ever seen.\nThe speed and accuracy is very impressive. Moreover, it is friendly to commercial usages. \n. Hi Davis,\nThanks for your reply. The second point is easy to fix.\nFor the first point, actually I did not want to use pointer. Without pointer, the following error message happens. So is there any solution to it? Thanks in advance.\n```\n/Users/wihoho/Github/MITIE/mitielib/java/../include/mitie/approximate_substring_set.h:18:11: error: cannot define the implicit copy assignment operator for\n      'mitie::approximate_substring_set', because non-static const member 'init_hash' can't use copy assignment operator\n    class approximate_substring_set\n          ^\n/Users/wihoho/Github/MITIE/mitielib/java/../include/mitie/approximate_substring_set.h:207:28: note: declared here\n        const dlib::uint32 init_hash;\n                           ^\n/Users/wihoho/Github/MITIE/mitielib/java/../include/mitie/word_morphology_feature_extractor.h:12:11: note: implicit copy assignment operator for 'mitie::approximate_substring_set' first\n      required here\n    class word_morphology_feature_extractor\n          ^\n/Users/wihoho/Github/MITIE/mitielib/java/../include/mitie/total_word_feature_extractor.h:16:11: note: implicit copy assignment operator for 'mitie::word_morphology_feature_extractor' first\n      required here\n    class total_word_feature_extractor\n          ^\n/Users/wihoho/Github/MITIE/mitielib/java/../include/mitie/ner_trainer.h:111:11: note: implicit copy assignment operator for 'mitie::total_word_feature_extractor' first required here\n    class ner_trainer\n          ^\n/Users/wihoho/Github/MITIE/mitielib/java/./swig_api.h:258:14: note: implicit copy assignment operator for 'mitie::ner_trainer' first required here\n        impl =  mitie::ner_trainer(filename);\n             ^\n4 errors generated.\n```\n. Hi Davis,\nMerry Christmas & Happy New Year.\nSorry for the late reply due to the holiday season. \nI have revised this PR as your suggestions. Please check. Thanks.\n. I agree with you. The original aim is to reduce the model size. Using one file is much more elegant.\nThe changes have been made. Please check. \n. Thanks. I will download visual studio and try again. Soon will update the status here.\n. Just like what you said, after pointing to the visual studio compiler, windows is able to produce the shared library. Thanks.\n. Thanks for your reply.\nWe have different cases to adopt this NER. For instance, one is to extract useful information from flight tickets. Also, there are many other cases. We have concerns on the resources needed if all data is aggregated to train a single model. Moreover, the accuracy may not be guaranteed. \n. Yeah. That will be great. \n. Hi Davis,\nThanks for your feedback. We will update the PR accordingly when we have time, \n. Already in maven \n\nedu.mit.ll\nmitie\n0.6\n\nhttp://search.maven.org/#artifactdetails%7Cedu.mit.ll%7Cmitie%7C0.6%7Cjar\n. Thank you for your opinion. Davis. ",
    "marghidanu": "Hello Davis,\nI'm having a similar problem where I allow users to create their own models and load them dynamically when changed.  So loading multiple model files can take up some memory (and also it's a bit redundant). If this feature would be available this would be great!\n. Awsome! Keep up the great work! \n. Hello Davis,\nFrom what I see the lastest approved PR (Python pure model persistence), solves our issue. Right? At least for Python users ... :)\nEdit: Actually no.. it only reduces the model footprint on disk. It does not aggregate models in memory. \n. Maybe the Java SWIG file can be adjusted to work for Ruby or Perl. ",
    "vinvinod": "Hello Davis,\nPlease have a look at #88 . \nI was in need of this feature for my code in python. \nI have made the changes which I needed.\nLet me know what you think.. I have converted all tabs to spaces.. I am really sorry! I should have been thorough.\nHopefully, now I haven't missed anything.. Hi Davis,\nAdded the required documentation for the functions and examples. \nSome redundant arguments have been removed as you have pointed out.\nAlso, I have removed the unnecessary temp variables I was using at some places.\n. I have made the required changes.\nNow there is a version info saved along with the pure model file. We can increment this if there is a change in serialisation process in the future.. I think you can close https://github.com/mit-nlp/MITIE/issues/36 now. Ok thanks. I have a doubt here.\nThere is an option just to use the BoW if the feature extractor is not supplied. \nif (fe.get_num_dimensions() == 0) {\n    temp = df.predict(extract_BoW_features(sentence));\n} else {\n    const std::vector<matrix<float, 0, 1> > &sent = sentence_to_feats(fe, sentence);\n    temp = df.predict(extract_combined_features(sentence, sent));\n}\nSo should it throw an error, or just give a warning that word-feature is not being used and just BoW is being used instead?. We will have to store the fingerprint of the feature extractor when we are serializing the pure model. I will make the required changes and commit soon.\nIt won't be backward compatible! As the old pure model files wont be having the fingerprint of the the feature extractor.. ",
    "SakthivelAnand": "Hello,\nI am new to NLP ,i don't know how to configure,i can't uderstand existing instructions , the mitie for java api...Please help me to config it and provide me aexample program for the ner train with File contents\nThank You. Thank you David ...I got it...\ud83d\ude05\ud83d\udc4d. Hello,\nI am trying to execute the NER example program that you are given on github....\ni can't compile ,,it shows the error like\nNative code library failed to load. \njava.lang.UnsatisfiedLinkError: no javamitie in java.library.path\ni referd it on discussion...I got a one idea to run it by using .sh file....as\nexport LD_LIBRARY_PATH=opt/etc/MITIE/mitielib\nexport CLASSPATH=opt/etc/mitie-0.1.jar:.\njavac NerMitie.java\njava NerMitie\nbut...This method also does not work...\nPlease help me...\nThank you ....in advance. Yaa...I did...Where the shared library stored in the mitielib directory(Name of the library)..i can't find it\nMay be this caused those problem.\nThank you. ",
    "lopuhin": "Thanks @davisking !\n. @jaksmid do you have any example of the input that cases errors for tokenize_with_offsets? I tried some unicode inputs and could not trigger the error.\n. @jaksmid sorry I was not clear - I meant the error you get when encoding into utf-8\n. > As we have to convert to bytes before passing it to the mitie api, NER model can detect entities that, after looking their start and end positions using MITIE tokenizer result in invalid start and end positions from the point of view of the utf-8 encoding. We get the error after converting back to utf-8 but only the substring given by the start and end positions. I hope this description is clear enough.\nYes, the description is clear - but I did not manage to get such invalid decodings myself. Can you provide such an example? More precisely, this is way I tried:\n```\n\n\n\n[w.decode('utf-8') for w, _ in mitie.tokenize_with_offsets(u'\u0430\u043b\u044c\u0442 \u0438\u043b\u0438 \u0431\u0430\u044f\u043d?'.encode('utf-8'))]\n['\u0430\u043b\u044c\u0442', '\u0438\u043b\u0438', '\u0431\u0430\u044f\u043d', '?']\n```\n\n\n\nOr, using indices:\n```\n\n\n\ntext = u'\u0430\u043b\u044c\u0442 \u0438\u043b\u0438 \u0431\u0430\u044f\u043d?'\nutf8_text = text.encode('utf-8')\nresult = mitie.tokenize_with_offsets(utf8_text)\nutf8_text[result[0][1]:result[1][1]].decode('utf-8')\n'\u0430\u043b\u044c\u0442 '\nutf8_text[result[1][1]:result[2][1]].decode('utf-8')\n'\u0438\u043b\u0438 '\n```\n\n\n\nThe indices are offsets into the utf-8 encoded string, as this is what MITIE gets.\n. Looks like MITIE converts \u2019 into ' during tokenize_with_offsets - not sure if this is expected (I'm not a MITIE developer, just use the Python API too). Perhaps this is some normalization step.\nThis seems to be a different issue though, right.\n. @jaksmid I see, thanks. For this string the output is\n[(b'Department', 0), (b'\\xe2\\x80\\x98\\xe2\\x80\\x98B', 11), (b\"'\", 18), (b\"'\", 19), (b'of', 25), (b'Charles', 28), (b'Nicolle', 36), (b'Hospital', 44), (b'(', 53), (b'Tunisia', 54), (b')', 61), (b'.', 62)]\nand expected output would be (19 -> 22):\n[(b'Department', 0), (b'\\xe2\\x80\\x98\\xe2\\x80\\x98B', 11), (b\"'\", 18), (b\"'\", 22), (b'of', 25), (b'Charles', 28), (b'Nicolle', 36), (b'Hospital', 44), (b'(', 53), (b'Tunisia', 54), (b')', 61), (b'.', 62)]\nSo looks like here one index is indeed wrong.\n. @mikeatm MITIE has basic python 3 support. I guess you need to encode filename, which is a string, to bytes: \ntrainer = ner_trainer(u\"../../MITIE-models/english/total_word_feature_extractor.dat\".encode('utf8'))\n. ",
    "mahaben": "Thanks for your reply! I have another question, actually I want to use the model ner_model.dat in the folder MITIE-models but wants to add other entities. Is it possible?\nThanks again :)\n. ",
    "aniket-chowdhury": "You can use rasa_nlu to train your custom model.. ",
    "skprasadu": "Yes as per README it is cmake -G \"Visual Studio 10 Win64\" ..\nI tried this and it did not work, also I tried cygwin and that also did not work. But I cannot use  Visual Studio because of company restriction.. I need Cygwin. Can you help me.\n. What is labels?\n. ",
    "dvorka": "Normally SVM tries to find a decision function for separating the data of one class from the data of another one. The prediction is returning the distance to this decision function. So the bigger, the more sure the data is in the class; and the sign is above or below the decision function, which is the 0 level. -- sop. ",
    "chrismattmann": "thanks for filing this @manalishah \n. thanks @arjunmajum \n. Thanks it's my understanding that the shared jni libs though are only for Linux \n. \ud83d\udc4d\ud83d\udcaf. any reason not to use the ALv2?. ah, OK @davisking got it. ",
    "manalishah": "thanks @arjunmajum. \n. ",
    "imxuyue": "I am asking this because I am trying to figure out what languages the library can support.\n. ",
    "grafael": "Let me know if I understood right. It means that I can use the same total_word_feature_vector.dat file for any language? Or I need to create a new one if I decide to train sentences in another language?. So, I couldn't find any example (at least in example folder) showing how to train my own feature extractor. There any point in the source code that I could start? I just found an example (python) showing the content of a feature extractor file.. Thanks @davisking  worked perfectly!. @davisking it's possible to extend the word vector generated by the tool \"wordrep\" ? I mean, there popular implementations like word2vec and GloVe, it's possible to take advantages of that ? or the word vector used in MITIE stands for something different?. By the way, what if I train 100, 1000 of distinct entities? I mean not only ORG, PERSON ... but thousands of entities? Will the algorithm fit well? In other words, the large number of instances seems to work well during the training phase, but the number of entities has some limitation?  What else could increase the time of training phase?. Try add one more entity... not just Product. If I understand right, you are trying to extend your dataset with data that is not labeled. In this case, your Precision and Recall will only increase for \"O\" (BILOU). Also, it may let your Named Entities Scores even worse. Give it a try and run the conneval script, it will clarify what I'm trying to explain.\n  . As far as I know, it will depend on the size of your datasets. Also, check the memory usage (maybe you are out of memory and the system starts to use swap). ",
    "jaksmid": "But python wrapper around mitie does not support UTF-8 (hence the conversion). Or am I mistaken?\n. At least if I call mitie.tokenize_with_offsets(somenonascii_unicodechar) I get the error.\nThats why we convert to python 2.7 string (which is equal to bytes).\nMitie model than happily detects entites that are in the middle of some unicode string as it does not know about the unicode. And the backwards conversion is no longer possible.\nFrom your comment it seems it is the issue in the python API to mitie.\nBut we have encoding consistent, it is because of mitie we had to create this inconsistency.\n. import mitie\ntokens_with_offset = mitie.tokenize_with_offsets(u'Bart\u2019s home')\nResults in Traceback (most recent call last):\n  File \"/Users/smidj/PycharmProjects/literature-search-pipeline/main.py\", line 8, in \n    tokens_with_offset = mitie.tokenize_with_offsets(u'Bart\u2019s home')\n  File \"/Users/smidj/.virtualenvs/ls/lib/python2.7/site-packages/mitie/mitie.py\", line 161, in tokenize_with_offsets\n    tok = mitie_tokenize(str, ctypes.byref(token_offsets))\nctypes.ArgumentError: argument 1: : 'ascii' codec can't encode character u'\\u2019' in position 4: ordinal not in range(128)\n. Oh, I see.\nWell, you can get the error like this:\nu\"Bart\u2019s home\".encode('utf-8')[0:6].decode('utf-8')\nSomething similar is obtainable for the beginning of the unicode.\nAs we have to convert to bytes before passing it to the mitie api, NER model can detect entities that, after looking their start and end positions using MITIE tokenizer result in invalid start and end positions from the point of view of the utf-8 encoding. We get the error after converting back to utf-8 but only the substring given by the start and end positions. I hope this description is clear enough.\nThanks,\nJakub\n. text = u\"Hemoglobin Bart\u2019s is a \u03b3 tetramer with a very high oxygen affinity, thus oxygen delivery to the tissues is poor.\"\nimport mitie\nencoded_text=text.encode('utf-8')\nresult =mitie.tokenize_with_offsets(encoded_text)\nresult[2][0] == encoded_text[15:19]\nThe issue may be somewhat different. I am using the length of the string in token to detect the end of the token in text. However, in the above case I would expect the last line to be true as the token detected is the weird symbol plus s and encoded text corresponds to that. Would you know why the comparison result in false?\n. But what if you want to detect the substring of the input text defined by the token? Only the beginning and normalised string is returned. For this you would also need the end of the token (beginning of the next token can be far far away and you cant guarantee that the length of the normalised token is the same as it would be without a normalization.) \n. Why would I want to write another tokenizer? I just want to save the positions in the original text and I am completely happy with the tokenizer as is.\nI would expect that this normalization would be at least documented somewhere.\nBetter way would be IMHO to do the normalization internally as tokenization is part of the public API.  One would expect that the tokens are substrings of the original text. This normalization is more of a side effect.\n. @lopuhin \nI got the original error we were discussing previously by running the following:\ntext = 'Department \u2018\u2018B\u2019\u2019 of Charles Nicolle Hospital (Tunisia).'\ntokens = mitie.tokenize_with_offsets(text)\nfor index, (token, offeset) in enumerate(tokens):\n    begin = offeset\n    if index+1 == len(tokens):\n        end = len(text)\n    else:\n        end = tokens[index+1][1]\n    substring = text[begin:end]\n    unicode = substring.decode('utf-8')\nThis results in UnicodeDecodeError: 'utf8' codec can't decode byte 0xe2 in position 0: unexpected end of data. In this case, the tokenizer indeed detects a token end in the middle of the unicode character encoded by multiple bytes.\n. ",
    "palicand": "I agree with @jaksmid in that it does seem to be quite weird. Doing these normalisations internally does make sense, but IMO users would expect the output tokens to be denormalised, i. e. really a substring of the input. Or at least output both the normalised and original token.\n. ",
    "maxmert": "^^^ @davisking Sorry, it was a very stupid question. And a looong baaad day. Thank you for your answer.\n. ",
    "raphael0202": "Thanks for your quick answer.\n. If you don't mind, I was wondering what was the size of your training set directory? It would help me to determine the amount of memory I need (all my text files are ~700MB)\n. Great, thanks!\n. I've submitted a pull request, the code should be fully python3 compatible :)\n. Yes it should be called on every string that comes from MITIE, I've spotted the remaining methods where to_default_str_type were not called (I've just added a commit to the PR). I'm only familiar with NER tagger, so if I've missed some piece of code where it should be called, don't hesitate to tell me.\n. ",
    "ossrapaport": "It certainly does, and having modded it a little I have found it to be a great package! Let me ask if there are any plans for Spanish binary relationship extraction? Much appreciated :)\n. ",
    "philipperemy": "Thank you very much! Much appreciated!\n. ",
    "Tony-HSU": "@davisking Should I tokenize my Chinese characters before i use wordrep to generate total_word_feature_extractor.dat ?\nFor example\n\n\u4eca\u5929\u5929\u6c23\u771f\u597d(original)\n\u4eca\u5929 \u5929\u6c23 \u771f\u597d(tokenized)\n\u4eca \u5929 \u5929 \u6c23 \u771f \u597d(just separate every characters with white space)\n\nwhich one is prefered?. ",
    "alejandrokonto": "@davisking \nTo introduce a new language all i need is tokenizer and annotated data? For the tokenizer, i understand it is needed and i can provide it. For the annotated data aren't you referring to the named entities annotation?\nHowever, to my (not yet that strong) understanding, MITIE uses pre-trained models on a few languages (English, Spanish, German), so, in order to use Chinese (for the purposes of my project) shouldn't i provide Chinese word embedding and pre-trained models similar to the other languages? . thanks for the prompt reply!. ",
    "amn41": "Cool - I'm currently making a Python API for the text_categorizer. Will submit a PR soon and we can test it out. \n. yep just figuring out how \ud83d\udc3c \n. cool should be easier to see changes now!\n. There's something wrong with the way the text_cateogorization_trainer gets allocated when I call trainer = text_categorizer_trainer(\"../../../MITIE-models/english/total_word_feature_extractor.dat\")\n1. if I give an invalid path to the init method it doesn't raise the exception conditioned on self.__obj == None\n2. if I give a valid path and then try to invoke a class method e.g. trainer.beta I get a seg fault. \nAny tips for debugging this? Can't see where the text_categorizer_trainer class differs from the other trainer classes\n. @davisking do you know a good way to debug this? not sure how to gdb when calling through python\n. I've got almost everything working, but a bit stuck now on how to pass a mutable string through the python/c++ interface. \nThe __call__ method of the text_categorizer class looks like this: \ndef __call__(self, tokens):\n        \"\"\"\"\"\"\n        score = ctypes.c_double()\n        label = ctypes.c_char_p() \n        #label1 = ctypes.cast(ctypes.create_string_buffer(50),ctypes.c_char_p)\n        ctokens = python_to_mitie_str_array(tokens)\n        if (_f.mitie_categorize_text(self.__obj, ctokens, ctypes.byref(label), ctypes.byref(score)) != 0):\n            raise Exception(\"Unable to classify text.\")\n        return label, score\nHave tried using ctypes.cast, label.value, etc to extract the data from the pointers passed to the c++ method, but everthing either segfaults or doesn't give the thing we want. @davisking I can't find anywhere else in the code this is done, but maybe you've had to do this elsewhere? \nAlternatively I could change the mitie_categorize_text method in mitie.cpp to return a string rather than modifying it in-place, but I don't want to break from the pattern of using a returned int to signify success/failure.\n. Cool - all seems to work now! @davisking thanks for the hint on the double pointers. Let me know if there's anything more to do before merging. \n. awesome, thanks @davisking for the detailed feedback. Memory allocation issue should be resolved as well as the copypasta errors in the comments. \n. quite right about the memory leak. Should be fixed now along w documentation\n. Hey @davisking rebased off master so conflicts gone\n. thanks for feedback @davisking - updated\n. ",
    "avitale": "Hi, I have added a Python API for the Total Word Feature Extractor and submitted a pull request, let me know if it's ok!\n. ok, thanks!\n. Hi,\nAfter this commit I started getting an error from the to_bytes function.\nThe error seems to be that string.encode('utf-8') gets called on a utf string where string.encode('utf-8') was previously called. I am using Python 2.7.\nI wrapped string.encode('utf-8') in a try/except and things started working again.\n. Sure, done\n. ~150 samples, 12 classes. Training time > 2 hours\n. No, I'm not sure compiler optimizations are on, I've just compiled with make under mitielib. Should I do something different?\nI can also try using cmake and linking a BLAS library.\n. I thought so at the beginning, but it actually performs pretty well on both training and holdout datasets.\nI'll try with a BLAS library and providing more samples and see if things change.\nThank you very much Davis!\n. Linking to BLAS brought multicore, still very long time to train.\nAs a solution, I split the classifier in multiple cascading ones, each with less classes.\nTo deploy multiple classifiers, it would make sense to do the sentence embedding outside of text_categorizer::predict and avoid saving the total_word_feature_extractor together with each text_categorizer.\nIf I find time to do it I'll submit a PR.\n. Done, the pull request is updated\n. Updated requirement descriptions\n. Cool, thanks for your patience :)\n. Please check if the new solution is ok\n. :) My C++ & Stack Overflow skills cannot come up with something better.\nAny suggestion on how to go from string vector to char \"array\"? Or other ways to return a list of strings to Python?\n. Oh no, it was so easy without trying to reinvent the wheel :)\n. ",
    "kpoots": "I saw a few feature requests about parallelism which were uncool.\nThis is not a question. This is another view of the work.\nIt is a thanks for the effort.\n. I am working on a project for school which requires knowledge extraction.\nI was wondering what was available - what I could use or build-on to avoid\ncoding from scratch.\nI haven't seen one like MITIE, where the source code is all nicely\nlaid-out, so I thought I would have a look.\nI need the relationships between entities to be driven by what's in the\ntext. For example, for  \"the cat sits by the door\", the nouns \"cat\" and\n\"door\" are found, and the relationship \"sits\" or \"sits by\" is extracted\nwithout a pre-coded classifier.  I think this is called \"Open Information\nExtraction.\". Anyway, I'm still looking if anything comes to mind.\nMITIE is also interesting because it includes some machine learning tools.\nI don't remember the reason, but we worked in Python when doing our machine\nlearning stuff. To see this in C is awesome.\nThanks !\nKent\nOn Fri, Sep 23, 2016 at 11:29 PM, Davis E. King notifications@github.com\nwrote:\n\nI'm not sure I understand what you are talking about. Is this a question?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/75#issuecomment-249342374, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AG38ID2YTXMnXazIU9D5gPpKGrbNvcI5ks5qtJkBgaJpZM4KFhzv\n.\n\n\nKent Poots\n. ",
    "edevil": "Well, the documentation mentions support for Python 2.7 explicitly, and I ran one of the examples using Python 3 and got a typical error of non Python2->3 conversion:\nTraceback (most recent call last):\n  File \"categorize_text.py\", line 23, in <module>\n    cat = text_categorizer(\"new_text_categorizer.dat\")\n  File \"//anaconda/envs/mitie/lib/python3.5/site-packages/mitie/mitie.py\", line 660, in __init__\n    raise Exception(\"Unable to load text_categorizer detector from \" + filename)\nTypeError: Can't convert 'bytes' object to str implicitly\n(The underlying problem was that I did not have the dataset in place, but it gave an indication that the code was not Python 3 ready).\n. ",
    "mariogintili": "additionally here's how the mitielib/java folder structure looks like https://gist.github.com/mariogintili/d1cd0da3abaf536a694ed6da0993de7d\nI also changed the CLASS_PATH to export the following:\nexport CLASSPATH=../../mitielib/java/build/lib/javamitie.jar:.\n. @davisking I have \ud83d\ude04 \nI'm using a relatively new OS(Mac OS Sierra) think that could be part of the problem? \n. @davisking Hello,\nThere are 2\n- one here\n- and another one here\nNone of them seem are located where the ENV var CLASSPATH points to\n. @davisking not sure I'm following, I should run make install from the java dir? \n. ``` shell\n$ pwd\n/Users/mariogintili/dev/MITIE/mitielib/java/build\n$ make --debug install\nGNU Make 3.81\nCopyright (C) 2006  Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.\nThere is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE.\nThis program built for i386-apple-darwin11.3.0\nReading makefiles...\nUpdating goal targets....\n File install' does not exist.\nMust remake targetinstall'.\nmake: *** No rule to make target `install'.  Stop.\n```\n. awesome!. ",
    "hartsantler": "that is the example i based my code on, there is no real difference in the code, so the problem is caused by something else.. ",
    "stefan-it": "E.g. (using GCC 6.2.1) :\nbash\nIn file included from /mnt/Repositories/mitie/dlib/dlib/data_io/../geometry/../serialize.h:157:0,\n                 from /mnt/Repositories/mitie/dlib/dlib/data_io/../geometry/rectangle.h:10,\n                 from /mnt/Repositories/mitie/dlib/dlib/data_io/../geometry.h:6,\n                 from /mnt/Repositories/mitie/dlib/dlib/data_io/image_dataset_metadata.h:8,\n                 from /mnt/Repositories/mitie/dlib/dlib/data_io/image_dataset_metadata.cpp:6:\n/mnt/Repositories/mitie/dlib/dlib/data_io/../geometry/../smart_pointers/shared_ptr.h:299:18: warning: 'template<class> class std::auto_ptr' is deprecated [-Wdeprecated-declarations]\n             std::auto_ptr<Y>& r\nThe workaround can be found here.. Can you provide the training script and the sample file here, so we can look into it a more deeper?. ",
    "evotianusx": "\nthanks for the quick reply. I dont think that the wrong tagging is what caused it. Please take a look at the attached image. My program will split the \" _ \" and assign it as the tag. As you can see sometimes it can find a hit sometimes it misses it.\nEven in the same sentence, some of the tagged words is recognized while some is missed.\nThe function NER is just a helper function to call the tokenizing and the tagging of the model . Do I need each tag instances on each of the training instances? Like on your examples, the 2 samples both have person and location tagging to them.. In both of the case I use the tokenize() function from the mitie, the same one you used on the python examples.. I think I figured out what went wrong, some of my training samples does not have any NER instance however my script add them to the training set regardless, I have put in an IF check condition, and re-training it again\nEDIT:\nImplementing an IF check increases the number of recognized entity, but there are still some that are not recognized( even though it is present in the training data) \nHere is the Sample input file and my training script. \nThank you for your time\nNER_Indonesia.zip\n\n. Have you tried installing it again this time use an administrator\ncredentials. It said that the file cannot be found ( or pip is not allowed\nto access the files)\nOn Fri, Jan 13, 2017, 7:00 AM Davis E. King notifications@github.com\nwrote:\n\nThat doesn't look like the entire output from the build process. So it's\nimpossible to say anything.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/87#issuecomment-272322616, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AHhr0pV2YlCBi8zqBAsSGFmPFoaHcvCaks5rRr61gaJpZM4LiDrt\n.\n. \n",
    "abubakarsohail": "I am having the exact same error while installing MITIE on Windows 10. Please check the screenshot attached.\n$ pip install git+https://github.com/mit-nlp/MITIE.git\nCollecting git+https://github.com/mit-nlp/MITIE.git\n  Cloning https://github.com/mit-nlp/MITIE.git to c:\\users\\abubak~1\\appdata\\loca                                                                                                                l\\temp\\pip-iosonl-build\nInstalling collected packages: mitie\n  Running setup.py install for mitie: started\n    Running setup.py install for mitie: finished with status 'error'\n    Complete output from command c:\\python27\\python.exe -u -c \"import setuptools                                                                                                                , tokenize;file='c:\\users\\abubak~1\\appdata\\local\\temp\\pip-iosonl-build                                                                                                                \\setup.py';f=getattr(tokenize, 'open', open)(file);code=f.read().replace('\\                                                                                                                r\\n', '\\n');f.close();exec(compile(code, file, 'exec'))\" install --record c:                                                                                                                \\users\\abubak~1\\appdata\\local\\temp\\pip-zyrmfi-record\\install-record.txt --single                                                                                                                -version-externally-managed --compile:\n    running install\n    running build\n    error: [Error 2] The system cannot find the file specified\n----------------------------------------\n\nCommand \"c:\\python27\\python.exe -u -c \"import setuptools, tokenize;file='c:\\                                                                                                                \\users\\abubak~1\\appdata\\local\\temp\\pip-iosonl-build\\setup.py';f=getattr(to                                                                                                                kenize, 'open', open)(file);code=f.read().replace('\\r\\n', '\\n');f.close();ex                                                                                                                ec(compile(code, file, 'exec'))\" install --record c:\\users\\abubak~1\\appdata\\                                                                                                                local\\temp\\pip-zyrmfi-record\\install-record.txt --single-version-externally-mana                                                                                                                ged --compile\" failed with error code 1 in c:\\users\\abubak~1\\appdata\\local\\temp\\                                                                                                                pip-iosonl-build\\\n\n. The thing is I am working on rasa.ai. I was following their tutorial. There was this link \"pip install git+https://github.com/mit-nlp/MITIE.git\". By the way I have successfully build using cmake. But don't know what to do next. I need it working with rasa.ai which is written in Python. Can you help?. As I told you, the build was successful. But I don't know what to do next. When I try to run from one of the python examples, the system is unable to find the specified module. \n\n. My friend was able to install mitie successfully on linux using this command \"pip install git+https://github.com/mit-nlp/MITIE.git\". Why can't I do the same on Windows?. @maxiz Were you able to build and use MITIE successfully? If so, can you please guide me as well? I have build MITIE using cmake but I am stuck on the next part. Don't know how to use it.. @davisking I was just supposed to run the scripts using python, right? Please check the screenshot.\n\n. Yes, I did. The build was successful. Is there any way to confirm the build was successful or not? The output showed 0 errors and some 180 warnings. If you want, I can run these commands again with a fresh repo clone.. Did everything from the start. Seems everything is working fine now. Thanks @davisking . You need to install cmake first.. Okay. Here's how I got it working. I made a folder named 'mitie' in the Lib folder of python installation and copied 3 files names 'init.py', 'mitie.py' and 'mitie.dll' in it. Try running rasa again and let me know if it helps.. Hey there. I don't have them right now since I stopped working on it. I am sorry. . I am having the exact same issue. Please check the screenshots. @davisking can you help?\n\n\n\n. I am using rasa_nlu. I am still a beginner. I am using rasa_nlu to train the model. I don't know how I am supposed to write a program. . Okay. Thanks.. Hey @davisking I am facing the same error after building MITIE again.\nC:\\Users\\Abu Bakar Sohail\\Desktop\\FYP\\restaurant-bot>python -m rasa_nlu.train -c config_mitie.json\nTraceback (most recent call last):\n  File \"C:\\Python27\\lib\\runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"C:\\Python27\\lib\\runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"build\\bdist.win32\\egg\\rasa_nlu\\train.py\", line 67, in <module>\n  File \"build\\bdist.win32\\egg\\rasa_nlu\\train.py\", line 56, in do_train\n  File \"build\\bdist.win32\\egg\\rasa_nlu\\train.py\", line 30, in create_trainer\n  File \"build\\bdist.win32\\egg\\rasa_nlu\\trainers\\mitie_trainer.py\", line 2, in <module>\n  File \"mitie.py\", line 665, in <module>\n    _f.mitie_load_text_categorizer_pure_model_without_feature_extractor.restype = ctypes.c_void_p\n  File \"C:\\Python27\\lib\\ctypes\\__init__.py\", line 375, in __getattr__\n    func = self.__getitem__(name)\n  File \"C:\\Python27\\lib\\ctypes\\__init__.py\", line 380, in __getitem__\n    func = self._FuncPtr((name_or_ordinal, self))\nAttributeError: function 'mitie_load_text_categorizer_pure_model_without_feature_extractor' not found. Thanks @davisking. Worked like a charm. . ",
    "maxiz": "@davisking That's the complete output I got on the console when I ran pip install git+https://github.com/mit-nlp/MITIE.git. \n@evotianusx  I even tried to run this as an administrator but got the same error.\nI'll try running cmake and see if it builds successfully.. ",
    "HardikShah289": "Hi @abubakarsohail ,\nI am facing the same issue. Using Cmake I have build. but when running any python py script it giving me same error as you got \"Module not found\". (Jan 16 snapshot).\nWhat did you do next?\nThanks in advanced? I am using x64 bit laptop. do i need to install python x64 bit too? I am also trying to connect it with rasa.ai.\nthanks for you all help. \n. There is mitie.pyc but not mitie.pyd file. . when you said python path, do i need put it inside Python installed path or path from where my ner.py is?\nThanks sir for your help.. I ran your given commands. Output: 157 warning 0 errors.\nStill no mitie.pyd file, but it has created mitie.dll, mitite.lib file.. I run it as admin\nTried on window 10 & window server 12. I have posted on rasa nlu only but they suggest to post it here. :( \nI am not python techie, don't know how to reproduce it. . if you can help to understand what this error is about, i can try to debug and provide some information. what is save_to_disk relation with mitie.py. ",
    "andikas": "Hi all, \n@abubakarsohail @davisking \nI got the same problem with abubakarsohaiil.\ni want to use MITIE too at my Rasa NLU.\nplease help me how to install that mitie. i got the same error. i dont know how to use cmake. cmake not recognized by command prompt.\nthanks before for all you guys.\ncheers,\n. Hi @abubakarsohail ,\nThanks for your quick respond.\nLook like I can't access their official website for now. the site always can't be reached.\nI'll give some feedback if I've installed cmake.\nThanks,\nCheers,. Hi @abubakarsohail,\nI've been able to install cmake and run this: \ncd tools/ner_stream\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release\nwhere do I put this folder?\n\nmy project location at: C:/xxxxxxxxx/rasa_nlu\nhow do I continue to rasa.ai?\nThanks,\ncheers. Hi @davisking,\nI know and i've followed that code.\ni just confuse why when I run 'python -m rasa_nlu.train -c config_mitie.json', I still asked to install mitie.\nI've download mitie from this github and run that code (the screenshot from my previous comment).\nI want to ask abubakar how he continue it to rasa.ai?\nare there something wrong with my folder structure so I keep asked to instal mitie?\nThanks,\nCheers. Hi @davisking,\nThanks for the reminder.\nHi @abubakarsohail,\nI have create a new issue in rasa_nlu, hopefully you could help me there.\nhttps://github.com/RasaHQ/rasa_nlu/issues/410\nThanks all,\nCheers. ",
    "devepro": "@abubakarsohail Thanks a lot..!! your solution worked. ",
    "modadugu": "@abubakarsohail can you share the pyhton binaries generated for mitie package.. current package on mitie is out of sync with the master.. Can you please share the link of uploaded binaries. I am not seeing any updates in the download section. ",
    "teja463": "@modadugu Attached the generatef files. I am using python 64 bit. See if those are usefull\nmitie.zip\n. ",
    "cjhurst": "I had this issue. pip install cmake.... fixed.. ",
    "korokokou": "I'm might be off subject but could someone explain to me what are Spectral word embedding or redirect me to ressources about this subject...??. thanks for the info ^^. Thanks for the answer. I have an other question, How many ram should i get if i want to drastically improve  my learning time.?? i'm currently at 8Gb.. Hi again.\nI finally chose 16 and, with some swap, managed to survives. Does Openblas have any impact on wordrep.?? I'm watching htop and it does'nt seem there is any multicore usage going on. Maybe i'm missing something....... Furthmore, i'm eager to avance the project. How could i help...??. That's what i thought.  Is there any option i have to activate to make sur wordrep use openBLAS..?? I'm currently doing somme computing on a AWS machine and it seems that there is only one core currently in use. I'm made sure mitie detect the library at compilation, so i don't understand where is my fuck up.. ",
    "kwkwvenusgod": "I can see your point. But I am curious whether you have tried GloVe previously. If you have done this, how about the performance? Thank you very much\n. ",
    "cmllmrnn": "Hello! Whenever I'm running corpora with more than 21,000 words, it stops after counting the number of raw ASCII files and it says \"bad allocation\". I can run those that have 20,000 number of words. I have 7GB RAM.. Now using 16GB RAM and it still says bad allocation. Any suggestions how much RAM should I need or any workarounds?. Hi, I'm now using a 160GB RAM but it still says bad allocation for 4GB, 1GB, 340MB and even 13MB data. My machine has 40 vCPU. Any machine specifications aside from the RAM? . Thanks. That seems to resolve it but I have another problem. Now, every time I run large data (tried 1GB and 4GB), it crashes. \n\"wordrep.exe has stopped working. A problem caused the program to stop working correctly. Please close the program\"\nI'm using Windows 10 and I enabled compatibility mode for Windows 8 in the Properties dialog box and ran Command Prompt and wordrep as admin. Do I need to do anything else?. Yup at first I didn't modify anything. But because it crashed for 300MB+ data, I searched Google for fixes assuming it's a generic problem but those didn't do the trick. . I ran the following when I'm in the MITIE-master folder:\ncd tools/wordrep\nmkdir build\ncd build\ncmake \"Visual Studio 15 2017 Win64\" ..\ncmake --build . --config Release. For small datasets, wordrep works fine. GitHub only allows files smaller than 10MB data and I have a 13MB data that worked fine. Since I cannot post it here, I'll just give the URL. This is the next smallest decent French corpus I found online: http://www.statmt.org/europarl/v7/fr-en.tgz with size 339MB that failed. \n\nOnce downloaded, extract the file and keep just the europarl-v7.fr-en.fr file\nOpen command prompt \ncd C:\\Users\\cmllmrnn\\Documents\\MITIE Workspace\\MITIE-master\\tools\\wordrep\\build\\Release\nwordrep -e \"C:\\path\\to\\file\\train\"\nA dialog box opens saying wordrep.exe has stopped working. It appears when these are in the console:\nnumber of raw ASCII files found: 1\nnum words: 200000\nsaving word counts to top_word_counts.dat\nnumber of raw ASCII files found: 1\nSample 50000000 random context vectors\nNow do CCA (left size: 50000000, right size: 50000000).. Thanks a lot! Will compile and train and will let you know as soon as possible.. I was able to train a 4GB data successfully. It took 3 days. Thank you!. \n",
    "rhazegh": "Thanks for the recommendations. I complied against OpenBLAS. I will try Intel MKL to see if it makes a difference. . I deleted my original OpenBLAS, downloaded the source code and compiled it. Got this:\n```\nOpenBLAS build complete. (BLAS CBLAS LAPACK LAPACKE)\nOS               ... Linux           \n  Architecture     ... x86_64             \n  BINARY           ... 64bit               \n  C compiler       ... GCC  (command line : gcc)\n  Fortran compiler ... GFORTRAN  (command line : gfortran)\n  Library Name     ... libopenblas_haswellp-r0.2.20.dev.a (Multi threaded; Max num-threads is 16)\n```\nComplied wordrep against this new OpenBLAS and it still uses only one CPU when doing the CCA.\n. > Is MITIE compiled to use it?  What did you do to compile MITIE?\nYes. When cmake .. is executed it shows that it has detected the OpenBLAS. Only after this I make the wordrep binary. . ",
    "cbonadio": "Hello\nI compiled against Intel MKL, but it still uses only on CPU on an Amazon R3.4xlarge 122GB instance \nRunning:\n./wordrep -e /home/txt\nnumber of raw ASCII files found: 730\nnum words: 200000\nsaving word counts to top_word_counts.dat\nnumber of raw ASCII files found: 730\nSample 50000000 random context vectors\nNow do CCA (left size: 41563228, right size: 41563228).\nOn compiling I got:\n-- Searching for BLAS and LAPACK\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void\n-- Check size of void - done\n-- Found Intel MKL BLAS/LAPACK library\n-- Check for STD namespace\n-- Check for STD namespace - found\n-- Looking for C++ include iostream\n-- Looking for C++ include iostream - found\n-- Configuring done\nIs there anything else that need to be set to use all CPUs \n%Cpu0  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu1  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu2  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu3  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu4  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu5  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu6  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu7  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu8  :  0.0 us,  0.3 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu9  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu10 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu11 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu12 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu13 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu14 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n%Cpu15 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nThanks. I downloaded the openblas from their github compiled and installed on /usr/local/openblas\non MITIE\ncd tools/wordrep\nmkdir build\ncd build \ncmake -DCMAKE_LIBRARY_PATH=/usr/local/openblas/lib ..\ncmake --build . --config Release --target install\n./wordrep -e /home/txt\nnumber of raw ASCII files found: 730\nnum words: 200000\nsaving word counts to top_word_counts.dat\nnumber of raw ASCII files found: 730\nSample 50000000 random context vectors\nNow do CCA (left size: 41563228, right size: 41563228).\nBut still uses only one CPU.\nI found this link, it says there is some problem with lapack, but it is old.\nhttps://github.com/xianyi/OpenBLAS/issues/244\n. Just to report the status, it finished after 36 hours on a r4.4xlarge instance using the  Intel MKL BLAS. As you pointed it really used only used 1 CPU.\nThanks very much.. ",
    "shgidi": "Hi @rhazegh , did you find any solution re the progress montioring?. ",
    "leandroneves": "Passed successfully. But at the end of this giving the error below.\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct<char*>(char*, char*, std::forward_iterator_tag) [clone .isra.176]':\nmain.cpp:(.text+0xc9): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::M_create(unsigned long&, unsigned long)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const dlib::wrap_string<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long, unsigned long, unsigned long) [clone .constprop.296]':\nmain.cpp:(.text+0x2a6): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text+0x2bb): refer\u00eancia indefinida para std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::basic_istringstream(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::_Ios_Openmode)'\nmain.cpp:(.text+0x2fc): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nmain.cpp:(.text+0x32d): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace(unsigned long, unsigned long, char const*, unsigned long)'\nmain.cpp:(.text+0x358): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::_M_sync(char, unsigned long, unsigned long)'\nmain.cpp:(.text+0x39f): refer\u00eancia indefinida para std::basic_istream<char, std::char_traits<char> >& std::operator>><char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)'\nmain.cpp:(.text+0x45e): refer\u00eancia indefinida parastd::basic_istream >& std::operator>>, std::allocator >(std::basic_istream >&, std::__cxx11::basic_string, std::allocator >&)'\nmain.cpp:(.text+0x4ee): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nmain.cpp:(.text+0x532): refer\u00eancia indefinida paravtable for std::__cxx11::basic_istringstream, std::allocator >'\nmain.cpp:(.text+0x53e): refer\u00eancia indefinida para vtable for std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >'\nmain.cpp:(.text+0x54a): refer\u00eancia indefinida paravtable for std::__cxx11::basic_stringbuf, std::allocator >'\nmain.cpp:(.text+0x574): refer\u00eancia indefinida para VTT for std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >'\nmain.cpp:(.text+0x57b): refer\u00eancia indefinida paraVTT for std::__cxx11::basic_istringstream, std::allocator >'\nmain.cpp:(.text+0x5ae): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nmain.cpp:(.text+0x645): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nmain.cpp:(.text+0x65d): refer\u00eancia indefinida para std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3otokenize(std::__cxx11::basic_string, std::allocator > const&)':\nmain.cpp:(.text+0x6ea): refer\u00eancia indefinida para std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::basic_istringstream(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::_Ios_Openmode)'\nmain.cpp:(.text+0x8d3): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_mutate(unsigned long, unsigned long, char const, unsigned long)'\nmain.cpp:(.text+0x994): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\nmain.cpp:(.text+0x9bc): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::resize(unsigned long, char)'\nmain.cpp:(.text+0xa1a): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::swap(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)'\nmain.cpp:(.text+0xaa5): refer\u00eancia indefinida paravtable for std::__cxx11::basic_istringstream, std::allocator >'\nmain.cpp:(.text+0xab1): refer\u00eancia indefinida para vtable for std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >'\nmain.cpp:(.text+0xabd): refer\u00eancia indefinida paravtable for std::__cxx11::basic_stringbuf, std::allocator >'\nmain.cpp:(.text+0xae7): refer\u00eancia indefinida para VTT for std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >'\nmain.cpp:(.text+0xaee): refer\u00eancia indefinida paraVTT for std::__cxx11::basic_istringstream, std::allocator >'\nmain.cpp:(.text+0xc7d): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_mutate(unsigned long, unsigned long, char const*, unsigned long)'\nmain.cpp:(.text+0xcce): refer\u00eancia indefinida parastd::__cxx11::basic_istringstream, std::allocator >::~basic_istringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > > std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > >, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > >, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > > >::_M_insert_unique_<std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > >, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > >, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > > >::_Alloc_node>(std::_Rb_tree_const_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > const&, std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > >, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > >, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, dlib::shared_ptr<std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> > > > > >::_Alloc_node&) [clone .isra.288] [clone .constprop.295]':\nmain.cpp:(.text+0xd2b): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::compare(std::__cxx11::basic_string, std::allocator > const&) const'\nmain.cpp:(.text+0xd3d): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nmain.cpp:(.text+0xd79): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::compare(std::__cxx11::basic_string, std::allocator > const&) const'\nmain.cpp:(.text+0xdad): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nmain.cpp:(.text+0xdec): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::compare(std::__cxx11::basic_string, std::allocator > const&) const'\nCMakeFiles/ner_stream.dir/src/main.cpp.o:main.cpp:(.text+0xe81): mais refer\u00eancias indefinidas para seguir std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::cmd_line_parser_kernel_c, std::allocator >, void, dlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 > > >::element()':\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv]+0x84): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv]+0x1df): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv]+0x246): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::cmd_line_parser_kernel_c, std::allocator >, void, dlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 > > >::element() const':\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv]+0x84): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv]+0x1df): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE7elementEv]+0x246): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3ostd::__cxx11::basic_string, std::allocator > std::operator+, std::allocator >(char const, std::__cxx11::basic_string, std::allocator > const&)':\nmain.cpp:(.text.ZStplIcSt11char_traitsIcESaIcEENSt7__cxx1112basic_stringIT_T0_T1_EEPKS5_RKS8[ZStplIcSt11char_traitsIcESaIcEENSt7__cxx1112basic_stringIT_T0_T1_EEPKS5_RKS8]+0x3b): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::reserve(unsigned long)'\nmain.cpp:(.text._ZStplIcSt11char_traitsIcESaIcEENSt7__cxx1112basic_stringIT_T0_T1_EEPKS5_RKS8_[_ZStplIcSt11char_traitsIcESaIcEENSt7__cxx1112basic_stringIT_T0_T1_EEPKS5_RKS8_]+0x5c): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_append(char const, unsigned long)'\nmain.cpp:(.text._ZStplIcSt11char_traitsIcESaIcEENSt7__cxx1112basic_stringIT_T0_T1_EEPKS5_RKS8[ZStplIcSt11char_traitsIcESaIcEENSt7__cxx1112basic_stringIT_T0_T1_EEPKS5_RKS8]+0x6d): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_append(char const*, unsigned long)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3ostd::__cxx11::basic_string, std::allocator > std::operator+, std::allocator >(std::__cxx11::basic_string, std::allocator > const&, char const)':\nmain.cpp:(.text.ZStplIcSt11char_traitsIcESaIcEENSt7__cxx1112basic_stringIT_T0_T1_EERKS8_PKS5[ZStplIcSt11char_traitsIcESaIcEENSt7__cxx1112basic_stringIT_T0_T1_EERKS8_PKS5]+0x48): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_append(char const*, unsigned long)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::deserialize(std::__cxx11::basic_string, std::allocator >&, std::istream&)':\nmain.cpp:(.text._ZN4dlib11deserializeERNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERSi[_ZN4dlib11deserializeERNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERSi]+0x33): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::resize(unsigned long, char)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::matrix, dlib::row_major_layout>::literal_assign_helper::~literal_assign_helper()':\nmain.cpp:(.text._ZN4dlib6matrixIdLl0ELl1ENS_33memory_manager_stateless_kernel_1IcEENS_16row_major_layoutEE21literal_assign_helperD2Ev[_ZN4dlib6matrixIdLl0ELl1ENS_33memory_manager_stateless_kernel_1IcEENS_16row_major_layoutEE21literal_assign_helperD5Ev]+0x42): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZN4dlib6matrixIdLl0ELl1ENS_33memory_manager_stateless_kernel_1IcEENS_16row_major_layoutEE21literal_assign_helperD2Ev[_ZN4dlib6matrixIdLl0ELl1ENS_33memory_manager_stateless_kernel_1IcEENS_16row_major_layoutEE21literal_assign_helperD5Ev]+0x166): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nmain.cpp:(.text._ZN4dlib6matrixIdLl0ELl1ENS_33memory_manager_stateless_kernel_1IcEENS_16row_major_layoutEE21literal_assign_helperD2Ev[_ZN4dlib6matrixIdLl0ELl1ENS_33memory_manager_stateless_kernel_1IcEENS_16row_major_layoutEE21literal_assign_helperD5Ev]+0x1eb): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::cmd_line_parser_kernel_c, std::allocator >, void, dlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 > > >::option(std::__cxx11::basic_string, std::allocator > const&) const':\nmain.cpp:(.text.ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE6optionERKS8[ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE6optionERKS8]+0x5f): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE6optionERKS8_[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE6optionERKS8_]+0x225): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nmain.cpp:(.text.ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE6optionERKS8[ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE6optionERKS8]+0x290): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::cmd_line_parser_kernel_c, std::allocator >, void, dlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 > > >::number_of_arguments() const':\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE19number_of_argumentsEv[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE19number_of_argumentsEv]+0x5b): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE19number_of_argumentsEv[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE19number_of_argumentsEv]+0x1b6): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE19number_of_argumentsEv[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE19number_of_argumentsEv]+0x21a): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3ostd::__cxx11::basic_string, std::allocator > const dlib::wrap_string, std::allocator >(std::__cxx11::basic_string, std::allocator > const&, unsigned long, unsigned long, unsigned long)':\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x3e): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x53): refer\u00eancia indefinida parastd::__cxx11::basic_istringstream, std::allocator >::basic_istringstream(std::__cxx11::basic_string, std::allocator > const&, std::_Ios_Openmode)'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x8c): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0xbd): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_replace(unsigned long, unsigned long, char const, unsigned long)'\nmain.cpp:(.text.ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0xe8): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x159): refer\u00eancia indefinida parastd::basic_istream >& std::operator>>, std::allocator >(std::basic_istream >&, std::__cxx11::basic_string, std::allocator >&)'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x21e): refer\u00eancia indefinida para std::basic_istream<char, std::char_traits<char> >& std::operator>><char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x2ae): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x2f2): refer\u00eancia indefinida para vtable for std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x2fe): refer\u00eancia indefinida paravtable for std::__cxx11::basic_istringstream, std::allocator >'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x30a): refer\u00eancia indefinida para vtable for std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x334): refer\u00eancia indefinida paraVTT for std::__cxx11::basic_istringstream, std::allocator >'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x33b): refer\u00eancia indefinida para VTT for std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x36e): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x439): refer\u00eancia indefinida para std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()'\nmain.cpp:(.text._ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm[_ZN4dlib11wrap_stringIcSt11char_traitsIcESaIcEEEKNSt7__cxx1112basic_stringIT_T0_T1_EERSA_mmm]+0x443): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o dlib::cmd_line_parser_kernel_1<char, dlib::map_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::binary_search_tree_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::memory_manager_stateless_kernel_1<char>, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, dlib::memory_manager_stateless_kernel_1<char> > >::cmd_line_parse_error::set_info_string()':\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv]+0x2f): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv]+0x74): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv]+0x9c): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv]+0xdd): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE20cmd_line_parse_error15set_info_stringEv]+0x36b): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o dlib::cmd_line_parser_kernel_1<char, dlib::map_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::binary_search_tree_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::memory_manager_stateless_kernel_1<char>, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, dlib::memory_manager_stateless_kernel_1<char> > >::option_t::argument(unsigned long, unsigned long) const':\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE8option_t8argumentEmm[_ZNK4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE8option_t8argumentEmm]+0x59): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE8option_t8argumentEmm[_ZNK4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE8option_t8argumentEmm]+0x2ab): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE8option_t8argumentEmm[_ZNK4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE8option_t8argumentEmm]+0x3ad): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o dlib::cmd_line_parser_kernel_c<dlib::cmd_line_parser_kernel_1<char, dlib::map_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::binary_search_tree_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::memory_manager_stateless_kernel_1<char>, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, dlib::memory_manager_stateless_kernel_1<char> > > >::operator[](unsigned long) const':\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEEixEm[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEEixEm]+0x3e): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEEixEm[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEEixEm]+0x20d): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nmain.cpp:(.text._ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEEixEm[_ZNK4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEEixEm]+0x2dd): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, dlib::memory_manager_stateless_kernel_1<char> >::remove_any(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)':\nmain.cpp:(.text._ZN4dlib17sequence_kernel_2INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEENS_33memory_manager_stateless_kernel_1IcEEE10remove_anyERS6_[_ZN4dlib17sequence_kernel_2INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEENS_33memory_manager_stateless_kernel_1IcEEE10remove_anyERS6_]+0x28): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::swap(std::__cxx11::basic_string, std::allocator >&)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o dlib::cmd_line_parser_kernel_1<char, dlib::map_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::binary_search_tree_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::memory_manager_stateless_kernel_1<char>, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, dlib::memory_manager_stateless_kernel_1<char> > >::parse(int, char const**)':\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x2fa): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::resize(unsigned long, char)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x499): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace(unsigned long, unsigned long, char const*, unsigned long)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x541): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x5d8): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace(unsigned long, unsigned long, char const*, unsigned long)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x5ea): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x643): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::swap(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x7a9): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::find(char, unsigned long) const'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x811): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0x86c): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0xa06): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace(unsigned long, unsigned long, char const*, unsigned long)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0xd35): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0xe70): refer\u00eancia indefinida para std::__throw_out_of_range_fmt(char const*, ...)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc[_ZN4dlib24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS7_S8_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS7_EEESB_EENS_17sequence_kernel_2IS7_SB_EENSG_IPS7_SB_EEE5parseEiPPKc]+0xf41): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o dlib::cmd_line_parser_check_1<dlib::cmd_line_parser_print_1<dlib::cmd_line_parser_kernel_c<dlib::cmd_line_parser_kernel_1<char, dlib::map_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::binary_search_tree_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::memory_manager_stateless_kernel_1<char>, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, dlib::memory_manager_stateless_kernel_1<char> > > > > >::cmd_line_check_error::set_info_string()':\nmain.cpp:(.text._ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv[_ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv]+0x2f): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv[_ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv]+0x104): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nmain.cpp:(.text._ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv[_ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv]+0x12c): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv[_ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv]+0x16d): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nmain.cpp:(.text._ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv[_ZN4dlib23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISA_SB_NS_33memory_manager_stateless_kernel_1IcEESt4lessISA_EEESE_EENS_17sequence_kernel_2ISA_SE_EENSJ_IPSA_SE_EEEEEEEEE20cmd_line_check_error15set_info_stringEv]+0x645): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o void dlib::cmd_line_parser_check_c<dlib::cmd_line_parser_check_1<dlib::cmd_line_parser_print_1<dlib::cmd_line_parser_kernel_c<dlib::cmd_line_parser_kernel_1<char, dlib::map_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::binary_search_tree_kernel_1<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void*, dlib::memory_manager_stateless_kernel_1<char>, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, dlib::memory_manager_stateless_kernel_1<char> >, dlib::sequence_kernel_2<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, dlib::memory_manager_stateless_kernel_1<char> > > > > > >::check_one_time_options<2ul>(char const* (&) [2ul]) const':\nmain.cpp:(.text._ZNK4dlib23cmd_line_parser_check_cINS_23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISB_SC_NS_33memory_manager_stateless_kernel_1IcEESt4lessISB_EEESF_EENS_17sequence_kernel_2ISB_SF_EENSK_IPSB_SF_EEEEEEEEEEE22check_one_time_optionsILm2EEEvRAT__PKc[_ZNK4dlib23cmd_line_parser_check_cINS_23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISB_SC_NS_33memory_manager_stateless_kernel_1IcEESt4lessISB_EEESF_EENS_17sequence_kernel_2ISB_SF_EENSK_IPSB_SF_EEEEEEEEEEE22check_one_time_optionsILm2EEEvRAT__PKc]+0x47): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZNK4dlib23cmd_line_parser_check_cINS_23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISB_SC_NS_33memory_manager_stateless_kernel_1IcEESt4lessISB_EEESF_EENS_17sequence_kernel_2ISB_SF_EENSK_IPSB_SF_EEEEEEEEEEE22check_one_time_optionsILm2EEEvRAT__PKc[_ZNK4dlib23cmd_line_parser_check_cINS_23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISB_SC_NS_33memory_manager_stateless_kernel_1IcEESt4lessISB_EEESF_EENS_17sequence_kernel_2ISB_SF_EENSK_IPSB_SF_EEEEEEEEEEE22check_one_time_optionsILm2EEEvRAT__PKc]+0x276): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nmain.cpp:(.text._ZNK4dlib23cmd_line_parser_check_cINS_23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISB_SC_NS_33memory_manager_stateless_kernel_1IcEESt4lessISB_EEESF_EENS_17sequence_kernel_2ISB_SF_EENSK_IPSB_SF_EEEEEEEEEEE22check_one_time_optionsILm2EEEvRAT__PKc[_ZNK4dlib23cmd_line_parser_check_cINS_23cmd_line_parser_check_1INS_23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1ISB_SC_NS_33memory_manager_stateless_kernel_1IcEESt4lessISB_EEESF_EENS_17sequence_kernel_2ISB_SF_EENSK_IPSB_SF_EEEEEEEEEEE22check_one_time_optionsILm2EEEvRAT__PKc]+0x361): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_insert_aux(__gnu_cxx::__normal_iterator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)':\nmain.cpp:(.text._ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE13_M_insert_auxEN9__gnu_cxx17__normal_iteratorIPS5_S7_EERKS5_[_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE13_M_insert_auxEN9__gnu_cxx17__normal_iteratorIPS5_S7_EERKS5_]+0xac): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE13_M_insert_auxEN9__gnu_cxx17__normal_iteratorIPS5_S7_EERKS5[ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE13_M_insert_auxEN9__gnu_cxx17__normal_iteratorIPS5_S7_EERKS5]+0xbe): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3ostd::vector, std::allocator >, std::allocator, std::allocator > > >::M_fill_insert(__gnu_cxx::__normal_iterator, std::allocator >, std::vector, std::allocator >, std::allocator, std::allocator > > > >, unsigned long, std::__cxx11::basic_string, std::allocator > const&)':\nmain.cpp:(.text.ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE14_M_fill_insertEN9__gnu_cxx17__normal_iteratorIPS5_S7_EEmRKS5[ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE14_M_fill_insertEN9__gnu_cxx17__normal_iteratorIPS5_S7_EEmRKS5]+0x1ff): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\nmain.cpp:(.text._ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE14_M_fill_insertEN9__gnu_cxx17__normal_iteratorIPS5_S7_EEmRKS5_[_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE14_M_fill_insertEN9__gnu_cxx17__normal_iteratorIPS5_S7_EEmRKS5_]+0x219): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE14_M_fill_insertEN9__gnu_cxx17__normal_iteratorIPS5_S7_EEmRKS5[ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS5_EE14_M_fill_insertEN9__gnu_cxx17__normal_iteratorIPS5_S7_EEmRKS5]+0x2a9): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3ostd::Rb_tree, std::allocator >, std::pair, std::allocator > const, dlib::matrix, dlib::row_major_layout> >, std::_Select1st, std::allocator > const, dlib::matrix, dlib::row_major_layout> > >, std::less, std::allocator > >, std::allocator, std::allocator > const, dlib::matrix, dlib::row_major_layout> > > >::_M_get_insert_unique_pos(std::__cxx11::basic_string, std::allocator > const&)':\nmain.cpp:(.text._ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE24_M_get_insert_unique_posERS7[ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE24_M_get_insert_unique_posERS7]+0x98): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3ostd::Rb_tree, std::allocator >, std::pair, std::allocator > const, dlib::matrix, dlib::row_major_layout> >, std::_Select1st, std::allocator > const, dlib::matrix, dlib::row_major_layout> > >, std::less, std::allocator > >, std::allocator, std::allocator > const, dlib::matrix, dlib::row_major_layout> > > >::_M_get_insert_hint_unique_pos(std::_Rb_tree_const_iterator, std::allocator > const, dlib::matrix, dlib::row_major_layout> > >, std::__cxx11::basic_string, std::allocator > const&)':\nmain.cpp:(.text._ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7[ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7]+0x2d): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nmain.cpp:(.text._ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7_[_ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7_]+0x3f): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::compare(std::__cxx11::basic_string, std::allocator > const&) const'\nmain.cpp:(.text.ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7[ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7]+0x7f): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nmain.cpp:(.text._ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7_[_ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7_]+0xc3): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::compare(std::__cxx11::basic_string, std::allocator > const&) const'\nCMakeFiles/ner_stream.dir/src/main.cpp.o:main.cpp:(.text.ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7[ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib6matrixIfLl0ELl1ENS8_33memory_manager_stateless_kernel_1IcEENS8_16row_major_layoutEEEESt10_Select1stISE_ESt4lessIS5_ESaISE_EE29_M_get_insert_hint_unique_posESt23_Rb_tree_const_iteratorISE_ERS7]+0x111): mais refer\u00eancias indefinidas para seguir std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >::add_to_tree(dlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >::node&, std::__cxx11::basic_string, std::allocator >&, void&)':\nmain.cpp:(.text.ZN4dlib27binary_search_tree_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_33memory_manager_stateless_kernel_1IcEESt4lessIS6_EE11add_to_treeERPNSC_4nodeERS6_RS7[ZN4dlib27binary_search_tree_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_33memory_manager_stateless_kernel_1IcEESt4lessIS6_EE11add_to_treeERPNSC_4nodeERS6_RS7]+0x100): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::swap(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::cmd_line_parser_kernel_c, std::allocator >, void, dlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 > > >::add_option(std::__cxx11::basic_string, std::allocator > const&, std::__cxx11::basic_string, std::allocator > const&, unsigned long)':\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m]+0x4a): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m]+0x2e0): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m]+0x348): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find_first_of(char const*, unsigned long, unsigned long) const'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m]+0x3f0): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m]+0x400): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m]+0x40c): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_assign(std::__cxx11::basic_string, std::allocator > const&)'\nmain.cpp:(.text._ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m[_ZN4dlib24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS8_S9_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS8_EEESC_EENS_17sequence_kernel_2IS8_SC_EENSH_IPS8_SC_EEEEE10add_optionERKS8_SO_m]+0x4e5): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3ostd::_Rb_tree, std::allocator >, std::pair, std::allocator > const, dlib::shared_ptr, std::allocator > > >, std::_Select1st, std::allocator > const, dlib::shared_ptr, std::allocator > > > >, std::less, std::allocator > >, std::allocator, std::allocator > const, dlib::shared_ptr, std::allocator > > > > >::_M_get_insert_unique_pos(std::__cxx11::basic_string, std::allocator > const&)':\nmain.cpp:(.text._ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib10shared_ptrINS0_19basic_ostringstreamIcS3_S4_EEEEESt10_Select1stISD_ESt4lessIS5_ESaISD_EE24_M_get_insert_unique_posERS7[ZNSt8_Rb_treeINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_N4dlib10shared_ptrINS0_19basic_ostringstreamIcS3_S4_EEEEESt10_Select1stISD_ESt4lessIS5_ESaISD_EE24_M_get_insert_unique_posERS7]+0x98): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3ostd::map, std::allocator >, dlib::shared_ptr, std::allocator > >, std::less, std::allocator > >, std::allocator, std::allocator > const, dlib::shared_ptr, std::allocator > > > > >::operator':\nmain.cpp:(.text.ZNSt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEN4dlib10shared_ptrINS0_19basic_ostringstreamIcS3_S4_EEEESt4lessIS5_ESaISt4pairIKS5_SA_EEEixERSE[ZNSt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEN4dlib10shared_ptrINS0_19basic_ostringstreamIcS3_S4_EEEESt4lessIS5_ESaISt4pairIKS5_SA_EEEixERSE]+0xbf): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::cmd_line_parser_print_1, std::allocator >, void, dlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 >, dlib::sequence_kernel_2, std::allocator >, dlib::memory_manager_stateless_kernel_1 > > > >::print_options(std::ostream&) const':\nmain.cpp:(.text._ZNK4dlib23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS9_SA_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS9_EEESD_EENS_17sequence_kernel_2IS9_SD_EENSI_IPS9_SD_EEEEEEE13print_optionsERSo[_ZNK4dlib23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS9_SA_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS9_EEESD_EENS_17sequence_kernel_2IS9_SD_EENSI_IPS9_SD_EEEEEEE13print_optionsERSo]+0x712): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\nmain.cpp:(.text._ZNK4dlib23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS9_SA_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS9_EEESD_EENS_17sequence_kernel_2IS9_SD_EENSI_IPS9_SD_EEEEEEE13print_optionsERSo[_ZNK4dlib23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS9_SA_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS9_EEESD_EENS_17sequence_kernel_2IS9_SD_EENSI_IPS9_SD_EEEEEEE13print_optionsERSo]+0x73b): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::compare(std::__cxx11::basic_string, std::allocator > const&) const'\nmain.cpp:(.text._ZNK4dlib23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS9_SA_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS9_EEESD_EENS_17sequence_kernel_2IS9_SD_EENSI_IPS9_SD_EEEEEEE13print_optionsERSo[_ZNK4dlib23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS9_SA_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS9_EEESD_EENS_17sequence_kernel_2IS9_SD_EENSI_IPS9_SD_EEEEEEE13print_optionsERSo]+0x7d1): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nmain.cpp:(.text._ZNK4dlib23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS9_SA_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS9_EEESD_EENS_17sequence_kernel_2IS9_SD_EENSI_IPS9_SD_EEEEEEE13print_optionsERSo[_ZNK4dlib23cmd_line_parser_print_1INS_24cmd_line_parser_kernel_cINS_24cmd_line_parser_kernel_1IcNS_12map_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_27binary_search_tree_kernel_1IS9_SA_NS_33memory_manager_stateless_kernel_1IcEESt4lessIS9_EEESD_EENS_17sequence_kernel_2IS9_SD_EENSI_IPS9_SD_EEEEEEE13print_optionsERSo]+0x9b3): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3o main':\nmain.cpp:(.text.startup+0x62f): refer\u00eancia indefinida parastd::basic_istream >& std::getline, std::allocator >(std::basic_istream >&, std::__cxx11::basic_string, std::allocator >&, char)'\nmain.cpp:(.text.startup+0x82a): refer\u00eancia indefinida para std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)'\nCMakeFiles/ner_stream.dir/src/main.cpp.o: na fun\u00e7\u00e3odlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >::remove_least_element_in_tree(dlib::binary_search_tree_kernel_1, std::allocator >, void, dlib::memory_manager_stateless_kernel_1, std::less, std::allocator > > >::node&, std::__cxx11::basic_string, std::allocator >&, void&)':\nmain.cpp:(.text.ZN4dlib27binary_search_tree_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_33memory_manager_stateless_kernel_1IcEESt4lessIS6_EE28remove_least_element_in_treeERPNSC_4nodeERS6_RS7[ZN4dlib27binary_search_tree_kernel_1INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPvNS_33memory_manager_stateless_kernel_1IcEESt4lessIS6_EE28remove_least_element_in_treeERPNSC_4nodeERS6_RS7]+0x55): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::swap(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)'\nmitie_build/libmitie.a(named_entity_extractor.cpp.o): na fun\u00e7\u00e3ovoid std::__cxx11::basic_string, std::allocator >::_M_construct(char, char, std::forward_iterator_tag) [clone .isra.229]':\nnamed_entity_extractor.cpp:(.text+0x89): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_create(unsigned long&, unsigned long)'\nmitie_build/libmitie.a(named_entity_extractor.cpp.o): na fun\u00e7\u00e3omitie::named_entity_extractor::named_entity_extractor(std::vector, std::allocator >, std::allocator, std::allocator > > > const&, mitie::total_word_feature_extractor const&, dlib::sequence_segmenter const&, dlib::multiclass_linear_decision_function, std::allocator > > >, unsigned long> const&)':\nnamed_entity_extractor.cpp:(.text+0x178f): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nnamed_entity_extractor.cpp:(.text+0x18bc): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nnamed_entity_extractor.cpp:(.text+0x1a38): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nnamed_entity_extractor.cpp:(.text+0x1b65): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nnamed_entity_extractor.cpp:(.text+0x1bca): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nnamed_entity_extractor.cpp:(.text+0x1c19): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nnamed_entity_extractor.cpp:(.text+0x1d43): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nnamed_entity_extractor.cpp:(.text+0x1da2): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nnamed_entity_extractor.cpp:(.text+0x1dda): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nmitie_build/libmitie.a(named_entity_extractor.cpp.o): na fun\u00e7\u00e3omitie::named_entity_extractor::named_entity_extractor(std::__cxx11::basic_string, std::allocator > const&)':\nnamed_entity_extractor.cpp:(.text+0x25e1): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(char const*) const'\nnamed_entity_extractor.cpp:(.text+0x26ab): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::compare(char const) const'\nnamed_entity_extractor.cpp:(.text+0x27e6): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_append(char const*, unsigned long)'\nmitie_build/libmitie.a(named_entity_extractor.cpp.o): na fun\u00e7\u00e3omitie::named_entity_extractor::named_entity_extractor(std::__cxx11::basic_string, std::allocator > const&, std::__cxx11::basic_string, std::allocator > const&)':\nnamed_entity_extractor.cpp:(.text+0x31f9): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(char const*) const'\nnamed_entity_extractor.cpp:(.text+0x326d): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::compare(char const) const'\nnamed_entity_extractor.cpp:(.text+0x347b): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(char const*) const'\nnamed_entity_extractor.cpp:(.text+0x35b4): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::_M_append(char const, unsigned long)'\nmitie_build/libmitie.a(named_entity_extractor.cpp.o): na fun\u00e7\u00e3o std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const dlib::cast_to_string<int>(int const&)':\nnamed_entity_extractor.cpp:(.text._ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_[_ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_]+0x30): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::Ios_Openmode)'\nnamed_entity_extractor.cpp:(.text._ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT[ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT]+0x57): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nnamed_entity_extractor.cpp:(.text._ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_[_ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_]+0x5e): refer\u00eancia indefinida paravtable for std::__cxx11::basic_ostringstream, std::allocator >'\nnamed_entity_extractor.cpp:(.text.ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT[ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT]+0x77): refer\u00eancia indefinida para vtable for std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >'\nnamed_entity_extractor.cpp:(.text._ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_[_ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_]+0xb3): refer\u00eancia indefinida paraVTT for std::__cxx11::basic_ostringstream, std::allocator >'\nnamed_entity_extractor.cpp:(.text.ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT[ZN4dlib14cast_to_stringIiEEKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT]+0x159): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nmitie_build/libmitie.a(ner_feature_extraction.cpp.o): na fun\u00e7\u00e3omitie::sentence_to_feats(mitie::total_word_feature_extractor const&, std::vector, std::allocator >, std::allocator, std::allocator > > > const&)':\nner_feature_extraction.cpp:(.text+0x68d): refer\u00eancia indefinida para std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_create(unsigned long&, unsigned long)'\nmitie_build/libmitie.a(ner_feature_extraction.cpp.o): na fun\u00e7\u00e3omitie::extract_ner_chunk_features(std::vector, std::allocator >, std::allocator, std::allocator > > > const&, std::vector, dlib::row_major_layout>, std::allocator, dlib::row_major_layout> > > const&, std::pair const&)':\nner_feature_extraction.cpp:(.text+0x86e6): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)'\nner_feature_extraction.cpp:(.text+0x8812): refer\u00eancia indefinida parastd::__cxx11::basic_stringbuf, std::allocator >::str() const'\nner_feature_extraction.cpp:(.text+0x8877): refer\u00eancia indefinida para std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()'\nner_feature_extraction.cpp:(.text+0x890a): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::basic_ostringstream(std::_Ios_Openmode)'\nner_feature_extraction.cpp:(.text+0x8a36): refer\u00eancia indefinida para std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const'\nner_feature_extraction.cpp:(.text+0x8a9b): refer\u00eancia indefinida parastd::__cxx11::basic_ostringstream, std::allocator >::~basic_ostringstream()'\nmitie_build/libmitie.a(stemmer.cpp.o): na fun\u00e7\u00e3o mitie::stem_word(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)':\nstemmer.cpp:(.text+0x46): refer\u00eancia indefinida parastd::__cxx11::basic_string, std::allocator >::resize(unsigned long, char)'\nstemmer.cpp:(.text+0x183): refer\u00eancia indefinida para `std::__cxx11::basic_string, std::allocator >::_M_create(unsigned long&, unsigned long)'\ncollect2: error: ld returned 1 exit status\nCMakeFiles/ner_stream.dir/build.make:102: recipe for target 'ner_stream' failed\nmake[2]:  [ner_stream] Error 1\nCMakeFiles/Makefile2:68: recipe for target 'CMakeFiles/ner_stream.dir/all' failed\nmake[1]:  [CMakeFiles/ner_stream.dir/all] Error 2\nMakefile:127: recipe for target 'all' failed\nmake: *** [all] Error 2\nThanks a lot. ",
    "A-tanveer": "no i haven't modified anything. every example gives this error.. It worked! Thank you very much!. ",
    "expatiating": "@davisking, I am not following your comment and I recommend this issue be reopened. I too have been unable to install and use on Windows 10, is there a specific section of the README to follow? I tried following the directions under Using MITIE from a Python 2.7 Program\nI get the same error as above when I run pip install git+https://github.com/mit-nlp/MITIE.git and when I run pip install git+https://github.com/mit-nlp/MITIE.git#egg=mitie (this is the recommended resolution in the Error message when the model fails to load) \nI am attempting to use MITIE from Python on Windows 10. After the above error occurred, I cloned this repo and attempted to install via pip locally as follows:\n```\n\ngit clone https://github.com/mit-nlp/MITIE.git\npip install -e path\\to\\mitie\nThen it appears installed correctly when I use the following:\npip list\nmitie (0.2.0, c:\\path\\to\\mitie)\n```\nBut then I still cannot get it run from another python program, I am attempting to use with Rasa NLU\n\nI have it working on a Mac following similar steps, however I have a requirement to support Win10. \nIf you have any thoughts or recommendations - those are definitely welcome.\nI'm no expert at python so there may be something simple I missing :)\n. ",
    "mvsrao": "Thank you for your help. I tried to run cmake with Visual studio C++ build tools with following commands \ncmake -G \"Visual Studio 15\" -T v140 ..\ncmake --build . --config Release --target install\nThe first one ran with 2 build failures and second one ran with 185 warnings and 0 errors. Please find the log file for errors from 1st command.  It generated the single dll: mitie.dll . But when I try to run example programs with that DLL, it gave an error : WindowsError: [Error 193] %1 is not a valid Win32 application\nI have noticed the Precompiled shared libraries for python under https://github.com/mit-nlp/MITIE/releases/download/v0.4/mitie-v0.2-python-2.7-windows-or-linux64.zip\nBut it seems to be bit old compared to the source. Could it be possible to upload the latest precompiled shared library for Python \nCMakeError.txt\nThanks again for your help\nRegards\nRao\n. I have got following error@ cmake ..\n-- Building for: Visual Studio 10 2010\n-- The C compiler identification is unknown\n-- The CXX compiler identification is unknown\nCMake Error in CMakeLists.txt:\n  No CMAKE_C_COMPILER could be found.\nCMake Error in CMakeLists.txt:\n  No CMAKE_CXX_COMPILER could be found.\n-- Configuring incomplete, errors occurred!\nSee also \"C:/DEVELOPMENT/SOFTWARES/MITIE-master/mitielib/build/CMakeFiles/CMakeOutput.log\".\nSee also \"C:/DEVELOPMENT/SOFTWARES/MITIE-master/mitielib/build/CMakeFiles/CMakeError.log\".\nNote: I don't have Visual Studio 10 2010 and I couldn't find it on the microsoft so I installed Microsoft VC++ 2015 build tools and tried to execute earlier with cmake passing the MS Studio version 2015 \nThanks\nRao\n. ",
    "kenyeung128": "hi @davisking  thanks, would you be able to guide me which example to do that? i was looking for python one but not  sure which one. Thanks. ",
    "KoolCards": "I get the access violation error as well while trying to use rasa nlu.. ",
    "tmbo": "@davisking I would be happy to help in fixing this issue, but to be honest I am not quite sure how we could provoke an access violation by using the python mitie library. Any insights you have why the access violation might be thrown would be very helpful. \nAnd to be fair, there isn't something special or hacky we do when training models using mitie - thats why I'd really appreciate any input here from your side.. Thanks :+1:. ",
    "kesak": "Hi Davis ,\nI have no experience in C++ . I just want to try MITIE libraries for NLU . but the setup is difficult as I am not sure about the softwares required to build it. kindly let me know if I have to install any additional softwares to make it work. I don't face this difficulties in linux machine. kindly help.\n1) pip install is not working.\n2) As you suggested in\n    https://github.com/mit-nlp/MITIE/issues/87\n3) I have installed MinGW and Cmake and build the MITIE using cmake GUI and cmake -G \"MinGW Makefiles\" .\nC:\\mitie\\MITIE-master\\mitielib\\build>cmake ..\n-- Configuring done\n-- Generating done\n-- Build files have been written to: C:/mitie/MITIE-master/mitielib\nC:\\mitie\\MITIE-master\\mitielib\\build>cmake --build . --config Release --target install\nThe system cannot find the file specified\nCMake Error: Generator: execution of make failed. Make command was: \"nmake\" \"/NOLOGO\" \"install\"\n. ",
    "willemchua": "Here's what happened when I ran the cmake ..\n-- Building for: Visual Studio 14 2015\n-- The C compiler identification is MSVC 19.0.23506.0\n-- The CXX compiler identification is MSVC 19.0.23506.0\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/cl.exe\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/cl.exe -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/cl.exe\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/cl.exe -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void*\n-- Check size of void* - done\n-- Searching for BLAS and LAPACK\n-- Check for STD namespace\n-- Check for STD namespace - found\n-- Looking for C++ include iostream\n-- Looking for C++ include iostream - found\n-- Configuring done\n-- Generating done\n-- Build files have been written to: C:/Users/ASUS/Desktop/Chatbot/MITIE-master/mitielib/build\nand when I ran the cmake --build . --config Release --target install, it went to a long installation and finished off with\n```\nassign_helper': function assumed not to throw an exception but does [C:\\Users\\ASUS\\Desktop\\Cha\ntbot\\MITIE-master\\mitielib\\build\\mitie.vcxproj]\n  c:\\users\\asus\\desktop\\chatbot\\mitie-master\\dlib\\dlib\\matrix/matrix.h(1598): warning C4297: 'dlib::matrix::literal_assign_helper::~literal_assign_helper': function assumed not to throw an exception but does [C:\\Users\\ASUS\\Desktop\\Chatbot\\\nMITIE-master\\mitielib\\build\\mitie.vcxproj]\n157 Warning(s)\n0 Error(s)\n\nTime Elapsed 00:02:07.46\n```\nAnd when I tried to run the ner.py, the first error still happened. Thanks, the last command seemed to do the trick.\n:D. ",
    "danwilhelm": "Because you're using 64-bit Python, ensure you're compiling 64-bit DLLs:\ncmake -G \"Visual Studio 14 2015 Win64\" ... ",
    "kiran-surya": "Hi Davis, Thanks for the quick reply. I got the issue. I was not using the latest version of code. In the latest version this issue is fixed.. ",
    "anujgupta82": "So whats is the best way to understand its internals ?. @davisking : We are not training on just one sentence but as @nsanthanam said \"whole of CoNLL dataset.\"\nHow does MITIE's word feature extractor model handle a unknown word ?\ni.e. in the Training set it has seen Chicago but not Chicaga. So, Chicaga is a word it has never seen. In such a case how is it handled ?   . ",
    "s9amaska": "It works for me on windows pretty well.. @davisking Thank you very much for answering.\nI have tried both ways. The model finds the important information correctly but it also detects other parts of text as entities mistakenly. Does it make sense to have some training sentences without any entity in them, to have negative instances?. ",
    "mcelvg": "Sure, I'll submit a PR. Thanks.. ",
    "satishkumar": "Thanks for the reply. I had triggered the training and it continues to run for more than 16 hours. \nDo you have some ideas on the other part of my question - i.e. whether the MITIE training is robust for CRF type labelling?. Can MITIE learn semantic relationships between nearby words and use it to identify synonyms(unseen words but that belong to the same entity group as previously learned) in new sentences?. Ok. Thanks.. ",
    "oximer": "I also having the same doubt! This training part is really clear to me.\nWhat are the inputs for wordrep?\nHow to generate a pure ner for my language?. I see.\nSo let me explain my scenario, so maybe you could help me here.\nI downloaded wiki dump and used it on Wordrep to obtain an total_word_feature_extractor.\nAfter it, I trained the ner_model.dat using this repo java example.\nAt this, point seems to me that I have a trained and ready MITIE.\nHowever, I'm troubled by the fact that training MITIE seems really simple.\nAs an example, Spacy seems much more complicated. I have to deal with Stop words, Tag maps, Tokenizer exceptions...\nWhy MITIE doesn't requires it? I'm missing anything?\nWhy so huge difference?. I imagine that it might have some performance cost.\nI'm wrong about?. ",
    "zakmandhro": "Hi Davis, 3 label categories (e.g. \"Movie\", \"TV show\", \"music video\"), 30 million distinct entities (e.g. \"Star Wars\", \"Game of Thrones\", \"Hello - Adele\". \n. ",
    "ghost": "ya, i meant that only. So, we have to call these function with the same kind of inputs for each sentence. Right?\nCant we use something like one single training file annotated with entities as an input for custom NER model. And one more query i have, is there any way to combine two classification models, like the pretrained ner model with custom NER model?. ",
    "AdamMiltonBarker": "Sorry just saw the message at the bottom when I posted, new dev machine not installed GIT :). Working now.. Thanks for the reply, I noticed I had not added the right entity name for the login page, changing this made it work correctly. Any idea on speeding up the process, it is very slow to detect an entity.. The way that it does not return the actual entity name is also an issue, is this able to be resolved ? \nWith the labelled entity Artificial Intelligence E-Commerce Store:\n\n\nI am interested in the artificial intelligence e-commerce store\n\n\n{'Received': 'I am interested in the artificial intelligence e-commerce store', 'Confidence': 0.99691617, 'Intent': u'InterestedIn', 'Responses': [u'No problem, I will take you to the Artificial Intelligence E-Commerce page', u'One moment, I will take you to the Artificial Intelligence E-Commerce page'], 'Entities': [{'Score': '0.231', 'Entity': u'artificial intelligence e-commerce store'}], 'Action': u'GoToProduct', 'ContextIn': 'NA', 'ContextCurrent': u'', 'Response': u'No problem, I will take you to the Artificial Intelligence E-Commerce page', 'ContextOut': u''}\n\n\nI am interested in the artificial intelligence e-commerce\n\n\n```\n{'Received': 'I am interested in the artificial intelligence e-commerce', 'Confidence': 0.99021143, 'Intent': u'InterestedIn', 'Responses': [u'No problem, I will take you to the Artificial Intelligence E-Commerce page', u'One moment, I will take you to the Artificial Intelligence E-Commerce page'], 'Entities': [{'Score': '0.161', 'Entity': u'artificial intelligence e-commerce'}], 'Action': u'GoToProduct', 'ContextIn': 'NA', 'ContextCurrent': u'', 'Response': u'No problem, I will take you to the Artificial Intelligence E-Commerce page', 'ContextOut': u''}\n```\nIt does not return the correct entity name, the last example above returns \"artificial intelligence e-commerce\", it should return  \"Artificial Intelligence E-Commerce Store\" case sensitive and correct entity name, this is a game breaker in my program, hoping there is a way around it.\nUPDATE\nI notice it does not actually return the entity name which I find quite strange, the entity name is generated using the tokens and range, is there a way to return the actual trained entity name ?\n. I think if I edit this:\nhttps://github.com/mit-nlp/MITIE/blob/c8da90493ea258503d004bbb24bf0b2b09df02bc/mitielib/mitie.py#L287\nI can make it return the actual entity name it was trained, I cannot locate this file on my system though, any ideas where it may be ? \n. This is a question related to MItie not Python, FYI I was a teaching assistant for MIT's online Computer Science course with Python, so I do not believe I need a course on Python. The questions remaining are:\nIs there a way to speed up the process of MITIE\nWhy does Mitie not return the actual named entity. Mitie does not return the actual named entity. . @davisking The model loading takes less than a second, it is the actual detection that takes the time, you can see this quite easily just using your training example. In my program each user has their own model so yes each time they access the program it will load their own model, this is an API application for a bot with multiple users and multiple models. The training code above is your own training code and in another file all I have added is your ner.py example with exception to the tokenizer which is NLTK.\nIn my program directly after the entity extraction it loads my custom intent classifier and classifies the intent within seconds on a very large model, adding in Mitie has reduced a second response time to above 10. \nYou are correct with your last answer that is exactly the thing I am asking about, why does it not return the actual named entity it was trained with, in the examples, you just use the tokens and the range and that is provided in the print, not actually returned from Mitie, which is my whole reason of asking the question, I need to access the ACTUAL named entity that was trained to it, not a variation of that. There is not a way that I can think of to match the actual entity when this is running in another program from the training, I only hardcoded the string for example, it is not a hard coded string in the application.\nIE:\n\"Artificial\", \"Intelligence\", \"E-Commerce\", \"Store\" is the actual named entity trained, yet, \"artificial\", \"intelligence\",\"e-commerce\" is recognized, that is great, if it returns the actual named entity of Artificial Intelligence E-Commerce Store, which it is not doing. . @davisking  Ok thanks for replying. Maybe if I give you what I am trying to achieve and you could point me in the direction or say it is not possible, I believe I have a way to fix to work how I need it but I cannot locate mitielib anywhere on my Linux box.\nI am writing my own solution to API.ai, I have everything complete with exception to a few things, one being entity extraction. \nIn API.ai,  you have Entities, IE Products is an entity then you have references and synonyms related to those references, when you query API.ai, it returns the entity type Product, and reference, Artificial Intelligence E-Commerce Store, if it matched that entity with Artificial Intelligence E-Commerce, it would still return the trained reference of Artificial Intelligence E-Commerce Store, not Artificial Intelligence E-Commerce, this is what I need to achieve. . @davisking I have solved this by mapping synonyms to entities, I still feel this is overkill, I will play around with the source when I get some time so it can include synonyms and correct values. . I wouldnt of needed to if the questions regarding Mitie had been answered instead of fobbed off.. Printing out files in mitie.py gives:\nD:\\Installations\\Mitie\\MITIE-master\\MITIE-master\\mitielib/mitie.dll\nWhich is correct and a valid path.. I think the solution here solves it, checking now.\nhttps://github.com/mit-nlp/MITIE/issues/150\n. Sorted that was it. . I re downloaded MITIE-models and replaced the ones I had and all works now. ",
    "ankitarath2011": "I am getting this much output only. \nThe system cannot find the file specified\nCMake Error: Generator: execution of make failed. Make command was: \"nmake\" \"/NOLOGO\" \"install\"\nI have VC++ 10 installed.\n. Actuallu for \"cmake .. \" command also I am getting some error I think. Please find below the output of cmake ..\n```\nC:\\Users\\ankita.a.rath\\Downloads\\MITIE-master\\mitielib\\build>cmake ..\n-- The C compiler identification is unknown\n-- The CXX compiler identification is unknown\nCMake Error in CMakeLists.txt:\n  The CMAKE_C_COMPILER:\ncl\n\nis not a full path and was not found in the PATH.\nTo use the NMake generator with Visual C++, cmake must be run from a shell\n  that can use the compiler cl from the command line.  This environment is\n  unable to invoke the cl compiler.  To fix this problem, run cmake from the\n  Visual Studio Command Prompt (vcvarsall.bat).\nTell CMake where to find the compiler by setting either the environment\n  variable \"CC\" or the CMake cache entry CMAKE_C_COMPILER to the full path to\n  the compiler, or to the compiler name if it is in the PATH.\nCMake Error in CMakeLists.txt:\n  The CMAKE_CXX_COMPILER:\ncl\n\nis not a full path and was not found in the PATH.\nTo use the NMake generator with Visual C++, cmake must be run from a shell\n  that can use the compiler cl from the command line.  This environment is\n  unable to invoke the cl compiler.  To fix this problem, run cmake from the\n  Visual Studio Command Prompt (vcvarsall.bat).\nTell CMake where to find the compiler by setting either the environment\n  variable \"CXX\" or the CMake cache entry CMAKE_CXX_COMPILER to the full path\n  to the compiler, or to the compiler name if it is in the PATH.\n-- Configuring incomplete, errors occurred!\nSee also \"C:/Users/ankita.a.rath/Downloads/MITIE-master/mitielib/build/CMakeFiles/CMakeOutput.log\".\nSee also \"C:/Users/ankita.a.rath/Downloads/MITIE-master/mitielib/build/CMakeFiles/CMakeError.log\".\n```. Thanks. Issue resolved. \nBut got into some other problem. When I am running the examples it is executing fine, but when I am trying to import mitie in some other file it is saying no module named mitie. Thanks. That issue is resolved. But getting one more error.\n`Traceback (most recent call last):\n  File \"C:\\Users\\ankita.a.rath\\Downloads\\MITIE-master\\examples\\python\\train_relation_extraction.py\", line 17, in \n    ner = named_entity_extractor(\"../../MITIE-models/english/ner_model.dat\")\n  File \"C:\\Users\\ankita.a.rath\\Downloads\\MITIE-master\\examples\\python/../../mitielib\\mitie.py\", line 247, in init\n    raise Exception(\"Unable to load named entity extractor from \" + to_default_str_type(filename))\nException: Unable to load named entity extractor from ../../MITIE-models/english/ner_model.dat\n\n\n\n`\n\n\n\nCan you please help on this.. Thanks a lot. That issue is resolved. \nOne more thing. Do I have to always add mitielib in sys.path in my code? I have added it in system env variable path. But when I am importing it is saying no module mitie. It is working once I am adding the path in sys.path.\n. ",
    "Rchanger": "I am facing the same issue but linking MITIE with golang on windows 7 machine. thanks for your reply but this is with python i am trying for golang \n. ",
    "playfulart": "Unsubscribe\nOn Tue, Jan 2, 2018 at 9:14 PM, Rafael Antonio Ribeiro Gomes \nnotifications@github.com wrote:\n\nIf I understand right, you are trying to extend your dataset with data\nthat is not labeled. In this case, your Precision and Recall will only\nincrease for \"O\" (BILOU). Also, it may let your Named Entities Scores even\nworst. Give it a try and run the conneval script, it will clarify what\nI'm trying to explain.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/153#issuecomment-354924443, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AANybUWWqIPXGm4TuGFhI1Le3_OhuWzBks5tGuKFgaJpZM4PY1Qj\n.\n. UNSUBSCRIBE\n\nOn Thu, Dec 21, 2017 at 11:30 AM, lzhao7812 notifications@github.com\nwrote:\n\nThanks!\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/mit-nlp/MITIE/issues/165#issuecomment-353395105, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AANybe5pLLcaaUyH-7jClGemEjNDDTvCks5tCoeOgaJpZM4RKBKy\n.\n. \n",
    "andymcm": "Ah ok, thanks for the response. . ",
    "Griffintaur": "Let's say I want to train MITIE for another language. so that it can be plugged into RASA.\nDoes it only need the data corpus of the language?\nCan someone point out the steps to generate total_word_feature_extractor.dat for that language?\nI couldn't find any documentation for that. ",
    "sea-boat": "thanks for your help.. ",
    "alvinhui": "thanks. ",
    "jeffThompson": "@davisking \u2013 maybe I didn't explain well. I ran all the commands to compile for Java (like you pasted above), and it did everything without any errors. But the instructions say it should place a javamitie shared library and jar file into the mitielib folder but I don't see a jar file created anywhere.. I don't know, I did run those commands exactly. I made a build folder in the java folder (not the examples one, the one in mitielib. I cd'd into the build folder and ran the two cmake commands.\nI'll try deleting and re-downloading everything (maybe I messed up a cmake file somewhere along the way) but I'm sure I'm following the instructions.. [groan] yep, totally. I was getting a ton of errors and trying too many different things. This is what I get for working on this late at night. Sorry about that!. ",
    "nacyzhaomin": "i want mitie migrate to python3, so what should i do. i see the document it support python2,7..thx.  i want run a demo on win10. ",
    "lzhao7812": "Thanks!. I saw in the setup.py, it specifies only upto 3.5, but not 3.6. Is it possible to update it to 3.6 so that it can be installed out of box?. Yes, here is the error:\nCollecting git+https://github.com/mit-nlp/MITIE.git\n  Cloning https://github.com/mit-nlp/MITIE.git to c:\\users\\xxx\\appdata\\local\\temp\\pip-1rcpzr_z-build\nInstalling collected packages: mitie\n  Running setup.py install for mitie ... error\n    Complete output from command c:\\users\\xxx\\envs\\venv-win-rasa\\scripts\\python.exe -u -c \"import setuptools, tokenize;file='C:\\Users\\xxx\\AppData\\Local\\Temp\\pip-1rcpzr_z-build\\setup\n.py';f=getattr(tokenize, 'open', open)(file);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, file, 'exec'))\" install --record C:\\Users\\xxx\\AppData\\Local\\Temp\\pip-5uwba90y-\nrecord\\install-record.txt --single-version-externally-managed --compile --install-headers c:\\users\\xxx\\envs\\venv-win-rasa\\include\\site\\python3.6\\mitie:\n    running install\n    running build\n    error: [WinError 2] The system cannot find the file specified\n. ",
    "munaAchyuta": "@davisking @grafael   could you please elaborate or give a little more examples \n what is inconsistent labeling ?  - is it mean number of labels varies from sentence to sentence !! like one sentence has 3 labels and other sentence has 5 labels..etc\n how labeling mistakes affecting application performance ? \ncan MITIE NER run on a distributed architecture ?. Thanks @davisking for your quick reply. this time i made sure that my annotated training data have consistent labels. but still i don't see any progress in performance.\nfrom log what i found, In mitie there are two trainings going on.. \n1. PART-I( Train Segmenter) : which is working fine as it is using all cores and using required memory. \n2. PART-II(Train Segment Classifier) : this is not using all cores. and also using huge memory compare to data size. CRITICAL - taking huge time.\nhere is some log ..\nTraining example annotated sentences count : 373\nMachine Details : RAM - 8GB, cores - 4 cores\nTraining to recognize 3 labels: 'B-act', 'B-sub', 'B-org'\nPart I: train segmenter\nwords in dictionary: 200000\nnum features: 271\nnow do training\nC:           20\nepsilon:     0.01\nnum threads: 4\ncache size:  5\nmax iterations: 2000\nloss per missed segment:  3\nC: 20   loss: 3     0.431569\nC: 35   loss: 3     0.437956\nC: 20   loss: 4.5   0.443431\nC: 5   loss: 3  0.440693\nC: 20   loss: 1.5   0.415146\nC: 6.5555   loss: 5.16517   0.457117\nC: 0.1   loss: 8.09489  0.327555\nC: 0.1   loss: 3.81119  0.30292\nC: 0.549491   loss: 5.61437     0.430657\nC: 7.8466   loss: 5.43597   0.457117\nC: 10.2883   loss: 5.1293   0.452555\nC: 6.0607   loss: 5.02357   0.456204\nC: 7.41861   loss: 5.28618  0.457117\nC: 7.13806   loss: 5.20935  0.458029\nC: 6.98092   loss: 5.16756  0.455292\nbest C: 7.13806\nbest loss: 5.20935\nnum feats in chunker model: 4095\ntrain: precision, recall, f1-score: 0.703608 0.747263 0.724779 \nPart I: elapsed time: 1027 seconds.\nPart II: train segment classifier\nnow do training\nnum training samples: 1441\nC: 200   f-score: 0.734335\nC: 400   f-score: 0.735081\nC: 300   f-score: 0.731994\nC: 500   f-score: 0.735241\nC: 700   f-score: 0.734709\nC: 520   f-score: 0.733273\nC: 450.957   f-score: 0.733804\nC: 483.4   f-score: 0.736308\nC: 480.156   f-score: 0.735241\nC: 490.078   f-score: 0.734653\nC: 484.607   f-score: 0.735241\nC: 482.381   f-score: 0.732305\nC: 483.799   f-score: 0.734653\nC: 483.236   f-score: 0.732149\nbest C: 483.4\ntest on train: \n286   2   0   3 \n  0 759   0   3 \n  0   0  43   0 \n  4   6   0 335 \noverall accuracy: 0.987509\nPart II: elapsed time: 19417 seconds.\ntotal time took in hour : 5\nnot sure what's going on !!\nyes memory always available.\nThanks in Advance. . Thanks @davisking . \ncould you please help me to understand why large value of \"C\" takes more time compare to small value of \"C\" ? where Accuracy and F1/F score are mostly same for different values of \"C\".\nfrom my understanding \"C\" just a regularisation parameter which helps to reduce/avoid mis-classification. so it doesn't have any effect on Accuracy and F/F1 score. if my understanding is correct , can i use small value of \"C\" !!. if so, then what is the max minimum value of \"C\" i can use ? (i mean what is the minimum threshold value of \"C\" i can use ?) and specially in this problem ?\nfor above problem please find log..\n=============================================== C=300 \nnum training samples: 1441\nC: 200 f-score: 0.734335\nC: 400 f-score: 0.735081\nC: 300 f-score: 0.731994\nC: 500 f-score: 0.735241\nC: 700 f-score: 0.734709\nC: 520 f-score: 0.733273\nC: 450.957 f-score: 0.733804\nC: 483.4 f-score: 0.736308\nC: 480.156 f-score: 0.735241\nC: 490.078 f-score: 0.734653\nC: 484.607 f-score: 0.735241\nC: 482.381 f-score: 0.732305\nC: 483.799 f-score: 0.734653\nC: 483.236 f-score: 0.732149\nbest C: 483.4\ntest on train:\n286 2 0 3\n0 759 0 3\n0 0 43 0\n4 6 0 335\noverall accuracy: 0.987509\nPart II: elapsed time: 19417 seconds.\n============================================== C=100\nnum training samples: 1420\nC: 0.01   f-score: 0.673219\nC: 200   f-score: 0.75807\nC: 100   f-score: 0.758977\nC: 148.954   f-score: 0.758783\nC: 124.134   f-score: 0.759333\nC: 121.721   f-score: 0.757521\nC: 136.154   f-score: 0.760752\nC: 134.952   f-score: 0.756639\nC: 142.253   f-score: 0.757164\nC: 138.668   f-score: 0.758945\nC: 137.088   f-score: 0.756806\nC: 136.031   f-score: 0.759333\nC: 136.479   f-score: 0.759459\nbest C: 136.154\ntest on train: \n286   2   0   3 \n  0 761   0   1 \n  0   0  43   0 \n  4   9   0 311 \noverall accuracy: 0.98662\nPart II: elapsed time: 6148 seconds.\n============================================== C=50\nnum training samples: 1432\nC: 0.01   f-score: 0.670678\nC: 200   f-score: 0.754349\nC: 100   f-score: 0.755016\nC: 149.215   f-score: 0.753461\nC: 121.914   f-score: 0.755938\nC: 118.753   f-score: 0.753097\nC: 134.168   f-score: 0.75631\nC: 129.929   f-score: 0.756474\nC: 129.128   f-score: 0.755917\nC: 131.916   f-score: 0.754349\nC: 130.128   f-score: 0.755402\nC: 129.586   f-score: 0.755938\nbest C: 129.929\ntest on train: \n286   2   0   3 \n  0 761   0   1 \n  0   0  43   0 \n  5  10   0 321 \noverall accuracy: 0.985335\nPart II: elapsed time: 5562 seconds.\ndf.number_of_classes(): 4\n============================================== C=300\nnum training samples: 1455\nC: 200   f-score: 0.73822\nC: 400   f-score: 0.736475\nC: 300   f-score: 0.738895\nC: 271.805   f-score: 0.737705\nC: 326.638   f-score: 0.735243\nC: 292.355   f-score: 0.738378\nC: 302.664   f-score: 0.733705\nC: 296.35   f-score: 0.736475\nC: 298.977   f-score: 0.737146\nC: 300.35   f-score: 0.736944\nC: 299.649   f-score: 0.738933\nC: 299.804   f-score: 0.735961\nbest C: 299.649\ntest on train: \n288   2   0   1 \n  0 760   0   2 \n  0   0  43   0 \n  5   8   0 346 \noverall accuracy: 0.987629\nPart II: elapsed time: 11576 seconds.\ndf.number_of_classes(): 4\n============================================== C=500\nPart II: train segment classifier\nnow do training\nnum training samples: 1358\nPART-II C:           500\nPART-II epsilon:     0.0001\nPART-II num threads: 4\nPART-II max iterations: 2000\nC: 400   f-score: 0.774171\nC: 600   f-score: 0.778615\nC: 500   f-score: 0.779291\nC: 538.343   f-score: 0.774471\nC: 470.021   f-score: 0.779522\nC: 480.425   f-score: 0.776386\nC: 443.145   f-score: 0.774217\nC: 463.96   f-score: 0.775954\nC: 472.435   f-score: 0.775831\nC: 468.168   f-score: 0.770751\nC: 470.707   f-score: 0.772416\nC: 469.493   f-score: 0.770333\nC: 470.138   f-score: 0.779291\nbest C: 470.021\ntest on train: \n287   2   0   2 \n  0 761   0   1 \n  0   0  43   0 \n  6   9   0 247 \noverall accuracy: 0.985272\nPart II: elapsed time: 18762 seconds.\ndf.number_of_classes(): 4\n==============================================\nfrom above log : why best C is coming nearer value of given \"C\" value ? no matter what C value i choose. you can see above log. my point is what is minimum best C or any threshold value of C which can be used for starting point ? \nwhat is \"num features\" and why is it always 271 ?\ncorrect me whether my interpretation is wrong !! --> \"number of samples\" is ( sum of number of labels in each sentence ). e.g : 2 sentence each has 3 label then number of samples is 6. right !!\nThanks in Advance. @grafael  @lopuhin @baali @davisking @autopost-get @autopost-. ",
    "PaulWoitaschek": "I have overseen the initial make instruction.. ",
    "vasilikivmo": "Thank you for your reply. Does this format affect the duration of the execution?\nI am struggling a lot running this, as it takes more than one hour on only a couple of annotated files, and as a result, I am not able to add more (ideally I would like to train around 1500 annotation files).\nI run this on an Ubuntu VM with 2-cores CPU (initializing 2 threads). If you need me to give more information please let me know.\nThank you!. ",
    "svazzole": "Ok. Thanks for you answer. So if I want to see how a sentence is represented, should I call the tokenizer and then take the mean of the vectors?. Thanks a lot for your help. I think I can close the issue.. ",
    "huyue8921": "Python 3.6.4\npip install git+https://github.com/mit-nlp/MITIE.git\nCollecting git+https://github.com/mit-nlp/MITIE.git\n  Cloning https://github.com/mit-nlp/MITIE.git to c:\\users\\huyue\\appdata\\local\\temp\\pip-yn_8mo_z-build\nInstalling collected packages: mitie\n  Running setup.py install for mitie ... error\nException:\nTraceback (most recent call last):\n  File \"d:\\localsdk\\python\\python36\\lib\\site-packages\\pip\\compat__init__.py\", line 73, in console_to_str\n    return s.decode(sys.stdout.encoding)\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 24: invalid continuation byte\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"d:\\localsdk\\python\\python36\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\n    status = self.run(options, args)\n  File \"d:\\localsdk\\python\\python36\\lib\\site-packages\\pip\\commands\\install.py\", line 342, in run\n    prefix=options.prefix_path,\n  File \"d:\\localsdk\\python\\python36\\lib\\site-packages\\pip\\req\\req_set.py\", line 784, in install\n    **kwargs\n  File \"d:\\localsdk\\python\\python36\\lib\\site-packages\\pip\\req\\req_install.py\", line 878, in install\n    spinner=spinner,\n  File \"d:\\localsdk\\python\\python36\\lib\\site-packages\\pip\\utils__init__.py\", line 676, in call_subprocess\n    line = console_to_str(proc.stdout.readline())\n  File \"d:\\localsdk\\python\\python36\\lib\\site-packages\\pip\\compat__init__.py\", line 75, in console_to_str\n    return s.decode('utf_8')\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 24: invalid continuation byte\n. ",
    "liuyue94": "sorry  ,I want to install mitie on my win7 system ,but I also encountered the above error. I have  tried so many times ,but It does not work\uff0cso i want to know whether you have  solved this problem , please help me ,thank you very much . I use  pip install git+https://github.com/mit-nlp/MITIE.git,  but  the error is that:\nC:\\Users\\user>pip3.6 install git+https://github.com/mit-nlp/MITIE.git\nCollecting git+https://github.com/mit-nlp/MITIE.git\n  Cloning https://github.com/mit-nlp/MITIE.git to c:\\users\\user\\appdata\\local\\te\nmp\\pip-08ubzvzl-build\nInstalling collected packages: mitie\n  Running setup.py install for mitie ... error\nException:\nTraceback (most recent call last):\n  File \"d:\\python3.6\\lib\\site-packages\\pip\\compat__init__.py\", line 73, in cons\nole_to_str\n    return s.decode(sys.stdout.encoding)\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 24: invalid\n continuation byte\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"d:\\python3.6\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\n    status = self.run(options, args)\n  File \"d:\\python3.6\\lib\\site-packages\\pip\\commands\\install.py\", line 342, in ru\nn\n    prefix=options.prefix_path,\n  File \"d:\\python3.6\\lib\\site-packages\\pip\\req\\req_set.py\", line 784, in install\n**kwargs\n\nFile \"d:\\python3.6\\lib\\site-packages\\pip\\req\\req_install.py\", line 878, in ins\ntall\n    spinner=spinner,\n  File \"d:\\python3.6\\lib\\site-packages\\pip\\utils__init__.py\", line 676, in call\n_subprocess\n    line = console_to_str(proc.stdout.readline())\n  File \"d:\\python3.6\\lib\\site-packages\\pip\\compat__init__.py\", line 75, in cons\nole_to_str\n    return s.decode('utf_8')\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 24: invalid\n continuation byte\nC:\\Users\\user>. ",
    "saravananpsg": "Thank you Davis for making it easy.  I have tried the pip install for python 3.6 on my windows 10 and installed the package successfully.\nAlso, I have used the following option:\nInstead of using , \nparent = os.path.dirname(os.path.realpath(file)) \n---use this for python 3.6--\nparent  = os.path.abspath(os.path.dirname(sys.argv[0])) \n. ",
    "MaryFllh": "Hello \nI'm using python 3.6 and tried running the text_categorizer_pure_model.py but raises an attribute error when loading the trained model using text_categorizer() :\nline 719, in del\n    self.__mitie_free(self.__obj)\nAttributeError: 'text_categorizer' object has no attribute '_text_categorizer__obj'\nHowever, the code runs perfectly fine on python 2.7. \nIs there any solution to this? . Hi\nI'm trying to run text_categorizer_pure_model.py on python 3.6, but an attribute error is raised when loading the trained model using text_categorizer():\nline 719, in del\n    self.__mitie_free(self.__obj)\nAttributeError: 'text_categorizer' object has no attribute '_text_categorizer__obj'\nThe code runs perfectly fine on python 2.7.\nIs there a solution to this?. Thank you very much. It is working now. . ",
    "juncaofish": "Thanks a lot.. ",
    "splendifer": "I see, thank you! Is the place where my run has stalled (right after the first \"loss per missed segment\" message) where the hyperparameter search is taking place?. Okay, good to know what's going on. I will double-check the data. Thanks!. ",
    "Samurais": "Related issue\nhttps://github.com/mit-nlp/MITIE/issues/118. ",
    "McWillie": "It did advance only after taking an unexpected amount of time (I have one other training session to compare with from somebody else), dropping resource use in comparison with when CCA was initiated and immediately after I provided user input so a coincidence would be very unlikely. I'm not implying that it's necessarily a bug or that it's designed to be in the code, this was just my experience.. Alright, I'll have to look elsewhere then.\nThank you for the work and speedy replies!. ",
    "davesomebody": "Thanks for the prompt reply.  I'll have to try CMake next time I guess.  I figured since I'm more familiar with old fashioned Make I would give that a shot.. ",
    "waynesonic": "Thanked your reply. ",
    "vamsitharun": "Traceback (most recent call last):\n  File \"mitie.py\", line 60, in \n    _f.mitie_extract_entities_with_extractor.restype = ctypes.c_void_p\n  File \"C:\\Users\\vamsi\\AppData\\Local\\Continuum\\miniconda3\\lib\\ctypes__init__.py\", line 364, in getattr\n    func = self.getitem(name)\n  File \"C:\\Users\\vamsi\\AppData\\Local\\Continuum\\miniconda3\\lib\\ctypes__init__.py\", line 369, in getitem\n    func = self._FuncPtr((name_or_ordinal, self))\nAttributeError: function 'mitie_extract_entities_with_extractor' not found\nThis is the error i am facing while running mitie.py, Kindly anyone help me quickly. ",
    "mortezakz": "Clarification, I am using Java. \n. The token number just gives you .... the token number. For instance, in the following, the token number of the entity would be 2 and 3, but the character offset in the original string would be 7 (and last char would be 14)\nI like New York. \n. Thank you very much.\nYes, I had not seen tokenizeWithOffsets(). I followed the Java example for your NER, and was looking only into the generated StringVector and not seeing the offsets. Didn't realize there was another class.\nWhere do you recommend I look for Java documentation or source? \nAlso, FYI, I am using the 0.8 distribution on Maven. Currently writing a paper with a section on NER performance comparison of different tools on a test dataset, so please let me know if you have a more up-to-date version so that I report your best results.\nThanks again. \n. Thank you! . ",
    "nsleta": "@davisking Thank you very much. (Removed)\nMitie works fine but already 3 days I am waiting for wordrep (~7 gb texts from wikipedia).. ",
    "nicola88": "I have the exact same error on Ubuntu Server 16.04 using MITIE 0.5 / 0.6 and Python 3.5.2 / 3.6.6.. ",
    "shanalikhan": "alright, do you have any published research paper available that shows the state-of-the-art wordrep algo and technique behind it. That would be great ?. "
}