{
    "Eloston": "Complete with 51.0.2704.106-2\n. Debian 8 uses libav, but Debian 9 and later now use ffmpeg; there may be some API differences between them that's causing that error.\nFortunately, ffmpeg has been backported in jessie-backports. Try installing the libavutil-dev, libavcodec-dev, and libavformat-dev packages from there. EDIT: Here's a link to the Debian page about the backported ffmpeg.\nThen, if you haven't touched the building sandbox since that build error, you can run dpkg-buildpackage -b -uc -nc in build-sandbox to resume building.\n. It looks like debhelper in Debian 8 is too old, so the option ddeb-migration is not supported.\nJust remove the following lines from build-sandbox/debian/rules and re-run the build command I provided earlier:\noverride_dh_strip:\n    # this line can be removed once stretch is released\n    dh_strip --ddeb-migration='chromium-dbg (<< 47.0.2526.80-4~)'\n. That's interesting. They must have changed the syntax in the new dpkg-parsechangelog since the manpage shows there should be a space (for version 1.18.4).\nAnyways, I'm glad I could help.\n. Changes implemented in 7f45ba754b77b89838d96b210fabbb379106fec2. Let me know if there's anything else I need to add.\n. I don't have an OS X machine to work with, so I won't be able to do this.\nThe shell scripts may be compatible with OS X, so you could try these rough steps:\n1. Run download_source.sh -v 48.0.2564.109\n2. cd into build-sandbox\n3. Run source_cleaner.sh\n4. Run domain_patcher.sh\n5. Apply the patches in patches with the order specified in patches/patch_order. I believe you can configure quilt to read that file and apply patches.\n6. Run python build/gyp_chromium with arguments from build_templates/debian/rules\n7. Run ninja -C out/Release chrome. The build output should appear in out/Release\nLet me know how this goes. If you get it to work, I can add OS X building instructions to the README.\n. It appears the GNU version of readlink has more features than Mac OSX's (BSD) version of readlink. It'll probably be better if you installed GNU version of the utilities instead of working around the deficiencies; here are some instructions I found to do this.\n. Any updates on this? ungoogled-chromium 51 introduced a new build system that might make things a bit easier (though there's no Python-based patching yet).\n. Done with c9597e447fbf348afa41e2d6770f231b35d16b68\n. The lack of searching is a feature. I do this for two reasons:\n- Mistyping or miscopying a URL will lead to a search, which I find annoying\n- Certain custom domain names (whether they are defined in /etc/hosts or a local DNS server) will also end up causing a search (at least historically).\nIf you want searching in the omnibox, don't apply the patch patches/ungoogled-chromium/disable-omnibox-searching.patch\n. I don't see the benefits in using this packaging system. I would rather create distribution-specific packages than use a third party system.\nThere are already scripts to create Debian and Ubuntu packages. If you need packages for another distribution, open a new issue report.\n. I don't understand what you mean be \"easy update system\". At least on Debian, one can download packages and use dpkg -i <package>.deb to install them. This seems pretty straight-forward and simple. Unless you mean you want a way to install updates without root privilages.\n. I was holding off on releasing new binaries until I had time to fix #7, but that won't be in a while. I'll upload binaries for 48.0.2564.116 shortly.\n. Are your patches applying relative to the root of the Chromium source tree? Did you remove any files beforehand? I just published 49.0.2623.111, so it should work.\n. From your build log with -p1:\nchecking file components/autofill/core/browser/autofill_download_manager.cc\nHunk #1 FAILED at 87.\n1 out of 1 hunk FAILED\nchecking file components/autofill/core/browser/autofill_manager.cc\nIf you applied the Iridium patches against a clean source tree, it should apply cleanly.\n. Ah yeah I forgot about that. :P Glad you figured it out.\n. No, only domain_patcher.sh is needed. source_cleaner.sh only removes files.\n. Interesting. What kind of error?\n. Is that all it says? At what point did you run source_cleaner.sh?\n. Is that the only error shown during the build? Usually the actual error shows up before that line.\n. This patch assumes that Chromium is built with safe_browsing=0. The fact that the built went fine with the proper GYP flags without source_cleaner.sh proves that source_cleaner.sh is not necessary to build ungoogled-chromium.\n. source_cleaner.sh is for deleting binary files residing in the source tree. As long as your build flags do not depend on any of the binaries deleted by source_cleaner.sh, then it won't hurt to use it.\n. safe_browsing_mode may have been the name of the flag before. Thanks for checking again to confirm that the safe_browsing flag still exists.\nEDIT: I've reported this here\n. Complete starting with 2422be661c4b7c9236a5345a4730db396a45d038\n. No, it does not. Also, an infobar should show up when the browser tries to connect to Google on its own.\n. Yes, it is.\n. I don't have a way of downloading ARC-Welder; so I can't help you with that.\nI noticed that ARChon uses NaCl. I disabled this in Debian builds (with the GYP flag disable_nacl=1). Did you build ungoogled-chromium without NaCl support?\nIIRC, building with NaCl requires additional downloading during the GYP configuration or ninja steps, so you'll need to undo some changes made by domain_patcher.sh.\n. Closing due to inactivity, and a new version is out. Let me know if there's something else that needs to be done with ungoogled-chromium.\n. @avently I do not want to support features that are not supported in Chromium, unless they align with the objectives of this project or someone else is willing to maintain them.. I did a quick search, and this extension for Chrome has a method of preventing canvas fingerprinting (though I'm not sure how it compares to CanvasBlocker).\nUnfortunately, I don't have enough time to work on CanvasBlocker now. I'll reconsider in the future. Thanks for showing me this extension though, it looks pretty interesting.\nP.S. WebGL can be used for fingerprinting too; Panopticlick can detect WebGL fingerprints. It'll be nice if CanvasBlocker could prevent WebGL fingerprinting too.\n. I'll start doing this for the next version of ungoogled-chromium, which will be based on a stable version of Chromium 51.\n. @triceratops1: I appreciate your effort, but I will not accept this. In the event that other libraries are renamed or the ABI starts to differ across distributions for the same library, your change will no longer apply. It is better to build directly on Ubuntu.\n. Done with 51.0.2704.106-1\n. Oops, I forgot to update my instructions to use a tag instead of the HEAD.\nThe HEAD will not always be in a working state. You need to use a tag.\n. The switch to GN has been delayed\n- A good number of GYP flags have no GN equivalents\n- Some from Debian and Iridium only work with GYP, and it would take some work to create GN equivalents and maintain them\n- Although a lot has been done already, the GN system still seems to be a WIP\n. This is pretty much done now. It started in 79d8a1a45e04ac30ef9b819f767682c7784d3115. Are you suggesting to use an open build platform to support more systems? If so, what systems and what build platforms do you recommend?\nIt's not a bad idea considering the hassle of building it myself. I'll need one or some that provides Debian Stretch, Ubuntu Xenial, and Windows environments.\n. I'll look into using OpenSUSE Build Service for building Debian 8 and Ubuntu 16.04 packages for now. I still have some work to do to make support for other platforms easier, and I still need to finish work on Chromium 51.\n. Please open another bug report for that.\n. For reference: There is some discussion about Travis-CI  and Launchpad over on #37.\n. There currently isn't a need for this right now. GitLab CI can handle Linux builds, or push to other platforms that can create other packages. Also, none of the other platforms need an automated process right now.. In recent months, I've changed my stance on this issue. Having CI would boost development productivity and shorten the time needed to build and publish binaries ourselves.\nRight now, there are several sub-ideal scripts I wrote to do sanity checking using CircleCI, but it would be better to actually run builds. It doesn't need to be after every commit; it could be done weekly or after a new tag is published for now.\nI'm open to suggestions. Free plans from TravisCI and many other systems are out of the question because Chromium takes quite a bit of computational resources compared to that of most other free CI jobs (CPU, RAM, storage, and time). I also don't want to take the responsibility of maintaining this system, especially if it means I need to manage a paid plan and the funds that go into them.. @intika \n\nOther idea : setup something like a \"button to build and publish\" that would cost 2\u20ac and any user can click it and pay to automatically build and publish hahahahaha never the less its doable (we will see a build popping up every day lol)\n\nThis is an interesting idea; have the user pay for computational power to run a predefined process. However, I'm not sure if users would be willing to pay for builds; the technically-able could just purchase computing power themselves, so people who aren't as knowledgeable would be the main audience. I'm not sure what the main audience would like in this scenario.\nYour other ideas are not bad, but they ultimately create more responsibility for at least one of us; examples of responsibilities include:\n\nUpholding a title (e.g. designated packager)\nMaintaining hardware (e.g. dedicated server)\nWorking with people (e.g. sponsor). I already have enough with what I do on GitHub.\n\nI think the best solution here is something that creates minimal responsibilitiy for us (financially and socially), and is sustainable for the provider (e.g. a CI service, volunteer, etc.). I realize that these requirements are pretty atypical (normally someone has to dedicate some part of their lives and resources to maintain this sort of thing), but I personally don't believe the benefits from a better CI system outweighs the dedication required.. @hrj brings up a good point; we need to get something going to make progress. As @T-vK brought up, we are pretty close to having an automated system for making .deb packages with GitLab and Launchpad; opening this channel for builds will help in bringing more users. Having more users helps with exposure, which in turn helps with development; it opens the possibility for a virtuous cycle of improvement. This should help build trust, which @sixtyfive and @intika brought up.\nAfter #37 gets resolved (or even simultaneously), we could consider solutions like the ones @alexbakker  brought up to setup automated builds for more configurations.. @hrj This is an interesting concept; thanks for sharing. However, I don't quite understand what value my approval has on this; what kind of responsibility would I incur as a result?\nIn addition, based on the article you linked, it seems that OpenCollective is targeted more towards funding developers rather than infrastructure itself. Are there similar cases to this on OpenCollective?. @hrj I looked into the GitHub permissions they use, and it seems they require a lot of permissions to work properly right now: https://github.com/opencollective/opencollective/issues/355\nIf we're going to use this, I'd rather we enable this on a mirror of this repository until the permissions are more reasonable. But, would this cause any major issues?. Started in 52a73685ff236ae884611fa2c7884d43e63f7129. The framework of it is pretty much done as of now, but it may continue to evolve.\n. They applied just fine when I committed them for version 51.0.2704.81. Though some of them don't have the correct offsets and have some fuzz (which quilt could deal with just fine). I never had the issue you described with quilt. What Debian version are you using? I'm guessing you're using the debian directory provided by this project?\n. New version is out. Please see the new README for building. Let me know if this doesn't fix the issue.\n. Not a bad idea.\n. Consolidating into #37.. I noticed in your logs that you're using an old version of the libav* libraries. Have you seen the note for Debian Jessie users?.\nIf you want to use Chromium's bundled FFmpeg, then don't apply ffmpeg.patch from build_templates/debian/patches/system/.\nLet me know how it goes. I haven't had the chance to test the new patches yet, so if it works that will be helpful information for me.\n. > \"a clean opensuse build service xenial vm\"\nAre you saying that you're trying to build on a Ubuntu Xenial machine now? Are you not building on Debian 8 anymore?\n\nSupervised users aren't enabled\n\nWhat are \"supervised users\"?\n\nand after the compilation has been aborted\n\nWhat's the error? Is it related to the code? If so, do you have a log?\n. New version is out. Please see the new README for info. Let me know if you still have the problem.\n. Not yet. I haven't finished working on it.\n. Here's Google's recommendations, but I've been able to go with less than that. I think you'll need about 30 GB of storage space. I have 4 GB of RAM on my build VM and two cores (with hyperthreading, for a total of 4 threads) on an Intel Xeon E5-2430L. It takes about 5-6 hours to build Chromium I believe.\n. You don't need a VM. I just used one because the machine I used is a VM host. If you match the specs I gave that should be sufficient.\n. No I didn't use a VPS. You can use one if you want. It really doesn't matter what kind of machine you use.\n. I do work on a VM that sits on a dedicated VM hypervisor. I use it because it has quite a bit of read and write storage cache, but it really doesn't make that much difference while building.\n. I did not know about this. Thanks for letting me know.\n. The logging idea is not bad. I'll implement it in some form.\nYour -n option is somewhat similar to what I was planning on doing. Instead of generating a .dsc, .orig.tar.xz, and .debian.tar.xz, it would output the source code to a directory and also generate a debian directory to put in there. I don't see the point of generating a .dsc, .orig.tar.xz, or ..debian.tar.xz if they're going to be unpacked on the same system for building. What do you need these files for?\nEDIT: Do you need these files for some APT repository or something?\n. Alright. Will do.\n. Closing this as wontfix since buildlib will be deprecated, and this enhancement does not make sense in the new system (#125).. I'll implement a way of generating all of the required files with the new build system.\n. Thanks for this. I still haven't built Chromium yet (I'm working on the build system and converting to GN) so I recommend you don't use the patches yet. You should wait until I release a new tag.\n. I haven't encountered this error in my build. I will release a new tag version soon (within a day or two) so you can try building with that.\n. Thanks for your interest in my project!\nAlthough I do build my own Debian packages, I actually don't know many details on what I would need to do as a maintainer, such as the proper procedures of submitting packages and source code, and providing support for the package. Plus, I'm pretty sure some of the things I do to the source code (namely the domain patcher and source cleaner, which are mostly automated and therefore somewhat unpredictable in what they can break) are things that would take more time to do if I were to follow Debian's rules.\nAlso, I'm currently in the process of creating a flexible and extensible cross-platform Python build system that will take care of downloading, patching, configuring, and building Chromium for a certain platform or distribution. The debian directory used for building will become pretty simple; it will just run the build command and bundle up the build artifacts into .deb packages. There are several reasons why I'm switching to this system, but one major reason is that it makes supporting other platforms such as Mac OSX and Windows easier. Perhaps Debian and other distributions would be fine with my unconventional method of building packages for their distributions, but I don't think I have the time right now to learn what I need to know to become a package maintainer.\nI could just propose to include a subset of the patches that aren't too dependent on a specific build configuration, but I'm fairly certain that my patches don't meet the standards of \"good\" patches. Also, I haven't been able to consistently keep up-to-date with the latest stable of Chromium, so Debian may not be happy with that.\nIn essence, I don't have a lot of time, and I use ways of saving time that others may not like very much.\nEDIT: If someone wants to maintain packages of ungoogled-chromium, go right ahead. I'll be happy to work with you.\n. @macandchief You make a point about package versions, but hopefully 62 comes out soon enough so that doesn't continue to be an issue. In develop, the packages have already been renamed with a ungoogled- suffix due to the inconvenience of package holding.\nI don't think it is necessary to have instructions for installing Debian package files here because many other software do not post instructions either. So, methods to install should be easy to find.. @macandchief I think that installation method is fine. We should move this discussion elsewhere if you still have questions.. Well it seems that the disable signin patch was included in Debian's 63.0.3239.40-1. That's kinda neat.. Not necessary with quilt refresh.. Implemented in 5a2a6c7c239762d079d48330dd3b66c9c61dff20\n. When I was working on the Windows build, I too tried to use git apply to apply the patches. However, git apply does not tolerate fuzz or offsets, which the patches have a lot of. This is why #28 exists.\nFor now, you'll have to get GNU patch and apply the patches with the -p1 argument.\nAlso another quick note: if you've domain substituted the source tree already, you need to do the same for the patches or they won't apply.\n. > There are some binaries in the release zip\nWhich release zip are you talking about? If you're talking about the zip of the source repository, there are no binaries in there.\n\nI tried executing the cleaning_list file from the 'src' folder but got a bunch of permission errors.\n\ncleaning_list is not a script. It's a list of files that should be removed from the source tree.\nHere's basically what you could do now:\n1. Remove the files listed in resources/common/cleaning_list\n2. For the files listed in resources/common/domain_subsitution_list, use the regular expressions defined in resources/common/domain_regex_list to replace the domain names\n   - EDIT: An entry in domain_regex_list (delimited by \\n) has search and replace expressions delimited by #.\n3. Run meta-build configuration (GN or GYP)\n4. Run ninja\nIf you don't want to put in the effort to setup or build additional utilities or modify the meta-build configuration to use system resources (like I did for Windows and Linux), you'll probably want to skip domain substitution and source cleaning.\n. Unfortunately, many of the patches depend on GYP and won't work with GN because they modify GYP files but not GN files. See #16.\nI think if you run the gclient hooks, they may invoke GYP configuration. They might have changed that already. But if you want to be sure, you can run build/gyp_chromium with Python 2 and it will generate ninja files in several directories in out/. For the GYP flags to set, have a look at resources/common/gyp_flags.\nI should also mention that some patches (namely those from ungoogled-chromium) like fix-building-with-safebrowsing.patch depend on safe browsing being disabled with GYP. If you choose not to set these GYP flags, you'll have to not apply the corresponding patch files. The patch names should be self-explanatory, and there is a short description inside of each that will help.\n. These are two separate issues:\n1. You can't use ffmpeg_branding=ChromeOS or ChromiumOS on any OS other than Linux without the proper patch (which ungoogled-chromium does on Debian and Ubuntu). You must use ffmpeg_branding=Chrome or ffmpeg_branding=Chromium. You also shouldn't enable enable_mpeg2ts_stream_parser=1 or enable_hevc_demuxing=1. I will update the GYP flags so the common flags won't include this.\n2. According to this and this, it seems that you're unable to import a Python module that comes with Apple's development tools. Maybe the solutions in those threads could give you some hints?\n. No, this doesn't have to do with leftover files. It seems your compiler is treating certain warnings as errors, which is strange since werror= should have disabled that. You do seem to be using Google's pre-built clang compiler, but I'm not sure if that's related...\n. That safebrowsing error is interesting. I'm assuming you disabled safebrowsing in GYP and applied fix-building-without-safebrowsing.patch?\nIf so, OS X might have different compiler macro values that somehow depend on that piece of code. In this case, according to blacklist.cc, SAFE_BROWSING_DB_LOCAL is defined for some reason. Maybe you could change the whole statement to say #if 0 and try recompiling?\nRegarding your edit: No, those GYP values don't really help.\n. Huh, I guess you just have to delete those functions and see what happens. It'll be easier than trying to figure out why your compiler is treating an unused function warning as an error. I can fix the patches for the next release so they won't be there.\nYou don't need to reapply the patches. If they applied without any errors, then it's fine.\n. You should delete the functions outlined in the error. Chromium developers usually design their code so warnings they don't explicitely ignore are warnings they fix. In future releases, I will start designing my patches better so they won't produce compiler warnings like that.\nAlso, the behavior you described is not really strange. Ninja will automatically run with multiple jobs based on the number of threads. There are some more details to this, but ninja will not necessarily generate object code in the same order every invocation, so that's why you're seeing it compile about 15-16 files each time before encountering the inevitable error.\n. Ah so now we finally ran into OS X-specific issues. Looks like I'll need to update the patches to fix this.\nNormally I disable one click signin via GYP and then use a patch fix-building-without-one-click-signin.patch to fix compilation errors that result. Since I've only done this on the supported platforms, it's not suprising that this error shows up.\nI will post a patch here that can fix this error. Unfortunately I don't know Objective-C (or Objective-C++ in this case) or have an OS X machine, so I'll post the patch here and we'll see how it goes before I include it in ungoogled-chromium.\n. You won't need to compile from scratch. I'm expecting this patch to modify some GYP files, so you'll need to re-run GYP and then invoke ninja again. Ninja will figure out which targets have changed and recompile only those.\n. Try applying the following patch from the top of the Chromium source tree:\n--- a/chrome/chrome_browser_ui.gypi\n+++ b/chrome/chrome_browser_ui.gypi\n@@ -3351,6 +3351,8 @@\n           'sources!': [\n             'browser/ui/views/sync/one_click_signin_bubble_view.cc',\n             'browser/ui/views/sync/one_click_signin_bubble_view.h',\n+            'browser/ui/cocoa/one_click_signin_bubble_controller.h',\n+            'browser/ui/cocoa/one_click_signin_bubble_controller.mm',\n           ],\n         }],\n         ['enable_supervised_users==0', {\nYou'll need to re-run GYP and then invoke the ninja command.\nEDIT: This assumes you already applied all the other patches, since this patch modifies code patched by fix-building-without-one-click-signin.patch\n. No they're not the same error; look closer at the file names.\nTry unapplying the earlier patch and apply this one instead:\n--- a/chrome/chrome_browser_ui.gypi\n+++ b/chrome/chrome_browser_ui.gypi\n@@ -3351,6 +3351,12 @@\n           'sources!': [\n             'browser/ui/views/sync/one_click_signin_bubble_view.cc',\n             'browser/ui/views/sync/one_click_signin_bubble_view.h',\n+            'browser/ui/cocoa/one_click_signin_bubble_controller.h',\n+            'browser/ui/cocoa/one_click_signin_bubble_controller.mm',\n+            'browser/ui/cocoa/one_click_signin_dialog_controller.h',\n+            'browser/ui/cocoa/one_click_signin_dialog_controller.mm',\n+            'browser/ui/cocoa/one_click_signin_view_controller.h',\n+            'browser/ui/cocoa/one_click_signin_view_controller.mm',\n           ],\n         }],\n         ['enable_supervised_users==0', {\n. Nice!\nOne last thing: Could you write out the steps you took? I want to include them as build instructions in BUILDING.md (and I can consider #3 finished)\n. Thanks for the instructions! I'll include a link to them from the building instructions.\nAnd yes there's always a \"get more extensions\" link at the bottom. I think it's part of the page's HTML.\nIt looks like this is it for now, so marking this issue as closed.\n. buildlib is a Python 3 module (tested on 3.5, may work on 3.4). See this and the following section of BUILDING.md for some general details about buildlib and this section of the README.md for the files it uses.\nAs buildlib is now, generic.py's classes should be treated as an abstract class (even though I did not decorate it as such). To support OS X, there needs to be a new Platform class that inherits from GenericPlatform which implements some functions, namely patching and generating an archive of the build artifacts.\nAdditionally, a new resources subdirectory may need to be created if additional gyp flags or patches are needed (which doesn't seem to be the case right now).\nI'm not too satisfied with the way buildlib turned out, especially with the way that end-users have to configure it. I'm considering changing this for future versions, but for now it's not terrible enough to warrant reworking right now.\n. I'm not sure how you're going to adapt Iridium's build script to work with ungoogled-chromium. Are you planning to invoke a modified Iridium build script from buildlib?\nEDIT: Just to speed things up, I can go in and start implementing OS X code. Then, you can make a pull request with the rest of it completed.\n. In 7053f747ef2cb7e560d11ff3c75c041cd505bfb7, I've added initial support for Mac OS in buildlib. This is all I could implement given what's said in your build instructions. You can extend it and try running it with build_macos.py\n. Oops... dd765eb8c6af24da701104ce614d71b2c2477f08\nJust a heads up: I'm not sure what compiler Chromium will use, since the source cleaner is run by default, and hooks are not run. I think it uses clang right? If so, we can adapt a Debian patch that uses the system's clang to use clang provided by homebrew or something.\n. Ooops... ... a437c9cd62032b75779ad2d9a57cb7581335b3f0\nYou shouldn't change the arguments of patch because -i is for passing the filename in via commandline arguments. As you can see from the function in macos.py, the patch file is opened in binary mode, read, and passed in to the subprocess's stdin.\nAlso you don't need to install clang via homebrew. I was just wondering whether you had clang (since it seems like Chromium uses clang on Mac).\n. Looks like pdfsqueeze isn't downloaded because it is a Mac-only dependency (this is because the source archive is generated by a Google buildbot on Linux). We can parse the DEPS file and download it via buildlib, download pdfsqueeze manually from that commit and then try building, or just hardcode the commit in buildlib and invoke git ourselves. For now we can just set it up manually.\nEDIT: The DEPS file is a text file in the root of the Chromium source tree\n. Nah. If you read the error code more closely, it's trying to use Google's build of clang.\nWe'll probably need to adapt Debian's clang patch as I expected, i.e. this patch. What's the path to clang and clang++ provided by Apple?\n. Try setting additional GYP flags clang=1 and make_clang_dir='/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr'\nEDIT: Also set clang_use_chrome_plugins=0\n. What happens if you set clang_dir='/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr' and set clang_xcode=1?\n. Try setting the GYP flag cflags='-w'\nEDIT: Also cflags_cc='-w'\n. Remove cflags_cc and change cflags to cflags='-Wno-error=unknown-warning-option'\n. cflags_cc was a part of the edit in my previous post. If you haven't tried cflags_cc='-w', then try that first.\nIf that doesn't work, then try cflags_cc='-Wno-error=unknown-warning-option'.\nAnd if that doesn't work, then remove cflags and cflags_cc and apply this patch:\n--- a/third_party/opus/opus.gyp\n+++ b/third_party/opus/opus.gyp\n@@ -62,7 +62,7 @@\n       'variables': {\n         'clang_warning_flags': [\n           # TODO(thakis): Remove once silk/macros.h has been fixed\n-          '-Wno-expansion-to-defined',\n+          #'-Wno-expansion-to-defined',\n         ],\n       },\n       'include_dirs': [\n. By the way, you can modify build_macos.py so you don't keep recreating the source tree every time.\n. Huh, just saw your edit. GitHub doesn't notify users of edits via email. :/\nMan these errors are getting more and more cryptic. If you remove clang_xcode=1, does it make a difference?\nAnother possibility is that Apple's clang (or entire toolchain) is too old. What version of clang does Apple use? (pass --version to clang)? How about the one from homebrew? If they're different enough, maybe we could try changing clang_dir and make_clang_dir to use homebrew's clang.\nAlso the warning when patching you get is fine, since it applied and we're not getting the same error anymore. It's probably some issue when copying-pasting.\n. I just did some searching, and it seems Apple's LLVM is a fork of LLVM with their own changes. This may be breaking our build, so it may be better to try compiling with homebrew's clang (which seems to be unmodified).\nIt looks like Chromium's using a certain revision of Clang 3.9. It's probably good enough to use Clang 3.8 (which seems to be the latest that homebrew has), so you should try getting LLVM 3.8 with clang via brew.\nFor GYP variables, here's what we can try setting:\n- Do not set clang_xcode=1\n- Set clang=1\n- Set the following variables with the path to homebrew's clang:\n  - host_cc\n  - CC\n- Set the following variables with the path to homebrew's clang++:\n  - host_cxx\n  - LDPLUSPLUS\n- Set clang_dir to the path to the directory containing homebrew's clang and clang++\n- Set make_clang_dir to the parent directory of clang_dir\nYou might want to clear the out directory, since we're changing compilers.\n\nDo you know if clang_dir is deprecated?\n\nclang_dir is not deprecated. I've been getting these variables from build/common.gypi.\n\nAlso, should I try to copy that file from the source tree I downloaded from Google? Any chance they are different?\n\nWhich file are you talking about? Are you talking about clang?\n. Sorry, I wasn't being very clear.\n\nSet the following variables with the path to homebrew's clang:\n\nThis should be the absolute path to the binary named clang\n\nSet the following variables with the path to homebrew's clang++:\n\nThis should be the absolute path to the binary named clang++\n. You should just delete those functions like before. I'm updating the patch that modifies this file so you shouldn't run into this problem again.\n. I have no idea. I don't know what files you're using, and I've never used a Mac. Your guess is as good as mine.\nIf you need files from the old build tree, we might as well use depot_tools, run the gclient hooks, and not run domain substitution or source cleaner. There's no point in running domain substitution or source cleaner if we can't get a build to work without any Google binaries. We can probably modify the Mac OS buildlib module to do this, even though it's not an ideal build process.\n. I did some more searching, and it seems like libc++ should be provided by Xcode, not homebrew.\nI'm not sure how to include more library paths to search in (which could solve the problem of not finding libc++). Maybe you could try setting clang_xcode=1? I'm out of ideas now as I'm not familiar with Mac's build environment. If we can't get this to work, we might just have to use Google's binary blobs to compile.\n. Maybe the LLVM you chose is too new? Clang 4 could have some larger changes that could be breaking the build. You have to remember that the Chromium we're building with came out in June, and the branch point was even earlier (51.0.2704.0 came out in April; dunno how much has changed since then). Try sticking with 3.8\n. I'm not sure where you got your information from, but HEAD usually implies building the code from the tip of the development branch (from a git repository). That's why your llvm path also has a partial SHA-1 hash in it.\n. It seems like the shell variable DYLD_LIBRARY_PATH is what you're looking for, except I don't really know how this is being set (since I don't see it in GYP). Maybe the library search paths are passed in another way to the linker. I believe the libc++ library should be named libc++.dylib\n. Try commenting out line 5281 (or the line that says 'library_dirs': [ '<(DEPTH)/third_party/libc++-static' ],) in build/common.gypi.\nEDIT: If that doesn't work, try changing <(DEPTH)/third_party/libc++-static to the path where you have libc++.dylib\n. That Chromium bug report doesn't look too relevant.\nIf by \"the first time\" you mean the time you downloaded the source code yourself, well, there's a simpler general explanation for that. gclient will download all of the platform dependencies and run some hooks that will setup Google's build utilities and toolchains. depot_tools may also contain some binaries for building too.\nIf you want a more specific answer, then it'll be hard to say without digging around in the GYP or even ninja files. According to some comments in build/common.gypi, third_party/libc++-static is supposed to contain some pre-built libraries. Maybe it is downloaded in one of the hooks? Maybe it's a platform dependency? It's hard to say without digging deeper.\nWe've reached a point where I can't really help you without spending quite a bit of time researching the Mac build system (or spending a little less time digging around on a Mac). Unless you're able to figure out something, we will probably have to modify buildlib to use depot_tools and download the source tree. However, keep in mind that I plan to switch from GYP to GN within the next few releases.\nRegarding your thoughts on the alternate plan, it'll probably be best to not run source_cleaner as that may screw up Google's toolchain. If you're going to use Google binaries, there's really no point in running source_cleaner.\n. So it looks like .a files are static libraries (aka archives), which are basically archives containing .o files. In build.sh, it looks like libtool is used to create this using files matching the pattern libcxx*/*.o. When you got LLVM from homebrew, did you also get any .a or .o files which could be related to libc++? It could save the efforts of trying to get build.sh to work.\nEDIT: Also congrats! I'm a bit suprised we managed to pull it off.\n. I haven't encountered any problems with libc++ before, so libc++.a doesn't seem to be used on other platforms.\nBTW, what path did you use in this post when you tried to use the path to libc++.dylib?\n. So you did find a libc++.dylib in /usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/usr/lib? If you did, that's interesting...\nIt seems that there should be a libc++.dylib on OS X 10.7 and higher. Is there one in /usr/lib? If so, it's possible the linker already tried searching in there (at least it would do this on Linux). I guess it wouldn't hurt to try setting that list value to use /usr/lib.\nBTW, I searched in DEPS and it seems that one of the download_from_google_storage actions will download a libc++.a for Mac only. So this seems to be a Mac-only issue.\nAlso this comment in build/common.gypi is interesting\n```\nTell the compiler to use libc++'s headers and the linker to link\nagainst libc++.  The latter part normally requires OS X 10.7,\nbut we still support running on 10.6.  How does this work?  Two\nparts:\n1. Chromium's clang doesn't error on -mmacosx-version-min=10.6\ncombined with -stdlib=libc++ (it normally silently produced a\nbinary that doesn't run on 10.6)\n2. Further down, library_dirs is set to\nthird_party/libc++-static, which contains a static\nlibc++.a library.  The linker then links against that instead\nof against /usr/lib/libc++.dylib when it sees the -lc++ flag\nadded by the driver.\n\nIn component builds, just link to the system libc++.  This has\nthe effect of making everything depend on libc++, which means\ncomponent-build binaries won't run on 10.6 (no libc++ there),\nbut for a developer-only configuration that's ok.  (We don't\nwant to raise the deployment target yet so that official and\ndev builds have the same deployment target.  This affects\nthings like which functions are considered deprecated.)\n```\nThe problem is, I don't know what flags determine a component build, and where these settings are.\nIf we can't get it to link against libc++.dylib, I guess we could try getting build.sh to work.\n. stdlib doesn't seem to be a GYP flag, so that probably didn't do anything.\nI guess we don't have much choice but to build libc++.a. So you tried running it and got visibility errors? If you didn't modify the script, what does the c++ command resolve to? You've tried using homebrew's clang++ without any success? Do you have g++?\n. So it seems that c++ is an alias for the system's default C++ compiler. You can try modifying the CXX variable in the script to use Homebrew's clang++ (though the visibility errors are probably not specific to Google's clang). Then you can modify it to use g++.\n. Does g++ point to GCC's C++ compiler, or is it also an alias for clang++?\n. Well no wonder. Could you try installing GCC from homebrew and try compiling with its g++?\n. Could you revert CXX back to c++ and comment out all of the sed lines?\n. Yeah I forgot to tell you to comment that out too. And libc++.a is supposed to go to third_party/libc++-static since that's the default path that common.gypi uses to look for it. So it looks like we just need to comment out these lines and invoke it as part of the build process.\nSo it looks like we need to assemble all of the GYP flags we used, download those two Mac directories, and invoke this script to make Mac building work properly. Did I miss anything else?\nOh and what archive format should I use to contain the resulting binaries? If Mac supports zip files in their archive utility already, that will make things easier (since I will be adapting the Windows buildlib code for doing this).\n. > (the gyp flags should not include the head folder since theres no --HEAD)\nIs HEAD-051e787 in your GYP flags what you're talking about? If so, what path should I use?\nEDIT: Also, what is the .app file you use to run? I'm looking into building a .dmg since that seems easier.\n. What is the .app file you use to run? I'm looking into building a .dmg since that seems easier.\n. Alright. I'll work on scripting this build process with buildlib. I'll post back with a new comment once I've got it ready for testing.\n. I just pushed 88c242532bf1f3c4302886d6de731ba7cb8f1166 which should build a .dmg from scratch. If you could test it out, that would be great.\nYou should start from scratch by deleting build_sandbox. You can leave chromium-51.0.2704.106.tar.xz and the .hashes file so you won't have to re-download them.\nI also wrote new build instructions in BUILDING.md. Could you check them out and see if I missed or messed up something?\nOh yeah, and I forgot to increment the release_revision to 3 in version.ini. Could you do that before building?\n. D'oh ac66c613c6473e21def771ef796d8127f701005b\n. 47b6c3b25795fe06471b2432e5d5ab2a558208df\n. If you're talking about google_util.cc, then that patch has already been updated.\n. New commits should fix these problems. I also updated disable-domain-reliability.patch, so you might want to extract the original google_configs.cc and reapply the relevant section of the patch, or reverse patch that file and apply the new section.\n. You should uncomment setup_build_utilities. That function sets an attribute for the command to invoke ninja. Or you can set the ninja_command attribute. I should revise this interface...\n. Could you try replacing libc++.a with the one that Google provides? I'm not sure if ninja will pick-up the change, so if that doesn't fix th error, we may need to start deleting some object files.\n. Alternatively, you could try uncommenting the sed lines in the build.sh script and change the CXX variable to point to Xcode's g++ compiler (not clang++). Then move the existing libc++.a out of the way so buildlib will rebuild it.\n. > For convenience, its a good idea to include a shortcut to /Applications aside Chromium.app. Most software in OS X distributed by third-parties are installed by copying them to that folder.\nI'm still not very familiar with Mac's application system, so any help in explaining that would be appreciated. What is a \"shortcut\"? Is it a file that is given special treatment like on Windows? Is \"/Applications\" a path on your root drive? Where is Chromium.app located? How is the dmg involved in this?\n\nIt seems that the g++ binary is just a shortcut to Xcode's clang. How can I check it? For some reason the system sees it as an UNIX binary instead of a shortcut, so I can't see where it points.\n\nIs this \"shortcut\" term the same as the one you used earlier? Also how are you checking where things point to? Does the checker you use also tell you where symlinks point to?\n. I'm still alive, I just had other things come up so I didn't get to work on this for a little while.\nI did some inspection of Firefox's .dmg with dmg2img, and I think i have a better idea of how it works now.\n- There's a symlink in the .dmg (which has a space as a filename) that points to /Applications\n- In .background, there's a PNG file that provides the blue background and arrow symbol you see.\n- There's also a .VolumeIcon.icns which apparently is a image file format used on Mac that gives the dmg file an icon (I think).\n- The .DS_Store file defines the positions and sizes of the icons when viewed, and maybe the background image to use. This is what makes the icons look large and in the right positions relative to the background.\n- And of course, there's also Firefox.app which is the directory that gets dragged into the /Applications symlink.\nHere's an example of creating a .dmg that pkg-dmg gives us:\npkg-dmg --source /Applications/DeerPark.app --target ~/DeerPark.dmg\n  --sourcefile --volname DeerPark --icon ~/DeerPark.icns\n  --mkdir /.background\n  --copy DeerParkBackground.png:/.background/background.png\n  --copy DeerParkDSStore:/.DS_Store\n  --symlink /Applications:\"/Drag to here\"\nSince I don't have a Mac, I can't generate all of these files. For now, I can just add a symlink to /Applications so users can drag the Chromium app onto it. If you want to make the installer look nicer, you can provide me a .DS_Store, the contents of .background/, and .VolumeIcon.icns so I can add them in to the dmg.\nIn the meantime, I will fixup the patches so the warnings won't break building.\n. I don't touch any compiler flags related to CPU architecture on Mac, so it's probably building a 64-bit binary. But I don't think the warnings are affected by this, since I build a 32-bit binary on Windows and 64-bit on Linux.\nI can probably ignore the warnings if I tweak some compiler flags in GYP. Apparently they're hardcoded on Mac but not Linux or Windows. I was trying to avoid doing this but it would seem to take more effort given the number of warnings.\n. 3bc83dfe4ae75b98e9410ef58f796b51406f01f9\nI don't remember if we've tried building with Xcode's clang with -arch i386 removed, so let's try that first. If it works, then it would fix that fingerprint issue.\nAlso the new buildlib doesn't require you to set the object attributes if you skip certain functions (if you leave the defaults). Also, the functions don't accept arguments anymore; they are now all object properties. See build.py for more info.\n. Fixed. 6640336360e85a59a3db7f262366596212170096\n. Fixed that and ninja invocation bug\n. 44066c711aa3953cf2e2b3535f5292bf6a85113c\nThat should put the end to these silly errors.\n. Alright I reverted the build script to gcc.\nI did some quick research and it looks like the fingerprint trusting you got is due to the binary's certificate. I don't know if homebrew signs its binaries and if it publishes its certificates used for signing, but you can also create your own certificate and sign the binaries yourself. Do you have to trust the fingerprint every time?\n. cf7bb0c76b52a7754a958d32e79185c92ed894d5 Here's an attempt at trying to fix this.\nI don't like that you have to manually trust the fingerprint each time, so I would like to somehow automate this or fix it. Signing the executable is one method, but it takes several steps and it would have to be done each time the executable changes. Could you describe in more detail how you trust the fingerprint? Is it all done in the terminal, or does some GUI dialog box show up?\n. Oh the fingerprint error was due to svn and NOT gcc?\nThat changes everything.\nThis is really easy to fix. Can you send me the output of svn help co? That way I can determine what arguments I will need to add.\n. d2a01cfee882c72c92247a258347f75a189c5c56\nI'm not exactly sure what compiler flags I can set to fix those linker warnings, so we'll see what happens.\n. Hopefully I fixed it now...\n. > Now it got to build libc++.a, but I had to manually trust the certificates like before.\nThat's strange. I updated the Mac OS-specific patches already so SVN would get --non-interactive --trust-server-cert (EDIT: I mean trust-server-cert) flags in build.sh. Are you sure you applied the updated patches?\nEDIT2: I think I put the arguments in the wrong order. 35ff9cd6591d4f5aca858b60ab29224afcd8e67e. You can ignore the next paragraph unless it doesn't work.\nIf so, that probably means your SVN help is lying to us. Could you try running svn info https://llvm.org/svn/llvm-project twice and see if you have to accept the fingerprint the second time (assuming you permanently accept it the first time)? If you do have to, then try the solutions on this page.\n\nWhy would it stop when building Chromium?\n\nI'm slightly confused by your question. Are you asking why the warnings stop the Chromium build but not the build script for libc++? If so, that's because the build script manually invokes the compiler and has its own set of compiler flags. When building Chromium, GYP and Ninja determine the compiler and the flags to use.\nBy default, the compiler doesn't stop on warnings. But Google made warnings into errors, so it halts building. I tried setting a GYP flag to disable converting warnings into errors, but it doesn't seem to work on Mac OS. So I added a Mac OS-specific patch for a GYP file to disable converting warnings into errors.\n\nGot an error, I think this is the first time we get this one.\n\nYes they seem to be new ones. Though they're quite puzzling. I'm not sure what we changed that is causing these errors...\n. Something is wrong with your url/gurl.cc file. I can see the definitions in the lines specified for the first occurance of every function, but there are no duplicates and your file has more lines than mine. Perhaps your build sandbox has become corrupted?\n. I wonder if we have extra symbols here because we didn't set the proper compiler flags for building libc++.a. Maybe if we tell the compiler to generate object files for the right Mac OS version, the extra symbols will go away? Maybe because I changed the minimum Mac OS version when building libc++.a? I don't know enough about the compiler flags to know how it affects the symbol table, but at least the unordered symbol list is a lot smaller now since we hide certain symbols like Google intended.\nMaybe it will be fine if we skip the symbol order verification, since this is probably a way that Google checks to make sure there's no extra code lingering around or all the symbols they need are present. Here's the Wikipedia page on the symbol table if you are a bit confused as to what is going on.\n8eb490803de53f0e7166224c2740111dde8b539c disables running the verify_order script. You'll need to re-run GYP for this to take effect.\n. > As you can see, it fails to detect that gurl.cc was patched before and then reapplies the patch.\nHuh that's interesting. The algorithms to make patching easier and lazier ends up making recursively applicable patches possible.\nThere's a pretty simple solution to this. I can just create a file in the ungoogled dir (.ungoogled in the build sandbox) that will track what patches have been applied. This is kind of how quilt does it.\nBut I just had another thought. Since we're already requiring Homebrew, we could just ask the user to install quilt via brew (apparently they have it). Quilt will keep track of applied patches (it makes copies of them when they are applied) and there are commands to check what patches have been applied, apply new ones, remove patches up to a certain point, etc.\nI already use quilt on Debian, so this will be a quick change to make.\n\nI can just copy it from the older build, and the average user won't be running buildlib multiple times\n\nI'm actually wondering who the \"average user\" that uses buildlib is. I mean, I already provide binary releases so people won't have to get a decent machine and setup the build environment themselves. Regardless, making the build process user-friendly to development on this project isn't a high priority right now.\nRegarding your second edit on things to improve, I will create separate issues instead of continuing this one. This issue is for getting ungoogled-chromium to build on Mac OS via buildlib, and we've got that to work.\nAnyways, I'm glad we got this to work. Good thing the extra symbols didn't break the build.\n. I've added #34 and #35\n. Huh, I didn't realize there were other ways to detect the platform. But do we need to do this in the Chromium source code? If it can be done via an extension, it would benefit more than those who use ungoogled-chromium.\n. From what I understand, ScriptSafe can deal with this. I don't see any need for ungoogled-chromium to do anything here.. No, there isn't a way to do that. You'll have to remove disable-signin.patch and recompile if you want that functionality.\nIn the future, I will probably add options somewhere to re-enable searching in the omnibox and the automated adding of search engines.\n. Looks good so far. You don't have to work so hard to create a nice volume icon; you can even grab the Chromium logo and use that. The Windows and Debian builds aren't getting anything nearly as fancy as this. Something simple, understandable, and functional will do.\nMinor nitpick: Could you change the text to \"ungoogled-chromium\"? It looks weird to me when the \"u\" is capitalized and the hyphen is removed, haha.\n. If someone wants to submit a PR for this, feel free to do so.. I almost forgot about this issue.\nI don't have a Mac to play around with, so it'll be hard for me to figure out how the UI corresponds with source code. If someone has some knowledge that can enlighten us, or wants to make a pull request, that will help a lot.\n. @probonopd Can Chromium even build on those platforms? Do your Chromium AppImages run on those systems? Are there enough people that use distributions that old?\nThis is a good idea, but it will take quite a bit of work. The Debian and Ubuntu package building process is based off of Debian's build of Chromium, so it has more system dependencies than Google's build of Chromium. This includes building with the system's Ninja builder, clang compiler, and linking against the system's FFmpeg libraries (which are all sensitive to the versions, except maybe Ninja).\nIf we are to get this work by modifying the Debian build process, there are several things that will have to be done. The meta-build configuration flags and patches to work with system libraries will have to be removed/disabled, the buildtype might need to be switched to Official, and some tools or scripts that have broken as a result of domain substitution or source cleaning will have to be provided or fixed in some way. If we are going to get this to work on Debian Wheezy or Ubuntu Trusty, some things might break beause the tools on those systems are pretty old.\nUnfortunately, I don't have enough time to execute what I've just stated. I am planning on upgrading these patches to the latest version of Chromium, and I have priorities outside of this project that are taking up my time. However, I will have some time to provide help and implement a process into buildlib. So if anyone wants to take up the task, go right ahead.\n. @probonopd Well those seem to be the earliest versions that Chrome supports, so I guess it can be done somehow.\n. #41 made me realize that my approach to this problem was wrong. I was too narrowly focused on modifying the Debian build process to realize the approach described in #41 would be better.\nOnce #41 is done, adding support for AppImage should be relatively easy.\n. @sahal2080 You have some solid reasoning. That may not be a bad idea.\n. @probonopd I haven't tried it yet, but I've had this concern in the past.. @Swiftpaw @probonopd Hey guys, please stay to the original topic of adding Flatpak or AppImage support. (Adding support for both will be fine too).. I will accept a pull request to add Flatpak or AppImage support (or both) into utilikit. Chances are you'll need a configuration type like linux_conservative and new build types for the build files generator.. Things have changed for version 64. One can use the linux_portable base bundle to build, and then add new packaging types for Flatpak and AppImage.\nThe existing packaging types are pretty simple and should work as a good reference for these ones. If anyone is interested in this, feel free to submit a PR.. @probonopd I have implemented a new packaging system (in the redesign branch) that is simpler and more straightforward. In the next few days, I will be working to merge it into master and then begin updating to version 68. If you are willing to wait, it should be easier to work with the new system.. @probonopd 68 is out now. You can have a look at the tar building instructions as a reference for your packaging scripts. The design doc's packaging section also changed a bit to reflect the new design.\nLet me know if you need clarifications.. @probonopd I don't believe it is necessary with linux_portable config bundle to build against the oldest Ubuntu version in order to maintain compatibility.\nThat being said, LLVM provides APT repos all the way back to Trusty. The package names for those tools seem to be the same. I'll add this into the instructions for convenience.. @probonopd \n\nUsing Python 3.6 (the newest one I can use) seems to remove that error\n\nI developed the code on 3.5 (the only Python 3 available in stretch), so 3.5 is the minimum. Using 3.6 shouldn't hurt, though.\n\nSyntaxError: unqualified exec is not allowed in function 'CallPythonScopeScript' it is a nested function\n\nI have seen this error once before on an older CentOS 7 machine. At the time, I didn't have much time to investigate.\nAfter reading around a bit, there may be some differences in how exec is implemented in different Python 2 versions.\nFrom the latest Python 2 docs (2.7.15 at the time of writing), it is supposed to work:\n\nThe first expression may also be a tuple of length 2 or 3. In this case, the optional parts must be omitted. The form exec(expr, globals) is equivalent to exec expr in globals, while the form exec(expr, globals, locals) is equivalent to exec expr in globals, locals. The tuple form of exec provides compatibility with Python 3, where exec is a function rather than a statement.\n\nBut, I keep seeing reports of people explicitly rewriting the exec function-like syntax into the old statement form. It might be originating from this bug, which was fixed in 2.7.9: https://bugs.python.org/issue21591\nDebian stretch ships with 2.7.13. What version of Python 2 are you using?. @probonopd Should be fixed in 674540188d48d997ea4bb02d0f19621743f64b29. @probonopd In that case, you may want to do what Arch Linux does for Python 2 on these lines:\n\nhttps://github.com/Eloston/ungoogled-chromium/blob/821a4414a892472eebfdcf648a025519a1458cb1/packaging/archlinux/PKGBUILD.ungoogin#L130\nhttps://github.com/Eloston/ungoogled-chromium/blob/821a4414a892472eebfdcf648a025519a1458cb1/packaging/archlinux/PKGBUILD.ungoogin#L84\n\nOut of curiosity, what platform are you building on that has python as Python 3? I thought you were building on Trusty?\n. @probonopd The Python issue may be because you specified \"3.6\" on top. Maybe you could specify \"2.7\" and then install 3.6 after the fact via apt so that python becomes Python 2?\nHowever, you seem to be trying to fit an elephant in the room by building the source code in Travis CI. It is something we investigated in #37 and it definitely won't work (Chromium's build process is too computationally demanding to be willingly built for free by most service providers). So you'll either need to pull from ungoogled-chromium-binaries for new Portable Linux binaries, or delegate compilation to a willing third-party service.. > Where is it compiled, where are the build logs, etc.? It would be most likely really trivial to hook in AppImage generation into the existing pipeline in this case.\nI like your approach of learning backwards (i.e. from the implementation back to the design, like I do for Chromium), but I have design docs so you don't need to do this. Have a look at the design doc section for packaging to get an idea of this part of the process. Also, have a look at the README for ungoogled-chromium-binaries to see what it's all about.\nFrom those, I think we can figure out a workflow that suits us both.. > are you saying there is no CI build pipeline (Jenkins, GitLab CI, Travis,...) and project members/you are building on local machines?\nThat is correct. For some background, I have declined offers in the past for dedicated building hardware because I did not want to handle that kind of responsibility. I also did not want others to feel obligated to provide the hardware either. It was a questionable perspective in hindsight, but that's where we are at now.\n\nIf so, what kind of local machines (which distribution)?\n\nThe latest versions of Portable Linux were built on the same machine I use to build Debian stretch packages. I don't know what compatibility is like on very old or new distributions, but no one has reported any issues of that nature.. > So, essentially if I write a bash script that takes the Portable Linux build and turns this into an AppImage, that's all you'd need?\nYep. I'm thinking that we can add a script like package_appimage.sh into linux_simple that runs after build.sh to generate the AppImage (and rename package.sh to package_tar.sh to prevent confusion). This way, we can generate multiple different packages directly from the build outputs.\nFYI I'm not sure if you will need this, but the buildkit command filescfg list (which uses filescfg_generator() in buildkit.filescfg) will list out only the files needed to run Chromium.. @probonopd Two potential issues:\n\nYou have written quite the shell command to determine the Portable Linux binary to download, but it's assuming that I will be the uploader. This will fail if someone else uploads a Portable Linux binary.\nThere is a slight branding change of the browser. I'm guessing this is unavoidable because of the nature of AppImages (e.g. a user has a real Chromium AppImage side-by-side with an ungoogled-chromium AppImage). If this is not the case, then I'd prefer if the change were reverted.\n\nEverything else LGTM.. @probonopd \n\nHow can I find the URL to the latest version? Do you have a permalink URL that redirects to the latest, for example? We could also change it so that instead of downloading something it copies in some local deb, but for that we would at least know the name and location of that deb.\n\nUnfortunately, there's no way to create a permalink using only GitHub Pages. I haven't really thought of using one before, so I never looked into it. Do you happen to know of any free permalink services that are simple enough to be updated via CI?\nThe other alternative would be to parse the INI file, but that won't be trivial with just shell commands (it's already hard enough to get the version to use).\n\nwe need to somehow distinguish it as something different from upstream Chromium. Please keep in mind that users may have multiple versions of Chromium on their machine, both Ungoogled and upstream\n\nI see. Thanks for confirming my suspicions in the previous message.\nIn that case, we can just leave it alone. But for aesthetics, could you change it to \"ungoogled-chromium\" or \"Chromium (ungoogled)\"? Seeing it as \"Ungoogled Chromium\" looks a little weird to me.. @probonopd \n\nWho else could be the uploader? And where would those files be hosted? Can the name of the uploader be determined dynamically? How?\nI have not quite understood what the problem is in the current method of getting the most recent available *_linux.tar.xz. Can you please elaborate and describe the optimal strategy? Thanks.\n\n\nEvery published version of 64-bit Portable Linux binaries are defined in ini files under config/platforms/linux_portable/64bit. Each ini file contains file names (in section headers, excluding the designated section for metadata), the hashes of said file, and the URL for retrieving the file contents via an HTTP GET request.\nAdditionally, each INI file represents a separate page with file links that you see on the downloads page. For example, 67.0.3396.87-2 for Portable Linux 64-bit has its INI file defined in config/platforms/linux_portable/64bit/67.0.3396.87-2.ini.\nBecause the version of each download is defined by the ini file name, config/valid_versions defines all valid published versions to prevent typos in the file names and define the ordering of versions. You could use this to determine potential INI file names.. @probonopd At that rate you might as well do a shallow clone of the ungoogled-chromium-binaries repo. That way you can use standard shell commands to sort the ini files in there, pick the latest one, and read it. Unless you're up to parsing generated HTML.... Well, AppImage suppport is in now. Thanks @probonopd for implementing it.\n\nIf anyone wants to add Flatpak or Snap support, please open separate issues for them.. @intika I don't have any plans to do it. If it's appropriate to do so, then I'd be willing to merge a PR.. @probonopd Why must I be the builder and publisher of the AppImage? Can't anyone do it?\nIf all it takes to be \"official\" is be on ungoogled-chromium-binaries, i.e. the \"contributor binaries website\", then I fail to see the reason. Also, I will be a bottleneck if I have to maintain binaries.. @probonopd Who's to say I'm more trustworthy than any other contributor here?\nI believe that everyone who has been contributing binaries are doing so out of their own good will, mainly because of the following factors:\n\nThe target audience of this project is relatively small (technically-able and privacy-conscious)\nThis is still a relatively small project within that target audience\nThe effort to produce malicious binaries is pretty high compared to any rewards from malicious intent I can think of.\n\nOnce binary reproducibility becomes a reality, then we could go by independent replication of the build process to verify if the binaries are valid. It's not as good as understanding and building the source code by oneself, but at least the trust is more distributed rather than centralized on single individuals.. I like the idea, but I don't have time to maintain a PPA manually. If this can be automated in some way, I would like to hear it.\nIf you or someone else would like to maintain a PPA or repository, go right ahead. I can add a link to it from the README.\n. Well the link you provided basically says that a CI can push packages to a PPA server, which means that I would need to figure out how to use Travis CI (or some other CI system) and find a server to host a PPA.\nThat sounds nice, so I might look into this in the future when I have more time.\n. @hrj: I'm not sure if I trust Travis CI enough to give it the public_repo permission to this account. But what really bugs me is that they telll you to use their magic command travis setup releases that obscures how things are setup:\n\nInstead of setting it up manually, it is highly recommended to use travis setup releases, which will automatically create a GitHub oauth token with the correct scopes and encrypts it.\n\nI could make another GitHub account that mirrors this repository and integrates with Travis CI, but that would require me to manage another GitHub account on top of Travis CI. Though this option seems more appealing the more I think about it.\n. @hrj: I'm pretty sure you have to own the repository. I'm a collaborator on another repository (with write access), and I couldn't get Travis CI to see it.\nFortunately, there are commands in git that make it easy to mirror a remote repository. Here's GitHub's documentation on them. This way my dummy account can be separate from this account.\n. @hrj: Huh, looks interesting. That would solve the hassle of setting up a separate account.\nI'm a bit worried about the build environment they provide us. They allocate 7.5 GB (since I have to use a Docker image of Ubuntu Xenial), which might be enough to link if I set the right flags. However, I'm not sure how much disk space they allocate -- my whole build directory is taking 4 GB, which is pretty small by Chromium standards. Also, I'm not clear what Travis considers a \"job\". From what I've read, a single job can only last for about 50 minutes maximum (assuming it prints output at at least 10 minute intervals), but the build can take as long as it needs to. Are jobs the processes Travis directly invokes? Does this include subprocesses? Threads? A build takes about 3 hours, so the definition is pretty crucial.\n. @podshumok Good to know. I might consider it if Travis doesn't work out. Would you mind linking some documentation to do this? Thanks.\n. @podshumok Alright thanks.\n. I'm not quite sure how APT or PPA repos work, but are they basically retrieving files from a web server? If so, it may be possible to generate these files and upload them to the GitHub pages repo of the downloads repository.. @craft37 Thanks for that link. This is what I was curious about earlier, and it seems it is possible. We can work on integrating this approach to the new WIP downloads system in the future.\nIt is unfortunate that PPAs are tied to Launchpad, but there's no significant benefit of also having a PPA.\nEDIT: Although I have no interest in mantaining a PPA, I will allow someone else to maintain a PPA for this project. However, this should wait until we have figured out the details of the downloads system.. @message \n\nbut there's no significant benefit of also having a PPA.\n\nBolded for emphasis.\nEDIT: I should clarify that \"but\" makes the statement confusing. What I mean to say that there's no need to have an APT repo AND a PPA.. @mtimofiiv Travis is not designed to compile Chromium. No free system out there that I know of will like people using their services to build Chromium.. @sixtyfive If it's related to my open-source projects, I prefer public communication. Otherwise, you can direct message me on Gitter (there is a link to Gitter from the README).. One hacky method to accomplish this is to setup a flat APT repo in GitHub Releases of the https://github.com/ungoogled-software/ungoogled-chromium-binaries/ repository. Each distribution and version combination (e.g. Debian Stretch) will have its own release (e.g. debian_stretch). Then, a script can be used to update any GitHub release with new APT repository info.. @T-vK I wouldn't mind this for the upcoming linux_portable config type; you could build it once then package using linux_simple (for a .tar.xz) and Debian minimal (for a .deb).\nRight now, there are some rough edges around the build and packaging processes for those types I listed, so I'd hold off if your goal is to make something that can build releases right now. I'm going to be making some changes which may break some scripts you would write.\nHowever, it wouldn't be a bad idea to see if GitLab CI can actually build ungoogled-chromium from a computational resources point of view. If you're curious, you can try it out and let us know how it goes.. @T-vK Oh, neat. Kinda sucks the log got truncated, though.\n\nIs there a way to make the build output less verbose? Maybe don't display warnings, only errors?\n\nThe only way I know of is to patch out the unimplemented warning options from GN files. I'm not really sure if there's a way to exclude warning output altogether.. Nice @T-vK. Is it possible to trigger the build when a new tag is pushed?\nAlso, is there some way for this to integrate with a PPA or APT repo? If not, we should move this discussion elsewhere.. @T-vK Thanks for all the work. Due to the build artifact restriction, I think it would be better to just build a .tar.xz of linux_portable because there's not enough capacity to store different packages.\nDebian source packages are pretty straight-forward. Basically, it consists of a .dsc, a tar of the original source code, and a tar of a debian directory (or a compressed patch file that adds the debian directory). They're the same files you get when you want to build any Debian package. I was thinking about adding a packaging method for it to fix #20 at some point.. @T-vK To clarify, I mean building different types of packages, such as .deb, .tar.xz, or even AppImages and Flatpacks from the same build output. But since a single packaging type is about 50 MB, that isn't feasible.. @T-vK \n\nwe could for instance first do some compiling in the before_script and then have multiple packaging jobs that create different packages.\n\nI wasn't aware that was possible. If all the compiling of linux_portable could be done in before_script, then that would save a lot of hassle of packaging that same binary in multiple different formats.\n\nI tried to build the linux_portable btw and it failed\n\nYou mean you failed to generate the packaging scripts for Debian minimal? That's expected. To clarify, linux_portable is a configuration type (soon to be renamed to base config bundle; more on that after I finish writing buildkit along with the documentation), which is separate from packaging types.\nYou should be able to build linux_portable base bundle with linux_simple packaging type with 1ff74286a677ed865b2dd46d1eec98cb8a46b077. Preliminary instructions are here; note the typo that UTILIKIT_CONFIG_TYPE=linux_simple should be linux_portable.. Are you reading General building instructions under Building generalizations and additional information? You don't need to read that; I linked the Other Linux distributions section which is above all that. The section ends at the line \"where OUTPUT_FILE is the path for the new archive\". It's understandable if you find the documentation confusing; I'm rewriting it along with buildkit.\nI took a look at the GitLab CI documentation, and I think I'm starting to understand what you mean by \"before_script\" and \"jobs\". So here's a rough pipeline for building and packaging linux_portable:\n\nInstall all build dependencies in before_script or have it installed in a pre-built Docker image (as you have suggested).\nIn the Build stage, there is one job that downloads and builds the code, and packages the necessary files into a .tar.xz. The .tar.xz will be the build artifact for this job.\nIn a Packaging stage, there can be multiple simultaneous jobs that repackage the xz-compressed tar archive into different formats; e.g. AppImage, Flatpak, Debian packages\nNote that both standard and minimal flavors build and package with the same command. I think there may be a way to tell dpkg-buildpackage to package only\n\n\n\nThen all of the packages, including the .tar.xz, can be artifacts available for download.. > Okay. For step 2, what are the \"necessary files\"?\nI should've been a bit more clear: only the necessary files for running Chromium need to be passed from the Build stage to the Packaging stage. The goal of the build stage is to download all the code necessary to build ungoogled-chromium, and produce the final binaries and supporting files. The goal of the packaging stage is to produce different formats of said binaries and supporting resources to give users options.\nTo be more specific, here are the steps that can be performed at various stages (these are untested and may have mistakes):\nHere's a hack to ensure all the proper requirements are installed in before_script:\n```\nexport UTILIKIT_CONFIG_TYPE=linux_simple\nConverting the standard flavor into minimal because it saves the hassle later.\npushd resources/packaging/debian/standard\npatch -p1 < minimal.patch\npopd\ntmpdebdir=/tmp/tmpdebdir\nmkdir $tmpdebdir\n./utilikit/generate_build_files.py --output-dir $tmpdebdir debian --flavor standard --apply-domain-substitution\nprintf \"y\\n\" | mk-build-deps -i $tmpdebdir/debian/control > /dev/null\nrm -rf $tmpdebdir\n```\nHere's what can be done in the Build stage:\n```\nexport UTILIKIT_CONFIG_TYPE=linux_simple\n./utilikit/prepare_sources.py\n./utilikit/substitute_domains.py\n./utilikit/generate_build_files.py linux_simple --apply-domain-substitution\ncd build/sandbox\nUse \"export CLANG_BASE_PATH=/path/to/clang_files\" if Clang and related files are not located under /usr\n./ungoogled_linux_simple/build.sh\n../../utilikit/archive_packager.py --files-cfg chrome/tools/build/linux/FILES.cfg --archive-format tar_xz --build-output-dir out/Default --target-cpu auto --output-file $OUTPUT_FILE\n``\nwhere$OUTPUT_FILE` is the build artifact for the only job of the Build stage.\nI don't know how to create Debian packages from the .tar.xz, but maybe something like this could work?:\n```\nexport UTILIKIT_CONFIG_TYPE=linux_simple\nsandboxdir=/tmp/debpkgs/sandbox\nI'm assuming the conversion from the standard to minimal flavors was preserved from before_script\n./utilikit/generate_build_files.py --output-dir $sandboxdir debian --flavor standard --apply-domain-substitution\nmkdir -p $sandboxdir\npushd $sandboxdir\nmkdir -p out/Default\npushd out/Default\ntar xf /path/to/build_artifact.tar.xz\npopd\ndpkg-buildpackage -b -uc -nc\n```\nand .deb packages would appear in /tmp/debpks, maybe. You might need to do some experimentation with dpkg-buildpackage if that doesn't produce binaries.\n\nI tried it on the latest develop branch and it fails. Any ideas? https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/47967733\n\nIt seems that Python is having some troubles identifying the correct encoding for a file. I'll have to look more into it later. If I don't get buildkit done soon enough, I might push a fix for utilikit in the meantime.. Hm, it seems the patch will need to be updated. Not sure why it failed in the first place.. @T-vK  I shall bring your attention to https://github.com/Eloston/ungoogled-chromium/issues/37#issuecomment-357693096:\n\n\nI tried it on the latest develop branch and it fails. Any ideas? https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/47967733\n\nIt seems that Python is having some troubles identifying the correct encoding for a file. I'll have to look more into it later. If I don't get buildkit done soon enough, I might push a fix for utilikit in the meantime.. @T-vK I got caught up with some stuff that pushed back work on ungoogled-chromium. I have finished designing buildkit, so I am currently implementing it.\n\nAlso, I have decided that all patches should be encoded in UTF-8. I'm guessing that all patches are already in UTF-8, so you can try 1f8f80e3221fc09a5dbe903e3c2f57454d316d4b and see if anything breaks.. Is there no series file in ungoogled_linux_simple/patches?. export UTILIKIT_CONFIG_TYPE=linux_simple\nlinux_simple is not a valid config type. Do you mean linux_portable?. Depends on your system. Debian places LLVM 3.9 files under /usr/lib/llvm-3.9. Hmm, there are two problems that'll need to be sorted out:\n\nWe need a command that invokes the \"install\" step of debhelper and beyond to produce packages, not try to attempt the \"build\" step.\nSome files are being copied/moved around in the \"build\" step before packages are created (presumably in the \"install\" step), so these commands will need to be moved out of the \"build\" step to before packaging files are collected but during the \"install\" step.\n\nI think I have an idea for Problem 2, but I don't know enough about the Debian packaging system to attempt Problem 1.. @dannycolin Thanks, but the issue isn't information, it's time. If someone already knows how to do this, it'll save some time.. If someone here wants to get a PPA for Ubuntu, it may be possible to build a source package with dpkg-source -b tree (if running within buildspace) and then upload the generated files to Launchpad to build. The code in develop should be working right now.. @T-vK Please read DESIGN.md in develop. If it's unclear, we can discuss that in a new issue.. @T-vK Please try f031462978e20edff44079f7c5313357d22fd759 and see if you can get more information.. @T-vK I fixed the buildspace tree problem in 4e3a14bad67a51bf2631513edc4fc1eb4c6b6bbf\nBased on your error, it seems that dpkg-source -b doesn't work. Anyone have ideas?. It seems that the debian folder format I'm using (i.e. 3.0 (quilt)) requires a orig tar file to already be present: \nFormat: 3.0 (quilt)\n       Supported since dpkg 1.14.17.  A source package in this format contains\n       at least an original tarball (.orig.tar.ext where ext can be  gz,  bz2,\n       lzma  and  xz)  and  a  debian  tarball  (.debian.tar.ext).\nWe could add a custom target to debian/rules to accomplish this I believe (similar to what the official Debian chromium package does) but we would use the contents of buildspace/tree excluding the debian directory.. @T-vK That's not really a huge problem. If PPAs are the main interest for this issue, then the refactoring of Debian packaging after #367 will make it possible to offload the compilation to Launchpad.. It's finally here. I haven't tested this yet, so I don't know what will happen.. I have fixed source package generation as of 9178feeb6f075611d312d3792882fbc0abc33636. Extraction via dpkg-source -x also works.\nI don't have the time to build right now. Anyone want to try building? Maybe uploading them to Launchpad?. @T-vK \n\nI'll try. https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92052639\nLooks like the build worked: https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92052639/artifacts/browse/build/\n\nI don't seem to have permission to view them?\n\nFirst of all Launchpad seems to want a PackageName_Version_source.changes file which doesn't seem to get generated during the build process.\n\nI did some research, and it seems that .changes files can be generated by either binary or source package generation.\nAccording to Ask Ubuntu, it seems we want to replace\nsh\ncd ..\ndpkg-source -b -uc\nwith \nsh\ndebuild -S -sa\nYou'll also need to setup a GPG key so that the debuild command can sign the files. I don't know how to do this yet. Another thing to note is that you may need to modify debian/changelog so that a corresponding GPG key is chosen for signing (which I'm guessing based on the above Ask Ubuntu link).\n\nAnd secondly they are talking about an ubuntu suite in the documentation without explaining what the hell that is supposed mean.\n\nIn Debian, suites and codenames are separate concepts. In Ubuntu, suites seem to be codenames according to packages.ubuntu.com (notice the top of the webpage: Search in specific suite: [trusty] [trusty-updates] [trusty-backports] [xenial] [xenial-updates] [xenial-backports] [artful] [artful-updates] [artful-backports] [bionic] [bionic-updates] [bionic-backports] [cosmic]).. @T-vK \n\nIn the building.md under Building via source package you say dpkg-source -b src. Is that what I should replace with debuild -S -sa?\n\nSorry, I made a small typo in my comment; dpkg-source -b -uc is supposed to be dpkg-source -b src. But, the intent remains the same; the commands cd .. and dpkg-source -b src should be replaced with debuild -S -sa.\n\nI already have a GPG key that I generated some months ago and added to my launchpad account. I guess I'll have to dig out the private key again if we need it outside of launchpad.\n\n:+1: \n\nThanks for digging out the information on the suit thingy. I was not able to find that. I guess I'll just put in stretch then if I want to build for Debian Stretch?\n\nAccording to the Launchpad docs you sent me:  You can upload a source from any Debian-compatible distribution straight to your PPA with no changes required and it will be built and published in the targeted Ubuntu suite.\nIf you want Debian packages, you might have to send it to something like the openSUSE Build Service, since they seem to provide an APT repo.\nIf we are okay with abusing git and/or potentially using Git LFS, we can do something like the following:\n Create another repo under ungoogled-software like ungoogled-chromium-apt that will hold only one commit with the binary and metadata files needed by APT.\n I can create another account that has write access only to ungoogled-chromium-apt that is accessible by a CI system (CI systems have a way to hide credentials from the public)\n* Trigger the CI system via changes in ungoogled-chromium-binaries, and activate a script I can write that detects any changes to binaries for Debian-based systems and push only what has changed to ungoogled-chromium-apt.\nGranted this will take a little bit of time to implement, whereas OBS already solves this APT repo hosting and has the added benefit of building the packages for us.. @T-vK I made a small tweak to Ubuntu bionic packaging that affects the resulting package name: 0e1461ec690a0559fc8a045372423205356a1ad5. @T-vK \n\ndpkg-source: error: cannot represent change to ungoogled-chromium-browser-build-deps_68.0.3440.106-1~buster_all.deb: binary file contents changed\n\nIt looks like you used mk-build-deps to install the build dependencies, but forgot to remove the resulting .deb package.. > I'm getting a lot of these:\nNot entirely sure, but a lot of it is due to minified JS causing the column length check to go crazy. Are those files actually missing though?\nBut this one is interesting: E: ungoogled-chromium-browser source: uploader-address-malformed Maintainer <maintainer@null>\nThis may be causing a problem for the second problem you described with No such file or directory if a file fails to be generated as a result. Hopefully I fixed it in 23ebfe4ba694e61fc179edae79dcb7685d951e6d\nOn a tangential note, I'm surprised at how deep the checks go; they reported spelling errors in patch descriptions and an old URLs in debian/control.. @T-vK Sorry for the delayed response. Are you able to get more details on that error? The CI job doesn't show where in the make target get-orig-source failed.. @message Thanks! I think it's nice to see progress on an issue that could've otherwise been forgotten. Do you have something you want to contribute?. @T-vK Could you add -d flag to get-orig-source so that it becomes: debian/rules -d get-orig-source\nEDIT: FYI, this enables debugging info for make files.. > The file ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc seems to be missing:\nTry adding your signing identity to the debian/control file as well.\n\nedit: I couldn't find the location of the third_party directory. Do you know where it is?\n\nThere are multiple, but the most commonly used one is the one at the root of the Chromium source tree.. Could you try replacing debuild -S -sa with debuild -i -S?. Well, I'm out of ideas now. If I figure something out, I'll let you know.. > I mean the error message does say source-is-missing , but at the same time it's talking about the line length of that file\nThe file isn't removed by ungoogled-chromium commands, and I don't see any reference to it or its parent directory (third_party/analytics) within the debian directory either. It is also present in a fresh unpacking of the Chromium source tree.\nHowever, it is domain substituted, which may cause the minified file to have lines that exceed 512 characters. But, I think it's more likely that it's normal to see these particular warnings since Chromium has minified files scattered about in the source code.. > Weird, I guess it's only temporarily being unpacked during the debuild command then?\nI'm not sure. Maybe it's being removed by debuild through some automatic filtering?\n\nBut I don't know...\n\nMy guess is that some file or tool required by signing isn't present, and the standard \"no such file or directory\" error is being propagated up without any context. I've seen this happen a few times in completely different situations, so it may be the case here considering the dsc file is present in the location given.\nIf that isn't the case, then it may be some sort of procedural error where the temporary directory is removed before it has finished using the files.. @mildfuzz Well that's assuming the webpage author doesn't abuse it, or the webpage doesn't keep repeatedly prompting dialog boxes. Your text editor is an application that you have more control over, so you can choose one that has a good UI.\nI get that you're trying to reduce some patching work, but I still find this a useful feature.\n. @mildfuzz Well your wish came true. Chromium now has a feature to hide dialog boxes on certain webpages that keep showing up, so it seems redundant to block beforeunload JavaScript dialog boxes.. It doesn't seem anyone cares about popups being forced into tabs, so I'm going to close this. If someone does care, let me know.. Technically you don't need it if you do not run domain substitution, but that should fix it.\n. The Xcode you updated to is 8.0, right?\nThe files in the error messages reside in /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk. Do you have a MacOSX10.11.sdk directory or something similar?\n. I checked the Chromium instructions, and they don't say anything about Xcode 8. The latest instructions say it supports \"7.3+\", but nothing about 8.0. The instructions for the version we're building with say \"5+\", but I think Google's build bots are running 7 already. I also tried Google searching, and I haven't seen anyone post issues with Xcode 8.0 and Chromium.\nI guess we're entering uncharted territory.\n. I'm not understanding how you installed the 10.11 SDK. Do you just drop the directory into that path? Are there some commands you run to set the default SDK? I'm wondering how Chromium knows which SDK to choose...\nI made that commit earlier hoping that Xcode 8.0's clang compiler included with the 10.12 SDK would be able to build Chromium without a hitch. I believe we've tried to build Chromium with the 10.11 SDK to no avail...\n. > Was there any change related to bluetooth and Macs in this version of Chromium?\nSeems like it. I inspected my build outputs on Debian, and it seems I'm using libstdc++ (GNU's implementation of the standard library), whereas you're using libc++ (LLVM\"s implementation of the standard library). We're both using Clang 3.8, but I guess the Chromium code changes don't like your version of libc++\nCould you pull in the commit to use Xcode's clang and try re-building? I want to avoid using Homebrew's LLVM altogether.\nEDIT: Could you also remove the 10.11 SDK? I would like to see what happens if Chromium tries to build with the 10.12 SDK\n. This error is really interesting, since it's the same file on the same line causing an error, but it's a different error this time :/\nIn build/common.gypi, line 5264 (or somewhere around there), could you change 'CLANG_CXX_LIBRARY': 'libc++', to have libstdc++ instead of libc++? This may be a terrible idea, but so far libc++ is not getting us anywhere with Homebrew's or Xcode's versions of them.\n. > Relevant information: I tried to build it with homebrew's clang... and got the same error. Doesn't seem to be a problem with Xcode.\nIn here, you got a different error with the same file. It looks like it trips up both LLVM 3.8 and Xcode.\n\nWhat SDK does Google use?\n\nThey use their own LLVM version between 3.9 and 4.0 I believe. We might get past these errors if you use Homebrew to install the latest revision or use a specific revision that's new enough. If they made some modifications to LLVM, then we may be out of luck.\nAlso I did more research and switching to libstdc++ was a pretty bad idea. Apple doesn't seem to provide updates to that library anymore.\n. > Unfortunately, it seems Xcode 8.0's CLT got released for Sierra only so far. Maybe an El Capitan version will appear next days.\nWow, that's frustrating. I wonder why they even bothered to release any Xcode 8.0 components for El Capitan if they're not all ready yet. There's no information on when the tools will be released, so we'd have to wait indefinitely.\nIf you want, you could try downgrading to 7.3 and use Homebrew's clang. Though I'm not sure if this will impact the errors we get with bluetooth_remote_gatt_service_mac.\n. Alright sounds good. If you get this to work, let me know where clang lives so I can update the GYP flags and buildlib accordingly. BTW, are you going to install LLVM from homebrew-core, or wait for homebrew-versions to update? I'm wondering if using the one from homebrew-core will remove the use of the version number in the path.\n. generate_build_configuration() is what reads the GYP flags (gyp_flags files) and runs GYP. setup_build_utilities() doesn't actually do anything at the moment (it will build GN in the future). So you should be good to go.\nI'm glad to hear that it got past the bluetooth error. Hopefully this is all that we needed to do...\nEDIT: I should note that GYP generates ninja configuration files, so ninja should be able to detect the changes and only rebuild the necessary components.\n. f006c7c10e5e0becd1758574025fff206280e75a. Run generate_package() only to test package building.\nI'm not sure what's causing the verification popup. Maybe because it's not installed in /Applications?\n. > Perhaps its a good idea to include downloading LLVM 3.9 in this, instead of using Homebrew's?\nSure. I'll look into implementing this.\n\nAlso, another question. How Chromium defines the locale of search engines? Ask's and Yahoo's searches point to my country's sub-domain.\n\nThrough files in multiple locations; see this patch for an example.\n. > Now it builds the damage\nI hadn't realized you hated dmgs that much ;)\na6253c69e8c0d46e4b835fc8512924ef6c6041d8. Now LLVM is exactly where Chromium expects it to be.\n. Actually I kind of want to resolve #42 before I upload a new version. But thanks for the build anyway.\n. This is not the best way to create a portable Linux version. The Debian and Ubuntu versions include additional patches (from Debian's chromium-browser source package) that depend on system libraries. If you moved this to a non-Ubuntu Xenial system, like Ubuntu Trusty, Debian, Arch, Fedora, etc., you will probably run into library problems.\nThe best way is to create a build the way that Chromium normally does it, which is statically compiling the libraries in. This is how Google makes Chrome distribution-agnostic.\nI just realized that this issue is pretty similar to #36, but this one is of broader scope. I will modify these issues to make them more distinguishable.\n. @triceratops1 Sorry, I'm not quite understanding what you want me to do with that link. Did you mean to post this on #44?\nEDIT: I just realized that #44 was created after your comment. That package building script doesn't really help too much since it just unpacks a pre-built binary, not building a statically-linked library like I suggested.\n. Just to let everyone know that the code to attempt a static build has been implemented in buildlib for a little while now. If anyone wants to attempt it and report back, go right ahead.\n. @9Morello: Sure. I saw you error over in the other issue, so try this out: a81d8e5fa90238ba978100c36fa19afe70b729e5. @9Morello If there were going to be Debian packages, they should be in the build directory. But the Linux static builder doesn't have a packaging system yet, so the binaries should be in the build/sandbox/out/Release directory for now.\nEDIT: The Linux static builder is ment to be a binary for any Linux system to use, so I will probably .tar.xz the binaries up.. So the binary doesn't run then? That's weird. It should return an error if it didn't build correctly.\nRegarding your new error, you might have to install libgtk2.0-dev. @9Morello Neat! If you haven't deleted it already, could you try the binaries on 14.04? I want to see how portable the binaries really are. The files you need are listed in chrome/tools/build/linux/FILES.cfg. @9Morello I just pushed a .tar.xz packaging support for Linux static builds in ad9c5b3bf77eb1475239d034c819a655995a7efc. If you could test out the 14.04 build with this that would be great. If you've already started the build, you don't need to re-run GN or anything since it doesn't change those parts of the code; you can just halt the compilation, pull, and restart the build command.. @9Morello Whoops I forgot to tell people that I'm upgrading to version 55 since I found out it was released yesterday. Right now master is broken since I only updated a few patches. I should really create a separate branch for development...\nRegarding your error, this might be due to some flags I have set so I'll need to try tweaking them.. (For reference, see the answer to @9Morello's question here)\nOnce the Debian build works, we should be able to start working on this again.. @9Morello Okay, beb4b62aac08ffc99cc86b3fac8358d5ecc2db13 is out. I tweaked the GN flags for Linux static builds, but I'm not sure if it will work.. @9Morello Yes, it is meant to be tested on both.. @9Morello d594cdfd857347dca39952250b53bb1d1f27a334 tries to tweak the GN flags more. Make sure you move build/sandbox/out/Release to build/sandbox/out/Default before running the build again. You should try running build/install-build-deps.sh to install some system dependencies (EDIT: You should set the command line flags so you don't install 32-bit libraries or install NaCl dependencies and others)\nIt seems that even Google doesn't actually have a static Linux build. I guess we have to try out what's suggested in the first post here or use this to create a portable version. This means that we need to build on Ubuntu 14.04 in order to achieve maximum portability.\n(FYI, this commit doesn't fix that macOS problem yet). @9Morello Regarding your install-build-deps.sh error, did you try passing it as an argument to bash? It should be using bash because of the shebang if you're invoking it like a local executable file though.... @9Morello It tries to use clang regardless of the flags huh? I guess it's the default now.\nThe reason I disabled the flags is I wanted to mimic a build setup like what Google uses. Since clang isn't happy, you could try adding only is_clang=true and clang_use_chrome_plugins=false in addition to what I already have (i.e. is_official_build=true). @9Morello Well it's nice to hear that it works with the old flags. I'll probably just have three flags to play it safe. Did you say you're running it in a VM? What VM hypervisor are you using? VirtualBox, VMware, or something else?. @9Morello VirtualBox on macOS? Well in any case, I know that 3D acceleration is a bit unstable and experimental. 3D acceleration with a Linux host and Windows guest is useable if the video drivers on the host are decent enough. I'm not sure what 3D acceleration is like with a Linux guest, much less on macOS.\nWell since you compiled with clang, I think the build should be fine. This is still on 14.04, right?. @9Morello I guess it wouldn't hurt to try.. @9Morello It might. I know that the creation of an AppImage for Chromium bundles some additional system libraries. Though it should work on all of the distributions that Google says should work in their system requirements.. @9Morello Distribution-ready binaries would be great. I've just published a new release too so I can upload them anytime.\nI think I will close this issue, even though the build isn't technically standalone (it won't run if a few system libraries aren't there or are too old, which shouldn't be the case in most Linux distributions).. @9Morello What is the error message if you don't use --no-sandbox?. @9Morello Fixed it in 38183f5e6bc9d2111fac142bea9b7ad448f086a0. @9Morello How did you install clang? Normally, Linux distributions have a default version of clang that is available as /usr/bin/clang++ (for the C++ Clang compiler). On Debian, they have /usr/lib/llvm-X where X is a version of LLVM to allow multiple LLVMs to be installed simultaneously from the package repository. Debian then has a clang package which symlinks the actual clang binary in one of those /usr/lib/llvm-* directories to /usr/bin/clang++. @9Morello So the clang-3.9 doesn't create a symlink /usr/bin/clang++? I guess that makes sense.. @9Morello I know why, and I know how to fix it for your system. But I don't like the solution since it requires all of the other systems to have clang in that location like Debian/Ubuntu have it.\nDoes the clang-3.9 not create a symlink?. @9Morello Oh cool it works now. Thanks.. Another restriction is that the tab has to stay on that URL. If you switch URLs, then the bug doesn't occur.\nI've narrowed down the issue to tabs that have the qjz9zk top-level domain in the address bar. For example, going to any website then going to qjz9zk, and then opening Settings, Downloads, etc. will trigger the same bug.\nThis means that other buttons in Chromium that open pages like this will have the same problem. However, \"Learn more\" links don't have this issue because they immediately go to about:blank.\nThis is a very specific and narrow bug, because it only happens normally when then user clicks that help button on that page, and leaves the tab open on that URL. I guess I can workaround this by just removing the button.\nEDIT: I should note that this is a hack, not a proper solution. I don't feel that the effort to find an ideal solution is worth the effort for such a specific situation.\n. I don't want ungoogled-chromium to be branded like other Chromium forks, and I believe changing that button to point here would be considered part of a branding change.\nTechnically, the fact that this button and all the other \"Learn more\" links are broken is a bug caused by domain substitution. Those links don't connect to Google on its own or affect the user's privacy, security, transparency, or control.\n. Thanks for the suggestion, but this is too similar to #37.\n. Alright. Thanks for the complement, I appreciate it. :)\nIf you or others are interested: If you have some Python background, you can adapt the Debian build module from buildlib/debian.py to work on Arch Linux. Or, you can detail out the exact steps to make a build. It would be ideal if Arch-specific changes to Chromium were included in the build of ungoogled-chromium, much like the way it is done for Debian.\nThough I wonder what @gcarq would think about this... (since @gcarq provides Arch binaries of Inox patchset)\n. @ilikenwf Are you using version 53? I'm in the middle of upgrading to 54, which will use GN. IIRC, an issue relating to cups compilation error in Inox was fixed with the upgrade to 54.. > I'll give er a shot once you've got it updated, probably tomorrow, \nThat is, if I can get it done tomorrow... at this stage, it's hard to predict what kind of problems I might run into (especially due to the switch to GN, which is pretty new to me).\n\nIn the future it may be nice to break out all the steps your builder takes, if possible, inside of a PKGBUILD instead as many times the people using the AUR like to tweak these packages before compilation to add/remove flags, patches, and features.\n\nYeah I haven't really considered this use-case when I evolved buildlib. I had the same problem back when people wanted to use OBS, which required a debian folder to do everything. I'll create a new issue for this topic.. That can be fixed with a GN flag as it is done on Debian. But I don't remember if I implemented the Python 2 hacking like it is done in the PKGBuild.. Alright then. You can try 8b6994f3a3eab1accc49e5642111f52ca227bccf out and see how that blows up for you. I basically copied over the Debian patches and GN flags for Arch.. @ilikenwf Try installing gperf and bison.. @ilikenwf How are you writing this PKGBUILD? Is it going to invoke buildlib, or are you going to make buildlib invoke it?. > It will invoke buildlib and package the resulting output...\nLet me clarify. Is your PKGBUILD going to run buildlib, or are you going to modify buildlib by overriding the generate_package method in the Archlinux builder class to call some commands to use a PKGBUILD file?\nEDIT: I should note that Debian overrides generate_package to copy a DPKG directory into the source tree and run dpkg-buildpackage. Okay. The only concern I have is that this implementation will be scrapped once I deprecate buildlib. If you still want to implement this before that happens, that'll be fine by me.. @ilikenwf That is probably a good idea, assuming I can implement the new system within a reasonable period of time.. @pickfire I can drop the quilt requirement in the new build system if you want to.. @HellishINC Looks like some problem with the Python distro module since it's not detecting your system to be Arch Linux.. @HellishINC As mentioned in the issue report you linked, there's no user namespace support on Arch by default. So the sandboxing part of this document should apply to you. The PKGBuild can be modified to setup the SUID sandbox properly in the future.. > The Arch PKGBUILD ungoogled-chromium was - is - will be hopelessly flawed affair from the begin.\n\nSorry, to sound rude - but yet again, infamous russians hackers were involved here.\n\nI don't know what you're talking about but it doesn't seem relevant to this discussion.\nRight now all that's left is to implement in the new build system is the build script generator. Once I get the build script generator working on Debian, it will be relatively easy to extend it to work on other platforms.. @altblitz I still don't see how it is related to this issue, which is about adding a PKGBuild for Arch Linux. I don't understand how a independent Chromium build is relevant to the discussion.. @altblitz I think we will be using some version of clang available in the Arch repos.. > Chromium can be build seemingly... And will fail at one test.\nWhat test are you referring to?\nBTW, all Linux distributions I've seen use their own version of clang when building their own versions of Chromium.. Clang 3.9.1 is the latest stable available, and what most distributions would be willing to package. Clang 4.0 is still in development. I don't know if Chromium can still compile on clang 3.8 or older. For ungoogled-chromium's Debian builds (stretch or equivalent), clang 3.9 is used from the repository.\nWhy is this important? What one test does it fail at if another version of clang is used?. > Yet, proper clang 4.0 build did compile .gn and chromium. From same chromium v55 source.\nWell Chromium can build with the system's clang 3.9 if the correct clang flags are set. I don't know what PKGBuild you're using or whether these flags are set correctly.\n\nI know now, chromium can starts and correctly displays sites, till it encounter certain site with 'font-awesome'.\nThat is the real world test.\nProper clang SVN build chromium passes this test, clang lesser SVN number - would fail always.\n\nCan you show me some images of what it is supposed to look like and how it fails? I went to some sites using \"font-awesome\" and I don't see any problems.. @altblitz I tried that page on ungoogled-chromium Debian 55.0.2883.87-1 and I have no problems. Arch Linux has Clang 3.9.1 just like Debian, so there might be another factor that is causing the crash.. @ilikenwf What's the error that you get?. @ilikenwf Oh. I forgot to add arguments to specify a different Python 2 interpreter. It defaults to python.\nThere shouldn't actually be anything in utilikit that breaks on Python 3.6, since I test it on 3.5 and I don't believe there is any backwards-compatibility breakage in 3.6. You can just skip check_requirements.py altogether since it's supposed to be a script for the user's convenience.. @ilikenwf \nI made some changes to BUILDING.md in an attempt to eliminate confusion. Let me know if there are parts that need clarification.\nRegarding the commands you used, I don't believe you want to put quotes around the arguments to the script because that will cause the shell to pass that in as one argument to Python. Also, you don't need to use --files_type because that is a positional argument (though it seems to work if you do anyway).. > Oh, and the quotes are expanded, this is within a PKGBUILD, the syntax is a bit weird.\nHm, really? It seems to me that the script is receiving one argument:\ngenerate_build_files.py: error: argument files_type: invalid choice: 'debian --flavor standard --apply-domain-substitution' (choose from 'debian')`. > Well, I am probably vastly ignorant about this build process, but what is the proper way to use the build output?\n\nHopefully I clarified this more with this commit.\n\nI've tried manually patching according to the patch_order file, after using prepare_sources and export_resources (see below).\n\nAm I supposed to see the actual invocations of those utilities, or am I just misunderstanding something?\n\nIs this all just because the new utilikit needs futher dev/input for other distros for it's build processes?\n\nThere are no precise instructions to build because there is no one specific workflow that applies to all configurations. I left it vague on purpose so people wouldn't get confused about the specifics of such instructions.\nFor example:\n Someone may want to use depot_tools and not apply domain substitution or source cleaning to create an Android build.\n Maybe there are some additional patches that one wants to apply so they could export the resources and append it to the end of the patch_order.\n Perhaps a user can't use utilikit (e.g. by not having Python 3 on a build machine), so they would want to export resources or generate build files to be moved onto to the build machine.\n The possibilities are numerous.\nI should note that I am open to working with someone to add a PKGBuild generator to the build files generator.. @seppiofish \n\nmy final goal was to write a PKGBUILD for Archlinux \n\nWhat a coincidence! I actually planned to write the initial code for an Arch Linux packaging type since I failed to make a Windows build. I finally finished it in 3381396af945279f84790c9a2c3a03b69fe526e3 (the time of which is also when I finished it).\nEveryone, please try it out and submit fixes as necessary. I don't plan on maintaining Arch Linux support.\n\nThe linux_portable build fails with a clang error in chrome_sandbox linking phase:\n\nShould be fixed in b460a214ea4f424521200ae9c2edcff5458788b4\n\nReguarding the linux_rooted error I have absolutely no clue, ninja fails with this error:\n\nI'm wondering if this is because you didn't unbundle the icu third party library in the Chromium source code. The PKGBUILD generated by the new packaging type should do this.. @seppiofish \n\nAs far as I know you must put all the source files in the root folder because makepkg expects to find them in the same directory of the PKGBUILD, in fact it fail otherwise, but again I may be wrong and there could be a way\n\nI was wondering about this and I couldn't find any information online about it. The patch names can be generated from their paths in the patch order.\n\nThen did you miss the .install file specified in the PKGBUILD or I did?\n\nI was really confused about that. Inox's PKGBUILD referenced inox.install, but I wasn't sure how it knew where inox.install was. From Inox's git repository, inox.install file doesn't do anything meaningful, so I think it's safe to exclude.\n\nAnd finally gn complies about not knowing the --fail-on-unused-args option so I again removed that to test.\n\nWhoops. I accidentally put that on the bootstrap command instead of gn gen.\n\nDo you want me to make pull requests to fix the PKGBUILD releated issues?\n\nI can fix the aforementioned issues right now (EDIT: cf9e6a2e0688702a98024ec93485acca3a318f06), except the patch path problem since it depends on how the next problem is solved.\n\nAnyway could you please explain how you intend the Archlinux build process to work? \n\nNow that you made me think about this, there's one major problem I overlooked: the usage of source file processors. buildkit normally creates the buildspace tree with the packaging files, so we can either:\n\nImplement the source file processors in the PKGBUILD\nUpload a pre-processed buildspace tree with the PKGBUILD\n\nI'd rather choose option 2 since it fits better with the typical buildkit usage, but option 1 is possible if the PKGBUILD wraps buildkit, or the source file processors are reimplemented in the PKGBUILD. What are your thoughts?. @seppiofish \n\nI don't think it is a great idea to provide an already processed buildpace along with the PKGBUILD on AUR, and could also become very annoying to manage.\n\nAlright, we can just make the PKGBUILD use buildkit only for the source file processors. The PKGBUILD can handle the downloading and unpacking of the Chromium source code (like it does already), and invoke quilt to apply patches (after using buildkit to generate a user config bundle and applying domain substitution to its patches).\n\nAnyway I keep hitting build failures. At first because of a bug in clang/llvm 5.0.1 so I temporarely downgraded and I will report it when I have time, and now i get this error from the linker:\nI'm beginning to think that I just hit an other bug (I'm using clang/llvm/lld 5.0 now). Which versions did you last build ungoogled-chromium with?\n\nDebian 9 and Ubuntu 17.10 use LLVM 5.0.1 with no issues. The error you ran into isn't something I've seen before. This is a shot in the dark, but I recall that Inox disabled jumbo builds; could you try setting the GN flag use_jumbo_build=false and see what happens?. I think it's because debian/system/event.patch creates a dependency on the system's libevent. Try adding libevent to depends and [libevent]=libevent to _system_libs (the unnecessary copy exists in base/third_party). > I was thinking of including this repo in the sources of the PKGBUILD\nYeah, I was thinking the same. This is also what the old ungoogled-chromium PKGBUILD did.\n\nWould that be sufficient or is there someting I am missing?\n\nYour plan sounds like what I had envisioned. If you want, you could also prune binaries from the buildspace tree too.. @seppiofish d6d30ea55aa1aeeeffb52bde12a786f5deb00d0b should finish off PKGBUILD support. If it works, I will tag 64.0.3282.186-1.. @seppiofish \n\nHow do you plan to put in the PKGBUILD the archive sha256 hash? Hardcoded or dinamically generated? As of now the check is skipped.\n\nI wasn't sure when I made that change, but I've come up with a few potential solutions:\n\nDynamically generate it. This will involve downloading the archive into RAM and then running the hash computation over it. This isn't too bad since the archive's only about 600 KB right now, but it does waste some bandwidth on repeated usage.\nStore it in an .ini in resources/packaging/archlinux, where the section name is the repo version and there is only one key for the SHA-256 hash. This saves some bandwidth on repeated usage with the downside of maintaining the .ini (e.g. adding new entries and purging old ones).\nAdd a command-line option to specify it. This can save some bandwidth on repeated usages (as in option 1), and also save some hardcoding (as in option 2), but there's some manual work involved.\nSome combination of the above options. Combining options 1 and 3 make the most sense to me, where a required command-line option takes either \"compute\" (to dynamically generate), \"skip\" (to add 'SKIP' to the PKGBUILD), or the sha256 hash. Including option 2 may ~~just make things unnecessarily complicated at this point in time~~ cause the complexity to outweigh the benefits of the combination.\n\nI'm leaning towards the combination of options 1 and 3 as explained in option 4. What are your thoughts?. Implemented repo archive verification in 61ea9a18e9cbe1207a8aefaf1583691997412669.\nIf all is well with this change, I think we can finally consider this issue finished.. 64.0.3282.186-1 is out with these changes. If someone wants to push a new package to the AUR, be my guest.. What platform are you using? I can see it on Windows 10, Debian, and Ubuntu.\n. Oh, okay. I don't actually have a Mac platform, so I can't test this out. @9Morello, can you confirm?\nI think you can go to chrome://settings/ under the People section to change users for now.\n. That's interesting. I've never personally used multiple user profiles before.\n@Noleli: if your intent is to separate cookies and other browsing data, I highly recommend that you use a separate browser profile instead via the --user-data-dir command-line argument. If that workflow doesn't work well for you, then we'll try to get this bug resolved.\nAssuming this bug is to be solved: I did a little investigation and I might have an idea of what happened. @9Morello, would you mind making a build with common/patches/inox-patchset/disable-new-avatar-menu.patch modified such that chrome/browser/profiles/avatar_menu.cc isn't patched? I have a feeling the avatar menu plays a different role on Mac OS.\n. @Noleli: You'll have to specify a directory with --user-data-dir, which will be used to store all of the preferences and state information for a browser session. I'm not sure how user profiles are implemented, so I see this command-line switch as a \"cleaner\" and more certain way of accomplishing what you need. This still requires that you launch an instance with this flag, and you can't switch data directories in a session.\nI did some testing of user profiles on Debian, and it seems that the user profiles are treated as separate windows (much like separate user data directories). The only benefit is that it's easy to launch or switch between them within Chromium.\nBy the way, there's also Incognito mode if you don't want cookies or other site data to persist. You'll also get to use your existing preferences.\n. I believe this is an issue for chrlauncher to take care of. Plus, chrlauncher already supports forks of Chromium. See this.\nI'm closing this for now unless I've been mistaken.\n. Sounds like a good idea if it's not implementable via an extension.\n. Sounds like it's already been done, so I'm closing this.. Thanks @mmoya.\n. Where exactly is \"Album Artist\" used? Is there a music player feature I'm overlooking?\n. > Well, who is the public of ungoogle-chromium?\n@9Morello pretty much got it. Users who understand the benefits of this project must already have a deeper understanding of the web and web browsers than an average internet surfer. These users are probably doing things to reduce their risk of being attacked, whether it be install extensions like uBlock Origin or disable plugins like Flash or Java. They could even run certain web applications within a VM when they need these features.\nI'll add a section to the FAQ and README to inform users about the safe browsing situation.\n. I'm not sure if you can disable these. They're normally not visible in chrome://extensions because they're not quite like normal extensions. Is there a reason you want them disabled in incognito?\n. @SharpMan: Ads aren't affected by the default extensions as far as I know. They should be only affected by third-party adblocking extensions, and those can already be toggled in incognito just fine.\n. Closing due to inactivity and the question seems to be answered. Please let me know if this is a mistake.. Yep, and Windows too (though you'll have to do a little more work).\nThough to what degree do you want the automation to be? It's already pretty automated; you don't have to download the source code, run GYP, or invoke ninja yourself.\nAnd like @9Morello said, all of these platforms have H.264 support enabled.\n. @RobinThrift: This is the wrong thread to post this information. Please head over to #17. Thanks!\nI am closing this issue since the question here seems to be answered. If this is not the case, please comment.\n. Sure, Fedora support could be added. Though I don't have a Fedora system, so someone else would have to figure out how to get it to build and possibly make a pull request.\nIf you don't care about using system libraries, you could wait until #41 is finished.\n. @esotericDisciple That's unpredictable, since more components can break if Debian changes its packages.\nIt'll be better to have a Fedora builder so Fedora-specific patches can be applied.\n. There is no clearly better option. Both options have their benefits and drawbacks that end up making them useful in different scenarios. A debate about this specific topic (i.e. whether bundled packages or dynamically-linking packages are universally better) is thus pointless. As seen in your last few posts, real applications have their own situations and objectives that makes one or the other the \"better\" option.\n\nit's not an either-or. Why not have both.\n\nThis is the solution we're aiming for. AppImage and the semi-static Linux build will cover the platforms that would be too much for the current contributors to handle. Until someone adds support for Fedora (presumably after 56 has been released), Fedora users will have to use the aforementioned options.. No, this is the first time it's been suggested. What platform would you want an ARM build for?\n. Are you talking about a Debian arm64 or or armhf build? Or are you looking for a generic Linux ARM build?\n. Alright. I don't have any experience with cross-compilation, so it'll have to be seen how this can be done.\n. It might be possible to make arm64 and armhf builds with the current code, using the compilation methods that the package maintainers of chromium in Debian use. I don't know if this includes cross-compilation or not.. Can this not be done via an extension? I know it's possible to override JavaScript API functions with your own.\n@9Morello does have a good point, but it kind of sucks to have an all-or-none situation. I mean, that's why adblock extensions even exist in the first place, right?\nSome features like changing the user agent is outside the scope of an extension, so that could be done through some new UI in the web browser.\nuBlock Origin can also prevent leaking of local IP addresses, but WebRTC is already disabled in the build configuration. I'm considering re-enabling it since there are some uses for WebRTC.\n. > No this cannot be done via extension. Why have extra overhead? Makes no sense.\nIt's not so much about overhead as it is the significant effort it would take to implement and maintain such a feature. Using an extension is better for several reasons:\n- JavaScript is much easier to work with than C++\n- There is significantly more documentation on JavaScript and Chrome extensions than there is the code structure of Chromium (which is basically none).\n- The Chromium codebase continually changes and restructures, whereas JavaScript and Chrome extension APIs stay relatively the same.\nI know for a fact that some of these features can be done via an extension, but others will probably require modifications to Chromium.\n\nFrankly Chrome can even read your clipboard. It's called Clipboard Hijacking and its done through HTML5.\nChrome = Privacy nightmare.\n\nWell I guess that's another one we'll have to add to the list.\nThough if you're very concerned about your privacy, then you should follow @9Morello 's advice. My approach is sub-optimal, since it's a cat-and-mouse game just like anti-virus, adblocking, and soon disabling HTML5 autoplay.\n. > Brave has some anti-fingerprinting measures built-in. I'm not sure how well they work, or how they're implemented. Anti-fingerprinting is very important given how aggressive trackers have gotten.\nYeah, it's always better to have some protection than none.\n\nThe problem with, e.g., uMatrix is I can't recommend it to a non-power user. Even my partner who is otherwise web savvy is just going to start turning it off a lot or going incognito. Users are a weak link in the chain of trust/defense.\n\nThat's a good point. I've generally assumed that most people using this project are already power-users, but I'm realizing that this isn't such a good assumption. Plus, it's not safe to assume that all power-users know much about this subject.\n\nDoes anyone know how hard this would be as an extension? I don't mind working on that.\n\nThe code that modifies the page isn't too bad. I don't remember all of the details, but you'll need to use Object.defineProperty and other \"low-level\" JavaScript APIs to manipulate objects in ways that are not well known.\nWhere the real work comes in is implementing this in an extension, and especially when designing a UI to configure the behavior. You'll run into limitations and hassles that slow you down. For example, when injecting a script into the real page's DOM (not the read-only one presented to the content script), there is the problem that if the page's JavaScript runs first, you may not be able to overwrite the properties in time. I haven't found a good solution to that when I was researching.\nI've been planning to implement this approach into Disable HTML5 Autoplay long before I've thought about this use-case, but I haven't gotten around to it.\n. @Atavic What are you talking about? He posted links to sites that show whether the browser is preventing those types of fingerprints.\n. @uBlock-user Oh wow that is a neat extension. Thanks for posting it here.\nClosing as wontfix.. @csagan5 While some users may find it useful to permanently disable those API, I don't want to risk breaking legitimate websites. However, I wouldn't mind those patches if they were implemented with a chrome://flag switch or only with a command-line switches.\nThe patch I'm least worried about is the Android user agent patch, but I'd still like that to be behind a flag if it is to be included.. @csagan5 I realize it is not my place to dictate how your project should be done, so I'll just state my perspective on this, and leave it to you to decide whether to act upon it.\n(Perspective follows)\n\nThe main communication channel for our projects are through issues on GitHub (and in ungoogled-chromium's case, also Gitter). Even if creating an issue or using Gitter didn't require any sort of account to use, you will never get a complete and accurate picture of what your userbase wants; you only hear from those that have decided to put in the effort to help the project by contacting the developer. This is why I take every issue and comment with deep consideration, because the volume of information flow is low to begin with.\nI never fully understood that until I read the response to my project on Reddit and Hacker News. Back then, ungoogled-chromium took more aggressive measures to deal with its main objectives, which included disabling features (e.g. WebRTC was a big one). The response on those sites clearly showed that disabling these features was a bad idea that broke many use cases. Unless a project's relatively popular, chances are that people would just move on without bothering to tell the developer about their dislike for some design decisions (it takes effort and can easily come off as rude).\nThis is why I generally try to move significant changes to the Chromium experience behind flags. I assign a relatively high priority to user experience and needs, so I have to play it safe here.\nObviously, your changes in Bromite are much more subtle and nuanced than disabling a large feature like WebRTC. But doing so may cause subtle breakages that will frustrate the user more than an obvious error. The less technically inclined user may not realize what's happening and think Bromite is broken without reporting the issue.\nAgain, this is just my perspective on the matter based on my own experiences. I don't know your intentions or long-term plans.. @csagan5 \n\nI have seen how you implemented the Clear HTTP cache feature, however that is not available in the Android UI if I understood correctly the patch?\n\nThere would need to be additional changes for it to work on Android, yes. The chain of functions to call should be similar, if not identical.\n\nmaybe you would be interested in that patch later on.\n\nYeah, it sounds interesting. I actually like your patches more than using an extension like ScriptSafe, because ScriptSafe can't guarentee those APIs won't be called. Plus, there are quite few more problems that need to be dealt with when hardening JavaScript to be injected. The only problem is it'll take effort to write the necessary code in the browser to make it toggleable per tab and per website like ScriptSafe. But, at least it's straight-forward to add a chrome://flag and easier to add a command-line switch to toggle the feature.. It's possible, but it will take a lot of work if you don't want to use Google binaries.\nI think Debian is working on building and packaging the Android development tools. Maybe it'll be easier to build for Android using Debian instead of building everything from source.\n. > can you add extensions too\nThis won't be trivial because I don't think there is any UI infrastructure to support extensions on Android.\n\nplease delete function with login\n\nThere is no login function feature in ungoogled-chromium as far as I can tell. What exactly do you mean?\n\nThe same please for windows and finaly as exe file installer\n\nThis should go into a separate issue report. This one is only for adding Android support.\n. > The Replicant (FSF-approved de-blobbed Android distro) devs have released a (somewhat dated) ungoogled version of the Android SDK (NDK too?) that can be used with Eclipse. Perhaps it could be used?\nI have no experience building the Android version of Chromium, so I wouldn't know the answer to that.\n\nYandex Alpha browser (closed source) has extensions implemented without any added UI elements in the statusbar, it simply adds access to the chrome://extensions page\n\nInteresting, but how are you supposed to access the popup menu? I know the Android version of Firefox uses a separate tab to display popups, but I don't know if this feature is implemented in Chromium or how difficult it would be to implement. Anyway, that is a bit off topic.\nI think the first objective will be to figure out how to build an Android version without using Google's binaries. Once we get an idea of how the procedure works, we can start adding in patches, domain substitution, and source cleaning.\nAny info or help for reaching that first objective is much appreciated. I would like to work on this myself, but I barely have time to respond to comments on here and make small changes to buildlib.\n. @magicgoose We can do this initially, but it should be switched in the long run. \"ungoogling\" also includes not using Google binaries.. @avently I am not working on this right now. Someone else has offered to take on the task. See #157.. @avently I am not interested in developing Android support.. @zt3phan What @magicgoose has said is correct.\nTo be honest, I might be interested in this if Debian's Android SDK and NDK packages are mature enough and Chromium on Android starts to support extensions.. @zt3phan Okay, sounds good.. @avently It's not as easy as switching on a flag. You'll need to at least create the UI in Android (which will probably involve a mixture of Java and C++).. @ilikenwf Nope, I haven't. I don't know anything about Copperhead OS. Are you suggesting that someone there would like to work on adding Android support ungoogled-chromium? Or are they interested in cetain features (e.g. transmissions to Google, but not binary pruning)?\nOn a related note, this project seems to aligns very well with what F-Droid wants (i.e. minimal binary dependencies in source tree, and no connectivity to non-free services). In fact, Brave browser didn't get into F-Droid because of the binary blobs and JARs. Getting a Chromium browser into F-Droid would be pretty nice, but I believe it'll be a much larger task than adding Windows support.. @ilikenwf Based on a quick look, their patches would be useful to include. If they were to include patches from us however, it's possible only a small subset would apply due to the architectural differences between Chromium's Desktop and Android implementations.\nAdditionally, ungoogled-chromium is pretty aggressive with its GN flags (e.g. disabling Safe Browsing). It doesn't seem like Copperhead OS developers went through the trouble of fixing unsupported GN settings.. @ilikenwf \n\nDon't you currently just do a find and replace at build time?\n\nThe process's a bit more involved than that. It's explained in DESIGN.md.. @csagan5 Yes, we'd welcome help with this issue. We can start out with a straight-forward build without binary pruning or domain substitution, but eventually I'd like to work up to something like the other platforms where all binaries are provided externally (i.e. not from Google).. @D0ve There are no updates on my end for building Chromium for Android with Debian packages. I don't know enough right now to determine if this is practical, or even feasible.\n\nYandex did this support somehow\n\nAre you saying Yandex supports extensions on Android? Do you have a direct link to the changes they made to accomplish this?. I am not against adding extension support. However, if I am to work on this, getting the build process closer to the goals would be a higher priority for me than adding extension support (since it aligns more with ungoogled-chromium's objectives and would allow publication on F-Droid). Regardless of my stance, I don't mind if someone else here wants to work on this and submit a PR with the patches and config necessary to make this possible. However, you may want to consider contributing to a project like Bromite (by @csagan5) for the time being, since it's further along in Android support than ungoogled-chromium is.\nIf you wish to discuss extension support more, let's move this to a separate issue to not diverge from the main topic here.. @csagan5 \n\nTo go back on topic: the F-Droid guys were nice, however I am afraid even if we build there with their VM and toolchain, we still have the problem of SDK/NDK (and the other binaries downloaded by gclient), in the sense that even when Chromium builds completely through fdroid tools, this might still be an open problem because you are letting a third-party (Google) binary in the build process (see DDC).\n\nI was hoping to use Debian packages to solve this issue (since they've been diligent in this area). I'm not sure if that's even possible right now, but we can theoretically bootstrap whatever Debian can't provide.\nThis is why I proposed working towards the idealistic build process in steps; we start with the regular build process and then replace components a piece at a time. Eventually, we would have a build with no dependency on depot tools or other Google binaries (like all currently supported platforms).. @csagan5 Yes, the features of depot_tools are either duplicated or replaced in some manner.\n ungoogled-chromium uses extra_deps.ini to download additional source code (or pre-built toolchains) not included in the chromium-browser-official compressed tar archives. Based on your description, it sounds similar in concept to F-Droid's srclibs.\n    * macOS's Google Toolbox for Mac is the only instance of this right now I believe.\n From what I've seen, hooks generally download binaries from Google storage, and sometimes entire build environments (i.e. sysroot). None of the existing platforms require hooks because the features requiring the binaries are usually handled by one or more of the following:\n    * Patched out (Windows support is a good example of this)\n    * Provided externally (via extra_deps.ini like on macOS or a system library on Linux)\n    * Built from source (which only happened once when I built syzygy's swapimports.exe along the Chromium source for Windows back in version 55).\nAdditionally, depot_tools also uses its own distribution of Python and possibly other binaries, which isn't acceptable by the ideal standards.\nBased on my knowledge of Android applications, I imagine that only the JDK and a handful of Android tools and libraries can be provided by Debian right now; some other version-sensitive tools and JARs will have to be built from source. Ideally, we would download the source code and write GN files to implement this.\nAlso a quick note about extra deps and git repositories: Most git browsers I've seen these days (including Google's git browser) include a feature to download an archive (usually tar or zip) at a specific commit. If we come across some code that has no archive option, we could extend extra_deps to use git.. @csagan5 So I did a quick investigation, and I think we only need to download components in DEPS that have a condition of only checkout_android if we use the chromium-browser-official tar archive.\nFortunately, I recall DEPS being implemented as Python code, and a quick skim through it confirms that this is so. So, I wrote a script to print out the dependencies and hooks needed only by Android. The output of the script follows (on the version 65 DEPS file):\n***Dependencies:\nsrc/third_party/android_ndk\nsrc/third_party/android_protobuf/src\nsrc/third_party/android_tools (Contains additional deps file: DEPS)\nsrc/third_party/apache-portable-runtime/src\nsrc/third_party/auto/src\nsrc/third_party/custom_tabs_client/src\nsrc/third_party/elfutils/src\nsrc/third_party/errorprone/lib\nsrc/third_party/findbugs\nsrc/third_party/gvr-android-sdk/src\nsrc/third_party/jsr-305/src\nsrc/third_party/junit/src\nsrc/third_party/leakcanary/src\nsrc/third_party/mockito/src\nsrc/third_party/netty-tcnative/src\nsrc/third_party/netty4/src\nsrc/third_party/requests/src\nsrc/third_party/robolectric/robolectric\nsrc/third_party/ub-uiautomator/lib\n***Hooks:\nAndroid CIPD Ensure\ndoclava\ngvr_static_shim_android_arm\ngvr_static_shim_android_arm64\nsdkextras\nvr_controller_test_api\nvr_test_apks\nI think this is a manageable number of hooks and dependencies to workaround, so I don't see a good reason to keep depot_tools in the long run if it's going to make it harder to track what binaries it uses. Additionally, some of these dependencies are only for unit testing and compile time debugging like findbugs, roboelectric, and ub-uiautomator.\nI have also confirmed that GN has built-in functionality for Java code, which should make compiling certain JARs from source relatively straight-forward.. @csagan5 I forgot to mention that the chromium-browser-official archive is is only 544 MB as of 65.0.3325.181. If we're going to use the Debian or F-Droid SDK and NDK, I am having troubles seeing this add up to 20 GB. Is 20 GB the size of a regular gclient checkout (i.e. including .git directories)?. @csagan5 \n\nAlthough if massive patches are needed for the build system (ninja/gn), then it'd become again a moving target and painful to support.\n\nI'm hoping that the Android-specific dependencies don't change too often or significantly (especially those in third_party), so this will mostly be a one-time effort.\n\nI suspect that if you sum up the size of the zips that you would fetch for each dependency, you would still get a big number\nI report below some partial listings from ncdu\n\nIt looks like most of the size is due to the Android SDK and NDK, and .git directories. I don't see many of the other deps taking that much space.\nIf you're really worried about the size, it should be relatively straight-forward to get the total size of these other deps by modifying my script from earlier: If the server supports it, query the HTTP headers for the sizes; otherwise, download them.\nBut before we worry too much about that, I think we need to see how to use our own Android SDK and NDK; either from Debian's SDK and NDK installer packages, or from F-Droid's own system.. @nikolowry I don't know a lot about CAF, but I'm betting they made pretty extensive changes that will be nontrivial to update to the latest version of Chromium.\nEither way, this isn't really on-topic. If you're looking for results now, you're better off looking into a project like Bromite which has working Android builds and is more experimental than ungoogled-chromium (from my perspective).. It maybe possible to do this automatically, but I'm not sure how. Does pressing F12 not work for you?\n. Closing this since there seems to be no problems with the suggested solutions.. I didn't realize that 64-bit Chromium was better than 32-bit. I'll consider deprecating the 32-bit build if no one uses them.\n. I've decided to build both x86 and x64 binaries for now.. Why use openSUSE Build Service as opposed to builders for the individual distributions like Launchpad for Ubuntu?\nThis is a duplicate of #17. Please respond in that issue report. Thanks\n. That may be convenient, but there may be other advantages and disadvantages we need to consider.\nPlese do not continue to post in this issue report. Use #17.\n. Well it looks like you're running on macOS. This is a pretty strange error.\n@9Morello: Any ideas?\n. @kd7lxl: Do you have out/Release/gen/protoc_out/components/suggestions/proto/suggestions.pb.h? If not, it may be due to a bug like this one. Otherwise, it's some other bug.\n. > Nope.\nHuh, then it's probably related to the bug report linked above. Which means we might have to patch some GYP files, or complete #16.\n\nYes, and I run the command rm -rf build before calling python3 build.py. Is this the correct procedure?\n\nYou shouldn't need to remove the build directory each time before running build.py, even if you choose to re-extract the source code every time.\n. @kd7lxl ungoogled-chromium version 54 works on macOS in the current state of the master branch (as of ecb9fb8883e83c01d1b47c1a4f756a227f17eb50). I've switched to GN in this version. Do you still have this problem?. Closing due to inactivity and there have been no cases like this since the switch to GN.. This exception is not intentional. Hopefully that commit fixes it. Let me know if it doesn't.\nThough if you need to re-run the build, you should comment out the build steps you don't need to run in build.py before running it.\n. I haven't tested it, but the code should be there to build it. Do you have some knowledge of Python? You'll need to add two lines to build.py:\n- Import CPUArch from buildlib.common\n- Set the target_arch attribute of builder to be CPUArch.x64\nThen run build.py normally and hope for the best.\n. Hi @woolyss, I really like your website. It has great info and binaries that I've used from time-to-time. Thanks :)\nA few questions: Does nik's build use domain substitution or source cleaning? Did nik use buildlib, or include the patches in his own build process?\n. @chrme @woolyss \nI see. Well that's a bit unfortunate. Would you mind adding a disclaimer on the site saying that several patches and domain substitution are not used? Also, since you're using GN, I'm guessing you're using binaries provided by Google? If so, I would also like that to be mentioned in the disclaimer.\nI may sound pedantic, but I think these differences are among the major features that ungoogled-chromium has to offer. The patches that depend on GYP are those that disable the more integrated features, and building without Google binaries gives users more certainty that Google isn't doing something behind our backs.\n. @woolyss Thanks\n\nFinally, can you compile a 64-bit version of ungoogled-chromium for Windows?\nI think it could be better than our merged builds! ;)\n\nYeah I'm planning to do that as soon as I can.\n. #147 implements this. Going to make x86 and x64 builds and upload them to the next tag.. No, thank you. Chromium already has scripts to generate Windows installers if I choose to do so.\n. Sure. Would probably just take some tweaking of some compiler and linker flags.\n. I believe the code in the repository right now can build natively for the i386 architecture.\nAnyone who wants to upload binaries, please let me know here or via Gitter.. Do you care about system libraries? Or creating Ubuntu packages? If not, #41 should get you what you need.\n. Alright, will do then.\n. I just realized a problem. If you want to use system libraries, you might not be able to install these binaries on any system other than Ubuntu 14.04 LTS. Is this what you want?\n. Okay. That'll work then.\n. I've decided that I don't want to make a Ubuntu 14.04 LTS-specific build since the system components are probably too old to work with Chromium. Instead, I will focus on the static build.\nThis does not mean I won't support running or building the static build on 14.04 LTS.\n@9Morello I will answer your problem over in #41.. ungoogled-chromium doesn't touch anything related to pinch-zoom, so it might be a Chromium problem. What website(s) are you trying to pinch-zoom on? Does it work on Chrome?\n@9Morello: Do you know anything about this?\n. Huh, that is strange. I'm not sure exactly what caused this to break.\n. @9Morello: Do you have any ideas?\n. Oh ok. Well I'll try to investigate more after I get other issues out of the way first, though that may be a while later.\nIf anyone else knows more about this, please help out!\n. @piningforthefnords Thanks for the info\n\nI'll be happy to help test in any way you like, but I have no idea what I'm doing with GUI apps.\n\nWell that makes four of us. :/\n. Possibly. I've seen pinch-to-zoom work on laptops with touchscreens, but I think those websites might have implemented it via JavaScript. Pinch-to-zoom on touchpads are a different interface.\n. @piningforthefnords Does pinch to zoom still not work on 54?. @piningforthefnords Wow there are blobs for this too? That's weird. I wonder what they are trying to hide.... Huh, alright.\n\nJust to clarify, ungoogled-chromium was not making any requests for blobs or anything else from Google.\n\nJust to clarify, I was wondering why pinch-to-zoom would require blobs at all since it doesn't seem like it would have any licensing restrictions that require it to be blobs.. @poiru Thanks for the info. We could build against the 10.10 SDK, but it looks like the problem will be fixing itself soon since https://bugs.chromium.org/p/chromium/issues/detail?id=624049 says all of the compile bots will be updating. ~~This could mean the problem will be fixed by the next stable version.~~\nEDIT: Well 56 just came out today, and it seems the build system hasn't updated yet. This may take some time before it is implemented.. @tectiv3 Oh, neat.. Does /usr/bin/env python resolve to Python 3 on Arch Linux? If so, you'll need to set builder.python2_command to be the command to launch Python 2.\n. You need to edit build.py and set the attribute where the code comment says to.\n. That's strange. Setting builder.python2_command = \"python2\" works as expected on my system.\nBTW, are you using a tagged version or the master branch?\n. You probably don't want to use a tag because the latest tag doesn't implement static Linux builds; it falls back to a Debian builder.\n. What does your build.py look like right now?\n. Looks like Inox had to do some workarounds too. Solving #69 should fix this issue.\n. Hopefully that commit does it. Let me know if it doesn't.\n. @pickfire Could you try setting python2_command to python?\n. Do you have a file named python in build/path_overrides?\n. Is there anything in it?\n. That's strange, because path overrides work on my system. Does python2 not launch Python 2 on your system?\n. Wait. Why are you setting python2_command to python? That's Python 3 isn't it? Try setting it to python2.\nAlso buildlib only works with Python 3, it says so in the docs too.\nEDIT: I just realized I said that. I keep forgetting that Arch is different from Debian :/\n. @pickfire Yes, that's correct. Except it's python2_command you set in build.py at the location specified by the code comment, not python_command\n. I made the change for you now in that commit so you don't have to modify build.py. See if that helps at all.\n. buildlib will be deprecated. See #125.. If the md5 doesn't match, that means the archive is corrupt. I'll modify it so the build script will halt if the hash check fails.\nWhat exactly did you do to fix your initial problem?\n. Oh ok. Thanks for that info. I might make the compiler detection a little smarter in the future.\nYou should probably try deleting your build/ directory and re-running build.py\n. Over 400 MB\n. It seems that Adobe's version of Flash player has an auto-update mechanism for macOS and Windows\nTo get it:\nGo to https://get.adobe.com/flashplayer/otherversions/ and:\n1. \"Mac OS X 10.6-10.12\"\n2. \"FP 23 Mac for Opera and Chromium - PPAPI\"\n. I already included a patch from Inox that should make the Widevine CDM module work. Is it not working?\n. Huh, that is strange. I don't know if the Widevine patch works on macOS, but I heard it works on Linux.\n@9Morello: Have you tried to get Widevine to work on macOS before?\n. Can anyone else confirm that this doesn't work on Windows? I haven't had time to test this on Linux, so if someone could try that too that would help.\n. Hmm. I wonder if domain substitution is breaking the Widevine DRM checking. I'm guessing that you don't see an infobar show up when you attempt to use widevine?\n. So it works properly on Linux, but not Windows or macOS? That's weird. This is probably not be a domain substitution problem then.\n@chrme: Would you mind telling us what did you do to get Widevine to work in your Windows builds? Do you know if it works on macOS?\n. @9Morello Is that a GN flag? I'm still on GYP. Though I'm probably going to switch in ungoogled-chromium 54 or 55.\n. Huh. You know, it would probably be a good idea to enable that flag.\n. @9Morello Sounds good. Thanks.\n. @9Morello Well that sucks. I guess the investigation continues...\n. You have libwidevinecdm.dylib? That's weird. We don't have the source code to that library, which means it must have downloaded while it's building. Only the widevinecdmadapter library is built.\nBTW, I scanned the GYP file and it seems that the manifest.json file is also provided before the build starts. So it seems we're only supposed to have the widevinecdmadapter library.\nEDIT: If we need to modify any meta-build configuration files, I would like to wait until we've switched to GN first.\n. I'm still deciding how to do this transition. Windows and Mac are the only platforms where GYP is becoming a bit troublesome, with bugs #89 and #60, respectively. Linux will be a lot more work due to the use of multiple flags not available in GN and heavy modifications to build against system libraries. So I might switch Windows and Mac to GN before another release, and wait until later to switch Linux over.\nRight now, inox-patchset is holding back the update to 54. Though I will try to squeeze in time this weekend to update the necessary patches to GN.\n. Not exactly sure yet since the packaging method is unique on Mac, but it's more than likely related to the differences in behavior when using Chromium instead of Chrome for branding.\n. @lewdnasty I didn't enable Widevine properly in the Windows build published on GitHub. Once I get version 54 to build on Windows, then we can start testing.\n@9Morello Does the new version 54 build you made still miss those files?. @9Morello Alright. I have widevine files in my output directory, but they give me the same error as in this comment. So it seems that switching to GN has no effect on this issue.. @gcarq Thanks for your input. altblitz got Widevine to work just fine on Linux doing exactly what you said.\n@9Morello On Linux, a stub version of libwidevinecdm.so is built. I'm assuming Windows and macOS have the same behavior (but have their respective file names). It's not broken, it's just a dummy placeholder. You will always need to get the official library from Chrome, unless they miraculously release the source code. Also, I am fairly confident the dummy binary is not being downloaded from the web, because the source code's referenced from the GN configuration (and domain substitution would've broken it anyway). > Only thing I see on the uploads page is version 55.0.2883.75-1, no 87-1.\nLooks like I need to make the link bigger.. @pjv Ah. Yeah looks like @9Morello forgot to update all of the references. Going to fix it right now.. @Zegnat With the new download page design, you should be reading files from here. There is no guarantee as to where macOS binary files will reside, but the downloads webpage should be using that configuration file format for a while.. Now that Widevine support builds on all of the platforms, we should probably add some instructions to the FAQ to let users know how to install the module. I will take care of the instructions for Linux.\nEDIT: Does anyone think it will be worthwhile to have two kinds of builds for each configuration? One with Widevine and one without? (Woolyss does this). Closing now, since this bug seems to be resolved.. @stfnhrrs I'm going to assume you're following the instructions in the FAQ.\nWhat version of Google Chrome did you take the WidevineCdm files from?. @stfnhrrs I'm not really sure what's going on. You're still on macOS, right?. Any ideas @9Morello?. Does that actually work on other platforms? Have you tried dragging from a file explorer?\n@9Morello: Do you know anything about this?\n. This may be a Chromium issue. gcarq probably tested only on Linux, so it'll work differently.\nI'm closing for now since it doesn't seem to be an ungoogled-chromium issue.\n. This will not be a trivial change. The Chrome developers are using Windows API features and libraries that don't work on XP, so all of those will have to change. Also, some technologies used for sandboxing aren't available on XP. You may even need to tweak some compiler settings to make this work too.\nIf someone wants to do this, go ahead. I don't have to knowledge to do it even if I wanted to.\nI'm closing this for now since I don't consider this a feature that many users here will use, much less want to implement. If someone has the knowledge and is willing to take this up, please respond.\n. Yeah someone reported that earlier and they closed it themselves for reasons I'm not sure...\nInstead of hardcoding the path in a config file, I want to implemenet a function in MacOSBuilder that can auto-detect the path to Homebrew's GCC. However, I don't know enough about Homebrew to figure out the best way to detect the GCC path.\nI am planning on using #69 to solve the problem of a version-dependent path to the compiler in the patch file.\n. Adding help wanted label so someone can help out with Homebrew.\n. I did some research, and this gist gives us some helpful hints.\n@dangom: Is gcc-4.9 or something similar already in your PATH?\n- If it does, does it point to Homebrew's GCC for that version?\n- If not, is there one in $(brew --prefix)/bin?\n. > No, it isn't. \nSo that means gcc-6.2 is not in your PATH? That's interesting.\n\nNo, I only have 6.2 on brew, and it isn't symlinked to /usr/local/bin/. My PATH still points to /usr/bin/gcc.\n\nSo brew --prefix returns /usr/local? Well I guess that makes sense.\n\nPrepending this to the PATH, as you suggested in #69, should do the trick without having to symlink all gcc binaries or overwrite user defaults.\n\nI'm confused. Are you saying that there's a gcc-6.2 in /usr/local/Cellar/gcc/6.2.0/bin? If not, then it doesn't help to append that to the PATH. Also, #69 isn't suggesting prepending system directories to PATH, unless I'm misinterpreting what you're saying.\nDo you know if there's a way to get a list of installed GCC versions? Is there a function to get information about a specific GCC version that's installed?\n. > Yes. These are the files in said directory:\nBut there's no file called gcc-6.2 in that directory. The problem is that those file names contain other values that are more likely to change depending on the version being built. gcc-6.2 is supposed to match against the latest GCC in the 6.2.x series. That's why I was hoping that there was a file named gcc-6.2 in /usr/local/bin so we wouldn't have to assume certain patterns in the actual GCC path.\nThe reason I want a command like that is so I don't have to use #69 to solve this problem.\nWell I did some very quick research and came across this bug report. It looks like there is a way to list gcc versions, and a way to create symlinks in /usr/local/bin. Could you try running brew link gcc and seeing if that adds a command called gcc-6.2 to your PATH?\n. Oh cool. I think that will work instead of using #69.\nWould you mind testing to see if GCC 4.9 from Homebrew is available as gcc-4.9 or something similar?\n. > It is. Takes an awful long time to build though.\nOh cool. Glad to hear it works. I didn't know that Homebrew actually builds the compiler each time; that's interesting.\n. Thanks\n. ? Is this a question? I'm confused\n. > I think he means the current name of this project is a bit dangerous. Google can shut it down easily I suppose?\nNo, they can't. I'm not violating any software licenses as far as I can tell.\n\nSince this has been getting so much attention now, I suggest a name change.\n\nWhat do you suggest?\n. @ajkblue You have solid reasoning. I also like the fact that the name tells users what to expect from the project, but I didn't have any good reasons to keep it until now. Thanks.\nI'm closing this for now since @yasindce786 isn't clarifying the original question, and all of the questions in here are answered.\n. @sahal2080 \n\nUngoogled is very antagonistic.\n\nI can't see what you mean here. I see it as a neutral term. Let me make an analogy: Are you saying that undoing something or unearthing something from the ground is antagonistic?\n\nit might drive away many non-techie people who would see this as \"hackers crazy stuff\"\n\nReally? I'm sure everyone recognizes \"google\", and when you un- something, it usually means to remove that thing. Sure the non-technically inclined users won't understand how or why, but the correct idea is conveyed.\n\nCurrent name might draw the attention of Goliath and unnecessary troubles that would just make life harder for a resource-limited project\n\nWell I tried looking up Goliath, and I still can't figure out what you mean. Could you re-explain with different kinds of words?\n\nif you involve the community in name/logo design and selection and the like\n\nDo you mean tell people to create a name/logo? I already let people contribute whatever ideas through issues.\n\nThe message as @ajkblue wouldn't be lost if it was renamed to something like Pure Chromium, Clean Chromium, Chromium Liberated,\n\nI think some of it will be lost. Consider this quote from @ajkblue:\n\n\"ungoogled-chromium\" tells me everything I need to know about the browser, basically \"Chromium without Google\"\n\nThe names you proposed are pretty generic; they can mean a lot of different things to different people. ungoogled-chromium is relatively specific.\n. Huh. I've never installed Chromium via the installer before, so I never knew about this behavior.\nWhat happens if you launch ungoogled-chromium with a different path for the user data directory?\n. You need to use quotes around the path, otherwise cmd will interpret the space as the end of an argument instead of being part of the path. Right now, your profile is located in c:\\users\\vladimir\\other\\ungoogled\n. I like your \"Install from file\" button idea. Though I don't know where in the code that extensions are installed, so I'll have to investigate.\nThough how would \"Install via id\" work? Would that attempt to install an extension from the Web Store?\nBTW, the \"Download more extensions\" link doesn't work because of domain substitution. The Web Store doesn't work because of other patches.\n. > Perhaps you can identify the point in the code where it starts the installation by searching for things related to drag-and-drop? Even though I guess the browser does a lot of other drag-and-drop as well.\nYeah that's what I was thinking, but I also need to figure out how to add the button and bring up a dialog button. I don't expect it to be too difficult, but it will take some time.\n\nAs for the \"Install via id\" button, I was thinking:\n\nI guess I could implement something like that. But there are already external programs that can download the crx file for you; all you would need to do is use Install from file. I thought that many users of ungoogled-chromium would rather get the extension from the developer's GitHub page instead of getting it from the Web Store, but I'm not sure.\n\nAs for the \"Download more extensions\" link: shouldn't it be possible to visit a Google domain if the user explicitly requests the browser to do so?\n\nThat's true, but I don't have a system in place to exclude domain substitution on parts of a file. Considering the Web Store doesn't work for installing extensions, its use is kind of limited.\n. > How about just removing it (and other things that don't work) then?\nI could, but that would be more patches to maintain. It doesn't confuse the user too much, and no one's really complained about them.\n. Yes it is, but not all users use domain substitution. So those patches would fail to apply. Right now there's no system in place to include additional patches when domain substitution is used.\n. Some extension conveniences were added or noted in 63. If those aren't satisfactory, let me know here.. Clarification: There is no x64 build of Chromium for Windows yet. There's only a x86 version that can run on x64.\nYou have a pretty strange bug. My build machine is Windows 10 Home x64 (with Anniversary update), and it works just fine there. I also have two VMs, both of which are Windows 10 Pro with Anniversary update, but one is x86 and the other is x64. ungoogled-chromium works just fine in both of them.\nI should note that I do not have anti-virus installed, and Windows Defender is disabled. Maybe this could be the problem?\n. Closing due to inactivity and a solution has been posted. Please let me know if this is a mistake.. No, there's no security issue here. That's just the result of domain substitution with the patch that intercepts all qjz9zk URLs. Is there a problem with this behavior?\n. Well these kinds of links are scattered throughout the UI, so I don't think it's too strange.\n. These are components that are built-in to Chrome/Chromium that cannot normally be disabled. They are actually hidden by default, but there is a patch to make them show up. I think these are components that happen to use the extensions API, but they are tightly integrated, so they won't be easy to make toggleable.\nIf you don't want to use the built-in PDF viewer, I think there's a way to force it to download.\nClosing since this answers the question. Feel free to ask follow-up questions though.\n. It can be, as long as someone is able and willing to do it.\nThis is a duplicate of #56.\n. Oh neat! Thanks for doing this. Have you tested them to see if it works?\nAlso, what are your future plans? Are you planning to update the rest of the patches that use GYP? It'll be nice to know so we don't have multiple people working on this.\nBTW, you'll need to modify patch_order if you add patches.\n. > I'm only compile the original chromium with a custom config\nSo you've converted all of the GYP flags from resources/common/gyp_flags to GN args I'm guessing?\n\nBut the GYP don't have compilation problems.\n\nHmm yeah you're making a Windows 64-bit build so you don't need wow_helper, and I'm guessing you're using Google's build of yasm since you're not running both source cleaner and domain substitution. You're also not building Debian or Mac OS packages, so you didn't need to port over those. I'm kind of surprised that you didn't have to fix fix-building-without-safebrowsing.patch though.\nAnyways, don't feel obligated to fix more patches for GN. I can do them over time if no one else has by then. You've already saved me some time by doing this, so thanks again.\n. Okay, thanks for the input and the effort you've put in.\n. You need the Windows 10 SDK to build. It includes libraries and header files such as the d3dcompiler_47.dll that you are missing.\nIt should still work on Windows 8.1 even though the name doesn't seem to imply that.\nLet me know if you run into other problems. I'll re-open the issue if you do.\n. I'm not exactly sure what happened here. Did you make sure you download and extracted all of the bison components listed in the build instructions?\n. I'm not really sure what's causing your problem. I also don't have a Windows 8.1 machine to test what's going on. I'll probably build a new Windows version sometime (on Windows 10), so if I run into this issue I'll be able to investigate more in-depth.\nBTW, what version of Chromium are you trying to build? Are you building a x86 or x64 binary?\n. > chromium-53.0.2785.143\nCould you try 116 instead of 143? There is a remote chance that 143 could have broken bison. If it did, it would be much easier to narrow down the problem.\n. I did some digging and I think you also need to download Sources as well. I wrote these instructions after I setup the build environment, so I probably missed this component.\nYou can switch back to 143 since it makes no difference.\n. I'm out of ideas now. I will be trying to setup and build on Windows 10 when I get the time to, so there may be a possibility that I may figure out what's going on here.\n. Oh cool. Glad to hear it works. Though I'm wondering why there's a difference between the two.\n. Yes, this has been known.\nDuplicate of #58.\n. New tab pages don't look like that in ungoogled-chromium. It is just a small grid of recently viewed pages.\nChrome extensions can change the New Tab page to be whatever you desire. You can find a blank New Tab page extension pretty easily. Is there any reason you would want this built-in?\n. Closing due to inactivity and a solution is known. Please re-open if this is a mistake.. Hmm it's not a bad idea. But if you want this feature now, you could implement it via a wrapper script.\n. @reclaimer: I could include a wrapper script, but I was thinking about implementing this feature in the Chromium code.\n. This looks like a feature introduced in Python 3.5. Python 3.5 is the default Python 3 version on Debian Stretch, so I hadn't realized I've broken Python 3.4 support. I'll make a quick fix.\n. You can use the --user-data-dir command-line switch to specify an alternate directory for the Chromium profile. You also probably don't want a disk cache since you want it to be portable, so you should set --disk-cache-dir=nul and --disk-cache-size=0 and --media-cache-size=0.\n. @the4anoni Does my answer not answer @AlxMxlA's question?\n. @sergeevabc \nSo the Crashpad directory is created with ungoogled-chromium 55 on Windows?\nFor ease of launching in a portable mode, would a batch script suffice?. @sergeevabc If there is some data that cannot be moved with command flags, then it will be worthwhile to add a patch to do so. I don't believe deviating from Chromium behavior just to make something more elegant is worth it; feel free to correct me otherwise.. @sergeevabc ~~The first link doesn't link to a download of Chrome or Chromium. I'm assuming that is a typo?~~\n~~Also, does this happen with the v55 Windows build of ungoogled-chromium?~~ EDIT: Okay. This was fixed upstream, but the changes don't apply cleanly onto 62: https://bugs.chromium.org/p/chromium/issues/detail?id=565446\nIt's probably best to wait, so I'm closing this.. OTA support? What do you mean by OTA in this case?\n. Oh okay. I'm not very familiar with the browser's built-in update feature since I've never seen it on Chromium and I've never tried it on Chrome.\nHowever, I don't really want to implement this since there are so many ways to setup ungoogled-chromium, and I don't want to write very complicated code to accomplish something that has little value. If you have a very good reason for implementing this, let me know.\n. @reclaimer: It's not a bad idea, but I don't want that to be a part of this project. This project tries not to deviate too much from the user experience provided by vanilla Chromium. It would be fine if that extension if such extension was made into a separate project and then referenced from ungoogled-chromium's documentation (e.g. the README).\n. @the4anoni You don't need the browser to self-update to know if there's an update. @reclaimer's solution will notify users when there's an update.\n. Oh wow the whole function isn't supported? That's annoying. I guess I can change the code to use a different function.\n. Glad to hear it's working now.\n\nBy the way, is there some reason why there aren't pre-built packages available for the new releases to download (e.g. for Debian/Ubuntu)?\n\nThat's because I haven't released a new version yet. I use tags to denote snapshots of the master branch that I deem stable or \"good enough\" for general use.\nAs to why I haven't tagged a new version yet: there are a few things I wanted to fix related to buildlib, but I guess they can wait. I might tag a new version soon.\n. Interesting. It looks like the ffmpeg component of the browser is causing the browser to crash. This may not be related, but does your docker image have graphics acceleration of any sort? (you can check chrome://gpu to be certain).\nIt also may be possible that you have a newer ffmpeg library than what I built against, which is causing some problems. But the error looks like it may be some memory problem.\n. That's weird. I've used a patch that Debian provides to build against the system's FFmpeg libraries, so there could be some differences between Debian and Ubuntu's versions or possibly with these distributions and the one that Google uses. That might be why videos are causing stability issues.\nHave you had any issues with video playback in your Docker container outside of this project?\n. It's possible that some software components in Arch are much newer than those in Ubuntu Xenial that it's causing issues; e.g. X server, Mesa. Debian Stretch will probably be closer to what you have in Arch.\n. I have a feeling that this error is related to your container/environment and not Chromium or the system libraries. Is this bug report related to your issue at all?\n. Hi, sorry it took me a little while to respond to your pull request as opposed to other issues here. I have a busy schedule with some variations, so I can only respond to issues on and off.\nAnyway, does c++-4.9 exist after brew link gcc is invoked, and does it always refer to the GCC C++ compiler? I was thinking that g++-4.9 would be better to use since it generally implies GCC's version.\n. @dangom @9Morello Sorry to bug you two, but do you know the answer to the question above? Here it is again for convenience:\n\nAnyway, does c++-4.9 exist after brew link gcc is invoked, and does it always refer to the GCC C++ compiler? I was thinking that g++-4.9 would be better to use since it generally implies GCC's version.\n. So what is /usr/local/bin/c++-4.9 then? The GCC C++ compiler? I'm worried that c++ is ambiguous and may instead refer to clang if the versions happen to align. Does g++-4.9 exist?\n. Cool, that's what I needed to know. Thanks\n. Huh, I didn't know this package existed. Though I'm pretty certain you just need to manually install quilt and build-essential in order to build Chromium. I'll amend the build instructions.\n. I'm confused. Are you trying to update your system?\n. Oh I see. In that case @castor-troy, don't install either. Your system is too old to use any of the packages provided by ungoogled-chromium. You can try building ungoogled-chromium yourself, or wait until #65 is done.\n. > Does the notification come to the tab (under the URL bar) where the connection was made? Or does the notification come by default for the active tab, despite what tab triggered it?\n\nThat's a good question. I haven't dug very deep into how infobars are displayed, so I don't know the answer to that.\n\nI was logged in my Google Accounts \n\nHow are you logging into Google? Are you going purely through the web (e.g. going to google.com and clicking the sign-in button)? Or is there some interface in Chromium you're using?\n. What platform are you using?\n. @tonowoe Do you have the same issue when you try to sign-in using incognito?\n. Well it's unfortunate you're not able to replicate it. I'm not sure what you did to trigger it, but I've never seen it happen before and I can't replicate it right now. I don't see any changes between 116 and 143 that change the sign-in code.\nHowever it's a good thing you kept a record of the URL it tried to connect to. I haven't dug very deep into the source code yet, but here's what I found out so far:\n- google_apis/gaia/gaia_urls.cc: The URL is probably constructed with the constants in here.\n- Here's a list of some files that may or may not be involved with this:\n- ./components/browser_sync/browser/profile_sync_service.cc\n- ./components/signin/core/browser/account_reconcilor.cc\n- ./components/signin/core/browser/account_investigator.cc\n- ./components/signin/core/browser/gaia_cookie_manager_service.cc\n- ./google_apis/gaia/gaia_auth_fetcher.cc\n- ./google_apis/gaia/gaia_auth_util.cc\n- ./chrome/browser/ui/webui/signin_internals_ui.cc\nThe objective is to find the code (that may not be in any of these files) that is making the request to this URL. Then the next objective is to see what triggers the function to make the request.\nFor future reference, here's the URL shown in the screenshot: https://accounts.9oo91e.qjz9zk/ListAccounts?gpsia=1&source=ChromiumBrowser&json=standard\n. Just to confirm @tonowoe, did you build Chromium with all of the GYP flags, all of the patches, and source cleaning? (i.e. did you build without modifying buildlib or the files in resources/?)\n. I wouldn't think that someone that is interested in this project would want to use Google services to the extent that you are, so I've never tested these kind of cases. But even if this doesn't fit a normal use-case, it means that there is still some special treatment despite our patching efforts (although it fails at communicating with Google over HTTP/HTTPS with a domain name in the source code). This is a problem since we don't know the extent of the special treatment (yet).\nRegarding your new error, I might split it off into a new issue report if these two issues are not related. But for now, I can't reproduce your new error; I went to translate.google.com, clicked \"Sign-In\", signed-in, and then it redirected me back to translate.google.com without any infobar. What exactly did you do to get the infobar?\n. I'm not getting anything here either. Your steps are probably indirectly triggering some code that is rarely executed. Hard to say without investigating the source code.\n. Nope\n. That's not related to this issue because that's not a background request to Google. The link is broken due to domain substitution.\n. Okay, so I just got this infobar too; identical to what @tonowoe reported already. I was not doing anything out of the ordinary, so I don't know how to reproduce this.\nI can say with high certainty that this is some bug that affects all platforms, but triggers only in very specific circumstances.\nEDIT: I have been keeping my session open, and it seems that this infobar occasionally pops up on GitHub only.\n. I don't know about this feature. What is the advantage of using POST requests over GET reequests?\n. Are you using the pre-built binary or building it on your own? I know someone that uses the pre-built binary on Ubuntu Xenial and the Flash player package from Ubuntu works just fine.\n. I don't know much about vivaldi, and I don't think it's related to this. Are you able to get Flash to work if you pass in the paths directly using the correct command-line flags?\n. I don't know of any adobe-flashplayer package. You said this one doesn't work?\n. That's strange; there might have been an Iridium patch that disabled loading system plugins? I'll have to check.\nWere you still not able to get --ppapi-flash-path flag to work even with the pepperflash package? I think you'll also need to set the flag that specifies the version too, otherwise it won't work.\n. When you use the flags, you're using an equal sign between them, right? e.g. --ppapi-flash-path=/path/to/pepperflashplayer.so\n. Weird. I don't have a system to test this right now, so if someone wants to test this go ahead.\nI'm also not sure what changes have been made that are breaking this. If someone wants to help out with the investigation that would be nice.\n. @usernamenotexist There are a LOT more attack points than just Flash. To be honest, I would be more worried about JavaScript; it's essentially filling the role that Flash did back in the day. Both the tab processes and Flash plugin have to be sandboxed nowadays.\nThough this is off-topic. Please limit this discussion to the original Flash plugin issue.\n. Is this still an issue? I know someone who tried with the current version (version 57) and it crashes the browser since WebRTC is disabled. WebRTC will be enabled in the future (see #179). I'm not sure what to say because using the command-line arguments to specify the pepperflash shared object file will cause the crash. Perhaps Ubuntu installs the plugin in a location that isn't picked up by ungoogled-chromium.. 62 is out. If this is still an issue, please respond here.. Oh, ok.\n. Do you have a libav-ffmpeg56 package? If not, then you'll probably need to build packages on your own system for now.\n. @9Morello I can provide minimal support like I do with macOS. Except I won't have much time to research errors I don't understand like I have been doing for macOS.\nThough I think most users are demanding support for older Ubuntus and other distros, so it'll probably be better to get the static build to work. The code to attempt a static build has been in there for a while; I just haven't tried it out.\n. @9Morello: Cool, thanks.\n. I don't like having to give my credentials. I described the reason somewhere in #37. Plus I'm concerned about the resources they provide for building, as described in that same issue.\nFurther CI discussion should probably go to #17.\n. @9Morello Do you mean GitHub Pages? If so, then I can setup a new repository just for a downloads website on this account. It seems I can transfer ownership of repositories at any time, so I can setup another GitHub user in the future if some CI service or buildbot needs access to a GitHub account.. @lenormf What @9Morello said is correct. I will probably add the additional requirement that binaries must be signed so users can be sure it actually came from those I designate.. @lenormf I don't want to be responsible for binaries I don't build myself. Therefore, those who build binaries will be credited on the downloads page for their respective binaries. But I will still select people to have the ability to upload binaries for organizational sake. In the future, I hope to automate building so this won't be such a big problem, but I will still have someone or some people maintain the build systems.\nIn general, I don't want to take the responsibility of maintaining builds for ungoogled-chromium. I believe it is in the best interest of everyone if I stay responsible for the development of ungoogled-chromium; i.e. the entire source code. For now, I will follow a development model that's more like what Linux has (where I approve all changes made to the source code). Over time, as more developers work on ungoogled-chromium, I will start shifting responsibilities to those I feel trustworthy.. @Impyy I was thinking about using some build service like openSUSE Build Service or some CI system. I don't think paying for a service will be worth it right now.\n@9Morello We should start planning out the new downloads page. I'm thinking about using the Releases feature to have a location to upload binaries to, and then we can modify the webpage to link to them (the master branch is where the webpage will live). I'm not sure how to design the page; should we write one from scratch using Markdown, HTML/CSS, or modify a template that GitHub can generate for us?. @9Morello Cool. I'll make something simple, and we can revise it later on.. An implementation is already in place.. Wait really? What platform and version are you running? What do you do that triggers this?\n. So it's basically the same as #104 since the URL is the same, but it's a different platform and slightly different version. I have a feeling that they are triggered by the same common code, but I'm a bit puzzled why you have it but @9Morello and I don't have it.\nI'll mark this as a bug for now as I can't say for sure this is a duplicate of #104.\n. @9Morello You have a good point.\n. Due to a situation I encountered (more details in #104), I've changed #104 to capture all instances of the bug reported here, and reverted this issue back to the enhancement proposed originally.\n. I just realized this is a duplicate of #112. Going to close this as such.. Okay, sounds good. I'm thinking about adding a flag to chrome://flags to configure this since it's more of an \"advanced\" feature that most users don't care too much about.\n. Done.. Thanks for submitting this, but what are the benefits over the Windows installer system that Google provides?\n. Okay. I have created #115 to address the general issue here.\n. Interesting. Do you have proof that a DNS request is made? The only way I can see a DNS request being made is if some parts of the code bypasses Chrome's networking infrastructure (i.e. does not use URLRequest) since I've modified the code to capture all instances of the qjz9zk domain.\nAlso, using 0.0.0.0 is a bad idea. There is a possibility that a server could be listening on that address.\n. Closing due to inactivity. If you have a problem with DNS requests being made, let me know and I will re-open the issue.. You can use GPG to sign the installer file and provide the signature file as a separate download. This makes it easier for non-Windows users to sign binaries and upload them. We should discuss the signing system in more detail on Gitter or elsewhere.\nRegarding the installer, I think there are scripts and tools to create installers (EDIT: that are in the Chromium source tree). I know of mini_installer, but there may be others.. Right now I'm waiting for inox-patchset to update to 54. Also I'm waiting for Debian to update to 54 (as this is the platform I develop on). I might release another update of 53 if 54 takes longer than expected.\nI will close this issue once 54 is released.\n. This is bugging me too so I might skip over another release of 53.\n. Still waiting for Inox to update. Right now I'm working on #70, and then I will start working on #16 (which will solve some other issues). If inox hasn't updated by then, I may take matters into my own hands.\n. @gcarq Neat! Your change from GYP to GN should help me out too.. Status update: a8ba2abf2a4048d8c96e639f38deddef1bcd2f40 allows building Debian stretch packages of 54 (I am using it right now). There's still quite a bit more to go; see the 54.x.x.x milestone. #104 is up next, then #41, and then the remaining platforms will follow.. @mimf ungoogled-chromium is almost to version 55 now. It seems to be working well on Debian stretch. The macOS version seems to be a bit slower, screws up previously-saved website credentials, and Widevine support won't compile for it. It's also possible to build Archlinux builds (although there aren't any packages generated for it yet). And standard Linux builds (misnamed as Linux static) seem to work, as compiled on 14.04. Windows support is a WIP, and I've encountered an issue I'm not sure how to solve yet.\nI'm thinking about releasing a tag version very soon, regardless of Windows support.. @mimf Sorry for not being specific enough. This is a build I made on my own machine for testing purposes, and it seems to be working well. I am in the process of preparing a new tag release.. New release is out: 55.0.2883.75-1\nmacOS build will be uploaded after I get the binaries for them. Other platforms will be uploaded in the future or in subsequent releases.. I don't know if any fork of Chromium complies with the free software guidelines. If you are using Debian or Ubuntu, I adapt all of Debian's changes to ungoogled-chromium. I've also stripped almost all of the binary blobs through source cleaner (all of the machine code is gone; some data in binary form for page distillation and international components for unicode).\nAlso the sources you've referenced are based on Google's Chromium repository. If you are to bring up evidence, you should do so in reference to what is being used and what is processed through ungoogled-chromium to prevent confusion.\n. @9Morello ungoogled-chromium has not been trying to conform with free software guidelines. It has been removing the binaries from the source tree and using source code.\n. Closing as wontfix since this is impractical to accomplish without rewriting larger portions of source code to use free software. There simply isn't enough manpower.. Huh, looks like a problem with swapimport. I know upstream has made some changes for x64, so maybe they've fixed this already? I'll need to try updating it to see.\nEDIT: FYI, swapimport code is downloaded from here: https://github.com/Eloston/syzygy\n. FYI,\n\nI know upstream has made some changes for x64, so maybe they've fixed this already?\n\nis equivalent to\n\nWell there are a lot of 64bit changes in the latest commits (at the google git)\nCould possibly be a fix for this.\n\nUnless you're also making notes to yourself with these messages.\n. @nopjmp Oh huh, didn't know that. Maybe we can force swapimport to be built as a 32-bit binary despite the target_cpu GN flag?\nAlternatively, we could just not reorder imports; I remember reading somewhere that whether any performance is gained on modern Windows versions is questionable (I'm having troubles finding the Chromium bug report where this was said).. @nopjmp Yeah I didn't expect it to work. I did a hasty port without quite knowing what I was doing for certain parts.\nYou're a big help by doing this. Thanks.. @nopjmp and I have decided to disable import reordering completely, since it would take some effort to port to GN and we're not really sure how much performance would be gained in modern Windows.\nClosing as wontfix since there's no swapimport anymore.. A lot of websites are having this now. In #116, I mentioned that I will upgrade to 54 to fix this problem, so hang tight.\n. @VittGam Thanks for the tip! Do you have some documentation on field trials? I don't know about it.. @VittGam Alright, thanks.. Going to close this since the new release is out. Builds for the platforms will roll out over time as they are built and bugs are worked out.. Alright, I'll remove the option then.. Implemented in b210c28d2eb8061267df97c9a3955dc1616fe1be. Please don't mix the requests for two distinct platforms in the same issue. We can discuss CopperheadOS support in #56, since it's Android-based.\nI will dedicate this issue to FreeBSD support.. Do you see any infobar show up when you attempt to use the security key? It would be along the lines of \"Blocked request to ...\". If you don't, then some patch is probably breaking this.\nI don't know how 2-step is implemented on the browser-side, so any input here will be much appreciated.. Alright, sounds good. I'm actively working on 54 right now, but what you find in 53 will probably apply to 54.. Also wanted to mention that it's possible that domain substitution is breaking something. Even though no requests are made, it can cause of domain name matching to fail. Take for example this patch that fixes devtools.. I also found this extension in remoting/webapp/crd/js/gnubby_auth_handler.js. If the Security Key works out-of-the-box on regular Chrome, then either it's installing it automatically or it's in the source code somewhere but it's not working.\nI could just add this to the documentation, but I'm kind of curious to know what's going on.. Alright then.. Thanks for the compliment @pmico :+1: \nClosing as duplicate of #119.. I haven't worked with extensions in a while, but it could be possible that it's trying to save settings to the signed-in Google account instead of saving them locally in the browser profile. Does the developer tools page for the background page or options page say anything useful?. Ah ok. Glad to hear a solution was found.. > I like Python too, but you may be able to do all this much more easily just using a combination of standard utils and cmake?\n\nThis goes double since CMake support is native in VS2015, and I think 2013? If not there's the CMake .sln generator.\n\nI'm not sure how this will work. There aren't really any standard utilities on Windows that are the same as any other platform. And I would rather not depend on something provided by Visual Studio; I can't trust it to keep consistent with what it provides.\nBut the bigger question is: How would CMake be used? Isn't CMake akin to the meta-build systems GYP and GN (in terms of its usage and purpose)? I don't need something like that. What I need is a meta-meta-build system.\nbuildlib is the way it is now because I wanted a more powerful version of the little shell scripts I used to use to build ungoogled-chromium with. But it ended becoming a more meta version of SCons (without even knowing what SCons was until recently), which also suffers from difficult packaging. I could add a ton of options, but that would dramatically increase the complexity. I believe CMake also suffers from the same problem.\nSo my idea is based off of two ideas:\n The UNIX philosophy, in that it's better to have separate smaller utilities that do their jobs well. This makes it easier for packagers to use the utilities in a more flexible manner (much like standard system utilities).\n Meta-build systems, in that the build configuration and the tools that read them are completely separate and build configuration files should not be Turing-complete. This can make the code less error-prone, as well as make it possible to check for build configuration semantic errors. This might seem a bit overkill if this build layer will stay simple, but I think it'll still help some in the long-run.\nThough I'm still quite new to this particular topic, so I would still like to hear what you had in mind.. > The main issue is supporting 3 different platforms with their own quirks. All other build systems are code oriented.\nThe thing is, packagers don't want something that's simple and easy to use. They want something that is flexible and can integrate well with their shell-based packaging scripts; hence the reason why I propose to split it up into multiple utilities. If I leave buildilb the way it is now and add a lot of configuration options, it would be closer to satisfying the flexibility requirement, but packagers still don't like using one monolithic build system to do everything (e.g. Debian doesn't like SCONS). Plus it's a pain to maintain a lot of configuration options.\nIf it wasn't for the packaging requirement, I would probably leave buildlib the way it is now and just add a JSON-based configuration file that users could modify.\n\nIt would be best to avoid deviating away from what Google is using for Chromium otherwise we risk of falling behind on updates which means leaving users vulnerable to exploits and bugs.\n\nI won't be deviating away from that. This is just a meta-meta-build system so users won't have to apply patches or run the various source processing scripts themselves. The rest of the build process stays to how Google does it.\n\nI do understand your point on simplifying the build system, but Windows makes it a pain.\n\nMy proposal doesn't seem too bad to implement on Windows. Once I start working on it (in the develop branch), it will probably make more sense.. @lenormf Bitbake is more sophisticated than what I need. My file formats will remain relatively simple.. What has been committed now is an initial working version that needs revision to meet other objectives. Not all of the configuration options are there yet, and some scripts are buggy or untested. Only the initial Debian support is in the build files generator right now.\nEDIT: Should point out that the buildlib files will be removed once everything's been ported over.. You're trying to rebuild? In that case, make sure you comment out some lines in build.py so it won't re-extract the source code and then try to unapply patches. build.py should be treated as an example build script.\nIf you didn't do that, then you can try to salvage your sandbox by moving the out directory somewhere else, setup the sandbox again without building, move the out directory back, and then just run the build command.\n(FYI, this design isn't friendly to end-users, so this is one of several reasons why #125 exists.)\nAlso I wouldn't recommend using the -f flag. That just makes things messier. But if it works for you, that's fine.. >  I had first wanted to build chromium 6 months ago to remove google specific components when I first found out that chrome and chromium run involuntary marketing research on all computers and send the result back to google.\nWell welcome to the club! I actually started hacking on Chromium for similar reasons starting around version 25 or something, but decided to create this project  much later on.\n\nit will be great if these two variables are printed out because they change the default behavior of quilt of looking for a series file, which is what most documentation online says that quilt is looking for. I wasted some time at this step when quilt was throwing up at this step and I was trying to debug quitl and I could not find the series file.\n\nI didn't think about printing the variables because they aren't something that change. If you look at common.py, the constructor of QuiltPatchComponent class defines quilt_env_vars. _sandbox_dir is defined in the constructor of Builder. (FYI, these are the ancestor classes for the macOS builder).\nI never really anticipated anyone to have problems with the patching system and attempt to go about the way you did to figure it out.\n\nThe rebuilding of chromium fails currently, for example if there is an error at the quilt push stage, and I rebuild the code, then the build crashes at the quilt pop stage, which is frustrating because that means I have to delete the build folder and start again.\n\nRebuilding is more challenging because there's no function for cleaning up the sandbox. Re-running build.py without any modifications will just try to stomp over what's already there. Because I never really thought anyone else would do rebuilding other than me, I would just manipulate the files as I needed (e.g. modify stuff in resources, and then modify build.py to run only certain steps). Whenever I changed my patches and wanted to rebuild, I would use developer_utilities/quilt_patches.py as a quilt proxy that takes care of the environment variables for me.\nTo use buildlib effectively for other situations, one basically has to know what it's doing at each step. This is why the design document exists, but it's supposed to be a general overview and not a replacement for reading the source code.\nAlso, I have this line in the building document:\nCurrently, there is no command-line-configurable build script. You must create a script or modify build.py to use buildlib.\nThis is supposed to imply that build.py is the means for the user to use buildlib. It's not a general-purpose script that uses buildlib.\n\nCurrently the OSX build guides people to use the g++-4.9 compiler. This is bad/wrong advice. The chromium developers have moved to clang for linux and osx and I can attest that clang is much faster than g++. Furthermore I was unable to finish building using g++ but that might just be because of error on my part.\n\nI think you're confused. g++ is only used for building a static version of libc++ that's required for building the rest of the macOS build. Clang is used for everything else. This is more evident in the gyp flags for macOS, and somewhat in buildlib. When I was working on macOS support with 9Morello (in another issue report), we discovered that Google couldn't get clang to build libc++ properly (and neither could we), so we tried g++ and it worked.\n\nAlso I found that I was unable to compile chromium using the macport's version of clang, instead, I directly downloaded Clang for Mac OS X from LLVM's website.\n\nFYI, buildlib does this for you and extracts it to the proper location. Or maybe it doesn't in the latest tag. I can't remember when I implemented this change, but I know I did it.\n\nChecking the macOS SDK version is definitely important. I did not know about the SDK requirement in the beginning and I can confirm that chromium can not be built with SDK 10.12, because I wasted a lot of time with errors like unexpected token: !tapi-tbd-v2 etc.\nPlease add the following code to buildlib/macos.py in place of the TODO to check for SDK version\n\nForgot to document that. Also thanks for the code snippet!\n\nFinally, it would be pretty sweet if there was a way to bypass the step where 7,000 files are untarred from the chromium source code and put into a source hierarchy. This step takes 4 minutes only but it occurs fairly early in the build process and it's hard to skip this step, so even this step doesn't take a long time in the grand scheme, some people might have to rerun this step a number of times during debugging and that can be frustrating.\n\nThis is supposed to be a one-time deal. Unless you accidentally screwed up some files or you screwed up when using quilt, there should be no need to re-extract the source code again. Like I mentioned earlier, you're supposed to modify build.py to do what you need it to do.\nWell it seems you had a pretty rough time trying to get ungoogled-chromium to build, and mostly all of it is due to a poorly designed user interface and lack of documentation. Many thanks for your feedback as that'll help me design the new build system.. I didn't push some changes I made because I didn't want people to think that 54 was ready yet. I think I'll just keep pushing to let people know things are being done.\nRegarding your PR: it's a good patch, but it's a bit late now. Thanks anyway. The Debian version 53 builds have the VA-API patch. It seems to work. But for some reason in 54, they removed it. I heard it's broken according to this. There is also some effort in that issue report to add the VA-API patch to Inox (which this project uses patches from).\nThe blog post you linked is very old. I don't think it will help me that much.\nIf I'm understanding you correctly, what you're asking for is already implemented. If this is not the case, please let me know and I will reopen.. @piningforthefnords How's the performance and efficiency? I heard it's not as good as it is on VMware. If it's decent, I can try setting it up some time in the future if I really need to.\n@9Morello Cool. A few things that will have to be done:\n Change GYP stuff to GN: macOS-specific patches and GYP flags\n  * I am not sure if all of the patches will have to be ported over though. I think at least disable-symbol-order-verification.patch will have to be ported.\n Update extra_deps.ini against the gclient DEPS file (checking against the one in the root of the source tree should be sufficient)\n  * Check if other macOS specific dependencies are not already in the source tarball, and update accordingly\n* Bonus: See if libc++ can build with clang (downloaded via buildlib into the specific location). Chances are that it won't though.\nEDIT: I will update the GN flags and the extra_deps.ini.\nEDIT2: Done: 88d3962d4842e14e80c1bdde5fd8d655ac56c274. I've also updated the patches. You can try to see if this will build without any other changes.. Oh I pushed f3395de2fec67aa20c0c51ff2b353faa56ac327a before I saw you edit. Good thing it works now.. Whoops 485c99ebc0dc799908c73744754d0c26b81be4b1. I forgot that ChromeOS only works on Linux platforms. It should be Chrome for everything else.. Try this out 52f10858d2c702dd873dcce14b217087ac417def. @9Morello That looks like the same error that @piningforthefnords got earlier. Did you make sure you ran GN before you invoked the build command again? (i.e. generate_build_configuration()). @piningforthefnords Regarding your latest error: ecb9fb8883e83c01d1b47c1a4f756a227f17eb50. @piningforthefnords Well considering that I build with flags that are quite different from what standard Chromium uses, I'm not too surprised. From a brief glance, it looks like the following is happening:\n Fieldtrial testing is disabled, which is why --force-fieldtrials and maybe --enable-features, --disable-features, and --blink-settings are not showing up in ungoogled-chromium\n WebRTC is disabled (lack of --enable-webrtc-hw-h264-encoding)\n* Some othe features like remoting, NaCl, Safe Browsing, One-Click Signin, Google Now, Hotwording, and Google APIs are disabled. Probably causing the lack of--content-image-texture-target,--mojo-application-channel-token,--channel`, and maybe some others.\n* Some GPU acceleration stuff is not enabled by default, which is kind of strange but regular Chromium could be communicating with Google to find optimal GPU settings.\nSome of this reasoning could be slightly off but it seems to all be accounted for to me.. @9Morello @piningforthefnords Good to hear. Thanks for helping out guys.. @luckydonald You can use this build until I've updated to Chromium 55.. @9Morello Yeah we are skipping 54. Usually I would wait for Iridium and Inox to update (especially since quite a few patches broke), but I didn't feel like waiting (and I have some time) so I'm spending it by updating them. Right now I'm about halfway through a Debian build and fixing stuff that comes up along the way.\nOnce I get the Debian build to work I'm going to repurpose this issue for updating to 55.. @piningforthefnords @9Morello beb4b62aac08ffc99cc86b3fac8358d5ecc2db13 allows me to build a working version of 55 on Debian stretch. Could you guys try this out on macOS?. @lenormf Of 55? Yes. If you want a build of 54, you can get it from one of the comments made earlier. But there will be no release for 54.. @lenormf I've designated #133 for your issue. In the future, please create a new issue if the problem you're having is not related to the issue you're posting in. Thanks\n@9Morello That's interesting. I noticed that 55 also removed some Windows wow_helper stuff that was there before. I guess it isn't needed anymore? Regarding your new error, I'm looking into it.. I don't have any clue why this is happening. There doesn't seem to be any change in the invocation of the linker or compiler, and Googling this error brings up stuff related to NaCl, which has never been enabled before (and it doesn't seem related to this particular issue). If someone has an idea what changed in version 55, that will help.. @9Morello Yeah we could try that.\nEDIT: You can set enable_widevine=false in resources/macos/gn_flags. @9Morello @piningforthefnords Well it's nice to hear that it builds now, but the problems you guys are having now seem pretty annoying. The performance regressions might by caused by the refactoring to reduce the amount of RAM and CPU consumed. But I don't really notice any regressions on my Linux system, so...\nI'm wondering if there's a flag to specify whether to use the password manager on macOS. On Linux, disabling the use of GNOME Keyring will force Chromium to store passwords in its profile.\nThe fact that a manifest.json file appears is interesting... do you know if it was there with 54 or if it is created with 55 regardless of the widevine flag?. @9Morello Oh okay. That's really weird. What widevine binaries do you need to get widevine to work? Does macOS use a libwidevineadapter library file? Or is that only a Linux thing?. @9Morello Is the adapter normally built by Chromium? Do you just need to get the official libwidevinecdm.dylib or do you need both?. @9Morello @piningforthefnords Could one of you upload binaries for version 55? I would like to upload them to the new release. Thanks.\nGoing to close this issue now since macOS support is pretty much done. I will open a new issue for building with Widevine support.. @9Morello I'm not doing any builds right now so you should be good to go.. @9Morello That's weird. I didn't change anything except the widevine flag on macOS.. @9Morello What are you using Homebrew for? There shouldn't be any use of Homebrew except for quilt (EDIT and ninja).. @9Morello Well it's still pretty strange since Chromium shouldn't be depending on any source code from Homebrew...\nIt could also be possible that there's a bug in Chromium's GN configuration so that the header file you needed is actually autogenerated but there was no explicit dependency so ninja happened to build things in the wrong order. It's hard to say without digging deeper.. The macOS build has been uploaded now. Thanks @9Morello.. @Eitot Oh nice. I'll add that to the list of supported SDKs in buildlib.. Duplicate of #45 \nIf you want, you can download a build of ungoogled-chromium 54 here. It should be practically the same as what I will publish to GitHub later on.. No worries. It happens to everyone.. Chromium 53 is going to be phased out very soon. If you want, you can use a snapshot of the repo at 1a246c50b9c78a95c024442156d244baff26c54a and build Chromium 54 (which is what I'm using right now). I haven't tagged 54 because I didn't finish porting to all of the platforms. But I just discovered that Chromium 55 released, so I'm currently in the middle of upgrading the patches to that.. distro gives me different values for those functions even though our os-release file is the same. Which probably means that distro is using another method to detect the distribution; maybe lsb_release?\nCould you try the latest master version of distro.py and report back what you get?\nFYI, here's what I get with the latest version:\n```\nPython 3.5.2+ (default, Nov 22 2016, 01:00:20) \n[GCC 6.2.1 20161119] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nimport distro\ndistro.linux_distribution()\n('Debian GNU/Linux', 'testing', 'stretch')\ndistro.info()\n{'like': '', 'version': 'testing', 'codename': 'stretch', 'id': 'debian', 'version_parts': {'major': '', 'build_number': '', 'minor': ''}}\n``. @lenormf Good to hear. I'm marking this as invalid since it's more of adistro` module issue.. This is pretty neat and it's very generous of you to share this with the community. However I would prefer a solution that has all of the logic in the client, like #83. Given that privacy and openness are some of the fundamental goals of this project, I don't think involving another blackbox (i.e. the server you setup) would help reach this goal. This is not to say that you have malicious intentions, but I think a number of users would not prefer your solution.\n\n\n\nHowever, a script or extension that adds or modifies a button on the Chrome Webstore to download and install the CRX file wouldn't be a bad idea; it would be a little more elegant than one of the buttons proposed in #83.. Oh that's neat. Is there some JavaScript API to read the actual browser version in place of the hardcoded version in the URL?. @Admicos I've added your userscript to the FAQ now. Had to workaround some weird glitch that GitHub gave me when pushing though.... @Admicos Ah yeah they do. I ran into that problem with Disable HTML5 Autoplay ages ago (about over a year). It's annoying, but it's a security measure to prevent hacking for oblivious users.\nAlso I wasn't aware that there was any other user script loader other than Chromium's for Chromium. I guess that means the Chromium sourcecode has to be modified.. @mikerockett I can still drag extensions onto the extensions page to install them on Linux. What platform are you using?. @mikerockett I usually drag extensions from the file manager, so there's no chance that Chromium would interpret the dropped content as a URL.. @szepeviktor We haven't confirmed if the script actually works everywhere yet. Even if it did, I would probably just link to it from the FAQ.. @vonagam Interesting hack. Does this actually work? I was certain that Google added a restriction so that no extension or user script could touch the Chrome Web Store. (On second thought, maybe domain substitution made that checking function match against the wrong domain...)\nFYI, it's a lot easier to modify URLs with HTMLAnchorElement. @szepeviktor That may not be necessary. For content scripts in extensions, the JS namespaces are isolated. Only the DOM tree is shared (with some writing methods disabled). I think userscripts are implemented as content scripts in Chromium.. 1341b6dc50305a603d26d71aacc94b1504127886. The modern web browser is much more sophisticated than web browsers were back in the day, so there are many options when it comes to attempting a hack; you have the networking stack, plugins, and JavaScript. However, most of these hacks are pretty sophisticated and/or limited, so it'll be hard to come across in daily browsing.\nHow safe you are also depends on how Chromium is built. In ungoogled-chromium's case, a lot of newer and/or potentially privacy-invading features are disabled, like NaCl and WebRTC, so there are fewer attack points. Chromium has these features enabled by default.\nOn a related note, there have been no new tags recently, but all platforms except Windows have support for version 55 in the master branch. I might tag a version before Windows support is added if it takes too long.\nIf you have more questions, let me know.. @waqas In the future, you can just click the \"subscribe\" button on the side to listen to notifications.\n@nopjmp GNU patch from MSYS2 (which I tell users to use in BUILDING.md) seems to be fine with different line endings. What are you using to apply patches?. @nopjmp The subscribe button message wasn't for you. Anyways, it's puzzling that you needed to invoke patch that way, because it worked fine before by passing the patch data in via stdin (and it still did when I attempted to build and got that error). Fixed in #147.. I'm in the process of preparing for the next tag release. I will need to ask those over in #129 for the binaries.. @strangefreeworld Your problem isn't related to this issue report, so please create a separate issue report next time.\nAre you trying to install the Debian Stretch binaries on your system? The only reason this issue report exists is because you can't do that.. @strangefreeworld No problem. It happens to people. I might need to put a notice so people won't keep trying this in the future.. @9Morello Linux and macOS only. I only use the latest stable clang compiler on those platforms.. @mimf I just merged @9Morello's pull request that should make use of the correct builder. You should be able to build Ubuntu packages now. Though I think @9Morello said he was going to upload 16.04 binaries in the post before yours.. @9Morello I guess the ffmpeg in xenial is too old now. We could either remove patches until xenial builds, or just use the static builder.. @9Morello Oh that was simple. Going to add Xenial back to the list of supported builders now.... @mimf They're now linked in the current release. I didn't feel like making a new tag for it yet.. @9Morello This is why I don't port the dynamic builder to lots of platforms; it's extra work to add and even more work to maintain (over a long enough period of time)\nThis is especially true (as you've seen) with 14.04. There are many examples I can bring up, but just look at Google Chrome: It only offers ONE binary (I treat the .rpm and .deb binaries as one because they are just different archive formats of the same binary). For them, it's good enough even though it's not as efficient as a distribution version-specific binary. Another example would be the Linux kernel; you can definitely build a kernel that has everything stripped out except the things needed by the system (and external hardware you use) and optimize it to utilize the hardware to its full capabilities. But there are just too many hardware configurations out there, which is why kernels shipped with distributions have lots of features enabled, and make some sacrifices to keep the majority of users happy.\nI would like to thank you again for the amount of effort you've put in to the binaries for macOS, Linux static, 16.10, 16.04, and now 14.04. Once we've wrapped these platforms up, I think that will be plenty to support for now.\nClosing this issue since binaries are available now.. @9Morello Alright. You can add that info to your previous messages since I linked to them from the downloads page. In the future, we should probably use the bundled ffmpeg library.. @9Morello \"Bundled\" as in the one that comes with the Chromium source code. I refer to the libraries provided by the system as \"system libraries\". @9Morello We don't need to do that. We can just build the same Chromium version with a different release revision (a concept I borrowed from packaging systems, mostly Debian). But I'd rather not do something like that before #125 is done. The new system should make this easier/more elegant.. @pjv I don't think so. You could try getting the widevine files from Chrome and seeing if it will work, but I don't think the browser has the code to interface with them.. @Eitot Either they can comment here and I will re-open, or they can open a new issue report (since it probably won't be related to this error).. Try launching an interactive Python 3 console in the buildlib/_external directory and let me know the output of the following:\nimport distro\ndistro.info(). @9Morello Ah I see. Thanks for your input. Going to merge your PR now.. Hmm, the permission control and team features look pretty enticing. I'll check this out.. Update: I've created a new organization called ungoogled-software. Going to try it out for binary downloads and syzygy swapimport before moving this repository over to get a better feel for how it will work.. How about Gitter?. I've created a new Gitter room for ungoogled-software. The permissions that Gitter requests are pretty nice.. I haven't figured out how to setup the organization and how to transition everything over yet, but we can discuss this more on Gitter.\nClosing for now.. @stefson \nTry following Ubuntu 16.04 build instructions. You should be able to modify the files from there to do what you want.\nThere's no .debian.tar.xz because utilikit is still used to setup the rest of the source tree. The debian directory is only used for applying patch files and building.\nEDIT: It seems that the latest Chromium is on trusty, except armhf. You can probably use that to help you modify ungoogled-chromium's generated debian directory.. @stefson \n\nin order to work with utilikit, you'll need a working python3.5?\n\nYes\n\nutilikit will generate the build scripts for the user, depending upon which value of ressources/config gets activated via export UTILIKIT_CONFIG_TYPE, correct\n\nNot quite. The generate_build_files.py does not depend on UTILIKIT_CONFIG_TYPE.\n\nis anyone able to download the sources of chromium-57.0.2987.133.tar.xz via the prepare_sources.py script?\n\nYou can download the tar.xz yourself (there's a template link in download_main_source()), but prepare_sources.py can do source cleaning during extraction. I think you can use a combination of tar and some other utilities to do source cleaning during extraction if you want to.. > for the UTILKIT* variables UTILIKIT_CONFIG_TYPE , UTILIKIT_RESOURCES , UTILIKIT_DOWNLOAD_DIR , UTIL_SANDBOX_DIR it seems to be mandantory to export their absolute paths (?), even though they are in the place they intended to be.\nOnly CONFIG_TYPE is mandatory. All the other ones have default values relative to where the scripts are located in the filesystem.\n\ndoes the download work for other users? I know that I can copy over the tar.xz archive into the right place where it gets recognized, but I can't download via the scripts. Is this a bug?\n\nI use prepare_sources.py every time I update. What problem are you having?\n\ndpkg-checkbuilddeps says ninja-build, the Building.md file says ninja\n\nThat's a typo in the documentation. What dpkg-checkbuilddeps tells you is correct.. Sorry for the delayed response. I must've forgotten to submit the message before I went elsewhere.\n\nI thought it was that ubuntu-security links statical, and this project links dynamical - but pointing on /usr/lib/chromium/chromium of the ubuntu-security build via file or ldd command shows that it is dynamically linked without a doubt.\n\nI don't know of any Chromium build that is completely static. Even the official Chrome builds are not static.\n\nIs it the patchset and some of the build options which you seem to alter?\n\nYes. Please read the beginning of the README for more details.\nThe main emphasis of this project is not to provide an easy means of compiling Chromium; the build system is mainly a superfluous feature.. @stefson What do you mean by 100%? Also, I only have a Debian build which will probably differ from your binary.. @stefson If python-3.5 is already on trusty in another architecture, you could try compiling it (or cross-compiling it) for arm trusty. Though I'm not sure if there's anything that would need to be tweaked for that to work...\nYou could also run utilikit on another machine and then copy the build sandbox over to your trusty machine to build.. @stefson I don't think I understand what you mean. What would happen if you copy over the build sandbox after you've done all of the domain substitution and generated all of the build scripts?. Okay. I also think it will become increasingly difficult to do dynamic building since Chromium's libraries are upgrading over time. It'll probably be easier to use linux_conservative on trusty.. Closing due to inactivity, and it's probably too impractical.. The commit message is fine. Good implementation of the changes. We should probably disable downloading syzygy for now by commenting out the lines in extra_deps.ini so there won't be extra downloading.\nAlso what is the problem with the original code for patching? What kind of errors (or any output) do you get? The GNU patch utility I instructed users to use in BUILDING works on Windows 10.. > The patch function outputs patching but it doesn't patch anything. I can look further into it.\nThat's really weird. I have no idea what can be causing that if the patch utility hasn't changed and buildlib's invocation of it hasn't changed. Maybe it's some weird Windows silent failure?. @nopjmp Ah yeah Python 3.5 changed some stuff with the subprocess module. You should upgrade since I haven't tested the behavior with Python 3.4 on Windows (someone has on Debian Jessie though, but it's different from Windows).. @nopjmp Alright sounds good. Glad to hear that we're almost there.. Perfect. Even all of the patches and code are consistent in style with everything else. Thanks for the great work!. We're working this out in #147. Almost there!. #147 has been merged. I am going to make builds now (x64 and x86) and upload them.. Binaries are up now.. Does --disable-setuid-sandbox have any effect?. Wait you're running in a firejail? That'll break the sandbox, so yes you have to use --no-sandbox.. FYI it's slightly better to run with chrome-wrapper with statically-linked builds since they do some setup that's not done without.\nAnd it's a bit redundant to run Chromium inside firejail since Chromium's sandbox uses the same technologies that firejail does.. Wait, were you trying to run the static build outside firejail in the beginning? Or were you always using firejail?. @tonowoe @nopjmp The namespace sandbox requires the user namespace, so that's most likely the cause.\n@tonowoe Are you also running on Arch? I know Debian also disables this by default, but it's configurable at runtime.\n@nopjmp Since the bug report you linked brought up the fact that the user namespace still has problems (and will for a while), do you think that Debian would be suffering from the same problem? It seems kind of strange when you consider that Ubuntu (which pretty much uses the same kernel as Debian I believe) has it enabled by default.\nTechnically this is kind-of off-topic, but it's fine as long as we don't have two major discussions in one thread (which neither aren't ATM).. @tonowoe It's in the long list in the README near the bottom:\n\nNot necessary to install if the kernel option unprivileged_userns_clone is enabled\n\nYou can use sysctl to set the option during startup. Do man sysctl.conf to learn about /etc/sysctl.conf and /etc/sysctl.d.\n@nopjmp Regarding user namespaces, I don't really know much about the implementation details, but I have used them for my linux containers (mainly for separation of software not security isolation). I always assumed they couldn't beat VMs, but I didn't know the extent of the problems until you brought it up.\nRegarding the static build, @9Morello builds it on 14.04 LTS. But we're using is_official_build=true so we can stay as close to Google Chrome for Linux as possible. Does the sandbox work for Chrome for Linux on Arch? If it does, then we should investigate this issue further; otherwise it's an upstream problem.\nAlternatively, there's also #44 that will add better support for Arch Linux.. @nopjmp The chrome-sandbox binary only provides the SUID sandbox. It's not needed if enough of the other sandboxing features are available.\nUnfortunately I don't know anything about Chromium's sandboxing implementation. Is SBX_CHROME_API_RQ only related to the SUID sandbox?\nEDIT: You've probably done it already, but if you're going to use the SUID sandbox, you'll need to set the bit on the sandbox binary.. @nopjmp I forgot that Debian renames chrome_sandbox to chrome-sandbox before packaging. Maybe we can create a script that can set the mode 4755 and the group to root like Debian does it?\nBut I'm wondering: is the SUID sandbox more or less secure than the user namespace sandbox? Which one does Google prefer?\n\nyou can use the debian specific sysctl kernel.unprivileged_userns_clone flag to enable user namespaces as well to prevent having to use setuid binaries.\n\nDunno if you saw this message or not. I guess yours is a little more clear than mine? shrugs. > patch it like Debian did\nI'm guessing it's to prevent the browser from failing due to a permission error and attempt to use the other sandboxing technologies. Not quite \"patching\", but I'm being pedantic.\nAnyways, the way the static build is now is unfriendly to novice users. Maybe we can include a special README for static builds to inform them?. 9Morello's build is inbetween the last two releases, and nothing has really changed since the commit 9Morello built against. It shows up in the changelog because the last release didn't have the fix.. The major additional features are listed in the README. Other than that, there's no Iridium branding and no patches that redirect traffic to Iridium servers. That's all I can think of off the top of my head.\nIf there's a specific Iridium feature you're curious about, let me know.. What do you mean?. Closing this because it's almost done in #293.. This is not practical to implement due to how domain substitution works and several patches that disable translation-specific functionality. Not to mention other patches that disable code in other components, which are probably needed to make translation work. More than likely, you will have to give something else up to allow translation to work.\nThis may be feasible if this project grows and more people start contributing. But for now, closing as wontfix.. Is this for the browser itself? In that case, it isn't even enabled in Chromium if my memory serves me correctly (since Chromium's usually built by developers, so there's no point in checking Google for updates). ungoogled-chromium definitely does not have this enabld.. > I changed target_cpu in windows.py, rather than build.py as the CPUArch include is missing in build.py so \"CPUArch\" is undefined, figured it wouldn't matter. (Unless it does and causes this issue ... )\nIt really doesn't matter, but users are supposed to import CPUArch from buildilb.common. Terrible design is terrible. I can just add the import to build.py by default I guess.\n\nIs this a known issue or did I do something wrong?\n\nI built the Windows x64 build on Windows 10 Pro x64, but I don't think that's related to the issue. This is a weird error, since I don't know why the includes are wrong (for a file within the Chromium source tree, nonetheless).\nDo your versions of Visual Studio and its components match exactly to what's listed in BUILDING? Do you have any other versions of Visual Studio installed?. The older 55.x.x.x tags don't build on Windows. Only the latest one works (55.0.2883.87-1 as of now). The master branch should also work at the time of this comment (but there are no significant changes for Windows between the tag and the branch right now)\n\nI figured, you only had to run \"vcvarsall\" in the \"VS2015 x64 Native Tools Command Prompt\"\n\nActually if you launch one of those command prompts, you don't need to run vcvarsall. The only reason I need to run in this command prompt is because the bootstrap build script for the GN tool won't build without the correct PATH containing the compilers.\nHowever, this shouldn't affect the main build because Google already does the detection of the compilers during the GN build step separately from the currently executing terminal environment.\nDid you install Visual Studio to the default location? I installed it to a custom location without spaces in it. Though I doubt this is the cause of the problems.\nEDIT: Have you changed your build output directory from out/Default to something else? Assuming you didn't, do you have a file out/Default/gen/blink/core/XPathGrammar.h (within build/sandbox)? Bison is supposed to be generating this file according to third_party/WebKit/Source/core/BUILD.gn in make_core_generated_bison. > And \"vcvarsall\" is not existing outside that cmd promt.\nI figure you could prob just run it directly by specifying the full path in any cmd.exe process, but .. if you can just open the native tools cmd.. it doesnt matter.\nOh I misunderstood what you meant. I got some concepts screwed up. Yeah that's fine.\n\nnor is there a build.gn in third_party/WebKit/Source/core/ only has core_event_interfaces_file_list.tmp\n\nSees image...\nCorrects ambiguity\n\nBison is supposed to be generating this file according to ~~third_party/WebKit/Source/core/BUILD.gn~~ build/sandbox/third_party/WebKit/Source/core/BUILD.gn in make_core_generated_bison\n\nThat file should have this section in it. Then your build sandbox is broken, because it's still there in 55.0.2883.95\nEDIT: I'm still having a hard time believing that the file isn't there if the GN step was successful. What else is in that directory?. (Reposting edit so you don't have to keep checking messages you already read)\nI'm still having a hard time believing that the file isn't there if the GN step was successful. What else is in that directory?. > Think you can see that on the images.\nNope, those files are generated during the build. The path I'm talking about is part of the source code tree, not in the out directory.\n\nI unfortunately do not have the full output anymore as I tested the official chromium build to see if that fails too. (Which takes a big chunk of my SSD, leaving no space for ungoogled)\n\nAh ok. ~50 GB of files is large indeed.\n\nMaybe you can read over the guide once too, see if really everything is correct, but then again no one else reported this issue, or barely anyone compiles this on/for Windows 64..\n\nnopjmp (who fixed Windows support for version 55) was able to get both 32-bit and 64-bit to build.\nI'm starting to think that this could be a file writing/filesystem problem. From experiences I heard and had, I no longer find Windows a reliable OS for storing data. Do you have an antivirus enabled (including Windows Defender)? Do you know of any background service that could be affecting your data? I know of some PCs that come pre-installed with some special software for their SSDs that end up making things worse.\nFYI, I run a fresh install of Windows 10 Pro inside a VirtualBox VM and with a lot of things turned off/tweaked. It's possible there's some external factor (to the build process) to your issue here.. The plot thickens...\nMaybe you could comment out the following in build.py so all of the build steps aren't executed:\nbuilder.setup_build_utilities()\n        builder.generate_build_configuration()\n        builder.build()\n        builder.generate_package()\nand see if build/sandbox/third_party/WebKit/Source/core/BUILD.gn is there at the end of it.. Sure.. > EDIT: btw, is there an easy way to re-run this without having to do all the patches again and getting errors about \"already patched\" etc? So that I can test theories ?\n\nEDIT2: ^above indeed re-runs it just fine, tested whether something in the back interferes, and nope, nothing is now running, and it still produces the same error\n\nYay you figured out how to use buildlib the way it's intended to. Apparently not many people read through the entire BUILDING document...\n\nEDIT3: btw there is this file, not sure if that helps in any way, it just stood out between all the headers and source files:\n\nAs you can see from the GN file I referenced a few times, that is the input file to Bison. Bison produces the header file and a corresponding C++ source file. The fact that the file is there is good, but Bison doesn't seem to be running for some reason.\n\nEDIT4: is there any way we can make the build more verbose?\n\nI'm assuming you want to increase verbosity of Ninja. In that case, pass in -v. You can add it in on this line of common.py. > Is there a way to debug bison / the bison command lines?\nYou can modify the Python script that they use to run bison. GN can't run executables directly; the only thing it can run are Python scripts.\n\nNothing new that could help me, but maybe it helps you.\n\nNope, sorry. . > Now the problem here is, where is bisonExe defined... as in the root of it, I can't see any other usage of bisonExe in the GN file\nbisonExe is defined at the top of the Python script. GN runs the Python script with a Python subprocess given the arguments as defined in the GN file.. More confusingly, make_core_generated_style_builder is in the same targets_generating_sources list as make_core_generated_bison of the core_generated target.\nWhy make_style_builder.py is invoked but not rule_bison.py makes no sense to me either.\nMaybe we should try investigating ninja files. Does rule_bison.py show up in out/Default/toolchain.ninja?. > After this, it should do xpathgrammar, but, no output\nMaybe the commands are out-of-order. The misordering should be reflected in the ninja files. Even if we figure out how ninja is doing it wrong, I'm not sure how this is going to help us figure out what GN is doing wrong.\n\nEDIT2: I also just compared both BUILD.gn (official LKGR and ungoogled)\nSome interesting differences are:\n\nI don't think that's related. If you compare it to what we're working with, it looks like they just moved it out for better formatting/structuring.\n@nopjmp Do you have any ideas why this issue is happening?. Do you mean EDIT2 and Before EDIT2 from here? Then yes. I replied to EDIT2 in the comment before this one.. Ah. Apparently I needed to refresh the webpage in order to see edits. But if you stay on the page, new comments will show up. Going to add the new info to BUILDING.\n@nopjmp Sorry for pinging you. It's all sorted out now.. > That's a short reply .. heh.. hoped you'd say a little more.\nshrugs\nWell here's more then\n\nFun fact, this is the first time I've ever opened ungoogled chrome, since I've never got it to compile before.. be it due to this issue or the non-existent 64bit support before.\n\nCould've ran the 32-bit version but I guess you like more bits and some more security.\n\njust wonder why it doesn't show this in the build output at all.....\n\nI think bison runs m4 (IIRC from the comment in the Python script), so even if the Python script were to redirect bison's standard I/O to its own, that error would only show up if bison spat out the error.\n\n(And also wonder how to fix this, a work-around for now is using a less... spacy .. location, but that seems stupid.. should be fixed with quotation...)\n\nThere's not really much we can do, unless we patch the tools and build it. But what really bugs me is why bison doesn't throw an error if m4 doesn't exit successfuly.\nI'm wondering how Google deals with this space issue. Maybe they patched their versions of the utilities? Or somehow used relative paths? Or they don't?. You need to run it on the C: drive because the sandboxing technologies used by Chromium aren't happy with executables running on non C: drives.. Oh saw your edit. Nevermind then.\n\n(now i just need ungoogled chromium for android...)\n\nYep, would like this too. Too bad extensions aren't supported yet though.. What \"sandbox binary\" are we talking about here? And zip file? I thought Chromium just made system API calls to get sandboxing to work. Huh, I remember that it wouldn't run on my secondary HDD attached to the VM, but it would run just fine on the C: drive. Maybe they changed it now?. I created a Gitter room. We should discuss more there instead of taking this issue off-track.. Hmm this is a nice issue report, but now I don't know what to do with #56. I guess I can close that one?\n\nExtend current build system to support Android\n\nShould probably wait for #125.. @Driesje32 This is still on a hiatus. I'm going close this and leave it closed until nopjmp decides to resume. #56 is still around if anyone wants to discuss Android support in general.. I don't see how this is necessary if there is a question in the FAQ that answers the question of how to install Flash player. Seems like simple deductive reasoning to me.\nMaybe I'm dumb today too. Let me know and I can reopen.. As per the README and project description, ungoogled-chromium is a modification of Google Chromium, not a fork. I do not consider ungoogled-chromium a fork because there is already the stigma that Chromium forks are not very good and do not keep up-to-date with the latest versions of Chromium. I like to think of this browser as Chromium, but with some additional changes. This is similar to the Wine and Wine-Staging situation.\nAlso, rebranding requires maintaining an additional patch, and can break integration with other software that use Chromium. We could just rebrand the user interface part, but that may become confusing the deeper someone goes into the browser's internals.\nTo solve your issue, you can use the --user-data-dir flag to use a different profile directory and rename the main executable as suggested by @DeadSix27. \nEDIT: If you have a counter-argument, I am open to hearing it. For now, closing as wontfix.. It may not be a bad idea to add the ungoogled-chromium version somewhere. I'll consider it.. I am fairly confident that casting requires communication with Google servers to work. Correct me if I'm wrong.\nRegarding Widevine, what @nopjmp said is correct.. @nopjmp So I'm guessing Chromecasts need Google servers to work?. Well if someone wants to look into this, go ahead.. @leso-kn Thank you for your insights. I don't know anything about Chromecasts; My previous comment was pure speculation.\nIf mDNS is all that is needed to make Chromecasts function, then I think ungoogled-chromium needs to consider re-enabling mDNS and Service Discovery (via patches/ungoogled-chromium/fix-building-without-mdns-and-service-discovery.patch and the flags in config_bundles/common/gn_flags.map). However, I am not knowledgeable of mDNS and Service Discovery. For example, what kinds of security and privacy implications are there for simply enabling both? What other components within Chromium use mDNS and Service Discovery?. If I'm not mistaken, mDNS or Service Discovery sends broadcast packets. This is not acceptable for users who don't use these services and don't want traffic to leak out. Perhaps a flag could block these broadcasts?. It will probably be too difficult ot switch the entire patch on and off since the patch assumes the GN flag is always off. The easiest place to implement this toggle may be for the code that sends the broadcast packet. But I'd prefer to have the toggle at a higher level, such as for the code that loads mDNS or Service Discovery facilities, if possible.. > Arround Christmas i might actually find time to have a look at the code. I'll try to figure out a useful place for the switch to put at.\nSounds good. Feel free to submit a PR whenever you are ready.\n\nMaybe you could release a test build with mDNS enabled to see if enabling it is already sufficient for chromecast?\n\nWhat platform do you use?. Thanks for writing a patch @leso-kn. Several comments/questions:\n\nDoes the flag toggle broadcasts in #436? If I'm not mistaken, these broadcasts are related to the features being enabled/disabled by this flag.\nI'm not too familiar with the code in this area. How is DnsSdDeviceLister used in Chromium? How will Chromium's behavior change with the flag toggled on and off? (Specific files would be great, but a description will work too)\nWhat code is affected by the GN flags for mDNS and Service Discovery? How will the current patch address any privacy/security concerns related to code that will be enabled? (Like Question 2, a description will work too)\nIn line 42 of the patch file, you define a function inside another function. This is not valid C++. In addition, you assign this function to a boolean variable in line 47, which also isn't valid C++. Also, will the command line flag be guarenteed to be read (in ::Discover()) before any other function is invoked in DnsSdDeviceLister?\nInstead of creating a global variable discoveryEnabled, you could define a new instance variable in the constructor of DnsSdDeviceLister (if you still decide it is appropriate to read the flag in this class). Once you compile the code, global variables get stored in a separate region of memory. I don't know enough about C++ to say if this can become an issue once the code is compiled, but it is still conventional in Chromium code to use instance variables for scenarios like these.\n\nHope this helps. Let me know if you need clarifications.. > The patch will probably bring back the mentioned every two minute broadcasts, though i don't think it's used for anything more than printer and chromecast discovery.\nWill it only bring it back if the flag is enabled?\n\nI don't know if i got the question right; the patch doesn't add a GN flag, it adds a chrome://flags flag and a command line argument for chromium.\n\nYes, but the patch should address any other code changes that result from changing the GN flags for mDNS and Service Discovery back to their default values (i.e. enabled).\n\nAs i just said, i don't think there are any privacy issues with browsing the local network\n\nIf the flag is disabled, broadcasts are not acceptable for more cautious users, such as those who want to harden their system. It is not about the payload of the broadcast; it is the act of broadcasting itself that is the issue.\n\nThe only other methods related code is invoked in are callbacks resulting from the discovery and a reset method related to discovery. Everything happens inside a single, nicely assessable file and the patch only enables code that had been disabled by a single patch before.\n\nI don't think I'm understanding you correctly. This addresses code within DnsSdDeviceLister, but how about the users of DnsSdDeviceLister (e.g. the code that creates an instance of DnsSdDeviceLister)? Are they guarenteed to call ::Discover() first? For example, is it possible for one of the callback functions to be invoked if a device is already paired before ::Discover() is invoked?\nRegarding the new patch:\n\nYou cannot change a command-line flag during a browser session; They are only read during startup. So, the scenario you described in the code comment is not possible.\nOn line 57, you are still assigning a function to a boolean variable. This is still not valid C++.\nOn line 24, you do not need to add ShouldEnableDiscovery to the header file. Instead, you can move the whole function definition to the unnamed namespace near the top of the .cc file.. > Facing the future of this issue: Do you want me to write a propper patch, or would you prefer writing the final version yourself?\nAs i said, it's only been a little time arround christmas and work will start again soon, so it may take me some time till i can continue (in a more propper way than before, sorry about all those small mistakes).\n\n\n\nIf I write this patch, it will not help ungoogled-chromium, its contributors, or myself significantly in the long-term. I'd rather spend time on contributors like yourself, and ensuring we can reach a satisfactory solution.\nI am in no rush to complete this feature. You can take as much time as you need.. I think the clang version is too old. I compile with at least Clang 3.9 on Linux and macOS. You do not need to change the GN flags unless Clang 3.9 is not the system's default version of Clang.\nEDIT: On Debian, Clang 3.9 is available in the repository, but is not the system's default version. Thus, the GN flag is changed accordingly. Alright.. I am closing this as wontfix. At the time of writing, Chromium 56 is not stable yet. Thus, there are no updates to Iridium, Inox, Debian, or other distributor patches yet. Once those have updated and have been included in ungoogled-chromium, then we can consider features that have not been patched appropriately.. Have you tried this?. Have you tried builds from Woolyss? They customize their build flags beyond what most Chromium projects do, like Whole Program Optimization.\nIf those builds have comparable performace to that of Chrome, then we could try implementing their changes in our builds.. Hm, so there is quite a bit of a performance benefit using x32. Interesting. Thanks for the info.. @gcarq I've set fieldtrial_testing_like_official_build=true, which I think disables all of the fieldtrial testing.. If there is no benefit of building it into the source code, then it should be just linked from the FAQ.. @robotme You can follow the instructions for installing extensions from the Chrome Webstore in the FAQ.. This issue is stale. If someone wants to submit a PR to include this in the FAQ, feel free to do so.. I don't know how font customization works. Does it work on Chrome?\nYou can install extensions from the Chrome Web Store if you follow these instructions.. > after a build on arch linux this error is apparent:\n\n[20552/22635] CXX obj/third_party/WebKit/Source/modules/modules/V8MediaKeySystemConfiguration.o\n\nAre you sure you finished building? Why do you have a line from ninja in the middle of your stack trace?. > lolwat\nExactly my thoughts when I saw a ninja line there for no reason.\n\nopen(\"/usr/share/icons/oxygen/16x16/actions/go-next.png\", O_RDONLY) = -1 ENOENT (No such file or directory)\n\nIs this a part of the stack trace or something else printing to your console? Does that file exist?. If you built it on arch it shouldn't need libraries from other systems to run. Do you know which builder buildlib uses when it tries to build?. Closing due to inactivity, and since 56 will have a new build system.. Duplicate of #75.. Whoops. Thanks for catching that.. We could probably create some sort of extension that users can install to have this functionality. Or we could have some external utility to check for updates.\nI am open to suggestions.. It's a bit unnecessary to provide an external updater system for Linux, as most Linux systems come with a package system. For Mac, I think there are several packaging systems out there already.. For users of feeds, an Atom feed is available for the contributor binaries download page. FYI my proposed solution for automatic extension updates is in #285.. In addition to the Atom feed for contributor binaries (link above), there's also the Atom feed for new tags from GitHub.. @intika This is something an extension can do perfectly well. I see no need for anything to be added to ungoogld-chromium for this. Once a solution comes around, we could suggest it in the Wiki.. I've ported over pretty much everthing except the redundant patches (that were already in other patchsets) and those that redirected traffic to Iridium servers. I did mention in the README that I used Iridium patches, but I was not very clear as to what I included.\nEDIT: Is there anything in particular that you wanted to be ported over?. @lenormf Thanks for offering. I'm not sure how the new system we're designing will work out in practice, so keep that on standby in case we need it.. @gcarq Alright, thanks for the heads up.. @triceratops1 No, I will not create \"regional issues\" unless they are necessary. Please see the edit in the original post.\nI appreciate your status updates related to the tasks. As a result, I have included additional status information for all of the tasks that I will try to keep up-to-date. This should remove the need for unnecessary notifications.. @triceratops1 I don't know what you're talking about. If you look at their git repo, they're currently in the process of updating to Chromium 57 (which is currently in beta).\nSo I will be updating them by hand to version 56 and include changes from the git repo as necessary.. Status update: I have successfuly built (and ran) version 56 for Debian stretch with the current changes in develop.. @nhantrn \n\nI don't want to make a new issue, so I'll report it here. For current release v 55.x\n\nPlease do create a separate issue. Your bug is not related at all to this one. Why don't you want to create a separate issue? It's just a click of a button.. Status update: I've updated the patches to version 57 (EDIT: for Debian) and finished refactoring the new build system into utilikit. Adding support for other configurations and documenting the new build systems is up next.. @perfect7gentleman You can get the full patch order for a given configuration using utilikit/export_resources.py as it now says in BUILDING.md in develop. If you want patch orders for a specific configuration, you need to go into resources/configs and open up patch_order as documented in DESIGN.md. @leeoniya Yes, there will be Windows binaries. I don't have an ETA because no one's working on updating the support right now.. @andrewoesten No one's taken up the task to port to Windows yet. There may be some patch changes involved. There also should be some code for Windows written in utilikit.. @triceratops1 You should export the resources if you want to use them outside of utilikit. Read the documentation for more details.. @darkenvy If you mean export resources, then yes; that is all documented. There will be a pull request made soon with the changes to add macOS support.. @grandfroid No one is working on it right now, so I don't know when, if ever, it will be done.. Also an update about macOS: Support has been added back in the develop branch right now, but I'll like to have at least two people try it out to see how well it works first (for now, @tectiv3 and @9Morello). If you'd like to build it and report back here, you're more than welcome to.. macOS binaries are up now.. Development on 57 has ceased in favor of 58. See #228 . There's no way of enabling WebRTC right now without rebuilding.\n~I am planning on adding an option for it and other features.~ I will probably make them global options until we figure out a good and flexible configuration system to implement. EDIT: See status update below.\nRelated to #38.. I tried looking through the source code, but it isn't clear to me how I should attempt to add an option for this; WebRTC code is all over the place. I believe some Chromium forks have an option like this, but I don't remember their names or if they have source code. Any help will be appreciated.\nAlso, does anyone know what the WebRTC log uploader does in chrome/browser/media/webrtc/webrtc_log_uploader.cc?. @Atavic I've gathered from your links that there's logging to aid in debugging applications that use WebRTC. But, I'm still not understanding how this relates to the WebRTC log uploader I mentioned earlier. Would you be able to clarify?\nBTW, I've determined that it uploads to chrome::kUploadURL (which is https://clients2.google.com/cr/report) in WebRtcLogUploader::UploadCompressedLog. @Atavic I can see what data they are capturing now, but I'm still not understanding why they are ~~capturing~~ uploading the data. Perhaps it is for diagnostic purposes just like crash reports?\nEDIT: capturing -> uploading. @Atavic Sorry, I made a typo in my original message. I mean to ask why they are uploading the logs to Google. I don't think this is something we can gather by just looking through code. I've tried looking online, but I haven't been able to find anything either.\nBTW, Protobuf is described here. It's used in all Google projects involving some networking protocol as far as I've seen.. @Atavic Thanks for the tip, but packet capturing will not be necessary. I will add a patch to disable log uploading altogether once a switch is implemented to turn on and off WebRTC support. (I should note that log uploading won't work anyway with domain substitution.). This article has been recently brought to my attention: https://nakedsecurity.sophos.com/2017/05/31/chrome-bug-that-lets-sites-secretly-record-you-not-a-flaw-insists-google/\nI haven't investigated the situation yet. If someone knows about the UI code behind this, that would be helpful to know.\nI don't know much about WebRTC in Chromium, but perhaps we can add another feature to re-ask for permission to use WebRTC after it had stopped being used?. I have decided to change my stance on this issue. Chromium has a feature to enable WebRTC per-site, so there's really no need to have another switch for it. The log uploader will be patched out in the next stable version.\nAlso, I don't feel that the indicator light problem is enough to keep WebRTC disabled. If Google isn't doing anything about it, and Inox has WebRTC, then I see no reason why ungoogled-chromium should keep it disabled. . @macandchief Yes, WebRTC will be enabled starting with version 62. All WebRTC runtime options will be the same as normal Chromium for now.. @macandchief I've seen more people complain about WebRTC being disabled than leaving it enabled. Regarding your concern, uBlock Origin has a feature to mitigate it: https://github.com/gorhill/uBlock/wiki/Prevent-WebRTC-from-leaking-local-IP-address. @macandchief While it's true that features are removed or disabled, I don't believe it significantly improves performance (although I don't have much concrete to back this up). ungoogled-chromium pretty much does what its name implies.\nAnd I'd like to emphasize that implication, because I think the major draw to this project is really just that. ungoogled-chromium hasn't really differed much from the status quo that Chromium and Firefox are setting (and that Brave is challenging) for the Internet. Significantly differing from this takes a lot more effort that I and some sporadic contributions can do. For now, I'll just ride along in a mostly similar path.. @lulcat Can you show us how WebRTC leaks data after denying hardware access permissions and using uBlock Origin's WebRTC local IP address leak prevention feature? If you show us, I will use that to reconsider my decision.\nSo far, the only two arguments I've seen against WebRTC in this thread are the following:\n\nWebRTC leaks one's local IP address - Solved by extensions such as uBlock Origin\nWebRTC is another attack surface (security concern); WebRTC could leak data (privacy concern) - I don't have any concrete information on this. I'm not going to disable something due to an abstract concern if there are strong and concrete reasons to keep it.\n\nDo note that if someone comes along with a patch that adds an option to toggle WebRTC (e.g. a command-line flag in chrome://flags), then I would more than likely go with this.. @Atavic Insightful, thanks. But if a user is not behind a NAT, JavaScript can simply connect to a peer that can discover the IP address, right? Would the safer option be to disable all WebRTC JavaScript APIs?\nNormally it would be better to disable WebRTC via GN, but it's not a tested configuration, and it breaks PepperFlash.. @Atavic @xsmile I know of that flag, but WebRTC traffic can still pass through undetected by extensions, even if all site permissions are disabled (which are only media permissions), right? I don't think that flag is a guarantee no data will go through. If so, it's still a privacy risk.\nI'm thinking it might be possible to use the flag's implementation as a reference for a new command-line flag that disables WebRTC.. I did some research, and this is my understanding thus far:\n\nSetting disable_non_proxied_udp will prevent the computer's address from being visible, and also the ISP address when a proxy or VPN is used (except with an extension-based VPN or proxy)\nDisabling site permissions for audio and video disables camera and microphone access in WebRTC\n\nThis implies the following:\n\nOnly data channels can be established, so no more types of data can be sent than what is possible with XmlHttpRequest.\nConnections by WebRTC will not contain any more identifying information than other connections by the browser.\n\n~~That means there is no privacy problem.~~ These mean that WebRTC is no more of a privacy risk than XmlHttpRequest or other connections. (edited for clarity)\nBut, there is still a minor concern: WebRTC cannot be filtered by an extension like XmlHttpRequest. This is similar to @Atavic's point in https://github.com/Eloston/ungoogled-chromium/issues/179#issuecomment-345825985. Thus, having a flag to disable WebRTC could still be useful to someone that wants to micro-manage their connections (until extensions can intercept WebRTC connections, or an extension wraps the WebRTC interface). However, I'm not sure if there is an actual need for this.\nAny thoughts?. 6f209526c3a440d933c736d92406843a5119560c disables log uploading. Since there are no objections to enabling WebRTC, I'm closing this.. They're still on the downloads page. I don't know what you mean.... Yes, and that points to the page to download binaries for other platforms.\nThe link will be changed once the new downloads system is finalized.. In the future, please make your title as specific and as concise as possible.. I skimmed through the corresponding bug report and it seems they have grouped plugin controls with the JavaScript settings and made custom plugins loadable via the command-line. They're discouraging the use of plugins now (which makes sense considering the rapid expansion of web standards in an effort to make web applications nearly as flexible as desktop ones).\nClosing now, since all of the desired functionality is available in alternate forms.. This is already fixed in master, but I haven't released a new tag with it. I'll close this when the next version comes out.. I appreciate your support and enthusiasm for a new version of ungoogled-chromium, but please do not post content that does not directly contribute to development.\nThank you.. #176 . By \"not implementing\", what do you mean exactly? Widevine support in Chromium doesn't work without the actual module.. ~This is a warning to stay on topic. This is not the place for projecting opinions that do not contribute to development.~ EDIT: The messages this was intended for were deleted by the user at some point.. Closing this because this isn't a bug.. Huh, I wonder why they called it eloston-chromium. I only wrote less than half of the patches.\nEDIT: I guess I do ultimately decide what does and doesn't get into the project, so the name's fine I guess. But you can't find the package by typing in ungoogled which sort of bugs me.. vitorgalvao has made fair points. In that case, I will just add a section to the README about it.. @dieideeistgut There's no version 57 support for macOS yet because it hasn't been updated yet.. @dieideeistgut macOS support haven't been implemented in the build files generator yet, nor has any of the macOS-specific patches been updated yet.\nI don't know if 9Morello needs help or not. You can ask by sending a One-to-One message on Gitter.. Whoops. Will be fixed with #125.. Closing since buildlib has been deprecated a while ago.. I actually want development to occur on develop from now on (which has the new file structure). I've updated #176 to reflect this change. Also, I usually update Debian patches before updating Inox patches, so I don't know if there's a conflict yet.\nSorry for the inconvenience. In the future, please let me know via #176 what tasks you want to work on and we can discuss it on there or some other place.. Yes, spell checking in Chrome and Chromium uses binaries from Google to work. I don't know if there's a way to get it to work without the binaries, such as by using a system library.. Well I found some other links:\nhttps://github.com/electron/electron/issues/3189\nhttps://bugs.debian.org/cgi-bin/bugreport.cgi?bug=814552. I should note that language spell check may work if one were to download the dictionaries manually and insert them into the profile directory.. @avently I'm not sure. I haven't dug deep into how it works since I'm using a patch from Inox that disables dictionary fetching from Google.. Some discussion about spell checking over here: https://github.com/gcarq/inox-patchset/issues/83. New status update: https://github.com/gcarq/inox-patchset/issues/83#issuecomment-323229832. It might work because version 55 (and 56 I believe) are building on an old macOS version I think. Do the binaries that are published work on those versions?. I hadn't realized Google no longer supports 10.8 and lower.\nIn that case, I will not personally support this. I do not know how much work is involved in figuring any of this out, and there are other more important tasks to attend to. However, as usual, I will allow contributions of instructions or code to make this work.. > That Google doesn't support \u226410.8 (is this still ungoogled-chromium, right?)\nYes. Generally, the set of all versions that Google Chrome supports is equal to that of Chromium.\n\nYou are already building it for 10.9. If you target 10.8\n\nOne reason that Google dropped support for Windows XP was becauase it lacked system-provided security features that newer Windows versions have. There could be a similar- nevermind, @nopjmp beat me to it.\nAlso, I'm not sure if there's a simple switch to target 10.8 or older. Even if it was easy, you may run into issues that @nopjmp described.. > after all, it's just a browser.\nThat's what I thought at first too. But, the modern web browser isn't some simple file-rendering application like the old days. It's essentially an application runner. Just consider the new technologies like WebRTC, WebAssembly, WebGL, WebUSB, Web Bluetooth, WebVR, HTML5, CSS3, APIs to access speakers, play video, use the microphone, use your webcam, and all of the new ECMAScript features coming out. And those are just the developing web standards that all modern web browsers are supposed to support; I haven't considered non-standard technologies like Native Client or Widevine.\nAlso, I believe Chromium takes as long (or longer) to compile than the Linux kernel.\n\ncould you ask @9Morello to target 10.8? The switch is a couple of clicks away, build and wait.\n\nI will let @9Morello or anyone else make that choice on their own. Plus, I'm not sure how this would be done; could you elaborate?. > They mainly changed the compiler flags and used clang instead of GCC in 10.9.\nAre the flags backwards-compatible? Does clang work in pre-10.9 systems?. > change MACOSX_DEPLOYMENT_TARGET to 10.8\n~Unfortunately, I don't know the GN flag where global environment variables can be specified (that won't be overridden by other parts of the GN config). It would be better to have a GN-specific flag for this.~ Nevermind, see the post above.\n\nI would ask @9Morello myself, had I a means to contact him\n\nI believe 9Morello has notifications enabled, so this should not be a problem.. Every time you use @ followed by a username, an email notification and/or other forms of notification are sent to the corresponding person.. @9Morello If you still have them, could you upload them to a fork of ungoogled-chromium-binaries and then update the site configuration files? I can regenerate the HTML pages if you aren't able to.\n@pr0ggy If we aren't able to upload Ubuntu 16.04 binaries, hang tight since we're currently in the process of upgrading to version 56.. Closing since new binaries were posted. Let us know if there are still issues.. > Are there any plans to update this project more regularely?\nOf course I would like to update more regularly, but as @Kendos-Kenlen mentioned, there's a lot of work involved. Update the patches requires a lot of trial-and-error and reading the source code for changes.\nCurrently, this process is done one patch at a time, since the current update method is very simplistic (which is difficult to parallelize). However, this issue has caused me to create #193.\nClosing now since the question seems to be answered.. There's a system in place that will be documented. The scripts in this process are already in develop.. Duplicate of #17.. The develop branch is for development, and master is generally stable. Unless you know what you are doing, it is recommended to stay on master or a tag release.\nRight now, develop is currently in the transition to the new build system. Also, develop will not build because not all of the patches have been updated yet. The building documentation will be updated once more progress has been made on 56.. #37 has it all :smile: \nEDIT: To clarify, yes this is a duplicate. Also, please don't take offense to my bad joke.. Yes, the profile directories are shared by default. You can use a command-line argument to specify what directory you want to designate as the profile directory.\nEDIT: I will add something to the documentation to clarify this issue and other related ones.. d67d389329150a524319a0500fee8ef9aabc3f7b. I will change it when Inox updates to 57. For now, I will continue 56 and updating related utilities.. Maybe clang in Debian Jessie is too old. I know the one in Stretch works. What version are you running?. It's possible that version of clang is too old. Debian might be using gcc on Jessie, which is something that isn't easy to configure the current build system (i.e. buildlib) to do.\nIf you really want to, you can take the build flags and patches from resources/common and apply them manually on Debian's version of Chromium. Otherwise someone will need to add Jessie support to the new build system (which is still in development).. I just use clang 3.9 from the Debian Stretch repositories. I believe Debian uses the gcc toolchain for all of its builds, however.. I managed to get Chromium to build on Ubuntu Xenial with GCC. I think the same configuration can be used on Debian Jessie without modification. I need to move some files around, and then I'll let you test it.. Okay, I've pushed these changes out to develop now. This will need to be documented, but here are the steps to build using standard file locations from the root of the repository source:\nexport UTILIKIT_CONFIG_TYPE=linux_conservative\nmkdir build/\nmkdir build/sandbox\nmkdir build/downloads\n./utilikit/prepare_sources.py\n./utilikit/substitute_domains.py\n./utilikit/generate_build_files.py debian --flavor conservative --apply-domain-substitution\ncd build/sandbox\ndpkg-buildpackage -b -uc. > so you have to install one that's in line with modern C++/flags.\nThis is completely incorrect. Debian jessie currently has version 56 in the repository, and they are using gcc from that system to build Chromium.. ~~Whether running Jessie is a good idea or not has no relevance to this issue report. Since Debian still supports the latest Chromium on Jessie, then we should support it too.~~ Let's just stay on topic, please.. I forgot that Debian Jessie only supports Python 3.4 That line should probably be changed so it doesn't use read_bytes() and write_bytes() since those were introduced in Python 3.5. Actually, why are you using buildlib? You should be using the build steps I outlined here. Closing due to inactivity and to clean up the issue tracker. Let me know if you're still having this issue.. Thanks, but we aren't lacking computational resources at this time.\nAlso, this is a duplicate of #17.. Like I said, we are not lacking computational resources at this time. If this does become an issue, we will deal with it then.. Alright, thanks for creating the issue.\nYour issue is pretty interesting. Are you saying you see http://www.ign.com/g00/?i10c.referrer= in the URL bar after the page finishes loading? Or do you only see this in the network log? I'm running an experimental version of 56 and I'm not seeing my URL bar change at all.\nEDIT: Forgot to mention that I don't see any ads going through either.. I did some research and it may be related to this: https://github.com/uBlockOrigin/uAssets/issues/227\nEDIT: More specifically this: https://github.com/uBlockOrigin/uAssets/issues/227#issuecomment-286862915\nEDIT2: And these comments too: https://github.com/uBlockOrigin/uAssets/issues/227#issuecomment-274333802. Are you just using uBlock Origin, or are you also using uBO-Extra? I can reproduce on experimental versions 56 and 57 (which I just updated to) with just uBlock Origin. However, the problem seems to be resolved after I installed the latest stable of uBO-Extra (at the time of writing, 2.13)\nEDIT: Can you test on a browser without WebRTC and see if that has any effect? chromium.woolyss.com has some Chromium builds you can use.. Do Vivaldi and CentBrowser have WebRTC enabled? I'm not sure if this is related but it's another factor.. The fact that you reported Vivaldi did not have the issue earlier means there are some other variables at play here. Also, I don't see any reason why CentBrowser is not susceptible to this problem. Therefore, tweaking various variables and performing more trials may bring out the issue on CentBrowser too.\nI'm inclined to say that this is not a problem of ungoogled-chromium but a uBlock Origin issue affecting Chromium versions older than 58 (as mentoined in the bug report). I don't see any similarities between Vivaldi and this project other than the Chromium codebase it derives from.\nUnless you or anyone else reading this is able to show concrete evidence that some change made by ungoogled-chromium is causing this behavior, I will say install uBO-Extra as that seems to fix the problem.. The current revision of that patch in develop does not break compiling on Chromium 57, because I am running on it right now. Please check your build enviornment thorougly.. I do not accept donations. We can improve development speed by having more people work on this project. As stated in the README, I always welcome contributors.. Because I want the freedom to choose how I spend my time.. I don't know if you already knew, but it seems that Inox accepts donations. ungoogled-chromium uses most of Inox's patches (especially the Safe Browsing patch, which can take considerable time to update). Having Inox be up-to-date will speed up the updating process for ungoogled-chromium. Also, donating may encourage Inox to grow and include more patches that will reduce the work to update ungoogled-chromium.. No one is working on re-adding this support in version 57. The task is open to anyone who wants to do it. I will update #176 once someone has claimed it.. This has been implemented in develop, but it needs some work to make the build process smooth.. > If \"ungoogled-chromium\" is truly \"ungoogled,\" why is it attempting to send feedback about anything?\nBecause this:\n\nit's much more work to tweak the UI than to just shunt all the google domains & comm internally.\n\nWith domain substitution and another patch to block the substituted domains from working, I am highly confident that even with the \"Send feedback to help us fix the issue\" checkbox enabled, it won't be able to send anything.\nIf you want to know exactly how this is done, you can read DESIGN.md to find out which files and scripts you need to look through, and also developer_utilities/update_lists.py for how some of the files are generated.\nIf you have further questions, you can continue asking them here. I will close the issue now.. There is no setting for it as far as I know. If you really want to disable IPv6, you may be able to do it from the system-side (specifically or not for an application). Why do you need this feature?. I'm not sure if this is what you want, but ab70ae0d55894c6779549d127c0b231492e3239a added an option to set the IPv6 probing result to false (the default is true; the probing is for detecting if IPv6 connections to the internet will work). I haven't been able to test it yet, though.. Closing due to inactivity and to clean up the issue tracker.. What specifically do you need clarifications on that the README does not provide you?. As the README states, the listed features are specific to ungoogled-chromium. If you want to know the features borrowed from other projects, then you can browse through the patches that ungoogled-chromium uses here.\nEDIT: Forgot to mention that there's no easy way to check for updates on the Chrome Web Store. However, you can use the first URL listed in this FAQ section to get a response that includes the version in it, and then parse that through some script.. No problem. Let me know if there's anything else you are unclear about.. ungoogled-chromium, like all of my other GitHub work so far, is just something I work on as a hobby. I work on this project because I wanted a browser like this. I published this on GitHub because I thought other technical users like me would be able to benefit from the work I've done and use it in their own builds of the browser. I was originally going to leave it as a simple repository with just patches and a few scripts I use to build Debian packages.\nThe main reason I developed the build system for easy building is that I had a need for a Windows build of ungoogled-chromium. Also, it was a fun programming project to develop said system.\nI came to realize later on that maintaining support for multiple platforms takes a lot of work and time. Now, I simply no longer have the interest in spending time to maintain multiple platforms on my own. There are other things I want to invest time into as well.\nAs long as there is no other project that does all (or enough) of what is done in this project, I will continue to maintain the patches, the build system, and support for whatever platform(s) I need. I will also continue to work with those who have questions, need help, or want to contribute to the project.. If I ever decide to support Windows again, I will post about it somewhere.. > I see that you are using dpkg to create debian package and I guess you are applying patches somewhere inside it, right?\nYes, that's correct. The Debian build system uses quilt to apply patches. The build files generator just places the files in correct locations for Debian to use them.\nTo get the full set of patches that are domain-substituted, you will need to use export_resources.py. Then you can configure quilt to use the exported patch order file and patches directory, or apply the patches using any other tool you choose.. Interesting. Do you have the error message for linking that library?. > The problem was with is_component_build = true that I set to speed up builds\nAh ok. That makes sense\n\nI put up my macOS instructions in my fork so if you want I can submit a pull request.\n\nSure. I'm making some minor revisions to utilikit right now to reduce code duplication so once you submit your pull request I can make some additional changes.. Closing since macOS support is in develop. I'm going to merge this and then make revisions to several files.. Okay, I've refactored macOS support to conform to my vision for the build files generator module of utilikit. I did a simple test and the code seems to work. If there are any other changes you want to make, let me know.. The code is missing for Windows in general.. #176 includes the status for Windows.. Which package are you trying to install?. @nzytkkunit That build was made by @9Morello. I'm not sure why you're getting those errors.\n@tristan-k There is no published build of version 57 for Ubuntu.. @tristan-k It says the following at the bottom of the changes list:\n\nThe downloads below are for Debian 9 (stretch) only. Visit the downloads page in the README for other platforms.\n. A version 58 build was just pushed. I don't think it requires PPA packages anymore. Let me know if you still have problems.. Good question. I've clarified the issue report.. Nothing yet.. Alright, sounds good. Most of utilikit should work OOTB. But if something blows up, let me know.. @egorpe What do you mean by \"stock Chromium\" exactly? How are you building it? What are you using and modifying?. @egorpe Well if you followed those instructions to the letter, then you've managed to build a development version of Chromium. It's a bit of a pain to use depot_tools to checkout a stable version to build, which is why I download and build with a compressed tar file containing the (essentially) complete source code in utilikit.\n\n@andrewoesten The order to apply patches in is defined in a utilikit configuration. The resources/patches directory only contains patch files grouped by their origin. There exists a windows configuration that is used to build the Windows version (and needs updating). See the DESIGN document if you need an explanation of the contents.\nAlso, you managed to build Chromium with the VS 2017 tools? I didn't even think that was possible considering Chromium depends on VS 2015 Update 3 with a specific SDK version. Back when I worked on Windows support, even a slightly newer VS compiler broke compilation.\nI should note that there's no build script generator for Windows yet (the utilikit code needs to be written based on the work from buildlib), so you'll need to build GN, run GN, and run Ninja yourself if you want to attempt a build for now.. @andrewoesten \n\nBut on which chromium version do these patches base? It seems the 58 source doesn't have any trk: scheme etc. So the patches must be for a newer version?\n\nEverything that the debian_stretch configuration uses is updated to version 58. Also, the patches have implicit dependencies on each other (mainly ungoogled-chromium patches on other patches), so you need to apply patches in the order defined in a configuration's patch order.\nThe specific change that you're mentioning is introduced in the Iridium patch that has the trk scheme implementation.\n\nYeah I got it compiled with VS 2017 tools and the specific SDK version:\n\nIt doesn't make sense for GN to use GYP_MSVS_VERSION. Also, do you happen to have VS 2015 installed too? GN didn't blindly use the latest VS in version 55.. > Here he reads the GYP_MSVS_VERSION and also seems to support 2017.\nOh that's neat. Saves me the hassle of downloading an old compiler. The 14393 is still available in VS 2017's installer? If so, that's interesting.. @FaceHiddenInsideTheDark Wow, that's pretty neat. I haven't kept up with WSL, but it sounds like they've implemented quite a bit already. Though it doesn't sound like it will be read for end-users anytime soon, so we'll probably leave it for now.. I just discovered that this issue only has Server Error 500 on the Desktop version. If the Mobile version is used (via changing the user agent), it works fine.\nI'm reposting what I stated in #332 here:\nI'm letting everyone know that a failed attempt at bringing back Windows support is in 94ee1be3d80c6215ce44d42554ab4039b44c394a.\nAs the commit states, it fails to link the final binaries with over 600 unresolved externals. I suspect the breakage may be in windows-fix-building-without-safebrowsing.patch, since I was trying to make changes to that patch before I stopped.\nI've lost access to the Windows machine I was using, and interest in trying to find the root problem. If anyone wants to finish off what I started, please do so.. What is the output of the dpkg -i command when it fails to install ungoogled-chromium? (i.e. you didn't purge the cache). Sorry, what I mean is the stdout and stderr of the program. Is there anything different about this output compared to installing a package with a name not known to the system?. Wait, I overlooked something in your message. When you say \"not replaced properly\", do you mean that after you install it you just have that sandbox issue, or the package you specified in the dpkg command isn't even being used at all?\nYou bring up a good point that the sandboxing stuff isn't documented anywhere. I think I separated the sandbox package from the chromium package because I wanted users to have an option to use either the SUID Sandbox or the Namespace Sandbox. I'll need to check what sandbox takes priority when both namespace sandboxing capabilities are enabled in the kernel and the SUID sandbox binary is present.. I tested it out and Chromium will default to the namespace sandbox when the SUID sandbox is available. f2c1cb079dce0558bcb71476819deeca4e75b0f7 uses this fact to simplify the packages.. Did you already have Chromium packages installed from the repo? How are you installing the packages?. @Somedude98 I am confused by your output. What does ||| signify in your message? Does your command output repeat twice, or are they from two different commands?. Closing due to inactivity and to clean up the issue tracker. Let me know if you're still having this issue.. There are no plans for that right now. Getting official builds (i.e. statically-linked binaries) working is a higher priority.\nI think 17.04 might be similar enough to Stretch for that configuration to work out-of-the-box. I will accept a pull request anytime to get this working if it is necessary.. @wincinderith There is no build server. People still have to compile on their own.. @wincinderith I have a team of people maintaining binaries. Do you want to join the team?\nThe process is pretty straight-forward:\n1. Fork the binaries repo\n2. Create a new release and upload the binaries to the fork\n3. Update the main binaries repo site data to point to the uploaded binaries. People in the binaries team have direct commit access for convenience. I guess pull requests can work too.. Closing because Canonical ended 17.04 support. See #310 for 17.10 development.. There's no access control mechanism for connections made by extensions.\nExtensions are something that users have more control over compared to random code being delivered from web servers. I don't really have a need for this kind of feature since I only use extensions with source code. However, I am open to having such a feature if someone really wants to implement this.. I also don't know how the extension system works, nor do I understand the UI framework that Chromium has.\nA normal firewall might be difficult because it would need to detect which chrome processes to block via command-line arguments I believe. Even then, there may be some IPC that will make this problem even more difficult.. > I recommend that you only install extensions that you trust. For better or worse, trust is a fundamental part of IT security, as it isn't feasible to check every line of code for every software you install.\nThis is a good point. I usually tend to trust free software because it doesn't make sense in most cases to publish code online that tracks you (within reason).. Closing due to inactivity and to clean up the issue tracker.. I think this resolves the issue.. Discord uses WebRTC for voice chat, which isn't enabled yet. See #179.\nI'll close this when that is resolved.. As #179 notes, WebRTC has been re-enabled for the upcoming 62 release.. Looks good.. There is now an issue for this: #228.. It's still there because it takes extra patching to remove UI elements. The UI is generally decoupled from the feature implementations, and ungoogled-chromium focuses on disabling features, so some nonfunctioning UI is left in.\nIf you or anyone else really wants to submit a pull request to remove it, then that's fine by me.. @Shalachaska I'm pretty sure I tried disabling this before, but it required lots of files to be patched (because it also includes local service discovery, which is heavily integrated for some reason). I think I would also need to disable Multicast DNS support too (enable_mdns) since that flag can enable enable_service_discovery when set to true.\nI can try it on the next version and see what happens.. @Shalachaska Adding patches that don't change any internal features is more of a burden than it's worth right now. Disabling enable_service_discovery would also disable other features that aren't very useful, which is why it might be worth the effort to disable it.. Status update: enable_service_discovery=false has been around for a little while now.\nI've also changed my mind about the patch. I will accept a PR for a patch to remove the UI, but I will not guarantee that the patch will stay across future versions if it becomes a pain to update.. All links from the browser's interface to Google are broken due to domain substitution. Even if you go to the Chrome Web Store page manually, you won't be able to use the interface to install extensions.\nIf you want to install extensions from the Chrome Web Store, you may follow the instructions documented in the FAQ. Otherwise, you can drag-and-drop crx files on the extensions page or load unpacked extensions after enabling the Developer mode checkbox.\nLet me know if something doesn't make sense. Closing for now.. This is pretty clever. Would you be able to make a pull request? (you can use the master branch since this isn't changing any features). @macandchief That URL never worked to auto-install CWS extensions. But since 62, chrome://flags/#extension-mime-request-handling was added to change the behavior. You can set it to \"Install always\" to make it prompt the user to install.\nEDIT: I will change the option to say \"Always prompt for install\" in the next release.. I don't change anything related to that. Chromium uses the keychain to store passwords from websites. I don't know if there's any way to disable that, but your best bet is a GN flag.\nLet me know if something I said doesn't make sense.. @lenormf Thanks for making builds, but I already uploaded Debian Stretch binaries to the binaries repo. It seems the page didn't update earlier since GitHub went down when I pushed the new webpages, so I just fixed it.. Moving on to version 60.. What specific instructions are you following? Are you using Notes for other systems, platforms, and configurations? Are you using depot_tools? utilikit? What are your GN flags?. Based on your interpretation, I've reformatted BUILDING to make more sense. It's currently available in the develop branch.\nIt's not documented yet (since there are some problems with GCC vs Clang that need to be worked out), but you can try generating a build script using the linux_simple build type.. Oh yeah, I forgot to mention where that build script is and how to use it. linux_simple can be used by running ungoogled_linux_simple/build.sh from within build/sandbox (or whatever you specified your build sandbox directory to be). It also uses quilt to apply patches. And it's only been tested in a fresh sandbox.. Are you sure you generated the build files correctly? I tested the code and it still works correctly.. debian in that command is the build type. Pass in --help to that script and subcommands of it for more info.. Closing to clean up the issue tracker. Let me know if you still have problems.. Conan is an interesting recommendation. But do they allow long-running and resource-intensive compile jobs? It doesn't make sense to me from a financial standpoint to do so. I've checked out popular CI options and they are too restrictive to compile Chromium.\n\nIs our project which is using a BSD-Style license even allowed to use this package?\n\nBased on my understanding of GPLv3, you're allowed to use ungoogled-chromium as a separate module, but any changes you make must be obtainable. I'm not exactly sure how CEF works, so I can't say for sure if you're able to meet those conditions for your use case.\n\nwhy add a license restriction when you're trying to free another software project?\n\nungoogled-chromium was actually public domain until 27f62c91a1de555f51c0bc5e6afb9be9b4fb546c. That was the time when I included Inox patches, which are GPLv3 licensed. I wasn't sure what other less restrictive licenses were comptabile with GPLv3, so I chose it to play it safe. If it weren't for Inox, I would probably have used BSD since I believe Iridium and Debian both use Chromium's BSD license.. @gcarq Okay, that's good to hear.\n@a-teammate Does the BSD license work for you? If it does, I can change to it for the version 58 release of ungoogled-chromium.. @a-teammate Okay, I'll switch it in a new commit soon.\nI'm not sure if Conan.io is appropriate for this project based on what I've heard so far. But if someone wants to investigate, that's fine by me.. > We claim no intellectual property rights over the content you upload to the Website. Your profile and content uploaded remain yours. \nRight under the section titled \"Intelectual property\". I don't believe conan.io is necessary since GitLab CI can be used (explored in #37). @Croydon @a-teammate As I understand, the main problems that Conan solves are the large time and space requirements needed to build Chromium. These requirements become problematic when a contributor wants to build Chromium but lacks the physical resources to do so. GitLab CI solves this problem, because someone else's hardware takes care of that for us (see footnote).\nReplacing bundled third-party libaries in Chromium with Conan packages is not practical, since there would be some work involved to join Chromium's build system (involving GN, Ninja, specific compilers and flags) with Conan's system. Google also makes its own changes to some of these libraries, which may not be available in Conan. This may mean that only a few third party libraries can by substituted by Conan packages. In addition, the impracticality is compounded by Chromium's rapid development.\nAlso, there are possible concerns of trust by involving another third party that provides binaries to build Chromium. This is quite similar to normal Chromium using binaries in the source tree.\nAnother problem that sounds related and solvable by Conan is the use of libraries provided by a Linux distribution. However, Conan is actually a competitor to all Linux distributions, since each provides their own ecosystem of libraries.\nFootnote: One could argue there are ethical concerns for using a free service to do this, but that's up to the maintainer of GitLab CI support to decide.. Duplicate of #36.. > The latest release is only compatible with Ubuntu/Debian according to the release notes.\n\nI'd like to know why that is.\n\nBecause I run Debian Stretch, and someone I know asked me for a new Ubuntu version too.\nEDIT: Also, no one else is working on support for other platforms right now.\n\nIs there a reason why this wouldn't work for ungoogled-chromium?\n\nYou might run into issues with system libraries. I use patches from Debian to build against more system libraries.. Going to close this since everything here seems resolved.. This is because WebRTC is disabled. Inox had the same problem before gcarq decided to re-enable WebRTC.\nI will leave this open until #179 is resolved.. This should be fixed in 62, since WebRTC has been re-enabled.. What build of ungoogled-chromium are you using?\nThe .desktop file generated by chrome-wrapper is from Google's own code. This project doesn't touch that at all.\nThe .desktop file that is part of the Debian and Ubuntu packages is from Debian and work fine on GNOME 3 for me.. That package isn't maintained by me or affiliated with this project. You should post the issue on that page. \nI don't know what that maintainer did, but the .desktop file that is part of the Debian packaging scripts of this project works correctly with GNOME 3. Maybe that can be used as a reference.. There is #44, which is to add a PKGBuild generator to utilikit (but it has not gotten anywhere). Otherwise, there is an archlinux configuration type in utilikit to produce GN flags and patches to use.. .md files are Markdown files. They can be viewed on GitHub if you click on them from the project's repository viewer (i.e. the list of files you see on the repository's home page). The links from the README.md document (opened already on the repository's home page) should open them for you.\nAt the time of writing, ungoogled-chromium does not build Windows. Issue #215 was made to re-add support, but there has been no concrete progress made yet.\nBased on what you've told me, here are the general steps you'll need to take to get ungoogled-chromium working on Windows:\n\nGet comfortable using the command-line (Command Prompt, though PowerShell might work). You'll be using it extensively, and all build tools (Google's and ungoogled-chromium's) are all commandline-based.\nUnderstand the regular Chromium build process on Windows.\nUnderstanding why this process is done this way and how all of the utilities work (at a somewhat high level) is essential to understanding how the ungoogled-chromium build process works.\nI recommend trying to get a build of regular Chromuim to work, so you can get some hands-on experience with these utilities and ensure your build environment is setup correctly (this is what I did when I started working on Chromium).\n\n\nKeep in mind that you'll need to learn about GN and Python 2 and 3 in more detail. This will be important when you run into issues relating to them.\nUnderstand the ungoogled-chromium build process from its documentation\nIt will also help to read the out-of-date Windows instructions to understand Windows-specific details to the build process.\n\n\nUpdate Windows support. This will more than likely involve making patches, tweaking GN flags, and writing Python code for utilikit.\n\nKeep in mind that these steps aren't detailed at all; there is quite a bit of depth to each step.\nIf you're still interested, I wish you the best of luck! It took me a while to learn everything I know about Chromium now, and there were quite a few setbacks along the way. Keep at it, and it will pay off in many more ways than just learning about building Chromium.\nIf you need some guidance, higher-level knowledge, or help with some cryptic errors relating to ungoogled-chromium, post it here or on Gitter (link in the README).. > Damn... looks like a LOT of stuff to do to get it running.\nYeah, this is a major reason why there aren't a lot of people working on Chromium in their free time. Like many things though, the initial learning is always the most challenging.. Well those steps describe the entire learning curve, so I'm not surprised that they seem like a lot of work.. @92847586 \n\nI thought the process might be something like just needing to install Visual Studio or Python and some dependencies and then running a command to compile or something\n\nWell that's essentially how it would work once Windows support is added back in (it would be similar to the oudated Windows build instructions). Regular Chromium is even easier to setup if you use depot_tools.\n\nActually Eloston, would you suggest Iridium, or the \"NoSync, No WebRTC, No Widevine\" version of Chromium provided at Woolyoss\n\nFrom what I can remember, Woolyss's builds are identical to regular Chromium apart from some different GN flags (all of the different variants are just different GN flags). The build process is pratically identical to regular Chromium and no patches are applied, which is why it's easy to build bleeding-edge versions. However, GN flags are quite limited and cannot disable or change a lot of features.\nIridium takes this a step further by patching code and using custom GN flags. One nice feature they add is the trk scheme, which is essentially a way to check if hardcoded URLs to Google are still being used despite patching. However, they do redirect  some traffic to Iridium's own servers, which is a questionable decision in my opinion. Regarding their claim about being \"secure\", I'm not really sure what exactly they mean; most of their patches are to prevent data from being sent to Google or tweak default preferences. There aren't any patches that stand out as increasing security.\nIn the end, either option has their benefits and drawbacks. It really depends on what you need.\n\nI'd need to take university courses in coding to know what I'm doing in any of this, since I've never written any actual programming or anything\n\nFor a project like this, you don't need to take a programming class. In fact, all of my projects on GitHub so far aren't that conceptually difficult; most of it is just a matter of creating some framework (for code and potentially files) and attaching pieces to it (whether it be libraries or programming language features). You can pick up fundamental programming concepts from practically anywhere in almost any form, which is pretty much all you really need conceptually to work on ungoogled-chromium.\nFor step 1, I should clarify that it's probably best to learn the command-line as you go. That way you can connect your knowledge to something that's concrete and practical.. > If it becomes as easy as just installing dependencies and compiling, I could do that. But I suppose once it becomes that simple you'll probably just start providing binaries yourself, huh...\nYeah. It takes little effort to publish binaries once support is there.\n\nHonestly, just getting that specific VS that Chromium wants, \"Visual Studio 2015 Update 3\", was hard enough. They seem to want you to make an account with them just to get to it, and I was like, \"Screw that I guess I have to pirate it then\"\n\nWell it seems you can still get a direct link to Visual Studio 2015 Update 3 Community. But who knows how long those links will last (hopefully they stay because even the most minor of updates still change enough to break Chromium).\n\nit looks to me like Iridium is nothing more than just \"Oh, it's Chrome but with different defaults\n\nI didn't mean to downplay the significance of the trk scheme feature; it's a pretty neat and simple but effective feature. But it doesn't catch as much as I would like it to (hence this project).\n\n(I take it you keep the Linux/Debian binaries updated).\n\nI normally keep binaries for whatever platform I'm working on up-to-date. Currently, that is Debian Stretch.. FYI for users who are getting 500 Server Error on #215 \"Update Windows support\": you need to use the Mobile version instead of the Desktop version. Changing the user agent via DevTools is one way to do this.. @mercerius Please see https://github.com/Eloston/ungoogled-chromium/issues/345#issuecomment-371022101. Let's move this discussion over there.. #215 is a prerequisite. Once that is done, uploading builds is trivial and straight-forward. Therefore, marking this as a duplicate.. Did you install the Ubuntu 16.04 version 58 packages?. Hmm. I've never had this kind of problem before.\n@dubvulture It seems that @matbonucci is using your build. Do you have any ideas?. @dubvulture Does chrome://sandbox show different values on Lubuntu and regular Ubuntu?. Hm, the regular Chromium config is probably crashing ungoogled-chromium somehow. Not sure what it could be though.\nIt's probably not a huge deal, so I'm closing this.. Nice. Is there anything in the instructions or code that needs to be changed?. That's good to hear, but I have a few questions:\n\nWhy do you need to check the build requirements in a separate directory? Why do you set the config type environment variable twice?\nWhy did you disable source cleaning?\nShould I update the build dependencies to Xcode 8 and macOS 10.12 (as it says on the downloads page)? Your build instructions still say Xcode 7, and so do Google's build instructions for this version.\nWhy enable Chrome plugins for Clang?. > there is a new warning though:\n\nAs long as it doesn't cause the build to fail, then it's fine. Google likes to use unstable LLVM versions to build Chromium since they include newer warning flags and other bleeding-edge features. The Debian build uses Clang 3.8, and there are quite a few warnings per target (so there's lots of console spam).\n\nOriginally, following tectiv3's build instructions resulted in some directories not found, however I just re-run the same commands and it worked OK - weird.\n\nI assume you mean the official build instructions?\n\nRe source cleaning, I believe it is not necessary if using prepare_sources.py\n\nYou had a flag earlier that effectively disabled source cleaning, but now it's gone. Nevermind.\n\nOh Chrome plugins 'for' Clang - I thought it is to enable installation of chrome extensions from the store. \n\nNo. That flag enables the use of Google's custom Clang plugins to run some additional checks during compilation (see here for more details). I don't believe the default plugins affect the build output in any significant way.\n\nCurrently I use Chrome-Extension-Downloader and install via drag and drop. Being able to install extensions from the store would be beneficial.\n\nTheoretically, if the extensions include an update check URL, manually checking updates via the Developer mode button should be able to download and install updates. I don't know if this works or not.\nBTW, I've just updated the build instructions and extra_deps.ini.. ungoogled-chromium builds in release mode by default. One can get a debug build by modifying the GN flags as such:\n\nRemove is_debug = false (or set it to true)\nSet symbol_level to -1, 1, or 2. 2 forces the most symbols. See build/config/compiler/compiler.gni for an explanation of the settings.\n\nEDIT: It'll probably be easiest to modify the generated build script instead of modifying files in resources/configs.\nNote that these options will cause the compilation to run longer and take more space.. Huh, I had forgotten about that issue.\nAnyways, glad to see a workaround was found.. In 58 it could have been an experimental option. I don't believe any patch affects notifications, so it could be due to some macOS build flags or build environment.\nWe can test this again in the next update to ungoogled-chromium.. I don't personally provide support for macOS binaries. This will need to be coordinated with those who build binaries. But right now, there is no person designated for that.. If using the signing system integrated with applications is too difficult, then we could just fallback to signing the dmg with gpg and uploading the signature file.. > the process of installing and updating the app and its extensions makes it a bad choice for everyone but the most savvy person. Thus, I've come to see that you probably do have a different threat model and usability requirement than I do.\nI originally created this project for the more savvy person, but it has since gained traction by those who aren't as much. Unfortunately, this project doesn't have the manpower like other browsers to keep up (it's pretty much a one-man show), so it's hard for me to determine if this project will ever grow much larger. The set of people who are capable and willing to work on a project like this seems to be quite small.\nEDIT: So far the majority of contributions have been binaries. The few others that have worked on the code have came and went.. @magicgoose Signing the .dmg can be used to verify the authenticity of the .dmg on GitHub (or at least that the signer has seen that particular .dmg). The cask just pulls from the binary uploaded to GitHub without doing any authenticity check (since there's no way to do it right now).. @magicgoose \n\nIt depends on the formula. Right now it checks sha256 sum that means the formula maintainer has seen that file and it didn't change from there.\n\nI should've been more verbose. Right now, it does an integrity check but not an authenticity check. The threat model I'm going off of assumes the GitHub account can be compromised.. Let's not get off-topic here. This is about signing to verify authenticity of the original binary; the security of the client's machine is independent.. Right now, we have no way to ensure binaries on GitHub have not been modified from the builder's original binary. Signing allows us to ensure that the uploaded binaries are what the builder originally created.\n(This goes for all binaries on ungoogled-chromium actually, not just macOS app bundles.). Duplicate of #215. Please support development of a Windows version there.. I've seen someone else get this error over on Gitter chat not too long ago, and I'm not sure why it's happening. libnettle4 isn't in Debian stretch repositories, and my system does not have it.\nPerhaps there is some old package or third-party package that is depending on it. Can you check what packages depend on libnettle4?. Just one method is fine.\nlibgnutls-deb0-28 and libhogweed2 aren't in Stretch either. It might be easier to use the ncurses aptitude interface (the default when running aptitude) to see what packages are considered obsolete (i.e. not in any of the configured APT repos). Having obsolete packages in your system can cause issues with other packages.. Glad to hear you got it working. I recently upgraded a separate machine from Debian 8 to Debian 9 via switching sources.list and using aptitude, but there were some pretty cryptic conflicts until I selected to remove the \"Obsolute and Locally Created Packages\". It makes me wonder if the automated apt-get dist-upgrade command would be able to resolve this correctly.\nRegarding the future, I plan on upgrading to Chromium 60 very soon. If I can, that might also include upgrading Windows support this time around.. So you're trying to build GN?\nI'm assuming you're following the macOS building instructions?\nWhat versions of macOS and Xcode are you running?\nEDIT: Also, what are the contents of ungoogled_macos/build.sh?. I don't recall anyone ever testing on Xcode 6.3 before. All development so far has occured on Xcode 7 or 8 as stated in BUILDING.md. Closing since the issue seems to be resolved.. Could you clarify what you mean by \"arbitrary\"? Additionally, what specifically do you consider to be \"Windows native style\"?\nFor my curiosity, do you mind posting a source to your claim that Google won't change this?. My knowledge on this is limited, but I believe Chrome uses its own rendering engine for its UI. It also has a consistent UI across all of its desktop platforms. So changing the context menu style may not be trivial.. @zcyzcy88 What I mean is Aura, which is not the same thing as the web rendering engine Blink.\nApparently macOS doesn't use Aura, which is why the style is not the same there (source). @zcyzcy88 Regarding your images, it's possible the context menu in the top image is from the title bar. The title bar might be rendered by Windows, not Chrome, so the style would be different.\nEDIT: wouldn't -> would. @Streetwalrus You are correct, but I would be fine with it if someone is able to continually maintain such patch and it doesn't interfere with main development (within reason). The motivations of this project describe the core changes I want in a Chromium browser, but I don't mind other changes if they don't deviate too far from how Chromium looks and behaves.. exist_ok was introduced in Python 3.5. The other errors are probably due to features introduced in Python 3.5. subprocess.run was also introduced in Python 3.5. Does Gentoo not have Python 3.5?. Hm, that's strange. Is there a file named series in ungoogled_linux_simple/patches?. Sorry for taking so long to respond. Got caught up in other things.\nlinux_simple is not a valid utilikit config type. That is only a packaging type. You probably want to specify linux_conservative, which has conservative settings.\nAlso, it took me too long to realize how incomprehensibly cryptic my documentation is. I'll be overhauling it for the next release, as well as utilikit (yet again).. Closing due to ~~activity~~ inactivity.\nEDIT: A word.. The names of ungoogled-chromium's Debian packages match Debian's builds of Chromium. There is no v59 release of ungoogled-chromium.\nI will probably change the package name next release because it's become a hassle for me to hold back the Chromium packages.. Most of the work was finished in bad99d5b98dbc09554fc23a6cdb2ed09a00da5e5. Minor revisions will continue as necessary.. buildkit is the successor to utilikit that implements the main ideas in this proposal. Most of the work has been finished since 44efa5e7a3bb6a24c5c93cf9e8779834f7bedf55; only minor revisions or extensions for new packaging types remain.. Progress update: The develop branch as of d3f1e8ae38acd9f9916dd91a4a38504edb2e6ad9 compiles and runs successfully; I haven't encountered any regressions yet.\nI will be pulling in new changes from xsmile's update of Inox patches right now, and then start work on #248 and #247 at some point.. @tectiv3 \n7f238719fa0a16e40559df36988aecf0082a8cf3 removes is_cfi=true, which may have been causing some problems (I haven't tested building with that flag on so I don't know if it works). That might fix the Unknown attribute kind (52) errors you're getting.\nIf you've fixed bootstrap.py, you can submit a patch for that too.\nEDIT: Minor tweaks to wording for clarity. @tectiv3 I'm thinking about waiting for Inox to make a release before I do the same. Also, it would be nice to get #248 and #247 done before a new release too (but it's not too important). Iridium says they're going to update for v60 too, but I might just release another revision if they make changes worth integrating.. I find that Iridium these days skip 2-3 major versions before updating.\nI have heard of Brave and Comodo Ice Dragon, but I do not know much about them. Are there any features in particular you want to see in this project?. @92847586 Very thoughtful post with some interesting analysis and insights. I have definitely noticed quite a few \"forks\" of Chromium here and there, but many are just as you say: a repackaged browser with no new innovations. And I think the same applies to Debian, which also has many forks that shares the same core.\n\nSometimes I forget some people really just have no interest in this stuff and just trust us to deal with it so that they don't have to. They pay for the convenience and because this junk doesn't interest them, it ain't their job. I guess I shouldn't be so quick to put down every project that doesn't include core code changes\n\nAn interesting perspective, but I think there's a bit more to this than just a monetary or popularity concern (which is how I interpreted your message). Some people like certain repackagings or different UIs because it aligns better with their viewpoint of use cases without having to do additional work; I think you can see this in all of the requests people make to this repository to have binaries for various different platforms.\nNot to mention that innovation is hard to come by and good work requires a lot of resources (e.g. time, people, knowledge, money, etc.). In fact, we may place such a high value on innovation because it is special; if it weren't so special, it would just be good work (not saying I wouldn't mind already having FTL-capable starships).\nEssentially, I'm saying that all these \"copycats\" are normal and also essential to what makes life the way it is. But, you may be just grumbling at all of them and wanted to vent or something. Regardless, I enjoyed reading your post and writing this out.\nP.S. I would say ungoogled-chromium isn't very innovative either. Perhaps the most innovative aspect is the build system, which I've spent quite some time pondering, writing, and rewriting (which continues to this day).\n@Artur96 Cool, thanks for confirming.. > Will keep using Ungoogled Chromium on Linux machines either way though of course, since it seems to have less trouble keeping up on Linux (as long as that continues to be the case).\nI'll probably keep maintaining ungoogled-chromium as long as no one else wants to, or something equivalent or better comes around. It's kinda nice to have a browser like this, even though there are probably quite a few other things that have more of an impact on my privacy and security.. > Might you update to 61 instead? Since it's already out as a stable build and stuff...\nYeah I'll probably do that, but Debian hasn't updated yet.\n\nBut generally I think instead of putting yourself on a version-dependent schedule, how about just checking once a month and updating to the latest version as of that time?\n\nThis is not a bad suggestion, but my time is not predictable like that. If maintaining this project didn't require large chunks of time, then I could probably work on it more frequently in little parts at a time. Maybe I'll figure out some workflow like this at some point.\n\nExtra - if you use Windows 10, please seriously consider getting the LTSB version... it's Windows 10 without all the crapware and spying pre-installed (mostly - still disable things in Privacy panel).\n\nI looked into LTSB, but it looks like more work than it's worth. It's harder to upgrade to a newer version (needs reinstall) and some applications like Visual Studio are not supported. The last reason is a dealbreaker for me for obvious reasons.\nAnyways, I'll close this issue and open a new one for the next version I decide to upgrade to, since it's getting kinda long. Hopefully this happens sooner than later.. @LeFroid Nice! Thanks for the work; it means a lot. I'll merge in these changes when I get the chance.. > although it took more manual intervention with ninja's build process than I'd like - such as manually directing ninja to build a protobuf target because it attempted to build the targets relying on that code first.\n@LeFroid Oh man, that might be a pain to fix. Do you know what ninja file was the cause?. @LeFroid Hmm. Well that should give some hint to the GN file that'll need to be patched (I'm assuming it is a GN file misbehaving due to the safebrowsing patch. I can't tell what the root cause is right now). I'm not able to take a closer look right now.\nHave you noticed the problem happening consistently?. > I'm building version 61.0.3163.91 now from a clean source tree, and just hit that error about 2/3rds of the way through\nHmm alright.\n\nBesides that, I noticed that the patch debian/gn/scheduler.patch is no longer needed, the code addition from that patch already seemed to be in the source tree\n\nNot too unexpected. That patch is from Debian, and Linux distributions pull in fixes from upstream on occasion. Debian hasn't updated to 61 yet, but it sounds like that patch will more than likely be removed.\n\nI'll see if I can come up with a fix for the ninja build, although I'm not too familiar with the build system since the transition was made from GYP to GN\n\nNo worries if you cannot/run out of time. The GN documentation isn't the easiest thing to read, and GN has several fundamental differences from GYP that'll take a little bit to get used to. Though YMMV.\nBTW, are you updating all the patches yourself, or are you including updated patches from xsmile's updates to 61?. @xsmile @LeFroid Let's move this discussion to #262.\nUnrelated, but with @xsmile being here, it just feels like ungoogled-chromium and Inox are getting even closer. We've already referenced each other in our READMEs and share patches back and forth, and we also keep up-to-date with each other's GitHub project activities. I can't decide if it's better this way or as one project.... @92847586 In response to this comment:\n\nWould be kinda cool to see a sort of UGC-Inox merge if that's possible.\n\nThere are two main downsides of a merge I can think of:\n\nCollaboration takes more effort. gcarq and I would need to co-ordinate efforts, which could have problems due to our inconsistent schedules and differing workflows. Right now, each project can be independently updated.\nI don't know what gcarq's vision of Inox is. At their cores, Inox and ungoogled-chromium have similar objectives, and some patches get shared between them. But that's where the similarities end. For example, ungoogled-chromium has a lot more patches than Inox that increases the time to rebase on a new Chromium version. Also, UI branding would require some effort to sort out too.\n\nThough, there are a few benefits for merging:\na. More manpower. Collaboration also allows for effective usage and delegation of available manpower.\nb. Development's more consolidated. Good for keeping track of issues relevant to both projects.\nIt should be noted that neither gcarq or I have made the initiative to talk to one another. The only thing I know from gcarq about a collaboration is this reddit comment from about a year ago (which is when I started thinking about this on-and-off).. @chew-z Development on version 60 has stopped, so there won't be a version 60 release. But, you could try asking someone here for binaries if you want.. @pjv I don't want to publish binaries on the contributor download page if a tag isn't out for it. For now, you can follow the instructions here up to step 3, then share the link to the release in your own fork.. @nyancat18 I had no idea that 62 would be coming out soon. In that case, I might merge in some changes for 61 and then wait for 62 to release before I upgrade everything else.. I do not think this is a good idea. Although it would be nice to have native support, it would be an enormous undertaking.to implement it.\nHowever, if anyone has a patch and is willing to maintain said patch, then let us know and we'll go from there.. I'd advise you not to build for Windows yet. See #235 and #215 for more details.\nFYI, the source package and symbolic link issue you're having is normal. The Python scripts used for extraction either attempt to create a symlink or just ignore it completely.\nEDIT: At least they're supposed to do that. I haven't tested on Windows.. @chantisnake \n\nIt would help me a great deal if you can add your binary download to your release.\n\nDo you mean GitHub Releases, or the ungoogled-chromium contributor binary downloads page? Or are you asking for a Windows support update (i.e. how @wimh interpreted the message)?. The GitHub Releases of this repository in particular or of any other contributor's repository?. I've stopped posting binaries to this repo. Binaries are now uploaded to forks of ungoogled-chromium-binaries, which are then referenced by the .ini files and generated HTML files in that repository. . Sorry, but the current binary publishing system doesn't allow for that. The system was designed to meet ~~two~~ three requirements:\n1) A group of people (currently me) manages what gets published.\n2) The same group of people need not to do a lot of work to publish binaries.\n3) It should be relatively straight-forward and simple for builders to submit binaries for publishing, but requirement no. 2 takes priority within reason.\nYou could try writing up a simple script to poll the GitHub Atom feed for recent commits, and then check for new .ini files in the windows platform configuration directory. Then the .ini files can be parsed for direct download links to the binaries.\nI also apologize for any inconveniences this system has caused you, but it's the best one I could think of so far. If you have a better method that meets my three requirements, then I would be happy to hear it.. Looks good.\nBTW, are you not using quilt to refresh the patch? I noticed the filenames are different in the patch header, which I think quilt removes if you use it to manage patches. There are some usage examples in DEVELOPING.md. In the latest commit (which is after the successful build I made), I enabled cfi for all platforms to follow xsmile's changes for Inox. I'll probably disable it for now since it will decrease performance a bit (unless cancelled out with LTO which I didn't enable due to the memory requirements, and Debian doesn't come with a new enough Clang to use ThinLTO).. 7f238719fa0a16e40559df36988aecf0082a8cf3 removes is_cfi=true. This might fix the problems you're having with GCC.\nIf Clang 3.9 is working for you, you could also try to follow the Debian 9 (stretch) instructions. It has more flags and uses more system libraries, but there may be some libraries in 16.04 that are too old. linux_conservative does not have these changes; it is intended to be a \"lowest common denominator\" build configuration that can build on a variety of system configurations.. Those are some interesting errors. There shouldn't be any other changes to media-related flags other than rtc_libvpx_build_vp9 which I think is WebRTC-specific (and your errors don't seem to be specific to WebRTC).\nIt could be possible that is_component_ffmpeg=true on its own is breaking the build... Ubuntu also sets is_component_build=true. However, Ubuntu's xenial build uses Clang 4.0 now.\nYou might have better luck if you use clang-4.0 by modifying CLANG_BASE_PATH in debian/rules and change the component GN flags. EDIT: Or try modifying the Debian 9 files to use Clang 4.0.\nFYI, ungoogled-chromium's configuration builds with proprietary codecs by default. You'll need to change the FFmpeg branding and proprietary codecs GN flags if you don't use the system's FFmpeg. linux_dynamic and its descendents are the only configurations that use the system's FFmpeg.. The libffmpeg.so warning can be fixed by splitting off a separate package just for libffmpeg.so like Ubuntu has it, so chromium-shell and regular Chromium can both depend on it. Or FFmpeg can be statically linked into the main executables.\nThe Widevine warning is fine, since that shared library is provided by the user when they want to use Widevine DRM.\nWere you able to test the main browser by installing and running it?. > Does this mean that it has to be included in the final release build or it's not necessary?\nFFmpeg is required, but how it's included doesn't matter too much. I'll probably just change it to static linking since it's easier, since the problem with proprietary codecs remains with either option.. baf81bb4b0c712bfbaf1ab5b5a6496b691e90a68. What platform are you running on?. What distribution and what version?. Closing due to inactivity.. It is impossible with 16 GB. IIRC, I've seen my build directory consume around 40 GB after the build finished. You will also need at least 8 GB for compiling and linking.\nIt may be possible to build with 64 GB of RAM (assuming you configure tmpfs to grow large enough. I think the default maximum is half the available RAM).\nAlso:\nhttps://github.com/gcarq/inox-patchset/issues/93\nhttps://github.com/gcarq/inox-patchset/pull/90#issuecomment-325148498\nAre you in a hurry or something?. @perfect7gentleman How much space does the whole build tree take at most?\nEDIT: I mean space. @nyancat18 perfect7gentleman said that Chromium can build with just 16 GB of RAM and no swap file. The CPU used does not have an effect.\nI would like to try it myself when I get the chance. It would definitely speed up compilation.. Building entirely from tmpfs does work, and is noted in 417b43295b94354c4a269e2a6d0ef145cea029bb for Debian Stretch builds.. Huh, neat.. The reasoning from @Artur96 is correct. AFAIK privacy and security are ~~still intact~~ not degraded with that button, so I see no reason to make a cosmetic change that deviates from Chromium's behavior.\nEDIT: wording. If you're following the build instructions, just ignore the generate_build_files.py step and everything afterwards.\nFYI, domain substitution or source cleaning may break support for some platforms right now.. @shak3800 It's coming, but slowly. I am not certain when I can release a new version.. @dimqua They're mostly patches to integrate with Debian better, such as patches to use system libraries. There are also a few very minor tweaks, a couple of which are privacy related.. @dimqua Because I use Debian.. Since 62 came out, focus has shifted onto it. Partial work has been done already, but I'm currently waiting for Debian to release a new version in order to continue.. @Calinou Can you show me which patch? In all of the time that I've dealt with Debian's Chromium package, I have never come across such patch.. @khalibadelni https://github.com/Eloston/ungoogled-chromium/issues/262#issuecomment-338043924. I cannot guarentee that I will finish updating to 62 in a timely manner once Debian updates. You can view more details about development in https://github.com/Eloston/ungoogled-chromium/commits/develop.\n@Calinou My previous message came out harsher than I intended; my apologies. Are you able to recall where you saw the change you mentioned? It's just for curiosity's sake.. @LeFroid Awesome. I'll merge your patch after I merge in Debian changes.. @leedoyle Not from me personally. It depends on what other people contribute.\n@sergeevabc Hmm... might as well prefix \"62\" with \"3\" before I forget then.. Debian released Chromium 62.0.3202.75-1. If nothing comes up, I plan to resume work next weekend.. I'm writing this message from 91a96717f6e5a2b1ee191c0c94dd8eb6aef8fe92, and the tip of develop is being built right now. I don't think anything I've committed since my last build will break anything, so everyone is welcome to try it out.. Just published 62.0.3202.94-1 with Debian 9.0 (stretch) binaries. Please consult the Wiki for current platform support.\nEDIT: Please note of the changes in the first comment: https://github.com/Eloston/ungoogled-chromium/issues/262#issue-258240886. This will be the format used in future issues like these.. Development on 62 has ceased in favor of 63.. @sergeevabc ungoogled-chromium has always been developed in bursts with long gaps between, because it's just a side project. If you're expecting more consistent and ongoing development, then most Chromium projects like these will probably disappoint you.\nPlatform support is lacking because it takes a lot of tedious work; it's time-consuming and not interesting. Not to mention the learning curve involved (see #235).. @chew-z @sergeevabc I believe it's unfair to group Linux with macOS or Windows.\nOn Linux, updating the build configuration and patches on one distribution essentially updates support across all other Linux distributions. The only major problems after that are distribution-specific changes to link against system libraries or work with the toolchain provided by the distro, which are already solved in the distribution's Chromium package (if it exists). ungoogled-chromium is just being generous by allowing modified versions of these distro-specific build scripts to be included for the ease of the user. Since not everyone can maintain such a script for their own distro, I plan to implement linux_portable so it can work across a variety of distros and compilers.\nOn macOS and Windows, I use the same build configuration and patches as I do on Linux, aside for changes specific to Linux. Even then, this configuration contains many deviations from the official build process or processes used elsewhere, so there ends up being many problems no one else has run into. These issues are generally not straight-forward, so they require experimentation and/or thorough investigation to solve (which is very* time-consuming). A subset of them require extensions to ungoogled-chromium's custom build system to automate, especially on Windows (otherwise there will be a lot of manual labor).\n@sergeevabc, you specifically pointed out Windows support in your comment. Windows deviates more from Linux than macOS does (in the toolchain and system APIs), so I suspect there will be quite a significant effort to get it updated.\nFootnotes:\n* This is mostly because I and the others I work with lack knowledge of how Chromium is built at the level it is failing. None of it is conceptually difficult.. I don't think I understand your question @nyancat18, but based on what @xsmile said, utilikit is supposed to be an extensible framework to build for multiple different platforms. But I haven't heard of fpm before; might be interesting to look into.. @nyancat18 utilikit can already be scripted based on the build instructions if you want that. Otherwise, utilikit can generate a shell script for buliding on Linux.. Fixed in 91a96717f6e5a2b1ee191c0c94dd8eb6aef8fe92. I'm not sure at this point. How are you building it?. linux_simple is not a valid utilikit config type. Perhaps you mean linux_conservative? You could also try archlinux.\nEDIT: I don't know if archlinux actually works, or what kind of setup is needed to make it build. It should be similar to Inox (gcarq's inox-patchset) though.\nThe other commands look fine to me.. The documentation (as it is now) does not explain it clearly, but the utilikit config type and the build files type are not the same thing. The utilikit config type is set through an environment variable, and the build files type is set in the argument to generate_build_files.py. Only the utilikit config type needs to be changed.. @Alex2242 Are you trying to build the develop branch? You shouldn't be getting that error on master.. @avently This seems to be a problem with ungoogled-chromium's code, but I'm not sure what the problem could be. I think the problems with the other configurations show that Archlinux support is finicky at best.\nFor now, I think it's best to hold off until the next stable version of ungoogled-chromium. I think trying to fix 58 may be more effort than it's worth.. @avently Alright, will do :+1: . @avently The GN flag icu_use_data_file=false is supposed to disable the use of icudtl.dat, and it works on Debian. Debian and Arch essentially have the same GN configuration, so I don't know why this is failing specifically on Arch.. After a quick search, it seems the only thing that might be making a difference is the unbundle script. This script essentially replaces some GN files so Chromium builds against more system libraries. Since the ICU library has a corresponding file, the unbundle script is probably causing Chromium to use the system ICU library, which may be bypassing the dependency on icudtl.dat (and also icu_use_data_file=false).\nSo, you could either:\n\nRemove icu_use_data_file=false and add back the original icudtl.dat\nRun the unbundle script in resources/packaging/debian/standard/scripts/, which will cause Chromium to build against more system libraries. But I have a feeling that this may break something else since 58 is pretty old.. Fixed in 5ca1b6e7bdcad5d32b5a998c69312758f681e6c1. Will figure this out myself.. Duplicate of #242 . In the forseeable future? Probably not. There's not enough activity for the project to keep up-to-date. If anything, only support for new platforms (mobile or desktop) will be added.\n\nOf course, I'm not going to reject anyone that wants to add support for this themselves, but I don't think it would be a wise time investment for most at this stage.. Closing for above reasons.. This seems like it breaks casting, which some users use. I don't see how Media Router violates any of ungoogled-chromium's goals, so I'm not merging this unless proven otherwise.\nEDIT: Design document for Media Router & Web Presentation API for reference. The instructions should always download the latest stable version of Chrome (which is version 61 at the time of writing). This is three versions ahead of the current stable for ungoogled-chromium, so there may be some incompatibilities that are causing it to fail. You might have better luck if you get the Widevine module from Chrome 58.. I modified your instructions for it to apply more generally.. Fixed in a3118ba8c1079487f1441cd0a14b4b0e87be577c. Fixed in a3118ba8c1079487f1441cd0a14b4b0e87be577c. 49 came out so long ago that I don't even remember much from back then. I went to check and found out that was still when I only supported Debian.\nSo, no. There is no configuration or instructions for building version 49 on Windows XP. I don't think it is reasonable for me to support a browser that is 13 major versions old, so I'm afraid you'll need to go elsewhere for additional help.. 62 isn't ready on my own platform, so it won't be ready to test on other platforms. I'll announce in #262 when it is ready for test building on other platforms (which I hope isn't too long from now).. A pull request for this huh...\nHmmm\nThis is mildly interesting.. Although it would be nice to include the entire patch, it seems to touch a lot of code that could break between version updates. I don't want to spend that much time updating features that aren't the main focus of ungoogled-chromium.\nIs there a separate font patch? I can only see one patch that includes everything.. I don't want to sift through all of the changes to extract out the font changes since it's a really large patch. The developer should probably be contacted after Windows support is added back into ungoogled-chromium, though.. Sorry, but ungoogled-chromium doesn't have enough resources to handle feature requests like these. This should be reported upstream.\nIf anyone is willing to maintain a patch for this, then feel free to submit one.. I'm closing this for the same reasons as #280. Again, anyone willing to maintain a patch is free to submit one.. I must've forgotten to respond to this. Sorry about that.\nI honestly don't care too much about what default search engine ungoogled-chromium uses; I have been just borrowing whatever Inox uses. If someone wants to write a patch to set the default or add new search engines, that's fine by me. More options won't hurt at this stage.\nHowever, I'm not going to remove the other search engines. Based on my experience, not all users of this browser have the same privacy requirements, so there may be someone who would want to use one of these other search engines.\nI don't believe tagging is worth the effort, because those kinds of choices are transparent enough for the user to understand the implications of choosing said choices. Plus, I don't see a nice way to tag search engines in the manner you want without changing the name, and I think that will ruin the cohesive appearance of the search engine list.. Based on your content, I will assume the context here is the Debian packages.\n\nThe difference between --temp-profile and --incognito is unclear from the manpage and not even mentioned in the FaQ. Since --temp-profile is apparently unique to ungoogled-chromium, it should probably be clarified.\n\nThis is partially correct. --temp-profile is unique to Debian's Chromium. ungoogled-chromium did not change the behavior. The implementation is in the script /usr/bin/chromium.\n\nI also think the Debian installation guide should warn users that the apt tools will confuse ungoogled-chromium with the official chromium, and attempt to \"upgrade\" to the official one.\n\nThe develop branch has all package names prefixed with ungoogled-. This change will be merged to master in the next release of ungoogled-chromium.\nOn a related note, I think that the --temp-profile and \"bug tracker\" documentation issues should be reported to Debian. Additionally, it might help to distinguish flags or environment variables introduced by Debian from existing ones.\nHowever, I will change the \"bug tracker\" section for ungoogled-chromium's packages to link to GitHub Issues.\nClosing since I don't believe there is anything else for ungoogled-chromium to do. ~~I will make the bug tracker tweak right now (which will show up on develop)~~ EDIT: I will make the manpage change later since Debian just has a small patch to modify Chromium's default manpage. I will also add the alias ungoogled-chromium for the manpage (if it is not a lot of work).. No need to purge the package. The configuration files can be reused by ungoogled-chromium, so you only need to delete.. > Anyone know how to fix these issues, apart from obliterating the profile?\nI think the profile should be fine when ungoogled-chromium updates to 62.. I'm not sure how I missed this issue. Is H265 working for you?. I don't know much about codec support on Windows. Help will be appreciated.. I see. If anyone wants to try it out, please let us know how it goes. Feel free to submit a PR; if no one else does, I will add in a patch sometime later.. How are you installing them?. Hm, I can confirm the behavior. Can these extensions still be updated via the Update extensions now from Developer mode?. Hm, that's interesting. It would be nice if we could use the update URL defined in the manifest file to check for extension updates.. @matthewd673 In addition, BUILDING.md states that Windows instructions are out-of-date. Currently, no one is working on re-adding support (but there is a small chance I might re-add it).\n@garoto I'm having the same issue with #215 here too; consistently getting error 500. I just sent a support request to GitHub.. @ribatamu Yep, working here too.. Nope, there are no other Windows builds than what you've seen. There won't be any until #215 is done (at the time of writing, it seems to cause GitHub to consistently throw a 500 error.). > What I am not doing correctly?\nBUILDING.md states the Windows instructions are out-of-date. Right now, I don't think you can get a Windows version to build without doing a lot of work manually.\nI don't know what is going on with your repository, but you should probably just clone a fresh copy from a directory that's not in a git repository.\n\nThis builds for windows are pain in the a.. when you don't know how to do them :)\n\nNope, it was always a pain to setup the build environment. The development was even more so, but it's nothing compared to what Google has to do.. See issue #215 (whenever GitHub decides to fix its problem) and #235 for more details if you're interested.. Sure, I can add this in. Even though it's not a high-priority feature, it looks pretty simple and straight-forward to patch. Plus, your post contains pretty much all the info I need to write the patch (thanks for the well-written post BTW). But, if Chromium significantly changes the code and breaks this patch, I won't go out of my way to rewrite it.\nI haven't looked at the source tree for 62 yet, so if you already know the answers to these questions it'll speed things up a bit:\n Is kTabStripStackedLayout configurable by the user at all? I don't see any configuration UI changes in the Issue you linked. You mentioned the pref code would have to be redone?\n What does adjust_layout do?. Hmm alright. I'll add options for both and see what happens.. Added in that referencing commit. Closing.. Sorry, I can't afford to spend time on old versions. If you can make builds, you can remove the patch that disables search engines in that version.. https://github.com/Eloston/ungoogled-chromium/blob/cd992fb1804bf05e9b285f99a8137a3e742bdaee/resources/common/patches/ungoogled-chromium/disable-omnibox-searching.patch. I think you need to change this line's path to base/synchronization/waitable_event_mac.cc. The macOS GN bootstrap patch probably needs to be updated.. I'm not sure what's causing the issue. It looks to be a problem with the GN files, but it doesn't make a lot of sense. If anyone has ideas, let us know.. @tectiv3 \nDoes #297 fix your problem with waitable_event_watcher?\nWith the bundle_contents_dir, it seems to be a context-dependent variable. The error is strange though, because it should be defined here, since that template is used in this file, which is a dependency here. It's quite possible that I'm misunderstanding the meaning of some keywords like public_deps, and how the namespaces are being modified as a result.. > but even after adding them,\n\n      base::WaitableEvent::WaitableEvent(base::WaitableEvent::ResetPolicy, base::WaitableEvent::InitialState) in base.a(waitable_event_mac.o)\n      base::WaitableEvent::UseSlowWatchList(base::WaitableEvent::ResetPolicy) in base.a(waitable_event_mac.o)>\n      base::WaitableEvent::Signal() in base.a(waitable_event_mac.o)\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\nld: symbol(s) not found for architecture x86_64```\n\nremains\n\nI assume you mean \"base::mac::internal::MacOSXMinorVersion()\" is missing based on what your comment source shows (it's not visible for some reason).\nPerhaps you could try adding the files\nbase/mac/mac_util.h\nbase/mac/mac_util.mm\nto somewhere in this list.. @tectiv3\nBased on the code around here in base/BUILD.gn and some quick grepping:\n\n\nAdd the following lines to the mac-specific base.sources list:\n'base/mac/scoped_typeref.h',\n'base/time/time_conversion_posix.cc',\n'base/time/time_mac.cc',\n'base/mac/dispatch_source_mach.cc',\n'base/mac/dispatch_source_mach.h',\n'base/mac/scoped_nsobject.mm',\n'base/mac/scoped_nsobject.h',\n'base/mac/mac_logging.mm',\n'base/mac/mac_logging.h',\n\n\n\nRemove the following from the POSIX-specific base.sources list:\n'base/threading/platform_thread_internal_posix.cc',\n\n\n\nAdd the following to the mac libs list:\n'-framework', 'IOKit',\n\n\n\nTechnically, the following should be added to the if is_posix and not is_mac: section added by the patch, but it doesn't matter too much since this is a mac-specific patch\n'base/threading/platform_thread_internal_posix.cc',\n'base/synchronization/waitable_event_mac.cc',\n\n\nAlso, base/synchronization/waitable_event_posix.cc shouldn't be deleted in the patch\n\n\n\nProbably would've been easier to send a patch instead of this.... I did some more investigation, and found out that the master branch version of chromium repo has documentation on bundle_contents_dir right after bundle_root_dir. However, there is no such reference in 62.0.3202.94, not even in the example for bundle_root_dir. I even did a grep for contents_dir, and found nothing in the GN source code for 62.0.3202.94.\nPerhaps the version of GN that is included in 62.0.3202.94 is out-of-sync with the rest of the source tree? It wouldn't surprise me that they don't bother to keep it up-to-date, since GN is normally downloaded from Google via depot_tools (as done by gclient by reading DEPS in the root of the source tree; the name of the hook is gn_mac). @Artur96 @tectiv3 Please clear out your source tree and update to the latest code in develop. I have changed LLVM+Clang from 4.0.0 to 5.0.0, and I'm trying out the GN code from 63 in 62, since I haven't seen a 62 source tree that has a GN implementing bundle_contents_dir. I have a feeling that this may break, but it's probably easier to fix than to backport a GN change from 63 to 62.. Included https://github.com/Eloston/ungoogled-chromium/issues/291#issuecomment-348392101 in 82ac9ac55257b5fe6462f7fea777ceac98ba95d3. Right now I don't have plans, but I may reconsider after #248 is done. I wouldn't count on it, though.. Ah, thanks for reminding me. In #248, I was going to support using a patch since it's more transparent and easier to update than replacing files.\nRight now, you'll need to apply the patch to standard manually.. > In order to build on Xenial these patches are needed to work with ninja 1.5.1\nAlright, thanks.\n\nShould they be included in the linux_conservative patches? Is that configuration even used for any other distro besides Ubuntu 16.04?\n\nYes, linux_conservative is supposed to be a build configuration that's generic enough to work anywhere (i.e. it has conservative build flags in contrast to linux_dynamic). It's supposed to work anywhere just like building regular Chromium does. On a tangential note, linux_official is basically linux_conservative but with is_official_build=true GN setting.\n(On a more unrelated note, your questions are reminding me about the documentation refactoring...)\nEDIT: To be clear, \"conservative\" is in respect to how much it will depend on the system. Regular Chromium is pretty self-contained, whereas linux_dynamic tries to depend on system libraries as much as possible (\"dynamic\" as in shared, or dynamically-linked libraries). Perhaps I should choose better names for these build configurations.... Heads up: https://github.com/Eloston/ungoogled-chromium/commit/816ceda92319ec24734ee7cd3f567b1008387260. I think these names are an improvement.. > These warnings pop up during compilation:\nThose warnings are fine as long as it doesn't cause problems in building or the final binary.\n\nAnyway I'm not really sure this patch is needed. Those flags are working with clang>=3.9 which is required for linux_portable\n\nIt's a dependency for Debian minimal, because it's a dependency for standard, because I believe it's best to use the newest clang possible to follow what Google does (also, I like new things). Debian minimal probably only needs to depend on gcc, because Debian (and I believe Ubuntu as well?) still use gcc.\nTo clarify ungoogled-chromium's build system a bit more, the linux_portable build config is independent of Debian minimal packaging config; in general, build configs and packaging configs should be decoupled. They're used together because they both share the same goal of compatibility (of building and running) over system dependencies. In the future, new packaging configs can be added that package linux_portable in different ways (e.g. different distro package formats, simple archiving, and single-file app package formats).\n\nAnd last but not least, build fails at [...]\n\nI'm not sure what is causing that build failure; if I had to guess, maybe it's because we didn't set use_custom_libcxx=false. I have a feeling that there may be some additional flags from linux_rooted that will need to be copied over to linux_portable.\nDo note that if clang just keeps causing problems, we could probably switch to gcc. This may also increase compatibility with older systems that have an even older clang.. > The only feedback I'm getting is a segfault somewhere much like #237 but erasing any older chromium configurations does not help. Plus, the same happens on a fresh system so I don't think it's related.\nIf the --disable-namespace-sandbox command-line flag fixes your problem for your segfaulting build, try applying opensuse/fix-kernel-user-namespace-crash.patch to your source tree and rebuild. You should be able to use the namespace sandbox after that patch is applied (as reported in chrome://sandbox)\nIf the above doesn't fix your problem, try adding these GN flags:\ngold_path=\"\"\ngoma_dir=\"\"\nlinux_use_bundled_binutils=false\nuse_allocator=\"none\"\nuse_custom_libcxx=false\nuse_gconf=false\nuse_gnome_keyring=false\nuse_gold=true\nuse_jumbo_build=true\n\nBuild with is_debug=true and symbol_level=1 failed at linking process throwing an incredible amount of undefined references.\n\nIf you still have the output, what kinds of undefined references are there?\nAlso, you don't need to set is_debug=true even if you set symbol_level=1. (Source: Chromium's docs/clang.md. If you want to draw ideas from that document, I wouldn't recommend setting is_component_build=true since it can break things). I haven't seen any behavior like that before. Maybe it's a clang issue on Ubuntu Xenial? We could try to build with GCC by setting is_clang=false and pull in the GCC patches from Xenial (or maybe from resources/patches/opensuse). So, let me see if I'm understanding you correctly:\n\nWith debug options enabled, both gcc and clang lead to the libtrknotify.so crash that you showed above.\nWith debug options disabled, using GCC causes the browser to work normally (e.g. YouTube works fine)\nWith debug options disabled, using clang 3.9 results in a build that partially functions (e.g. the YouTube homepage always crashes)\nYou haven't tested clang 4.0 at the time of writing \"EDIT2\" (IMO, it probably won't be different from clang 3.9).\n\nAre these right?. This is a shot in the dark, but I suspect all these behaviors are related to libtrknotify, and the differences are caused by the build type (Debug vs. Release) and compiler behavior.\nFor now, I will put this on hold. Chromium 63 is out, and Iridium updated its patches to 62.. 63 is ready for testing, so let me know how that changes things.. Hm, ok. I'm not sure if this affects debug symbols, but I recently added debian/fixes/optimize.patch.\nUnrelated, but do you still need Node.js since there is optimize_webui=false in common? I don't need it in my build.. I tried building linux_portable with linux_simple, and everything worked on the machine used for building Debian Stretch packages.\nWith the current code in develop, here's what I did from the ungoogled-chromium source:\nexport UTILIKIT_CONFIG_TYPE=linux_simple\n./utilikit/prepare_sources.py\n./utilikit/substitute_domains.py\n./utilikit/generate_build_files.py linux_simple --apply-domain-substitution\ncd build/sandbox\nexport CLANG_BASE_PATH=/usr/lib/llvm-3.9/\n./ungoogled_linux_simple/build.sh\n./out/Default/chrome\nand everything just works.\n(I should note that I have user namespaces support enabled already, and I didn't build the SUID sandbox.)\n. Try a54128418114c0d6d8a4e5f4530cbf0d126bde71. So, it seems that the missing files caused Chromium to break. Since the different compilers resulted in varying behavior, I'm wondering if it was the GL shared objects that are the causing the major problems. Those pages you linked in https://github.com/Eloston/ungoogled-chromium/issues/293#issuecomment-355673840 may be using may be using certain web features (such as certain CSS transforms) that cause Chromium to use 3D acceleration, thus invoking GL.\nEDIT: Just tried moving those files away in my build and it doesn't seem to change anything. I'm at a loss for what is happening.. I have reverted the minimal packaging type patch, and switching the build to use LLVM 5.0 with LLD (which is available in 17.10). I will try this out and see how it goes.. The standard flavor seeems to be working on 17.10, so I don't think I will try minimal this time. And since minimal worked in 63, I believe this issue's resolved already.. All I can say is: #215. If you're curious to know what ungoogled-chromium changes, then I highly recommend that you look only at code in ungoogled-chromium. Pointing out specific features or changes from a project that is used by ungoogled-chromium is not representative of ungoogled-chromium.\nThat being said, that kind of change you've referenced is one of the changes ungoogled-chromium did not borrow from Iridium. Unfortunately, I can't recall all of the other changes that weren't included off the top of my head.. I've pushed 9855e1efa00b21aeb86bde0e265c0bae3d7fcb08 in an attempt to emphasize my point.\nEDIT: Rewording a bit in 0f2a8c56c32e1e678c400dd2ab4497ecca5143c4. #215 . I'm going to guess that this has something to do with disabling safebrowsing. There is a chance this may has to do with GN configuration. I don't have time at the moment to investigate.. Yep, in common. I was thinking about going through GN files to find what invokes build/toolchain/mac/filter_libtool.py, and how libsafe_browsing.a gets involved.\nEDIT: The original message has been deleted by the other user, so this has lost context.. Thanks, just merged. If you want, you can submit a PR to add a binary to the downloads page; there will be a litte bit of time before 63's released.. I decided that it'll be easier to update based on your changes than fix conflicts later. So, I'm merging now. Thanks for the work!. @stfnhrrs Yep. It's in the milestone, so it's safe to assume it will be worked on during the version 63 development cycle.. I'm currently running 0611409007f7079234a330cc571e0527a830b72a, which is version 63 on Debian Stretch. Feel free to test.. Moving this macOS discussion to #321\n  . Because of #247, #248, and #329, I am ceasing development of 63 in favor of 64.\nEDIT: 64 development status is in #332 . Could you give me more details about your installation? What binaries and version are you using?. That package isn't maintained by me; someone else is providing that. The only information I know about Arch Linux packages are in #44.\nIf I had to guess, the packager probably wasn't able to get sandboxing to work at all, so they might have set --no-sandbox in a wrapper script. This is all I can say based on what I know now.. In this release, I have introduced a page about platform support. It is noted there that the Debian conservative packaging type is broken right now.. No idea. If no one figures it out beforehand, I'll investigate after progress is made with version 63.. @PonyPC I, too, would like to know your method. Based on your patch, I only see removal of Safe Browsing code from various files.\n\nHow did you figure out that the remaining references to various Safe Browsing code was causing the linker to include the non-existant Safe Browsing static library? Is this some behavior of build/toolchain/win/tool_wrapper.py or .ninja files?\nWhat did you use to find the references?\n\nEDIT: I will include these changes in 63. Thanks for the help!. @PonyPC Ah, I see. GN was the missing link that made everything here \"click\" for me.\nFrom what I understand, the static_library keyword in GN causes the linker to look for a corresponding static library file, hence your original error. So you removed the GN dependency, which removed the visibility of header and source files in chrome/*/safe_browsing. To fix it, you patched out those references (many of which are Windows-specific since the existing Safe Browsing patch removes the cross-platform references), which made the build work.\n@tectiv3 you can remove the //chrome/browser/safe_browsing line that @PonyPC has done, and then try building. You will encounter errors about missing headers and such in chrome/*/safe_browsing/ and related paths; just patch them out in the same manner that is done in the existing patches. If trial-and-error isn't your style (or is too sloppy), you could use some code analysis tool to find includes of the path chrome/browser/safe_browsing or chrome/common/safe_browsing, and patch those files.\n@ribatamu FYI, because @PonyPC seems to be using Depot Tools, there is a high probability that domain substitution or source cleaning were not used. As a result, Google binaries were involved in the build and could be included, and there may be an occasional leak from the browser (e.g. #302).. No one's built it with the archlinux build type. You could try with the linux_portable type and see how it goes, but there may be some things you'll need to fix along the way.. Can you post the errors? I only see warnings.. How are you trying to build? What happens if you try to apply this patch?: https://github.com/Eloston/ungoogled-chromium/blob/master/resources/patches/inox-patchset/breakpad-use-ucontext_t.patch. > does it means i'm already using it when building?\nNo, because it's not used in the Debian 9 patch order list. So, you'll need to apply it yourself.. v63 no longer requires the breakpad patch. You can try building it and see how it goes.. Building on 17.10 using the instructions in develop works for me. Let me know if you have issues.. Is this is the Debian build I made? Are you running this on Debian 9 amd64?. It might be some system library incompatibility, but it's hard to say since debugging symbols weren't built. You'll probably have to build it from source, unfortunately.. LGTM :+1: . @tectiv3 Any ideas? I don't know why your's and @Artur96's systems differ like this.... What Xcode and OS X SDKs are you guys using?. @Artur96 Good find! If that commit is in 63, it may be easier to just wait for 63 to come out.. According to your linked bug report, it isn't trivial to add an option that disables autocompletion. So, it would require a significant amount of time to write something that isn't working towards ungoogled-chromium's main objectives.\nEven though I have no issue with the Omnibox and agree with Google's decision in the bug report, I will allow a patch to add this option if someone's willing to maintain it.\n(FYI, If Backspace didn't clear away inline autocompletion, I would also be a bit annoyed). 63 is ready for testing. If this is still a problem, please report here.. Could you guys report what arguments are passed into crashpad_handler? What's the parent process? Is there an instance of run_with_crashpad anywhere?. For reference, here's documentation for Crashpad: https://chromium.googlesource.com/crashpad/crashpad. @tectiv3 Do those processes have any parents or children that should be noted?. Hmm, well it seems none of the debugging options will be easy. Either we look through the code and patches, do a debug build/make modifications and debug at runtime, or both. I haven't worked with this area of Chromium before so I have no ideas.. I was thinking about it, but I'm not sure how integrated the crashpad client (or the whole client module) is in Chromium. It may not be that straight-forward to remove. That can cause some more unintended side-effects.\nIt's an option we can take if we aren't able to fix crashpad_handler.. Could you guys check to see if dbf4c0e58765b77b9e3569facd3eee589084b0ee changes anything? I doubt this is the cause, but I'd like to be certain.. @stfnhrrs I just finished up major rework to the build system. I'm starting development on 64, so we can test again once I merge everything in.. @sebvargo If you experience this with 72.0.3626.109-1, please create a new issue. Thanks.. What @dubvulture said is correct. Because my focus is on version 63, I can't support major development on 62.. Yes, the GN flag is broken because Google doesn't support it on desktop platforms. ungoogled-chromium is not going to disable WebRTC unless it causes a security risk or breaches privacy; see #179 for a more detailed explanation.\nUnless shown otherwise, I am closing this as invalid.. This was already discussed in #179. You are welcome to submit a PR.. I've heard that changing these settings will break some websites like Google Hangouts or Discord. Plus, these settings can be configured via the extension API; uBlock Origin has an option for this.\nAs a result, I won't include these changes unless you have another reason for doing so.. Note to self: There are still search engines being added, such as when using the search bar on pypi.python.org. 4d5674ff45b9a217e32ce995f4eda04813037546 fixes the patch and finishes this feature.. Closing until new building issues arise.. @tectiv3 It appears the changes you made to ungoogled-chromium/macos/fix-gn-bootstrap.patch in #322 created an invalid patch. Would you be able to fix that? Thanks. @tectiv3 If you're able to, I'll appreciate some input in #315 . LGTM. That looks about right. Thanks :+1: . I've never seen that kind of behavior before. What do you mean by \"hiding\"? What do you see instead?. I don't know why this happens. Does this happen on regular Chromium?. In that case, there might be something in the Inox or Iridium patches that I've included (Inox includes some changes from Iridium, and Inox patches are applied first, so I've left those Iridium patches out).. Windows support is back in 65, so closing this as invalid unless it re-occurs in a Windows build.. From my experience, 16.04 is too old. You'll have to build it yourself.. That is the method intended by those instructions, yes.\nI later discovered that mk-build-deps from devscripts creates a package that depends on the build dependencies. I will note this in the instructions.. Would you be able to clarify why -j is redundant? The patch that adds this flag is resources/patches/debian/gn/parallel.patch. Ah, missed that.\nLGTM :+1: . LGTM. Thanks.. Thanks for the PR. Everything looks awesome.\nFYI, I'm currently in the middle of implementing #248, which includes some pretty major changes to some file structures, utilities, and documentation. You won't have to do anything though; I'll merge your changes into the revised system as soon as I get my refactoring done.. I will begin development on 64 soon.. I think this is because WebRTC is disabled in that version. There's not much that can be done except rebuild it with WebRTC, or wait for a new Windows build.\nEDIT: It's possible that there may be some compatibility issues due to the Flash plugin being released later than that Chromium version. Either way, there's no simple fix.. Status update: develop builds on Debian Stretch. 89776f7ff21a0883cb5d7f4517391d7b07186f82 should be working even though I didn't make a build with #333 yet.. @onabi Yes, I will publish Debian binaries when they're ready. I haven't built with #333 yet.. Because #215 yields Server Error 500 (again), I'm letting everyone know that a failed attempt at bringing back Windows support is in 94ee1be3d80c6215ce44d42554ab4039b44c394a.\nAs the commit states, it fails to link the final binaries with over 600 unresolved externals. I suspect the breakage may be in windows-fix-building-without-safebrowsing.patch, since I was trying to make changes to that patch before I stopped.\nI've lost access to the Windows machine I was using, and interest in trying to find the root problem. If anyone wants to finish off what I started, please do so.. 64.0.3282.168-1 is out with Debian 9 binaries. I know Ubuntu 17.10 builds (but I don't have binaries), and linux_portable base bundle builds as well.. 64.0.3282.186-1 is out. I'm still building Debian 9 binaries.. It was brought to my attention that the download links for Debian 9 version 64.0.3282.186-1 were broken. They're fixed now.. Development has ceased on 64 since PRs were merged for 65. See #352 . LGTM, but it's not referenced by any patch order config file. I'll add that in for you.\nBTW, what does this flag do exactly? There's not much information about it online.. Hmm, alright. I guess I'll have to dig around the code if I want to find out.. Alright. Let me know when it's ready to be reviewed.. The formatting looks fine, but I don't have the time to review the changes themselves to see how it works.\nIf you know how to reproduce the issue, you could try building with debug symbols and running a debugger. If you aren't able to diagnose the issue or resolve it, I can merge the changes and then create a new issue for this problem.. @Artur96 Do you have a method to reproduce the crash or a stack trace? I would like to see if that crash will happen on my build.\nThe only patches I can tell that deal with TemplateURLRef directly are inox-patchset/0008-restore-classic-ntp.patch and ungoogled-chromium/disable-google-host-detection.patch. Though, nothing particularly stands out that could cause a crash in either of them.. Could you guys try removing ungoogled-chromium/add-flag-for-search-engine-collection.patch and see if the crash still happens? If it does, try different combinations that include ungoogled-chromium/disable-google-host-detection.patch and patches/inox-patchset/0008-restore-classic-ntp.patch (these last two patches involve Template URLs in some form, but they don't modify them to the same level as the search collection patch).\nAlso, does the freezing happen consistently on every search, are there some fixed conditions that make it freeze/crash, or is it seemingly random?. Hmm, If @Artur96 can confirm, then I will investigate the patch.. @Artur96 What is that first result that you find on DuckDuckGo? Perhaps that page is causing the issue.. Alright, so here's what I'm going to do: I'll merge this PR first, and then @Artur96's fix for crashpad can be submitted as another PR. Then, I will create another issue to deal with the search collection bug.. @tectiv3 @Artur96 If you guys could check out #338, that would be great. I'm close to finishing the other changes for 64.0.3282.186-1, and would like to ensure that macOS support works.. Right now, I use the README to accomplish what a website does. I usually just expect users to scroll down on the main repository page to see it.\nBut if that isn't clear enough, I could add a simple GitHub Pages website for ungoogled-chromium that just has the contents of README with a link to the GitHub repository. Is this what you're looking for?. If you have some ideas you want to implement, by all means go ahead and do so. I don't have much opinion on this matter.\nPerhaps we could start with a prototype and work from there.. @macandchief Eloston Browser is not a bad name in itself, but it's not without its disadvantages:\n ungoogled-chromium is a unique name that clearly states the main objective of this project\n If I decide to pass on responsibility of ungoogled-chromium to someone or some group in the future, having my name in it wouldn't make much sense (I would probably move it to github.com/ungoogled-software)\n* Lastly, using my name in my own project is too egotistical for my taste ;)\nAlso, why are you writing \"Eloston/Ungoogled Chromium\"? Are you using that to tell others about the project, or do you just mean the URL on GitHub?. @macandchief \n\nThis seems to be sort of the \"official\" name for the browser, showing e.g. right now on the window border.\n\nIf you're referring to the GitHub webpage title, by extension of your logic, I should call uBlock Origin \"gorhill/uBlock\" and Inox \"gcarq/inox-patchset\". Doesn't make a whole lot of sense, but maybe I'm just missing some context here.\n\nLet's take Vivaldi as an example - it was surely better for that project in comparison to \"Pre-tuned Chromium\"\n\nAccording to Wikipedia, Vivalid's main goal is to restore popular features lost in Opera post version 12. In that case, a name like \"Opera Origin\" probably would've worked well (disregarding any legal issues with the name).\n\nUngoogled Chromium states the objective of the project, but with \"Chromium\" in the name it's not as unique as \"Eloston Browser\" \n\nI question the emphasis for a unique name. Maybe it's because I'm biased towards an engineering perspective, but I prefer clarity over aesthetics. \"ungoogled-chromium\" is clunky, but it conveys the main idea right from the start. I can't say the same for Vivaldi, even if the name does sound nice.\nAn ideal name would be something like uBlock (where \"u\" is supposed to be the Greek mu, the SI unit prefix), which is unique, and concise and accurate in meaning.. @mtimofiiv I never really thought about that, but it's possible. If Google has a problem with it, I'll be open to changing it.. @0vermind @intika Thanks for your suggestions, but please keep discussion focused on creating a website. Acronyms should be discussed elsewhere.. I'm having troubles grasping the situation. What happens exactly when you clear the browsing data? Does the browser crash or not? When are you restarting it?. > I click \"clear data\" button (no matter \"advanced\" or \"basic\" tab), browser window closing\nYou mean the browser window closes itself?. I'm not able to reproduce this on my Debian 9 build. Does this happen every time you try to clear data on that profile? Do you get this with a fresh profile, or after doing certain actions with a fresh profile?\nAlso, would you be able to run a debugger and get a stack trace or crash dump?\nTo anyone else with this issue, feedback will be appreciated.. That stack trace isn't useful to me without symbols. Are you able to get symbols?. Please re-test with 64.0.3282.186-1 and report back if the problem still occurs.. I discovered that I had a huge oversight on something that should've been quite obvious...\n@tectiv3 @Artur96 Am I correct to assume that you both left search engine collection enabled? If so, e8a903a29de76c2954d42075124b91339121c89b should fix the crashing.. Issue seems to be resolved according to #334.. FYI, I'm thinking that the following process can be used to make an Arch Linux build via a PKGBUILD:\n\nOn some machine: buildkit genpkg -b archlinux archlinux\nCopy resulting PKGBUILD to build machine.\nBuild with PKGBUILD.\n\nI'm assuming that people who use a PKGBUILD don't make local builds, or don't care about the redundancy of the ungoogled-chromium repositories.\nFor people who want to make local builds with Arch Linux system libraries, I'm thinking the build instructions for other Linux systems can be used with the archlinux base bundle, except that the packaging type will have to be something like linux_simple.. > I'm sorry but what do you mean with 'local builds'?\nI mean builds that people make on their own machines for their own use, as opposed to building it on a remote machine using some automated package publishing process.. > I think it is great that buildkit supports this and if I can I will help maintaining this support.\nActually, I never intended buildkit to be used within the packaging scripts like this because of the extra dependency on Python 3. It just worked out this way due to my modular design and internal representation of configuration.\nThat being said, I don't think buildkit will be replaced anytime in the forseeable future (if ever). Even if it were, this is definitely a scenario that will be given more thought.\n\nMy idea was to use the default chromium name for the paths and executables. Of course the package itself would still be called ungoogled-chromium and installed and referenced as such but I will have to make it conflict with official chromium\n\nThis is exactly how it's done on Debian. If you could do the same here, that would be great.. Thanks for finding these bugs. Could you please test 204465832ce82335e89122eb0feec655c9c377a9?\nAlthough I appreciate the PR, I wanted to make the changes differently for the following reasons:\n\noutput_dir.mkdir(parents=True, exists_ok=True) is dangerous because it could potentially make a long chain of unwanted directories or create files in an unexpected location if the path was specified incorrectly.\n (Generally, I prefer to fail more aggressively so human error won't cause unexpected behavior.)\nshutil.copy does the same thing as copyfile and copymode combined\ntar can create compressed tar archives directly, but I forgot to specify the required compression type.\nUsing forward slashes in the transform expression can cause problems if $TARPREFIX is multiple directories deep. The tar documentation used commas as a delimiter in this scenario, but I forgot to specify the delimiter following the replacement string in the transform expression.. > This was the reason I did the compression in an extra step - I couldn't find a way to add a file to the compressed archive in-place.\n\nAh, I didn't realize this. Another option would be to combine the tar commands into one, but it probably isn't worth the effort.. Hmm, 64.0.3282.168-1 must've been tagged before macOS support was properly updated; I'll update the status in the Wiki shortly.\n64.0.3282.186-1 will come out soon with working macOS support after Arch Linux support is finalized.. Ah, I forgot I already set the status for macOS to Broken.. @socketbox You are correct to take it face value. However, BUILDING.md states to check the platform status too. The platform status states the issues that needed resolution to fix macOS support. The issues were fixed in develop, not master or any current tag.. I'm not sure what you mean by \"dead\". It's just being moved.\nIf 803135 indicates anything, it'll be moved again anyway. So we'll deal with this when the changes come down to stable.. d18ca160b3d8cc66490d4dcace52b82a29d23481. @mikerockett The current state is described here: https://github.com/Eloston/ungoogled-chromium/issues/332#issuecomment-366890227. Basically, the Windows build almost works, except for some Windows-specific code that broke due to GN configuration (which I suspected in the linked comment to be caused by disabling Safe Browsing).\nThe move to Clang actually slowed me down a bit, because I didn't want to have to setup yet another tool to build Chromium (for purists, this potentially means yet another tool to build from source). In the end, I gave in because some non-trivial problems occurred with the Microsoft compiler.\nIf anyone's interested, BUILDING.md contains the steps and some notes I used to build Chromium up to the point of failure. I think all it takes to make a working build is to patch out some more obscure references to Safe Browsing-related components. But, there may also be something wrong with the changes I made to the GN files. Faster said than done for me at least.\n(A bit unrelated, but I found it interesting that the Chrome Cleaner (downloads and runs the Chrome Cleanup Tool) is implemented within Safe Browsing. Safe Browsing's been more than just a website blacklisting service for a while now, but this is pushing the boundaries even further.). @mercerius (This is a response to https://github.com/Eloston/ungoogled-chromium/issues/235#issuecomment-370989331)\nI forgot to mention that I disabled the 260 character limit for file paths. ~~I'll add a note about that to the BUILDING instructions.~~ See edits\nEDIT: I just realized you're using Windows 7. In that case, I'm not sure if Python 3 is the only tool affected by this problem, or if there's a way to use \\\\?\\ in Python scripts.\nEDIT2: It seems to be possible to use \\\\?\\, but it's a pain to implement properly. Even Python didn't want to deal with it (Python issue 18199). You could try skipping domain substitution and see if the build will break before the failure point I had. If it does not, then we could add some workarounds to buildkit to accomodate this.. Status update for version 65: With #351, the Safe Browsing patch needs to be refreshed.. @squalus With #356, do you still get the same problem that I got?. @squalus \n\nWhich problem - the path limit thing? No, I never hit that one. I saw your build doc and took your suggestion of using official Python3.6 binaries and I had a fully updated Win10 system\n\nAt that time, I was wondering what caused your build to fail. But you have solved that already, so yay!\n(Following quotes are from https://github.com/Eloston/ungoogled-chromium/pull/359#issuecomment-374105450 )\n\nbuild.bat script did not copy the args.gn file. Don't know why yet. Windows batch files are awful!\n\nHmm, maybe %~dp0 didn't resolve correctly?\n\nquilt needed the series file to be in unix rather than windows (CRLF) format. Though this may have been because I was using WSL instead of MSYS2. I'll need to check this\n\nI believe MSYS2's git does not convert the newlines automatically to CRLF during cloning (the original files are already in LF). I don't know about the version of git you're using.\n\nbuild.bat needs to have gperf/bison env vars set\n\nNoted in build.bat\n\nI needed to run the \"x64 Native Tools\" command prompt rather than use the entries in build.bat. Not sure why\n\nThat is strange, since invoking one of them in an interactive command prompt window sets the variables for me. Not sure what's happening here.\n\nLLVM needs to be copied into tree (I have a patch coming to do this in getsrc)\n\nAre you doing this through the extra dependencies mechanism? I would rather extend that than use some hack in buildkit.\nEDIT: I'm wondering if it's possible to download gperf and bison this way from the SourceForge links through extra dependencies.\n\nNo packaging or installer at the end. I tried using ninja mini-installer but the installer did not start up. Haven't looked into it yet.\n\nI was thinking about using resources/packaging/shared/list_build_outputs.py to determine what files would be added to a zip file. If it's easier, we can write a small Python script to do this rather than use a batch script.\n\nAlso, I used the 64 bit LLVM 6.0.0 official binaries from llvm.org\n\nNoted in aa972bd51c46196e739711ca3092143fac520b0f. @squalus \n\nMaybe in this case the same script could be shared between the platforms.\n\nThere'll be some performance penalty using Python's implementation (e.g. Python bottlenecks the Chromium source tree unpacking), but it shouldn't be too bad I suppose. I suppose I didn't make the most rational decision here. I can refactor that script to do this.\nAlso, would you be able to test if %VS140COMNTOOLS% is available in regular command-prompt (or similar variable)? It'll save some path hardcoding (info from https://stackoverflow.com/questions/18711595/how-run-clang-from-command-line-on-windows).. @squalus So does %ProgramFiles(x86)%\\Microsoft Visual Studio\\Installer\\vswhere.exe exist?. Huge thanks to @squalus for fixing, developing, and testing Windows support, as well as refactoring the build process into something much more user-friendly (the changes of which have benefitted other platforms too).\nDiscussion of a Windows build is taking place in #352 (for now).. > Will an updated version for windows ever be made?\nNo idea. No one is working on it AFAIK.. Could you clarify what is hard to understand?. I made a few tweaks to the README. Let me know if you still need help.. ungoogled-chromium-bin is a third-party package. We do not provide support for packaging issues with third-party packages. Please contact the maintainer for that package, or switch to the officially supported ungoogled-chromium AUR package.. Thanks! I'll merge this after I merge xsmile's PR for Arch Linux (which should be after the build is confirmed working).. Thanks to @squalus and @xsmile, most (if not all) of the work for 65 is already done. I'll be making a build for Debian and possibly tweak a few minor things.. I am running a new 65 build on Debian 9 amd64, but there is something wrong with VP9 decoding (but not VP8 or H264) with VA-API hardware acceleration on a Kabylake machine versus the Skylake build machine. I'm not sure if it's a Mesa problem or the use of the bundled libvpx library (since the one in Debian 9 would need some patching). If anyone has some insights on this problem, I'd like to know.\nEDIT: To elaborate more visually, the video appears as a garbled mess that is partitioned horizontally into 2 or 4 (or possibly more) pieces. Though on occasion, the video will render normally for a short time.. @xsmile Yeah that seems to be it. Disabling hardware video decode works around the problem.. @tectiv3 I'm not getting any of those problems in my Debian build. Those artifacts appear to be some low-level rendering issue in Chromium (for macOS) or a bug in macOS.. Here are my Debian 9 amd64 binaries of 65.0.3325.162-1. Other than the aforementioned Kabylake VA-API VP9 decoding issue, I haven't encountered any other issues yet.. @tectiv3 @Artur96 Are you guys running the same binaries? If not, you could consider sending each other's builds. Then we can determine if the problem is due to the build environment or the runtime environment.. @nikolowry Just in case you missed it, did you see lines 431-435 in that PKGBUILD you referenced? Also, I'm guessing you might need to ensure the Vulkan code (lines 254, 265, and 266 in that PKGBUILD) are kept (though I don't think our PKGBUILD would remove it by default anyway).. @nikolowry I see. In that case, waiting for v66 may not be a bad idea.. Here are my Debian 9 amd64 65.0.3325.181-1 binaries. Built at commit fc3e102bba0b80acba7ce2203f3fd7527f45aaff. Status update: It seems like platform support is pretty stable across the board now, so I'm planning on making the initial release of 65 within the next day or two.\nBetween now and then, I will be making a build of linux_portable with the linux_simple packaging type to update the stale \"Semi-statically-linked Linux build\" (which will be renamed to \"Portable Linux build\"). If it goes well, I will publish the build along with the release.\nI would also like to see the release of a new Windows build this time around. If you can make a build on a clean Windows system, please let us know here. Alternatively, getting a build on an online build service may work as well.\nIf there are any minor fixes you wish to make, please submit them now. You may submit larger changes, but I won't merge them until after the initial release.\nAlso, I'd like to say thanks to everyone for their help and support thus far. It's been nice to see activity grow over time.. Portable linux build is available here (as the ungoogled-chromium_65.0.3325.181-1_linux.tar.xz file).. 65.0.3325.181-1 has been released. I'll be uploading my Debian 9 amd64 and Portable Linux builds to the contributor binaries page.\nI'll accept PRs to the downloads page for macOS and Windows binaries. The builds should be made at earliest 5d056b3da816b024cc3597419e20241caecc9ad6.. @nsuchy Yes, the instructions are linked from the README. Should I add an additional link to the contributing section?. @squalus I wonder if the family of issues #380, #381, and #382 are related to is_multi_dll_chrome=false (or even use_jumbo_build=true). Maybe we could try disabling the trk scheme code net-add-trk-scheme-and-help-identify-URLs-being-retr.patch (and not apply intercept-all-modified-domains.patch and windows-fix-non-multi-dll-build.patch).\nIf is_multi_dll_chrome=false is the cause, I'll look into rewriting the trk: scheme code to work with multiple DLLs.. @squalus Awesome. Looking forward to it.\nAlso, it seems Iridium ran into the same Incognito issue, but I can't find any changes in their Git repo (their only location of updated source code) for this; the latest changes are from 2017-11-30. Also, the download page for Windows is at version 2017.11-1, which doesn't exist in their Git repository. The GitHub issue: https://github.com/iridium-browser/tracker/issues/184\nOn a tangential note, I wonder what is happening to Iridium. I can't find a link to their mailing list anymore (which is referenced several times throughout the site, e.g. the Contribute page), and this change to their website is intriguing me: https://github.com/iridium-browser/website/commit/42dfd3d411080d3526593b9206313ce6cbc41fe3. Also the footer of their website says:\n\nConnect with the team and chat with us. Create an account on our Mattermost.\n\nIt seems Mattermost requires registration to do anything, which is a big downside compared to their mailing list.\nI was hoping to get a lead on these problems from Iridium, but I don't like how inconvenient it has become to contact them (and how closed-up development feels now). It's quite unfortunate.\nEDIT: s/froom/from/. @squalus I overloaded the trk feature to detect all requests with the domain substitution-exclusive string qjz9zk. So it's also useful to disable unnecessary services that fail to connect to Google, and potentially other related code that affects privacy and security.\nEDIT: That is where the intercept-all-modified-domains.patch name comes from.. @squalus Thanks for confirming. I'll get to rewriting the trk code and let you know when it's ready.. Status update: I've pushed da4ccbd269facfce83e2d34ae062b84e244dce9c, but the SEGV_MAPERR is unacceptable and I don't want to go back to Iridium's solution since it's a huge hack (but a cleverly written one).\nI'm guessing the difference between Iridium's working solution (on non-multi-component builds at least) and my patch is the placement of the function invoked by URLRequest in chrome_main.cc instead of in browser_process_impl.cc like I did. But, I'm still not exactly sure why URLRequest throws these errors and not HandleTraceScheme (in browser_url_handler_impl.cc); I thought that everything is in one binary and thus should be accessable, but it seems I was wrong. Another strange issue I was having in a previous iteration of the patch was that using AttemptTrkNotification (from util.cc) caused SIGTRAP and made the whole browser close after logging my error message. If anyone knows what could be happening in these two issues, I'd like to know for future reference.\nInstead, I recently discovered URLRequestInterceptor, which can intercept the creation of URLRequestJob (see the design docs for more info about the networking stack). There are quite a few implementations of URLRequestInterceptor that live close to or in the UI code, so I'm hoping to implement my own URLRequestInterceptor to create the infobars (and hopefully it will work on Windows too).\nIf it doesn't work, I am thinking about modifying the patch I committed to only log the errors and possibly redirect the user to a custom internal page (for the HandleTraceScheme route) to let them know about the interception. This should be pretty safe and straight-forward to implement given that logging seems to be working fine in the current patch.\n@squalus @xsmile The patches and patch order have changed a bit in this commit. Feel free to update your v66 branches against these changes; I'll only be changing block-trk-and-substituted-domains-in-urlrequest.patch to solve this issue.. Since 66 is out, I decided to postpone my URLRequestImplementor redesign for 66.\n@squalus I have pushed 643b6adc86f258cda2500d05feb75c51f41f07af which disables the trk infobar completely and has an attempt to fix your linker error. Also, how far along is Windows support for 66? If it's close enough to being done, I will probably merge @xsmile's and your branches into develop now that I've started the v66 development cycle (#392).. Closing due to the beginning of the v66 development cycle #392.. Whether EV certificates are beneficial or not is controversial, so I suppose Iridium didn't want to give its userbase a false sense of trust (which would be your average internet user with a concern about security and privacy). I personally don't mind since it's purely a cosmetic change, so I just took what Iridium had.\nI'll just revert my changes and leave it the way it was originally.. Duplicate of #36 . Awesome!\nWould you be able to post a binary to #345 for others to test? Thanks.. I see. I'm sure we'll figure out some way to get a clean build soon enough.. It seems that the LLVM installer is a NSIS installer, so I believe you may be able to use /S and /D options as explained here: http://nsis.sourceforge.net/Docs/Chapter3.html\nIf it works, we could extend extra dependencies to invoke this automatically. But, I'd rather try to find a way to extract the file instead of invoking it if possible.. Well it seems that 7za can't extract all formats. You'll have to use 7z.exe.\nTo get 7z.exe, we can use the .msi format and use msiexec to extract the files into a directory, then invoke it to extract the llvm installer. (EDIT: But, see the below alternative solution).\nAs much as I like your code, I don't see much of a reason to copy a pre-installed LLVM toolchain installed to the system; in the future, we may need to switch back to a specific snapshot version. Copying from an existing path is nicer, but you might as well extract it directly to the destination path at that point.\nThere's not really a mechanism to have extra dependencies depend on each other, and I'm kind of disappointed in the performance of my hacky tar extraction script, so here's what I'm thinking:\n\nHave the user obtain 7-zip somehow (either a portable version or install it via the installer)\nFor the CLI, add an extra optional flag --7zip-cli to specify a path to 7z.exe. If it isn't specified, we default to using the registry to find it (on Linux, which 7z is used). Additionally, --gnu-tar, which specifies the path to GNU tar (default is which tar).\nExtend extra dependencies mechanism to support an extractor field. Use tar to extract with a tar-capable extractor (first GNU tar, then 7zip, then the internal extractor), 7zip to force extraction with 7zip, gnu_tar to force GNU tar, and internal_tar to force the internal extractor.\nIf necessary, add an arguments or type field to specify additional arguments to the utilities needed for extraction.\n\nThoughts?. I've refactored your code a bit in 2cd39da2cbd584247fcb6c35487a19f71ff4571f, but it's missing the code to read from the registry. Could you add that in?. I made some more changes. If everything works I'll merge.. I confirmed that GNU tar decompression works, but I don't have a Windows machine on me. Would you be able toconfirm my 7-zip registry-related changes work?. Awesome :+1: . @ik9999 It's hard to say. Given that this is a pretty large leak and that you've been affected by it in previous versions, I think it's more likely that it's due to some change in ungoogled-chromium.. @ik9999 67 is out. Are you still experiencing major memory leaks?. Good to hear. @ik9999 Does your memory usage still grow?. If memory usage is not concerning so far, then I'll close this issue. Until (or unless) ungoogled-chromium formalizes development with better practices (i.e. running code testing and analysis tools that Google uses over the code), I don't see any point in digging deeper into memory usage; any attempt to do so could end up futile with updates and new features.. #56 . I implemented your suggestion for output_path. Thanks :+1: \n\nAlso I had SSL cert validation errors downloading from Sourceforge using official Python3.6 Windows binaries. I need to investigate this further, as it may be some local configuration problem. Linux/macOS works fine, and they don't need to download from Sourceforge anyway. Is it ok to disable SSL cert validation in the downloader, since we are checking hashes anyway?\n\nYeah, I think that'll be fine. Just make sure to leave a comment in the code just in case anyone else gets confused by that decision.. The desktop interface is highly dependant on the system's userland rendering facilities (e.g. there's always been X11 on Linux, but Wayland support is coming). Android has a unique rendering stack that is completely incompatible, so I don't expect there to be anyone that would want to do this.\nThis isn't even mentioning the non-rendering userland components, which may also require some modification to work with the desktop UI.\nIf you're running Wayland or X11 with a regular Linux distro on your Android phone however, then that might work already without any modification (just do a native or cross-compilation for that distro's architecture and run it). But I'm guessing you mean the former.. Alternatively, we could use python-quilt. But for non-developers, this adds a lot of complexity. It's simpler to just invoke patch directly.\n\nIf we decide to use patch, the gnuwin32 binary can be downloaded automatically.\n\nIn the previous Windows instructions (before I attempted to update Windows support recently), I manually download MSYS2's patch binary from SourceForge (with the required DLL to make it run). I can't recall exactly why, but there may have been some issues with GNUWin32's old version of GNU patch. Since we can now automatically download and extract (almost) everything, we could just automate that procedure.. For now, I think it's better to play it safe by invoking patch directly and using MSYS2's patch. I think it'll be fine to include the patching code this as a new module patching.py with CLI command patsrc (for \"patch source\", unless you can think of a better name).. git apply requires Git to be downloaded. If you're not a developer, this is a large and non-portable dependency (IIRC it's a subset of MSYS). On the other hand, my GNU patch approach only requires two small downloads; of which only a single exe and dll are required from it.\nIf one of your goals is to make building easier for non-developers, then I don't think it makes sense to download Git (EDIT: since no other step requires git, it doesn't make sense to require it only for this. Users may download tar or zip archives of the repository instead).\n\nAlso it appears python-quilt just invokes patch :)\n\nYep, and it's stated in its README that patch and diff are required for applying and creating patches, respectively.\nThe only reason I considered including python-quilt is for its usefulness in development, while also being lightweight (compared to MSYS2). If we're certain that developers ~~won't~~ will not be using python-quilt over MSYS 2 or WSL, then python-quilt is just more bloat and complexity compared to invoking patch directly (EDIT: due to the fact that the only consideration are those who simply wants to build, or a CI service).\n\nWould the new buildkit command run between subdom and genpkg? And I guess we no longer need genpkg to copy patches or patching scripts to the tree.\n\nActually, thinking about the python-quilt problem made me realize that there's no good way to let buildkit know where patch is located, since it's being downloaded to a configuration-specific location. This could be solved by downloading it to a dedicated location like buildspace/utilities and adding a new config file utiliites.ini to specify shell commands to implement specific features, but I don't want to make buildkit configuration-specific or add complex logic to make it \"smart\"; I would rather choose simplicity and transparency over convenience when it's reasonable.\nInstead, I think it's better to go with the alternative to patsrc I had in mind, which is to add a shared packaging Python script to apply a patch series using GNU patch or git apply (i.e. a script like apply_patch_series.py in resources/packaging/shared/). This is because the windows base bundle and packaging types are already semantically linked to one another, so it's valid for build.bat to use apply_patch_series.py and the predetermined location of GNU patch. buildkit and packaging types don't have this sort of relationship.\nFrom a more abstract perspective, applying patches could arguably be classified as either source file processing, or as part of building in the packaging process. (Also, this ambiguity is what made it difficult for me to choose between patsrc or apply_patch_series.py in my previous comment.). Also, I forgot that applying patches ~~was~~ is part of packaging, not buildkit as per my own design document...\n\nIf patsrc is run after getsrc it's no longer necessary to perform subdomain replacement on the patches, so that code could be deleted in the subdom step. Is this what you have in mind?\n\nIf applying patches was part of buildkit, this couldn't work because Debian applies patches as part of its build process. Also, domain substitution over the source tree and user bundle allows users to build Chromium in an environment without Python 3 (but this isn't really a common use case, as I now realize).. (I just added a new section to DESIGN.md about buildkit's design philosophy, which generalizes and distills the underlying thoughts of my earlier post. Please submit issues or PRs if it needs clarification!). > To me it makes more sense as a buildkit source processing step, because it can be done before subdom and the patch substituion code can be eliminated. The patch substitution just seems like unnecessary complexity.\nYou're right, it is very complicated. You're not the first to point out the issue. Separating buildkit with packaging scripts and avoiding Python 3 in the packaging scripts are objectives that don't make much sense, and they conflict with the design of Linux-based packaging systems (e.g. Arch Linux's PKGBUILD and Debian's dpkg system in #37 ) and the goal of keeping things simple and cross-platform.\nI am brainstorming options here to amend these problems with minimal changes. I'm projecting that only the packaging scripts and build process will go through the largest changes, but the file structures and buildkit itself will stay mostly intact.. These changes will take some time, so you may submit a PR whenever you're ready. It should be pretty straight-forward to merge your script into buildkit if we choose to do so then.. 83a6cbc80682a2dc1ec116c6db0d79e4df6c5bd5. I tried looking around, but I couldn't find a solution that meets my requirements.\nA simple method with a straight-forward implementation I'm considering uses a .tar.gz of a file tree that mirrors the buildspace tree, but contains only the original versions of the files modified by domain subsitution. Another plain-text file will contain the CRC32 checksums of the files in the archive after they have been domain substituted. These files are then used like the following:\n Substituting domains is pretty straight-forward: For each file in the domain substitution list, substitute the domains in memory. If no substitutions were made, go to the next file and repeat these steps. Otherwise, store the original file in the .tar.gz, compute the CRC32 checksum, and replace the original file with the substituted one.\n Reversal is pretty straight-forward as well: For all files in the CRC32 checksum list, compute the hashes of the actual files. For any file that has a hash mismatch, let the user know and continue. If hash checking completes with no mismatches, unpack the .tar.gz over the buildspace tree, replacing all the files that were already present. Then delete the .tar.gz and CRC32 hashes (they need to be recomputed if any files with domains get modified).\nNote about compression: From the results of a benchmark of gzip, bzip2, and lzma, it seems that gzip with compression level 1 will suffice to compress the tar archive as these files are mainly source code, and speed is more important than saving a little on size.\nIf anyone has a better method, I'd like to hear it. Otherwise, I'm going to start implementing this.. Implemented, except Windows stuff. That can be done whenever, if necessary.. It's fine if someone wants to patch it out for aesthetics, but they won't do anything if switched on.. It should be enough to add the hidden attribute to the entries that should be removed. You can submit a PR if you want.. I wouldn't mind showing puny codes by default, but I'm not sure how much this could bother users that visit legitimate sites using puny code. Maybe adding it as a chrome://flag option will be safer (and it would be documented in the README).. You can submit that PR whenever you're ready.. It seems we've run into a race condition; I did bedf856a4b9680756b562c963720de29b8b02157 before I noticed you submitted this PR. Sorry for not giving a notice ahead of time; I'll create more issues for tasks like these to better coordinate our efforts next time.\nI haven't fully tested what I've committed yet. If you could test the Windows side of it, that'll be of great help.. fd7bf846945e64f7c3fdfbfa4963af2e2589894c. Oops. Yeah, it's supposed to be action.. ee34616277d4f66fd3b9e3f97bb48ab7acc18698. If that works, I think we can close this PR.. Please note from the FAQ (bolded for emphasis):\n\nTo use the template, replace [EXTENSION_ID] with the extension-id from the Chrome Web Store, and [VERSION] with the browser's version.\n\nWith this issue corrected in your URL, it downloads the extension successfully.\nAlso, the extension ID is simply oooganmdnecfpdgmmneaojopkhjljjbi. I'm guessing the capital D in front of your ID is a typo by copy-pasting from your constructed URL.. What is a Void build? I've never heard of it before.. I see. This should be possible, but I would wait until #367 has been finished before attempting it. Regardless, I'll accept a PR anytime.. In the meantime, you should be able to use linux_portable to make a build right now (or use the Portable Linux binary on Void Linux).. @ThatNerdyPikachu I just updated it ;)\nhttps://ungoogled-software.github.io/ungoogled-chromium-binaries/releases/linux_portable/64bit/65.0.3325.181-1. Portable Linux version 66 is already out. What exactly isn't working?. @travankor Thanks for confirming that it works with glibc. Do regular Chromium or Chrome work with musl?. @faulesocke I wasn't too clear earlier, but I'm diverging a bit from the original topic at hand.\nThe purpose of my question is to learn more about musl and where compatibility is breaking; if it's in ungoogled-chromium, then it's a bug with the Portable Linux build, since Void isn't the only system that uses musl (and users may not want to wait for a package to come around for their distro). Otherwise, if Chromium and Chrome are also broken, then we would have to include those patches to work with musl.\n\nHowever, first ask in IRC if they even want new browser packages, otherwise you're wasting your time.\n\nIf it's straight-forward for users to install package files manually, packages for Void can be added to the contributor binaries page (if someone submits them). If Void wants to have it included officially, then this can be dropped.\nIn the meantime or as an alternative, a derivative of the Portable Linux config for musl could be added.\n\nSince I'm not using chromium-derivatives anymore since Firefox 57, I'm not too motivated to put too much time into this (I was asked if I could help a little bit here)\n\nNo problem. For platforms I don't use, I generally leave it to someone else to do the actual work of implementing support.\nUnrelated to the main topic, but I'm genuinely interested to see how Firefox Quantum progresses down the road. I could see myself jumping ship if Chromium becomes too much of a burden for me to keep up.. WHY CAN'T YOU READ\nREEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\nIn all seriousness, you can build it yourself easily if you can't wait. No one's taken up the offer of providing a clean build yet.. The 5% noise is actually from a cited source:\nN. Nikiforakis, W. Joosen, and B. Livshits, \u201cPrivaricator: Deceiving\nfingerprinters with little white lies,\u201d in Proceedings of the 24th\nInternational Conference on World Wide Web, 2015, pp. 820\u2013830\nThat paper is available here: http://www.www2015.it/documents/proceedings/proceedings/p820.pdf\nUnlike this patch, PriVaricator applies 5% offsets to more than just get*ClientRect[s]. Their results have shown minimal to no breakages for the top 1000 Alexa sites by comparing screenshots of the rendered sites.\nHowever, there are still a few concerning aspects:\n I can't say with strong confidence that these sites are representative of the designs and structures of sites browsed by ungoogled-chromium users.\n The paper's breakage evaluation does not consider dynamic behavior for sites that have a heavier use of JavaScript for rendering, such as web games. Errors in these values may cause accumulative error throughout the runtime of said web applications.\nWhile such concerns may be silly for people like us, I believe it's better to keep cautious when it comes to behavior-mutating changes like these, especially if they can introduce subtle (and potentially frustrating) bugs like this patch.\nAs such, I would like to have this feature behind a command-line flag or chrome://flag option. Not only does it offer configurability, but it also informs the user of potential issues this can cause.\nI'm not too familiar with the DOM side of web application execution, but maybe we could read this flag once per tab, and then have it pass down through Document to individual Elements to reduce the cost of looking up command-line arguments. If we are to implement multiple ~~fingerprinting methods~~ fingerprinting deception methods in the future, perhaps we could create a generic fingerprinting argument that accepts a comma-separated list of fingerprinting deception methods, and store these as a bit field to be read by various components of the DOM implementation as necessary.. Opened issues #380 and #381 to resolve new issues.\nclients2.google.com could be extensions trying to do an update check. You can try without extensions to see if any connections to clients2.google.com still go through.\nClosing this one with invalid due to https://github.com/Eloston/ungoogled-chromium/issues/378#issuecomment-377807512. See https://github.com/Eloston/ungoogled-chromium/issues/352#issuecomment-378152272 and https://github.com/Eloston/ungoogled-chromium/issues/352#issuecomment-378158828. I will rewrite the trk scheme code to fix this.. Should be fixed in 643b6adc86f258cda2500d05feb75c51f41f07af.. What build are you using?. Might be related to #380 or #381. We should re-check after fixing those first.. Fixed with #394.. Do you see the same window as clicking on \"Manage people\" (titled \"Chromium\") after you click \"Close all your windows\"? If I use \"Close all your windows\" then close the new window that shows up, I get no errors after starting Chromium again.\n(I am running my Debian 9 amd64 65.0.3325.181-1 build). Sounds like a Windows-specific bug. I'm not gettig it on my Linux system.\n@squalus Do you get this error in the build that you fixed incognito?. @squalus Awesome. I'll close this when I release a new version.. It's a bit of a hassle to keep this open for no good reason, so closing.. Awesome, thanks for the stack trace too.. https://github.com/Eloston/ungoogled-chromium/blob/master/FAQ.md#how-do-i-install-widevine-cdm\nIf you still have questions, let me know.. Hmm, ok. I can't see anything obvious from the PKGBUILD. I'll open up the AUR version for testing.\nDoes Widevine work with the Portable Linux build?. @xsmile Actually, the FAQ doesn't specify where to extract the file to; it only says where to extract the shared object from in Chrome's .deb package. I'll add a small note about where to extract files to.\nFor all distribution packaging methods we have, I believe they all put Chromium's main files in /usr/lib/chromium.. @ryanmusante libwidevinecdm.so should be from a Chrome browser version matching that of ungoogled-chromium. If it isn't, I don't know if it will work.. Closing due to inactivity. If this is still an issue, please let us know.. To add to what @xsmile said, I've only seen this on Windows only. When I attempted to revive Windows support, I had to fix some broken references to Chrome Cleaner due to disabling Safe Browsing; this never happened on macOS or Linux.. Good catch. Thanks.. @xsmile I see. Just in case older LLVMs cause problems, I'll target LLVM 6.0 for Portable Linux and require users to manually add that patch to their user config bundle's patch order. I'd rather not have the burden of supporting older compilers whenever reasonable.. It seems to be working on all platforms so far. Closing.. Closing since multiple versions have been released since version 65. If this is still an issue, please let us know.. Status update: The common base bundle has been updated. As such, I will begin work on Debian shortly. Feel free to submit PRs for other base bundles.\nDue to 5c192485e446e90fde5df7c79ff428ffa7997012, linux_rooted is currently broken. The mentioned patch should be included soon.. @nsuchy You don't need to know a lot of C++-specific knowledge; most problems depend more on knowledge of Chromium code and its structure rather than anything else. The way I learned is just by blindly diving in and reading the code or design docs as I need to. Granted, this is not a fast process.\nIf you're looking to contribute patches in the future, I'd suggest having a look at the current macOS patches and seeing how they work in the actual code. The kinds of problems we run into in new versions is pretty consistent from release to release. In addition, you can consider updating the patches yourself to see what the process is like and to see the kinds of errors you'll run into.. Status update: I've updated the statuses for macOS, Windows, and openSUSE. I've also started work on Debian/Ubuntu.. Status update: I've incorporated changes from Debian, and ended up changing a few things in the process. Please re-test and let me know if anything broke.\nUbuntu and Debian buster support has been updated but not tested. Updated instructions are in BUILDING.md.. My binaries of 66.0.3359.139-1 for Debian stretch and Linux portable are available for testing here.. Status update: I've released 66.0.3359.139-1 and removed the updated status for platforms I don't have a working status confirmation.. @macandchief I made a typo. The links are fixed.. @LeFroid I just remembered that I changed openSUSE GN config to use the linux unbundle toolchain, so the exported compiler environment variable flags are now used to specify the compiler. Do the default flags there correctly use LLVM 6?. I've been able to build and run 66.0.3359.170 on Debian without needing any changes on develop.. Moving onto 67: #414 . I have decided to abandon this effort.\nFor the components I was referencing, they seem to be shifting from URLRequestInterceptor to NavigationThrottle (defined in content/public/browser/navigation_throttle.h) for the components I was basing my code off of (e.g. https://chromium-review.googlesource.com/c/chromium/src/+/868994), so I'm worried about issues I may run into in future versions of Chromium.\nPlus, I never found a good way to send a message to the UI from the networking code since it fundamentally goes against the whole Chromium architecture (the networking layer I'm working on is several layers away from the UI code with a dependency relationship in the opposite direction of how I'm trying to form a link). I can't come up with any method that won't be prone to bugs or high maintenance, so it'll be easier to just monitor the logs for any problems.\nUnfortunately, monitoring the logs isn't as convenient as having some built-in functionality to notify the user directly, but I don't see any easier solution. Feel free to investigate.. Does this fix #382?. @waqas Alright, thanks. I'll release a new version of 65.. I'm not getting this in my Debian v65 build, so it sounds more likely to be a Windows-only bug.. @intika No. This is a long-standing issue with the patches even in the latest Windows version available.. I further tweaked the spec file in 44dd30b88e053c87e35b8a4844a190f9367e8ec2. Hopefully that didn't break anything.. Thanks! Glad you're liking it.. @Obsessive Huh, that's not something your hear everyday. Out of curiosity, what made you switch?. @intika \n\nMay be i am crazy using all those stuff lol... and i did even not talked about android lol\n\nLots of people like to play with their systems, whether it be a desktop, server, DIY electrical device, car modding, etc. You're definitely not alone.\n\ni was a little skeptical when i first find it because of the lack of website and the given name to the project\n\nInteresting. I tend to go to GitHub (or similar services) to see what a project is like, because it allows me to see attributes that aren't visible on a website; e.g. development activity, code quality, stability, the kind of atmosphere it promotes, etc.\nBut that's just my opinion. Others prefer websites for a variety of reasons, and that's understandable. (If you would be interested in helping to make the website, we should discuss more in #335.). @niftylettuce This is a month late, but ungoogled-chromium is a side project for me, and I intend to keep it that way for the forseeable future. Nevertheless, thank you for your show of appreciation!. Closing this as wontfix in favor of #401. . Thanks for the PR, but I'm planning on releasing 66 within a day. Hopefuly I get Debian/Ubuntu and Portable Linux finished by then; if not, I'll release with what we've got.. My Debian changes ended up being more involved than I thought, so it broke builds temporarily. 988a46b457d3c648654f7b5ed56cf4bc6836ffad builds on my system and it should work on yours too.. Hmm, I've never seen this error before. Are you not able to use the latest version of ungoogled-chromium?. Does your system have the proper dependencies to do a build using the Debian 9 building steps (or newer Debian)? If it does, I'd like to see if these errors still show up there.. So Linux Mint doesn't have the dependencies to build with the Debian stretch configuration? Hm, that's unfortunate.\nI believe Linux minimal still works on Ubuntu, so I'm not sure why Linux Mint is different. Maybe the default debhelper configuration is different? If someone knows, I'd like to know.\nClosing for now since a solution was found.. Do you have any entries for the site(s) in question in chrome://settings/content/microphone and/or chrome://settings/content/camera?. Do you have the same problem with the Portable Linux build?. Since Portable Linux is having the same problem, it's possible this is a bug in Chromium. Could you try out the new Debian binaries I published just to be sure?\n\nI am now thinking I should have done purge?\n\nI don't think this is a problem with your browser profile. But if you want to test, you can just move or delete your configuration in ~/.config/chromium and let the browser generate a new one to be certain.\nAlso, the purge scripts of the Debian packages don't clear out directories in your home directory (i.e. ~/.cache/chromium, ~/.config/chromium, etc). 67 is out. If this is still a problem for you, let us know here.. Status update: I'm updating patches and configs for Debian and Portable Linux now, which include changes to common and linux_rooted. I'll push my changes once I finish.. 1b9bc64c465543101f7944aee7e8a52087d40344 can build Debian stretch packages that can't play any media. I need to refresh Portable Linux patches and try building.. Status update: Portable Linux seems to be fully functional as of fb6a3a450508ba633914aa6a2924aeb42a620e64 with a build available here. @xsmile I didn't save the logs, but both stderr and chrome://media-internals said something about FFmpegDemuxer not being able to open a context (I tried looking it up, and it's a generic failure trying to load FFmpeg). When I tried opus audio (e.g. YouTube or opus audio files), it just says the audio decoder wasn't able to initialize, or something to that effect. chrome://gpu didn't have anything IIRC, and toggling VA-API acceleration has no effect.\nI suspect this may be a FFmpeg incompatibility (not too sure about opus though). I'm just going to wait and see if Debian will push a patch to fix this or not, because I haven't seen anyone else building 67 with old FFmpeg yet.. I did a rough update to 67.0.3396.87 in 0649233267c91b3094544f7d61e02bb79f91cd46. Please test and submit a PR if anything's broken.. Portable Linux build of 67.0.3396.87-1 is now available for testing here.. Debian Stretch binaries for 67.0.3396.87-1 have been uploaded for testing.\nHashes are in .buildinfo and .changes files.. Status update: Windows support has been updated. A build is available here. Please test and report any bugs; I will tag a new release after several days if there aren't any major issues.. I have moved 67.0.3396.87-2 to prerelease status for now. To encourage more consistent testing, I am looking to switching my development model to include \"prereleases\" (same meaning as a GitHub prerelease). There will be no changes to the tagging scheme. I will work out the specifics of this system and document it somewhere.\n@Ti-R @Wyse- e9ce6ca67ed84d68a2716e7cca8ba55d3feca963 should reverse the breaking changes I made.\n@dubvulture I think it should be possible to just disable the dependency on the testing fonts.\n. @seppiofish I've never heard of this issue. Do you know what file(s) are growing in size?. @Wyse- If you believe the Windows binaries are good, you can submit them to the contributor binaries site (ungoogled-chromium-binaries). @Wyse- Hmm, you brought up a good point about master and develop branches. It's unnecessary to have two branches like this with the new release model that I've developed. I'll have to consolidate them.\nI also don't really have a system to receive feedback for testing, to promote development binaries to release binaries.\nSome documentation about the new release system is here (I will need to organize it a bit better):\n https://github.com/ungoogled-software/ungoogled-chromium-binaries#changing-version-statuses\n https://ungoogled-software.github.io/ungoogled-chromium-wiki/statuses. Closing due to development on version 68.. It says Chromium because ungoogled-chromium does not change the branding. From the beginning of the README:\n\nungoogled-chromium should not be considered a fork of Chromium. The main reason for this is that a fork is associated with more significant deviations from the Chromium, such as branding, configuration formats, file locations, and other interface changes. ungoogled-chromium will not modify the Chromium browser outside of the project's goals.. What are you doing to cause the message to appear? Do you make copies of profiles while in use or kill Chromium externally?. If someone wants to submit a patch to do this, feel free.. @luckydonald All feature requests of this nature are opt-in by default, unless there is a good reason otherwise. I'm not one who wants to break workflows.. Have you tried other flags and see if they have any effect? You can also check chrome://version to see if the flags have taken effect (they are listed between --flag-switches-begin and --flag-switches-end). If you still have this problem, please let us know here.. Thanks for the PR, but I was already considering rewriting the build script in Python 3 for the redesign. The redesigned script will also be more automated, so I don't think there'll be much value in publishing a wrapper batch script.. LGTM, ~~but proprietary codecs would be enabled with the bundled FFmpeg. I'm not too clear about proprietary codec licensing issues, so would that be a problem for the distribution of a binary from these files?~~\n\nEDIT: Based on https://ffmpeg.org/legal.html, it's probably fine.. So if I'm understanding you correctly, you did the following:\n\nDownload a .crx file to some location\nOpen a file manager in aforementioned location\nOpen chrome://extensions in the web browser\nDrag the .crx from the file manager into chrome://extensions\n\nWith these steps, I have no issues with the same ungoogled-chromium binary and the extension Disable HTML5 Autoplay.. If you're still having this issue, please let me know so we can investigate further.. What happens if you call chrome directly without using chrome-wrapper?. Also, does this error occur in a clean Chromium profile?. A few things:\n chrome is an ELF binary, not a shell script. Also, you don't need to invoke either chrome or chrome-wrapper with sh since they should both have the execute bit set in the filesystem.\n The \"Learn more\" link is a constant URL from the browser. It is expected to break due to domain substitution. The page it leads to and the \"Block URL in\" are due to the patch block-trk-and-subdomains.patch, not due to any extension as the page suggests.\n* The InitializeSandbox() error may be due to some incompatibility with your Linux kernel. I don't see anything abnormal in chrome://sandbox that could cause this. However, I don't know if this error will affect anything either; you could check and see what chrome://gpu says.\nOn second thought, I don't think chrome-wrapper is the cause of your problem. I don't see it setting any runtime flags remotely related (note chrome-wrapper is a shell script that invokes chrome at the end).\nWhile you are dragging the .crx file from your file manager into the chrome://extensions page, do you see an overlay with a dark puzzle piece icon and the text Drop to install? The only reason I can think of that Chromium creates the error (Apps, extensions, and user scripts cannot be added from this website) is because Chromium thinks the thing being dragged and drop from your file manager is a URL instead of a filesystem path. What file manager and desktop environment are you using?. > I believe I figured out the issue. Try enabling Developer Mode in the top right corner of the extensions page. Afterwards dragging .crx files should work with the Chromium version of your distribution as well as with the portable version of Ungoogled Chromium. Most probably this change was introduced with version 67.\nAh, I forgot about the Developer Mode switch. I've always had it enabled. Good catch.\nI'm wondering what the rationale is for the removal; if it's for some security reasons, there's already a confirmation box to install the extension. Also, it's frustrating and odd that there wasn't any error added in place of the decision to disable drag-and-dropping when not in Developer Mode; optimistically this could be a bug, but I feel like the use cases for drag-and-dropping CRX files is small enough that Google didn't bother to write any sort of notification.\nMarking as invalid since this isn't an issue with ungoogled-chromium. I'll modify the Wiki to include a notice about this.. If this is an Inox bug, then please open an issue there. If it's the final packaging step that failed, then it might be an issue with chrome/installer/mac/pkg-dmg (which is written by the Chromium team). Do you know which command in build.sh failed?\nIf pkg-dmg is the issue, then we can check for any additional CLI options in the script before resorting to patching it.\n\nI had to get rid of the tree and do the whole build again.\n\nGenerally this shouldn't be necessary as packaging commands don't touch any files in the build output. In the event that they are missing or modified, you can rerun ninja to regenerate those missing files without rebuilding the entire browser.. I added a check to ensure /var/empty is actually empty before building (I'm assuming nothing will be adding files to /var/empty during that time).\nDuring that change, I noticed that pkg-dmg is given /var/empty via the --source flag. If this directory is used only during the generation of the dmg and not in the dmg, then it may be better to just create and use a temporary directory instead.. I refreshed the patches for Debian buster in https://github.com/Eloston/ungoogled-chromium/commit/e53a61bbce4de58089153c36e02c82c645f99f77.\nI'm not exactly sure what you did when you tried building using stretch config, but it seems like not all the patches were applied. Maybe try recreating the build tree?. The warnings are normal. The unused-private-field warnings are due to patches; they could be removed in their corresponding patches.\n\nOne more tip: when use_kerberos=false then checking for libkrb5-dev in debian/control is useless.\n\nThere are several unused dependencies there (Debian's chromium package included), but I haven't meticulously gone though to remove them due to the work involved (the tedious work is checking what's unbundled by the unbundle script).\n\nI've noticed that ffmpeg is internal now and not depending on system's libavcodec library, opposite to previous versions.\n\nYep, this is a Debian change. FFmpeg libraries older than 4 stopped working with Chromium since 67 (at runtime, not compile time).. I'm not completely certain FFmpeg 4 is the cause, but all Debian versions except experimental have 3.4 or older right now. If you backported version 4 yourself, then you can try reverting resources/packaging/debian/buster/scripts/unbundle and resources/packaging/debian/buster/clean in https://github.com/Eloston/ungoogled-chromium/commit/e53a61bbce4de58089153c36e02c82c645f99f77 to build with the system's FFmpeg again.. @Wyse- It looks like the GN bootstrap command failed, but I not 100% sure since vcvars64.bat seems to have disabled echoing of commands. Can you add @echo on after call \"%VS_PATH%\\VC\\Auxiliary\\Build\\vcvars64.bat\" to build.bat to see which command failed?. What output do you get from running the command that failed with exit status 2? i.e. '['C:\\\\Python27\\\\python.exe', 'C:\\\\ungoogled-chromium-master\\\\buildspace\n\\\\tree\\\\build\\\\toolchain\\\\win\\\\setup_toolchain.py', 'C:\\\\Program Files (x86)/Mic\nrosoft Visual Studio/2017/Community', 'C:\\\\Program Files (x86)\\\\Windows Kits\\x08\n', 'C:\\\\Windows\\\\Sysnative;C:\\\\Windows/SysWOW64', 'x64', 'true']'. Wow, this is pretty bad breakage. I guess they didn't update the GN bootstrap script for Windows in time (this isn't the first time this happened; it has happened with macOS before).\nFor future reference, I figured I'd document how I approached this problem:\nUsually the next major version of Chromium has a newer snapshot of GN bootstrap.py, so I looked at the script for 68.0.3440.38.\nI initially tried the online git-blame tool, but comparing dates and commit hashes was too tedious.\nThen I compared the logs between the two versions (67 here and 68 here) to and picked out the following commits to be included (based on changes that didn't add files not in 67):\n95fe44b3c31cf5e1a668d9ef8853aaf2cf9523a5\n0d3bbfb6b8ba05af199b49f5dd71d842f6acffda\nand wrote them to a patch using the following shell command for each:\nsh\ncurl https://chromium.googlesource.com/chromium/src/+/COMMIT_HERE%5E%21?format=TEXT | base64 -d >> gn_fixes.patch.patch\nprintf '\\n' >> gn_fixes.patch.patch\n(replacing COMMIT_HERE with the full commit hash)\nThen I added it to the proper patch order, refreshed it, and created the commit here: 3ea744b02afbb4b3dcac93d8d4fa9116d0d6183b\nLet me know how that goes.. Wow, we got lucky that nothing else needed changes. Neat.. Thanks for letting me know about these features.\n\nFor these you probably would want to add a flag; I am not sure about a general flag for anti-fingerprinting or one for each aspect, I would be inclined for a general one, but I leave that aspect to you.\n\nWhile creating one flag for all fingerprinting deception would be less implementation work, I still want to give users more flexibility when it comes to features that change the browser's behavior.\n\nyou already have an older version of this patch here\n\nI don't see any new changes in the Bromite patch you linked me. Can you clarify?\n\nhttps://github.com/bromite/bromite/blob/master/patches/BRM049_Battery-API-return-nothing.patch\n\nWhat purpose does this patch serve when the other battery API patch is also included?. After looking through the code just now, I'm going to include these two patches behind flags:\n\nhttps://github.com/bromite/bromite/blob/master/patches/BRM052_Canvas-fingerprinting-mitigations-for-image-data-and-webGL.patch\n(this one updated) https://github.com/bromite/bromite/blob/master/patches/BRM053_getClientRects-getBoundingClientRect-measureText-add-fingerprinting-mitigation.patch\n\n@csagan5 Do you have any other patches that are worth considering? EDIT: This wasn't intended to be offensive. There are a lot of patches, and the effects aren't always obvious just by reading the patch.. > https://github.com/bromite/bromite/blob/master/patches/BRM056_Add-a-flag-for-DNS-over-HTTPS.patch (should work fine on desktop browsers too)\nI was debating about including this since I personally believe DNS over HTTPS is silly (almost defeating the purpose of having different networking protocols on different ports, and abuse of HTTP), but it doesn't look like it would be degrading performance or anything, so I'll probably include it.\n\nhttps://github.com/bromite/bromite/blob/master/patches/BRM003_Battery-API-return-nothing.patch (the patch you already have is not sufficient, for some reason)\n\nI tried the Battery API with the latest tag of ungoogled-chromium (68.0.3440.106-1), and it doesn't seem to be returning real data. Can you elaborate on what is being leaked? Maybe this is an Android-specific problem?\n\nhttps://github.com/bromite/bromite/blob/master/patches/BRM051_AudioBuffer-AnalyserNode-fingerprinting-mitigations-via-IDL.patch (I am planning to redo this patch to provide always randomised results as the other patches do, eventually)\n\nI might wait for the rewrite then ;)\n\nhttps://github.com/bromite/bromite/blob/master/patches/BRM058_Add-flag-to-configure-maximum-connections-per-host.patch\n\nThis is a nice patch, but could you explain what you mean by this?: this can however be detrimental to devices with limited CPU/memory resources and it is disabled by default. How exactly can this be detrimental?\n\nI can also tell you that I checked the Brave implementation for fingerprinting mitigation and I concluded that Bromite's patches (so basically those you mentioned) are not that bad, probably better (I can't say as I am biased).\n\nI see, I'll take a look there too. Thanks for the heads up.\n\nPlease note that the URLs you are using point to master and not the specific commit and unfortunately sometimes I reorganise the patches and the BRMxx prefix would change so the links would return 404 eventually (it would still be possible to find them by their subject as that does not change)\n\nNo problem. I've already dealt with this once before and I'm not much better myself.... > I am reporting almost 1:1 the comment you can find here: https://github.com/chromium/chromium/blob/master/net/socket/client_socket_pool_manager.cc#L37\nI see. A lot of the original discussion seems to be around HTTP 1.0 connection persistence and also large and/or full duplex data transfers (where Web Sockets were brought up multiple times by Chromium devs). I don't think this is as much of an issue in 2018, but we still have other ones with intermediate networking nodes imposing their own restrictions and a niche of users having specific requirements. So I see no issue with including the patch.\n\nIt could be. Perhaps on Android it has some other hook to update state? It has been a while since I last touched that part of the code; it had been reported to me in this issue and I verified that indeed without the patch battery data was returned.\n\nIn that case, I'll see if I can find a cleaner solution by disable the monitoring service or system calls for the info. If not, I'll use what you have. \n\nIt is technically an abuse of the protocol, but I prefer it to the complete lack of customisation of the DNS choice on Android\n\nHm, I didn't consider the lack of good DNS configuration on Android. It's quite a limited system in some ways...\nThe current options don't bother me, but I suppose it will be some work to allow the users customize this freely since the chrome://flags infrastructure only supports finite states. I'll just use what you have.. > Let me know, I might use your version as well.\nI'll close this issue after I've merged in these patches, so I'll be sure to let you know.\n\nIf you are building for Android you will see that this and other patches make more sense than for the desktop use-case sometimes.\n\nI'm starting to see that piece-by-piece. Thanks for the insight into the Android world :+1: . The patch in 2db96d939088199d75a6e6c47c41fe85c8b96c3d should be able to replace the two battery API patches you have, which are:\n BRM002_battery_status_service-disable-more-privacy-nightmares.patch\n BRM003_Battery-API-return-nothing.patch. It certainly would be, but then you don't get to easily see the code that changes within the conditional macro. This is problematic when combined with automatic patch refreshing; it runs the risk of excluding new code that you may not want to be excluded.\nIMO, a good patch is one that explicitly shows its changes, not one that is easier to automatically refresh. It's generally easier to see the code's intent this way, and can help catch localized bugs (e.g. forgetting to update some state while stubbing out a function).\nI also purposely changed more code than necessary to reduce the risk of upstream changes causing an implicit breakage. It can make things harder/longer to read, but I place more emphasis on safety in order to reduce complicated issues like #362.. > You mean that more specific changes help in troubleshooting?\nSorry, I wasn't clear enough. Doing more extensive and \"cleaner\" stubbing can reduce the risk of breaking assumptions made in involved components. Memory leaking can be a symptom of assumptions being broken.\nAn example of this is the disable-metrics patch that xsmile wrote a little while back, but it ended up causing the Chromium profile to experience unbounded disk growth. (It was decided that fixing the patch wasn't worth the effort, so it was removed.). By the way, is there any reason why DNS over HTTPS is available on Android only? Can it be enabled for all platforms?. Forgot to reference eb5aa1a0431937aede292acd2f9481d3a26ab575 to this issue.\nAll the patches I wanted to include have been included now. After I get an answer to the earlier question, then I'll close this issue.. > Correct me if I am wrong, but I have not seen anywhere published what are the upstream (Chromium) plans for this feature.\nI didn't even know it was being implemented in Chromium until you showed me your patch. I'm not well versed in DNS over HTTPS.\n\nEdit: from what I remember there was no Android-specific code involved, it seemed to me as well to be arbitrarily limited to Android.\n\nAlright. I'll just remove the restriction then.\n\nIn short, no. It is not related to DNS-over-HTTPS though, it is just that in Chromium adding a free-entry text field is a pain, flags cannot have it and thus you should implement the UI\n\nAt least on desktop, we could check the command-line arguments first before checking the feature flag setting. I don't think DNS over HTTPS will be that useful on desktop, though.\n\nAny idea for future similar collaborations? We do not really have forums or a similar place for OOB communication.\n\nI think the issue tracker works well enough as a forum substitute; I think it's perfectly fine to have issues purely for discussion. Otherwise, there are the Gitter and Matrix chat rooms.. I decided not to include DoH: f05f73c9dcceef4a3059fc49961e16642685a98a\nEverything else is still included, but I haven't tested them yet.. Whoops, I forgot the Canvas fingerprinting patch.... > I have seen your improvement to the randomisation in the Canvas patch and the \"return nothing\" non-breaking patch for the WebGL info; I will probably pick at least the latter and credit you in the patch commit message.\n:+1: \n\nEdit: I checked the returned WebGL information: unfortunately there is a lot more there, texture parameters etc. Hiding just the vendor and renderer name would not suffice to prevent unique identification of the GPU hardware.\n\nInteresting. How do you access this from JS?. NOTE: My knowledge of information theory and 3D graphics is lacking. Some of what I say here may not be completely correct.\nAs we both know, the purpose of fingerprinting deception is to eliminate high entropy sources that do not affect functionality of web applications in any significant way. The high precision of the floating point numbers is a good example; that kind of precision is useless to a web application, but its consistency and uniqueness increases its entropy (due to the video driver, display configuration, etc.) EDIT: I had the getClientRects and measureText metrics in mind when I referred to \"the floating point numbers\"\nSo, when we evaluate potential sources of fingerprinting, we need to consider the two questions:\n\nHow much entropy is being conveyed? Basically, is there a significant amount of data that is able to be used down to narrow down to a small set of users?\nHow useful is this information to web applications?\n\nApplying these questions to our situation:\n\nSome of the data looks to be based on powers of two, so those values shouldn't be too surprising to anyone (low entropy). I can't speak for the other values; we would need to find samples from other configurations to find out the kinds of variations for these values (i.e. sampling the random variable to determine the probability distribution).\nA lot of these attributes seem to be maximum values for various graphics-related features. I can see this being useful for applications that want to automatically determine a \"quality level\" to keep consistent performance across various devices. In extreme cases, this can be used to prevent visual bugs due to exceeding the capabilities of said devices.. > given a specific GPU hardware, and the complete set of values excluding GL renderer and vendor, is that combination unique?\nThis and other concerns could be talked better with some data at hand\n\n\n\nI see what you mean now. You're right. We can't conclude anything else without data at this point.\nFor the debug info, the worst case scenario is the blocking breaks webpages. Considering that these strings are similar to User Agent strings, this is a non-zero possibility. However, there are APIs to test features now, and the APIs still respond normally with this patch, so I don't think it will be likely.\nThe debug info patch is very small right now; I don't suspect it will become a significant maintenance burden unless the APIs or code structure keep changing. I'm going to keep it in for now. The only major change I forsee is the ability to spoof these values, for reasons not unlike that of User Agent strings.\nFor the other values, I don't think we should manipulate them unless we have a good reason to. At least, I don't think we should for ungoogled-chromium.\nEDIT: Fixed logical mistakes and added more info.. Are you using a build of ungoogled-chromium based on the Linux Rooted bundle? Since you mentioned that a chrome://flag is unavailable, it doesn't sound like it.\nThe Portable Linux build doesn't include this VA-API patch. I don't see any reason why it can't be in Portable Linux, so it must've been a mistake I made. I'll move it so Linux Portable can have it too.\nIf the VA-API patch still doesn't work or you are already using a build with it applied, let me know.. It's already possible to use Tor in the whole browser by setting up Tor as a SOCKS5 proxy for Chromium. I suppose some UI to make this configurable for private tabs wouldn't hurt.. I don't see any benefits of bundling Tor. All users of Tor already install a Tor client themselves (from what I've seen), so there would be marginal benefits at best; it will certainly complicate an already complicated packaging process.\nOn the other hand, adding features to improve interoperability with Tor is fine to an extent. I will need to see what the implementation is like before I can make a decision.. @intika \n\nThe more i read issues the more i think ungoogled-chrome will become a whole different browser on it's own \n\nIf the development momentum grows, this might happen. There isn't much else that can be done relating to removing Google integration, which is why I started venturing into other areas.\nI am not against ungoogled-chromium evolving further beyond, and outgrowing its given name. But IMO, at least a small team of people would be necessary to make that a reality.\n\nmay be a lot more to maintain if you are doing it alone, or may be get paid by search engines and working on the project full time if it's not already the case :D :P\n\nFor personal reasons, I don't believe I will reach that level of involvement. In addition, I will not want to be paid to work on this project.. @anchev I didn't know about the identity rotation feature of TBB. Is it not possible to do this in an extension?\n@intika I believe Tor integration should be fine if it's an optional feature. However, like I said earlier, I will need more information about the implementation for me to decide. Namely, what kinds of features beyond the capabilities of extensions would be included? How will these features be implemented?. @anchev Chromium allows you to spoof the timezone with an environment variable. Does TBB spoof the timezone by default?. So far, I am fine with the general idea of adding better Tor integration to achieve feature parity with TBB. Before anyone submits a PR, I'd like to see a proposal of an implementation so we can work on a design we all agree on and minimize wasted developer work.\nMaybe we could offload most of the logic to a special extension with access to a new private API (like the Webstore extension uses)?. > According to about:config the setting is privacy.use_utc_timezone=true (which is the same I saw in the cookie when testing).\nI see. I just set TZ='Etc/UTC' whenever I need to spoof timezone to UTC.\n\nas unlinke Firefox it doesn't connect to Mozilla's telemetry, Amazon, Akamai and all the rest of Mozilla's \"privacy respecting\" stuff\n\nIMO it's all comes down to putting in the effort to implement something for Firefox like what ungoogled-chromium did for Chromium. Unless Firefox's design makes this significantly more difficult, I believe the potential in this area is equal to Chromium.. > Thanks. But which other programs may be affected by this?\n@anchev At least with the popular shells on Linux, you can just place the value inline to have the variable set just for that process, e.g. TZ='Etc/UTC' chromium. You can also use the env command to do this. Furthermore with the Debian packages of ungoogled-chromium, you can add a file in /etc/chromium.d/ to set it by default (since chromium on Debian is a shell script wrapper around the actual binary)\n\nI created because following all that is a real nightmare - very time consuming and IMO unreliable. That's why I think UC is a much cleaner thing to start with.\nThe advantage with chromium is that we dont need to deal with all the functions added in chrome as they are 2 different projects\n\n@anchev @intika I see, interesting insights. Thanks.. @anchev Your link is discussing Tor over QUIC, not QUIC over Tor.\n@ian-moone The Wikipedia page for QUIC says it is based on UDP. The overview page of Tor on Tor Project's website says it only supports TCP streams. Thus, QUIC should be ignored by Tor. I don't know if Tor has explicit QUIC support or not.. Well gsettings-desktop-schemas-dev basically only adds that dependency right now, so I think it's safer to do it this way just in case the dependencies change. If you can show me a source package that has gsettings-desktop-schemas explicitly as a runtime dependency, then it might be fine to change it.. A note about this was also added into the FAQ following that issue.\nGiven Google's push for Material Design UI, I cannot guarentee that the \"Enable Material Design extensions\" switch will continue to last.. To my knowledge, Chrome/Chromium never had a setting to clear history automatically on shutdown. Can someone else confirm this?. I'm guessing these are hacks for the latest Windows binary?\nI'm not sure if the crashpad-handler process is a bug or not from our side, but the UDP broadcasting deserves a look.. > I took a little time to find out which of the countermeasures I'd tried actually does the trick. It seems the UDP traffic is gone if and only if EnableMediaRouter is set to 0 via group policy. \nHmm, do the UDP broadcasts occur in the Linux and macOS builds as well? If so, I wonder what it is necessary to disable them. We could use that info to make a patch that makes it easier to disable these UDP broadcasts, if someone is inclined to do so.. Given that there is an existing policy setting to disable media router, I'd rather have a CLI flag for this toggle than patch out this specific code within media router.. @intika Would you be able to submit a PR for this to the User Resources page on the Wiki? Thanks.. There are no instances of vcxproj files in the binary pruning list, so one of the files in the pruning list must be involved with the schema URL. If the file does not contain any other domain names that should be substitued, then we can ignore it from the binary pruning list.. I don't know. Those in the linked bug report are tweaking settings at a pretty high level (i.e. settings exposed by the UI), and a lot of our modifications are based on Wireshark traffic and digging around in the source code (mostly the latter).\nIf you do find a leak, please report it.. Domain substitution covers the domains that you reported in the bug report (1e100.net, google*.com, and many more not mentioned in the report). So any domain names hardcoded into the source code will not be able to function correctly unless obfuscated.\nI also modified Chromium to log if the browser attempts to connect with the modified domains, so I can disable the unnecessary code and any other related services.\nI am certainly not claiming to have blocked everything, but I believe that most, if not all unwarranted connections have been disabled.. Not only is it an invalid TLD, ungoogled-chromium will intercept and block all requests that go through Chromium's network stack (which includes URLRequest) that contain the qjz9zk domain name. So, the likelihood that Chromium will actually attempt any sort of connection with a URL with that domain name is very small.\nHowever, services not using URLRequest theoretically could attempt a connection. Though I am not aware of any such cases.\n. Regarding the Windows build not being linked, no one has submitted a PR to ungoogled-chromium-binaries for inclusion. I leave the responsibility of keeping contributor binaries up-to-date to the contributors that submit them (or someone else that wants to do it). EDIT: I also don't keep track of statuses of platforms that I don't support.\nIf you have more questions regarding this issue's main topic, please respond here. If you have other questions, please create a separate issue for each separate topic. Thanks.. ungoogled-chromium functions exactly like Chromium for profiles. You can even migrate an existing Chromium profile to ungoogled-chromium by simply running the browser.. Looks like pylint updated and broke the entire check. The config looks good, so I'll merge.. Hmm, this is interesting.\nIs Brave Browser portable?. Thanks for testing, and the technical details. I may be able to propose a patch later once my current tasks are complete, but I don't have a machine to make a Windows build with right now.\nFeel free to submit a PR before then.. @mehrdadn Thanks for your solution. Did you have this problem on a non-Windows platform?\nAlso, do you have an idea why Google decided to have this feature? If there's a technical reason for this feature, then it may be problematic to enable it by default.. @mehrdadn Based on the symbol names of your solution, it seems your solution is modifying code related to the preferences store. I believe the preferences store is one component of a profile (i.e. the Preferences file and potentially several other files). I suspect there may be separate logic to determine if the profile is being used on a different machine.\nFurthermore, if a hash is used to ensure validity of the store, then it's possible that not all syntax or semantic errors are caught after hash validation passes successfully. This can be a problem if the stored preferences gets corrupted (and also if someone makes a mistake modifying preferences. But, I believe it's important to maintain integrity over ease of tweaking for most users. At most, I will allow a flag to toggle hash validation.). > note that migrating profiles between machines is not the real issue here\nIn this issue, that seems to be the real issue... is there an alternative interpretation I'm missing here?\n\nthe problem here is that even on the exact same account and machine, you can't migrate a Chrome profile to ungoogled-chromium\n\nI didn't realize that was also a side effect of this problem from reading your issue report. Thanks for clarifying.\n\nAnd yes, it's true that not all errors are caught, but errors are not introduced in the first place unless an external entity is messing with the profile\n\nI just realized that the files mentioned here and in your report are the same... it's possible that the logic is more unified and the metric gathering more extensive than I originally thought.\nBut, if the \"pref hash store\" also includes a hash of the preference contents, then my earlier point still stands with corruption, i.e. errors introduced by hardware and/or software glitches.. > And again, yes, it does \"catch\" corruption caused by software/hardware glitches, and it \"fixes\" it by just obliterating almost everything. You can judge whether that's a cure better or worse than the disease\nI will reserve decisions and further comments on this issue until I learn how the hashing works, what exactly it needs to function, and how it relates to hashes generated by other Chromium variants (e.g. Chrome, Opera, Brave, regular Chromium).. I think we can reference these changes to solve this issue:\n\nhttps://github.com/brave/brave-core/pull/795\nhttps://github.com/Eloston/ungoogled-chromium/issues/538#issuecomment-435613533\nI'm planning on investigating the CWS change to see what it affects.\n\n\n\nIf I have time, I'll look into it.. Unfortunately, Windows support is broken and no one's working on it right now (#475). I could test this on Linux once it gets added.. Thanks for finding the files. I will add exceptions to the list generation script later after I finish up some work first.. Thanks for the show of appreciation, but I currently do not want to change the Chromium branding as stated in the README.. Let me attempt to answer your questions at once.\nungoogled-chromium is Google Chromium sans integration with Google. There are also some changes to improve privacy, control, and transparency, but they shouldn't break compatibility with regular Chromium. So expect all existing settings, executable names, and branding to be exactly as they are in regular Chromium.\nFor convenience, ungoogled-chromium first generates packaging scripts for various systems. On Linux, we try our best to match the Chromium packages for the respective distributions. They are otherwise standard packaging scripts; all the actual building steps occur within them. You are free to add, remove, and modify as you would with any other packaging script. This will become more apparent once I've finished the work I'm doing in the redesign branch.\nBecuase of ungoogled-chromium's privacy focus, settings already default to enhance privacy in new profiles. This is pretty standard across all Chromium derivatives, and it is no different here. In ungoogled-chromium's case, most of the defaults come from Inox browser; you can find its source code patch in its patches directory.. > I am rather interested in being able to configure/customize the build, install it where I want, git-update/recompile it when appropriate and maintain it this way for all computers I manage. And all this - whithout creating conflict with existing (distro-provided) packages, their configs or file paths.\nI see. Thanks for giving me the high-level objective.\nIn that case, you may be more interested in the Portable Linux build process, which are portable binaries. If you want to use the openSUSE configuration from ungoogled-chromium, you can choose to use the opensuse config bundle instead of linux_portable, but still use the linux_simple packaging scripts. Follow the instructions for Other Linux distributions and follow the packaging instructions for an Archive. Before you run build.sh, have a look through the comments inside and make changes as necessary.\n\nWhen you say most that implies there are others which don't come from that browser. Could you please elaborate? Also - what should one do if one wants to modify Inox's (or the rest of the) settings?\n\nThere are many Chromium derivatives, i.e. independent free software projects spun off of Chromium's code. One of them is Inox, and ungoogled-chromium uses patches from it (as you may already know from the README). As with any free software project, the developers are free to use code from others or not. ungoogled-chromium happens to be a project that is a combination of borrowed changes and new changes.\nIf you are interested in modifying the default settings Inox changes, here are two straight-forward options you may be interested in:\n1. Modify Inox's patch before the build starts\n2. Apply the patches, modify the source code manually, then run the build commands.. @anchev \n\nHowever I have no idea how to make startpage default search engine and use its POST search feature. Do you know about that?\n\nSee #105, which is the same thing but for DDG.. @anchev \n\nThe link gives 404\n\nI changed the section names some time after that comment. It's \"Any Linux distribution\" now.. @anchev \n\nAm I missing something?\n\nSame answer as https://github.com/Eloston/ungoogled-chromium/issues/473#issuecomment-417107870. > How do I fix this please?\nI am resolving this in #472 . I don't think so, but I haven't investigated yet.. What version of LLVM are you using?. Please upgrade to at least LLVM 6. I'm not sure if a newer version is required for version 68.. @anchev \n\nETA: I see that LLVM 7.0 was released today. Why would a software which was released before it require it for building itself?\n\nBoth you and @intika are using linux_portable to build, which enables newer optimizations like LTO, CFI, etc. Google likes to push the bleeding edge for new compiler optimizations, so they use their own build of LLVM of a specific revision for Chrome/Chromium builds (which is specified in tools/clang/scripts/update.py). This is typically a revision that is newer than any released version of LLVM.\nIn addition, it seems likely that linux_portable actually requires at least LLVM 8; see https://github.com/Eloston/ungoogled-chromium/issues/494#issuecomment-422861767\nIndependent of linux_portable, there is also the openSUSE packaging that uses GCC and doesn't use these newer optimizations, but no one has made the initiative to update it yet.. @anchev \n\nYeah, but as we talked above - it seems not to give the flexibility I am looking for. If it was more customizable then perhaps that would be the right thing to use.\n\nOops, you're right. I forgot the context.\n\nThat is what I would rather be interested to try. Currently looking for info how to do it.\n\nThere are two options off the top of my head:\n\nAdd the bin of the LLVM root directory to your PATH, and ensure that the environment variables specifying the compilers are correctly referencing said LLVM in PATH\nRemove the GN args that specify to use the \"unbundled\" compiler, and place the entire LLVM binary tree (i.e. files that would be installed with make install) into third_party/llvm-build/Release+Asserts (which is what is done for macOS and Windows, see their downloads.ini config files)\n\n\nBTW the whole build process takes about 2 hours here. I wonder if there is a way to optimize it. Any suggestions? I am using a simple bash script for the whole thing:\n\nThat's faster than my machine for building Debian stretch, and it isn't even as aggressive with compiler optimizations as Portable Linux...\n2-4 hours is pretty typical for higher-end regular consumer machines. If you have a lot of threads, you could try reducing the jumbo file merge limit (default is 50).. @anchev \n\nIn which file(s) do I check this please?\n\nThere's a bin directory in the LLVM root directory. You need to make sure your PATH environment variable includes it, and then ensure the CC, CXX, LD, etc. variables use the LLVM binaries in bin.\n\nWhat are \"GN args\" and how do I remove them?\n\nYou should read the Chromium build instructions and related documentation on GN for a more complete picture.\nThe build script generates an args.gn file that you will need to modify before the invocation of gn.\n\nWhat is \"jumbo file merge limit\" and how do I reduce it?\n\nGoogle has good documentation on Jumbo in the docs/ directory of the Chromium source tree.\n\nyou really have an interesting approach - going back to Google to build an ungoogled chromium :)\n\nEven though we probably don't want to use the binaries from Cloud Compute, it's nice to see some real data of the power of cloud-based computing. Who knows, it may be useful if this project continues to grow and reproducible builds become a reality...\nHowever, I am biased. I wouldn't be working as much on this project as I have been if it weren't for the depth of new and fun challenges it offers (and not just engineering-related either). I see peope like @intika playing with these kinds of projects for similar reasons; and they bring forth new energy and perspectives in their pursuit.. > Along the lines of building a portable version: does /etc/default/chromium matter at all? If not - which is the \"master\" settings file where one can set default preferences for all users on the system?\nI don't believe this is modified from regular Chromium for linux_portable bundle, but I may be mistaken.\n\nIs it possible that due to the UGC's specific replacement of host names the \"HSTS preloaded list\" of Chrome doesn't work?\n\nIf that's a link to update the HSTS list, then yes it's broken. Auto-updating the HSTS list from Google would violate this project's primary objective, so we would need to find another way to load it if needed.\nThe built-in HSTS list works just fine; there was a resolved issue about this a while ago.\n\nSpell check doesn't seem to work. Is it because it needs connection to Google?\n\nYes, the spell check dictionaries need connections to Google. They can be downloaded manually if I'm not mistaken; there's an open issue about this.\n\nEarlier you mentioned that I need to modify the Inox patches in order to have default settings the way I want them. However looking at them I see they include specific line numbers which can change with any new version of Chrome, so it seems to need a continuous careful work which I am not sure I will have the time to do. Isn't there a simpler way to approach this?\n\nYou could create a template profile that contains the settings you want, and just use copies of it for running the browser.\n\nuBlock/uMatrix: Do you happen to know where \"Export to cloud storage\" actually uploads? When I click it I see no Internet connections but it still seems to work.\n\nThere are chrome extension APIs for local storage and cloud/sync storage. They have different size restrictions, but the function identically from a read/write API perspective. Both get stored locally in the profile, but cloud/sync storage gets synced to the browser's signed-in Google account if available. (In ungoogled-chromium's case, this obviously does not happen.)\n\nWhile browsing chrome://settings/ I was watching a ss -tuapn on the side and noticed a TCP connection to 104.20.23.46:443. At that time I was on the Language setting. Then I ran rcnetwork restart and tried to reproduce it but I could not. Some minutes later when I opened several chrome://flags tabs it showed up again. Since then I haven't seen it. I have no idea what this host is but considering its location it may be worth checking if it is an attempt of Chrome to connect to something:\n\nI don't know. I can't find any domain name associated with that IP, and that IP is not in the source code as 104.20.23.46. It doesn't make sense to me that Google would be using Cloudfare as a CDN either. Are you sure that it is ungoogled-chromium causing it?\n\nWhat benefit has using --set-ipv6-probe-false?\n\nFrom my usage, it causes Chromium to not use IPv6 because it thinks the probing for IPv6 returned a negative result.\n\nDoes installing an extension as CRX result in possibility to have it auto-updated from Chrome store? I am just looking for a way to install from file \"HTTPS Everywhere\" but EFF's site seems to offer only CRX downloads.\n\nDoesn't seem like it. There's an open issue about using the update URL in the manifest file for updates.\n\nDo I need to do the first 2 inserts in the build.sh itself or will it be enough to simply export the CFLAGS in my own bash script?\n\nThose compiler and linker flags need to be readable by GN, since they're used in the generation of the ninja files (which have all the flags resolved). gn gen is run explicitly once already, but ninja can also run GN if it's necessary. As long as the variables are visible to both the gn and ninja processes, it should be sufficient.\n\nDo you think you could probably include my modification of the build.sh by adding -j$(nproc) to the ninja command? It seems a universal modification which would benefit everyone.\n\n\nIt's not clear to me where nproc is defined\nninja will automatically set the value for -j depending on the number of thread available (see ninja --help)\n\n\nI have an old 32-bit laptop for which I am willing to build UGC too. But I am afraid it may be a terribly slow process (if possible at all because it has a small disk and not so much RAM). How can I use the stronger desktop machine to create a binary for the laptop? I wonder if it just a matter of different CFLAGS (and what should they be) or something else? I hope you can shed some light.\n\nI believe you will need to set some GN flags for cross-compilation defined within the GN files of the Chromium source code. I have no experience with them (nor cross-compiling in general), so I can't help you here.. > I can see what it does but I don't understand the benefit of it. Privacy, security, anything else?\nIt was connecting to Google's DNS server before. Some others just redirect it to another DNS server that supports IPv6, but I wanted the ability to control whether I want to use IPv6 or not (there was a situation where I was using a dual stack IPv4/6 network configuration)\n\nwhich implies that unless explicitly specified, it will always use the default (10). Hence the suggestion.\n\nIt's recomputed whenever you run the command. On my machine, it's 6.. > Does that mean that it no longer connects to it regardless of using this flag?\nIt no longer makes any sort of request to determine the status of IPv6 probing.. @anchev \n\nForgive me, I am not a network expert, so this is a bit difficult for me. All I know is that 'probing' is an action used to determine a state of the network\n\nSorry, I wasn't clear enough. There is a small routine in Chromium that probes the availability of IPv6 via pinging a IPv6 DNS. I stubbed that method to force the result of the probing routine to be determined only by that command-line flag.\n\nWhy one would want to avoid IPv6? I hope you can clarify as for a layman.\n\nI'm not nearly as well versed in IPv6 implications as @intika. I only have surface-level knowledge of it.. > So in short (as far as I understand): it is better to use this CLI option unless there is some special reason not to use it (e.g. accessing a web site which uses only an IPv6 addres? any other?)\nThere's no harm in enabling it if you don't need IPv6. But if you disable IPv6 in your system, the CLI flag won't affect much.. I forgot to update the README with the updated link. Thanks for reminding me @antonin-lebrard \nEDIT: I forgot I already added this to the redesign branch. I hope to merge redesign into master soon.\n@floggle If you are still having troubles, let us know.. I don't know of anyone else that is doing or has done this. Feel free to proceed.. @stefantalpalaru Could you describe a use-case for having both Chromiums installed to the system? It seems contradictory to me to have both installed.. @stefantalpalaru \n\n\"The Great Suspender\" extension was not working on ungoogled-chromium\n\nThis may be a bug with ungoogled-chromium. If you could file a new issue for this, that would be much appreciated.\n\nI also noticed that ungoogled-chromium has no access to the app store, so if you want to install an extension from there, you have to use Chromium.\n\nThis is not true. The first question of the FAQ addresses this concern. In terms of updating extensions, users have proposed multiple external solutions for this problem (in issues somewhere), but I believe the best solution is #285.\nSo far, the issues you described are all addressable in ungoogled-chromium. Are there any other use-cases you have? As @ian-moone pointed out, it is a top priority to retain the Chromium experience, including the packaging.. It is the same as with regular Chromium. ungoogled-chromium will not affect this. Can you clarify what you mean?. I suppose I could bold the entry in the Table of Contents to make it easier for those who just want binaries. Those that want to build from source would probably be reading more carefully anyway.. Do you know if your site uses WebRTC?. Does it work with Chrome or regular Chromium?. Welcome to the free software community, where developers are plentiful and support is minimal on average.\nI am support*, and also the main developer. This isn't a company with a paid support team; this is a hobby project. I don't have time to provide support all day, much less develop on it every day. Although I would like to have all issues resolved in a timely manner, this simply isn't possible.\nI'd recommend that you stick to Brave or Chromium, and tweak them to your liking. They aren't as aggressive in removing Google integration, so the possibility of breakage is low.\n* There are other kind strangers who lend a hand in support too.\nNow, regarding your issue:\nGiven your site is a web-based call system, it is very likely that it is using WebRTC. I do recall calling not working on Discord (also WebRTC-based), but I haven't dug into it to discover the issue. If you or anyone can confirm this site is using WebRTC, that would be helpful. (If not, we'd still probably need to know what they're using.)\nI'm also curious to know if Chromium or Brave work with the site too. If there's Chrome-specific code making it work, then there may not be much we can do about it.. > If you guys can see if it can work in Chromium that would be awesome!\nI'm confused. So you confirmed that Chromium doesn't work? Or by \"Chromium\", do you mean ungoogled-chromium?\n\nSo it would be possible it can work?\n\nWebRTC testing sites say WebRTC is functional, but it seems that certain web applications don't work anyway. I don't know why, and I'm not sure how to diagnose (I know little about WebRTC). Seeing whether Chromium and Chromium-based browsers (like Brave) work or not may give us a clue of the root cause.. Good catch. I believe you should be able to just change the dependency URLs to the correct 32-bit and update the hashes to have it work.\nIf this works, we can split up the Windows config bundle into three parts: windows_common, windows_x64, and windows_x32.. These kinds of cosmetic changes don't add a lot of value and increase the amount of patching required. However, you are welcome to submit and maintain such a patch.. If you just want to build the browser, then you should stick to the instructions: use a tag version. The branches are only meaningful to developers.. > Disabling vaapi in the flags prevents the build from compiling. Commenting the patch out results in the same.\nI'm guessing you mean the GN flag use_vaapi and the patch inox-patchset/chromium-vaapi-r18.patch, respectively.\nSo do you get the same result disabling chrome://flags/#enable-accelerated-video?\nWhat conditions causes this crash?\n\n[31788:31788:0813/230900.638838:FATAL:search_terms_data.cc(24)] Check failed: base_url.is_valid().\n\nThis is an interesting error. I'm not sure if it's related to the VA-API errors above, but it does have a higher severity level... Maybe this is causing the crash?. I see. I am in the middle of updating to version 68, so I can help you more after that.. First version of 68 is out. I don't know if Arch Linux builds work yet; if not, we should open a new issue for that.\nIf you still have this issue after updating, let me know and we can investigate.. I can get back to you after I've done some work on version 68.\nTo anyone else, feel free to pitch in.. Let me know if you still have this problem with 68.. I can't read French. I'm guessing this has something to do with credentials storage?. So if we disable this, credentials can't be saved, right?\nThere's a flag in Chromium to change the credentials storage type. Would changing it to another one disable this dialog box?. Yes, but do we have any other option? Is there a way to automatically unlock it? What does Chrome do?. @antonin-lebrard Thanks\n@Artur96 Ah, I see. So if password saving is disabled in Chromium and the user never authorizes access, does the prompt still appear?\n@pzeups Are you storing passwords in Chromium or not?. 68 is out. Closing stale bugs.\n@pzeups If none of the above solutions are satisfactory, then please let us know what you want.. This seems like it will break anything using VA-API, so even linux_portable should have this. I'll take care of moving the flag around.\nBTW, this breakage was introduced in 68, right?. I've seen this before in #279. Closing this as a duplicate.. Thanks. Didn't realize it was already in the repository directory.. Whoops, I forgot to upload them... Thanks.. Actually, Debian's chromium on Stretch has the same issue. All Debian builds link against the system's libvpx, which provides VP8 and VP9 encoding. Debian Stretch has a really old libvpx version that doesn't support VP9 encoding, so it has been patched out in patches/debian/system/vpx16.patch. 4K YouTube videos are encoded only in VP9, but 1080p@60fps is also available in H.264 and/or VP8.\nTo fix this for Debian stretch, you can rebuild the browser with the bundled libvpx and remove vpx16.patch. Alternatively, you can upgrade to Debian buster or use Portable Linux.\nI don't want to change the Debian stretch configuration because I want to stay as close to Debian's configuration as I can to ease upgrades.. I'm fine with this, as long as it lives behind a command-line flag (at most a setting behind chrome://flags). But, I can't guarentee that it will continue to be maintained in the event that the codebase changes significantly.\nI'll see to adding this info into the README, since I think I've seen this come up often enough.. Do you still want a switch for this feature? If not, I'll close this.. I don't have a use for this feature.\nFor anyone reading this, feel free to submit a PR if inclined.. How did you install the Widevine CDM module?. ungoogled-chromium is the same as regular Chromium; you must install the Widevine CDM. No one has reported how to do this on Windows. If you figure it out, you may submit a PR against the Wiki to add it.. I'm not sure if version 67 has working Widevine or not. In 68, there were several changes to Widevine support. Are you able to build ungoogled-chromium?. Yes, 67 is the current version for Ubuntu bionic. If you are willing to wait, usually someone will come around to submit binaries.. Closing since 69 has come out. If Widevine still doesn't show in chrome://components and it doesn't work, then let us know.. > I think it would be a good idea to add the information in to the building page that you need at least 8GB of RAM to be able to build chromium, less than that and building will likely fail. I just tested building the ungoogled-chromium on 64-bit Intel 4 core CPU with 4GB RAM and it failed due to lack of RAM.\nYou are correct that it at least deserves a mention, especially since there are flags that can be tweaked which affect RAM consumption during building (e.g. GN flag jumbo_file_merge_limit).\n\nThe building commands could be little bit clearer\n\nThanks for the feedback. I will see to clarifying them.. Fixed in master. Should be fixed in the referenced commit. Otherwise, please let me know.. Please, read your quoted text again and more carefully.. This repository contains the \"ungoogled-chromium source tree\" because it contains source code files for ungoogled-chromium. Therefore, the \"Chromium source tree\" contains source code files for Chromium. Google owns Chromium, so you can get the Chromium source tree from Google.\nHope this helps.. Thanks for this. I'm going to merge this later since 69 isn't stable yet. At most, I will merge it as a new branch that will later be merged into master.\n\nEDIT: I really like the checks but I'm not sure what to do about error in validate_patches. The URL fails to load because gn was relocated from the chromium tree to its own repository.\n\nNot only that, but the path is wrong. By inspecting the chromium official tar.xz for this version, it should now be located at tools/gn/tools/gn/ninja_build_writer.cc, not tools/gn/ninja_build_writer.cc.\nIt's not clear to me how they're downloading the GN code into the chromium official tar.xz yet; I'll need to dig a bit deeper so I can implement a non-hacky solution.. I extended the logic for validate_patches.py. You can use devutils/update_patches.py to speed up patch refreshing if you need it. (This and more is documented in docs/developing.md.)\nEDIT: Yes the logic is a bit hacky. Unfortunately, I could not find a way to determine the GN version used in the chromium-browser-official tarball automatically without actually downloading it... Hence why the version is hardcoded.. > I refreshed the patches but cannot figure out why debian/gn/libcxx.patch does not pass validation. Updating the patch manually with quilt or via update_patches.py does not alter its contents.\nBefore db11c83809c725d6e9b2aff5bbc80e8ee29993ab, I hardcoded the GN version used in the chromium-browser-official tar file. Since you changed the Chromium version, the hardcoded GN version went out-of-date. With db11c83809c725d6e9b2aff5bbc80e8ee29993ab, I implemented an idea I had to auto-detect the GN version (see the commit message for an explanation of the logic).. Awesome. Thanks for testing and the other PRs to fix my silly mistakes.. > Looking at the other platforms' build scripts I assume the Windows one should handle everything from source downloading to packaging as well.\nYour assumption is correct. The build scripts will need to be reworked to support the new packaging strategy (i.e. handle everything itself).\nA little while ago, @squalus suggested that we should rework the build scripts in Python, but it would make some tasks more difficult, such as providing the shell variables from vcvarsall to certain commands (e.g. the GN bootstrap script). I'm not familiar enough with batch scripting to determine whether it is worth the effort to switch to Python entirely, or stay with the hybrid approach we have with batch scripts. What are your thoughts?. With 7c2d1b8a216f7e9dacc1d6a78d0a6a4f98076f5f, the scripts have been rewritten in Python (but they haven't been tested). Patches haven't been touched and still need to be updated.. EDIT: I just saw the log again, and you're using python, not py.  python always refers to Python 2 for compatibility with Chromium scripts, and py is a command introduced by Python 3 that has some logic to auto determine whether to use Python 2 or 3.\n~~That's interesting... you were able to use get_package.py, but you couldn't use build.py? Both use Python 3-only syntax, so it's surprising to see one work but not another, especially since the py command reads the shebang line in all of the files to determine which Python interpreter to use (and they're all python3)~~\n~~Maybe you're using an old Python 3? buildkit uses additional unpacking generalization (PEP 448), which was added in 3.5.~~\n~~If that doesn't work for some reason, you can also use py -3 to force usage of Python 3.~~. At some point in time, Chromium's Python 2 scripts used pypiwin32, hence the requirement. None of my scripts require that.\nIn 366b1eed5ce975ab537bbd3062b77a0bb5e3064f, the scripts now explicitly check for Python 3.. > Tested the the scripts on the latest commit and build.py still seems to check for pypiwin32 in lines 85-87\nIs the check not working? What happens if you launch Python 2 and import pypiwin32?. > My bad, I assumed the script was looking for pypiwin32 in the python3 installation, I should've taken a look at the code.\nI'm guessing the build instructions were confusing to you, because the exact steps to take are all there. Could you tell me what confused you, or submit a PR with fixes?\n\nFrom what I can see it seems like pypiwin32 is not supposed to be imported with its name, but with import win32api.\n\nFixed with #488. Thanks for letting me know regardless.\n\nAfter this change the script works, until, while applying patches, I get this:\n\nThat's expected. The patches haven't been updated yet. I might have an opportunity to update them this and/or next week, but I can't guarantee anything.\nEDIT: Feel free to take the initiative to update the patches if you'd like. Portable Linux and Debian stretch are higher priorities for me right now.. @92847586 Yeah, development on 68 has ended ever since xsmile's update to 69 was merged.. c1a95aa5c50924e96ef51ab8c3b937fc4a764a2f has the existing patches refresh with moderate guessing involved. I have not tested anything yet.. >  E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src>\"C:\\Python27\\python.EXE\" \"tools\\gn\\bootstrap\\bootstrap.py\" \"-oout\\Default\\gn.exe\"\nLook like I forgot a comma in the build script. The last argument is wrong, but it still worked I guess...\nI have no clue why the \"gn\" target doesn't exist. It looks like a bug in bootstrap.py. @Wyse- Strange, I didn't change anything from when @shiromichi ran the script in that area. I noticed your current working directory is changing between vcvars64.bat and bootstrap.py. I don't know what is happening there.... Is there a cache_index.list in debian/scripts/ungoogled-chromium/domsubcache.tar.gz?. That means the domain substitution cache (domsubcache.tar.gz) is corrupted. Do you have any logs from before the build was invoked? Specifically the output from override_dh_auto_configure, where the cache is generated.. > By the way: Did you ever think about automating your builds in your CI system?\nChromium is too resource demanding for free CI systems. I don't want to maintain a paid service either. If you have an alternative suggestion, I'd like to hear it.. > Rebuilt using the initially mentioned commit. Could not reproduce the bug.\nI'm not really sure why this would happen unless there's a bug in Python and/or your filesystem glitched. I'll leave this issue as it is unless it keeps happening. Thanks for reporting, anyway.. Thanks. There was a small bug in my script which I solved in da719778ad9987e1d2fde3d2f2a70cb9663e134c. It seems like it fails on the sed command right after domain substitution, which is line 80 of PKGBUILD.ungoogin.\n@xsmile Have the file paths changed, or should the line be removed?. @xsmile I see, didn't realize it was in the wrong directory. Thanks.. My guess would be cookie settings. By default, third-party cookies are disabled. There may be some other default settings in chrome://settings that are causing session identification information to be lost. Let me know if the settings can't be tweaked to fix your problem.\nI believe this behavior is desirable by privacy-conscious users. However, if this behavior can't be changed via settings, then it is a bug.. Same as https://github.com/Eloston/ungoogled-chromium/issues/492#issuecomment-420129329. Same as https://github.com/Eloston/ungoogled-chromium/issues/492#issuecomment-420129329. Thanks for the instructions. If you could, please submit a PR with the information integrated into the Portable Linux building instructions.\nIssues are not designed for long-term discussions. They are designed for short conversations that address specific concerns. If changes need to be made, they can be said in commit comments or new issues. This may not be what others are doing with issues, but it's a system that has been working well with this project (and long discussions definitely don't work on GitHub).. > having fun lol ... i am learning chromium backward\nIf you need more help, have a look through the linux_simple build scripts and also the documentation under docs/. You should also have a look through the official Chromium building instructions.. I'm not sure why the compiler is making a difference here. Do you still have the sysroot error after f6fbb168b8936509ab43f657f54014f97c4410b4?. Thanks for the detailed steps and output. I'm not sure why this is happening; I'll need to investigate.. I realized the problem was here:\nsubprocess.CalledProcessError: Command '['out/Default/gn', 'gen', '/home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build', '--args= is_debug=false', '--root=/home/intika/chrome/69/ungoogled-chromium/build/src']' returned non-zero exit status 1\ni.e. the args aren't being read from out/gn_build/args.gn as I thought they would due to the forced usage of --args. It should be fixed now.. Congratulations on getting a build working!\n\nnote that it did not work with lld/llvm/clang v6 i had to update to v8 to bypass the error for chrome v69\n\nSo it seems Google is pushing for bleeding edge features yet again. Thanks for the info; I'll update the docs.\n\ndo you know the impact of that error ?\n\nThis also happens on Debian stretch builds, but I haven't looked into what causes it. If I am to guess, it's probably some Python script in the Chromium source tree that is running git.. Do you know if LLVM 7 will work? It will be released soon, so it will be more widely available than LLVM 8.. > i tried to use LLVM 7 etc. but i got some build error with it. (it could be because of the package being in a beta repo)\nI see... then I suppose the features Google is using are present only in LLVM 8. That's unfortunate, considering LLVM 7 was just released :(\n\nThus said v69 src package from opensuse does not require clang8 nor clang7 i think the package from suse is using gcc to build\n\nRight, there are a different set of fixes needed to work with GCC. Also, the configuration is different too (e.g. not using newer optimizations like CFI, LTO, etc.). I'm not sure why you're bringing this up since you're using linux_portable via linux_simple.. @intika I just pushed a new tag for 69.0.3497.100-1. You may submit a PR to ungoogled-chromium-binaries for that tag.. I didn't know that kind of metadata was available. Thanks for showing me :+1: . I would be okay with appending the ungoogled-chromium version, but I don't want to change the existing string. I'd also prefer to have it set through CHROME_VERSION_EXTRA instead of through the source code to make it easier to implement.. @webbertakken Yes. Debian's chromium package (and also ungoogled-chromium's Debian packages) use these environment variable to set the Debian versions used for building and running.. @mintunitish You basically need to get the ungoogled-chromium version info from version.ini via get_package.py. One simple way to do this is to add a .ungoogin file that will contain only the ungoogled-chromium version, and then modify the Chromium launching wrapper scripts to modify CHROME_VERSION_EXTRA with the value from this file. How you modify the packaging scripts depends on the packaging scripts you modify.. I just realized this patch violates the layered infrastructure: https://www.chromium.org/developers/design-documents/cookbook\nI will probably move these constants into //net and reference them from //components. Thanks.. Since the introduction of jumbo builds, single-threaded performance has become more relevant than in the past. If your processor's single-threaded performance is poor, that may be a factor. (There's documentation in the docs/ folder of the Chromium source tree if you want to learn more.)\nAlso, IO performance is relatively important too (lots of intermediate files being generated), and having more RAM will help (so more data can be cached in RAM).. That explain it.\n\n2GB ram\n\n~~I'm surprised building even works for you at all~~. The minimum required RAM is 8 GB according to Google's documentation, so if you end up using swap space...\nEDIT: It'll work, but it won't be a fun experience. If you're really intent on getting it to work, you might want to change the jumbo file merge limit (see the docs/ folder in the Chromium source tree for details) to not push your memory too hard.. I'm going to bet that your macOS is too old because:\nApplication Specific Information:\nabort() called\nso it's likely that Chromium decided to kill itself for some reason.\nIf the aged system isn't the issue, I'd be glad to reopen and have others investigate.\n\nAm I entirely hosed for preventing privacy raping?\n\nLinux works well across a broader range of hardware, and software compatibility is better too. Given that you have an older Macbook Pro, it should work very well.. If you're referring to the GitHub releases, I don't use them to denote stability anymore. Tags denote versions ready to test/release candidates for at least one configuration; you can see more info through the README.\nOtherwise, let me know what you mean.. @alexoler Yes, it is in progress. See #475.. > this change skips re-download same archive file from remote location..\nI'm not sure what you mean. Can you clarify? The only changes I see made to the packaging scripts is -p to mkdir...\nAlso, it looks like macOS patches apply cleanly now. You can fix the CI check by removing the patches_outdated marking from bundlemeta.ini of macos.. Oh. In that case, mkdir ... || true would also work. But -p works, too.. Funny, your workaround is the same exact compromise I came to :) (EDIT: For context, I was trying to get a build with Canvas and WebGL patch starting before the commit introducing the patch.)\nIt is a solution with the fewest changes and lowest risk of hard name conflict bugs to resolve for now. But, I don't like accumulating technical debt.... I'm assuming this is the same problem as #510. Please correct me otherwise.. You can use the Portable Linux version. It's essentially the Linux equivalent of the Windows build.. In Chromium, you can change the user data directory to a custom path via a command-line argument. This is a commonly-used feature you can search online for.. > where you can select the user directory path\nWhat do you mean by a \"user directory path\"?. Chromium's default installer does not support this. If you want this functionality, please develop it as a standalone wrapper around Chromium.. Interesting, I didn't realize they have a different target name for building GN on Windows. This isn't the case the Chromium on Windows; it seems my assumption was wrong. Thanks for investigating.\nIt looks like you didn't update the patches. I'm guessing you aren't able to because you don't have quilt setup on your machine? Please do so in future PRs.\nI believe the more Windows version-agnostic and lighter weight way to set this up is using MSYS2; it includes quilt through its pacman-based packaging system.. I also noticed that you seemed to have created the patch without following the patch orders. You can use devutils/generate_patch_order.py to generate the complete patch order for a given config bundle. There is more info about the development workflow in docs/developing.md; let me know if anything in it needs clarification.. Both debian_buster and debian_stretch config bundles build against the system's fontconfig library. I've tested both and never had any problems related to fontconfig.\nWhat is your build configuration? What config bundles and packaging scripts are you using?. You can retry debian_minimal with the latest commit and see if that fixes this for you.. I think it would be better to have another autocomplete URL field for this.. @xsmile Is extending the UI and config infrastructure to add the necessary fields not sufficient to fix this?. @xsmile \n\nFrom my point of view there is no way to use this feature with Google - or apparently any other search engine - without hard-coding the full search engine template\n\nRight. My idea is to add the infrastructure necessary to convert these hard-coded values into new text fields in the search engine editing UI, so users can freely set them.\nI haven't looked at the code either, so I don't know how involved it will be. My guess is that it will at least require additions to HTML, JavaScript, and C++ in the browser (to implement both frontend and backend code for the settings). I believe the last file modified might be useful, but I'll need to find some time if I am to investigate. It's a small patch, so if it doesn't break anything on desktop, then it should be fine.. > compiling the codebase takes 16GB RAM with just 1 compilation thread\nThis is not true with the correct configuration; see the following response.\n\nI like to put the entire source and objects into a RAM disk, which can take another 16GB\n\nIt's possible to have the source tree fit entirely within 8-9 GB and still have enough to compile and link. I do this for my Debian builds on a machine with 16 GB of RAM.\nBut I do this to reduce wear on my storage devices, not for performance. I don't believe there is much of a performance improvement with RAM disks compared to non-volatile storage devices, but I have no data to back this up.\n\nusing the end result would still account for significant drains in available memory, and all that memory, where does it go if I can't tell the difference in performance with competing slimmer browsers? Is it going to Bitcoin mining?\n\nI don't know the Chromium code nearly well enough to tell you the breakdown of memory usage. You'd need people with the equivalent knowledge of core Chromium developers (for at least Blink and V8) to get a satisfactory answer. On a tangential note, DevTools has some profiling tools that might give you some insights on the HTML/CSS/JavaScript side.\n\nI hope these issues are somehow addressed here by virtue of ungoogling the codebase.\n\nAll of your concerns fall under secondary objectives of this project. I am open to anyone contributing features to resolve these problems.. > I beg to differ. Using LibreOffice as an example I testify that putting /var/tmp (default $TMPDIR for Portage) into a 23GB RAM disk allows me to emerge it in just 40 minutes compared to standard 440 minutes. \nI forgot to mention that I have a SATA III SSD, so I'm not sure if RAM disks yield a significant improvement. If you're using a HDD, then your numbers make more sense.. > rough performance is somewhere at 200-320MB/s\nIs this for random or sequential reading/writing? I don't think RAID 10 will help either performance metric much beyond what the HDDs already give you.. The reason for this change and a brief history of the licensing are all in #230.\nSwitching back to GPLv3 would break license compatibility with that project.\nI also don't see any reason why I'd need to change the license to anything else. In terms of code sharing, BSD has more freedom than GPLv3 in that non-GPL products or projects can easily use and modify this code. If the risk is of a company profiting off these changes with a proprietary solution, I fail to see how that would affect the main audience this project is targeting.\nHowever, if you have stronger reasons for changing, please let me know.. @csmk Thanks.\n@anchev Please let us know if this doesn't answer the question.. @csmk \n\nI need to investigate this further. I'm also getting that first line in your log.\n\nI've also been getting that error for many versions now (at least with the Debian builds). If you do find something, I'll be interested in hearing it :+1: . @csmk I see, perhaps there's an open Chromium bug report somewhere if it's that prevalent. If you find a method to fix it (beyond just updating Chromium), let us know via a new issue. Thanks.. I like this idea. I've thought about this further by stripping out the directories dedicated to Google integration (it'll increase certainty that no communication is happening with Google beyond URLRequests, and also reduce dead code), but never had time to resolve all of the code that broke as a result. For now, just removing signin files should be good enough.\nIf you go through with it, feel free to submit a PR. :+1: . You did not install the build dependencies. Please see the recommendations for doing so in the building instructions.. If it's stored or cached in the profile, it should be viewable by Chromium.\nI'm not sure if the branding difference between Chrome and Chromium makes any difference. If it doesn't work, let us know.. I don't know. How is it used inside the GN files?. No, I'm referring to the GN definition files, which consist of BUILD.gn and *.gni files throughout the Chromium source tree.. According to components/os_crypt/features.gni, the flag use_gnome_keyring is only useful for legacy systems without libsecret (which is the successor to an older gnome-keyring interface). That file references the following bug reports:\n\nhttps://bugs.chromium.org/p/chromium/issues/detail?id=355223\nhttps://bugs.chromium.org/p/chromium/issues/detail?id=466975\n\nIf I am to guess, libsecret is probably what implements the --password-store=gnome option.\nOn a related note, it seems that use_glib controls whether libsecret support is built or not. But I'm not sure if toggling it is a good idea, since other integration features with GNOME may be grouped under it.. @anchev Based on this comment, it should have been ready about 2-3 years ago; otherwise password storage wouldn't be secure for newer systems (they fallback to basic storage).. > Based on this and this info on Linux one still needs to specify explicitly --password-store=gnome or --password-store=kwallet, otherwise it would fallback to basic (unencrypted). Also according to this bug report the work on dropping KDE's and Gnome's backends is started but not finished.\nIt uses GNOME Keyring by default for Debian stretch builds. I personally use it. use_gnome_keyring=false is set for all builds by default.. > Even with use_gnome_keyring=false? How is this possible? Isn't that setting supposed to disable it?\nNo, that GN flag disables the legacy interface. Like the Chromium issues mention, libsecret is the current mechanism used to interface with GNOME Keyring in modern systems, and also KWallet it seems.\n\nI don't know what \"Debian stretch builds\" means. I build it from source (as we talked in other issues).\n\nThese are the builds for Debian stretch that I build and publish myself.. What is navigator.webdriver?. @nadavhury I have very limited experience with chromedriver. Are you not able to try it yourself?. I looked into it a bit more, and I don't see any code that should be affecting this. If it's not working, please open a new issue with the specific interfaces that aren't working.. Does the development version 69 have the same issue? (It was published not too long ago). @Artur96 Thanks.\n@HunterMeyer If the problem still occurs for you after upgrading, let us know.. Is there any harm to adding *.gn and *.gni files to domain substitution?. I believe the patch ungoogled-chromium/linux/fix-libva1-compatibility.patch will fix the problem. You can use debian_stretch as a reference for when to apply the patch in the patch order.. Sorry, I don't accept money. This is just a side project for me.\nIf you want to help out, I'd greatly appreciate any contributors. Otherwise, spreading the word around will help in general.. I don't think this is a problem with ungoogled-chromium; rather it is a problem with using the C/C++ compilers clang and gcc. Perhaps you should try asking the LLVM community for help first.. You could try StackOverflow and other compiling-related forums. I don't know much about compiler optimizations.\nIf you know the processor code name (e.g. haswell, broadwell, skylake, kabylake, etc.), then it seems clang should have one of them as an option.. It looks like the standard library headers aren't available for some reason. Based on the compiler command includes, it doesn't seem to be using Chromium's built-in libcxx library. So, you may need to have your system's standard library headers available so GN can be built. linux_portable should then use its own standard library to build Chromium itself.. Perhaps the GN bootstrap script doesn't support cross-compiling. You can try setting native compilation flags for GN bootstrap, then change them to your desired pentium-m setting before you run gn gen and ninja.. > How come? I cross-compile successfully for other 64-bit architecture as mentioned in an earlier comment.\nAs I understand it, you are now compiling on a 64-bit host for a 32-bit target. ~~Were you compiling on a 64-bit host for a 64-bit target before (because existing 64-bit shared libraries could be used)?~~ Were you compiling the same version of Chromium (because GN bootstrap script has changed)?\nEDIT: I just re-read and you mentioned you could do both cross and native compilation (i.e. 64-bit host to 64-bit target, and 64-bit host to 32-bit target). I'm not sure if pentium-m would affect anything from the compiler's point-of-view compared to any other 32-bit target architecture. So, the GN bootstrap process could be the culprit.\n\nCan you elaborate on this please?\n\nI am proposing that you modify build.sh so you have something like this:\n\nSet flags to target native 64-bit architecture\nRun GN bootstrap.py\nSet flags to target your pentium-m machine\nRun the rest of the build commands; i.e. gn gen, ninja\n\nThat way we avoid any issues with the target configuration requiring 32-bit headers ~~that aren't configured correctly on your 64-bit host~~ with either the compiler or GN bootstrap process.. > So far I have cross-compiled successfully only 64-bit host to 64-bit target. I am still struggling with 64 host to 32 target.\nI see. Compiling for 32-bit targets from 64-bit hosts is another level of difficulty because of the number of differences between 32-bit and 64-bit architectures. You can't group cross-compilation of different CPU features (i.e. different supported assembly instructions) with the differences in the number of bits (i.e. 32-bit vs 64 bit); they are quite different.\n\nSo far I have cross-compiled successfully only 64-bit host to 64-bit target. I am still struggling with 64 host to 32 target.\n\nThe fact that GN links now means that my assumption about the GN bootstrap script not supporting 64-bit to 32-bit cross compilation was correct.\n\nand that again gave the error:\nhttps://susepaste.org/fd8c60a2\n\nFrom the paste:\n```\n/usr/include/glib-2.0/glib/gtypes.h:423:3: error: '_GStaticAssertCompileTimeAssertion_33' declared as an array with a negative size\n  G_STATIC_ASSERT(sizeof (unsigned long long) == sizeof (guint64));\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/include/glib-2.0/glib/gmacros.h:232:103: note: expanded from macro 'G_STATIC_ASSERT'\ndefine G_STATIC_ASSERT(expr) typedef char G_PASTE (GStaticAssertCompileTimeAssertion, COUNTER)[(expr) ? 1 : -1] G_GNUC_UNUSED\n                                                                                                  ^~~~~~~~~~~~~~~\n\n```\nIt looks like you're trying to build against 64-bit system libraries, which obviously won't work because the address sizes are completely wrong (note (sizeof (unsigned long long) == sizeof (guint64) uses guint64, which I'm assuming is a 64-bit unsigned integer).\nI belive you will need to set some GN flags in order to tell the build process to cross-compile a 32-bit binary. Unfortunately, I don't have any experience with this.. > The doucmentation says that clang is a cross-compiler. From what you say it sounds to me that the program should be written in a way which supports cross compilation. I wonder what that means.\nLike I said before, cross-compilation is a broad term. Architecture is just one parameter that defines a target configuration, see the Target Triple for other parameters. Compiling for different architectures (e.g. 64-bit to 32-bit) is much more challenging than compiling for the same architecture (e.g. 64-bit to 64-bit).\nI believe Debian manages to build i386 packages on i386 systems. You can have a look at the chromium-browser source package to see how they did it. Otherwise if you must cross-compile, I'm not sure what all the flags (i.e. GN, CXX, LD, etc.) you will need. target_cpu = \"x86\" sounds like a good first step.. > I have linked to the same reading earlier. The big question which still remains is: how does one specify the target tripple when building UC? Currently I do it by exporting CFLAGS inside build.sh. Are you suggesting any other approach?\nI see, I don't know much about the Target Triple beyond it being a compiler flag that affects how it should build the binary.\n\nI don't know how this can be possible, considering that chromim developers explain that linking needs more than 4GB of memory.\n\nI'm not entirely sure if Debian builds its Chromium packages with cross-compilation or native compilation. There are cross-compilation instructions here. Debian's Chromium package has builds for the architectures amd64, i386, arm64, and armhf. There is some logic to set GN flags depending on the CPU architecture inside the debian/rules file, but I'm not entirely sure how or why the flags they configured work. If Debian does native compilation, maybe they use the settings jumbo_file_merge_limit=12 and concurrent_links=1 (inside that debian/rules file) to reduce enough RAM usage?\n\nCan you please \"decypher\" for me what this means and how to use it in the context of UC? (considering that I am building linux_portable and not debian-specific)\n\nThey are basically setting target_cpu to x86 and using a \"sysroot\". A sysroot is basically a pre-made chroot environment of an old Debian (in your link's case, wheezy) that Chromium links against for standard system libraries. A few notable details:\n\nUsing a sysroot maximizes Chromium's shared library backwards-compatibility because the sysroot is generally made of an older Linux distro. It also increases consistency across builds by using the same shared libraries.\nGoogle normally uses sysroots in Linux builds, but ungoogled-chromium and all other Linux distros that package Chromium don't use them.\nSysroots are normally downloaded as archives containing a pre-made environment from Google in normal Chromium builds.\nIIRC, there are scripts in the Chromium repository to create a sysroot archive.. > Does that mean there is a risk of ending up with a binary which is not ungoogled?\n\nPotentially yes, only if you use Google's pre-built sysroot while building.. Sorry, I didn't make it very clear in my previous comment. There are scripts in the Chromium source code to create a sysroot environment of Debian using Debian's repositories. You would need to use these scripts to create an i386 sysroot environment, and configure the Chromium build to use it. In addition, you'll also need to set target_cpu to x86 as well.\nI don't know how the sysroot creation scripts work, so I cannot provide instructions. However, I will be learning more when ungoogled-chromium starts to integrate sysroots for linux_portable builds.. > Are these the scripts you are you are talking about?\nYes, specifically the sysroot-creator* scripts. There is a little bit of documentation in Chromium's docs/linux_sysroot.md. @csmk @Rob--W Thanks.. @brokoli-mate Since you're using NVIDIA drivers, VA-API won't work natively. I don't recall if there's a library that converts VA-API to VDPAU calls, but you could try researching that approach.\nOtherwise, does disabling chrome://flags/#enable-accelerated-video work?. You could try building 69.0.3497.100-2 using a packaging defaulting to linux_portable bundle, which no longer has the VA-API requirement.. > @Eloston 2dc0d02 is video acceleration still active on 69.0.3497.100-2 portable ?\nEDIT: The VA-API patch currently adds a libva runtime requirement. If it was possible to have the library conditionally loaded, then this wouldn't be a problem.\nNo. I don't want to have a dependency on libva for linux_portable, because I want to have the fewest dependencies on the system libraries as possible for that configuration.\n\nwhat about other flavors @brokoli-mate is using debian package ?\n\nGood point, I missed that detail.\n@brokoli-mate You can try building and installing debian_minimal to see if that resolves your problem.. Closing since 70 has been out for a while.. Wait, does the Portable Linux build require VA-API libraries to run?. @csmk Thanks. I didn't realize that VA-API support required the shared libraries to run. I'll remove this dependency for the next version.. Sign-in functionality is disabled multiple ways via patches and domain substitution, so stored credentials shouldn't do anything to the browser itself. At most, it will affect webpage behavior if it sees it.. It seems the chrome://flags//#account-consistency is a flag that is tied into Sync, the mechanism in discussion. This flag could be a lead to understanding how Sync's inner workings, but that should be left for #520.. > BTW: I see many flags which are set to \"Default\" but there is no indication what that default actually is. How do we know that?\nI think it's specified in chrome/browser/about_flags.cc.. > 69.0.3497.100-3\nThis version doesn't exist. Do you mean 69.0.3497.100-2?\n\nWhat additional information could I provide to help in diagnosing this problem?\n\nUnless someone knows what those Mesa errors mean, we would probably need to use a debug build to get a stack trace and possibly use gdb. I believe setting is_debug=true GN flag should be sufficient (it's false by default in the PKGBUILD).. > The version number listed on the AUR here is 69.0.3497.100-3\nThat isn't maintained by us. The PKGBUILD maintained by us is available simply as ungoogled-chromium.\n\nWhere do I put is_dubug=true in the PKGBUILD? It appears as if gn is a google-specific build tool, and I don't know how to use it.\n\nYou need to build from source using the PKGBUILD generated from our build instructions, or the PKGBUILD from ungoogled-chromium in the AUR.. > I am now looking through ungoogled-chromium's PKGBUILD from a computer where ungoogled-chromium is not installed and I don't know where to add is_dubug=true\nReplacing the only instance of is_debug=false to is_debug=true should work. Though, I'm not sure if the debug symbols will be included in the final package or not; you might have to run the browser from the build output directory.. Whoops, I forgot I changed that. You'll need to edit $srcdir/chromium-$pkgver/out/Default/args.gn then with sed or similar.. You can also edit it right after it is generated by buildkit, where the output of gnargs print is redirected to that location.. I haven't made a debug build in ages, so I don't know what's needed to make it work for recent versions.\nMy guess is that this error resulted from jumbo. Maybe we need to disable jumbo (use_jumbo_build=false) in debug builds to fix the error? Alternatively, this could be a bug in patches/ungoogled-chromium/disable-download-quarantine.patch.. Closing since version 70 has been out for a while. Let us know if you still encounter this error.. I'd prefer a solution that doesn't require a patch first. If it doesn't exist, then I welcome a PR to add this functionality behind a flag.. @pjv Huh. It's always surprising for me to see the impact of this project, considering my scope is pretty limited to GitHub.\n@intika Thanks for investigating. For the issues list you found, we could pick applicable ideas to implement. (Please open seperate issues for them.). @dimqua If you find any Brave patches that are applicable to this project, please let us know.. What version of LLVM are you using?. @intika Actually, the packaging scripts for debian_minimal are wrong. debian_minimal uses linux_portable, which enables is_official_build=true GN flag, which requires a very new clang compiler. IIRC, you said LLVM 8 is the minimum required version.\n@brokoli-mate If you want, you can try installing LLVM 7 via the APT repo first (see instructions under Any Linux Distribution). You will have to modify the export ... lines to say 7.0 instead of 6.0 under # use system LLVM via unbundling in the file debian/rules.\nIf LLVM 7 doesn't work, then you will have to build and install LLVM 8 somewhere, and update the export ... lines to the proper commands or executable paths for your LLVM build.. Were you able to build Chromium successfully?. Let me rephrase: Did build.py complete successfully? What did it say near the end of its output?. Interesting, I didn't know Windows support was fixed. Are you able to run the browser from the build outputs? (e.g. located in build/src/out/Default/chrome.exe). > And there is sadly no chrome.exe file in my folder.\nThen the build has failed. Packaging won't do anything for you.\n\nBut what really surprised me was that it didn't even execute a single line from 'package.py'. I debugged it and it exited immediately after starting and didn't even execute the import.\n\nI have no idea why this happens if build.py is able to run.\nI'm closing this for now, since it doesn't make sense to work on this until #475 is done. We can debug this issue if it occurs then.. Are you able to refresh the patches (update_patches.py)? The CI check is failing.. As it was asked in the issue template, what is your platform and configuration?. * Please correct the configuration bundle and packaging types.\n Since you're compiling, you can use the development issue template.\n Please post more output of the error. Only the invocation command and the status message are in your snippet.. Please specify the configuration bundle and packaging type you are using, or the building steps you are taking.\nIf you are using linux_portable config bundle, you need to upgrade to at least LLVM 7 or 8 as stated in the build instructions.. By the way, the instructions for buliding an AppImage, Flatpak, or Snap should be updated and possibly renamed.. This isn't our PKGBUILD. Please report the error to that PKGBUILD's authors.. > removed patches/iridium-browser/safe_browsing-support-trk-prefix.patch:\nI don't think we need to preserve this patch; we don't support Safe Browsing.\n\ndisabled prefs::kSigninAllowedOnNextStartup by deault. The setting can be found at chrome://settings:\n\nIs this related to the Sync functionality (such as https://github.com/Eloston/ungoogled-chromium/issues/535#issuecomment-425679921 and #520)? I'm wondering how it's related. Also, does this flag still do anything even though the signin code is partially disabled?. I see, thanks. It definitely won't hurt to have it for now.. I'm planning to merge after 70 becomes stable, unless you think there's a reason to merge earlier. I'll ask if you're ready to merge when the time comes.. @csagan5 I agree with @xsmile. It's better to exclude Android-specific patches until Android support gets added into ungoogled-chromium. I don't see any benefit of including those patches ahead of time.\n@xsmile Thanks for updating the config. I've fixed the patch validator to attempt retries with a backoff.. > On a separate topic, is the canvas mitigation still effective? I got an issue report (bromite/bromite#154) but not investigated yet.\nI'm not sure. I can test after Debian stretch has been updated, but I suspect you will figure out an answer before that happens.. If you're referring to Portable Linux, then builds are already available on the Contributor Binaries website. Otherwise, let us know what specific difficulties you are encountering.. @tavlima I've reported the statically-linked issue in #556.\nRegarding the build instructions, please use the instructions in the tag you've downloaded instead of referencing master. I have added a notice about this.\nIn addition, Chromium 67 is not the latest stable. Please refer to the latest tags instead of GitHub Releaes. I've added a notice to the latest GitHub Releases with this info.. Arch Linux has the same problem where python points to Python 3 instead of Python 2. As a result, the PKGBUILD for Arch Linux modifies the Chromium source tree to use python2. I do not recommend modifying your system to make python point to Python 2.. Here is my rough tl;dr for this issue:\nThis issue is mainly dealing with Chromium build tools (i.e. in the source tree) using Python 3 instead of Python 2, which is solvable by either:\n\nMaking python in PATH be Python 2\nModifying the Chromium source tree so it uses python2 to invoke Python 2 (like Arch Linux does in its package build).\n\nAlso, there are some minor issues with getting a new fLLVM, Python 2.6 vs 2.7 (with the latter being required), and installing all other required build tools (e.g. gperf). \nFrom a broader perspective, the issue topic shifted from a bug report to a support thread for setting up the build environment for @jlj2.\nEverything looks solved now. Closing.. My knowledge of this area of Chrome/Chromium is limited. Here are several questions I have:\n\nWhat are the shared library dependencies for Chrome? How about an official build of Chromium (with optimizations and is_official_build=true enabled like Chrome)?\nHow are these dependencies being used?\nIf there is no strong justification to use the shared library, how feasible is it to remove the dependency? What are the consequences of removing the dependency? What kind of issues can arise if the libraries are statically-linked instead?\nHow does the use of shared libraries change over time? Is there a general policy or guideline for what Google does in regards to shared libraries?\n\nIn general, I just want to understand the whole situation regarding shared libraries in Chromium. If anyone could enlighten us, that would be much appreciated.. After contemplating about this a bit more, I'm not really inclined to work on this (because I have no personal need) unless someone is willing to push for this. Additionally, it seems Google doesn't have fully statically linked libraries, which is why they use a sysroot by default.\nFor linux_portable bundle, I think it's best to disable shared library dependencies on a best-effort basis via GN flags and/or small patches. Each shared library should be considered individually (unless they are related in some manner), where we would need to consider\n\nthe stability/compatibility of the ABI.\nfeatures in Chromium dependent on the shared library.\nany maintenance work involved with patches we would need to add.\n\nIf anyone wants to request the removal of a shared library dependency, please do so in a new issue. Also, specify any knowledge you have of the above three considerations.\nFinally, if anyone wants to work on static linking support, let us know here and this issue can be re-opened. I believe it should be done in new config bundle, like linux_static. linux_portable should maintain close compatibility with the Chromium \"official\" builds.. I think I took the wrong approach to this issue. If our goal is to match what Chromium does, then I think we should use a sysroot as well (maybe one we generate ourselves). Otherwise, I think we should take down Portable Linux contributor builds; having inconsistencies in the build environment can be problematic for users, who span a variety of configurations. Thoughts?. @jlj2 I see. In that case, taking the route of creating and using sysroots may be the most reasonable here.. > Are we using domainsubcache.tar.gz file anywhere after zipping?\nIf by \"zipping\", you mean the production of an archive of the build outputs, then no. domainsubcache.tar.gz exists to allow people to revert domain substitution. The main use case is to allow developers to update patches and resume building, since patches can include code with Google domains in them.\n\nCan we create this zip file inside \"build/src/out\" folder?\nCurrently, dmg file creates in \"build/src/ungoogled_packaging\" folder, can we move it to \"build/src/out\" folder?\n\nCould you explain why?\n\nCan we comment \"-Wno-ignored-pragma-optimize\" flag in \"build/config/compiler/BUILD.gn:1519\" for macOS?\nlooks like this flag mainly for Microsoft optimzation which means for WindowsOS..\n\nHere's the relevant comment for the associated bug report (in the GN file you linked): https://bugs.chromium.org/p/chromium/issues/detail?id=505314#c7\nThe report says that pragma optimize breaks Windows compilation. So, they ignore it by default and add exceptions for configurations like macOS so that the warning doesn't appear.\nI don't see any benefit of removing the flag.. > I mean archive file for \"zipping\"..\nI don't understand what you are referring to. Do you mean the creation of domainsubcache.tar.gz, or the .dmg (which can be understood as an archive)?\n\nJust checking as this is an output file, so can we keep in out folder or is it okay to keep in ungoogled_packaging folder?\n\nIt doesn't matter too much for this specific file, but I'd rather keep files introduced by ungoogled-chromium in one place. The compressed archive isn't part of the normal Chromium build process, but something generated by ungoogled-chromium tools.\n\nI see below warning 11462 times..\n\nThis might be because we're using the old LLVM 6.0.0 on macOS. What happens if LLVM 7.0.0 is used? FYI, LLVM is normally downloaded via downloads.ini in the macos config bundle.. > In general, how do you start rebuild? by deleting entire \"ungoogled_packaging\" folder and run python script?\nThere's no rebuild support, because the logic to do so robustly is sophisticated. It is up to the user to determine how to restart the build. However, if you halted your build during ninja and you need to restart it, you can generally re-run just the ninja command as shown in the build script. Then, the packaging script can be run normally.\n\nWe may need to update build readme file for macOS, it says DMG file might generate in build folder.. So, i was thinking DMG file should be in \"out\" folder instead of build folder, that's why i asked question :)\n\nAh, I didn't realize the instructions were out-of-date. I'll update it.\n\nDo i need to update google toolbox version too? we are using from jul 24th 2017 version..\n\nIt depends if DEPS at the root of the source tree is using a newer version or not.. Closing since questions seem to be answered and inactivity.. @intika @ian-moone Thanks for responding here.\nI have re-opened #17 to discuss this further.. I didn't realize there were patches between fix-libva1-compatibility.patch that needed to be refreshed. I took care of that.. If I'm understanding what you're saying, use_gold=true is already implied when use_lld=true. Could you explain what your choice of use_gold=false with use_lld=true does?. I see, thanks for explaining.\n\nWe could even remove both lines, as long as is_clang is true.\n\nI like this idea more, since it reduces potential breakages due to our GN configuration. I'll take care of this.. This issue gave me deja-vu, until I discovered that I actually solved this problem before.\n@xsmile Just a heads up: I have made a few changes to Debian patches when I included them. In this issue, I needed to remove a section unrelated to fontconfig from debian/system/fontconfig.patch that was causing this error. I will make a note in the patch itself so we won't make the same mistake next time.\nI will fix this. Thanks for reporting @anchev.. @s1nceri7y In the first post, you were using an AppImage. Are you now using the Portable Linux build? What happens if you try the AppImage again?. Opened #568 to discuss crashing due to existing Google account.. @intika \n\nUC will become very different in internals from chromium overtime...\n\nCould you elaborate? What factors are contributing to this?. @intika \n\nFlags : some flags are present here but not there and it could potentially lead to crash/loosing-settings i don't know exactly how chromium deal with unknown flags but it could be a source of problem\n\nI believe chrome://flags come and go all the time, so unknown flags may be dropped.\n\nWe could have a lot of arguments in each side but at the end of the day uc is not chromium\n\nSure, but trying to separate from Chromium violates the drop-in replacement goal of ungoogled-chromium.\nIf bi-directional compatibility with Chromium is not possible at some point in the future, I'd still like to support importing Chromium profiles.. If this can't be fixed practically with a code change, I would at least like some utility to strip out the Google account so ungoogled-chromium can read the profile data.. > Do I need to upgrade to a newer version of LLVM (7.0)?\nThat might be the solution. It's likely that LLVM 6.0 is too old; aside from the obvious llvm-ar-6.0 errors, it seems clang 6.0 doesn't know about -Wno-ignored-pragma-optimize.\nYou can try installing clang-7.0, lld-7.0, and llvm-7.0-dev; then, update debian/rules (after generating the packaging) with the 7.0 equivalents of the LLVM commands.. @ian-moone Do you know what defines the path to cfi_blacklist.txt? Is it a GN file?. So to fix building on Debian Buster, we need to\n\nset path to cfi_blacklist.txt via build_overrides/build.gni\npatch nullptr_t with std::nullptr_t\n\nIs this correct @kabo?. @kabo I see, thanks for the info. I'll try setting the GN flag for the next release and see if it works.. Currently working on 70.0.3538.110 for Debian/Ubuntu, and I suspect current_toolchain != default_toolchain in build/config/sanitizers/BUILD.gn, which is preventing cfi_blacklist_path from being set. I'm not sure why this is the case, because there was another location where set_default_toolchain() is called on custom_toolchain if it is provided (which is the unbundle toolchain in our GN config). Perhaps default_toolchain and set_default_toolchain() are not related?\nI'm going to keep experimenting and see what I find.. This should be fixed. A new tag will come out soon.. @bill-mcgonigle Thanks for letting me know. I guess my assumptions were wrong; Debian packaging is quite the process.. You're better off modifying the script yourself, or maintaining your own build tool. The build script in linux_simple isn't designed to be a flexible build tool; it's just for a simple one-time build.\nIf we ever need a comprehensive, flexible build tool, shell is a bad language for this. It lacks good static analysis tools, testing infrastructure, and intuitive data manipulation syntax (at least for me, shell is clunky for manipulating variable contents). We would also need to plan the design for such tool, so it is intuitive to use and robust for all applicable use cases.. Why would you need that patch in your builds of Portable Linux?. I see. I'll include it then.. Fixed with 94b7493c72a3a5767e8b1bca6c7f160f5449fa02. This is the first time I've seen LLVM segfault. Maybe it's unstable? Does LLVM 7 work for you?\nBTW, if you're disabling CFI because of cfi_blacklist.txt, you can use a temporary solution here: https://github.com/Eloston/ungoogled-chromium/issues/569#issuecomment-433331103. Since the original problem has been resolved (crashing with LLVM 8) and the new issue is the same as #569, I'm going to close this.. @probonopd Recall that ungoogled-chromium is Google Chromium, sans integration with Google. Thus, preloading extensions that changes the browsing experience significantly would violate this objective.\nIf you want integrated adblocking/privacy features by default, you may be more interested in projects like Brave Browser (as mentioned earlier). ungoogled-chromium will not take a stance on these kinds of issues for its users (except Google integration). At most, this project enables users to go beyond the vanilla Chromium experience via the addition of disabled-by-default feature flags.. Do they work in regular Chromium or Chrome?. We need more details to determine what is going on. Are there any errors in the DevTools console?. Does the behavior change if you change your user agent to a non-Chrome/Chromium one? e.g. Firefox. @qvint Thanks for the help.\n@FriendlyAI If this doesn't resolve your issue, please let us know.. I'm thinking that it may be helpful to have info like this in the ungoogled-chromium-wiki. It'll be nice for users who are informing themselves, and happened to hit ungoogled-chromium early in their learning process.\nMaybe we could setup a page in the Wiki for extensions and settings to consider?. We could add this to the Wiki as I proposed in https://github.com/Eloston/ungoogled-chromium/issues/577#issuecomment-435170463\nBut there are a few things I don't understand about the security considerations:\n\nThe author mentions how WASM is a binary format and requires sandboxing to be secure. Isn't this pretty similar to the issues JavaScript has? JavaScript's usually obfuscated nowadays (which I'd argue is pretty close to a binary form, especially with a technology like asm.js), and it's also JIT compiled by the V8 engine (in Blink-based browsers) to machine code for execution. Is there something fundamental about WASM and/or JavaScript that I'm missing here?\n\n\nIntegrity checking is not possible as WASM modules are not required to be signed by their author\n\n\nI may be out-of-the-loop here; does JavaScript have a solution for this?\n\n\n\n\nTransmission and execution does not require TLS, HSTS, or any other transport layer security mechanism\n\n\nI'm not sure how this differs from what JavaScript has.\n\n\n\n\nWebAssembly assumes that 'safe applications' can be derived from language subsets and a few rules to prevent specific type of behavior.\n\n\nI don't understand the general idea behind this statement. What do they mean by \"language subsets\" and \"specific type of behavior\"?. > The claim of WASM being sandboxed is somewhat baseless considering that CPUs are flawed on hardware level \n\n\n\nHis example is regarding sandboxing concerns at a higher level, e.g. security vulnerabilities with Adobe Flash. IMO, a better comparison would be to compare WASM and JavaScript.\nBut, I fail to see how the execution environment for WASM and JavaScript are different enough to open up a new class of vulnerabilities. Perhaps it is easier to exploit certain vulnerabilities in Blink/V8's existing sandboxing technology compared to JavaScript due to JIT?\n\nPerhaps he means the subresouce integrity attribute.\n\nHmm, but this is just hashing, not signing. Unless the author meant hashing?. Sorry for the late response; not sure if you have figured it out yet or not.\n\n#passwords-keyboard-accessory: Do you have #experimental-ui enabled? It looks like the passwords keyboard can be turned on when either flag is enabled:\nhttps://chromium.googlesource.com/chromium/src/+/70.0.3538.110/chrome/browser/password_manager/password_accessory_controller.cc#164\nhttps://chromium.googlesource.com/chromium/src/+/70.0.3538.110/chrome/android/java/src/org/chromium/chrome/browser/autofill/keyboard_accessory/ManualFillingMediator.java#414\n\n\n#enable-query-in-omnibox: The link you provided is to the wrong flag (kUIExperimentMaxAutocompleteMatches). Even after searching around with the correct flag, I'm not too sure why it is being enabled.\n\nAlternatively, both flags are listed under testing/variations/fieldtrial_testing_config.json (in CamelCase). I believe this is a place where field trials are defined and set, so it may have been enabled randomly. You can disable fieldtrials with a GN flag that is defined here. See components/feature_engagement/README.md for more general info about field trials, and testing/variations/README.md (also linked in the previous document) for the format of fieldtrial_testing_config.json.\nI haven't looked at how you configured Bromite, nor do I know much about field trial tests, so I could be wrong. Let me know what you find.. > Would you say that the patch I use here https://github.com/bromite/bromite/blob/70.0.3538.95/patches/BRM071_Disable-fetching-of-all-field-trials.patch is ineffective to disable those?\nThat's a good question; I don't really know how this system works as a whole. If I have more time, I can look into it.. Adding this feature would go against the primary objective of this project. In addition, removing the patch for GCM isn't enough; we would need to modify domain substitution (which is risky, since other components may share some code).\nIf there exists an alternative implementation of GCM servers, then I'd allow an option to set the server to use for GCM.. See #475 . The args.gn file is broken because I made a silly mistake.\nHowever, Windows support is broken in other ways right now; see #475.. Is Python 3 the default in Ubuntu 18.04?. python still refers to Python 2 by default. I don't want to add the hack that Arch uses to fix Python 2 scripts unless it's the default behavior in Ubuntu, so I'm closing this.. Illegal instruction may arise because LLVM is compiling with an assembly instruction that your CPU doesn't support. I don't have a clue why LLVM would do this, though... it might have something to do with running development versions of LLVM.\nI'm going to close this because it seems like a rare case due to an unstable compiler. We should stick either to stable versions or LLVM revisions that Google uses to compile; it will be difficult to support people otherwise.. > I don't see why. I am building everything with -march=native and -mtune=native -- the way I have always done and which has always worked so far.\nIt's hard to say unless we get down to the specific changes that happened in trunk. I won't take much for granted for a complicated system (i.e. the LLVM toolchain, and any modern compiler for that matter) if I barely know how it works.\n\nI also remember your words about it:\n\nGood catch. I forgot about this and confused myself with Debian. Maybe we could document the LLVM revision that works and/or Google uses?. Thanks, going to merge this with an update to 70.0.3538.102.. FYI, the User Resources page on the Wiki has a section for useful extensions. Feel free to submit a PR (according to the guidelines outlined in that section).. > Disable HTML5 Autoplay - by @Eloston.\nI'm flattered that you'd suggest this, but there are caveats. It works fine for the most part, but there are a number of sites where it just doesn't work well or at all. In fact, there are several cases where it can cause the website to severly misbehave, such as unbounded memory growth or a busy loop. However, you can workaround this with a whitelist/blacklist.. I believe Push Notifications in Chrome/Chromium uses GCM (just like on Android), so it may be requiring code that has been disabled. Can anyone confirm?. Alright, then I will close this as wontfix for now. The main concerns here are any privacy and security, especially if there is any proactive background communication with Google. If there is a way to implement Cloud Messaging while addressing these concerns, I'll be open to it.. Might be because bootstrap.py wasn't updated after the snapshot of the GN repo was updated. I'll look into it. EDIT: This is technically a Chromium bug, but it shouldn't be hard to fix.. @saltama I think tarballs are usually built whenever a new stable version is released. Are there cases where they manually trigger builds of non-stable versions? If manual build triggering does not happen and the next stable is not due for a little wihle, then it may be a better idea to include the patch so we can stay with the latest stable version.. Looking good, but a couple questions:\n\nWhy is this marked as a WIP? What else needs to be done?\nWhat happens if you disable machine ID but leave encryption enabled? Is encryption still tied to the current machine? Are the machine ID and encryption mechanisms independent of each other?. BTW on Windows, does Chromium store credentials internally in the user data directory by default? Or is there a credential storage mechanism that Chromium uses? I'm trying to understand why passwords are included in the encryption.. I see, it kinda sucks that the Windows version doesn't use a credentials storage. Thanks for the info.. Nice work! One question: Does suggest_url from components/search_engines/prepopulated_engines.json get filled into the Suggestions URL box for built-in search engines?. Nice. Everything looks good.. No problem, thanks for submitting a PR anyway.. This is a command in buildkit. I parse FILES.cfg to only select the files from the build outputs that are necessary to run Chromium. The tar.xz generation logic is included here as well, and there's no trivial way to implement multi-threading here using the standard library.\n\nI am open to having the code re-written so it uses xz and/or GNU tar directly (Python's tarfile module is not that fast). The only thing that's annoying about tar is it's hard to specify the file structure inside of tar archives (without copying/moving files into the desired structure); Python's tarfile is easier to use in this regard. Feel free to submit a PR.. @anchev Any solution is fine as long as it's easy to maintain and doesn't require bulky or obscure dependencies.. @anchev Right now it's all in Python: https://github.com/Eloston/ungoogled-chromium/blob/efe5ffcd19d8e777c40f354b48d5f6ca54e14683/buildkit/filescfg.py#L62\ntarfile uses the lzma module internally if given a tar mode that specifies xz compression.\nThe alternative solutions can be to create a tar with no compression (via buildkit) and stream the output to xz, or print the list of necessary files from FILES.cfg and send it to tar and xz. I'm not sure how much faster the former solution would be, but the latter solution is harder to implement.. @clapbr This is a custom (albeit primitive) distro-agnostic archive generation process I wrote. It has nothing to do with Arch Linux's makepkg.. > About the suggestions, I am making changes to use the official Chromium depot_tools bundle. I was wondering why you weren't using it anyway?\nThe main reasons are:\n\nIt's written in Python 2.\nI didn't want to modify the code to ensure it doesn't connect to Google. By extension, this includes any pre-built binaries or toolchain packages.\nI don't need gclient since I'm using the Chromium tar.xz.\n\nWhat do you want to use from it?. > I notice that the github page referred to above has also been updated to describe the latest version, v70.0.3538.110-1\nYeah the page download thing was a problem I fixed. Cirrus CI broke something without my knowledge and I had to workaround their bug. It was annoying to fix. Based on this article, it looks like Google Meet is just redesigned Hangouts. In that case, what @ian-moone should be correct. I don't want to change the GN flag or add extra code (e.g. patches for a flag or something) since it clearly goes against the spirit of this project. I will at most allow instructions in the Wiki to get this working (if anyone is inclined to write them in the first place).\nIf this is not due to the Hangouts extension, please let us know.. @csalvato I don't understand how supporting this \"extension\" (it's actually code built-in to the browser) will contribute to the goals of this project. Also, if you need the extension, changing the flag that @Atavic mentioned and re-building the browser will fix the issue. Could you explain your use-case in more depth? Why would you need a Google-specific component in a browser designed to remove Google integration?. @csalvato First, I would like to note that we are not affiliated with Brave. It just so happens that both projects share similar intentions and goals.\nAnyway, while I would like to have this project grow, it is secondary to the main objective of this project: to remove integration with Google services. Based on that fact alone, supporting a feature which only benefits the usage of Google services is contradictory. However, I understand that there are a variety of valid use cases that does not exclude Google completely, so I generally don't outright reject suggestions like these. There is no clear line to draw here.\nAfter investigating the code for the Hangout service extension, I will retract my earlier statement about rejecting this completely. I think it is possible to have a flag that can enable this extension to be loaded, but not bundle the code in the browser. However, I do not have any interest in working on this, nor do I suspect many others here will given my experience thus far.. The changes here look good, but I've recently developed a new experimental workflow for updating Debian packages. In response to this PR, I've updated the documentation with the workflow I'd like to try out. See the README in https://github.com/ungoogled-software/ungoogled-chromium-debian for instructions on the new workflow (it's now linked in docs/developing.md too).\nHopefully this isn't too much of an inconvenience for you. Let me know if you have questions or suggestions. Thanks!. Resolved by #607.. I could change the error message for BLOCKED_BY_CLIENT (which I don't like too much because it is conflating a standard error with an error we introduced), or I could add a new NET_ERROR that has its own message. I'd like to leave the links in because it's nice to know where to look for more information about certain features.\nAlternatively, I could write a system that does something crazier:\n\nFind all support.google.com help URLs in the source code\nDownload these help pages and modify them to depend on local resources only (also maybe run DOM Distiller over them?)\nDump all these documentation files into an extension (or embeds them into Chromium itself)\nModify the support.google.com URLs to point to the local help files (in the extension or embedded within Chromium)\n\nI like this alternative solution more because it's more fun to implement, but also because I'm not sure of the reprecussions of modifying code related to NET_ERROR. What do you guys think?. > Be careful when downloading Google owned content. It may be copyrighted (and risky for this precious project).\nGood points. \n\nPerhaps the safest (and maybe easier for you) would be to display a special page explaining (for all links) that this is ungoogled chromium and that's why it has no links to Google whatsoever, underlining that it is not an error (broken) but that it is so by design and concept.\n\nIn that case, adding a new NET_ERROR error may work pretty well. This way, I'll be able to have a custom message explaining what is going on, including a link explaining what to do to.\nAnother idea is to combine the two ideas I had. I could replace all the support.google.com URLs to a new internal Chrome page that tells the users why it's blocked, and what to do to view the actual page (maybe even provide the real link to view the page?). That way I don't need to add or modify anything related to NET_ERROR.. I'm not sure when I will have time to implement this.. So the 3 second waiting time issue is resolved now? Instead, does ungoogled-chromium not open because of the libva error?. I'm not entirely sure what the delay may be, but I have set some flags in /etc/chromium.d/default-flags that may cause some slowdowns. You could try tweaking them to see if they change performance.\nRegarding the libva issue, it may be because you just have libva1 installed but not any of the runtimes (e.g. libva-drm1, libva-egl, libva-glx, etc). You can safely ignore this error if you don't need VA-API acceleration. I don't think it should have any performance impacts.. Do you have background processes enabled in regular Chromium? (i.e. \"Continue running background apps when Chromium is closed\" under chrome://settings). Strange. I don't know what is causing the issue.. /usr/bin/chromium is a shell script that eventually runs /usr/lib/chromium. This shell script is essentially the same script that is used in Debian's chromium package. Perhaps you could try Debian's chromium and see if it is slow for you as well?. @taahamahdi At the very least, you need ungoogled-chromium and ungoogled-chromium-common.. Well here's the diff between Debian's chromium script and ours (via git diff 61208729aeb17e51ab3f929f074f32e90d1b1ad1 7df5850b4e510f6ab3f989447502cf4a82e87f4c -- debian/scripts/chromium inside ungoogled-chromium-debian):\n```\ndiff --git a/debian/scripts/chromium b/debian/scripts/chromium\nindex b9e312d..84f85f9 100644\n--- a/debian/scripts/chromium\n+++ b/debian/scripts/chromium\n@@ -10,7 +10,6 @@ APPNAME=chromium\nGDB=/usr/bin/gdb\n LIBDIR=/usr/lib/$APPNAME\n-BUILD_DIST=\"@BUILD_DIST@\"\nusage () {\n   echo \"$APPNAME [-h|--help] [-g|--debug] [--temp-profile] [options] [URL]\"\n@@ -55,8 +54,18 @@ fi\n export CHROME_DESKTOP=\"chromium.desktop\"\n# Set CHROME_VERSION_EXTRA text, which is displayed in the About dialog\n-DIST=cat /etc/debian_version\n-export CHROME_VERSION_EXTRA=\"built on Debian $BUILD_DIST, running on Debian $DIST\"\n+DIST=printf \"%s %s/%s\" $(lsb_release -si) $(lsb_release -sc) $(lsb_release -sr)\n+BUILD_DIST=\"@BUILD_DIST@\"\n+export CHROME_VERSION_EXTRA=\"built on $BUILD_DIST, running on $DIST\"\n+\n+# Add LIBDIR to LD_LIBRARY_PATH to load libffmpeg.so (if built as a component)\n+if [ -z \"${LD_LIBRARY_PATH:+nonempty}\" ] ; then\n+    LD_LIBRARY_PATH=$LIBDIR\n+else\n+    LD_LIBRARY_PATH=$LIBDIR:$LD_LIBRARY_PATH\n+fi\n+\n+export LD_LIBRARY_PATH\nwant_debug=0\n want_temp_profile=0\n@@ -82,12 +91,6 @@ while [ $# -gt 0 ]; do\n   esac\n done\n-# Whitelist installed extensions that are specified via --load-extension\n-if [ -z \"$(echo $CHROMIUM_FLAGS | grep \\-\\-enable-remote-extensions)\" ]; then\n-  export CHROMIUM_FLAGS=\"$CHROMIUM_FLAGS --disable-background-networking\"\n-  export CHROMIUM_FLAGS=\"$CHROMIUM_FLAGS --disable-extensions-except=$(echo $CHROMIUM_FLAGS | tr ' ' \\n | grep \\-\\-load-extension | cut -d= -f2 | tr \\n ,)\"\n-fi\n-\n if [ $want_temp_profile -eq 1 ] ; then\n   TEMP_PROFILE=mktemp -d\n   CHROMIUM_FLAGS=\"$CHROMIUM_FLAGS --user-data-dir=$TEMP_PROFILE\"\n```\nYou could try experimenting with your /usr/bin/chromium script using these changes as a reference and see if it runs fast.. @arturkomoter Are you able to build from source on that machine?. I see. Could anyone else with Ubuntu 18.10 cosmic confirm or deny this?. @arturkomoter Have you tried using a new user data directory?. @arturkomoter I mean a new Chromium user data directory, via --user-data-dir. Good to hear. Closing.. @zchlm Thanks for letting me know. Reopening.. @jjpe Did you follow the instructions in your original error?:\n__main__.SdkError: 'Install Xcode, launch it, accept the license agreement, and run `sudo xcode-select -s /path/to/Xcode.app` to continue.'\nAlso, when you re-ran the build, did you remove build/src first?. I'm not familiar with them. Do you have any recommended readings?. No problem. Thanks for letting me know anyway.. Strange, the ungoogled-chromium-sandbox package should've fixed this (via SUID sandbox). I might have broken something re-writing the Debian packaging... I'll look into it.. Do you have the text file build/src/debian/patches/series? Does it have any content?. That's strange. The -j flag is added through parallel.patch, which is listed in the series file you gave me. The fact that you do not have the -j flag in your bootstrap.py means that something went wrong when applying patches; The patches should have been applied when you invoked the dpkg-buildpackage command.\nIn the output from dpkg-buildpackage, did you see output about applying patches for each entry in build/src/debian/patches/series?. Whoops, I only wanted 8c49d061de6fe764f8fc3d08547261114c4b41e4 to be approved again, not the entire PR.... Try this patch instead of the one proposed in this PR:\n```\n--- a/media/gpu/vaapi/vaapi_jpeg_decode_accelerator.cc\n+++ b/media/gpu/vaapi/vaapi_jpeg_decode_accelerator.cc\n@@ -38,6 +38,10 @@ enum VAJDADecoderFailure {\n   VAJDA_DECODER_FAILURES_MAX,\n };\n+#ifndef VA_FOURCC_I420\n+#define VA_FOURCC_I420 VA_FOURCC('I', '4', '2', '0')\n+#endif\n+\n static void ReportToUMA(VAJDADecoderFailure failure) {\n   UMA_HISTOGRAM_ENUMERATION(\"Media.VAJDA.DecoderFailure\", failure,\n                             VAJDA_DECODER_FAILURES_MAX + 1);\n```\nI haven't tried it yet, so I don't know if it works. It's assuming that VA_FOURCC('I', '4', '2', '0') works as it did in the current version of this patch.. I'm going to experiment with my changes and see where it leads me.. Thanks for sharing! To reduce clutter, issues are not for submitting tips. Instead, please consider submitting a PR to the ungoogled-chromium-wiki.. If you're using the latest Windows build, I think there's a bug in that version with the patch that disables metrics collection. The bug was fixed in subsequent version of ungoogled-chromium, but support for Windows hasn't been updated yet. If you cannot wait for the new version, you can try re-building the browser without the metrics disabling patch.. Also, please split off the \"startup commmand line option\" into a separate issue. Thanks.. @englishextra As much as I would like to make every user happy, I just don't have enough interest or the time to do so. Even if I had a Windows development environment ready to go, it's not insignificant to fix Windows support.\nIf you know people that could fix Windows support, that would be great.. I just merged #627. If it works, I can create a new tag so new macOS binaries can be published.. > Missing --build-path argument \u2014 bootstrap.py generated out/Release by default.\nCould you elaborate? What is being generated in out/Release?. I see, it doesn't really matter then. We can leave it alone. Thanks for the explanation.. These changes are well done. However, will this patch affect other ways of loading web pages? For example, how about command-line-supplied web addresses?. Awesome. Thanks for looking into it.. @intika That isn't affected by this patch. Only URLs without a scheme are considered.. Sorry, but that goes against this project's goals (stated in the beginning of the README). If you want something like that, you should propose the idea to a browser that makes its own design choices, like Brave browser. If you don't need something exclusive to Chrome/Chromium, there's always Firefox and its derivatives.\nHowever, I will accept toggles to enable such customizations. That is, if anyone is inclined to implement them.. Thanks for testing and writing up your results. I am new to the subject of reproducible builds, so these results are interesting to me.\nIn regards to the differences, you mentioned in both bionic and cosmic how it is just the buildinfo and changes files that vary. These are just plain-text metadata files, so I don't think it matters if they are identical. However, I still think we should consult Debian's documentation on reproducible builds for their practices here.\nThat being said, what would you like us to do with this information? Do you think ungoogled-chromium should start applying ideas of reproducible builds?. Good point. These instructions should also be available to all users who use Debian packages. However, I don't know the best place to put these instructions; Any suggestions?. I was referring to users of contributor binaries as well. I suppose an installation document could serve this purpose.. That's because the changelog file has a fixed timestamp. For example: https://github.com/ungoogled-software/ungoogled-chromium-debian/blob/2400d42958d1b9788bea30928c7d7f9bb70fcc75/debian/changelog.ungoogin\nIdeally, the timestamp should be set to the time the tag of a version was made. However, that is hard to determine and not available in certain scenarios. Perhaps we should have the debian/rules file generate the changelog file with the proper timestamp?. Are the instructions not working?. The instructions are probably out-of-date. Can any macOS users provide feedback here?. @seppiofish is correct. Adding the harfbuzz patch will break Debian stretch, since its harfbuzz library is too old. Thus, I think adding the harfbuzz patch to Arch Linux's patch_order is the best solution here.\nAlso, I would appreciate it if you all could give some input to #640. Thanks!. Closing per @intika's request.. In theory, I agree with you. However, I don't think the distinction is so clear in practice. For example, consider binary pruning. While one can argue that it is a measure to remove all binaries from Google (thus ungoogling), it also affects the build process. There is a similar situation with domain substitution; sure, it disables all background service URLs in the Chromium code, but it also breaks scripts used for building (which also prevents them from accessing Google servers). If ungoogling is all there really is to this project, then what about flags like use_sysroot=false, proprietary_codecs=true, enable_swiftshader=false, or enable_nacl=false? What about buildkit, a system I spent writing and rewriting, that ends up controlling most of the build process?\nHonestly, I don't know. However, I suspect that this issue is actually tightly coupled to a much larger issue that I've been thinking about lately; see the revised first comment for details.\nI will now change the topic of this issue.. Just a heads up anyone who has read the post: to everyone who has already read the post: I have made a few clarifications, namely how my personal \"requirements\" affect ungoogled-chromium (they're actually preferences I use when the ungoogled-chromium goals are not clear). I have also expanded on the \"What should ungoogled-chromium be?\" section to clarify what particular issues I am having.\nTo those that have responded already: Thank you for your insights. Let me try to summarize your points: @azdps and @qvint are leaning more towards breaking up the project and clarifying what \"ungoogling\" entails, leaving more control to builders and packagers in what they want \"ungoogled-chromium\" to be. However, @black-ish seems to lean more towards a scope change for the browser, which means the ungoogled-chromium developers have to decide more in terms of building and packaging. Are these summaries correct?. Thank you all for your responses. After considering your perspectives and my own motivations for this project and beyond, I have decided to opt for a mixture of the proposed solutions. ungoogled-chromium's name will remain (for now) and so will its effective goals (which will be clarified in the new README). However, I will more cleanly separate \"core\" features that remove Google integration from \"extra\" features that provide additional privacy/security/control enhancements. In addition, I will be fragmenting the ungoogled-chromium repo into multiple repositories under the ungoogled-software organization for each individual platform.\nThe refactoring progress will be tracked in #651.. @csagan5 \n\nhaving the name contain a trademark of a company is problematic and it will always be the case, so I would suggest to loose it whenever possible to avoid any potential future issue; IANAL but this is probably the feedback you would get from any lawyer, you can also contact one through EFF (although probably you will get a referral and not an official endorsement)\n\nYou're right, but it's hard for me to decide on a good name. I'm not sure how I would let others submit feedback and vote on names either. Also, I need the name to be decent enough since it takes work to change the name. So, I have been leaving the name alone since no one's had any large issues with it yet.\n\ntry to split it in a way that you are still motivated and happy to work on it, and delegate parts to collaborators (as you feel fit) that might want to contribute their time; I am suggesting this as a general rule of thumb if you see the project increasing in size outside your comfort zone\n\nThis isn't an issue under the current system. Nowadays, I spend most of the time on this project responding to feedback on GitHub, reviewing code, and making any foundational or DevOps-related changes. I don't really know how to delegate responsibility for feedback response or code reviewing on a project run by volunteers (assuming it's possible), and the changes I make are things I find interesting (which take time in a good way).. Do you have any suggestions?. Thanks for the suggestions @intika. I will discuss my decision in #640.\nClosing this issue as invalid because it's not constructive.. Yes, they're all there except for patches used to change the branding.. @csagan5 Thanks for the info.\n@dumblob The entire quarantine component should have been disabled via disable-download-quarantine.patch since at least 2016. Do you still have the MOTW with ungoogled-chromium?. > What do you think made ungoogled-chromium successful ?\n\"Success\" is a pretty broad term. I will assume you define \"success\" based on the number of users, what users say about the project, and the kinds of bug reports this project receives. In that case, there are several points I can note (in no particular order of importance):\n\nContinual desire to improve the project and oneself. I think this is the most important point. I mainly gather ideas based on feedback, experiences from this and past software projects, and experimenting with software in general. I also gather ideas by reading code and docs from Google, reading technical blog posts about software, and reading about new developments in software engineering.\nDedicating a lot of time to the project. Especially in the following areas:\nConsistent attention to overall quality of documentation, code, and user experience (building the browser, using the browser, downloading pre-built binaries, reading documentation, etc.)\nResponding to feedback on GitHub.\nConsidering all aspects of a bug, enhancement, request, question, etc. \n\n\nLeaving a good impression on anyone who comes by. This happens in a number of ways, but a lot of this happened via the points I made above.\nContributors keep the momentum going. Particularly in updating Chromium versions.\nThe Chrome/Chromium userbase is large. The number of people concerned about privacy/security and Google's role in privacy is also decently large. Having a number of people interested in a project like this helps a lot.\nIn the beginning (some time before the first spike of users), I went to a few different places to advertise this project. Then, I let other people spread the word. This works because of the number of interested users.\n\n\nRegarding the stargazers and star-track (see capture bellow) i see that you gained over 2000 star in just few days and twice on 09/25/2016 and 09/22/2018 it's amazing ! what's the secret ? smiley\nFor the stars thins i guess i have the answer the first boom it is from a reddit post and lifehacker article, the second one i think its me joining the team hahhaha just kidding i have no clue for the second one\n\nThere was quite a bit of activity from Hacker News as well. Especially during the spike in 2018. I believe you can this from GitHub Insights.\n\nAlso one thing, a lot of people asked me about mozilla trademark (Firefox) while i was disturbing a patched version it's curious that uc did not face this problem, i guess google folks are more permissive.\n\nThis project is not widely known, and people aren't confusing it with the trademarked Chrome and Chromium. If it becomes an issue, then I'll be fine with changing it.\n\nDo you have any advice/comments regarding the direction of my project ?\n\nI don't know much about Firefox, so I can't give you any specific advice. Hopefully my comments on what made this project successful will help you too.\nRegardless, I am glad that my project has inspired you to create Librefox. I wish you luck with it!. If I'm not mistaken, install-sysroot.py will download binaries from Google to work. That doesn't make sense since this project is trying to remove Google integration. Could you look into using the script to create the sysroot? If possible, I'd like to cache the created sysroot instead of re-creating it every time.. The Debian binaries are fine. The main thing is that they aren't from Google. For example, on Windows and macOS, we download the LLVM toolchain from LLVM.. Maybe instead of sysroots, we can require people to build ungoogled-chromium inside a container or chroot of Debian stable?. > i think if i go further in fixing the compatibility i will may be end up having 5 or 6 additional commands... i don't think we should break compatibility.\n\nThis would be faster and more reliable than a container or a chroot.\n\nThe sysroot creation script is not under our control. I think this will be more work for us to maintain if Google changes it. This is why a chroot or a container of Debian stable are more practical options, since we are in total control of them.\n\n@Off-topic by the way are you going to the FOSDEM event in Brussels ?\n\nNope.. > Limit portable building integrating sysroot to debian (this somehow what google is doing by its unique debian sysroot)\nI don't understand what this solution is. Are we requiring people to build on Debian machines (no chroot/container)?\n\nSolution implementation 2:\nDebian chroot/container:\n\nThis may not be too complicated if we use Docker. But still, the overhead is not ideal like you mentioned.\n\nSolution implementation 3:\nHosting a debian prebuild sysroot on a separate git\n\nI like this solution the most because there are commands to build a sysroot image relatively easily (therefore, any user can build it themselves if they choose). But, how do we make Chromium use the sysroot image?\n\nSolution implementation 4:\nimplement a container just to build the sysroot not the whole chromium thing... this is kind a solution 2 with less con.\n\nI don't understand this solution. Why does using a container to build the sysroot help?\n\nGoogle is claiming their binary are coming from debian repo https://chromium.googlesource.com/chromium/src/+/HEAD/docs/linux_sysroot.md\nUsing the binary from the google hosting may be a solution\n\nThey also have hashes for the entire sysroot images (in tar files), so maybe we could have some way of verifying these hashes are valid by building the images ourselves too? I'm not sure if the tar file is reproducible though.... I see, I didn't realize that building the sysroot image requires Debian. In that case, my view is different.\nThere are essentially two groups of users with their own trade-offs we need to consider for controlled build environments (e.g. sysroot, chroot, container, VM, dedicated system):\n\nThose that only build ungoogled-chromium for their own Linux systems. Technically, these users don't need to worry about a controlled build environment as long as they run their binary on a system that is compatible with theirs.\nNot using a controlled environment:  However, there still can be issues if their system libraries are too different from Chromium's expected library versions, or they end up running the binary on a system that is no longer compatible (e.g. by switching distros, or maybe package updates). Even then, I'd expect the number of people in this group to have issues to be relatively small.\nUsing a controlled environment: Using a controlled environment will eliminate the problems from above, but it is more costly (time and space) for the user. The methods for creating controlled build environments are described in the next group.\n\n\nThose that build ungoogled-chromium for use on all* Linux systems. Backwards-compatibilty with the system libraries is important to ensure runtime compatibility. This group will want to have a binary they can readily download and run anywhere (e.g. from Contributor Binaries). Therefore, binaries for this group must be built in a controlled environment.\nUsing sysroots: Since this must be built in a Debian environment, it is silly to require the users to make a container just to build the sysroot. Instead, you mentioned that we could provide pre-built sysroot images. However, this will be more for us to maintain (even if we automate the building and publishing of sysroot images via CI). Also, we'd need to patch Google's script to use our own sysroot image, which means we will need to keep track of changes Google makes to this script.\nUsing other methods: This removes all complications involving sysroots. In fact, with a solution like Docker, we could provide a Dockerfile that could automate the entire build for us. Sysroots don't provide us that kind of power. However, I'm not sure what kinds of downsides we would have using something like Docker.\n\n\n\n* That is, distros supported by Chromium\nEssentially, we need to answer these two questions:\n\nFor Group 1, should we enforce a controlled build environment?\nTo make a controlled build environment, should we use sysroots or another method like Docker?. Here's an example I just found for building Chromium in Docker: https://github.com/chromedp/docker-chromium-builder\n\nI have worked with Docker before, so I could put something together relatively easily. However, this requires users to install Docker in order to use it. This is more work for the user compared to the sysroot solution.\nWhile I don't like that we would have to maintain patches for the sysroot scripts, I think it's better than Docker for users who want to make builds. I will re-open this PR and create a new repo under ungoogled-software for you to PR against.. I created ungoogled-chromium-sysroot. I'm not sure if you can PR against an empty repo, so let me know if it doesn't work.\nAlso I should note that Docker will be our fallback if sysroots don't work as well as we think they will.. Looks like the CI check broke. Is there fuzz in debian_buster/fixes/as-needed.patch now?. Thanks for reporting. Going to close this as a duplicate of #605 and make that issue cover this one.. In https://github.com/Eloston/ungoogled-chromium/blob/47c6164c3b2c4a84ff54d90893ab5b650e9838cb/docs/design.md#source-file-processors\n\nThe regular expressions to use are listed in domain_regex.list; the search and replacement expressions are delimited with a pound (#) symbol.\n\nSo the file mentioned would be here: https://github.com/Eloston/ungoogled-chromium/blob/47c6164c3b2c4a84ff54d90893ab5b650e9838cb/config_bundles/common/domain_regex.list\n(FYI, this will be moved to the root of the repository in the refactor).. Are you using Python 3 provided from Ubuntu? If you're not, it's possible it's not accessing all the root certificates on your system.. Could be possible, not very likely. Google probably refreshes their certs before they expire.. That doesn't sound like a normal Ubuntu setup if wget doesn't find your SSL certs by default. You may want to try a clean install; perhaps a VM or container (e.g. LXD or Docker).\nIf you still have issues with a clean setup, let me know.. I don't see how the error is related. Your link is regarding Windows, not Linux.\nStill, if wget isn't working with HTTPS out-of-the-box, something in your environment is not normal. I've never seen anything happen like this on Ubuntu.. I don't use GitHub Releases anymore because it's extra manual work with little to no gain. In addition, the refactor (#651) will cease the use of tags on this repository; all tags will be made on the repositories for the individual platforms.. @lipici Right now, I don't think there's is anyone working on Windows support., so no issue has been created for it.. I can't accept that binary because it re-enables the Safe Browsing component. That weakens the removal of Google service integration in ungoogled-chromium.. Also, Windows support has not been fully fixed yet, which is why no new binary has been published.. >  providing official tamper-free binaries (for Windows) is absolutely crucial\n\n[...]\nIs there a reason why this project relies on contributor binaries?\n\nWhat would you constitute to be \"official\"? Being \"official\" requires there to be an authorative and trustworthy source, which no one person or party here can provide. Trust is hard to establish when everyone here is generally anonymous and unknown.\nThe closest we can get to \"official\" binaries is reproducible builds; i.e. having anyone be able to produce the same exact binaries from a given source. This almost already seems to be a reality on Linux (#632), but I don't know what the state of reproducibility is on Windows.\nUntil reproducibility becomes a reality, contributor binaries is a solution for those who can't build ungoogled-chromium themselves and they trust other volunteers enough. If security/privacy is a significant enough concern for you, then don't use contributor binaries.. Official Build has a special meaning for Chromium builds, so I want to preserve that.\nI don't want to change the branding of the browser, but perhaps we could insert a string like (ungoogled-chromium) to indicate that this is an ungoogled-chromium build.. Did you install Python 2 per the instructions?. I'm going to close this as a duplicate so we don't have too many Windows issues sitting around. Once the fragmentation refactor is done, I'm going to move all of them to the Windows repo.. @virtadpt asked something similar on Gitter:\n\nGiven that Chrome and seemingly Chromium-mainline are going to lose the use of the webRequest API, which is going to break many ad-blocking extensions (https://www.howtogeek.com/fyi/chrome-may-get-faster-ad-blocking-while-breaking-ublock-origin/), are there plans to keep it in Ungoogled Chromium?  Or would this be technically infeasible due to ongoing maintenance concerns?\n\nMy response:\n\nGoogle has stated that their draft is subject to change, so I won't plan anything unless it is certain to become a reality.\nThat being said, I have nothing against such patch as long as it's implemented well. If the patch becomes too difficult to maintain, we could look into other options like Brave's native blocking implementation. We will discuss this on GitHub Issues if it ever gets to that point.. Thanks for describing in depth your problem and motivations. I believe I understand the situation better now.\n\nWe would all appreciate new feature development, even if it isn't immediately useful, or even if it doesn't end up useful at all. While I can't guarentee that I will personally contribute code, I would at least like to provide guidance and support for you and this feature.\nIt looks like you have a vision of what you want this feature to become, so I won't push back with feature requirements or the sort at this time. I think this'll be a great way to let you familiarize yourself with the Chromium codebase, and allow us to form better ideas based on actual work.\nYou said you've worked on large codebases before, so here are some brief tips I can give (in no particular order of importance):\n\nTake a look through Google's design docs in chromium.org and in the Chromium source tree under docs/. At least skim them to get an idea of what's there and to set your bearings straight while in the code.\nHave a look through ungoogled-chromium's patches to get an idea of how certain components of Chromium work.\nTry reading through the code mentioned by the design docs or patches. Especially code comments, like those in the header files. Reading helped me get an intuitive \"feel\" for Chromium's code style and structure.\nThere are several major differences between ungoogled-chromium's build process and Chromium's build process. There are several reasons for doing so, but they should make more sense as you go through them.\n\nI realize that working on Chromium, or any new large codebase, is a daunting task. But like any other large codebase, no one person will know how all of Chromium works, or even what all the individual components are. Thankfully, there is a nice coherent structure and style throughout that makes reading Chromium code a lot easier, even satisfying at times. Reading the design docs covering overall motivations, structures, and processes helped quite a bit too (albeit it is usually a bit outdated). While the amount of code you will need to look through will not be insignificant, it shouldn't be too overwhelming either.\nTo keep track of your work, I think it is best to start a fork; perhaps we could maintain a Pull Request here to increase visibility.\nFinally, to wrap up with a question you had:\n\nQuestion: Does anyone know if this is feasible? Or is there another online service I could use?\n\nHave a look through #17. Basically, Travis won't work. You could try OpenSUSE Build Service or maybe something like an Amazon EC2 instance.. > FYI the chromium build requirements are just crazy. If you want to hack on the chromium source, you really need a beefy machine with a lot of ram, the more cores the better. On my old 8-core-8-thread-32G system it takes about 12 hours to build, and I have to turn off debug symbols or else I run out of ram. On my new 16-core-32-thread-64G system, it takes two or three hours without symbols and three or four with debug symbols.\nI'm not sure what your setup is like, but that sounds excessive. I have been using a laptop for all my recent ungoogled-chromium builds; a Skylake i5 (dual core, hyper-threaded) with 16 GB of RAM. I can put the entire build tree on tmpfs (no swap), and it compiles in roughly 3-6 hours (time varies due to the particular build configuration and Chromium version). For my Debian builds, the entire build tree takes somewhere between 8 GB to 10 GB, and the compiler and linker are just fine with the remaining amount of RAM (though, I do have to log out of GNOME 3 to prevent an OOM issue during linking).\nEDIT: I should note I usually build in release mode, which is why I'm able to fit the build tree into tmpfs.. Are you trying to install LLVM packages from apt.llvm.org for bionic?. Works for me. Thanks.. I'm guessing you are referring to --cfi=all. It's possible that Clang 7 is too old now; we may need to either upgrade LLVM or disable CFI.. Hm, it seems your builds are using the system's GNU ld linker instead of LLVM's lld linker. Could you guys try adding use_lld=true in your GN flags?\nAlso, it seems that icf refers to a compiler optimization called Identical Code Folding. It's pretty much what the name suggests.. This may be related to GN flags. We are using the unbundle toolchain, which means we specify what tools to use for compiling. However, the unbundle toolchain defers determination of the linker to the C++ compiler, which means that Clang may not be selecting the right linker. We could try adding -fuse-ld=lld to LDFLAGS (in debian/rules) to see if that will force the use of LLD (also leave use_lld=true just in case).. @spotlightishere is correct. It seems we didn't add this to the documentation for macOS. Python 3 is needed for get_package.py, and Python 2 is needed for Chromium build scripts. I will note this in the documentation.. 82b1194615a6542c28edfc5505d357c9dfca88c7. It is possible to do this, but it won't be easy. The syncing code in Chromium is deeply tied with Google-specific services and specifications. We would need to define how we would want this syncing to work (as you implied at the end), and then investigate what we would need to do to implement it in the Chromium code. It will a large undertaking, to say the least.\nIf you don't use all three systems at the same time, maybe you could consider an external syncing system that can synchronize the entire profile directory?. I'm not entirely sure if the profile directories will be compatible under such platforms, but you'll need to synchronise the user data directory. The path to the currently-used profile can be found under chrome://version under \"Profile Path\". The user data directory is the parent directory of the Profile Path.. Yes, blindly applying a generic file-synchronization service to the profile directory is a bad idea. File synchronization services make assumptions about how the files are used that are not valid for a Chromium profile (as you experienced first-hand). For example, generic file sync assumptions about consistency and how to approach consistency do not work for Chromium profile files; the atomic changes (e.g. adding a new bookmark, adding a new website to the history) made to the Chromium profile may require changes across multiple files.\nIf there is some way to translate the atomic changes to a format that conform to the assumptions of generic file synchronization services (e.g. DecSync, which assumes Syncthing), then it should be possible to use a generic file sync service to sync changes. However, this still isn't a trivial task.... This may be a side effect of the Chromium profile compatibility/integrity checking breaking when the machine ID changes. We need someone with more knowledge of this to fill us in.. ungoogled-chromium stays with the latest stable version of Chromium. At the time of writing, 72.0.3626.96 is the latest stable version, not 74.\nIf we had more manpower, then perhaps we could consider keeping up with more unstable versions of Chromium.. If the Arch Linux build is reproducible, then we could see if others can build and verify. Otherwise, there's no good way to determine safety.. Patches haven't been updated yet for macOS. This error is expected. You can see the status of patches in the validate_patches CI task in commits, like this one.. It may be related to VA-API decoding, since it changed in 72. What video driver are you using? What does chrome://gpu say about video decoding? Does toggling chrome://flags/#disable-accelerated-video-decode do anything?. Near the top of the building document, it indicates the following:\n\nChoosing a version: It is highly recommended to choose a tag version for building. master and other branches are not guaranteed to be in a working state.\n\nTherefore, this note is irrelevant. If there's anything that should be changed, it's the section at the top to make this more obvious to new builders.\n(Also, trying to help new developers use unstable code is a recipe for disaster).. Looks like the static assert is indicative of the error: v8 is required to build with ICU 63 and up\nIt's possible the following errors are caused by a system ICU that is too old. We may have to use the bundled ICU library instead. I believe there's a GN flag for this, and a code change in debian/scripts/unbundle required to use the bundled ICU library.. @riyad \n\nThe documentation mentions that .list files are concatenated down the dependency chain ... so how do I skip or undo a patch from a dependency?\n\nThere isn't. It's a design choice I made because I feel the additional complexity due to such a feature would make it more difficult to reason what flags/patches would be applied. If you want to remove a patch from a dependency (e.g. linux_rooted), you have to move the flags/patches to all its dependents (e.g. archlinux, debian_buster, etc.) except the bundles you don't want the flags/patches in.\nFYI, I am on my way to updating support for Debian buster and stretch in the ungoogled-chromium-debian repo. However, there is a chance that these changes for Debian aren't fully compatible with Ubuntu, so feel free to keep working on your own changes in the meantime.. Sure. Since it's such a small change, it should probably go under linux_rooted.\nFeel free to submit a PR.. AV1 codec requires a libav that is newer than what stretch provides. This isn't a new issue; I have been following whatever upstream (i.e. Debian) does for its chromium package. I just haven't gotten around to updating ungoogled-chromium for Debian yet.. > Not only UnGoogled, but UnCompiled too\n\nMyself and others may be interested in trying this IF there was an installer or compiled version.\n\nYou're sending me mixed messages here...\nIn all seriousness, links to binaries are available via the README... I suppose the README's still too convoluted for people to see it. I will consider revising again at some point.\n\nbut it's evidently for developers and/or power-users only, not the general public. Not even advanced users.\n\nI'm curious to know what gave you that impression. As I mentioned, downloads are available, so it's not hard to get a build of ungoogled-chromium running. Also, the browser experience is pretty much regular Chromium, so there aren't any difficulties I can see ther either.. This is a duplicate of #623.. This sounds like #688. What version are you running?. Ah, I misread your issue. Thanks for clarifying.\nSince this is only affecting URLs typed in the Omnibox, I think this is purely a user experience design decision. As @tie argues in #628, having https in the URL bar addresses potential privacy/security issues.\nApproximately what proportion of websites do you visit that are affected by this issue? How often do you encounter them?. I don't believe this is worth the effort, because flag checking code would need to be added to a number of places; mostly in C++ code, but also a JavaScript file. I'd rather not maintain that much extra complexity for a less common use-case, especially since this doesn't significantly deviate from regular Chromium's behavior.\nIf this is troublesome enough for you, and you have the resources to do so, you could consider rebuilding the browser without that patch. The browser should work just fine without it.. Could you clarify how this causes a data leak? I'm not familiar with this scenario.. Sorry, I still don't understand. Could you point out and explain exactly what I should be looking for?. I see, so when you apply the patch above:\n\nWhat happens to the dialog box?\nWhat does \"Keep Changes\" do now?\nWhat does \"Restore Settings\" do now?\nWhat happens to extension_id_ above the return statement?. I'm not sure if this is a Windows-specific issue, so I'm going to leave this open for now. If it is Windows-specific, I will close this since we don't support customized versions of ungoogled-chromium (because Windows support isn't updated yet).. > Obviously KeePassXC-Browser don't allow unpacked installation, but only CRX from Web Store.\n\nInteresting. Didn't know that extensions had the ability to determine that.\n\nIf not, I guess this can be closed.\nOnly KeePassXC at this time. Works with others extensions tested.\n\nSounds fine with me.. Which binary are you using?. You should ask whoever built that binary for support. There is no official Windows binary for version 72.. WebRTC is not disabled. If it doesn't work, please let us know.. As stated in #589, Push Notifications depends on GCM. I don't think it will be easy to re-enable GCM if you still want to maintain the features of ungoogled-chromium. You could try to switch to Chromium or another Chromium-based browser if this is really important to you.. Thanks for the well-constructed report.\nI actually removed this patch while working on the fragmentation branch, but forgot to do it for master. I'll push a change later.\nAs for the reason why I dropped this patch, it really comes down to how strongly I want to adhere to FOSS principles. While Michael decided that it is important to break features, even large ones, to adhere to FOSS (as shown in the patch comment), I'm not sure if I want to do the same for ungoogled-chromium, at least not for all platforms. I think I'll limit it to Debian platforms only.. There has been discussion about this in #662. I think it's best to move discussion over to that issue.\nTo briefly answer your question: Right now, there are no concrete plans related to this issue.. I'm sorry if I offended you in any way. I just want to consolidate the discussion.\nYou make a good point, so I will revise the title of that issue.. Thanks for taking the time to submit a bug fix for this script, but I'll be deprecating it soon as part of #651. The new system won't need to synchronize changes like this anymore.. Thanks for the offer, but this is not necessary since the next version of Debian binaries will be built off new code from #651. For now, I plan on testing and building binaries for Debian buster and stretch.. Ninja != Quilt. Could you make that quick fix please? Thanks\n. What is the reason for adding \"type\": \"remote\"? With domain substitution, this effectively disables the module in all scenarios.. I'm guessing these patches no longer applied cleanly (or at all)?. At this rate, perhaps it would help to make opensuse inherit from linux_rooted instead of common? Or are there changes in linux_rooted you don't want?. Would you mind adding a short description for this patch? I can't tell what this does from the changes alone.. Ah, I was more interested in knowing what the change does so I could determine if I needed to include it in linux_rooted or not (like the user namespace sandbox patch). But since the source doesn't specify, I'll probably leave it in opensuse for now.. Good to know. Thanks!. No problem. I'll change it after I merge.. Looks like domain substitution tripped you up too huh. I'm a bit worried about this, because develop is a changing state. When we generate a PKGBUILD using buildkit, I'm thinking that we should substitute the current commit here (like it was done for patch_hashes) so we always checkout a consistent state. This makes it easier for reproducibility, and it can be done at any point in development (as opposed to checking out a tag which requires creating tags).. If we're not going to need this and patch_hashes, we should probably cleanup the corresponding PKGBUILD generation code in buildkit.. When I was creating this PKGBUILD from Inox's, I wasn't sure what to do with the product_logo images. If they're not needed, I think it's best to remove it and related code elsewhere to reduce clutter.\nDoes ungoogled-chromium still have an icon if these files are removed? If not, I believe there is an original Chromium logo in the build output that we can use.. As I mentioned earlier, I don't think tags will work well for development builds. With tags, one would have to create tags just to try a build, or modify the PKGBUILD by hand to specify a commit.\nThis could be useful to allow users to test some new changes before making a release, for example.. Why is the build output path hardcoded here? Is there something wrong with out/Default or some other user-specified build output directory?. > I may use tags and download the tarball instead of cloning the repo only in the PKGBUILD that I will upload to AUR, since that will use specific releases.\nYou brought up a good point about archives; I almost forgot about them. GitHub allows you to download an archive of the tree at any commit via https://github.com/Eloston/ungoogled-chromium/archive/${commit}.tar.gz (another example is in the macOS base bundle extra deps). That'll save some bandwidth and space.\nHowever, I don't quite understand your rationale for preferring tags over commits specifically for the AUR. Why go through more effort when one process can generate PKGBUILDs for both development and release builds?\n\nI think it would be better if it is you who fix the python code\n\nCan do. I'll start working on it after we clarify the above issue and the new review regarding out/Release.. Ahh, I see. In that case, I will by default use the config bundle's version to determine the tag to download. I will also add a CLI option to enable use of the current commit.. Was the GTK2 patch removed in Debian?. Do you know what this file is used for?. Yeah, I don't see much benefit of including them in this case.\n~~@squalus Could you include @xsmile's change as a new patch in the common base bundle (and also refresh any subsequent patches that also touch this file)?~~. Nevermind I can merge now and do it.. I don't understand why the nodejs is needed here. I already disabled WebUI optimization in common base bundle (optimize_webui=false) and removed the symlink to the nodejs binary from the PKGBUILD. Is there still a reference to nodejs somewhere?. Is there a reason why you want to hardcode the build output directory (key build_output)?. I would rather not disable template processing, because I will modify resources/packaging/list_build_outputs.py to support archive generation, and I will want to add a package.bat script that calls this Python script. That batch script will need ConfigBundle.version.version_string for the output package name.\nI will have reverted this by the time you're read this.. The Python 3.5 and newer installers for Windows can install the py launcher. There's no python3 command that is installed by the installer (AFAIK), and this can be confusing to users who copy these instructions verbatim.\nFrom my experience, the py launcher will correctly read the shebang of buildkit-launcher.py and use Python 3 instead of Python 2 to run buildkit. If you're worried about this, you can just use py -3 to force using Python 3.\nIs there a reason why you chose to use python3 here? If not, we could just explicitly tell users to ensure that they install the py launcher.. This is a duplicate of ungoogled-chromium/linux/fix-libstdcxx630-errors.patch. This and its associated function should be removed (see alternative solution in other comments). With optimize_webui=false in the common base bundle, Node.js shouldn't be necessary.. Instead of manipulating the buildspace tree here, it's better to do it in ungoogled_packaging.sh. You can move the buildspace tree at the end of that script, or just add a hardlink or softlink to the buildspace tree from BUILD/. That way, we can remove the hardcoded dependency on unpacked_src_dir.. Maybe something like this would be better:\n\nCreate a directory called resources/packaging/opensuse/sources_template\nDuring the buildkit genpkg step, copy sources_template/ to ungoogled_packaging/SOURCES using shutil.copytree(), and then process .in files using process_templates() from buildkit.packaging._common. Then, just cp -r $(dirname $(readlink -f $0))/SOURCES/* ~/rpm/SOURCES/\n\nAssuming the contents of chromium-icons.tar.bz2 lives in resources/packaging/opensuse/chromium-icons_contents/, copy it using shutil.copytree() to ungoogled_packaging/chromium-icons_contents/. Then something like the following code can generate the .tar.bz2:\nshell\npushd $(dirname $(readlink -f $0))/chromium-icons_contents\ntar cjf ~/rpm/SOURCES/chromium-icons.tar.bz2 *\npopd. If you haven't already, please check and fix warnings and errors detected by developer_utilities/pylint_buildkit.py for this code if you haven't already. It will be much appreciated :+1: . Please replace the .tar.bz2 with its contents (code to generate the archive is proposed in other comment for setup.sh). I like to keep files reasonably transparent in the repo.. If this isn't going to be used, it should be removed.. Out of curiosity, what kind of benefits and changes are needed with is_official_build=true?. So is this basically a newer version of the patch ungoogled-chromium/linux/fix-libstdcxx630-errors.patch? If so, we should probably remove that one.\n\n\nAnd if I'm not mistaken, this is a fix for libstdc++, not clang. Using libc++ doesn't require this change (see any platform that isn't Debian or Ubuntu for version 65).. So this is a newer version of ungoogled-chromium/linux/fix-libstdcxx630-errors.patch? If so, we should probably remove that patch.\nBased on this patch's name, I'm given the impression that this is a fix for using clang. I'm thinking that it may be more appropriate to specify it's a fix for libstdc++, because libc++ doesn't have this problem.. Would this work on Windows? I'm not exactly sure how this addresses #354. (Granted I haven't seen if this code has changed significantly in 66).. If it's easier to keep things consistent with Inox, you can just remove my patch and rename yours to fix-building-with-libstdcxx or something, to prevent confusion with Gentoo's naming scheme.\nIf you aren't going to include this in Inox (since it's using libc++ now IIRC), then you can just refresh my patch and remove the 630 from the name (since it doesn't seem to be a problem with a specific libstdc++ version).. Huh, I didn't realize both comments appeared. My tab crashed several moments after I posted the other comment, so I refreshed and didn't see it. Hence, this one was created.. Would you be able to revert these changes back to the original form? If #354 is still an issue, it'll be a pain to fix it.\nOut of curiosity, why did you choose to write the patch this way?. If it doesn't have any other adverse effects, I'm thinking we can include this as a patch in common base bundle instead.. Would a patch of this in linux_rooted allow is_official_build=true to work?. I think we can at least keep the first comment line of this patch.. I see. I'm going to merge now so others can start updating their changes. I'm thinking about trying this out on Debian a little later, so you can submit another PR to convert this into a patch if you'd like.. If you're worried about this breaking compatibility on newer systems, maybe we could use a compiler macro that goes by the SDK version?. I'm thinking it may be better to move this to the common bundle because these changes may be nice for other platforms.. Why are the not conditions necessary (lines 92 and 93)? Isn't this covered by line 90?. I believe this TODO should be removed since it goes against the objective of sticking to the default Chromium experience.. If pkg2appimage is a standalone script, it may be better just to retrieve it directly via HTTPS.\nOtherwise, I think it would be better to use a shallow clone here to save a little bandwidth.. Could you enlighten me of the purpose of change_password_handler.cc? Also, what purpose does this function and the one below have?. I see, I didn't realize service_ was referring to Safe Browsing code. Thanks for explaining.\n\ni guess we could replace \"ShouldShowChangePasswordSettingUI\" with \"true\" boolean value..\n\nWe would need to set the whole boolean statement to true in this scenario.\nCould you check what change-password-visibility does from the Web UI JavaScript (since FireWebUIListener triggers a JavaScript event)? I'm not able to inspect the code at the moment.. I see. In that case, what you have in the patch is good. Thanks.. What is the purpose of NOTREACHED() here? Does disable-machine-id break debug builds or something?. Could you add a brief comment to the top of the patch?. The purpose of NOTREACHED() is to raise an assertion (i.e. crash the browser) when the code is reached. So, NOTREACHED() in this context doesn't make sense. The reason why this works is because NOTREACHED() is implemented as DCHECK(false), which only triggers in debug builds; ungoogled-chromium is built in release mode by default. See the documentation here for more info. (Sidenote: The fact that Linux and macOS have NOTREACHED() further confirms that these platforms aren't supposed to use the machine ID mechanism.)\nI don't see anything other troublesome code here, but please check that the code immediately affected by your changes makes sense in the future. Otherwise, we'd be accumulating technical debt that can be challenging to solve (e.g. #362).. The standard structure is to have the downloads cache inside the build directory. I don't want to support multiple different structures since it can get confusing. I also like to keep .gitignore files as short and simple as possible to encourage cleaner file structures. If you want to propose a new standard structure, please let me know.. It is the user's responsibility to clean up the source tree after a failed attempt. Removing files preemptively is dangerous if the user makes a mistake with their paths. At most, I would tell the user what happen and recommend a course of action.\n(Also FYI, this code breaks under Python 3.5 because it doesn't implement PEP 519). It is the user's responsibility to clean up the source tree after a failed attempt. Removing files preemptively is dangerous if the user makes a mistake with their paths. At most, I would tell the user what happen and recommend a course of action.\nAlso, the error that you get is probably the one right below this code you added...\n(Also FYI, this code breaks under Python 3.5 because it doesn't implement PEP 519). Oh, I see. I never tested that script, so feel free to fix it. It's a recent addition to deprecate batch scripts.. I don't think it is necessary to have this patch considering that all of this code will be removed in disable-google-host-detection.patch. Please don't revert this.\nFYI, I've been trying to develop a new workflow for updating Debian-related patches and packaging files. It should be able to catch cases like this. The instructions for this workflow are here: https://github.com/ungoogled-software/ungoogled-chromium-debian. That being said, I don't think it is necessary to re-work this PR using that workflow. If you decide to try it out for the next release, let me know how it goes.. I don't have any configurations that use the GTK2 UI. I'm guessing it is not necessary to include this?. I manually added this line back in because I wasn't sure if removing this line would cause any issues or not.. Does pyenv support creating a symlink to Python as python? I don't think bash aliases will work in all of the cases that use Python 2 (correct me if I'm wrong).. ",
    "ik9999": "Thank you for your response.\nI managed to finish making, but got this error:\n\nmake[1]: Leaving directory '/home/eq/Programs/ungoogled-chromium/build-sandbox'\n   debian/rules override_dh_strip\nmake[1]: Entering directory '/home/eq/Programs/ungoogled-chromium/build-sandbox'\nthis line can be removed once stretch is released\ndh_strip --ddeb-migration='chromium-dbg (<< 47.0.2526.80-4~)'\ndh_strip: unknown option; aborting\ndebian/rules:166: recipe for target 'override_dh_strip' failed\nmake[1]: * [override_dh_strip] Error 25\nmake[1]: Leaving directory '/home/eq/Programs/ungoogled-chromium/build-sandbox'\ndebian/rules:127: recipe for target 'binary' failed\nmake: * [binary] Error 2\ndpkg-buildpackage: error: fakeroot debian/rules binary gave error exit status 2\n\nIs it the problem in chromium itself?\n. I've managed to build it. Thank you very much for your support and for this project.\nAlso, for my dpkg version(1.17.26) i needed to edit download_source.sh(i've removed space after -l)\n\n\nDOWNLOAD_VERSION=$(dpkg-parsechangelog -l $DEBIAN_CHANGELOG -S Version | sed s/-.*//);\nDOWNLOAD_VERSION=$(dpkg-parsechangelog -l$DEBIAN_CHANGELOG -S Version | sed s/-.*//);\n. About jessie-backports, i added this to my sources.list:\n\ndeb http://ftp.se.debian.org/debian/ jessie-backports main\ndeb-src http://ftp.se.debian.org/debian/ jessie-backports main\ndeb http://http.debian.net/debian jessie-backports main\ndeb-src http://http.debian.net/debian jessie-backports main\n\nThen did:\n\nsudo apt-get install libavutil-dev/jessie-backports libavcodec-dev/jessie-backports libavformat-dev/jessie-backports\n. Are you sure that its not a chromium issue? I can't check it right now.. @Eloston I feel like memory usage grows slower now, it was 721mb yesterday, now its 889mb. . @Eloston Installed v71 using your deb binaries. Running it for like 24 hours. Memory grew from 300mb to 800mb. Maybe it happens because i have many extensions/long-running tabs. Will wait for few more days, maybe it will stop growing. \n\nUpdate after 1 day: 1.1gb\nUpdate after 2 days: 1.4gb\nUpdate after 4 days: 1.6gb\nUpdate after 6 days: 1.7gb\nUpdate aftre 8 days: 1.8gb\nUpdate after 13 days: 1.9gb\nUpdate after 14 days: 2.0gb\nUpdate after 15 days: 2.1gb\nUpdate after 17 days: 2.2gb\nUpdate after 20 days: 2.3gb\nUpdate after 21 days: 2.4gb\nUpdate after 24 days: 2.5gb\nUpdate after 26 days: 2.51gb\nUpdate after 26 days: 2.528gb\nLooks like the memory almost stopped to grow at this point.\n. Memory grows slower after some time, so most likely its not a memory leak, but some kind of cache or something.. I have to close the browser.\nThats the chart of RAM growing through the time.\n\nCan memory leak cause this kind of growing which slows down that much?. @intika \n\nThe line is days or hours ?\n\nDays.\n\nwas the browser just open or used ?\n\nOpened and used.\n. I dont feel like usage makes it grow more. I've used it a lot in last 2 days, but memory almost stopped growing.. >The above two questions can be generalized as follows: Should the browser be split up to let other developers determine how they want to package ungoogled-chromium (e.g. like Android, Linux distros, even Windows to an extent), or should it more strictly control the entire process of the browser creation (e.g. iOS, Chrome, perhaps Brave)?\n@Eloston, you are doing 90%+ work on this project for free, so if you will choose to extend the scope of this project, which will require even more of your time, consider accepting some kind of donations.\n. ",
    "kirill9000": "Hello. I've just run into same three issues (space after -l in dpkg-parsechangelog arguments, old libav and override_dh_strip) while building on Debian Stable. Could you please fix the scripts so they would check distro version and work on stable without manual modifications? Oh, and mentioning jessie-backports in README would be nice too. Thanks!\n. @ik9999 Yeah, I figured that and successfully built Chromium with your and @Eloston's instructions. Just thought that having this information in README would help since a lot of people use Stable.\n. Works like a charm now, thank you.\n. ",
    "tristan-k": "Thanks! Will report back later.\n. I'm running in some syntax issues.\n$ ./download_source.sh -v 48.0.2564.109                                                                                                       (master) \nreadlink: illegal option -- f\nusage: readlink [-n] [file ...]\nusage: dirname path\n. Thanks! Should have read the readme more carefully. \n. > I would rather create distribution-specific packages than use a third party system. \nThat would be great. I'm just concerned about security updates which wont make it to the avaerage user because of the lack of a easy update system.\n. Same here. Package 57.0.2987.110-1.\nDependency is not satisfiable: libavcodec57 (>= 7:3.2.4)|libavcodec-extra57 (>= 7:3.2.4) . > NOTE: This version only supports Debian and Ubuntu\nThis is confusing.. ",
    "perfect7gentleman": "yes, of course.\noriginal Iridium patches applied ok.\n. i ran domain_patcher.sh, and patches were magically applied.\n. also, it is needed to run source_cleaner.sh\n. without source_cleaner.sh i get error at the very end of compilation\n. ninja: build stopped: subcommand failed.\n. yep, that's all\nI ran it at the beginning before domain_patcher.sh and applying the patches\n. it is the only one. no errors before that.\nthere is ebuild modified. you can take a look.\nhttps://github.com/perfect7gentleman/pg_overlay/blob/master/www-client/chromium/chromium-49.0.2623.111.ebuild\ni also added those parameters to configuration \n        -Dsafe_browsing=0\n        -Dremoting=0\n        -Denable_prod_wallet_service=0\nmaybe it was them which made compilation successful.\nif it is necessary, i could try to build chromium without source_cleaner.sh and give thorough log.\n. 1. No source_cleaner.sh, but \n   -Dsafe_browsing=0\n   -Dremoting=0\n   -Denable_prod_wallet_service=0\nCompilation successful.\n1. source_cleaner.sh, but no \n   -Dsafe_browsing=0\n   -Dremoting=0\n   -Denable_prod_wallet_service=0\nCompilation failed\nFAILED: x86_64-pc-linux-gnu-g++ -MMD -MF obj/chrome/browser/extensions/browser_extensions.blacklist.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D_FILE_OFFSET_BITS=64 -DDISABLE_NACL -DCHROMIUM_BUILD -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_ASH=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_DEFAULT_RENDER_THEME=1 -DUSE_LIBJPEG_TURBO=1 -DUSE_X11=1 -DUSE_CLIPBOARD_AURAX11=1 -DENABLE_ONE_CLICK_SIGNIN -DENABLE_WEBRTC=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_CONFIGURATION_POLICY -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DUSE_UDEV -DDONT_EMBED_BUILD_METADATA -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_BACKGROUND=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_SPELLCHECK=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_MDNS=1 -DENABLE_SERVICE_DISCOVERY=1 -DENABLE_HANGOUT_SERVICES_EXTENSION=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DGL_GLEXT_PROTOTYPES -DMOJO_USE_SYSTEM_IMPL -DUSE_SYSTEM_MINIZIP -DTOOLKIT_VIEWS=1 -DPROTOBUF_USE_DLLS -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DSK_SUPPORT_GPU=1 -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DU_USING_ICU_NAMESPACE=0 -DI18N_ADDRESSINPUT_USE_BASICTYPES_OVERRIDE=1 -DWEBRTC_CHROMIUM_BUILD -DWEBRTC_LINUX -DWEBRTC_POSIX -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen/shim_headers/libflac/target -Igen/shim_headers/snappy/target -Igen/shim_headers/libpng/target -Igen/shim_headers/harfbuzz-ng/target -Igen/shim_headers/zlib/target -Igen/shim_headers/icuuc/target -Igen/shim_headers/icui18n/target -Igen/shim_headers/libevent/target -Igen -I../.. -Iobj/chrome/browser_extensions.gen -Iobj/chrome/browser_extensions.gen/chrome -I../../third_party/khronos -I../../gpu -I../../skia/config -Igen/angle -I../../third_party/WebKit/Source -Igen/chrome -Igen/protoc_out -I../../third_party/protobuf -I../../third_party/protobuf/src -I../../third_party/dom_distiller_js/dist/proto_gen -Igen/components/strings -Igen/content/app/resources/ -I../../third_party/WebKit -Igen/extensions -Igen/extensions/strings -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/pdf -I../../third_party/skia/include/gpu -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../skia/ext -I../../third_party/cacheinvalidation/overrides -I../../third_party/cacheinvalidation/src -I../../third_party/leveldatabase/src/include -I../../third_party/leveldatabase/src -I../../third_party/leveldatabase -I../../third_party/re2/src -I../../third_party/libaddressinput/chromium/override -I../../third_party/libaddressinput/src/cpp/include -Igen/third_party/libaddressinput/ -I../../third_party/webrtc_overrides -I../../third_party -Igen/ui/resources -Igen/ui/keyboard -Igen/ui/views/resources -Igen/policy -fstack-protector --param=ssp-buffer-size=4  -pthread -fno-strict-aliasing -Wall -Wno-extra -Wno-unused-parameter -Wno-missing-field-initializers -fvisibility=hidden -pipe -fPIC -Wno-unused-local-typedefs -pthread -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/nss -I/usr/include/nspr -I/usr/include/dbus-1.0 -I/usr/lib64/dbus-1.0/include -I/usr/include/freetype2 -I/usr/include/harfbuzz -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/freetype2 -I/usr/include/harfbuzz -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -m64 -march=x86-64 -O2 -fno-ident -fdata-sections -ffunction-sections -funwind-tables -march=native -mtune=native -O3 -pipe -fomit-frame-pointer -fno-stack-protector -fno-exceptions -fno-rtti -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -Wno-narrowing  -c ../../chrome/browser/extensions/blacklist.cc -o obj/chrome/browser/extensions/browser_extensions.blacklist.o\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\n../../chrome/browser/extensions/blacklist.cc: In constructor \u2018extensions::{anonymous}::LazySafeBrowsingDatabaseManager::LazySafeBrowsingDatabaseManager()\u2019:\n../../chrome/browser/extensions/blacklist.cc:42:49: error: \u2018class BrowserProcess\u2019 has no member named \u2018safe_browsing_service\u2019\n     if (g_browser_process && g_browser_process->safe_browsing_service()) {\n                                                 ^\n../../chrome/browser/extensions/blacklist.cc:44:30: error: \u2018class BrowserProcess\u2019 has no member named \u2018safe_browsing_service\u2019\n           g_browser_process->safe_browsing_service()->database_manager();\n                              ^\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\n<command-line>:0:0: warning: \"_FORTIFY_SOURCE\" redefined\n<built-in>: note: this is the location of the previous definition\nninja: build stopped: subcommand failed.\n. I assumed that Inox-patchset uses safe_browsing=0. But I see safe_browsing_mode=0, and they are different options.\nDo you recommend to use source_cleaner.sh for other distros or not ?\n. according to https://chromium.googlesource.com/chromium/src.git/+/master/build/common.gypi, there is no such flag safe_browsing_mode=0\n. what do you mean by 'buggy' ? they can't be applied or the patches themselves are bad ?\n. thanx\n. how does that script work? i don't see any button on store's extension page.. @Admicos, i don't use Tampermonkey, but uMatrix. I've disabled it but it won't help.\nhttp://pasteboard.co/6ZCkE9TTv.png. @Admicos, I've just drap&drop it into the extensions tab.\nhttp://pasteboard.co/HnHzwEhK.png. @Admicos, still no luck :(. heh. where is patch order for 57 ?. @Eloston, okay.. I have 16gb RAM, 13gb tmpfs, 13gb zram, no swap file. Have no problem building Chromium.. @nyancat18, not 3 for work, but 16, as tmpfs can be empty. @Eloston, honestly don't know, never made any measurements.. No, they are not updated via the Update extensions now from Developer mode. Have both of you tested your ebuilds?. v70 ebuild  thanks to @ian-moone . master. @intika, but it works :). Do not agree.\nversion: Update to 70.0.3538.67 \n. there are just lots of testing, typos and etc.\nalso I don't force anyone to use my overlay.. Template - Archlinux\nwww-client/chromium-69.0.3497.100::pg_overlay was built with the following:\nUSE=\"cups custom-cflags (pic) proprietary-codecs pulseaudio suid system-ffmpeg system-icu system-libvpx tcmalloc vaapi -component-build -gnome-keyring -hangouts -jumbo-build -kerberos (-neon) (-selinux) -thin-lto -widevine\" L10N=\"ru -am -ar -bg -bn -ca -cs -da -de -el -en-GB -es -es-419 -et -fa -fi -fil -fr -gu -he -hi -hr -hu -id -it -ja -kn -ko -lt -lv -ml -mr -ms -nb -nl -pl -pt-BR -pt-PT -ro -sk -sl -sr -sv -sw -ta -te -th -tr -uk -vi -zh-CN -zh-TW\" PYTHON_TARGETS=\"python2_7 python3_7\"\nCFLAGS=\"-march=native -mtune=native -O3 -pipe -fomit-frame-pointer -fno-stack-protector\"\nCXXFLAGS=\"-march=native -mtune=native -O3 -pipe -fomit-frame-pointer -fno-stack-protector -stdlib=libc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -Wl,--strip-debug -flto=thin -Wl,--thinlto-jobs=9 -fuse-ld=lld\"\n\nsys-devel/llvm-7.0.0-r1::gentoo was built with the following:\nUSE=\"gold libffi ncurses -debug -doc -exegesis -libedit -test -xar -xml\" LLVM_TARGETS=\"(X86) -AArch64 -AMDGPU -ARM -BPF -Hexagon -Lanai -MSP430 -Mips -NVPTX -PowerPC -Sparc -SystemZ -XCore\"\nCFLAGS=\"-march=native -mtune=native -O2 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin\"\nCXXFLAGS=\"-march=native -mtune=native -O2 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin -stdlib=libc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -Wl,--strip-debug -flto=thin -Wl,--thinlto-jobs=9 -fuse-ld=lld\"\nsys-devel/clang-7.0.0::gentoo was built with the following:\nUSE=\"default-compiler-rt default-libcxx -debug -doc -static-analyzer -test -xml (-z3)\" LLVM_TARGETS=\"(X86) -AArch64 -AMDGPU -ARM -BPF -Hexagon -Lanai -MSP430 -Mips -NVPTX -PowerPC -Sparc -SystemZ -XCore\" PYTHON_TARGETS=\"python2_7\"\nCFLAGS=\"-march=native -mtune=native -O2 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin\"\nCXXFLAGS=\"-march=native -mtune=native -O2 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin -stdlib=libc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -Wl,--strip-debug -flto=thin -Wl,--thinlto-jobs=9 -fuse-ld=lld\"\n. bug is irrelevant as I took ebuild from chaos-overlay and it builds fine.\nthere was one bug https://gitlab.com/chaoslab/chaoslab-overlay/issues/47\nx86_64-pc-linux-gnu-clang++: error: no such file or directory: '/usr/lib/llvm/7/bin/../../../../lib/clang/7.0.0/share/cfi_blacklist.txt'\nsolved with\nEXTRA_GN=\"clang_use_default_sample_profile=false is_cfi=false\". @ian-moone, with what flags have you llvm/clang compiled ?. I got\nsys-devel/llvm-7.0.0-r1::gentoo was built with the following:\nUSE=\"gold libffi ncurses -debug -doc -exegesis -libedit -test -xar -xml\" LLVM_TARGETS=\"(X86) -AArch64 -AMDGPU -ARM -BPF -Hexagon -Lanai -MSP430 -Mips -NVPTX -PowerPC -Sparc -SystemZ -XCore\"\nCFLAGS=\"-march=native -mtune=native -O2 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin\"\nCXXFLAGS=\"-march=native -mtune=native -O2 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin -stdlib=libc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -Wl,--strip-debug -flto=thin -Wl,--thinlto-jobs=9 -fuse-ld=lld\"\nsys-devel/clang-7.0.0::gentoo was built with the following:\nUSE=\"default-compiler-rt default-libcxx -debug -doc -static-analyzer -test -xml (-z3)\" LLVM_TARGETS=\"(X86) -AArch64 -AMDGPU -ARM -BPF -Hexagon -Lanai -MSP430 -Mips -NVPTX -PowerPC -Sparc -SystemZ -XCore\" PYTHON_TARGETS=\"python2_7\"\nCFLAGS=\"-march=native -mtune=native -O2 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin\"\nCXXFLAGS=\"-march=native -mtune=native -O2 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin -stdlib=libc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -Wl,--strip-debug -flto=thin -Wl,--thinlto-jobs=9 -fuse-ld=lld\"\nI think that USE=static-analyzer makes use of cfi possible..\nsys-devel/clang-runtime-7.0.0:7.0.0::gentoo  USE=\"compiler-rt libcxx openmp -crt -sanitize\"\nwhat do you have there?.\nx86_64-pc-linux-gnu-clang++: error: no such file or directory: '/usr/lib/llvm/7/bin/../../../../lib/clang/7.0.0/share/cfi_blacklist.txt'\n. There is no such file in the system.. I don't think it's LLVM/Clang bug as if there is no sanitizer (cfi) support, imo cfi_blacklist.txt should not be generated..\n ~ $ chromium\n(chromium-browser:17169): Gtk-WARNING **: 18:08:42.659: Theme parsing error: gtk.css:68:35: The style property GtkButton:child-displacement-x is deprecated and shouldn't be used anymore. It will be removed in a future version\n(chromium-browser:17169): Gtk-WARNING **: 18:08:42.659: Theme parsing error: gtk.css:69:35: The style property GtkButton:child-displacement-y is deprecated and shouldn't be used anymore. It will be removed in a future version\n(chromium-browser:17169): Gtk-WARNING **: 18:08:42.659: Theme parsing error: gtk.css:73:46: The style property GtkScrolledWindow:scrollbars-within-bevel is deprecated and shouldn't be used anymore. It will be removed in a future version\nAborted\n. @ian-moone , Clang is default for chromium deps such as nodejs and others. New dep introduced in 71, jsoncpp, is also built with Clang.\n ~ $ cat /etc/portage/env/O3_clang \nCC=\"clang\"\nCXX=\"clang++\"\nCFLAGS=\"-march=native -mtune=native -O3 -pipe -fomit-frame-pointer -fno-stack-protector -flto=thin -flto-jobs=9 -fuse-ld=lld\"\nCXXFLAGS=\"${CFLAGS} -stdlib=libc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -Wl,--strip-debug -Wl,--thinlto-jobs=9 -flto=thin -fuse-ld=lld\"\nAR=\"llvm-ar\"\nNM=\"llvm-nm\"\nRANLIB=\"llvm-ranlib\"\n\n ~ $ emerge -avtp clang llvm libcxx libcxxabi\n[ebuild   R   #] sys-devel/clang-7.0.1_rc2:7::gentoo  USE=\"default-compiler-rt default-libcxx -debug -doc -static-analyzer -test -xml (-z3)\" LLVM_TARGETS=\"(X86) -AArch64 -AMDGPU -ARM -BPF -Hexagon -Lanai -MSP430 -Mips -NVPTX -PowerPC -Sparc -SystemZ -XCore\" PYTHON_TARGETS=\"python2_7\" 13,076 KiB\n[ebuild   R   #]  sys-libs/libcxx-7.0.1_rc2::gentoo  USE=\"libcxxabi libunwind -libcxxrt -static-libs -test\" 1,603 KiB\n[ebuild   R   #]   sys-libs/libcxxabi-7.0.1_rc2::gentoo  USE=\"libunwind -static-libs -test\" 523 KiB\n[ebuild   R   #]    sys-devel/llvm-7.0.1_rc2:7::gentoo  USE=\"gold libffi ncurses -debug -doc -exegesis -libedit -test -xar -xml\" LLVM_TARGETS=\"(X86) -AArch64 -AMDGPU -ARM -BPF -Hexagon -Lanai -MSP430 -Mips -NVPTX -PowerPC -Sparc -SystemZ -XCore\" 27,642 KiB\n```. > ave you successfully built chromium against libcxx/libxxabi in the past?\nyes, and lastest ungoogled-chromium-70 too.\n\nI had to build dev-libs/re2, dev-libs/jsoncpp\n\nthey are built with Clang. I don't see any big differences between ebuilds for 70 and 71. Only jsonccp as new dep.. ",
    "9Morello": "Thats nice, thanks for clarifying.\nEdit: is there a way to prevent canvas fingerprinting? https://www.browserleaks.com/canvas\n. Thanks for your attention. I already know that extension, but unfortunately its not working anymore. Having it enabled and disabling the header reading doesn't change the results: https://www.browserleaks.com/canvas\n. @Eloston Thanks for the tip, now patching worked flawlessly!\nHow should I proceed with the rest? There are some binaries in the release zip, where, how and in which order should I execute them? It seems they are for substitution, but I haven't used them yet.\nI tried executing the cleaning_list file from the 'src' folder but got a bunch of permission errors.\n. @Eloston Thanks for responding. I just tried it from scratch. Downloaded the chromium tree, set the version with\ngit checkout -f 51.0.2704.106\ngclient sync -R --nohooks --with_branch_heads\nand then applied the patches. But when I try to run gn gen out/Default, I get the following error:\ngn gen out/Default\nERROR at //components/domain_reliability/BUILD.gn:22:1: Missing response_file_contents definition.\naction(\"bake_in_configs\") {\n^--------------------------\nThis target uses {{response_file_name}} in the args, but does not\ndefine response_file_contents which means the response file\nwill be empty.\nAny idea on what it could be?\n. Thanks for responding. I tried running the following commands:\nexport GYP_DEFINES=\"werror= default_apps_list=[] default_apps_list_linux_dest=[] remoting=0 disable_nacl=1 disable_pnacl=1 disable_newlib=1 enable_remoting_host=0 enable_automation=0 enable_google_now=0 safe_browsing=0 enable_webrtc=0 remoting=0 enable_hotwording=0 enable_hangout_services_extension=0 enable_wifi_bootstrapping=0 use_official_google_api_keys=0 enable_rlz=0 enable_pre_sync_backup=0 enable_prod_wallet_service=0 enable_one_click_signin=0 enable_hidpi=1 fastbuild=1 disable_fatal_linker_warnings=1 tracing_like_official_build=1 fieldtrial_testing_like_official_build=1 linux_strip_binary=1 proprietary_codecs=1 ffmpeg_branding=ChromeOS enable_mpeg2ts_stream_parser=1 enable_hevc_demuxing=1 remove_webcore_debug_symbols=1\"\nbuild/gyp_chromium\nAnd it didn't fail, despite giving the following error:\ngyp: Undefined variable c_sources in /Users/Morello/chromium/src/third_party/ffmpeg/ffmpeg.gyp\nThen, I started compiling using ninja -C out/Release chrome and it started, but I got an error after ~10 minutes in:\nninja: Entering directory `out/Release'\n[6000/20363] MACTOOL copy-bundle-resource obj/components/chrome_manifest_bundle.gen/app_manifest/en.lproj/Localizable.strings\nFAILED: org.chromium.Chromium.manifest/Contents/Resources/en.lproj/Localizable.strings \nexport ALWAYS_SEARCH_USER_PATHS=NO; export ARCHS=x86_64; export BUILT_FRAMEWORKS_DIR=/Users/Morello/chromium/src/out/Release; export BUILT_PRODUCTS_DIR=/Users/Morello/chromium/src/out/Release; export SRCROOT=/Users/Morello/chromium/src/out/Release/../../components; export SOURCE_ROOT=\"${SRCROOT}\"; export CC=\"${SOURCE_ROOT}/../third_party/llvm-build/Release+Asserts/bin/clang\"; export CLANG_CXX_LANGUAGE_STANDARD=c++11; export CLANG_CXX_LIBRARY=libc++; export CLANG_LINK_OBJC_RUNTIME=NO; export CLANG_WARN_OBJC_MISSING_PROPERTY_SYNTHESIS=YES; export CONFIGURATION=Release; export CONTENTS_FOLDER_PATH=org.chromium.Chromium.manifest/Contents; export COPY_PHASE_STRIP=NO; export EXECUTABLE_NAME=org.chromium.Chromium; export EXECUTABLE_PATH=org.chromium.Chromium.manifest/Contents/MacOS/org.chromium.Chromium; export FULL_PRODUCT_NAME=org.chromium.Chromium.manifest; export GCC_CW_ASM_SYNTAX=NO; export GCC_C_LANGUAGE_STANDARD=c99; export GCC_DYNAMIC_NO_PIC=NO; export GCC_ENABLE_CPP_EXCEPTIONS=NO; export GCC_ENABLE_CPP_RTTI=NO; export GCC_ENABLE_PASCAL_STRINGS=NO; export GCC_INLINES_ARE_PRIVATE_EXTERN=YES; export GCC_OBJC_CALL_CXX_CDTORS=YES; export GCC_PRECOMPILE_PREFIX_HEADER=YES; export GCC_SYMBOLS_PRIVATE_EXTERN=YES; export GCC_THREADSAFE_STATICS=NO; export GCC_TREAT_WARNINGS_AS_ERRORS=YES; export GCC_VERSION=com.apple.compilers.llvm.clang.1_0; export INFOPLIST_PATH=org.chromium.Chromium.manifest/Contents/Info.plist; export LDPLUSPLUS=\"${SOURCE_ROOT}/../third_party/llvm-build/Release+Asserts/bin/clang++\"; export MACH_O_TYPE=mh_bundle; export MACOSX_DEPLOYMENT_TARGET=10.7; export OTHER_LDFLAGS=\"-Wl,-search_paths_first -Wl,-ObjC\"; export PRODUCT_NAME=org.chromium.Chromium; export PRODUCT_TYPE=com.apple.product-type.bundle; export SDKROOT=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk; export SHARED_PRECOMPS_DIR=\"${CONFIGURATION_BUILD_DIR}/SharedPrecompiledHeaders\"; export SYMROOT=../xcodebuild; export TARGET_BUILD_DIR=/Users/Morello/chromium/src/out/Release; export TEMP_DIR=\"${TMPDIR}\"; export UNLOCALIZED_RESOURCES_FOLDER_PATH=org.chromium.Chromium.manifest/Contents/Resources; export USE_HEADERMAP=NO; export WARNING_CFLAGS=\"-Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value\"; export WRAPPER_NAME=org.chromium.Chromium.manifest; export XCODE_VERSION_ACTUAL=0731; ./gyp-mac-tool copy-bundle-resource obj/components/chrome_manifest_bundle.gen/app_manifest/en.lproj/Localizable.strings org.chromium.Chromium.manifest/Contents/Resources/en.lproj/Localizable.strings False\nTraceback (most recent call last):\n  File \"./gyp-mac-tool\", line 709, in <module>\n    sys.exit(main(sys.argv[1:]))\n  File \"./gyp-mac-tool\", line 29, in main\n    exit_code = executor.Dispatch(args)\n  File \"./gyp-mac-tool\", line 44, in Dispatch\n    return getattr(self, method)(*args[1:])\n  File \"./gyp-mac-tool\", line 67, in ExecCopyBundleResource\n    self._CopyStringsFile(source, dest)\n  File \"./gyp-mac-tool\", line 133, in _CopyStringsFile\n    import CoreFoundation\nImportError: No module named CoreFoundation\n[6009/20363] ACTION base_nacl: build newlib plib_9b4f41e4158ebb93a5d28e6734a13e85\nninja: build stopped: subcommand failed.\nAny idea on what could it be?\n. Thanks, it seems its going to work after installing PyObjC with pip. My last attempt failed because my disk ran out of space during the build.\nI tried building again, this time after cleaning ~15GB of free space, but got this error:\nninja -C out/Release chrome\nninja: Entering directory `out/Release'\n[4631/8881] CXX obj/components/google/core/browser/google_core_browser.google_util.o\nFAILED: obj/components/google/core/browser/google_core_browser.google_util.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/components/google/core/browser/google_core_browser.google_util.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_WEBRTC=1 -DENABLE_MEDIA_ROUTER=1 -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DFIELDTRIAL_TESTING_ENABLED -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../skia/config -Igen/components/strings -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -gdwarf-2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -Xclang -load -Xclang /Users/Morello/chromium/src/third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.dylib -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-templates -Xclang -plugin-arg-find-bad-constructs -Xclang follow-macro-expansion -fcolor-diagnostics -fno-strict-aliasing  -c ../../components/google/core/browser/google_util.cc -o obj/components/google/core/browser/google_core_browser.google_util.o\n../../components/google/core/browser/google_util.cc:49:6: error: unused function 'IsValidHostName' [-Werror,-Wunused-function]\nbool IsValidHostName(base::StringPiece host,\n     ^\n../../components/google/core/browser/google_util.cc:80:6: error: unused function 'IsValidURL' [-Werror,-Wunused-function]\nbool IsValidURL(const GURL& url, google_util::PortPermission port_permission) {\n     ^\n2 errors generated.\n[4640/8881] CXX obj/components/feedback/feedback_component.feedback_uploader_delegate.o\nninja: build stopped: subcommand failed.\nCould this be related to leftover files from the previous build attempt? If so, what should I delete from out/Release?\n. @Eloston I just deleted every file on the out/Release folder, except gyp-mac-tool and the obj and gen folders. I got a different error this time:\nninja -C out/Release chrome\nninja: Entering directory `out/Release'\n[2712/6528] CXX obj/chrome/browser/extensions/browser_extensions.blacklist.o\nFAILED: obj/chrome/browser/extensions/browser_extensions.blacklist.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/chrome/browser/extensions/browser_extensions.blacklist.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_WEBRTC=1 -DENABLE_MEDIA_ROUTER=1 -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DFIELDTRIAL_TESTING_ENABLED -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DMOJO_USE_SYSTEM_IMPL -DTOOLKIT_VIEWS=1 -DPROTOBUF_USE_DLLS -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DSK_SUPPORT_GPU=1 -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DI18N_ADDRESSINPUT_USE_BASICTYPES_OVERRIDE=1 -DWEBRTC_CHROMIUM_BUILD -DWEBRTC_MAC -DWEBRTC_POSIX -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -Iobj/chrome/browser_extensions.gen -I../../third_party/khronos -I../../gpu -I../../skia/config -Igen/angle -I../../third_party/WebKit/Source -Igen/chrome -Igen/protoc_out -I../../third_party/protobuf -I../../third_party/protobuf/src -I../../third_party/dom_distiller_js/dist/proto_gen -Igen/policy -Igen/components -Igen/components/strings -Igen/content/app/resources/ -I../../third_party/WebKit -Igen/third_party/WebKit -Igen/extensions -Igen/extensions/strings -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/pdf -I../../third_party/skia/include/gpu -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/utils/mac -I../../skia/ext -I../../third_party/cacheinvalidation/overrides -I../../third_party/cacheinvalidation/src -I../../third_party/icu/source/i18n -I../../third_party/icu/source/common -I../../third_party/leveldatabase/src/include -I../../third_party/leveldatabase/src -I../../third_party/leveldatabase -I../../third_party/re2/src -I../../third_party/libaddressinput/chromium/override -I../../third_party/libaddressinput/src/cpp/include -Igen/third_party/libaddressinput/ -I../../third_party/webrtc_overrides -I../../third_party -Igen/ui/resources -Igen/ui/views/resources -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -gdwarf-2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wexit-time-destructors -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -Xclang -load -Xclang /Users/Morello/chromium/src/third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.dylib -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-templates -Xclang -plugin-arg-find-bad-constructs -Xclang follow-macro-expansion -fcolor-diagnostics -fno-strict-aliasing  -c ../../chrome/browser/extensions/blacklist.cc -o obj/chrome/browser/extensions/browser_extensions.blacklist.o\n../../chrome/browser/extensions/blacklist.cc:42:49: error: no member named 'safe_browsing_service' in 'BrowserProcess'\n    if (g_browser_process && g_browser_process->safe_browsing_service()) {\n                             ~~~~~~~~~~~~~~~~~  ^\n../../chrome/browser/extensions/blacklist.cc:44:30: error: no member named 'safe_browsing_service' in 'BrowserProcess'\n          g_browser_process->safe_browsing_service()->database_manager();\n          ~~~~~~~~~~~~~~~~~  ^\n2 errors generated.\nEdit: I found the following link. Is it related?\nhttps://src.chromium.org/svn/trunk/src/build/common.gypi\n```\n    # .gyp files or targets should set chromium_code to 1 if they build\n    # Chromium-specific code, as opposed to external code.  This variable is\n    # used to control such things as the set of warnings to enable, and\n    # whether warnings are treated as errors.\n    'chromium_code%': 0,\n# Disable fatal linker warnings, similarly to how we make it possible\n# to disable -Werror (e.g. for different toolchain versions).\n'disable_fatal_linker_warnings%': 0,\n\n```\n. Tried it again after running gclient runhooks and exporting the GYP flags one more time. Got this error now:\nninja -C out/Release chrome\nninja: Entering directory `out/Release'\n[13279/17901] CXX obj/components/google/core/browser/google_core_browser.google_util.o\nFAILED: obj/components/google/core/browser/google_core_browser.google_util.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/components/google/core/browser/google_core_browser.google_util.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../skia/config -Igen/components/strings -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -Xclang -load -Xclang /Users/Morello/chromium/src/third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.dylib -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-templates -Xclang -plugin-arg-find-bad-constructs -Xclang follow-macro-expansion -fcolor-diagnostics -fno-strict-aliasing  -c ../../components/google/core/browser/google_util.cc -o obj/components/google/core/browser/google_core_browser.google_util.o\n../../components/google/core/browser/google_util.cc:49:6: error: unused function 'IsValidHostName' [-Werror,-Wunused-function]\nbool IsValidHostName(base::StringPiece host,\n     ^\n../../components/google/core/browser/google_util.cc:80:6: error: unused function 'IsValidURL' [-Werror,-Wunused-function]\nbool IsValidURL(const GURL& url, google_util::PortPermission port_permission) {\n     ^\n2 errors generated.\n[13288/17901] CXX obj/components/feedback/feedback_component.feedback_uploader_delegate.o\nninja: build stopped: subcommand failed.\nShould I apply all the patches again? Here are the commands I Ctrl+V'd to the terminal to apply them:\n```\npatch -p1 -i third_party/WebKit/Source/iridium-browser/net-cert-increase-default-key-length-for-newly-gener.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/webrtc-disable-WebRTC-identity-store.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/webrtc-generate-real-ephemeral-keys.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/dns-send-IPv6-connectivity-probes-to-RIPE-DNS-rather.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/profile-resetter-do-not-tick-send-settings-by-defaul.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/browser-ui-disable-warning-about-missing-API-keys.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/mime_util-force-text-x-suse-ymp-to-be-downloaded.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/autofill-disable-autofill-download-manager.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-disable-Use-a-web-service-to-help-resolve-navi.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-disable-Use-a-prediction-service-to-help-compl.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-disable-network-DNS-prediction.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-block-third-party-cookies-by-default.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/cloud-print-disable-in-prefs-and-component-loader.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-disable-background-mode-by-default.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-disable-hyperlink-auditing.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-do-not-store-passwords-by-default.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-only-keep-cookies-until-exit.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-always-prompt-for-download-directory-by-defaul.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/first_run-barf-if-metrics_reporting-is-activated.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/prefs-disable-translation-service.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/first_run-deactivate-autoupdate-globally.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/build-build-the-sandbox-with-PIE.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/updater-disable-auto-update.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/Remove-EV-certificates.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/spellchecker-flag-downloading-dictionary-from-Google.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/google-cloud-messaging-disable-experiment-status-che.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/net-add-trk-scheme-and-help-identify-URLs-being-retr.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/updater-disable-updater-pings.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/safe_browsing-disable-incident-reporting.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/safe_browsing-disable-reporting-of-safebrowsing-over.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/safe_browsing-support-trk-prefix.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/safe_browsing-disable-cookie-transmission.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/all-add-trk-prefixes-to-possibly-evil-connections.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/promo-disable-Google-promotion-fetching.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/hotword-disable-at-build-time-by-default.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/google_now-disable-this.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/search-show-blank-tab-for-new-tab-page.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/browser-disable-profile-auto-import-on-first-run.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/extensions-always-show-component-extensions-in-the-e.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/battery_status_service-disable-more-privacy-nightmar.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/translate-disable-fetching-of-translate-languages-fr.patch\npatch -p1 -i third_party/WebKit/Source/iridium-browser/build-use-Wl-no-keep-memory.patch\npatch -p1 -i third_party/WebKit/Source/debian/disable/promo.patch\npatch -p1 -i third_party/WebKit/Source/debian/disable/google-api-warning.patch\npatch -p1 -i third_party/WebKit/Source/debian/disable/external-components.patch\npatch -p1 -i third_party/WebKit/Source/debian/disable/default-browser-warning.patch\npatch -p1 -i third_party/WebKit/Source/debian/ps-print.patch\npatch -p1 -i third_party/WebKit/Source/debian/gpu-timeout.patch\npatch -p1 -i third_party/WebKit/Source/debian/webui.patch\npatch -p1 -i third_party/WebKit/Source/inox-patchset/disable-autofill-download-manager.patch\npatch -p1 -i third_party/WebKit/Source/inox-patchset/disable-default-extensions.patch\npatch -p1 -i third_party/WebKit/Source/inox-patchset/disable-first-run-behaviour.patch\npatch -p1 -i third_party/WebKit/Source/inox-patchset/disable-google-url-tracker.patch\npatch -p1 -i third_party/WebKit/Source/inox-patchset/disable-new-avatar-menu.patch\npatch -p1 -i third_party/WebKit/Source/inox-patchset/disable-translation-lang-fetch.patch\npatch -p1 -i third_party/WebKit/Source/inox-patchset/modify-default-prefs.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-web-resource-service.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/clear-http-auth-cache-menu-item.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-crash-reporter.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-formatting-in-omnibox.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-google-host-detection.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-omnibox-searching.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-persistent-site-properties.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-signin.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-translate.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-unload-javascript-dialog-box.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/popups-to-tabs.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/prevent-trace-url-requests.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-untraceable-urls.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-ipv6-pinging.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-profile-avatar-downloading.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/remove-disable-setuid-sandbox-as-bad-flag.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/fix-building-without-safebrowsing.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-logging-urls-to-stderr.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/change-trace-infobar-message.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-copresence.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-gcm.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-domain-reliability.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/intercept-all-modified-domains.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/disable-intranet-redirect-detector.patch\npatch -p1 -i third_party/WebKit/Source/ungoogled-chromium/fix-building-without-one-click-signin.patch\n```\n. Hahaha I'm getting an strange behavior out of this.\nI just tried to run ninja -C out/Release chrome again, without changing or deleting anything. It went on for about 15 files, got the same error then stopped again. Then I ran the commance once more, and noticed the number of files to compile was smaler.\nninja -C out/Release chrome\nninja: Entering directory `out/Release'\n[7/4350] CXX obj/components/google/core/browser/google_core_browser.google_util.o\nFAILED: obj/components/google/core/browser/google_core_browser.google_util.o #... a big error\n../../components/google/core/browser/google_util.cc:49:6: error: unused function 'IsValidHostName' [-Werror,-Wunused-function]\nbool IsValidHostName(base::StringPiece host,\n     ^\n../../components/google/core/browser/google_util.cc:80:6: error: unused function 'IsValidURL' [-Werror,-Wunused-function]\nbool IsValidURL(const GURL& url, google_util::PortPermission port_permission) {\n     ^\n2 errors generated.\n[16/4350] CXX obj/content/utility/content_utility.utility_thread_impl.o\nninja: build stopped: subcommand failed.\nMorello$ ninja -C out/Release chrome\nninja: Entering directory `out/Release'\n[7/4335] CXX obj/components/google/core/browser/google_core_browser.google_util.o\nFAILED: obj/components/google/core/browser/google_core_browser.google_util.o  #... another big error\n../../components/google/core/browser/google_util.cc:49:6: error: unused function 'IsValidHostName' [-Werror,-Wunused-function]\nbool IsValidHostName(base::StringPiece host,\n     ^\n../../components/google/core/browser/google_util.cc:80:6: error: unused function 'IsValidURL' [-Werror,-Wunused-function]\nbool IsValidURL(const GURL& url, google_util::PortPermission port_permission) {\n     ^\n2 errors generated.\n[16/4335] CXX obj/components/leveldb/gen/comp...interfaces/leveldb_public_lib.leveldb.mojom.o\nninja: build stopped: subcommand failed.\nninja -C out/Release chrome\nninja: Entering directory `out/Release'\n[18/4320] CXX obj/components/google/core/browser/google_core_browser.google_util.o\nFAILED: obj/components/google/core/browser/google_core_browser.google_util.o #one more big error\n../../components/google/core/browser/google_util.cc:49:6: error: unused function 'IsValidHostName' [-Werror,-Wunused-function]\nbool IsValidHostName(base::StringPiece host,\n     ^\n../../components/google/core/browser/google_util.cc:80:6: error: unused function 'IsValidURL' [-Werror,-Wunused-function]\nbool IsValidURL(const GURL& url, google_util::PortPermission port_permission) {\n     ^\n2 errors generated.\n[27/4320] CXX obj/content/public/browser/content_browser.browser_message_filter.o\nninja: build stopped: subcommand failed.\nBasically its getting an error every 15 or 16 files, but the number of files to compile keeps getting smaller. I wonder what happens if I keep running this command until I get to 0.\n. Thanks for responding.\nI'm left with 99 files to compile.  I've edited some of them, but I don't know how to get rid of this error:\nIn file included from ../../chrome/browser/ui/cocoa/one_click_signin_bubble_controller.mm:5:\n../../chrome/browser/ui/cocoa/one_click_signin_bubble_controller.h:39:61: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n                             callback:(const BrowserWindow::StartSyncCallback&)\n                                             ~~~~~~~~~~~~~~~^\nIn file included from ../../chrome/browser/ui/cocoa/one_click_signin_bubble_controller.mm:10:\n../../chrome/browser/ui/cocoa/one_click_signin_view_controller.h:46:18: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n  BrowserWindow::StartSyncCallback startSyncCallback_;\n  ~~~~~~~~~~~~~~~^\n../../chrome/browser/ui/cocoa/one_click_signin_view_controller.h:58:45: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n         syncCallback:(const BrowserWindow::StartSyncCallback&)syncCallback\n                             ~~~~~~~~~~~~~~~^\n../../chrome/browser/ui/cocoa/one_click_signin_bubble_controller.mm:27:61: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n                             callback:(const BrowserWindow::StartSyncCallback&)\n                                             ~~~~~~~~~~~~~~~^\n4 errors generated.\nThat seems strange, why am I seeing sync things? Are they normally compiled?\nIt seems they are OSX-specific UI files.\n. Thanks, I'll be here all day long so take your time.\nCan I just apply the patch normally or do I need to start compiling from scratch?\n. Strange, I got the same error at the same place despite applying the patch.\n```\nMorello$ patch -p1 -i osx_patch1.patch\npatching file chrome/chrome_browser_ui.gypi\npatch unexpectedly ends in middle of line\nHunk #1 succeeded at 3351 with fuzz 1.\nand later on...\nIn file included from ../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.mm:5:\n../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.h:30:28: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n      const BrowserWindow::StartSyncCallback& sync_callback,\n            ~~~~~~~~~~~~~~~^\nIn file included from ../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.mm:11:\n../../chrome/browser/ui/cocoa/one_click_signin_view_controller.h:46:18: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n  BrowserWindow::StartSyncCallback startSyncCallback_;\n  ~~~~~~~~~~~~~~~^\n../../chrome/browser/ui/cocoa/one_click_signin_view_controller.h:58:45: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n         syncCallback:(const BrowserWindow::StartSyncCallback&)syncCallback\n                             ~~~~~~~~~~~~~~~^\n../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.mm:15:26: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n    const BrowserWindow::StartSyncCallback& sync_callback,\n          ~~~~~~~~~~~~~~~^\nIn file included from ../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.mm:5:\n../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.h:23:1: error: [chromium-style] Complex class/struct needs an explicit out-of-line constructor.\nclass OneClickSigninDialogController : public ConstrainedWindowMacDelegate {\n^\n5 errors generated.\n```\n. We did it man! Compiled, up and running.\n\nThanks for the help. I had to comment some files as the errors were appearing but it worked out. Confirmed working on OS X El Capitan.\n. So, I'll write everything I did. I had previously installed Python through Homebrew, so I expect steps to vary a little if you don't.\nRequirements:\nAll the official requirements to build Chromium on OS X, plus:\nHomebrew (to install GNU Patch)\nPatches for your target release (in my case, 51.0.2704.106). You can find them in the Ungoogled Chromium release page.\nFirst, follow the official instruction to get the Chromium source code on your PC. You need at least ~16GB of free space to download it. To build it, I recommend having 20+GB of free space. I don't know how many GBs you need, but at my first attempt I ran out of space while having ~10GB free before.\nAfter downloading it, run:\n```\nBelow, put your target release version\ngit checkout -f 51.0.2704.106\ngclient sync -R --nohooks --with_branch_heads\n```\nAfter that, you need to apply the patches. Install GNU Patch using Homebrew.\nbrew install homebrew/dupes/gpatch\nThen, copy the patch folders you're going to use to the src folder, and apply them. Here is a scratch of what I used:\n```\npatch -p1 -i /iridium-browser/net-cert-increase-default-key-length-for-newly-gener.patch\npatch -p1 -i /iridium-browser/webrtc-disable-WebRTC-identity-store.patch\npatch -p1 -i /iridium-browser/webrtc-generate-real-ephemeral-keys.patch\npatch -p1 -i /iridium-browser/dns-send-IPv6-connectivity-probes-to-RIPE-DNS-rather.patch\npatch -p1 -i /iridium-browser/profile-resetter-do-not-tick-send-settings-by-defaul.patch\npatch -p1 -i /iridium-browser/browser-ui-disable-warning-about-missing-API-keys.patch\npatch -p1 -i /iridium-browser/mime_util-force-text-x-suse-ymp-to-be-downloaded.patch\npatch -p1 -i /iridium-browser/autofill-disable-autofill-download-manager.patch\npatch -p1 -i /iridium-browser/prefs-disable-Use-a-web-service-to-help-resolve-navi.patch\npatch -p1 -i /iridium-browser/prefs-disable-Use-a-prediction-service-to-help-compl.patch\npatch -p1 -i /iridium-browser/prefs-disable-network-DNS-prediction.patch\npatch -p1 -i /iridium-browser/prefs-block-third-party-cookies-by-default.patch\npatch -p1 -i /iridium-browser/cloud-print-disable-in-prefs-and-component-loader.patch\npatch -p1 -i /iridium-browser/prefs-disable-background-mode-by-default.patch\npatch -p1 -i /iridium-browser/prefs-disable-hyperlink-auditing.patch\npatch -p1 -i /iridium-browser/prefs-do-not-store-passwords-by-default.patch\npatch -p1 -i /iridium-browser/prefs-only-keep-cookies-until-exit.patch\npatch -p1 -i /iridium-browser/prefs-always-prompt-for-download-directory-by-defaul.patch\npatch -p1 -i /iridium-browser/first_run-barf-if-metrics_reporting-is-activated.patch\npatch -p1 -i /iridium-browser/prefs-disable-translation-service.patch\npatch -p1 -i /iridium-browser/first_run-deactivate-autoupdate-globally.patch\npatch -p1 -i /iridium-browser/build-build-the-sandbox-with-PIE.patch\npatch -p1 -i /iridium-browser/updater-disable-auto-update.patch\npatch -p1 -i /iridium-browser/Remove-EV-certificates.patch\npatch -p1 -i /iridium-browser/spellchecker-flag-downloading-dictionary-from-Google.patch\npatch -p1 -i /iridium-browser/google-cloud-messaging-disable-experiment-status-che.patch\npatch -p1 -i /iridium-browser/net-add-trk-scheme-and-help-identify-URLs-being-retr.patch\npatch -p1 -i /iridium-browser/updater-disable-updater-pings.patch\npatch -p1 -i /iridium-browser/safe_browsing-disable-incident-reporting.patch\npatch -p1 -i /iridium-browser/safe_browsing-disable-reporting-of-safebrowsing-over.patch\npatch -p1 -i /iridium-browser/safe_browsing-support-trk-prefix.patch\npatch -p1 -i /iridium-browser/safe_browsing-disable-cookie-transmission.patch\npatch -p1 -i /iridium-browser/all-add-trk-prefixes-to-possibly-evil-connections.patch\npatch -p1 -i /iridium-browser/promo-disable-Google-promotion-fetching.patch\npatch -p1 -i /iridium-browser/hotword-disable-at-build-time-by-default.patch\npatch -p1 -i /iridium-browser/google_now-disable-this.patch\npatch -p1 -i /iridium-browser/search-show-blank-tab-for-new-tab-page.patch\npatch -p1 -i /iridium-browser/browser-disable-profile-auto-import-on-first-run.patch\npatch -p1 -i /iridium-browser/extensions-always-show-component-extensions-in-the-e.patch\npatch -p1 -i /iridium-browser/battery_status_service-disable-more-privacy-nightmar.patch\npatch -p1 -i /iridium-browser/translate-disable-fetching-of-translate-languages-fr.patch\npatch -p1 -i /iridium-browser/build-use-Wl-no-keep-memory.patch\npatch -p1 -i /debian/disable/promo.patch\npatch -p1 -i /debian/disable/google-api-warning.patch\npatch -p1 -i /debian/disable/external-components.patch\npatch -p1 -i /debian/disable/default-browser-warning.patch\npatch -p1 -i /debian/ps-print.patch\npatch -p1 -i /debian/gpu-timeout.patch\npatch -p1 -i /debian/webui.patch\npatch -p1 -i /inox-patchset/disable-autofill-download-manager.patch\npatch -p1 -i /inox-patchset/disable-default-extensions.patch\npatch -p1 -i /inox-patchset/disable-first-run-behaviour.patch\npatch -p1 -i /inox-patchset/disable-google-url-tracker.patch\npatch -p1 -i /inox-patchset/disable-new-avatar-menu.patch\npatch -p1 -i /inox-patchset/disable-translation-lang-fetch.patch\npatch -p1 -i /inox-patchset/modify-default-prefs.patch\npatch -p1 -i /ungoogled-chromium/disable-web-resource-service.patch\npatch -p1 -i /ungoogled-chromium/clear-http-auth-cache-menu-item.patch\npatch -p1 -i /ungoogled-chromium/disable-crash-reporter.patch\npatch -p1 -i /ungoogled-chromium/disable-formatting-in-omnibox.patch\npatch -p1 -i /ungoogled-chromium/disable-google-host-detection.patch\npatch -p1 -i /ungoogled-chromium/disable-omnibox-searching.patch\npatch -p1 -i /ungoogled-chromium/disable-persistent-site-properties.patch\npatch -p1 -i /ungoogled-chromium/disable-signin.patch\npatch -p1 -i /ungoogled-chromium/disable-translate.patch\npatch -p1 -i /ungoogled-chromium/disable-unload-javascript-dialog-box.patch\npatch -p1 -i /ungoogled-chromium/popups-to-tabs.patch\npatch -p1 -i /ungoogled-chromium/prevent-trace-url-requests.patch\npatch -p1 -i /ungoogled-chromium/disable-untraceable-urls.patch\npatch -p1 -i /ungoogled-chromium/disable-ipv6-pinging.patch\npatch -p1 -i /ungoogled-chromium/disable-profile-avatar-downloading.patch\npatch -p1 -i /ungoogled-chromium/remove-disable-setuid-sandbox-as-bad-flag.patch\npatch -p1 -i /ungoogled-chromium/fix-building-without-safebrowsing.patch\npatch -p1 -i /ungoogled-chromium/disable-logging-urls-to-stderr.patch\npatch -p1 -i /ungoogled-chromium/change-trace-infobar-message.patch\npatch -p1 -i /ungoogled-chromium/disable-copresence.patch\npatch -p1 -i /ungoogled-chromium/disable-gcm.patch\npatch -p1 -i /ungoogled-chromium/disable-domain-reliability.patch\npatch -p1 -i /ungoogled-chromium/intercept-all-modified-domains.patch\npatch -p1 -i /ungoogled-chromium/disable-intranet-redirect-detector.patch\npatch -p1 -i /ungoogled-chromium/fix-building-without-one-click-signin.patch\n```\nYou'll also need to apply the patch posted by @Eloston in this thread.\nThen, delete every file listed in the cleaning_list file. I don't remember what command I used to do it automatically, but you can find it one in your favorite search engine (probably not Google if you're here).\nIf you, for some reason, installed Python through Homebrew, then install PyObjC for it:\npip install -U pyobjc\nThis one might take some time to install.\nAfter applying the patches and deleting the files, run this to prepare the build:\nbuild/gyp_chromium -Dremove_webcore_debug_symbols=1 -Dffmpeg_branding=Chromium -Dproprietary_codecs=1 -Dlinux_strip_binary=1 -Dfieldtrial_testing_like_official_build=1 -Dtracing_like_official_build=1 -Ddisable_fatal_linker_warnings=1 -Dfastbuild=1 -Denable_hidpi=1-Denable_one_click_signin=0 -Denable_prod_wallet_service=0 -Denable_pre_sync_backup=0 -Denable_rlz=0 -Duse_official_google_api_keys=0 -Denable_wifi_bootstrapping=0 -Denable_hangout_services_extension=0 -Denable_hotwording=0 -Dremoting=0 -Denable_webrtc=0 -Dsafe_browsing=0 -Denable_google_now=0 -Denable_automation=0 -Denable_remoting_host=0 -Ddisable_newlib=1 -Ddisable_pnacl=1 -Ddisable_nacl=1 -Dremoting=0 -Ddefault_apps_list_linux_dest=[] -Ddefault_apps_list=[] -Dwerror= -Dwunused-function=\nThen this, to start building:\nninja -C out/Release chrome\nIn an ideal world, this should just work. But, for some reason, my clang refused to proceed every time it found an unused function or variable. So, if you happen to run into the same issue, you'll need to read the errors, check which files have unused variables/functions and comment them.\nThis build is missing the domain substitution in the source code, but it works as intended. I have not seen any connection attempt by just opening it, nor seen it trying to talk to Google. Still, do not forget to install uBlock Origin. Do it from source instead of Store, if possible.\nIt took quite some time to build it, so I might be forgetting some step.\nAgain, thanks to @Eloston for helping me and making those wonderful patches.\n. @Eloston a question: was there supposed to be an \"Get more extensions\" button on the Extensions page? Might be my memory but I don't remember it being there on Linux.\n. @Eloston Any chance we can modify generic.py to make it work on OS X? Thats the error I get when trying to use it:\npython generic.py\n  File \"generic.py\", line 263\n    def _run_subprocess(self, *args, append_environ=None, **kwargs):\n                                                  ^\nSyntaxError: invalid syntax\n. @Eloston I see. I'll check the Iridium build script and see if I can adapt it to work with Ungoogled Chromium. Seems fairly simple to modify and it will help creating more general instructions.\nI will start testing as soon as I get free space to build Iridium.\n. I just tried it. Seemed to download fine, and then I got this error:\nMorello$ python3 build_macos.py\n2016-08-14 18:25:57,363 - INFO: Sandbox root does not exist. Creating...\n2016-08-14 18:25:57,363 - INFO: ungoogled_dir does not exist. Creating...\n2016-08-14 18:25:57,363 - INFO: Downloading chromium-51.0.2704.106.tar.xz ...\n2016-08-14 18:49:34,475 - INFO: Downloading chromium-51.0.2704.106.tar.xz.hashes ...\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 57, in main\n    platform.setup_chromium_source()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 365, in setup_chromium_source\n    self._download_helper(self.sourcearchive_hashes, force_download, check_if_exists, self._download_source_hashes)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 158, in _download_helper\n    downloader()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 151, in _download_source_hashes\n    self._download_file(download_url, self.sourcearchive_hashes)\nNameError: name 'download_url' is not defined\n. It proceeded further now, got this error:\npython3 build_macos.py\n2016-08-14 19:26:37,475 - INFO: chromium-51.0.2704.106.tar.xz already exists. Skipping download.\n2016-08-14 19:26:37,475 - INFO: chromium-51.0.2704.106.tar.xz.hashes already exists. Skipping download.\n2016-08-14 19:26:37,475 - INFO: Checking source archive integrity...\n2016-08-14 19:26:37,476 - DEBUG: Running 'md5' hash check...\n2016-08-14 19:26:38,415 - DEBUG: Running 'sha1' hash check...\n2016-08-14 19:26:39,349 - DEBUG: Running 'sha224' hash check...\n2016-08-14 19:26:41,019 - DEBUG: Running 'sha256' hash check...\n2016-08-14 19:26:42,621 - DEBUG: Running 'sha384' hash check...\n2016-08-14 19:26:43,856 - DEBUG: Running 'sha512' hash check...\n2016-08-14 19:26:45,131 - INFO: Extracting source archive into building sandbox...\n2016-08-14 19:26:45,134 - WARNING: Symlinks not supported. Will ignore all symlinks\n2016-08-14 19:28:26,189 - INFO: Running domain substitution over build sandbox...\n2016-08-14 19:28:37,799 - INFO: Applying patches via 'patch -p1 -i' ...\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 59, in main\n    platform.apply_patches() # Change the command for GNU patch here\n  File \"/Users/Morello/ungoogled-chromium/buildlib/macos.py\", line 26, in apply_patches\n    self._generate_patches(self.sandbox_patches, self._ran_domain_substitution)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 242, in _generate_patches\n    platform_patch_order = self.PLATFORM_RESOURCES / self.PATCHES / self.PATCH_ORDER\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/pathlib.py\", line 879, in __rtruediv__\n    return self._from_parts([key] + self._parts)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/pathlib.py\", line 638, in _from_parts\n    drv, root, parts = self._parse_args(args)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/pathlib.py\", line 630, in _parse_args\n    % type(a))\nTypeError: argument should be a path or str object, not <class 'NoneType'>\nI also changed the arguments of patch to -p1 -i to install them. Before it didn't work with just -p1.\nI'm currently using the clang version provided by Xcode, not Homebrew:\nMorello$ clang --version\nApple LLVM version 7.3.0 (clang-703.0.31)\nTarget: x86_64-apple-darwin15.6.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\nI'll install it through homebrew and see what happens.\n. Ok, its almost starting to compile. Got this error now:\n```\n2016-08-14 20:16:09,132 - DEBUG: Applying patch ungoogled-chromium/disable-windows-zone-identifier.patch ...\npatching file content/browser/safe_util_win.cc\n2016-08-14 20:16:09,136 - INFO: Running gyp command...\n2016-08-14 20:16:09,137 - DEBUG: GYP command: python build/gyp_chromium --depth=. --check -Denable_one_click_signin=0 -Denable_pre_sync_backup=0 -Denable_wifi_bootstrapping=0 -Denable_hidpi=1 -Denable_google_now=0 -Dtracing_like_official_build=1 -Denable_webrtc=0 -Ddisable_pnacl=1 -Dffmpeg_branding=Chrome -Dfastbuild=1 -Dwerror= -Ddisable_fatal_linker_warnings=1 -Dproprietary_codecs=1 -Denable_rlz=0 -Dremoting=0 -Duse_official_google_api_keys=0 -Ddefault_apps_list=[] -Denable_prod_wallet_service=0 -Dlinux_strip_binary=1 -Dsafe_browsing=0 -Ddefault_apps_list_linux_dest=[] -Denable_automation=0 -Ddisable_nacl=1 -Dfieldtrial_testing_like_official_build=1 -Denable_hangout_services_extension=0 -Denable_hotwording=0 -Ddisable_newlib=1 -Denable_remoting_host=0 -Dremove_webcore_debug_symbols=1\nUpdating projects from gyp files...\n2016-08-14 20:16:55,189 - INFO: Running build command...\nninja: Entering directory `out/Release'\nninja: error: '../../third_party/pdfsqueeze/pdfsqueeze.m', needed by 'obj/third_party/pdfsqueeze/pdfsqueeze.pdfsqueeze.o', missing and no known rule to make it\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in \n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n```\n. It seems that only pdfsqueeze and some files from google_toolbox_for_mac are missing. I've copied them from the old build folder and it started to build.\nHowever, it seems I fucked up something by installing clang from brew...\n```\nninja: Entering directory `out/Release'\n[4/19472] CC obj/third_party/libpng/libpng.pngmem.o\nFAILED: obj/third_party/libpng/libpng.pngmem.o \n../../third_party/llvm-build/Release+Asserts/bin/clang -MMD -MF obj/third_party/libpng/libpng.pngmem.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DCHROME_PNG_WRITE_SUPPORT -DPNG_USER_CONFIG -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/zlib -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-self-assign -Wno-unused-variable -std=c99 -Xclang -load -Xclang /Users/Morello/ungoogled-chromium/build_sandbox/third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.dylib -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-templates -Xclang -plugin-arg-find-bad-constructs -Xclang follow-macro-expansion -fcolor-diagnostics -fno-strict-aliasing  -c ../../third_party/libpng/pngmem.c -o obj/third_party/libpng/libpng.pngmem.o\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang: No such file or directory\n[13/19472] ACTION js2c: js2c_3be296d1a8596ff6585e83c8932d0107\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in \n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n```\n. This one: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang\n. Thats strange, it didn't find it somehow. I just accessed the directory and clang is there.\n```\n/bin/sh: ../..//Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang: No such file or directory\n[10/19472] ACTION Generating resources from ../webui/resources/webui_resources.grd\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in \n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n```\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang is literally what appears if I drag and drop clang into OSX's terminal. Its also on pair with the output of clang --version that I posted before.\nEdit: I tested it with Homebrew's clang and got the same error. No idea why it can't find it.\n/bin/sh: ../..//usr/local/opt/llvm/bin/clang: No such file or directory\n[10/19472] CC obj/third_party/libusb/src/libusb/os/libusb.darwin_usb.o\nFAILED: obj/third_party/libusb/src/libusb/os/libusb.darwin_usb.o \n../../'/usr/local/opt/llvm'/bin/clang -MMD -MF obj/third_party/libusb/src/libusb/os/libusb.darwin_usb.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DDEFAULT_VISIBILITY= -DHAVE_GETTIMEOFDAY=1 -DHAVE_POLL_H=1 -DHAVE_SYS_TIME_H=1 '-DLIBUSB_DESCRIBE=\"1.0.16\"' -DPOLL_NFDS_TYPE=nfds_t -DTHREADS_POSIX=1 -DOS_DARWIN=1 -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/libusb/src -I../../third_party/libusb/src/libusb -I../../third_party/libusb/src/libusb/os -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-unused-function -Wno-unused-variable -std=c99 -fcolor-diagnostics -fno-strict-aliasing  -c ../../third_party/libusb/src/libusb/os/darwin_usb.c -o obj/third_party/libusb/src/libusb/os/libusb.darwin_usb.o\n/bin/sh: ../..//usr/local/opt/llvm/bin/clang: No such file or directory\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n. @Eloston It worked! Now, it compiles for some time, but I'm getting this error now:\n[1439/19472] CC obj/third_party/opus/src/celt/opus.celt_lpc.o\nFAILED: obj/third_party/opus/src/celt/opus.celt_lpc.o \ncc -MMD -MF obj/third_party/opus/src/celt/opus.celt_lpc.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DOPUS_BUILD -DOPUS_EXPORT= -DHAVE_LRINT -DHAVE_LRINTF -DVAR_ARRAYS -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/opus/src/celt -I../../third_party/opus/src/include -I../../third_party/opus/src/silk -I../../third_party/opus/src/silk/float -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-expansion-to-defined -Wno-unused-variable -Wno-#pragma-messages -std=c99 -fcolor-diagnostics -fno-strict-aliasing  -c ../../third_party/opus/src/celt/celt_lpc.c -o obj/third_party/opus/src/celt/opus.celt_lpc.o\nerror: unknown warning option '-Wno-expansion-to-defined'; did you mean '-Wno-macro-redefined'? [-Werror,-Wunknown-warning-option]\n[1448/19472] CXX obj/third_party/pdfiu...fpdf_render/fpdfapi.fpdf_render_text.o\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n. Got the same error.\nninja: Entering directory `out/Release'\n[1313/19472] CC obj/third_party/opus/src/celt/opus.celt_lpc.o\nFAILED: obj/third_party/opus/src/celt/opus.celt_lpc.o \ncc -MMD -MF obj/third_party/opus/src/celt/opus.celt_lpc.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DOPUS_BUILD -DOPUS_EXPORT= -DHAVE_LRINT -DHAVE_LRINTF -DVAR_ARRAYS -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/opus/src/celt -I../../third_party/opus/src/include -I../../third_party/opus/src/silk -I../../third_party/opus/src/silk/float -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-expansion-to-defined -Wno-unused-variable -Wno-#pragma-messages -std=c99 -fcolor-diagnostics -fno-strict-aliasing  -c ../../third_party/opus/src/celt/celt_lpc.c -o obj/third_party/opus/src/celt/opus.celt_lpc.o\nerror: unknown warning option '-Wno-expansion-to-defined'; did you mean '-Wno-macro-redefined'? [-Werror,-Wunknown-warning-option]\n[1322/19472] CXX obj/third_party/pdfiu...fpdf_render/fpdfapi.fpdf_render_text.o\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n. I'm sorry, where is cflags_cc?\nTried compiling with the cflags='-Wno-error=unknown-warning-option' flag, same error.\n. Ok, the patch seems to have done the job. Its compiling now!\nEdit: nope.jpg\nGot an error.\n[5815/18503] CXX obj/third_party/cacheinvalidation/src/google/cacheinvalidation/impl/cacheinvalidation.safe-storage.o\nFAILED: obj/third_party/cacheinvalidation/src/google/cacheinvalidation/impl/cacheinvalidation.safe-storage.o \nc++ -MMD -MF obj/third_party/cacheinvalidation/src/google/cacheinvalidation/impl/cacheinvalidation.safe-storage.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DPROTOBUF_USE_DLLS -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../../third_party/cacheinvalidation/overrides -I../../third_party/cacheinvalidation/src -I../.. -I../../third_party/cacheinvalidation/google/cacheinvalidation -Igen/protoc_out -I../../third_party/protobuf -I../../third_party/protobuf/src -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing  -c ../../third_party/cacheinvalidation/src/google/cacheinvalidation/impl/safe-storage.cc -o obj/third_party/cacheinvalidation/src/google/cacheinvalidation/impl/cacheinvalidation.safe-storage.o\nIn file included from ../../third_party/cacheinvalidation/src/google/cacheinvalidation/impl/safe-storage.cc:19:\nIn file included from ../../third_party/cacheinvalidation/src/google/cacheinvalidation/impl/safe-storage.h:22:\nIn file included from ../../third_party/cacheinvalidation/src/google/cacheinvalidation/include/system-resources.h:26:\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/string:439:\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/algorithm:627:\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/utility:264:58: error: no matching constructor for initialization of 'invalidation::Status'\n    _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR pair() : first(), second() {}\n                                                         ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/type_traits:2375:38: note: in instantiation of member function 'std::__1::pair<invalidation::Status, std::__1::basic_string<char> >::pair' requested here\n    : public integral_constant<bool, __is_constructible(_Tp, _Args...)>\n                                     ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/type_traits:2679:14: note: in instantiation of template class 'std::__1::is_constructible<std::__1::pair<invalidation::Status, std::__1::basic_string<char> >>' requested here\n    : public is_constructible<_Tp>\n             ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/tuple:387:13: note: in instantiation of template class 'std::__1::is_default_constructible<std::__1::pair<invalidation::Status, std::__1::basic_string<char> > >' requested here\n    : __all<is_default_constructible<_Tp>::value...>\n            ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/tuple:636:26: note: in instantiation of template class 'std::__1::__all_default_constructible<std::__1::__tuple_types<base::internal::OwnedWrapper<base::Callback<void (std::__1::pair<invalidation::Status, std::__1::basic_string<char> >), base::internal::CopyMode::Copyable> >, std::__1::pair<invalidation::Status, std::__1::basic_string<char> > > >' requested here\n                         __all_default_constructible<\n                         ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/tuple:645:9: note: in instantiation of default argument for 'tuple<std::__1::pair<invalidation::Status, std::__1::basic_string<char> >>' required here\n        tuple(allocator_arg_t, const _Alloc& __a, _Up&&... __u)\n        ^~~~~\n../../base/bind_internal.h:432:9: note: while substituting deduced template arguments into function template 'tuple' [with _Alloc = std::__1::pair<invalidation::Status, std::__1::basic_string<char> >, _Up = <>, $2 = (no value)]\n        bound_args_(std::forward<ForwardArgs>(bound_args)...) {}\n        ^\n../../base/bind.h:106:11: note: in instantiation of function template specialization 'base::internal::BindState<base::internal::RunnableAdapter<void (base::Callback<void (std::__1::pair<invalidation::Status, std::__1::basic_string<char> >), base::internal::CopyMode::Copyable>::*)(std::__1::pair<invalidation::Status, std::__1::basic_string<char> >) const>, void (const base::Callback<void (std::__1::pair<invalidation::Status, std::__1::basic_string<char> >), base::internal::CopyMode::Copyable> *, std::__1::pair<invalidation::Status, std::__1::basic_string<char> >), base::internal::OwnedWrapper<base::Callback<void (std::__1::pair<invalidation::Status, std::__1::basic_string<char> >), base::internal::CopyMode::Copyable> >, std::__1::pair<invalidation::Status, std::__1::basic_string<char> > &>::BindState<base::internal::OwnedWrapper<base::Callback<void (std::__1::pair<invalidation::Status, std::__1::basic_string<char> >), base::internal::CopyMode::Copyable> >, std::__1::pair<invalidation::Status, std::__1::basic_string<char> > &>' requested here\n      new BindState(internal::MakeRunnable(functor),\n          ^\n../../third_party/cacheinvalidation/overrides/google/cacheinvalidation/deps/callback.h:129:38: note: in instantiation of function template specialization 'base::Bind<void (base::Callback<void (std::__1::pair<invalidation::Status, std::__1::basic_string<char> >), base::internal::CopyMode::Copyable>::*)(std::__1::pair<invalidation::Status, std::__1::basic_string<char> >) const, base::internal::OwnedWrapper<base::Callback<void (std::__1::pair<invalidation::Status, std::__1::basic_string<char> >), base::internal::CopyMode::Copyable> >, std::__1::pair<invalidation::Status, std::__1::basic_string<char> > &>' requested here\n  return new ::base::Closure(::base::Bind(\n                                     ^\n../../third_party/cacheinvalidation/src/google/cacheinvalidation/impl/safe-storage.cc:48:26: note: in instantiation of function template specialization 'invalidation::NewPermanentCallback<std::__1::pair<invalidation::Status, std::__1::basic_string<char> > >' requested here\n      /* Owns 'done'. */ NewPermanentCallback(done, read_result));\n                         ^\n../../third_party/cacheinvalidation/src/google/cacheinvalidation/include/types.h:316:7: note: candidate constructor (the implicit move constructor) not viable: requires 1 argument, but 0 were provided\nclass Status {\n      ^\n../../third_party/cacheinvalidation/src/google/cacheinvalidation/include/types.h:316:7: note: candidate constructor (the implicit copy constructor) not viable: requires 1 argument, but 0 were provided\n../../third_party/cacheinvalidation/src/google/cacheinvalidation/include/types.h:339:3: note: candidate constructor not viable: requires 2 arguments, but 0 were provided\n  Status(Code code, const string& message) : code_(code), message_(message) {}\n  ^\n1 error generated.\n[5824/18503] CXX obj/third_party/cacheinvalidation/src/google/cacheinvalidation/impl/cacheinvalidation.throttle.o\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\nNot sure if relevant but I got a warning when running the patch:\npatching file third_party/opus/opus.gyp\npatch unexpectedly ends in middle of line\nHunk #1 succeeded at 62 with fuzz 1.\nIt was supposed to be ran inside build_sandbox, right?\nEdit: from that I've tested, it seems changing clang_dir does nothing if I use clang_xcode=1.\n. No problem, good to see you're alive.\nHere is the output out clang --version:\nMorello$ clang --version\nApple LLVM version 7.3.0 (clang-703.0.31)\nTarget: x86_64-apple-darwin15.6.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\nDo you know if clang_dir is deprecated? Seemed that it just tried to use google's clang when I removed clang_xcode=1.\nAlso, should I try to copy that file from the source tree I downloaded from Google? Any chance they are different?\n. @Eloston I was talking about cacheinvalidation.throttle.o (the file the compiler failed on last time). I thought the problem could be a difference between the sources.\nI'll try to compile with those parameters and post the result.\n. It didn't find the clang++ binary somehow.\nFAILED: obj/v8/src/base/platform/v8_libbase.condition-variable.o \n../../'/usr/local/Cellar/llvm/3.8.1'/bin/clang++ -MMD -MF obj/v8/src/base/platform/v8_libbase.condition-variable.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DV8_TARGET_ARCH_X64 -DV8_I18N_SUPPORT -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../../v8 -Igen -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O3 -fstrict-aliasing -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-unused-variable -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing  -c ../../v8/src/base/platform/condition-variable.cc -o obj/v8/src/base/platform/v8_libbase.condition-variable.o\n/bin/sh: ../..//usr/local/Cellar/llvm/3.8.1/bin/clang++: No such file or directory\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\nIs strange, since I can literally drag clang and clang++ to the terminal and confirm that its path is /usr/local/Cellar/llvm/3.8.1/bin.\nHere is how gyp_flags currently is now:\nwerror=\ndefault_apps_list=[]\ndefault_apps_list_linux_dest=[]\nremoting=0\ndisable_nacl=1\ndisable_pnacl=1\ndisable_newlib=1\nenable_remoting_host=0\nenable_automation=0\nenable_google_now=0\nsafe_browsing=0\nenable_webrtc=0\nremoting=0\nenable_hotwording=0\nenable_hangout_services_extension=0\nenable_wifi_bootstrapping=0\nuse_official_google_api_keys=0\nenable_rlz=0\nenable_pre_sync_backup=0\nenable_prod_wallet_service=0\nenable_one_click_signin=0\nenable_hidpi=1\nfastbuild=1\ndisable_fatal_linker_warnings=1\ntracing_like_official_build=1\nfieldtrial_testing_like_official_build=1\nlinux_strip_binary=1\nproprietary_codecs=1\nffmpeg_branding=Chrome\nremove_webcore_debug_symbols=1\nclang_dir='/usr/local/Cellar/llvm/3.8.1/bin'\nmake_clang_dir='/usr/local/Cellar/llvm/3.8.1'\nclang_use_chrome_plugins=0\nclang=1\nhost_cc='/usr/local/Cellar/llvm/3.8.1/bin'\nCC='/usr/local/Cellar/llvm/3.8.1/bin'\nhost_cxx='/usr/local/Cellar/llvm/3.8.1/bin'\nLDPLUSPLUS='/usr/local/Cellar/llvm/3.8.1/bin'\n. It seems it doesn't like quotation marks. Removed them and it started compiling. Lets see what happens.\n. Got an error:\n```\nninja: Entering directory `out/Release'\n[14838/19472] CXX obj/components/googl...wser/google_core_browser.google_util.o\nFAILED: obj/components/google/core/browser/google_core_browser.google_util.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang++ -MMD -MF obj/components/google/core/browser/google_core_browser.google_util.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../skia/config -Igen/components/strings -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing  -c ../../components/google/core/browser/google_util.cc -o obj/components/google/core/browser/google_core_browser.google_util.o\n../../components/google/core/browser/google_util.cc:49:6: error: unused function 'IsValidHostName' [-Werror,-Wunused-function]\nbool IsValidHostName(base::StringPiece host,\n     ^\n../../components/google/core/browser/google_util.cc:80:6: error: unused function 'IsValidURL' [-Werror,-Wunused-function]\nbool IsValidURL(const GURL& url, google_util::PortPermission port_permission) {\n     ^\n2 errors generated.\n[14847/19472] CXX obj/components/feedback/feedback_component.feedback_util.o\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in \n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n```\nI wonder if theres anything wrong with the way werror is set?\n. I'm using the files from the old source folder and it seems to be working. I'm getting this warning with some files, though:\n/ungoogled-chromium/build_sandbox/chrome/app/nibs/DevicePermissionsPrompt.xib:global: warning: This file is set to build for a version older than the deployment target. Functionality may be limited. [9]\nIs that normal?\n. I'm sorry, I meant that I was copying the files I edited (by adding comments) to the build folder. They were the same files, it was just so I wouldn't need to edit one by one again to comment the unused functions.\nI also copied the folders google_toolbox_for_mac and pdfsqueeze from the old build tree, as they had some files the buildlib's source tree doesn't.\nMaybe its better to download the whole source on OS X, unfortunately.\nI got an error:\nninja: Entering directory `out/Release'\n[177/248] PACKAGE FRAMEWORK 'Chromium Framework.framework', POSTBUILDS\nFAILED: Chromium Framework.framework \n./gyp-mac-tool package-framework 'Chromium Framework.framework' A && (export BUILT_FRAMEWORKS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export BUILT_PRODUCTS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export CONFIGURATION=Release; export CONTENTS_FOLDER_PATH=\"Chromium Framework.framework/Versions/A\"; export DYLIB_INSTALL_NAME_BASE=@executable_path/../Versions/51.0.2704.106; export EXECUTABLE_NAME=\"Chromium Framework\"; export EXECUTABLE_PATH=\"Chromium Framework.framework/Versions/A/Chromium Framework\"; export FULL_PRODUCT_NAME=\"Chromium Framework.framework\"; export INFOPLIST_PATH=\"Chromium Framework.framework/Versions/A/Resources/Info.plist\"; export LD_DYLIB_INSTALL_NAME=\"@executable_path/../Versions/51.0.2704.106/Chromium Framework.framework/Chromium Framework\"; export MACH_O_TYPE=mh_dylib; export PRODUCT_NAME=\"Chromium Framework\"; export PRODUCT_TYPE=com.apple.product-type.framework; export SDKROOT=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk; export SRCROOT=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release/../../chrome; export SOURCE_ROOT=\"${SRCROOT}\"; export TARGET_BUILD_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export TEMP_DIR=\"${TMPDIR}\"; export UNLOCALIZED_RESOURCES_FOLDER_PATH=\"Chromium Framework.framework/Versions/A/Resources\"; export WRAPPER_NAME=\"Chromium Framework.framework\"; export XCODE_VERSION_ACTUAL=0731; (cd ../../chrome && ../build/mac/tweak_info_plist.py \"--breakpad=1\" \"--breakpad_uploads=0\" \"--keystone=0\" \"--scm=1\" \"--branding=Chromium\" && tools/build/mac/verify_order _ChromeMain \"${BUILT_PRODUCTS_DIR}/${EXECUTABLE_PATH}\"); G=$?; ((exit $G) || rm -rf 'Chromium Framework.framework') && exit $G) && touch 'Chromium Framework.framework'\ntools/build/mac/verify_order: /Users/Morello/ungoogled-chromium/build_sandbox/out/Release/Chromium Framework.framework/Versions/A/Chromium Framework depends on libc++\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\nEdit:\nI kept running the build command and it seems its failing to make the package.\n[119/190] PACKAGE FRAMEWORK 'Chromium Framework.framework', POSTBUILDS\nFAILED: Chromium Framework.framework \n./gyp-mac-tool package-framework 'Chromium Framework.framework' A && (export BUILT_FRAMEWORKS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export BUILT_PRODUCTS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export CONFIGURATION=Release; export CONTENTS_FOLDER_PATH=\"Chromium Framework.framework/Versions/A\"; export DYLIB_INSTALL_NAME_BASE=@executable_path/../Versions/51.0.2704.106; export EXECUTABLE_NAME=\"Chromium Framework\"; export EXECUTABLE_PATH=\"Chromium Framework.framework/Versions/A/Chromium Framework\"; export FULL_PRODUCT_NAME=\"Chromium Framework.framework\"; export INFOPLIST_PATH=\"Chromium Framework.framework/Versions/A/Resources/Info.plist\"; export LD_DYLIB_INSTALL_NAME=\"@executable_path/../Versions/51.0.2704.106/Chromium Framework.framework/Chromium Framework\"; export MACH_O_TYPE=mh_dylib; export PRODUCT_NAME=\"Chromium Framework\"; export PRODUCT_TYPE=com.apple.product-type.framework; export SDKROOT=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk; export SRCROOT=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release/../../chrome; export SOURCE_ROOT=\"${SRCROOT}\"; export TARGET_BUILD_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export TEMP_DIR=\"${TMPDIR}\"; export UNLOCALIZED_RESOURCES_FOLDER_PATH=\"Chromium Framework.framework/Versions/A/Resources\"; export WRAPPER_NAME=\"Chromium Framework.framework\"; export XCODE_VERSION_ACTUAL=0731; (cd ../../chrome && ../build/mac/tweak_info_plist.py \"--breakpad=1\" \"--breakpad_uploads=0\" \"--keystone=0\" \"--scm=1\" \"--branding=Chromium\" && tools/build/mac/verify_order _ChromeMain \"${BUILT_PRODUCTS_DIR}/${EXECUTABLE_PATH}\"); G=$?; ((exit $G) || rm -rf 'Chromium Framework.framework') && exit $G) && touch 'Chromium Framework.framework'\ntools/build/mac/verify_order: /Users/Morello/ungoogled-chromium/build_sandbox/out/Release/Chromium Framework.framework/Versions/A/Chromium Framework depends on libc++\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\nMight be a problem with brew's llvm...\n. Adding clang_xcode=1 made it start compiling from scratch again (and getting an error afterwards).\nDoes this link gives you any clue?\nhttp://nigorojr.com/articles/21\nEdit: tried to link the libraries, but it still couldn't find libc++.\nsudo ln -s /usr/local/lib/ /usr/local/Cellar/llvm/3.8.1/lib\nThe output of clang /usr/local/Cellar/llvm/3.8.1/bin/clang-3.8 -Xlinker -v/usr/local/Cellar/llvm/3.8.1/bin/clang-3.8 -Xlinker -vis this:\n@(#)PROGRAM:ld  PROJECT:ld64-264.3.102\nconfigured to support archs: armv6 armv7 armv7s arm64 i386 x86_64 x86_64h armv6m armv7k armv7m armv7em (tvOS)\nLibrary search paths:\n    /usr/lib\n    /usr/local/lib\nFramework search paths:\n    /Library/Frameworks/\n    /System/Library/Frameworks/\nUndefined symbols for architecture x86_64:\n  \"_main\", referenced from:\n     implicit entry/start for main executable\nld: symbol(s) not found for architecture x86_64\nclang-3.8: error: linker command failed with exit code 1 (use -v to see invocation)\nMaybe those links might give you a clue:\nhttps://langui.sh/2015/07/24/osx-clang-include-lib-search-paths/\nEdit 2: Linking the include folder also didn't work.\nsudo ln -s /usr/include /usr/local/Cellar/llvm/3.8.1/include\nsudo ln -s /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1 /usr/include/c++/v1\n. I've found something interesting.\nI tried reinstalling llvm from scratch with some flags, and got this after installing:\n```\nLLVM executables are installed in /usr/local/opt/llvm/bin.\nExtra tools are installed in /usr/local/opt/llvm/share/llvm.\nTo use the bundled libc++ please add the following LDFLAGS:\n  LDFLAGS=\"-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib\"\nThis formula is keg-only, which means it was not symlinked into /usr/local.\nOS X already provides this software and installing another version in\nparallel can cause all kinds of trouble.\nGenerally there are no consequences of this for you. If you build your\nown software and it requires this formula, you'll need to add to your\nbuild variables:\nLDFLAGS:  -L/usr/local/opt/llvm/lib\nCPPFLAGS: -I/usr/local/opt/llvm/include\n\nIf you need Python to find bindings for this keg-only formula, run:\n  echo /usr/local/opt/llvm/lib/python2.7/site-packages >> /usr/local/lib/python2.7/site-packages/llvm.pth\n```\nEdit: tried building with the fresh installed llvm and got an error. It seems the flags I used made homebrew install clang 4.0.\nI installed it with the following command:\nbrew install llvm --HEAD --all-targets --with-clang --with-lld --with-libcxx --with-clang-extra-tools --with-libcxxabi --with-lldb --with-compiler-rt --with-libunwind --with-openmp\nninja: Entering directory `out/Release'\n[1205/17752] CXX obj/third_party/pdfium/core/fxge/ge/fxge.fx_ge_ps.o\nFAILED: obj/third_party/pdfium/core/fxge/ge/fxge.fx_ge_ps.o \n/usr/local/Cellar/llvm/HEAD-1238f8d/bin/clang++ -MMD -MF obj/third_party/pdfium/core/fxge/ge/fxge.fx_ge_ps.o.d -DOPJ_STATIC -DPNG_PREFIX -DPNG_USE_READ_MACROS -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DPDF_ENABLE_V8 -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../.. -I../../third_party/pdfium -I../../third_party/pdfium/third_party/freetype/include -I../../third_party/pdfium/third_party/freetype/include/freetype -Igen -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -Werror -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wno-sign-compare -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-switch -Wno-unused-variable -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing  -c ../../third_party/pdfium/core/fxge/ge/fx_ge_ps.cpp -o obj/third_party/pdfium/core/fxge/ge/fxge.fx_ge_ps.o\nIn file included from ../../third_party/pdfium/core/fxge/ge/fx_ge_ps.cpp:7:\nIn file included from ../../third_party/pdfium/core/include/fxge/fx_ge.h:10:\nIn file included from ../../third_party/pdfium/core/include/fxge/fx_dib.h:10:\n../../third_party/pdfium/core/fxcrt/include/fx_basic.h:275:28: error: binding dereferenced null pointer to reference has undefined behavior [-Werror,-Wnull-dereference]\n      return (const TYPE&)(*(volatile const TYPE*)NULL);\n                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~\n../../third_party/pdfium/core/fxge/ge/fx_ge_ps.cpp:88:30: note: in instantiation of member function 'CFX_ArrayTemplate<FX_RECT>::GetAt' requested here\n  m_ClipBox = m_ClipBoxStack.GetAt(m_ClipBoxStack.GetSize() - 1);\n                             ^\n1 error generated.\n[1214/17752] CXX obj/third_party/pdfiu...fpdfsdk/pdfwindow/pdfwindow.PWL_Edit.o\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n. I actually didn't choose it manually. I installed llvm without pointing a specific version (I thought 3.8 was the newest release by homebrew). I'm installing llvm38 now with those flags, lets see what happens.\n. I found it on some github page where the guy was having problems with libc++ missing. Its installing 3.8 with that flag, so I don't know how it will behave. Lets see what happens.\nEdit: seems to be building without any problems using llvm3.8 installed with those flags. Its still 60% in.. lets see if it will find libc++ this time.\n. Got the same error in the end. :/\nIt built everything, and when starting the post build, it says the Chromium Framework depends on libc++.\nI think we are really close to compile it, its just a matter of copying the libc++ files to the correct folder. How can I check where it is looking for it?\n. Hey, do you think it could be being set by buildtools/third_party/libc++/libc++.gyp?\nI tried setting DYLD_LIBRARY_PATH to /usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/usr/lib/ (where libc++.dylib is), but got the same error.\n. Commenting that line is making it recompile some files, it seems. I'll edit this and post the result.\nEdit: got the same error with the line commented, am building now with the path changed.\nDoes this page contains any clues?\nhttps://bugs.chromium.org/p/chromium/issues/detail?id=597459\nEdit 2: no success, got the same result with both.\nPACKAGE FRAMEWORK 'Chromium Framework.framework', POSTBUILDS\nFAILED: Chromium Framework.framework \n./gyp-mac-tool package-framework 'Chromium Framework.framework' A && (export BUILT_FRAMEWORKS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export BUILT_PRODUCTS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export CONFIGURATION=Release; export CONTENTS_FOLDER_PATH=\"Chromium Framework.framework/Versions/A\"; export DYLIB_INSTALL_NAME_BASE=@executable_path/../Versions/51.0.2704.106; export EXECUTABLE_NAME=\"Chromium Framework\"; export EXECUTABLE_PATH=\"Chromium Framework.framework/Versions/A/Chromium Framework\"; export FULL_PRODUCT_NAME=\"Chromium Framework.framework\"; export INFOPLIST_PATH=\"Chromium Framework.framework/Versions/A/Resources/Info.plist\"; export LD_DYLIB_INSTALL_NAME=\"@executable_path/../Versions/51.0.2704.106/Chromium Framework.framework/Chromium Framework\"; export MACH_O_TYPE=mh_dylib; export PRODUCT_NAME=\"Chromium Framework\"; export PRODUCT_TYPE=com.apple.product-type.framework; export SDKROOT=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk; export SRCROOT=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release/../../chrome; export SOURCE_ROOT=\"${SRCROOT}\"; export TARGET_BUILD_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export TEMP_DIR=\"${TMPDIR}\"; export UNLOCALIZED_RESOURCES_FOLDER_PATH=\"Chromium Framework.framework/Versions/A/Resources\"; export WRAPPER_NAME=\"Chromium Framework.framework\"; export XCODE_VERSION_ACTUAL=0731; (cd ../../chrome && ../build/mac/tweak_info_plist.py \"--breakpad=1\" \"--breakpad_uploads=0\" \"--keystone=0\" \"--scm=1\" \"--branding=Chromium\" && tools/build/mac/verify_order _ChromeMain \"${BUILT_PRODUCTS_DIR}/${EXECUTABLE_PATH}\"); G=$?; ((exit $G) || rm -rf 'Chromium Framework.framework') && exit $G) && touch 'Chromium Framework.framework'\ntools/build/mac/verify_order: /Users/Morello/ungoogled-chromium/build_sandbox/out/Release/Chromium Framework.framework/Versions/A/Chromium Framework depends on libc++\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 445, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 317, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\nDo you have any idea why I didn't get this error when compiling for the first time?\n. Thinking ahead, if we can't get this to work you could modify buildlib to download the entire chromium source tree, delete the files, do the domain substitution and then build as normal, I think. I deleted the files in cleaning_list with some command and it worked just fine.\n. I managed to compile it!\nHere is what I found: for some reason, there wasn't any libc++.a file inside third_party/libc++-static. It seems that, at some point, it should have built it there and copied it to the main folder.\nSo, I copied the libc++.a from the third_party/libc++-static folder from the old build to the /out/Release folder of the new build, and the link worked.\nI tried running third_party/libc++-static/build.sh to build it, but it got some errors about visibility. It seems this is a problem with clang, according to the commentaries on build.sh. Perhaps we could compile it with gcc and some flags.\n. There are a bunch of .a files on /usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/lib, but I can't tell if they are related to libc++ or not. At least, there are none with libcxx on their names.\nSo, in the end, I had to copy from the old build folder:\nthird_party/google_toolbox_for_mac folder (some files were missing, I don't know which, since I just merged them)\nthird_party/pdfsqueeze folder (this one I'm not sure if it was present or not)\nlibc++.a\nIs libc++.a used to build for other platforms? The 2 folders seem to be Mac specific stuff.\nEdit: haha, same. Actually I ran python3 build_macos.py expecting to run into the same error again. I was very surprised to see it actually linked successfully. We did it!\n. I tried commenting it and using /usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/usr/lib. Got the same results as before with both (failing when trying to link the build). Then I turned off my PC and forgot to change it back to the default value. haha\nIt seems it wasn't related to the link problem. But if I'm not mistaken, changing the path made it recompile around 1800 files.\n. I don't remember if I found it there or if I copied it from somewhere. I ended placing libc++.dylib in a bunch of directories, hoping that the linker would find it. haha\nAlso, I'm sure I tried using the gyp flag \"stdlib=libc++\" at some point to fix the link error.\n. c++ seems to point to Xcode's clang. Yes, I do have g++.\nThough, it seems the script tries to use Google's clang by default. Here are the errors:\n```\nChecked out revision 245965.\n+ mkdir libcxxbuild\n+ cd libcxxbuild\n+ mkdir libcxx\n+ pushd libcxx\n/var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/libcpp.17fv5pHM/libcxxbuild/libcxx /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/libcpp.17fv5pHM/libcxxbuild ~/ungoogled-chromium/build_sandbox/third_party/libc++-static\n+ sed -i '' 's/\"default\"/\"hidden\"/g' ../../libcxx/include/__config\n+ c++ -c -I../../libcxx/include/ ../../libcxx/src/algorithm.cpp ../../libcxx/src/any.cpp ../../libcxx/src/bind.cpp ../../libcxx/src/chrono.cpp ../../libcxx/src/condition_variable.cpp ../../libcxx/src/debug.cpp ../../libcxx/src/exception.cpp ../../libcxx/src/future.cpp ../../libcxx/src/hash.cpp ../../libcxx/src/ios.cpp ../../libcxx/src/iostream.cpp ../../libcxx/src/locale.cpp ../../libcxx/src/memory.cpp ../../libcxx/src/mutex.cpp ../../libcxx/src/new.cpp ../../libcxx/src/optional.cpp ../../libcxx/src/random.cpp ../../libcxx/src/regex.cpp ../../libcxx/src/shared_mutex.cpp ../../libcxx/src/stdexcept.cpp ../../libcxx/src/string.cpp ../../libcxx/src/strstream.cpp ../../libcxx/src/system_error.cpp ../../libcxx/src/thread.cpp ../../libcxx/src/typeinfo.cpp ../../libcxx/src/utility.cpp ../../libcxx/src/valarray.cpp -nostdinc++ -O3 -std=c++11 -fstrict-aliasing -fvisibility=hidden -fvisibility-inlines-hidden -mmacosx-version-min=10.6 -arch i386 -arch x86_64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk\nIn file included from ../../libcxx/src/algorithm.cpp:10:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/algorithm.cpp:10:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/algorithm.cpp:10:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/algorithm.cpp:10:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/any.cpp:10:\nIn file included from ../../libcxx/include/experimental/any:80:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/any.cpp:10:\nIn file included from ../../libcxx/include/experimental/any:80:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/any.cpp:10:\nIn file included from ../../libcxx/include/experimental/any:80:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/any.cpp:10:\nIn file included from ../../libcxx/include/experimental/any:80:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/bind.cpp:10:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/bind.cpp:10:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/bind.cpp:10:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/bind.cpp:10:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/chrono.cpp:12:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/chrono.cpp:12:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/chrono.cpp:12:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/chrono.cpp:12:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/condition_variable.cpp:14:\nIn file included from ../../libcxx/include/condition_variable:111:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/condition_variable.cpp:14:\nIn file included from ../../libcxx/include/condition_variable:111:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/condition_variable.cpp:14:\nIn file included from ../../libcxx/include/condition_variable:111:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/condition_variable.cpp:14:\nIn file included from ../../libcxx/include/condition_variable:111:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/debug.cpp:13:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/debug.cpp:13:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/debug.cpp:13:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/debug.cpp:13:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/exception.cpp:13:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/exception.cpp:13:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/exception.cpp:13:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/exception.cpp:13:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/future.cpp:14:\nIn file included from ../../libcxx/include/future:366:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/future.cpp:14:\nIn file included from ../../libcxx/include/future:366:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/future.cpp:14:\nIn file included from ../../libcxx/include/future:366:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/future.cpp:14:\nIn file included from ../../libcxx/include/future:366:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/hash.cpp:10:\nIn file included from ../../libcxx/include/__hash_table:16:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/hash.cpp:10:\nIn file included from ../../libcxx/include/__hash_table:16:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/hash.cpp:10:\nIn file included from ../../libcxx/include/__hash_table:16:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/hash.cpp:10:\nIn file included from ../../libcxx/include/__hash_table:16:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/ios.cpp:12:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/ios.cpp:12:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/ios.cpp:12:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/ios.cpp:12:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/iostream.cpp:10:\nIn file included from ../../libcxx/include/__std_stream:15:\nIn file included from ../../libcxx/include/ostream:138:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/iostream.cpp:10:\nIn file included from ../../libcxx/include/__std_stream:15:\nIn file included from ../../libcxx/include/ostream:138:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/iostream.cpp:10:\nIn file included from ../../libcxx/include/__std_stream:15:\nIn file included from ../../libcxx/include/ostream:138:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/iostream.cpp:10:\nIn file included from ../../libcxx/include/__std_stream:15:\nIn file included from ../../libcxx/include/ostream:138:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/locale.cpp:16:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/locale.cpp:16:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/locale.cpp:16:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/locale.cpp:16:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/memory.cpp:11:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/memory.cpp:11:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/memory.cpp:11:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/memory.cpp:11:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/mutex.cpp:11:\nIn file included from ../../libcxx/include/mutex:176:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/mutex.cpp:11:\nIn file included from ../../libcxx/include/mutex:176:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/mutex.cpp:11:\nIn file included from ../../libcxx/include/mutex:176:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/mutex.cpp:11:\nIn file included from ../../libcxx/include/mutex:176:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/new.cpp:14:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/new.cpp:14:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/new.cpp:14:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/new.cpp:14:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n../../libcxx/src/new.cpp:44:14: error: visibility does not match previous\n      declaration\n_LIBCPP_WEAK _LIBCPP_NEW_DELETE_VIS\n             ^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n../../libcxx/src/new.cpp:90:14: error: visibility does not match previous\n      declaration\n_LIBCPP_WEAK _LIBCPP_NEW_DELETE_VIS\n             ^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n../../libcxx/src/new.cpp:119:14: error: visibility does not match previous\n      declaration\n_LIBCPP_WEAK _LIBCPP_NEW_DELETE_VIS\n             ^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n../../libcxx/src/new.cpp:141:14: error: visibility does not match previous\n      declaration\n_LIBCPP_WEAK _LIBCPP_NEW_DELETE_VIS\n             ^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n8 errors generated.\nIn file included from ../../libcxx/src/optional.cpp:10:\nIn file included from ../../libcxx/include/experimental/optional:144:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/optional.cpp:10:\nIn file included from ../../libcxx/include/experimental/optional:144:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/optional.cpp:10:\nIn file included from ../../libcxx/include/experimental/optional:144:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/optional.cpp:10:\nIn file included from ../../libcxx/include/experimental/optional:144:\nIn file included from ../../libcxx/include/functional:477:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/random.cpp:15:\nIn file included from ../../libcxx/include/random:1642:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/random.cpp:15:\nIn file included from ../../libcxx/include/random:1642:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/random.cpp:15:\nIn file included from ../../libcxx/include/random:1642:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/random.cpp:15:\nIn file included from ../../libcxx/include/random:1642:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/regex.cpp:10:\nIn file included from ../../libcxx/include/regex:757:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/regex.cpp:10:\nIn file included from ../../libcxx/include/regex:757:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/regex.cpp:10:\nIn file included from ../../libcxx/include/regex:757:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/regex.cpp:10:\nIn file included from ../../libcxx/include/regex:757:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/shared_mutex.cpp:14:\nIn file included from ../../libcxx/include/shared_mutex:130:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/shared_mutex.cpp:14:\nIn file included from ../../libcxx/include/shared_mutex:130:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/shared_mutex.cpp:14:\nIn file included from ../../libcxx/include/shared_mutex:130:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/shared_mutex.cpp:14:\nIn file included from ../../libcxx/include/shared_mutex:130:\nIn file included from ../../libcxx/include/__mutex_base:16:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/stdexcept.cpp:12:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/stdexcept.cpp:12:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/stdexcept.cpp:12:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/stdexcept.cpp:12:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/string.cpp:10:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/string.cpp:10:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/string.cpp:10:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/string.cpp:10:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/strstream.cpp:10:\nIn file included from ../../libcxx/include/strstream:131:\nIn file included from ../../libcxx/include/ostream:138:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/strstream.cpp:10:\nIn file included from ../../libcxx/include/strstream:131:\nIn file included from ../../libcxx/include/ostream:138:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/strstream.cpp:10:\nIn file included from ../../libcxx/include/strstream:131:\nIn file included from ../../libcxx/include/ostream:138:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/strstream.cpp:10:\nIn file included from ../../libcxx/include/strstream:131:\nIn file included from ../../libcxx/include/ostream:138:\nIn file included from ../../libcxx/include/ios:216:\nIn file included from ../../libcxx/include/__locale:15:\nIn file included from ../../libcxx/include/string:439:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/system_error.cpp:13:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/system_error.cpp:13:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/system_error.cpp:13:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/system_error.cpp:13:\nIn file included from ../../libcxx/include/system_error:225:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/thread.cpp:13:\nIn file included from ../../libcxx/include/thread:90:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/thread.cpp:13:\nIn file included from ../../libcxx/include/thread:90:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/thread.cpp:13:\nIn file included from ../../libcxx/include/thread:90:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/thread.cpp:13:\nIn file included from ../../libcxx/include/thread:90:\nIn file included from ../../libcxx/include/__functional_base:18:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\nIn file included from ../../libcxx/src/valarray.cpp:10:\nIn file included from ../../libcxx/include/valarray:346:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:131:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new(std::size_t __sz)\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/valarray.cpp:10:\nIn file included from ../../libcxx/include/valarray:346:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:137:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete(void* __p) _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/valarray.cpp:10:\nIn file included from ../../libcxx/include/valarray:346:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:144:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void* operator new\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\nIn file included from ../../libcxx/src/valarray.cpp:10:\nIn file included from ../../libcxx/include/valarray:346:\nIn file included from ../../libcxx/include/algorithm:628:\nIn file included from ../../libcxx/include/memory:603:\n../../libcxx/include/new:150:1: error: visibility does not match previous\n      declaration\n_LIBCPP_NEW_DELETE_VIS void  operator delete _NOEXCEPT;\n^\n../../libcxx/include/new:128:33: note: expanded from macro\n      '_LIBCPP_NEW_DELETE_VIS'\ndefine _LIBCPP_NEW_DELETE_VIS _LIBCPP_FUNC_VIS\n                            ^\n\n../../libcxx/include/__config:200:42: note: expanded from macro\n      '_LIBCPP_FUNC_VIS'\ndefine _LIBCPP_FUNC_VIS attribute ((visibility(\"hidden\")))\n                                     ^\n\nnote: previous attribute is here\n4 errors generated.\n```\nIt seems on pair with was written in the script (that their clang would fail).\n. As you expected, those errors are not specific to Google's clang. I tried building it using Homebrew's clangs (both 3.8 and 4.0 versions) as well as g++, got more or less the same output on all of them (a bunch of visibility errors).\n. Seems to be pointing to Xcode's clang++ too.\n. I installed gcc 4.9, and got a bunch of errors like this:\n/var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T//ccGYsKMX.s:603:7: error: register %rbp is only available in 64-bit mode\nThats strange, because I pointed to the x86_64 version:\nCXX=/usr/local/Cellar/gcc49/4.9.3/bin/x86_64-apple-darwin15.4.0-g++-4.9\n. It did the job!\nThe script fails later by trying to upload the generated library to Google server, but it doesn't really matter since the libc++.a library is generated.\nIt didn't copy it to the out/Release folder, though. What supposed to do that?\n(heres the missing script)\nbuild.sh: line 50: upload_to_google_storage.py: command not found\n. Yes, OS X supports zip ootb.\nHere are the GYP flags I used:\nwerror=\ndefault_apps_list=[]\ndefault_apps_list_linux_dest=[]\nremoting=0\ndisable_nacl=1\ndisable_pnacl=1\ndisable_newlib=1\nenable_remoting_host=0\nenable_automation=0\nenable_google_now=0\nsafe_browsing=0\nenable_webrtc=0\nremoting=0\nenable_hotwording=0\nenable_hangout_services_extension=0\nenable_wifi_bootstrapping=0\nuse_official_google_api_keys=0\nenable_rlz=0\nenable_pre_sync_backup=0\nenable_prod_wallet_service=0\nenable_one_click_signin=0\nenable_hidpi=1\nfastbuild=1\ndisable_fatal_linker_warnings=1\ntracing_like_official_build=1\nfieldtrial_testing_like_official_build=1\nlinux_strip_binary=1\nproprietary_codecs=1\nffmpeg_branding=Chrome\nremove_webcore_debug_symbols=1\nclang_dir=/usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/bin\nmake_clang_dir=/usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/\nclang_use_chrome_plugins=0\nclang=1\nhost_cc=/usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/bin/clang\nCC=/usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/bin/clang\nhost_cxx=/usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/bin/clang++\nLDPLUSPLUS=/usr/local/Cellar/llvm38/HEAD-051e787/lib/llvm-3.8/bin/clang++\nI'm uploading the Mac-only folders I copied from the old build.\nSo, here are the things we should remember to make general instructions to build it:\n- The user needs to install GNU Patch through Homebrew;\n- The user needs to install llvm38 through Homebrew with those flags:\n- brew install llvm --all-targets --with-clang --with-lld --with-libcxx --with-clang-extra-tools --with-libcxxabi --with-lldb --with-compiler-rt --with-libunwind --with-openmp (the gyp flags should not include the head folder since theres no --HEAD)\n- I'm not sure if this still needs Xcode or not, since we used Homebrew's llvm to build it. Probably safer to install it anyway;\n- The compiler will stop if it get warnings;\n- You posted a patch here that I applied, it should be included with the OS X specific patches.\nTested and compiled using OS X 10.11.6 (last update of El Capitan).\nNot sure if I'm forgetting anything. heh\n. Yes, I used it on my pathes.\nThe default path for an install without the --HEAD flag is /usr/local/Cellar/llvm/3.8.1/bin/clang.\nNote: it only found the clang after I pointed the path without quotation marks.\nEdit: I forgot to upload the folders I copied from the old build. Here they are. \nFolders that should be inside third_party.zip\nI got a Chromium.app inside out/Release after building it.\nEdit 2: a .dmg will probably be better if the goal is to distribute pre-built binaries.\n. I just run the Chromium.app inside out/Release folder. I copied it to /Applications to make it appear on Launchpad.\n. Ok, lets go!\nHere is the first error:\npython3 build_macos.py\nTraceback (most recent call last):\n  File \"build_macos.py\", line 30, in <module>\n    import buildlib.macos\n  File \"/Users/Morello/ungoogled-chromium/buildlib/macos.py\", line 25, in <module>\n    class MacOSPlatform(generic.GenericPlatform):\n  File \"/Users/Morello/ungoogled-chromium/buildlib/macos.py\", line 26, in MacOSPlatform\n    PLATFORM_RESOURCES = pathlib.Path(\"resources\", \"macos\")\nNameError: name 'pathlib' is not defined\nI'll take a look at the build instructions and see if I find something strange. When we're finished, I'll also see if I can test this on someone else's computer.\n. Got an error after downloading the missing files.\n```\n2016-08-21 19:27:16,888 - INFO: Downloading pdfsqueeze-5936b871e6a087b7e50d4cbcb122378d8a07499f.tar.gz ...\n2016-08-21 19:27:19,050 - INFO: Downloading google-toolbox-for-mac-401878398253074c515c03cb3a3f8bb0cc8da6e9.tar.gz ...\n2016-08-21 19:27:33,744 - INFO: Extracting pdfsqueeze archive...\n2016-08-21 19:27:33,744 - WARNING: Symlinks not supported. Will ignore all symlinks\n2016-08-21 19:27:33,766 - INFO: Extracting google-toolbox-for-mac archive...\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in \n    exit(main())\n  File \"build_macos.py\", line 57, in main\n    platform.setup_chromium_source()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/macos.py\", line 66, in setup_chromium_source\n    self._extract_tar_file(google_toolboxarchive, google_toolbox_dir, list(), \"google-toolbox-for-mac-{}\".format(self.GOOGLE_TOOLBOX_FOR_MAC))\nAttributeError: 'MacOSPlatform' object has no attribute 'GOOGLE_TOOLBOX_FOR_MAC'\n```\n. It built libc++.a just fine, it started compiling Chromium now.\nShould I expect the compiler to complain about unused functions this time?\n. Ok, I just got the first error about unused functions. I'll list the file(s) here.\n../../components/domain_reliability/google_configs.cc:511:1: error: unused function 'CreateGoogleConfig' [-Werror,-Wunused-function]\n../../components/autofill/core/browser/autofill_download_manager.cc:88:6: error: unused function 'GetRequestUrl' [-Werror,-Wunused-function]\n../../components/autofill/core/browser/autofill_download_manager.cc:67:12: error: unused variable 'kClientName' [-Werror,-Wunused-const-variable]\n../../chrome/browser/browsing_data/browsing_data_remover.cc:140:15: error: unused function 'UIThreadTrampoline' [-Werror,-Wunused-function]\n../../chrome/browser/browsing_data/browsing_data_remover.cc:199:6: error: unused function 'ClearCookiesOnIOThread' [-Werror,-Wunused-function]\n../../chrome/browser/profiles/profile_avatar_downloader.cc:18:12: error: unused variable 'kHighResAvatarDownloadUrlPrefix' [-Werror,-Wunused-const-variable]\n../../chrome/browser/download/download_danger_prompt.cc:34:12: error: unused variable 'kDownloadDangerPromptPrefix' [-Werror,-Wunused-const-variable]\n../../chrome/browser/download/download_danger_prompt.cc:270:13: error: unused function 'GetDangerTypeString' [-Werror,-Wunused-function]\nEdit:\nI forgot to edit build_macos.py to repeat the first steps, and it gets an error and stops if pdfsqueeze was already there:\n2016-08-21 21:17:27,973 - WARNING: Symlinks not supported. Will ignore all symlinks\n2016-08-21 21:19:23,743 - INFO: pdfsqueeze-5936b871e6a087b7e50d4cbcb122378d8a07499f.tar.gz already exists. Skipping download.\n2016-08-21 21:19:23,743 - INFO: google-toolbox-for-mac-401878398253074c515c03cb3a3f8bb0cc8da6e9.tar.gz already exists. Skipping download.\n2016-08-21 21:19:23,743 - INFO: Extracting pdfsqueeze archive...\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 57, in main\n    #platform.setup_chromium_source()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/macos.py\", line 60, in setup_chromium_source\n    os.makedirs(str(pdfsqueeze_dir))\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/os.py\", line 241, in makedirs\n    mkdir(name, mode)\nFileExistsError: [Errno 17] File exists: 'build_sandbox/third_party/pdfsqueeze'\n. I'm having trouble restarting the build process.\nAfter editing autofill_download_manager.cc, I've commented the following lines in build_macos.py before running it again and resuming the building:\n#platform.setup_chromium_source()\n    #platform.setup_build_sandbox()\n    #platform.apply_patches() # Change the command for GNU patch here\n    #platform.setup_build_utilities(python2_command=\"python\") # Change the commands for ninja and Python 2 here\nBut I got the following error:\nbuild_macos.py\n2016-08-21 23:31:51,167 - INFO: Running gyp command...\n2016-08-21 23:31:51,168 - DEBUG: Successfully appended platform list\n2016-08-21 23:31:51,168 - DEBUG: GYP command: build/gyp_chromium --depth=. --check -Dhost_cc=/usr/local/Cellar/llvm/3.8.1/bin/clang -Dremove_webcore_debug_symbols=1 -Ddisable_pnacl=1 -Dwerror= -Denable_automation=0 -Ddisable_newlib=1 -Dtracing_like_official_build=1 -Ddefault_apps_list_linux_dest=[] -Denable_prod_wallet_service=0 -Duse_official_google_api_keys=0 -Dlinux_strip_binary=1 -DCC=/usr/local/Cellar/llvm/3.8.1/bin/clang -Denable_remoting_host=0 -Denable_google_now=0 -Ddefault_apps_list=[] -Dproprietary_codecs=1 -DLDPLUSPLUS=/usr/local/Cellar/llvm/3.8.1/bin/clang++ -Dfieldtrial_testing_like_official_build=1 -Denable_hotwording=0 -Dfastbuild=1 -Denable_webrtc=0 -Denable_wifi_bootstrapping=0 -Dhost_cxx=/usr/local/Cellar/llvm/3.8.1/bin/clang++ -Dsafe_browsing=0 -Denable_one_click_signin=0 -Dremoting=0 -Denable_hangout_services_extension=0 -Dffmpeg_branding=Chrome -Dclang=1 -Dclang_dir=/usr/local/Cellar/llvm/3.8.1/bin -Dclang_use_chrome_plugins=0 -Denable_pre_sync_backup=0 -Ddisable_fatal_linker_warnings=1 -Denable_rlz=0 -Dmake_clang_dir=/usr/local/Cellar/llvm/3.8.1 -Ddisable_nacl=1 -Denable_hidpi=1\nUpdating projects from gyp files...\n2016-08-21 23:32:33,529 - INFO: libc++.a already exists. Skipping its building\n2016-08-21 23:32:33,529 - INFO: Running build command...\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/macos.py\", line 88, in build\n    super(MacOSPlatform, self).build(*args, **kwargs)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 450, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 320, in _run_ninja\n    result = self._run_subprocess([ninja_command, \"-C\", str(build_output), *targets], cwd=str(self.sandbox_root))\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 271, in _run_subprocess\n    return subprocess.run(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/subprocess.py\", line 696, in run\n    with Popen(*popenargs, **kwargs) as process:\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/subprocess.py\", line 950, in __init__\n    restore_signals, start_new_session)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/subprocess.py\", line 1467, in _execute_child\n    executable = os.fsencode(executable)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/os.py\", line 820, in fsencode\n    raise TypeError(\"expect bytes or str, not %s\" % type(filename).__name__)\nTypeError: expect bytes or str, not NoneType\n. Got the first error in the post build process.\n[180/251] PACKAGE FRAMEWORK 'Chromium Framework.framework', POSTBUILDS\nFAILED: Chromium Framework.framework \n./gyp-mac-tool package-framework 'Chromium Framework.framework' A && (export BUILT_FRAMEWORKS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export BUILT_PRODUCTS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export CONFIGURATION=Release; export CONTENTS_FOLDER_PATH=\"Chromium Framework.framework/Versions/A\"; export DYLIB_INSTALL_NAME_BASE=@executable_path/../Versions/51.0.2704.106; export EXECUTABLE_NAME=\"Chromium Framework\"; export EXECUTABLE_PATH=\"Chromium Framework.framework/Versions/A/Chromium Framework\"; export FULL_PRODUCT_NAME=\"Chromium Framework.framework\"; export INFOPLIST_PATH=\"Chromium Framework.framework/Versions/A/Resources/Info.plist\"; export LD_DYLIB_INSTALL_NAME=\"@executable_path/../Versions/51.0.2704.106/Chromium Framework.framework/Chromium Framework\"; export MACH_O_TYPE=mh_dylib; export PRODUCT_NAME=\"Chromium Framework\"; export PRODUCT_TYPE=com.apple.product-type.framework; export SDKROOT=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk; export SRCROOT=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release/../../chrome; export SOURCE_ROOT=\"${SRCROOT}\"; export TARGET_BUILD_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export TEMP_DIR=\"${TMPDIR}\"; export UNLOCALIZED_RESOURCES_FOLDER_PATH=\"Chromium Framework.framework/Versions/A/Resources\"; export WRAPPER_NAME=\"Chromium Framework.framework\"; export XCODE_VERSION_ACTUAL=0731; (cd ../../chrome && ../build/mac/tweak_info_plist.py \"--breakpad=1\" \"--breakpad_uploads=0\" \"--keystone=0\" \"--scm=1\" \"--branding=Chromium\" && tools/build/mac/verify_order _ChromeMain \"${BUILT_PRODUCTS_DIR}/${EXECUTABLE_PATH}\"); G=$?; ((exit $G) || rm -rf 'Chromium Framework.framework') && exit $G) && touch 'Chromium Framework.framework'\ntools/build/mac/verify_order: unordered symbols in /Users/Morello/ungoogled-chromium/build_sandbox/out/Release/Chromium Framework.framework/Versions/A/Chromium Framework:\n__ZNSt3__18__rs_getEv\n__ZNSt3__16__sortIRNS_6__lessIccEEPcEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIccEEPcEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIwwEEPwEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIwwEEPwEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIaaEEPaEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIaaEEPaEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIhhEEPhEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIhhEEPhEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIssEEPsEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIssEEPsEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIttEEPtEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIttEEPtEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIiiEEPiEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIiiEEPiEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIjjEEPjEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIjjEEPjEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIllEEPlEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIllEEPlEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessImmEEPmEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessImmEEPmEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIxxEEPxEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIxxEEPxEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIyyEEPyEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIyyEEPyEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIffEEPfEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIffEEPfEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIddEEPdEEvT0_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIddEEPdEEbT0_S5_T_\n__ZNSt3__16__sortIRNS_6__lessIeeEEPeEEvT0_S5_T_\n__ZNSt3__17__sort5IRNS_6__lessIeeEEPeEEjT0_S5_S5_S5_S5_T_\n__ZNSt3__127__insertion_sort_incompleteIRNS_6__lessIeeEEPeEEbT0_S5_T_\n__ZNSt3__125notify_all_at_thread_exitERNS_18condition_variableENS_11unique_lockINS_5mutexEEE\n__ZSt18uncaught_exceptionv\n__ZSt19uncaught_exceptionsv\n__ZNSt16nested_exceptionC2Ev\n__ZSt17current_exceptionv\n__ZNSt16nested_exceptionC1Ev\n__ZNSt16nested_exceptionD2Ev\n__ZNSt16nested_exceptionD1Ev\n__ZNSt16nested_exceptionD0Ev\n__ZNKSt16nested_exception14rethrow_nestedEv\n__ZSt17rethrow_exceptionSt13exception_ptr\n__ZNSt3__115future_categoryEv\n__ZNSt3__112future_errorC2ENS_10error_codeE\n__ZNSt3__112future_errorC1ENS_10error_codeE\n__ZNSt3__112future_errorD2Ev\n__ZNSt3__112future_errorD1Ev\n__ZNSt3__112future_errorD0Ev\n__ZNSt3__112__next_primeEm\n__ZNSt3__117iostream_categoryEv\n__ZNSt3__18ios_base7failureC2ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS_10error_codeE\n__ZNSt3__18ios_base7failureC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS_10error_codeE\n__ZNSt3__18ios_base7failureC2EPKcRKNS_10error_codeE\n__ZNSt3__18ios_base7failureC1EPKcRKNS_10error_codeE\n__ZNSt3__18ios_base7failureD2Ev\n__ZNSt3__18ios_base7failureD1Ev\n__ZNSt3__18ios_base7failureD0Ev\n__ZNSt3__112__do_nothingEPv\n__ZNSt3__121__throw_runtime_errorEPKc\n__ZNSt3__116__check_groupingERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEPjS8_Rj\n__ZNSt3__112bad_weak_ptrD2Ev\n__ZNSt3__112bad_weak_ptrD1Ev\n__ZNSt3__112bad_weak_ptrD0Ev\n__ZNKSt3__112bad_weak_ptr4whatEv\n__ZNSt3__112__get_sp_mutEPKv\n__ZNSt3__117declare_reachableEPv\n__ZNSt3__119declare_no_pointersEPcm\n__ZNSt3__121undeclare_no_pointersEPcm\n__ZNSt3__118get_pointer_safetyEv\n__ZNSt3__121__undeclare_reachableEPv\n__ZNSt3__15alignEmmRPvRm\n__ZNSt3__111__call_onceERVmPvPFvS2_E\n__ZSt17__throw_bad_allocv\n__Znwm\n__ZnwmRKSt9nothrow_t\n__Znam\n__ZnamRKSt9nothrow_t\n__ZdlPv\n__ZdlPvRKSt9nothrow_t\n__ZdlPvm\n__ZdaPv\n__ZdaPvRKSt9nothrow_t\n__ZdaPvm\n__ZNSt11logic_errorC2ERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE\n__ZNSt11logic_errorC1ERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE\n__ZNSt11logic_errorC2EPKc\n__ZNSt11logic_errorC1EPKc\n__ZNSt11logic_errorC2ERKS_\n__ZNSt11logic_errorC1ERKS_\n__ZNSt11logic_erroraSERKS_\n__ZNSt13runtime_errorC2ERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE\n__ZNSt13runtime_errorC1ERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE\n__ZNSt13runtime_errorC2EPKc\n__ZNSt13runtime_errorC1EPKc\n__ZNSt13runtime_errorC2ERKS_\n__ZNSt13runtime_errorC1ERKS_\n__ZNSt13runtime_erroraSERKS_\n__ZNSt3__14stoiERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEPmi\n__ZNSt3__14stoiERKNS_12basic_stringIwNS_11char_traitsIwEENS_9allocatorIwEEEEPmi\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build_macos.py\", line 68, in <module>\n    exit(main())\n  File \"build_macos.py\", line 62, in main\n    platform.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib/macos.py\", line 88, in build\n    super(MacOSPlatform, self).build(*args, **kwargs)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 450, in build\n    self._run_ninja(self.ninja_command, self.build_output, build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib/generic.py\", line 322, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n. Ok, indeed the error was from because we were using a broken libc++.a. I used the one from the older build and it worked perfectly, creating the .dmg file. For convenience, its a good idea to include a shortcut to /Applications aside Chromium.app. Most software in OS X distributed by third-parties are installed by copying them to that folder.\nAbout compiling libc++.a, I'm not sure I'm using Xcode's g++. It seems that the g++ binary is just a shortcut to Xcode's clang. How can I check it? For some reason the system sees it as an UNIX binary instead of a shortcut, so I can't see where it points. Running g++ --version says installed in in /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin, but theres no bin for it there.\nEdit: I also tried to build it with gcc's g++, but got a bunch of errors about functions only available in 64-bit mode despite pointing to the x86_64 binary.\n. Nevermind, managed to get it to work. There problem was the arch -i386 flag and the way THIS_DIR was declared. Here is my modified script: \n```\n!/bin/bash\nCopyright 2015 The Chromium Authors. All rights reserved.\nUse of this source code is governed by a BSD-style license that can be\nfound in the LICENSE file.\nset -eux\nREV=245965\nDIR=$(mktemp -d -t libcpp)\nTHIS_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\nTODO(thakis): Figure out why our clang complains about visibility and\nredeclarations.\nCXX=\"$THIS_DIR/../llvm-build/Release+Asserts/bin/clang++\"\nCXX=/usr/local/Cellar/gcc49/4.9.3/bin/x86_64-apple-darwin15.4.0-c++-4.9\nFLAGS=\"-nostdinc++ -O3 -std=c++11 -fstrict-aliasing -fvisibility=hidden -fvisibility-inlines-hidden -mmacosx-version-min=10.6 -arch x86_64 -isysroot $(xcrun -show-sdk-path)\"\npushd \"${DIR}\"\nsvn co --force https://llvm.org/svn/llvm-project/libcxx/trunk@$REV libcxx\nsvn co --force https://llvm.org/svn/llvm-project/libcxxabi/trunk@$REV libcxxabi\nmkdir libcxxbuild\ncd libcxxbuild\nmkdir libcxx\npushd libcxx\nsed -i '' 's/\"default\"/\"hidden\"/g' ../../libcxx/include/__config\n\"$CXX\" -c -I../../libcxx/include/ ../../libcxx/src/*.cpp $FLAGS\npopd\nmkdir libcxxabi\npushd libcxxabi\nsed -i '' 's/\"default\"/\"hidden\"/g' ../../libcxxabi/src/\nsed -i '' 's/push(default)/push(hidden)/g' ../../libcxxabi/src/\nLet the default handler not depend on __cxa_demangle, this saves 0.5MB binary\nsize in each binary linking against libc++.a\npatch -d ../../libcxxabi -p0 < \"${THIS_DIR}/libcxxabi.patch\"\n\"$CXX\" -c -I../../libcxx/include/ -I../../libcxxabi/include ../../libcxxabi/src/*.cpp $FLAGS\npopd\nlibtool -static -o libc++.a libcxx/.o\ncp libc++.a \"${THIS_DIR}/libc++.a\"\nupload_to_google_storage.py -b chromium-libcpp \"${THIS_DIR}/libc++.a\"\npopd\nrm -rf \"${DIR}\"\n```\nAbout your questions:\nYes, /Applications is a root path where all the apps are installed too. For example, to install Firefox, you open a .dmg file and then drag n' drop the Firefox.app file to /Applications.\nShortcuts, afaik, are files treated differently by the system. I can check where a shortcut points to by right clicking it and clicking on \"Get Info\". Similar to the Properties option on Windows, I can see some things, including where it points too. For some reason, I've noticed that some shortcuts are not recognized as such by the system, and so they appear as a random binary file. For those, theres no info about the original file when I click on \"Get Info\".\nChromium.app, at the end of the build, is located inside the /out/Release folder. It contains the whole Chromium install, and the user can open Chromium by just clicking on it. Similarly, to \"install\" it (as in, make it appear on Spotlight with the other apps), you copy it to the /Applications folder. \nThe .dmg file is an iso-like file where, when the user opens it, the system mounts a virtual drive with the files inside the .dmg. For most software, inside the .dmg file theres the .app container and a shortcut to /Applications, so the user can drag it to the shortcut to install it.\n. So, right now, we just need to patch the files I pointed in this comment, test with the new libc++.a from that script and see if it works ootb. Then I'll test the whole process from start to see if we can get through without errors and as less user input as possible.\nUnfortunately, the user needs to trust the llvm's fingerprint 2 times when building libc++.a, so he can't really turn off his attention until that point (and the timeout is ridicously low lol). But I guess there is no solution for that.\nEdit: I've attached 2 pictures to show how a .dmg file looks like when opened by the user.\n\n\n\n\n. Okay, I'll be waiting for the next patches.\nBy the way, is buildlib configured to generate a 32-bit binary? I feel that this could be related to the compiler stopping after warnings, somehow.\nDepending on which OS X releases you want to support, its generally okay to drop 32-bit. All releases after Lion were 64-bit only.\nI'll work on these files asap so we can get a nice .dmg ready for distribution.\n. Got an error.\n```\nMorello$ python3 build.py\nTraceback (most recent call last):\n  File \"build.py\", line 44, in \n    exit(main())\n  File \"build.py\", line 32, in main\n    builder.check_build_environment()\nTypeError: check_build_environment() missing 1 required positional argument: 'self'\n```\n. Error:\n```\nMorello$ python3 build.py\n2016-08-29 16:32:38,338 - INFO: Initialized default logger\n2016-08-29 16:32:38,338 - INFO: sandbox_root path build_sandbox does not exist. Creating...\n2016-08-29 16:32:38,339 - INFO: _ungoogled_dir path build_sandbox/.ungoogled does not exist. Creating...\nTraceback (most recent call last):\n  File \"build.py\", line 44, in \n    exit(main())\n  File \"build.py\", line 33, in main\n    builder.setup_chromium_source()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 633, in setup_chromium_source\n    super(MacOSBuilder, self).setup_chromium_source()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 350, in setup_chromium_source\n    self.source_archive = self.download_dir / pathlib.Path(\"chromium-{version}.tar.xz\".format(version=self.chromium_version))\nAttributeError: 'MacOSBuilder' object has no attribute 'chromium_version'\n```\n. Error:\nMorello$ python3 build.py\n2016-08-29 17:00:42,061 - INFO: Initialized default logger\n2016-08-29 17:00:42,061 - INFO: sandbox_root path build_sandbox does not exist. Creating...\n2016-08-29 17:00:42,061 - INFO: _ungoogled_dir path build_sandbox/.ungoogled does not exist. Creating...\nTraceback (most recent call last):\n  File \"build.py\", line 44, in <module>\n    exit(main())\n  File \"build.py\", line 33, in main\n    builder.setup_chromium_source()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 630, in setup_chromium_source\n    super(MacOSBuilder, self).setup_chromium_source()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 351, in setup_chromium_source\n    self._download_if_needed(self.source_archive, \"https://commondatastorage.googleapis.com/chromium-browser-official/chromium-{version}.tar.xz\".format(version=self.chromium_version))\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 152, in _download_if_needed\n    elif force_download or not file_path.is_file():\nNameError: name 'force_download' is not defined\n. Got the usual visibility errors when trying to build libc++.a.\n. Yep, I do.\n. Got an error compiling libc++.a.\n+ popd\n/var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/libcpp.W2us72Tp/libcxxbuild ~/ungoogled-chromium\n+ mkdir libcxxabi\n+ pushd libcxxabi\n/var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/libcpp.W2us72Tp/libcxxbuild/libcxxabi /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/libcpp.W2us72Tp/libcxxbuild ~/ungoogled-chromium\n+ sed -i '' 's/\"default\"/\"hidden\"/g' ../../libcxxabi/src/CMakeLists.txt ../../libcxxabi/src/abort_message.cpp ../../libcxxabi/src/abort_message.h ../../libcxxabi/src/config.h ../../libcxxabi/src/cxa_aux_runtime.cpp ../../libcxxabi/src/cxa_default_handlers.cpp ../../libcxxabi/src/cxa_demangle.cpp ../../libcxxabi/src/cxa_exception.cpp ../../libcxxabi/src/cxa_exception.hpp ../../libcxxabi/src/cxa_exception_storage.cpp ../../libcxxabi/src/cxa_guard.cpp ../../libcxxabi/src/cxa_handlers.cpp ../../libcxxabi/src/cxa_handlers.hpp ../../libcxxabi/src/cxa_new_delete.cpp ../../libcxxabi/src/cxa_personality.cpp ../../libcxxabi/src/cxa_thread_atexit.cpp ../../libcxxabi/src/cxa_unexpected.cpp ../../libcxxabi/src/cxa_vector.cpp ../../libcxxabi/src/cxa_virtual.cpp ../../libcxxabi/src/exception.cpp ../../libcxxabi/src/fallback_malloc.ipp ../../libcxxabi/src/private_typeinfo.cpp ../../libcxxabi/src/private_typeinfo.h ../../libcxxabi/src/stdexcept.cpp ../../libcxxabi/src/typeinfo.cpp\n+ sed -i '' 's/push(default)/push(hidden)/g' ../../libcxxabi/src/CMakeLists.txt ../../libcxxabi/src/abort_message.cpp ../../libcxxabi/src/abort_message.h ../../libcxxabi/src/config.h ../../libcxxabi/src/cxa_aux_runtime.cpp ../../libcxxabi/src/cxa_default_handlers.cpp ../../libcxxabi/src/cxa_demangle.cpp ../../libcxxabi/src/cxa_exception.cpp ../../libcxxabi/src/cxa_exception.hpp ../../libcxxabi/src/cxa_exception_storage.cpp ../../libcxxabi/src/cxa_guard.cpp ../../libcxxabi/src/cxa_handlers.cpp ../../libcxxabi/src/cxa_handlers.hpp ../../libcxxabi/src/cxa_new_delete.cpp ../../libcxxabi/src/cxa_personality.cpp ../../libcxxabi/src/cxa_thread_atexit.cpp ../../libcxxabi/src/cxa_unexpected.cpp ../../libcxxabi/src/cxa_vector.cpp ../../libcxxabi/src/cxa_virtual.cpp ../../libcxxabi/src/exception.cpp ../../libcxxabi/src/fallback_malloc.ipp ../../libcxxabi/src/private_typeinfo.cpp ../../libcxxabi/src/private_typeinfo.h ../../libcxxabi/src/stdexcept.cpp ../../libcxxabi/src/typeinfo.cpp\n+ patch -d ../../libcxxabi -p0\nbuild_sandbox/third_party/libc++-static/build.sh: line 42: build_sandbox/third_party/libc++-static/libcxxabi.patch: No such file or directory\nTraceback (most recent call last):\n  File \"build.py\", line 44, in <module>\n    exit(main())\n  File \"build.py\", line 38, in main\n    builder.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 807, in build\n    raise Exception(\"libc++.a build script returned non-zero exit code\")\nException: libc++.a build script returned non-zero exit code\nungoogled-chromium Morello$ /Users/Morello/ungoogled-chromium/build_sandbox/third_party/libc++-static/libcxxabi.patch\nIt didn't find libcxxabi.patch for some reason. In the last line, I dragged libcxxabi.patch to the terminal to make sure the folder was the same.\nThis seems to be the same problem I had before. I got it to work by changing the way $THIS_DIR was defined in build.sh to this:\nTHIS_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\nEdit: just tested the change above and it worked. It started building Chromium now.\nEdit 2: I'm getting some interesting warnings this time.\nld: warning: object file (../../third_party/libc++-static/libc++.a(string.o)) was built for newer OSX version (10.11) than being linked (10.7)\nld: warning: object file (../../third_party/libc++-static/libc++.a(abort_message.o)) was built for newer OSX version (10.11) than being linked (10.7)\nld: warning: could not create compact unwind for __ZNKSt3__17num_putIcNS_19ostreambuf_iteratorIcNS_11char_traitsIcEEEEE3putES4_RNS_8ios_baseEcm: dwarf uses DW_CFA_GNU_args_size\nld: warning: object file (../../third_party/libc++-static/libc++.a(future.o)) was built for newer OSX version (10.11) than being linked (10.7)\nAnd tons of similar warnings. On the bright side, they are not stopping the compiler.\n. Its all done in the terminal. It asks if I want to trust the fringerprint, and I just need to press 'p' 2 times for the 2 downloads it does.\nThe annoying part is that the timeout is really small, so you can't start the script then pay attention to something else. If you miss the timeout, then you have to edit build.py (to comment the steps you've already done, ie patching) before trying it again.\n+ svn co --force https://llvm.org/svn/llvm-project/libcxx/trunk@245965 libcxx\nError validating server certificate for 'https://llvm.org:443':\n - The certificate is not issued by a trusted authority. Use the\n   fingerprint to validate the certificate manually!\nCertificate information:\n - Hostname: llvm.org\n - Valid: from Tue, 24 Jun 2014 00:00:00 GMT until Fri, 23 Jun 2017 23:59:59 GMT\n - Issuer: InCommon, Internet2, US\n - Fingerprint: 87:b8:45:4d:9d:66:7e:93:fb:30:58:79:bc:a7:f8:53:f0:44:05:69\n(R)eject, accept (t)emporarily or accept (p)ermanently? p\nI got the first warning about an unused constant in autofill_download_manager.cc and it stopped the compiling as usual.\nEdit: tried the new commit, it couldn't find build.sh:\nUpdating projects from gyp files...\n2016-08-30 12:05:30,377 - INFO: Building libc++.a ...\n/bin/sh: build_sandbox/third_party/libc++-static/build.sh: No such file or directory\nTraceback (most recent call last):\n  File \"build.py\", line 44, in <module>\n    exit(main())\n  File \"build.py\", line 38, in main\n    builder.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 807, in build\n    raise Exception(\"libc++.a build script returned non-zero exit code\")\nException: libc++.a build script returned non-zero exit code\n. You're the boss.\n```\nMorello$ svn help co\ncheckout (co): Check out a working copy from a repository.\nusage: checkout URL[@REV]... [PATH]\nIf specified, REV determines in which revision the URL is first\n  looked up.\nIf PATH is omitted, the basename of the URL will be used as\n  the destination. If multiple URLs are given each will be checked\n  out into a sub-directory of PATH, with the name of the sub-directory\n  being the basename of the URL.\nIf --force is used, unversioned obstructing paths in the working\n  copy destination do not automatically cause the check out to fail.\n  If the obstructing path is the same type (file or directory) as the\n  corresponding path in the repository it becomes versioned but its\n  contents are left 'as-is' in the working copy.  This means that an\n  obstructing directory's unversioned children may also obstruct and\n  become versioned.  For files, any content differences between the\n  obstruction and the repository are treated like a local modification\n  to the working copy.  All properties from the repository are applied\n  to the obstructing path.\nSee also 'svn help update' for a list of possible characters\n  reporting the action taken.\nValid options:\n  -r [--revision] ARG      : ARG (some commands also take ARG1:ARG2 range)\n                             A revision argument can be one of:\n                                NUMBER       revision number\n                                '{' DATE '}' revision at start of the date\n                                'HEAD'       latest in repository\n                                'BASE'       base rev of item's working copy\n                                'COMMITTED'  last commit at or before BASE\n                                'PREV'       revision just before COMMITTED\n  -q [--quiet]             : print nothing, or only summary information\n  -N [--non-recursive]     : obsolete; try --depth=files or --depth=immediates\n  --depth ARG              : limit operation by depth ARG ('empty', 'files',\n                             'immediates', or 'infinity')\n  --force                  : force operation to run\n  --ignore-externals       : ignore externals definitions\nGlobal options:\n  --username ARG           : specify a username ARG\n  --password ARG           : specify a password ARG\n  --no-auth-cache          : do not cache authentication tokens\n  --non-interactive        : do no interactive prompting\n  --trust-server-cert      : accept SSL server certificates from unknown\n                             certificate authorities without prompting (but only\n                             with '--non-interactive')\n  --config-dir ARG         : read user configuration files from directory ARG\n  --config-option ARG      : set user configuration option in the format:\n                                 FILE:SECTION:OPTION=[VALUE]\n                             For example:\n                                 servers:global:http-library=serf\n```\n--non-interactive and --trust-server-cert should solve this.\n. It didn't find build.sh for some reason.\nUpdating projects from gyp files...\n2016-08-30 23:39:48,526 - INFO: Building libc++.a ...\n/bin/sh: build.sh: command not found\nTraceback (most recent call last):\n  File \"build.py\", line 44, in <module>\n    exit(main())\n  File \"build.py\", line 38, in main\n    builder.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 808, in build\n    raise Exception(\"libc++.a build script returned non-zero exit code\")\nException: libc++.a build script returned non-zero exit code\n. Now it got to build libc++.a, but I had to manually trust the certificates like before.\nInteresting though, I get some warnings building it but it proceeds normally. Why would it stop when building Chromium?\n. Got an error, I think this is the first time we get this one.\nFAILED: obj/url/url_lib.gurl.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang++ -MMD -MF obj/url/url_lib.gurl.o.d -DV8_DEPRECATION_WARNINGS -DCLD_VERSION=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=264915-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DENABLE_TOPCHROME_MD=1 -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_AUTOFILL_DIALOG=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_APP_LIST=1 -DENABLE_SETTINGS_APP=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DURL_IMPLEMENTATION -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DUSE_LIBPCI=1 -DUSE_OPENSSL=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../third_party/icu/source/i18n -I../../third_party/icu/source/common -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing  -c ../../url/gurl.cc -o obj/url/url_lib.gurl.o\n../../url/gurl.cc:571:14: error: redefinition of 'gurl_strip_trk'\nstd::string &gurl_strip_trk(std::string &s)\n             ^\n../../url/gurl.cc:544:14: note: previous definition is here\nstd::string &gurl_strip_trk(std::string &s)\n             ^\n../../url/gurl.cc:576:6: error: redefinition of 'gurl_is_trq'\nbool gurl_is_trq(const std::string &s)\n     ^\n../../url/gurl.cc:549:6: note: previous definition is here\nbool gurl_is_trq(const std::string &s)\n     ^\n../../url/gurl.cc:583:12: error: redefinition of 'strip_trk'\nGURL GURL::strip_trk(void) const\n           ^\n../../url/gurl.cc:556:12: note: previous definition is here\nGURL GURL::strip_trk(void) const\n           ^\n../../url/gurl.cc:591:12: error: redefinition of 'is_trq'\nbool GURL::is_trq(void) const\n           ^\n../../url/gurl.cc:564:12: note: previous definition is here\nbool GURL::is_trq(void) const\n           ^\n4 errors generated.\n[5871/19472] ACTION Generating resourc... policy/resources/policy_templates.grd\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build.py\", line 44, in <module>\n    exit(main())\n  File \"build.py\", line 38, in main\n    builder.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 810, in build\n    super(MacOSBuilder, self).build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 510, in build\n    self._run_ninja(self.build_output, self.build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 361, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\n. > That's strange. I updated the Mac OS-specific patches already so SVN would get --non-interactive --trust-server-cert (EDIT: I mean trust-server-cert) flags in build.sh. Are you sure you applied the updated patches?\nYes, I'm sure. I had modified buildlib.py to skip already applied patches and remember reading the line where it applied the new ones.\nThe link you sent me solves the problem with trusting the fingerprints. It would ask me to trust it again after trusting it once.\n\nI'm slightly confused by your question. Are you asking why the warnings stop the Chromium build but not the build script for libc++? If so, that's because the build script manually invokes the compiler and has its own set of compiler flags. When building Chromium, GYP and Ninja determine the compiler and the flags to use.\nBy default, the compiler doesn't stop on warnings. But Google made warnings into errors, so it halts building. I tried setting a GYP flag to disable converting warnings into errors, but it doesn't seem to work on Mac OS. So I added a Mac OS-specific patch for a GYP file to disable converting warnings into errors.\n\nI see, thanks for the explanation.\n\nSomething is wrong with your url/gurl.cc file. I can see the definitions in the lines specified for the first occurance of every function, but there are no duplicates and your file has more lines than mine. Perhaps your build sandbox has become corrupted?\n\nI'll just delete the current folders and start from scratch. Maybe I messed up something.\n. Nice! It built libc++.a and started building Chromium without any input by me. Lets see how well it goes this time. I'm still getting those warnings, though:\nld: warning: object file (../../third_party/libc++-static/libc++.a(future.o)) was built for newer OSX version (10.11) than being linked (10.7)\nEdit: Yesss, I think you did the magic. I got two warnings that didn't stop the compiling process. Lets wait for the link.\n```\n../../components/autofill/core/browser/autofill_download_manager.cc:67:12: warning: unused variable 'kClientName' [-Wunused-const-variable]\nconst char kClientName[] = \"Chromium\";\n../../components/autofill/core/browser/autofill_download_manager.cc:88:6: warning: unused function 'GetRequestUrl' [-Wunused-function]\nGURL GetRequestUrl(AutofillDownloadManager::RequestType request_type) {\n```\nEdit 2: so close, yet so far.\n[19401/19472] PACKAGE FRAMEWORK 'Chromium Framework.framework', POSTBUILDS\nFAILED: Chromium Framework.framework \n./gyp-mac-tool package-framework 'Chromium Framework.framework' A && (export BUILT_FRAMEWORKS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export BUILT_PRODUCTS_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export CONFIGURATION=Release; export CONTENTS_FOLDER_PATH=\"Chromium Framework.framework/Versions/A\"; export DYLIB_INSTALL_NAME_BASE=@executable_path/../Versions/51.0.2704.106; export EXECUTABLE_NAME=\"Chromium Framework\"; export EXECUTABLE_PATH=\"Chromium Framework.framework/Versions/A/Chromium Framework\"; export FULL_PRODUCT_NAME=\"Chromium Framework.framework\"; export INFOPLIST_PATH=\"Chromium Framework.framework/Versions/A/Resources/Info.plist\"; export LD_DYLIB_INSTALL_NAME=\"@executable_path/../Versions/51.0.2704.106/Chromium Framework.framework/Chromium Framework\"; export MACH_O_TYPE=mh_dylib; export PRODUCT_NAME=\"Chromium Framework\"; export PRODUCT_TYPE=com.apple.product-type.framework; export SDKROOT=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk; export SRCROOT=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release/../../chrome; export SOURCE_ROOT=\"${SRCROOT}\"; export TARGET_BUILD_DIR=/Users/Morello/ungoogled-chromium/build_sandbox/out/Release; export TEMP_DIR=\"${TMPDIR}\"; export UNLOCALIZED_RESOURCES_FOLDER_PATH=\"Chromium Framework.framework/Versions/A/Resources\"; export WRAPPER_NAME=\"Chromium Framework.framework\"; export XCODE_VERSION_ACTUAL=0731; (cd ../../chrome && ../build/mac/tweak_info_plist.py \"--breakpad=1\" \"--breakpad_uploads=0\" \"--keystone=0\" \"--scm=1\" \"--branding=Chromium\" && tools/build/mac/verify_order _ChromeMain \"${BUILT_PRODUCTS_DIR}/${EXECUTABLE_PATH}\"); G=$?; ((exit $G) || rm -rf 'Chromium Framework.framework') && exit $G) && touch 'Chromium Framework.framework'\ntools/build/mac/verify_order: unordered symbols in /Users/Morello/ungoogled-chromium/build_sandbox/out/Release/Chromium Framework.framework/Versions/A/Chromium Framework:\n__Znwm\n__Znam\n__ZdlPv\n__ZdaPv\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"build.py\", line 44, in <module>\n    exit(main())\n  File \"build.py\", line 38, in main\n    builder.build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 810, in build\n    super(MacOSBuilder, self).build()\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 510, in build\n    self._run_ninja(self.build_output, self.build_targets)\n  File \"/Users/Morello/ungoogled-chromium/buildlib.py\", line 361, in _run_ninja\n    raise Exception(\"ninja returned non-zero exit code: {}\".format(result.returncode))\nException: ninja returned non-zero exit code: 1\nI think we built a broken libc++.a. Building it with the older one should work.\nSome warnings that may be relevant or not:\nld: warning: could not create compact unwind for __ZNKSt3__17num_putIcNS_19ostreambuf_iteratorIcNS_11char_traitsIcEEEEE3putES4_RNS_8ios_baseEcl: dwarf uses DW_CFA_GNU_args_size\nld: warning: could not create compact unwind for __ZNKSt3__17num_putIcNS_19ostreambuf_iteratorIcNS_11char_traitsIcEEEEE6do_putES4_RNS_8ios_baseEcl: dwarf uses DW_CFA_GNU_args_size\n. Welp, I messed up gurl.cc again.\nHere is what I did to apply the new patch: ran git pull, added the -N flag to the patch command, and changed the line 794 of buildlib.py to not stop if it returns 1. The output was skipping patches it had already applied:\n```\n2016-09-01 09:11:53,313 - DEBUG: Applying patch ungoogled-chromium/disable-domain-reliability.patch ...\npatching file components/domain_reliability/baked_in_configs.gypi\nReversed (or previously applied) patch detected!  Skipping patch.\n1 out of 1 hunk ignored -- saving rejects to file components/domain_reliability/baked_in_configs.gypi.rej\npatching file components/domain_reliability/google_configs.cc\nReversed (or previously applied) patch detected!  Skipping patch.\n2 out of 2 hunks ignored -- saving rejects to file components/domain_reliability/google_configs.cc.rej\npatching file components/domain_reliability/uploader.cc\nReversed (or previously applied) patch detected!  Skipping patch.\n1 out of 1 hunk ignored -- saving rejects to file components/domain_reliability/uploader.cc.rej\n2016-09-01 09:11:53,318 - DEBUG: Applying patch ungoogled-chromium/intercept-all-modified-domains.patch ...\npatching file chrome/app/chrome_main.cc\nReversed (or previously applied) patch detected!  Skipping patch.\n2 out of 2 hunks ignored -- saving rejects to file chrome/app/chrome_main.cc.rej\npatching file content/browser/browser_url_handler_impl.cc\nReversed (or previously applied) patch detected!  Skipping patch.\n1 out of 1 hunk ignored -- saving rejects to file content/browser/browser_url_handler_impl.cc.rej\npatching file url/gurl.cc\nHunk #1 succeeded at 582 (offset 27 lines).\nlater on...\n2016-09-01 09:11:53,254 - DEBUG: Applying patch ungoogled-chromium/prevent-trace-url-requests.patch ...\npatching file url/gurl.cc\nHunk #1 succeeded at 570 (offset 32 lines).\n```\nAs you can see, it fails to detect that gurl.cc was patched before and then reapplies the patch. I can just copy it from the older build, and the average user won't be running buildlib multiple times, but any idea on how to solve this? If skipping the already applied patches works, it'll make testing next releases easier.\nEdit: I'm reading the terminal again and another file got the patches reapplied. I'll list them.\n```\n2016-09-01 09:11:52,818 - DEBUG: Applying patch iridium-browser/net-add-trk-scheme-and-help-identify-URLs-being-retr.patch ...\npatching file chrome/app/chrome_main.cc\nHunk #1 FAILED at 7.\nHunk #2 succeeded at 51 (offset 19 lines).\nHunk #3 FAILED at 94.\npatching file chrome/app/chrome_main.cc\nHunk #1 succeeded at 54 (offset 21 lines).\n```\nEdit 2: I went and copied those 2 files from the older build directory. It worked! The users should now be able to build and run it on El Capitan without any extra work. Here are a few things we could try to improve:\n- On the OS X Chromium's top menu, there is still an \"Sign in\" option. Clicking it does nothing, so I suppose it can be harmlessly removed.\n- Make the installer look better - I can work on this, I suppose we need a .DS_Store file (could be the same from Firefox's), a background, and a volume icon. I'll try to make them and ask you for feedback.\n- Remove the connection it tries to make when adding another profile to ungoogled-chromium. Not sure if this was present on Linux, but if I click on \"Add person...\" in the Settings page, then on \"Sign in\", there is a connection attempt to a changed domain (which is blocked by ungoogled-chromium).\n- On the OS X Chromium's top menu, If I click on \"Help\", and then on \"Chromium Help\", it attempts to connect to a remote support page (and then its blocked by ungoogled-chromium).\n. Here is the .dmg: https://my.mixtape.moe/pdxynp.dmg\nYes, I'm happy we got this to work too. I hope I can contribute to future releases and debugging on OS X as well.\n. Aaand here we go!\nJust tried to build the next release, got the following error:\nMorello$ python3 build.py\n2016-09-16 23:20:25,859 - INFO: Initialized default console logging handler\n2016-09-16 23:20:25,859 - INFO: Using builder MacOSBuilder\n2016-09-16 23:20:25,859 - INFO: Checking Python 2 command...\n2016-09-16 23:20:25,859 - INFO: No Python 2 command specified; testing with 'python'\n2016-09-16 23:20:25,879 - DEBUG: Using Python version '2.7.12'\n2016-09-16 23:20:25,879 - INFO: Checking ninja command...\n2016-09-16 23:20:25,882 - DEBUG: Using ninja version '1.7.1'\n2016-09-16 23:20:25,883 - INFO: Checking quilt command...\n2016-09-16 23:20:25,886 - DEBUG: Using quilt command '0.64'\n2016-09-16 23:20:25,886 - INFO: Checking svn command...\n2016-09-16 23:20:26,284 - DEBUG: Using svn command version '1.9.4'\n2016-09-16 23:20:26,285 - INFO: Checking libtool command...\nerror: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: unknown option character `-' in: --version\nUsage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool -static [-] file [...] [-filelist listfile[,dirname]] [-arch_only arch] [-sacLT] [-no_warning_for_no_symbols]\nUsage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool -dynamic [-] file [...] [-filelist listfile[,dirname]] [-arch_only arch] [-o output] [-install_name name] [-compatibility_version #] [-current_version #] [-seg1addr 0x#] [-segs_read_only_addr 0x#] [-segs_read_write_addr 0x#] [-seg_addr_table <filename>] [-seg_addr_table_filename <file_system_path>] [-all_load] [-noall_load]\n2016-09-16 23:20:26,623 - ERROR: libtool command returned non-zero exit code 1\nMight be related to the new version of Xcode that was released a few days ago.\nI've managed to start building it by commenting the libtool check. I'm getting a lot of these warnings, though:\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIt stopped building after some time with the following error:\n[919/20047] OBJCXX obj/base/message_loop/base.message_pump_mac.o\nFAILED: obj/base/message_loop/base.message_pump_mac.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang++ -MMD -MF obj/base/message_loop/base.message_pump_mac.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DBASE_IMPLEMENTATION -DSYSTEM_NATIVE_UTF8 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wexit-time-destructors -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis -fobjc-call-cxx-cdtors  -c ../../base/message_loop/message_pump_mac.mm -o obj/base/message_loop/base.message_pump_mac.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../base/message_loop/message_pump_mac.mm:5:\nIn file included from ../../base/message_loop/message_pump_mac.h:47:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSArray.h:5:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h:44:12: error: unknown property attribute 'class'\n@property (class, readonly) BOOL supportsSecureCoding;\n           ^\nIn file included from ../../base/message_loop/message_pump_mac.mm:5:\nIn file included from ../../base/message_loop/message_pump_mac.h:47:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:6:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:262:12: error: unknown property attribute 'class'\n@property (class, readonly) const NSStringEncoding *availableStringEncodings;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:269:12: error: unknown property attribute 'class'\n@property (class, readonly) NSStringEncoding defaultCStringEncoding;    // Should be rarely used\n           ^\nIn file included from ../../base/message_loop/message_pump_mac.mm:5:\nIn file included from ../../base/message_loop/message_pump_mac.h:47:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:11:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSNotification.h:45:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSNotificationCenter *defaultCenter;\n           ^\nIn file included from ../../base/message_loop/message_pump_mac.mm:5:\nIn file included from ../../base/message_loop/message_pump_mac.h:47:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:33:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSBundle *mainBundle;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allBundles;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:47:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allFrameworks;\n           ^\nIn file included from ../../base/message_loop/message_pump_mac.mm:5:\nIn file included from ../../base/message_loop/message_pump_mac.h:47:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:7:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly) NSTimeInterval timeIntervalSinceReferenceDate;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:60:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantFuture;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:61:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantPast;\n           ^\nIn file included from ../../base/message_loop/message_pump_mac.mm:5:\nIn file included from ../../base/message_loop/message_pump_mac.h:47:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:108:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSCalendar *currentCalendar;                                  // user's preferred calendar\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:109:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSCalendar *autoupdatingCurrentCalendar NS_AVAILABLE(10_5, 2_0); // tracks changes to user's preferred calendar identifier\n           ^\nIn file included from ../../base/message_loop/message_pump_mac.mm:5:\nIn file included from ../../base/message_loop/message_pump_mac.h:47:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:15:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:21:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *controlCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:22:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:23:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceAndNewlineCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:24:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *decimalDigitCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:25:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *letterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:26:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *lowercaseLetterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:27:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *uppercaseLetterCharacterSet;\n                     ^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n2 warnings and 20 errors generated.\n[920/20047] CXX obj/ui/events/blink/events_blink.input_handler_proxy.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[921/20047] CXX obj/base/allocator/base.allocator_extension.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[922/20047] CXX obj/base/metrics/base.field_trial.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[923/20047] CXX obj/components/display_compositor/display_compositor.gl_helper.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[924/20047] CXX obj/base/base.sync_socket_posix.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[925/20047] CXX obj/base/base.at_exit.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[926/20047] CXX obj/components/gen/protoc_out...icy_proto_generated_compile.cloud_policy.pb.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[928/20047] ACTION Generating resources from policy/resources/policy_templates.grd\nninja: build stopped: subcommand failed.\n2016-09-16 23:56:11,894 - ERROR: ninja returned non-zero exit code: 1\n. So, I've made a simple background image we can use with the .dmg.\nI believe we can add some scripts from here to build the .dmg with the background and the correct icon sizes to fit: https://asmaloney.com/2013/07/howto/packaging-a-mac-os-x-application-using-a-dmg/\n\nAs for a volume icon, I'll see if I can mock up something... its definitively harder to make something passable. hehe\n. You're the boss.\n\n. For the third problem, I think its safe to remove it, along with the \"Report an issue...\" option (that one is grayed out and nothing happens when the user clicks on it).\nFor the second, maybe we should check first if Chromium somehow integrates with the OS X's users by any chance. But I suppose removing the \"Sign in\" link should be ok.\n. No, I didn't get a similar output running brew doctor. I'm still on El Capitan (10.11.6). It seems there aren't many clues on brew doctor:\n```\nPlease note that these warnings are just used to help the Homebrew maintainers\nwith debugging if you file an issue. If everything you use Homebrew for is\nworking fine: please don't worry and just ignore them. Thanks!\nWarning: Unbrewed dylibs were found in /usr/local/lib.\nIf you didn't put them there on purpose they could cause problems when\nbuilding Homebrew formulae, and may need to be deleted.\nUnexpected dylibs:\n    /usr/local/lib/libc++abi.dylib\n    /usr/local/lib/libcurl.4.dylib\nWarning: Unbrewed header files were found in /usr/local/include.\nIf you didn't put them there on purpose they could cause problems when\nbuilding Homebrew formulae, and may need to be deleted.\nUnexpected header files:\n    /usr/local/include/curl/curl.h\n    /usr/local/include/curl/curlbuild.h\n    /usr/local/include/curl/curlrules.h\n    /usr/local/include/curl/curlver.h\n    /usr/local/include/curl/easy.h\n    /usr/local/include/curl/mprintf.h\n    /usr/local/include/curl/multi.h\n    /usr/local/include/curl/stdcheaders.h\n    /usr/local/include/curl/typecheck-gcc.h\nWarning: Unbrewed .la files were found in /usr/local/lib.\nIf you didn't put them there on purpose they could cause problems when\nbuilding Homebrew formulae, and may need to be deleted.\nUnexpected .la files:\n    /usr/local/lib/libcurl.la\nWarning: Unbrewed .pc files were found in /usr/local/lib/pkgconfig.\nIf you didn't put them there on purpose they could cause problems when\nbuilding Homebrew formulae, and may need to be deleted.\nUnexpected .pc files:\n    /usr/local/lib/pkgconfig/libcurl.pc\nWarning: Unbrewed static libraries were found in /usr/local/lib.\nIf you didn't put them there on purpose they could cause problems when\nbuilding Homebrew formulae, and may need to be deleted.\nUnexpected static libraries:\n    /usr/local/lib/libcurl.a\n```\nAnyway, I just ran brew update, brew upgrade and started from scratch. It got a bit further. Also, it seems it restarted despite failing building some files.\n[2963/20047] OBJC obj/third_party/goog...it/google_toolbox_for_mac.GTMIBArray.o\nFAILED: obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMIBArray.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang -MMD -MF obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMIBArray.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/google_toolbox_for_mac -I../../third_party/google_toolbox_for_mac/src -I../../third_party/google_toolbox_for_mac/src/AppKit -I../../third_party/google_toolbox_for_mac/src/DebugUtils -I../../third_party/google_toolbox_for_mac/src/Foundation -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-unused-variable -std=c99 -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis  -c ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.m -o obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMIBArray.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSArray.h:5:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h:44:12: error: unknown property attribute 'class'\n@property (class, readonly) BOOL supportsSecureCoding;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:6:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:262:12: error: unknown property attribute 'class'\n@property (class, readonly) const NSStringEncoding *availableStringEncodings;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:269:12: error: unknown property attribute 'class'\n@property (class, readonly) NSStringEncoding defaultCStringEncoding;    // Should be rarely used\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:11:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSNotification.h:45:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSNotificationCenter *defaultCenter;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:33:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSBundle *mainBundle;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allBundles;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:47:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allFrameworks;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:7:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly) NSTimeInterval timeIntervalSinceReferenceDate;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:60:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantFuture;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:61:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantPast;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:108:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSCalendar *currentCalendar;                                  // user's preferred calendar\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:109:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSCalendar *autoupdatingCurrentCalendar NS_AVAILABLE(10_5, 2_0); // tracks changes to user's preferred calendar identifier\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMIBArray.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:15:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:21:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *controlCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:22:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:23:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceAndNewlineCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:24:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *decimalDigitCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:25:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *letterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:26:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *lowercaseLetterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:27:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *uppercaseLetterCharacterSet;\n                     ^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n2 warnings and 20 errors generated.\n[2964/20047] OBJC obj/third_party/goog...toolbox_for_mac.GTMKeyValueAnimation.o\nFAILED: obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMKeyValueAnimation.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang -MMD -MF obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMKeyValueAnimation.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/google_toolbox_for_mac -I../../third_party/google_toolbox_for_mac/src -I../../third_party/google_toolbox_for_mac/src/AppKit -I../../third_party/google_toolbox_for_mac/src/DebugUtils -I../../third_party/google_toolbox_for_mac/src/Foundation -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-unused-variable -std=c99 -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis  -c ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.m -o obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMKeyValueAnimation.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.h:18:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSArray.h:5:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h:44:12: error: unknown property attribute 'class'\n@property (class, readonly) BOOL supportsSecureCoding;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.h:18:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:6:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:262:12: error: unknown property attribute 'class'\n@property (class, readonly) const NSStringEncoding *availableStringEncodings;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:269:12: error: unknown property attribute 'class'\n@property (class, readonly) NSStringEncoding defaultCStringEncoding;    // Should be rarely used\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.h:18:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:11:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSNotification.h:45:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSNotificationCenter *defaultCenter;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.h:18:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:33:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSBundle *mainBundle;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allBundles;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:47:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allFrameworks;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.h:18:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:7:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly) NSTimeInterval timeIntervalSinceReferenceDate;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:60:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantFuture;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:61:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantPast;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.h:18:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:108:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSCalendar *currentCalendar;                                  // user's preferred calendar\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:109:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSCalendar *autoupdatingCurrentCalendar NS_AVAILABLE(10_5, 2_0); // tracks changes to user's preferred calendar identifier\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMKeyValueAnimation.h:18:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:15:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:21:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *controlCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:22:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:23:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceAndNewlineCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:24:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *decimalDigitCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:25:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *letterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:26:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *lowercaseLetterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:27:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *uppercaseLetterCharacterSet;\n                     ^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n2 warnings and 20 errors generated.\n[2965/20047] OBJC obj/third_party/goog...r_mac.GTMFadeTruncatingTextFieldCell.o\nFAILED: obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMFadeTruncatingTextFieldCell.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang -MMD -MF obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMFadeTruncatingTextFieldCell.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/google_toolbox_for_mac -I../../third_party/google_toolbox_for_mac/src -I../../third_party/google_toolbox_for_mac/src/AppKit -I../../third_party/google_toolbox_for_mac/src/DebugUtils -I../../third_party/google_toolbox_for_mac/src/Foundation -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-unused-variable -std=c99 -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis  -c ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.m -o obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMFadeTruncatingTextFieldCell.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSArray.h:5:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h:44:12: error: unknown property attribute 'class'\n@property (class, readonly) BOOL supportsSecureCoding;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:6:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:262:12: error: unknown property attribute 'class'\n@property (class, readonly) const NSStringEncoding *availableStringEncodings;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:269:12: error: unknown property attribute 'class'\n@property (class, readonly) NSStringEncoding defaultCStringEncoding;    // Should be rarely used\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:11:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSNotification.h:45:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSNotificationCenter *defaultCenter;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:33:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSBundle *mainBundle;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allBundles;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:47:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allFrameworks;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:7:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly) NSTimeInterval timeIntervalSinceReferenceDate;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:60:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantFuture;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:61:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantPast;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:108:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSCalendar *currentCalendar;                                  // user's preferred calendar\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:109:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSCalendar *autoupdatingCurrentCalendar NS_AVAILABLE(10_5, 2_0); // tracks changes to user's preferred calendar identifier\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.m:18:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMFadeTruncatingTextFieldCell.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:15:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:21:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *controlCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:22:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:23:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceAndNewlineCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:24:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *decimalDigitCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:25:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *letterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:26:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *lowercaseLetterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:27:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *uppercaseLetterCharacterSet;\n                     ^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n2 warnings and 20 errors generated.\n[2966/20047] OBJC obj/third_party/goog...lbox_for_mac.GTMNSAnimation+Duration.o\nFAILED: obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMNSAnimation+Duration.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang -MMD -MF obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMNSAnimation+Duration.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/google_toolbox_for_mac -I../../third_party/google_toolbox_for_mac/src -I../../third_party/google_toolbox_for_mac/src/AppKit -I../../third_party/google_toolbox_for_mac/src/DebugUtils -I../../third_party/google_toolbox_for_mac/src/Foundation -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-unused-variable -std=c99 -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis  -c ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.m -o obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMNSAnimation+Duration.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.h:20:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSArray.h:5:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h:44:12: error: unknown property attribute 'class'\n@property (class, readonly) BOOL supportsSecureCoding;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.h:20:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:6:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:262:12: error: unknown property attribute 'class'\n@property (class, readonly) const NSStringEncoding *availableStringEncodings;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:269:12: error: unknown property attribute 'class'\n@property (class, readonly) NSStringEncoding defaultCStringEncoding;    // Should be rarely used\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.h:20:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:11:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSNotification.h:45:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSNotificationCenter *defaultCenter;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.h:20:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:33:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSBundle *mainBundle;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allBundles;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:47:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allFrameworks;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.h:20:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:7:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly) NSTimeInterval timeIntervalSinceReferenceDate;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:60:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantFuture;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:61:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantPast;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.h:20:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:108:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSCalendar *currentCalendar;                                  // user's preferred calendar\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:109:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSCalendar *autoupdatingCurrentCalendar NS_AVAILABLE(10_5, 2_0); // tracks changes to user's preferred calendar identifier\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSAnimation+Duration.h:20:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/AppKit.framework/Headers/AppKit.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:15:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:21:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *controlCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:22:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:23:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceAndNewlineCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:24:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *decimalDigitCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:25:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *letterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:26:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *lowercaseLetterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:27:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *uppercaseLetterCharacterSet;\n                     ^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n2 warnings and 20 errors generated.\n[2967/20047] OBJC obj/third_party/goog...oogle_toolbox_for_mac.GTMCarbonEvent.o\nFAILED: obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMCarbonEvent.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang -MMD -MF obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMCarbonEvent.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/google_toolbox_for_mac -I../../third_party/google_toolbox_for_mac/src -I../../third_party/google_toolbox_for_mac/src/AppKit -I../../third_party/google_toolbox_for_mac/src/DebugUtils -I../../third_party/google_toolbox_for_mac/src/Foundation -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-unused-variable -std=c99 -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis  -c ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.m -o obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMCarbonEvent.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSArray.h:5:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h:44:12: error: unknown property attribute 'class'\n@property (class, readonly) BOOL supportsSecureCoding;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:6:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:262:12: error: unknown property attribute 'class'\n@property (class, readonly) const NSStringEncoding *availableStringEncodings;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:269:12: error: unknown property attribute 'class'\n@property (class, readonly) NSStringEncoding defaultCStringEncoding;    // Should be rarely used\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:11:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSNotification.h:45:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSNotificationCenter *defaultCenter;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:33:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSBundle *mainBundle;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allBundles;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:47:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allFrameworks;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:7:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly) NSTimeInterval timeIntervalSinceReferenceDate;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:60:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantFuture;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:61:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantPast;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:108:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSCalendar *currentCalendar;                                  // user's preferred calendar\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:109:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSCalendar *autoupdatingCurrentCalendar NS_AVAILABLE(10_5, 2_0); // tracks changes to user's preferred calendar identifier\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.m:19:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMCarbonEvent.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:15:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:21:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *controlCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:22:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:23:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceAndNewlineCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:24:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *decimalDigitCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:25:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *letterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:26:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *lowercaseLetterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:27:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *uppercaseLetterCharacterSet;\n                     ^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n2 warnings and 20 errors generated.\n[2968/20047] OBJC obj/third_party/goog...olbox_for_mac.GTMNSBezierPath+CGPath.o\nFAILED: obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMNSBezierPath+CGPath.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang -MMD -MF obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMNSBezierPath+CGPath.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_LIBPCI=1 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -Igen -I../../third_party/google_toolbox_for_mac -I../../third_party/google_toolbox_for_mac/src -I../../third_party/google_toolbox_for_mac/src/AppKit -I../../third_party/google_toolbox_for_mac/src/DebugUtils -I../../third_party/google_toolbox_for_mac/src/Foundation -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-unused-variable -std=c99 -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis  -c ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.m -o obj/third_party/google_toolbox_for_mac/src/AppKit/google_toolbox_for_mac.GTMNSBezierPath+CGPath.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSArray.h:5:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h:44:12: error: unknown property attribute 'class'\n@property (class, readonly) BOOL supportsSecureCoding;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:6:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:262:12: error: unknown property attribute 'class'\n@property (class, readonly) const NSStringEncoding *availableStringEncodings;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:269:12: error: unknown property attribute 'class'\n@property (class, readonly) NSStringEncoding defaultCStringEncoding;    // Should be rarely used\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:11:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSNotification.h:45:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSNotificationCenter *defaultCenter;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:33:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSBundle *mainBundle;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allBundles;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:47:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allFrameworks;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:7:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly) NSTimeInterval timeIntervalSinceReferenceDate;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:60:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantFuture;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:61:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantPast;\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:108:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSCalendar *currentCalendar;                                  // user's preferred calendar\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:109:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSCalendar *autoupdatingCurrentCalendar NS_AVAILABLE(10_5, 2_0); // tracks changes to user's preferred calendar identifier\n           ^\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.m:20:\nIn file included from ../../third_party/google_toolbox_for_mac/src/AppKit/GTMNSBezierPath+CGPath.h:19:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:15:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:21:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *controlCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:22:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:23:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceAndNewlineCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:24:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *decimalDigitCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:25:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *letterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:26:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *lowercaseLetterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:27:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *uppercaseLetterCharacterSet;\n                     ^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n2 warnings and 20 errors generated.\n[2969/20047] CXX obj/third_party/harfbuzz-ng/src/harfbuzz-ng.hb-coretext.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[2970/20047] CXX obj/third_party/harfb...z-ng.hb-ot-shape-complex-indic-table.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[2971/20047] CXX obj/third_party/harfbuzz-ng/src/harfbuzz-ng.hb-ot-layout.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[2972/20047] CC obj/third_party/sqlite/amalgamation/sqlite.sqlite3.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\nninja: build stopped: subcommand failed.\n2016-09-17 17:12:17,820 - ERROR: ninja returned non-zero exit code: 1\n. I don't, and I'm not sure it should have. The MacOSX10.12.sdk folder is just a link to the MacOSX.sdk folder.\nI also have a MacOSX10.6.sdk folder that I installed for something else.\n. I got 10.11's SDK from here and added to the Xcode folder. Its compiling, lets see what happens.\n. I just downloaded MacOSX10.11.sdk and copied it to to the same folder where MacOSX10.12.sdk is. I haven't changed any flag or anything. The only edit I did was comment some lines in build.py to resume the build properly.\nIts compiling just fine so far. hahaha\nEdit: and just as I was posting this...\n[10001/19885] OBJCXX obj/device/blueto...th.bluetooth_remote_gatt_service_mac.o\nFAILED: obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang++ -MMD -MF obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DDEVICE_BLUETOOTH_IMPLEMENTATION -DSK_SUPPORT_GPU=1 -DSK_IGNORE_DW_GRAY_FIX -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DUSE_LIBPCI=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../skia/config -I../../third_party/boringssl/src/include -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/pdf -I../../third_party/skia/include/gpu -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/utils/mac -I../../skia/ext -I../../third_party/icu/source/i18n -I../../third_party/icu/source/common -Igen/device/bluetooth/strings -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis -fobjc-call-cxx-cdtors  -c ../../device/bluetooth/bluetooth_remote_gatt_service_mac.mm -o obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../device/bluetooth/bluetooth_remote_gatt_service_mac.mm:5:\nIn file included from ../../device/bluetooth/bluetooth_remote_gatt_service_mac.h:12:\nIn file included from ../../base/containers/scoped_ptr_hash_map.h:14:\nIn file included from ../../base/containers/hash_tables.h:9:\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/unordered_map:605:11: error: call to implicitly-deleted copy constructor of 'value_type' (aka 'pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >')\n        : __cc(std::forward<_Args>(__args)...) {}\n          ^    ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/memory:1740:31: note: in instantiation of function template specialization 'std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >::__hash_value_type<const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n            ::new((void*)__p) _Up(_VSTD::forward<_Args>(__args)...);\n                              ^\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/memory:1656:18: note: in instantiation of function template specialization 'std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, void *> >::construct<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n            {__a.construct(__p, _VSTD::forward<_Args>(__args)...);}\n                 ^\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/memory:1502:14: note: in instantiation of function template specialization 'std::__1::allocator_traits<std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, void *> > >::__construct<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n            {__construct(__has_construct<allocator_type, _Tp*, _Args...>(),\n             ^\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/__hash_table:2044:20: note: in instantiation of function template specialization 'std::__1::allocator_traits<std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, void *> > >::construct<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n    __node_traits::construct(__na, _VSTD::addressof(__h->__value_), _VSTD::forward<_Args>(__args)...);\n                   ^\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/__hash_table:1828:25: note: in instantiation of function template specialization 'std::__1::__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > > >::__construct_node<const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n    __node_holder __h = __construct_node(_VSTD::forward<_Pp>(__x));\n                        ^\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/unordered_map:945:26: note: in instantiation of function template specialization 'std::__1::__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > > >::__insert_unique<const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n        {return __table_.__insert_unique(__x);}\n                         ^\n../../device/bluetooth/bluetooth_remote_gatt_service_mac.mm:103:50: note: in instantiation of member function 'std::__1::unordered_map<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> >, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > > >::insert' requested here\n    auto result_iter = gatt_characteristic_macs_.insert(\n                                                 ^\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/utility:315:5: note: explicitly defaulted function was implicitly deleted here\n    pair(const pair& __p) = default;\n    ^\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/utility:286:9: note: copy constructor of 'pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >' is implicitly deleted because field 'second' has a deleted copy constructor\n    _T2 second;\n        ^\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/memory:2613:31: note: copy constructor is implicitly deleted because 'unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> >' has a user-declared move constructor\n    _LIBCPP_INLINE_VISIBILITY unique_ptr(unique_ptr&& __u) _NOEXCEPT\n                              ^\n2 warnings and 1 error generated.\n[10002/19885] OBJCXX obj/device/blueto...tooth_remote_gatt_characteristic_mac.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[10003/19885] CXX obj/device/bluetooth...oth_mojom.bluetooth_uuid.mojom-blink.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[10004/19885] CXX obj/device/bluetooth...bluetooth_mojom.bluetooth_uuid.mojom.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[10005/19885] CXX obj/third_party/WebK...vice_worker_event_status.mojom-blink.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[10006/19885] OBJCXX obj/device/blueto...evice_bluetooth.bluetooth_socket_mac.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[10007/19885] CXX obj/third_party/WebK...ojo_bindings.geolocation.mojom-blink.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[10008/19885] CXX obj/third_party/WebK...o_bindings.mime_registry.mojom-blink.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[10009/19885] CXX obj/third_party/WebK...ngs.notification_service.mojom-blink.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[10010/19885] CXX obj/third_party/WebK...bindings.background_sync.mojom-blink.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\nninja: build stopped: subcommand failed.\n2016-09-17 18:59:46,416 - ERROR: ninja returned non-zero exit code: 1\nEdit: I've made a few tests. I renamed the folders to make MacOSX.sdk have the contents of 10.11's SDK. Got the same error at the same place. Was there any change related to bluetooth and Macs in this version of Chromium?\n. Got an error:\n[1382/20047] CXX obj/printing/backend/printing.print_backend_cups.o\nFAILED: obj/printing/backend/printing.print_backend_cups.o \nc++ -MMD -MF obj/printing/backend/printing.print_backend_cups.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DPRINTING_IMPLEMENTATION -DPRINT_BACKEND_AVAILABLE -DSK_SUPPORT_GPU=1 -DSK_IGNORE_DW_GRAY_FIX -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DUSE_CUPS -DUSE_LIBPCI=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../skia/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/pdf -I../../third_party/skia/include/gpu -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/utils/mac -I../../skia/ext -I../../third_party/icu/source/i18n -I../../third_party/icu/source/common -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing  -c ../../printing/backend/print_backend_cups.cc -o obj/printing/backend/printing.print_backend_cups.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n../../printing/backend/print_backend_cups.cc:243:21: error: use of undeclared identifier 'cupsGetPPD'\n    ppd_file_path = cupsGetPPD(name);\n                    ^\n../../printing/backend/print_backend_cups.cc:256:21: error: use of undeclared identifier 'cupsGetPPD2'\n    ppd_file_path = cupsGetPPD2(http.http(), name);\n                    ^\n2 warnings and 2 errors generated.\n. Got another error related to bluetooth.\n[5543/18659] OBJCXX obj/device/bluetoo...th.bluetooth_remote_gatt_service_mac.o\nFAILED: obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o \nc++ -MMD -MF obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DDEVICE_BLUETOOTH_IMPLEMENTATION -DSK_SUPPORT_GPU=1 -DSK_IGNORE_DW_GRAY_FIX -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DUSE_LIBPCI=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../skia/config -I../../third_party/boringssl/src/include -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/pdf -I../../third_party/skia/include/gpu -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/utils/mac -I../../skia/ext -I../../third_party/icu/source/i18n -I../../third_party/icu/source/common -Igen/device/bluetooth/strings -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis -fobjc-call-cxx-cdtors  -c ../../device/bluetooth/bluetooth_remote_gatt_service_mac.mm -o obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../device/bluetooth/bluetooth_remote_gatt_service_mac.mm:5:\nIn file included from ../../device/bluetooth/bluetooth_remote_gatt_service_mac.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/vector:265:\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/__bit_reference:15:\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/algorithm:628:\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/memory:1740:31: error: call to implicitly-deleted copy constructor of 'std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >'\n            ::new((void*)__p) _Up(_VSTD::forward<_Args>(__args)...);\n                              ^   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/memory:1656:18: note: in instantiation of function template specialization 'std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, void *> >::construct<std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n            {__a.construct(__p, _VSTD::forward<_Args>(__args)...);}\n                 ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/memory:1502:14: note: in instantiation of function template specialization 'std::__1::allocator_traits<std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, void *> > >::__construct<std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n            {__construct(__has_construct<allocator_type, _Tp*, _Args...>(),\n             ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/__hash_table:2276:20: note: in instantiation of function template specialization 'std::__1::allocator_traits<std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, void *> > >::construct<std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n    __node_traits::construct(__na, _NodeTypes::__get_ptr(__h->__value_),\n                   ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/__hash_table:1998:29: note: in instantiation of function template specialization 'std::__1::__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > > >::__construct_node_hash<const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n        __node_holder __h = __construct_node_hash(__hash, _VSTD::forward<_Args>(__args)...);\n                            ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/__hash_table:1144:16: note: in instantiation of function template specialization 'std::__1::__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > > >::__emplace_unique_key_args<std::__1::basic_string<char>, const std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > &>' requested here\n        return __emplace_unique_key_args(_NodeTypes::__get_key(__x), __x);\n               ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/unordered_map:934:26: note: in instantiation of member function 'std::__1::__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > > >::__insert_unique' requested here\n        {return __table_.__insert_unique(__x);}\n                         ^\n../../device/bluetooth/bluetooth_remote_gatt_service_mac.mm:103:50: note: in instantiation of member function 'std::__1::unordered_map<std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> >, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > > > >::insert' requested here\n    auto result_iter = gatt_characteristic_macs_.insert(\n                                                 ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/utility:288:5: note: explicitly defaulted function was implicitly deleted here\n    pair(const pair& __p) = default;\n    ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/utility:259:9: note: copy constructor of 'pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >' is implicitly deleted because field 'second' has a deleted copy constructor\n    _T2 second;\n        ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/memory:2609:31: note: copy constructor is implicitly deleted because 'unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> >' has a user-declared move constructor\n    _LIBCPP_INLINE_VISIBILITY unique_ptr(unique_ptr&& __u) _NOEXCEPT\n                              ^\n2 warnings and 1 error generated.\n[5544/18659] CXX obj/device/bluetooth/device_bluetooth.bluetooth_socket_net.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[5545/18659] OBJCXX obj/device/bluetoo...tooth_remote_gatt_characteristic_mac.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[5546/18659] OBJCXX obj/device/bluetoo...evice_bluetooth.bluetooth_socket_mac.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\n2 warnings generated.\n[5552/18659] ACTION Generating about:credits\nninja: build stopped: subcommand failed.\n2016-09-18 21:41:29,944 - ERROR: ninja returned non-zero exit code: 1\n. I did what you said and got an error in /skia/ext/skia_histogram.h (and a bunch of other files) saying it couldn't find the cstdint header. Changing it to cstdint.h made it start compiling again, but I got the same error with another header:\n```\nIn file included from ../../third_party/zlib/google/compression_utils.cc:13:\n../../base/bit_cast.h:9:10: fatal error: 'type_traits' file not found\ninclude \n```\nChanging this to type_traits.h didn't make it work. I've tried a few values for std (c++0x, c++11, etc.) and stdlib (libc++, libstdc++), but got the same result.\nEdit: this answer is relevant to the SDK stuff.\nhttps://stackoverflow.com/questions/38960314/getting-fatal-error-type-traits-file-not-found-include-type-traits-while\n. Relevant information: I tried to build it with homebrew's clang... and got the same error. Doesn't seem to be a problem with Xcode.\n[5005/14906] OBJCXX obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o\nFAILED: obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o \n/usr/local/Cellar/llvm/3.8.1/bin/clang++ -MMD -MF obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DDEVICE_BLUETOOTH_IMPLEMENTATION -DSK_SUPPORT_GPU=1 -DSK_IGNORE_DW_GRAY_FIX -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DUSE_LIBPCI=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../skia/config -I../../third_party/boringssl/src/include -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/pdf -I../../third_party/skia/include/gpu -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/utils/mac -I../../skia/ext -I../../third_party/icu/source/i18n -I../../third_party/icu/source/common -Igen/device/bluetooth/strings -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis -fobjc-call-cxx-cdtors  -c ../../device/bluetooth/bluetooth_remote_gatt_service_mac.mm -o obj/device/bluetooth/device_bluetooth.bluetooth_remote_gatt_service_mac.o\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../device/bluetooth/bluetooth_remote_gatt_service_mac.mm:5:\nIn file included from ../../device/bluetooth/bluetooth_remote_gatt_service_mac.h:12:\nIn file included from ../../base/containers/scoped_ptr_hash_map.h:14:\nIn file included from ../../base/containers/hash_tables.h:9:\n/usr/local/Cellar/llvm/3.8.1/bin/../include/c++/v1/unordered_map:605:11: error: call to implicitly-deleted copy constructor of 'value_type' (aka 'pair<const std::__1::basic_string<char>, std::__1::unique_ptr<device::BluetoothRemoteGattCharacteristicMac, std::__1::default_delete<device::BluetoothRemoteGattCharacteristicMac> > >')\nThat being said, I had to switch to the OSX 10.11's SDK, as I was getting these errors with 10.12:\n[13/18710] OBJCXX obj/third_party/WebKit/Source/build/mac/webcore_remaining.Prefix.h-mm.gch\nFAILED: obj/third_party/WebKit/Source/build/mac/webcore_remaining.Prefix.h-mm.gch \n/usr/local/Cellar/llvm/3.8.1/bin/clang++ -MMD -MF obj/third_party/WebKit/Source/build/mac/webcore_remaining.Prefix.h-mm.gch.d -DV8_DEPRECATION_WARNINGS -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=274142-1 -DUSE_LIBJPEG_TURBO=1 -DENABLE_MEDIA_ROUTER=1 -DUSE_PROPRIETARY_CODECS -DENABLE_PEPPER_CDMS -DENABLE_NOTIFICATIONS -DUSE_EXTERNAL_POPUP_MENU -DTRACING_IS_OFFICIAL_BUILD=1 -DENABLE_TASK_MANAGER=1 -DENABLE_EXTENSIONS=1 -DENABLE_PDF=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_PLUGINS=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_THEMES=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DV8_USE_EXTERNAL_STARTUP_DATA -DBLINK_IMPLEMENTATION=1 -DINSIDE_BLINK -DENABLE_LAYOUT_UNIT_IN_INLINE_BOXES=0 -DENABLE_OILPAN=1 -DWTF_USE_CONCATENATED_IMPULSE_RESPONSES=1 -DWTF_USE_ICCJPEG=1 -DWTF_USE_QCMSLIB=1 -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DSK_SUPPORT_GPU=1 -DSK_IGNORE_DW_GRAY_FIX -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DLIBXML_STATIC -DLIBXSLT_STATIC -DUSE_LIBPCI=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -D_FORTIFY_SOURCE=2 -Igen -I../.. -I../../skia/config -I../../third_party/WebKit/Source -I../../third_party/khronos -I../../gpu -Igen/angle -Igen/blink -I../../third_party/angle/include -I../../third_party/icu/source/i18n -I../../third_party/icu/source/common -I../../third_party/WebKit -Igen/third_party/WebKit -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/pdf -I../../third_party/skia/include/gpu -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/utils/mac -I../../skia/ext -I../../third_party/iccjpeg -I../../third_party/libpng -I../../third_party/libwebp -I../../third_party/libxml/mac/include -I../../third_party/libxml/src/include -I../../third_party/libxslt -I../../third_party/ots/include -I../../third_party/qcms/src -I../../third_party/zlib -I../../v8/include -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -O2 -fvisibility=hidden -mmacosx-version-min=10.7 -arch x86_64 -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-selector-type-mismatch -Wpartial-availability -Wheader-hygiene -Wno-char-subscripts -Wno-unneeded-internal-declaration -Wno-covered-switch-default -Wstring-conversion -Wno-c++11-narrowing -Wno-deprecated-register -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wglobal-constructors -Wexit-time-destructors -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -fno-threadsafe-statics -fcolor-diagnostics -fno-strict-aliasing -Wobjc-missing-property-synthesis -fobjc-call-cxx-cdtors -x objective-c++-header -c ../../third_party/WebKit/Source/build/mac/Prefix.h -o obj/third_party/WebKit/Source/build/mac/webcore_remaining.Prefix.h-mm.gch\nwarning: unknown warning option '-Wno-undefined-var-template'; did you mean '-Wno-undefined-internal'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-nonportable-include-path'; did you mean '-Wno-gnu-include-next'? [-Wunknown-warning-option]\nIn file included from ../../third_party/WebKit/Source/build/mac/Prefix.h:54:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:10:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSArray.h:5:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h:44:12: error: unknown property attribute 'class'\n@property (class, readonly) BOOL supportsSecureCoding;\n           ^\nIn file included from ../../third_party/WebKit/Source/build/mac/Prefix.h:54:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:6:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:262:12: error: unknown property attribute 'class'\n@property (class, readonly) const NSStringEncoding *availableStringEncodings;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSString.h:269:12: error: unknown property attribute 'class'\n@property (class, readonly) NSStringEncoding defaultCStringEncoding;    // Should be rarely used\n           ^\nIn file included from ../../third_party/WebKit/Source/build/mac/Prefix.h:54:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:11:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSNotification.h:45:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSNotificationCenter *defaultCenter;\n           ^\nIn file included from ../../third_party/WebKit/Source/build/mac/Prefix.h:54:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:12:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:33:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSBundle *mainBundle;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allBundles;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSBundle.h:47:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSArray<NSBundle *> *allFrameworks;\n           ^\nIn file included from ../../third_party/WebKit/Source/build/mac/Prefix.h:54:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:7:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:46:12: error: unknown property attribute 'class'\n@property (class, readonly) NSTimeInterval timeIntervalSinceReferenceDate;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:60:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantFuture;\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSDate.h:61:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSDate *distantPast;\n           ^\nIn file included from ../../third_party/WebKit/Source/build/mac/Prefix.h:54:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:14:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:108:12: error: unknown property attribute 'class'\n@property (class, readonly, copy) NSCalendar *currentCalendar;                                  // user's preferred calendar\n           ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCalendar.h:109:12: error: unknown property attribute 'class'\n@property (class, readonly, strong) NSCalendar *autoupdatingCurrentCalendar NS_AVAILABLE(10_5, 2_0); // tracks changes to user's preferred calendar identifier\n           ^\nIn file included from ../../third_party/WebKit/Source/build/mac/Prefix.h:54:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Cocoa.framework/Headers/Cocoa.h:12:\nIn file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h:15:\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:21:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *controlCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:22:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:23:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *whitespaceAndNewlineCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:24:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *decimalDigitCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:25:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *letterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:26:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *lowercaseLetterCharacterSet;\n                     ^\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSCharacterSet.h:27:22: error: unknown property attribute 'class'\n@property (readonly, class, copy) NSCharacterSet *uppercaseLetterCharacterSet;\n                     ^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n2 warnings and 20 errors generated.\nWhat SDK does Google use?\n. I tried getting a newer version of llvm, turns out Xcode 8.0 has problems building it. haha Now I can't even install llvm3.8 from homebrew.\nI'll look into downgrading Xcode to 7.3.\nEdit: I think I found the problem. I'm using Xcode 7.3's command line tools with Xcode 8.0. This is probably messing with the compiling of llvm and chromium.\nUnfortunately, it seems Xcode 8.0's CLT got released for Sierra only so far. Maybe an El Capitan version will appear next days.\nMore info: https://forums.developer.apple.com/thread/63250\n. Well, I've looked around and it seems some of my hardware don't support Sierra (yet). I was going to update  just for this, but I guess I'm going to downgrade Xcode to 7.3.1 and try again.\nAnything I should look for before trying to compile?\nEdit: downgraded Xcode 7.3.1. At first, I got the same error. We might have to wait a few days before llvm 3.9 gets officially released on homebrew.\nhttps://github.com/Homebrew/homebrew-core/issues/4937\n. I'll probably install it from homebrew-core. I think using it from there removes the version number from the path.\nI'm trying to compile with LLVM 3.9 directly downloaded from the official website. Seems to have gotten past the bluetooth error.\nBefore getting it to compile though, I was under the impression buildlib was ignoring my changes in the gyp_flags.\nbuilder.setup_build_utilities()\nbuilder.generate_build_configuration()\nbuilder.build()\nLeaving those 3 lines uncommented in build.py should be enough to make my changes in gyp_flags work, right? It refused to, I had to delete the entire sandbox folder and restart from scratch to get it to change the flags.\n. Its working! There was a small error when building the .dmg, though.\n2016-09-21 18:37:00,496 - INFO: Generating .dmg file...\nmktemp -d /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpm24ourbj/pkg-dmg.60768.XXXXXXXX\n/var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpm24ourbj/pkg-dmg.60768.jYnUwe2u\nmkdir /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpm24ourbj/pkg-dmg.60768.jYnUwe2u/stage\nrsync -aC --include \\*.so --copy-unsafe-links /var/empty/ /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpm24ourbj/pkg-dmg.60768.jYnUwe2u/stage\nrsync -aC --include \\*.so --copy-unsafe-links build/sandbox/out/Release/Chromium.app/ /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpm24ourbj/pkg-dmg.60768.jYnUwe2u/stage/Chromium.app\nrsync: link_stat \"/Volumes/Bakuya/ug_newbuild/ungoogled-chromium/build/build/sandbox/out/Release/Chromium.app/.\" failed: No such file or directory (2)\nrsync error: some files could not be transferred (code 23) at /BuildRoot/Library/Caches/com.apple.xbs/Sources/rsync/rsync-47/rsync/main.c(992) [sender=2.6.9]\nsandbox/chrome/installer/mac/pkg-dmg: copyFiles failed for method copy (cleaning up)\n2016-09-21 18:37:00,689 - ERROR: pkg-dmg returned non-zero exit code\nHowever, the most interesting part was the message I got when trying to run it:\n\nDo you know what is it?\nOtherwise, seems to be working as intended. I can search through Omnibox now (DDG as default - maybe Startpage is a better option?) and there is new tab page now.\n. Hmm, I highly doubt so. I've tested version 51 the same way and didn't get this popup.\nAbout the building precess... using LLVM 3.9 requires almost no work from the user. You literally just download the zip, extract it and edit the flags to point to that folder. Perhaps its a good idea to include downloading LLVM 3.9 in this, instead of using Homebrew's?\nAlso, another question. How Chromium defines the locale of search engines? Ask's and Yahoo's searches point to my country's sub-domain.\nEdit: still getting the error. Its repeating the build folder for some reason.\nMorello$ python3 build.py\n2016-09-22 11:49:30,918 - INFO: Initialized default console logging handler\n2016-09-22 11:49:30,918 - INFO: Using builder MacOSBuilder\n2016-09-22 11:49:30,919 - INFO: Generating .dmg file...\nmktemp -d /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpkfj_ja83/pkg-dmg.7390.XXXXXXXX\n/var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpkfj_ja83/pkg-dmg.7390.cCd4sld1\nmkdir /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpkfj_ja83/pkg-dmg.7390.cCd4sld1/stage\nrsync -aC --include \\*.so --copy-unsafe-links /var/empty/ /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpkfj_ja83/pkg-dmg.7390.cCd4sld1/stage\nrsync -aC --include \\*.so --copy-unsafe-links build/sandbox/out/Release/Chromium.app /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpkfj_ja83/pkg-dmg.7390.cCd4sld1/stage/Chromium.app\nrsync: link_stat \"/Volumes/Bakuya/ug_newbuild/ungoogled-chromium/build/build/sandbox/out/Release/Chromium.app\" failed: No such file or directory (2)\nrsync error: some files could not be transferred (code 23) at /BuildRoot/Library/Caches/com.apple.xbs/Sources/rsync/rsync-47/rsync/main.c(992) [sender=2.6.9]\nsandbox/chrome/installer/mac/pkg-dmg: copyFiles failed for method copy (cleaning up)\n2016-09-22 11:49:30,967 - ERROR: pkg-dmg returned non-zero exit code\nEdit 2: that message seems to be a bug related to upgrading Chromium in OS X. More info here. \n. @Eloston Now it builds the damage, but puts the Chromium.app container inside a folder called Chromium.app.\nIt created a folder called Chromium.app, copied Chromium to it, and then moved the folder instead of the app to the .dmg file.\n. https://my.mixtape.moe/cioatb.dmg\nI'll try to build it from scratch tomorrow to check if its working.\nAlso I can't help but think of damage when I read dmg hahaha\n. The current version builds like a charm. Tried it from scratch and everything worked after running the script once. Here is the .dmg:\nhttps://my.mixtape.moe/lzxjmu.dmg\nI think we can close this issue.\n. @Eloston I plan to start working in Ubuntu 16.10 in this weekend. I suspect the 16.04 build process will work just fine, but should we use it as an opportunity to test this?\nIt should help with 14.04 support too.. @Eloston It seems that error was a problem with my build environment. I tried it again in an older snapshot and it built successfully (before trying your last commit). However, there are no Debian packages inside the /out directory.. There is a file named chrome inside /out/Release, but I can't run it. PacmanFM recognizes it as a \"system library\" and not an executable.\nThis was on Ubuntu 14.04. I'll test it with 16.10.\nEdit: got an error.\n```\nERROR at //build/config/linux/pkg_config.gni:85:17: Script returned non-zero exit code.\n    pkgresult = exec_script(pkg_config_script, args, \"value\")\n                ^----------\nCurrent dir: /home/jojo/uc_static/ungoogled-chromium/build/sandbox/out/Release/\nCommand: python -- /home/jojo/uc_static/ungoogled-chromium/build/sandbox/build/config/linux/pkg-config.py gmodule-2.0 gtk+-2.0 gthread-2.0\nReturned 1.\nstderr:\nPackage gtk+-2.0 was not found in the pkg-config search path.\nPerhaps you should add the directory containing `gtk+-2.0.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'gtk+-2.0' found\nCould not run pkg-config.\nSee //build/config/linux/gtk2/BUILD.gn:14:1: whence it was called.\npkg_config(\"gtk2_internal_config\") {\n^-----------------------------------\nSee //chrome/test/BUILD.gn:476:26: which caused the file to be included.\n            configs += [ \"//build/config/linux/gtk2:gtk2_internal_config\" ]\n                         ^-----------------------------------------------\n2016-12-03 20:39:06,220 - ERROR: gn gen returned non-zero exit code: 1\n``. Yes. I'll try it again with a fresh VM after testing 16.10. Installing libgtk2.0-dev fixed the issue and I'm building it now.. The static build worked on Lubuntu 16.10.\nI'll try it with 14.04 again.. @Eloston Uh, I'm getting a strange behavior with the package. The version built and the package name don't match (downloaded and builtchromium-54.0.2840.101, the built package's name is ungoogled-chromium_55.0.2883.75-1_linuxstatic.tar.xz`).\nI'll try the binaries on the 14.04 machine and report back.\nEdit: the binaries built on 16.10 didn't run on 14.04. Got the following error:\n~/Desktop/ungoogled-chromium_55.0.2883.75-1$ ./chrome./chrome: /lib/x86_64-linux-gnu/libdbus-1.so.3: no version information available (required by ./chrome)\n./chrome: relocation error: ./chrome: symbol _ZTVNSt7__cxx1115basic_stringbufIcSt11char_traitsIcESaIcEEE, version GLIBCXX_3.4.21 not defined in file libstdc++.so.6 with link time reference\nI have libstdc++ with GLIBCXX_3.4.21 installed.. @Eloston I see. Are we waiting for the next inox-patchset release? It might be a good idea to release a v54 build due to problems like this one.. @Eloston You're the boss. Mention me when its ready to build again.. @Eloston I saw a few Cocoa-related lines in the commit, is this meant to be tested on OS X too?. @Eloston got the following error with the linker on Ubuntu 14.04. It built all files without errors before that.\n```\n, content::AppCacheStorage::Delegate)'\nobj/content/browser/browser/appcache_update_job.o:../../content/browser/appcache/appcache_update_job.cc:function content::AppCacheUpdateJob::ContinueHandleManifestFetchCompleted(bool): error: undefined reference to 'content::AppCacheManifest::AppCacheManifest()'\nobj/content/browser/browser/appcache_update_job.o:../../content/browser/appcache/appcache_update_job.cc:function content::AppCacheUpdateJob::ContinueHandleManifestFetchCompleted(bool): error: undefined reference to 'content::ParseManifest(GURL const&, char const, int, content::ParseMode, content::AppCacheManifest&)'\nobj/content/browser/browser/appcache_update_job.o:../../content/browser/appcache/appcache_update_job.cc:function content::AppCacheUpdateJob::ContinueHandleManifestFetchCompleted(bool): error: undefined reference to 'content::AppCacheManifest::~AppCacheManifest()'\nobj/content/browser/browser/cache_storage_manager.o:../../content/browser/cache_storage/cache_storage_manager.cc:function content::CacheStorageManager::CacheStorageManager(base::FilePath const&, scoped_refptr, scoped_refptr): error: undefined reference to 'content::CacheStorageQuotaClient::CacheStorageQuotaClient(base::WeakPtr)'\nobj/content/browser/browser/service_worker_handler.o:../../content/browser/devtools/protocol/service_worker_handler.cc:function content::devtools::service_worker::(anonymous namespace)::DidFindRegistrationForDispatchSyncEventOnIO(scoped_refptr, std::string const&, bool, content::ServiceWorkerStatusCode, scoped_refptr): error: undefined reference to 'content::BackgroundSyncContext::background_sync_manager() const'\nobj/content/browser/browser/resource_dispatcher_host_impl.o:../../content/browser/loader/resource_dispatcher_host_impl.cc:function content::ResourceDispatcherHostImpl::UpdateRequestForTransfer(int, int, int, content::ResourceRequest const&, std::_Rb_tree_iterator > > >): error: undefined reference to 'content::AppCacheInterceptor::CompleteCrossSiteTransfer(net::URLRequest, int, int, content::ResourceMessageFilter)'\nobj/content/browser/browser/resource_dispatcher_host_impl.o:../../content/browser/loader/resource_dispatcher_host_impl.cc:function content::ResourceDispatcherHostImpl::ContinuePendingBeginRequest(int, content::ResourceRequest const&, IPC::Message, int, net::HttpRequestHeaders const&, mojo::InterfaceRequest, mojo::InterfacePtr, bool, int): error: undefined reference to 'content::AppCacheInterceptor::SetExtraRequestInfo(net::URLRequest, content::AppCacheServiceImpl, int, int, content::ResourceType, bool)'\nobj/content/browser/browser/resource_loader.o:../../content/browser/loader/resource_loader.cc:function content::ResourceLoader::MarkAsTransferring(scoped_refptr const&): error: undefined reference to 'content::AppCacheInterceptor::PrepareForCrossSiteTransfer(net::URLRequest, int)'\nobj/content/browser/browser/resource_loader.o:../../content/browser/loader/resource_loader.cc:function content::ResourceLoader::CompleteTransfer(): error: undefined reference to 'content::AppCacheInterceptor::MaybeCompleteCrossSiteTransferInOldProcess(net::URLRequest, int)'\nobj/content/browser/browser/resource_loader.o:../../content/browser/loader/resource_loader.cc:function content::(anonymous namespace)::PopulateResourceResponse(content::ResourceRequestInfoImpl, net::URLRequest, content::ResourceResponse): error: undefined reference to 'content::AppCacheInterceptor::GetExtraResponseInfo(net::URLRequest, long, GURL)'\nobj/content/browser/browser/render_process_host_impl.o:../../content/browser/renderer_host/render_process_host_impl.cc:function content::RenderProcessHostImpl::RegisterMojoInterfaces(): error: undefined reference to 'content::BackgroundSyncContext::CreateService(mojo::InterfaceRequest)'\nobj/content/browser/browser/storage_partition_impl.o:../../content/browser/storage_partition_impl.cc:function content::StoragePartitionImpl::~StoragePartitionImpl(): error: undefined reference to 'content::BackgroundSyncContext::Shutdown()'\nobj/content/browser/browser/storage_partition_impl.o:../../content/browser/storage_partition_impl.cc:function content::StoragePartitionImpl::Create(content::BrowserContext, bool, base::FilePath const&): error: undefined reference to 'content::BackgroundSyncContext::BackgroundSyncContext()'\nobj/content/browser/browser/storage_partition_impl.o:../../content/browser/storage_partition_impl.cc:function content::StoragePartitionImpl::Create(content::BrowserContext, bool, base::FilePath const&): error: undefined reference to 'content::BackgroundSyncContext::Init(scoped_refptr const&)'\nobj/content/browser/browser/storage_partition_impl_map.o:../../content/browser/storage_partition_impl_map.cc:function content::StoragePartitionImplMap::Get(std::string const&, std::string const&, bool): error: undefined reference to 'content::AppCacheInterceptor::AppCacheInterceptor()'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::SystemInfoAPI::OnListenerAdded(extensions::EventListenerInfo const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetInstance()'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::SystemInfoAPI::OnListenerAdded(extensions::EventListenerInfo const&): error: undefined reference to 'storage_monitor::StorageMonitor::EnsureInitialized(base::Callback)'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::(anonymous namespace)::AddEventListener(std::string const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetInstance()'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::(anonymous namespace)::AddEventListener(std::string const&): error: undefined reference to 'storage_monitor::StorageMonitor::AddObserver(storage_monitor::RemovableStorageObserver)'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::SystemInfoAPI::OnListenerRemoved(extensions::EventListenerInfo const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetInstance()'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::SystemInfoAPI::OnListenerRemoved(extensions::EventListenerInfo const&): error: undefined reference to 'storage_monitor::StorageMonitor::EnsureInitialized(base::Callback)'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::(anonymous namespace)::RemoveEventListener(std::string const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetInstance()'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::(anonymous namespace)::RemoveEventListener(std::string const&): error: undefined reference to 'storage_monitor::StorageMonitor::RemoveObserver(storage_monitor::RemovableStorageObserver)'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::(anonymous namespace)::SystemInfoEventRouter::~SystemInfoEventRouter(): error: undefined reference to 'storage_monitor::StorageMonitor::RemoveObserver(storage_monitor::RemovableStorageObserver)'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::(anonymous namespace)::SystemInfoEventRouter::~SystemInfoEventRouter(): error: undefined reference to 'storage_monitor::StorageMonitor::RemoveObserver(storage_monitor::RemovableStorageObserver)'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function extensions::(anonymous namespace)::SystemInfoEventRouter::OnRemovableStorageDetached(storage_monitor::StorageInfo const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetTransientIdForDeviceId(std::string const&)'\nobj/extensions/browser/api/system_info/system_info/system_info_api.o:../../extensions/browser/api/system_info/system_info_api.cc:function non-virtual thunk to extensions::(anonymous namespace)::SystemInfoEventRouter::~SystemInfoEventRouter(): error: undefined reference to 'storage_monitor::StorageMonitor::RemoveObserver(storage_monitor::RemovableStorageObserver)'\nobj/extensions/browser/api/system_storage/system_storage/storage_info_provider.o:../../extensions/browser/api/system_storage/storage_info_provider.cc:function extensions::systeminfo::BuildStorageUnitInfo(storage_monitor::StorageInfo const&, extensions::api::system_storage::StorageUnitInfo): error: undefined reference to 'storage_monitor::StorageMonitor::GetTransientIdForDeviceId(std::string const&)'\nobj/extensions/browser/api/system_storage/system_storage/storage_info_provider.o:../../extensions/browser/api/system_storage/storage_info_provider.cc:function extensions::StorageInfoProvider::GetAllStoragesIntoInfoList(): error: undefined reference to 'storage_monitor::StorageMonitor::GetAllAvailableStorages() const'\nobj/extensions/browser/api/system_storage/system_storage/storage_info_provider.o:../../extensions/browser/api/system_storage/storage_info_provider.cc:function extensions::StorageInfoProvider::InitializeProvider(base::Callback const&): error: undefined reference to 'storage_monitor::StorageMonitor::EnsureInitialized(base::Callback)'\nobj/extensions/browser/api/system_storage/system_storage/storage_info_provider.o:../../extensions/browser/api/system_storage/storage_info_provider.cc:function extensions::StorageInfoProvider::GetStorageFreeSpaceFromTransientIdOnFileThread(std::string const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetAllAvailableStorages() const'\nobj/extensions/browser/api/system_storage/system_storage/storage_info_provider.o:../../extensions/browser/api/system_storage/storage_info_provider.cc:function extensions::StorageInfoProvider::GetStorageFreeSpaceFromTransientIdOnFileThread(std::string const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetDeviceIdForTransientId(std::string const&) const'\nobj/extensions/browser/api/system_storage/system_storage/system_storage_api.o:../../extensions/browser/api/system_storage/system_storage_api.cc:function extensions::SystemStorageEjectDeviceFunction::RunAsync(): error: undefined reference to 'storage_monitor::StorageMonitor::EnsureInitialized(base::Callback)'\nobj/extensions/browser/api/system_storage/system_storage/system_storage_api.o:../../extensions/browser/api/system_storage/system_storage_api.cc:function extensions::SystemStorageEjectDeviceFunction::OnStorageMonitorInit(std::string const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetDeviceIdForTransientId(std::string const&) const'\nobj/extensions/browser/api/web_request/web_request/web_request_api_helpers.o:../../extensions/browser/api/web_request/web_request_api_helpers.cc:function extension_web_request_api_helpers::ClearCacheOnNavigation(): error: undefined reference to 'web_cache::WebCacheManager::GetInstance()'\nobj/extensions/browser/api/web_request/web_request/web_request_api_helpers.o:../../extensions/browser/api/web_request/web_request_api_helpers.cc:function extension_web_request_api_helpers::ClearCacheOnNavigation(): error: undefined reference to 'web_cache::WebCacheManager::ClearCacheOnNavigation()'\nobj/extensions/browser/api/web_request/web_request/web_request_api_helpers.o:../../extensions/browser/api/web_request/web_request_api_helpers.cc:function extension_web_request_api_helpers::(anonymous namespace)::ClearCacheOnNavigationOnUI(): error: undefined reference to 'web_cache::WebCacheManager::GetInstance()'\nobj/extensions/browser/api/web_request/web_request/web_request_api_helpers.o:../../extensions/browser/api/web_request/web_request_api_helpers.cc:function extension_web_request_api_helpers::(anonymous namespace)::ClearCacheOnNavigationOnUI(): error: undefined reference to 'web_cache::WebCacheManager::ClearCacheOnNavigation()'\nobj/extensions/browser/app_window/app_window/app_window.o:../../extensions/browser/app_window/app_window.cc:function extensions::AppWindow::Init(GURL const&, extensions::AppWindowContents, content::RenderFrameHost, extensions::AppWindow::CreateParams const&): error: undefined reference to 'content::WebContentsUserData::kLocatorKey'\nobj/extensions/browser/app_window/app_window/app_window.o:../../extensions/browser/app_window/app_window.cc:function extensions::AppWindow::Init(GURL const&, extensions::AppWindowContents, content::RenderFrameHost, extensions::AppWindow::CreateParams const&): error: undefined reference to 'web_modal::WebContentsModalDialogManager::WebContentsModalDialogManager(content::WebContents)'\nobj/extensions/browser/app_window/app_window/app_window.o:../../extensions/browser/app_window/app_window.cc:function extensions::AppWindow::Init(GURL const&, extensions::AppWindowContents, content::RenderFrameHost, extensions::AppWindow::CreateParams const&): error: undefined reference to 'content::WebContentsUserData::kLocatorKey'\nobj/extensions/browser/app_window/app_window/app_window.o:../../extensions/browser/app_window/app_window.cc:function extensions::AppWindow::Init(GURL const&, extensions::AppWindowContents, content::RenderFrameHost, extensions::AppWindow::CreateParams const&): error: undefined reference to 'content::WebContentsUserData::kLocatorKey'\nobj/extensions/browser/app_window/app_window/app_window.o:../../extensions/browser/app_window/app_window.cc:function extensions::AppWindow::Init(GURL const&, extensions::AppWindowContents, content::RenderFrameHost, extensions::AppWindow::CreateParams const&): error: undefined reference to 'web_modal::WebContentsModalDialogManager::SetDelegate(web_modal::WebContentsModalDialogManagerDelegate)'\nobj/extensions/browser/app_window/app_window/app_window.o:../../extensions/browser/app_window/app_window.cc:function extensions::AppWindow::~AppWindow(): error: undefined reference to 'web_modal::WebContentsModalDialogManagerDelegate::~WebContentsModalDialogManagerDelegate()'\nobj/extensions/browser/app_window/app_window/app_window.o:../../extensions/browser/app_window/app_window.cc:function extensions::AppWindow::OnNativeClose(): error: undefined reference to 'content::WebContentsUserData::kLocatorKey'\nobj/extensions/browser/app_window/app_window/app_window.o:../../extensions/browser/app_window/app_window.cc:function extensions::AppWindow::OnNativeClose(): error: undefined reference to 'web_modal::WebContentsModalDialogManager::SetDelegate(web_modal::WebContentsModalDialogManagerDelegate)'\nobj/extensions/browser/guest_view/extension_options/extension_options/extension_options_guest.o:../../extensions/browser/guest_view/extension_options/extension_options_guest.cc:function extensions::ExtensionOptionsGuest::DidNavigateMainFrame(content::LoadCommittedDetails const&, content::FrameNavigateParams const&): error: undefined reference to 'content::WebContentsUserData::kLocatorKey'\nobj/extensions/browser/guest_view/extension_options/extension_options/extension_options_guest.o:../../extensions/browser/guest_view/extension_options/extension_options_guest.cc:function extensions::ExtensionOptionsGuest::DidNavigateMainFrame(content::LoadCommittedDetails const&, content::FrameNavigateParams const&): error: undefined reference to 'zoom::ZoomController::SetZoomMode(zoom::ZoomController::ZoomMode)'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::GetZoom() const: error: undefined reference to 'content::WebContentsUserData::kLocatorKey'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::GetZoom() const: error: undefined reference to 'zoom::ZoomController::GetZoomLevel() const'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::GetZoomMode(): error: undefined reference to 'content::WebContentsUserData::kLocatorKey'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::ClearData(base::Time, unsigned int, base::Callback const&): error: undefined reference to 'web_cache::WebCacheManager::GetInstance()'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::ClearData(base::Time, unsigned int, base::Callback const&): error: undefined reference to 'web_cache::WebCacheManager::ClearCacheForProcess(int)'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::DidCommitProvisionalLoadForFrame(content::RenderFrameHost, GURL const&, ui::PageTransition): error: undefined reference to 'content::WebContentsUserData::kLocatorKey'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::DidCommitProvisionalLoadForFrame(content::RenderFrameHost, GURL const&, ui::PageTransition): error: undefined reference to 'zoom::ZoomController::SetZoomLevel(double)'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::SetZoom(double): error: undefined reference to 'zoom::ZoomController::SetZoomLevel(double)'\nobj/extensions/browser/guest_view/web_view/web_view/web_view_guest.o:../../extensions/browser/guest_view/web_view/web_view_guest.cc:function extensions::WebViewGuest::SetZoomMode(zoom::ZoomController::ZoomMode): error: undefined reference to 'zoom::ZoomController::SetZoomMode(zoom::ZoomController::ZoomMode)'\nobj/chrome/browser/ui/libui.a(tab_strip_model.o):../../chrome/browser/ui/tabs/tab_strip_model.cc:function TabStripModel::InsertWebContentsAt(int, content::WebContents, int): error: undefined reference to 'web_modal::WebContentsModalDialogManager::IsDialogActive() const'\nobj/chrome/browser/ui/libui.a(core_tab_helper.o):../../chrome/browser/ui/tab_contents/core_tab_helper.cc:function CoreTabHelper::WasShown(): error: undefined reference to 'web_cache::WebCacheManager::GetInstance()'\nobj/chrome/browser/ui/libui.a(core_tab_helper.o):../../chrome/browser/ui/tab_contents/core_tab_helper.cc:function CoreTabHelper::WasShown(): error: undefined reference to 'web_cache::WebCacheManager::ObserveActivity(int)'\nobj/chrome/browser/ui/libui.a(browser.o):../../chrome/browser/ui/browser.cc:function Browser::SetAsDelegate(content::WebContents, bool): error: undefined reference to 'web_modal::WebContentsModalDialogManager::SetDelegate(web_modal::WebContentsModalDialogManagerDelegate)'\nobj/chrome/browser/ui/libui.a(browser.o):../../chrome/browser/ui/browser.cc:function Browser::SetAsDelegate(content::WebContents, bool): error: undefined reference to 'zoom::ZoomController::AddObserver(zoom::ZoomObserver)'\nobj/chrome/browser/ui/libui.a(browser.o):../../chrome/browser/ui/browser.cc:function Browser::SetAsDelegate(content::WebContents, bool): error: undefined reference to 'translate::ContentTranslateDriver::AddObserver(translate::ContentTranslateDriver::Observer)'\nobj/chrome/browser/ui/libui.a(browser.o):../../chrome/browser/ui/browser.cc:function Browser::SetAsDelegate(content::WebContents, bool): error: undefined reference to 'zoom::ZoomController::RemoveObserver(zoom::ZoomObserver)'\nobj/chrome/browser/ui/libui.a(browser.o):../../chrome/browser/ui/browser.cc:function Browser::SetAsDelegate(content::WebContents, bool): error: undefined reference to 'translate::ContentTranslateDriver::RemoveObserver(translate::ContentTranslateDriver::Observer)'\nobj/chrome/browser/ui/libui.a(browser_commands.o):../../chrome/browser/ui/browser_commands.cc:function chrome::CanResetZoom(content::WebContents): error: undefined reference to 'zoom::ZoomController::IsAtDefaultZoom() const'\nobj/chrome/browser/ui/libui.a(browser_commands.o):../../chrome/browser/ui/browser_commands.cc:function chrome::CanResetZoom(content::WebContents): error: undefined reference to 'zoom::ZoomController::PageScaleFactorIsOne() const'\nobj/chrome/browser/ui/libui.a(browser_commands.o):../../chrome/browser/ui/browser_commands.cc:function chrome::CanPrint(Browser): error: undefined reference to 'web_modal::WebContentsModalDialogManager::IsDialogActive() const'\nobj/chrome/browser/ui/libui.a(browser_commands.o):../../chrome/browser/ui/browser_commands.cc:function chrome::CanRouteMedia(Browser): error: undefined reference to 'web_modal::WebContentsModalDialogManager::IsDialogActive() const'\nobj/chrome/browser/ui/libui.a(browser_commands.o):../../chrome/browser/ui/browser_commands.cc:function chrome::Zoom(Browser, content::PageZoom): error: undefined reference to 'zoom::PageZoom::Zoom(content::WebContents, content::PageZoom)'\nobj/chrome/browser/ui/libui.a(chrome_web_modal_dialog_manager_delegate.o):../../chrome/browser/ui/chrome_web_modal_dialog_manager_delegate.cc:function ChromeWebModalDialogManagerDelegate::~ChromeWebModalDialogManagerDelegate(): error: undefined reference to 'web_modal::WebContentsModalDialogManagerDelegate::~WebContentsModalDialogManagerDelegate()'\nobj/chrome/browser/ui/libui.a(chrome_web_modal_dialog_manager_delegate.o):../../chrome/browser/ui/chrome_web_modal_dialog_manager_delegate.cc:function ChromeWebModalDialogManagerDelegate::~ChromeWebModalDialogManagerDelegate(): error: undefined reference to 'web_modal::WebContentsModalDialogManagerDelegate::~WebContentsModalDialogManagerDelegate()'\nobj/chrome/browser/ui/libui.a(chrome_web_modal_dialog_manager_delegate.o):../../chrome/browser/ui/chrome_web_modal_dialog_manager_delegate.cc:vtable for ChromeWebModalDialogManagerDelegate: error: undefined reference to 'web_modal::WebContentsModalDialogManagerDelegate::SetWebContentsBlocked(content::WebContents, bool)'\nobj/chrome/browser/ui/libui.a(chrome_web_modal_dialog_manager_delegate.o):../../chrome/browser/ui/chrome_web_modal_dialog_manager_delegate.cc:vtable for ChromeWebModalDialogManagerDelegate: error: undefined reference to 'web_modal::WebContentsModalDialogManagerDelegate::GetWebContentsModalDialogHost()'\nobj/chrome/browser/ui/libui.a(tab_contents_synced_tab_delegate.o):../../chrome/browser/ui/sync/tab_contents_synced_tab_delegate.cc:function TabContentsSyncedTabDelegate::TabContentsSyncedTabDelegate(content::WebContents): error: undefined reference to 'sync_sessions::SyncedTabDelegate::SyncedTabDelegate()'\nobj/chrome/browser/ui/libui.a(tab_contents_synced_tab_delegate.o):../../chrome/browser/ui/sync/tab_contents_synced_tab_delegate.cc:function TabContentsSyncedTabDelegate::~TabContentsSyncedTabDelegate(): error: undefined reference to 'sync_sessions::SyncedTabDelegate::~SyncedTabDelegate()'\nobj/chrome/browser/ui/libui.a(tab_contents_synced_tab_delegate.o):../../chrome/browser/ui/sync/tab_contents_synced_tab_delegate.cc:function non-virtual thunk to TabContentsSyncedTabDelegate::~TabContentsSyncedTabDelegate(): error: undefined reference to 'sync_sessions::SyncedTabDelegate::~SyncedTabDelegate()'\nobj/chrome/browser/ui/libui.a(tab_contents_synced_tab_delegate.o):../../chrome/browser/ui/sync/tab_contents_synced_tab_delegate.cc:function TabContentsSyncedTabDelegate::~TabContentsSyncedTabDelegate(): error: undefined reference to 'sync_sessions::SyncedTabDelegate::~SyncedTabDelegate()'\nobj/chrome/browser/ui/libui.a(tab_contents_synced_tab_delegate.o):../../chrome/browser/ui/sync/tab_contents_synced_tab_delegate.cc:function non-virtual thunk to TabContentsSyncedTabDelegate::~TabContentsSyncedTabDelegate(): error: undefined reference to 'sync_sessions::SyncedTabDelegate::~SyncedTabDelegate()'\nobj/chrome/browser/ui/libui.a(tab_helpers.o):../../chrome/browser/ui/tab_helpers.cc:function TabHelpers::AttachTabHelpers(content::WebContents): error: undefined reference to 'zoom::ZoomController::ZoomController(content::WebContents)'\nobj/chrome/browser/ui/libui.a(tab_helpers.o):../../chrome/browser/ui/tab_helpers.cc:function TabHelpers::AttachTabHelpers(content::WebContents): error: undefined reference to 'web_modal::WebContentsModalDialogManager::WebContentsModalDialogManager(content::WebContents)'\nobj/chrome/browser/ui/libui.a(ntp_user_data_logger.o):../../chrome/browser/ui/webui/ntp/ntp_user_data_logger.cc:function NTPUserDataLogger::NTPUserDataLogger(content::WebContents): error: undefined reference to 'sync_sessions::SyncSessionsMetrics::RecordYoungestForeignTabAgeOnNTP(sync_sessions::SessionsSyncManager)'\nobj/chrome/browser/ui/libui.a(browser_view_layout.o):../../chrome/browser/ui/views/frame/browser_view_layout.cc:function BrowserViewLayout::WebContentsModalDialogHostViews::~WebContentsModalDialogHostViews(): error: undefined reference to 'web_modal::WebContentsModalDialogHost::~WebContentsModalDialogHost()'\nobj/chrome/browser/ui/libui.a(location_bar_view.o):../../chrome/browser/ui/views/location_bar/location_bar_view.cc:function LocationBarView::LocationBarView(Browser, Profile, CommandUpdater, LocationBarView::Delegate, bool): error: undefined reference to 'zoom::ZoomEventManager::GetForBrowserContext(content::BrowserContext)'\nobj/chrome/browser/ui/libui.a(location_bar_view.o):../../chrome/browser/ui/views/location_bar/location_bar_view.cc:function LocationBarView::LocationBarView(Browser, Profile, CommandUpdater, LocationBarView::Delegate, bool): error: undefined reference to 'zoom::ZoomEventManager::AddZoomEventManagerObserver(zoom::ZoomEventManagerObserver)'\nobj/chrome/browser/ui/libui.a(location_bar_view.o):../../chrome/browser/ui/views/location_bar/location_bar_view.cc:function LocationBarView::~LocationBarView(): error: undefined reference to 'zoom::ZoomEventManager::GetForBrowserContext(content::BrowserContext)'\nobj/chrome/browser/ui/libui.a(location_bar_view.o):../../chrome/browser/ui/views/location_bar/location_bar_view.cc:function LocationBarView::~LocationBarView(): error: undefined reference to 'zoom::ZoomEventManager::RemoveZoomEventManagerObserver(zoom::ZoomEventManagerObserver)'\nobj/chrome/browser/ui/libui.a(zoom_bubble_view.o):../../chrome/browser/ui/views/location_bar/zoom_bubble_view.cc:function ZoomBubbleView::ButtonPressed(views::Button, ui::Event const&): error: undefined reference to 'zoom::PageZoom::Zoom(content::WebContents, content::PageZoom)'\nobj/chrome/browser/ui/libui.a(zoom_view.o):../../chrome/browser/ui/views/location_bar/zoom_view.cc:function ZoomView::Update(zoom::ZoomController): error: undefined reference to 'zoom::ZoomController::IsAtDefaultZoom() const'\nobj/chrome/browser/ui/libui.a(zoom_view.o):../../chrome/browser/ui/views/location_bar/zoom_view.cc:function ZoomView::Update(zoom::ZoomController): error: undefined reference to 'zoom::ZoomController::GetZoomRelativeToDefault() const'\nobj/chrome/browser/ui/libui.a(chrome_autofill_client.o):../../chrome/browser/ui/autofill/chrome_autofill_client.cc:function autofill::ChromeAutofillClient::ChromeAutofillClient(content::WebContents): error: undefined reference to 'zoom::ZoomController::AddObserver(zoom::ZoomObserver)'\nobj/chrome/browser/ui/libui.a(chrome_zoom_level_prefs.o):../../chrome/browser/ui/zoom/chrome_zoom_level_prefs.cc:function ChromeZoomLevelPrefs::SetDefaultZoomLevelPref(double): error: undefined reference to 'zoom::ZoomEventManager::OnDefaultZoomLevelChanged()'\nobj/chrome/browser/ui/libui.a(chrome_zoom_level_prefs.o):../../chrome/browser/ui/zoom/chrome_zoom_level_prefs.cc:function ChromeZoomLevelPrefs::OnZoomLevelChanged(content::HostZoomMap::ZoomLevelChange const&): error: undefined reference to 'zoom::ZoomEventManager::OnZoomLevelChanged(content::HostZoomMap::ZoomLevelChange const&)'\nobj/chrome/browser/ui/libui.a(app_menu_model.o):../../chrome/browser/ui/toolbar/app_menu_model.cc:function AppMenuModel::AppMenuModel(ui::AcceleratorProvider, Browser): error: undefined reference to 'zoom::ZoomEventManager::GetForBrowserContext(content::BrowserContext)'\nobj/chrome/browser/ui/libui.a(app_menu_model.o):../../chrome/browser/ui/toolbar/app_menu_model.cc:function AppMenuModel::AppMenuModel(ui::AcceleratorProvider, Browser): error: undefined reference to 'zoom::ZoomEventManager::AddZoomLevelChangedCallback(base::Callback const&)'\nobj/chrome/browser/ui/libui.a(app_menu.o):../../chrome/browser/ui/views/toolbar/app_menu.cc:function AppMenu::ZoomView::ZoomView(AppMenu, ui::ButtonMenuItemModel, int, int, int): error: undefined reference to 'zoom::ZoomEventManager::GetForBrowserContext(content::BrowserContext)'\nobj/chrome/browser/ui/libui.a(app_menu.o):../../chrome/browser/ui/views/toolbar/app_menu.cc:function AppMenu::ZoomView::ZoomView(AppMenu, ui::ButtonMenuItemModel, int, int, int): error: undefined reference to 'zoom::ZoomEventManager::AddZoomLevelChangedCallback(base::Callback const&)'\nobj/chrome/browser/ui/libui.a(app_menu.o):../../chrome/browser/ui/views/toolbar/app_menu.cc:function AppMenu::ZoomView::ZoomLabelMaxWidth() const: error: undefined reference to 'zoom::PageZoom::PresetZoomFactors(double)'\nobj/chrome/browser/ui/libui.a(constrained_web_dialog_delegate_base.o):../../chrome/browser/ui/webui/constrained_web_dialog_delegate_base.cc:function ConstrainedWebDialogDelegateBase::ConstrainedWebDialogDelegateBase(content::BrowserContext, ui::WebDialogDelegate, ui::WebDialogWebContentsDelegate): error: undefined reference to 'zoom::ZoomController::ZoomController(content::WebContents)'\nobj/chrome/browser/devtools/libdevtools.a(devtools_ui_bindings.o):../../chrome/browser/devtools/devtools_ui_bindings.cc:function DevToolsUIBindings::ZoomIn(): error: undefined reference to 'zoom::PageZoom::Zoom(content::WebContents, content::PageZoom)'\nobj/chrome/browser/devtools/libdevtools.a(devtools_ui_bindings.o):../../chrome/browser/devtools/devtools_ui_bindings.cc:function DevToolsUIBindings::ZoomOut(): error: undefined reference to 'zoom::PageZoom::Zoom(content::WebContents, content::PageZoom)'\nobj/chrome/browser/devtools/libdevtools.a(devtools_window.o):../../chrome/browser/devtools/devtools_window.cc:function DevToolsWindow::DevToolsWindow(Profile, content::WebContents, DevToolsUIBindings, content::WebContents, bool): error: undefined reference to 'zoom::ZoomController::ZoomController(content::WebContents)'\nobj/components/constrained_window/libconstrained_window.a(constrained_window_views.o):../../components/constrained_window/constrained_window_views.cc:function constrained_window::(anonymous namespace)::WidgetModalDialogHostObserverViews::~WidgetModalDialogHostObserverViews(): error: undefined reference to 'web_modal::ModalDialogHostObserver::~ModalDialogHostObserver()'\nobj/components/constrained_window/libconstrained_window.a(constrained_window_views.o):../../components/constrained_window/constrained_window_views.cc:function constrained_window::(anonymous namespace)::WidgetModalDialogHostObserverViews::~WidgetModalDialogHostObserverViews(): error: undefined reference to 'web_modal::ModalDialogHostObserver::~ModalDialogHostObserver()'\nobj/components/constrained_window/libconstrained_window.a(constrained_window_views.o):../../components/constrained_window/constrained_window_views.cc:function non-virtual thunk to constrained_window::(anonymous namespace)::WidgetModalDialogHostObserverViews::~WidgetModalDialogHostObserverViews(): error: undefined reference to 'web_modal::ModalDialogHostObserver::~ModalDialogHostObserver()'\nobj/components/constrained_window/libconstrained_window.a(constrained_window_views.o):../../components/constrained_window/constrained_window_views.cc:function non-virtual thunk to constrained_window::(anonymous namespace)::WidgetModalDialogHostObserverViews::~WidgetModalDialogHostObserverViews(): error: undefined reference to 'web_modal::ModalDialogHostObserver::~ModalDialogHostObserver()'\nobj/components/constrained_window/libconstrained_window.a(show_modal_dialog_views.o):../../components/constrained_window/show_modal_dialog_views.cc:function constrained_window::ShowModalDialog(aura::Window, content::WebContents): error: undefined reference to 'web_modal::WebContentsModalDialogManager::ShowDialogWithManager(aura::Window, std::unique_ptr >)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::InitWithWebContents(base::DictionaryValue const&, content::WebContents): error: undefined reference to 'zoom::ZoomController::ZoomController(content::WebContents)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::InitWithWebContents(base::DictionaryValue const&, content::WebContents): error: undefined reference to 'zoom::ZoomController::AddObserver(zoom::ZoomObserver)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::SetUpSizing(base::DictionaryValue const&): error: undefined reference to 'zoom::ZoomController::GetZoomLevelForWebContents(content::WebContents const)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::SetUpSizing(base::DictionaryValue const&): error: undefined reference to 'zoom::ZoomController::GetZoomLevelForWebContents(content::WebContents const)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::DidDetach(): error: undefined reference to 'zoom::ZoomController::RemoveObserver(zoom::ZoomObserver)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::Destroy(): error: undefined reference to 'zoom::ZoomController::RemoveObserver(zoom::ZoomObserver)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::WillAttach(content::WebContents, int, bool, base::Callback const&): error: undefined reference to 'zoom::ZoomController::RemoveObserver(zoom::ZoomObserver)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::StartTrackingEmbedderZoomLevel(): error: undefined reference to 'zoom::ZoomController::AddObserver(zoom::ZoomObserver)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::StartTrackingEmbedderZoomLevel(): error: undefined reference to 'zoom::ZoomController::GetZoomLevel() const'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::StartTrackingEmbedderZoomLevel(): error: undefined reference to 'zoom::ZoomController::SetZoomLevel(double)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::PhysicalPixelsToLogicalPixels(int) const: error: undefined reference to 'zoom::ZoomController::GetZoomLevelForWebContents(content::WebContents const)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::DidNavigateMainFrame(content::LoadCommittedDetails const&, content::FrameNavigateParams const&): error: undefined reference to 'zoom::ZoomController::GetZoomLevel() const'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::DidNavigateMainFrame(content::LoadCommittedDetails const&, content::FrameNavigateParams const&): error: undefined reference to 'zoom::ZoomController::SetZoomLevel(double)'\nobj/components/guest_view/browser/libguest_view_browser.a(guest_view_base.o):../../components/guest_view/browser/guest_view_base.cc:function guest_view::GuestViewBase::SetGuestZoomLevelToMatchEmbedder(): error: undefined reference to 'zoom::ZoomController::GetZoomLevel() const'\nobj/components/browser_sync/libbrowser_sync.a(profile_sync_service.o):../../components/browser_sync/profile_sync_service.cc:function browser_sync::ProfileSyncService::Initialize(): error: undefined reference to 'sync_sessions::SessionsSyncManager::SessionsSyncManager(sync_sessions::SyncSessionsClient, syncer::SyncPrefs, syncer::LocalDeviceInfoProvider, std::unique_ptr >, base::Callback const&, base::Callback const&)'\nobj/components/browser_sync/libbrowser_sync.a(profile_sync_service.o):../../components/browser_sync/profile_sync_service.cc:function browser_sync::ProfileSyncService::GetFaviconCache(): error: undefined reference to 'sync_sessions::SessionsSyncManager::GetFaviconCache()'\nobj/components/browser_sync/libbrowser_sync.a(profile_sync_service.o):../../components/browser_sync/profile_sync_service.cc:function browser_sync::ProfileSyncService::OnSyncCycleCompleted(): error: undefined reference to 'sync_sessions::SessionsSyncManager::DoGarbageCollection()'\nobj/components/subresource_filter/content/browser/libbrowser.a(content_subresource_filter_driver_factory.o):../../components/subresource_filter/content/browser/content_subresource_filter_driver_factory.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::ContentSubresourceFilterDriverFactory, subresource_filter::ContentSubresourceFilterDriverFactory, void, void (subresource_filter::ContentSubresourceFilterDriverFactory::)()): error: undefined reference to 'IPC::MessageT, void>::Read(IPC::Message const, std::tuple<>)'\nobj/components/subresource_filter/content/browser/libbrowser.a(content_subresource_filter_driver_factory.o):../../components/subresource_filter/content/browser/content_subresource_filter_driver_factory.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::ContentSubresourceFilterDriverFactory, subresource_filter::ContentSubresourceFilterDriverFactory, void, void (subresource_filter::ContentSubresourceFilterDriverFactory::)()): error: undefined reference to 'SubresourceFilterHostMsg_DidDisallowFirstSubresource_Meta::kName'\nobj/components/subresource_filter/content/browser/libbrowser.a(content_subresource_filter_driver_factory.o):../../components/subresource_filter/content/browser/content_subresource_filter_driver_factory.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::ContentSubresourceFilterDriverFactory, subresource_filter::ContentSubresourceFilterDriverFactory, void, void (subresource_filter::ContentSubresourceFilterDriverFactory::)()): error: undefined reference to 'SubresourceFilterHostMsg_DidDisallowFirstSubresource_Meta::kName'\nobj/components/subresource_filter/content/browser/libbrowser.a(content_subresource_filter_driver.o):../../components/subresource_filter/content/browser/content_subresource_filter_driver.cc:function subresource_filter::ContentSubresourceFilterDriver::ActivateForProvisionalLoad(subresource_filter::ActivationState): error: undefined reference to 'IPC::MessageT, void>::MessageT(IPC::Routing, subresource_filter::ActivationState const&)'\nobj/chrome/browser/extensions/libextensions.a(extension_view_host.o):../../chrome/browser/extensions/extension_view_host.cc:function extensions::ExtensionViewHost::~ExtensionViewHost(): error: undefined reference to 'web_modal::WebContentsModalDialogManager::SetDelegate(web_modal::WebContentsModalDialogManagerDelegate)'\nobj/chrome/browser/extensions/libextensions.a(extension_view_host.o):../../chrome/browser/extensions/extension_view_host.cc:function extensions::ExtensionViewHost::~ExtensionViewHost(): error: undefined reference to 'web_modal::WebContentsModalDialogHost::~WebContentsModalDialogHost()'\nobj/chrome/browser/extensions/libextensions.a(extension_view_host.o):../../chrome/browser/extensions/extension_view_host.cc:function extensions::ExtensionViewHost::~ExtensionViewHost(): error: undefined reference to 'web_modal::WebContentsModalDialogManagerDelegate::~WebContentsModalDialogManagerDelegate()'\nobj/chrome/browser/extensions/libextensions.a(extension_view_host.o):../../chrome/browser/extensions/extension_view_host.cc:function extensions::ExtensionViewHost::LoadInitialURL(): error: undefined reference to 'web_modal::WebContentsModalDialogManager::WebContentsModalDialogManager(content::WebContents)'\nobj/chrome/browser/extensions/libextensions.a(extension_view_host.o):../../chrome/browser/extensions/extension_view_host.cc:vtable for extensions::ExtensionViewHost: error: undefined reference to 'web_modal::WebContentsModalDialogManagerDelegate::SetWebContentsBlocked(content::WebContents, bool)'\nobj/chrome/browser/libbrowser.a(browsing_data_remover.o):../../chrome/browser/browsing_data/browsing_data_remover.cc:function BrowsingDataRemover::RemoveImpl(BrowsingDataRemover::TimeRange const&, int, BrowsingDataFilterBuilder const&, int): error: undefined reference to 'web_cache::WebCacheManager::ClearCache()'\nobj/chrome/browser/libbrowser.a(chrome_render_message_filter.o):../../chrome/browser/renderer_host/chrome_render_message_filter.cc:function ChromeRenderMessageFilter::OnUpdatedCacheStats(unsigned long, unsigned long, unsigned long, unsigned long, unsigned long): error: undefined reference to 'web_cache::WebCacheManager::ObserveStats(int, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long)'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function ChromeTranslateClient::ChromeTranslateClient(content::WebContents): error: undefined reference to 'translate::ContentTranslateDriver::ContentTranslateDriver(content::NavigationController)'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function ChromeTranslateClient::ChromeTranslateClient(content::WebContents): error: undefined reference to 'translate::ContentTranslateDriver::AddObserver(translate::ContentTranslateDriver::Observer)'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function ChromeTranslateClient::~ChromeTranslateClient(): error: undefined reference to 'translate::ContentTranslateDriver::RemoveObserver(translate::ContentTranslateDriver::Observer)'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function ChromeTranslateClient::~ChromeTranslateClient(): error: undefined reference to 'translate::ContentTranslateDriver::~ContentTranslateDriver()'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function non-virtual thunk to ChromeTranslateClient::~ChromeTranslateClient(): error: undefined reference to 'translate::ContentTranslateDriver::RemoveObserver(translate::ContentTranslateDriver::Observer)'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function non-virtual thunk to ChromeTranslateClient::~ChromeTranslateClient(): error: undefined reference to 'translate::ContentTranslateDriver::~ContentTranslateDriver()'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function non-virtual thunk to ChromeTranslateClient::~ChromeTranslateClient(): error: undefined reference to 'translate::ContentTranslateDriver::RemoveObserver(translate::ContentTranslateDriver::Observer)'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function non-virtual thunk to ChromeTranslateClient::~ChromeTranslateClient(): error: undefined reference to 'translate::ContentTranslateDriver::~ContentTranslateDriver()'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function non-virtual thunk to ChromeTranslateClient::~ChromeTranslateClient(): error: undefined reference to 'translate::ContentTranslateDriver::~ContentTranslateDriver()'\nobj/chrome/browser/libbrowser.a(chrome_translate_client.o):../../chrome/browser/translate/chrome_translate_client.cc:function ChromeTranslateClient::BindContentTranslateDriver(content::RenderFrameHost, mojo::InterfaceRequest): error: undefined reference to 'translate::ContentTranslateDriver::BindRequest(mojo::InterfaceRequest)'\nobj/chrome/browser/libbrowser.a(chrome_sync_client.o):../../chrome/browser/sync/chrome_sync_client.cc:function browser_sync::ChromeSyncClient::ChromeSyncClient(Profile): error: undefined reference to 'sync_sessions::SyncSessionsClient::SyncSessionsClient()'\nobj/chrome/browser/libbrowser.a(chrome_sync_client.o):../../chrome/browser/sync/chrome_sync_client.cc:function browser_sync::SyncSessionsClientImpl::~SyncSessionsClientImpl(): error: undefined reference to 'sync_sessions::SyncSessionsClient::~SyncSessionsClient()'\nobj/chrome/browser/libbrowser.a(chrome_sync_client.o):../../chrome/browser/sync/chrome_sync_client.cc:function browser_sync::SyncSessionsClientImpl::~SyncSessionsClientImpl(): error: undefined reference to 'sync_sessions::SyncSessionsClient::~SyncSessionsClient()'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleryPrefInfo::AbsolutePath() const: error: undefined reference to 'storage_monitor::MediaStorageUtil::FindDevicePathById(std::string const&)'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleryPrefInfo::GetGalleryDisplayName() const: error: undefined reference to 'storage_monitor::MediaStorageUtil::FindDevicePathById(std::string const&)'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleryPrefInfo::GetGalleryDisplayName() const: error: undefined reference to 'storage_monitor::MediaStorageUtil::FindDevicePathById(std::string const&)'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleryPrefInfo::GetGalleryTooltip() const: error: undefined reference to 'storage_monitor::MediaStorageUtil::FindDevicePathById(std::string const&)'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleryPrefInfo::GetGalleryAdditionalDetails() const: error: undefined reference to 'storage_monitor::MediaStorageUtil::IsRemovableStorageAttached(std::string const&)'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleriesPreferences::FinishInitialization(): error: undefined reference to 'storage_monitor::StorageMonitor::AddObserver(storage_monitor::RemovableStorageObserver)'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleriesPreferences::FinishInitialization(): error: undefined reference to 'storage_monitor::StorageMonitor::GetAllAvailableStorages() const'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleriesPreferences::AddDefaultGalleries(): error: undefined reference to 'storage_monitor::MediaStorageUtil::GetDeviceInfoFromPath(base::FilePath const&, storage_monitor::StorageInfo, base::FilePath)'\nobj/chrome/browser/libbrowser.a(media_galleries_preferences.o):../../chrome/browser/media_galleries/media_galleries_preferences.cc:function MediaGalleriesPreferences::LookUpGalleryByPath(base::FilePath const&, MediaGalleryPrefInfo) const: error: undefined reference to 'storage_monitor::MediaStorageUtil::GetDeviceInfoFromPath(base::FilePath const&, storage_monitor::StorageInfo, base::FilePath)'\nobj/chrome/browser/libbrowser.a(off_the_record_profile_impl.o):../../chrome/browser/profiles/off_the_record_profile_impl.cc:function OffTheRecordProfileImpl::UpdateDefaultZoomLevel(): error: undefined reference to 'zoom::ZoomEventManager::OnDefaultZoomLevelChanged()'\nobj/chrome/browser/libbrowser.a(browser_process_impl.o):../../chrome/browser/browser_process_impl.cc:function BrowserProcessImpl::StartTearDown(): error: undefined reference to 'storage_monitor::StorageMonitor::Destroy()'\nobj/chrome/browser/libbrowser.a(browser_process_impl.o):../../chrome/browser/browser_process_impl.cc:function BrowserProcessImpl::PreMainMessageLoopRun(): error: undefined reference to 'storage_monitor::StorageMonitor::Create()'\nobj/chrome/browser/libbrowser.a(media_file_system_registry.o):../../chrome/browser/media_galleries/media_file_system_registry.cc:function ExtensionGalleriesHost::GetMediaFileSystems(std::set, std::allocator > const&, std::map, std::allocator > > const&, base::Callback > const&), (base::internal::CopyMode)1, (base::internal::RepeatMode)1> const&): error: undefined reference to 'storage_monitor::MediaStorageUtil::FilterAttachedDevices(std::set, std::allocator >, base::Callback const&)'\nobj/chrome/browser/libbrowser.a(media_file_system_registry.o):../../chrome/browser/media_galleries/media_file_system_registry.cc:function ExtensionGalleriesHost::RegisterMediaFileSystem(MediaGalleryPrefInfo const&, base::Callback const&): error: undefined reference to 'storage_monitor::MediaStorageUtil::FilterAttachedDevices(std::set, std::allocator >, base::Callback const&)'\nobj/chrome/browser/libbrowser.a(media_file_system_registry.o):../../chrome/browser/media_galleries/media_file_system_registry.cc:function MediaFileSystemRegistry::MediaFileSystemRegistry(): error: undefined reference to 'storage_monitor::StorageMonitor::AddObserver(storage_monitor::RemovableStorageObserver)'\nobj/chrome/browser/libbrowser.a(media_file_system_registry.o):../../chrome/browser/media_galleries/media_file_system_registry.cc:function ExtensionGalleriesHost::GetMediaFileSystemsForAttachedDevices(std::set, std::allocator > const, std::set, std::allocator > const&, std::map, std::allocator > > const&, base::Callback > const&), (base::internal::CopyMode)1, (base::internal::RepeatMode)1> const&): error: undefined reference to 'storage_monitor::MediaStorageUtil::CanCreateFileSystem(std::string const&, base::FilePath const&)'\nobj/chrome/browser/libbrowser.a(media_file_system_registry.o):../../chrome/browser/media_galleries/media_file_system_registry.cc:function ExtensionGalleriesHost::GetMediaFileSystemsForAttachedDevices(std::set, std::allocator > const, std::set, std::allocator > const&, std::map, std::allocator > > const&, base::Callback > const&), (base::internal::CopyMode)1, (base::internal::RepeatMode)1> const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetTransientIdForDeviceId(std::string const&)'\nobj/chrome/browser/libbrowser.a(media_file_system_registry.o):../../chrome/browser/media_galleries/media_file_system_registry.cc:function ExtensionGalleriesHost::RegisterAttachedMediaFileSystem(std::set, std::allocator > const, MediaGalleryPrefInfo const&, base::Callback const&): error: undefined reference to 'storage_monitor::MediaStorageUtil::CanCreateFileSystem(std::string const&, base::FilePath const&)'\nobj/chrome/browser/libbrowser.a(media_file_system_registry.o):../../chrome/browser/media_galleries/media_file_system_registry.cc:function ExtensionGalleriesHost::RegisterAttachedMediaFileSystem(std::set, std::allocator > const, MediaGalleryPrefInfo const&, base::Callback const&): error: undefined reference to 'storage_monitor::StorageMonitor::GetTransientIdForDeviceId(std::string const&)'\nobj/chrome/browser/libbrowser.a(gallery_watch_manager.o):../../chrome/browser/media_galleries/gallery_watch_manager.cc:function GalleryWatchManager::AddWatch(content::BrowserContext, extensions::Extension const, unsigned long, base::Callback const&): error: undefined reference to 'storage_monitor::StorageMonitor::AddObserver(storage_monitor::RemovableStorageObserver)'\nobj/chrome/renderer/librenderer.a(chrome_content_renderer_client.o):../../chrome/renderer/chrome_content_renderer_client.cc:function ChromeContentRendererClient::RenderThreadStarted(): error: undefined reference to 'web_cache::WebCacheImpl::WebCacheImpl()'\nobj/chrome/renderer/librenderer.a(chrome_render_frame_observer.o):../../chrome/renderer/chrome_render_frame_observer.cc:function ChromeRenderFrameObserver::ChromeRenderFrameObserver(content::RenderFrame): error: undefined reference to 'translate::TranslateHelper::TranslateHelper(content::RenderFrame, int, int, std::string const&)'\nobj/chrome/renderer/librenderer.a(chrome_render_frame_observer.o):../../chrome/renderer/chrome_render_frame_observer.cc:function ChromeRenderFrameObserver::DidStartProvisionalLoad(): error: undefined reference to 'translate::TranslateHelper::PrepareForUrl(GURL const&)'\nobj/chrome/renderer/librenderer.a(chrome_render_frame_observer.o):../../chrome/renderer/chrome_render_frame_observer.cc:function ChromeRenderFrameObserver::CapturePageText(ChromeRenderFrameObserver::TextCaptureType): error: undefined reference to 'translate::TranslateHelper::PageCaptured(std::basic_string > const&)'\nobj/chrome/renderer/librenderer.a(chrome_render_thread_observer.o):../../chrome/renderer/chrome_render_thread_observer.cc:function ChromeRenderThreadObserver::ChromeRenderThreadObserver(): error: undefined reference to 'visitedlink::VisitedLinkSlave::VisitedLinkSlave()'\nobj/chrome/renderer/librenderer.a(chrome_render_thread_observer.o):../../chrome/renderer/chrome_render_thread_observer.cc:function ChromeRenderThreadObserver::ChromeRenderThreadObserver(): error: undefined reference to 'visitedlink::VisitedLinkSlave::GetBindCallback()'\nobj/chrome/renderer/librenderer.a(chrome_render_view_observer.o):../../chrome/renderer/chrome_render_view_observer.cc:function ChromeRenderViewObserver::Navigate(GURL const&): error: undefined reference to 'web_cache::WebCacheImpl::ExecutePendingClearCache()'\nobj/components/subresource_filter/content/renderer/librenderer.a(ruleset_dealer.o):../../components/subresource_filter/content/renderer/ruleset_dealer.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::RulesetDealer, subresource_filter::RulesetDealer, void, void (subresource_filter::RulesetDealer::)(base::FileDescriptor const&)): error: undefined reference to 'IPC::MessageT, void>::Read(IPC::Message const, std::tuple)'\nobj/components/subresource_filter/content/renderer/librenderer.a(ruleset_dealer.o):../../components/subresource_filter/content/renderer/ruleset_dealer.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::RulesetDealer, subresource_filter::RulesetDealer, void, void (subresource_filter::RulesetDealer::)(base::FileDescriptor const&)): error: undefined reference to 'SubresourceFilterMsg_SetRulesetForProcess_Meta::kName'\nobj/components/subresource_filter/content/renderer/librenderer.a(ruleset_dealer.o):../../components/subresource_filter/content/renderer/ruleset_dealer.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::RulesetDealer, subresource_filter::RulesetDealer, void, void (subresource_filter::RulesetDealer::)(base::FileDescriptor const&)): error: undefined reference to 'SubresourceFilterMsg_SetRulesetForProcess_Meta::kName'\nobj/components/subresource_filter/content/renderer/librenderer.a(subresource_filter_agent.o):../../components/subresource_filter/content/renderer/subresource_filter_agent.cc:function subresource_filter::SubresourceFilterAgent::SignalFirstSubresourceDisallowedForCommittedLoad(): error: undefined reference to 'IPC::MessageT, void>::MessageT(IPC::Routing)'\nobj/components/subresource_filter/content/renderer/librenderer.a(subresource_filter_agent.o):../../components/subresource_filter/content/renderer/subresource_filter_agent.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::SubresourceFilterAgent, subresource_filter::SubresourceFilterAgent, void, void (subresource_filter::SubresourceFilterAgent::)(subresource_filter::ActivationState)): error: undefined reference to 'IPC::MessageT, void>::Read(IPC::Message const, std::tuple)'\nobj/components/subresource_filter/content/renderer/librenderer.a(subresource_filter_agent.o):../../components/subresource_filter/content/renderer/subresource_filter_agent.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::SubresourceFilterAgent, subresource_filter::SubresourceFilterAgent, void, void (subresource_filter::SubresourceFilterAgent::)(subresource_filter::ActivationState)): error: undefined reference to 'SubresourceFilterMsg_ActivateForProvisionalLoad_Meta::kName'\nobj/components/subresource_filter/content/renderer/librenderer.a(subresource_filter_agent.o):../../components/subresource_filter/content/renderer/subresource_filter_agent.cc:function bool IPC::MessageT, void>::Dispatch(IPC::Message const, subresource_filter::SubresourceFilterAgent, subresource_filter::SubresourceFilterAgent, void, void (subresource_filter::SubresourceFilterAgent::)(subresource_filter::ActivationState)): error: undefined reference to 'SubresourceFilterMsg_ActivateForProvisionalLoad_Meta::kName'\nobj/chrome/browser/ui/libui.a(chrome_zoom_level_otr_delegate.o):../../chrome/browser/ui/zoom/chrome_zoom_level_otr_delegate.cc:function ChromeZoomLevelOTRDelegate::OnZoomLevelChanged(content::HostZoomMap::ZoomLevelChange const&): error: undefined reference to 'zoom::ZoomEventManager::OnZoomLevelChanged(content::HostZoomMap::ZoomLevelChange const&)'\nobj/chrome/browser/ui/libui.a(browser_synced_window_delegates_getter.o):../../chrome/browser/ui/sync/browser_synced_window_delegates_getter.cc:function browser_sync::BrowserSyncedWindowDelegatesGetter::BrowserSyncedWindowDelegatesGetter(Profile): error: undefined reference to 'sync_sessions::SyncedWindowDelegatesGetter::SyncedWindowDelegatesGetter()'\nobj/chrome/browser/ui/libui.a(browser_synced_window_delegates_getter.o):../../chrome/browser/ui/sync/browser_synced_window_delegates_getter.cc:function browser_sync::BrowserSyncedWindowDelegatesGetter::~BrowserSyncedWindowDelegatesGetter(): error: undefined reference to 'sync_sessions::SyncedWindowDelegatesGetter::~SyncedWindowDelegatesGetter()'\nobj/chrome/browser/ui/libui.a(browser_synced_window_delegates_getter.o):../../chrome/browser/ui/sync/browser_synced_window_delegates_getter.cc:function browser_sync::BrowserSyncedWindowDelegatesGetter::~BrowserSyncedWindowDelegatesGetter(): error: undefined reference to 'sync_sessions::SyncedWindowDelegatesGetter::~SyncedWindowDelegatesGetter()'\nobj/chrome/browser/ui/libui.a(chrome_web_contents_view_delegate_views.o):../../chrome/browser/ui/views/tab_contents/chrome_web_contents_view_delegate_views.cc:function ChromeWebContentsViewDelegateViews::Focus(): error: undefined reference to 'web_modal::WebContentsModalDialogManager::IsDialogActive() const'\nobj/chrome/browser/ui/libui.a(chrome_web_contents_view_delegate_views.o):../../chrome/browser/ui/views/tab_contents/chrome_web_contents_view_delegate_views.cc:function ChromeWebContentsViewDelegateViews::Focus(): error: undefined reference to 'web_modal::WebContentsModalDialogManager::FocusTopmostDialog() const'\nobj/chrome/browser/ui/libui.a(browser_options_handler.o):../../chrome/browser/ui/webui/options/browser_options_handler.cc:function options::BrowserOptionsHandler::SetupPageZoomSelector(): error: undefined reference to 'zoom::PageZoom::PresetZoomFactors(double)'\nobj/components/browser_sync/libbrowser_sync.a(profile_sync_components_factory_impl.o):../../components/browser_sync/profile_sync_components_factory_impl.cc:function browser_sync::ProfileSyncComponentsFactoryImpl::RegisterCommonDataTypes(syncer::SyncService, syncer::EnumSet, syncer::EnumSet): error: undefined reference to 'sync_sessions::SessionDataTypeController::SessionDataTypeController(base::Callback const&, syncer::SyncClient, syncer::LocalDeviceInfoProvider, char const)'\nobj/components/history/content/browser/libbrowser.a(content_visit_delegate.o):../../components/history/content/browser/content_visit_delegate.cc:function history::ContentVisitDelegate::ContentVisitDelegate(content::BrowserContext): error: undefined reference to 'visitedlink::VisitedLinkMaster::VisitedLinkMaster(content::BrowserContext, visitedlink::VisitedLinkDelegate, bool)'\nobj/components/history/content/browser/libbrowser.a(content_visit_delegate.o):../../components/history/content/browser/content_visit_delegate.cc:function history::ContentVisitDelegate::Init(history::HistoryService): error: undefined reference to 'visitedlink::VisitedLinkMaster::Init()'\nobj/components/history/content/browser/libbrowser.a(content_visit_delegate.o):../../components/history/content/browser/content_visit_delegate.cc:function history::ContentVisitDelegate::AddURL(GURL const&): error: undefined reference to 'visitedlink::VisitedLinkMaster::AddURL(GURL const&)'\nobj/components/history/content/browser/libbrowser.a(content_visit_delegate.o):../../components/history/content/browser/content_visit_delegate.cc:function history::ContentVisitDelegate::AddURLs(std::vector > const&): error: undefined reference to 'visitedlink::VisitedLinkMaster::AddURLs(std::vector > const&)'\nobj/components/history/content/browser/libbrowser.a(content_visit_delegate.o):../../components/history/content/browser/content_visit_delegate.cc:function history::ContentVisitDelegate::DeleteURLs(std::vector > const&): error: undefined reference to 'visitedlink::VisitedLinkMaster::DeleteURLs(visitedlink::VisitedLinkMaster::URLIterator*)'\nobj/components/history/content/browser/libbrowser.a(content_visit_delegate.o):../../components/history/content/browser/content_visit_delegate.cc:function history::ContentVisitDelegate::DeleteAllURLs(): error: undefined reference to 'visitedlink::VisitedLinkMaster::DeleteAllURLs()'\nobj/components/subresource_filter/content/browser/libbrowser.a(content_ruleset_distributor.o):../../components/subresource_filter/content/browser/content_ruleset_distributor.cc:function subresource_filter::ContentRulesetDistributor::PublishNewVersion(base::File): error: undefined reference to 'IPC::MessageT, void>::MessageT(IPC::Routing, base::FileDescriptor const&)'\nobj/components/subresource_filter/content/browser/libbrowser.a(content_ruleset_distributor.o):../../components/subresource_filter/content/browser/content_ruleset_distributor.cc:function subresource_filter::ContentRulesetDistributor::Observe(int, content::NotificationSource const&, content::NotificationDetails const&): error: undefined reference to 'IPC::MessageT, void>::MessageT(IPC::Routing, base::FileDescriptor const&)'\nobj/chrome/browser/extensions/libextensions.a(tabs_api.o):../../chrome/browser/extensions/api/tabs/tabs_api.cc:function extensions::TabsSetZoomFunction::RunAsync(): error: undefined reference to 'zoom::ZoomController::SetZoomLevelByClient(double, scoped_refptr const&)'\nobj/chrome/browser/extensions/libextensions.a(tabs_api.o):../../chrome/browser/extensions/api/tabs/tabs_api.cc:function extensions::TabsSetZoomSettingsFunction::RunAsync(): error: undefined reference to 'zoom::ZoomController::SetZoomMode(zoom::ZoomController::ZoomMode)'\nobj/extensions/components/native_app_window/libnative_app_window.a(native_app_window_views.o):../../extensions/components/native_app_window/native_app_window_views.cc:function native_app_window::NativeAppWindowViews::~NativeAppWindowViews(): error: undefined reference to 'web_modal::WebContentsModalDialogHost::~WebContentsModalDialogHost()'\nobj/extensions/components/native_app_window/libnative_app_window.a(native_app_window_views.o):../../extensions/components/native_app_window/native_app_window_views.cc:function extensions::NativeAppWindow::~NativeAppWindow(): error: undefined reference to 'web_modal::WebContentsModalDialogHost::~WebContentsModalDialogHost()'\nobj/chrome/browser/ui/libui.a(media_galleries_dialog_views.o):../../chrome/browser/ui/views/extensions/media_galleries_dialog_views.cc:function MediaGalleriesDialogViews::AcceptDialogForTesting(): error: undefined reference to 'web_modal::WebContentsModalDialogManager::CloseAllDialogs()'\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nninja: build stopped: subcommand failed.\n2016-12-05 17:13:27,258 - ERROR: ninja returned non-zero exit code: 1\n``. @Eloston runninginstall-build-deps.sh` gives me the following error:\ninstall-build-deps.sh: 77: install-build-deps.sh: [[: not found\ninstall-build-deps.sh: 163: install-build-deps.sh: arm_list+= g++-4.8-multilib-arm-linux-gnueabihf\n                gcc-4.8-multilib-arm-linux-gnueabihf: not found\ninstall-build-deps.sh: 195: install-build-deps.sh: Syntax error: \"(\" unexpected\nI installed a few packages that I saw in the script and hadn't installed before, but got the same error. I'm going to try your new commit now.. Tried building with the new commit. It didn't find clang++.\nINFO: Running build command...\nninja: Entering directory `out/Default'\n[6/23938] CXX obj/base/base_paths/base_paths.o\nFAILED: ../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/base/base_paths/base_paths.o.d -DV8_DEPRECATION_WARNINGS -DENABLE_MDNS=1 -DENABLE_NOTIFICATIONS -DENABLE_PEPPER_CDMS -DENABLE_PLUGINS=1 -DENABLE_PDF=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_CLIPBOARD_AURAX11=1 -DUSE_DEFAULT_RENDER_THEME=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DDISABLE_NACL -DENABLE_EXTENSIONS=1 -DENABLE_TASK_MANAGER=1 -DENABLE_THEMES=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DUSE_PROPRIETARY_CODECS -DOFFICIAL_BUILD -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=282487-1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DBASE_IMPLEMENTATION -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/ug/v55/ungoogled-chromium/build/sandbox=. -pthread -m64 -march=x86-64 -Wall -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -O2 -fno-ident -fdata-sections -ffunction-sections -g0 -fvisibility=hidden -Xclang -load -Xclang ../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-ipc -Wheader-hygiene -Wstring-conversion -Wexit-time-destructors -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../base/base_paths.cc -o obj/base/base_paths/base_paths.o\n/bin/sh: 1: ../../third_party/llvm-build/Release+Asserts/bin/clang++: not found\nEDIT: This could be because I messed up the VM. llvm-3.9 seems fine, though.\nEDIT2: nvm, I messed up build.py. It should start building correctly now.. @Eloston That made it run correctly. It installed a bunch of stuff.\nThe error about clang not being found keeps happening, though. I tried it from scratch and there is no /third_party/llvm-build folder for some reason. That folder is there on OS X, and should be on every platform since the downloaded source is the same, I think.\nEdit: that folder from the downloaded llvm+clang. Do you want to try downloading it manually for Linux too? \nEdit2: downloading llvm from their website results in the following error:\nerror: unable to load plugin '../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so': '../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so: cannot open shared object file: No such file or directory'\nninja: build stopped: subcommand failed.\n2016-12-06 12:24:17,881 - ERROR: ninja returned non-zero exit code: 1\nEdit3: the above error is related to this. I'm trying to build with the old flags now, lets see if installing all those packages will change anything.. @Eloston. It compiled (using the old flags, not just those 3). Heres a screenshot of how its running: https://fuwa.se/p/uzPPkm.png\nI guess something went really wrong. hahah\nThe browser seems to be working, but I can't see anything.\nEdit: here is a screenshot with the interface working (just launched it again). Seems like webkit rendering is broken, maybe?\n. Yes, I'm running it on VirtualBox.. @Eloston Yes. If you this thats the cause of the problem, I can try running this VM on Windows.\nYes, its Lubuntu 14.04.. @Eloston Good news! Not only it displayed correctly on Windows, but the static build compiled in 14.04 works on 16.10.\nIs this expected to work on non-Debian distros too? \nTell me if you want distribution-ready binaries - I have to compile it without the extra flags.. @Eloston Testes this on an Antergos VM and it worked (had to run with --no-sandbox, though).. @Eloston something about the kernel. I'll post the entire message when I boot the VM again.\nSeems like something is wrong in the master branch. Got the same error as before when compiling it:\n```\n[7/23938] CXX obj/base/base_static/switches.o\nFAILED: ../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/base/base_static/switches.o.d -DV8_DEPRECATION_WARNINGS -DENABLE_MDNS=1 -DENABLE_NOTIFICATIONS -DENABLE_PEPPER_CDMS -DENABLE_PLUGINS=1 -DENABLE_PDF=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_CLIPBOARD_AURAX11=1 -DUSE_DEFAULT_RENDER_THEME=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DDISABLE_NACL -DENABLE_EXTENSIONS=1 -DENABLE_TASK_MANAGER=1 -DENABLE_THEMES=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DUSE_PROPRIETARY_CODECS -DOFFICIAL_BUILD -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=282487-1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/ug/release_build/ungoogled-chromium/build/sandbox=. -pthread -m64 -march=x86-64 -Wall -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -g0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -O2 -fno-ident -fdata-sections -ffunction-sections -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../base/task_scheduler/switches.cc -o obj/base/base_static/switches.o\n/bin/sh: 1: ../../third_party/llvm-build/Release+Asserts/bin/clang++: not found\n[7/23938] ACTION //mojo/common:common_...ngs(//build/toolchain/linux:clang_x64)\nninja: build stopped: subcommand failed.\n```. @Eloston\n[6/23934] CXX obj/base/allocator/tcmalloc/linuxthreads.o\nFAILED: ../../../../../../../../usr/bin/clang++ -MMD -MF obj/base/allocator/tcmalloc/linuxthreads.o.d -DNO_HEAP_CHECK -DV8_DEPRECATION_WARNINGS -DENABLE_MDNS=1 -DENABLE_NOTIFICATIONS -DENABLE_PEPPER_CDMS -DENABLE_PLUGINS=1 -DENABLE_PDF=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_CLIPBOARD_AURAX11=1 -DUSE_DEFAULT_RENDER_THEME=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DDISABLE_NACL -DENABLE_EXTENSIONS=1 -DENABLE_TASK_MANAGER=1 -DENABLE_THEMES=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DUSE_PROPRIETARY_CODECS -DOFFICIAL_BUILD -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=282487-1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DTCMALLOC_DONT_REPLACE_SYSTEM_ALLOC -I../../base/allocator -I../../third_party/tcmalloc/chromium/src/base -I../../third_party/tcmalloc/chromium/src -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/ug/release_build/ungoogled-chromium/build/sandbox=. -pthread -m64 -march=x86-64 -g0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wall -Wno-unused-variable -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-reorder -Wno-unused-function -Wno-unused-local-typedefs -Wno-unused-private-field -Wno-sign-compare -Wno-unused-result -O2 -fno-ident -fdata-sections -ffunction-sections -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -Wno-deprecated -c ../../third_party/tcmalloc/chromium/src/base/linuxthreads.cc -o obj/base/allocator/tcmalloc/linuxthreads.o\n/bin/sh: 1: ../../../../../../../../usr/bin/clang++: not found\nllvm-3.9 is installed.\nEdit: I thought it was a problem with the path, but seems like clang++ is referred to as clang++-3.9. I just renamed the shortcuts and it seems to be working.. @Eloston I added the repositories from here then did sudo apt install llvm-3.9. I think the default version of 14.04 is 3.4, so I never installed it.. @Eloston any idea why we only got this error now?. It seems it didn't create a symlink before.\n@Eloston\nungoogled-chromium 55.0.2883.75-1 (static build)\nSHA-1: 7d013ec44b22c561dc21f028de57c90b7eb8b66b\nMD5: 4cbeb5459274649b25c5ab9a20bb7d3f\nDownload link: https://my.mixtape.moe/effpyy.tar.xz\nTested on Ubuntu 14.04, Ubuntu 16.10 and Antergos.. Discovered how to reproduce it:\n1) Open ungoogled-chromium\n2) Go to the \"About Chromium\" page\n3) Click on \"Get help with using Chromium\". It should open a new tab and attempt to connect to the link pointed in the first post. Close the warning.\n4) From now on, as long as you don't close the tab opened before, it should attempt to connect to that link every time you visit the \"Extensions\" page, or any other page through the menu (Downloads, Settings, History, etc).\n5) This does not happen if you directly type the URL (ie. chrome://extensions).\n. Perhaps you could link the \"Get help with Chromium\" to this Github page?\nMaybe change the text a bit to make it clear its about ungoogled-chromium.\n. I see. Makes sense. ungoogled-chromium feels just like regular Chromium, but without google integration - instead of a full blown fork. Good to read that this is intentional and you intend to keep it that way.\n. Yes, the button is not there. I also can't change user through the settings page. You only get a new session when you create a new user, and once you close it, you can't open a new session for that user anymore.\n. @Eloston Just started building it, should be able to post my results tomorrow.\nI think its good for @Noleli to run Facebook in a separate profile. It'll probably have different add-ons installed and most likely will have a different fingerprint.\n. Confirmed, building it without patching avatar_menu.cc brings the menu back.\nThis also fixed another bug. I can now right click Chromium's icon in the dock to select user - it wasn't showing anything before. I also didn't see any additional connection when messing with the users, this seems safe to enable.\nHere is the resulting .dmg: https://my.mixtape.moe/srkvhc.dmg\n. > only asks the servers\nI think that, for the public of ungoogled-chromium, its not desirable if it connects to Google servers, even if it was designed with privacy in mind. Though they are very different issues, the reasoning seems similar with Signal's dependence on GCM.\nThe main principle of this project is that it will block any kind of connection to Google. As it is with other Google services, you'll lose a bit of convenience by not using them.\nI think its likely that most users of ungoogled-chromium are also using add-ons like uBlock Origin, which already provides blocklists for malware domains.\n. > Well, who is the public of ungoogle-chromium?\n@Eloston should respond this one, but IMO the average user of ungoogled-chromium are power users who actively filter their browsing with extensions (such as uBlock Origin and uMatrix). They rather use a Chromium-based browser instead of Firefox or one of its forks because its way more responsive.\n\nPhishing sites are designed to deceive, and they deceive power users, too. Safe Browsing also blocks sites serving malicious content (like exploit kits, where you don't even have to click anything to get infected).\n\nI've yet to see someone using uBlock Origin and/or uMatrix to get infected through phishing sites. Based on what you say \"they deceive power users\"? As anecdotal as it is, I've yet to see a normal, tech-illiterate user get infected with a proper adblock installed.\n\nIf it were only convenience you lost, then I wouldn't have filed this issue. This has a direct security impact on your users, and you're exposing them to risks without explaining what they are. I'm merely asking you to explain these risks, to make sure that users know what to expect.\n\nI agree with you in this instance. Having a page explaining how safe browsing works would have no harm.\n\nAdblockers don't update often enough to provide the same level of protection, and if you're not preinstalling one, then you can't expect everyone to have one.\nSource on this? What adblock are you using? uBlock Origin's default lists are updated almost every day.\n\nAlso, you're right in the sense that I cannot prove everyone using ungoogled-chromium is also using an Adblock. But I also highly doubt they aren't. If they are the kind of users to install this variant in the first place (maybe compiling it from source), I'm pretty damn sure they know what an adblock is.\n. What platform are you using? It should build just fine in Debian Jessie/Stretch, Ubuntu 16.04-based distros and OS X (with proprietary codecs support). Check the build page.\nAfter installing the dependencies, you just run build.py and it should build without more input from you.\n. Currently, there is no support for Linux distributions that aren't Debian-based. If you want to use ungoogled-chromium in Fedora, you can check Google's official instructions to build Chromium on Fedora and apply the patches manually. You can have more info in the building page.\n. Its easier to just block JavaScript by default with uMatrix. It solves literally all of the issues you pointed out.\nAs for WebRTC, check this and this. You can't disable WebRTC in the Desktop version of Chrome/Chromium, but privacy-wise, It only matters if you're using a VPN. \nWebRTC would leak your external and local IP addresses even behind a VPN - that extension fixes this.\n. Then you enable it manually for the sites you want. You can use uMatrix for that.\nI think thats easier than playing a cat-and-mouse game with JS.\nHere are a few solutions to the issues you pointed that don't involve disabling JavaScript:\nCanvas fingerprinting: run Chromium with --disable-reading-from-canvas flag\nWebRTC leaks: https://chrome.google.com/webstore/detail/webrtc-block/nphkkbaidamjmhfanlpblblcadhfbkdm\nYet, here are some fingerprinting sources you have by leaving JS enabled by default:\n-     UserAgent\n-     Language\n-     Color Depth\n-     Screen Resolution\n-     Timezone\n-     Has session storage or not\n-     Has local storage or not\n-     Has indexed DB\n-     Has IE specific 'AddBehavior'\n-     Has open DB\n-     CPU class\n-     Platform\n-     DoNotTrack or not\n-     Full list of installed fonts (maintaining their order, which increases the entropy), implemented with Flash.\n-     A list of installed fonts, detected with JS/CSS (side-channel technique) - can detect up to 500 installed fonts without flash\n-     Canvas fingerprinting\n-     WebGL fingerprinting\n-     Plugins (IE included)\n-     Is AdBlock installed or not\n-     Has the user tampered with its languages\n-     Has the user tampered with its screen resolution\n-     Has the user tampered with its OS\n-     Has the user tampered with its browser\n-     Touch screen detection and capabilities\n-     Pixel Ratio\n-     Multi-monitor detection\n-     Internal HashTable implementation detection\n-     WebRTC fingerprinting\n-     Math constants\n-     Accessibility fingerprinting\n-     Camera information\n-     DRM support\n-     Accelerometer support\n-     Virtual keyboards\n-     List of supported gestures (for touch-enabled devices)\n-     Pixel density\n-     Video and audio codecs availability\n-     Audio stack fingerprinting\nsource\n. Imo, a simple setup for people with no tech knowledge at all, and still decent privacy-wise, would be just uBlock Origin with more lists enabled than default (specially the multipurpose lists). Still, there aren't (or I'm not aware about) easy to use, working alternatives to FF extensions like Self-Destructing Cookies and Decentraleyes. There is Packet Guard to manage cookies, but its interface isn't as easy to use as SDC. In the topic of privacy+ease to use, there is really no super easy way to select which sites you want to save cookies from.\nTo keep this about fingerprinting: uBlock Origin helps in stopping fingerprinting elements from running, but for this specific issue, unfortunately I can't see a middle ground between just using a good blocker like uBO and script blocking with uMatrix or NoScript.\nDoes anyone knows how Privacy Badger works? This part from their site seems relevant:\n\nAt a more technical level, Privacy Badger keeps note of the \"third party\" domains that embed images, scripts and advertising in the pages you visit. If a third party server appears to be tracking you without permission, by using uniquely identifying cookies (and, as of version 1.0, local storage super cookies and canvas fingerprinting as well) to collect a record of the pages you visit across multiple sites, Privacy Badger will automatically disallow content from that third party tracker. In some cases a third-party domain provides some important aspect of a page's functionality, such as embedded maps, images, or stylesheets. In those cases Privacy Badger will allow connections to the third party but will screen out its tracking cookies and referrers.\n\nThe WebExtensions version of Decentraleyes can't come soon enough.\n. @kd7lxl This is pretty strange. There is no such file (suggestions.pb.h) in my build folder, and I built Chromium without any problems.\nI'll test the build process again.\n. I just tested the build process from scratch and it built successfully. I'm also on OS X 10.11.6.\nMy instant_service.h also includes components/suggestions/proto/suggestions.pb.h, but I don't have that file. I suppose it gets deleted at some point in the build process.\nDid you try to build it multiple times? Did you run python3 build.py more than once?\n. Nevermind, @Eloston is correct. I was looking at the wrong folder. suggestions.pb.h is there for me.\n. > Yes, and I run the command rm -rf build before calling python3 build.py. Is this the correct procedure?\nThere is no need to delete the build folder. You can edit build.py and comment the lines you don't want to repeat. \nbuilder.check_build_environment()\n        builder.setup_chromium_source()\n        builder.setup_build_sandbox()\n        builder.apply_patches()\n        builder.setup_build_utilities()\n        builder.generate_build_configuration()\n        builder.build()\n        builder.generate_package()\nIf you stopped building for some reason and want to resume it without any changes, you can comment all these lines except the last two.\n. @Eloston I'm trying to use the the static build to work on Ubuntu 14.04. It seems to compile just fine, but I'm getting the following error when linking. Any ideas?\n[215/215] LINK ./chrome\nFAILED: ../../../../../../../usr/lib/llvm-3.9/bin/clang++ -pie -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -fuse-ld=gold -B -Wl,--icf=all -pthread -m64 -Wl,-O1 -Wl,--gc-sections -Wl,--no-as-needed -lpthread -Wl,--as-needed -Wl,-rpath-link=../Release -Wl,--disable-new-dtags -Wl,--export-dynamic -Wl,-uhb_ft_face_create_cached,-uhb_glib_get_unicode_funcs -o \"./chrome\" -Wl,--start-group @\"./chrome.rsp\"  -Wl,--end-group  -ldl -lrt -lpangocairo-1.0 -lpango-1.0 -lcairo -lgobject-2.0 -lglib-2.0 -lX11 -lXcomposite -lXcursor -lXdamage -lXext -lXfixes -lXi -lXrender -lXtst -lgmodule-2.0 -lgthread-2.0 -lnss3 -lnssutil3 -lsmime3 -lplds4 -lplc4 -lnspr4 -lcups -lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err -lgcrypt -lz -lpthread -lm -lcrypt -lexpat -lgio-2.0 -lfontconfig -ldbus-1 -latomic -lresolv -lfreetype -lXss -lXrandr -latk-1.0 -lasound -lgtk-x11-2.0 -lgdk-x11-2.0 -lpangoft2-1.0 -lgdk_pixbuf-2.0 \nobj/content/browser/browser/zygote_main_linux.o:../../content/zygote/zygote_main_linux.cc:function content::ZygoteMain(content::MainFunctionParams const&, ScopedVector<content::ZygoteForkDelegate>): error: undefined reference to 'blink::WebFontRendering::setSkiaFontManager(SkFontMgr*)'\nobj/extensions/renderer/renderer/messaging_bindings.o:../../extensions/renderer/messaging_bindings.cc:function extensions::(anonymous namespace)::ExtensionImpl::PostMessage(v8::FunctionCallbackInfo<v8::Value> const&): error: undefined reference to 'blink::WebUserGestureIndicator::isProcessingUserGesture()'\nobj/extensions/renderer/renderer/request_sender.o:../../extensions/renderer/request_sender.cc:function extensions::RequestSender::InsertRequest(int, extensions::PendingRequest*): error: undefined reference to 'blink::WebUserGestureToken::reset()'\nobj/extensions/renderer/renderer/request_sender.o:../../extensions/renderer/request_sender.cc:function extensions::RequestSender::RemoveRequest(int): error: undefined reference to 'blink::WebUserGestureToken::reset()'\nobj/extensions/renderer/renderer/request_sender.o:../../extensions/renderer/request_sender.cc:function extensions::RequestSender::StartRequest(extensions::RequestSender::Source*, std::string const&, int, bool, bool, base::ListValue*): error: undefined reference to 'blink::WebUserGestureIndicator::currentUserGestureToken()'\nobj/extensions/renderer/renderer/request_sender.o:../../extensions/renderer/request_sender.cc:function extensions::RequestSender::StartRequest(extensions::RequestSender::Source*, std::string const&, int, bool, bool, base::ListValue*): error: undefined reference to 'blink::WebUserGestureToken::assign(blink::WebUserGestureToken const&)'\nobj/extensions/renderer/renderer/request_sender.o:../../extensions/renderer/request_sender.cc:function extensions::RequestSender::StartRequest(extensions::RequestSender::Source*, std::string const&, int, bool, bool, base::ListValue*): error: undefined reference to 'blink::WebUserGestureToken::reset()'\nobj/extensions/renderer/renderer/request_sender.o:../../extensions/renderer/request_sender.cc:function extensions::RequestSender::StartRequest(extensions::RequestSender::Source*, std::string const&, int, bool, bool, base::ListValue*): error: undefined reference to 'blink::WebUserGestureIndicator::isProcessingUserGesture()'\nobj/extensions/renderer/renderer/request_sender.o:../../extensions/renderer/request_sender.cc:function extensions::RequestSender::HandleResponse(int, bool, base::ListValue const&, std::string const&): error: undefined reference to 'blink::WebUserGestureToken::reset()'\nobj/extensions/renderer/renderer/user_gestures_native_handler.o:../../extensions/renderer/user_gestures_native_handler.cc:function extensions::UserGesturesNativeHandler::IsProcessingUserGesture(v8::FunctionCallbackInfo<v8::Value> const&): error: undefined reference to 'blink::WebUserGestureIndicator::isProcessingUserGesture()'\nobj/extensions/renderer/renderer/user_gestures_native_handler.o:../../extensions/renderer/user_gestures_native_handler.cc:function extensions::UserGesturesNativeHandler::RunWithoutUserGesture(v8::FunctionCallbackInfo<v8::Value> const&): error: undefined reference to 'blink::WebUserGestureIndicator::consumeUserGesture()'\nobj/pdf/libpdf.a(pdfium_engine.o):../../pdf/pdfium/pdfium_engine.cc:function chrome_pdf::InitializeSDK(): error: undefined reference to 'FSDK_SetUnSpObjProcessHandler'\nobj/pdf/libpdf.a(pdfium_engine.o):../../pdf/pdfium/pdfium_engine.cc:function chrome_pdf::PDFiumEngine::ContinueLoadingDocument(std::string const&): error: undefined reference to 'FPDFDoc_GetPageMode'\nobj/content/child/libchild.a(quota_dispatcher.o):../../content/child/quota_dispatcher.cc:function content::QuotaDispatcher::RequestStorageQuota(int, GURL const&, storage::StorageType, unsigned long, content::QuotaDispatcher::Callback*): error: undefined reference to 'blink::WebUserGestureIndicator::isProcessingUserGesture()'\nobj/third_party/WebKit/Source/web/libblink_web.a(WebScopedUserGesture.o):../../third_party/WebKit/Source/web/WebScopedUserGesture.cpp:function blink::WebScopedUserGesture::WebScopedUserGesture(blink::WebUserGestureToken const&): error: undefined reference to 'blink::WebUserGestureToken::operator WTF::PassRefPtr<blink::UserGestureToken>() const'\nobj/third_party/WebKit/Source/web/libblink_web.a(WebViewImpl.o):../../third_party/WebKit/Source/web/WebViewImpl.cpp:function blink::WebViewImpl::handleGestureEvent(blink::WebGestureEvent const&): error: undefined reference to 'blink::WebSettingsImpl::doubleTapToZoomEnabled() const'\nobj/third_party/WebKit/Source/web/libblink_web.a(WebViewImpl.o):../../third_party/WebKit/Source/web/WebViewImpl.cpp:function blink::WebViewImpl::handleGestureEvent(blink::WebGestureEvent const&): error: undefined reference to 'blink::WebSettingsImpl::multiTargetTapNotificationEnabled()'\nobj/third_party/WebKit/Source/web/libblink_web.a(WebViewImpl.o):../../third_party/WebKit/Source/web/WebViewImpl.cpp:function blink::WebViewImpl::updatePageDefinedViewportConstraints(blink::ViewportDescription const&): error: undefined reference to 'blink::WebSettingsImpl::WebSettingsImpl(blink::Settings*, blink::DevToolsEmulator*)'\nobj/third_party/WebKit/Source/web/libblink_web.a(WebViewImpl.o):../../third_party/WebKit/Source/web/WebViewImpl.cpp:function blink::WebViewImpl::updatePageDefinedViewportConstraints(blink::ViewportDescription const&): error: undefined reference to 'blink::WebSettingsImpl::WebSettingsImpl(blink::Settings*, blink::DevToolsEmulator*)'\nobj/third_party/WebKit/Source/web/libblink_web.a(WebViewImpl.o):../../third_party/WebKit/Source/web/WebViewImpl.cpp:function blink::WebViewImpl::updatePageDefinedViewportConstraints(blink::ViewportDescription const&): error: undefined reference to 'blink::WebSettingsImpl::WebSettingsImpl(blink::Settings*, blink::DevToolsEmulator*)'\nobj/third_party/WebKit/Source/web/libblink_web.a(WebViewImpl.o):../../third_party/WebKit/Source/web/WebViewImpl.cpp:function blink::WebViewImpl::updatePageDefinedViewportConstraints(blink::ViewportDescription const&): error: undefined reference to 'blink::WebSettingsImpl::WebSettingsImpl(blink::Settings*, blink::DevToolsEmulator*)'\nobj/third_party/WebKit/Source/web/libblink_web.a(ChromeClientImpl.o):../../third_party/WebKit/Source/web/ChromeClientImpl.cpp:function blink::ChromeClientImpl::openJavaScriptAlertDelegate(blink::LocalFrame*, WTF::String const&): error: undefined reference to 'blink::WebUserGestureIndicator::currentUserGestureToken()'\nobj/third_party/WebKit/Source/web/libblink_web.a(ChromeClientImpl.o):../../third_party/WebKit/Source/web/ChromeClientImpl.cpp:function blink::ChromeClientImpl::openJavaScriptAlertDelegate(blink::LocalFrame*, WTF::String const&): error: undefined reference to 'blink::WebUserGestureToken::setJavascriptPrompt()'\nobj/third_party/WebKit/Source/web/libblink_web.a(ChromeClientImpl.o):../../third_party/WebKit/Source/web/ChromeClientImpl.cpp:function blink::ChromeClientImpl::openJavaScriptConfirmDelegate(blink::LocalFrame*, WTF::String const&): error: undefined reference to 'blink::WebUserGestureIndicator::currentUserGestureToken()'\nobj/third_party/WebKit/Source/web/libblink_web.a(ChromeClientImpl.o):../../third_party/WebKit/Source/web/ChromeClientImpl.cpp:function blink::ChromeClientImpl::openJavaScriptConfirmDelegate(blink::LocalFrame*, WTF::String const&): error: undefined reference to 'blink::WebUserGestureToken::setJavascriptPrompt()'\nobj/third_party/WebKit/Source/web/libblink_web.a(ChromeClientImpl.o):../../third_party/WebKit/Source/web/ChromeClientImpl.cpp:function blink::ChromeClientImpl::openJavaScriptPromptDelegate(blink::LocalFrame*, WTF::String const&, WTF::String const&, WTF::String&): error: undefined reference to 'blink::WebUserGestureIndicator::currentUserGestureToken()'\nobj/third_party/WebKit/Source/web/libblink_web.a(ChromeClientImpl.o):../../third_party/WebKit/Source/web/ChromeClientImpl.cpp:function blink::ChromeClientImpl::openJavaScriptPromptDelegate(blink::LocalFrame*, WTF::String const&, WTF::String const&, WTF::String&): error: undefined reference to 'blink::WebUserGestureToken::setJavascriptPrompt()'\nobj/third_party/WebKit/Source/web/libblink_web.a(LinkHighlightImpl.o):../../third_party/WebKit/Source/web/LinkHighlightImpl.cpp:function blink::LinkHighlightImpl::computeHighlightLayerPathAndPosition(blink::LayoutBoxModelObject const&): error: undefined reference to 'blink::WebSettingsImpl::mockGestureTapHighlightsEnabled() const'\nobj/third_party/WebKit/Source/web/libblink_web.a(UserMediaClientImpl.o):../../third_party/WebKit/Source/web/UserMediaClientImpl.cpp:function blink::UserMediaClientImpl::requestUserMedia(blink::UserMediaRequest*): error: undefined reference to 'blink::WebUserMediaRequest::WebUserMediaRequest(blink::UserMediaRequest*)'\nobj/third_party/WebKit/Source/web/libblink_web.a(UserMediaClientImpl.o):../../third_party/WebKit/Source/web/UserMediaClientImpl.cpp:function blink::UserMediaClientImpl::requestUserMedia(blink::UserMediaRequest*): error: undefined reference to 'blink::WebUserMediaRequest::reset()'\nobj/third_party/WebKit/Source/web/libblink_web.a(UserMediaClientImpl.o):../../third_party/WebKit/Source/web/UserMediaClientImpl.cpp:function blink::UserMediaClientImpl::cancelUserMediaRequest(blink::UserMediaRequest*): error: undefined reference to 'blink::WebUserMediaRequest::WebUserMediaRequest(blink::UserMediaRequest*)'\nobj/third_party/WebKit/Source/web/libblink_web.a(UserMediaClientImpl.o):../../third_party/WebKit/Source/web/UserMediaClientImpl.cpp:function blink::UserMediaClientImpl::cancelUserMediaRequest(blink::UserMediaRequest*): error: undefined reference to 'blink::WebUserMediaRequest::reset()'\nobj/content/renderer/librenderer.a(render_frame_impl.o):../../content/renderer/render_frame_impl.cc:function content::RenderFrameImpl::OnTextSurroundingSelectionRequest(unsigned int): error: undefined reference to 'blink::WebSurroundingText::WebSurroundingText()'\nobj/content/renderer/librenderer.a(render_frame_impl.o):../../content/renderer/render_frame_impl.cc:function content::RenderFrameImpl::OnTextSurroundingSelectionRequest(unsigned int): error: undefined reference to 'blink::WebSurroundingText::initializeFromCurrentSelection(blink::WebLocalFrame*, unsigned long)'\nobj/content/renderer/librenderer.a(render_frame_impl.o):../../content/renderer/render_frame_impl.cc:function content::RenderFrameImpl::OnTextSurroundingSelectionRequest(unsigned int): error: undefined reference to 'blink::WebSurroundingText::isNull() const'\nobj/content/renderer/librenderer.a(render_frame_impl.o):../../content/renderer/render_frame_impl.cc:function content::RenderFrameImpl::OnTextSurroundingSelectionRequest(unsigned int): error: undefined reference to 'blink::WebSurroundingText::textContent() const'\nobj/content/renderer/librenderer.a(render_frame_impl.o):../../content/renderer/render_frame_impl.cc:function content::RenderFrameImpl::OnTextSurroundingSelectionRequest(unsigned int): error: undefined reference to 'blink::WebSurroundingText::startOffsetInTextContent() const'\nobj/content/renderer/librenderer.a(render_frame_impl.o):../../content/renderer/render_frame_impl.cc:function content::RenderFrameImpl::OnTextSurroundingSelectionRequest(unsigned int): error: undefined reference to 'blink::WebSurroundingText::endOffsetInTextContent() const'\nobj/content/renderer/librenderer.a(render_frame_impl.o):../../content/renderer/render_frame_impl.cc:function content::RenderFrameImpl::OnTextSurroundingSelectionRequest(unsigned int): error: undefined reference to 'blink::WebSurroundingText::~WebSurroundingText()'\nobj/content/renderer/librenderer.a(render_frame_impl.o):../../content/renderer/render_frame_impl.cc:function content::RenderFrameImpl::OpenURL(GURL const&, bool, scoped_refptr<content::ResourceRequestBodyImpl> const&, content::Referrer const&, blink::WebNavigationPolicy, bool, bool): error: undefined reference to 'blink::WebUserGestureIndicator::consumeUserGesture()'\nobj/content/renderer/librenderer.a(render_frame_proxy.o):../../content/renderer/render_frame_proxy.cc:function content::RenderFrameProxy::navigate(blink::WebURLRequest const&, bool): error: undefined reference to 'blink::WebUserGestureIndicator::consumeUserGesture()'\nobj/content/renderer/librenderer.a(render_view_impl.o):../../content/renderer/render_view_impl.cc:function content::RenderViewImpl::createView(blink::WebLocalFrame*, blink::WebURLRequest const&, blink::WebWindowFeatures const&, blink::WebString const&, blink::WebNavigationPolicy, bool): error: undefined reference to 'blink::WebUserGestureIndicator::consumeUserGesture()'\nobj/content/renderer/librenderer.a(render_view_linux.o):../../content/renderer/render_view_linux.cc:function content::RenderViewImpl::UpdateFontRenderingFromRendererPrefs(): error: undefined reference to 'blink::WebFontRendering::setHinting(SkPaint::Hinting)'\nobj/content/renderer/librenderer.a(render_view_linux.o):../../content/renderer/render_view_linux.cc:function content::RenderViewImpl::UpdateFontRenderingFromRendererPrefs(): error: undefined reference to 'blink::WebFontRendering::setAutoHint(bool)'\nobj/content/renderer/librenderer.a(render_view_linux.o):../../content/renderer/render_view_linux.cc:function content::RenderViewImpl::UpdateFontRenderingFromRendererPrefs(): error: undefined reference to 'blink::WebFontRendering::setUseBitmaps(bool)'\nobj/content/renderer/librenderer.a(render_view_linux.o):../../content/renderer/render_view_linux.cc:function content::RenderViewImpl::UpdateFontRenderingFromRendererPrefs(): error: undefined reference to 'blink::WebFontRendering::setAntiAlias(bool)'\nobj/content/renderer/librenderer.a(render_view_linux.o):../../content/renderer/render_view_linux.cc:function content::RenderViewImpl::UpdateFontRenderingFromRendererPrefs(): error: undefined reference to 'blink::WebFontRendering::setSubpixelRendering(bool)'\nobj/content/renderer/librenderer.a(render_view_linux.o):../../content/renderer/render_view_linux.cc:function content::RenderViewImpl::UpdateFontRenderingFromRendererPrefs(): error: undefined reference to 'blink::WebFontRendering::setSubpixelPositioning(bool)'\nobj/content/renderer/librenderer.a(render_view_linux.o):../../content/renderer/render_view_linux.cc:function content::RenderViewImpl::UpdateFontRenderingFromRendererPrefs(): error: undefined reference to 'blink::WebFontRendering::setDefaultFontSize(int)'\nobj/content/renderer/librenderer.a(embedded_shared_worker_stub.o):../../content/renderer/shared_worker/embedded_shared_worker_stub.cc:function content::EmbeddedSharedWorkerStub::EmbeddedSharedWorkerStub(GURL const&, std::basic_string<unsigned short, base::string16_char_traits, std::allocator<unsigned short> > const&, std::basic_string<unsigned short, base::string16_char_traits, std::allocator<unsigned short> > const&, blink::WebContentSecurityPolicyType, blink::WebAddressSpace, bool, int): error: undefined reference to 'blink::WebSharedWorker::create(blink::WebSharedWorkerClient*)'\nobj/content/renderer/librenderer.a(pepper_plugin_instance_impl.o):../../content/renderer/pepper/pepper_plugin_instance_impl.cc:function content::PepperPluginInstanceImpl::SetFullscreen(bool): error: undefined reference to 'blink::WebUserGestureToken::hasGestures() const'\nobj/content/renderer/librenderer.a(pepper_plugin_instance_impl.o):../../content/renderer/pepper/pepper_plugin_instance_impl.cc:function content::PepperPluginInstanceImpl::HandleInputEvent(blink::WebInputEvent const&, blink::WebCursorInfo*): error: undefined reference to 'blink::WebUserGestureToken::assign(blink::WebUserGestureToken const&)'\nobj/content/renderer/librenderer.a(pepper_plugin_instance_impl.o):../../content/renderer/pepper/pepper_plugin_instance_impl.cc:function content::PepperPluginInstanceImpl::HandleInputEvent(blink::WebInputEvent const&, blink::WebCursorInfo*): error: undefined reference to 'blink::WebUserGestureToken::setOutOfProcess()'\nobj/content/renderer/librenderer.a(pepper_plugin_instance_impl.o):../../content/renderer/pepper/pepper_plugin_instance_impl.cc:function content::PepperPluginInstanceImpl::UpdateFlashFullscreenState(bool): error: undefined reference to 'blink::WebUserGestureToken::hasGestures() const'\nobj/content/renderer/librenderer.a(pepper_plugin_instance_impl.o):../../content/renderer/pepper/pepper_plugin_instance_impl.cc:function content::PepperPluginInstanceImpl::IsProcessingUserGesture(): error: undefined reference to 'blink::WebUserGestureToken::hasGestures() const'\nobj/content/renderer/librenderer.a(pepper_plugin_instance_impl.o):../../content/renderer/pepper/pepper_plugin_instance_impl.cc:function content::PepperPluginInstanceImpl::CurrentUserGestureToken(): error: undefined reference to 'blink::WebUserGestureToken::hasGestures() const'\nobj/content/renderer/librenderer.a(pepper_plugin_instance_impl.o):../../content/renderer/pepper/pepper_plugin_instance_impl.cc:function content::PepperPluginInstanceImpl::CurrentUserGestureToken(): error: undefined reference to 'blink::WebUserGestureToken::assign(blink::WebUserGestureToken const&)'\nobj/content/renderer/librenderer.a(pepper_plugin_instance_impl.o):../../content/renderer/pepper/pepper_plugin_instance_impl.cc:function content::PepperPluginInstanceImpl::CurrentUserGestureToken(): error: undefined reference to 'blink::WebUserGestureToken::assign(blink::WebUserGestureToken const&)'\nobj/third_party/pdfium/libpdfium.a(fpdf_dataavail.o):../../third_party/pdfium/fpdfsdk/fpdf_dataavail.cpp:function FPDFAvail_GetDocument: error: undefined reference to 'CheckUnSupportError(CPDF_Document*, unsigned int)'\nobj/third_party/pdfium/libpdfium.a(fpdfview.o):../../third_party/pdfium/fpdfsdk/fpdfview.cpp:function FPDF_LoadMemDocument: error: undefined reference to 'CheckUnSupportError(CPDF_Document*, unsigned int)'\nobj/third_party/pdfium/libpdfium.a(fpdfview.o):../../third_party/pdfium/fpdfsdk/fpdfview.cpp:function FPDF_LoadCustomDocument: error: undefined reference to 'CheckUnSupportError(CPDF_Document*, unsigned int)'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::LoadFXAnnots(): error: undefined reference to 'CheckUnSupportAnnot(CPDF_Document*, CPDF_Annot const*)'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::LoadFXAnnots(): error: undefined reference to 'CPDFSDK_AnnotHandlerMgr::CPDFSDK_AnnotHandlerMgr(CPDFDoc_Environment*)'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_Document::SetFocusAnnot(CPDFSDK_Annot*, unsigned int): error: undefined reference to 'CPDFSDK_AnnotHandlerMgr::CPDFSDK_AnnotHandlerMgr(CPDFDoc_Environment*)'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_Document::KillFocusAnnot(unsigned int): error: undefined reference to 'CPDFSDK_AnnotHandlerMgr::CPDFSDK_AnnotHandlerMgr(CPDFDoc_Environment*)'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::~CPDFSDK_PageView(): error: undefined reference to 'CPDFSDK_AnnotHandlerMgr::CPDFSDK_AnnotHandlerMgr(CPDFDoc_Environment*)'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::PageView_OnDraw(CFX_RenderDevice*, CFX_Matrix*, CPDF_RenderOptions*): error: undefined reference to 'CPDFSDK_AnnotIterator::CPDFSDK_AnnotIterator(CPDFSDK_PageView*, bool)'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::PageView_OnDraw(CFX_RenderDevice*, CFX_Matrix*, CPDF_RenderOptions*): error: undefined reference to 'CPDFSDK_AnnotIterator::Next()'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::PageView_OnDraw(CFX_RenderDevice*, CFX_Matrix*, CPDF_RenderOptions*): error: undefined reference to 'CPDFSDK_AnnotIterator::~CPDFSDK_AnnotIterator()'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::GetFXWidgetAtPoint(float, float): error: undefined reference to 'CPDFSDK_AnnotIterator::CPDFSDK_AnnotIterator(CPDFSDK_PageView*, bool)'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::GetFXWidgetAtPoint(float, float): error: undefined reference to 'CPDFSDK_AnnotIterator::Next()'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::GetFXWidgetAtPoint(float, float): error: undefined reference to 'CPDFSDK_AnnotIterator::Next()'\nobj/third_party/pdfium/libpdfium.a(fsdk_mgr.o):../../third_party/pdfium/fpdfsdk/fsdk_mgr.cpp:function CPDFSDK_PageView::GetFXWidgetAtPoint(float, float): error: undefined reference to 'CPDFSDK_AnnotIterator::~CPDFSDK_AnnotIterator()'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_interform.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_interform.cpp:function CPDFSDK_InterForm::DoAction_Hide(CPDF_Action const&): error: undefined reference to 'CPDFSDK_BAAnnot::GetFlags() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_interform.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_interform.cpp:function CPDFSDK_InterForm::DoAction_Hide(CPDF_Action const&): error: undefined reference to 'CPDFSDK_BAAnnot::SetFlags(unsigned int)'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::IsWidgetAppearanceValid(CPDF_Annot::AppearanceMode): error: undefined reference to 'CPDFSDK_BAAnnot::GetAnnotDict() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::IsWidgetAppearanceValid(CPDF_Annot::AppearanceMode): error: undefined reference to 'CPDFSDK_BAAnnot::GetAppState() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::GetFieldType() const: error: undefined reference to 'CPDFSDK_BAAnnot::GetAnnotDict() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::GetFormField() const: error: undefined reference to 'CPDFSDK_BAAnnot::GetAnnotDict() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::GetFormControl() const: error: undefined reference to 'CPDFSDK_BAAnnot::GetAnnotDict() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_PushButton(): error: undefined reference to 'CPDFSDK_BAAnnot::GetBorderWidth() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_PushButton(): error: undefined reference to 'CPDFSDK_BAAnnot::GetBorderStyle() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_PushButton(): error: undefined reference to 'CPDFSDK_BAAnnot::WriteAppearance(CFX_ByteString const&, CFX_FloatRect const&, CFX_Matrix const&, CFX_ByteString const&, CFX_ByteString const&)'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_PushButton(): error: undefined reference to 'CPDFSDK_BAAnnot::WriteAppearance(CFX_ByteString const&, CFX_FloatRect const&, CFX_Matrix const&, CFX_ByteString const&, CFX_ByteString const&)'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_PushButton(): error: undefined reference to 'CPDFSDK_BAAnnot::WriteAppearance(CFX_ByteString const&, CFX_FloatRect const&, CFX_Matrix const&, CFX_ByteString const&, CFX_ByteString const&)'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_CheckBox(): error: undefined reference to 'CPDFSDK_BAAnnot::GetBorderWidth() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_CheckBox(): error: undefined reference to 'CPDFSDK_BAAnnot::GetBorderStyle() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_CheckBox(): error: undefined reference to 'CPDFSDK_BAAnnot::WriteAppearance(CFX_ByteString const&, CFX_FloatRect const&, CFX_Matrix const&, CFX_ByteString const&, CFX_ByteString const&)'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_CheckBox(): error: undefined reference to 'CPDFSDK_BAAnnot::GetAppState() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_CheckBox(): error: undefined reference to 'CPDFSDK_BAAnnot::SetAppState(CFX_ByteString const&)'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_RadioButton(): error: undefined reference to 'CPDFSDK_BAAnnot::GetBorderWidth() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_RadioButton(): error: undefined reference to 'CPDFSDK_BAAnnot::GetBorderStyle() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_RadioButton(): error: undefined reference to 'CPDFSDK_BAAnnot::GetAppState() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_RadioButton(): error: undefined reference to 'CPDFSDK_BAAnnot::SetAppState(CFX_ByteString const&)'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_ComboBox(wchar_t const*): error: undefined reference to 'CPDFSDK_BAAnnot::GetBorderWidth() const'\nobj/third_party/pdfium/libpdfium.a(cpdfsdk_widget.o):../../third_party/pdfium/fpdfsdk/cpdfsdk_widget.cpp:function CPDFSDK_Widget::ResetAppearance_ComboBox(wchar_t const*): error: undefined reference to 'CPDFSDK_BAAnnot::GetBorderStyle() const'\nobj/third_party/pdfium/libformfiller.a(cffl_iformfiller.o):../../third_party/pdfium/fpdfsdk/formfiller/cffl_iformfiller.cpp:function CFFL_IFormFiller::OnDraw(CPDFSDK_PageView*, CPDFSDK_Annot*, CFX_RenderDevice*, CFX_Matrix*, unsigned int): error: undefined reference to 'CPDFSDK_BAAnnot::IsVisible() const'\nobj/third_party/pdfium/libformfiller.a(cffl_iformfiller.o):../../third_party/pdfium/fpdfsdk/formfiller/cffl_iformfiller.cpp:function CFFL_IFormFiller::IsVisible(CPDFSDK_Widget*): error: undefined reference to 'CPDFSDK_BAAnnot::IsVisible() const'\nobj/third_party/pdfium/libfxedit.a(fxet_edit.o):../../third_party/pdfium/fpdfsdk/fxedit/fxet_edit.cpp:function CFX_Edit::DrawEdit(CFX_RenderDevice*, CFX_Matrix*, CFX_Edit*, unsigned int, unsigned int, CFX_FloatRect const&, CFX_FloatPoint const&, CPVT_WordRange const*, CFX_SystemHandler*, void*): error: undefined reference to 'CFX_SystemHandler::IsSelectionImplemented() const'\nobj/third_party/pdfium/libfxedit.a(fxet_edit.o):../../third_party/pdfium/fpdfsdk/fxedit/fxet_edit.cpp:function CFX_Edit::DrawEdit(CFX_RenderDevice*, CFX_Matrix*, CFX_Edit*, unsigned int, unsigned int, CFX_FloatRect const&, CFX_FloatPoint const&, CPVT_WordRange const*, CFX_SystemHandler*, void*): error: undefined reference to 'CFX_SystemHandler::IsSelectionImplemented() const'\nobj/third_party/pdfium/libfxedit.a(fxet_edit.o):../../third_party/pdfium/fpdfsdk/fxedit/fxet_edit.cpp:function CFX_Edit::DrawEdit(CFX_RenderDevice*, CFX_Matrix*, CFX_Edit*, unsigned int, unsigned int, CFX_FloatRect const&, CFX_FloatPoint const&, CPVT_WordRange const*, CFX_SystemHandler*, void*): error: undefined reference to 'CFX_SystemHandler::OutputSelectedRect(void*, CFX_FloatRect&)'\nobj/third_party/pdfium/libjavascript.a(Annot.o):../../third_party/pdfium/fpdfsdk/javascript/Annot.cpp:function Annot::hidden(IJS_Context*, CJS_PropValue&, CFX_WideString&): error: undefined reference to 'CPDFSDK_BAAnnot::GetFlags() const'\nobj/third_party/pdfium/libjavascript.a(Annot.o):../../third_party/pdfium/fpdfsdk/javascript/Annot.cpp:function Annot::hidden(IJS_Context*, CJS_PropValue&, CFX_WideString&): error: undefined reference to 'CPDFSDK_BAAnnot::SetFlags(unsigned int)'\nobj/third_party/pdfium/libjavascript.a(Annot.o):../../third_party/pdfium/fpdfsdk/javascript/Annot.cpp:function Annot::name(IJS_Context*, CJS_PropValue&, CFX_WideString&): error: undefined reference to 'CPDFSDK_BAAnnot::SetAnnotName(CFX_WideString const&)'\nobj/third_party/pdfium/libjavascript.a(Annot.o):../../third_party/pdfium/fpdfsdk/javascript/Annot.cpp:function Annot::name(IJS_Context*, CJS_PropValue&, CFX_WideString&): error: undefined reference to 'CPDFSDK_BAAnnot::GetAnnotName() const'\nobj/third_party/pdfium/libjavascript.a(Document.o):../../third_party/pdfium/fpdfsdk/javascript/Document.cpp:function Document::getAnnot(IJS_Context*, std::vector<CJS_Value, std::allocator<CJS_Value> > const&, CJS_Value&, CFX_WideString&): error: undefined reference to 'CPDFSDK_AnnotIterator::CPDFSDK_AnnotIterator(CPDFSDK_PageView*, bool)'\nobj/third_party/pdfium/libjavascript.a(Document.o):../../third_party/pdfium/fpdfsdk/javascript/Document.cpp:function Document::getAnnot(IJS_Context*, std::vector<CJS_Value, std::allocator<CJS_Value> > const&, CJS_Value&, CFX_WideString&): error: undefined reference to 'CPDFSDK_AnnotIterator::Next()'\nobj/third_party/pdfium/libjavascript.a(Document.o):../../third_party/pdfium/fpdfsdk/javascript/Document.cpp:function Document::getAnnot(IJS_Context*, std::vector<CJS_Value, std::allocator<CJS_Value> > const&, CJS_Value&, CFX_WideString&): error: undefined reference to 'CPDFSDK_BAAnnot::GetAnnotName() const'\nobj/third_party/pdfium/libjavascript.a(Document.o):../../third_party/pdfium/fpdfsdk/javascript/Document.cpp:function Document::getAnnot(IJS_Context*, std::vector<CJS_Value, std::allocator<CJS_Value> > const&, CJS_Value&, CFX_WideString&): error: undefined reference to 'CPDFSDK_AnnotIterator::~CPDFSDK_AnnotIterator()'\nobj/third_party/pdfium/libjavascript.a(Field.o):../../third_party/pdfium/fpdfsdk/javascript/Field.cpp:function Field::SetBorderStyle(CPDFSDK_Document*, CFX_WideString const&, int, CFX_ByteString const&): error: undefined reference to 'CPDFSDK_BAAnnot::SetBorderStyle(BorderStyle)'\nobj/third_party/pdfium/libjavascript.a(Field.o):../../third_party/pdfium/fpdfsdk/javascript/Field.cpp:function Field::SetBorderStyle(CPDFSDK_Document*, CFX_WideString const&, int, CFX_ByteString const&): error: undefined reference to 'CPDFSDK_BAAnnot::SetBorderStyle(BorderStyle)'\nobj/third_party/pdfium/libjavascript.a(Field.o):../../third_party/pdfium/fpdfsdk/javascript/Field.cpp:function Field::display(IJS_Context*, CJS_PropValue&, CFX_WideString&): error: undefined reference to 'CPDFSDK_BAAnnot::GetFlags() const'\nobj/third_party/pdfium/libjavascript.a(Field.o):../../third_party/pdfium/fpdfsdk/javascript/Field.cpp:function Field::SetDisplay(CPDFSDK_Document*, CFX_WideString const&, int, int): error: undefined reference to 'CPDFSDK_BAAnnot::GetFlags() const'\nobj/third_party/pdfium/libjavascript.a(Field.o):../../third_party/pdfium/fpdfsdk/javascript/Field.cpp:function Field::SetDisplay(CPDFSDK_Document*, CFX_WideString const&, int, int): error: undefined reference to 'CPDFSDK_BAAnnot::SetFlags(unsigned int)'\nobj/third_party/pdfium/libjavascript.a(Field.o):../../third_party/pdfium/fpdfsdk/javascript/Field.cpp:function Field::SetDisplay(CPDFSDK_Document*, CFX_WideString const&, int, int): error: undefined reference to 'CPDFSDK_BAAnnot::SetFlags(unsigned int)'\nobj/third_party/pdfium/libjavascript.a(Field.o):../../third_party/pdfium/fpdfsdk/javascript/Field.cpp:function Field::SetLineWidth(CPDFSDK_Document*, CFX_WideString const&, int, int): error: undefined reference to 'CPDFSDK_BAAnnot::SetBorderWidth(int)'\nobj/third_party/pdfium/libjavascript.a(Field.o):../../third_party/pdfium/fpdfsdk/javascript/Field.cpp:function Field::SetLineWidth(CPDFSDK_Document*, CFX_WideString const&, int, int): error: undefined reference to 'CPDFSDK_BAAnnot::SetBorderWidth(int)'\nobj/third_party/pdfium/libjavascript.a(app.o):../../third_party/pdfium/fpdfsdk/javascript/app.cpp:function GlobalTimer::GlobalTimer(app*, CPDFDoc_Environment*, CJS_Runtime*, int, CFX_WideString const&, unsigned int, unsigned int): error: undefined reference to 'CFX_SystemHandler::SetTimer(int, void (*)(int))'\nobj/third_party/pdfium/libjavascript.a(app.o):../../third_party/pdfium/fpdfsdk/javascript/app.cpp:function GlobalTimer::~GlobalTimer(): error: undefined reference to 'CFX_SystemHandler::KillTimer(int)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_EditCtrl.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_EditCtrl.cpp:function CPWL_EditCtrl::SetCursor(): error: undefined reference to 'CFX_SystemHandler::SetCursor(int)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_FontMap.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_FontMap.cpp:function CPWL_FontMap::GetNativeFont(int): error: undefined reference to 'CFX_SystemHandler::FindNativeTrueTypeFont(CFX_ByteString)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_FontMap.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_FontMap.cpp:function CPWL_FontMap::AddSystemFont(CPDF_Document*, CFX_ByteString&, unsigned char): error: undefined reference to 'CFX_SystemHandler::AddNativeTrueTypeFontToPDF(CPDF_Document*, CFX_ByteString, unsigned char)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_ListBox.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_ListBox.cpp:function CPWL_ListBox::DrawThisAppearance(CFX_RenderDevice*, CFX_Matrix*): error: undefined reference to 'CFX_SystemHandler::IsSelectionImplemented() const'\nobj/third_party/pdfium/libpdfwindow.a(PWL_ListBox.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_ListBox.cpp:function CPWL_ListBox::DrawThisAppearance(CFX_RenderDevice*, CFX_Matrix*): error: undefined reference to 'CFX_SystemHandler::OutputSelectedRect(void*, CFX_FloatRect&)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Timer::~CPWL_Timer(): error: undefined reference to 'CFX_SystemHandler::KillTimer(int)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Timer::~CPWL_Timer(): error: undefined reference to 'CFX_SystemHandler::KillTimer(int)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Timer::SetPWLTimer(int): error: undefined reference to 'CFX_SystemHandler::KillTimer(int)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Timer::SetPWLTimer(int): error: undefined reference to 'CFX_SystemHandler::SetTimer(int, void (*)(int))'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Wnd::InvalidateRect(CFX_FloatRect*): error: undefined reference to 'CFX_SystemHandler::InvalidateRect(void*, FX_RECT)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Wnd::SetCursor(): error: undefined reference to 'CFX_SystemHandler::SetCursor(int)'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Wnd::IsCTRLpressed(unsigned int) const: error: undefined reference to 'CFX_SystemHandler::IsCTRLKeyDown(unsigned int) const'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Wnd::IsSHIFTpressed(unsigned int) const: error: undefined reference to 'CFX_SystemHandler::IsSHIFTKeyDown(unsigned int) const'\nobj/third_party/pdfium/libpdfwindow.a(PWL_Wnd.o):../../third_party/pdfium/fpdfsdk/pdfwindow/PWL_Wnd.cpp:function CPWL_Wnd::IsALTpressed(unsigned int) const: error: undefined reference to 'CFX_SystemHandler::IsALTKeyDown(unsigned int) const'\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nninja: build stopped: subcommand failed.\n2016-12-02 23:53:11,378 - ERROR: ninja returned non-zero exit code: 1\n. Unfortunately, I don't have a Macbook with a trackpad to test this.\n. @Eloston I haven't. I'll try to install it as soon as I can.\n. @henrypp Sorry to bother you, but can you help us with this?\n. @Eloston does the Windows and OS X builds use the enable_widevine = true flag?\n. I'm not sure, I saw it in this comment.\nAccording to this other comment, its a GYP flag.\n. I'll try building and testing with the tool from this comment and see if it works.\n. Compiled with the enable_widevine=1 flag and there wasn't any differences. The widevine plugin still doesn't appear on chrome://components or chrome://plugins. I cannot select the widevine videos on the site to test them.\n. Ok, I've found some clues.\nAdding the enable_widevine=1 flag actually made it compile the Widevine plugin components. They just weren't added to the Chromium.app package for some reason. The files libwidevinecdm.dylib and widevinecdmadapter.plugin are inside the /out folder. I tested them and they work, enabling playback on that test site as well on Netflix.\nHowever, a manifest.json file is also required  for Widevine and, for some reason, it isn't being build. I discovered this by downloading Google Chrome and looking into their .app folder. There, I found the 2 Widevine files plus the manifest.json.\nOn OS X, you can get Widevine support on ungoogled-chromium by doing this:\n1) Create a file with the name manifest.json and the following contents:\n{\n  \"manifest_version\": 2,\n  \"update_url\": \"https://clients2.google.com/service/update2/crx\",\n  \"name\": \"WidevineCdm\",\n  \"description\": \"Widevine Content Decryption Module\",\n  \"offline_enabled\": false,\n  \"version\": \"1.4.8.903\",\n  \"minimum_chrome_version\": \"47.0.2526.0\",\n  \"x-cdm-module-versions\": \"4\",\n  \"x-cdm-interface-versions\": \"8\",\n  \"x-cdm-host-versions\": \"8\",\n  \"x-cdm-codecs\": \"vp8,vp9.0,avc1\",\n  \"icons\": {\n    \"16\": \"imgs/icon-128x128.png\",\n    \"128\": \"imgs/icon-128x128.png\"\n  },\n  \"platforms\": [\n    {\n      \"os\": \"win\",\n      \"arch\": \"x86\",\n      \"sub_package_path\": \"_platform_specific/win_x86/\"\n    },\n    {\n      \"os\": \"win\",\n      \"arch\": \"x64\",\n      \"sub_package_path\": \"_platform_specific/win_x64/\"\n    },\n    {\n      \"os\": \"mac\",\n      \"arch\": \"x86\",\n      \"sub_package_path\": \"_platform_specific/mac_x86/\"\n    },\n    {\n      \"os\": \"mac\",\n      \"arch\": \"x64\",\n      \"sub_package_path\": \"_platform_specific/mac_x64/\"\n    }\n  ]\n}\n2) Get inside your Chromium.app package, and go to Contents/Versions/your_chromium_version/Chromium Framework.framework/\n3) Create a Libraries folder there\n4) Inside it, paste the WidevineCdmfolder from the /out folder.\n5) Put the manifest.json inside the WidevineCdm folder.\nIt should work now. Alternatively, you can just download Chrome and copy the Libraries folder from their package - it also works, even if the Chromium and Chrome versions don't match.\nPutting these files inside a Chromium.app package that was built without the enable_widevine=1 flag doesn't work.\nThe Windows/Linux builds might be getting similar behavior (widevinecdm.dll/libwidevinecdm.so files left in the out folder without being used). We probably can get Widevine support in a similar way with them.\n. Yes, I have libwidevinecdm.dylib. Its probably as you said.\nIts fine by me to wait. Are we going to get any other releases before the switch to GN?\n. Okay.\nAny clues on why those 2 files are not being moved to the Chromium.app package?\n. @Eloston Yes, the files are still missing. They weren't even downloaded, as they're also missing from the /out/Release folder.. @gcarq Thanks for replying. In OS X's case, the libwidevinecdm.dylib file is downloaded and placed in the correct folder inside the Chromium.app package, but for some reason its broken. Its smaller than the one Chrome provides (1.4MB vs 5.2MB)\nReplacing it with Google Chrome's libwidevinecdm.dylib fixes the problem.. @Eloston @gcarq Thanks for clarifying. I'm going to upload the new OS X binaries today.. @pjv here. @pjv @Eloston Whoops, my bad.. @pjv Put the latest Google Chrome.app and the Chromium.app in the same folder. Open that folder in the terminal and run this:\ncp -R Google\\ Chrome.app/Contents/Versions/55.0.2883.95/Google\\ Chrome\\ Framework.framework/Libraries/WidevineCdm Chromium.app/Contents/Versions/55.0.2883.95/Chromium\\ Framework.framework/Libraries/\n. @stfnhrrs could you please post a screenshot of your about:plugins page?. Did you follow this post's instructions? It should be showing the correct version of Widevine.. Try to build a tag release instead of the master branch. \n. I'm sorry, do you mean Chromium (as in, the vanilla Chromium browser by Google)?\nChromium, despite not having the Chrome brand, phones Google for a variety of functions (most of them having some trade-off with privacy). ungoogled-chromium is Chromium with many patches to modify/change these functions so the browser doesn't connect to Google at all.\n. c++-4.9 points by default to /usr/local/bin/c++-4.9.\n. Sorry for not responding clearly before. Yes, it points to the GCC C++ compiler. (/usr/local/Cellar/gcc49/4.9.3/bin/c++-4.9). g++-4.9 exists and its a shortcut to /usr/local/Cellar/gcc49/4.9.3/bin/g++-4.9.\n. tl;dr no, you shouldn't be worried.\nThe connections to the \"9oo91e.qjz9zk\" domain are actually blocked connection attempts to Google servers. ungoogled-chromium uses domain-substitution to remove any Google domain from the source code, and replaces it with a \"9oo91e.qjz9zk\" domain. The warnings you're seeing are to warn you that something happened and it triggered a Google connection attempt.\nFrom the readme:\n\n\n(Iridium Browser feature change) Prevent URLs with the trk: scheme from connecting to the Internet\nAlso prevents any URLs with the top-level domain qjz9zk (as used in domain substitution) from attempting a connection. \n\n\nIf you can replicate it, please post the instructions so we can investigate what triggers it.\n. Are you seeing any connections right when you open your browser?\n. > If you don't mean notifications; should I monitor my traffic when I open up my browser to spot some weird/Google connections?\nNo need to. If it tries to connect to Google, it will show a notification. I should have said notifications.\nIf you want to monitor your traffic, remember you'll see ungoogled-chromium connecting to some IPs to update the uBO/uMatrix lists when you open the browser, and thats it.\n. I don't use any of Google's services. Unfortunately I cannot test it.\nI haven't gotten any requests through navigation alone, only by clicking specific elements of the UI.\n. I'm not getting any notifications when visiting that page.\nAre you managing your cookies? Do you currently have Google cookies stored in your browser?\n. No notification here too.\n. I just tested and the master branch currently builds and works on Xubuntu 16.10.\nI got an error with the latest tag release (which didn't seem related to 16.10). Unfortunately I fucked up and forgot to save the log. I think it was something with 'print_backend_cups.cc'.\n@Eloston are you interested in supporting 16.10? I don't mind building for it.\n. @Eloston those terms are fine by me. I don't expect to meet nearly as many errors on Ubuntu 16.10 as we normally get on OS X.\nI'll provide builds for both in the next release then.\n. @Eloston what do you think about setting up a GitHub webpage for ungoogled-chromium?. @Eloston Yes, thats what I meant.. @lenormf\nHe said collaborators in his post, so not everybody will upload binaries to said page. About the 'responsibility' part, the user is free to not trust the devs at all and build everything from source if they want to (buildlib does that by default). We will always provide hashes so the users can verify their packages.. @Eloston Yeah, I was thinking the same thing.\nI guess we could use something similar to Chromium's homepage (the one you get after an install). I'm not familiar with Github Pages, but I think its fine to just modify a template.. Are you logged into Google?\n. Regarding the intent of the original post, it might be a good idea to implement a way to disable the notifications of blocked connection attempts. While a power user might prefer to have them on, I can see this being a problem if someone setups ungoogled-chromium for another person.\n. I think it should be enabled by default. I expect most users here want to know if an attempt to phone Google happens. Its useful for finding bugs too.\nBut a little checkbox to disable it in the Settings page would do no harm. I'd use it if I was setting up ungoogled-chromium for someone else (less tech-familiar).\n. Yeah, a flag in chrome://flags seems better to control this.\n. Sorry if I'm missing something, but doesn't ungoogled-chromium already do that essentially, as @Eloston pointed out?\nI don't know if you can get Chromium to work with only free software, but it works just fine with only OSS.\n. Ok, lets do this.. Got an error.\n2016-11-30 00:08:43,686 - DEBUG: GN command: out/bootstrap_gn gen out/Release --args=use_sysroot=false safe_browsing_mode=0 enable_rlz=false is_clang=true treat_warnings_as_errors=false google_default_client_secret=\"\" enable_hangout_services_extension=false enable_google_now=false enable_one_click_signin=false enable_widevine=true enable_nacl_nonsfi=false enable_nacl=false enable_remoting=false is_debug=false enable_webrtc=false clang_use_chrome_plugins=false icu_use_data_file=false use_ozone=false fatal_linker_warnings=false enable_mse_mpeg2ts_stream_parser=true ffmpeg_branding=\"ChromeOS\" proprietary_codecs=true google_api_key=\"\" remove_webcore_debug_symbols=true google_default_client_id=\"\" fieldtrial_testing_like_official_build=true enable_hevc_demuxing=true enable_hotwording=false use_official_google_api_keys=false\nERROR at //chrome/browser/ui/BUILD.gn:629:9: Item not found\n        \"views/sync/one_click_signin_dialog_view.cc\",\n        ^-------------------------------------------\nYou were trying to remove \"views/sync/one_click_signin_dialog_view.cc\"\nfrom the list but it wasn't there.\nSee //chrome/test/BUILD.gn:764:7: which caused the file to be included.\n      \"//chrome/browser/ui\",\n      ^--------------------\n2016-11-30 00:08:57,982 - ERROR: gn gen returned non-zero exit code: 1\nEDIT: seems like removing those lines from /chrome/browser/ui/BUILD.gn solved the problem. Lets see if this will bug something when building chromium later.\nsources -= [\n        \"views/sync/one_click_signin_dialog_view.cc\",\n        \"views/sync/one_click_signin_dialog_view.h\",\n    ]\nAlso, it seems it built libc++ flawlessly. I'm starting to build chromium now.. Got an error.\n```\n[415/15424] LIBTOOL-STATIC obj/third_party/ffmpeg/libffmpeg_internal.a\nFAILED: obj/third_party/ffmpeg/libffmpeg_internal.a \nrm -f obj/third_party/ffmpeg/libffmpeg_internal.a && TOOL_VERSION=1479358929 python ../../build/toolchain/mac/filter_libtool.py libtool -static  -o obj/third_party/ffmpeg/libffmpeg_internal.a \nerror: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: no files specified\nUsage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool -static [-] file [...] [-filelist listfile[,dirname]] [-arch_only arch] [-sacLT] [-no_warning_for_no_symbols]\nUsage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool -dynamic [-] file [...] [-filelist listfile[,dirname]] [-arch_only arch] [-o output] [-install_name name] [-compatibility_version #] [-current_version #] [-seg1addr 0x#] [-segs_read_only_addr 0x#] [-segs_read_write_addr 0x#] [-seg_addr_table ] [-seg_addr_table_filename ] [-all_load] [-noall_load]\n```\nEDIT: shouldn't the ffmpeg branding be Chromium instead of ChromeOS there?\nDEBUG: GN command: out/bootstrap_gn gen out/Release --args=proprietary_codecs=true use_official_google_api_keys=false use_ozone=false remove_webcore_debug_symbols=true enable_hangout_services_extension=false enable_mse_mpeg2ts_stream_parser=true enable_one_click_signin=false fieldtrial_testing_like_official_build=true is_clang=true treat_warnings_as_errors=false google_api_key=\"\" icu_use_data_file=false enable_rlz=false google_default_client_secret=\"\" enable_google_now=false enable_remoting=false use_sysroot=false fatal_linker_warnings=false ffmpeg_branding=\"ChromeOS\" safe_browsing_mode=0 clang_use_chrome_plugins=false enable_nacl_nonsfi=false enable_webrtc=false enable_hotwording=false is_debug=false google_default_client_id=\"\" enable_nacl=false enable_hevc_demuxing=true enable_widevine=true. Got an error.\n[13248/15668] OBJCXX obj/chrome/browse...i/one_click_signin_dialog_controller.o\nFAILED: obj/chrome/browser/ui/ui/one_click_signin_dialog_controller.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/chrome/browser/ui/ui/one_click_signin_dialog_controller.o.d -DV8_DEPRECATION_WARNINGS -DENABLE_NOTIFICATIONS -DENABLE_PEPPER_CDMS -DENABLE_PLUGINS=1 -DENABLE_PDF=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DNO_TCMALLOC -DUSE_EXTERNAL_POPUP_MENU=1 -DDISABLE_NACL -DENABLE_EXTENSIONS=1 -DENABLE_TASK_MANAGER=1 -DENABLE_THEMES=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DUSE_PROPRIETARY_CODECS -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=278861-1 -DCR_XCODE_VERSION=0731 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DUSE_CUPS -DTOOLKIT_VIEWS=1 -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DHAVE_PTHREAD -DENABLE_IPC_FUZZER -DSK_IGNORE_DW_GRAY_FIX -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_SUPPORT_GPU=1 -DSK_BUILD_FOR_MAC -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC -DV8_USE_EXTERNAL_STARTUP_DATA -DENABLE_WEBSOCKETS -DMESA_EGL_NO_X11_HEADERS -DLEVELDB_PLATFORM_CHROMIUM=1 -DFEATURE_ENABLE_SSL -DFEATURE_ENABLE_VOICEMAIL -DEXPAT_RELATIVE_PATH -DGTEST_RELATIVE_PATH -DNO_MAIN_THREAD_WRAPPING -DNO_SOUND_SYSTEM -DWEBRTC_CHROMIUM_BUILD -DWEBRTC_POSIX -DWEBRTC_MAC -DXML_STATIC -DSSL_USE_OPENSSL -DHAVE_OPENSSL_SSL_H -DFEATURE_ENABLE_SSL -DLOGGING=1 -DNO_MAIN_THREAD_WRAPPING -DI18N_ADDRESSINPUT_USE_BASICTYPES_OVERRIDE=1 -DI18N_ADDRESS_VALIDATION_DATA_URL=\\\"https://chromium-i18n.appspot.com/ssl-aggregate-address/\\\" -Igen/chrome/browser/ui -I../.. -Igen -I../../third_party/khronos -I../../gpu -I../../third_party/protobuf/src -Igen/protoc_out -I../../third_party/protobuf/src -I../../skia/config -I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/images -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pdf -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/gpu -I../../third_party/skia/src/gpu -Igen -I../../third_party/icu/source/common -I../../third_party/icu/source/i18n -Igen/ui/views/resources -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -Igen/chrome -I../../third_party/ced/src -Igen/components/strings -Igen/components/strings -Igen/components/strings -Igen/components/strings -I../../third_party/WebKit -Igen/third_party/WebKit -I../../v8/include -I../../v8/include -I../../third_party/boringssl/src/include -I../../third_party/mesa/src/include -Igen/ui/resources -Igen/ui/resources -I../../third_party/libwebm/source -I../../third_party/opus/src/include -I../../third_party/re2/src -Igen -Igen/extensions -Igen/extensions -Igen/extensions -Igen -Igen/extensions/strings -I../../third_party/google_toolbox_for_mac -I../../third_party/google_toolbox_for_mac/src -I../../third_party/google_toolbox_for_mac/src/AppKit -I../../third_party/google_toolbox_for_mac/src/DebugUtils -I../../third_party/google_toolbox_for_mac/src/Foundation -I../../third_party/cacheinvalidation/overrides -I../../third_party/cacheinvalidation/src -Igen/components -Igen/components -I../../third_party/zlib -I../../third_party/leveldatabase -I../../third_party/leveldatabase/src -I../../third_party/leveldatabase/src/include -I../../third_party/webrtc_overrides -I../../testing/gtest/include -I../../third_party -I../../third_party/webrtc_overrides -I../../third_party -I../../third_party/expat/files/lib -I../../third_party/jsoncpp/overrides/include -I../../third_party/jsoncpp/source/include -I../../third_party/libaddressinput/src/cpp/include -I../../third_party/libaddressinput/chromium/override -Igen/third_party/libaddressinput -Igen -fno-strict-aliasing -fstack-protector -fcolor-diagnostics -arch x86_64 -Wall -Wextra -Wpartial-availability -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -O2 -g0 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -mmacosx-version-min=10.7 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wno-nonnull -Wexit-time-destructors -Wno-unused-function -fno-threadsafe-statics -fvisibility-inlines-hidden -std=c++11 -stdlib=libc++ -fobjc-call-cxx-cdtors -Wobjc-missing-property-synthesis -fno-rtti -fno-exceptions -include obj/chrome/browser/ui/ui/precompile.h-mm -c ../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.mm -o obj/chrome/browser/ui/ui/one_click_signin_dialog_controller.o\nwarning: unknown warning option '-Wno-address-of-packed-member' [-Wunknown-warning-option]\nIn file included from ../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.mm:5:\n../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.h:30:28: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n      const BrowserWindow::StartSyncCallback& sync_callback,\n            ~~~~~~~~~~~~~~~^\nIn file included from ../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.mm:11:\n../../chrome/browser/ui/cocoa/one_click_signin_view_controller.h:46:18: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n  BrowserWindow::StartSyncCallback startSyncCallback_;\n  ~~~~~~~~~~~~~~~^\n../../chrome/browser/ui/cocoa/one_click_signin_view_controller.h:58:45: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n         syncCallback:(const BrowserWindow::StartSyncCallback&)syncCallback\n                             ~~~~~~~~~~~~~~~^\n../../chrome/browser/ui/cocoa/one_click_signin_dialog_controller.mm:15:26: error: no type named 'StartSyncCallback' in 'BrowserWindow'\n    const BrowserWindow::StartSyncCallback& sync_callback,\n          ~~~~~~~~~~~~~~~^\n1 warning and 4 errors generated.\nEDIT: this error seems similar to this one. Adding those lines to chrome_browser_ui.gypi didn't help.. Just got it building too. I'll try a build from scratch just to check if everything is ok. @piningforthefnords thanks for contributing to OS X support. Having someone else to test the code really helps.\n. @piningforthefnords Did it build the .dmg normally for you? Here, its hanging when trying to build the .dmg file. I didn't notice before because I tested the Chromium.app package directly.\n[22358/22358] STAMP obj/chrome/chrome.stamp\n2016-12-01 03:57:39,095 - INFO: Generating .dmg file...\nmktemp -d /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.XXXXXXXX\n/var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9\nmkdir /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9/stage\nrsync -aC --include \\*.so --copy-unsafe-links /var/empty/ /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9/stage\nrsync -aC --include \\*.so --copy-unsafe-links sandbox/out/Release/Chromium.app/ /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9/stage/Chromium.app/\nln -s /Applications /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9/stage/Drag\\ to\\ here\\ to\\ install\nchmod -R a+rX,a-st,u+w,go-w /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9/stage\nhdiutil makehybrid -hfs -hfs-volume-name Chromium -hfs-openfolder /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9/stage -ov /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9/stage -o /var/folders/jy/d01dhkjj3wq4k42p92kvd19m0000gn/T/tmpsd36qqyv/pkg-dmg.64502.PBj9mzS9/hybrid.dmg. @Eloston My problem was related to disk space. It builds the .dmg flawlessly now. Are we skipping 54? I thought you were going to wait for the new inox patches.. @Eloston \n```\nApplying patch ../patches/ungoogled-macos/fix-libcxx-archive-build-script.patch\ncan't find file to patch at input line 5\nPerhaps you used the wrong -p or --strip option?\nThe text leading up to this was:\n\n|# Modify libc++.a build script to make it build\n|\n|--- a/third_party/libc++-static/build.sh\n|+++ b/third_party/libc++-static/build.sh\n\nNo file to patch.  Skipping patch.\n2 out of 2 hunks ignored\nPatch ../patches/ungoogled-macos/fix-libcxx-archive-build-script.patch does not apply (enforce with -f)\n2016-12-05 12:37:22,231 - ERROR: Quilt returned non-zero exit code: 1\n```\nThe third_party/libc++-static folder doesn't exist in v55 source. Perhaps Chromium doesn't use it anymore?\nI've copied the folder from the source of v54 in the meantime so I can test it while you make the changes in buildlib.\nEDIT: got an error further in the building. Does v55 uses llvm3.9? Or could this be related to the libc++.a?\n[6329/23922] SOLINK WidevineCdm/_platf...cific/mac_x64/libwidevinecdm.dylib.TOC\nFAILED: WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC \nif [ ! -e \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" -o ! -e \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\" ] || otool -l \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | grep -q LC_REEXPORT_DYLIB ; then TOOL_VERSION=1480633325 ../../build/toolchain/mac/linker_driver.py ../../third_party/llvm-build/Release+Asserts/bin/clang++ -shared -Wl,-exported_symbol,_PPP_GetInterface -Wl,-exported_symbol,_PPP_InitializeModule -Wl,-exported_symbol,_PPP_ShutdownModule -stdlib=libc++ -arch x86_64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -mmacosx-version-min=10.7 -Wl,-ObjC -o \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" -Wl,-filelist,\"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.rsp\" -framework ApplicationServices -framework AppKit -lbsm -framework CoreFoundation -framework IOKit -framework Security  && { otool -l \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | grep LC_ID_DYLIB -A 5; nm -gP \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | cut -f1-2 -d' ' | grep -v U$$; true; } > \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\"; else TOOL_VERSION=1480633325 ../../build/toolchain/mac/linker_driver.py ../../third_party/llvm-build/Release+Asserts/bin/clang++ -shared -Wl,-exported_symbol,_PPP_GetInterface -Wl,-exported_symbol,_PPP_InitializeModule -Wl,-exported_symbol,_PPP_ShutdownModule -stdlib=libc++ -arch x86_64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -mmacosx-version-min=10.7 -Wl,-ObjC -o \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" -Wl,-filelist,\"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.rsp\" -framework ApplicationServices -framework AppKit -lbsm -framework CoreFoundation -framework IOKit -framework Security  && { otool -l \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | grep LC_ID_DYLIB -A 5; nm -gP \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | cut -f1-2 -d' ' | grep -v U$$; true; } > \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.tmp\" && if ! cmp -s \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.tmp\" \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\"; then mv \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.tmp\" \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\" ; fi; fi\nUndefined symbols for architecture x86_64:\n  \"_PPP_GetInterface\", referenced from:\n     -exported_symbol[s_list] command line option\n  \"_PPP_InitializeModule\", referenced from:\n     -exported_symbol[s_list] command line option\n  \"_PPP_ShutdownModule\", referenced from:\n     -exported_symbol[s_list] command line option\nld: symbol(s) not found for architecture x86_64\nclang-3.9: error: linker command failed with exit code 1 (use -v to see invocation)\nTraceback (most recent call last):\n  File \"../../build/toolchain/mac/linker_driver.py\", line 222, in <module>\n    Main(sys.argv)\n  File \"../../build/toolchain/mac/linker_driver.py\", line 72, in Main\n    subprocess.check_call(compiler_driver_args)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py\", line 541, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['../../third_party/llvm-build/Release+Asserts/bin/clang++', '-shared', '-Wl,-exported_symbol,_PPP_GetInterface', '-Wl,-exported_symbol,_PPP_InitializeModule', '-Wl,-exported_symbol,_PPP_ShutdownModule', '-stdlib=libc++', '-arch', 'x86_64', '-isysroot', '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk', '-mmacosx-version-min=10.7', '-Wl,-ObjC', '-o', 'WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib', '-Wl,-filelist,WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.rsp', '-framework', 'ApplicationServices', '-framework', 'AppKit', '-lbsm', '-framework', 'CoreFoundation', '-framework', 'IOKit', '-framework', 'Security']' returned non-zero exit status 1. @Eloston should we try to build it on OS X without the Widevine flags?. Adding this flag is making it go further in the build process. Lets see what happens.. @piningforthefnords Are you talking about a message of Chromium asking to use stored credentials, or something like that?\nI've been getting that since v51 I think, no problems yet.\nI got the same impression. It feels less responsive than older versions (haven't tried browsing on it yet).\n@Eloston it also built fine here. This version doesn't work with Widevine as expected, but there is a manifest.jsonfor it inside the package. Interesting... it wasn't there before (you had to create it manually or copy from Chrome to get Widevine support), even when compiled with Widevine support.. @piningforthefnords Wow, thats bizarre. I'm not running it on a VM, but I don't use a pw manager nor store credentials.\nI wonder if this is happening with vanilla Chromium too.. @Eloston It wasn't there in 54. I think we were still using that flag when compiling it.\nOn 55, it fails to build if enable_widevine is set as true, and I get the manifest.json file with it set as false.. Yes, it uses widevinecdmadapter.plugin and libwidevinecdm.dylib. I need both (plus the manifest file) to get Widevine to work.. @Eloston I think it downloads and/or builds both files during the build process. Before, the problem was that they weren't being added to the package (see this). Alternatively, the user could just copy them from Google Chrome (even from a different version).\nEven with the files, it doesn't work if you build Chromium with enable_widevine=false. Haven't tested this using the latest widevine files from Chrome 55, though. I'll look into it later.. @Eloston Ok, I'll start a fresh build. I'm going to upload binaries for OS X, *buntus and the static build, so please tell me if you're already building any of those. . @Eloston The master branch is not building on OS X:\n```\n1 warning generated.\n[1550/24360] CXX obj/extensions/browser/api/serial/serial/serial_api.o\nFAILED: obj/extensions/browser/api/serial/serial/serial_api.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/extensions/browser/api/serial/serial/serial_api.o.d -DV8_DEPRECATION_WARNINGS -DENABLE_NOTIFICATIONS -DENABLE_PEPPER_CDMS -DENABLE_PLUGINS=1 -DENABLE_PDF=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_BROWSER_SPELLCHECKER=1 -DNO_TCMALLOC -DUSE_EXTERNAL_POPUP_MENU=1 -DDISABLE_NACL -DENABLE_EXTENSIONS=1 -DENABLE_TASK_MANAGER=1 -DENABLE_THEMES=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_PLUGIN_INSTALLATION=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DUSE_PROPRIETARY_CODECS -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=282487-1 -DCR_XCODE_VERSION=0731 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../.. -Igen -Igen -fno-strict-aliasing -fstack-protector -fcolor-diagnostics -arch x86_64 -Wall -Wextra -Wpartial-availability -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -O2 -g0 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -mmacosx-version-min=10.7 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -fno-threadsafe-statics -fvisibility-inlines-hidden -std=c++11 -stdlib=libc++ -fno-rtti -fno-exceptions -c ../../extensions/browser/api/serial/serial_api.cc -o obj/extensions/browser/api/serial/serial/serial_api.o\nwarning: unknown warning option '-Wno-address-of-packed-member' [-Wunknown-warning-option]\nIn file included from ../../extensions/browser/api/serial/serial_api.cc:5:\n../../extensions/browser/api/serial/serial_api.h:10:10: fatal error: 'device/serial/serial.mojom.h' file not found\ninclude \"device/serial/serial.mojom.h\"\n``. @Eloston seems like runningbrew updateandbrew upgrade fixed it.. @Eloston I hadn't paid attention to the software brew upgraded, but not a single one seems related to this exceptchromedriver. Thinks like node, ffmpeg, harfbuzz.. @Eloston\nungoogled-chromium 55.0.2883.75-1\n**SHA-1:**1d334feed258866d946dc463b59bcf5c09e0b75e**MD5:**6c2bd5a644bf9964c244d1d12f1276d7`\nDownload link: https://my.mixtape.moe/dzerxu.dmg. @Eloston OSX 10.11's SDK.. @jgoldgh In a few hours.. @Eloston Ubuntu 16.10 packages:\n\nchromedriver_55.0.2883.75-1_amd64.deb\nSHA1: 8617a53f5cdd6f65fd0df9e2dc5c80c9c3034d95\nMD5: 1eab099927af427e1ecd47d3d5951261\nSHA256: 604c2cf6def8c9fb438655a24648e9d4685d7ce5bd5926b89d1b512f30ce3c31\nchrome-sandbox_55.0.2883.75-1_amd64.deb\nSHA1: e75dee7267dd36d79643a07f75467dad4339fbbb\nMD5: 5fc2c046daffd5d65eca4ddbea47d5d8\nSHA256: 46c4e02a22507828795839bff98dcea8b6fb8f2776112c809336416370de83c9\nchromium_55.0.2883.75-1_amd64.deb\nSHA1: 5f8ea4d6d2825ab9d52c8bd8458e143936143fc9\nMD5: 3a0038e6bea212be899facd92326fc14\nSHA256: fdd2dd3ac41ba8d2b6ffbfd3e4ba1c81a3a4e9024d873e2d0d55e811aa47623a\nchromium-browser_55.0.2883.75-1_amd64.changes\nSHA1: 76439b16aa53616e197af75c504e7a54f60bc6b1\nMD5: 432f94a200d01d456b751050656bfde2\nSHA256: 61f23038a222bf0015fc022b2e3f03f421f5eaf36d8d3d74dc916a0950dfd525\nchromium-l10n_55.0.2883.75-1_all.deb\nSHA1: 751df4cdfe6b6003951aea5df3d439212d5acf2c\nMD5: 3f32ca4c9c4d40c71fb8c07008fa4511\nSHA256: 352f82cd374baeb51862c97ef0e9caf832f823c18365fdff4783e8fad7053230\nUbuntu 16.04 should come in a few hours.. @Eloston is Chromium using llvm-3.9 in every platform?. @Eloston I'm actually getting an error on 16.04 pretty similar to the one I was getting on 14.04.\n\n[65/12933] CXX obj/media/ffmpeg/ffmpeg/ffmpeg_common.o\nFAILED: ../../../../../../../../usr/lib/llvm-3.9/bin/clang++ -MMD -MF obj/media/ffmpeg/ffmpeg/ffmpeg_common.o.d -DV8_DEPRECATION_WARNINGS -DENABLE_MDNS=1 -DENABLE_NOTIFICATIONS -DENABLE_PEPPER_CDMS -DENABLE_PLUGINS=1 -DENABLE_PDF=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_CLIPBOARD_AURAX11=1 -DUSE_DEFAULT_RENDER_THEME=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DDISABLE_NACL -DENABLE_EXTENSIONS=1 -DENABLE_TASK_MANAGER=1 -DENABLE_THEMES=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DUSE_PROPRIETARY_CODECS -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=282487-1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DUSE_PULSEAUDIO -DMEDIA_IMPLEMENTATION -DGL_GLEXT_PROTOTYPES -DUSE_GLX -DUSE_EGL -I../.. -Igen -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -Igen/shim_headers/libevent_shim -I../../third_party/khronos -I../../gpu -Igen/shim_headers/re2_shim -Igen/shim_headers/icuuc_shim -Igen/shim_headers/zlib_shim -Igen/shim_headers/icui18n_shim -Igen/shim_headers/harfbuzz_shim -Igen/shim_headers/libpng_shim -Igen/shim_headers/ffmpeg_shim -I/usr/include/x86_64-linux-gnu -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -fcolor-diagnostics -fdebug-prefix-map=/home/ug/release_build/ungoogled-chromium/build/sandbox=. -pthread -m64 -march=x86-64 -Wall -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -O2 -fno-ident -fdata-sections -ffunction-sections -g0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../media/ffmpeg/ffmpeg_common.cc -o obj/media/ffmpeg/ffmpeg/ffmpeg_common.o\nwarning: unknown warning option '-Wno-address-of-packed-member' [-Wunknown-warning-option]\n../../media/ffmpeg/ffmpeg_common.cc:801:1: error: use of undeclared identifier 'AVCOL_PRI_SMPTEST428_1'; did you mean 'AVCOL_PRI_SMPTE240M'?\nTEST_PRIMARY(SMPTEST428_1);\n^\n../../media/ffmpeg/ffmpeg_common.cc:778:58: note: expanded from macro 'TEST_PRIMARY'\n      static_cast<int>(gfx::ColorSpace::PrimaryID::P) == AVCOL_PRI_##P, \\\n                                                         ^\n<scratch space>:114:1: note: expanded from here\nAVCOL_PRI_SMPTEST428_1\n^\n/usr/include/x86_64-linux-gnu/libavutil/pixfmt.h:485:5: note: 'AVCOL_PRI_SMPTE240M' declared here\n    AVCOL_PRI_SMPTE240M   = 7, ///< functionally identical to above\n    ^\n../../media/ffmpeg/ffmpeg_common.cc:801:1: error: static_assert failed \"gfx::ColorSpace::PrimaryID::SMPTEST428_1 does not match AVCOL_PRI_SMPTEST428_1\"\nTEST_PRIMARY(SMPTEST428_1);\n^~~~~~~~~~~~~~~~~~~~~~~~~~\n../../media/ffmpeg/ffmpeg_common.cc:777:3: note: expanded from macro 'TEST_PRIMARY'\n  static_assert(                                                        \\\n  ^\n../../media/ffmpeg/ffmpeg_common.cc:819:1: error: use of undeclared identifier 'AVCOL_TRC_SMPTEST2084'\nTEST_TRANSFER(SMPTEST2084);\n^\n../../media/ffmpeg/ffmpeg_common.cc:783:59: note: expanded from macro 'TEST_TRANSFER'\n      static_cast<int>(gfx::ColorSpace::TransferID::T) == AVCOL_TRC_##T, \\\n                                                          ^\n<scratch space>:114:1: note: expanded from here\nAVCOL_TRC_SMPTEST2084\n^\n../../media/ffmpeg/ffmpeg_common.cc:820:1: error: use of undeclared identifier 'AVCOL_TRC_SMPTEST428_1'; did you mean 'AVCOL_TRC_SMPTE240M'?\nTEST_TRANSFER(SMPTEST428_1);\n^\n../../media/ffmpeg/ffmpeg_common.cc:783:59: note: expanded from macro 'TEST_TRANSFER'\n      static_cast<int>(gfx::ColorSpace::TransferID::T) == AVCOL_TRC_##T, \\\n                                                          ^\n<scratch space>:114:1: note: expanded from here\nAVCOL_TRC_SMPTEST428_1\n^\n/usr/include/x86_64-linux-gnu/libavutil/pixfmt.h:502:5: note: 'AVCOL_TRC_SMPTE240M' declared here\n    AVCOL_TRC_SMPTE240M    = 7,\n    ^\n../../media/ffmpeg/ffmpeg_common.cc:820:1: error: static_assert failed \"gfx::ColorSpace::TransferID::SMPTEST428_1 does not match AVCOL_TRC_SMPTEST428_1\"\nTEST_TRANSFER(SMPTEST428_1);\n^~~~~~~~~~~~~~~~~~~~~~~~~~~\n../../media/ffmpeg/ffmpeg_common.cc:782:3: note: expanded from macro 'TEST_TRANSFER'\n  static_assert(                                                         \\\n  ^\n1 warning and 5 errors generated.\nI was trying to use the Xenial Builder on 14.04 and got into a very similar issue before giving up and starting working with the Static Builder.\nEdit: It seems I had the wrong version of libavcodec-extra installed.\nOut of curiosity, I'll test this with 14.04 later.. @Eloston It built when installing the correct libavcodec-extra. I'm trying to get widevine to work on OSX now, but I'll upload the 16.04 binaries today.. @Eloston The new subversion is not building on 16.04.\n[10449/23938] CXX obj/services/ui/surf...s/surfaces/surfaces_context_provider.o\nFAILED: ../../../../../../../../usr/bin/clang++ -MMD -MF obj/services/ui/surfaces/surfaces/surfaces_context_provider.o.d -DV8_DEPRECATION_WARNINGS -DENABLE_MDNS=1 -DENABLE_NOTIFICATIONS -DENABLE_PEPPER_CDMS -DENABLE_PLUGINS=1 -DENABLE_PDF=1 -DENABLE_PRINTING=1 -DENABLE_BASIC_PRINTING=1 -DENABLE_PRINT_PREVIEW=1 -DENABLE_SPELLCHECK=1 -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_CLIPBOARD_AURAX11=1 -DUSE_DEFAULT_RENDER_THEME=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DDISABLE_NACL -DENABLE_EXTENSIONS=1 -DENABLE_TASK_MANAGER=1 -DENABLE_THEMES=1 -DENABLE_CAPTIVE_PORTAL_DETECTION=1 -DENABLE_SESSION_SERVICE=1 -DENABLE_SUPERVISED_USERS=1 -DENABLE_SERVICE_DISCOVERY=1 -DUSE_PROPRIETARY_CODECS -DOFFICIAL_BUILD -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=282487-1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DGL_GLEXT_PROTOTYPES -DUSE_GLX -DUSE_EGL -DSK_IGNORE_DW_GRAY_FIX -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_SUPPORT_GPU=1 -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_NOEXCEPT= -DU_STATIC_IMPLEMENTATION -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC -I../.. -Igen -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I../../third_party/khronos -I../../gpu -I../../skia/config -I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/images -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pdf -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/gpu -I../../third_party/skia/src/gpu -I../../third_party/skia/src/sksl -I../../third_party/icu/source/common -I../../third_party/icu/source/i18n -I../../third_party/mesa/src/include -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/ug/release_build_forreal/ungoogled-chromium/build/sandbox=. -pthread -m64 -march=x86-64 -Wall -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -O2 -fno-ident -fdata-sections -ffunction-sections -g0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../services/ui/surfaces/surfaces_context_provider.cc -o obj/services/ui/surfaces/surfaces/surfaces_context_provider.o\n../../services/ui/surfaces/surfaces_context_provider.cc:80:37: error: default initialization of an object of const type 'const gpu::SharedMemoryLimits' without a user-provided default constructor\n  constexpr gpu::SharedMemoryLimits default_limits;\n                                    ^\n                                                  {}\n3 warnings and 1 error generated.\nEdit: whoops, it seems that I didn't pay attention and tried to build using the StaticBuilder instead. I'm testing it again from scratch.. Ubuntu 16.04 packages are building correctly in the master branch.\n@Eloston\nUbuntu 16.04\n\nchromedriver_55.0.2883.87-1_amd64.deb\nSHA1: 2688efd7e4a2ff200fe97a74fa87df31dbad9982\nMD5: b43db2b7d7418273aae87a149dae9a9c\nSHA256: 1077f9aaa921e4c58a603300cfa82902c0b4b93dc92cc0c738a7caaf2da36eb9\nchrome-sandbox_55.0.2883.87-1_amd64.deb\nSHA1: 33c2bbb38da10e9b941ecb97183213ddabc32ba5\nMD5: 406a217a866f92950bf6a20fee03db70\nSHA256: fdc6012e192a44df0de889b846f027f4f992930bf0bc9e703da45a855d433dad\nchromium_55.0.2883.87-1_amd64.deb\nSHA1: 408c409e1c5110bf021c69f5efb453c5e0de9ee8\nMD5: c087f121d7f5948517659d0d29c483b9\nSHA256: 2bc4359f31893a0e0fe2af4b65338d04e94f0fd472e9e3f537ac422df298e6ab\nchromium-browser_55.0.2883.87-1_amd64.changes\nSHA1: 3d620d17ac9f41fa7a7bac2f773194346bf2d17b\nMD5: de3deb4101fafb8276d1310df0fbd413\nSHA256: d8b5bfbed99c7dd7c940616d135222a2078ab50fa79abd032ee9ec006432d07d\nchromium-l10n_55.0.2883.87-1_all.deb\nSHA1: ebcaad2b6fbdb5101423e5b79a5e9a63c3dbc5f0\nMD5: 583f0aff7a1e6ef3436731f368399a7e\nSHA256: a882b27ba70da830a3aa840eac53af8441824b762d504460e70a2719269cae74\n\nLatest Ubuntu 16.10 binaries are here. @Eloston AFAIR I only installed llvm-3.9 and the dependencies buildlib require when you run it. I got an error when it got to the ffmpeg part because I had installed an old version of libavcodec-extra. I think it worked fine after that.\nUnfortunately, the errors Chromium give to you when compiling are not clear at all - they're mostly because certain packages are not installed or are too old, but they don't point out exactly which ones. I end up installing tons of packages until it works. It wasn't much trouble in 16.04, but it was a pain on 14.04 - which is why I created this issue.\nTL;DR I think that with 16.04, I just chose a different version of libavcodec-extra and it worked. But I might be wrong - if so, we should further investigate and update the dependencies buildlib asks for.. @Eloston I was checking the VMs and noticed I had to install a PPA to get a newer FFmpeg on Ubuntu 16.04. You also need to install it so the pre-built binaries can work. Sorry for not pointing that earlier.\nIts more or less the same with 14.04, except that Trusty doesn't have any PPA with FFmpeg built dynamically and the user has to build it himself.. @Eloston The bundled ffmpeg library didn't work. Seems like Xenial's ffmpeg is too old.. @Eloston Oh, I see.\nIf you want to start working on it earlier, we can try building the Chromium beta tags.. @message Are you using it in a VM?\nI just tested the pre-built packages and they are working, could you please test them and see if you get the same error?. I got a similar error when trying it on a VM, but the same packages worked fine on an actual install.\nI'm supposing you tested both on the same machine. Not sure what is causing this.\nPerhaps some packaged got updated in 16.04 or the PPA and it broke your build.. @message Here is solution to the issue.. @Eitot The master branch works with Widevine. The user still has to copy the plugin files from Google Chrome.\nThe Widevine files are actually being built and placed in the correct folder now, but they're not working (and also not showing their version correctly for some reason).. @Eitot Sorry, seems like I wrote your response days ago and forgot to actually post it.\nI haven't tested, nor I've read about regular Chromium building with Widevine on OS X. Its hard to test without using the same flags.. The version output was \"Yakkety Yak\". The version output on 16.04 was \"Xenial Xerus\". Using the capitalized full names fixes the issue.. @pjv Yes, but getting the 16.04 packages is priority now. \nYou will need to replace the Libraries folder inside Chromium.app/Contents/Version/55.xxxx with the same folder from Google Chrome's package.. @stefson I actually wrote a draft, but it was for buildlib. It will not work for newer versions of ungoogled-chromium, so its useless now.\nI suppose the current build system might work if you use the conservative settings and install clang-3.9 from a backport PPA.. @stefson Sorry, I just checked the notes and I actually didn't write them in English. :/\nEither way, here are the packages you would need to build from source: icu, re2, harfbuzz, libsnappy, libsigsegv2, m4, libnettle and the whole ffmpeg.\nYou need to build ffmpeg with the --enable-shared flag. Here are the commands I was using (they're mostly the official instructions to build ffmpeg plus the --enabled-shared flag):\n```\nsudo apt-get update\nsudo apt-get -y install autoconf automake build-essential libass-dev libfreetype6-dev libsdl1.2-dev libtheora-dev libtool libva-dev libvdpau-dev libvorbis-dev libxcb1-dev libxcb-shm0-dev libxcb-xfixes0-dev pkg-config texinfo zlib1g-dev\nmkdir ffmpeg_sources\ncd ffmpeg_sources\nwget http://www.tortall.net/projects/yasm/releases/yasm-1.3.0.tar.gz\ntar xzvf yasm-1.3.0.tar.gz\ncd yasm-1.3.0\n./configure --enable-shared\nmake && sudo make install && make distclean\ncd ..\nwget http://download.videolan.org/pub/x264/snapshots/last_x264.tar.bz2\ntar xjvf last_x264.tar.bz2\ncd x264-snapshot*\n./configure --enable-shared --disable-opencl\nmake && sudo make install && make distclean\ncd ..\nsudo apt-get install cmake mercurial\nhg clone https://bitbucket.org/multicoreware/x265\ncd ~/ffmpeg_sources/x265/build/linux\ncmake -G \"Unix Makefiles\" -DENABLE_SHARED:bool=on ../../source\nmake && sudo make install && make distclean\ncd ..\nwget -O fdk-aac.tar.gz https://github.com/mstorsjo/fdk-aac/tarball/master\ntar xzvf fdk-aac.tar.gz\ncd mstorsjo-fdk-aac*\nautoreconf -fiv\n./configure --enable-shared\nmake && sudo make install && make distclean\ncd ..\nsudo apt-get install nasm\nwget http://downloads.sourceforge.net/project/lame/lame/3.99/lame-3.99.5.tar.gz\ntar xzvf lame-3.99.5.tar.gz\ncd lame-3.99.5\n./configure --enable-nasm --enable-shared\nmake && sudo make install && make distclean\ncd ..\nwget http://downloads.xiph.org/releases/opus/opus-1.1.3.tar.gz\ntar xzvf opus-1.1.3.tar.gz\ncd opus-1.1.3\n./configure --enable-shared\nmake && sudo make install && make distclean\ncd ..\nwget http://storage.googleapis.com/downloads.webmproject.org/releases/webm/libvpx-1.6.0.tar.bz2\ntar xjvf libvpx-1.6.0.tar.bz2\ncd libvpx-1.6.0\n./configure --disable-examples --disable-unit-tests --enable-shared\nmake && sudo make install && make distclean\ncd ..\nwget http://ffmpeg.org/releases/ffmpeg-snapshot.tar.bz2\ntar xjvf ffmpeg-snapshot.tar.bz2\ncd ffmpeg\n./configure \\\n  --enable-gpl \\\n  --enable-libass \\\n  --enable-libfdk-aac \\\n  --enable-libfreetype \\\n  --enable-libmp3lame \\\n  --enable-libopus \\\n  --enable-libtheora \\\n  --enable-libvorbis \\\n  --enable-libvpx \\\n  --enable-libx264 \\\n  --enable-libx265 \\\n  --enable-nonfree\n  --enable-shared\nmake && sudo make install && make distclean\nhash -r\ncd ..\n```\nAt that time, Chromium only build using libvpx1.5.0, so I had to compile and install it separately from the rest. Not sure if this is still the case.\nIf you try to use utilikit to build it, you might find that the following packages are missing from 14.04:\nlibre2-dev libvpx-dev libavcodec-dev (>= 7) libavformat-dev libspeechd-dev (>= 0.8.3) libminizip-dev libcups2-dev (>= 1.5.0) libgcrypt20-dev\nYou might run into strange errors when building it. The solution, in most cases, is to look for the fault file, discover the associated package with it and manually install a newer version.\nThis should get you started in building it.. Perhaps wrapping the static build in a .deb package could solve this.. @nopjmp Is it possible to add extension support to Android builds of Chromium?. @DeadSix27 @nopjmp I see, thanks for the heads up.. @Eloston The problem 1 in the first post also applies to OS X. Not sure what change caused it.. The patch is applying fine here. Did you install quilt beforehand?\nAfter applying it, you're going to run into the first problem of this post. Using the same solution provided by him (but using OSX's cleaning_list instead) should fix it.. @nopjmp Oh. Thats strange. I just tested it from scratch and its working normally here.\nAbout the icu data file, maybe buildlib can download and compile it. I had to manually compile it on Ubuntu 14.04.. An extension that checks for new Chromium versions would be cool. Not sure whats the best way for extensions, though.. @Driesje32 I plan to release OS X pre-built binaries in the next days. Sorry for the delay.. I would appreciate some help as I'm not going to have free time until after the next week.\n@dieideeistgut If you want to make a personal build, you can use the scripts to build the source, apply the patches and domain substitution and build everything manually.. I could test if it builds targetting OS X 10.8, but for the reasons @nopjmp pointed out I doubt it will work just by changing a flag. I searched a bit and it seems some people hacked Chrome v52 to work on ML, while v54 doesn\u00b4t even launch.\nI suggest upgrading to a newer OS X version if you can, as 10.8's support ended in 2015 and it won't receive security updates anymore.. @1-61803 I decided not to do it.. I should still have them, I'll reupload as soon as I find the correct VM I used to build it.. @pr0ggy https://ungoogled-software.github.io/ungoogled-chromium-binaries/releases/ubuntu/xenial_amd64/55.0.2883.95-1. What is your ffmpeg version?. Do this:\n```\nsudo add-apt-repository -y ppa:jonathonf/ffmpeg-3\nsudo apt-get update\nsudo apt-get install -y debhelper ninja-build python-jinja2 flex yasm xvfb wdiff gperf bison valgrind libglew-dev libgl1-mesa-dev libglu1-mesa-dev libegl1-mesa-dev libgles2-mesa-dev mesa-common-dev libxt-dev libre2-dev libgbm-dev libpng-dev libxss-dev libelf-dev libvpx-dev libpci-dev libcap-dev libdrm-dev libicu-dev libffi-dev libkrb5-dev libexif-dev libflac-dev libudev-dev libopus-dev libwebp-dev libxtst-dev libsrtp-dev libjpeg-dev libxml2-dev libgtk2.0-dev libxslt1-dev libpulse-dev libpam0g-dev libsnappy-dev libgconf2-dev libavutil-dev libavcodec-dev libavformat-dev libglib2.0-dev libasound2-dev libsqlite3-dev libjsoncpp-dev libspeechd-dev libminizip-dev libhunspell-dev libharfbuzz-dev libusb-1.0-0-dev ffmpeg libmodpbase64-dev libgnome-keyring-dev libnss3-dev libnspr4-dev libcups2-dev libevent-dev libjs-excanvas libjs-jquery-flot libgcrypt20-dev quilt build-essential\n```\nthen try to install again.. Are you running the packages in a VM?. Then I'll have to investigate further. You're not the first one reporting this problem, and I don't know what is causing it.\nThe packages you downloaded are not the same packages I uploaded before (those are from a slighty newer version). I don't have the older versions anymore, so if this one is broken for you, unfortunately  you'll have to wait for v56 or build yourself (and see if it works).\n. @pr0ggy Are you using a NVIDIA graphics card?. Ok, I've found the problem. The shipped version of harfbuzz in Ubuntu 16.04 is too old and produces broken Chromium packages. Building it with a >1.2 harfbuzz package solves the problem. I probably built the working packages in a VM which had a PPA with a newer harfbuzz package.\nI have new, working binaries, but I can't upload them now. If you don't mind waiting, you can build them yourself (this PPA has a harfbuzz package that is new enough).. link. @nzytkkunit Could you please try the following?\n1. Add this PPA:\nsudo add-apt-repository -y ppa:jonathonf/ffmpeg-3\nsudo apt-get update\n2. Try to install the dependencies and the packages again.\n@tristan-k Theres still no binary release of v57 for Ubuntu 16.04, but the master branch should be working if you want to build it from source.. @nzytkkunit Could you please link where you got your packages from?. @nzytkkunit Could you please tell me the version of harfbuzz installed in your computer? If it's below 1.2, consider getting a newer version from this PPA. I just tested it in a Virtual Machine and it should fix it for you.. I can confirm that the develop branch works out of the box in 17.04.. I recommend that you only install extensions that you trust. For better or worse, trust is a fundamental part of IT security, as it isn't feasible to check every line of code for every software you install.\nIts not what you're looking for, but uMatrix is a good browser firewall (not meant for extensions).. > Configuring the build + CFLAGS\nYou can \"configure\" the build by choosing a flavor and then, if you want to change it further, manually changing its flags. To do what you asked, you could build the compressed tar archive (see the bottom of BUILDING.md) and edit the generated build.sh file. There you'll see at which line you should put the extra flags you want (it's commented).\n\nFor good and clean separation I like to put custom build software which is not part of the official repos in /opt/. In this case that would be /opt/ungoogled-chromium. How can I do that?\n\nThe static/portable/tar_archive build will generate a compressed folder, which you can extract to /opt/ungoogled-chromium or anywhere you want. You'd run it by simply opening the chromium binary inside it.\n\nCurrently on Leap 15.0 I have openSUSE's chromium package installed. Do I need to uninstall it before building ungoogled-chromium?\n\nFor the static/simple build, no you shouldn't need to uninstall it. If you want RPMs though, I believe you'd need to. Maybe someone more experienced with openSUSE will give a better answer (neither me or eloston use it).\n\nIs there any danger that it may break after a zypper update? If yes - could you recommend steps to minimize the chance for this, so that one doesn't need to rebuild it (except for new versions).\n\nBuild the archive version and you shouldn't have any problems after updates.\n\nWill ungoogled-chromium detect my existing ~/.config/chromium or should I remove it and start from scratch?\n\nIt should work with it normally. No need to remove it.\n\nIn non-ungoogled chromium there is this nightmare of first run which has all kinds of features enabled and loads some home page which the user may have never wanted to send one's IP address to\n\nThis simply won't ever happen in ungoogled-chromium. It won't connect to any domains on startup, unless you added an extension that explicitly does so (for example, uBlock Origin checking for list updates). All Google domains are replaced in the source code before building, so there's no chance of that happening, really.\nThe defaults are similar to the ones you posted, minus JS (it's enabled by default), search engine (DuckDuckGo by default) and cookies (1st-party enabled, 3rd-party blocked). I am not sure how you could change the defaults for a fresh build, but really wouldn't bother do. UGC defaults are more than sane enough privacy-wise.. ",
    "KyleSanderson": "@Eloston you should put this in the readme.\n. ",
    "avently": "Chromium for Linux does not work with apks via Arc Welder and Archon. So maybe a problem is deeper than just NaCl. Do you looked at it after closing an issue? Would be useful to have apks support. any news @Eloston ?. @Eloston\nSeems like @nopjmp is not working on this. Can you add Android support to your to-do list? Really waiting Ungoogled for Android. . I tried to build Chromium for Android with enable_extensions=true with Clang. I got tens of errors during build time. I fixed it and when the process had come to end, bad thing happened. \nOne of the last stage is linking: SOLINK ./libchrome.so.\nAnd i got hundreds of errors like:\n../../chrome/browser/prefs/browser_prefs.cc:0: error: undefined reference to 'ComponentToolbarActionsFactory::kMediaRouterActionId'\nAll errors were \"undefined reference to \".\ni don't know C++ or C so i don't know how to fix it. Maybe someone can repeat what Yandex team did. We are waiting you:). @Eloston I think chrome://extensions page should be available. It will be enough to test extensions. . I tried to compile with extensions support. I fixed tens of errors until \"linking\" stage. It was pretty easy. Just commented and uncommented some lines of code from log Then I got ~thousand errors on the linking stage. Every time I had fixed error and tried to rebuild the rebuilding process had taking 1 hour on my old harware (just linking libchrome.so). \nSo maybe would be a good idea to build separate libs (not just one). Maybe it will be faster, I didn't check it. \nI don't really understand how chromium code works that's why I couldn't build it with extensions. I think you can do it.. @nopjmp  any news?. @Eloston how to do that?. @Eloston builds fine on Arch except problem mentioned here: https://github.com/Eloston/ungoogled-chromium/issues/266#issuecomment-337654506\nBuilt with icudat from source (just exlcuded it from cleaning_list). @Alex2242 did you successfully build ungoogled on arch?\nI had build error related to ICU (no rules to build a target). Fixed it. But build stopped on error related to Breakpad. . @Alex2242 I have no time and hardware resources to try to fix every error I get while building software. I think the developer can make as easy build configuration as possible. One hour of developer time can save thousands hours of time for regular users that need to fix build errors. \nI don't know why build fails on my arch. Maybe gn attributes is wrong. Removing gn attributes one by one can help.. @Eloston this happens on master. Using zsh and bash. With clang and gcc.\nexport UTILIKIT_CONFIG_TYPE=archlinux\nmkdir build/                                                                                                                                                                                     \nmkdir build/sandbox\nmkdir build/downloads\n./utilikit/prepare_sources.py\n./utilikit/substitute_domains.py\n./utilikit/generate_build_files.py linux_simple --apply-domain-substitution                                                                                                                      \ncd build/sandbox\nungoogled_linux_simple/build.sh\nninja: Entering directory `out/Default'\nninja: error: '../../third_party/icu/common/icudtl.dat', needed by 'obj/third_party/icu/make_data_assembly.inputdeps.stamp', missing and no known rule to make it\ntouch third_party/icu/common/icudtl.dat\nninja -C out/Default chrome\nninja: Entering directory `out/Default'\n[47/26165] CXX obj/breakpad/client/exception_handler.o\nFAILED: obj/breakpad/client/exception_handler.o \n../../../../../../../../usr/bin/clang++ -MMD -MF obj/breakpad/client/exception_handler.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DDISABLE_NACL -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=\\\"296320-1\\\" -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../../breakpad -I../../breakpad/src -I../../breakpad/src/client -I../../breakpad/src/third_party/linux/include -I../.. -Igen -I../../breakpad/src -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -Wno-builtin-macro-redefined -D__DATE__= -D__TIME__= -D__TIMESTAMP__= -funwind-tables -fPIC -pipe -fcolor-diagnostics -m64 -march=x86-64 -pthread -O2 -fno-ident -fdata-sections -ffunction-sections -g0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wall -Wno-unused-variable -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-block-capture-autoreleasing -Wno-unused-lambda-capture -Wno-user-defined-warnings -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -Wno-deprecated -c ../../breakpad/src/client/linux/handler/exception_handler.cc -o obj/breakpad/client/exception_handler.o\nIn file included from ../../breakpad/src/client/linux/handler/exception_handler.cc:66:\n../../breakpad/src/client/linux/handler/exception_handler.h:194:21: error: field has incomplete type 'struct ucontext'\n    struct ucontext context;\n                    ^\n../../breakpad/src/client/linux/handler/exception_handler.h:194:12: note: forward declaration of 'google_breakpad::ucontext'\n    struct ucontext context;\n           ^\n../../breakpad/src/client/linux/handler/exception_handler.cc:442:41: error: invalid application of 'sizeof' to an incomplete type 'struct ucontext'\n  memcpy(&g_crash_context_.context, uc, sizeof(struct ucontext));\n                                        ^     ~~~~~~~~~~~~~~~~~\n../../breakpad/src/client/linux/handler/exception_handler.h:194:12: note: forward declaration of 'google_breakpad::ucontext'\n    struct ucontext context;\n           ^\n../../breakpad/src/client/linux/handler/exception_handler.cc:456:13: error: member access into incomplete type 'struct ucontext'\n  if (uc_ptr->uc_mcontext.fpregs) {\n            ^\n../../breakpad/src/client/linux/handler/exception_handler.h:194:12: note: forward declaration of 'google_breakpad::ucontext'\n    struct ucontext context;\n           ^\n../../breakpad/src/client/linux/handler/exception_handler.cc:457:49: error: member access into incomplete type 'struct ucontext'\n    memcpy(&g_crash_context_.float_state, uc_ptr->uc_mcontext.fpregs,\n                                                ^\n../../breakpad/src/client/linux/handler/exception_handler.h:194:12: note: forward declaration of 'google_breakpad::ucontext'\n    struct ucontext context;\n           ^\n../../breakpad/src/client/linux/handler/exception_handler.cc:479:19: error: variable has incomplete type 'struct ucontext'\n  struct ucontext context;\n                  ^\n../../breakpad/src/client/linux/handler/exception_handler.h:194:12: note: forward declaration of 'google_breakpad::ucontext'\n    struct ucontext context;\n           ^\n5 errors generated.\n[52/26165] CXX obj/base/base/file_util_posix.o\nninja: build stopped: subcommand failed.. @xsmile yes, now it builds fine. Thank you!\n@Eloston please, include this patch into your repo. In arch repo chromium version is 62 and this patch will be compatable with your next milestone.. @Eloston also, what about\nninja: error: '../../third_party/icu/common/icudtl.dat', needed by 'obj/third_party/icu/make_data_assembly.inputdeps.stamp', missing and no known rule to make it\n?\ntouch third_party/icu/common/icudtl.dat   -- doesn't work. Later i received an error related to this file. I could only return this file from chromium repo because it gets deleted via cleaning_list. . @Eloston for now i'm building with icu. In the next version i'll try second option. @Eloston another build error\nLINK ./font_service.service\nFAILED: font_service.service \n../../../../../../../../usr/bin/clang++ -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -lpthread -Wl,--as-needed -fuse-ld=gold -B -Wl,--icf=all -m64 -pthread -Wl,-O1 -Wl,--gc-sections -Wl,-rpath-link=. -Wl,--disable-new-dtags -Wl,--export-dynamic -o \"./font_service.service\" -Wl,--start-group @\"./font_service.service.rsp\"  -Wl,--end-group  -ldl -lrt -lgmodule-2.0 -lgobject-2.0 -lgthread-2.0 -lglib-2.0 -latomic -lsmime3 -lnss3 -lnssutil3 -lplds4 -lplc4 -lnspr4 -lpangocairo-1.0 -lpango-1.0 -lcairo -lfontconfig -lfreetype -lexpat -lgio-2.0 \nobj/base/libbase.a(message_pump_libevent.o):../../base/message_loop/message_pump_libevent.cc:function base::MessagePumpLibevent::WatchFileDescriptor(int, bool, int, base::MessagePumpLibevent::FileDescriptorWatcher*, base::MessagePumpLibevent::Watcher*): error: undefined reference to 'event_get_fd'\nclang-5.0: error: linker command failed with exit code 1 (use -v to see invocation)\n[8/11380] CXX obj/media/capture/mojo/...ure_types/video_capture_types.mojom.o\nninja: build stopped: subcommand failed.\nSeems like this line ruins the build:\nhttps://github.com/Eloston/ungoogled-chromium/blob/d3f382b9c723aea48b1a50ed533b303c91d02498/resources/patches/debian/system/event.patch#L82\nI returned the old line and then the build continued.. another error:\nFAILED: obj/third_party/WebKit/Source/platform/platform/SharedGpuContext.o \n../../../../../../../../usr/bin/clang++ -MMD -MF obj/third_party/WebKit/Source/platform/platform/SharedGpuContext.o.d -DBLINK_PLATFORM_IMPLEMENTATION=1 -DINSIDE_BLINK -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DDISABLE_NACL -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DCR_CLANG_REVISION=\\\"296320-1\\\" -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DGLIB_VERSION_MAX_ALLOWED=GLIB_VERSION_2_32 -DGLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_26 -DGL_GLEXT_PROTOTYPES -DUSE_GLX -DUSE_EGL -DSK_IGNORE_DW_GRAY_FIX -DSK_IGNORE_DIRECTWRITE_GASP_FIX -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_SUPPORT_GPU=1 -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DHAVE_PTHREAD -DENABLE_LAYOUT_UNIT_IN_INLINE_BOXES=0 -DENABLE_OILPAN=1 -DWTF_USE_CONCATENATED_IMPULSE_RESPONSES=1 -DWTF_USE_WEBAUDIO_FFMPEG=1 -DWTF_USE_DEFAULT_RENDER_THEME=1 -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_STATIC_IMPLEMENTATION -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC -DUSE_SYSTEM_LIBJPEG -DENABLE_IPC_FUZZER -Igen/blink -I../../third_party/ffmpeg -I../.. -Igen -I../../third_party/WebKit/Source -I../../third_party/WebKit -Igen/blink -Igen/third_party/WebKit -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I../../third_party/khronos -I../../gpu -I../../third_party/libwebp -I../../skia/config -I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/images -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pdf -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/include/gpu -I../../third_party/skia/src/gpu -I../../third_party/skia/src/sksl -I../../third_party/libwebm/source -I../../third_party/protobuf/src -Igen/protoc_out -I../../third_party/protobuf/src -I../../third_party/boringssl/src/include -I/usr/include/nss -I/usr/include/nspr -I../../third_party/icu/source/common -I../../third_party/icu/source/i18n -I../../third_party/iccjpeg -I../../third_party/libpng -I../../third_party/zlib -I../../third_party/ots/include -I../../v8/include -Igen/v8/include -I../../third_party/ced/src -I../../third_party/harfbuzz-ng/src -I../../third_party/ffmpeg/chromium/config/ChromeOS/linux/x64 -I../../third_party/ffmpeg -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -Wno-builtin-macro-redefined -D__DATE__= -D__TIME__= -D__TIMESTAMP__= -funwind-tables -fPIC -pipe -fcolor-diagnostics -m64 -march=x86-64 -pthread -Wall -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-block-capture-autoreleasing -Wno-unused-lambda-capture -Wno-user-defined-warnings -O2 -fno-ident -fdata-sections -ffunction-sections -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wglobal-constructors -g0 -Wno-header-guard -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.cpp -o obj/third_party/WebKit/Source/platform/platform/SharedGpuContext.o\nIn file included from ../../third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.cpp:5:\n../../third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h:38:16: error: no template named 'function' in namespace 'std'\n  typedef std::function<std::unique_ptr<WebGraphicsContext3DProvider>()>\n          ~~~~~^\n../../third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h:53:53: error: cannot initialize a member subobject of type 'blink::SharedGpuContext::ContextProviderFactory' (aka 'int') with an rvalue of type 'nullptr_t'\n  ContextProviderFactory m_contextProviderFactory = nullptr;\n                                                    ^~~~~~~\n2 errors generated.\nfixed by suggest from https://bugs.webkit.org/show_bug.cgi?id=162268\nSolution was to add \n```\ninclude \n```\nto\nthird_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h\nThan build was successfull. @libBletchley\ndeusu.org:\n403 - Verboten: Zugriff verweigert.\ndeusu.de:\nOne contributor for search engine...\nOnly for german\nIt Is really bad\nsearchx.me:\nSo good idea\nSo bad implementation\nResults in russian are terrible. Even in english results are bad\nstartpage:\nSlow\nDoesn't have Google and duckduckgo features\nBad design\nIs it FOSS? Is it corporate free? Why do you believe in it?\nAnyway, my choice is duckduckgo. It's bad in queries related to programming but everything else contains a right answer in the top result or in the first page.\n. ",
    "nyancat18": "the binary is  compatible with ubuntu, but i needed modify the control file of control.tar.gz   \nwith this \"control\"    this binary works fine\nhttps://gist.github.com/triceratops1/080b57b91333db34108db738997c06a4\n. if you want compatibility with ubuntu, please replaces libjpeg62-turbo with libjpeg62   \ni proved it, modifying your  debs \n. and i've got a very disturbing bug of  ungoogled \"a clean opensuse build service xenial vm\"   \nwith this log Supervised users aren't enabled\nand after the compilation has been aborted \n.    i have a very small questio for you   \nhow many time - resources   need for compile ?\n. what build vm reccomend= \n. a vps?\n. are you using your computer \"native\"?? \n. yes,   the purpose  of -n is  \nmake very easy use online compiling services \"instead of compile locally / vps\"\nand  make easy upload them to an apt repo     \nwith an \"original\" dsc, we could defeat the \"fuzz\"  issue \nand with the original source code  gonna be very easy compile \n. @probonopd \nhttps://github.com/Eloston/ungoogled-chromium/releases/tag/51.0.2704.106-1\n. https://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=google-chrome\n. WORKAROUND  \nadd the chromium firejail profile\nand a bashscript\nfirejail --profile=chromium.profile ./chrome --no-sandbox. Linux * 4.4.38. no :(\n./chrome --disable-setuid-sandbox\n[16137:16137:1216/223834:FATAL:zygote_host_impl_linux.cc(107)] No usable sandbox! Update your kernel or see https://chromium.9oo91esource.qjz9zk/chromium/src/+/master/docs/linux_suid_sandbox_development.md for more information on developing with the SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox.\nAbortado (core' generado). ./chrome \n[16242:16242:1216/224018:FATAL:zygote_host_impl_linux.cc(107)] No usable sandbox! Update your kernel or see https://chromium.9oo91esource.qjz9zk/chromium/src/+/master/docs/linux_suid_sandbox_development.md for more information on developing with the SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox.\nAbortado (core' generado)\n./chrome --disable-setuid-sandbox[16230:16230:1216/224012:FATAL:zygote_host_impl_linux.cc(107)] No usable sandbox! Update your kernel or see https://chromium.9oo91esource.qjz9zk/chromium/src/+/master/docs/linux_suid_sandbox_development.md for more information on developing with the SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox.\nAbortado (core' generado)\n. sh chrome-wrapper\n[16344:16344:1216/224232:FATAL:zygote_host_impl_linux.cc(107)] No usable sandbox! Update your kernel or see https://chromium.9oo91esource.qjz9zk/chromium/src/+/master/docs/linux_suid_sandbox_development.md for more information on developing with the SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox.\nAbortado (core' generado)\n. @eloston\nrelease an universal debian file (for debian, ubuntu, mint)  \nlike google chrome. @9Morello YES  . @nopjmp  i use webgl at ungoogled\nbut with scriptsafe (deletes identifiable info). @eloston ok\nbut i want alert about this issue\ni've send alerts to inox and iridium too  . @eloston  \nscriptsafe has webvr protection  . @andryou has it\nhttps://github.com/andryou/scriptsafe/releases/download/v1.0.9.0_beta/ScriptSafe_v1.0.9.0_BETA.zip   . @eloston you could add\nthe first uploadboy link has the ScriptSafe crx + the best setting for it\nthe second its my addon. Scriptsafe has an official build\nhttps://github.com/andryou/scriptsafe/releases/download/v1.0.9.0_beta/ScriptSafe_v1.0.9.0_BETA.zip . @robotme\nplease check https://github.com/SethDusek/extension-downloader/blob/master/downloader.py\nreplace inox with your ungoogled path (afik, that works at linux)  . @eloston \ncould you create \"regional\" issues\n1 issue per issue. ok  http://mirrors.dcarsat.com.ar/debian/pool/main/c/chromium-browser/chromium-browser_56.0.2924.76-1.debian.tar.xz. iridium doesnt give updates    .  Include (or upgrade) patches from Iridium (Will wait for new Iridium patches unless the previous tasks are done), iridium doesnt update from 54 :-1: \nUpdate ungoogled-chromium's own patches (Pending) (you now've ready at linux=. @eloston  can you talk me about the flags\nad patch process?\nfor make a \"human-readable\" fork of ungoogled?\nideal for windows/mac/other distros (export to ebuild/pkgbuild/rpm-spec). http://mirrors.dcarsat.com.ar/debian/pool/main/c/chromium-browser/chromium-browser_56.0.2924.76-1.debian.tar.xz. ok. but that would make very easy \nfor users with bad pcs\nmantain ungoogled . @Eloston i gonna try  . @lenormf i've tried to use the deb \nbut uses ancient libraries\nor wait to ungoogled-chromium at aur (after iit i build online). Debian\nhttp://ftp2.de.debian.org/debian/pool/main/c/chromium-browser/chromium-browser_58.0.3029.81-1.debian.tar.xz\nInox\n@gcarq has it READY\nIridium\nhttps://downloads.iridiumbrowser.de/source/iridium-browser-58.0.tar.xz. @eloston  sorry for the question  \nbut   are you planning sleep it for ug61  and wait for 62  afik google will release it at less than 10 days\nor you'll try to make ug 61 (and 62) . @perfect7gentleman     with only 3  for work )16-13)\ni may be safe?. @perfect7gentleman BUT\nwith just 16GB  (ram)\nand a  Ryzen 5 1600  the best, and more tested\ncould i build inox at tmpfs?\nof i need made it at hdd 80-90 mins more / ssd 20-30 extra. @92847586 \n\n\niridium-team had promised update iridium to 61xxxx\n\n\n@eloston its working at ug-61\n\n\ni'm trying to make this edgy merge \n\n\nand i've some misfortunes\nhttps://p.teknik.io/Raw/olbFC\n\n\nhttps://p.teknik.io/Raw/lQLWD. @92847586 \ni've making something just like this as near to this ideal as is possible\nbecause iridium has some unuseful patches, that try to harden webrtc, i dont need it because i've removed it, some crappy changes pings from google to their site and unuseful talks to unexistent files at chromium tree\nand @eloston ungooggled chromium has the same trouble for ug isnt bad, but for me its bad, as i take the chromium raw source lol\n@Eloston has some death flags, that i've removed it.\nbut i've gave some classic mitigation tricks for normal chromium,  for cancel any leak  \n\ndeath flag, you use it, you wait your 3.4 hours and when says LINK CHROME......FAILLL\n\nhttps://crbug.com/767185\nhttps://github.com/nyancat18/inox-patchset. @eloston feel free to use my wip (i've adapted your paches)\n\nyour patches are 40xx... @eloston  i  talk  about  how translate utilkit's work  to bash (good for pkgbuild). i'm searching the file\nbut i cant see it . WORKED with enable webrtc  \n\n. ",
    "Alvintrmp": "opensuse build service supports   debian 7-8, ubuntu 15.10-16.04, centos 6-7,  fedora 22-23, oepnsuse 13.1-1.2, tumbleweed and arch linux  \nand gives an extra advantage, lets users of ancient computers \"or without huge amounts of ram\"   compile them, because the buildscript used for now requires  a good cpu and many ram \"intel i5 + 16gm ram delays 5 hours\" \n. as i think  would fine  give support  \"ading to the default chromium .src.rpm\"     the patches for opensuse and fedora,  or at least arch   \nthat lets anybody enjoy it   \"without a good hardware\"\n. this junk of clear-http-auth-cache-menu-item.patch  isn't compatible with chromium 51\ngpaste.us/5ca429b0\nand  this bug\nhttp://gpaste.us/352fe25d\n. ",
    "devnoname120": "Related: https://github.com/ungoogled-software/ungoogled-chromium-binaries/issues/30\n\nFree plans from TravisCI and many other systems are out of the question because Chromium takes quite a bit of computational resources compared to that of most other free CI jobs (CPU, RAM, storage, and time)\n\nI would suggest asking them anyway, we never know what they might answer.. @intika I don't feel comfortable asking on the behalf of a project I'm not the owner of (I'm not even a contributor).. ",
    "intika": "\nRelated: ungoogled-software/ungoogled-chromium-binaries#30\n\nFree plans from TravisCI and many other systems are out of the question because Chromium takes quite a bit of computational resources compared to that of most other free CI jobs (CPU, RAM, storage, and time)\n\nI would suggest asking them anyway, we never know what they might answer.\n\n@devnoname120 Send a request referring to this issue and let us know... but i don't think they will answer with a free offer that will build the project in a reasonable time (a server with 48 x 2Ghz and 128GRam build the project in 15 min). Now i have an idea... google-cloud-computing offer a cli to manage servers and they bill only when the server is running, i could make some script that will automate the whole process BUT never the less this will cost approx 1~2 euros per build... \nBasically it's what i am doing manually to build the releases that i published... \nThinking of 2 releases per month time the different releases 1,5\u20ac x 2 releases x 10 builds = 30\u20ac/month a financial solution could be using \"google search\" to pay back the costs \nAll this to come back to what @Eloston have posted \n\nI also don't want to take the responsibility of maintaining this system, especially if it means I need to manage a paid plan and the funds that go into them.\n\nSo to make it simple is there any volunteer for that ?\nNote : in my personal situation i don't want to assume that (even if i do that manually from time to time)\nWe could setup a paypal donation account or something similar, but \n1. is @Eloston okay with such a solution ?\n2. is there any volunteer to manage that account ?\nOther Idea : a designated packagers team... \n(in my case i can not guarantee that i will build every release)\nOther Idea : identify who make the build... let say to be able to publish a build  you need to be identified name/adresse... disclosed to @Eloston or something\nOther idea : deploy the package to all distro repos (find an official packager for evey distro)\nOther idea : we make a little funding to make a gift to this project and offer him a server :D :dancing_men: \nOther idea : find a sponsor \nOther idea : stop publishing builds looool ahaha\nOther idea : setup something like a \"button to build and publish\" that would cost 2\u20ac and any user can click it and pay to automatically build and publish hahahahaha never the less its doable (we will see a build  popping up every day lol)\nThinking of that, that would be damn cool to have that button on a bench of projects loool i am giving away this idea of business for free guys lol hahahaha :D. > but I personally don't believe the benefits from a better CI system outweighs the dedication required.\nAgree 100%\n\n...\n\n@Eloston i love the way you write its amazing and aspirating, english is not my mother lang but i would love to be able to write like you :) ... you should write a book lol :D :yum: :dancing_women: \n\nI don't feel comfortable asking on the behalf of a project I'm not the owner of (I'm not even a contributor).\n\n@devnoname120 You are a contributor participating to this by you answers etc. :+1: \n\n...\n\n@Alvintrmp @devnoname120 @ArjonBu @ryneeverett @9Morello @lenormf @alexbakker @d33tah @RobinThrift @pizzadude @hrj @podshumok @MikolajQ @kirylpl @Lesik @zabbal @message @pseudoj @T-vK @metsatron @mtimofiiv @fedenko @sixtyfive  @olosz @dannycolin  @raininja @nyancat18 and all others and any one interested in this... \nAny one willing to pay for builds ? \n. Summarizing :\nWe just need some one that would take care of that... (in any case .../server/button/ci-services/...)\nAny volunteer ? \nHonestly i think none of those solutions is suitable, the project just need more users, then packagers of every distro will make this available in their repo... . > @intika Why did you tag me?\n\nBTW Just use the opensuse build service.\n\nWhy not ! lol ... (just joking... i tagged you because of https://github.com/Eloston/ungoogled-chromium/issues/59). is pushing an appimage binary to download section planned ? . @probonopd why don't you just PR https://github.com/ungoogled-software/ungoogled-chromium-binaries with the appimage you did ?\nthis is what i did for v68 portable and it's now available on download section \nor may be you want it to be build and published by @Eloston . > Once binary reproducibility becomes a reality\nIts very cool and important to see devs working on that, opensource world is unique  \n\nYes, I'm highly interested in peer-producing a web-of-trust!\n\nmee too :D \nBut at the end of the day who is willing to provide the appimage binary ?. a build from @Eloston is not a must have, according to this project policy about binary distribution system, also all linux distro packages are not build by the same person... so... in the other hand it's a waste of time regarding the time consumption of dev for this project... following the idea of @picsi & @Eloston  i think adding the appimage build script to the sources with a PR (and a PR to build instructions) will be the way to go and once merged i guess we will at least have one build from @Eloston or not lol :+1: but at least we will have a build  . Just landed an AppImage build based on my portable build\ni will pr that soon \nhttps://www.opendesktop.org/p/1266054/. Done https://github.com/ungoogled-software/ungoogled-chromium-binaries/pulls\nNote that i did had to edit the pkg2appimage script to make it work with a non debian system\n(Just needed to replace the apt-get commands, and also the needed package have different name like libgconf vs lib64gconf). Now TODO : \n- Update/PR pkg2appimage to make it compatible with non debian system \n- Integrate & PR pkg2appimage/uc-appimage script to ungoogled-chromium\n@Eloston do you think we should add appimage script to the project or just using it from @probonopd git is enough ?  may be for maintenance and updates its better to leave things as it is no ?. Done everything is landed \nhttps://github.com/ungoogled-software/ungoogled-chromium-binaries/pull/29 and https://github.com/Eloston/ungoogled-chromium/pull/551 and https://github.com/AppImage/AppImages/pull/349\nBuild instructions : \nOn portable build instructions after : \n./ungoogled_packaging/build.sh\n./ungoogled_packaging/package.sh\nJust run \n./ungoogled_packaging/package.appimage.sh\nNote 1 : @probonopd the script is git cloning my fort of AppImage awaiting the merging of my pr ;)\nNote 2 : Do i love ug that much ? lol :p. AppImages builds are now available... ;). Update checker for UC : \nHere are some extensions solution that can be used to check for update for UC other than a distro repo \n\n\nWebsite Monitoring For Change Extensions like visualping or page-monitor \n(you just need add uc-site to the monitored sites...)\n\n\nGithub notification like notifier-for-github (does not require to be logged in... of course you will need to subscribe to UC repo)\n\n\nRss-Feed Reader like feedbro\n. a function chat check that link could be added easily mainstream but in one hand \n\n\nupdate are important for security \nand the other\n\nusers may dislike a connection to github\n\nI think as it would just check one link for updates i think it would be fair to enable it by default (this eventual feature) and add a flag to make it disableable \n@Eloston what do you think ?  . - A website even with just the readme and link to github is good for the image of the project, also this would make the project look like a solid long life application not just a git project (this is just my opinion)\n\nIn my personal install i rename it to UGChrome the original name is kind a phrase... \n\nThanks a lot for your project and work . Some practical question and suggestions : \n1. Git page : \n- Git page is a very good initiative ! (https://ungoogled-software.github.io/ungoogled-chromium-binaries/) to avoid a paying a server... \n- We could just edit that page to make it more modern with a theme from https://themeforest.net/ or https://www.codegrape.com/ i think just the first page is enough (@Eloston i could personally do that) \n- Then adding a .org domain linking to that site and that's it (the domain indeed should be owned by @Eloston )\nThe name : (because of the domain)\nBefore picking a site the project should definitely have its own name even if we stick with ungoogled-chromium but in the purpose of growth i think this browser is unique and should have its own name and identity... all this in the hypothesis that this browser scope will grow beyond privacy any way this should be decided before the project become too big... names examples (Uchrome/UGChrome/Copper/Krypton/Oxygen/Oxium/Oxiweb/Oxfree/Chrodom/Atom/Earth/Sky/Star/Orion/Photon/Electron/...) loool but i kind a like Orion-Browser \nA Team : what about creating a team or just listing tasks of what should be done and any one involved could choose what to do. \n . Nice growth you should invest some finance in there hahahaha \nThe line is days or hours ? \nwas the browser just open or used ?. hard to debug when the browser is used but i think this affect upstream as well  . @Eloston been looking after a source/rolling distro lately and ended up with void/gentoo choice and void seems really to be damn interesting... i will be probably installing that on one of my main machines soon i will see if i can help then, it does not seems to be in a hurry issue here so... \noff-topic : Now about the firefox i have to be honest i switched back lool still using uc tho but firefox v62, v63 just fly in term of speed etc... still need some customization tho for privacy (https://github.com/Eloston/ungoogled-chromium/issues/560#issuecomment-431713666) and also it have auto-update forced (can be disabled...)... but other than that they have done a damn pretty good work  \nBy the way not all void linux are using musl its optional . duplicate of https://github.com/Eloston/ungoogled-chromium/issues/619 ?\n@Eloston . > Interesting. I tend to go to GitHub (or similar services) to see what a project is like, because it allows me to see attributes that aren't visible on a website; e.g. development activity, code quality, stability, the kind of atmosphere it promotes, etc.\nYeah me too but for a project like a browser (even if it's a fork) i expected to see more than a git, i know now the background but back then i was like \"this is someone who are playing with chromium this is not serious and may be it will not survive a long time\" but as i already said after digging in it's a whole other story... as we say \"first impression is a bitch\" lol. > \"respecting our users is at the core of what we do\" is the latest Google's nonsense in this bug report about Chromes privacy issues related to connections to Google:\n\nSo once again: huge thanks to @Eloston for this great project.\n\nYes they do because if not no one would use the product, in the other hand we sometime forget that all of this is free... in the butom line we are the product... there is reason why google services are so good it's because they know so well theirs users lol hahaha\nWe are the exception/a-minority seeking for privacy not the majority and very very far from it . Tor have nothing to do with the scope of this project... at best a fork should be made for that purpose . @anchev i know that you are on topic here regarding this issue, i down-voted the comments about integrating tor as a feature because this is out of the scope of uc which is more or less cleaning chromium not bundling other security related application/extensions/protocols... thus said nothing prevent anyone from integrating this to the browser in a fork, and or PR a light acceptable modification like proxy per tab or proxy in incognito mode as @Eloston already mentioned \nPlus the asked feature is something that have to be done on the other end (tor extension/tor proxy) not in UC. > ...as a SOCKS5 proxy for Chromium. I suppose some UI to make this configurable for private tabs wouldn't hurt.. > IMO it's all comes down to putting in the effort to implement something for Firefox like what ungoogled-chromium did for Chromium. Unless Firefox's design makes this significantly more difficult, I believe the potential in this area is equal to Chromium.\nhere https://github.com/pyllyukko/user.js and here https://github.com/Eloston/ungoogled-chromium/issues/560#issuecomment-431713666 \nno need for patching... even if it could be better to completely remove the questionable code\n\nAs Firefox piles up more and more \"features\" they can add new connections at any time with new Mozilla's partners and the about:config flags for controlling all that are poorly documented (if at all). There are people who spend a lot of time to find info about that and reflect it in the multiple user.js projects but so far I haven't found a project focused on eliminating completely the unrequested connections (TBB also doesn't seem to do it). My own attempts in that were successful to a point but I stopped keeping up to date the user.js I created because following all that is a real nightmare - very time consuming and IMO unreliable. That's why I think UC is a much cleaner thing to start with.\n\nEither way devs reviewing mozilla code and patching it or reviewing code to change something in about:config it takes all time... and still mozilla is reactive when someone ask to add a new flag in about:config to block this or that operation with a flag. \nThe advantage with chromium is that we dont need to deal with all the functions added in chrome as they are 2 different projects. We need to add a patch for that main stream to fix it for all platforms. To fix this create a text file to /etc/chromium/policies/managed/policies.json\nand here is what it should contain : \n{\n  \"EnableMediaRouter\": false\n}\njust as example here are some additional settings \n{\n  \"EnableMediaRouter\": false,\n  \"DefaultWebUsbGuardSetting\": 2,\n  \"DefaultWebBluetoothGuardSetting\": 2,\n  \"NativeMessagingUserLevelHosts\": false,\n  \"WPADQuickCheckEnabled\": false,\n  \"BackgroundModeEnabled\": false,\n  \"DisablePluginFinder\": true\n}\n. Done https://github.com/ungoogled-software/ungoogled-chromium-wiki/pull/3. @anchev have a look at https://github.com/Eloston/ungoogled-chromium/issues/490\nyou can install llvm 6 by adding this repo \nzypper addrepo -f https://download.opensuse.org/repositories/devel:/tools:/compiler/openSUSE_Leap_42.3/ new-devels-clang6llvm\nedit the link to match your opensuse version... also check if the repo exist for your opensuse version\n. @anchev \nThe repo i am using is listed on opensuse.org >> https://software.opensuse.org/package/lld8\nHere is the version for your distro https://build.opensuse.org/package/show/home%3Akhnazile%3Avideo/llvm\nI am also skeptical when using non official repo but this beast is a pain in a.. to build so just using what ever i find to get it to build then once we know what it need exactly we can look for official releases OR just build llvm/clang/lld from sources it's not that big of a deal. > As far as I can see @intika is using Leap 42.3 and a repo of a specific user, which is neither listed on software.opensuse.org, nor even a community repo. Even if there was such repo for Leap 15.0 I would still be highly reluctant to use it. I was even hesitant about the one which I currently use as it is still an unofficial one.\nDon't affirm something without being sure ! dig a little bit ! https://github.com/Eloston/ungoogled-chromium/issues/447#issuecomment-422868920\n\nI wonder how come this was supposed to work version 6 and now it suddenly requires something else?\nETA: I see that LLVM 7.0 was released today. Why would a software which was released before it require it for building itself?\n\nYou can build chromium a million ways ... indeed v69 sources packages from various linux distros (opensuse included) use gcc-7 to build it and does not require clang at all (nor lld nor llvm)  . @anchev \n\n\nusing what ever i find to get it to build\n\nI am not really a fan of such approach. It makes even less sense along the lines of the current project: one is trying to free oneself from untrusted stuff and the way to it is not to use whatever. (imo)\n\nThis is just a step to get it to build to see what it need THEN i clean the install to make a final release this is just to avoid loosing time. \n\n\nbuild llvm/clang/lld from sources it's not that big of a deal\n\nThat is what I would rather be interested to try. Currently looking for info how to do it.\n\nHere is how to https://clang.llvm.org/get_started.html also have-a-look/apply the patchs used in Akhnazile LLVM8 Repo before building \nAlso you will need to enable it in PATH as @Eloston already indicated... in my case i just symlink it to /usr/bin \nYes indeed you machine is a fast one, it takes 4h in my laptop... but i don't build there i am using google cloud computing... it takes about 10 min there https://github.com/Eloston/ungoogled-chromium/issues/491\nThe is also an alternative if you have an other machine locally, you could use its cpu to help building it's Distcc but i did not try it . @anchev \n\nensure that the environment variables specifying the compilers are correctly referencing said LLVM in PATH\nIn which file(s) do I check this please?\n\necho $PATH\nhttps://www.google.com/search?hl=en&q=linux+path\nBasically its where any binary is located, this variable is used for any command\n\nWhat are \"GN args\" and how do I remove them?\n\nhttps://www.google.com/search?hl=en&q=%22GN+args%22\nhttps://www.chromium.org/developers/gn-build-configuration\nDon't worry too much about them in my test config it build without changing those with a custom llvm.\n\nWhat is \"jumbo file merge limit\" and how do I reduce it?\n\nhttps://www.google.com/search?hl=en&q=%22jumbo_file_merge_limit%22\nhttps://www.google.com/search?hl=en&q=%22jumbo+file+merge+limit%22+chromium\nhttps://chromium.googlesource.com/chromium/src/+show/69.0.3455.3/docs/jumbo.md\nhttps://groups.google.com/a/chromium.org/forum/#!topic/chromium-dev/ThDAjO7fTro\n\n@intika you really have an interesting approach - going back to Google to build an ungoogled chromium :)\n\n...and on a chromebook lol\nSome lecture.. \nhttps://www.google.com/search?hl=en&q=%22Trusting+Trust%22\nAah by the way if you are not using http://www.google.com for your searches you can try http://www.qwant.com   :D :1st_place_medal: :+1: :1234: \n. > Forgive me, I am not a network expert, so this is a bit difficult for me. All I know is that 'probing' is an action used to determine a state of the network (e.g. ping, nmap) and that IPv6 is a newer protocol, with much larger amount of IP addresses and includes certain improvements. Why one would want to avoid IPv6? I hope you can clarify as for a layman.\nIPv6 is a whole new world compared to ipv4... i personally don't like it i have my reasons (how this new protocol works, who invented it, and the history...)... now when it come to general IT here is some reason where you may want to disable ipv6 \n\n\nFirewall : if your firewall does not handle ipv6\n\n\nSetup : if you have a setup that does not handle ipv6 let say an ipv4 VPN for example \n\n\nA lot of network tool does not handle ipv6 yet..\n\n\nSecurity and Stability : even if ipv6 have been around since a quite long time it still have some major difference with ipv4, some links http://www.ipv6now.com.au/primers/IPv6SecurityIssues.php and https://www.google.com/search?hl=en&q=leak+ipv6 and https://www.google.com/search?hl=en&q=vulnerability+ipv6 \n\n\nComplexity : many IT prefer ipv4 for its simple addressing system, compared to v6 when you look at an ip it a little bit more complex to handle and understand \n\n\n... and so on we could find a million reasons not to use it... the main purpose of ipv6 is the limited amount of available ips addresses and for the moment the impact is limited...   . @stefantalpalaru \n@Eloston just merged v70 to the master project... i guess @perfect7gentleman is building master... it's a super devel package but it should work... but indeed v70 of uc is not yet released\ni am always fascinated to see how most of people always wants the latest release no matter what ^^. thanks for your answers \ni made a modified version with an ugly patch to \"chrome/browser/ui/views/tabs/tab.cc\" around line 1000 next to middle click close tab function... if i can made my patch clean i will pull request... \ni am just having trouble with libc version to make my compiled version work on my main machine which have older libc... . Here is my ugly patch... it works but for up-streaming it need some additional work or maybe a timer or so... i will maybe make a new version that can be up-streamed any way the thing is i just wanted to full fill the need of dbl click close tab quickly \ni don't know if it's needed to keep this issue open... if its not really needed may be just link here in the readme for those who want to build with this patch... \n```\n--- chromnormal/ungoogled-chromium/build/src/chrome/browser/ui/views/tabs/tab.cc        2018-08-08 19:10:41.000000000 +0000\n+++ tab.cc      2018-09-10 04:24:37.114899715 +0000\n@@ -964,10 +964,14 @@\n         }\n       } else if (!IsSelected()) {\n         controller_->SelectTab(this);\n+        //intika\n+        dblClick = 0;\n         base::RecordAction(UserMetricsAction(\"SwitchTab_Click\"));\n       }\n     } else if (!IsSelected()) {\n       controller_->SelectTab(this);\n+      //intika\n+      dblClick = 0;\n       base::RecordAction(UserMetricsAction(\"SwitchTab_Click\"));\n     }\n     ui::MouseEvent cloned_event(event_in_parent, parent(),\n@@ -982,6 +986,9 @@\n   return true;\n }\n+//Intika Fucking dblclick \n+int dblClick = 0;\n+\n void Tab::OnMouseReleased(const ui::MouseEvent& event) {\n   controller_->OnMouseEventInTab(this, event);\n@@ -990,13 +997,16 @@\n   // In some cases, ending the drag will schedule the tab for destruction; if\n   // so, bail immediately, since our members are already dead and we shouldn't\n   // do anything else except drop the tab where it is.\n-  if (controller_->EndDrag(END_DRAG_COMPLETE))\n-    return;\n+  if (controller_->EndDrag(END_DRAG_COMPLETE)){\n+        dblClick = 0;\n+       return;\n+    }\n\n// Close tab on middle click, but only if the button is released over the tab\n// Close tab on \u00b5middle click, but only if the button is released over the tab\n   // (normal windows behavior is to discard presses of a UI element where the\n   // releases happen off the element).\n   if (event.IsMiddleMouseButton()) {\ndblClick = 0;\n     if (HitTestPoint(event.location())) {\n       controller_->CloseTab(this, CLOSE_TAB_FROM_MOUSE);\n     } else if (closing_) {\n@@ -1013,11 +1023,28 @@\n     // If the tab was already selected mouse pressed doesn't change the\n     // selection. Reset it now to handle the case where multiple tabs were\n     // selected.\n\ncontroller_->SelectTab(this);\n\nif (alert_indicator_button_ && alert_indicator_button_->visible() &&\nalert_indicator_button_->bounds().Contains(event.location())) {\nbase::RecordAction(UserMetricsAction(\"TabAlertIndicator_Clicked\"));\n\n//--------------------------------------------------------INTIKA\nif (!IsSelected()) {\ndblClick = 0;\n}\n\nif (dblClick > 1) {\ndblClick = 0;\nif (HitTestPoint(event.location())) {\ncontroller_->CloseTab(this, CLOSE_TAB_FROM_MOUSE);\n} else if (closing_) {\nTab* closest_tab = controller_->GetTabAt(this, event.location());\nif (closest_tab)\ncontroller_->CloseTab(closest_tab, CLOSE_TAB_FROM_MOUSE);\n}\n} else { //------------------------------------------------INTIKA\ncontroller_->SelectTab(this);\ndblClick++;\nif (alert_indicator_button_ && alert_indicator_button_->visible() &&\nalert_indicator_button_->bounds().Contains(event.location())) {\nbase::RecordAction(UserMetricsAction(\"TabAlertIndicator_Clicked\"));\n}\n     }\n   }\n }\n\n```. I made my custom version available here https://github.com/intika/UGChrome/. just close it, it's a little bit out of the scope of the project, i will maintain this patch on https://github.com/intika/UGChrome/ tho.\nbut it's up to you, if you want to add the feature to ungoogled-chromium i will maintain it too ;). Update for v69 \nFollowing the instruction for v68 here is what is needed to build v69\n```\nzypper addrepo -f https://download.opensuse.org/repositories/home:/forkbomb:/turboAMD/openSUSE_Leap_42.3/ libva\nzypper addrepo -f https://download.opensuse.org/repositories/home:/khnazile:/video/openSUSE_Leap_42.3/ clang8\nzypper remove libswscale-devel libva-devel libva-gl-devel llvm6 clang6 lld6 clang3_9-checker-3.9.1-33.12.x86_64 libLLVM70-32bit-7.0~svn20180529-18.1.x86_64\nzypper install gcc7 devgcc7 uuid yami vaapi libva-devel-2.2.0-112.1.x86_64 libva flac-devel gcc7-c++ gn krb5-devel libevent-devel libudev-devel libvorbis-devel memory-constraints nodejs6 python-simplejson sqlite3 gnome-keyring libtcmalloc perftools ffmpeg-4-libav keyutils-devel libcom_err-devel libverto-devel llvm8 clang8 python3-clang lld8* \nzypper update \n```. @Eloston i just sent a pr ;) . maybe also adding the new section to the main index. Yes it makes sens... \n\nA lot of the instructions look redundant. I think we should just state the packages needed to build Chromium in the \"Any Linux distribution\" section. Also, please trim the packages down to the necessary ones.\n\ni will make an other pull request later because it need some work to trim the package down to get the exact needed packages...   \n\nI don't think we should include the Google Cloud setup information in this document. We should move it to a separate document, or the ungoogled-chromium Wiki.\n\nYes good idea i was not at ease writing this here on such organized project i will also make a pr for that on the wiki \ni will close this pr for the moment :)\n. By the way thank you for your amazing work and for your kindness :) :+1: . i could get it to pass this error with \n./tools/gn/bootstrap/bootstrap.py -o out/Default/gn --gn-gen-args 'use_sysroot=false'\nbut this generated some errors about safe_browsing on some \"Build.gn\" so i just commented those lines \"//chrome/browser/safe_browsing\", ... \nthen it gave me this error\nERROR Unresolved dependencies.\n//content/gpu:gpu_sources(//build/toolchain/linux:clang_x64)\n  needs //media/gpu:libva_config(//build/toolchain/linux:clang_x64) \nSo i commented  public_configs = [ \"//media/gpu:libva_config\" ] under the file content/gpu/BUILD.gn to disable vaapi \nand now it works... \ni did not build tho \nEDIT\nosuse-leap-42-3-2018:/home/intika/chro/ungoogled-chromium/build/src # ./ungoogled_packaging/build.sh\n+ BUNDLE=linux_portable\n+++ readlink -f ./ungoogled_packaging/build.sh\n++ dirname /home/intika/chro/ungoogled-chromium/build/src/ungoogled_packaging/build.sh\n+ DOWNLOAD_CACHE=/home/intika/chro/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache\n+ rm -rf out\n+ mkdir out\n+ mkdir out/Default\n+++ readlink -f ./ungoogled_packaging/build.sh\n++ dirname /home/intika/chro/ungoogled-chromium/build/src/ungoogled_packaging/build.sh\n+ pushd /home/intika/chro/ungoogled-chromium/build/src/ungoogled_packaging\n/home/intika/chro/ungoogled-chromium/build/src/ungoogled_packaging /home/intika/chro/ungoogled-chromium/build/src\n+ popd\n/home/intika/chro/ungoogled-chromium/build/src\n+ export AR=llvm-ar\n+ AR=llvm-ar\n+ export NM=llvm-nm\n+ NM=llvm-nm\n+ export CC=clang\n+ CC=clang\n+ export CXX=clang++\n+ CXX=clang++\nOk\nosuse-leap-42-3-2018:/home/intika/chro/ungoogled-chromium/build/src # ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn --gn-gen-args 'use_sysroot=false'\nninja: Entering directory `/home/intika/chro/ungoogled-chromium/build/src/out/Release/gn_build'\n[171/171] LINK gn\nDone. Made 9965 targets from 1718 files in 3316ms\nSeems Ok\nosuse-leap-42-3-2018:/home/intika/chro/ungoogled-chromium/build/src # ninja -j48 -C out/Default chrome chrome_sandbox chromedriver\nninja: Entering directory `out/Default'\nninja: error: loading 'build.ninja': No such file or directory\nosuse-leap-42-3-2018:/home/intika/chro/ungoogled-chromium/build/src #\nNok \nninja: error: loading 'build.ninja': No such file or directory\n... \nhaving fun lol ... i am learning chromium backward. apparently the issue raised when i updated gcc to v7... i had v4.8 when building v68...\n1- here is the situation i setup the machine to work with v68 build etc everything work... \n2- tired to build current v69 version but i had an error... advice was to update gcc to > 5... so i did \n3- resulting in \nERROR at //build/config/sysroot.gni:57:5: Assertion failed.\n    assert(\n    ^-----\nMissing sysroot (//build/linux/debian_sid_amd64-sysroot). To fix, run: build/linux/sysroot_scripts/install-sysroot.py --arch=amd64\nSee //build/config/sysroot.gni:58:9:\ndo you have any advice on dependency etc from v68 to v69 ? while keeping your build method\nNote : sorry to bother you. and thanks for your help :). Thanks for your answer... i did setup a new VM just to build v69 \nhere is some useful infos about that VM \n```\npython --version\nPython 2.7.15\npython3 --version\nPython 3.6.6\nclang --version\nclang version 6.0.1 (tags/RELEASE_601/final 335528)\nTarget: x86_64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /usr/bin\nlld\nlld             lld-6.0.1       lld-link        lld-link-6.0.1  \ngcc --version\ngcc (SUSE Linux) 4.8.5\ncc --version\ncc (SUSE Linux) 4.8.5\nc++ --version\nc++ (SUSE Linux) 4.8.5\nninja --version\n1.7.2\nldd --version\nldd (GNU libc) 2.22\nuname -a\nLinux osuse-leap-42-3-2018-69 4.4.104-39-default #1 SMP Thu Jan 4 08:11:03 UTC 2018 (7db1912) x86_64 x86_64 x86_64 GNU/Linux\n```\ngit checkout tags/68.0.3440.106-2 \nThis version build correctly with the current setup\nNow when trying to build v69 (downloaded chromium-69.0.3497.92.tar.xz)\nhere is what's the result (after ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn --build-path out/gn_build)\n```\n...\n+ ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn --build-path out/gn_build\nninja: Entering directory /home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build/gn_build'\n[5/171] CXX base/json/string_escape.o\nFAILED: base/json/string_escape.o\n...\nungoogled-chromium/build/src/tools/gn/base/template_util.h:148:46: error: no template named 'is_trivially_copy_constructible' in namespace 'std'\n...\n```\n**And a bunch of other errors here is a larger output capture** \n```\n2018-09-13 01:38:32,167 - INFO: Path has no substitutions: third_party/crashpad/crashpad/doc/support/crashpad_doxygen.css\n2018-09-13 01:38:37,473 - INFO: Path has no substitutions: tools/md_browser/base.css\n+ python3 -m buildkit gnargs print -b config_bundles/linux_portable\n+ popd\n/home/intika/chrome/69/ungoogled-chromium/build/src\n+ cp out/Default/args.gn out/gn_build/args.gn\n+ export AR=llvm-ar\n+ AR=llvm-ar\n+ export NM=llvm-nm\n+ NM=llvm-nm\n+ export CC=clang\n+ CC=clang\n+ export CXX=clang++\n+ CXX=clang++\n+ ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn --build-path out/gn_build\nninja: Entering directory/home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build/gn_build'\n[5/171] CXX base/json/string_escape.o\nFAILED: base/json/string_escape.o \nclang++ -MMD -MF base/json/string_escape.o.d  -I/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn -I/home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build/gn_build -DNDEBUG -O3 -fdata-sections -ffunction-sections -D_FILE_OFFSET_BITS=64 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -pthread -pipe -fno-exceptions -fno-rtti -fdiagnostics-color -std=c++14 -Wno-c++11-narrowing -c /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/json/string_escape.cc -o base/json/string_escape.o\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/json/string_escape.cc:5:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/json/string_escape.h:12:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/string_piece.h:30:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/logging.h:21:\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/template_util.h:148:46: error: no template named 'is_trivially_copy_constructible' in namespace 'std'\nusing is_trivially_copy_constructible = std::is_trivially_copy_constructible;\n                                        ~~~~~^\n1 error generated.\n[6/171] CXX base/files/file_path_constants.o\nFAILED: base/files/file_path_constants.o \nclang++ -MMD -MF base/files/file_path_constants.o.d  -I/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn -I/home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build/gn_build -DNDEBUG -O3 -fdata-sections -ffunction-sections -D_FILE_OFFSET_BITS=64 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -pthread -pipe -fno-exceptions -fno-rtti -fdiagnostics-color -std=c++14 -Wno-c++11-narrowing -c /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/files/file_path_constants.cc -o base/files/file_path_constants.o\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/files/file_path_constants.cc:7:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/files/file_path.h:114:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/string_piece.h:30:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/logging.h:21:\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/template_util.h:148:46: error: no template named 'is_trivially_copy_constructible' in namespace 'std'\nusing is_trivially_copy_constructible = std::is_trivially_copy_constructible;\n                                        ~~~~~^\n1 error generated.\n[7/171] CXX base/strings/string16.o\nFAILED: base/strings/string16.o \nclang++ -MMD -MF base/strings/string16.o.d  -I/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn -I/home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build/gn_build -DNDEBUG -O3 -fdata-sections -ffunction-sections -D_FILE_OFFSET_BITS=64 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -pthread -pipe -fno-exceptions -fno-rtti -fdiagnostics-color -std=c++14 -Wno-c++11-narrowing -c /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/string16.cc -o base/strings/string16.o\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/string16.cc:18:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.h:13:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/string_piece.h:30:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/logging.h:21:\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/template_util.h:148:46: error: no template named 'is_trivially_copy_constructible' in namespace 'std'\nusing is_trivially_copy_constructible = std::is_trivially_copy_constructible;\n                                        ~~~~~^\n1 error generated.\n[8/171] CXX base/strings/utf_string_conversions.o\nFAILED: base/strings/utf_string_conversions.o \nclang++ -MMD -MF base/strings/utf_string_conversions.o.d  -I/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn -I/home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build/gn_build -DNDEBUG -O3 -fdata-sections -ffunction-sections -D_FILE_OFFSET_BITS=64 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -pthread -pipe -fno-exceptions -fno-rtti -fdiagnostics-color -std=c++14 -Wno-c++11-narrowing -c /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.cc -o base/strings/utf_string_conversions.o\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.cc:5:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.h:13:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/string_piece.h:30:\nIn file included from /home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/logging.h:21:\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/template_util.h:148:46: error: no template named 'is_trivially_copy_constructible' in namespace 'std'\nusing is_trivially_copy_constructible = std::is_trivially_copy_constructible;\n                                        ~~~~~^\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.cc:56:26: error: no template named 'decay_t' in namespace 'std'; did you mean 'decay'?\n    SizeCoefficient, std::decay_t>::value;\n                    ~~~~~^~~~~~~\n                         decay                                                                                                                                        \n/usr/bin/../lib64/gcc/x86_64-suse-linux/4.8/../../../../include/c++/4.8/type_traits:1725:11: note: 'decay' declared here\n    class decay \n          ^\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.cc:56:49: error: no template named 'decay_t' in namespace 'std'; did you mean 'decay'?\n    SizeCoefficient, std::decay_t>::value;\n                                           ~~~~~^~~~~~~\n                                                decay                                                                                                                 \n/usr/bin/../lib64/gcc/x86_64-suse-linux/4.8/../../../../include/c++/4.8/type_traits:1725:11: note: 'decay' declared here\n    class decay \n          ^\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.cc:27:3: error: static_assert failed \"Default case: from a smaller encoding to the bigger one\"\n  static_assert(sizeof(SrcChar) < sizeof(DestChar),\n  ^             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.cc:56:5: note: in instantiation of template class 'base::(anonymous namespace)::SizeCoefficient, std::decay >' requested here\n    SizeCoefficient, std::decay_t>::value;\n    ^\n/home/intika/chrome/69/ungoogled-chromium/build/src/tools/gn/base/strings/utf_string_conversions.cc:183:20: note: in instantiation of variable template specialization 'base::(anonymous namespace)::size_coefficient_v' requested here\n                   size_coefficient_v, std::basic_string >' requested here\n  return UTFConversion(StringPiece(src, src_len), output);\n```\nSo after some search, i guess i have to update gcc so i did install gcc5 gcc6 & gcc7 + devels\nzypper install gcc5 gcc6 gcc7\nzypper install *dev*gcc5*\nzypper install *dev*gcc6*\nzypper install *dev*gcc7*\nResult\n```\ngcc\ngcc             gcc-6           gcc-ar-4.8      gcc-ar-7        gcc-nm-5        gcc-ranlib      gcc-ranlib-6  \ngcc-4.8         gcc-7           gcc-ar-5        gcc-nm          gcc-nm-6        gcc-ranlib-4.8  gcc-ranlib-7  \ngcc-5           gcc-ar          gcc-ar-6        gcc-nm-4.8      gcc-nm-7        gcc-ranlib-5    gccmakedep\ngcc --version\ngcc (SUSE Linux) 4.8.5\n**Now** `./tools/gn/bootstrap/bootstrap.py -o out/Default/gn --build-path out/gn_build` **give :**\n[171/171] LINK gn\nERROR at //build/config/sysroot.gni:57:5: Assertion failed.\n    assert(\n    ^-----\nMissing sysroot (//build/linux/debian_sid_amd64-sysroot). To fix, run: build/linux/sysroot_scripts/install-sysroot.py --arch=amd64\n**Larger output**\n2018-09-13 02:20:52,632 - INFO: Path has no substitutions: third_party/catapult/third_party/polymer/components/font-roboto/roboto.html\n2018-09-13 02:20:52,791 - INFO: Path has no substitutions: third_party/catapult/tracing/third_party/gl-matrix/jsdoc-template/static/default.css\n2018-09-13 02:20:53,506 - INFO: Path has no substitutions: third_party/crashpad/crashpad/doc/support/crashpad_doxygen.css\n2018-09-13 02:20:57,883 - INFO: Path has no substitutions: tools/md_browser/base.css\n+ python3 -m buildkit gnargs print -b config_bundles/linux_portable\n+ popd\n/home/intika/chrome/69/ungoogled-chromium/build/src\n+ cp out/Default/args.gn out/gn_build/args.gn\n+ export AR=llvm-ar\n+ AR=llvm-ar\n+ export NM=llvm-nm\n+ NM=llvm-nm\n+ export CC=clang\n+ CC=clang\n+ export CXX=clang++\n+ CXX=clang++\n+ ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn --build-path out/gn_build\nninja: Entering directory `/home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build/gn_build'\n[171/171] LINK gn\nERROR at //build/config/sysroot.gni:57:5: Assertion failed.\n    assert(\n    ^-----\nMissing sysroot (//build/linux/debian_sid_amd64-sysroot). To fix, run: build/linux/sysroot_scripts/install-sysroot.py --arch=amd64\nSee //build/config/sysroot.gni:58:9: \n        exec_script(\"//build/dir_exists.py\",\n        ^-----------------------------------\nThis is where it was set.\nSee //chrome/installer/BUILD.gn:7:1: whence it was imported.\nimport(\"//build/config/sysroot.gni\")\n^----------------------------------\nSee //BUILD.gn:67:5: which caused the file to be included.\n    \"//chrome/installer\",\n    ^-------------------\nTraceback (most recent call last):\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 101, in \n    sys.exit(main(sys.argv[1:]))\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 96, in main\n    '--args=%s' % gn_gen_args, \"--root=\" + SRC_ROOT\n  File \"/usr/lib64/python2.7/subprocess.py\", line 190, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['out/Default/gn', 'gen', '/home/intika/chrome/69/ungoogled-chromium/build/src/out/gn_build', '--args= is_debug=false', '--root=/home/intika/chrome/69/ungoogled-chromium/build/src']' returned non-zero exit status 1\n```\nSo yes still same error after f6fbb16 \nAm i doing something wrong ? any advice ? \nthanks . Thank you a lot for your help it's appreciated :) Thanks again !!! \nIndeed your commit fixed the error i had... \nI did added some packages needed for v69 since last time to get build process go further... and did some modification to the build machine then i had an other error but after debugging and updating to last version it is solved... i am very close to get a working 69 version ^^... but i am stuck again \nHere is what i am facing currently \n1. ERROR:root:Git error: rc=0, output='' this does not seem to stop the build process\n``\n+ ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn\nninja: Entering directory/home/intika/chrome/test/ungoogled-chromium/build/src/out/Release/gn_build'\n[171/171] LINK gn\n+ ./out/Default/gn gen out/Default --fail-on-unused-args\nDone. Made 9356 targets from 1632 files in 6371ms\n+ ninja -C out/Default chrome chrome_sandbox chromedriver\nninja: Entering directory `out/Default'\n[451/20983] ACTION //chrome/test/chromedriver:embed_version_in_cpp(//build/toolchain/linux/unbundle:default)\nERROR:root:Git error: rc=0, output=''\n[15000/20983] CXX obj/chrome/browser/media/router/discovery/discovery/dns_sd_device_lister.o\nThen some warning during the build process then \n**2.** `Alias must point to a definition i32 (%struct._FcCharSet*, i32)* @FcCharSetHasChar`\n[20973/20983] LINK ./v8_context_snapshot_generator\nFAILED: v8_context_snapshot_generator \npython \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./v8_context_snapshot_generator\" -- clang++ -Wl,--build-id=sha1 -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -fuse-ld=lld -Wl,--icf=all -Wl,--color-diagnostics -flto=thin -Wl,--thinlto-jobs=8 -Wl,--thinlto-cache-dir=thinlto-cache -Wl,--thinlto-cache-policy,cache_size=10\\%:cache_size_bytes=10g:cache_size_files=100000 -Wl,--lto-O0 -fwhole-program-vtables -m64 -Wl,-O2 -Wl,--gc-sections -nostdlib++ -fsanitize=cfi-vcall -fsanitize=cfi-icall -rdynamic -Wl,-rpath-link=. -Wl,--disable-new-dtags -Wl,--icf=none -o \"./v8_context_snapshot_generator\" -Wl,--start-group @\"./v8_context_snapshot_generator.rsp\"  -Wl,--end-group   -ldl -lpthread -lrt -lgmodule-2.0 -lgobject-2.0 -lgthread-2.0 -lglib-2.0 -lsmime3 -lnss3 -lnssutil3 -lplds4 -lplc4 -lnspr4 -latomic -lresolv -lgio-2.0 -lX11 -lX11-xcb -lxcb -lXcomposite -lXcursor -lXdamage -lXext -lXfixes -lXi -lXrender -lXtst -lexpat -luuid -lXrandr -lpangocairo-1.0 -lpango-1.0 -lcairo -lXss -lasound -lm -lz -lpci -ldbus-1 \nAlias must point to a definition\ni32 (%struct._FcCharSet, i32) @FcCharSetHasChar\nLLVM ERROR: Broken module found, compilation aborted!\nLLVM ERROR: Failed to rename temporary file thinlto-cache/Thin-df2176.tmp.o to thinlto-cache/llvmcache-2AE339AC3FA8CE37836989F97A1BE24C7BAE5823: No such file or directory\nLLVM ERROR: Failed to rename temporary file thinlto-cache/Thin-f96b49.tmp.o to thinlto-cache/llvmcache-0DCDEB0F93C0D9DE77470F3D49634B8957B7318F: No such file or directory\nLLVM ERROR: Failed to rename temporary file thinlto-cache/Thin-e0d114.tmp.o to thinlto-cache/llvmcache-69F26B8A7958A256B2245F81A373EE61ACF0DE95: No such file or directory\nclang-6.0.1: error: linker command failed with exit code 1 (use -v to see invocation)\nninja: build stopped: subcommand failed.\n```\nAny Advices ? \nThanks again\nFull Build Logs :\n``\nosuse-leap-42-3-2018-69:/home/intika/chrome/test # git clone https://github.com/Eloston/ungoogled-chromium.git\nCloning into 'ungoogled-chromium'...\nremote: Counting objects: 9621, done.\nremote: Compressing objects: 100% (72/72), done.\nremote: Total 9621 (delta 53), reused 72 (delta 37), pack-reused 9510\nReceiving objects: 100% (9621/9621), 4.95 MiB | 9.31 MiB/s, done.\nResolving deltas: 100% (6007/6007), done.\nosuse-leap-42-3-2018-69:/home/intika/chrome/test # cd ungoogled-chromium/\nosuse-leap-42-3-2018-69:/home/intika/chrome/test/ungoogled-chromium # mkdir -p build/src\nosuse-leap-42-3-2018-69:/home/intika/chrome/test/ungoogled-chromium # ./get_package.py linux_simple build/src/ungoogled_packaging\nosuse-leap-42-3-2018-69:/home/intika/chrome/test/ungoogled-chromium # cd build/src\nosuse-leap-42-3-2018-69:/home/intika/chrome/test/ungoogled-chromium/build/src # ./ungoogled_packaging/build.sh\n+ BUNDLE=linux_portable\n+++ readlink -f ./ungoogled_packaging/build.sh\n++ dirname /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/build.sh\n+ DOWNLOAD_CACHE=/home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache\n+ rm -rf out\n+ mkdir out\n+ mkdir out/Default\n+++ readlink -f ./ungoogled_packaging/build.sh\n++ dirname /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/build.sh\n+ pushd /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging\n/home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging /home/intika/chrome/test/ungoogled-chromium/build/src\n+ mkdir /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache\n+ python3 -m buildkit downloads retrieve -b config_bundles/linux_portable -c /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache\n2018-09-18 14:07:37,131 - DEBUG: Initialized logger 'buildkit'\n2018-09-18 14:07:37,131 - INFO: Downloading \"chromium\" to \"chromium-69.0.3497.100.tar.xz\" ...\n2018-09-18 14:07:37,131 - INFO: Downloading /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache/chromium-69.0.3497.100.tar.xz ...\nProgress: 100.0% of 617,374,764 B\n2018-09-18 14:07:46,116 - INFO: Downloading hashes for \"chromium\"\n2018-09-18 14:07:46,116 - INFO: Downloading /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache/chromium-69.0.3497.100.tar.xz.hashes ...\nProgress: 1260.3% of 650 B\n2018-09-18 14:07:46,405 - INFO: Verifying hashes for \"chromium\" ...\n2018-09-18 14:07:46,811 - DEBUG: Verifying md5 hash...\n2018-09-18 14:07:47,964 - DEBUG: Verifying sha1 hash...\n2018-09-18 14:07:48,783 - DEBUG: Verifying sha224 hash...\n2018-09-18 14:07:50,574 - DEBUG: Verifying sha256 hash...\n2018-09-18 14:07:52,364 - DEBUG: Verifying sha384 hash...\n2018-09-18 14:07:53,559 - DEBUG: Verifying sha512 hash...\n+ python3 -m buildkit downloads unpack -b config_bundles/linux_portable -c /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache ../\n2018-09-18 14:07:54,888 - DEBUG: Initialized logger 'buildkit'\n2018-09-18 14:07:54,888 - INFO: Unpacking \"chromium\" to ./ ...\n2018-09-18 14:07:54,893 - DEBUG: Using BSD or GNU tar extractor\n2018-09-18 14:07:54,893 - DEBUG: tar command line: /bin/tar -xf /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache/chromium-69.0.3497.100.tar.xz -C ..\n+ python3 -m buildkit prune -b config_bundles/linux_portable ../\n+ python3 -m buildkit patches apply -b config_bundles/linux_portable ../\n2018-09-18 14:08:53,150 - DEBUG: Initialized logger 'buildkit'\n2018-09-18 14:08:53,150 - INFO: * Applying chromium-arflags.patch (1/116)\n2018-09-18 14:08:53,150 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/chromium-arflags.patch -d .. --no-backup-if-mismatch --forward\npatching file build/toolchain/gcc_ar_wrapper.py\npatching file build/toolchain/gcc_toolchain.gni\n2018-09-18 14:08:53,307 - INFO: * Applying chromium-clang-compiler-flags.patch (2/116)\n2018-09-18 14:08:53,307 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/chromium-clang-compiler-flags.patch -d .. --no-backup-if-mismatch --forward\npatching file build/config/compiler/BUILD.gn\n2018-09-18 14:08:53,478 - INFO: * Applying chromium-exclude_unwind_tables.patch (3/116)\n2018-09-18 14:08:53,479 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/chromium-exclude_unwind_tables.patch -d .. --no-backup-if-mismatch --forward\npatching file build/config/compiler/compiler.gni\n2018-09-18 14:08:53,631 - INFO: * Applying chromium-skia-harmony.patch (4/116)\n2018-09-18 14:08:53,631 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/chromium-skia-harmony.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/skia/src/ports/SkFontHost_FreeType.cpp\n2018-09-18 14:08:53,637 - INFO: * Applying chromium-widevine-r2.patch (5/116)\n2018-09-18 14:08:53,637 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/chromium-widevine-r2.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/widevine/cdm/stub/widevine_cdm_version.h\npatching file third_party/widevine/cdm/BUILD.gn\n2018-09-18 14:08:53,815 - INFO: * Applying disable-cfi-icall-for-va_stubs.patch (6/116)\n2018-09-18 14:08:53,815 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/disable-cfi-icall-for-va_stubs.patch -d .. --no-backup-if-mismatch --forward\npatching file tools/cfi/blacklist.txt\n2018-09-18 14:08:53,941 - INFO: * Applying fix-cfi-icall-failure-with-use_system_libjpeg-true.patch (7/116)\n2018-09-18 14:08:53,942 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/fix-cfi-icall-failure-with-use_system_libjpeg-true.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/blink/renderer/platform/image-decoders/jpeg/jpeg_image_decoder.cc\npatching file third_party/blink/renderer/platform/wtf/compiler.h\n2018-09-18 14:08:54,078 - INFO: * Applying only-disable-cfi-icall-when-use_system_libjpeg-true.patch (8/116)\n2018-09-18 14:08:54,078 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/only-disable-cfi-icall-when-use_system_libjpeg-true.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/blink/renderer/platform/image-decoders/jpeg/jpeg_image_decoder.cc\n2018-09-18 14:08:56,175 - INFO: * Applying 0001-fix-building-without-safebrowsing.patch (9/116)\n2018-09-18 14:08:56,175 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0001-fix-building-without-safebrowsing.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/chrome_content_browser_client.cc\npatching file chrome/browser/profiles/profile_impl.cc\npatching file chrome/browser/loader/chrome_resource_dispatcher_host_delegate.cc\npatching file chrome/browser/ui/webui/interstitials/interstitial_ui.cc\npatching file chrome/browser/extensions/blacklist_state_fetcher.cc\npatching file chrome/browser/extensions/blacklist_state_fetcher.h\npatching file chrome/browser/download/chrome_download_manager_delegate.cc\npatching file chrome/browser/browser_process_impl.cc\npatching file chrome/browser/browser_process_impl.h\npatching file chrome/browser/browser_process.h\npatching file chrome/browser/ui/webui/md_downloads/md_downloads_dom_handler.h\npatching file chrome/browser/ui/webui/md_downloads/md_downloads_dom_handler.cc\npatching file chrome/browser/extensions/api/downloads/downloads_api.cc\npatching file chrome/browser/extensions/api/downloads/downloads_api.h\npatching file chrome/browser/download/download_prefs.cc\npatching file chrome/browser/component_updater/file_type_policies_component_installer.cc\npatching file chrome/browser/download/download_target_determiner.cc\npatching file chrome/browser/download/download_commands.cc\npatching file chrome/browser/BUILD.gn\npatching file chrome/browser/ui/BUILD.gn\npatching file chrome/browser/ssl/security_state_tab_helper.cc\npatching file chrome/browser/browsing_data/chrome_browsing_data_remover_delegate.cc\npatching file chrome/browser/metrics/chrome_metrics_service_client.cc\npatching file chrome/browser/profiles/chrome_browser_main_extra_parts_profiles.cc\npatching file chrome/browser/ssl/captive_portal_blocking_page.cc\npatching file chrome/browser/ssl/cert_report_helper.cc\npatching file chrome/browser/ui/tab_helpers.cc\npatching file chrome/browser/subresource_filter/chrome_subresource_filter_client.cc\npatching file chrome/browser/extensions/webstore_inline_installer.cc\npatching file chrome/browser/safe_browsing/BUILD.gn\npatching file chrome/renderer/chrome_content_renderer_client.cc\npatching file chrome/renderer/chrome_content_renderer_client.h\npatching file chrome/browser/net/trial_comparison_cert_verifier.cc\npatching file chrome/browser/extensions/api/webstore_private/webstore_private_api.cc\npatching file chrome/browser/download/download_item_model.cc\npatching file components/safe_browsing/features.cc\n2018-09-18 14:08:56,293 - INFO: * Applying 0003-disable-autofill-download-manager.patch (10/116)\n2018-09-18 14:08:56,293 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0003-disable-autofill-download-manager.patch -d .. --no-backup-if-mismatch --forward\npatching file components/autofill/core/browser/autofill_download_manager.cc\n2018-09-18 14:08:56,476 - INFO: * Applying 0004-disable-google-url-tracker.patch (11/116)\n2018-09-18 14:08:56,476 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0004-disable-google-url-tracker.patch -d .. --no-backup-if-mismatch --forward\npatching file components/google/core/browser/google_url_tracker.cc\n2018-09-18 14:08:56,482 - INFO: * Applying 0005-disable-default-extensions.patch (12/116)\n2018-09-18 14:08:56,482 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0005-disable-default-extensions.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/extensions/component_loader.cc\npatching file chrome/browser/extensions/external_component_loader.cc\npatching file chrome/browser/extensions/webstore_installer.cc\npatching file chrome/browser/extensions/component_extensions_whitelist/whitelist.cc\n2018-09-18 14:08:56,575 - INFO: * Applying 0006-modify-default-prefs.patch (13/116)\n2018-09-18 14:08:56,576 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0006-modify-default-prefs.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/chrome_content_browser_client.cc\npatching file chrome/browser/ui/browser_ui_prefs.cc\npatching file chrome/browser/net/prediction_options.cc\npatching file chrome/browser/net/prediction_options.h\npatching file chrome/browser/background/background_mode_manager.cc\npatching file components/content_settings/core/browser/cookie_settings.cc\npatching file chrome/browser/ui/navigation_correction_tab_observer.cc\npatching file components/autofill/core/browser/autofill_manager.cc\npatching file chrome/browser/resources/settings/reset_page/reset_profile_dialog.html\npatching file chrome/browser/signin/signin_promo.cc\npatching file components/bookmarks/browser/bookmark_utils.cc\npatching file chrome/browser/profiles/profile.cc\npatching file chrome/service/cloud_print/connector_settings.cc\npatching file chrome/browser/ui/webui/local_discovery/local_discovery_ui.cc\npatching file extensions/common/extension.cc\npatching file components/safe_browsing/common/safe_browsing_prefs.cc\npatching file components/password_manager/core/browser/password_manager.cc\npatching file components/payments/core/payment_prefs.cc\n2018-09-18 14:08:56,639 - INFO: * Applying 0007-disable-web-resource-service.patch (14/116)\n2018-09-18 14:08:56,639 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0007-disable-web-resource-service.patch -d .. --no-backup-if-mismatch --forward\npatching file components/web_resource/web_resource_service.cc\n2018-09-18 14:08:56,734 - INFO: * Applying 0008-restore-classic-ntp.patch (15/116)\n2018-09-18 14:08:56,734 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0008-restore-classic-ntp.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/search/search.cc\npatching file components/ntp_snippets/features.cc\n2018-09-18 14:08:56,855 - INFO: * Applying 0009-disable-google-ipv6-probes.patch (16/116)\n2018-09-18 14:08:56,855 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0009-disable-google-ipv6-probes.patch -d .. --no-backup-if-mismatch --forward\npatching file net/dns/host_resolver_impl.cc\n2018-09-18 14:08:57,007 - INFO: * Applying 0010-disable-gcm-status-check.patch (17/116)\n2018-09-18 14:08:57,007 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0010-disable-gcm-status-check.patch -d .. --no-backup-if-mismatch --forward\npatching file components/gcm_driver/gcm_channel_status_request.cc\n2018-09-18 14:08:57,160 - INFO: * Applying 0011-add-duckduckgo-search-engine.patch (18/116)\n2018-09-18 14:08:57,161 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0011-add-duckduckgo-search-engine.patch -d .. --no-backup-if-mismatch --forward\npatching file components/search_engines/prepopulated_engines.json\npatching file components/search_engines/search_engine_type.h\npatching file components/search_engines/template_url_prepopulate_data.cc\n2018-09-18 14:08:57,243 - INFO: * Applying 0013-disable-missing-key-warning.patch (19/116)\n2018-09-18 14:08:57,243 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0013-disable-missing-key-warning.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/ui/startup/google_api_keys_infobar_delegate.cc\n2018-09-18 14:08:57,282 - INFO: * Applying 0014-disable-translation-lang-fetch.patch (20/116)\n2018-09-18 14:08:57,283 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0014-disable-translation-lang-fetch.patch -d .. --no-backup-if-mismatch --forward\npatching file components/translate/core/browser/translate_language_list.cc\npatching file chrome/browser/spellchecker/spellcheck_hunspell_dictionary.cc\npatching file components/translate/core/browser/translate_ranker_impl.cc\n2018-09-18 14:08:57,341 - INFO: * Applying 0015-disable-update-pings.patch (21/116)\n2018-09-18 14:08:57,341 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0015-disable-update-pings.patch -d .. --no-backup-if-mismatch --forward\npatching file components/component_updater/configurator_impl.cc\n2018-09-18 14:08:57,393 - INFO: * Applying 0016-chromium-sandbox-pie.patch (22/116)\n2018-09-18 14:08:57,393 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0016-chromium-sandbox-pie.patch -d .. --no-backup-if-mismatch --forward\npatching file sandbox/linux/BUILD.gn\n2018-09-18 14:08:57,474 - INFO: * Applying 0017-disable-new-avatar-menu.patch (23/116)\n2018-09-18 14:08:57,475 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0017-disable-new-avatar-menu.patch -d .. --no-backup-if-mismatch --forward\npatching file components/signin/core/browser/signin_manager.cc\n2018-09-18 14:08:57,510 - INFO: * Applying 0018-disable-first-run-behaviour.patch (24/116)\n2018-09-18 14:08:57,511 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0018-disable-first-run-behaviour.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/ui/startup/startup_tab_provider.cc\n2018-09-18 14:08:57,630 - INFO: * Applying 0019-disable-battery-status-service.patch (25/116)\n2018-09-18 14:08:57,630 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0019-disable-battery-status-service.patch -d .. --no-backup-if-mismatch --forward\npatching file services/device/battery/battery_status_service.cc\npatching file services/device/battery/battery_status_service.h\n2018-09-18 14:08:57,699 - INFO: * Applying 0021-disable-rlz.patch (26/116)\n2018-09-18 14:08:57,699 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/0021-disable-rlz.patch -d .. --no-backup-if-mismatch --forward\npatching file rlz/buildflags/buildflags.gni\n2018-09-18 14:08:57,837 - INFO: * Applying parallel.patch (27/116)\n2018-09-18 14:08:57,837 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/gn/parallel.patch -d .. --no-backup-if-mismatch --forward\npatching file tools/gn/bootstrap/bootstrap.py\n2018-09-18 14:08:57,949 - INFO: * Applying skia.patch (28/116)\n2018-09-18 14:08:57,950 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/arm/skia.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/skia/src/opts/SkRasterPipeline_opts.h\n2018-09-18 14:08:57,956 - INFO: * Applying gcc_skcms_ice.patch (29/116)\n2018-09-18 14:08:57,956 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/arm/gcc_skcms_ice.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/skia/third_party/skcms/skcms.gni\n2018-09-18 14:08:58,017 - INFO: * Applying mojo.patch (30/116)\n2018-09-18 14:08:58,018 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/mojo.patch -d .. --no-backup-if-mismatch --forward\npatching file content/shell/BUILD.gn\npatching file content/shell/browser/layout_test/layout_test_content_browser_client.cc\npatching file chromecast/common/mojom/typemaps.gni\n2018-09-18 14:08:58,135 - INFO: * Applying sizet.patch (31/116)\n2018-09-18 14:08:58,135 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/sizet.patch -d .. --no-backup-if-mismatch --forward\npatching file media/base/subsample_entry.h\n2018-09-18 14:08:58,240 - INFO: * Applying optimize.patch (32/116)\n2018-09-18 14:08:58,240 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/optimize.patch -d .. --no-backup-if-mismatch --forward\npatching file build/config/compiler/BUILD.gn\n2018-09-18 14:08:58,358 - INFO: * Applying ps-print.patch (33/116)\n2018-09-18 14:08:58,358 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/ps-print.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/ui/libgtkui/print_dialog_gtk.cc\n2018-09-18 14:08:58,471 - INFO: * Applying as-needed.patch (34/116)\n2018-09-18 14:08:58,471 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/as-needed.patch -d .. --no-backup-if-mismatch --forward\npatching file build/config/compiler/BUILD.gn\n2018-09-18 14:08:59,132 - INFO: * Applying inspector.patch (35/116)\n2018-09-18 14:08:59,133 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/inspector.patch -d .. --no-backup-if-mismatch --forward\npatching file v8/src/inspector/BUILD.gn\n2018-09-18 14:08:59,219 - INFO: * Applying gpu-timeout.patch (36/116)\n2018-09-18 14:08:59,220 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/gpu-timeout.patch -d .. --no-backup-if-mismatch --forward\npatching file gpu/ipc/service/gpu_watchdog_thread.cc\n2018-09-18 14:09:00,138 - INFO: * Applying empty-array.patch (37/116)\n2018-09-18 14:09:00,139 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/empty-array.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/blink/renderer/platform/text/character_property_data_generator.h\n2018-09-18 14:09:00,141 - INFO: * Applying ownership-error.patch (38/116)\n2018-09-18 14:09:00,141 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/ownership-error.patch -d .. --no-backup-if-mismatch --forward\npatching file services/resource_coordinator/coordination_unit/coordination_unit_base.cc\n2018-09-18 14:09:00,144 - INFO: * Applying widevine-locations.patch (39/116)\n2018-09-18 14:09:00,144 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/widevine-locations.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/common/chrome_paths.cc\n2018-09-18 14:09:00,147 - INFO: * Applying connection-message.patch (40/116)\n2018-09-18 14:09:00,147 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/fixes/connection-message.patch -d .. --no-backup-if-mismatch --forward\npatching file components/error_page_strings.grdp\n2018-09-18 14:09:00,149 - INFO: * Applying android.patch (41/116)\n2018-09-18 14:09:00,150 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/disable/android.patch -d .. --no-backup-if-mismatch --forward\npatching file device/vr/buildflags/buildflags.gni\npatching file BUILD.gn\n2018-09-18 14:09:00,153 - INFO: * Applying fuzzers.patch (42/116)\n2018-09-18 14:09:00,153 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/disable/fuzzers.patch -d .. --no-backup-if-mismatch --forward\npatching file BUILD.gn\npatching file content/test/BUILD.gn\npatching file v8/tools/BUILD.gn\n2018-09-18 14:09:00,550 - INFO: * Applying perfetto.patch (43/116)\n2018-09-18 14:09:00,551 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/disable/perfetto.patch -d .. --no-backup-if-mismatch --forward\npatching file BUILD.gn\npatching file services/tracing/BUILD.gn\npatching file services/tracing/tracing_service.h\npatching file services/tracing/public/cpp/BUILD.gn\npatching file services/tracing/public/cpp/trace_event_agent.cc\n2018-09-18 14:09:00,726 - INFO: * Applying welcome-page.patch (44/116)\n2018-09-18 14:09:00,726 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/disable/welcome-page.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/profiles/profile_manager.cc\n2018-09-18 14:09:00,919 - INFO: * Applying google-api-warning.patch (45/116)\n2018-09-18 14:09:00,919 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/disable/google-api-warning.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/ui/startup/startup_browser_creator_impl.cc\n2018-09-18 14:09:01,155 - INFO: * Applying device-notifications.patch (46/116)\n2018-09-18 14:09:01,156 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/disable/device-notifications.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/printing/cloud_print/privet_notifications.cc\n2018-09-18 14:09:01,258 - INFO: * Applying swiftshader.patch (47/116)\n2018-09-18 14:09:01,259 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/disable/swiftshader.patch -d .. --no-backup-if-mismatch --forward\npatching file BUILD.gn\n2018-09-18 14:09:01,440 - INFO: * Applying attribute.patch (48/116)\n2018-09-18 14:09:01,440 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/warnings/attribute.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/s2cellid/src/s2/util/math/vector.h\npatching file third_party/s2cellid/src/s2/s1angle.h\n2018-09-18 14:09:01,638 - INFO: * Applying enum-compare.patch (49/116)\n2018-09-18 14:09:01,638 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/warnings/enum-compare.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/ui/views/passwords/password_generation_popup_view_views.cc\npatching file ui/aura/hit_test_data_provider_aura.cc\n2018-09-18 14:09:01,770 - INFO: * Applying initialization.patch (50/116)\n2018-09-18 14:09:01,770 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/warnings/initialization.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/cacheinvalidation/src/google/cacheinvalidation/include/types.h\n2018-09-18 14:09:01,904 - INFO: * Applying multichar.patch (51/116)\n2018-09-18 14:09:01,904 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/warnings/multichar.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/crashpad/crashpad/BUILD.gn\n2018-09-18 14:09:01,997 - INFO: * Applying null-destination.patch (52/116)\n2018-09-18 14:09:01,997 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/warnings/null-destination.patch -d .. --no-backup-if-mismatch --forward\npatching file base/strings/stringprintf.cc\n2018-09-18 14:09:02,114 - INFO: * Applying printf.patch (53/116)\n2018-09-18 14:09:02,115 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/warnings/printf.patch -d .. --no-backup-if-mismatch --forward\npatching file ui/gfx/ipc/buffer_types/gfx_param_traits.cc\npatching file content/browser/web_package/signed_exchange_handler.cc\n2018-09-18 14:09:02,236 - INFO: * Applying sequence-point.patch (54/116)\n2018-09-18 14:09:02,236 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/warnings/sequence-point.patch -d .. --no-backup-if-mismatch --forward\npatching file headless/lib/browser/protocol/browser_handler.cc\n2018-09-18 14:09:02,567 - INFO: * Applying unused-typedefs.patch (55/116)\n2018-09-18 14:09:02,567 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/warnings/unused-typedefs.patch -d .. --no-backup-if-mismatch --forward\npatching file build/config/linux/atk/BUILD.gn\n2018-09-18 14:09:02,638 - INFO: * Applying fontconfig.patch (56/116)\n2018-09-18 14:09:02,639 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/debian/system/fontconfig.patch -d .. --no-backup-if-mismatch --forward\npatching file base/test/BUILD.gn\npatching file content/shell/test_runner/BUILD.gn\n2018-09-18 14:09:02,768 - INFO: * Applying net-cert-increase-default-key-length-for-newly-gener.patch (57/116)\n2018-09-18 14:09:02,769 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/net-cert-increase-default-key-length-for-newly-gener.patch -d .. --no-backup-if-mismatch --forward\npatching file net/cert/x509_util.cc\n2018-09-18 14:09:02,990 - INFO: * Applying mime_util-force-text-x-suse-ymp-to-be-downloaded.patch (58/116)\n2018-09-18 14:09:02,991 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/mime_util-force-text-x-suse-ymp-to-be-downloaded.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/blink/common/mime_util/mime_util.cc\n2018-09-18 14:09:03,352 - INFO: * Applying prefs-only-keep-cookies-until-exit.patch (59/116)\n2018-09-18 14:09:03,352 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/prefs-only-keep-cookies-until-exit.patch -d .. --no-backup-if-mismatch --forward\npatching file components/content_settings/core/browser/content_settings_registry.cc\n2018-09-18 14:09:03,489 - INFO: * Applying prefs-always-prompt-for-download-directory-by-defaul.patch (60/116)\n2018-09-18 14:09:03,489 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/prefs-always-prompt-for-download-directory-by-defaul.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/download/download_prefs.cc\n2018-09-18 14:09:03,605 - INFO: * Applying updater-disable-auto-update.patch (61/116)\n2018-09-18 14:09:03,606 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/updater-disable-auto-update.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/app_controller_mac.mm\n2018-09-18 14:09:03,653 - INFO: * Applying Remove-EV-certificates.patch (62/116)\n2018-09-18 14:09:03,653 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/Remove-EV-certificates.patch -d .. --no-backup-if-mismatch --forward\npatching file net/cert/ev_root_ca_metadata.cc\n2018-09-18 14:09:03,709 - INFO: * Applying safe_browsing-disable-incident-reporting.patch (63/116)\n2018-09-18 14:09:03,709 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/safe_browsing-disable-incident-reporting.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/safe_browsing/incident_reporting/incident_report_uploader_impl.cc\npatching file chrome/browser/safe_browsing/incident_reporting/incident_reporting_service.cc\npatching file chrome/browser/safe_browsing/safe_browsing_blocking_page.cc\npatching file chrome/browser/safe_browsing/safe_browsing_service.cc\npatching file components/security_interstitials/core/safe_browsing_loud_error_ui.cc\n2018-09-18 14:09:03,720 - INFO: * Applying safe_browsing-disable-reporting-of-safebrowsing-over.patch (64/116)\n2018-09-18 14:09:03,720 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/safe_browsing-disable-reporting-of-safebrowsing-over.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/safe_browsing/client_side_detection_service.cc\n2018-09-18 14:09:03,859 - INFO: * Applying safe_browsing-support-trk-prefix.patch (65/116)\n2018-09-18 14:09:03,859 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/safe_browsing-support-trk-prefix.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/safe_browsing/protocol_manager.cc\n2018-09-18 14:09:03,985 - INFO: * Applying all-add-trk-prefixes-to-possibly-evil-connections.patch (66/116)\n2018-09-18 14:09:03,985 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/all-add-trk-prefixes-to-possibly-evil-connections.patch -d .. --no-backup-if-mismatch --forward\npatching file build/mac/tweak_info_plist.py\npatching file chrome/browser/chromeos/customization/customization_document.cc\npatching file chrome/browser/chromeos/extensions/file_manager/private_api_drive.cc\npatching file chrome/browser/chromeos/extensions/file_manager/private_api_misc.cc\npatching file chrome/browser/chromeos/extensions/file_manager/private_api_strings.cc\npatching file chrome/browser/extensions/api/cryptotoken_private/cryptotoken_private_api.cc\npatching file chrome/browser/extensions/install_signer.cc\npatching file chrome/browser/nacl_host/nacl_infobar_delegate.cc\npatching file chrome/browser/net/predictor.cc\npatching file chrome/browser/profiles/profile_avatar_downloader.cc\npatching file chrome/browser/resources/chromeos/chromevox/chromevox/background/prefs.js\npatching file chrome/browser/resources/default_apps/external_extensions.json\npatching file chrome/browser/safe_browsing/client_side_detection_service.cc\npatching file chrome/browser/safe_browsing/download_protection/download_feedback.cc\npatching file components/safe_search_api/url_checker.cc\npatching file chrome/browser/spellchecker/spellcheck_hunspell_dictionary.cc\npatching file chrome/browser/supervised_user/supervised_user_service.cc\npatching file chrome/browser/tracing/crash_service_uploader.cc\npatching file chrome/browser/ui/views/outdated_upgrade_bubble_view.cc\npatching file chrome/browser/ui/webui/ntp/ntp_resource_cache.cc\npatching file chrome/common/extensions/chrome_extensions_client.cc\npatching file chrome/common/url_constants.cc\npatching file chrome/installer/util/google_chrome_distribution.cc\npatching file chromecast/browser/service/cast_service_simple.cc\npatching file chromeos/geolocation/simple_geolocation_provider.cc\npatching file components/cloud_devices/common/cloud_devices_urls.cc\npatching file components/crash/content/app/breakpad_linux.cc\npatching file components/drive/service/drive_api_service.cc\npatching file components/feedback/feedback_uploader.cc\npatching file components/gcm_driver/gcm_account_tracker.cc\npatching file components/history/core/browser/web_history_service.cc\npatching file components/invalidation/impl/gcm_network_channel.cc\npatching file components/invalidation/impl/p2p_invalidator.cc\npatching file components/metrics/url_constants.cc\npatching file components/password_manager/core/browser/password_store.cc\npatching file components/policy/core/common/policy_loader_win.cc\npatching file components/policy/resources/policy_templates.json\npatching file components/rappor/rappor_service_impl.cc\npatching file components/search_engines/prepopulated_engines.json\npatching file components/translate/core/browser/translate_url_fetcher.cc\npatching file components/translate/core/common/translate_util.cc\npatching file components/variations/variations_url_constants.cc\npatching file content/browser/speech/speech_recognition_engine.cc\npatching file content/shell/browser/shell_browser_main_parts.cc\npatching file google_apis/gaia/gaia_constants.cc\npatching file google_apis/gaia/google_service_auth_error.cc\npatching file google_apis/gcm/engine/gservices_settings.cc\npatching file jingle/notifier/base/gaia_token_pre_xmpp_auth.cc\npatching file remoting/base/breakpad_mac.mm\npatching file remoting/protocol/jingle_messages.cc\npatching file remoting/webapp/base/js/xmpp_login_handler.js\npatching file remoting/webapp/crd/manifest.json.jinja2\npatching file ui/views/examples/webview_example.cc\npatching file extensions/browser/updater/safe_manifest_parser.cc\npatching file extensions/common/extension_urls.cc\n2018-09-18 14:09:06,203 - INFO: * Applying promo-disable-Google-promotion-fetching.patch (67/116)\n2018-09-18 14:09:06,204 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/promo-disable-Google-promotion-fetching.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/signin/signin_promo.cc\n2018-09-18 14:09:06,441 - INFO: * Applying browser-disable-profile-auto-import-on-first-run.patch (68/116)\n2018-09-18 14:09:06,442 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/iridium-browser/browser-disable-profile-auto-import-on-first-run.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/chrome_browser_main.cc\n2018-09-18 14:09:06,631 - INFO: * Applying add-third-party-ungoogled.patch (69/116)\n2018-09-18 14:09:06,632 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/add-third-party-ungoogled.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/ungoogled/BUILD.gn\npatching file third_party/ungoogled/ungoogled_switches.cc\npatching file third_party/ungoogled/ungoogled_switches.h\n2018-09-18 14:09:06,634 - INFO: * Applying clear-http-auth-cache-menu-item.patch (70/116)\n2018-09-18 14:09:06,635 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/clear-http-auth-cache-menu-item.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/app/chrome_command_ids.h\npatching file chrome/app/generated_resources.grd\npatching file chrome/browser/ui/toolbar/app_menu_model.cc\npatching file chrome/browser/ui/toolbar/app_menu_model.h\npatching file chrome/browser/ui/views/frame/global_menu_bar_x11.cc\npatching file chrome/browser/ui/browser_command_controller.cc\npatching file tools/metrics/histograms/histograms.xml\npatching file net/http/http_auth_cache.cc\npatching file net/http/http_auth_cache.h\npatching file tools/metrics/histograms/enums.xml\n2018-09-18 14:09:06,776 - INFO: * Applying disable-crash-reporter.patch (71/116)\n2018-09-18 14:09:06,776 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-crash-reporter.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/breakpad/breakpad/src/client/linux/sender/google_crash_report_sender.cc\npatching file chrome/browser/tracing/crash_service_uploader.cc\n2018-09-18 14:09:06,919 - INFO: * Applying disable-formatting-in-omnibox.patch (72/116)\n2018-09-18 14:09:06,919 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-formatting-in-omnibox.patch -d .. --no-backup-if-mismatch --forward\npatching file components/url_formatter/url_formatter.cc\n2018-09-18 14:09:07,191 - INFO: * Applying disable-google-host-detection.patch (73/116)\n2018-09-18 14:09:07,192 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-google-host-detection.patch -d .. --no-backup-if-mismatch --forward\npatching file net/base/url_util.cc\npatching file components/variations/net/variations_http_headers.cc\npatching file chrome/browser/page_load_metrics/page_load_metrics_util.cc\npatching file components/search_engines/template_url.cc\npatching file components/google/core/browser/google_util.cc\npatching file chrome/common/page_load_metrics/page_load_metrics_util.cc\n2018-09-18 14:09:07,476 - INFO: * Applying replace-google-search-engine-with-nosearch.patch (74/116)\n2018-09-18 14:09:07,476 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/replace-google-search-engine-with-nosearch.patch -d .. --no-backup-if-mismatch --forward\npatching file components/search_engines/prepopulated_engines.json\n2018-09-18 14:09:07,763 - INFO: * Applying disable-signin.patch (75/116)\n2018-09-18 14:09:07,763 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-signin.patch -d .. --no-backup-if-mismatch --forward\npatching file components/signin/core/browser/signin_manager_base.cc\npatching file chrome/browser/ui/chrome_pages.cc\n2018-09-18 14:09:08,003 - INFO: * Applying disable-translate.patch (76/116)\n2018-09-18 14:09:08,003 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-translate.patch -d .. --no-backup-if-mismatch --forward\npatching file components/translate/core/browser/translate_manager.cc\npatching file components/translate/content/renderer/translate_helper.cc\npatching file components/translate/core/browser/translate_script.cc\n2018-09-18 14:09:08,167 - INFO: * Applying popups-to-tabs.patch (77/116)\n2018-09-18 14:09:08,167 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/popups-to-tabs.patch -d .. --no-backup-if-mismatch --forward\npatching file content/renderer/render_view_impl.cc\n2018-09-18 14:09:08,313 - INFO: * Applying disable-untraceable-urls.patch (78/116)\n2018-09-18 14:09:08,313 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-untraceable-urls.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/plugins/plugins_resource_service.cc\npatching file chrome/browser/safe_browsing/client_side_model_loader.cc\npatching file chrome/browser/safe_browsing/client_side_model_loader.h\npatching file rlz/lib/lib_values.cc\npatching file rlz/lib/lib_values.h\npatching file rlz/lib/financial_ping.cc\n2018-09-18 14:09:08,488 - INFO: * Applying add-ipv6-probing-option.patch (79/116)\n2018-09-18 14:09:08,488 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/add-ipv6-probing-option.patch -d .. --no-backup-if-mismatch --forward\npatching file net/dns/host_resolver_impl.cc\n2018-09-18 14:09:08,662 - INFO: * Applying disable-profile-avatar-downloading.patch (80/116)\n2018-09-18 14:09:08,663 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-profile-avatar-downloading.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/profiles/profile_avatar_downloader.cc\n2018-09-18 14:09:08,747 - INFO: * Applying remove-disable-setuid-sandbox-as-bad-flag.patch (81/116)\n2018-09-18 14:09:08,747 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/remove-disable-setuid-sandbox-as-bad-flag.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/ui/startup/bad_flags_prompt.cc\n2018-09-18 14:09:08,921 - INFO: * Applying disable-gcm.patch (82/116)\n2018-09-18 14:09:08,921 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-gcm.patch -d .. --no-backup-if-mismatch --forward\npatching file components/gcm_driver/gcm_client_impl.cc\n2018-09-18 14:09:09,070 - INFO: * Applying disable-domain-reliability.patch (83/116)\n2018-09-18 14:09:09,070 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-domain-reliability.patch -d .. --no-backup-if-mismatch --forward\npatching file components/domain_reliability/google_configs.cc\npatching file components/domain_reliability/uploader.cc\npatching file components/domain_reliability/bake_in_configs.py\npatching file components/domain_reliability/BUILD.gn\n2018-09-18 14:09:09,243 - INFO: * Applying block-trk-and-subdomains.patch (84/116)\n2018-09-18 14:09:09,244 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/block-trk-and-subdomains.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/autocomplete/chrome_autocomplete_scheme_classifier.cc\npatching file chrome/browser/history/history_utils.cc\npatching file chrome/browser/ui/singleton_tabs.cc\npatching file components/omnibox/browser/autocomplete_input.cc\npatching file content/browser/child_process_security_policy_impl.cc\npatching file net/url_request/url_request.cc\npatching file url/url_constants.cc\npatching file url/url_constants.h\npatching file components/url_formatter/url_fixer.cc\npatching file net/BUILD.gn\npatching file android_webview/browser/net/aw_url_request_context_getter.cc\npatching file chrome/browser/profiles/profile_io_data.cc\npatching file chromecast/browser/url_request_context_factory.cc\npatching file net/url_request/trk_protocol_handler.cc\npatching file net/url_request/trk_protocol_handler.h\npatching file net/url_request/url_request_context_builder.cc\npatching file url/url_util.cc\n2018-09-18 14:09:09,396 - INFO: * Applying disable-intranet-redirect-detector.patch (85/116)\n2018-09-18 14:09:09,396 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-intranet-redirect-detector.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/intranet_redirect_detector.cc\n2018-09-18 14:09:10,420 - INFO: * Applying fix-building-without-one-click-signin.patch (86/116)\n2018-09-18 14:09:10,420 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/fix-building-without-one-click-signin.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/ui/sync/one_click_signin_sync_starter.cc\npatching file chrome/browser/ui/sync/one_click_signin_links_delegate_impl.cc\npatching file chrome/browser/ui/BUILD.gn\n2018-09-18 14:09:10,530 - INFO: * Applying enable-page-saving-on-more-pages.patch (87/116)\n2018-09-18 14:09:10,530 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/enable-page-saving-on-more-pages.patch -d .. --no-backup-if-mismatch --forward\npatching file content/public/common/url_utils.cc\npatching file chrome/browser/ui/browser_commands.cc\npatching file components/offline_pages/core/offline_page_model.cc\npatching file content/common/url_schemes.cc\n2018-09-18 14:09:10,709 - INFO: * Applying disable-download-quarantine.patch (88/116)\n2018-09-18 14:09:10,710 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-download-quarantine.patch -d .. --no-backup-if-mismatch --forward\npatching file content/browser/renderer_host/pepper/pepper_file_io_host.cc\npatching file content/browser/renderer_host/pepper/pepper_file_io_host.h\npatching file components/download/internal/common/base_file.cc\npatching file components/download/quarantine/quarantine.cc\npatching file content/browser/BUILD.gn\n2018-09-18 14:09:10,924 - INFO: * Applying disable-gaia.patch (89/116)\n2018-09-18 14:09:10,924 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-gaia.patch -d .. --no-backup-if-mismatch --forward\npatching file google_apis/gaia/gaia_auth_fetcher.cc\npatching file chrome/browser/resources/component_extension_resources.grd\npatching file chrome/browser/extensions/signin/gaia_auth_extension_loader.cc\npatching file chrome/browser/extensions/component_extensions_whitelist/whitelist.cc\npatching file chrome/browser/ui/webui/signin/inline_login_ui.cc\npatching file chrome/browser/browser_resources.grd\n2018-09-18 14:09:11,107 - INFO: * Applying disable-fonts-googleapis-references.patch (90/116)\n2018-09-18 14:09:11,107 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-fonts-googleapis-references.patch -d .. --no-backup-if-mismatch --forward\npatching file components/dom_distiller/content/browser/dom_distiller_viewer_source.cc\npatching file components/dom_distiller/core/html/preview.html\npatching file third_party/catapult/third_party/polymer/components/font-roboto/roboto.html\npatching file third_party/catapult/tracing/third_party/gl-matrix/jsdoc-template/static/default.css\npatching file third_party/crashpad/crashpad/doc/support/crashpad_doxygen.css\npatching file third_party/flatbuffers/src/docs/header.html\npatching file components/dom_distiller/core/javascript/dom_distiller_viewer.js\npatching file tools/md_browser/base.css\n2018-09-18 14:09:11,355 - INFO: * Applying disable-webstore-urls.patch (91/116)\n2018-09-18 14:09:11,355 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-webstore-urls.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/extensions/chrome_content_verifier_delegate.cc\npatching file extensions/common/extension_urls.cc\npatching file extensions/browser/updater/extension_downloader.cc\npatching file chrome/browser/extensions/extension_migrator.cc\npatching file chrome/browser/extensions/extension_migrator.h\n2018-09-18 14:09:11,508 - INFO: * Applying fix-learn-doubleclick-hsts.patch (92/116)\n2018-09-18 14:09:11,508 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/fix-learn-doubleclick-hsts.patch -d .. --no-backup-if-mismatch --forward\npatching file net/tools/transport_security_state_generator/transport_security_state_generator.cc\n2018-09-18 14:09:11,659 - INFO: * Applying disable-webrtc-log-uploader.patch (93/116)\n2018-09-18 14:09:11,660 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-webrtc-log-uploader.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/media/webrtc/webrtc_log_uploader.cc\n2018-09-18 14:09:11,801 - INFO: * Applying fix-building-without-mdns-and-service-discovery.patch (94/116)\n2018-09-18 14:09:11,801 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/fix-building-without-mdns-and-service-discovery.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/media/router/discovery/mdns/dns_sd_device_lister.cc\n2018-09-18 14:09:11,993 - INFO: * Applying use-local-devtools-files.patch (95/116)\n2018-09-18 14:09:11,994 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/use-local-devtools-files.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/blink/renderer/devtools/BUILD.gn\npatching file third_party/blink/renderer/devtools/front_end/audits2_worker.json\npatching file third_party/blink/renderer/devtools/front_end/devtools_app.json\npatching file third_party/blink/renderer/devtools/front_end/shell.json\npatching file third_party/blink/renderer/devtools/front_end/worker_app.json\n2018-09-18 14:09:12,136 - INFO: * Applying add-flag-to-stack-tabs.patch (96/116)\n2018-09-18 14:09:12,136 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/add-flag-to-stack-tabs.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/ui/views/tabs/browser_tab_strip_controller.cc\npatching file chrome/browser/about_flags.cc\n2018-09-18 14:09:12,232 - INFO: * Applying add-flag-to-configure-extension-downloading.patch (97/116)\n2018-09-18 14:09:12,232 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/add-flag-to-configure-extension-downloading.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/about_flags.cc\npatching file chrome/browser/download/download_crx_util.cc\npatching file chrome/browser/extensions/extension_management.cc\npatching file chrome/browser/download/download_crx_util.h\npatching file chrome/browser/download/download_target_determiner.cc\n2018-09-18 14:09:13,360 - INFO: * Applying disable-network-time-tracker.patch (98/116)\n2018-09-18 14:09:13,361 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-network-time-tracker.patch -d .. --no-backup-if-mismatch --forward\npatching file components/network_time/network_time_tracker.cc\n2018-09-18 14:09:13,390 - INFO: * Applying add-flag-for-search-engine-collection.patch (99/116)\n2018-09-18 14:09:13,390 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/add-flag-for-search-engine-collection.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/about_flags.cc\npatching file chrome/renderer/chrome_render_frame_observer.cc\npatching file chrome/renderer/chrome_render_frame_observer.h\npatching file components/search_engines/template_url_service.cc\npatching file components/search_engines/template_url_service.h\n2018-09-18 14:09:13,635 - INFO: * Applying add-flag-to-disable-beforeunload.patch (100/116)\n2018-09-18 14:09:13,635 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/add-flag-to-disable-beforeunload.patch -d .. --no-backup-if-mismatch --forward\npatching file components/app_modal/javascript_dialog_manager.cc\n2018-09-18 14:09:13,858 - INFO: * Applying add-flag-to-enable-potentially-annoying-security-features.patch (101/116)\n2018-09-18 14:09:13,858 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/add-flag-to-enable-potentially-annoying-security-features.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/about_flags.cc\n2018-09-18 14:09:14,243 - INFO: * Applying disable-mei-preload.patch (102/116)\n2018-09-18 14:09:14,243 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-mei-preload.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/BUILD.gn\n2018-09-18 14:09:16,688 - INFO: * Applying add-flag-to-force-punycode-hostnames.patch (103/116)\n2018-09-18 14:09:16,689 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/add-flag-to-force-punycode-hostnames.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/about_flags.cc\npatching file components/url_formatter/url_formatter.cc\n2018-09-18 14:09:16,693 - INFO: * Applying fix-building-without-safebrowsing.patch (104/116)\n2018-09-18 14:09:16,693 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/fix-building-without-safebrowsing.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/chrome_content_browser_client.cc\npatching file chrome/browser/ui/cocoa/download/download_item_controller.mm\npatching file chrome/browser/download/download_item_model.cc\npatching file chrome/browser/ui/views/safe_browsing/password_reuse_modal_warning_dialog.cc\n2018-09-18 14:09:16,697 - INFO: * Applying searx.patch (105/116)\n2018-09-18 14:09:16,697 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/searx.patch -d .. --no-backup-if-mismatch --forward\npatching file components/search_engines/prepopulated_engines.json\npatching file components/search_engines/search_engine_type.h\npatching file components/search_engines/template_url_prepopulate_data.cc\n2018-09-18 14:09:16,745 - INFO: * Applying remove-third-party-analytics.patch (106/116)\n2018-09-18 14:09:16,746 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/remove-third-party-analytics.patch -d .. --no-backup-if-mismatch --forward\npatching file ui/webui/resources/webui_resources.grd\n2018-09-18 14:09:16,766 - INFO: * Applying gn-bootstrap-remove-gn-gen.patch (107/116)\n2018-09-18 14:09:16,766 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/gn-bootstrap-remove-gn-gen.patch -d .. --no-backup-if-mismatch --forward\npatching file tools/gn/bootstrap/bootstrap.py\n2018-09-18 14:09:17,269 - INFO: * Applying disable-webgl-renderer-info.patch (108/116)\n2018-09-18 14:09:17,269 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/disable-webgl-renderer-info.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/blink/renderer/modules/webgl/webgl_rendering_context_base.cc\n2018-09-18 14:09:17,457 - INFO: * Applying fingerprinting-flags-client-rects-and-measuretext.patch (109/116)\n2018-09-18 14:09:17,457 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/bromite/fingerprinting-flags-client-rects-and-measuretext.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/about_flags.cc\npatching file content/child/runtime_features.cc\npatching file third_party/blink/renderer/core/dom/document.cc\npatching file third_party/blink/renderer/core/dom/document.h\npatching file third_party/blink/renderer/core/dom/element.cc\npatching file third_party/blink/renderer/core/dom/range.cc\npatching file third_party/blink/renderer/platform/runtime_enabled_features.json5\npatching file third_party/blink/renderer/platform/exported/web_runtime_features.cc\npatching file third_party/blink/public/platform/web_runtime_features.h\npatching file chrome/browser/BUILD.gn\npatching file content/browser/BUILD.gn\npatching file content/browser/renderer_host/render_process_host_impl.cc\npatching file content/child/BUILD.gn\npatching file third_party/blink/renderer/platform/BUILD.gn\npatching file third_party/blink/renderer/modules/canvas/canvas2d/canvas_rendering_context_2d.cc\npatching file third_party/blink/renderer/core/html/canvas/text_metrics.h\npatching file third_party/blink/renderer/core/html/canvas/text_metrics.cc\n2018-09-18 14:09:17,852 - INFO: * Applying flag-max-connections-per-host.patch (110/116)\n2018-09-18 14:09:17,852 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/bromite/flag-max-connections-per-host.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/about_flags.cc\npatching file chrome/browser/flag_descriptions.cc\npatching file chrome/browser/flag_descriptions.h\npatching file components/network_session_configurator/common/network_features.cc\npatching file components/network_session_configurator/common/network_features.h\npatching file components/network_session_configurator/common/network_switch_list.h\npatching file chrome/browser/browser_process_impl.cc\npatching file chrome/browser/BUILD.gn\n2018-09-18 14:09:18,607 - INFO: * Applying flag-fingerprinting-canvas-image-data-noise.patch (111/116)\n2018-09-18 14:09:18,607 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/bromite/flag-fingerprinting-canvas-image-data-noise.patch -d .. --no-backup-if-mismatch --forward\npatching file third_party/blink/renderer/platform/graphics/image_data_buffer.cc\npatching file third_party/blink/renderer/platform/graphics/static_bitmap_image.cc\npatching file third_party/blink/renderer/platform/graphics/static_bitmap_image.h\npatching file chrome/browser/about_flags.cc\npatching file content/child/runtime_features.cc\npatching file third_party/blink/renderer/platform/runtime_enabled_features.json5\npatching file third_party/blink/renderer/platform/exported/web_runtime_features.cc\npatching file third_party/blink/public/platform/web_runtime_features.h\npatching file content/browser/renderer_host/render_process_host_impl.cc\npatching file third_party/blink/renderer/platform/BUILD.gn\n2018-09-18 14:09:19,317 - INFO: * Applying chromium-vaapi-r18.patch (112/116)\n2018-09-18 14:09:19,317 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/inox-patchset/chromium-vaapi-r18.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/browser/about_flags.cc\npatching file chrome/browser/chromeos/login/chrome_restart_request.cc\npatching file chrome/browser/flag_descriptions.cc\npatching file chrome/browser/flag_descriptions.h\npatching file content/browser/gpu/compositor_util.cc\npatching file content/browser/gpu/gpu_process_host.cc\npatching file content/browser/renderer_host/media/video_capture_browsertest.cc\npatching file content/browser/renderer_host/render_process_host_impl.cc\npatching file content/browser/webrtc/webrtc_media_recorder_browsertest.cc\npatching file content/gpu/BUILD.gn\npatching file content/gpu/gpu_main.cc\npatching file content/public/browser/gpu_utils.cc\npatching file content/public/common/content_switches.cc\npatching file content/public/common/content_switches.h\npatching file content/renderer/media/webrtc/peer_connection_dependency_factory.cc\npatching file content/renderer/render_thread_impl.cc\npatching file gpu/config/software_rendering_list.json\npatching file media/gpu/BUILD.gn\npatching file media/base/media_switches.cc\npatching file media/base/media_switches.h\npatching file content/browser/utility_process_host.cc\n2018-09-18 14:09:19,521 - INFO: * Applying no-new-ninja-flag.patch (113/116)\n2018-09-18 14:09:19,522 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ubuntu/no-new-ninja-flag.patch -d .. --no-backup-if-mismatch --forward\npatching file tools/gn/bootstrap/bootstrap.py\n2018-09-18 14:09:20,346 - INFO: * Applying relax-ninja-version-requirement.patch (114/116)\n2018-09-18 14:09:20,347 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ubuntu/relax-ninja-version-requirement.patch -d .. --no-backup-if-mismatch --forward\npatching file tools/gn/tools/gn/ninja_build_writer.cc\n2018-09-18 14:09:20,660 - INFO: * Applying manpage.patch (115/116)\n2018-09-18 14:09:20,660 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/linux/manpage.patch -d .. --no-backup-if-mismatch --forward\npatching file chrome/app/resources/manpage.1.in\n2018-09-18 14:09:20,668 - INFO: * Applying remove-fcomplete-member-pointers-cflag.patch (116/116)\n2018-09-18 14:09:20,668 - DEBUG: /usr/bin/patch -p1 --ignore-whitespace -i /home/intika/chrome/test/ungoogled-chromium/build/src/ungoogled_packaging/patches/ungoogled-chromium/remove-fcomplete-member-pointers-cflag.patch -d .. --no-backup-if-mismatch --forward\npatching file build/config/compiler/BUILD.gn\n+ python3 -m buildkit domains apply -b config_bundles/linux_portable -c domainsubcache.tar.gz ../\n2018-09-18 14:09:21,771 - DEBUG: Initialized logger 'buildkit'\n2018-09-18 14:09:21,772 - INFO: Path has no substitutions: chrome/browser/plugins/plugins_resource_service.cc\n2018-09-18 14:09:21,941 - INFO: Path has no substitutions: chrome/browser/safe_browsing/client_side_model_loader.cc\n2018-09-18 14:09:22,242 - INFO: Path has no substitutions: chrome/common/page_load_metrics/page_load_metrics_util.cc\n2018-09-18 14:09:22,549 - INFO: Path has no substitutions: components/dom_distiller/content/browser/dom_distiller_viewer_source.cc\n2018-09-18 14:09:22,550 - INFO: Path has no substitutions: components/dom_distiller/core/html/preview.html\n2018-09-18 14:09:22,552 - INFO: Path has no substitutions: components/domain_reliability/google_configs.cc\n2018-09-18 14:09:22,590 - INFO: Path has no substitutions: components/google/core/browser/google_url_tracker.cc\n2018-09-18 14:09:23,037 - INFO: Path has no substitutions: components/variations/net/variations_http_headers.cc\n2018-09-18 14:09:24,042 - INFO: Path has no substitutions: net/tools/transport_security_state_generator/transport_security_state_generator.cc\n2018-09-18 14:09:24,175 - INFO: Path has no substitutions: rlz/lib/lib_values.cc\n2018-09-18 14:09:26,519 - INFO: Path has no substitutions: third_party/catapult/third_party/polymer/components/font-roboto/roboto.html\n2018-09-18 14:09:26,695 - INFO: Path has no substitutions: third_party/catapult/tracing/third_party/gl-matrix/jsdoc-template/static/default.css\n2018-09-18 14:09:27,447 - INFO: Path has no substitutions: third_party/crashpad/crashpad/doc/support/crashpad_doxygen.css\n2018-09-18 14:09:34,267 - INFO: Path has no substitutions: tools/md_browser/base.css\n+ python3 -m buildkit gnargs print -b config_bundles/linux_portable\n+ popd\n/home/intika/chrome/test/ungoogled-chromium/build/src\n+ export AR=llvm-ar\n+ AR=llvm-ar\n+ export NM=llvm-nm\n+ NM=llvm-nm\n+ export CC=clang\n+ CC=clang\n+ export CXX=clang++\n+ CXX=clang++\n+ ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn\nninja: Entering directory/home/intika/chrome/test/ungoogled-chromium/build/src/out/Release/gn_build'\n[171/171] LINK gn\n+ ./out/Default/gn gen out/Default --fail-on-unused-args\nDone. Made 9356 targets from 1632 files in 6371ms\n+ ninja -C out/Default chrome chrome_sandbox chromedriver\nninja: Entering directory `out/Default'\n[451/20983] ACTION //chrome/test/chromedriver:embed_version_in_cpp(//build/toolchain/linux/unbundle:default)\nERROR:root:Git error: rc=0, output=''\n[15000/20983] CXX obj/chrome/browser/media/router/discovery/discovery/dns_sd_device_lister.o\n../../chrome/browser/media/router/discovery/mdns/dns_sd_device_lister.cc:13:6: warning: unused function 'FillServiceInfo' [-Wunused-function]\nvoid FillServiceInfo(const ServiceDescription& service_description,\n     ^\nIn file included from ../../chrome/browser/media/router/discovery/mdns/dns_sd_device_lister.cc:5:\n../../chrome/browser/media/router/discovery/mdns/dns_sd_device_lister.h:45:24: warning: private field 'delegate_' is not used [-Wunused-private-field]\n  DnsSdDelegate const delegate_;\n                       ^\n../../chrome/browser/media/router/discovery/mdns/dns_sd_device_lister.h:47:8: warning: private field 'started_' is not used [-Wunused-private-field]\n  bool started_;\n       ^\n3 warnings generated.\n[15484/20983] CXX obj/components/autofill/core/browser/browser/autofill_download_manager.o\n../../components/autofill/core/browser/autofill_download_manager.cc:145:34: warning: unused function 'GetNetworkTrafficAnnotation' [-Wunused-function]\nnet::NetworkTrafficAnnotationTag GetNetworkTrafficAnnotation(\n                                 ^\n1 warning generated.\n[15550/20983] CXX obj/components/component_updater/component_updater/configurator_impl.o\nIn file included from ../../components/component_updater/configurator_impl.cc:5:\n../../components/component_updater/configurator_impl.h:98:14: warning: private field 'require_encryption_' is not used [-Wunused-private-field]\n  const bool require_encryption_;\n             ^\n1 warning generated.\n[16966/20983] CXX obj/google_apis/google_apis/gaia_auth_fetcher.o\n../../google_apis/gaia/gaia_auth_fetcher.cc:42:14: warning: unused variable 'kMaxMessageSize' [-Wunused-const-variable]\nconst size_t kMaxMessageSize = 1024 * 1024;  // 1MB\n             ^\n1 warning generated.\n[17581/20983] CXX obj/chrome/browser/browser/browser_jumbo_23.o\nIn file included from gen/chrome/browser/browser_jumbo_23.cc:43:\n./../../chrome/browser/net/trial_comparison_cert_verifier.cc:91:12: warning: unused variable 'profile' [-Wunused-variable]\n  Profile profile = reinterpret_cast(profile_id);\n           ^\n1 warning generated.\n[17603/20983] CXX obj/chrome/browser/browser/browser_jumbo_11.o\nIn file included from gen/chrome/browser/browser_jumbo_11.cc:20:\n./../../chrome/browser/search/search.cc:97:20: warning: unused function 'GetDefaultSearchProviderTemplateURL' [-Wunused-function]\nconst TemplateURL GetDefaultSearchProviderTemplateURL(Profile profile) {\n                   ^\n./../../chrome/browser/search/search.cc:140:6: warning: unused function 'IsURLAllowedForSupervisedUser' [-Wunused-function]\nbool IsURLAllowedForSupervisedUser(const GURL& url, Profile profile) {\n     ^\n./../../chrome/browser/search/search.cc:157:6: warning: unused function 'ShouldShowLocalNewTab' [-Wunused-function]\nbool ShouldShowLocalNewTab(Profile profile) {\n     ^\n./../../chrome/browser/search/search.cc:164:6: warning: unused function 'ShouldDelayRemoteNTP' [-Wunused-function]\nbool ShouldDelayRemoteNTP(const GURL& search_provider_url, Profile profile) {\n     ^\n4 warnings generated.\n[17662/20983] CXX obj/chrome/browser/browser/browser_jumbo_1.o\nIn file included from gen/chrome/browser/browser_jumbo_1.cc:59:\n./../../chrome/browser/browsing_data/chrome_browsing_data_remover_delegate.cc:262:6: warning: unused function 'OnClearedCookies' [-Wunused-function]\nvoid OnClearedCookies(base::OnceClosure done,\n     ^\n1 warning generated.\n[17694/20983] CXX obj/chrome/browser/ui/ui/one_click_signin_links_delegate_impl.o\nIn file included from ../../chrome/browser/ui/sync/one_click_signin_links_delegate_impl.cc:5:\n../../chrome/browser/ui/sync/one_click_signin_links_delegate_impl.h:26:18: warning: private field 'browser_' is not used [-Wunused-private-field]\n  Browser const browser_;\n                 ^\n1 warning generated.\n[17695/20983] CXX obj/chrome/browser/extensions/extensions/extensions_jumbo_8.o\nIn file included from gen/chrome/browser/extensions/extensions_jumbo_8.cc:45:\n./../../chrome/browser/extensions/webstore_installer.cc:114:16: warning: unused function 'GetDownloadFilePath' [-Wunused-function]\nbase::FilePath GetDownloadFilePath(const base::FilePath& download_directory,\n               ^\n./../../chrome/browser/extensions/webstore_installer.cc:144:6: warning: unused function 'MaybeAppendAuthUserParameter' [-Wunused-function]\nvoid MaybeAppendAuthUserParameter(const std::string& authuser, GURL url) {\n     ^\n2 warnings generated.\n[18502/20983] CXX obj/extensions/browser/updater/updater/extension_downloader.o\n../../extensions/browser/updater/extension_downloader.cc:90:12: warning: unused variable 'kDefaultInstallLocation' [-Wunused-const-variable]\nconst char kDefaultInstallLocation[] = \"\";\n           ^\n1 warning generated.\n[20973/20983] LINK ./v8_context_snapshot_generator\nFAILED: v8_context_snapshot_generator \npython \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./v8_context_snapshot_generator\" -- clang++ -Wl,--build-id=sha1 -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -fuse-ld=lld -Wl,--icf=all -Wl,--color-diagnostics -flto=thin -Wl,--thinlto-jobs=8 -Wl,--thinlto-cache-dir=thinlto-cache -Wl,--thinlto-cache-policy,cache_size=10\\%:cache_size_bytes=10g:cache_size_files=100000 -Wl,--lto-O0 -fwhole-program-vtables -m64 -Wl,-O2 -Wl,--gc-sections -nostdlib++ -fsanitize=cfi-vcall -fsanitize=cfi-icall -rdynamic -Wl,-rpath-link=. -Wl,--disable-new-dtags -Wl,--icf=none -o \"./v8_context_snapshot_generator\" -Wl,--start-group @\"./v8_context_snapshot_generator.rsp\"  -Wl,--end-group   -ldl -lpthread -lrt -lgmodule-2.0 -lgobject-2.0 -lgthread-2.0 -lglib-2.0 -lsmime3 -lnss3 -lnssutil3 -lplds4 -lplc4 -lnspr4 -latomic -lresolv -lgio-2.0 -lX11 -lX11-xcb -lxcb -lXcomposite -lXcursor -lXdamage -lXext -lXfixes -lXi -lXrender -lXtst -lexpat -luuid -lXrandr -lpangocairo-1.0 -lpango-1.0 -lcairo -lXss -lasound -lm -lz -lpci -ldbus-1 \nAlias must point to a definition\ni32 (%struct._FcCharSet, i32)* @FcCharSetHasChar\nLLVM ERROR: Broken module found, compilation aborted!\nLLVM ERROR: Failed to rename temporary file thinlto-cache/Thin-df2176.tmp.o to thinlto-cache/llvmcache-2AE339AC3FA8CE37836989F97A1BE24C7BAE5823: No such file or directory\nLLVM ERROR: Failed to rename temporary file thinlto-cache/Thin-f96b49.tmp.o to thinlto-cache/llvmcache-0DCDEB0F93C0D9DE77470F3D49634B8957B7318F: No such file or directory\nLLVM ERROR: Failed to rename temporary file thinlto-cache/Thin-e0d114.tmp.o to thinlto-cache/llvmcache-69F26B8A7958A256B2245F81A373EE61ACF0DE95: No such file or directory\nclang-6.0.1: error: linker command failed with exit code 1 (use -v to see invocation)\nninja: build stopped: subcommand failed.\n``. OMG i solved the \"**2.**Alias must point to a definition i32 (%struct._FcCharSet, i32) @FcCharSetHasChar`\" this was too stupid really too stupid... main reason was outaded lld version in the process of setting up the machine i did forget to install lld6 because v68 did not needed it to be at v6 or v8 (note that it did not work with lld/llvm/clang v6 i had to update to v8 to bypass the error for chrome v69)\nSo Solution Was :\nzypper addrepo -f https://download.opensuse.org/repositories/home:/khnazile:/video/openSUSE_Leap_42.3/ clang8\nzypper remove llvm6* clang6* *lld6* clang3_9-checker-3.9.1-33.12.x86_64 libLLVM70-32bit-7.0~svn20180529-18.1.x86_64\nzypper install *llvm8* *clang8* python3-clang* *lld8*\nNow i have this error left \"1. ERROR:root:Git error: rc=0, output=''\" but it does not break the build process, i also removed gcc-6 and leaved gcc-7 installed, some dev adviced that because of that error... also it could be because of my glibc version (2.22) but i want a large backward compatibility for my build so... do you know the impact of that error ? \n[493/20983] ACTION //chrome/test/chromedriver:embed_version_in_cpp(//build/toolchain/linux/unbundle:default)\nERROR:root:Git error: rc=0, output=''\nAnyway v69 needs an update to the build process wiki\nYaaAaAaAaaY i am finally having this v69 version to build... (still did not launch the binary lool) . > Do you know if LLVM 7 will work? It will be released soon, so it will be more widely available than LLVM 8.\ni tried to use LLVM 7 etc. but i got some build error with it. (it could be because of the package being in a beta repo)\nThus said v69 src package from opensuse does not require clang8 nor clang7 i think the package from suse is using gcc to build . > Right, there are a different set of fixes needed to work with GCC. Also, the configuration is different too (e.g. not using newer optimizations like CFI, LTO, etc.). I'm not sure why you're bringing this up since you're using linux_portable via linux_simple.\nAt first when it failed to build i was thinking of applying the patchs directly to the src version provided by suse... i just had that in mind it's why i talked about it... but indeed it's not the same build . @Eloston Just pushed the binaries to https://github.com/intika/ungoogled-chromium-binaries/releases\nI guess i will not PR ungoogled-chromium-binaries until v69.0.3497.92 is in dev. \nplus users can still views those releases by clicking \"view other release from...\" \nDo you prefer that i PR ungoogled-chromium-binaries ? with v69. @Eloston by the way have a look at this download stats :+1: :D (i know we could see that somewhere in the file stats... but this display is cool ^^ may be you already know). ungoogled-chromium should have it's own identity because it's a lot more than just few patches . Good work :+1:  but DDG or Google it's the same issue at the end of the day it's almost impossible to have some services without loosing a little of privacy... (it's the price to pay for a free service) now when it come to DDG i personally prefer using Google at least they are clear in what they are doing... DDG is for sure somehow better for privacy at first look but they are not angels ether, DDG is not an exception to the rule when a service is free it mean that we are the product (what i don't like about them is that they are calming privacy etc. but they are doing otherwise when you look deeper... cookies/how they work/who's the investor etc. so...)\nTo be back @ this issue, may be using a flag to restore suggestions function . i personally use http://crxextractor.com/ to install extensions . you still need to set the flag #extension-mime-request-handling to \"always prompt...\" under \"chrome://flags\" then the site works... i like that site because it extract the real link it's not proxified or something... . > Did you try to download the aforementioned extension?!\nindeed does not work https://stackoverflow.com/questions/7184793/how-to-download-a-crx-file-from-the-chrome-web-store-for-a-given-id i did try some different variable like \"os\" and \"arch\" also different chrome version but no it did not work... i will monitor chrome to see what link it's using... . - Are you using portable version ? \n- When you run it from terminal does it display any errors ? . your video acceleration library (libva) is not well working this explain that \n1. can you test the portable version please.\n2. what version of libva package are installed in your system ? is it updated ? . i have the same issue on one of my machines... i tired upgrading libva to v2.2 but does not seem to sole the issue, it need some more investigation . Okay found what it is\nlong answer short... you will need to install \n- vaapi-driver-intel v2.1 \n- or vaapi-driver-intel v2.2 + libva v2.2\nlet me know if you need help to install them . @Eloston  https://github.com/Eloston/ungoogled-chromium/commit/2dc0d020009db737f5da3d128184afcce297a638 is video acceleration still active on 69.0.3497.100-2 portable ? \nwhat about other flavors @brokoli-mate is using debian package ?. will build the new version tomorrow https://github.com/Eloston/ungoogled-chromium/issues/532#issuecomment-425622766 @brokoli-mate. i checked a little bit the list of patches from brave and i have 2 issues about it \n\nThe names of the patches are not very clear sometime in what they do\nI did not really find patches about privacy on the list you linked (i only came around translation patch components-translate-core-browser-language_state.h.patch and components-translate-core-browser-translate_url_fetcher.cc.patch) but i think core translation servers are already disabled on UC \n\nSo i don't really see a patch that can help this project, but i may missed something can you please point out a patch if you find one useful for this project ?  . also : https://github.com/brave/brave-browser/issues?q=is%3Aissue+label%3Aprivacy+is%3Aopen. you need to check what version is used while compiling... \nwhat does 'llvm-gcc -v' return ? otherwise adapt the link to llvm v6 \nEDIT : you will probably need v8\nNote : i have build and posted last portable https://github.com/intika/ungoogled-chromium-binaries/releases if you want to test. yaaay cool :). We need more details about your config \n\n\nWhat's your version of those application\n-- lld\n-- gcc \n\n\nThe output of uname -a \n\n\nWhat version are you trying to build\n\n\nIf possible indicate what steps are you doing. You need to provide more infos... but still i had a similar issue caused by lack of available ram so : \n\nmake sure to run the compiler alone all other app closed \nincrease your swap\nyou can try to run the compiler with one single instance \nninja -j1 -C out/Default chrome chrome_sandbox chromedriver\nthis is the last line from the build script... . > By the way, the instructions for buliding an AppImage, Flatpak, or Snap should be updated and possibly renamed.\n\nWill do that ;). Updated and resolved as needed ;) on Fix3\nAlso tested\nall good ;). good ;). What's the exact issue ? \nIf you need help building give more details about the system you are using and the steps you are doing\nBuilding help page and other closed issue should help you to get the project building on your system. Yeah it depend what version tag you are downloading, on the main repo you can chose the version tag before downloading the zip and then you should have the exact same version.\nNow going back to your issue, it seems that you have a python issue probably the used version of python is not good\ncan you please check what's the output of python --version otherwise try to link the compiling script to the right version of python or link your /usr/bin/python to the right version... i think that you will need python 3.6.6\nLet me know if this solve your issue ;). @jlj2 normally the gn python code should be run with python 2.7 not with python3... something is missing on your system, can you post what's the output of python2 --version i am not sure if 3.6.6 is really required it's the version i am using to build UC. \nYou will need LLVM 7 later in the building process so after solving you will probably have other errors because of llvm (Or you can build v68 it does not require llvm7)\nalso be aware that the build time is about 5h~6h on average machines (to have an idea i build the project in 15min with a machine having 48 Cores of 2ghz and 64 ram)\nEDIT : \nOkay i just understand what's going on... when you have python3 and python2 installed on the same system /usr/bin/python should be linked to /usr/bin/python2.7 ... but this depend on the system needs and configuration. so don't edit the link under /usr/bin it can break your system after reboot... a simple solution would be \nalias python=/usr/bin/python2.7 \nrun this before starting the build script and you should be fine . @jlj2 it's not a problem thank you for your kindness, and don't worry we will figure that out and you will get it to build ;) at least i am sure that you will with v68 (if you don't want to upgrade llvm)\nThe thing is that GN Script is using python v2 it's intended to work that way, it's possible to convert that script to python v3 but it's a lot of work for nothing. we just need to figure out why python 3 is used at that moment in your machine... \nNote python v2 syntax differ from v3 it's why you are having that issue and why GN script is not working...  \nokay here is something you can try instead\n- Start again from scratch\n- At step build.sh before running the (./ungoogled_packaging/build.sh)\n- Edit ./ungoogled_packaging/build.sh   and delete 3 last lines or comment them with # here are the lines i am talking about\n./tools/gn/bootstrap/bootstrap.py -o out/Default/gn\n./out/Default/gn gen out/Default --fail-on-unused-args\nninja -C out/Default chrome chrome_sandbox chromedriver\n- Run the build script it should work just fine... (at least you will have a build dir ready to manipulate you don't have to start from scratch every time and wait 15 min) \n- Run the next command manually (instead of ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn run python2 ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn\n- if it works just run the 2 last commands manually \nLet me know if it worked, if it's the case i will PR build script with the modifications to fix that... for users who have python3 set as main python command\nLet me know what's the next error i will tell you what you need to do ;)\nEdit : if it does not work you can try to edit the link '/usr/bin/python' currently on your system it should link to '/usr/bin/python3' or something similar... but be very careful don't reboot the system while you have that file modified you have to put it back as it was when you don't need it anymore... \nhere is an example of how you can edit it... before running the build commands one more time\nsudo mv /usr/bin/python /usr/bin/pythonbakup\nsudo ln -s /usr/bin/python2 /usr/bin/python\nto get the system back again as it was just\nsudo mv /usr/bin/python /usr/bin/pythontmp\nsudo mv /usr/bin/pythonbakup /usr/bin/python\ni think you there should be some export/env command to use to avoid all that hassle... devs reading this may correct me ;) \n. @jlj2 \nFirst thing first here is some infos about switching default python version temporarily... \nhttps://stackoverflow.com/questions/7237415/python-2-instead-of-python-3-as-the-temporary-default-python \nand \nhttps://stackoverflow.com/questions/36278220/how-to-switch-to-python2-in-a-particular-terminal-window-temporarily\nNow going back to your build... first \n\nERROR:root:Git error: rc=0, output=''\n\nThis one is normal we all have that, just ignore that... \nFor the error \n\nFAILED: gen/third_party/blink/renderer/platform/color_data.cc \n\nYou probably missing a package/python-module... (in this case i think the missing package is gperf-native) and you will probably have other errors later for other missing packages / out dated package version... so to accelerate a little bit the whole thing you can install all needed dependency to build chromium/uc with some commands... there is an aur package https://aur.archlinux.org/packages/ungoogled-chromium for UC \nYou can use that command to get what package is missing \nmakepkg -s PKGBUILD\n-s, --syncdeps\n           Install missing dependencies using pacman. When build-time or run-time dependencies are not found, pacman\n           will try to resolve them. If successful, the missing packages will be downloaded and installed.\nthere is also an other command to install dependency for building a package this is emerge -o package-name replace package name with chromium or chromium-browser depending on how the package is named on gentoo \nAfter getting the missing dependency you can run once again the build as you did or use the aur i linked... \nLet me know what's next ;)\nNote : as you are making some modification to your system i suggest you to do a backup before playing with building chromium... it's a big big big project that require a lot of packages so... a backup is always good... \nNote II : Also as you are using llvm 6 you can directly try to build v68 just use 'git checkout 68...' after cloning the project... but if you want to 69/70 i think at one point or an other you will need to build llvm/clang from source and install that... it's easy to do https://clang.llvm.org/get_started.html and it will be installed along with your current version so don't worry will be probably installed in /usr/local... \n . @jlj2 \n\n(Q1)-(Q2)-(Q3)\n\nThere is 2 levels of dependency for every package the first level is usage level and the second is build level... so if you just want to use a package you will be installing the depended on packages, but in the other hand if you want to build the package you will need a whole other set of packages like devel one etc. so having chromium installed does mean that you have all the needed packages to build it and it's often not the case. those commands i gave you are used to install required packages for building purpose. most of the time UC and Chromium need the same packages set to be built so you don't need to have UC on your distro repo just install dependency of chromium and you should be good to go. i am not using an Arch based system, i can't test to give you the exact syntax... just for info in my system i use dnf builddep chromium-browser in your system the command should be something like makepkg -s chromium-browser\n\nA backup could be done to proceed, but the link you suggested to build LLVM 7 lists python 2.7 as a prerequisite, which is missing on my system and is not planned to be installed. Maybe once my python 2 is upgraded I will\n\nYou already have python 2.7... you will just probably need to set it as default during build like you do for UC\n$ python2 --version\nPython 2.7.15\n\nV68 could be a fallback. (Q4) Could you please spell out that command, as I am not familiar with 'after cloning the project', and the last tagged v68 source code tagged is 68.0.3440.106-2, e.g.\n\ngit clone https://github.com/Eloston/ungoogled-chromium.git\ncd ungoogled-chromium\ngit checkout tags/68.0.3440.106-2\n\n(Q5) Another alternative: what do you think about using ebuilds offered for gentoo, as suggested earlier, which may address environments like mine with python 2.6.5 and llvm 6.0.1?\n\nYes of course you could do that... if you have unsolved building issue with the ebuilds you could fall back to what we are doing here ;) \n\nWell, this was thought to be a bug report, but it isn't identified as that. (Q6) Is it because my system is missing python 2.7 and LLVM 7? Is it kept open to try to solve situations with systems that 'default' to python 3 (as signalled earlier re Arch systems)? Despite your continued help, my interest to keep stable python 2.6.5 seems to mean that there is no way forward for Linux Simple UC v69 here. Even some temporary install of python 2.7 in order to build LLVM 7 is not appealing.\n\nIt will be probably closed when @Eloston will have the time to. And/or when your specific issue will be solved :D... this is not a bug but an issue about helping you building the project :D \"Help needed\" tag will be probably added to this issue later... outdated dependency is not a bug indeed but it's always good to have work around for other users with the same issue :) ... now regarding default python 2/3 this is not a bug either as @Eloston already mentioned PKGBUILD for Arch Linux modifies the Chromium source tree to use python2 so it's solved on specific PKGBUILD ... now this topic is helpful for any system that have python3 set to default ;)\n\nThank you very much anyway for all your help, @antika, and have a great Friday and weekend!\n\nYou are welcome, have a great weekend too ;)\n. 1. What about including those library on the appimage ? \n2. Statically linking would make the package :\n- Much bigger \n- Used ram and performance impact ? \n3. Those libs differ a little bit from one system to an other, i think statically linking them in the build machine would somehow make UC work only on similar distro as the build machine (need to be tested) ... Also those libs depends on other libs so not an easy task (Plus maintenance...)\n4. We are talking about commonly used library on X systems gtk etc. does statically linking those library have a real impact or negligible one ? (i don't think this is worth it)\n5. Flatpak could be a solution as it include almost a whole system framework. . i was a little busy with Librefox i will see what i can do ;) . i am building portable with sysroots right now... the build script needs some adjustment... i will PR if everything went ok  . Done https://github.com/Eloston/ungoogled-chromium/pull/649/. this is not a real issue, the problem we are facing is that sysroot is pre compiled (binary) we would need to maintain that as well if we want to build it from sources.. sysroot is a little more complicated to be added while respecting this project rules... i added a full review about it here https://github.com/Eloston/ungoogled-chromium/pull/649... so wait and see what we decide... . Just in case some one is interested here is my patch to latest firefox to make it respect privacy \nintika-config-prefs.js (file to be copied to firefox_install_dir/default/pref) ... ungoogled-firefox hahahaha\npref(\"datareporting.healthreport.service.enabled\", false);\npref(\"datareporting.healthreport.uploadEnabled\", false);\npref(\"toolkit.telemetry.rejected\", true);\npref(\"toolkit.telemetry.enabled\", false);\npref(\"toolkit.telemetry.unified\", false);\npref(\"devtools.telemetry.supported_performance_marks\", \"\");\npref(\"devtools.telemetry.tools.opened.version\", \"\");\npref(\"toolkit.telemetry.cachedClientID\", \"\");\npref(\"toolkit.telemetry.infoURL\", \"\");\npref(\"toolkit.telemetry.previousBuildID\", \"\");\npref(\"toolkit.telemetry.server\", \"\");\npref(\"toolkit.telemetry.server_owner\", \"\");\npref(\"toolkit.telemetry.infoURL\", \"\");\npref(\"toolkit.telemetry.prompted\", 2);\npref(\"app.update.lastUpdateTime.telemetry_modules_ping\", 0);\npref(\"experiments.enabled\", false);\npref(\"extensions.getAddons.cache.enabled\", false);\npref(\"network.http.speculative-parallel-limit\", 0);\npref(\"network.predictor.enabled\", false);\npref(\"network.prefetch-next\", false);\npref(\"browser.newtabpage.directory.source\", \"0.0.0.0\");\npref(\"browser.newtabpage.directory.ping\", \"0.0.0.0\");\npref(\"browser.aboutHomeSnippets.updateUrl\", \"0.0.0.0\");\npref(\"privacy.trackingprotection.enabled\", true);\npref(\"beacon.enabled\", false);\npref(\"browser.search.suggest.enabled\", false);\npref(\"browser.send_pings\", false);\npref(\"dom.event.clipboardevents.enabled\", false);\npref(\"geo.enabled\", false);\npref(\"layout.css.visited_links_enabled\", false);\npref(\"network.http.referer.trimmingPolicy\", 2);\npref(\"browser.pocket.enabled\", false);\npref(\"browser.search.update\", false);\npref(\"device.sensors.enabled\", false);\npref(\"dom.battery.enabled\", false);\npref(\"dom.gamepad.enabled\", false);\npref(\"dom.vibrator.enabled\", false);\npref(\"loop.enabled\", false);\npref(\"media.eme.enabled\", false);\npref(\"media.gmp-eme-adobe.enabled\", false);\npref(\"media.gmp-gmpopenh264.enabled\", false);\npref(\"media.gmp-provider.enabled\", false);\npref(\"media.video_stats.enabled\", false);\npref(\"webgl.disabled\", true);\npref(\"clipboard.autocopy\", false);\npref(\"sync.enabled\", false);\npref(\"browser.casting.enabled\", false);\npref(\"dom.permissions.enabled\", false);\npref(\"browser.newtabpage.enhanced\", false);\npref(\"dom.popup_maximum\", 5);\npref(\"browser.urlbar.trimURLs\", false);\npref(\"dom.enable_performance\", false);\npref(\"javascript.options.asmjs\", false);\npref(\"media.navigator.enabled\", false);\npref(\"media.peerconnection.enabled\", false);\npref(\"social.remote-install.enabled\", false);\npref(\"browser.fixup.alternate.enabled\", false);\npref(\"gfx.font_rendering.opentype_svg.enabled\", false);\npref(\"gfx.font_rendering.opentype_svg.enabled\", false);\npref(\"browser.newtabpage.directory.ping\", \"0.0.0.0\");\npref(\"browser.safebrowsing.downloads.enabled\", false);\npref(\"browser.safebrowsing.enabled\", false);\npref(\"browser.safebrowsing.malware.enabled\", false);\npref(\"browser.safebrowsing.downloads.remote.enabled\", false);\npref(\"browser.safebrowsing.allowOverride\", false);\npref(\"browser.safebrowsing.blockedURIs.enabled\", false);\npref(\"browser.safebrowsing.downloads.remote.block_dangerous\", false);\npref(\"browser.safebrowsing.downloads.remote.block_dangerous_host\", false);\npref(\"breakpad.reportURL\", \"\");\npref(\"app.vendorURL\", \"\");\npref(\"social.directories\", \"\");\npref(\"captivedetect.canonicalURL\", \"\");\npref(\"identity.fxaccounts.auth.uri\", \"\");\npref(\"devtools.gcli.imgurUploadURL\", \"\");\npref(\"app.update.url\", \"\");\npref(\"extensions.blocklist.itemURL\", \"\");\npref(\"extensions.blocklist.url\", \"\");\npref(\"devtools.gcli.jquerySrc\", \"\");\npref(\"devtools.gcli.lodashSrc\", \"\");\npref(\"devtools.gcli.underscoreSrc\", \"\");\npref(\"devtools.devices.url\", \"\");\npref(\"plugins.crash.supportUrl\", \"\");\npref(\"app.releaseNotesURL\", \"\");\npref(\"mailnews.mx_service_url\", \"\");\npref(\"browser.search.geoip.url\", \"\");\npref(\"social.whitelist\", \"\");\npref(\"extensions.update.background.url\", \"\");\npref(\"app.update.url\", \"\");\npref(\"app.update.url.manual\", \"\");\npref(\"app.update.url.details\", \"\");\npref(\"devtools.devedition.promo.url\", \"\");\npref(\"mailnews.messageid_browser.url\", \"\");\npref(\"media.gmp-manager.url\", \"\");\npref(\"security.ssl.errorReporting.url\", \"\");\npref(\"toolkit.crashreporter.infoURL\", \"\");\npref(\"webextensions.storage.sync.serverURL\", \"\");\npref(\"sync.jpake.serverURL\", \"\");\npref(\"sync.serverURL\", \"\");\n\n\nplus disabling index . Yes this is a good idea... (and this was already requested) \n\n\n1 - Please post here If you know example of any service that could provide that \n\n\n2 - PR are open to any modification that would make such a thing possible\n\n\n3 - This is a small free non profit project (i personally pay 1~2 euros to build every release on a google cloud server and publish it back here) but in the case of a server/bot dedicated to that we would need something else or the project would bring in some financial aspect...  \n\n\n4 - I think @Eloston is welcome to any solution if you have one . i don't know about mac may be @pastmaster007 can let you know... but for linux new design is enabled automatically since v69 \nwhat version are you using ?. @ODB88 please close the issue . > Any way to hide the profile icon?\n\n\nyes this #show-avatar-button is a new feature added by @qvint in v70 \njust browse chrome://flags\n. Same error with both builds... stick with the portable version for debugging... \n\nDo you have the same issue with chromium ? \nDo you have same issue with v67 portable ?\nHow did you disable namespaces in the first place \nAre you using a custom kernel ? what's the output of \"uname -a\" ?\n\nTry to run it with a different user or with a new profile . Cool :) i am glad that helped, can you please close the issue . UC will become very different in internals from chromium overtime... \nWhy not just use a separate profile folder ? \n. @Eloston for me personally uc is a full replacement of chromium so it does not matter, but here is why it could be useful to have a different profile location for uc \n\n\nFirst i think most classic users are considering uc as a complete different browser (even if technically its a patched chromium)\n\nWhat i meant is the more features that come in the more the browser will be different from chromium... and uc is likely to be having growing features numbers\n\nIn the case where both browsers are used and or migration from chromium to uc : \n- Flags : some flags are present here but not there and it could potentially lead to crash/loosing-settings i don't know exactly how chromium deal with unknown flags but it could be a source of problem \n- Out of the box experience (An old profile could lead to problems like https://github.com/Eloston/ungoogled-chromium/issues/567)\n- Version mismatch : chromium does not like when a profile is used with a previous version and even show an error when we do so... (in case chromium/uc version mismatch)\n- We could have a lot of arguments in each side but at the end of the day uc is not chromium \nAny way just developing what i was talking about... but for me its not something that i would put a lot of effort/energy in... nor bothering making the change... in the other hand the bug have to be fixed so... \n. so may be cleaning the profile on first run as @s1nceri7y mentioned... but some users may not like being disconnected... does this issue deserve changing the code at all ? . - i do my patching manually just before the final building process for my custom build (https://github.com/intika/UGChrome)\n- depending on the needs and the used machine i change the number of cores used to build every time i build like (ninja \"-j 20\") or something . thanks for taking time to clarify... it makes sens . What the patch does :\n```\n--- a/ui/gfx/native_pixmap_handle.cc\n+++ b/ui/gfx/native_pixmap_handle.cc\n@@ -12,6 +12,9 @@\n namespace gfx {\n#if defined(OS_LINUX)\n+#ifndef DRM_FORMAT_MOD_INVALID\n+#define DRM_FORMAT_MOD_INVALID ((1ULL<<56) - 1)\n+#endif\n static_assert(NativePixmapPlane::kNoModifier == DRM_FORMAT_MOD_INVALID,\n               \"gfx::NativePixmapPlane::kNoModifier should be an alias for\"\n\"DRM_FORMAT_MOD_INVALID\");\n```\nWhy it does what it does :\nDRM_FORMAT_MOD_INVALID is part of the linux kernel  https://github.com/torvalds/linux/blob/master/include/uapi/drm/drm_fourcc.h and was introduced in 4.14 https://github.com/torvalds/linux/commit/e6fc3b68558e4c6d8d160b5daf2511b99afa8814#diff-94ab8a47ff02fa7f35cb0451290e1d85 this patch permit compatibility backward post v4.14\nWhy \nThe patch is not really tied to opensuse... its why i suggested adding it to the portable, i am using this on my personal build its why i just asked here may be it would be useful... . @probonopd i personally use the same solution as you and probably as many users... but integrating the extension in uc is just out of the scope of the project i don't really see the benefit of bundling the whole thing... \nnowadays browser are integrating ab blocking in their main code... we will may be see this feature coming around... \nNow you have to be careful for legal reasons because the cookie notification thing is there for a legal reason and disabling it with integrated component without letting the user choose it himself may put you in an illegal situation (... just to say)   . the good thing about this is that it makes non technical user to be aware a little bit about what's happening behind the scene. > Is there any way to update extensions automaticly?\nmay be opening classic chromium and let it updates the extensions... but it will not work in future version if @Eloston decide to change the profile location... also do a backup of your profile before proceeding... there is may be an other solution that i am not aware of. . yes its just about cookies . Also can you try v70. what about site that only use those ciphers you switch back to http with this settings ? \n(using https with those ciphers is better than http...) \n- a flag could be useful \n- its may be the work of an extensions like https... back in the days there was an extension for that in firefox . Okay, the site just don't work when blocking ciphers giving back this error (tested with uc v70)\nThis site can\u2019t provide a secure connection intika.be uses an unsupported protocol.\nERR_SSL_VERSION_OR_CIPHER_MISMATCH\nYou can reproduce the test with --cipher-suite-blacklist=0xC02F,0xC030,0xC013,0xC014,0x009C,0x009D,0x002F,0x003C,0x0035,0x003D \nand navigating to https://intika.be\nYou have a nice setup but i personally don't like \"HTTPS Everywhere\" at all because of :\n- The code quality is very poor (make the extension huge resources eater) \n- How web extensions works to monitor traffic is in itself a resources eater method, and when the code is not good... (try browsing an hour or two without it you will see a huge difference in speed) \n- Last time i checked the extensions does not always work\n- I did found some glitch about privacy in the code that i did not like back when i reviewed the extension\n- Having an extension that is sized 1.7 Mo (compressed) that have access to all what i do ?! no thanks... any simple script that does exactly the same thing would never go over 50kb (compressed) \n- I wrote my own https redirector some times ago (i did not publish it...) and the main js code was about 5kb and it did works exactly as expected link-1 link-2\nAny way here is what i am using right now : \nFirefox : \n\n\"security.mixed_content...\" settings\n\"security.insecure_connection\" settings\nAnd NoHttp and or Http...\n\nUC :\n\n#enable-potentially-annoying-security-features flag\n#disallow-unsafe-http-downloads\n#enable-mark-http-as\n\nI think in a near future browsers themselves will start blocking http, it would be nice to have a big warning when surfing http as the extension for firefox do... \nAny way would be cool to have a flag for \"--cipher-suite-blacklist=0x000a,0x009c,0x009d,0x002f,0x0035\"\n. My site is no longer maintained... my mail is intikadev at gmail. Am not really convinced because JS itself have the same issues... why would a hacker exploit that if he could just exploit js without going as deep... but i could understand that we may have exploits available on webassembly but not on classic js... in short its a good prevention action :+1: ... its sad that the current web is not really usable without js. \ninsecure by design right ?! this is what made the internet so popular . it seems that you are using python3 as default python instead of python2 same as https://github.com/Eloston/ungoogled-chromium/issues/555. duplicate of https://github.com/Eloston/ungoogled-chromium/issues/584#issuecomment-437003240 please close the issue. should we call the police because of the Illegal instruction ? hahahaha just kidding . > @intika You may want to check the Session Buddy extensions, it does have a Google Analytics tracker inside it. I removed it because of that\nThanks for the info i did reviewed-and-edited all my firefox extensions but did not have the time to do it for chrome yet... \nI'll patch that extension to remove privacy related stuff (i dont know any other session extension as good as this one) i'll upload patched version here when i do ;) as you may be interested ;)\nThat's a cool topic, to report what extensions is not clean... i'll do that when i will tackle this todo :)  . > This is something I would gladly re-download if it were cleaned :) But I don't know if it would be possible as it seems to not be open source, and copyrighted without any trace of legal agreements or privacy policy :/\nCan extensions be closed source ? i saw some that used some js masking but js is always reversible am not aware that we could use binary in extensions... now when it come to copyright, they did not ask to copy my private information lool... but i guess they are just analyzing who use the extension...  . > * directory.shoutcast.com\nNice i use to play shoutcast all the time before spotify came in... indeed it does not work with https because the stream is coming from an unencrypted location (proof that HTTPs Everywhere is still not working as expected) it is what it is some services just don't use encryption\nNote that i did not yet reviewed the code of the extensions that i am listing... \n\n\nDark new tab clean dark new tab\n\n\nAdjust-screen-brightness\n\n\nNotifier-for-github\n\n\nSimpleextmanager easily disable/enable/remove extensions. > Doesn't chrome://flags/#autoplay-policy control this?\n\n\nYes but not if the site force autoplay with some script . can you try with all addons disabled ? \nand eventually with a new uc profile . loooool. Try removing use_sysroot=false from config_bundles/common/gn_flags.map (just after git clone). > I question that and you should question it too (unless you have inspected personally all the millions of lines of code).\ni don't have the time to maintain a more elaborated version... but this work is based on a lot of other works aiming to secure firefox i am not alone watching settings changes over new versions... all what could be done at this scale is done... awaiting hardware manufacturer to come with a new solid machine we do what we can to solve/mitigate the problems\n\nThis is an impossible task, so no serious project should ever claim even an attempt for full security and privacy, especially in conjunction with speed performance. Not only because security and speed are contradictory (in today's computer world) but also because of all the issues in the hardware itself which cannot be fixed - neither at kernel level, even less at browser settings level.\n\nImpossible is not in my vocabulary ^^ there is always 0days and there will always be uncovered exploits it is what it is now using Original-Firefox or Privafox-Firefox i prefer using the later... it does not solve everything nor make coffee lol but it aim to \nOne thing for sure the user have the choice if he want to enforce advanced settings like disabling javascript, but this is meant to remain usable. \n. > In any case this is much more off-topic than the issue about implementing Tor functionality in UC, so we should probably stop here :)\nIndeed. In the download page\nUnder Files tab you have \"2 files (7 archived)\" when you click archived it uncover all the previous versions... \nI am going to un-archive them  . Fixed... i un-archived them you don't need to click archived any more.\nCan you please close the issue . Oww that's too much kindness ^^ thanks you !. Safe-browsing patches needs to be updated windows builds are failing because of it (the is a workaround re enabling safe-browsing https://github.com/Eloston/ungoogled-chromium/issues/639#issuecomment-466478108 to be able to build on windows)  . Nice patch :+1: but should not this added with a flag or or something there is a lot site using only http, i know that most of them will be opened after searching a web-engine... any way just my 2 cents not really important. safe-browsing patches needs to be updated for windows, i will see what i can do ;)  . i guess this would be solved here https://github.com/Eloston/ungoogled-chromium/issues/619 later on @Eloston can you close this. Very interesting topic ! keep it clear and simple right?! :) here are my comments : \n\n\nFeedback in here could represent a minority (this should be took in consideration)\n\n\nUC is mainly fine as it is this is what made it successful so careful on drastic changes (you already have an opinion/feedback from reddit where you got 89% upvotes and it brought the project more than 1000 stars which mean almost 100% of people that read that article liked the project here are some statistics about uc on my other post) \n\n\nUC experience should be the same over different platform and therefore patches should be separated in 2 sections, core patches (security/privacy/etc.), patches that are necessary for this or that platform (core patches should never be present on a platform and not on an other one). therefore i think it's important to have a more solid core patches.\n\n\nFollowing this point i think UC should be kept centralized as much as possible, spiting is inevitable i know but this should be done with care to keep the experience the same. (so avoid too different version because of platform patches that would handle a core feature) \n\n\nAccording to the statics i listed here; your personal preference seems to make happy most of your users (me included) i think the key here is just to avoid features that break the usage.\n\n\nGive choice ! this one is very important, (its somehow already the case and i think it's one of the key element that are making UC popular) this point is about: 1. Applying all changes that does not break usability 2. Give the user the choice for the rest over flags or command parameter.  \n\n\nOne very important thing is a clear and well defined updater (i know distro's repo are taking care of that where UC is published) but an update system for other builds should be developed.  \n\n\nAndroid can bring a lot of users, i think android version is a must BUT this should come after taking care of the main project roadmap. (i know android is very difficult to do regarding \"core patches/features\" may be separating android version from main UC could be a way to go)    \n\n\nAlso as other already reported back binary pruning and domain substitution, should be kept as they are useful.\n\n\nI think UC should get a new name, and change the chrome trademarks even if the project is amazing it's kind a lack of identify while it is using chromium trademark. thus said the project should continue to stick to main Chromium. and not deviate too much to keep things simple and manageable therefore keeping the current patching system. \n\n\nThe name and domain: @azdps pure-chromium i like it :) may be just 'Pure' is better (those 2 issues should be considered https://github.com/Eloston/ungoogled-chromium/issues/642 and https://github.com/Eloston/ungoogled-chromium/issues/335)\n\n\nConsidered question 1 definition: you are already defining what 'ungoogling' mean by your personal action/decision and it's working, you just need convert your personal key elements to a feature or core element for the project and while converting them eject what could break the usage and keep the feature as a choice. \n\n\nConsidered question 2 scope: already answered on question 1 answer, but one important thing, UC should not derive a lot from chromium for maintenance/update/etc.\n\n\nConsidered question 2 name: yes the name should be changed (personally not for me) but to get more users this is a key element (example i get a lot of audience by renaming Privafox to Librefox)\n\n\nConsidered question 3 splitting: may be for android because its a lot different but not for the rest, similar user experience is a key element. (i already answered with the proposition of core/distro patches) \n\n\nOne last advice is decide and just go for it whatever you decide don't wait you can still change/adapt it afterward. \n. Also discussed here https://github.com/Eloston/ungoogled-chromium/issues/335\nI would suggest : \n\nUGChrome\nLibrerom\nUchrome\nCopper\nKrypton\nOxygen\nOxium\nOxiweb\nOxfree\nChrodom\nAtom\nEarth\nSky\nStar\nOrion\nPhoton\nElectron\n\nAt the end of the day the project is already well known so whatever you pick will be good, having a good name will bring more users tho.. For the stars thins i guess i have the answer the first boom it is from a reddit post and lifehacker article, the second one i think its me joining the team hahhaha just kidding i have no clue for the second one \nEdit : its may be not false loool it could be because of this opendesktop but i can not verify it. also at that time i think uc was added in many different repo.. Also one thing, a lot of people asked me about mozilla trademark (Firefox) while i was disturbing a patched version it's curious that uc did not face this problem, i guess google folks are more permissive. . @Eloston Thank you very much for taking the time to give me your feedback, it's really appreciated :+1: . Yes it is grabbing it from google i thought about that too i guess its why sysroot is removed in the first place... i am investigating that and will report back . https://chromium.googlesource.com/chromium/src/+/HEAD/docs/linux_sysroot.md\nyes it should be doable... i am trying that out but i am not sure if the build does not download anything . To install the sysroot install-sysroot.py is used and to \"build\" them sysroot-creator-sid.sh BuildSysrootAmd64 is used BUT in both cases the binaries are downloaded \neither from \nhttps://commondatastorage.googleapis.com/chrome-linux-sysroot/toolchain/e7c53f04bd88d29d075bfd1f62b073aeb69cbe09/debian_sid_amd64_sysroot.tar.xz\nor from\nhttp://ftp.us.debian.org/debian//dists/experimental/main/binary-amd64/Packages.xz\nI know its possible to build all those package from sources etc. but it a huge work what do you think ? should we stop here or go into a gentoo venture ? loool :p just kidding. the right thing to do is to create a script to build all the needed package from sources, and to be honest i don't have time to do it not right now. \nSo decide and let me know . or may be provide both binaries with and without sysroot (splitting portable release). > The Debian binaries are fine. The main thing is that they aren't from Google. For example, on Windows and macOS, we download the LLVM toolchain from LLVM.\nlooooooool it's truly about ungoogling the stuff hahahah ok, i will see how to implement that because i am building on suse and the main method give some errors if not on debian... . i am facing a little problem the command to build is ./build/linux/sysroot_scripts/sysroot-creator-sid.sh BuildSysrootAmd64 and as i mentioned i am building on suse... and finally this can not be done on suse nor on non debian based system the reason i am building one suse is because of the glibc version v2.22 for a good backward compatibility. \npossible solution is to host a pre-built sysroot from debian on uc repo and adapt the command to grab that file instead on the one coming from google. otherwise this will break compatibility with non debian system based on the portable build\nThe only down side with this solution is that binary have to be updated from time to time \nNote : google is claiming their binary are coming from debian repo https://chromium.googlesource.com/chromium/src/+/HEAD/docs/linux_sysroot.md\nwhat should we do ?  \ni guess we are not going to break non debian builder so\n1- use google hosted binaries \n2- build those binaries and host them here or on a special repo for the purpose\nalso the process of building sysroot-creator-sid.sh is not building but packaging (i am not sure 100% but almost). To fix the issue i was having with non debian system i started by adding manually the Debian signature keys... (it's a single command like to fix that)... this fixed the first step of the process, then i was asked dpkg-deb (or something similar)... i stopped there... i think if i go further in fixing the compatibility i will may be end up having 5 or 6 additional commands... i don't think we should break compatibility. \nmay be going further in debugging and fixing the compatibility on non Debian system would be the way to go (this is what is mostly done on the different build wiki over here)\nThis would be faster and more reliable than a container or a chroot.\nWhat do you think ? \n(i will look into that later on, i am a little out of time lool)\nNote : i became a github junkie loooool . @Off-topic by the way are you going to the FOSDEM event in Brussels ?  . i reevaluated the situation here, i may just end up building on debian... i am summarizing \nNeeds: \nuse_sysroot to increase systems compatibility\nIssue:\nuse_sysroot is using a pre compiled binary hosted on google servers\nNote:\nchromium build tools are using debian sysroot other distro are not implemented \nSolution:\nbuild/gather sysroot from debian repo > this require a debian system/chroot/container\nSolution implementation 1:\nLimit portable building integrating sysroot to debian (this somehow what google is doing by its unique debian sysroot) user who want to build on other system would just build without sysroot (as generally most of the time the system we build on are the target system for the application to be run on)\n\nPro: \n-- Easy to implement\n-- Almost zero maintenance \n-- User who want to build on system other than debian can do so while disabling the sysroot feature (this is not a problem as long as the targeted distro is the same)\n-- Users building on system A (other than debian) and targeting system B are a very small user base\nCon:\n-- Portable build with sysroot feature (not including google binary) will be limited to debian\n-- Users who wants to build on system A (other than debian) and target system B, can encounter https://github.com/Eloston/ungoogled-chromium/issues/556 \n\nSolution implementation 2: \nDebian chroot/container:\n- Pro: \n-- Portable release would be build-able on any system and targeting any system\n-- That chroot/container could be hosted and maintained on ug git that would be kind a VM for building portable uc that devs would just use without facing compatibility/missing-package issues\n- Con:\n-- Not easy to implement \n-- All the build environment needs to be integrated/added/installed on that container \n-- Need considerable maintenance in case it's hosted \n-- If it's implemented as a script/instruction to install/add a chroot/container that would make building uc super complicated and it is already the case i don't think we need to supercharge the building system\n-- Space needed to build \n-- Time needed to build \n-- Do-ability regarding noobs \n-- Issue generator for unqualified users and thus wasting time helping them.    \nSolution implementation 3: \nHosting a debian prebuild sysroot on a separate git\nBasically doing the following on a debian system and uploading the result at every release.\n$ cd build/linux/sysroot_scripts\n$ ./sysroot-creator-stretch.sh BuildSysrootAll\n-Pro:\n-- Super easy to do\n-- Solve all the headache\n-- No change to the current build system \n-- All distro will remain compatible without changes\n-- Implementation would be super easy as well just changing the url from the google server to the generated file\n-Con:\n-- Sysroot need to be generated from time to time or on every release\nSolution implementation 4: \nimplement a container just to build the sysroot not the whole chromium thing... this is kind a solution 2 with less con. \nAlternative: \nGoogle is claiming their binary are coming from debian repo https://chromium.googlesource.com/chromium/src/+/HEAD/docs/linux_sysroot.md\nUsing the binary from the google hosting may be a solution \nPersonal situation\nI have limited time for UG i personally can not go in a road that require more maintenance time than the current situation, i will then close this PR as current solution is not suitable, temporarily i will build next releases on debian system to be able to add sysroot (not the one from google servers) OR i will build that sysroot on a debian system and use it in my current build system (opensuse) this would be the easier way for me, if this solution is suitable long term, i may maintain a build script for sysroot and PR it. That script would be used as solution 3... \nAny way let me know what you decide and i will see if i can do something about it ;) otherwise i am not alone contributing for portable ;) others may help in case of the container solution.      . > I don't understand what this solution is. Are we requiring people to build on Debian machines (no chroot/container)?\nWhen we add sysroot using google tools/script it download sysroot from google and thus this works on any system BUT if we want to build/package it ./sysroot-creator-stretch.sh BuildSysrootAll this require a debian system and can not be run on any system \n\nI don't understand this solution. Why does using a container to build the sysroot help?\n\nIf we want to build the sysroot with the current build script it require debian, now we can implement a new script that build sysroot on any system but it would require a lot of maintenance... \nSo the theoretical idea here was to use a debian container to build sysroot while keeping the current build method/script\n\nThey also have hashes for the entire sysroot images (in tar files), so maybe we could have some way of verifying these hashes are valid by building the images ourselves too? I'm not sure if the tar file is reproducible though...\n\nYeah tar would produce a different hash, what we could do instead is verify/check that google is indeed using debian binary (this require same effort as solution 3) we would decompress the tar and check the hash of all file inside it (comparing them to debian build) this could get complicated if there are version miss-match between google's hosted binary and debian binary... (i mean miss-match between latest and used version)\n\nI like this solution the most because there are commands to build a sysroot image relatively easily (therefore, any user can build it themselves if they choose). But, how do we make Chromium use the sysroot image?\n\nMe too... to make Chromium use the sysroot image is relatively super easy, current patching system is removing the google link (link of the google's hosted sysroot) we would just replace that link with our link. (would just require only one additional line on the patch that remove google's links from sources)\nI can implement solution 3, would be relatively easy (may be one day or half day) to get everything done... we would need an additional sysroot git... if you want to go for it just create an other git for the hosted sysroot under ungoogled-chromium organization, i will PR to it later on once implemented. \nSo that solution would require: \n- a git/repo for hosting the script to build sysroot and the built sysroot\n- a PR to UC similar to the current one (with one line difference or so...)  \n. > you mentioned that we could provide pre-built sysroot images. However, this will be more for us to maintain (even if we automate the building and publishing of sysroot images via CI). Also, we'd need to patch Google's script to use our own sysroot image, which means we will need to keep track of changes Google makes to this script.\nYes but it does not require a lot of time \n\n\nFor Group 1, should we enforce a controlled build environment?\n\n\nTheoretically that group does not need sysroot the build script could be adapted to add a \"local portable version\". Enforcing a controlled build environment will depend on how we implement that controlled build environment if that would require installing docker and setting it up it may be a downside (additional heavy steps) may be splitting the build system could be a solution here \n- Build a portable widely compatible with a controlled build environment\n- Build a portable for local usage\nIf the controlled build environment solution is fairly easy to implement we would just enforce it and avoid all the headache  \n\n\nTo make a controlled build environment, should we use sysroots or another method like Docker?\n\n\ni know how docker works but am not familiar with it (not using it) do you have the time to implement this ? basically what would that Dockerfile do ? the container would be a debian system ? in short what's required for the docker solution ? \nJust pick a solution that works best according to what's required, keep in mind some important things\n\nOver complicating a build system that is already complicated may not help \nThe solution would need to be easily maintainable by you or any contributor (what i mean is that this should not be a time consuming solution otherwise we would remove the portable and add more distributions support)\n\n. I will add \"Clean issues..\" 57 are open and almost haft of then should be closed... just to keep things organized and avoid wasting time ;) \nAlso grouping similar one.... Duplicate of https://github.com/Eloston/ungoogled-chromium/issues/675 ?. @Eloston can you close this, it will be solved here https://github.com/Eloston/ungoogled-chromium/issues/619. Re enabling safe-browsing is a workaround, the patches needs to be updated to get a real fix . @TCB13 can you please develop i am not aware of that . Yes indeed i just forget to remove it was on the original script. you mean remove i guess... is not that related to the folder depth/location ?. ",
    "hrj": "@intika Great to see your enthusiasm. I can chip in about 5 to 10 USD per month and send it to any paypal account designated by @Eloston or @intika .\nIf we are able to collect the target of 30\u20ac/month, then fine. Otherwise, we can choose a smaller server and live with increased build time for now. Instead of 15 min per build, it might be 2 hours per build.\nIMO the important thing is to get the ball rolling.. Regarding the financial and legal overhead of managing something like this:\nI came across OpenCollective today, which might be suitable for this project. In a nut shell, they \"host\" a collective, which means they take care of the bank account and accounting hassle. People who incur costs for the collective can raise an invoice, and the collective's admin can approve the invoice. Once approved, the funds for the invoice are released. People who want to donate to the collective get more transparency.\nA good article explaining it is here\nIf there is interest and approval, especially from @Eloston, I will be happy to setup a collective for this project and see how it flies.. @Eloston It is definitely useful for infrastructure. I have seen collectives which have invoices for loomio for example. Here's another collective that was started for paying hosting and domain costs: https://www.reddit.com/r/ponylang/comments/9nw2uy/pony_is_a_now_a_member_of_opencollective_looking/\nAbout approval, I just meant informal approval, that is, confirmation that you don't mind something like this.\nI tried creating a collective for my own projects, but it requires some github permissions to the repo. So, I probably won't be able to create a collective for this repo. You, or somebody with contributor permission to the repo, will have to initiate the creation.. @Eloston As a first step, you could also consider pushing the build from Travis-CI to Github Releases pages as per this doc. That will take care of hosting atleast.\n. @Eloston Oh, that's an overarching permission. I understand your hesitation.\nI wonder how the permission system works. If you create a dummy Github account, add it as a collaborator on this repository (without write permissions), create an oauth token for the dummy account and give it to Travis, will Github allow code writes through that token? If it allows releases but not code-writes, then it might be worth exploring.\n. @Eloston Ah, ok.\nFWIW, Github seems to have come out with a new auth system yesterday. Here's hoping that Travis-CI leaps on to it quickly.\n. > I don't understand why using the OBS as suggested in #17 and #59 was rejected.\nIt wasn't rejected. #59 was closed as a duplicate of #17, which is still open. \n. @Eloston Probably, the GitLab CI system would suit this project. I haven't used it, but from what I have read:\n Works similar to Travis-CI\n It's open-source.\n* Can use our own build machines or use the ones provided on gitlab.com\n\nAside, is the cost of build machines a constraint? If so, I can chip in. I guess a single $5 per month Digital Ocean instance would be sufficient (?). And if more people contribute, one could run multiple builds in parallel (either for different platforms, or for cross-verification).. Nice to see progress. FYI, the Gitlab build configuration allows you to specify build artifacts. These are available for download for every pipeline/job. You could mark the tee output as a build artifact and thus not worry about the 4MB limit. You could also use the same idea to mark the generated .deb as a build artifact allowing anyone to download it.\n(I am familiar with this process but currently travelling; so I won't have time for another week to contribute directly) . ",
    "alexbakker": "Asking DigitalOcean for some free credits on their platform may be worth a shot. They're known to support lots of open source projects.. I think setting up some sort of build bot would be a good idea. It would spin up a beafy server every time a new release is ready, build all of the binaries, and destroy itself again. \nThe builds will be pretty expensive, however. I'm currently running a test on Digital Ocean to see how long a build takes on their $160/month server to determine the exact price. The servers could be paid for by crowd funding or by trying to get Digital Ocean to sponsor the project somehow :)\nEdit: Actually, the build instructions appear to be incomplete. I'm missing a bunch of dependencies. I'll try again later.. @Eloston I'd be very surprised if openSUSE provides the infrastructure required to build chromium in a reasonable amount of time for free.\nAlso, my test showed that the compilation on Digital Ocean took a little over 3 hours. That would be pretty expensive, around $0,70 per build.. ",
    "T-vK": "It wouldn't really be a problem to set up a private GitLab instance on a $5/month VPS, but we would need a maintainer who we can trust and who always ensures that the latest security patches are installed. And honestly there are not many people who I would trust enough to blindly load their binaries onto my computer. \nIn my opinion we should use a trusted service that takes care of the CI process. I'm not even sure if it would be necessary to pay for it at all. For instance, once #37 is resolved, we would be able to fully automate builds and distribution for Ubuntu, just by using a free gitlab.com account and launchpad.net.. Instead of running Gitlab on a rented server, how about using gitlab.com directly? They allow up to 2000 build minutes (=33 hours) per month. And in case we should ever need more, we could upgrade for $19 to get 10000 minutes. I'd be more than willing to donate. But for now 33 hours should be plenty.  https://about.gitlab.com/gitlab-com/\nI have used gitlab-ci before. If you're interested I could try to get it to build ungoogled-chromium and if I succeed I could give you the instructions.\nEdit: \nI just realize, they actually say We \u2764\ufe0f open source: public projects and groups get all gold plan features for free..\nThis would mean, we would get 50000 build minutes per month for free.. I was too curious too see what would happen and already started it a few hours ago. It seems to work so far (lots of warnings, no errors). I think the build process will take around 5 hours actually.\nI just found a limitation though. It will only display the first 4Mb of the console output.  \nYou can take a look at the build process here: https://gitlab.com/T-vK/ungoogled-chromium/-/jobs/47589261\nIs there a way to make the build output less verbose? Maybe don't display warnings, only errors?. Well, I could pipe the output to grep and strip out all lines containing the word \"warning\". But if an error, for some reason, contains the word \"warning\", then we won't see it.\nI could also use tee to pipe the unfiltered output to a file. But it would be a lot of work to keep the script from exiting after the build failed in order to send the file to some place where we could read it. \nEdit:\nOkay, here is another build attempt with the warnings stripped out: https://gitlab.com/T-vK/ungoogled-chromium/-/jobs/47652559\nEdit 2:\nOkay, the build succeeded. :)\nThe first time it took 12 hours for some reason and the second time it took 6 hours and 40 minutes. And by stripping out the warnings the log is now less than 4Mb. \nEdit3:\nIt was pretty easy to set up btw. You just need to add this .gitlab-ci.yml file to the project, then every push to the master will trigger a build job. And make sure to increase the default timeout of 60 minutes in the (Project!) Settings -> CI/CD -> General pipelines settings. \nI tried to set the repo up as a mirror which automatically syncs with a github repo, but the sync doesn't trigger the build unfortunately. It might be possible to tell github to trigger it using a simple REST call.\n. Just found another limitation: The artifacts can't be bigger than 100Mb: https://gitlab.com/T-vK/ungoogled-chromium/-/jobs/47700776\nI probably shouldn't have specified the whole build directory...\nI just started another build and this time I tried to only mark the *.deb, *..changes, and *.buildinfo files as artifacts. These are only a little over 56Mb at the moment. If this becomes a problem in the future we can still do a simple curl or ftp upload to some other place. \nHere is the new build: https://gitlab.com/T-vK/ungoogled-chromium/-/jobs/47776752  \n@Eloston \nI think it is possible to have a new tag be the trigger. About the PPA thingy. I would say, if it can be scripted in bash, then it can be done. Unless there is another unexpected limitation.\nEdit: \nI'm not quite sure if I understand this. On launchpad they say you have to upload a source package and then launchpad will attempt to build the package: https://help.launchpad.net/Packaging/PPA/Uploading\nIf anyone has any information on what the source package is and if we even have one, I would try to add this to the Gitlab CI file. \nEdit2:\n@Eloston \nI just figured out how to tell Gitlab to only run the the build job when a new tag was pushed.  \nI also found a setting which allegedly would make the build job run every time the repository is synchronized. (I couldn't test it yet, though)  (EDIT: tested and works)\nI was not able to find a way to manually trigger the sync process. (There's supposed to be an \"Update\" button, but it says \"Update scheduled...\"  for me and isn't clickable.) Triggering the \"update\" using the REST API results in a  401 - Unauthorized. \nAnd in addition to that the repo doesn't sync automatically (according to gitlab it would auto sync once every hour)... Not sure what to make out of that.  (EDIT: I stand corrected. It actually does automatically sync. It just takes 1.5 hours instead of the alleged 1 hour.)\nAbout the GitHub WebHooks: It doesn't seem to be possible to trigger the GitLab API with it. GitHub adds too much junk to the simple POST request which I would need, causing it to not get recognized by GitLab. \nIt might be possible work around this issue by using Travis CI (not to build, but) to run a simple curl command to trigger it. But for that the API would have to work in the first place...\nI'd say let's not worry about that, though. I mean the already auto sync works, it just takes up to 1.5 hours until it is auto synced. But in the end everything would happen automatically.\nEdit 3:\nThe build succeeded and the artifacts can be downloaded as a zip archive. On this site click on jobs and then there should be a download icon on the right: https://gitlab.com/T-vK/ungoogled-chromium/pipelines/16098473/builds\nAlternatively you can use the download icon on the main page and click download build: https://gitlab.com/T-vK/ungoogled-chromium/tree/master. @Eloston \nFrom what I understand, the artifact size limit is per job. So we could simply add more build jobs and build them all in parallel. But if you actuallly add the option to create a source package, we could just upload it to launchpad and let them do the hosting for the .deb packages.\nEdit:\nI managed to properly access the GitLab API from a Github WebHook now. GitLab responds with a 200 status code implying that everything went okay, but for some reason it doesn't trigger the pull.. @Eloston \nBut does it really have to be the same output? I mean we could for instance first do some compiling in the before_script and then have multiple packaging jobs that create different packages. \nSo we could have 100Mb for the debian packages and 100Mb for the linux_portable thing etc.\nI tried to build the linux_portable btw and it failed: https://gitlab.com/T-vK/ungoogled-chromium-mirror/-/jobs/47846500\nNot an existing flavor: 'minimal' \nDid I misunderstand the build instructions? I used ./utilikit/generate_build_files.py debian --flavor minimal --apply-domain-substitution . I was trying to compile the linux_portable, but I guess I misunderstood the building instructions and to be honest I still don't really understand them. There are lots of things that aren't clear to me.\nAt the moment the before_script just looks like this:\nbefore_script:\nbash\napt-get -qq update --yes\napt-get -qq install --yes packaging-dev python3 python ninja-build > /dev/null\nmkdir build/\nmkdir build/sandbox\nmkdir build/downloads\nand the debian package job looks like this:\n``` bash\n./utilikit/prepare_sources.py\n./utilikit/substitute_domains.py\n./utilikit/generate_build_files.py debian --flavor standard --apply-domain-substitution\ncd build/sandbox\ndpkg-checkbuilddeps # Checks and reports any additional packages needed\necho -en \"y\\n\" | mk-build-deps -i debian/control > /dev/null # install any additional packages needed\ndpkg-buildpackage -b -uc | grep -v \"warning\"\n```\nand that worked fine.\nNow the question is what should I move into the before_script and how would the debian package job change? \nFrom the new instructions you linked I would assume something like this:\nbefore_script:\n``` bash\napt-get -qq update --yes\napt-get -qq install --yes packaging-dev python3 python ninja-build > /dev/null\nexport UTILIKIT_CONFIG_TYPE=linux_portable\n./utilikit/check_requirements.py\nmkdir build/\nmkdir build/sandbox\nmkdir build/downloads\n./utilikit/prepare_sources.py\n./utilikit/substitute_domains.py\n./utilikit/generate_build_files.py # I assume this would't work for linux_portable?\n./utilikit/export_resources.py # Is this required in order to get the patches?\n\"2. Apply patches\" (Is \"1.\" missing?) I've never used .patch files, how do you apply them?\n\"Build GN via tools/gn/bootstrap/bootstrap.py\" - There is no such path in the project. Will this be generated? Or did you mean ./utilikit/build_gn.py ?\n\"Run gn gen with the GN flags\" - Do I have to parse resources/configs/linux_portable/gn_flags and add these lines as parameters to the command gn gen?\n\"Build chromium via ninja\" - now I'm really lost.\n\"Package the build outputs\" # using ./utilikit/archive_packager.py ? Where is FILES.cfg for--files-cfg `?\n```\nFor the debian build job script I can only guess.\nEdit:\nI just had another good idea to improve the build speed. We can just create our own docker image and tell Gitlab CI to do the building using that image. In that image we could do all the stuff that always needs to be done and doesn't really change with new releases of ungoogled-chromium, like installing python etc and maybe even a part of the before_script (?).... Edit: (Edited the whole comment)\n@Eloston \nOkay. For step 2, what are the \"necessary files\"? The whole build directory? The directory is bigger than the 100Mb limit, so that wouldn't work. The before_script might make more sense for this.\nI'm also unsure how to apply the patch that is currently necessary.\nShould this work?\npatch < resources/packaging/debian/minimal.patch\nSo the .gitlab-ci.yml file would look something like this:\n``` yml\nimage: debian:stretch\nbefore_script:\n  - apt-get -qq update --yes\n  - apt-get -qq install --yes packaging-dev python3 python ninja-build > /dev/null\n  - mkdir -p build/{downloads,sandbox}\n  - export UTILIKIT_CONFIG_TYPE=linux_portable\n  - ./utilikit/prepare_sources.py\n  - ./utilikit/substitute_domains.py\nstages:\n  - package\ndebian_package:\n  stage: package\n  script:\n    - export UTILIKIT_CONFIG_TYPE=debian_stretch\n- ./utilikit/generate_build_files.py debian --flavor minimal --apply-domain-substitution\n- ./utilikit/generate_build_files.py debian --flavor standard --apply-domain-substitution\n- cd resources/packaging/debian\n- patch < ./minimal.patch\n- cd ../../..\n- cd build/sandbox\n- echo -en \"y\\n\" | mk-build-deps -i debian/control > /dev/null # install any additional packages needed\n\n- # If necessary, change the dependencies in debian/control and modify CLANG_BASE_PATH in debian/rules to accomodate your environment.\n- dpkg-buildpackage -b -uc | grep -v \"warning\"\n- cd ../../\n\nartifacts:\n    paths:\n    - ./build/.\narchive:\n  stage: package\n  script:\n    - export UTILIKIT_CONFIG_TYPE=linux_portable\n    - ./utilikit/generate_build_files.py linux_simple --apply-domain-substitution\n    - cd build/sandbox\n- # Use \"export CLANG_BASE_PATH=/path/to/clang_files\" if Clang and related files are not located under /usr\n- ./ungoogled_linux_simple/build.sh\n- cd ../../\n- ./utilikit/archive_packager.py --files-cfg chrome/tools/build/linux/FILES.cfg --archive-format tar_xz --build-output-dir out/Default --target-cpu auto --output-file ./build/ungoogled-chromium.tar.xz\n\nartifacts:\n    paths:\n    - ./build/ungoogled-chromium.tar.xz\n```\nEdit2:\nChanged the code above.\nEdit3: \nI tried it on the latest develop branch and it fails. Any ideas? https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/47967733\nEdit4:\nIs there a specific place where you would like me to document the steps required to get everything running that I have so far? Should I create a pull request? . @Eloston \nOkay I updated the .gitlab-ci.yml. And I also created a Docker image. \nThe build job fails after these two lines:\npushd resources/packaging/debian/standard\npatch -p1 < ../minimal.patch\nhttps://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/48009184. Too bad.. Well, let me know when it's fixed. I'd really like to see this working.. Okay, I applied the PR and get a new error now: https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/48376514. @Eloston Any news/progress?. @Eloston Nice. :) I applied the change and the error is gone now.\nIt seems like the download that ./utilikit/prepare_sources.py tries to do is failing:\nhttps://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/51663632\nedit: There were just a few folders missing. I get pretty far now:\nhttps://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/51692646\n$ ./ungoogled_linux_simple/build.sh\n+ true /usr\n+ rm -rf out\n+ mkdir out\n+ mkdir out/Default\n+ env QUILT_PATCHES=ungoogled_linux_simple/patches quilt push -a\nNo patches in series\nERROR: Job failed: exit code 1. We shall see... https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/51767956\nEdit: \nYes, there is: -rw-r--r--. 1 root root 0 Feb  8 21:42 ./ungoogled_linux_simple/patches/series\nBut it is 0 bytes in size.. Ah, sorry yes of course.. https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/51773290\n/bin/sh: 1: ../../../../../../../bin/clang++: not found\nninja: build stopped: subcommand failed.\nI assume I need to set CLANG_BASE_PATH? But I'm not sure to which directory.. Seems to work. I guess this will take a few hours now: https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/51808431\nEdit: Not sure what happened. The runner we got this time was extremely slow, maybe so slow that it timed out. I restarted it: https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/52039324. It seems to work now. Only the artifact uploading failed for some reason. I'll try to fix that.\nEdit:\nWe should look into Open Build Service. From what I read it can provide package repositories for all sorts of dpkg and rpm based distros. It seems much more complicated, though. \nEdit:\nIt might also be worth it to look into alien-pkg-convert to convert deb packages to other formats like rpm.. Success!\nBuild: https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/52117512\nArtifacts: https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/52117512/artifacts/browse/build/. @Eloston I have not been able to get the packaging job to work yet: https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/52322641\ndpkg-buildpackage output:\n```\n$ dpkg-buildpackage -b -uc -nc\ndpkg-buildpackage: info: source package ungoogled-chromium-browser\ndpkg-buildpackage: info: source version 63.0.3239.132-1\ndpkg-buildpackage: info: source distribution stable\ndpkg-buildpackage: info: source changed by Maintainer maintainer@null\n dpkg-source --before-build sandbox\ndpkg-buildpackage: info: host architecture amd64\n debian/rules build\n debian/rules binary\nmake: 'build' is up to date.\ndh binary --parallel\n   dh_testdir -O--parallel\n   dh_update_autotools_config -O--parallel\n   debian/rules override_dh_auto_configure\nmake[1]: Entering directory '/tmp/debpkgs/sandbox'\noutput compiler information\ng++ --version\ng++ (Debian 6.3.0-18) 6.3.0 20170516\nCopyright (C) 2016 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nmake[1]: Leaving directory '/tmp/debpkgs/sandbox'\n   debian/rules override_dh_auto_build-arch\nmake[1]: Entering directory '/tmp/debpkgs/sandbox'\nmkdir -p out/Default || true\n./tools/gn/bootstrap/bootstrap.py -o out/Default/gn -s -j2\nmake[1]: ./tools/gn/bootstrap/bootstrap.py: Command not found\ndebian/rules:88: recipe for target 'out/Default/gn' failed\nmake[1]:  [out/Default/gn] Error 127\nmake[1]: Leaving directory '/tmp/debpkgs/sandbox'\ndebian/rules:85: recipe for target 'binary' failed\nmake:  [binary] Error 2\ndpkg-buildpackage: error: debian/rules binary gave error exit status 2\nERROR: Job failed: exit code 1\n```\nThe job:\n```\n    - export UTILIKIT_CONFIG_TYPE=linux_portable\n    - export sandboxdir=/tmp/debpkgs/sandbox\n    - mkdir -p $sandboxdir\nI'm assuming the conversion from the standard to minimal flavors was preserved from before_script\n- ./utilikit/generate_build_files.py --output-dir $sandboxdir debian --flavor standard --apply-domain-substitution\n- pushd $sandboxdir\n- mkdir -p out/Default\n- pushd out/Default\n- wget https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/52117512/artifacts/raw/build/ungoogled-chromium.tar.xz\n- tar xf ungoogled-chromium.tar.xz\n- rm ungoogled-chromium.tar.xz\n- popd\n- dpkg-buildpackage -b -uc -nc\n\n```\nAny ideas?. @Eloston What exactly do you mean by buildspace? Do you mean the \"build\" directory after all the commands from the before_script and build stage have been executed?. @Eloston ./buildkit-launcher.py getsrc says: \n2018-02-21 12:37:35,414 - ERROR: Buildspace downloads does not exist: buildspace/downloads\n\nwhich is weird because I ran mkdir -p buildspace/downloads.\nhttps://gitlab.com/T-vK/ungoogled-chromium-clone-2018-02-20/-/jobs/53630707\nedit:\nI think I would be able to upload a source package to this launchpad ppa via sftp from Gitlab-CI now. But I'm still not sure why getsrc failed.. Now I get:\n2018-02-22 09:54:37,556 - ERROR: Directory of file not found: [Errno 2] No such file or directory: '/builds/T-vK/ungoogled-chromium-clone-2018-02-20/buildspace/tree'\nhttps://gitlab.com/T-vK/ungoogled-chromium-clone-2018-02-20/-/jobs/53815547\nIf I create that directory, I get this:\n$ dpkg-source -b tree\ndpkg-source: error: can't build with source format '3.0 (quilt)': no upstream tarball found at ../ungoogled-chromium-browser_64.0.3282.168.orig.tar.{bz2,gz,lzma,xz}\nhttps://gitlab.com/T-vK/ungoogled-chromium-clone-2018-02-20/-/jobs/53816318. Since the official Chromium is available on Launchpad, I wonder if there is a way to get the information on how this has been done and if it could be adjusted to work with ungoogled-chromium.\nSome code can be viewed here for instance: https://bazaar.launchpad.net/~chromium-team/chromium-browser/xenial-stable/files but I'm not sure if that really helps.... Bad news, I got an email from GitLab:\n\nDear T-vK,\nAt GitLab we are working hard to make GitLab.com as stable and reliable as it can be. But sometimes it means that we need to enforce some limits to make the service stable.\nSince the beginning of CI at GitLab.com, our Shared Runners are available for all projects and are free of charge. However, to improve the reliability and general availability of Shared Runner for all GitLab.com users, we are forced to set a 3 hours build timeout for each job that is handled by these.\nWe have done a research to find out what is the best value for such timeout and we are convinced that 3 hours is a reasonable value, that will allow us to make the service stable and still affect as less projects as it can. At this moment, looking on the Project timeout setting in our database, we can say that enforcing chosen timeout may affect 584 projects. This means only 0.013% of all projects on GitLab.com.\nWe wrote \u2018may be affected\u2019, because not every job in projects that are using a bigger timeouts is indeed running for so long. But starting on May 8, 2018, a 3 hour timeout set on Shared Runners will take a precedence over the timeout configured in Project settings.\nYou are receiving this email because some of your GitLab.com projects are using Shared Runners and are specifying a bigger timeout than we plan to enforce:\nungoogled-chromium-dev-test uses timeout: 1mo 4d 17h 20m\nungoogled-chromium uses timeout: 1mo 4d 17h 20m\nStarting on May 8, 2018, timeout setting in specified projects will be overwritten by Shared Runners setting.\n\nIf any of your jobs need to work for a longer time than 3 hours, you may still provide your own Runners that will handle them. Please read the documentation at https://docs.gitlab.com/ce/ci/runners/README.html if you need a guidance for how to do this.\n\nIf you have any questions, please contact support@gitlab.com.\n\nSincerely,\nGitLab Support Team. I'll try. https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92052639\n\nLooks like the build worked: https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92052639/artifacts/browse/build/\n\nFor the Launchpad upload I'm not entirely sure yet. There are some things that I don't really get. \nFirst of all Launchpad seems to want a PackageName_Version_source.changes file which doesn't seem to get generated during the build process. And secondly they are talking about an ubuntu suite in the documentation without explaining what the hell that is supposed mean. So I'm not sure how to set up this part in the ftp config properly: ~<lp_name>/ubuntu/<ppa_name>/<an ubuntu suite>.\nhttps://help.launchpad.net/Packaging/PPA/Uploading#Using_packages_from_other_distributions. Sorry, I forgot to set the repo to be public. The links should work now.\n\nAccording to Ask Ubuntu, it seems we want to replace\ncd ..\ndpkg-source -b -uc\n\nIn the building.md under Building via source package you say dpkg-source -b src. Is that what I should replace with debuild -S -sa?\nI already have a GPG key that I generated some months ago and added to my launchpad account. I guess I'll have to dig out the private key again if we need it outside of launchpad.\nThanks for digging out the information on the suit thingy. I was not able to find that. I guess I'll just put in stretch then if I want to build for Debian Stretch?. I see. I'll try to get it to work with ubuntu bionic then. If we get the launchpad thing to work, I might also try to get it to work with OBS. I'm not sure if I understand the git abusing idea correctly. Where would the binaries come from? I mean we can't build them in CI because of the time limitations, right? I think it would be much nicer to have a fully automated solution.\nI found the GPG private key btw. But importing it to the CI docker container turns out to be very difficult.  I'll keep trying tough.  \nEdit:\nI finally managed to import the GPG key. Let's see what happens: https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92419835. Maybe this will fix this issue? https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92514801\nI pulled the changes and started another build: https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92519818. @Eloston Thanks. I just did another build: https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92569956\nLooks like I have some more work to do to make it recognize the imported GPG key? Or do you think this is something that has to be fixed in the sources?\nEdit: I think it tries to use a key with the user ID \"ungoogled-chromium Authors maintainer@null\", but of course the user ID of my key is different. Maybe passing the -k flag with the wanted key ID will fix this.\nEdit2: \nhttps://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92667907\nI'm getting a lot of these:\nE: ungoogled-chromium-browser source: source-is-missing third_party/analytics/google-analytics-bundle.js line length is 525 characters (>512)\nE: ungoogled-chromium-browser source: source-is-missing third_party/web-animations-js/sources/web-animations-next-lite.min.js\nand also this one:\nNow signing changes and any dsc files...\n signfile dsc ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc tavk tavk <t-v.k@gmx.net>\ngpg: signing failed: No such file or directory\ngpg: /tmp/debsign.6qMhz92i/ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc: clear-sign failed: No such file or directory\ndebsign: gpg error occurred!  Aborting....\ndebuild: fatal error at line 1081:\nrunning debsign failed\nany ideas?. I pulled the changes and started another build. https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/92885375\nI am replacing -- ungoogled-chromium Authors <maintainer@null> from the packaging/ubuntu_bionic/changelog.ungoogin file before the build btw because it seemed like the data has to match with the user ID of the GPG key.\nI haven't had the time to check if the files are actually missing.\nI got a new error message btw, during debian/rules get-orig-source:\nmake: *** [get-orig-source] Error 25\nSeems like the download fails every time. I retried a coupe of times, but I keep getting that error.\nI got that same error before the merge already btw.. @Eloston \nThe Error 25 came from me trying to replace the -- ungoogled-chromium Authors <maintainer@null> thing with the GPG user ID. I undid this. This time I'm getting make: *** [get-orig-source] Error 255:\nhttps://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/94960498\nI'm not sure what that means. It's really hard for me to debug because I don't have Debian or Ubuntu. So I have to constantly make changes, commit and push them, wait for Gitlab CI to build it and then check the build output for errors. \nThe error is coming form the debian/rules get-orig-source.. @Eloston Thanks, that helped a lot! I managed to get rid of the error. \nThis one: E: ungoogled-chromium-browser source: uploader-address-malformed Maintainer <maintainer@null> is gone now btw.\nI'm getting this one though: E: ungoogled-chromium-browser changes: changed-by-address-malformed ungoogled-chromium Authors <maintainer@null>\nhttps://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/95187525\nBy replacing the ungoogled-chromium Authors <maintainer@null> from packaging/ubuntu_bionic/changelog.ungoogin with the the GPG key's user ID, I managed to get rid of that one as well.\nhttps://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/95194118\nThe file ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc seems to be missing:\nNow signing changes and any dsc files...\n signfile dsc ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc tavk tavk <t-v.k@gmx.net>\ngpg: signing failed: No such file or directory\ngpg: /tmp/debsign.hwokAatw/ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc: clear-sign failed: No such file or directory\ndebsign: gpg error occurred!  Aborting....\ndebuild: fatal error at line 1081:\nrunning debsign failed\nAnd I still get these source-is-missing errors for a lot of files in the third_party directory.\nI'll try to do an ls on a few of these pathes before the debuild to check if the files are actually missing.\nedit: I couldn't find the location of the third_party directory. Do you know where it is?. @Eloston I also changed the identity in debian/control now, but I till get the error saying that ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc is missing.\nhttps://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/95610619. Of course. \nI'm still getting the same error: https://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/95980083. In the meantime I ran find / -name \"google-analytics-bundle.js\" before the debuild and also after the debuild fails and bot times I get no result. Not sure what to make out of that. I mean the error message does say source-is-missing , but at the same time it's talking about the line length of that file:\nE: ungoogled-chromium-browser source: source-is-missing third_party/analytics/google-analytics-bundle.js line length is 525 characters (>512)\n. Weird, I guess it's only temporarily being unpacked during the debuild command then? Anyway, I extracted the source tree and found the file in there. The line in question doesn't have any sort of domain string in it:\n(function() { 'use strict';var h,aa=aa||{},k=this,m=function(a){return void 0!==a},ba=function(){},ca=function(a){var b=typeof a;if(\"object\"==b)if(a){if(a instanceof Array)return\"array\";if(a instanceof Object)return b;var c=Object.prototype.toString.call(a);if(\"[object Window]\"==c)return\"object\";if(\"[object Array]\"==c||\"number\"==typeof a.length&&\"undefined\"!=typeof a.splice&&\"undefined\"!=typeof a.propertyIsEnumerable&&!a.propertyIsEnumerable(\"splice\"))return\"array\";if(\"[object Function]\"==c||\"undefined\"!=typeof a.call&&\nThe other files for which source-is-missing was reported seem to be there as well.\nI also checked if the ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc is actually missing and it's not. It's located in build/ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc but debuild seems to expect it at /tmp/debsign.YogMWoVr/ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc. My guess is that it tries to copy the file to that tmp location and then sign it in there and finally copy it back. And the first copy step probably already fails. But I don't know.... Still stuck at that gpg: /tmp/debsign.ndBgYzyR/ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc: clear-sign failed: No such file or directory error. :/. @podshumok \nI just tried. Unfortunately it didn't seem to work. \nI basically did this:\n```\nexport DEBUILD_SIGNING_HOOK='(pwd; lstree /) > lstree_gitliab_artifact.txt'\ndebuild -i -S || echo\nAnd then I checked for the file:\nls -la\ntotal 32\ndrwxr-xr-x. 4 root root 4096 Nov 18 06:37 .\ndrwxr-xr-x. 3 root root 4096 Nov 18 06:38 ..\ndrwxr-xr-x. 6 root root 4096 Nov 18 06:38 debian\ndrwxr-xr-x. 3 root root 4096 Nov 18 06:37 third_party\ncat lstree_gitliab_artifact.txt\ncat: lstree_gitliab_artifact.txt: No such file or directory\nhttps://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/121993418. @podshumok that doesn't appear to work either..\n$ echo \"#!/usr/bin/env bash\" > signing-hook-script.sh\n$ echo \"(pwd; ls -la; tree /) > lstree_gitliab_artifact.txt\" >> signing-hook-script.sh\n$ chmod +x signing-hook-script.sh\n$ export DEBUILD_SIGNING_HOOK='signing-hook-script.sh'\n```\nhttps://gitlab.com/T-vK/ungoogled-chromium-launchpad/-/jobs/122212458\nMaybe the current directory is not the one I expected during the execution of the signing hook. I'll try to specify absolute paths.\nEdit: Nope, it's still not working. Even if I specify absolute paths.. @podshumok \nThe man page is indeed wrong. \nHere is the output of the signing hook. (ls -la / followed by tree /) https://t-vk.gitlab.io/-/ungoogled-chromium-launchpad/-/jobs/123825062/artifacts/build/lstree_gitliab_artifact.txt\nWhile attempting to sign a file using gpg I made a very helpful observation.\nWhen the file to be signed does not exist you get an error like this:\ngpg: can't open '/non-existing-file.txt': No such file or directory\ngpg: /non-existing-file.txt: clear-sign failed: No such file or directory\nAnd when only the output directory does not exist, you get an error like this:\ngpg: writing to '/non-existing-output-dir'\ngpg: pinentry launched (585 curses 1.1.0 not a tty - -)\ngpg: signing failed: No such file or directory\ngpg: /existing-file.txt: clear-sign failed: No such file or directory\nComparing that to the error that is currently preventing the ungoogled chromium file from being signed: \ngpg: signing failed: No such file or directory\ngpg: /tmp/debsign.hwokAatw/ungoogled-chromium-browser_68.0.3440.106-1~bionic.dsc: clear-sign failed: No such file or directory\nthe issue might actually be that the output directory that debuild passes to gpg doesn't exist.. The devscripts package version is 2.17.12ubuntu1.1.\nUnfortunately mktemp seems to work :(\n$ TMP_FILE=\"$(mktemp)\"\n$ ls -la /tmp\ntotal 20\ndrwxrwxrwt. 1 root root 4096 Nov 23 10:17 .\ndrwxr-xr-x. 1 root root 4096 Nov 23 10:17 ..\n-rw-------. 1 root root    0 Nov 23 10:17 tmp.nKYuLBJlJm\n$ echo \"test 123\" >> \"$TMP_FILE\"\n$ ls -la \"$TMP_FILE\"\n-rw-------. 1 root root 9 Nov 23 10:17 /tmp/tmp.nKYuLBJlJm\n$ cat \"$TMP_FILE\"\ntest 123. People with the necessary skill set to do so, seem to be very rare though. May I ask why you don't want to accept donations?. @funghetto Debian sid is unstable and uses 4.9. Just to give you a perspective, this kernel  is 6 months old. Fedora is way on top of that with 4.11, which is the latest. \n@Eloston Okay, thank you.. @funghetto \nI don't know, Fedora feels quite stable. Personally, I would compare it more to Debian's testing branch.\nI've never actually tried running Debian's experimental or unstable branches, but I've heard some bad things and feel like it's too risky. But maybe I'm just lucky with my Fedora.... I tried it on gitlab and it still failed: https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/48375840\nThen I added the suggested flag and it also failed: https://gitlab.com/T-vK/ungoogled-chromium-dev-test/-/jobs/48376514. ",
    "sixtyfive": "Whatever you feel you should do, you should do. Because in turn, at the moment there doesn't seem to be an awful lot of trust in you from the side of distributions. At least Solus think it's better to stay away from ungoogled-chromium: https://dev.getsol.us/T1117 .. @Eloston Is there any way to get in touch with you privately? GPG mail, etc.?. I didn't know that one, thank you! Here's the download command if anybody else wants to get that extension without first having to look up the download URL scheme and inserting the ID into it:\nwget -c https://clients2.google.com/service/update2/crx?response=redirect\\&prodversion=48.0\\&x=id%3Ddpjamkmjmigaoobjbekmfgabipmfilij%26installsource%3Dondemand%26uc -O emptynewtab.crx```\n. Perhaps you can identify the point in the code where it starts the installation by searching for things related to drag-and-drop? Even though I guess the browser does a lot of other drag-and-drop as well.\nAs for the \"Install via id\" button, I was thinking:\n1. User enters id (as found in the appstore or sent by someone else like @stfnhrrs did in another ticket) in a text input field and clicks the button next to it.\n2. Browser inserts the id into the URL found at https://github.com/Eloston/ungoogled-chromium/blob/master/FAQ.md#can-i-install-extensions-from-the-chrome-webstore\n3. Browser opens that URL in the background trying to download a .crx file from there, e.g. to /tmp/extension-foi4ntjrnk2kjjew.crx\n4. Browser tries to install that file the same way it would if the \"Install from file\" button had been clicked\nThat might be over-complicated or nonsensical. You know the code and might have a better idea.\nAs for the \"Download more extensions\" link: shouldn't it be possible to visit a Google domain if the user explicitly requests the browser to do so? As for the web store not working, I personally don't care. Perhaps it's a good thing it doesn't work, because that requires you to think a little more about whether you really need an extension...\n. Sounds awesome! I'll remain subscribed! :smile: \nI didn't think of there being any other place than Google's store to get crx files from. It's a good point. A more sophisticated solution might be to try and parse a URL given by the user. I.e. figure out whether it's a web store address or a GitHub address or whatever. But that'd need too much work I guess. Just a thought.\n\nThat's true, but I don't have a system in place to exclude domain substitution on parts of a file. Considering the Web Store doesn't work for installing extensions, its use is kind of limited.\n\nHow about just removing it (and other things that don't work) then?\n. Just out of curiosity: isn't the tool used to apply patches sort-of smart about where to apply them? Such a string seems like a very easy thing to track automatically and remove from wherever it is...\n. ",
    "ArjonBu": "@intika Why did you tag me? \nBTW Just use the opensuse build service. . Because opensuse build service will create them all see this example: https://software.opensuse.org/download.html?project=home%3AHorst3180&package=arc-theme\n. ",
    "macandchief": "Just a remark: For less experienced users it is a bit unclear how to install this browser. I was struggling with the process (even if I studied the github description). I found some install instructions in a forum of the debian based distro called bunsenlabs helpful.\nFor Stretch, amd64 (one liner):\nmkdir ~/src && cd ~/src && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/58.0.3029.110-1/chromium_58.0.3029.110-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/58.0.3029.110-1/chromium-widevine_58.0.3029.110-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/58.0.3029.110-1/chromium-shell_58.0.3029.110-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/58.0.3029.110-1/chromium-l10n_58.0.3029.110-1_all.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/58.0.3029.110-1/chromium-driver_58.0.3029.110-1_amd64.deb && sudo gdebi chromium_58.0.3029.110-1_amd64.deb && sudo gdebi chromium-driver_58.0.3029.110-1_amd64.deb && sudo gdebi chromium-widevine_58.0.3029.110-1_amd64.deb && sudo gdebi chromium-l10n_58.0.3029.110-1_all.deb && sudo gdebi chromium-shell_58.0.3029.110-1_amd64.deb\nThis requires wget and gdebi and it downloads the packages in a folder called src and installs them. Those packages are older than the packages in the repos, so apt upgrade tries to replace them. To avoid upgrading the following command helps:\nsudo apt-mark hold chromium chromium-driver chromium-l10n chromium-shell\nAs I mentioned this is for less experienced users but it might be helpful to point out such steps in the description. Great work btw, it's striking how less resources this browser uses when all the junk has been removed. . Ok, thank you for the details, that's great with ungoogled-. I'm looking forward to give version 62 a try.. v62 got released, fantastic! If there is v58 already installed, is simply running the following a proper way to update?\nmkdir ~/src && cd ~/src && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium_62.0.3202.94-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-widevine_62.0.3202.94-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-shell_62.0.3202.94-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-l10n_62.0.3202.94-1_all.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-driver_62.0.3202.94-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-common_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-common_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-driver_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-widevine_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-l10n_62.0.3202.94-1_all.deb && sudo gdebi ungoogled-chromium-shell_62.0.3202.94-1_amd64.deb. @Eloston Yes, indeed, the part from my post might be more useful elsewhere as the topic clearly changed and does not suit to Push to Debian.\nSo this is how the update v58 -> v62 went:\nFirst I run (although it might not be necessary as I removed these packages later):\napt-mark unhold chromium chromium-driver chromium-l10n chromium-shell\nAfter that I tried the one-liner I posted, but:\nThis package is uninstallable\nDependency is not satisfiable: ungoogled-chromium-common (= 62.0.3202.94-1)\nI was thinking about installing ungoogled-chromium-common first and the package ungoogled-chromium after that, but: dpkg: error processing archive ungoogled-chromium-common_62.0.3202.94-1_amd64.deb (--install): trying to overwrite '/usr/lib/chromium/natives_blob.bin', which is also in package chromium 58.0.3029.110-1\nAt this point I simply removed the installed packages (first I used this command without the chromium-shell package, but it needs to be removed. otherwise it gives an error message while installing ungoogled-chromium-shell):\napt remove chromium chromium-shell\nAnd after that:\nsudo gdebi ungoogled-chromium-common_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-driver_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-widevine_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-l10n_62.0.3202.94-1_all.deb && sudo gdebi ungoogled-chromium-shell_62.0.3202.94-1_amd64.deb\nThere is an error message if chromium-shell wasn't removed, but I mentioned it already above:\ndpkg: dependency problems prevent configuration of chromium-shell:\n ungoogled-chromium-shell (62.0.3202.94-1) breaks chromium-shell and is installed.\nIf I'm not mistaken apt-mark hold is not necessary anymore.\nUpdate done. The browser is working fine! Some extensions needs to be updated (re-installed too). Fantastic work, well done.\nAccording to these steps I guess this is how an update v58 -> v62 should work as a one liner:\nmkdir ~/src && cd ~/src && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium_62.0.3202.94-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-widevine_62.0.3202.94-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-shell_62.0.3202.94-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-l10n_62.0.3202.94-1_all.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-driver_62.0.3202.94-1_amd64.deb && wget https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/62.0.3202.94-1/ungoogled-chromium-common_62.0.3202.94-1_amd64.deb && sudo apt-mark unhold chromium chromium-driver chromium-l10n chromium-shell && sudo apt remove chromium chromium-shell && sudo gdebi ungoogled-chromium-common_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-driver_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-widevine_62.0.3202.94-1_amd64.deb && sudo gdebi ungoogled-chromium-l10n_62.0.3202.94-1_all.deb && sudo gdebi ungoogled-chromium-shell_62.0.3202.94-1_amd64.deb\nThere will be the packages left in the ~/src directory but after the update these can be also removed.. In that superuser thread the Kill Evil extension https://chrome.google.com/webstore/detail/kill-evil/epieehnpcepgfiildhdklacomihpoldk was mentioned.\nIn Scriptsafe there is also \"Options/Fingerprint Protection/Prevent Clipboard Interference\" to check.. Besides blocking scripts and spoofing user agent I'd like to add two add-ons that are important for Ungoogled Chromium v62 (as it has WebRTC now and on default WebGL is enabled):\n- WebRTC Protect\n- Disable WebGL\nuBlock Origin has a Prevent WebRTC... setting too. To install an extension protecting from canvas fingerprinting is also a good idea. . May I ask: Do I understand it correctly that WebRTC will be enabled on default in this browser?\n. I see, thank you for the quick response. Somehow I had the understanding that being WebRTC removed is an advantage from a security point of view. As a comment under the \"Chrome bug that lets sites secretly record you 'not a flaw'\" says: \"Disable WebRTC which honestly from a security and privacy standpoint you should have disabled anyway as it leaks information such as your real IP address and location even when using a VPN.\"\nI liked it not being part of Eloston/ungoogled-chromium, but I guess it simply means that I will have to care about to disable it in the future.. Yes, I understand. Although those complains seem to be a bit strange to me as basically every other browser from FF over Chromium till Brave have WebRTC, if anyone needs it. While I considered it to be the unique feature of ungoogled chromium having basic functionality without all the junk (which makes it absolutely fantastic - and secure -, especially with the right add-ons being fast and easy on resources). Obviously it's ok too to add it and using something like uBlock Origin in the future. Anyhow thank you for the clarification.. It seems that the method with this link https://clients2.google.com/service/update2/crx?response=redirect&prodversion=48.0&x=id%3D[EXTENSION_ID]%26installsource%3Dondemand%26uc does not work on Ungoogled Chromium v62.. In the end I tried every method given on the readme page and somehow none of them worked for me (even tried maninex and it did not work because of python2). However there is  https://chrome-extension-downloader.com/  which simply downloads the .crx file, so drag & drop on the extensions page works that way.. I like Startpage. Often read about privacy concerns regarding DDG. I'd like to mention framabee.org, which is based on searx. Considering results I'd say these are the best choices: startpage or a searx instance like framabee.. I think this is a good idea. I suspect in the OP it wasn't meant to be a separate github page, but more like an own site. Something like www.ungoogledchromium.io   \nThough I think simply \"Eloston Browser\" sounds much better (and as a slogan: Ungoogled Chromium). I know the files just got a new name (not like before with Chromium), so you might not even consider this, which is of course all right, but it's just sort of \"uneasy\" to write every time \"Eloston/Ungoogled Chromium\".\nwww.elostonbrowser.io\nUngoogled Chromium\nThis just looks and sounds too good.  :). @Eloston Well, I think it's not just me, but many users call it (write about it as) \"Eloston/Ungoogled Chromium\". This seems to be sort of the \"official\" name for the browser, showing e.g. right now on the window border. \nI do understand your points, especially the last one about being too egoistic, but the truth is though, that you put so much work in the project, that the browser even deserves to be called \"Eloston Browser\".If the responsibility is passed, nobody in his right mind would question the brilliant idea of starting the project and the amount of work to build it up step by step.\nUngoogled Chromium states the objective of the project, but with \"Chromium\" in the name it's not as unique as \"Eloston Browser\" - as mentioned, it just sounds good, easy to pronounce (and ungoogled chromium is a perfect slogan). Let's take Vivaldi as an example - it was surely better for that project in comparison to \"Pre-tuned Chromium\". Just my 0,02$.. Those .deb files seem to be unavailable at the moment.. Same here!\nGreat project, fantastic work, well done.. ",
    "Atavic": "WebKit Trac has a good list about Fingerprinting.\nAlso see: https://github.com/Eloston/ungoogled-chromium/issues/13 https://github.com/Eloston/ungoogled-chromium/issues/55. EDIT: My point is that the test sites need JS enabled.\n. Which distro exactly?\n. I retrieved this:\nhttps://chromium.googlesource.com/external/webrtc/+/master/webrtc/common_types.cc\nby looking at mozilla wiki that linked to a similar common_types.cc. https://clients2.google.com/cr/report is also used for Crash Reports.\nHere there are some comments. Here is a parser. Hope it's somewhat useful.\n. Paragraph 6.4.2 [Page 41] of http://www.ietf.org/rfc/rfc3550 is listed here.\nIt's for optimization of audio and video streams, based on bandwidth and eventual lags.\nMonitoring happens in real time for 10 seconds here.\nWhat I have gathered today is that proto is the log stored locally.. Wireshark could come handy.. Bug report.. >WebRTC is another attack surface (security concern);\nFirefox and Chrome have implemented WebRTC that allow requests to STUN servers be made that will return the local and public IP addresses for the user. These request results are available to javascript, so you can now obtain a users local and public IP addresses in javascript.\nAdditionally, these STUN requests are made outside of the normal XMLHttpRequest procedure, so they are not visible in the developer console or able to be blocked by plugins such as AdBlockPlus or Ghostery. This makes these types of requests available for online tracking if an advertiser sets up a STUN server with a wildcard domain.\n\nWebRTC leaks one's local IP address; WebRTC could leak data (privacy concern)\n\nuBo is preventing the not-internet facing machines info to be sent (or leaked), while the machine connecting to the WebRTC service is still announced (that's needed for WebRCT to work).. The CLI switch\n--force-webrtc-ip-handling-policyhas some options that limit the interfaces opened to WebRTC communication.. The term interfaces used here refers to network cards.\nFor clarification, see: https://datatracker.ietf.org/doc/draft-ietf-rtcweb-ip-handling/?include_text=1. @jhuss https://github.com/hunspell/hunspell. > How can we ban the certain extensions to access internet, or filter their connections?\nYou can use a OS Firewall.. This repository removes Google integration and enhances privacy.\nBetter safe than sorry.\nSee: https://github.com/Eloston/ungoogled-chromium/issues/179. I'm no lawyer, but if I read here:\n\nHowever, please notice that by uploading contents to Conan you expressly grant Conan the right of distribution, reproduction and public communication of the contents, as established in the Intellectual Property Act (Minimum Required License) as this license is needed by Conan's platform to render its services to other users.\n\nI see that the user grants a license to this barbarian.. Sure, but does it mean that the user gives the intellectual property to Conan? . Zero Round Trip Time Resumption (0-RTT) is included into QUIC, an Alphabet (Google) effort.\nA good explanation is here. Issues like this make even sense? This is ungoogled-chromium and you want to use it with Google Meet? Use Google Chrome instead!. Ok, now understand your position. Corporations like MS, Apple, Google and Amazon are improving the grip on their customers every minute. My only idea (for an issue that I met myself) is to install more browsers or use more profiles for specific needs. Even Virtual Machines can be useful.. Because it is disabled with this option when chromium is built from source.. Writable Files API. ",
    "ciampolo": "I had to write this already for another repo but PLEASE DO NOT SPOOF YOUR OS, the only thing it does is make you so easily identifable it is astonishing. It is more than foolish to assume Github, Google etc. are not abusing this since at least a decade.\nTCP/IP fingerprinting works without Javascript/HTML/CSS; just by pinging a server that server can tell your OS and even rough version like WinNT X, Linux Kernel xx etc. That's the reason mozilla decided to keep the original OS even if privacy.resistFingerprinting is enabled.\nBest bet is to use a VPN service with many users that is hosted in a trustworthy EU country (as in DACH or BENELUX). Everything else should be considered unsafe, while anything from the Five Eyes countries should be considered malicious. If you care any percent about privacy and then still pipe your traffic through any of UK/US/CA/AU/NZ you should really just stop using the internet and open your private home to the general public, including that Nigerian prince.. ",
    "probonopd": "I am already converting Chromium snapshots from https://download-chromium.appspot.com/dl/Linux_x64?type=snapshots to AppImages in a fully automated way using Travis CI. It would be easy to do for ungoogled-chromium if there are deb packages, too.\nAppImage has the advantage that it runs on most (also older) distributions.\n. Can you provide ones for debian oldstable or trusty? That way the resulting AppImage could run on more but the very newest distros.\n. \"Are there enough people that use distributions that old?\" - I cannot answer that but I do know that projects like Firefox and LibreOffice put a lot of care to build on old systems to maximize compatibility.\n. Can you get it to build on Travis CI?. Providing an AppImage would have, among others, these advantages:\n- Works for most Linux distributions (including Ubuntu, Fedora, openSUSE, CentOS, elementaryOS, Linux Mint, and others)\n- One app = one file = super simple for users: just download one AppImage file, make it executable, and run\n- No unpacking or installation necessary\n- No root needed\n- No system libraries changed\n- Works out of the box, no installation of runtimes needed\n- Optional desktop integration with appimaged\n- Optional binary delta updates, e.g., for continuous builds (only download the binary diff) using AppImageUpdate\n- Can optionally GPG2-sign your AppImages (inside the file)\n- Works on Live ISOs\n- Can use the same AppImages when dual-booting multiple distributions\n- Can be used with different sandboxes of the users' choice (e.g., Firejail, Bubblewrap)\nHere is an overview of projects that are already distributing upstream-provided, official AppImages.\nFP has sandboxing built in but FP needs to be installed on the target system first.. Sorry @Swiftpaw but some of your claims are simply not correct (e.g., FP needs to be installed first, scatters files into the filesystem, and does not work on Live systems, just to name 3). In order not to further spam this thread, let's close this here though.. How does one use the linux_portable base bundle to build?. Can you please point me at what I have to do on Ubuntu 14.04 (the oldest still-supported LTS release) to get the dependencies in place?\n$ sudo apt-get -y install clang-6.0 lld-6.0 llvm-6.0-dev python python3 ninja-build\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package clang-6.0\nE: Couldn't find any package by glob 'clang-6.0'\nE: Couldn't find any package by regex 'clang-6.0'\nE: Unable to locate package lld-6.0\nE: Couldn't find any package by glob 'lld-6.0'\nE: Couldn't find any package by regex 'lld-6.0'\nE: Unable to locate package llvm-6.0-dev\nE: Couldn't find any package by glob 'llvm-6.0-dev'\nE: Couldn't find any package by regex 'llvm-6.0-dev'\nThank you.. Running into\n$ ./get_package.py linux_simple build/src/ungoogled_packaging\nTraceback (most recent call last):\n  File \"./get_package.py\", line 18, in <module>\n    from buildkit.common import (ENCODING, BuildkitAbort, get_logger, validate_and_get_ini,\n  File \"/home/travis/build/probonopd/ungoogled-chromium/buildkit/common.py\", line 42\n    return schema_dictcast({configparser.DEFAULTSECT: object, **data})\n                                                               ^\nSyntaxError: invalid syntax\nReference:\nhttps://travis-ci.org/probonopd/ungoogled-chromium/builds/420681072#L599-L606. Using Python 3.6 (the newest one I can use) seems to remove that error, but now I am running into\n+./tools/gn/bootstrap/bootstrap.py -o out/Default/gn -s\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 80\n    print 'Building gn manually in a temporary directory for bootstrapping...'\n                                                                             ^\nSyntaxError: Missing parentheses in call to 'print'. Did you mean print(t 'Building gn manually in a temporary directory for bootstrapping...')?\nReference:\nhttps://travis-ci.org/probonopd/ungoogled-chromium/builds/420686866#L1305\nHow can I enforce ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn -s to use Python 2.7?. With python2 I now get\n+python2 ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn -s\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 115\n    exec(response, _globals, _locals)\nSyntaxError: unqualified exec is not allowed in function 'CallPythonScopeScript' it is a nested function. After having pulled in Python 3.6.3 from a PPA, this error seems to be gone and I now have a new error:\n/home/travis/build/probonopd/ungoogled-chromium/build/src/base/template_util.h:145:46: error: no template named 'is_trivially_copy_constructible' in namespace 'std'\nusing is_trivially_copy_constructible = std::is_trivially_copy_constructible<T>;\n                                        ~~~~~^\n1 error generated.\n[7/367] CC base/third_party/libevent/evrpc.o\nninja: build stopped: subcommand failed.\nCommand '['ninja', '-C', '/tmp/tmp3nKiQf', 'gn']' returned non-zero exit status 1\nhttps://travis-ci.org/probonopd/ungoogled-chromium/jobs/420804430#L2399-L2405. Thank you. More errors... https://travis-ci.com/probonopd/ungoogled-chromium/builds/82908706#L2463-L2488. Yes, I am building on Trusty. Here is my .travis.yml.. > In that case, you may want to do what Arch Linux does for Python 2 on these lines\n@Eloston I don't know where to insert those lines. Since you know a lot about how to build Chromium (and I don't), do you think you could clone my .travis.yml and get it to work up to the line https://github.com/probonopd/ungoogled-chromium/blob/67483c0f3ee6fd5817f5af90a1b54b67b1fc1b8e/.travis.yml#L43? Then I could take over from thereon.\nThanks for your help!. The latest binaries on https://github.com/ungoogled-software/ungoogled-chromium-binaries/releases are from Dec 19, 2016?\nEDIT: There is more at https://ungoogled-software.github.io/ungoogled-chromium-binaries/ (why not on GitHub Releases?). Are they working on trusty?. > so that python becomes Python 2\nI am doing this explicitly here:\nhttps://github.com/probonopd/ungoogled-chromium/blob/67483c0f3ee6fd5817f5af90a1b54b67b1fc1b8e/.travis.yml#L35. Can you describe how e.g., https://ungoogled-software.github.io/ungoogled-chromium-binaries/releases/linux_portable/64bit/67.0.3396.87-2 gets created? Where is it compiled, where are the build logs, etc.? It would be most likely really trivial to hook in AppImage generation into the existing pipeline in this case.. Not sure I read the 2nd document correctly, but are you saying there is no CI build pipeline (Jenkins, GitLab CI, Travis,...) and project members/you are building on local machines? If so, what kind of local machines (which distribution)?. > That is correct. For some background, I have declined offers in the past for dedicated building hardware because I did not want to handle that kind of responsibility. I also did not want others to feel obligated to provide the hardware either. It was a questionable perspective in hindsight, but that's where we are at now.\nI fully understand your decision (and have made my fair share of mistakes trusting random people lending housed hardware in the past).\nSo, essentially if I write a bash script that takes the Portable Linux build and turns this into an AppImage, that's all you'd need?. I have written an initial recipe to convert the existing build into an AppImage:\nhttps://github.com/AppImage/AppImages/blob/master/recipes/ungoogled-chromium.yml\nFeedback appreciated.. Thanks for your feedback @Eloston.\n\nHow can I find the URL to the latest version? Do you have a permalink URL that redirects to the latest, for example? We could also change it so that instead of downloading something it copies in some local deb, but for that we would at least know the name and location of that deb.\nAre you referring to the fact that I change the desktop file to say \"Ungoogled Chromium\" instead of \"Chromium\"? I think this is the correct thing to do since the name of the application is actually \"Ungoogled Chromium\", and we need to somehow distinguish it as something different from upstream Chromium. Please keep in mind that users may have multiple versions of Chromium on their machine, both Ungoogled and upstream. What should I do?. > You have written quite the shell command to determine the Portable Linux binary to download, but it's assuming that I will be the uploader. This will fail if someone else uploads a Portable Linux binary.\n\nWho else could be the uploader? And where would those files be hosted? Can the name of the uploader be determined dynamically? How?\n\nThe other alternative would be to parse the INI file\n\nLike so?\nexport VERSION=$(wget -q \"https://raw.githubusercontent.com/Eloston/ungoogled-chromium/master/version.ini\" -O - | grep chromium_version | cut -d \" \" -f 3)-$(wget -q \"https://raw.githubusercontent.com/Eloston/ungoogled-chromium/master/version.ini\" -O - | grep release_revision | cut -d \" \" -f 3)\necho $VERSION\nThis currently gives me https://github.com/Eloston/ungoogled-chromium-binaries/releases/download/68.0.3440.106-1/ungoogled-chromium_68.0.3440.106-1_linux.tar.xz but that file does not exist, there are only debs. So looking at version.ini doesn't look like a viable strategy to me. \nI have not quite understood what the problem is in the current method of getting the most recent available *_linux.tar.xz. Can you please elaborate and describe the optimal strategy? Thanks.. Would this be a good strategy?\n\nLook at https://raw.githubusercontent.com/ungoogled-software/ungoogled-chromium-binaries/master/releases/linux_portable/64bit/index.html and take the topmost version from the list there\nUsing that version number, get the corresponding ini file from https://github.com/ungoogled-software/ungoogled-chromium-binaries/tree/master/config/platforms/linux_portable/64bit and look up the URL from there\nUse that URL to generate the AppImage. @Eloston that'd be of course awesome, as it would a) be much easier for users b) \"official\" (never trust applications downloaded from random sites - especially browsers!), and c) would allow the application to be listed in the AppImageHub central directory of available AppImages.. > Well, AppImage suppport is in now. \n\nPlease don't forget to update\nhttps://github.com/Eloston/ungoogled-chromium/blob/cc80091a8e6b357e6ba8fc21ab566a63255fc90d/docs/building.md#building-an-appimage-flatpak-or-snap-package\non how to get it.. > may be you want it to be build and published by @Eloston\nyes \ud83d\udc4d . Who ensures how that we can trust those binaries?. Yes, I'm highly interested in peer-producing a web-of-trust!. ...hence I was wondering if we could/should use Travis CI or something like it for the builds (not just the AppImage). See https://github.com/probonopd/AppImageKit/wiki/Bundling-Google-Chrome for an example on how to bundle Google Chrome as an AppImage.. Run on a debian or Ubuntu system:\nwget \"https://github.com/probonopd/AppImages/raw/master/recipes/meta/Recipe\"\nwget \"https://github.com/probonopd/AppImages/raw/master/recipes/meta/Ungoogled_Chromium.yml\"\nbash -ex Recipe Ungoogled_Chromium.yml\nThis will use the latest ungoogled-chromium deb files available on GitHub Releases and convert them into an AppImage. Please provide wheezy packages that could be used as ingredients for the AppImage. This would make the AppImage run on older but the most recent systems, too.. It should. Let me know if it doesn't.. @Lesik it's not an either-or. Why not have both. Strange as it may feel to you, a \"real repo\" is not what all people prefer, because it's always targeting only one specific distro. And yes, if you download Chromium for macOS or Windows, too, it comes with its own set of libraries that are not shared with other applications.. Which is why the application should try to work with the system openssl instead. Which openssl does the official Google Chrome use?. Should be fixed in https://github.com/probonopd/AppImages/commit/cb68c174338ea93aa4fe164cb3a60336b95cdfc7. Some fine tuning will probably be necessary. Specifically, be aware that it will only run on Linux distributions no older than the one this was compiled on. So to maximize compatibility, compile on an older system.. @Gridlocked what error did you get?. That sounds more like a generic firejail issue on the system than something with this specific AppImage. Do other AppImages run?. May be worth reporting at https://github.com/netblue30/firejail/issues.. @Gridlocked personally I wouldn't want to get into the habit of downloading AppImages from \"random\" dropbox links, so possibly this project may consider to do official AppImages and upload them to GitHub Releases?. @Gridlocked perfectly fine with a Dropbox link for such testing reasons, just wanted to suggest additionally a more official one ;-). > The Appimage is cool - thanks to those who worked on building that.\nif (...) I would not be surprised if the Fedora steering committee decided that ungoogled-chromium should be the version officially shipped \nThat is the main philosophical difference - with distribution packaging, applications must be \"in line with\" and \"supported by\" the distribution in order to have a good user experience, whereas AppImage is explicitly built to enable upstream application authors to provide their software in a format that runs well without such approval.. @eLement87 thanks, changed.. About the cookie thing, the sane thing would have been to have a setting in the browser, that in turn would communicate the user's consent (or lack thereof) to cookies as part of the request header.\nPlus, as long as i don't click \"accpet\", do websites still use cookies? Because I never click these buttons.... ",
    "sahal8020": "Since AppImage can handle updating the package as well, this approach might be suited to be the \"official\" way to provide the app. In addition to less work building for different distros, this also minimizes the bugs related to dependencies hell (e.g. #107). I'm suggesting this especially since you're not able to support the project as much as you used to. \nI personally use Ubuntu so having this application on APT (#37) would be nice. Imho though, focusing more on unGoogling chromium should be the highest priority and where the majority of the fine work be. If someone sees the convenience of installation/updating as a higher priority, they can always install chromium/chrome.\n. @Eloston I know you closed this but I think there's merit to a name change\n- Ungoogled is very antagonistic. Though it might draw the privacy oriented person, it might drive away many non-techie people who would see this as \"hackers crazy stuff\"\n- Current name might draw the attention of Goliath and unnecessary troubles that would just make life harder for a resource-limited project\nImho, since your point was made already with the name as is, renaming into a distinct brand sometime soon wouldn't hurt (I believe it'll help!). This is especially if you involve the community in name/logo design and selection and the like. The message as @ajkblue wouldn't be lost if it was renamed to something like Pure Chromium, Clean Chromium, Chromium Liberated, etc. You can just look at thesaurus for more inspiration.\n. ",
    "ghost": "Would be great to see flatpak or appimage replace all the existing builds.  Now that the stand-alone build is possible this should be easy I think.  I always thought flatpak had better integration features than appimage but not sure.  FP has sandboxing which I don't think AI has (by default?).  Sandboxing would probably be a good idea for an additional layer of security.. Works for most Linux distributions - so does Flatpak\nOne app = one file = super simple for users - so is Flatpak\nNo unpacking or installation necessary - if by \"installing\" you mean have launcher icons created for the easy launching of games and apps then this is a feature that users want so both formats need to create those.  Also, if you mean AI keeps running from the same downloaded file and doesn't make a copy into a hidden location, that's annoying because the user would lose the app if they cleared out their downloaded files.  I'd rather it was \"installed\" so I could save the installation package if I so chose to do so but that had no impact on me continuing to run the app.\nNo root needed - same for flatpak, plus sandboxing\nNo system libraries changed - same with flatpak.\nWorks out of the box, no installation of runtimes needed - runtimes, if they are used, are automatically downloaded and installed.  Having shared libraries is a good thing and means FP packages are going to be smaller than AI packages since AI has no library sharing.\nOptional desktop integration - FP's integration is default AFAIK\nOptional binary delta updates - FP's default\nGPG2-signing - FP has it\nWorks on Live ISOs - FP can be installed on liveISOs just like any program can be, and if FP was included by default if it takes off and becomes a good standard, then obviously installation wouldn't be needed.\nCan use the same AppImages when dual-booting multiple distributions - I'd think you wouldn't need to duplicate the app data with either system.\nCan be used with different sandboxes of the users' choice (e.g., Firejail, Bubblewrap) - I'm not sure if FP can work with alternate sandboxing, but as long as FP uses the best one and there's no big reason to use a different one, that wouldn't matter much.. Uh what?  Did you even read (and comprehend) anything I wrote?  Or do you try to shut down anyone whom you think is biased even though I was simply listing the features of each package system that I know about?  You were the one who sounded biased by listing several features that you made sound exclusive to AI over FP which is totally incorrect as my original reply pointed out.\n\"FP needs to be installed first\"...while AI doesn't, is how you were intending that?  This wasn't a bullet point mentioned, but that's correct if that's what you meant.  If you're referring to \"works for most Linux distros\", both FP and AI are compatible with most Linux distributions, but FP isn't available out-of-the-box, not until it comes standard.  It's easy to install on all those distros, though.  So yeah, AI is a little better in this regard, so what's your problem here?  Explain yourself.\n\"Scatters files into the filesystem\", I was arguing that FP probably does this while AI might not?  Given that FP needs to be installed first, and that FP \"installs programs\", I assume AI doesn't need to copy files elsewhere while FP does.  My point was that this isn't necessarily a bad thing.  I like installing packages and not having to keep the package file around on my desktop if I want to run the same app again in the future.  So, what are you trying to say about this part?\n\"Does not work on Live systems\", the only thing you mentioned was \"FP\", so I assume you're talking about FP here?  Regardless, I was saying that FP does work in Linux environments, and that both will do so.  You can run anything in a live environment because it's just a RAM disk.  There is nothing particularly special about putting program data into a RAM disk instead of a HDD.  You can even download, install, and run games in a live environment as long as that live environment enabled sufficient graphics drivers to do so.  So, explain yourself here again too, what about this do you disagree with?  Since that's the defensive attitude you're showing.\nBoth FP and AI have some features that the other doesn't have, but overall they are fairly comparable and they are both step ups above the old static binary method and either solution would be better than trying to make repos for every distro out there.  I'm in favor of both, but you, probonopd, acted like the things you listed are exclusive features of AI over FP, and that's definitely wrong, hence my original response.. Eloston, it works, but when i launch browser opens \"http://chromium/cache\" page instead of the home page. I use --user-data-dir=c:\\users\\vladimir\\other\\ungoogled chromium\\cache in shortcut configuration\n. Eloston, yes, now everything works as it should. Thank you!\n. @Eloston But what about CryptoTokenExtension? How to delete/ remove it?. It would be good to have linux version of it too which would be portable. \n(GNU/Linux Debian 8 & Linux Arch)\n. Any progress? Guess that a ungoogled-chromium app in the F-droid repos will be beneficial for a lot of people, also on CoS. . Seems like as we're very close to release, the project has come to a hold a little bit... Any idea when the pre-built binaries will be released?. Sorry to bother you, but here's the description of the inox-patchset:\n\"Inox patchset is applied on the chromium source code and tries to prevent data transmission to Google to get a minimal Chromium based browser. The patches are split up based on features, so it's easy to patch only a subset of them.\"\nSnippet from the Iridium Browser page:\n\"Chromium (which Iridium is based on) is a very secure browser, yes. But it does call home to Google. And we did even more to enhance security to the maximum extent possible.\" \nAnd here's ungoogled-chromium's:\n\"Modifications to Google Chromium for removing Google integration and enhancing privacy, control, and transparency\"\nI support what you're doing, but I don't understand what's different. Sorry!\n(Also, is there a way to auto-update extensions that from the chrome web store? I know I can install them, but at the very least is there a way to tell if there's an update? Thanks!) \nEdit: s/can\\'t/don\\'t/g . Sorry!. I understand. Sorry!. Damn... looks like a LOT of stuff to do to get it running.\nI'll see if I can dedicate time to doing it sometime, but yeah it looks way over my head.\nI'll do my best, but I really appreciate if you or anyone else reading this who knows what they're doing can make new Windows builds sometime.\nThanks.. Well, after looking into it more and getting up to barely step 2... yeah I think it's fair to say that I can't do this myself. \nI thought the process might be something like just needing to install Visual Studio or Python and some dependencies and then running a command to compile or something, but it's clearly not that simple and you need to actually know how to code and stuff. I'd need to take university courses in coding to know what I'm doing in any of this, since I've never written any actual programming or anything (my \"code\" knowledge ends at HTML/CSS, which is hardly what anyone would call coding).\nSo yeah... if anyone does know how to do this then I would seriously appreciate it if you can take it upon yourself to get this done and let Eloston add it to the contributor binaries section.\nFor the time being I guess I'm switching to Iridium since that's probably the closest I can get to Ungoogled Chromium for Chromium 58+, until I switch to Linux.\nThanks for the responses though.\nEdit: Actually Eloston, would you suggest Iridium, or the \"NoSync, No WebRTC, No Widevine\" version of Chromium provided at Woolyoss here?: https://chromium.woolyss.com/ (second entry in the second box down)\nThe plus side to those too is that you get the bleeding edge new Chromium with it as well (currently 61).\nI'm not sure if it might be even better than using Iridium. Iridium talks about making those things more secure, but this distro of Chromium outright doesn't include them. I don't need them for anything so I figure maybe this might be even better.. > Well that's essentially how it would work once Windows support is added back in (it would be similar to the oudated Windows build instructions). Regular Chromium is even easier to setup if you use depot_tools.\nIn that case, will it be easier to just wait until that's done?\n\nFor step 1, I should clarify that it's probably best to learn the command-line as you go. That way you can connect your knowledge to something that's concrete and practical.\n\nWell I at least know how to use the command line to an extent. \"cd %DirectoryHere%\" etc. I can navigate in it and do a few basic things, but I've never had to use it a ton.\n\nFor a project like this, you don't need to take a programming class. In fact, all of my projects on GitHub so far aren't that conceptually difficult; most of it is just a matter of creating some framework (for code and potentially files) and attaching pieces to it (whether it be libraries or programming language features). You can pick up fundamental programming concepts from practically anywhere in almost any form, which is pretty much all you really need conceptually to work on ungoogled-chromium.\n\nYeah, it just seemed like the kinda thing I'd need a teacher actually there showing me the ins-and-outs for me to learn. To be honest I flunked the easiest math course there is, and coding seems very math-like and anything that's not in plain English tends to lose me and start seeming cryptic to me. I was barely able to complete an HS computer science course. Much as I love computers, my actual best courses were English and humanities, haha. The most coding I've been able to do is HTML and CSS - Java looks cryptic to me and I was able to modify some Lua for a game before but that was mostly just guesswork and copy/pasting things from one place to another...\nWhat I learned is that while I'm good at memorizing what to do inside a GUI or OS and can fix the vast majority of people's problems, I'm far from being actually \"good with computers\". I'm just as good as any tech support at BestBuy or whatever else is, not a coder or anything.\nBut I may take another crack after this \"Windows support\" issue is out of the way. Maybe that'll make it easier. Step 5 sounded like it was going to be way over my head which made me feel like \"Well even if I could get that far, I'm certain to hit a dead end at that point\". \nIf it becomes as easy as just installing dependencies and compiling, I could do that. But I suppose once it becomes that simple you'll probably just start providing binaries yourself, huh...\nHonestly, just getting that specific VS that Chromium wants, \"Visual Studio 2015 Update 3\", was hard enough. They seem to want you to make an account with them just to get to it, and I was like, \"Screw that I guess I have to pirate it then\" (I hate Microsoft, and making unnecessary accounts for things), and well that took a while to do.\nI might revisit when the update issue is fixed. Sounds like I need to know some Python to be able to get it done anyway.\n\nIridium takes this a step further by patching code and using custom GN flags. One nice feature they add is the trk scheme, which is essentially a way to check if hardcoded URLs to Google are still being used despite patching. However, they do redirect some traffic to Iridium's own servers, which is a questionable decision in my opinion. Regarding their claim about being \"secure\", I'm not really sure what exactly they mean; most of their patches are to prevent data from being sent to Google or tweak default preferences. There aren't any patches that stand out as increasing security.\n\nThat's kinda what I was thinking - it looks to me like Iridium is nothing more than just \"Oh, it's Chrome but with different defaults, which you could easily just set by downloading Chrome and doing it yourself\". Which in that case I would just use Chrome. The choice to redirect to their own servers is kinda sketchy even.\nI mean, I already disable all prefetching and form autocomplete and saving passwords and stuff like that, and even block all cookies and javascript except ones from sites I explicitly whitelist. I also flip a few switches in chrome://flags and have a suite of extensions.\nI'm not sure if Iridium and other browsers are really doing much more than that to help. And in that case I may as well just get normal Chrome until Ungoogled Chromium is caught up or I switch to Linux which will eventually be happening (I take it you keep the Linux/Debian binaries updated).\nWhat interested me most about the projects is just ensuring that truly zero data is sent to Google, and eliminating binary blobs. Everything else falls upon the user and their choice of preferences I would think.. Ha, I just saw this while checking up on Ungoogled Chromium. Must have forgotten to update after getting it working.\nIn the end I was able to get it running. Involved uninstalling a few conflicting things iirc. This was a while ago now though.\nSorry to revive a dead thread, just thought I'd say that I did get it working in the end but it involved deleting quite a few things manually from Debian 9. Perhaps those things were in the Debian 9 because it was a Qubes VM as opposed to an actual fresh install of Debian 9. Also comes to mind is that I updated that Template VM from Debian 8 to Debian 9 at some point. Perhaps they were residual leftovers. No idea though. I believe Qubes 4 should have all of it's Template VMs stock-updated so hopefully that won't be a problem in the future.\nYou might notice I'm also the person that asked about building it on Windows. Looks like Iridium is going to update to Chromium 60 before long. I've been using it for Windows lately since UGC is kinda Windows-unsupported for now.  Hoping that Chromium 60 might be a change for that, or at least you'll keep up with Debian builds.\nThanks!. You can see the method I used to update the Debian 8 TemplateVM to Debian 9 here: https://www.qubes-os.org/doc/template/debian/upgrade-8-to-9/\nIt could've left behind the conflicting files assuming they're present in Debian 8 and aren't automatically cleaned out by the upgrade, I suppose. Though I figured Step 5 would handle that.\nAnd that sounds great. I know that Windows support has been broken for 58, but I was hoping that Google itself would address this problem eventually for later Chromium versions, like 60. Right now it seems that you have to install a bunch of obscure nonsense and fix a bunch of things to build it on Windows, and I wouldn't think they'd just leave it a mess like that.. Great job getting this started! Anticipating the result.\nI see you already got the first three steps done - but be sure to check back with Iridium when they push out their own version 60 which should be soon. May be best to wait until that before releasing a new build, just to be sure you don't miss anything.\nAs I said before, I'd love to help with the Windows if I actually understood what I was doing. But last time I tried I ended up concluding that if I could do it, you surely would've figured it out already. I hope that Windows support will be easier this time, crossed fingers.\nGranted, I've largely moved on to Linux, I'd still love for my Windows machine to have it too.. Try visiting IridiumBrowser.de right now.\nAnyone else getting the same security warning that I am? Looks like their HTTPS/SSL certificate has gone bad... strange. Hope nothing bad has happened with them.\nGlad I have their latest version pre-downloaded. I don't think downloading from them would be smart to do while their certificate is invalid.. I think there may be no point in waiting for Iridium after all.\nLooking at their Git and branches and what-not, I kinda wonder if the project has silently died. Maybe the devs got too busy with other things and the project is mostly abandoned now.\nOr maybe they're just working on it and it'll be out later, I dunno. The github just looks kinda dead.\nHey @Eloston, are you aware of Brave by the way? It's a distro of Chromium being worked on by the co-founder of the Mozilla project apparently - https://brave.com/\nNot sure if anything from that can be incorporated into UGC though.\nThere's also Comodo Ice Dragon to look at: https://www.comodo.com/home/browsers-toolbars/icedragon-browser.php\nJust more browsers to consider. These are all the top picks for chromium-based browsers that are serious about privacy/security. Just thought I'd mention them all.. @Eloston @xsmile  Yeah I have no idea about Iridium, all I know is that their due date passed so I checked in on their Git and there wasn't much going on it seemed. I started thinking that if it might just be a hobby project by a few geeks and maybe it's falling through now, dunno though. I know that's been the case with so much software out there.\nYou might be right, they could just be waiting for Chromium 61. In that case I guess Eloston could just update to 61 instead, right? Unless that would cause any problems or roll back your progress so far, in which case I wouldn't worry about it and you can just make a new release later.\nAs for the other browsers, I don't really know much about them either, just found them in searches for \"Most Secure Web Browser 20XX\" and stuff, which I do once in a while. I mean there's also stuff like Epic Privacy Browser and the likes, and I know there used to be WhiteHat Aviator and stuff.\nTruthfully, I figure most of these are basically just Chromium with extensions built-in. If you're a power-user that knows how to tweak your settings and install extensions then most of them are basically pointless IMHO, and I fall into that category. There's so many \"Chrome Distros\" nowadays and that seems to be the idea - repackage Chrome with some built in extensions, change the icon and rename it, yay you have a \"new\" browser. I've even considered trying this myself. The self-promotion articles on some of them even make me laugh a little, I mean, what the hell does \"military-grade performance\" even mean? Saying that implies they even know what the military uses, and that's a secret I'm pretty damn sure.\nBasically there's as many Chromium distros as there are Linux distros nowadays, and it seems the same underlying principles behind them - repackage the thing with some different defaults or installations. But with no changes to the underlying core, it's nothing you couldn't have achieved on your own provided with the original. More advanced stuff like Qubes gets omitted as I think it actually does have kernel modifications. Seems to me that it's all just for people too lazy to learn. \nBut... I guess that's the job of us techies, and why we have job security, right? Sometimes I forget some people really just have no interest in this stuff and just trust us to deal with it so that they don't have to. They pay for the convenience and because this junk doesn't interest them, it ain't their job. I guess I shouldn't be so quick to put down every project that doesn't include core code changes - it's just that when I see a project that doesn't really DO anything code-wise, I look at it and say \"Hey, this is something anyone with a bit of experience with the GUI could do, this isn't anything new or revolutionary, what the heck?\"\nMost of what these browsers do can be achieved with a couple extensions and some settings tweaks from the default No-Flash No-Widevine No-WebRTC version of Chromium you can get from Woolyss. \"Blocks third party cookies and sends a no-track request!\", yeah okay I can do that myself thanks. Extensions like uBlock Origin, AdGuard, HTTPS Everywhere, ScriptSafe, Decentraleyes, PrivacyBadger, Disconnect, Stealth Mode, Proxy SwitchyOmega, a nice hosts file, etc can handle the rest. But I digress...\nAnyway, Brave had my attention because it seems to be a bit more than that, being that it's actually being worked on by Mozilla and has an entirely different interface by what I can tell. The specifics of what they've done security/privacy wise I don't think anyone has an ordered list of or anything. It's open-source and I figure the best way to check it out is to just download them and use them a bit and you probably get the idea if any of what they did is worth putting into your own project.\nPerhaps I'm wrong though, it could just be another repackage that's just been styled up a bit. I guess the \"Mozilla\" on the product just made me take it more seriously. As a well-established  tech foundation I didn't take them as the type to do such a thing, especially when the \"market\" is already oversaturated with them and there's no need for another one. Guess I just have higher expectations of Mozilla.\nJust figured I'd let you know about them and see if you thought anything of them, more or less.. @Eloston Yeah I'm mostly just grumbling, as I do on most forums. I'm just a bit of a grumbly guy.\nWhat I meant with that bit wasn't just about monetary incentive, but rather that people leave it up to us power-users to do things for them because they don't wanna learn it, because it doesn't interest them and is just work to them, work that they leave to computer nerds. Which is why I said, maybe I shouldn't be so quick to dismiss anything that doesn't do core changes - just because I understand how to do it myself doesn't mean everyone does I guess. \"Good for you\" I guess is what they'd say.\nUngoogled Chromium is a bit better, I've read about the actual changes that Iridium and Inox do and they seem like things that'd be more of a hassle to try to do on your own - things that go a bit deeper than just tweaking some settings, adding some extensions, or changing a few things in chrome://flags. Things like the trk scheme and increasing encryption or whatever, and source cleaning etc. Sounds like a lot of things are contained in flags that aren't accessible by just going to the flags panel in the browser, like you have to change them before compiling the browser or something. And compiling it on Windows is yeah, a huge pain in the ass it sounds like it.\nI don't know much about the \"Debian patches\" though.\nWell, actually, until either Iridium or even better, Ungoogled Chromium is updated to a more recent version, I'm actually just using the No-Sync, No-WebRTC, No-Widevine (and there's no Flash either of course) version of Chromium 62 from Woolyss. Jesus the actual Chromium project goes really fast. \nI've actually thought on the drawbacks of just switching to stock Chromium permanently and manually changing everything I can would be. I basically concluded that I'll keep on Ungoogled Chromium or Iridium if either one can keep a Windows release within 1-2 versions of the latest. If it can't do that then I may just stick to the Woolyss Chromium, because I feel that the security and feature updates that Google implements are more important to have than my tinfoil hat NSA-conspiracy fears. I lock it down pretty well using extensions and settings anyway, and I run it's traffic through both a VPN and Tor - so ya know... it's probably good enough. Bluntly put - if they can get past all of that then the changes in UGC probably isn't going to matter either. If the NSA conspiracy stuff is true then I'm just stupid to even still be on Windows, using any software (especially closed-source) made by a for-profit corporation at all,  or be on any device using any modern Intel hardware at all (fortunately, Purism is working on rooting out the Intel Management Engine and putting a blobless Coreboot on their machines with all drivers/firmware fully freed too, which has my attention).\nWill keep using Ungoogled Chromium on Linux machines either way though of course, since it seems to have less trouble keeping up on Linux (as long as that continues to be the case).. > It's kinda nice to have a browser like this, even though there are probably quite a few other things that have more of an impact on my privacy and security.\nTrue that. It's a nice thing to be making, and we appreciate the fruits of your hobby. I do still like Ungoogled Chromium and will continue using it where it's still updated.\nMight you update to 61 instead? Since it's already out as a stable build and stuff...\nBut generally I think instead of putting yourself on a version-dependent schedule, how about just checking once a month and updating to the latest version as of that time? Seems like it'd be a better way to manage the workload. Sometimes Chromium probably wouldn't have any updates, and others maybe they'd have two updates within a short timeframe. But you needn't pay attention to that - just re-release UGC on a fixed date every month, or maybe even once every-other month is probably fine.\nBut yeah, when talking about security and privacy with someone, I stress that all else aside, there are really just a ten rule list that REALLY impacts security and privacy.\n\nUse strong passwords and keep them stored in a secure database (keep backups!). Never use a weak or non-random password, and never use the same password twice.\nUse a VPN, one that utilizes OpenVPN with AES-256 + SHA-256 and at least RSA-2048 (though mine uses RSA-4096) strongly preferred.\nKeep your shit updated - especially your OS and browser and router firmware. Given infinite time and resources, any hacker find an exploit. But keeping updated keeps you ahead of them. Their methods are almost always only effective against people who aren't up-to-date.\nSecure your network. Learn how to browse your router configuration.\nUse open source software and firmware as often as possible.\nUse extensions and HOSTS file (link to a great one) to block all the nastiness of the web. Learning how to use a Script blocker/manager is a plus. These are also ways to block fingerprinting, but the usefulness of doing so is subject of debate and breaks some sites.\nDon't use sites that don't use SSL. Best to just tell HTTPS everywhere to block all unencrypted requests. Still, I understand the need to lower that shield for sites you know are fine and still want to use.\nClear your temp data / cookies often, and block third-party cookies. (Some sites still need them sometimes though, like some functions of YouTube needs docs.google.com to be allowed sometimes).\nFlash and Adobe Reader are cancer, don't touch them. Ever. No site worth your respect still uses Flash and Chromium can open PDF - and if you don't use Chromium there's plenty of alternatives.\nLearn how computers and the internet work, and change your habits! Know how to spot sketchy nonsense. There's no replacement for common sense, this is the most important rule!\nExtra - if you use Windows 10, please seriously consider getting the LTSB version... it's Windows 10 without all the crapware and spying pre-installed (mostly - still disable things in Privacy panel).\n\nThat last one is really something I stress. An educated mind is the strongest defense online - you'll rarely ever have any problems as you'll naturally avoid bad things, and even if something DOES get passed your defenses, you'll act quickly and accurately to counter it.\nExtra for Admins! : Hash and Salt your databases, and NOT with MD5! It's 2017 FFS!! I cannot believe how many sites still use this. I'm looking at you Equifax. And at you PayPal - you work with people's money, how the hell can you be this way?\nProTip: If a site has a character limit of 20 or less and restricts use of most \"special characters\" etc, it reeks of them using an outdated method to store passwords. Those kinds of restrictions usually means they're just storing your password as an MD5 hash, which was broken more than a decade, with the first flaws being found more than TWO decades ago.\nAlso if the \"forgot password\" function just sends your plaintext password to your e-mail address - you need to run the hell away, because that means they're storing your password in plaintext. This was something some users noticed about Equifax. Tch, who the hell are they to be \"rating\" people when they themselves are clearly not anyone worth respecting when it comes to security?\nThat's pretty much it. From there, usually it delves into black-magic fuckery and \"SUSPECT EVERYTHING!!\" tinfoil hat stuff. Which I'm all for, as long as it doesn't break anything. I recently stopped using a lot of the Windows 10 Privacy apps because they were doing more harm than good, causing lock-ups and crashes, all for the sake of my own paranoia. Which may be justified paranoia, but still... if you're that afraid of Windows and Microsoft then why the hell are you even still on it? That's right. Games and production software. So just have two machines then - one for that and one for stuff you don't want people to know. Done and done.\nBlah, sorry, rambling again. Keep up the good work dude!. Well being blunt I just pirate it off of TPB from Generation2. Yeah, getting it the official way would be a hassle and expensive. And yeah, reinstalling is necessary, though I do that every 3-6 months anyway.\nThe pages for Visual Studio may say that LTSB is unsupported but it works anyway. I think they just say that because they haven't really tested it very much on those versions, which makes sense because it wasn't intended for being a developer platform.\nBut yeah, that comment was really more aimed at the guest audience anyway. As a developer I figure you know what you wanna stick to.. Go guys go!\nWas cool seeing your little discussion in the last thread. Was starting to look like this project was having people come together as a team. Would be kinda cool to see a sort of UGC-Inox merge if that's possible.\nI just know that I like seeing the collaboration and discussion.\nNot sure what to think of Iridium. They're not meeting their deadlines or giving any comment. Think they might've dropped it. Hope you can continue to implement their changes anyway.\nWill definitely keep using it on Linux, but fingers crossed for a Windows build.\nEither way, definitely referencing it as a good browser on my own personal site (a place where I reference lots of helpful tools and security/privacy stuff, which I'm revamping now).. > Moved from Firefox quantum to Chrome thanks to this project ;)\nFor me it is because Firefox is far worse on the privacy side. If you tcpdump it - not only it connects to Google (for unsafe browsing and who knows what else) but also to other hosts of Amazon, Akamai, Mozilla (for telemetry and what not), OCSP etc. Chromium at least communicates only with 1 entity. Of course through certain combinations of about:config settings Firefox background chatter can be reduced but it requires quite a lot of fine tuning and constant monitoring as in new versions they keep adding more and more \"features\". When I reported all that to Mozilla they ignored and closed my bug reports, didn't update their documentation about how to stop background communication and as a whole behave in a very repulsive way. People who trust \"non-profit\" Mozilla (actually a multimillion dollar corporation) are very mislead imo.. \"respecting our users is at the core of what we do\" is the latest Google's nonsense in this bug report about Chromes privacy issues related to connections to Google:\nSo once again: huge thanks to @Eloston for this great project.. I use ungoogled-chromium with TOR socks proxy. However I find a difference comparing it to Tor browser bundle (TBB). I don't know why but some websites which use Cloudflare show captcha challenge test while the same sites work on TBB without showing that. Testing in command line with the exact same headers which TBB sends also results in recaptcha page:\ncurl <url> \\\n--proxy socks5h://127.0.0.1:9050/ \\\n-H 'User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:60.0) Gecko/20100101 Firefox/60.0' \\\n-H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' \\\n-H 'Accept-Language: en-US,en;q=0.5' \\\n-H 'Accept-Encoding: gzip, deflate, br' \\\n-H 'DNT: 1' \\\n-H 'Upgrade-Insecure-Requests: 1' \\\n--compressed\nSo it seems to me TOR socks may not be enough and TBB may be adding something else to the whole picture.\nThoughts?. And one more thing: the feature to request a \"new identity\" in TBB is essential for avoiding the possibility of fingerprinting based on site visits associated with UA string + IP address. TBB can request at least a change in the IP address. However in UGC all we can do is wait for (~10 minutes) until the tor service connects another socket. So ideally a function which can spoof UA an IP (periodically, manually or more fine controlled) would be great. Not sure what programming that requires though... (trusting UA-spoofing extesnions is questionable too). > Tor have nothing to do with the scope of this project... at best a fork should be made for that purpose\nWell, this issue has not been marked as rejected but as enhancement and is still open which I read as \"open to discussion\". So I don't quite see the reason for downvoting my comment which is on topic for both Tor and privacy in general.. I didn't suggest integration or any particular development strategy. I just read what @Eloston said:\n\nI suppose some UI to make this configurable for private tabs wouldn't hurt.\n\nand shared some observations and general privacy considerations along these lines (as Tor is about privacy).. > Is it not possible to do this in an extension?\nI am not aware what extensions can and cannot do, so I cannot answer. But you can take a look at Tor Browser's User Manual which explains about managing identities.\n\nI believe Tor integration should be fine if it's an optional feature.\n\nMy thoughts exactly. It should be up to the user.\n\nNamely, what kinds of features beyond the capabilities of extensions would be included?\n\nAFAIK TBB runs its own tor service. It also includes that security slider which I personally find fairly useless as one who cares about online anonymity would generally always keep it on \"Safest\" position as the moment JS comes into action the game of cat and mouse changes quite a lot in favor of the mouse.\nAnother thing which should be given special thought IMO and which is currently problematic in TBB (being a Firefox fork): the \"fingerprint\" which can be created by extensions themselves. Example: extensions like uBO which connect to various hosts to update their lists etc. This is a privacy problem because one can be identified by the pattern of the hosts one connects to which does not depend on IP address, UA string or cookies. Right now there is this issue related to Firefox's bug which causes \"private browsing\" (AKA incoginto mode in Chrome) to always force an update of all lists in uBO. While there is no such bug in Chrome (respectively UC) I think it should still be considered and addressed properly if a Tor-like or similar extra privacy features are implemented. For example: in \"anonymous mode\" (or whatever it may be called) such connections should not be made through the same identity which the actual browsing uses. Otherwise anonymity can be compromised.\nSimilarly: special care should be taken to warn the user that browsing the web itself may create a detectable pattern. To prevent this: Ideally each HTTP request should be made through a separate identity. However while this may work for sites which don't require a login (cookies) it may be problematic for ones which do. I am not aware of how this can be done efficiently. Just sharing some thoughts on the subject as many people falsely think that it is enough to hide one's IP address in the Tor network and that gives them the perfect hide away.. > tweaking settings at a pretty high level\nYes. That's why the bug report is titled \"Privacy disrespected (by default)\".\nAs you can see my test is also based on monitoring network connections. Not using wireshark but tcpdump.\n\nIf you do find a leak, please report it.\n\nI have already done this - not in ungoogled-chromium but in chromium itself. I thought you might be interested to test the same in your tweaked version and check if it is fixed. Considering you already have a compiled version it will be much easier than waiting for me to learn how to compile your version, then test it etc. Of course - I will, but it may take a long time and if it is an actual leak, it may still not be fixed while you wait for me. Hence the whole report here. I hope that clarifies.. Thank you for the additional explanation. I will read how to build the software on openSUSE and report back if I find anything else.. Thanks for the reply!\n\nungoogled-chromium is Google Chromium sans integration with Google. [...]\n\nOK. This answers the Profiles question.\n\nFor convenience, ungoogled-chromium first generates packaging scripts for various systems. [...]\n\nI have never packaged software so for the moment I am not concerned about building a distributable package. So that convenience is not of primary importance to me. As you may have guessed from the nature of the questions: I am rather interested in being able to configure/customize the build, install it where I want, git-update/recompile it when appropriate and maintain it this way for all computers I manage. And all this - whithout creating conflict with existing (distro-provided) packages, their configs or file paths. Do you think you could please answer the rest of the questions? (as I don't know python and finding the answers by looking at your code was difficult for me, even after a few hours)\n\n[...] most of the defaults come from Inox browser [...]\n\nWhen you say most that implies there are others which don't come from that browser. Could you please elaborate? Also - what should one do if one wants to modify Inox's (or the rest of the) settings?. Thank you for the explanations and sorry for the late reply.\nI will look at the build process you guys described.\n\nsearch engine (DuckDuckGo by default) [...] UGC defaults are more than sane enough privacy-wise.\n\nDDG is a bad choice as it is hosted on Amazon:\n[~]: host duckduckgo.com\nduckduckgo.com has address 46.51.179.90\nduckduckgo.com has address 176.34.155.23\nduckduckgo.com has address 79.125.105.113\nduckduckgo.com mail is handled by 20 in2-smtp.messagingengine.com.\nduckduckgo.com mail is handled by 10 in1-smtp.messagingengine.com.\n[~]: host 46.51.179.90\n90.179.51.46.in-addr.arpa domain name pointer ec2-46-51-179-90.eu-west-1.compute.amazonaws.com.\n[~]: host 176.34.155.23\n23.155.34.176.in-addr.arpa domain name pointer ec2-176-34-155-23.eu-west-1.compute.amazonaws.com.\n[~]: host 79.125.105.113\n113.105.125.79.in-addr.arpa domain name pointer ec2-79-125-105-113.eu-west-1.compute.amazonaws.com.\nSo if that is supposed to be a privacy respecting program https://www.startpage.com (or something else) looks like a better choice. However I have no idea how to make startpage default search engine and use its POST search feature. Do you know about that?. > If you want to use the openSUSE configuration from ungoogled-chromium, you can choose to use the opensuse config bundle instead of linux_portable, but still use the linux_simple packaging scripts.\nHow do I do this please?\n\nFollow the instructions for Other Linux distributions and follow the packaging instructions for an Archive. Before you run build.sh, have a look through the comments inside and make changes as necessary.\n\nThe link gives 404. Also the documentation for \"Any Linux distribution\" is referencing a file which doesn't exist (which I filed in a separate issue #473).\n. Thanks.\nBTW another thing:\n\nTo do what you asked, you could build the compressed tar archive (see the bottom of BUILDING.md) and edit the generated build.sh file. There you'll see at which line you should put the extra flags you want (it's commented).\n\nI can't find such path:\n```\nSee build/toolchain/linux/unbundle/ in the Chromium source for more details.\n```\nAm I missing something?. Thanks.\nOK. I have been following closely the instructions for \"Any Linux distribution\" and the additional info given here. On openSUSE Leap 15.0 there is no LLVM 6.0 but there is 5, so that is what I installed (along with all the other packages listed in the zypper in command in the openSUSE section). BTW I also needed to install mozilla-nss-devel because I was getting an error that Package nss was not found.\nSo I added my 2 flag lines in build.sh on lines 33-34 as advised by @9Morello:\nexport CFLAGS=\"-O2 -pipe -march=native\"\nexport CXXFLAGS=\"${CFLAGS}\"\nand I ran ./ungoogled_packaging/build.sh which ended with:\n/tmp/download/ungoogled-chromium/build/src\n+ export AR=llvm-ar\n+ AR=llvm-ar\n+ export NM=llvm-nm\n+ NM=llvm-nm\n+ export CC=clang\n+ CC=clang\n+ export CXX=clang++\n+ CXX=clang++\n+ export 'CFLAGS=-O2 -pipe -march=native'\n+ CFLAGS='-O2 -pipe -march=native'\n+ export 'CXXFLAGS=-O2 -pipe -march=native'\n+ CXXFLAGS='-O2 -pipe -march=native'\n+ ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn -s\nBuilding gn manually in a temporary directory for bootstrapping...\nninja: Entering directory `/tmp/tmpK68wZb'\n[415/415] LINK gn\n+ ./out/Default/gn gen out/Default --fail-on-unused-args\nERROR at //build/config/posix/BUILD.gn:56:28: Undefined identifier in string expansion.\n      \"CR_LIBCXX_REVISION=$libcxx_svn_revision\",\n                           ^------------------\n\"libcxx_svn_revision\" is not currently in scope.\nSee //build/config/compiler/BUILD.gn:1150:18: which caused the file to be included.\n    configs += [ \"//build/config/posix:runtime_library\" ]\n                 ^-------------------------------------\nHow do I fix this please?. Thanks for the info.\nCould you please just confirm if that is due to LLVM version, i.e. if it is mandatory to have 6.0+?. Then I will have to wait till you fix the other issue. Thank you.. Hi,\nI see you closed #472 through a particular commit. But repeating the same build process now gives me a much longer list of problems. I share through susepaste.org as I am not sure if it would be OK to paste such long text here:\nhttps://susepaste.org/c518a638. [~]: rpm -q llvm\nllvm-5.0.1-lp150.4.3.1.x86_64. OK. Upgraded packages:\n[~]: rpm -q llvm\nllvm-6.0.1-lp150.530.2.x86_64\n[~]: rpm -q clang\nclang-6.0.1-lp150.530.2.x86_64\n[~]: rpm -q lld\nlld-6.0.1-lp150.530.2.x86_64\nUnfortunately I am still getting errors:\nhttps://susepaste.org/f455519c\n. Thanks.\nBTW I didn't get an email notification for that commit although it is in an issue opened by me. I wouldn't know about it if I didn't visit the web page here. Is that normal?\nAlso I am still getting errors (and warnings):\nhttps://susepaste.org/8e917bc9\n. A side note: I had to install also alsa-devel, libuuid-devel and libpulse-devel because otherwise I was getting other errors (as \"Missing uuid.h\" and similar). You may want to add these to the list of required packages in the docs.. I am already using the latest llvm and lld (6.0.1) for Leap 15.0 from devel:tools:compiler repo as listed here:\nhttps://software.opensuse.org/package/lld\nAs far as I can see @intika is using Leap 42.3 and a repo of a specific user, which is neither listed on software.opensuse.org, nor even a community repo. Even if there was such repo for Leap 15.0 I would still be highly reluctant to use it. I was even hesitant about the one which I currently use as it is still an unofficial one.\nI wonder how come this was supposed to work version 6 and now it suddenly requires something else?\nETA: I see that LLVM 7.0 was released today. Why would a software which was released before it require it for building itself?. > using what ever i find to get it to build\nI am not really a fan of such approach. It makes even less sense along the lines of the current project: one is trying to free oneself from untrusted stuff and the way to it is not to use whatever. (imo)\n\nbuild llvm/clang/lld from sources it's not that big of a deal\n\nThat is what I would rather be interested to try. Currently looking for info how to do it.\n\nthere is also the openSUSE packaging\n\nYeah, but as we talked above - it seems not to give the flexibility I am looking for. If it was more customizable then perhaps that would be the right thing to use.\nBTW the whole build process takes about 2 hours here. I wonder if there is a way to optimize it. Any suggestions? I am using a simple bash script for the whole thing:\n```\n!/bin/bash\nworkdir='/tmp/download'\ngiturl='https://github.com/Eloston/ungoogled-chromium.git'\nsrc='ungoogled-chromium'\necho \"\u2588\u2588\u2588\u2588 Remove ${workdir}/${src}\"\nmkdir -p \"${workdir}\"\ncd \"${workdir}\"\nrm -rf \"${src}\"\necho '\u2588\u2588\u2588\u2588 Download from GIT'\ngit clone \"${giturl}\" \"${src}\"\ncd \"${src}\"\nmkdir -p build/src\n./get_package.py linux_simple build/src/ungoogled_packaging\ncd build/src\nBUILD_SCRIPT=\"${workdir}/${src}/build/src/ungoogled_packaging/build.sh\"\necho '\u2588\u2588\u2588\u2588 Adding custom build flags'\nsed -i -n 'p;33a export CXXFLAGS=\"${CFLAGS}\"' \"${BUILD_SCRIPT}\"\nsed -i -n 'p;33a export CFLAGS=\"-O2 -pipe -march=native\"' \"${BUILD_SCRIPT}\"\nsed -i \"s/ninja -C/ninja -j$(nproc) -C/g\" \"${BUILD_SCRIPT}\"\ncat \"${BUILD_SCRIPT}\"\nwhile true; do\n    read -n 1 -p \"\u2588\u2588\u2588\u2588 Check configuration. Continue (y/n)? \" answer\n    case $answer in\n        [Yy] ) echo; break;;\n        [Nn] ) echo; exit;;\n        * ) echo -e \"\\nPlease answer (y)es or (n)o.\";;\n    esac\ndone\nif ! ./ungoogled_packaging/build.sh ; then\n    echo '\u2588\u2588\u2588\u2588 build.sh exited with error'\n    exit 1\nfi\n./ungoogled_packaging/package.sh\n```. Thank you guys.\n\nensure that the environment variables specifying the\ncompilers are correctly referencing said LLVM in\nPATH\n\nIn which file(s) do I check this please?\n\nRemove the GN args\n\nWhat are \"GN args\" and how do I remove them?\n\nyou could try reducing the jumbo file merge limit\n\nWhat is \"jumbo file merge limit\" and how do I reduce\nit?\n\ni am using google cloud computing...\n\n@intika you really have an interesting approach -\ngoing back to Google to build an ungoogled chromium :)\n. Friends, I made it! Thank you for your help :)\nI have built LLVM from source and then used it to build ungoogled chromium (UGC). Here is the little script I wrote for the purpose, in case anyone is interested to use it:\n```\n!/bin/bash\nSTART_TIME=$SECONDS\nworkdir='/tmp/download'\nsvnurl='https://llvm.org/svn/llvm-project'\nsrc='llvm-project'\nbuild='llvm-build'\ndest='/opt/llvm'\necho \"\u2588\u2588\u2588\u2588 Remove ${workdir}/${src}\"\nrm -rf \"${workdir}/${src}\"\nmkdir -p \"${workdir}/${src}\"\necho '\u2588\u2588\u2588\u2588 Checkout LLVM'\ncd \"${workdir}/${src}\"\nsvn co -q \"${svnurl}/llvm/trunk\" llvm\necho '\u2588\u2588\u2588\u2588 Checkout Clang'\ncd \"${workdir}/${src}\"\ncd llvm/tools\nsvn co -q \"${svnurl}/cfe/trunk\" clang\necho '\u2588\u2588\u2588\u2588 Checkout Extra Clang Tools'\ncd \"${workdir}/${src}\"\ncd llvm/tools/clang/tools\nsvn co -q \"${svnurl}/clang-tools-extra/trunk\" extra\necho '\u2588\u2588\u2588\u2588 Checkout LLD linker'\ncd \"${workdir}/${src}\"\ncd llvm/tools\nsvn co -q \"${svnurl}/lld/trunk\" lld\necho '\u2588\u2588\u2588\u2588 Checkout Polly Loop Optimizer'\ncd \"${workdir}/${src}\"\ncd llvm/tools\nsvn co -q \"${svnurl}/polly/trunk\" polly\necho '\u2588\u2588\u2588\u2588 Checkout Compiler-RT (required to build the sanitizers)'\ncd \"${workdir}/${src}\"\ncd llvm/projects\nsvn co -q \"${svnurl}/compiler-rt/trunk\" compiler-rt\necho '\u2588\u2588\u2588\u2588 Checkout Libomp (required for OpenMP support)'\ncd \"${workdir}/${src}\"\ncd llvm/projects\nsvn co -q \"${svnurl}/openmp/trunk\" openmp\necho '\u2588\u2588\u2588\u2588 Checkout libcxx and libcxxabi'\ncd \"${workdir}/${src}\"\ncd llvm/projects\nsvn co -q \"${svnurl}/libcxx/trunk\" libcxx\nsvn co -q \"${svnurl}/libcxxabi/trunk\" libcxxabi\necho '\u2588\u2588\u2588\u2588 Get the Test Suite Source Code'\ncd \"${workdir}/${src}\"\ncd llvm/projects\nsvn co -q \"${svnurl}/test-suite/trunk\" test-suite\necho '\u2588\u2588\u2588\u2588 Configure and build LLVM and Clang'\ncd \"${workdir}\"\nrm -rf \"${build}\"\nmkdir \"${build}\"\ncd \"${build}\"\nexport CFLAGS=\"-O3 -pipe -march=native\"\nexport CXXFLAGS=\"${CFLAGS}\"\ncmake -G Ninja \\\n    -DCMAKE_INSTALL_PREFIX=\"${dest}\" \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    \"${workdir}/${src}/llvm\"\nif [[ $? -ne 0 ]]\nthen\n    echo '\u2588\u2588\u2588\u2588 cmake exited with error'\n    exit 1\nfi\necho '\u2588\u2588\u2588\u2588 Running ninja'\nif ! ninja -j$(nproc) -C \"${workdir}/${build}\"; then\n    echo '\u2588\u2588\u2588\u2588 Ninja exited with error'\n    exit 1\nfi\nELAPSED_TIME=$(($SECONDS - $START_TIME))\nhours=$((ELAPSED_TIME / 3600))\nseconds=$((ELAPSED_TIME % 3600))\nminutes=$((seconds / 60))\nseconds=$((seconds % 60))\necho \"\u2588\u2588\u2588\u2588 Elapsed time: $hours hour(s) $minutes minute(s) $seconds second(s)\"\n``\n*Note:* Perhaps the-DCMAKE_INSTALL_PREFIXis not needed whenninjais used (and notmake`). Building LLVM takes about 1 hour here.\nI also added the following line to the previous script I shared (the one I use to build UGC itself):\nexport PATH=\"/tmp/llvm-build/bin:$PATH\"\nbefore the line which runs build.sh.\nFirst impression: UGC feels faster than standard Chromium! I don't know if it is due to it being a custom build for the particular machine but it is great.\nSome other things I would like to discuss with you if I may:\n\n\nAlong the lines of building a portable version: does /etc/default/chromium matter at all? If not - which is the \"master\" settings file where one can set default preferences for all users on the system?\n\n\nSpell check doesn't seem to work. Is it because it needs connection to Google?\n\n\nEarlier you mentioned that I need to modify the Inox patches in order to have default settings the way I want them. However looking at them I see they include specific line numbers which can change with any new version of Chrome, so it seems to need a continuous careful work which I am not sure I will have the time to do. Isn't there a simpler way to approach this?\n\n\nchrome://net-internals/#hsts section HSTS/PKP shows a link https://www.ch40m1um.qjz9zk/hsts which made me wonder: Is it possible that due to the UGC's specific replacement of host names the \"HSTS preloaded list\" of Chrome doesn't work? (which has a certain security implication)\n\n\nWhile browsing chrome://settings/ I was watching a ss -tuapn on the side and noticed a TCP connection to 104.20.23.46:443. At that time I was on the Language setting. Then I ran rcnetwork restart and tried to reproduce it but I could not. Some minutes later when I opened several chrome://flags tabs it showed up again. Since then I haven't seen it. I have no idea what this host is but considering its location it may be worth checking if it is an attempt of Chrome to connect to something:\n[~]: geoiplookup 104.20.23.46\nGeoIP Country Edition: US, United States\nGeoIP City Edition, Rev 1: US, CA, California, San\n  Francisco, 94107, 37.769699, -122.393303, 807, 415\n  GeoIP ASNum Edition: AS13335 CloudFlare, Inc.\n\n\nuBlock/uMatrix: Do you happen to know where \"Export to cloud storage\" actually uploads? When I click it I see no Internet connections but it still seems to work.\n\n\nWhat benefit has using --set-ipv6-probe-false?\n\n\nDoes installing an extension as CRX result in possibility to have it auto-updated from Chrome store? I am just looking for a way to install from file \"HTTPS Everywhere\" but EFF's site seems to offer only CRX downloads.\n\n\nRe. the build process:\nAs you can see in my UGC build script there are 3 sed lines. The first 2 of them insert the specific CFLAGS. The third one modifies the ninja line to use the actual number of cores instead of the default (10). My questions are:\n\n\nDo I need to do the first 2 inserts in the build.sh itself or will it be enough to simply export the CFLAGS in my own bash script?\n\n\nDo you think you could probably include my modification of the build.sh by adding -j$(nproc) to the ninja command? It seems a universal modification which would benefit everyone.\n\n\nI have an old 32-bit laptop for which I am willing to build UGC too. But I am afraid it may be a terribly slow process (if possible at all because it has a small disk and not so much RAM). How can I use the stronger desktop machine to create a binary for the laptop? I wonder if it just a matter of different CFLAGS (and what should they be) or something else? I hope you can shed some light.\n. Thanks again for the answers.\n\n\n\nIf that's a link to update the HSTS list, then yes it's broken.\n\nIt's a link in the description saying \"See https://www.ch40m1um.qjz9zk/hsts.\" but I thought it might be related to what you say, that's why I mentioned it. I don't know how to check if it is broken or not. Testing with a few websites showed me HTTP 307 with an HSTS header but I don't know if this confirms anything.\n\nYou could create a template profile that contains the settings you want, and just use copies of it for running the browser.\n\nThat's what I do.\n\nAre you sure that it is ungoogled-chromium causing it?\n\nWhat I am sure is that: while I was testing no other programs were open and I took care to stop other network services which create Internt connections (such as ntpd for example). And it happened while I was playing with the settings. But in ss it did not show up with a process name. So I relate it to UGC just because of all these factors.\n\nFrom my usage, it causes Chromium to not use IPv6 because it thinks the probing for IPv6 returned a negative result.\n\nI can see what it does but I don't understand the benefit of it. Privacy, security, anything else?\n\nIt's not clear to me where nproc is defined\n\n[~]: which nproc\n/usr/bin/nproc\n\nsee ninja --help\n\nI have seen it while writing my script:\n-j N     run N jobs in parallel [default=10, derived from CPUs available]\nStill it is not clear how exactly \"derived from CPUs [is] available\". I can't find any documentation saying much about it. The manual summarizes:\n\nNo matter what pools you specify, ninja will never run more concurrent jobs than the default parallelism, or the number of jobs specified on the command line (with -j).\n\nwhich implies that unless explicitly specified, it will always use the default (10). Hence the suggestion.\n. Thanks for explaining.\n\nIt was connecting to Google's DNS server before.\n\nDoes that mean that it no longer connects to it regardless of using this flag?\n\nIt's recomputed whenever you run the command.\n\nI wasn't aware of that because I don't read anywhere about it in the docs. Thanks for the info.\n. Forgive me, I am not a network expert, so this is a bit difficult for me. All I know is that 'probing' is an action used to determine a state of the network (e.g. ping, nmap) and that IPv6 is a newer protocol, with much larger amount of IP addresses and includes certain improvements. Why one would want to avoid IPv6? I hope you can clarify as for a layman.. Thanks @intika. I wasn't aware of 4. Now I have another thing to worry about :). Thanks @Eloston.\nSo in short (as far as I understand): it is better to use this CLI option unless there is some special reason not to use it (e.g. accessing a web site which uses only an IPv6 addres? any other?). To answer my own question:\n\nAlong the lines of building a portable version: does /etc/default/chromium matter at all?\n\nI tested today and it seems this file is disregarded.. May I please ask what is \"Chromium source tree\"? Maybe I have misunderstood that part as I was looking at https://github.com/Eloston/ungoogled-chromium/tree/master/docs. Thanks for clarifying.. Chrome 69 is out now, figure you may as well just skip to that yeah?. Thanks.\n\nAs your system supports namespaces, then there's nothing to do about it.\n\nDoes that mean I should simply run chrome and not worry about any other executables?\nThanks also for the link, I will have a look at it.. chrome://sandbox/ is telling me 'No' for SUID Sandbox and 'Yama LSM Enforcing'.\nchrome://gpu/ shows Sandboxed: false and in its Log Messages I read:\n[11455:11455:0928/001738.993275:ERROR:sandbox_linux.cc(379)] : InitializeSandbox() called with multiple threads in process gpu-process.\n[11455:11455:0928/001739.994164:WARNING:ipc_message_attachment_set.cc(49)] : MessageAttachmentSet destroyed with unconsumed attachments: 0/1\nIs all that OK or should I do anything about it?. Thanks for explaining.\n\nI need to investigate this further. I'm also getting that first line in your log.\n\nI hope you can share your findings.. Considering the reply about what GN args are, I suppose you mean args.gn. (Please correct me if I am wrong) However I didn't keep the source code after building, just the final tar.xz. Do I need to rebuild again the whole thing in order to find the answer to your question or something else?. [/tmp/download]: grep -rln use_gnome_keyring . | grep -E \"BUILD.gn|(.+\\.gni)\"\n./ungoogled-chromium/build/src/components/os_crypt/features.gni\n./ungoogled-chromium/build/src/components/os_crypt/BUILD.gn\n./ungoogled-chromium/build/src/chrome/test/BUILD.gn\n./ungoogled-chromium/build/src/chrome/browser/BUILD.gn\nThe first file seems to define the usage of gnome keyring itself.\nThe others contain conditions based on it.\n. Yes. This comment talks about it but it is still not clear how it should be set. If I am reading this correctly libsecret is still not ready.. Thanks for this info.\nHm. But that still sounds contradictory. I also searched the web for more.\nBased on this and this info on Linux one still needs to specify explicitly --password-store=gnome or --password-store=kwallet, otherwise it would fallback to basic (unencrypted). Also according to this bug report the work on dropping KDE's and Gnome's backends is started but not finished.\nWhat do you understand from all that? It sounds like a big mess to me.. > It uses GNOME Keyring by default for Debian stretch builds.\nEven with use_gnome_keyring=false? How is this possible? Isn't that setting supposed to disable it?\nI don't know what \"Debian stretch builds\" means. I build it from source (as we talked in other issues).. I see.\nThanks!\n. > Perhaps you should try asking the LLVM community for help first.\nI have asked in clang's mailing list about 5 days ago but there is no reply whatsoever. So I hoped you might probably know as there is really no info about it.. > You could try StackOverflow\nI have. Zero replies :(\nFWIW: I have successfully cross-compiled for nocona and the binary works fine.\n\nIf you know the processor code name (e.g. haswell, broadwell, skylake, kabylake, etc.), then it seems clang should have one of them as an option.\n\nFrom what I see the error message of clang seems to list only 64-bit architecture names. This CPU is 32-bit though. Unfortunately even this info doesn't really answer in a clear way.. > At most, it will affect webpage behavior if it sees it.\nThat's what I was wondering: would the user be auto signed in the particular G owned site if there are stored credentials for that site. I suppose it won't happen since you have replaced all domain names and any check like \"if (user is on site X) { login(); }\" would fail. I haven't tested though.. I see.\nBTW: I see many flags which are set to \"Default\" but there is no indication what that default actually is. How do we know that?. Thanks!\n. Thanks to you!. > Have a \"No Nonsense Edition\" of this browser that comes with\n\n...\npreinstalled and preconfigured.\n\nThe nonsense come from the web sites, not from ungoogled-chromium. 'preinstalled' implies someone choosing software and version for another and everyone conforming to that choice. (this is what Google does in Googled Chrome). Similarly 'preconfigured' implies that someone else knows what I want which is nonsense itself.\n\nAbout the cookie thing, the sane thing would have been to have a setting in the browser, that in turn would communicate the user's consent (or lack thereof) to cookies as part of the request header.\n\nAs @intika explained: cookie consent has legal implications and exactly because of them you see all those annoying notifications on various sites. Site owners are required by the law to display them (GDPR etc.) So it is not sane thing to use a catch-all consent. I may trust my bank but I don't trust Zuckerberg (just an random example).\n\nPlus, as long as i don't click \"accpet\", do websites still use cookies? Because I never click these buttons...\n\nLegally the cookie consent is required only for cookies related to your 'personal data' (as defined in GDPR), e.g. tracking cookies. No consent is required for \"regular\" (e.g. login) cookies. That said: don't rely on sites following strictly the law or being bug free.\nIf you want to sanitize your web experience:\n\nUse Internet as little as possible\nDon't trust anything on the web (me included)\nUse a clean browser, not something with pre-installed choices\nConfigure everything the way you want it to work\nBe wise. Don't rely on anyone respecting your (non-)consent.\n\nPersonally I use uBO, uMatrix and HTTPS everywhere, I have all cookies disabled and enable them only on sites on which I need to login. I also have JS disabled and enable it only temporarily for a specific site, with all other tabs and apps closed as I am paranoid about the CPU vulnerabilities which will stay with us for quite a long time as it seems.. > what about site that only use those ciphers you switch back to http with this settings ?\nActually I don't know if it works like this (pseudo code):\nif (cipher is disabled) { use_plain_HTTP() }\nor like this:\nif (cipher is disabled) { use_strong_cipher() }\nif (strong cypher is unavailable) { drop_connection_with_error_message() }\nCan you provide some info about it?\nMy suggestion is with the assumption of the second (and I may be wrong). Personally I use HTTPS Everywhere with \"Block all unencrypted requests\" enabled 99.99% of the time. So if some site attempts to switch to HTTP I would be notified quite well.\n\n(using https with those ciphers is better than http...)\n\nWell... maybe, maybe not. As you surely know a false sense of security is worse than being aware of insecurity.\n\nMaybe we could setup a page in the Wiki for extensions and settings to consider?\n\nYes.. Thanks for confirming that the setting doesn't result in switching to plain HTTP.\nThanks also for the info about HTTPS Everywhere. I have emailed you as I have some off-topic questions about all this.. Unfortunately your server returned:\n<postmaster@ [...] 550 sorry, user over quota [mail153] (#5.1.1) (in reply to RCPT TO command). Sent. Thanks!\n. Thanks. Just a note you may want to add: the IDs of the cypher suites must be in the exact format 0x0000. My tests show that any other (e.g. 0x00 or 0x000000) has no effect.. Disclaimer: I have written JS (not a developer per se), some Assembly and C (many many years ago) but I know nothing about WASM and JIT. So what I say is based on that limited experience + general security considerations. As I mentioned in another issue: Personally I browse the web with JS completely disabled and enable it only selectively and temporarily where it is inevitable and really important for what I need.\nRe. JIT: I have read it can be evil too.\n\nIs there something fundamental about WASM and/or JavaScript that I'm missing here?\n\nMy understanding is that WASM being binary would be practically impossible to understand without significant reverse engineering. JS OTOH, even in obfuscated form, could be \"beautified\" to a readable form and if one has the time and desire - one can still figure how it works (which of course is far from real OSS). So perhaps the answer is: time and speed. Anything that is more cryptic and faster opens the door to faster and greater abuse. So excluding blind trust from anything and relying only on the sanity of healthy verifiable facts: why would a privacy and security aware user who chooses ungoogled-chromium allow someone sending unknown binaries and executing them locally? The claim of WASM being sandboxed is somewhat baseless considering that CPUs are flawed on hardware level (Spectre, Meltdown, ... the whole gang) which breaks the essential security mechanism in computing (isolation) and for the moment we rely on software mitigations (which are not fixes). In that sense: one must be extremely careful about what software one runs.\n\nI may be out-of-the-loop here; does JavaScript have a solution for this?\n\nPerhaps he means the subresouce integrity attribute.\n\nI'm not sure how this differs from what JavaScript has.\n\nWell, JS can be transmitted via TLS although it is not required. So perhaps there is no difference but he rather means that a newer technology like WASM, being newly developed, is not properly secured considering the challenges of today's web.\n\nI don't understand the general idea behind this statement. What do they mean by \"language subsets\" and \"specific type of behavior\"?\n\nI don't know. Generally when something is assumed (as he explains) it becomes blind trust.\nSorry for the lengthy reply.. > Am not really convinced because JS itself have the same issues...\nI wasn't aiming at convincing anyone of anything. This is not a propaganda :) Just answering the questions the way I understand it (which is in no way absolute or complete). I agree JS itself has the similar issues but does that mean the issues with WASM are non-issues?\n\nIMO, a better comparison would be to compare WASM and JavaScript.\n\nWould that invalidate the security concerns for either one?\n\nPerhaps it is easier to exploit certain vulnerabilities in Blink/V8's existing sandboxing technology compared to JavaScript due to JIT?\n\nI don't know. Easiness is not a factor or even less guarantee. Sophisticated attacks can be multilevel. I guess it all depends on the purpose.\n\nHmm, but this is just hashing, not signing. Unless the author meant hashing?\n\nI just shared my association with the word \"integrity\" in regards to HTML. I don't know what the author means but if it is signing in the sense of establishing an authority: that doesn't reduce the potential of any closed code to be malicious.. Some more info about WASM in relation to CPU vulnerabilities:\nhttps://it.slashdot.org/story/18/06/24/1657223/changes-in-webassembly-could-render-meltdown-and-spectre-browser-patches-useless\nhttps://github.com/WebAssembly/meetings/blob/master/2018/CG-01-09.md#update-on-webassembly-atomics. Fresh news (and one more reason to have external scripts of whatever language disabled by default):\nhttps://it.slashdot.org/story/18/11/04/0426252/old-school-sniffing-attacks-can-still-reveal-your-browsing-history. @Eloston. Fortunately I found an older build (version ungoogled-chromium_70.0.3538.67-1_linux.tar.xz from 2018-10-25) which works. I tried running that one from console too and it also gives the InitializeSandbox error line but without the Illegal instruction (core dumped).. It seems the culprit may be the LLVM version (which I also build from source code as usual). I found an older build on my machine:\nclang -v\nclang version 8.0.0 (trunk 346299)\nTarget: x86_64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /<***>/llvm-build/bin\nFound candidate GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7\nSelected GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7\nCandidate multilib: .;@m64\nSelected multilib: .;@m64\nand using it I rebuilt ungoogled-chromium and I ran diff to compare the bad build and the working one:\n```\ndiff -qr bad/ ungoogled-chromium/\nFiles bad/chrome and ungoogled-chromium/chrome differ\nFiles bad/chrome_sandbox and ungoogled-chromium/chrome_sandbox differ\nFiles bad/chromedriver and ungoogled-chromium/chromedriver differ\nFiles bad/libEGL.so and ungoogled-chromium/libEGL.so differ\nFiles bad/libGLESv2.so and ungoogled-chromium/libGLESv2.so differ\nFiles bad/v8_context_snapshot.bin and ungoogled-chromium/v8_context_snapshot.bin differ\nNow I still get:\n[23943:23943:1111/125039.974622:ERROR:sandbox_linux.cc(379)] InitializeSandbox() called with multiple threads in process gpu-process.\n``\nbut UC works fine and there is noIllegal instruction` message.\nUnfortunately I have no idea how to report this to LLVM at all. So if anyone has - it seems that deserves attention as LLVM is essential to building UC.. ",
    "rugk": "Flatpak support would be great, as it runs this here in a sandbox then.. ",
    "picsi": "Perhaps with a script there's a way to automatically produce appimage binaries as soon as @Eloston builds ungoogled-chromium with little to no maintenance on his part?. I'm using this one: https://aur.archlinux.org/packages/ungoogled-chromium-bin/. Thanks for the heads up. Does this project maintain any binaries/PKGBUILDs for Arch-like distros?. I'm okay with things as they are, but as others have said, the pre-built binaries and auto-updates would be the only thing I'm still missing from this project. That's about it.. ",
    "pizzadude": "I'm not sure how to make a PPA, I'm not a developer. But PPA's can be automated. http://askubuntu.com/questions/550012/how-to-create-a-automatic-ppa\nSorry if this is too much to ask. :<\n. ",
    "podshumok": "Launchpad can automate on-commit build, packaging and publishing of deb packages\nYou just need\n1) a debian/ directory\n2) bzr-script https://help.launchpad.net/Packaging/SourceBuilds/Recipes\n3) setup launchpad mirror of source repo\n. Some docs are available here https://help.launchpad.net/Packaging/SourceBuilds/GettingStarted\nThe hardest part is to actually make a debian/ directory, everything else is more or less obvious, although may seem not so easy at the beginning...\nYou may want to look at https://code.launchpad.net/~chromium-team/chromium-browser/chromium-browser.head\nBest thing is that Launchpad provides separate everyday builds for different platforms and Ubuntu versions\n. @T-vK  you may want to add some information-gathering script (like (pwd; lstree /) > lstree_gitliab_artifact to debuild's signing-hook (see man). @T-vK \nhmm. I think it should be a separate script with +x attr and variable should have its path as a value. Well.\nFirst, looks like I was wrong about environment variables.\nHOOK should be specified in config file or as an argument to debuild script. For some reason documentation mentions this hook as --signing-hook-foo while I thing it should be --signing-hook=/signing-hook-script.sh\nSecond, looks like we need to see what gpg is doing:\nsh\ngpg --verbose  --local-user \"tavk tavk <t-v.k@gmx.net>\" --clearsign \\\n    --list-options no-show-policy-urls \\\n    --armor --textmode --output \"/build/test-signature\"\\\n    \"/build/ungoogled-chromium-browser_*.dsc\"\n(or maybe try to sign any other file)\n. This is some progress! (almost :)) What is the devscripts version?\ndebsign should create /tmp.debsign.XXXXXXX directory (mktemp) and through an error if fails to do so.\nMeanwhile in directory listing you provided /tmp folder is completely empty and I find it surprising.\nPerhaps it is somehow weirdly mounted? Can you manually run mktemp and see if you can interact with directory?. ",
    "MikolajQ": "PPA would be great!\n+1 for PPA\n. ",
    "kirylpl": "Please add the PPA. \nAnd great thanks for you work, really.\n. @Eloston Personal Package Archive (PPA) only works with launchpad\nhttps://askubuntu.com/questions/71510/how-do-i-create-a-ppa. ",
    "Lesik": "I oppose the use of PPAs/Launchpad.\nI don't understand why using the OBS as suggested in #17 and #59 was rejected. The OBS allows building binaries for Debian, Ubuntu, Fedora, CentOS/RHEL, Arch Linux and many more distributions. By investing some time into this you receive a unified build/hosting service serving packages for all distributions, not just Ubuntu. Launchpad, on the other hand, only supports Ubuntu (and while it would theoretically work to install a PPA on Debian, you should never do that!)\n. @zabbal How do Ubuntu users benefit from Launchpad more than from OBS? Why maintain two services? OBS does everything Launchpad can, and much more. Or am I mistaken?. It's a horrible idea to use alien for this. A native Fedora specfile should be created, possibly on the basis of Fedora's chromium spec as @logic mentioned.\n. This is a horrible solution. Packaging precompiled binaries including all libraries into some container isn't a real repo. What's next, we bundle openssl into our binaries? The packages need to be dynamically linked and natively compiled on the OS they're built for. If you don't have enough horsepower for that, use COPR or OBS. This is what the people want, a real repo, not some AppImage one-archive-fits-them-all-but-in-a-really-crappy-way solution.. @probonopd The way software is distributed on OS X and Windows is wrong and broken in my opinion, and also the reason why the security on those systems is laughable. As an example, if your application bundles openssl, and a critical vulnerability in openssl is discovered, your system won't be patched right when the openssl update is released, it will stay unpatched until your application delivers an update.. I assume the bundled one. But that's kinda acceptable because Google is quick to release an update in a matter of hours, and Chrome auto-updates itself without user confirmation, whereas we are a volunteer project and it might take days until someone gets his hands to building the binary, then a few more days until the AppImage is updated and distributed, and only then the users receive the patch.. ",
    "zabbal": "Using OBS does not contradict using Launchpad - those are orthogonal things. Having ppa would be really convenient for Ubuntu users which would greatly help with wider adoption and testing.\n. ",
    "message": "bump. > but there's no significant benefit of also having a PPA.\nWell, i can get updates when they are ready, and not checking every month for fresh release.. This ticket was created 2 years ago today. Congratulations :tada: . @mimf Installation instructions for 16.04\nadd following to /etc/apt/sources.list\n```\n3.9 - clang\ndeb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-3.9 main\ndeb-src http://apt.llvm.org/xenial/ llvm-toolchain-xenial-3.9 main\n```\nTerminal\n```bash\nsudo add-apt-repository -y ppa:jonathonf/ffmpeg-3\nsudo apt-get update\nsudo apt-get install -y clang-3.9 debhelper ninja-build python-jinja2 flex yasm xvfb wdiff gperf bison valgrind libglew-dev libgl1-mesa-dev libglu1-mesa-dev libegl1-mesa-dev libgles2-mesa-dev mesa-common-dev libxt-dev libre2-dev libgbm-dev libpng-dev libxss-dev libelf-dev libvpx-dev libpci-dev libcap-dev libdrm-dev libicu-dev libffi-dev libkrb5-dev libexif-dev libflac-dev libudev-dev libopus-dev libwebp-dev libxtst-dev libsrtp-dev libjpeg-dev libxml2-dev libgtk2.0-dev libxslt1-dev libpulse-dev libpam0g-dev libsnappy-dev libgconf2-dev libavutil-dev libavcodec-dev libavformat-dev libglib2.0-dev libasound2-dev libsqlite3-dev libjsoncpp-dev libspeechd-dev libminizip-dev libhunspell-dev libharfbuzz-dev libusb-1.0-0-dev ffmpeg libmodpbase64-dev libgnome-keyring-dev libnss3-dev libnspr4-dev libcups2-dev libevent-dev libjs-excanvas libjs-jquery-flot libgcrypt20-dev quilt build-essential\n./build.py\nInstall packages\nsudo dpkg -i build/chrom*.deb\n```. @Eloston, everything was built, but every single page i try to open i get - Aww, snap! Any hints what may went wrong? . @9Morello packages which you pre-built are working fine. The issue is with packages which i built by myself. I just don't get why every page throws Aww, snap! for me :/. ",
    "pseudoj": "+1 for a PPA repository.. ",
    "mtimofiiv": "I might be late to the party, but...\n\n@hrj: I'm pretty sure you have to own the repository. I'm a collaborator on another repository (with write access), and I couldn't get Travis CI to see it.\n\n@Eloston if you make an organisation on GH and move the repo into it, all users that are part of the org should be able to add via Travis.. Could do that. If you want someone else to take care of this as well, I wouldn't mind helping out, and @stfnhrrs seems also eager!. Does the name \"Ungoogled Chromium\" impose some kind of trademark violations however? I'm not an expert but if I open a greasy burger joint and call it \"Not McDonalds\" I feel like that I'd have a nice letter from their lawyers in my mailbox within a couple days.. ",
    "fedenko": "+1 for a PPA. ",
    "olosz": "+1 for a PPA.\nKeep up the good work.. ",
    "dannycolin": "PPA is too Ubuntu-centric. I'll prefer to see ungoogled-chromium directly in the Debian Repository. That way, it can easily be push to the ubuntu repository as well (an any other Debian/Ubuntu-based distro).. > @Eloston I think I have an idea for Problem 2, but I don't know enough about the Debian packaging system to attempt Problem 1.\nYou can find informations on that wiki page. There's some links pointing to more advance stuff too.\nhttps://wiki.debian.org/Packaging. ",
    "dubvulture": "patch -p1 --ignore-whitespace < ../minimal.patch should temporarily solve this issue.\nEDIT: #328 should fix it.. I just tested on a virtual machine with Lubuntu 16.04.2.\nIt worked for me but I got the following message (which I do not get on Ubuntu vanilla):\n[27106:27106:0614/084735.470713:ERROR:sandbox_linux.cc(343)] InitializeSandBox() called with multiple threads in process gpu-process\nIt went away by launching chromium --disable-gpu (but again, chromium worked even without it) so if you could try this and let me know what happens that would be very helpful.\nAnyway, signal 11 SEGV_MAPERR 000000000000 looks like a segmentation fault so the abovementioned error could be something not even related.\nIn the meanwhile in the next 10 hours I will try to replicate this on a different physical machine.. @Eloston nope, they're all the same.\nAnyway I tested on another machine with Lubuntu 16.04.2 and it worked perfectly (with no sign of the InitializeSandbox() error*)\n\nupon further inspection in sandbox_linux.cc(343) it seems that is not even a real error since it is stated that  // The GPU process is allowed to call InitializeSandbox() with threads.\n\nEdit:\n@matbonucci I have only two options left:\n- Did you check the hashes?\n- After publishing that build I made another one while testing some flags so you might try that out -> https://www.dropbox.com/s/lku4ed8hnebzl9t/build.tar.xz. Build failed throwing a lot of error: member access into incomplete type 'AVCodecParameters', see gist\nTomorrow I'll try again with gcc and the new commit.. With 7f238719fa0a16e40559df36988aecf0082a8cf3 both clang 4.0 and gcc 5.4.0 finished building successfully. (tomorrow I'll check again clang 3.8 and 3.9)\nHowever, both produced the following warnings:\ndpkg-shlibdeps: warning: couldn't find library libffmpeg.so needed by debian/ungoogled-chromium/usr/lib/chromium/chromium (ELF format: 'elf64-x86-64'; RPATH: '')\n        install -d debian/ungoogled-chromium-l10n/DEBIAN\n        install -d debian/ungoogled-chromium-shell/DEBIAN\n        dpkg-shlibdeps -Tdebian/ungoogled-chromium-shell.substvars debian/ungoogled-chromium-shell/usr/bin/chromium-shell\ndpkg-shlibdeps: warning: couldn't find library libffmpeg.so needed by debian/ungoogled-chromium-shell/usr/bin/chromium-shell (ELF format: 'elf64-x86-64'; RPATH: '/usr/bin/.')\n        dpkg-shlibdeps -Tdebian/ungoogled-chromium-widevine.substvars debian/ungoogled-chromium-widevine/usr/lib/chromium/libwidevinecdmadapter.so\ndpkg-shlibdeps: warning: couldn't find library libwidevinecdm.so needed by debian/ungoogled-chromium-widevine/usr/lib/chromium/libwidevinecdmadapter.so (ELF format: 'elf64-x86-64'; RPATH: '/usr/lib/chromium/.')\n. >The libffmpeg.so warning can be fixed by splitting off a separate package just for libffmpeg.so like Ubuntu has it, so chromium-shell and regular Chromium can both depend on it. Or FFmpeg can be statically linked into the main executables.\nDoes this mean that it has to be included in the final release build or it's not necessary?\n\nWere you able to test the main browser by installing and running it?\n\nYes, both build ran fine. Note: the previous version had to be uninstalled manually. due to the package name change.. Anyway, just for the record, with the new commit:\n\nclang 3.8 - failed (compiler problem, maybe due to ubuntu patches? who knows)\nclang 3.9 - successful. Somewhat related since it relies on the conservative build patch.\n\nIn order to build on Xenial these patches are needed to work with ninja 1.5.1\n- relax-ninja-version-requirement.patch\n- no-new-ninja-flag.patch\nShould they be included in the linux_conservative patches? Is that configuration even used for any other distro besides Ubuntu 16.04?. Ok I've been trying to build the portable/minimal version and here's a quick recap:\n\nninja/xenial patches are working and later I'll add them (maybe in a new folder like /resources/patches/ubuntu/ or just /resources/patches/ungoogled-chromium/linux/)\nThese warnings pop up during compilation:\n-Wno-user-defined-warnings (suggests -Wno-user-defined-literals)\n-Wno-enum-compare-switch (suggests -Wno-enum-compare)\n-Wno-unused-lambda-capture (suggests -Wno-unused-parameter)\nremove-new-flags.patch cannot be applied by quilt but works manually.\ndpkg-source: info: the patch has fuzz which is not allowed, or is malformed\nAnyway I'm not really sure this patch is needed. Those flags are working with clang>=3.9 which is required for linux_portable\n\nAnd last but not least, build fails at\n[2841/31274] LINK ./chrome_sandbox\nFAILED: python \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./chrome_sandbox\" -- ../../../../../../../usr/lib/llvm-3.9/bin/clang++ -pie -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -lpthread -Wl,--as-needed -fuse-ld=gold -B../../third_party/binutils/Linux_x64/Release/bin -Wl,--threads -Wl,--thread-count=4 -Wl,--icf=all -m64 -Wl,-O1 -Wl,--gc-sections -nostdlib++ -Wl,-rpath-link=. -Wl,--disable-new-dtags -o \"./chrome_sandbox\" -Wl,--start-group @\"./chrome_sandbox.rsp\"  -Wl,--end-group   -ldl -lpthread -lrt\nclang: error: unknown argument: '-nostdlib++'\n[2841/31274] CXX obj/ppapi/thunk/thunk/ppb_cursor_control_thunk.o\n(clang 3.9). Using use_custom_libcxx=false fixed that issue, everything compiled fine... but the browser refuses to render any page (even with --disable-gpu) and extensions crash on startup.\nThe only feedback I'm getting is a segfault somewhere much like #237 but erasing any older chromium configurations does not help. Plus, the same happens on a fresh system so I don't think it's related.\nI also tried removing that flag and fixing -nostdlib++ by applying this patch taken from the official xenial chromium build but I got the same end result.\nI guess I should have enabled debug symbols :) cya in another dozen hours when the new build finishes (using use_custom_libcxx=false FYI)*\nIn the meantime I found the problem with remove-new-flags.patch: domains substitution breaks the patch on line 12. I guess build/config/compiler/BUILD.gn should be added to domain_substitution_list?\n*EDIT:\nBuild with is_debug=true and symbol_level=1 failed at linking process throwing an incredible amount of undefined references.. > If the --disable-namespace-sandbox command-line flag fixes your problem\nI doesn't unfortunately.\n\nIf the above doesn't fix your problem, try adding these GN flags:\n\nI tried and I got the same undefined references. Here's a bunch of them.. Ok here's the specific command that fails and its first undefined references:\nFAILED: python \"../../build/toolchain/gcc_solink_wrapper.py\" --readelf=\"readelf\" --nm=\"nm\" --sofile=\"./libtrknotify.so\" --tocfile=\"./libtrknotify.so.TOC\" --output=\"./libtrknotify.so\"  -- ../../../../../../../usr/lib/llvm-3.9/bin/clang++ -shared -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -lpthread -Wl,--as-needed -fuse-ld=gold -B../../third_party/binutils/Linux_x64/Release/bin -Wl,--threads -Wl,--thread-count=4 -Wl,--icf=all -m64 -Wl,--export-dynamic -o \"./libtrknotify.so\" -Wl,-soname=\"libtrknotify.so\" @\"./libtrknotify.so.rsp\"\n../../third_party/skia/include/core/SkColor.h:33: error: undefined reference to 'SkDebugf(char const*, ...)'\n../../content/public/browser/web_contents_user_data.h:55: error: undefined reference to 'content::WebContentsUserData<InfoBarService>::kLocatorKey'\n../../chrome/browser/apps/app_window_registry_util.cc:25: error: undefined reference to 'g_browser_process'\n../../chrome/browser/apps/app_url_redirector.cc:147: error: undefined reference to 'Profile::FromBrowserContext(content::BrowserContext*)'\n../../chrome/browser/apps/app_window_registry_util.cc:27: error: undefined reference to 'ProfileManager::GetLoadedProfiles() const'\n../../chrome/browser/apps/app_window_registry_util.cc:46: error: undefined reference to 'g_browser_process'\nThis happened with GCC 5.4.0 too (FYI this patch was needed for gcc)\nEDIT:\nI tried to build with GCC without debug options and now the browser seems to work normally. I guess I'll build again with clang-3.9 and clang-4.0.\nEDIT 2:\nAaaaaand it crashes randomly on most sites (youtube homepage always) even with disabled extensions, disabled namespace sandbox, disabled sandbox and clean installation.. Partially. sorry for the confusion.\n\nDebug\nGCC and Clang3.9 \u2192 libtrknotify.so crash and undefined references\nNo debug\nGCC \u2192 partially functions (e.g. the YouTube homepage always crashes)\nClang3.9 \u2192 fails to render any page (even internal ones like chrome://sandbox) and extensions crash upon startup\nClang4.0 \u2192 works normally for now (even on websites that made the GCC-build crash)\n\nEDIT: see Clang4.0 above. I don't know what to say anymore.. So, after the last edit I used the resulting build as my daily browser and so far I encountered no problems whatsoever.\nShould I proceed with the build release?\nShould I try to build without the iridium browser patchset (and what depends on them) to see if it the root of the problem? (seeing that problem with libtrknotify.so)\nJust bumping the required clang version to 4.0 feels wrong to me.. I understand.\nAnyway, I created a new release with the (so far) working binaries if anyone really wants to upgrade.. Clang 3.9 build results:\nNo problems during compilation, I just had to update some patches (pr soon)\nBut... every page loads correctly except for (as far as I could test)\n- https://github.com/any_person/any_repo\n- https://www.tensorflow.org/install/install_sources\n- https://askubuntu.com/questions/000/any_question\n- https://code.launchpad.net/any_package\nAll are throwing segfaults like the clang 3.9 chromium62 build used to do.\nDebug build soon I guess.. >  do you still need Node.js\nNope. (but to be honest I don't even remember if it was required before)\nAnyway, libtrknotify.so strikes again with its failure during linking process.. Update:\n\nBuilding (debian minimal, linux_portable) with clang 4.0 resulted in a build that failed to render ANY page (for the record, with v62 it worked)\nBuilding (linux_simple, linux_portable) with clang 3.9 resulted in a working build.. Tried with clang 3.9 + the new patch and it seems to be working.\nI'll build again with clang 4.0 just to double check.\n\nEDIT:\nAaaaaaaaand it's working!. See #293 \nYou have to manually apply the minimal patch and rename the directory.. For 16.04 look here.\nAs discussed in #293 I didn't request a pull on the main repo since the build is working but the path that lead to the success is obscure to say the least.\nFor windows, again #215. -j options is already included while defining njobs here.\nPlus, njobs might not be defined and bootstrap.py will complain about the dangling -j.\n. That error is not related to that patch or any of the files it modifies. (still, you should report that on the main issue page). Successfully built on Ubuntu 16.04. link\nToo early to comment on #362. Cannot buil linux_portable on Ubuntu 16.04\n./out/Default/gn gen out/Default --args=\"host_cpu=\\\"x64\\\" blink_symbol_level=0 clang_use_chrome_plugins=false enable_ac3_eac3_audio_demuxing=true enable_google_now=false enable_hangout_services_extension=false enable_hevc_demuxing=true enable_iterator_debugging=false enable_mdns=false enable_mse_mpeg2ts_stream_parser=true enable_nacl=false enable_nacl_nonsfi=false enable_one_click_signin=false enable_reading_list=false enable_remoting=false enable_reporting=false enable_service_discovery=false enable_swiftshader=false enable_widevine=true exclude_unwind_tables=true fatal_linker_warnings=false ffmpeg_branding=\\\"Chrome\\\" fieldtrial_testing_like_official_build=true google_api_key=\\\"\\\" google_default_client_id=\\\"\\\" google_default_client_secret=\\\"\\\" is_clang=true is_debug=false is_official_build=true optimize_webui=false proprietary_codecs=true safe_browsing_mode=0 symbol_level=0 treat_warnings_as_errors=false use_gnome_keyring=false use_jumbo_build=true use_official_google_api_keys=false use_ozone=false use_sysroot=false use_unofficial_version_number=false custom_toolchain=\\\"//build/toolchain/linux/unbundle:default\\\" host_toolchain=\\\"//build/toolchain/linux/unbundle:default\\\" linux_use_bundled_binutils=false optimize_for_size=false use_gtk3=true use_kerberos=false use_lld=true use_vaapi=true\" --fail-on-unused-args\nDone. Made 8488 targets from 1535 files in 6893ms\nninja -j1 -C out/Default chrome chrome_sandbox content_shell chromedriver\nninja: Entering directory `out/Default'\nninja: error: '../../third_party/test_fonts/test_fonts/Arimo-Bold.ttf', needed by 'test_fonts/Arimo-Bold.ttf', missing and no known rule to make it\ndebian/rules:120: recipe for target 'override_dh_auto_build-arch' failed\nmake[1]: *** [override_dh_auto_build-arch] Error 1\nmake[1]: Leaving directory '/home/manuel/ungoogled-chromium/buildspace/tree'\ndebian/rules:105: recipe for target 'binary' failed\nmake: *** [binary] Error 2\ndpkg-buildpackage: error: fakeroot debian/rules binary gave error exit status 2. ",
    "metsatron": "What is the current status of the PPA?. ",
    "pcraciunoiu": "Subscribed, and\n:+1: for anyone who can figure this out or provide instructions for figuring it quickly / others to help unblock. ",
    "Etheryte": "It would probably make for the easiest transition to new users if the default values are similar to the default Chrome build.\n. ",
    "mildfuzz": "I really do not think onbeforeunload should be blocked. That's like saying you should remove reminders to save work from a text editor, which is a pretty clear anti-pattern to me. Sure, people can abuse it, but its usefulness in modern web applications is profound. \n. ",
    "SentToDevNull": "Can't figure out how to add the label \"enhancement\" to this bug report.\n. ",
    "ilikenwf": "To be fair, even the Inox PKGBUILD just grabs the patches itself:\nhttps://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=inox\nOtherwise the only other options are those in the build there, and possibly the ones to toggle GTK3 and whatever plugins/libs should be included.\nI'm chiming in here because while I support Palemoon in principle and goals, it is becoming a hindrance to use it.\n. I've not got a PKGBUILD yet, but to get a bit further in Arch, you have to specify the PKG_CONFIG_PATH before running build.py :\nexport PKG_CONFIG_PATH=/usr/lib/pkgconfig\nFrom there, we fail, despite having libcups installed, at:\ngyp: Call to 'python cups_config_helper.py --api-version /media/disk/makepkg/ungoogled-chromium/build/sandbox/build/linux/debian_wheezy_amd64-sysroot' returned exit status 1 while in /media/disk/makepkg/ungoogled-chromium/build/sandbox/printing/printing.gyp.\n2016-11-26 02:00:43,777 - ERROR: GYP command returned non-zero exit code: 1. @Eloston yes, I am, since it's the current master HEAD.\nI'll give er a shot once you've got it updated, probably tomorrow, and if it works out ok I'll write a PKGBUILD that just wraps around your python build script, at least for now...\nIn the future it may be nice to break out all the steps your builder takes, if possible, inside of a PKGBUILD instead as many times the people using the AUR like to tweak these packages before compilation to add/remove flags, patches, and features.. I'm patient, basically whenever you can is when I'll get to it...Arch needs\nthis in it's life.\nI use a combo of Pale Moon and Ungoogled Chromium on my Windows machines\nbut am waiting for Ungoogled-Chromium to arrive for my Arch machines..PM\nand vanilla Chromium can suffice until then, since I use Chromium myself\nmore for sites that won't render properly with my privacy setup in Pale\nMoon.\nOn Sat, Nov 26, 2016 at 2:23 AM, Eloston notifications@github.com wrote:\n\nI'll give er a shot once you've got it updated, probably tomorrow,\nThat is, if I can get it done tomorrow... at this stage, it's hard to\npredict what kind of problems I might run into (especially due to the\nswitch to GN, which is pretty new to me).\nIn the future it may be nice to break out all the steps your builder\ntakes, if possible, inside of a PKGBUILD instead as many times the people\nusing the AUR like to tweak these packages before compilation to add/remove\nflags, patches, and features.\nYeah I haven't really considered this use-case when I evolved buildlib. I\nhad the same problem back when people wanted to use OBS, which required a\ndebian folder to do everything. I'll create a new issue for this topic.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-263051156,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOg0dJy-lHeP4nBEiq57xrpRqV8XUks5rB-x-gaJpZM4KGCx8\n.\n. Just so you know, even with the current system, I get as far as this, and know not what to do next:\n\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory. I'll have to investigate how you did that for debian.\nThe real fun with open source is that every new thing like this makes us\nall noobs again, except for the creator :)\nOn Thu, Dec 1, 2016 at 10:14 PM, Eloston notifications@github.com wrote:\n\nThat can be fixed with a GN flag as it is done on Debian. But I don't\nremember if I implemented the Python 2 hacking like it is done in the\nPKGBuild.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-264369502,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOhCV64yFw9WcaJxi5itjTtl5WeOnks5rD5s_gaJpZM4KGCx8\n.\n. Closer, but no cigar:\n\n```\nFAILED: gen/blink/core/CSSValueKeywords.cpp gen/blink/core/CSSValueKeywords.h \npython ../../third_party/WebKit/Source/build/scripts/make_css_value_keywords.py ../../third_party/WebKit/Source/core/css/CSSValueKeywords.in ../../third_party/WebKit/Source/core/css/SVGCSSValueKeywords.in --output_dir gen/blink/core --gperf gperf\nTraceback (most recent call last):\n  File \"../../third_party/WebKit/Source/build/scripts/make_css_value_keywords.py\", line 177, in \n    in_generator.Maker(CSSValueKeywordsWriter).main(sys.argv)\n  File \"/media/disk/Linux/makepkg/ungoogled-chromium/build/sandbox/third_party/WebKit/Source/build/scripts/in_generator.py\", line 95, in main\n    writer.write_files(options.output_dir)\n  File \"/media/disk/Linux/makepkg/ungoogled-chromium/build/sandbox/third_party/WebKit/Source/build/scripts/in_generator.py\", line 71, in write_files\n    self._write_file_if_changed(output_dir, generator(), file_name)\n  File \"../../third_party/WebKit/Source/build/scripts/make_css_value_keywords.py\", line 172, in generate_implementation\n    gperf = subprocess.Popen(gperf_args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, universal_newlines=True)\n  File \"/usr/lib/python2.7/subprocess.py\", line 711, in init\n    errread, errwrite)\n  File \"/usr/lib/python2.7/subprocess.py\", line 1343, in _execute_child\n    raise child_exception\nOSError: [Errno 2] No such file or directory\n[2798/22635] ACTION //third_party/WebKit/Source/core:make_core_generated_css_property_names(//build/toolchain/linux:clang_x64)\nFAILED: gen/blink/core/CSSPropertyNames.cpp gen/blink/core/CSSPropertyNames.h \npython ../../third_party/WebKit/Source/build/scripts/make_css_property_names.py ../../third_party/WebKit/Source/core/css/CSSProperties.in --output_dir gen/blink/core --gperf gperf\nTraceback (most recent call last):\n  File \"../../third_party/WebKit/Source/build/scripts/make_css_property_names.py\", line 238, in \n    in_generator.Maker(CSSPropertyNamesWriter).main(sys.argv)\n  File \"/media/disk/Linux/makepkg/ungoogled-chromium/build/sandbox/third_party/WebKit/Source/build/scripts/in_generator.py\", line 95, in main\n    writer.write_files(options.output_dir)\n  File \"/media/disk/Linux/makepkg/ungoogled-chromium/build/sandbox/third_party/WebKit/Source/build/scripts/in_generator.py\", line 71, in write_files\n    self._write_file_if_changed(output_dir, generator(), file_name)\n  File \"../../third_party/WebKit/Source/build/scripts/make_css_property_names.py\", line 233, in generate_implementation\n    gperf = subprocess.Popen(gperf_args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, universal_newlines=True)\n  File \"/usr/lib/python2.7/subprocess.py\", line 711, in init\n    errread, errwrite)\n  File \"/usr/lib/python2.7/subprocess.py\", line 1343, in _execute_child\n    raise child_exception\nOSError: [Errno 2] No such file or directory\n```. Closer now...but it doesn't like ICU 58.1 - seems someone at FreeBSD has a\npatch:\nhttps://reviews.freebsd.org/rP426523\nOn Wed, Dec 7, 2016 at 10:42 PM, Eloston notifications@github.com wrote:\n\n@ilikenwf https://github.com/ilikenwf Try installing gperf and bison.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-265651664,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOsRdcG1j_5RuwsBZk7DsRGA3VbH0ks5rF4qggaJpZM4KGCx8\n.\n. Better yet, at gentoo:\nhttps://gitweb.gentoo.org/repo/gentoo.git/tree/www-client/chromium/files/chromium-icu-58.patch\n\nOn Wed, Dec 7, 2016 at 11:00 PM, parwok@gmail.com parwok@gmail.com wrote:\n\nCloser now...but it doesn't like ICU 58.1 - seems someone at FreeBSD has a\npatch:\nhttps://reviews.freebsd.org/rP426523\nOn Wed, Dec 7, 2016 at 10:42 PM, Eloston notifications@github.com wrote:\n\n@ilikenwf https://github.com/ilikenwf Try installing gperf and bison.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-265651664,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOsRdcG1j_5RuwsBZk7DsRGA3VbH0ks5rF4qggaJpZM4KGCx8\n.\n\n\n. I tried that patch locally, and with it things build and run correctly.\n\nI'll try to put together a PKGBUILD tomorrow.. It will invoke buildlib and package the resulting output...\nI haven't dug into the specifics yet, but is there any way to have it leave\nthe output without tarring it up, as PKGBUILDs typically expect to copy or\nuse make install or manually install -D /path/to/each/file for a given\npackage, to create the Arch specific package itself?\nOn Thu, Dec 8, 2016 at 1:35 AM, Eloston notifications@github.com wrote:\n\n@ilikenwf https://github.com/ilikenwf How are you writing this\nPKGBUILD? Is it going to invoke buildlib, or are you going to make\nbuildlib invoke it?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-265673027,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOqdY6mYksQYXDSBZUJMQwJRhVb_oks5rF7NSgaJpZM4KGCx8\n.\n. I've not dug into this yet, but ideally we'd only need to override generate_package to have it just dump all the files into a given directory, after which the Arch package can be compressed...\n\nIdeally, we do what the Inox package does for packaging:\nhttps://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=inox#n236. So should I hold off and just decompress the resulting tarball for now? I\ncan do that in the interim.\nOn Sun, Dec 11, 2016 at 10:41 PM, Eloston notifications@github.com wrote:\n\nOkay. The only concern I have is that this implementation will be scrapped\nonce I deprecate buildlib. If you still want to implement this before that\nhappens, that'll be fine by me.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-266341923,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOuk5khESyWCykfT3H2G-XZ8PCf9Aks5rHNBdgaJpZM4KGCx8\n.\n. I was tempted to override the package building line, but didn't feel like it tonight.\n\nIf you could perhaps give us  a way of passing an argument or setting an environment variable to not pack a tarball, but just dump the final output that would otherwise be tarballed into a directory, that'd be great!\nhttps://aur.archlinux.org/packages/ungoogled-chromium/. python2 is in the makedepends, you should install it\nOn Wed, Dec 21, 2016 at 12:11 AM, Helly notifications@github.com wrote:\n\nCurrently the following error is thrown when building:\n2016-12-21 01:05:12,811 - INFO: Initialized default console logging\nhandler 2016-12-21 01:05:12,811 - INFO: Using builder LinuxStaticBuilder\n2016-12-21 01:05:12,812 - INFO: Setting up environment overrides...\n2016-12-21 01:05:12,812 - INFO: Checking Python 2 command... 2016-12-21\n01:05:12,812 - INFO: No Python 2 command specified; testing with 'python'\n2016-12-21 01:05:12,834 - ERROR: Unsupported Python version '3.5.2'\nThis error is thrown when manually running python3 build.py as well though\nso I'm not sure if it's an issue with the buildpkg itself.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-268444677,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOomsP0f1VZwkb--0OCSzervfsAnVks5rKMMegaJpZM4KGCx8\n.\n. Personally I use firejail.... Recent changes (replacing buildlib with utilkit) breaks building on Arch, it seems, as we run python 3.6 :(\n\nSee user comments at https://aur.archlinux.org/packages/ungoogled-chromium/. python check_requirements.py\n--common\n[04/04 01:14 AM]\nChecking common requirements...\nChecking Python 2 command...\nTraceback (most recent call last):\n  File \"check_requirements.py\", line 143, in \n    exit(main(sys.argv[1:]))\n  File \"check_requirements.py\", line 137, in main\n    method()\n  File \"check_requirements.py\", line 44, in check_common_requirements\n    result.stdout.strip(\"\\n\")))\nException: Unsupported Python version '3.6.1'\nOn Tue, Apr 4, 2017 at 1:09 AM, Eloston notifications@github.com wrote:\n\n@ilikenwf https://github.com/ilikenwf What's the error that you get?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-291402943,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOv6wiMYKWPyDU26XVcMraxqOGXXSks5rsd6ngaJpZM4KGCx8\n.\n. Yeah, well 3.6 works other than the python2 thing...\n\nI've yet to have time to mess with it past this point though.\nOn Tue, Apr 4, 2017 at 1:15 AM, Eloston notifications@github.com wrote:\n\n@ilikenwf https://github.com/ilikenwf Oh. I forgot to add arguments to\nspecify a different Python 2 interpreter. It defaults to python.\nThere shouldn't actually be anything in utilikit that breaks on Python\n3.6, since I test it on 3.5 and I don't believe there is any\nbackwards-compatibility breakage in 3.6. You can just skip\ncheck_requirements.py altogether since it's supposed to be a script for\nthe user's convenience.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-291403827,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOohLF2KPm7VoeuXHPVld2q7zcLoTks5rseASgaJpZM4KGCx8\n.\n. Is there something missing from the readmes as far as generating a vanilla style build script, or do I need to manually go into the sandbox at this point and have the PKGBUILD patch the patches in?\n\n`export UTILIKIT_CONFIG_TYPE=archlinux\n    export UTILIKIT_DOWNLOADS_DIR=${srcdir}\nmkdir -p \"$srcdir/${pkgname}/build/sandbox\"\n/usr/bin/python \"$srcdir/${pkgname}/utilikit/prepare_sources.py\"\n/usr/bin/python \"$srcdir/${pkgname}/utilikit/substitute_domains.py\"\n/usr/bin/python \"$srcdir/${pkgname}/utilikit/generate_build_files.py\" \"--files_type debian --flavor standard --apply-domain-substitution\"\n\n/media/disk/Linux/makepkg/ungoogled-chromium/src/chromium-57.0.2987.110.tar.xz already exists. Skipping download.\n/media/disk/Linux/makepkg/ungoogled-chromium/src/chromium-57.0.2987.110.tar.xz.hashes already exists. Skipping download.\nChecking source archive integrity...\nRunning 'md5' hash check...\nRunning 'sha1' hash check...\nRunning 'sha224' hash check...\nRunning 'sha256' hash check...\nRunning 'sha384' hash check...\nRunning 'sha512' hash check...\nExtracting source archive into building sandbox...\nusage: generate_build_files.py [-h] [--ignore-environment]\n                               [--resources DIRECTORY]\n                               [--output-dir DIRECTORY]\n                               {debian} ...\ngenerate_build_files.py: error: argument files_type: invalid choice: 'debian --flavor standard --apply-domain-substitution' (choose from 'debian')`. Thank you, sir.\nI'll investigate once I get a free moment.. Oh, and the quotes are expanded, this is within a PKGBUILD, the syntax is a bit weird.. I may be mistaken, I'm tired and I get crazy when I am.\nOn Fri, Apr 7, 2017 at 12:14 AM, Eloston notifications@github.com wrote:\n\nOh, and the quotes are expanded, this is within a PKGBUILD, the syntax is\na bit weird.\nHm, really? It seems to me that my script is receiving one argument:\ngenerate_build_files.py: error: argument files_type: invalid choice: 'debian --flavor standard --apply-domain-substitution' (choose from 'debian')`\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/44#issuecomment-292442231,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAZUOq5cR7KLotKWF9dIk_KKshNTNGV4ks5rtcZHgaJpZM4KGCx8\n.\n. Well, I am probably vastly ignorant about this build process, but what is the proper way to use the build output?\n\nI've tried manually patching according to the patch_order file, after using prepare_sources and export_resources (see below).\nIs this all just because the new utilikit needs futher dev/input for other distros for it's build processes?\npython tools/gn/bootstrap/bootstrap.py --gn-gen-args \"${_flags[*]}\" \n    out/Release/gn gen out/Release --args=\"${_flags[*]}\" --script-executable=/usr/bin/python\n    ninja -C out/Release chrome chrome_sandbox. I have disowned the PKGBUILD on the AUR because I don't have the time or patience to maintain it - feel free:\nhttps://aur.archlinux.org/packages/ungoogled-chromium/. Great job everyone! I built last night. One minor suggestion would be to forcibly add -fno-fast-math to the CFLAGS and CXXFLAGS as one of my two systems have ffast-math set and that breaks the sqlite build.. Have you considered presenting this item to the Copperhead OS guys? It aligns with what they're doing perfectly.. @Eloston I know for a fact that they are interested in preventing transmissions to Google; removal of binaries and the other patches may also fit within their scope of interest as the goal of their work is to create a hardened Android that is totally free out of the box from Google's tendrils. I think right now that they use a prebuilt of their own for Chromium...but they already maintain SOME patches (any of use to us?) ...maybe open an issue there suggesting collaboration?\nhttps://github.com/CopperheadOS/chromium_patches\nhttps://copperhead.co/android/docs/building#chromium-and-webview\nI also believe it would be a shoe-in to get included in F-Droid.. @Eloston nice, if nothing else more patches for us here. I may alert them to ungoogled-chromium's existence, at least, as it would be nice at the least to have Android chromium builds that don't talk to the mothership. Don't you currently just do a find and replace at build time?. @Eloston :+1: \n\nHello ilikenwf,\nThank you for supporting Copperhead, it truly means a lot to us.\nYou are absolutely right, the less Google in your devices, the better\nyour privacy and security.\nThank you for the good link. I've forwarded it to our developers who\nwill decide whether we can\nuse any of the code in our own projects.\nGood looking out!\nThank you,\n\nAnd then a second one:\n\nUs again.\nThought it might be of interest to you what work we have done ourselves\non Chromium\nhttps://github.com/CopperheadOS/chromium_patches\nhttps://copperhead.co/android/docs/usage_guide#default-connections-made-by-copperheados\nHave a great day,\nCopperhead. I like Python too, but you may be able to do all this much more easily just using a combination of standard utils and cmake? It can call the Google/Chrome/Ungoogled/Inox speicifc scripts that are 100% required without overcomplicating the amount of code you have to (re) write...\n\nThis goes double since CMake support is native in VS2015, and I think 2013? If not there's the CMake .sln generator.. ",
    "pickfire": "Seems like quilt is needed for build but it is not a makedepend.. @Eloston I still find error building with python2 or python3:\npython2\nFile \"build.py\", line 50\n    print(\"ERROR: {!s}\".format(exc), file=sys.stderr)\n                                         ^\nSyntaxError: invalid syntax\npython3\nNow at patch ../patches/ungoogled-chromium/fix-building-with-iridium-trknotify.patch\n2016-10-19 10:25:39,381 - INFO: Running gyp command...\n2016-10-19 10:25:39,382 - DEBUG: Appending resources/common/gyp_flags\n2016-10-19 10:25:39,382 - DEBUG: GYP command: build/gyp_chromium --depth=. --check -Dlinux_strip_binary=1\n-Ddisable_nacl=1 -Denable_pre_sync_backup=0 -Dtracing_like_official_build=1 -Dremove_webcore_debug_symbols=1 -Denable_remoting_host=0 -Denable_rlz=0 -Denable_hidpi=1 -Dffmpeg_branding=Chrome -Denable_google_now=0 -Ddefault_apps_list_linux_dest=[] -Ddisable_pnacl=1 -Dproprietary_codecs=1 -Denable_hotwording=0 -Ddisable_newlib=1 -Dsafe_browsing=0 -Denable_webrtc=0 -Denable_automation=0 -Denable_prod_wallet_service=0 -Duse_official_google_api_keys=0 -Ddisable_fatal_linker_warnings=1 -Ddefault_apps_list=[] -Denable_one_click_signin=0 -Denable_wifi_bootstrapping=0 -Dwerror= -Dfieldtrial_testing_like_official_build=1 -Denable_hangout_services_extension=0 -Dremoting=0 -Dfastbuild=2\nTraceback (most recent call last):\n  File \"build/gyp_chromium\", line 12, in <module>\n    execfile(__file__ + '.py')\nNameError: name 'execfile' is not defined\n2016-10-19 10:25:39,431 - ERROR: GYP command returned non-zero exit code: 1\n. Yeah, I get the same outcome too.\n. @Eloston Seems so. Is that related?\n. Yup, shell but instead it said bash:\n``` sh\n!/bin/bash\npython2 \"$@\"\n``\n. @Elostonpython2does launch python 2, but usingpython2 build.pydoesn't even work like I said.\n. @Eloston I am a bit confused now. So we are supposed topython3 build.pybut then we need to setpython_command = \"python2\"? Still I have some problems with missing parenthesis if I runpython3 build.py`:\nUpdating projects from gyp files...\n  File \"../tools/clang/scripts/update.py\", line 121\n    print ' Done.'\n                 ^\nSyntaxError: Missing parentheses in call to 'print'\ngyp: Call to 'python ../tools/clang/scripts/update.py --print-revision' returned exit status 1 while in /home/ivan/src/ungoogled-chromium/build/sandbox/build/all.gyp.\n2016-10-21 17:37:52,068 - ERROR: GYP command returned non-zero exit code: 1\nBut then if I python2 build.py, it doesn't even run:\nFile \"build.py\", line 50\n    print(\"ERROR: {!s}\".format(exc), file=sys.stderr)\n                                         ^\nSyntaxError: invalid syntax\n. @Eloston Still same thing happened:\nUpdating projects from gyp files...\n  File \"../tools/clang/scripts/update.py\", line 121\n    print ' Done.'\n                 ^\nSyntaxError: Missing parentheses in call to 'print'\ngyp: Call to 'python ../tools/clang/scripts/update.py --print-revision' returned exit status 1 while in /home/ivan/src/ungoogled-chromium/build/sandbox/build/all.gyp.\n2016-10-22 17:45:27,591 - ERROR: GYP command returned non-zero exit code: 1\n. Weird, what are these errors, I think it's not related to the python script now:\nNow at patch ../patches/ungoogled-chromium/fix-building-with-iridium-trknotify.patch\n2016-10-23 23:01:07,275 - INFO: Running gyp command...\n2016-10-23 23:01:07,276 - DEBUG: Appending resources/common/gyp_flags\n2016-10-23 23:01:07,277 - DEBUG: GYP command: python2 build/gyp_chromium --depth=. --check -Dproprietary_codecs=1 -Ddisable_fatal_linker_warnings=1 -Ddefault_apps_list_linux_dest=[] -Denable_webrtc=0 -Dtracing_like_official_build=1 -Dwerror= -Denable_hidpi=1 -Dffmpeg_branding=Chrome -Dremoting=0 -Denable_hotwording=0 -Dfieldtrial_testing_like_official_build=1 -Ddisable_pnacl=1 -Denable_automation=0 -Dremove_webcore_debug_symbols=1 -Duse_official_google_api_keys=0 -Ddisable_nacl=1 -Dsafe_browsing=0 -Denable_rlz=0 -Denable_wifi_bootstrapping=0 -Ddisable_newlib=1 -Denable_hangout_services_extension=0 -Denable_pre_sync_backup=0 -Denable_prod_wallet_service=0 -Denable_one_click_signin=0 -Ddefault_apps_list=[] -Dfastbuild=2 -Denable_remoting_host=0 -Denable_google_now=0 -Dlinux_strip_binary=1\nUpdating projects from gyp files...\ngyp: Call to 'python cups_config_helper.py --api-version /home/ivan/src/ungoogled-chromium/build/sandbox/build/linux/debian_wheezy_amd64-sysroot' returned exit status 1 while in /home/ivan/src/ungoogled-chromium/build/sandbox/printing/printing.gyp.\nPackage libpulse was not found in the pkg-config search path.\nPerhaps you should add the directory containing `libpulse.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'libpulse' found\nPackage libpulse was not found in the pkg-config search path.\nPerhaps you should add the directory containing `libpulse.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'libpulse' found\ngyp: Call to '../build/linux/pkg-config-wrapper \"/home/ivan/src/ungoogled-chromium/build/sandbox/build/linux/debian_wheezy_amd64-sysroot\" \"x64\" \"lib\" --cflags libpulse' returned exit status 1 while in /home/ivan/src/ungoogled-chromium/build/sandbox/media/media.gyp.\nPackage atk was not found in the pkg-config search path.\nPerhaps you should add the directory containing `atk.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'atk' found\nPackage atk was not found in the pkg-config search path.\nPerhaps you should add the directory containing `atk.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'atk' found\ngyp: Call to '../../build/linux/pkg-config-wrapper \"/home/ivan/src/ungoogled-chromium/build/sandbox/build/linux/debian_wheezy_amd64-sysroot\" \"x64\" \"lib\" --cflags atk' returned exit status 1 while in /home/ivan/src/ungoogled-chromium/build/sandbox/build/linux/system.gyp.\n2016-10-23 23:01:35,618 - ERROR: GYP command returned non-zero exit code: 1\nI am sure that I have installed atk and libpulse.\n. ",
    "HellishINC": "Currently the following error is thrown when building:\n2016-12-21 01:05:12,811 - INFO: Initialized default console logging handler\n2016-12-21 01:05:12,811 - INFO: Using builder LinuxStaticBuilder\n2016-12-21 01:05:12,812 - INFO: Setting up environment overrides...\n2016-12-21 01:05:12,812 - INFO: Checking Python 2 command...\n2016-12-21 01:05:12,812 - INFO: No Python 2 command specified; testing with 'python'\n2016-12-21 01:05:12,834 - ERROR: Unsupported Python version '3.5.2'\nThis error is thrown when manually running python3 build.py as well though so I'm not sure if it's an issue with the buildpkg itself.. @ilikenwf Correct me if I'm wrong but isn't that the point of makedepends in the pkgbuild? Python2 along with everything else mentioned in the current latest tag build docs was installed.\n@Eloston Thanks for pointing that out. That was due to my \"unpure\" Antergos installation. I managed to temporarily work around that by editing my os-release (not recommended if anyone else reads this).\nAfter working on this all day I finally got it to compile. I had to add minizip as a build dependency, though because I'm a stated newcomer to makepkg, I also added quilt (from the build.md) and clang (from a comment on the AUR). I think that's understandable considering it took well over 4 hours to build on its successful run.\nI am however now running into a sandbox issue using the stock arch kernel. Using --disable-setuid-sandbox from #149 results in the same and with --no-sandbox everything under chrome://sandbox has a 'No'. Should I open a new issue instead of spamming this one?. Well, I renamed chrome_sandbox to chrome-sandbox and set ownership to root/4755 and it now runs.. ",
    "seppiofish": "Hi, I don't know if this is the right place to write but since my final goal was to write a PKGBUILD for Archlinux users I'll do it here.\nFirst of all I'm trying to build ungoogled-chromium using the new buildkit, as explained in the documentation, with linux_rooted and linux_portable bundles, but I need some help. Needless to say that I failed in both cases.\nThe linux_portable build fails with a clang error in chrome_sandbox linking phase:\n[2805/24148] LINK ./chrome_sandbox\nFAILED: chrome_sandbox\npython \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./chrome_sandbox\" -- ../../../../../../../../bin/clang++ -pie -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -lpthread -Wl,--as-needed -fuse-ld=lld -m64 -Wl,-O1 -Wl,--gc-sections -nostdlib++ -Wl,-rpath-link=. -Wl,--disable-new-dtags -o \"./chrome_sandbox\" -Wl,--start-group @\"./chrome_sandbox.rsp\"  -Wl,--end-group   -ldl -lpthread -lrt\nclang-5.0: error: unknown argument: '-nostdlib++'\nI suspect that could be caused by some variable not correctly set in the chromium toolkit but I may quite possibly be wrong.\nReguarding the linux_rooted error I have absolutely no clue, ninja fails with this error:\n+ ninja -C out/Default chrome chrome_sandbox chromedriver\nninja: Entering directory `out/Default'\nninja: error: '../../third_party/icu/common/icudtl.dat', needed by 'icudtl.dat', missing and no known rule to make it\nAs for the PKGBUILD itself it actually doesn't seem to me a great issue, having read the official chromium PKGBUILD, as soon as the build works properly. I intended to use the linux_rooted bundle but of course if you want to create a specific archlinux bundle I could help.. @Eloston \n\nWhat a coincidence! I actually planned to write the initial code for an Arch Linux packaging type since I failed to make a Windows build. I finally finished it in 3381396 (the time of which is also when I finished it).\nEveryone, please try it out and submit fixes as necessary. I don't plan on maintaining Arch Linux support.\n\nGreat I gave it a look. There are some issues with the PKGBUILD but it should work. \nAs far as I know you must put all the source files in the root folder because makepkg expects to find them in the same directory of the PKGBUILD, in fact it fail otherwise, but again I may be wrong and there could be a way. Then did you miss the .install file specified in the PKGBUILD or I did? (I simply deleted the line to test the build on an Arch environment) And finally gn complies about not knowing the --fail-on-unused-args option so I again removed that to test. There are some other minor issues but I fixed them.\nAs of now I'm waiting for the build to end and everything seems to be working. In the meantime I could adopt the pacakge on AUR and start to write it properly. Do you want me to make pull requests to fix the PKGBUILD releated issues?\nAnyway could you please explain how you intend the Archlinux build process to work? To generate the pkgbuild I simply invoked buildkit genbun archlnux and buildkit genpkg archlinux so that the scripts put the right values in the PKGBUILD variables and then I used the makepkg Archlinux tool to do everything else as is intended to create an Arch package.\n\nShould be fixed in b460a21\n\nWonderful it was exactly what I was thinking.\n\nI'm wondering if this is because you didn't unbundle the icu third party library in the Chromium source code. The PKGBUILD generated by the new packaging type should do this.\n\nI did not indeed. Thanks, my fault.. @Eloston \n\nI was really confused about that. Inox's PKGBUILD referenced inox.install, but I wasn't sure how it knew where inox.install was. From Inox's git repository, inox.install file doesn't do anything meaningful, so I think it's safe to exclude.\n\nUsually .install files are used to do certain spaecific actions after the installation so that they do not affect the packages themselves. I mostly see them used to create user configurations or simply print messages, so I don't think we'll need it.\n\nNow that you made me think about this, there's one major problem I overlooked: the usage of source file processors. buildkit normally creates the buildspace tree with the packaging files, so we can either:\n\nImplement the source file processors in the PKGBUILD\nUpload a pre-processed buildspace tree with the PKGBUILD\n\nI'd rather choose option 2 since it fits better with the typical buildkit usage, but option 1 is possible if the PKGBUILD wraps buildkit, or the source file processors are reimplemented in the PKGBUILD. What are your thoughts?\n\nWell I understand why you prefer the second option but I don't think it is a great idea to provide an already processed buildpace along with the PKGBUILD on AUR, and could also become very annoying to manage. I think on the other hand that the PKGBUILD could well handle you buildkit scripts if of course adapted to process the sources downloaded and unpacked by the PKGBUILD (using the archlinux bundle).\nAnyway I keep hitting build failures. At first because of a bug in clang/llvm 5.0.1 so I temporarely downgraded and I will report it when I have time, and now i get this error from the linker:\n```\n[20932/22938] LINK ./font_service.service\nFAILED: font_service.service\n/usr/bin/python2 \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./font_service.service\" -- clang++ -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -lpthread -Wl,--as-needed -fuse-ld=lld -m64 -Wl,-O1 -Wl,--gc-sections -Wl,-rpath-link=. -Wl,--disable-new-dtags -Wl,--export-dynamic -Wl,-O1,--sort-common,--as-needed,-z,relro,-z,now -o \"./font_service.service\" -Wl,--start-group @\"./font_service.service.rsp\"  -Wl,--end-group   -ldl -lpthread -lrt -lgmodule-2.0 -lgobject-2.0 -lgthread-2.0 -lglib-2.0 -licui18n -licuuc -licudata -latomic -lsmime3 -lnss3 -lnssutil3 -lplds4 -lplc4 -lnspr4 -lfreetype -ljpeg -lexpat -lfontconfig -lz -lwebp -lwebpdemux -lwebpmux\n/usr/bin/ld.lld: error: undefined symbol: event_get_fd\n\n\n\nreferenced by gen/base/base_jumbo_2.cc\n              base_jumbo_2.o:(base::MessagePumpLibevent::WatchFileDescriptor(int, bool, int, base::MessagePumpLibevent::FileDescriptorWatcher, base::MessagePumpLibevent::Watcher)) in archive obj/base/libbase.a\nclang-5.0: error: linker command failed with exit code 1 (use -v to see invocation)\n[20937/22938] CXX obj/v8/v8_base/v8_base_jumbo_2.o\nninja: build stopped: subcommand failed.\n```\n\n\n\nI am not much of an expert here and I can't guess what could be the cause. It is since chrmoium 56 that I don't attempt a build, could be that there was not enough RAM? I gave the VM only 10GB.\nEDIT: I'm beginning to think that I just hit an other bug (I'm using clang/llvm/lld 5.0 now). Which versions did you last build ungoogled-chromium with? Anyway I forgot that I had to change the output directory for gn and ninja from out/Default/ to out/Release/ in the PKGBUILD.. @Eloston \n\nDebian 9 and Ubuntu 17.10 use LLVM 5.0.1 with no issues. The error you ran into isn't something I've seen before. This is a shot in the dark, but I recall that Inox disabled jumbo builds; could you try setting the GN flag use_jumbo_build=false and see what happens?\n\nDone, but that doesn't seem to be the problem:\n```\n[22679/30274] LINK ./font_service.service\nFAILED: font_service.service\n/usr/bin/python2 \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./font_service.service\" -- clang++ -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -lpthread -Wl,--as-needed -fuse-ld=lld -m64 -Wl,-O1 -Wl,--gc-sections -Wl,-rpath-link=. -Wl,--disable-new-dtags -Wl,--export-dynamic -Wl,-O1,--sort-common,--as-needed,-z,relro,-z,now -o \"./font_service.service\" -Wl,--start-group @\"./font_service.service.rsp\"  -Wl,--end-group   -ldl -lpthread -lrt -lgmodule-2.0 -lgobject-2.0 -lgthread-2.0 -lglib-2.0 -licui18n -licuuc -licudata -latomic -lsmime3 -lnss3 -lnssutil3 -lplds4 -lplc4 -lnspr4 -lfreetype -ljpeg -lexpat -lfontconfig -lz -lwebp -lwebpdemux -lwebpmux\n/usr/bin/ld.lld: error: undefined symbol: event_get_fd\n\n\n\nreferenced by ../../base/message_loop/message_pump_libevent.cc\n              message_pump_libevent.o:(base::MessagePumpLibevent::WatchFileDescriptor(int, bool, int, base::MessagePumpLibevent::FileDescriptorWatcher, base::MessagePumpLibevent::Watcher)) in archive obj/base/libbase.a\nclang-5.0: error: linker command failed with exit code 1 (use -v to see invocation)\n[22684/30274] ACTION //v8:js2c(//build/toolchain/linux/unbundle:default)\nninja: build stopped: subcommand failed.\n```\nI then updated llvm/clang/lld to 5.0.1 and enabled jumbo builds again. Hope this time it'll work. With this settings I'm attempting to build 64.0.3282.186 since it can now be downloaded but note that the sha256 hashes in pkgbuild for the tarball and the txt file mismatched.. @Eloston \n\n\n\nAnother fail:\n```\n[14560/22938] LINK ./font_service.service                                                              \nFAILED: font_service.service                                                                          \n/usr/bin/python2 \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./font_service.service\" -- clang++ -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -W\nl,--no-as-needed -lpthread -Wl,--as-needed -fuse-ld=lld -m64 -Wl,-O1 -Wl,--gc-sections -Wl,-rpath-link=. -Wl,--disable-new-dtags -Wl,--export-dynamic -Wl,-O1,--sort-comm\non,--as-needed,-z,relro,-z,now -o \"./font_service.service\" -Wl,--start-group @\"./font_service.service.rsp\"  -Wl,--end-group   -ldl -lpthread -lrt -lgmodule-2.0 -lgobject\n-2.0 -lgthread-2.0 -lglib-2.0 -licui18n -licuuc -licudata -latomic -lsmime3 -lnss3 -lnssutil3 -lplds4 -lplc4 -lnspr4 -lfreetype -ljpeg -lexpat -lfontconfig -lz -lwebp -l\nwebpdemux -lwebpmux                                                                 \n/usr/bin/ld.lld: error: undefined symbol: event_get_fd                            \n\n\n\nreferenced by gen/base/base_jumbo_2.cc                                        \n              base_jumbo_2.o:(base::MessagePumpLibevent::WatchFileDescriptor(int, bool, int, base::MessagePumpLibevent::FileDescriptorWatcher, base::MessagePumpLibe\nvent::Watcher)) in archive obj/base/libbase.a                                      \nclang-5.0: error: linker command failed with exit code 1 (use -v to see invocation)\n[14565/22938] CXX obj/services/resource_coordinator/public/interfaces/interfaces_internal/interfaces_internal_jumbo_1.o\nninja: build stopped: subcommand failed.\n```\n\n\n\nI have absolutely no clue at this point. Suggestions?. That was it. It successfully compiled : )\nWe just need to make the PKGBUILD and buildkit process the sources now. How would you like to do that? I was thinking of including this repo in the sources of the PKGBUILD (it simply clones the git repository along with the downloads of the other sources) instead of the patches themselves so the scripts can invoke buildkit to do the domain substitution and quilt to apply the patches from the repo. Doing so we should have the ungoogled git repository folder and chromium source folder (downloaded and unpacked by the PKGBUILD) in the same directory, so the relative path to the git repo would always be something like ../chromium-{version}/\nI gave a brief look at your buildkit scripts and notices that a path can be specified.\nSo something like this after the source are unpacked should be what we need:\n```\nbuildkit genbun -u $ubpath archlinux\nbuildkit subdom -u $ubpath -t $treepath\n```\nAnd then the PKGBUILD would do the rest.\nWould that be sufficient or is there someting I am missing?. > If you want, you could also prune binaries from the buildspace tree too.\nIndeed.\nThis should produce a working build using archlinux makepkg tool: #340. @Eloston I tested it. The PKGBUILD is generated correctly and works. I tested only a PKGBUILD generated with --repo-commit since 64.0.3282.186-1 does not yet exist but should work with no issues.\nI have just a question. How do you plan to put in the PKGBUILD the archive sha256 hash? Hardcoded or dinamically generated? As of now the check is skipped.. I agree with you. Option 4, as you explained it, seems to me the most reasonable one and it also contemplates all the most probable usage scenarios.. Everything seem right. I also tested it and I can confirm it works well. Great job.. @Preconf I'm not sure what you are asking. Would you like ungoogled chromium to officially provide an archlinux binary package here or me to do that?\nIn the first case you sould not ask me but the developer and administrator of this repo and open an appropriate issue. In the second case there sould be an ungoogled-chromium-bin package in the AUR. I do not remember where that binary came from and I do not encourage the usage of binary packages in the AUR (AUR is not meant to share binaries in a tricky way if sources are available and buildable). For this reason I think unofficial repos should be used in this cases, as long as the user trusts the owner of the repo. If you like you can use my personal archlinux repo which I maintain for my personal use and which is public and accessible to everyone, even if I never 'registered' in the Archlinux wiki.\nI checked and found that the bin version of ungoogled-chromium in the AUR has been deleted. I must say now that I'm not interested nor I want to create such binary package in the AUR for the reasons I previously wrote, but I have no problems if anyone would use my repo to download any package I build for myself.. > I'm assuming that people who use a PKGBUILD don't make local builds, or don't care about the redundancy of the ungoogled-chromium repositories.\nI'm sorry but what do you mean with 'local builds'?. Well actually this is what AUR is intended for. A lot of people use wrappers for pacman (archlinux official package manager) or so called 'AUR helpers' which basically download and run the PKGBUILD from AUR and subsequently install the created package. I think very few people, and for very partiular reasons, would not use a PKGBUILD for their own build, if one is available (since it is obviously editable and adaptable). Of course it would be a good thing that the package could also be built using archlinux base bundle and following the steps that the PKGBUILD does except from the packaging. This leaves more freedom and  more customizations options available. The process you described, the one reguarding the PKGBUILD build, seems fair to me, and I think it is great that buildkit supports this and if I can I will help maintaining this support.\nAnyway I have a question reguarding the PKGBUILD packaging: you wrote (or simply took from inox PKGBUILD) the install paths using tha variable $pkgname but this means that the binaries and the libraries paths in this case contains ungoogled-chromium which kind of breaks everything without further reconfigurations. In my builds I replaced them with chromium to have everything working but of course this way the executables are called 'chromium' and I wanted your opinion on this before making the changes. What about branding? My idea was to use the default chromium name for the paths and executables. Of course the package itself would still be called ungoogled-chromium and installed and referenced as such but I will have to make it conflict with official chromium (if I remember well this apporach is used by Iridium on Archlinux). What do you think?. This chenges should solve all the issues, except from the checkout command, but I left a comment above.. Forgot about this one.. @Eloston I built 67.0.3396.87-1 on Archlinux and after using it for a few days I noticed that the profile was just growing in size until my laptop went OOM (I use a daemon that syncs the profile on disk once in a while to improve speed and reduce disk I/O and therefore keeps the whole profile in memory).\nI'm not familiar with chromium profile data and its data caching. Is this an Archlinux-only issue or this depends on the new version or build flags?. @Eloston yes, a file named BrowserMetrics-spare.pma of 8MB is created and then a folder named BrowserMetrics, in which new files BrowsersMetrics-<hex_string>.pma of 8Mb of size each are constantly created growing the profile size indefinitely.. If I am not mistaken archlinux config bundle depends on linux_rooted bundle, so adding it there shoud do. But will it not be a problem for systems that don't yet have harfbuzz 2 and build with linux_rooted bundle to have chromium patched that way? I truly don't know so I'm genuinely asking.. ok that was unintended... I must have done something wrong. Hope reopening the PR fixes this. Anyway I deleted the previous two commits since one was unnecessary and the other wrong (I recived an advice from an AUR user and basically jsoncpp is an actual dependecy and not only a build one), and now committed the correct changes.\nEDIT: it seems everything is good. I hope this doesn't create confusion.\nAnyway... I forgot. @Eloston I read #640 and I'm actually thinking about it. I'll take my time but I will add my contribution to the discussion.. Whoops, that was not intended. I missed it while I was reviewing the code used during testing. I thought using master could actually be safe enough but I see no harm in setting the commit hash instead.. Yes, I will have a look at that. Let you know if I need help.. > Does ungoogled-chromium still have an icon if these files are removed?\nDon't know... I'll check.. Checked and this is not needed. I'll delete the lines and add the icons and logos the same way official chromium PKGBUILD does (simpliy taking them from the source tree).. Now that you made me think about it, I do not think it would be a bad idea to use tags in the PKGBUILD. Of course now can't be used since the last tag does not have PKGBUILD support but could be used since the next one. What do you think?. You are right, here is better to use the current commit. I may use tags and download the tarball instead of cloning the repo only in the PKGBUILD that I will upload to AUR, since that will use specific releases.\nAbout the line to be fixed, I think it would be better if it is you who fix the python code to set the checkout command to the current hash since I am relativerly ignorant of python3 and I don't want to mess around.. I had a very annoying issue using out/Default that I was not able to solve, so I thought the default gn path could be ok. But since, to be sure, I now tried again to reproduce the issue, and everything worked well (clearly something else was causing it) I will revert back using you default path.\nI'm sorry, as always rushing thinks makes you make mistakes.. > However, I don't quite understand your rationale for preferring tags over commits specifically for the AUR. Why go through more effort when one process can generate PKGBUILDs for both development and release builds?\nIn fact I don't. Perhaps I did't explained it well, speaking about tags I ment the release archives actually. I always ment to use source tarballs that GitHub generates in the PKGBUILD for the release build, and cloning git repo in the one for the developent build. This way I could also verify the hash of the downloaded archive and the \"release PKGBUILD\" would be more consistent and clean in my opinion.. ",
    "Noleli": "Sorry, I'm on OS X 10.11.x.\n\nOn Sep 25, 2016, at 20:05, Eloston notifications@github.com wrote:\nWhat platform are you using? I can see it on Windows 10, Debian, and Ubuntu.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thanks for looking into it! Is there a reason using --user-data-dir is preferable to user profiles? I'd rather only have to run one instance of Chromium. Launching another one every time I want to use Facebook (which I isolate from everything else) sounds annoying (though probably good for my health).\n. \n",
    "mmoya": "Check Can I install extensions from the Chrome Webstore? in the FAQ.\n. ",
    "bobberb": "wow...wrong project, off by 1 tab.\nepic...\n. ",
    "lorenzhs": "Well, who is the public of ungoogle-chromium? Phishing sites are designed to deceive, and they deceive power users, too. Safe Browsing also blocks sites serving malicious content (like exploit kits, where you don't even have to click anything to get infected). Isn't the privacy and information security impact of a malware infection worse than sending a few hashes of partial URLs to Google?\n\n> Though they are very different issues, the reasoning seems similar with Signal's dependence on GCM.\nThat's not a good comparison, the circumstances are completely different. There are no good alternatives to GCM / APNS, and even then, Signal can fall back to websockets. That's what the Desktop client uses (I'm not sure if it's implemented in the mobile clients).\n\n\nThe main principle of this project is that it will block any kind of connection to Google. As it is with other Google services, you'll lose a bit of convenience by not using them.\n\nIf it were only convenience you lost, then I wouldn't have filed this issue. This has a direct security impact on your users, and you're exposing them to risks without explaining what they are. I'm merely asking you to explain these risks, to make sure that users know what to expect.\nAdblockers don't update often enough to provide the same level of protection, and if you're not preinstalling one, then you can't expect everyone to have one.\n. Thank you! I think this is helpful.\n. ",
    "SharpMan": "maybe you want to see how websites are with ads in incognito \n. ",
    "RobinThrift": "It would be amazing to have automated builds with automated releases. So every time the repo ist updated with a new version, an automated system would build it and add it as a github release. This would greatly reduce setup cost for users and make in generally more accessible.\n. something like https://www.appveyor.com/ could be used for windows builds and https://travis-ci.org for mac and linux builds.\n. whops, my bad, copy and paste error. Will fix\n. Fixed.\n. ",
    "logic": "As an FYI to anyone looking at this, Chromium finally made it into Fedora proper recently, and a good starting point for this task might be the chromium RPM git repository to get a feel for how the upstream projects were packaged.\n. ",
    "esotericDisciple": "It seems that the only thing needed is to change the naming conventions for the libav-FFMPEG suite of libraries. Fedora's libav and FFMPEG packages don't add a -FFMPEG to the end of their libraries. Making symbolic links doesn't work either: \n\n/usr/lib/chromium/chromium: /lib64/libavcodec-ffmpeg.so.56: version LIBAVCODEC_FFMPEG_56' not found (required by /usr/lib/chromium/chromium)\n/usr/lib/chromium/chromium: /lib64/libavutil-ffmpeg.so.54: versionLIBAVUTIL_FFMPEG_54' not found (required by /usr/lib/chromium/chromium)\n/usr/lib/chromium/chromium: /lib64/libavformat-ffmpeg.so.56: version LIBAVFORMAT_FFMPEG_56' not found (required by /usr/lib/chromium/chromium)\n/usr/lib/chromium/chromium: /lib64/libswresample.so.1: versionLIBSWRESAMPLE_1' not found (required by /lib64/libavcodec-ffmpeg.so.56)\n\nIf you can fix that, then simply converting the deb packages to rpm's with alien and rpmrebuild should be enough, right? Oh and libjpeg.so.8 needs to be built for fc24, as well...\n. ",
    "Gridlocked": "AppImage would be a good way to bring this to Fedora, SuSe and all the other rpm based distros.  Right now in yumex Fedora's Chromium is stuck at 55 anyway.\nWhile the privacy aspect of ungoogled chromium is certainly attractive - not being able to disable plugins (a coming change in Chrome/Chromium) makes this a superior build from a security pov also.. I'd probably need some hand holding the 1st time doing that such as there are 3 .deb packages that have to be melded together.  But I would gladly offer my computer time to compile these and then test.   I try that exact example Saturday and see how far I can get.. I'll run that tonight.  It should work on Fedora after creating the appimage?  . [QUOTE]Run on a debian or Ubuntu system:\nwget \"https://github.com/probonopd/AppImages/raw/master/recipes/meta/Recipe\"\nwget \"https://github.com/probonopd/AppImages/raw/master/recipes/meta/Ungoogled_Chromium.yml\"\nbash -ex Recipe Ungoogled_Chromium.yml\nThis will use the latest ungoogled-chromium deb files available on GitHub Releases and convert them into an AppImage. Please provide wheezy packages that could be used as ingredients for the AppImage. This would make the AppImage run on older but the most recent systems, too.[/QUOTE]\n1st 2 commands no problem, at the very end of a lengthy response to the bash command I get this -\n--2017-02-11 11:14:07--  https://github.com/Eloston/ungoogled-chromium/releases/download/55.0.2883.87-1/chromedriver_.deb\nResolving github.com (github.com)... 192.30.253.112, 192.30.253.113\nConnecting to github.com (github.com)|192.30.253.112|:443... connected.\nHTTP request sent, awaiting response... 404 Not Found\n2017-02-11 11:14:07 ERROR 404: Not Found.\n. That did the trick.  I now have -\nUngoogled_Chromium_Web_Browser-55.0.2883.87.glibc2.15-x86_64.AppImage\nI'll try it on Fedora later today.. I've got it on Mint right now. I wanted to try running the appimage in firejail but I'm doing something wrong.12.02.2017, 16:20, \"probonopd\" notifications@github.com:Some fine tuning will probably be necessary. Specifically, be aware that it will only run on Linux distributions no older than the one this was compiled on. So to maximize compatibility, compile on an older system.\n\u2014You are receiving this because you commented.Reply to this email directly, view it on GitHub, or mute the thread.. firejail --appimage Ungoogled_Chromium_Web_Browser-55.0.2883.87.glibc2.15-x86_64.AppImage\nError: cannot access AppImage file\n. It runs great without firejail so I agree.12.02.2017, 17:55, \"probonopd\" notifications@github.com:That sounds more like a generic firejail issue on the system than something with this specific AppImage. Do other AppImages run?\n\u2014You are receiving this because you were mentioned.Reply to this email directly, view it on GitHub, or mute the thread.. Works on Fedora!!. I'll remove that - I just thought I'd make it available for someone to look at.   . Okay!14.02.2017, 14:12, \"probonopd\" notifications@github.com:@Gridlocked perfectly fine with a Dropbox link for such testing reasons, just wanted to suggest additionally a more official one ;-)\n\u2014You are receiving this because you were mentioned.Reply to this email directly, view it on GitHub, or mute the thread.. Yes, that gives their project a huge number of possible users with a simple build process for Fedora, Suse, Korora, Redhat, Centos & likely some others I have left out.. ",
    "bill-mcgonigle": "The Appimage is cool - thanks to those who worked on building that.  But just a little comment on direction:  \nThe reason I'm running Chromium from the Fedora repo is because I thought, erroneously apparently, that the delta between Chrome and Chromium was what it turns out is the delta between Chrome and ungoogled-chromium.  Some of the behaviours of regular Chromium, as outlined on this project page, run contrary to Fedora Packaging Guidelines for including non-free code, so there must be exceptions currently granted to Chromium to make it into Fedora.\nLong story short - if a version of ungoogled-chromium were packaged as a standard Fedora package, using the existing chromium.spec as a baseline, I would not be surprised if the Fedora steering committee decided that ungoogled-chromium should be the version officially shipped and supported in Fedora.  It's definitely more in line with the free software ethos of the Fedora Project.\n. If we can get to a statically linked output that will have value to people working on projects like kiosks where simple remote updates are really valuable.  They have the challenge of keeping their geographically diverse fleet of machines running securely without breakage from OS updates, etc.  The ability to run chromium-compatible platforms without Google code fiddling around inside their machines and a stable static binary would probably make some of these admins /very/ happy.  I might have an upcoming project that could use such a thing, and could help if that pans out.. After updating 022468b..00fe212, everything is working right except:\ndpkg: error processing archive ungoogled-chromium-l10n_70.0.3538.110-1~buster_all.deb (--install):\n trying to overwrite '/usr/lib/chromium/locales/en-US.pak', which is also in package ungoogled-chromium 70.0.3538.110-1~buster\n--force overwrite works, and a quick smoketest looks good.  Thanks!. Some data.  From the build logs I saw:\ntest ! -e ../ungoogled-chromium_72.0.3626.109.orig.tar.xz || rm -f ../ungoogled-chromium_72.0.3626.109.orig.tar.xz\ntar cf - chromium-72.0.3626.109 | xz -6 -T 1 - > ../ungoogled-chromium_72.0.3626.109.orig.tar.xz\necho $(($(date +%s) - $(cat ../ungoogled-chromium_72.0.3626.109.seconds))) seconds\n1454 seconds\nrm -rf chromium-72.0.3626.109\necho $(($(date +%s) - $(cat ../ungoogled-chromium_72.0.3626.109.seconds))) seconds | tee seconds\n1459 seconds\nfind debian/scripts/ungoogled-chromium/ -name __pycache__ -type d -exec rm -r {} +\nWhich is a bit slow.  I had previously done some compression benchmarking[1] and regularly use xz in -0 --threads=0 mode and decided to compare (0 means 'all cpu cores/threads' in xz-speak, which is eight threads on this laptop).  Summary (file-level-threads-time) in name:\n-rw-r--r-- 1 me me 1534832640 Feb 18 12:11 ungoogled-chromium_72.0.3626.109.orig.tar\n-rw-r--r-- 1 me me  304215500 Feb 18 12:14 ungoogled-chromium_72.0.3626.109.orig.tar.xz-0-0-16s\n-rw-r--r-- 1 me me  220908524 Feb 18 12:11 ungoogled-chromium_72.0.3626.109.orig.tar.xz-6-0-1m59s\n-rw-r--r-- 1 me me  218261160 Feb 18 12:29 ungoogled-chromium_72.0.3626.109.orig.tar.xz-6-1-9m20s\n-rw-r--r-- 1 me me  218261160 Feb 18 12:11 ungoogled-chromium_72.0.3626.109.orig.tar.xz-orig\nExplained:\nThe original tar file was about 1.5GB.\nThe current system uses xz level 6 compression and forces single threaded operation.  This gives a 218MB file and takes 9 minutes and 20 seconds on this hardware[2].\nUsing level 6 with all cores gives a 220MB file but takes 1 minute 59 seconds.  There's a tiny size overhead with multithreaded writers in the xz format (lzma can't do this AFAIK).\nUsing level 0 with all cores gives a 304MB file and takes just 16 seconds.\nSuggestion:\nI know the mechanism is being worked out above, but when that's in place I recommend using the \"-0 --threads=0\" tuning for normal builds.  Multithreading alone saves about 7 minutes on my system.  In my system I can spare 85MB of disk space to save 1m42s of build time (the delta of -0 and -6) as it's a tiny fraction of the space required to build and my time is more valuable than 85MB of disk.  I'm currently trying to get my build on buster working again which requires many iterations and that scenario is likely to come up again for many contributors.\nIf somebody winds up building source packages for distro repos it might make sense in that one case to crank compression up to 9 to minimize repo space utilization and data transfer from their mirrors.  I don't think it's worth slowing down builds in other cases, but that would imply the ability to tune it on the fly (or at least tweak settings without too much trouble).\n[1] https://bfccomputing.com/2017/08/01/xz-your-next-default-compression-tool.html\n[2]\nprocessor       : 7\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 70\nmodel name      : Intel(R) Core(TM) i7-4750HQ CPU @ 2.00GHz\nstepping        : 1\nmicrocode       : 0x1a\ncpu MHz         : 3071.823\ncache size      : 6144 KB. ",
    "eLement87": "+1\nIt would be awesome to have a Fedora Version of ungoogled-chromium.. Excuse me for report an issue in the wrong repository. But i believe, it helps others to create the Ungoogled-Chromium AppImage.\n@probonopd - in your Ungoogled_Chromium.yml \nin Line 14 \n| cut -d \"/\" -f 8) \nmust be \n| cut -d \"/\" -f 6) to get the Version\nand in Line 15 the Packename\nchromedriver_${VERSION}amd64.deb\nmust be\nchromium-driver${VERSION}_amd64.deb\nAfter that Changes i'm able to \"Compile\" the AppImage. \nIn Fedora 25 it works so far. Thank You.. ",
    "qvint": "I would like to present to you ungoogled-chromium-fedora which was forked from the Fedora chromium package to make it possible to build ungoogled-chromium as RPM-files.. Here is an easy-to-maintain and Google-independent solution:\n\nPatch convert_dict utility so that it can print all possible bdic file names.\nUsing this utility, make a script that converts all system hunspell dictionaries to ~/.config/chromium/Dictionaries. The script is intended to be run manually by the user.\n\nI have implemented it in qvint/ungoogled-chromium-fedora@a68fdd679566da5134d916776f14e00c8e6a8042.\nThe only language that convert_dict fails to process is uk_UA :confused: . I think the issue is not related to ungoogled-chromium. It seems Google Drive requires some third-party cookies. Adding https://[*.]googleusercontent.com:443 to the cookie exceptions list (chrome://settings/content/cookies) resolves the issue. At least it did work for me. See [1], [2].. > Does suggest_url from components/search_engines/prepopulated_engines.json get filled into the Suggestions URL box for built-in search engines?\nYes, it does.. How about completely removing all broken links from Chromium including its online help pages? (e.g. F1) See the screenshot for more examples.. I don't see much difference between \"support.9oo91e.qjz9zk Blocked by client\" and \"Link is deliberately not working\" messages... In both situations user will get the impression of something [deliberately] broken. If we remove the links, he won't see any error message at all--there will be no link to click.. > a new internal Chrome page that tells the users why it's blocked, and what to do to view the actual page (maybe even provide the real link to view the page?)\nI like the idea. How about prefixing all help URLs with \"chrome://unsafe-nav?url=\" and splitting them up to prevent domain substitution?\n Before: \"https://support.google.com/chrome/?p=settings_password\"\n After: \"chrome://unsafe-nav?url=https%3A%2F%2Fsupport\" \".google\" \".com%2Fchrome%2F%3Fp%3Dsettings_password\"\nIn this case we could display a typical Chrome's \"Back to safety\" page with our own danger text and additional \"Proceed anyway\" button.. > * removed add-flag-to-show-avatar-button.patch, the new UI places the avatar button in line with the settings button instead of the title bar and switching to the old UI is not possible anymore\nDoes the patch stop working in version 71? Did you check that? It works for both UIs in version 70.. @xsmile Please update the patch, it is fixed now.. I think it would be great to separate \"actual ungoogling\" patches/GN-args from all others. For example, safe_browsing_mode is clearly related to privacy, while is_clang is not. Why are they in a single bundle? What if some distro (not supported by ungoogled-chromium yet) prefers using gcc over clang?. > what about flags like use_sysroot=false, proprietary_codecs=true, enable_swiftshader=false, or enable_nacl=false?\nThese args have nothing to do with \"ungoogling\" and should be left to concrete distros. For example, in Fedora repository, proprietary codecs must be disabled due to US laws, but in RPM Fusion they are allowed. You can split this git repo to ungoogled-chromium, ungoogled-chromium-debian, ungoogled-chromium-gentoo etc., update them independently or delegate their maintenance to other people. This is how the project could grow: more people, clear responsibility areas.. This const is somehow left unchanged.\nhttps://github.com/Eloston/ungoogled-chromium/blob/a58db880c15e5077e881cad7b07d1a277ecd463a/patches/ungoogled-chromium/disable-formatting-in-omnibox.patch#L13. Redundant conditions are removed.. ",
    "lwis": "@Eloston Raspberry Pi 3, if at all possible! \n. Debian arm64 or armhf build would be brilliant!\nOn Mon, 26 Sep 2016, 7:49 pm Eloston, notifications@github.com wrote:\n\nAre you talking about a Debian arm64 or or armhf build? Or are you looking\nfor a generic Linux ARM build?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/54#issuecomment-249661468,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AA1TO6NaEt2I8w3WLxUNWQQkNOMl1MULks5quBPSgaJpZM4KGcIg\n.\n. \n",
    "gameb0y": "If you disable JavaScript, many websites won't work properly\nThis is Cent Browser\nhttp://www.centbrowser.com\n\n. ",
    "optomux": "No this cannot be done via extension. Why have extra overhead? Makes no sense. Frankly Chrome can even read your clipboard. It's called Clipboard Hijacking and its done through HTML5.\nChrome = Privacy nightmare. \n. Probably no. That's why I think it would be easier to just create a dll injector and disable some of the stuff that way..\nMore on patching:\nhttps://lifeinhex.com/tag/chrome/. ",
    "kxpvcr": "Brave has some anti-fingerprinting measures built-in. I'm not sure how well they work, or how they're implemented. Anti-fingerprinting is very important given how aggressive trackers have gotten. \nThe problem with, e.g., uMatrix is I can't recommend it to a non-power user. Even my partner who is otherwise web savvy is just going to start turning it off a lot or going incognito. Users are a weak link in the chain of trust/defense.\nBut I'm not the one maintaining this repo, I've no idea how complicated it is. Does anyone know how hard this would be as an extension? I don't mind working on that.\n. Any other metals, perhaps? Would be nice to say this is browser X, so it doesn't confuse anyone (Chromium makes you think of Google Chrome).\n. Yeah, it's not very relevant vs. the amount of work to get it in. Right?\n. FreeSMUG has Chromium builds. They don't auto-update, but there's an extension that checks for newer builds. It then prompts you to download the updated version. It's not a perfect solution, but it's a good one.\n. The extension is basically checking Sourceforge for a newer build. A Github-based approach might actually be more elegant.\n. ",
    "Dequim": "Hm it's for mozilla but it can be useful\nhttps://github.com/dillbyrne/random-agent-spoofer\n. Ctrl+Shift+i \nworks here\n. ",
    "uBlock-user": "\nNo this cannot be done via extension. \n\nhttps://chrome.google.com/webstore/detail/scriptsafe/oiigbmnaadbkfbmpbfijlflahbdbdgdf?hl=en\nOfcourse it can be done and NO, there's hardly any overhead being added. Gameboy has been spamming other repos with these block fingerprinting requests too and whatever he has posted, he took them directly from this extension.. ",
    "csagan5": "Premise: I am using in Bromite some patches from this project and Inox, but I am not keeping up with latest developments of both.\nPosting here as a heads-up because I am developing some patches that mitigate fingerprinting by disabling specific APIs; I thought somebody here might be interested.\nhttps://github.com/bromite/bromite/tree/master/patches\nAnything from patch number 40 to 44 are on topic and can be cherry-picked. I am also going to cover the client rects API.. @Eloston I understand. I went for the radical approach because I am not very well aware of how useful/necessary these APIs are. For the client rects I am going for a randomisation approach, as mentioned in this nice paper.\nFor the others I might stay on the \"axe\" approach, at least until I am aware of the consequences.\nAs per flags, sorry that does not match with the effort I want to put in the development of these mitigations, but I agree that it would be better.. @Eloston no, I totally agree. I am very familiar with what you say (e.g. the incentive to report, the \"small horizon\" problem etc). It is the same story of security vs usability: damage the latter, and you don't get the former because people will use post-its (just an example).\nAlso, regarding breakage: it is enough to give a look to the UI tests and unit tests of Chromium to realise that basically nothing can be changed without breaking some.\nIn Bromite I am enjoying this \"freedom to break\" as I experiment with things and make users participate to this experiment (with the pros/cons you described). I can do this now as there is a small user base, and I am aware that it might detract from it; in the past I did some \"pre-releases\", to get the user feedback. However the fact the users are few and not educated to report bugs doesn't allow me to do this proper.\nSo, in short:\n user base grows -> more conservative development choices, possibility to have dedicated testing from users\n user base is small -> not much testing aside from my own, since we are not updating or running the automated tests\nI need more advanced users to follow the path you describe but I am just hanging around XDA and the user base (remember: Android) is not so advanced except for a few welcome exceptions.\nTo go back on the topic of options to toggle features: the biggest problem on Android is the lack of extensions support; this seems on-topic: https://github.com/brave/browser-android-tabs/issues/316\nSo without any type of extension support available, the fallback is to implement patches/mini-features as I am doing, trying to limit the scope. I have seen how you implemented the Clear HTTP cache feature, however that is not available in the Android UI if I understood correctly the patch?\nFor the features I am working on (not just fingerprinting mitigations) I plan to eventually add some Android-specific UI (since that is my main focus), I have not yet become \"good enough\" to tackle that. The codebase is huge, the recent addition of an official Chromium mirror to Github helps in this task.\nSorry for the long post; I wanted to post here as a heads-up that something is being done on my side, but I know there are differences on approach/requirements.\nI have successfully implemented the getClientRects/getBoundingRects randomisation, patch to be published with next release of Bromite. I do not currently reckon the necessity of a toggle for that as the rationale is to simply spoil the precision of the floating point data returned, without any breakage; maybe you would be interested in that patch later on.. > There would need to be additional changes for it to work on Android, yes. The chain of functions to call should be similar, if not identical.\nYes. The part that I believe is more complicated is what you mention afterwards, having flags per-tab and per-site.\nYou can see how easily I implemented a toggle for Javascript (https://github.com/bromite/bromite/issues/37) in next release of Bromite in this patch: https://github.com/bromite/bromite/blob/master/patches/BRM046_Add-menu-option-to-toggle-global-Javascript-preference.patch\nBefore this implementation, I was going for the full-range approach e.g. having it implemented in the NavigationEntry (per-tab), including the session serialisation part. I gave up because I could not easily understand how the Javascript setting goes from Chromium preferences to the Webkit engine, but in general I believe it's doable to implement this and similar features per-tab/per-site.\nI believe Chromium should have these features upstream; see also: https://bugs.chromium.org/p/chromium/issues/detail?id=826681 (@Primokorn reported that one for cookies). However I am not making any effort to upstream the changes...I kinda gave up on that.\nFor the getClientRects,getBoundingClientRect fingerprinting mitigation I published the Bromite patch ahead of the release and opened PR #377 . I build Bromite, which uses some of the patches from ungoogled-chromium, Iridium and others I wrote. The project is specifically targeting android although does not go as far as blocking all connections to Google servers (see https://github.com/bromite/bromite/issues/8).\nI assume the procedure of building ungoogled-chromium would be very similar; I offer my help if I can be of support for this issue.\nI have tried getting this to build for F-Droid, with little success so far: https://gitlab.com/fdroid/rfp/issues/378 Their VM-based approach is too complicated/bloated in my opinion.. For extensions, see also Brave, the source code is on Github. But I agree it is better discussed in another issue.</offtopic>\nTo go back on topic: the F-Droid guys were nice, however I am afraid even if we build there with their VM and toolchain, we still have the problem of SDK/NDK (and the other binaries downloaded by gclient), in the sense that even when Chromium builds completely through fdroid tools, this might still be an open problem because you are letting a third-party (Google) binary in the build process (see DDC).\nRegarding the binaries downloaded by gclient: they are basically more recent versions of the upstreams, with specific patches/improvements from the Chromium team. One version might work, another might not. The differences should not be too big so in theory one could also track what are the patches and build even those tools (although that's some work...).. Premise: Chromium has lots of dependencies. These are not git submodules, but repositories* checked out in Chromium's src working copy.\nAgree with the ideal build process, also because IMO all build processes should be arranged like:\n\nget the source code of main repo and all dependencies at the right version/commit\nget all the right tools (binary or compiled in place, although Chromium goes for binaries AFAIK)\nperform build (build can be done without any network access, thanks to previous steps)\n\n(1) and (2) are relatively complex, that's why depot_tools is there and its use-case overlaps/conflicts with F-Droid's own srclibs feature for example. It was a bit painful but I had managed to convert DEPS to srclibs for F-Droid.\ngclient also runs \"hooks\" (corresponding to (2) in list above) which further prepare the code within the repositories, no idea what these hooks do in detail but I see they're python mostly.\nSo, in conclusion: if we rip out depot_tools, are we not going to end up writing something similar? Perhaps we should keep that, it is all python anyway.\nThe problem, as far as I can see, is with the binaries/blobs being downloaded. That is for sure not something that would make it in a Debian repository or F-Droid (if the criteria for inclusion are respected, and they should).\n* = not necessarily git repositories, although I see everything is git nowadays?. From my POV, I advise against replacing depot_tools, mostly because of the extra work involved with no benefits.\n\nAdditionally, depot_tools also uses its own distribution of Python and possibly other binaries\n\nI was not aware of the custom python distro, but I think that is not necessary. Any recent python would do, no custom python features are being used. As for other binaries, I have seen no others used by depot_tools itself (just in the hooks).\nBut regarding the rest you mentioned: yes it would be extremely useful to start individuating them and the possible FOSS replacements (it is a moving target).\n\nMost git browsers I've seen these days (including Google's git browser) include a feature to download an archive (usually tar or zip) at a specific commit.\n\nI find it more useful to use git because you can download the incremental changes, otherwise this becomes a 20GB-per-time download job. Build nodes (like the Debian/F-Droid ones) do care about this aspect.. @Eloston 20GB (it is more, actually) is the size of everything checked out, including SDK/NDK and everything else downloaded/checked out by gclient. It includes all .git directories, not much git garbage as I ran git gc --prune=all few weeks ago.\nIn short, everything that exists under src/ in the builder filesystem. See bottom of this post.\nYes, I would love to get rid of as much deps as possible (I only exclude nacl at the moment). Although if massive patches are needed for the build system (ninja/gn), then it'd become again a moving target and painful to support. I am aware of the small size of the chromium-browser-official, but I doubt that on Android we can get away with something similar? I suspect that if you sum up the size of the zips that you would fetch for each dependency, you would still get a big number. This would be completely fine to replace the binaries downloaded by gclient, no binary patching happens for them anyway (AFAIK).\nAnyway, feel free to ignore me on this. I'd be glad to get through experimentation a slimmer build and possibly using more FOSS tools rather than the Chromium default ones. After few months building for Android I kinda gave up on this (without really trying, but just from the \"feeling\" of it).\nI report below some partial listings from ncdu. The out directory contains intermediates + final products, which one would ideally want to keep for faster incremental builds (but these do not count in terms of dependencies download estimation, obviously).\n23.2 GiB [##########] /third_party                                                                                                                                                         \n   22.6 GiB [######### ] /out\n    8.8 GiB [###       ] /.git\n  972.2 MiB [          ] /v8\n  686.0 MiB [          ] /chrome\n  427.8 MiB [          ] /native_client\n  393.5 MiB [          ] /build\n  392.1 MiB [          ] /.cipd\n  156.3 MiB [          ] /tools\n  127.8 MiB [          ] /components\n  120.3 MiB [          ] /buildtools\n   81.8 MiB [          ] /content\n   78.4 MiB [          ] /media\n   68.2 MiB [          ] /net\n   67.5 MiB [          ] /ui\n   41.4 MiB [          ] /native_client_sdk\n   40.6 MiB [          ] /ios\n   18.7 MiB [          ] /extensions\n   18.3 MiB [          ] /base\n   17.4 MiB [          ] /remoting\n   16.6 MiB [          ] /ash\n   14.4 MiB [          ] /ppapi\n   12.9 MiB [          ] /gpu\n   11.5 MiB [          ] /services\n   11.1 MiB [          ] /cc\n    8.4 MiB [          ] /testing\n    8.2 MiB [          ] /chromeos\n    8.0 MiB [          ] /device\n    7.2 MiB [          ] /mojo\n    6.4 MiB [          ] /android_webview\n    5.9 MiB [          ] /headless\n    5.9 MiB [          ] /docs\n    5.1 MiB [          ] /courgette\n    4.5 MiB [          ] /chromecast\n    3.7 MiB [          ] /sandbox\n    3.1 MiB [          ] /storage\n    2.2 MiB [          ] /google_apis\n    1.1 MiB [          ] /skia\n    1.0 MiB [          ] /ipc\n  896.0 KiB [          ] /url\n  892.0 KiB [          ] /printing\n  784.0 KiB [          ] /pdf\n[...]\nDrilling down into third_party:\n9.9 GiB [##########] /android_tools\n    3.7 GiB [###       ] /android_ndk\n    1.4 GiB [#         ] /WebKit\n  756.1 MiB [          ] /catapult\n  736.7 MiB [          ] /skia\n  494.3 MiB [          ] /gvr-android-sdk\n  474.6 MiB [          ] /icu\n  400.6 MiB [          ] /instrumented_libraries\n  397.3 MiB [          ] /deqp\n  307.2 MiB [          ] /boringssl\n  294.6 MiB [          ] /hunspell_dictionaries\n  276.2 MiB [          ] /webrtc\n  270.8 MiB [          ] /ffmpeg\n  241.5 MiB [          ] /angle\n  230.2 MiB [          ] /llvm-build\n  202.5 MiB [          ] /swiftshader\n  190.7 MiB [          ] /liblouis\n  165.8 MiB [          ] /libaom\n  161.4 MiB [          ] /pdfium\n  154.9 MiB [          ] /webgl\n  151.8 MiB [          ] /sqlite\n  148.8 MiB [          ] /vulkan-validation-layers\n  126.3 MiB [          ] /node\n  124.9 MiB [          ] /chromite\n  122.7 MiB [          ] /libvpx\n  112.5 MiB [          ] /android_protobuf\n  110.1 MiB [          ] /openh264\n  102.4 MiB [          ] /depot_tools\n  102.2 MiB [          ] /sfntly\n   79.4 MiB [          ] /libphonenumber\n[...]\nIn android_tools:\n4.9 GiB [##########] /.git\n    3.8 GiB [#######   ] /ndk\n    1.2 GiB [##        ] /sdk\n   12.0 KiB [          ]  LICENSE\n[...]\nAnd in android_ndk:\n1.6 GiB [##########] /toolchains\n    1.0 GiB [######    ] /.git\n  579.5 MiB [###       ] /platforms\n  454.3 MiB [##        ] /sources\n   79.3 MiB [          ] /prebuilt\n   35.3 MiB [          ] /simpleperf\n   12.8 MiB [          ] /sysroot\n    6.4 MiB [          ] /shader-tools\n    1.0 MiB [          ] /build\n[...]. @nikolowry those patches are effectively scattered around ~500 commits, see my comment here; by doing the changes that way, the CodeAurora devs made it impossible to easily maintain/port the patches.\nAlso, I am not really sure that ungoogled-chromium would benefit from them; there is a night mode, always-incognito mode, and integration with Web Defender and Secure Connect.\n(sorry for the off-topic). @xsmile you could use the commits of this project: https://gitlab.com/thermatk/Unobtainium/commits/liberated (in particular those with \"kill\" in the commit subject, which I use in Bromite).\nIt is going through the process of F-Droid inclusion so you have the same goal there (binaries removal).. I have had at least one similar report; my suggestion is to look upstream for possible Chromium issues. Difficult to say whether it's the same root cause or not, since Bromite builds for Android and there are a lot of differences also in the memory model.. Another suggestion: what do you see in the task manager (Shift + Esc)? A leak would not associate memory to any specific tab.. > The 5% noise is actually from a cited source:\n\nThat paper is available here: http://www.www2015.it/documents/proceedings/proceedings/p820.pdf\n\nI did not understand that the whole paragraph was about PriVaricator. Thanks.\n\nUnlike this patch, PriVaricator applies 5% offsets to more than just get*ClientRect[s]. Their results have shown minimal to no breakages for the top 1000 Alexa sites by comparing screenshots of the rendered sites.\n\nYet no source code was published, it would have helped similar implementations.\n\nAs such, I would like to have this feature behind a command-line flag or chrome://flag option. Not only does it offer configurability, but it also informs the user of potential issues this can cause.\n\nSorry, no plans to add this. I will close this PR.\n\nI'm not too familiar with the DOM side of web application execution, but maybe we could read this flag once per tab, and then have it pass down through Document to individual Elements to reduce the cost of looking up command-line arguments.\n\nThere are similar flags already in Chromium, like those that are periodically added when a feature is being deprecated (see the deep and shadow CSS selectors for example). One can just look at how those implementations work to do the same.. I use this for Bromite, no specific issues to report. You can mention me in case you see something weird during the build and perhaps I can remember if I already met the problem context.\nFrom the top of my head, a note about Google services integration: it checks if a header file with API keys is present, if not it just keeps going. The file obviously is not there in your case as you would get this file only in the internal Google network.. > I don't see any new changes in the Bromite patch you linked me. Can you clarify?\nRight, I can see only the percentage was downscaled from 5% to 3%; I did this because I suspect some websites have a \"flickering\" effect as they try to move objects while you scroll (suspicion not verified though). But it's pretty arbitrary so I am not suggesting you should change that too.\n\nWhat purpose does this patch serve when the other battery API patch is also included?\n\nNow that you mention it, I am not sure. I will merge both.. @Eloston I forgot to mention: in the DNS-over-HTTPS patch I have done some other changes than just allowing a provider selection via chrome://flags: I set the URL request priority to high (it seems like a reasonable thing to do) and I reduce the headers to minimum with a new load mode (see https://github.com/bromite/bromite/issues/70).. @Eloston considering the scope of ungoogled-chromium, I would additionally suggest only:\n https://github.com/bromite/bromite/blob/master/patches/BRM056_Add-a-flag-for-DNS-over-HTTPS.patch (should work fine on desktop browsers too)\n https://github.com/bromite/bromite/blob/master/patches/BRM003_Battery-API-return-nothing.patch (the patch you already have is not sufficient, for some reason)\nOn the same topic of anti-fingerprinting mitigations, but decisively more invasive (since it breaks the functionality):\n* https://github.com/bromite/bromite/blob/master/patches/BRM051_AudioBuffer-AnalyserNode-fingerprinting-mitigations-via-IDL.patch (I am planning to redo this patch to provide always randomised results as the other patches do, eventually)\nNot so important, but since Firefox has this configurable option you could also consider:\n* https://github.com/bromite/bromite/blob/master/patches/BRM058_Add-flag-to-configure-maximum-connections-per-host.patch\nI can also tell you that I checked the Brave implementation for fingerprinting mitigation and I concluded that Bromite's patches (so basically those you mentioned) are not that bad, probably better (I can't say as I am biased).\nPlease note that the URLs you are using point to master and not the specific commit and unfortunately sometimes I reorganise the patches and the BRMxx prefix would change so the links would return 404 eventually (it would still be possible to find them by their subject as that does not change). > This is a nice patch, but could you explain what you mean by this?: this can however be detrimental to devices with limited CPU/memory resources and it is disabled by default. How exactly can this be detrimental?\nI am reporting almost 1:1 the comment you can find here: https://github.com/chromium/chromium/blob/master/net/socket/client_socket_pool_manager.cc#L37\nHowever I do not \"buy\" it: Firefox has been using 15 for ages, I have done some experimentation and there is no difference, without mentioning that a cap to 6 connections per host is yet another way to detect that a Chrome-based browser is running on the other end of the wire (I know, super-tinfoil-hat idea, but it would not be difficult at all to detect browsers capped at 6 connections...).\n\nI tried the Battery API with the latest tag of ungoogled-chromium (68.0.3440.106-1), and it doesn't seem to be returning real data. Can you elaborate on what is being leaked? Maybe this is an Android-specific problem?\n\nIt could be. Perhaps on Android it has some other hook to update state? It has been a while since I last touched that part of the code; it had been reported to me in this issue and I verified that indeed without the patch battery data was returned.\n\nI was debating about including this since I personally believe DNS over HTTPS is silly (almost defeating the purpose of having different networking protocols on different ports, and abuse of HTTP)\n\nI still believe it is of great advantage (and the least of all evils, a reasonable compromise) in current situation on Android; see also my write up here where I articulate why between your ISP and Google, Cloudflare might be a better choice as they should have less datapoints about the user/user's IP: https://github.com/bromite/bromite/issues/98#issuecomment-408224699 \nIt is technically an abuse of the protocol, but I prefer it to the complete lack of customisation of the DNS choice on Android; it is not enabled by default on Bromite but these days I advise users to do so as explained in the wiki page: https://github.com/bromite/bromite/wiki/Enabling-DNS-over-HTTPS . > In that case, I'll see if I can find a cleaner solution by disable the monitoring service or system calls for the info. If not, I'll use what you have.\nLet me know, I might use your version as well.\n\nHm, I didn't consider the lack of good DNS configuration on Android.\n\nThis as other patches of Bromite are mainly Android-focused, and very much following Bromite's mission of practical privacy for Android users. To be precise about DNS on Android, this is a summary of the situation:\n you can use a VPN (for example, blokada, DNS66, Intra and similar create a localhost VPN) to override DNS for all connections and set your preferred DNS, and additionally gain possibility of host-based adblocking (which is inferior to URL or DOM-based adblocking anyways)\n you can configure the DNS for each wifi connection you use\n you cannot override mobile data DNS settings, nor proxy settings\n Chromium on Android has no settings for DNS nor proxy and uses system configuration for those\n(If I am wrong on this summary, please somebody correct me)\nHence the possibility of using DNS-over-HTTPS configurable from the browser becomes more practical than any of the available options, which 99% of the userbase will likely not pursue.\n\nI suppose it will be some work to allow the users customize this freely since the chrome://flags infrastructure only supports finite states. \n\nI noticed this and I plan to eventually add a chrome:// page where one could also customize proxy settings for the browser, however I am no good at UI changes so this is taking a while, nor I have had much time to work on it. Even if/when I would develop it, it would be mostly Android-focused for the reasons detailed above.\nIf you are building for Android you will see that this and other patches make more sense than for the desktop use-case sometimes.. FYI I updated the max connections patch yesterday: https://github.com/bromite/bromite/blob/master/patches/BRM058_Add-flag-to-configure-maximum-connections-per-host.patch\nI fixed the logged warning and reduced the options to 6 and 15 since the default was already 6.. @Eloston thanks, will give this a try. For the bulk of the deleted code in the .cc file, wouldn't the #if 0 approach be more cherry-pick friendly?. I understand, you're right; not sure about the correlation with #362 though. You mean that more specific changes help in troubleshooting?. > By the way, is there any reason why DNS over HTTPS is available on Android only? Can it be enabled for all platforms?\nMore juicy marketing segments on Android, since you can correlate the data there better? No idea, just my speculation/guess. It will work just fine on all platforms; as you can see my implementation also tries to cover https://github.com/bromite/bromite/issues/70 (original thread: https://mailarchive.ietf.org/arch/msg/doh/vHjITrOMhWSdrozGFe4-eGNMEJc).\nSince DoH is an opt-in setting, nothing wrong to allow it; Firefox even switches to it by default, which I actually think it's wrong because users which know how DNS work have the legit expectation that all DNS goes through the DNS that they configured.\nThe whole DoH-in-chromium feature seems an experimental/underdeveloped feature, I guess it's somebody's pet project and it is not yet clear where they want to go. Feels like they regret adding it and they do not move further? Correct me if I am wrong, but I have not seen anywhere published what are the upstream (Chromium) plans for this feature.\nEdit: from what I remember there was no Android-specific code involved, it seemed to me as well to be arbitrarily limited to Android. Of course it is possible that there is some specific problem that makes it not working/unusable outside Android, but I guess you will have to find it out, since no comments mentioned anything of this sort in the relevant code.\n\nIs possible to add custom servers? apart from Google and Cloudflare anyone can run there own DoH server.\n\nIn short, no. It is not related to DNS-over-HTTPS though, it is just that in Chromium adding a free-entry text field is a pain, flags cannot have it and thus you should implement the UI. UI means: Linux/Windows, iOS, Android. And the translations; that means some work, even if you cover only main OSes.\nAs usual, patches are welcome.\n\nForgot to reference eb5aa1a to this issue.\n\nYes, you have the correct (latest) version of this patch, I checked. Some previous version would spam the logs with a conversion error.\n\nAfter I get an answer to the earlier question, then I'll close this issue.\n\nAny idea for future similar collaborations? We do not really have forums or a similar place for OOB communication.. The Android version even checks for command line arguments, but it's not possible to pass any there, so you see code reading from the process' command line but actually it's just a buffer for parameters inherited from elsewhere (never investigated deeper on this). It might be the case that with some special intent you can pass some information to an Android app, but I would not know how, nor if it is even possible.. I have seen your improvement to the randomisation in the Canvas patch and the \"return nothing\" non-breaking patch for the WebGL info; I will probably pick at least the latter and credit you in the patch commit message.\nAs for the randomisation improvement (e.g. reduction of calls to grab randomness), it should be fine as well but at the moment I am not quite sure if something similar was tried or not in terms of effectiveness.\nEdit: I checked the returned WebGL information: unfortunately there is a lot more there, texture parameters etc. Hiding just the vendor and renderer name would not suffice to prevent unique identification of the GPU hardware.. @Eloston I think it's all the info below \"WebGL Image\" here: https://browserleaks.com/webgl\nAlso look at the two reports here: http://webglreport.com/?v=1 http://webglreport.com/?v=2\nI suspect that this information can allow identifying the specific GPU hardware regardless of the vendor string (which should not be unmasked anyways)? Or, in \"bits of uniqueness\" parlance, it provides the same amount of bits.\nEdit: now that I think of it, not reporting the WebGL information/capabilities might be \"security by obscurity\": what if it is perfectly possible to reconstruct it via Javascript/WebGL by attempting to use each of them? In that case I would be against having any security by obscurity in place.. Yes I agree in theory (related: https://github.com/bromite/bromite/issues/131); my point was more like: given a specific GPU hardware, and the complete set of values excluding GL renderer and vendor, is that combination unique? If yes there is no point to hide them since somewhere it can exist a database where given the hash of all the rest, you can get back the text we are hiding. Or more: the amount of entropy is unchanged by the patch, it just takes trivial more work to extract it.\nThis and other concerns could be talked better with some data at hand, but none of the online services (https://browserleaks.com/, https://amiunique.org/) publishes it, although they all do harvest it (the page I setup at https://www.bromite.org/detect doesn't: it's just a static github page).\nThere might be somewhere a database of these, probably researchers of the field and/or online marketers, but I am not aware of the public research data (although one could expect these to be published, I did not search) and I am not friend with the latter.. I will have time to start working on this next week; I will report back my findings. My hope is that the impact in code changes is manageable.. I had tried myself to port the safebrowsing-eviction patch to v70, didn't manage; glad you have a working version here.\nI have some additional changes for Android (the v69 addendum is here: https://github.com/bromite/bromite/blob/master/patches/BRM080_Fixes-for-building-without-safebrowsing-on-Android.patch), I will publish the new version adapted for v70. Not sure you should include it now if you're not building for Android (might quickly go stale) but I thought to mention it here for other people trying to build for Android without safe browsing.. @Eloston we all agree \n\nNot sure you should include it now if you're not building for Android (might quickly go stale) . On a separate topic, is the canvas mitigation still effective? I got an issue report (https://github.com/bromite/bromite/issues/154) but not investigated yet.\n\n(the rects part is fine) . The issue with canvas was due to an invalid automatic patch application with fuzziness, my bad; I have also updated the patch to use the optimisation of reduced rand() calls: https://github.com/bromite/bromite/blob/70.0.3538.71/patches/BRM053_Canvas-fingerprinting-mitigations-for-image-data-and-webGL.patch#L142\nOn another topic (sorry for going kinda-off-topic here): have you experienced issues at fetching the webrtc third-party dependency via git?\nIn v69 and v70 (and in the past as well) I cannot fetch the git commit specified in DEPS but rather I can get it via the web interface (https://chromium.googlesource.com/external/webrtc/).\n@xsmile are you doing the same? Otherwise, how do you fetch webrtc via git? Just curious if for some reason I am not able to fetch it via git because the tree is not published via git but only via HTTP.. Thanks for the pointer! I use gclient sync --upstream, and in your script --no-history --shallow I guess have the same limitation/feature: they do not fetch extra refs, hence that's why it is needed to use the explicit fetch for the separate WebRTC tree.. > Sorry for the late response; not sure if you have figured it out yet or not.\nNo worries, thanks for your reply. I have not figured it out yet.\n\n\n#passwords-keyboard-accessory: Do you have #experimental-ui enabled?\n\n\nThey are both disabled by default according to the Chromium code.\n\n\n#enable-query-in-omnibox: The link you provided is to the wrong flag (kUIExperimentMaxAutocompleteMatches). Even after searching around with the correct flag, I'm not too sure why it is being enabled.\n\n\nYes, the search results from that site are not pinned to a version. I am still puzzled as well about this one.\n\nAlternatively, both flags are listed under testing/variations/fieldtrial_testing_config.json (in CamelCase). I believe this is a place where field trials are defined and set, so it may have been enabled randomly. You can disable fieldtrials with a GN flag that is defined here. See components/feature_engagement/README.md for more general info about field trials, and testing/variations/README.md (also linked in the previous document) for the format of fieldtrial_testing_config.json.\n\n\nThis is interesting, thanks for the pointers. I had read about this before but I was not aware of the role of that JSON file.\nWould you say that the patch I use here https://github.com/bromite/bromite/blob/70.0.3538.95/patches/BRM071_Disable-fetching-of-all-field-trials.patch is ineffective to disable those?\n\nI haven't looked at how you configured Bromite, nor do I know much about field trial tests, so I could be wrong. Let me know what you find.\n\nI use is_official_build=true but of course that does not set the branded flag, I will try a build with fieldtrial_testing_like_official_build=true, I think that might make the defaults I expect become effective.\nI will report back, thanks again!. I can confirm that fieldtrial_testing_like_official_build=true made the defaults in the code effective; thanks again!. I did not notice this issue before, some (late) feedback:\n* having the name contain a trademark of a company is problematic and it will always be the case, so I would suggest to loose it whenever possible to avoid any potential future issue; IANAL but this is probably the feedback you would get from any lawyer, you can also contact one through EFF (although probably you will get a referral and not an official endorsement)\nEverything I have read here and also @Eloston decisions make sense, my 2 cents:\n the build system is the most important part also related to making FOSS builds; this is a concern which has before popped up to my attention (for the Android targets) with https://gitlab.com/thermatk/Unobtainium and more recently in https://github.com/nikolowry/bromite-builder/issues/4; however, the holy grail here would be to upstream a \"FOSS mode\" build in Chromium itself; I am saying this because otherwise patch maintenance is a relatively big burden for any downstream\n the build system would ideally be very flexible and allow customization of the patchsets to use\n* @Eloston you should not inflate this project to become so big that it takes away all your free time and drains your energy: try to split it in a way that you are still motivated and happy to work on it, and delegate parts to collaborators (as you feel fit) that might want to contribute their time; I am suggesting this as a general rule of thumb if you see the project increasing in size outside your comfort zone\nI have also read the privacytools.io issue (my comment here: https://github.com/privacytoolsIO/privacytools.io/issues/274#issuecomment-452332784); I disagree that a privacy violation must be proven before disabling an integration, as the user should always have choice regardless, but I agree that for some other patches (like fingerprinting) there should be scientific proof before adoption and use (and I have tried to follow the scientific approach in such \"experiments\" with fingerprinting mitigations).. The relative code (for Linux) is here: https://cs.chromium.org/chromium/src/components/download/quarantine/quarantine_linux.cc?q=kSourceURLExtendedAttrName&dr=C&l=48\nAlthough the function is called QuarantineFile, it seems always called on downloads.. ",
    "seba2282": "I have question. If it will be, can you add extensions too supported and converted from chrome and mozilla ? It will be the best product and please delete function with login. The same please for windows and finaly as exe file installer :)\n. ",
    "GeitHub": "Very interested in helping with this in any way that I can. The Replicant (FSF-approved de-blobbed Android distro) devs have released a (somewhat dated) ungoogled version of the Android SDK (NDK too?) that can be used with Eclipse. Perhaps it could be used?\nAlso, if this is attempted & is successful the earlier request here about adding extensions might not be as difficult as one might imagine. Yandex Alpha browser (closed source) has extensions implemented without any added UI elements in the statusbar, it simply adds access to the chrome://extensions page. This is a separate issue though, but it's worth mentioning because it'd surely bring a lot of eyes to the project (and hopefully more devs!).\n. ",
    "usernamenotexist": "ANDROID?\nUSE ORFOX AND ORBOT.\n. Flash must die. It cause security risk.\n. ",
    "magicgoose": "\nThe Replicant (FSF-approved de-blobbed Android distro) devs have released a (somewhat dated) ungoogled version of the Android SDK (NDK too?)\n\nI think there's no big deal in using official (\"googled\") Android SDK, as long as one is not using closed-source google libraries \u2014 stuff like Google Play Services (ungoogled chromium doesn't need them anyway), etc. The build product still will not be googled in that case.. @zt3phan I think they would say if they did.. @woolyss it's only for windows\u2122.. This is not a big deal if it is installed via brew cask install caskroom/cask/eloston-chromium because it can check hashes and signatures automatically, and it doesn't have to be Apple-issued (and b.t.w. the Apple way of signing is a flaky business because AFAIK it still allows signing only a subset of files inside an .app and thus it's possible to replace unsigned parts; but with normal signing methods, the entire archive is signed)\nPerhaps it'd be more gain to just make sure (if not already so) that the formula in homebrew-cask is up-to-date at all times.. > The cask just pulls from the binary uploaded to GitHub without doing any authenticity check (since there's no way to do it right now).\nIt depends on the formula. Right now it checks sha256 sum that means the formula maintainer has seen that file and it didn't change from there.\nThere's a possibility to add a GPG key and then it will also check if it's signed with that key.. @nsuchy but which systems are not compromised? If we count Intel's ME and AMD's PSP as backdoors (which they very likely are), then a lot of systems (used by us, mere mortals), are compromised.\nBut security is not \"black&white\", there is such a concept as \"Defense in Depth\". And even if the system is compromised to some extent (for example, somebody like CIA having full control), it doesn't always mean that one must give up and not protect it from other possible attackers.. ",
    "zt3phan": "Is anyone currently working on Android support at all?. @magicgoose Point taken,hade to ask thou. Very eager to get an android port.. Eloston: I just shared tour github-link on fb as i know a few good dev's. Hope you'll get support! Would be great, as it surely get's to work on LineageOS too, as it's a built on CyanogenMod (aosp).... ",
    "D0ve": "Any knews about - 'Debian's Android SDK and NDK packages and Chromium on Android extensions support' ?\nCould it possible compile the browser builds with Debian Android SDK?\nAnd about extensions..., Yandex did this support somehow..., there's a key to compile with-to supoort extensions on android, but popuping a lots paths errors to solve...\n. https://habrahabr.ru/company/yandex/blog/309014/\ntranslated   https://translate.google.com/translate?hl=&sl=auto&tl=en&u=https%3A%2F%2Fhabrahabr.ru%2Fcompany%2Fyandex%2Fblog%2F309014%2F&sandbox=1\nAs they wrote, they used enable_extensions flag when compilling, but got a lots of errors.... and did fix it all.\nImho need some reverse engineering or look inside to compilled build to see what they did to support extensions on browser for Android.\n. ",
    "thermatk": "Hey there!\nTo build with standard SDK/NDK instead of patched prebuilts, seems like you just have to provide paths in gn args, for instance:\ndefault_android_sdk_root = \"/opt/android-sdk\"\ndefault_android_ndk_root = \"/opt/ndk-r16b\"\nAnd more vars here: https://chromium.googlesource.com/chromium/src/+/master/build/config/android/config.gni. Even better, I successfully build with standard SDK and NDK by replacing the bundled with symlinks. ",
    "nikolowry": "Any advice on integrating ungoogled-chromium with the CAF Browser (Chromium Browser for Snapdragon), https://www.codeaurora.org/project/chromium-browser-for-snapdragon?  \nI know they aren't actively maintaining their fork anymore, but I've been doing custom builds with the latest release tag (it's mirrored/imported via a bot). Their instructions for v55 are for the most part still working and valid.. Building and running fine on Arch (2+ days as daily driver).  However, I've been struggling with trying to customize the build to support Vulkan (enable_vulkan=true)  -- if anyone has some pointers, don't hesitate to share.\nCurrently, the build errors out nearly at the halfway mark with the following:\n```\n[8624/21757] CXX obj/skia/skia/SkImage.o\nFAILED: obj/skia/skia/SkImage.o \nclang++ -MMD -MF obj/skia/skia/SkImage.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUSE_AURA=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DCHROMIUM_BUILD -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNO_UNWIND_TABLES -DCR_CLANG_REVISION=\\\"321529-2\\\" -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_HAS_PNG_LIBRARY -DSK_HAS_WEBP_LIBRARY -DSK_HAS_JPEG_LIBRARY -DSK_VULKAN_HEADER=\\\"../../skia/config/SkVulkanConfig.h\\\" -DSK_VULKAN=1 -DSK_SUPPORT_GPU=1 -DSK_GAMMA_EXPONENT=1.2 -DSK_GAMMA_CONTRAST=0.2 -DSK_DEFAULT_FONT_CACHE_LIMIT=20971520 -DGLIB_VERSION_MAX_ALLOWED=GLIB_VERSION_2_32 -DGLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_26 -DUSE_SYSTEM_ZLIB=1 -DUSE_SYSTEM_LIBJPEG -DUSING_SYSTEM_ICU=1 -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC -DUCHAR_TYPE=uint16_t -I../.. -Igen -I../../skia/config -I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/encode -I../../third_party/skia/include/gpu -I../../third_party/skia/include/images -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pdf -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/vulkan/include -I/usr/include -I../../third_party/skia/src/gpu -I../../third_party/skia/src/sksl -I../../third_party/skia/include/gpu/vk -I../../third_party/skia/include/codec -I../../third_party/skia/include/private -I../../third_party/skia/include/client/android -I../../third_party/skia/src/codec -I../../third_party/skia/src/core -I../../third_party/skia/src/image -I../../third_party/skia/src/images -I../../third_party/skia/src/opts -I../../third_party/skia/src/pdf -I../../third_party/skia/src/ports -I../../third_party/skia/src/shaders -I../../third_party/skia/src/shaders/gradients -I../../third_party/skia/src/sfnt -I../../third_party/skia/src/utils -I../../third_party/skia/src/lazy -I../../third_party/skia/third_party/gif -I../../third_party/skia/src/effects/gradients -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -Igen/shim_headers/libevent_shim -Igen/shim_headers/zlib_shim -Igen/shim_headers/icuuc_shim -I../../third_party/libpng -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/harfbuzz -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I../../third_party/sfntly/src/cpp/src -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -Wno-builtin-macro-redefined -D__DATE__= -D__TIME__= -D__TIMESTAMP__= -fno-unwind-tables -fno-asynchronous-unwind-tables -fPIC -pipe -pthread -fcolor-diagnostics -no-canonical-prefixes -m64 -march=x86-64 -fno-omit-frame-pointer -g0 -fvisibility=hidden -Wall -Wno-unused-variable -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-unused-lambda-capture -Wno-user-defined-warnings -Wtautological-constant-out-of-range-compare -O2 -fno-ident -fdata-sections -ffunction-sections -std=gnu++14 -fno-exceptions -fno-rtti -fvisibility-inlines-hidden -D_FORTIFY_SOURCE=2 -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector-strong -fno-plt -c ../../third_party/skia/src/image/SkImage.cpp -o obj/skia/skia/SkImage.o\nIn file included from ../../third_party/skia/src/image/SkImage.cpp:29:\nIn file included from ../../third_party/skia/include/gpu/GrTexture.h:12:\nIn file included from ../../third_party/skia/include/gpu/GrBackendSurface.h:16:\nIn file included from ../../third_party/skia/include/gpu/vk/GrVkTypes.h:13:\n../../third_party/skia/include/gpu/vk/GrVkDefines.h:51:2: error: \"Vulkan header version is too low\"\nerror \"Vulkan header version is too low\"\n```\nAttempting a build now that omits the patches to determine whether it's a build configuration error on my part or if a patch is the culprit.  If it turns out to be a build configuraiton issue, I'm planning on copying some of the GN args' values from https://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=chromium-dev&id=8670e9e1691649f1424759b7b258572bdc6165ef.\nI'll comment back here either way with my findings, and possibly open a new issue once the root cause of the error is.\n\nI've made no progress tracking the root of this error, going to pause on my trial/error attempts until v66. @Eloston tried a bunch of different ways (even compiled Clang locally) -- but no luck. \nAfter thinking about it I don't know if it was the Vulkan or SwiftShader support that fixes my specific GPU problems (blinking mouse pointer when hovering over GTK3 widgets) when running a mixed dpi multi monitor setup (i7 Skylake laptop w Intel HD).  \nI'll keep experimenting, the inox-dev/beta builds seemed to have figured it out.. Thanks for the background @xsmile -- just removed it!. ",
    "trymeouteh": "I would love this for testing my website on my Andriod device and not need to use Google's Chrome anymore. And please make this andriod version of Ungoogled Chrome available on the F-Driod store.\nAlso not only that it would not be worthwile to make a Ungoogled Chromium for iOS since iOS does not allow Chromium, Firefox, or any other browser engine to run on iOS except for the Safari Webkit.. This is for Linux, Not windows. I would like to install this browser multiple times on my Ubuntu machine but cannot figure out a way.. Is it possible to create an installer that is an portable installer where you can select the user directory path for a more user friendly setup?. By choosing the user data directory custom path without a command line but instead use a installer to select the data directory. ",
    "xsmile": "I created a configuration bundle and build scripts for Android at https://github.com/xsmile/ungoogled-chromium/tree/android. All patches are applied, domain substitution is done and system Clang is used for the build. Binary pruning is done only partially and multiple proprietary binaries and libraries - mainly SDK, NDK, Play Services - are used for the build. While the result is far from being \"ungoogled\", this should be a good start.\nI'm not sure if it is a good idea to create a PR at this point, as the new android bundle can in theory depend on the common bundle for the most part but more changes would be needed.\nDetailed descriptions of the changes can be found in the respective commit messages.. @csagan5 Thanks, this is interesting. It should speed up things a bit.. @Atavic, @Eloston I'm not sure if I see any real issue here. The public IP is needed to initiate connections to other servers and is exposed even without WebRTC, independently of the user's connection method.\n@Atavic I believe the information is mostly outdated, see [1][2].\n1: https://github.com/diafygi/webrtc-ips\n2: https://github.com/diafygi/webrtc-ips/issues/25. @Eloston Are you referring to this article [1]? They say that \"a user first has to grant a site permission before it can access audio and video\". \nChromium extensions have access to WebRTC IP handling settings, see [2]. Google's official WebRTC extension accesses them [3] and so does uBlock Origin [4]. From a privacy point of view the safest option for webRTCIPHandlingPolicy should be disable_non_proxied_udp which exposes the public IP only.\nTests did not show my local IP address and could not even show the public one if I activated uBlock's WebRTC feature - with and without being connected to an OpenVPN server.\nEDIT:\nPossibly webRTCIPHandlingPolicy can be pre-set to disable_non_proxied_udp, eliminating the need for uBlock in this case. However I cannot imagine myself browsing the web without it nowadays.\n1: https://nakedsecurity.sophos.com/2017/05/31/chrome-bug-that-lets-sites-secretly-record-you-not-a-flaw-insists-google/\n2: https://chromium.googlesource.com/chromium/src/+/master/chrome/common/extensions/api/privacy.json#40\n3: https://chrome.google.com/webstore/detail/webrtc-network-limiter/npeicpdbkakmehahjeeohfdhnlpdklia\n4: https://github.com/gorhill/uBlock/blob/master/platform/chromium/vapi-background.js#L199. @Atavic The webRTCIPHandlingPolicy setting disable_non_proxied_udp corresponds to Mode 4 as defined in draft-ietf-rtcweb-ip-handling-04 and is activated by uBlock Origin.. Chromium 61 is scheduled for release in three days and it is likely the Iridium team is waiting for it.. @LeFroid, I updated the Inox patchset recently and pushed the changed to its develop branch. Despite not being in master yet, it compiles and runs fine. Should the build error affecting chunk.proto result from the safe-browsing patches, please take a look in there to hopefully save some time. I encountered a similar error when updating the patches. Thanks for the hard work!\nEDIT: Eloston was faster :P. Another point to consider are the platforms supported by both projects. While Inox is made specifically for Arch Linux, Ungoogled Chromium supports Linux, OS X and Windows. This hardly makes any difference patch-wise, but each OS requires its own set of build flags that change over time. Further each release should ideally be tested to ensure everything works as it should, requiring even more resources.\nEleston's toolkit provides an abstraction for Chromium's build process and allows to create configurations for different systems and setups in a consistent way. It should be possible to create an Inox config without much trouble.\nMaybe a merge isn't that bad after all. Seeing that Iridium's team has trouble keeping their patches up to date, it might be an idea to additionally get in contact with them too. Ungoogled would benefit from the Windows support and Iridium from the bigger community hopefully helping keep things up-to-date from time to time.\nPersonally I'm happy with having an up-to-date Arch Linux build but I'm not opposed to contribute to a more generic solution, if needed.. You can use something like this patch https://raw.githubusercontent.com/xsmile/inox-patchset/e111eb8dadedbb9fa673f0a7bb129d10ab93fe2e/9003-disable-avatar-button.patch which disables the button unless it is enabled via chrome://flags.\nAlternatively as mentioned by @Artur96 it might be better to keep it enabled by deault unless the user disables it.. That's an interesting question. fpm for instance can generate platform-specific packages for dpkg, RPM, pacman and some other package managers.\n. @avently Most probably you need to apply breakpad-use-ucontext_t.patch from the official Arch Linux chromium package, see https://git.archlinux.org/svntogit/packages.git/tree/trunk?h=packages/chromium.. If the issue only affects VA-API, it should be related to the libva library. If I'm not mistaken Debian 9 uses libva1, while libva2 has been out for some time including several Kabylake and VP9 fixes.\nI'm not sure why the issue appeared with 65 though.. @ryanmusante The AUR has a chromium-widevine package that installs the component in /usr/lib/chromium/ ~~instead of /opt/google/chrome/ as described in the FAQ~~. Not sure if this makes a difference, most probably Chromium supports both paths.. From what I gathered from [1] Chrome Cleanup Tool consists of a Software Reporting component and a Cleanup Tool that is downloaded on-demand if a threat is found by Software Reporting.\nThe first one can be found in Google Chrome only but not in Chromium; check the page chrome:components to see if it is installed. Furthermore ungoogled-chromium prevents components from being updated. The second one heavily relies on the Safe Browsing service which is not available in ungoogled-chromium. Even if the tool was downloaded automatically somehow, although very unlikely since all Google URLs were removed to prevent any unwanted communication, it would not function properly.\n1: https://cs.chromium.org/chromium/src/chrome_cleaner/README.md?q=UwS&sq=package:chromium&dr=C&l=5. I don't mind rebasing the PR on the updated develop branch when you finish your changes.. I rebased the PR and updated it to 66.0.3359.117 stable.\n@Eloston Please review the commits again as they have might have slightly changed.. The minimum should be LLVM 5.0 as e.g. build/config/compiler/BUILD.gn uses linker options not available in previous versions like --thinlto-cache-dir. Still a patch is required.\nLLVM 6.0 is fully supported.. This seems to be a rather unnecessary restriction, at least for our purposes.\nWe will know if I forgot any other changes :P. I have been using squalus' build for a couple of days and it works fine so far.. That was quick, great.. Does media playback with the faulty builds produce any logs in the console or on the chrome:gpu, chrome:media-internals pages?. @dubvulture @Eloston test_fonts can most probably be skipped using the patch at  https://github.com/Eloston/ungoogled-chromium/commit/ba903b2e93036ba366ca7be5f9e90d39b839bb2e#diff-31eef377f22cab09ac4b8eabe94dd6b2 which was removed a while ago.. @seppiofish I can confirm the issue. My profile directory contains about 10GB consisting of many 8MB sized BrowserMetrics-*.pma files. A new file seems to be created each time a new browser session is started.\nStarting with version 67 inox-patchset/9000-disable-metrics.patch was changed to use Chromium's new DummyHistogram class to prevent histogram recording and apparently this has some unwanted side-effects. I will look into it for the next stable release in two weeks.\nIn the meantime you should disable write access to the BrowserMetrics directory to prevent .pma files from being written. I'm not sure how psd will react to this though.\nEDIT: The method InstantiatePersistentHistograms is responsible for writing these files and it is managed by the Field Trials feature. I cannot see a connection to the changes mentioned above. It must be something else.. @jlj2 To clarify - in hope that my suspicion is true - as I use XFCE with Thunar and the results should be the same. Do you drag the extension to the address bar or to the page?\n\nWhen drag-and-dropping the extension from within the Thunar file manager, the pointer becomes an icon resembling a hand grabbing a white 'file' with a 'plus' sign .\n\nThat pointer appears when dragging a .crx file to the address bar or to any page except chrome://extensions. When dragging it to the chrome://extensions page, you should see an arrow pointing upwards instead of the plus sign and a grey overlay covering the whole page as mentioned by Eloston.\nDoes an unmodified Chromium version show the same behavior or it is specific to Ungoogled Chromium?. @jlj2 Dragging extensions in the portable build of 67.0.3396.87-1 does not work for me either. It behaves exactly the way that you described.\nFollowing ribatamu's suggestion works. The old extension page allows extensions to be installed.\nI believe I figured out the issue. Try enabling Developer Mode in the top right corner of the extensions page. Afterwards dragging .crx files should work with the Chromium version of your distribution as well as with the portable version of Ungoogled Chromium. Most probably this change was introduced with version 67.\nThe fork is used to submit pull requests to the original repository, usually for updating patches when a new Chromium version is released.. See https://github.com/Eloston/ungoogled-chromium/issues/423#issuecomment-398940894.. The UDP broadcast of the media router is not limited to Windows and can be effectively disabled by creating a managed policy setting for EnableMediaRouter, at least in Linux.\nThe state of the media router is set in chrome/browser/media/router/media_router_feature.cc:\n```\nbool MediaRouterEnabled(content::BrowserContext* context) {\nif defined(OS_ANDROID) || BUILDFLAG(ENABLE_EXTENSIONS)\nconst PrefService::Preference* pref = GetMediaRouterPref(context);\n  // Only use the pref value if it set from a mandatory policy.\n  if (pref->IsManaged() && !pref->IsDefaultValue()) {\n    bool allowed = false;\n    CHECK(pref->GetValue()->GetAsBoolean(&allowed));\n    return allowed;\n  }\n// The component extension cannot be loaded in guest sessions.\n  // TODO(crbug.com/756243): Figure out why.\n  return !Profile::FromBrowserContext(context)->IsGuestSession();\nelse  // !(defined(OS_ANDROID) || BUILDFLAG(ENABLE_EXTENSIONS))\nreturn false;\nendif  // defined(OS_ANDROID) || BUILDFLAG(ENABLE_EXTENSIONS)\n}\n``. @2x9Mon Did you restart Chromium after setting the policy? I cannot reproduce it with Windows 10 and Ungoogled Chromium 67.0.3396.87. Does the chrome:policy page show aMandatory` level for the policy? Otherwise it won't have an effect.\nThis is the policy I used, same as yours:\nWindows Registry Editor Version 5.00\n[HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Chromium]\n\"EnableMediaRouter\"=dword:00000000. @2x9Mon I used the binaries compiled by Wyse- at https://github.com/Eloston/ungoogled-chromium/issues/414#issuecomment-402553207.. See https://github.com/Eloston/ungoogled-chromium/issues/441.\nI wonder about the installer, too. Currently Ungoogled Chromium cannot be registered as the default browser in Windows 10 without manually editing the registry but this is just a minor drawback.. @anchev: Please see https://github.com/Eloston/ungoogled-chromium/issues/494#issuecomment-422631189, I believe intika faced the same issue and solved it by using a recent version of lld.. > BTW, this breakage was introduced in 68, right?\nYes, 67 worked well without the need for this flag.. The text file was pulled by the official PKGBUILD a while back but it is not needed anymore, see the relevant commit. It should be removed.. I refreshed the patches but cannot figure out why debian/gn/libcxx.patch does not pass validation. Updating the patch manually with quilt or via update_patches.py does not alter its contents.\nThe remaining config bundles should probably be marked as outdated for now.. The current patches seem to be sufficient for the stable build 69.0.3497.81, they just need to be refreshed.. This is fine, however sed and the following commands need to be run on the Chromium source. A cd \"$_tree\" is missing after the buildkit operations.. It's a feature, see #484.. The search engine template in the source code allows the specification of an additional autocomplete URL, otherwise the feature won't work. For Google it was removed, DuckDuckGo has it and it works well, Searx' autocomplete API doesn't seem to be compatible to Chromium on the other hand and no URL was inserted.\nI can't say much about custom search engines which are added while visiting web sites. If that URL is not added automatically, the only way to change this is probably by adding that search engine to the source.. I'm not sure how this can be done without restoring Google search which is removed by replace-google-search-engine-with-nosearch.patch.\nEven if only the relevant suggest_url field is restored, I don't think it will be used when Google is added as a search engine during runtime.. @Eloston I'm not sure I follow.\nThe suggestion/autocomplete feature works as of now, see DuckDuckGo.\nFrom my point of view there is no way to use this feature with Google - or apparently any other search engine - without hard-coding the full search engine template, as it is done in the original Chromium. I may be wrong though, I didn't check the source.. @Eloston This sounds doable, considering that a very similar text field already exist for editing the URL of a search engine.\nThe Preferences text file in the user data directory stores the currently selected search engine and contains a suggestions_url property. Editing it manually will probably work too, as long as the search engine settings are not changed.. This seems to be related to the \"Sign-in to Chromium\" function of the browser which is disabled.\nOtherwise all Google cookies are deleted, at least the ones contained in the 'Cookies' file found in the browser profile.. You can run Chromium with a new temporary profile, login to various Google sites,\nrm -rf /tmp/chromium-profile && chromium --user-data-dir=/tmp/chromium-profile\nand inspect the cookie database with e.g. sqlitebrowser:\nsqlitebrowser /tmp/chromium-profile/Default/Cookies. Seems to work well so far. Mostly URLs found in comments are substituted.\nI created a PR at #534.. @maxbla You can additionally try to run the chromium-vaapi-bin package from the AUR. The only difference to the official package is the VA-API patch which is included in ungoogled-chromium, too.\nShould it fail to run, then we have a suspect.. @Eloston It is definitely related but I didn't have the chance to investigate yet. I assume that it won't do anything since users cannot sign in into Chromium. In any case, disabling the preference should be the better option.. Alright, I will most likely refresh the patches and add the lists once the stable build is published.. I refreshed the existing and updated patches for Debian which include an important change:\nThe path to the master_preferences file was changed from /usr/share/chromium/master_preferences to /etc/chromium/master_preferences.\n@csagan5 I did a few Android builds to test compatibility with the ungoogled patchset but I don't think I will continue to do it. It's probably better to keep the patches separated for now.\nNevertheless, it's nice to see the safebrowsing patches included in Bromite.. @csagan5 No issue here. The canvas fingerprint changes each time.. @csagan5 This is the workaround I used for the WebRTC repository for 69: https://github.com/xsmile/ungoogled-chromium/blob/android/packaging/android/build.sh.ungoogin#L35.\nI'm not sure why depot_tools doesn't find the commit and I assumed this is not an issue if you stick to the original build instructions.. #569 is likely related. In any case, both the error and the warning should not appear with LLVM 7.. Some additions which might be interesting:\n Nano Defender - Unbreaks sites which lock out users of ad-blockers\n Skip Redirect - Skips requests to intermediary pages\n* Neat URL - Removes common unwanted parameters from URLs. AFAIK 0-RTT is not implemented in Chromium right now and this should not be an issue. This might change with future releases though.. > Does the patch stop working in version 71? Did you check that? It works for both UIs in version 70.\nI checked it briefly and it requires updating as code referencing the old UI was removed. If needed, I can update and include it again.. > @xsmile Please update the patch, it is fixed now.\nThank you, I included it again.. The harfbuzz patch is already present in patches/debian_buster/system and can be used by listing it in config_bundles/archlinux/patch_order.list. ungoogled' build scripts will take care of the rest.. > Should I break this project up and define a more concrete and narrower definition of \"ungoogling\"?\nKeeping the key features as a requirement, maybe with the addition of patches from the borrowed features, and marking the enhancing features as optional might be an alternative. That way you can have a clear definition of the project without dropping some interesting patches not directly related to the core idea. For example, I don't want to miss the recent HTTPS patch, although I do not consider it a key feature of ungoogled-chromium. Where to draw the line is a good question and this is also a question of maintenance.\nI consider binary pruning and domain substitution to be more of a fail safe but still an important part of this project. Auditing the changes of each Chromium release is impossible and both help to maintain a Google free browser, especially if a feature with connectivity was left intact after all patches were applied.\n\nShould I change the scope of ungoogled-chromium to more align with my preferences (and perhaps change the name as well)?\n\nI believe that for the most part you should decide in which direction this project will be heading. After all this is your hobby and I imagine that you want to keep an interest in it. The project name doesn't matter much to me.\n\nShould the browser be split up to let other developers determine how they want to package ungoogled-chromium (...), or should it more strictly control the entire process of the browser creation (...)?\n\nAssuming the current philosophy, the building process needs to be controlled to a certain extent by altering the source and by providing sets of patches and GN flags. Certain settings can be overridden during building as long as they don't violate the key ideas. Either way, what happens after this step should not be your responsibility anymore.. subprocess.call([bisonExe, '-d', '-p', prefix, inputFile, '-o', outputCpp]) and OSError: [Errno 2] No such file or directory likely indicate that bison is not installed. As Parabola is based on Arch Linux, you need to install the base-devel package group.\nYou can also use the AUR package ungoogled-chromium.. This might be a memory issue. You can try using a swap file during the compilation process.. Alright, the remaining errors seem to be related to the other bundles I didn't update.. Alternatively the mei_preload files can be excluded with this patch:\n```\n--- a/chrome/BUILD.gn\n+++ b/chrome/BUILD.gn\n@@ -304,7 +304,6 @@ if (!is_android && !is_mac) {\n       }\n   data_deps += [\n\n\n\"//chrome/browser/resources/media/mei_preload:component\",\n         \"//third_party/widevine/cdm:widevinecdmadapter\",\n       ]\n\n@@ -1239,7 +1238,6 @@ if (is_win) {\n       \":widevine_cdm_library\",\n       \"//build/config:exe_and_shlib_deps\",\n       \"//chrome/app/nibs:chrome_xibs\",\n-      \"//chrome/browser/resources/media/mei_preload:component_bundle\",\n     ]\n if (is_chrome_branded) {\n\n``\nI didn't notice anything unusual with such a build yet.. The vpx and lcms2 patches can also be removed for Chromium 65, see the [Debian series file](https://sources.debian.org/src/chromium-browser/65.0.3325.146-1/debian/patches/series/).. You are right, it can be removed..is_official_buildis responsible for a set of optimization flags. E.g. for 64-bit Linux it enables ThinLTO and control-flow integrity. It slows down the build process but should have advantages during runtime. I experimented with these flags a while back if you remember and recentlyis_official_build` made it into the official Arch Linux build script.\nI can't comment on the effects for other operating systems though and it will need to be tested.\nAdditional changes to make it work are listed at [1] and [2]. Specifically the patch for ICU is needed if the system library is used and I believe that the rest is optional.\n1: https://git.archlinux.org/svntogit/packages.git/commit/trunk?h=packages/chromium&id=067cef8b936524e5ff1801a57042b2d121ef1363\n2: https://git.archlinux.org/svntogit/packages.git/commit/trunk?h=packages/chromium&id=8f15906c7fab24107b34f42f05a4be8e337969e3. Indeed, this is the same patch. It originates from the Gentoo repository, hence the name.\nYou are probably right. Maybe it is better to remove inox-patchset/chromium-clang-r4.patch and to refresh ungoogled-chromium/linux/fix-libstdcxx630-errors.patch to avoid confusion?. See my comment above :). I have no idea, sorry.. I just realized that I used an older version of the patch :confused:  It should be fine now.. It was not required and I refreshed and renamed your patch.. Done. I can't comment on the Google Meet functionality but the rest seems to work so far.. AFAIK generate_shim_headers.py is invoked for unbundled libraries set up with build/linux/unbundle/replace_gn_files.py.\nIt definitely makes sense to include the patch in this config bundle.. Done.. Done, see #396.. Fixed.. Right, fixed.\nThanks for the instructions, I'll take a look next time.. This is optional, I removed the patch.. Fixed.. ",
    "kd7lxl": "It's OS X 10.11.6.\n$ uname -v\nDarwin Kernel Version 15.6.0: Mon Aug 29 20:21:34 PDT 2016; root:xnu-3248.60.11~1/RELEASE_X86_64\nYes, it's pretty strange. I don't find the reference to suggestions.pb.h in a code search: https://cs.chromium.org/chromium/src/chrome/browser/search/instant_service.h?sq=package:chromium&dr&l=20\nBut it's right there in build/sandbox/chrome/browser/search/instant_service.h on my build:\n``` c\ninclude \"components/keyed_service/core/keyed_service.h\"\ninclude \"components/search_engines/template_url_service_observer.h\"\ninclude \"components/suggestions/proto/suggestions.pb.h\"\ninclude \"components/suggestions/suggestions_service.h\"\ninclude \"content/public/browser/notification_observer.h\"\ninclude \"content/public/browser/notification_registrar.h\"\n```\n. > Do you have out/Release/gen/protoc_out/components/suggestions/proto/suggestions.pb.h?\nNope.\nls: build/sandbox/out/Release/gen/protoc_out/components/suggestions/proto/suggestions.pb.h: No such file or directory\nAnd elsewhere:\n$ ls build/sandbox/components/suggestions/proto/\nBUILD.gn        suggestions.proto\n\nDid you try to build it multiple times? Did you run python3 build.py more than once?\n\nYes, and I run the command rm -rf build before calling python3 build.py. Is this the correct procedure?\n. Still same problem.\n```\n2016-09-27 20:49:16,581 - DEBUG: Appending resources/common/cleaning_list\n2016-09-27 20:50:55,542 - ERROR: Exception thrown for tar member chromium-53.0.2785.116/third_party/skia/tools/gyp\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/tarfile.py\", line 2197, in makelink\n    os.symlink(tarinfo.linkname, targetpath)\nFileExistsError: [Errno 17] File exists: '../third_party/externals/gyp/' -> 'build/sandbox/third_party/skia/tools/gyp'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/tarfile.py\", line 2207, in makelink\n    self._extract_member(self._find_link_target(tarinfo),\n  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/tarfile.py\", line 2370, in _find_link_target\n    raise KeyError(\"linkname %r not found\" % linkname)\nKeyError: \"linkname 'chromium-53.0.2785.116/third_party/skia/tools/../third_party/externals/gyp/' not found\"\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"build.py\", line 57, in \n    exit(main())\n  File \"build.py\", line 37, in main\n    builder.setup_chromium_source()\n  File \"/Users/tom/src/ungoogled-chromium/buildlib/common.py\", line 357, in setup_chromium_source\n    \"chromium-{}\".format(self.chromium_version))\n  File \"/Users/tom/src/ungoogled-chromium/buildlib/_util.py\", line 128, in extract_tar_file\n    raise exc\n  File \"/Users/tom/src/ungoogled-chromium/buildlib/_util.py\", line 125, in extract_tar_file\n    tar_file_obj._extract_member(tarinfo, str(destination)) # pylint: disable=protected-access\n  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/tarfile.py\", line 2116, in _extract_member\n    self.makelink(tarinfo, targetpath)\n  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/tarfile.py\", line 2210, in makelink\n    raise ExtractError(\"unable to resolve link inside archive\")\ntarfile.ExtractError: unable to resolve link inside archive\n```\nIt's too bad tarfile doesn't have an overwrite option.\n. ",
    "xianwenchen": "Thank you!\n. ",
    "woolyss": "Hello everybody,\nPlease, can you test new releases of 64-bit chromium with ungoogled-chromium patches?\nhttps://chromium.woolyss.com/#windows-64-bit\nFor info, nik is the main developer of stable 64-bit Chromium versions, available over the Internet.\nAnd chromium.woolyss.com is reliable source without ads.\n. Hello @Eloston, thank you very much. I made a simple resource and Nik has mainly improved it with its Chromium releases.\nI am not Nik but I can try to answer you. I invited him to come here.\n1) He uses source cleaning.\n2) I do not know if he uses buildlib but he includes the patches in his own build process.\nNik does not use all patches because there are few limitations. Some of patches are not working because they are for GYP build system (fix-building-without-one-click-signin.patch and others) - Ref.: https://github.com/Eloston/ungoogled-chromium/issues/16#issuecomment-233821506 - Nik compiles Chromium with GN build system and PGO optimization.\nAnyway, good work @Eloston ! ;)\n. @Eloston: Ok, I understand. I wrote a disclamer on the site.\nhttps://chromium.woolyss.com/#windows-64-bit\nFinally, can you compile a 64-bit version of ungoogled-chromium for Windows?\nI think it could be better than our merged builds! ;)\n. > Yeah I'm planning to do that as soon as I can.\nNice! Thank you for your work and support.\n. @chrcoluk, I have nothing against Eloston and its project but see my review at:\nhttps://chromium.woolyss.com/?all=1#comment-1566\n(note this link will display all comments. So the content can be slow to display)\nAnyway you can download our 64-bit version (chromium-ungoogled.zip) at:\nhttps://github.com/henrypp/chromium/releases/tag/v53.0.2785.143-r403382-win64\nFor info, you will find a site archive at:\nhttps://web.archive.org/web/20161115065312/http://chromium.woolyss.com/#windows-64-bit-chocolatey. @Eloston : Henry updated its tool (chrlauncher) to install, update and launch ungoogled-chromium ;)\nhttps://github.com/henrypp/chrlauncher/issues/33#issuecomment-279736691. Henry updated its tool (chrlauncher) to install, update and launch ungoogled-chromium ;)\nhttps://github.com/henrypp/chrlauncher/issues/33#issuecomment-279736691\n...but nothing about extensions. Sorry.. @magicgoose, Yes. It is only for Windows.\nI know it is possible to write a shell script to update ungoogled-chromium on Mac and Linux.\nAn example about Chromium: https://github.com/mloporchio/chromium-downloader-script\nMore on my site: https://chromium.woolyss.com/#updater (this is about Chromium but can be improved for ungoogled-chromium). Yes @Eloston, I completely agree with you.. You talk about this patch https://github.com/hparadiz/chromium-disable-profile-button-patch\nNo, it doesn't work on new Chromium versions. . ",
    "chrme": "Hi @Eloston, i've used some of your patches from \"patch_order\" file only (some was failed and some i've disabled because of \"trk\" part and domain substitution).\n. > Have you tested them to see if it works?\nYes, it works.\n\nwhat are your future plans?\n\nI'm only compile the original chromium with a custom config (i have fully automatic script that also checking for a new version) because i don't have much free time.\n\nAre you planning to update the rest of the patches that use GYP?\n\nBut the GYP don't have compilation problems.\n. > So you've converted all of the GYP flags from resources/common/gyp_flags to GN args I'm guessing?\nsome args are gone in GN, but i'm use most of it\n\nyou're using Google's build of yasm\n\nunfortunately yes\n\nsince you're not running both source cleaner and domain substitution.\n\ni'm running both, but on 32-bit windows the wow_helper is cleaned and i compile it by hand (can't figure it out how to send 'msvs_target_platform': 'x64' to BUILD.gn because it use x86 and show the error)\n. ",
    "chrcoluk": "woolyss so what happened to your builds? I see no mention of it on your site.. ",
    "cheater": "As i understand, there are memory utilization drawbacks to static builds - so yes - and also I would eventually like a ppa that will let me update with apt, so having a deb for a start is an important step in that direction.\n. Yes, that is what I would like - 14.04 is going to be the second most used version of Ubuntu and it is the one I use. I use it on the i686 arch \n. Great, thanks for triaging it so quickly!\n. ",
    "notDavid": "Any website.\nYes, I just tried pinch to zoom in the exact same version (53.0.2785.116) from Chromium FreeSmug and zooming works.\n. > Unfortunately, I don't have a Macbook with a trackpad to test this.\nI assume Linux/Windows can also do pinch to zoom, on a laptop? Maybe someone can test if they also have the same issue, on another OS..\n. OS X 10.12.1, 53.0.2785.116 (64-bit).\nI don't know, i just opened Chromium for example, and immediately got a popup. Closed it, then browsed to some random website and within 15 seconds got a second popup. Another website, no popup. Went to Reddit.com clicked around a bit and another popup within 20 seconds.... etc.\nhttp://i.imgur.com/3bsvWTS.png \n. Nope (i don't even have a Google account..)\n. ",
    "piningforthefnords": "Confirming this is broken on El Capitan (2015 MBP Retina 15\") as well. It does work with generic Chromium and Chrome, as well as other things (eg; Preview). Zoom using CMD+ works fine.\nI'll be happy to help test in any way you like, but I have no idea what I'm doing with GUI apps.\n. @Eloston Correct, it's still not working, although CMD+/- does. This was why I was looking at arguments in the build thread, though the zoom option is present in both. There's no mention of zoom or pinch in any of the patches here, so I'm beginning to wonder if part of that takes place in a blob it fetches from Google.\nI started Chromium, the latest build of ungoogled-chromium, and srware iron (another chromium variant) while wireshark was running, and saw the other two fetching blobs from Google, whereas this did not. Both of the other ones did have a working pinch to zoom.\nI'll see about fetching all the blobs tomorrow and trying to find a reference to it in there.. @Eloston I'm not sure what's going on really. The first blob (unzip works on it) I fetched was pretty innocent looking, but after that it was all SSL, and I don't currently have certs set up on this laptop to allow interception (though I'll get that set up tomorrow). Both of the other Chromium variants fetched quite a bit of data before I quit.\nJust to clarify, ungoogled-chromium was not making any requests for blobs or anything else from Google.. @Eloston Does not appear to be a blob. Even with all cache and profile data wiped and network disconnected, zoom worked. I'll post if I figure out what it is.. You can install OSX in virtualbox if you don't care so much about the legality of doing so, or I can provide you with a VM running on a laptop (though I can't guarantee I'll remember not to shut the lid), or will help with testing.. Same error on ffmpeg for me. Looks like it's looking for it in \"ungoogled-chromium/build/sandbox/out/Release/obj/third_party/ffmpeg\"; I built ffmpeg by hand and placed the files there. Rerunning build now; let's see what happens.. Got a new error - see https://gist.github.com/piningforthefnords/ace46e59e9368a0a4cfb3f1f14dfdc40. New error here as well, see gist.. @Eloston @9Morello - Last nights final commit fixed the StartSyncCallback error for me. Still having the issue with iridium::trace_url_request; haven't had much of a chance to dig into it today (I've spent today fighting with a completely different google product).. Build successful, using it now. There's a non-production/test DMG here with sha256 sum of ff82f965726e89110ec19f95382143fd25f2758ace231b03d1aa843d0c82bc78 if you want to throw it in a VM to see what happens. Build log is here.\nI'm not sure if it's a bug or not, but the arguments it now runs with are different than what it had before (if memory serves), and very different than the ones used by generic Chromium. They're in the same gist as the build log.. @Eloston @9Morello Thanks for the heads up on the args; I knew about the field trials one, but not how it worked with the other arguments. I was hoping one might be related to pinch to zoom #67 issue, even though it does seem to be present. And thanks for all the hard work with this! People appreciate having a safe browser.. @9Morello It did create the package successfully for me. Have you tried attaching to it with dtruss to see what it's hanging on?. @Eloston Tried building; same error as @9Morello.\n[7879/24388] SOLINK WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\nFAILED: if [ ! -e \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" -o ! -e \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\" ] || otool -l \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | grep -q LC_REEXPORT_DYLIB ; then TOOL_VERSION=1480633325 ../../build/toolchain/mac/linker_driver.py ../../third_party/llvm-build/Release+Asserts/bin/clang++ -shared -Wl,-exported_symbol,_PPP_GetInterface -Wl,-exported_symbol,_PPP_InitializeModule -Wl,-exported_symbol,_PPP_ShutdownModule -stdlib=libc++ -arch x86_64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -mmacosx-version-min=10.7 -Wl,-ObjC -o \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" -Wl,-filelist,\"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.rsp\" -framework ApplicationServices -framework AppKit -lbsm -framework CoreFoundation -framework IOKit -framework Security  && { otool -l \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | grep LC_ID_DYLIB -A 5; nm -gP \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | cut -f1-2 -d' ' | grep -v U$$; true; } > \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\"; else TOOL_VERSION=1480633325 ../../build/toolchain/mac/linker_driver.py ../../third_party/llvm-build/Release+Asserts/bin/clang++ -shared -Wl,-exported_symbol,_PPP_GetInterface -Wl,-exported_symbol,_PPP_InitializeModule -Wl,-exported_symbol,_PPP_ShutdownModule -stdlib=libc++ -arch x86_64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -mmacosx-version-min=10.7 -Wl,-ObjC -o \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" -Wl,-filelist,\"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.rsp\" -framework ApplicationServices -framework AppKit -lbsm -framework CoreFoundation -framework IOKit -framework Security  && { otool -l \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | grep LC_ID_DYLIB -A 5; nm -gP \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib\" | cut -f1-2 -d' ' | grep -v U$$; true; } > \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.tmp\" && if ! cmp -s \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.tmp\" \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\"; then mv \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.tmp\" \"WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.TOC\" ; fi; fi\nUndefined symbols for architecture x86_64:\n  \"_PPP_GetInterface\", referenced from:\n     -exported_symbol[s_list] command line option\n  \"_PPP_InitializeModule\", referenced from:\n     -exported_symbol[s_list] command line option\n  \"_PPP_ShutdownModule\", referenced from:\n     -exported_symbol[s_list] command line option\nld: symbol(s) not found for architecture x86_64\nclang-3.9: error: linker command failed with exit code 1 (use -v to see invocation)\nTraceback (most recent call last):\n  File \"../../build/toolchain/mac/linker_driver.py\", line 222, in <module>\n    Main(sys.argv)\n  File \"../../build/toolchain/mac/linker_driver.py\", line 72, in Main\n    subprocess.check_call(compiler_driver_args)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py\", line 540, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['../../third_party/llvm-build/Release+Asserts/bin/clang++', '-shared', '-Wl,-exported_symbol,_PPP_GetInterface', '-Wl,-exported_symbol,_PPP_InitializeModule', '-Wl,-exported_symbol,_PPP_ShutdownModule', '-stdlib=libc++', '-arch', 'x86_64', '-isysroot', '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk', '-mmacosx-version-min=10.7', '-Wl,-ObjC', '-o', 'WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib', '-Wl,-filelist,WidevineCdm/_platform_specific/mac_x64/libwidevinecdm.dylib.rsp', '-framework', 'ApplicationServices', '-framework', 'AppKit', '-lbsm', '-framework', 'CoreFoundation', '-framework', 'IOKit', '-framework', 'Security']' returned non-zero exit status 1\n[7879/24388] CXX obj/third_party/widevine/cdm/widevinecdmadapter/cdm_helpers.o\n. @Eloston @9Morello I set enable_widevine=false in gn_flags and it built. No crashes yet, but it seems slower than 54.x (or maybe it's just my imagination).\nEdit: There's an issue with it doing something ugly with stored credentials. Don't run it outside of a VM if you let it store creds / aren't using a password manager.. @9Morello Nope, it wasn't the stored credential warning (though it did do this, as expected), it rendered existing credentials unusable. Any credentials saved by a previous version were lost on the first run of 55, though any credentials added in 55 were saved and worked properly. When reverting to 54 the old credentials still didn't work.\nThe startup time is definitely much longer than before, and I'm agreeing with you that it does feel less responsive. I think most of that unresponsiveness is in UI stuff and not browsing/rendering HTML.\nWhen I make it back home I'll see if I can figure out what it did to them.\n. ",
    "poiru": "@Eloston I ran into this with another Chromium-based project and filed https://bugs.chromium.org/p/chromium/issues/detail?id=680927\nYou might be running into the same problem. If so, you can work around it by building against the macOS 10.10 SDK. Hope this helps!. ",
    "tectiv3": "Wow, it works now!. I'll give it a try later today.. It works.. Got it, thank you!\nI have a lot of ninja errors because of the missing files (those that were removed when cleaning sources) how do you run build without those files? I think they are mostly required by unittests, can we build without tests?. Nevermind. Do you happen to know why it would fail on:\nFAILED SOLINK libtrknotify.dylib libtrknotify.dylib.TOC. Disabled \"//iridium:trknotify\", and finally built Chromium 57 for macOS :). I got this one too. The problem was with is_component_build = true that I set to speed up builds. With component_build disabled iridium trknotify builds just fine.\nI put up my macOS instructions in my fork so if you want I can submit a pull request.. Current instructions work just fine, no need to alter them.\nthere is a new warning though: \nwarning: unknown warning option '-Wno-unused-lambda-capture'; did you mean '-Wno-unused-parameter'? [-Wunknown-warning-option]\nOn 10.11.6 and Xcode 8.2.1. I've tested it on 10.9 and 10.11.. Got some errors building it on a mac:\n/ungoogled-chromium/build/sandbox/base/time/time_exploded_posix.cc:30:2: error: \"This implementation is for POSIX platforms other than Mac.\"\n ^\n1 error generated.\n```\n/ungoogled-chromium/build/sandbox/base/time/time_now_posix.cc:22:2: error: \"This implementation is for POSIX platforms other than Fuchsia or Mac.\"\nerror \"This implementation is for POSIX platforms other than Fuchsia or Mac.\"\n^\n/ungoogled-chromium/build/sandbox/base/time/time_now_posix.cc:56:2: error: No usable tick clock function on this platform.\nerror No usable tick clock function on this platform.\n^\n/ungoogled-chromium/build/sandbox/base/time/time_now_posix.cc:87:20: error: use of undeclared identifier 'ClockNow'\n  return TimeTicks(ClockNow(CLOCK_MONOTONIC));\n                   ^\n3 errors generated.\nIt should use `time_mac.cc` not `time_now_posix.cc` I think.. bootstrap.py is the reason.\nI've fixed bootstrap.py with moving time_now and time_exploded into:python\n  if is_posix and not is_mac:\n    static_libraries['base']['sources'].extend([\n        'base/time/time_exploded_posix.cc',\n        'base/time/time_now_posix.cc',\n    ])\nalso I needed to add\n        'base/task_scheduler/environment_config.cc',\ntopython\n  if is_posix:\n    static_libraries['base']['sources'].extend([\n```\nalso quilt patching isn't working properly:\n$ ./ungoogled_macos/build.sh\nThe series file no longer matches the applied patches. Please run 'quilt pop -a'.\n$ quilt pop -a\nPatch ungoogled_macos/patches/ungoogled-chromium/macos/fix-widevine-macos.patch does not remove cleanly (refresh it or enforce with -f)\nfixed quilt patch (it was widevine patch that failed) see #253\nStill can't build though.\n[466/26883] LIBTOOL-STATIC obj/components/gcm_driver/common/libcommon.a\nFAILED: obj/components/gcm_driver/common/libcommon.a\nrm -f obj/components/gcm_driver/common/libcommon.a && TOOL_VERSION=1502737495 python ../../build/toolchain/mac/filter_libtool.py libtool -static  -o obj/components/gcm_driver/common/libcommon.a obj/components/gcm_driver/common/common/gcm_messages.o\nerror: Unknown attribute kind (52) (Producer: 'LLVM4.0.0' Reader: 'LLVM APPLE_1_800.0.42.1_0')\nor\n[176/26409] LIBTOOL-STATIC obj/base/third_party/libevent/libevent.a\nFAILED: obj/base/third_party/libevent/libevent.a\nrm -f obj/base/third_party/libevent/libevent.a && TOOL_VERSION=1502737495 python ../../build/toolchain/mac/filter_libtool.py libtool -static  -o obj/base/third_party/libevent/libevent.a obj/base/third_party/libevent/libevent/buffer.o obj/base/third_party/libevent/libevent/evbuffer.o obj/base/third_party/libevent/libevent/evdns.o obj/base/third_party/libevent/libevent/event.o obj/base/third_party/libevent/libevent/event_tagging.o obj/base/third_party/libevent/libevent/evrpc.o obj/base/third_party/libevent/libevent/evutil.o obj/base/third_party/libevent/libevent/http.o obj/base/third_party/libevent/libevent/log.o obj/base/third_party/libevent/libevent/poll.o obj/base/third_party/libevent/libevent/select.o obj/base/third_party/libevent/libevent/signal.o obj/base/third_party/libevent/libevent/strlcpy.o obj/base/third_party/libevent/libevent/kqueue.o\nerror: Unknown attribute kind (52) (Producer: 'LLVM4.0.0' Reader: 'LLVM APPLE_1_800.0.42.1_0')\nno idea what it wants now. Yes, removing is_cfi=true helped. Should I upload resulting dmg somewhere?\nSee #255 for bootstrap.py patch. no, just diff.\nI didn't touch the filenames though, I think it's just github patch syntax highlighting.. Nope, didn't think about it.. I have another error after changing waitable_event_mac line:\n[372/372] c++  -o gn tools/gn/gn_main.o -framework AppKit -framework CoreFoundation -framework Foundation -framework Security libevent.a base.a gn_lib.a dynamic_annotations.a\nFAILED: gn\nc++  -o gn tools/gn/gn_main.o -framework AppKit -framework CoreFoundation -framework Foundation -framework Security libevent.a base.a gn_lib.a dynamic_annotations.a\nUndefined symbols for architecture x86_64:\n  \"base::DispatchSourceMach::Resume()\", referenced from:\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\n  \"base::DispatchSourceMach::DispatchSourceMach(dispatch_queue_s*, unsigned int, void () block_pointer)\", referenced from:\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\n  \"base::DispatchSourceMach::~DispatchSourceMach()\", referenced from:\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\n      void std::__1::vector<std::__1::unique_ptr<base::DispatchSourceMach, std::__1::default_delete<base::DispatchSourceMach> >, std::__1::allocator<std::__1::unique_ptr<base::DispatchSourceMach, std::__1::default_delete<base::DispatchSourceMach> > > >::__push_back_slow_path<std::__1::unique_ptr<base::DispatchSourceMach, std::__1::default_delete<base::DispatchSourceMach> > >(std::__1::unique_ptr<base::DispatchSourceMach, std::__1::default_delete<base::DispatchSourceMach> >&&) in base.a(waitable_event_mac.o)\n  \"base::mac::internal::MacOSXMinorVersion()\", referenced from:\n      base::WaitableEvent::WaitableEvent(base::WaitableEvent::ResetPolicy, base::WaitableEvent::InitialState) in base.a(waitable_event_mac.o)\n      base::WaitableEvent::UseSlowWatchList(base::WaitableEvent::ResetPolicy) in base.a(waitable_event_mac.o)\n      base::WaitableEvent::Signal() in base.a(waitable_event_mac.o)\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\nld: symbol(s) not found for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nUpdate:\nbase::DispatchSourceMach::Resume() I found in:\nhttps://chromium-review.googlesource.com/c/chromium/src/+/553497\nand added two more targets:\nbase/mac/dispatch_source_mach.cc\nbase/synchronization/waitable_event_watcher_mac.cc\nBut base::mac::internal::MacOSXMinorVersion() is totally absent. I fixed it in source files manually :/\nAnd I also got broken Build.gn as @Artur96 \nUpdate 2:\nIt can't seems to find bundle_contents_dir substitution.. no, it didn't fix it. You still need to add\nbase/mac/dispatch_source_mach.cc\nbase/synchronization/waitable_event_watcher_mac.cc\nbut even after adding them, \n\"base::mac::internal::MacOSXMinorVersion()\", referenced from:\n      base::WaitableEvent::WaitableEvent(base::WaitableEvent::ResetPolicy, base::WaitableEvent::InitialState) in base.a(waitable_event_mac.o)\n      base::WaitableEvent::UseSlowWatchList(base::WaitableEvent::ResetPolicy) in base.a(waitable_event_mac.o)\n      base::WaitableEvent::Signal() in base.a(waitable_event_mac.o)\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\nld: symbol(s) not found for architecture x86_64\nremains. yeah, I did, but it's failing on the next stuff that was nowhere to be found.. Undefined symbols for architecture x86_64:\n  \"_IOObjectRelease\", referenced from:\n      base::mac::GetModelIdentifier() in base.a(mac_util.o)\n  \"_IORegistryEntryCreateCFProperty\", referenced from:\n      base::mac::GetModelIdentifier() in base.a(mac_util.o)\n  \"_IOServiceGetMatchingService\", referenced from:\n      base::mac::GetModelIdentifier() in base.a(mac_util.o)\n  \"_IOServiceMatching\", referenced from:\n      base::mac::GetModelIdentifier() in base.a(mac_util.o)\n  \"base::DispatchSourceMach::Resume()\", referenced from:\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\n  \"base::DispatchSourceMach::DispatchSourceMach(dispatch_queue_s*, unsigned int, void () block_pointer)\", referenced from:\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\n  \"base::DispatchSourceMach::~DispatchSourceMach()\", referenced from:\n      base::WaitableEvent::WaitMany(base::WaitableEvent**, unsigned long) in base.a(waitable_event_mac.o)\n      void std::__1::vector<std::__1::unique_ptr<base::DispatchSourceMach, std::__1::default_delete<base::DispatchSourceMach> >, std::__1::allocator<std::__1::unique_ptr<base::DispatchSourceMach, std::__1::default_delete<base::DispatchSourceMach> > > >::__push_back_slow_path<std::__1::unique_ptr<base::DispatchSourceMach, std::__1::default_delete<base::DispatchSourceMach> > >(std::__1::unique_ptr<base::DispatchSourceMach, std::__1::default_delete<base::DispatchSourceMach> >&&) in base.a(waitable_event_mac.o)\n  \"base::internal::ScopedNSProtocolTraitsRelease(objc_object*)\", referenced from:\n      base::mac::(anonymous namespace)::GetLoginItemForApp() in base.a(mac_util.o)\n  \"logging::OSStatusLogMessage::OSStatusLogMessage(char const*, int, int, int)\", referenced from:\n      base::mac::SetFileBackupExclusion(base::FilePath const&) in base.a(mac_util.o)\n  \"logging::OSStatusLogMessage::~OSStatusLogMessage()\", referenced from:\n      base::mac::SetFileBackupExclusion(base::FilePath const&) in base.a(mac_util.o)\n  \"_kIOMasterPortDefault\", referenced from:\n      base::mac::GetModelIdentifier() in base.a(mac_util.o)\nld: symbol(s) not found for architecture x86_64\nthose. @Eloston thank you! I will try that \"patch\" tomorrow. . Here is the patch to make it work:\n```\n--- ~/ungoogled-chromium/build/sandbox/tools/gn/bootstrap/bootstrap.py.orig 2017-12-01 12:30:14.000000000 +0900\n+++ ~/ungoogled-chromium/build/sandbox/tools/gn/bootstrap/bootstrap.py  2017-12-01 12:26:54.000000000 +0900\n@@ -707,10 +707,18 @@\n         'base/process/process_iterator_mac.cc',\n         'base/process/process_metrics_mac.cc',\n         'base/strings/sys_string_conversions_mac.mm',\n+        'base/threading/worker_pool_posix.cc',\n+        'base/synchronization/read_write_lock_posix.cc',\n         'base/synchronization/waitable_event_mac.cc',\n         'base/sys_info_mac.mm',\n         'base/time/time_mac.cc',\n         'base/threading/platform_thread_mac.mm',\n+        'base/mac/dispatch_source_mach.cc',\n+        'base/tracking_info.cc',\n+        'base/tracked_objects.cc',\n+        'base/mac/mac_util.mm',\n+        'base/mac/scoped_nsobject.mm',\n+        'base/mac/mac_logging.mm',\n     ])\n     static_libraries['libevent']['include_dirs'].extend([\n         os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'mac')\n@@ -724,6 +732,7 @@\n         '-framework', 'CoreFoundation',\n         '-framework', 'Foundation',\n         '-framework', 'Security',\n+        '-framework', 'IOKit',\n     ])\nif is_win:\n```\nThank you @Eloston !!. [10075/24633] LIBTOOL-STATIC obj/chrome/browser/safe_browsing/libsafe_browsing.a\nFAILED: obj/chrome/browser/safe_browsing/libsafe_browsing.a\nrm -f obj/chrome/browser/safe_browsing/libsafe_browsing.a && TOOL_VERSION=1510603750 python ../../build/toolchain/mac/filter_libtool.py libtool -static  -o obj/chrome/browser/safe_browsing/libsafe_browsing.a\nerror: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: no files specified\nUsage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool -static [-] file [...] [-filelist listfile[,dirname]] [-arch_only arch] [-sacLT] [-no_warning_for_no_symbols]\nUsage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool -dynamic [-] file [...] [-filelist listfile[,dirname]] [-arch_only arch] [-o output] [-install_name name] [-compatibility_version #] [-current_version #] [-seg1addr 0x#] [-segs_read_only_addr 0x#] [-segs_read_write_addr 0x#] [-seg_addr_table <filename>] [-seg_addr_table_filename <file_system_path>] [-all_load] [-noall_load]\nOr should I open another issue? Since this is another problem.\nalso lots of warnings:\nwarning: unknown warning option '-Wno-enum-compare-switch'; did you mean '-Wno-enum-compare'? [-Wunknown-warning-option]\n. Here is the patch to make it work\n```\ndiff -ENwbur ./build/config/compiler/BUILD.gn ../sandbox_b/build/config/compiler/BUILD.gn\n--- ./build/config/compiler/BUILD.gn    2017-11-14 05:09:10.000000000 +0900\n+++ ../sandbox_b/build/config/compiler/BUILD.gn 2017-12-01 14:22:57.000000000 +0900\n@@ -1222,7 +1222,7 @@\n         \"-Wno-user-defined-warnings\",\n     # TODO(thakis): https://crbug.com/753973\n\n\n\"-Wno-enum-compare-switch\",\n\n\"-Wno-enum-compare-switch\",\n]\n } else if (use_xcode_clang && xcode_version_int >= 830) {\n   # This is necessary to allow a progressive transition from using xcode 8.0\ndiff -ENwbur ./chrome/browser/BUILD.gn ../sandbox_b/chrome/browser/BUILD.gn\n--- ./chrome/browser/BUILD.gn   2017-12-16 12:54:46.000000000 +0900\n+++ ../sandbox_b/chrome/browser/BUILD.gn    2017-12-16 00:14:12.000000000 +0900\n@@ -1532,7 +1532,6 @@\n \"//chrome/browser/metrics/variations:chrome_ui_string_overrider_factory\",\n \"//chrome/browser/net:probe_message_proto\",\n \"//chrome/browser/profiling_host\",\n\n\"//chrome/browser/safe_browsing\",\n     \"//chrome/browser/ssl:proto\",\n     \"//chrome/browser/ui\",\n     \"//chrome/common/net\",\ndiff -ENwbur ./chrome/browser/extensions/BUILD.gn ../sandbox_b/chrome/browser/extensions/BUILD.gn\n--- ./chrome/browser/extensions/BUILD.gn    2017-11-14 05:09:13.000000000 +0900\n+++ ../sandbox_b/chrome/browser/extensions/BUILD.gn 2017-12-16 01:48:01.000000000 +0900\n@@ -799,7 +799,6 @@\n     \"//chrome/browser/devtools\",\n     \"//chrome/browser/media/router\",\n     \"//chrome/browser/media/router/discovery\",\n\"//chrome/browser/safe_browsing\",\n     \"//chrome/common\",\n     \"//chrome/common/extensions:mojo_bindings\",\n     \"//chrome/common/extensions/api:api_registration\",\ndiff -ENwbur ./chrome/browser/ui/BUILD.gn ../sandbox_b/chrome/browser/ui/BUILD.gn\n--- ./chrome/browser/ui/BUILD.gn    2017-12-16 12:54:46.000000000 +0900\n+++ ../sandbox_b/chrome/browser/ui/BUILD.gn 2017-12-16 00:46:47.000000000 +0900\n@@ -488,7 +488,6 @@\n     \"//chrome/browser/engagement:mojo_bindings\",\n     \"//chrome/browser/media:mojo_bindings\",\n     \"//chrome/browser/profiling_host\",\n\"//chrome/browser/safe_browsing\",\n     \"//chrome/browser/ui/webui/omnibox:mojo_bindings\",\n     \"//chrome/browser/ui/webui/usb_internals:mojo_bindings\",\n     \"//chrome/common\",\n. @Eloston I am preparing a pull request to include this as a macOS patch. Also your bootstrap patch didn't work, needed to fix path, including it as well. OK. Will do. Got this error when preparing sources:\nExtracting clang+llvm-5.0.1-x86_64-apple-darwin.tar.xz...\nException thrown for tar member clang+llvm-5.0.1-final-x86_64-apple-darwin\nTraceback (most recent call last):\n  File \"./utilikit/prepare_sources.py\", line 223, in \n    exit(main(sys.argv[1:]))\n  File \"./utilikit/prepare_sources.py\", line 218, in main\n    download_extra_deps(extra_deps, root_dir, downloads_dir)\n  File \"./utilikit/prepare_sources.py\", line 120, in download_extra_deps\n    root_dir / pathlib.Path(section), downloads_dir)\n  File \"./utilikit/prepare_sources.py\", line 104, in _setup_tar_dependency\n    _extract_tar_file(tar_destination, dep_destination, list(), strip_tar_dirs)\n  File \"./utilikit/prepare_sources.py\", line 85, in _extract_tar_file\n    raise exc\n  File \"./utilikit/prepare_sources.py\", line 63, in _extract_tar_file\n    relative_path = pathlib.PurePosixPath(tarinfo.name).relative_to(relative_to) # pylint: disable=redefined-variable-type\n  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/pathlib.py\", line 870, in relative_to\n    .format(str(self), str(formatted)))\nValueError: 'clang+llvm-5.0.1-final-x86_64-apple-darwin' does not start with 'clang+llvm-5.0.1-x86_64-apple-darwin'\n``. Fixed after adding-finaltostrip_leading_dirsinextra_deps.ini`.\n\nstrip_leading_dirs = clang+llvm-{version}-final-x86_64-apple-darwin. Next:\nApplying patch ungoogled_macos/patches/ungoogled-chromium/macos/fix-gn-safe_browsing.patch\npatching file build/config/compiler/BUILD.gn\nHunk #1 FAILED at 1222.\n1 out of 1 hunk FAILED -- rejects in file build/config/compiler/BUILD.gn\npatching file chrome/browser/BUILD.gn\nHunk #1 FAILED at 1532.\n1 out of 1 hunk FAILED -- rejects in file chrome/browser/BUILD.gn\npatching file chrome/browser/extensions/BUILD.gn\nHunk #1 succeeded at 802 (offset 3 lines).\npatching file chrome/browser/ui/BUILD.gn\nHunk #1 FAILED at 488.\n1 out of 1 hunk FAILED -- rejects in file chrome/browser/ui/BUILD.gn\nPatch ungoogled_macos/patches/ungoogled-chromium/macos/fix-gn-safe_browsing.patch does not apply (enforce with -f)\nFixed those (https://github.com/tectiv3/ungoogled-chromium/commit/2a471813420dde53be883b0033e6367336f08647)\nNext, modifications to bootstrap.py:\nremove from if is_mac::\n'base/threading/worker_pool_posix.cc',\n        'base/synchronization/read_write_lock_posix.cc',\n        'base/tracking_info.cc',\n        'base/tracked_objects.cc',\nNext:\nclang (LLVM option parsing): Unknown command line argument '-instcombine-lower-dbg-declare=1'.  Try: 'clang (LLVM option parsing) -help'\nclang (LLVM option parsing): Did you mean '-instcombine-maxarray-size=1'?\nNext one is weird though (after removing -instcombine-lower-dbg-declare=1)\nclang (LLVM option parsing): Unknown command line argument '-o'\ne.g.\n[19/23838] CC obj/third_party/libpng/libpng_sources/pngrtran.o\nFAILED: obj/third_party/libpng/libpng_sources/pngrtran.o\n../../third_party/llvm-build/Release+Asserts/bin/clang -MMD -MF obj/third_party/libpng/libpng_sources/pngrtran.o.d -DPNG_INTEL_SSE_OPT=1 -DV8_DEPRECATION_WARNINGS -DNO_TCMALLOC -DCHROMIUM_BUILD -DCR_XCODE_VERSION=0821 -DCR_CLANG_REVISION=\\\"313786-1\\\" -D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORE=0 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../.. -Igen -I../../third_party/libpng -I../../third_party/zlib -fno-strict-aliasing -fstack-protector -Wno-builtin-macro-redefined -D__DATE__= -D__TIME__= -D__TIMESTAMP__= -fcolor-diagnostics -Xclang -mllvm -no-canonical-prefixes -arch x86_64 -Oz -fno-omit-frame-pointer -g0 -isysroot ../../../../../../../../Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -mmacosx-version-min=10.9.0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wall -Wno-unused-variable -Wunguarded-availability -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-unused-lambda-capture -Wno-user-defined-warnings -Wno-tautological-unsigned-zero-compare -Wno-null-pointer-arithmetic -Wno-tautological-unsigned-enum-zero-compare -Wno-tautological-constant-out-of-range-compare -std=c11 -c ../../third_party/libpng/pngrtran.c -o obj/third_party/libpng/libpng_sources/pngrtran.o\nwarning: unknown warning option '-Wno-tautological-unsigned-zero-compare' [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-null-pointer-arithmetic'; did you mean '-Wno-null-arithmetic'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-tautological-unsigned-enum-zero-compare'; did you mean '-Wno-tautological-undefined-compare'? [-Wunknown-warning-option]\nclang (LLVM option parsing): Unknown command line argument '-o'.  Try: 'clang (LLVM option parsing) -help'\nclang (LLVM option parsing): Did you mean '-mv4'?\nninja: build stopped: subcommand failed.\n. so, the same as macOS then... https://github.com/Eloston/ungoogled-chromium/issues/301. @PonyPC can you please recap what you did? So I could try to reproduce it for macOS.. @Eloston no it's exactly my style =) yeah, was going to do exactly that. yep, I was able to build successfully. Just needed to remove a couple of entries from various Build.gn files, there was no need in fixing sources.\nI will prepare a patch tomorrow.. nope, none :/. Xcode 8.2.1 and macOS 10.11. yep, I have it too. Killing it won't get it started again.. Still there.... user           77256  50.4  0.0  2437952   6168   ??  R     1:09AM   0:16.72 /Applications/Chromium.app/Contents/Versions/63.0.3239.132/Chromium Framework.framework/Helpers/crashpad_handler --no-periodic-tasks --monitor-self-annotation=ptype=crashpad-handler --database=/Users/user/Library/Application Support/Chromium/Crashpad --annotation=plat=OS X --annotation=prod=Chromium_Mac --annotation=ver=63.0.3239.132 --handshake-fd=4\nuser           77254  50.3  0.0  2457936   6308   ??  S     1:09AM   0:16.68 /Applications/Chromium.app/Contents/Versions/63.0.3239.132/Chromium Framework.framework/Helpers/crashpad_handler --monitor-self --monitor-self-annotation=ptype=crashpad-handler --database=/Users/user/Library/Application Support/Chromium/Crashpad --metrics-dir=/Users/user/Library/Application Support/Chromium --annotation=plat=OS X --annotation=prod=Chromium_Mac --annotation=ver=63.0.3239.132 --handshake-fd=9\nQuitting those two processes won't bring them back (until chromium restart)\nno run_with_crashpad spotted.. No children, parent is launchd, process group - Chromium.\nActually I was wrong, sending them SIGTERM will quit that stuck process and re-spawn a normal one:\nuser           77256   0.0  0.0  2438976   5384   ??  S     1:09AM   0:24.01 /Applications/Chromium.app/Contents/Versions/63.0.3239.132/Chromium Framework.framework/Helpers/crashpad_handler --no-periodic-tasks --monitor-self-annotation=ptype=crashpad-handler --database=/Users/user/Library/Application Support/Chromium/Crashpad --annotation=plat=OS X --annotation=prod=Chromium_Mac --annotation=ver=63.0.3239.132 --handshake-fd=4\nuser           77254   0.0  0.0  2457936   5496   ??  S     1:09AM   0:27.29 /Applications/Chromium.app/Contents/Versions/63.0.3239.132/Chromium Framework.framework/Helpers/crashpad_handler --monitor-self --monitor-self-annotation=ptype=crashpad-handler --database=/Users/user/Library/Application Support/Chromium/Crashpad --metrics-dir=/Users/user/Library/Application Support/Chromium --annotation=plat=OS X --annotation=prod=Chromium_Mac --annotation=ver=63.0.3239.132 --handshake-fd=9. Even better, sending them SIGTERM will just stop them using all CPU without restarting a process :/\nNotice the same PID.\nBTW after that quitting Chromium won't quit those two crashpad_handler processes. They have to be killed with SIGKILL.. Can we just disable it all-together?. OK, I will try it a bit later.. @stolendata nope, it refuses to build for me too.. In /build/sandbox/build/config/compiler/BUILD.gn\n# TODO(hans): Remove this once Clang generates better optimized debug info by\n  # default. https://crbug.com/765793\n  if (is_clang && !is_nacl && current_toolchain == host_toolchain &&\n      target_os != \"chromeos\") {\n    cflags += [\n      \"-Xclang\",\n      \"-mllvm\",\n      \"-Xclang\",\n      \"-instcombine-lower-dbg-declare=1\",\n    ]\n  }\nI removed \n\"-Xclang\",\n      \"-instcombine-lower-dbg-declare=1\",\n. I removed the whole block. It is building now.. Yep, built successfully.. got it, don't understand why it happened. But will fix it.\nFixed in https://github.com/Eloston/ungoogled-chromium/pull/323. Building now with ver.132 . Built successfully. Crashpad bug still here.. With a few patches I was able to build this version. Sadly bug with crashpad is still there.\nCreated PR: https://github.com/Eloston/ungoogled-chromium/pull/334. I'll open a PR with build for macos then. Don't merge it yet please. I think my mapped_file fix isn't really a fix.\nChromium started to hang indefinitely (in uninterruptible state) so only system restart is able to kill it.. or may be it is a different problem, because according to:\nhttps://chromium.googlesource.com/chromium/src/+/0413fd9f7c660ba7504dade7bb838862f138348e/base/files/memory_mapped_file_posix.cc#104\nit is supposed to fallback to manual mode on everything that is not APFS.\nSo, this version is unstable for some other reason.. nope. Still crashing. So it's definitely something else.. It is ready.\nThe problem is not with my patches. But I need someone else to confirm it.. @Artur96 it doesn't crash for me immediately. First time it did after a couple of hours of actively using it.. @Artur96 it's been two days, how does it work for you so far?. @Artur96 does it actually crash? Because for me it's just freezing and ps reporting main chromium process is in uninterruptible wait (UE status).. for me it also freezing on search. I am not sure, cause first time I built and run it - it was couple of hours before it froze, but now I do remember it was on search.\nI'll try it now.. Disabled ungoogled-chromium/add-flag-for-search-engine-collection.patch.\nSo far so good.... Still good on my side, doesn't crash on any DuckDuckGo query.\n@Artur96 can you please upload your crashpad patch? I'm very eager to try it.. @Artur96 running it now, all good!. I've uploaded my build here: https://github.com/tectiv3/ungoogled-chromium-binaries/releases/tag/64.0.3282.186-1. okay, building it now. So far so good.. There is no such patch anymore, try to build from develop.. macOS build built successfully. Going to test it for a few days. Binary uploaded here. \nSo far so good, the only thing I've noticed is a high CPU usage in developer tools Inspect element and a few artefacts:\n\n\n. @Artur96 just open up developer tools, it's right there. \nDoesn't bother me much, just thought I should mention it.. @Artur96 10.11. @Artur96 can you please try to run my build? (https://github.com/tectiv3/ungoogled-chromium-binaries/releases/tag/65.0.3325.162-1). @Artur96 thank you. Then it's the OS.. Built macOS using #401, so far so good.. #401 has it and was already merged into develop.. Weird, I've built 65 with this patch present.\nokay. nice catch!. hey, I am building for macOS atm and this line https://chromium.googlesource.com/chromium/src/base/+/master/mac/sdk_forward_declarations.h#288\ndoes not work on 10.11 \nerror: expected ';' after top level declarator\ntypedef NSString* VNImageOption NS_STRING_ENUM;\nGot to replace it with typedef NSString* VNImageOption;\nShould be fine on newer systems though.\nI am hesitant to creating a patch for this since it looks like an upstream problem and it affects only people on older systems.. Also found out that this commit:\nhttps://chromium.googlesource.com/chromium/src/+/4d7c604370eee1648617069beef729cd97871f7f\nspecifically changes to https://chromium.googlesource.com/chromium/src/+blame/master/chrome/browser/ui/views/safe_browsing/password_reuse_modal_warning_dialog.cc#61\nis breaking build on the linking stage for me, safe browsing as usual :)\nDoesn't look like macOS specific though so it's weird that it built fine on linux.\n. @Eloston please merge it only after someone on 10.13 tries it first.. yeah, I just noticed this. Sometimes one of the tabs starts hogging CPU.. @nixballs no random high CPU usage? It happens once or twice a day for me on my build.. It wasn't about tabs count, some random tab was consuming 100% CPU. Happened to me only couple of times in those two weeks. Good to know .79 address that!. Latest macOS build (.87) - no issues in four days.. thing is it's already inside such macro. ok. ",
    "sakaru": "Seems this is a python3/python2 thing, see http://stackoverflow.com/questions/6357361/alternative-to-execfile-in-python-3\n. ",
    "sjug": "@Eloston how do I pass the python2_command?\n. Yeah I had done that in order to get past the error early on Checking Python 2 command...\nI was just wondering if there was another way to do it.\nI'm seeing that error with it set to python2 which is correct.\n. Just building straight off master, I'll try a tag.\n. I was just about to say it's failing with DebianBuilder errors.\n. It's unmodified just the buildlib/common.py has the python2_command set.\n. Did a fresh build and it dies on: \nNow at patch ../patches/ungoogled-chromium/remove-get-help-button.patch\n2016-09-29 18:58:54,281 - INFO: Running gyp command...\n2016-09-29 18:58:54,281 - DEBUG: Appending resources/common/gyp_flags\n2016-09-29 18:58:54,282 - DEBUG: Appending resources/linux_static/gyp_flags\n2016-09-29 18:58:54,282 - DEBUG: GYP command: python2 build/gyp_chromium --depth=. --check -Dtracing_like_official_build=1 -Ddefault_apps_list=[] -Denable_hotwording=0 -Dremoting=0 -Dsafe_browsing=0 -Ddefault_apps_list_linux_dest=[] -Denable_wifi_bootstrapping=0 -Denable_pre_sync_backup=0 -Dfieldtrial_testing_like_official_build=1 -Dwerror= -Ddisable_nacl=1 -Ddisable_fatal_linker_warnings=1 -Denable_hangout_services_extension=0 -Dfastbuild=2 -Denable_hidpi=1 -Denable_google_now=0 -Dproprietary_codecs=1 -Ddisable_newlib=1 -Denable_rlz=0 -Denable_automation=0 -Dbuildtype=Official -Dffmpeg_branding=Chrome -Ddisable_pnacl=1 -Dlinux_strip_binary=1 -Denable_remoting_host=0 -Denable_one_click_signin=0 -Dremove_webcore_debug_symbols=1 -Denable_webrtc=0 -Duse_official_google_api_keys=0 -Denable_prod_wallet_service=0\nUpdating projects from gyp files...\n  File \"../tools/clang/scripts/update.py\", line 121\n    print ' Done.'\n                 ^\nSyntaxError: Missing parentheses in call to 'print'\ngyp: Call to 'python ../tools/clang/scripts/update.py --print-revision' returned exit status 1 while in /home/user/ungoogled-chromium/build/sandbox/build/all.gyp.\n2016-09-29 18:58:57,337 - ERROR: GYP command returned non-zero exit code: 1\nThe python version mixing is angry.\n. I see the same error as @pickfire.\nEven after setting python2_command to python I get the same error:\nNow at patch ../patches/ungoogled-chromium/fix-building-with-iridium-trknotify.patch\n2016-10-20 06:07:03,608 - INFO: Running gyp command...\n2016-10-20 06:07:03,608 - DEBUG: Appending resources/common/gyp_flags\n2016-10-20 06:07:03,608 - DEBUG: GYP command: python build/gyp_chromium --depth=. --check -Dfastbuild=2 -Ddisable_pnacl=1 -Dremove_webcore_debug_symbols=1 -Dproprietary_codecs=1 -Dremoting=0 -Denable_one_click_signin=0 -Denable_remoting_host=0 -Denable_google_now=0 -Denable_rlz=0 -Dffmpeg_branding=Chrome -Ddisable_nacl=1 -Denable_automation=0 -Denable_hotwording=0 -Ddisable_fatal_linker_warnings=1 -Ddefault_apps_list_linux_dest=[] -Denable_webrtc=0 -Duse_official_google_api_keys=0 -Denable_hangout_services_extension=0 -Denable_prod_wallet_service=0 -Dtracing_like_official_build=1 -Dsafe_browsing=0 -Dfieldtrial_testing_like_official_build=1 -Denable_pre_sync_backup=0 -Denable_wifi_bootstrapping=0 -Dlinux_strip_binary=1 -Denable_hidpi=1 -Ddefault_apps_list=[] -Ddisable_newlib=1 -Dwerror=\nTraceback (most recent call last):\n  File \"build/gyp_chromium\", line 12, in <module>\n    execfile(__file__ + '.py')\nNameError: name 'execfile' is not defined\n2016-10-20 06:07:03,629 - ERROR: GYP command returned non-zero exit code: 1\n. ",
    "hellodstyle": "https://github.com/notifications/unsubscribe-auth/AVdADMd7KfteTAwpqyPI8tjc-kRO7zOsks5qvBZFgaJpZM4KKZuZ\n2016\u5e749\u670829\u65e5\u661f\u671f\u56db\uff0cEloston notifications@github.com \u5199\u9053\uff1a\n\nCreate a directory build/path_overrides that contains files to override\nPATH commands. This path_overrides directory will be prepended to the\nPATH variable of the meta-build configuration command and build command.\nFor Python, /usr/bin/python will have to be changed to point to the\nPython command in path_overrides.\nOn Linux, path_overrides will contain shell scripts with absolute paths\nto the user-provided commands. On Windows, they will be batch scripts. This\nis basically how depot_tools does it.\nPATH overrides will be generated in the setup_build_utilities step. That\nmeans there will not be any overrides for patching commands (i.e. patch\nor quilt). This should be fine since patch and quilt usually do not use\ncommands that need overrides.\nImplementation details: Implement _generate_path_override() that will\ntake the command as a string and write out the PATH override file.\n_generate_path_override() will invoke _write_path_override_file(), which\nimplements the file writing for the current platform.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/69, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AVdADMd7KfteTAwpqyPI8tjc-kRO7zOsks5qvBZFgaJpZM4KKZuZ\n.\n. mute the thread\n\n2016\u5e749\u670830\u65e5\u661f\u671f\u4e94\uff0cstormxeron notifications@github.com \u5199\u9053\uff1a\n\nOh!\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/71#issuecomment-250671200,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AVdADK_uyb-Q0yY1Iqxj2zvuUX_ksZTZks5qvK8KgaJpZM4KKrsL\n.\n. \n",
    "stormxeron": "Ok edited buildlib/macos.py and ungoogled-macos/fix-libcxx-archive-build-script.patch, working for now, see if any error comes! \n. Now I am having this problem:\n\nI think it is searching for PRESUBMIT.py for Archive do not have matching md5. How do I fix this?\nThanks\n. Actually I edited the files macos.py and fix-libcxx-archive-build-script.patch. Changed the line (x86_64-apple-darwin15.4.0-c++-4.9 -> x86_64-apple-darwin16.0.0-c++-4.9)\n. Ok, Thanks \ud83d\udc4d \n. Oh! Its going to take forever then! HaHa, building isn't a simple task\n. ",
    "stfnhh": "The above instructions work perfectly, can I suggest marking this as closed?  I'll make a pull request and add this answer to the FAQ I assume a lot of people are going to want flash.\n. No, I'm not seeing it in chrome://components/ or chrome://plugins/ I'm running MacOS Sierra. I've also tried installing the standalone Widevine plugin but don't see any change, please see attached screenshots.\n\n\n\n. It works in regular chrome.\n. @Eloston Amazon Video still doesn't seem to work, please let me know if you'd like further help debugging this.\n\n. @Eloston I did follow the instructions, I'm using version 55.0.2883.95 of Google Chrome.. @Eloston yes MacOS 10.12.3 (16D32). @9Morello \n\n. You could install this extension https://chrome.google.com/webstore/detail/empty-new-tab-page/dpjamkmjmigaoobjbekmfgabipmfilij follow these instructions to install it.  I can confirm this extension is working on OS X.\n. @Eloston will version 63 include the fixes for building on Mac OS (issue #301 )?. @Eloston any progress on this bug?. If there's support for this, I'd love to help.. No, qjz9zk is not a valid TLD (https://en.wikipedia.org/wiki/List_of_Internet_top-level_domains) so it couldn't be purchased.  If you use 8.8.8.8/8.8.4.4 as your DNS Google could direct that request wherever they'd like.  Using Googles DNS service and UnGoogled Chromium seem contradictory if you're worried about privacy.. Any way to hide the profile icon?. ",
    "GabrielCARangel": "Hello, I have the same issue on the lastest Windows build. Netflix doesn't work.\nRunning Windows 7.\n\n. ",
    "lewdnasty": "\nWindows 7 user, latest release. Same error as OP.\n. ",
    "gcarq": "@9Morello, @Eloston: enable_widevine=1 just enables the support for widevine. You need libwidevinecdm.so is in the browsers working directory (at least for linux). If you have a local chromium installation where widevine works you can symlink it. I created a section in the README for this: https://github.com/gcarq/inox-patchset#use-widevine. Tested with ArchLinux and Netflix.. @Eloston I'm upgrading the inox-patchset to version 54 right now, a release can be expected tonight or tomorrow. @Eloston I'm glad you like it. Thanks for your patch to fix builds with safe_browsing_mode=0.. It is also possible that some fieldtrial testing code is active in one built but not in the other, which would explain the performance differences.\nYou can see the active fieldtrial modifications in chrome://version as Variations.\nMore info on this: http://superuser.com/questions/541466/what-is-the-variations-section-in-the-output-of-aboutversion-or-chrome-v. I'm currently compiling inox-56.0.2924.76, some patches needed an update. The progress is being tracked here: https://github.com/gcarq/inox-patchset/issues/54. Hi, I've got your attention from https://github.com/gcarq/inox-patchset/issues/77. I'm answering here instead, to keep the conversation up. I honestly don't mind under which license the inox-patches are, I would be happy with either GPLv3, BSD or public domain.. @a-teammate, @Eloston I will also change the license to BSD soon.. Switched to BSD \"Simplified\", see https://github.com/gcarq/inox-patchset/commit/5a5543657e90df2af0f472643f8ef5f6feb4f229. ",
    "pjv": "@9Morello If those OS X binaries that are widevine compatible are available somewhere, I can't find them. Only thing I see on the uploads page is version 55.0.2883.75-1, no 87-1.. @9Morello  Thanks!. > Looks like I need to make the link bigger.\nActually, i think you are linking to the wrong 3rd party releases page from the main releases page. Or that 3rd party page needs to be updated to include @9Morello's newer builds here: https://github.com/ungoogled-software/ungoogled-chromium-binaries/releases/tag/55.0.2883.95. @Eloston @9Morello Instructions for widevine for macos would be appreciated. I think I have actually done what's needed -- copied the WidevineCDM directory from ~/Library/Application Support/Google/Chrome/WidevineCDM to ~/Library/Application Support/Chromium/WidevineCDM -- but it is not working for me, even though chromium is registering that it is there in chrome://components/. \nI tried clicking the \"Check for update\" button, and I get \"Component not updated\"\n\n. @9Morello Finally. - Thanks!. @luckydonald It looks to me like devs here are working on a new build but it's not ready yet. In the mean time, you can get around the problem you are having by launching the current version from the terminal with a command like this (all one line):\n/Applications/Chromium.app/Contents/MacOS/Chromium --force-fieldtrials=*EnforceCTForProblematicRoots/Disabled/ >/dev/null 2>&1 &. is there a viable, manual workaround for getting this to work with the current v55 9morello.dmg?. nice. @9Morello will you be updating your binary that is linked from the releases page here?\nalso, can you say exactly which files need to be copied over from chrome?\nthanks!. i wrote a super-kludgy shell script with a node package dependency, a dependency on jq, and a dependency on curl that looks at the extensions you have installed and then downloads the latest version from the play store into a directory of your choosing. You then have to drag them into the extensions page to install the updates.\nIt only works with play store extensions and it's a long way from a proper updater, but it beats doing it all manually, and I think if anyone wanted to it could be improved/extended.\nHere's a gist.\nEDIT: this is only tested on OS X.. Unfortunately, I have been unable to use versions past 55 on macOS due to \"aw snap\" page crashes on a lot of different sites. I have tried deleting my profile and even deleting the whole chromium config folder from ~Library/Application Support and still get crashes.\nI downloaded a vanilla chromium snapshot of version 58.0.3029.110 (same as latest mac ungoogled chromium build) and it does not crash on those pages.\nMy mac is a 2015 retina 5K iMac with 32 GB, running macOS 10.12.5.\nThree random example pages that crash for me on v 58, but not on v 55: \nhttp://sass2stylus.com/\nhttps://themeforest.net/item/savoy-minimalist-ajax-woocommerce-theme/12537825/comments\nhttp://blog.janjonas.net/2011-04-22/configure-nullmailer-smtp-authentication\nAnyone else on macOS have problems with those URLs?\n@nixballs ?\nEDIT: addendum: I also tried launching with --enable-logging --v=1 but the stack trace was not useful.\nReceived signal 11 SEGV_MAPERR 000000000020 \n[0x00010e210d7c] \n[0x00010e210c31] \n[0x7fffc1e55b3a] \n[0x7ff4efae0e50] \n[0x00010e2116f0] \n[0x000111058cdc] \n[0x000111056e42] \n[0x00010e2116f0] \n[0x00010e23e87b] \n[0x00010e23ebcc] \n[0x00010e23f003] \n[0x00010e2428ca] \n[0x00010e230b2a] \n[0x00010e2422a4] \n[0x7fffac4ec321] \n[0x7fffac4cd21d] \n[0x7fffac4cc716] \n[0x7fffac4cc114] \n[0x7fffadedf4e2] \n[0x00010e24317e] \n[0x00010e2426ec] \n[0x00010e23e54e] \n[0x00010e269bf3] \n[0x00011241ccc7] \n[0x00010de97c60] \n[0x00010de96ea6] \n[0x00010c563a5f] \n[0x00010c52adba] \n[0x7fffc1c46235] \n[0x000000000012] \n[end of stack trace]. Hey @nixballs, thanks for the suggestion and the confirmation that it must be something in my setup. Unfortunately, i can't nuke everything that has 'chromium' on my disk, as there are a lot of things with that string in it that are not relevant (e.g. something in my dev projects folder has a node module called chromium-pickle.js and other things like that). \nBut i'll go through the list of stuff and get rid of whatever seems like it might potentially be contributing and then try again with a clean install and an empty config file and see what happens.. Alas - after cleaning everything possible. Fresh install of v. 58. Blank config.\n\nI tried upgrading my MBPr to v. 58 and it also crashes on the same URL as in the gif above. On a hunch I thought it might have to do with the resolution setting for the retina display, but I tried various resolutions on the MBP and it had no effect. Tried turning off hardware acceleration in chromium advanced settings. Also tried logging in as a different user on the MBP with the same result as well.\nDowngrading to v. 55 on each machine \"cures\" the crashes.\nI wish there was some way to debug this. It doesn't spit anything to the system log when it crashes and the stack trace is useless.. I built ungoogled chromium from source hoping that maybe it would just magically fix itself if compiled in my env, but that didn't work either.\nThen I stumbled onto #233, uninstalled PPAPI and viola! No more aw snap. Feel kind of dumb for not thinking of flash as a potential culprit.. I also successfully built v. 60 on MacOS 10.12.6 with Xcode 8.3.3 using the instructions on the build page.. @Eloston @chew-z I have a v. 60 MacOS DMG binary that I'd be happy to put up on the contributor downloads page. How would I do that?. @Eloston got it - thanks.\n@chew-z here you go.. Pretty sure you can do the same mkdir on linux.. from the error messages, I'm pretty sure it was the last command in build.sh that failed.\n\n\nI had to get rid of the tree and do the whole build again.\n\nGenerally this shouldn't be necessary as packaging commands don't touch any files in the build output. In the event that they are missing or modified, you can rerun ninja to regenerate those missing files without rebuilding the entire browser.\n\ni thought that should be right, so after clearing out the /var/empty directory, i went into build.sh and commented out most of the stuff above that last command, but i think i botched what i did and didn't comment so that failed for me. I should have read through the script more carefully but i was doing too many things at the same time.\nthe second build went fine, so it was definitely having that errant root-owned directory in /var/empty that caused the problem. If i had sudo'd the build i think it would have worked, but then i also think that pkg-dmg would have potentially copied some random stuff that just happened to be in that directory into the package (though it says it is copying *.so so likely nothing would have gone anyway).\n. >During that change, I noticed that pkg-dmg is given /var/empty via the --source flag. If this directory is used only during the generation of the dmg and not in the dmg, then it may be better to just create and use a temporary directory instead.\nyeah, i think it would be better to make and use a temporary directory under buildspace. On a quick glance through chrome/install/mac/pkg-dmg and then again at build.sh it looks like passing --source /var/empty implies that nothing is actually going in there in the build and that using it as --source is really an attempt at a way to start with an empty directory to then copy stuff into in the .dmg. My guess is that creating and using an emtpy temp dir under buildspace would work fine.\ni'll test that out when i have a chance and report back.\n(i'll also suggest to the anydesk guys to stop using /var/empty as a /tmp). See also: https://github.com/brave/brave-browser/issues/1431. from an AMA with Brave's CISO\n\n. ",
    "Zegnat": "\n\nOnly thing I see on the uploads page is version 55.0.2883.75-1, no 87-1.\n\nLooks like I need to make the link bigger.\n\n@Eloston will you no longer be including any macOS builds from now on? Because then the eloston-chromium formula for Homebrew Cask should be updated to point at @9Morello\u2019s builds. I don\u2019t mind doing that, but if the next version will be on this repo again, I don\u2019t really see the point.. ",
    "DeadSix27": "@Eloston I saw he does. I like his idea. But if we offer that, we should also offer LKGR, if nojmp helps to keep the patches up to date.. I worked on that.\nCreated a simple installer building script. For authors mainly (probably will go into bin tools).\nBut what about signing them?\nCode Signing Certificates are very expensive more than 150$ /year \nI could easily self-sign them but that would still popup a warning that might scare users off.\nHowever I still think self signed is better than not signed at all.\n\n. Well there are a lot of 64bit changes in the latest commits (at the google git)\n\"Add the 64-bit Asan redirectors.\"\n\"Enable the IAT patcher unittests in x64.\"\n\"Add probes for x64. \" \netc.\nCould possibly be a fix for this.\n. Good point, wrote that after I woke up, usually I'm the one complaining when people write exactly what I already wrote in a previous post. Was about time someone does the same to me ;)\n. Probably should close this now.. I installed all the requirements correctly.\nVisual studio has all the required things selected and I added all the needed binaries to the Path.\nI now set builder.target_cpu = CPUArch.x64 and imported CPUarch in build.py\nAnd I ran:\nG:\\chromium>git clone https://github.com/Eloston/ungoogled-chromium.git\nG:\\chromium>cd ungoogled-chromium\n- (Added x64 to build.py)\nG:\\chromium\\ungoogled-chromium>C:\\Python35\\python.exe build.py\nAnd now I get this error:\n```\nDEBUG:root:Running: mc.exe -r c:\\users*\\appdata\\local\\temp\\tmp0abet4\\gen\\base/trace_event/etw_manifest -h c:\\users*\\appdata\\local\\temp\\tmp0abet4\\gen\\base/trace_event/etw_manifest -u -um G:\\chromium\\ungoogled-chromium\\build\\sandbox\\base/trace_event/etw_manifest/chrome_events_win.man\nTraceback (most recent call last):\n  File \"tools\\gn\\bootstrap\\bootstrap.py\", line 754, in \n    sys.exit(main(sys.argv[1:]))\n  File \"tools\\gn\\bootstrap\\bootstrap.py\", line 121, in main\n    return run_build(tempdir, options)\n  File \"tools\\gn\\bootstrap\\bootstrap.py\", line 71, in run_build\n    build_gn_with_ninja_manually(tempdir, options)\n  File \"tools\\gn\\bootstrap\\bootstrap.py\", line 183, in build_gn_with_ninja_manually\n    'base/trace_event/etw_manifest/chrome_events_win.man')\n  File \"tools\\gn\\bootstrap\\bootstrap.py\", line 134, in write_compiled_message\n    os.path.join(SRC_ROOT, source),\n  File \"tools\\gn\\bootstrap\\bootstrap.py\", line 44, in check_call\n    subprocess.check_call(cmd, cwd=GN_ROOT, kwargs)\n  File \"C:\\Python27\\lib\\subprocess.py\", line 181, in check_call\n    retcode = call(*popenargs, kwargs)\n  File \"C:\\Python27\\lib\\subprocess.py\", line 168, in call\n    return Popen(popenargs, *kwargs).wait()\n  File \"C:\\Python27\\lib\\subprocess.py\", line 390, in init\n    errread, errwrite)\n  File \"C:\\Python27\\lib\\subprocess.py\", line 640, in _execute_child\n    startupinfo)\nWindowsError: [Error 2] The system cannot find the file specified\n2016-12-21 11:24:54,721 - ERROR: GN bootstrap command returned non-zero exit code: 1\nG:\\chromium\\ungoogled-chromium>\n```\nEDIT: I figured, you only had to run \"vcvarsall\" in the \"VS2015 x64 Native Tools Command Prompt\"\nSo I did not run the build.py in it now, but I will try that now and see if that fixes the above error and if the actual error I was reporting is still appearing (I did actually run it in the native tools cmd before and got that include error, so it wasnt about that)\nI will come back to this and EDIT it after it finished. (Or reply if  you replied in the meantime)\nEDIT2:\nYep I re-ran everything from scratch, double checked I have all the requirements and it still gives me the same error:\n[17085/24289] CXX obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj\nFAILED: obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj\nninja -t msvc -e environment.x64 -- \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64/cl.exe\" /nologo /showIncludes /FC @obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj.rsp /c ../../third_party/WebKit/Source/core/xml/XPathParser.cpp /Foobj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj /Fd\"obj/third_party/WebKit/Source/core/xml/xml_cc.pdb\"\ng:\\chromium\\ungoogled-chromium\\build\\sandbox\\third_party\\webkit\\source\\core\\xml\\xpathparser.cpp(31): fatal error C1083: Cannot open include file: 'core/XPathGrammar.h': No such file or directory\nEDIT3: Now switched to tag 55.0.2883.87-1 to see if it runs into the same issue as master.\nWill edit after its finished.\nEDIT4:\nNow with the tag mentioned above^\nSame error:\n[17143/24289] CXX obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj\nFAILED: obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj\nninja -t msvc -e environment.x64 -- \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64/cl.exe\" /nologo /showIncludes /FC @obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj.rsp /c ../../third_party/WebKit/Source/core/xml/XPathParser.cpp /Foobj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj /Fd\"obj/third_party/WebKit/Source/core/xml/xml_cc.pdb\"\ng:\\chromium\\ungoogled-chromium\\build\\sandbox\\third_party\\webkit\\source\\core\\xml\\xpathparser.cpp(31): fatal error C1083: Cannot open include file: 'core/XPathGrammar.h': No such file or directory\nEDIT5:\nTried tag 55.0.2883.75-1\nDoesn't even begin to compile.. errors out.. Let's sum up: I can not start the build without using the Native Tools CMD Prompt, otherwise it errors\nas seen in post3: https://github.com/Eloston/ungoogled-chromium/issues/156#issuecomment-268489583\nAnd \"vcvarsall\" is not existing outside that cmd promt. \nI figure you could prob just run it directly by specifying the full path in any cmd.exe process, but .. if you can just open the native tools cmd.. it doesnt matter.\nAs to your EDIT, I use \"Default\" and I checked out/Default/gen/ there is no gen/blink at all (CORRECTION, there is, but there is no XPathGrammar)\nnor is there a build.gn in third_party/WebKit/Source/core/ only has core_event_interfaces_file_list.tmp\nJust in case, this time, here is the full output log:\nhttps://paste.ubuntu.com/23667883/\n\n\n. > Sees image...\n\nCorrects ambiguity\n\nheh, ye I pre-written the entire text expecting that folder to not be there, yet it eventually got created, but without the file out/Default/gen/blink/core/XPathGrammar.h which the image shows you as well.\nEither way, now I'm lost, am I supposed to look for BUILD.gn in build/sandbox/third_party/WebKit/Source/core/\nnow? In which case, that file does not exist.\n. Which is odd because I seriously just followed the guide.. I mean I can't do much wrong beside that..\nConsidering official chromium compiles just fine without any issues.\nAnd they use almost the same setup. Meaning, my compiler works fine. My python works fine.\nDo you think it could be an issue with one of the binaries you have to install? (patch,bison,etc. see below)\nOtherwise I really can't think of what I could have done wrong...\n2016-12-22 10:14:27,869 - INFO: Checking Python 2 command...\n2016-12-22 10:14:27,895 - DEBUG: Using Python version '2.7.6'\n2016-12-22 10:14:27,895 - INFO: Checking ninja command...\n2016-12-22 10:14:27,903 - DEBUG: Using ninja version '1.7.2'\n2016-12-22 10:14:27,903 - INFO: Checking patch command...\n2016-12-22 10:14:27,917 - DEBUG: Using patch command 'GNU patch 2.7.5'\n2016-12-22 10:14:27,917 - INFO: Checking bison command...\n2016-12-22 10:14:27,929 - DEBUG: Using bison command 'bison (GNU Bison) 2.4.1'\n2016-12-22 10:14:27,929 - INFO: Checking gperf command...\n2016-12-22 10:14:27,938 - DEBUG: Using gperf command 'GNU gperf 3.0.1'\nI will run the entire process again from start, with nothing (as in, delete everything I've done (binaries etc), if it still fails with this issue.\nThen ye.. I don't know.. Think you can see that on the images.\nI unfortunately do not have the full output anymore as I tested the official chromium build to see if that fails too. (Which takes a big chunk of my SSD, leaving no space for ungoogled) \nBut as I previously mentioned, I will re-run everything from scratch and report back again, only this way I can re-assure I did everything according to the guide (which I'm very very sure I did.)\nMaybe you can read over the guide once too, see if really everything is correct, but then again no one else reported this issue, or barely anyone compiles this on/for Windows 64... Sorry about the closing, ignore that, I misclicked.. as I was writing a text and thought it said Update Comment and not Close issue (which for some reason github thought would be a good idea to make green and or gray and not red) :)\nBut ye Defender is not installed/disabled, I have nothing running that could interfere, I run Windows 10 Pro too, actually a fresh install as well.\nBut its compiling right now, so we will see in a bit whether it works now.\nEDIT: I did tweak most of the stuff out of windows 10 as well. 'least I hope so. \nEDIT: Do you sit in a IRC channel or so? Could make this easier and less github-issue-tracker-spammy. Alright, ran through, it has the above file, and the file also contains:\n```\naction_foreach(\"make_core_generated_bison\") {\n  script = \"../build/scripts/rule_bison.py\"\n  sources = [\n    \"xml/XPathGrammar.y\",\n  ]\n  outputs = [\n    \"$blink_core_output_dir/{{source_name_part}}.cpp\",\n    \"$blink_core_output_dir/{{source_name_part}}.h\",\n  ]\n  args = [\n    \"{{source}}\",\n    rel_blink_core_gen_dir,\n    bison_exe,\n  ]\n  if (!use_system_xcode) {\n    args += [ hermetic_xcode_path ]\n  }\ndeps = make_core_generated_deps\n}\n```\nEDIT: It does not contain the header. (XpathGrammar.h)\nEDIT2: Late-night me probably didn't write that properly, what I meant by that is, it does not include the text \"XpathGrammar.h\" but thats probably what $blink_core_output_dir/{{source_name_part}}.h will be translated to.\nShould I try the rest now?:\n```\nbuilder.setup_build_utilities()\nbuilder.generate_build_configuration()\nbuilder.build()\nbuilder.generate_package()\n. Alright, finished, was kinda hoping to see it work now\nSteps I took:\nG:\\chromium>git clone https://github.com/Eloston/ungoogled-chromium.git\nCloning into 'ungoogled-chromium'...\nremote: Counting objects: 2517, done.\nremote: Compressing objects: 100% (40/40), done.\nremote: Total 2517 (delta 6), reused 0 (delta 0), pack-reused 2476\nReceiving objects: 100% (2517/2517), 1.28 MiB | 326.00 KiB/s, done.\nResolving deltas: 100% (1446/1446), done.\nG:\\chromium>\"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat\" amd64\nG:\\chromium>cd ungoogled-chromium\nG:\\chromium\\ungoogled-chromium>C:\\Python35\\python.exe build.py\n```\nError:\n[16906/24289] CXX obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj\nFAILED: obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj\nninja -t msvc -e environment.x64 -- \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64/cl.exe\" /nologo /showIncludes /FC @obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj.rsp /c ../../third_party/WebKit/Source/core/xml/XPathParser.cpp /Foobj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj /Fd\"obj/third_party/WebKit/Source/core/xml/xml_cc.pdb\"\ng:\\chromium\\ungoogled-chromium\\build\\sandbox\\third_party\\webkit\\source\\core\\xml\\xpathparser.cpp(31): fatal error C1083: Cannot open include file: 'core/XPathGrammar.h': No such file or directory\n[16914/24289] CXX obj/third_party/WebKit/Source/core/xml/xml/DocumentXSLT.obj\nEDIT: btw, is there an easy way to re-run this without having to do all the patches again and getting errors about \"already patched\" etc? So that I can test theories ?\nMaybe running just?:\ntry:\n        builder = buildlib.get_builder()\n        builder.target_cpu = CPUArch.x64\n        builder.setup_environment_overrides()\n        builder.build()\nEDIT2: ^above indeed re-runs it just fine, tested whether something in the back interferes, and nope, nothing is now running, and it still produces the same error\nEDIT3: btw there is this file, not sure if that helps in any way, it just stood out between all the headers and source files:\n\nEDIT4: is there any way we can make the build more verbose?. > The fact that the file is there is good, but Bison doesn't seem to be running for some reason.\nIs there a way to debug bison / the bison command lines?\nalso, with -v:\nNothing new that could help me, but maybe it helps you.\n[16954/24289] ninja -t msvc -e environment.x64 -- \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64/cl.exe\" /nologo /showIncludes /FC @obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj.rsp /c ../../third_party/WebKit/Source/core/xml/XPathParser.cpp /Foobj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj /Fd\"obj/third_party/WebKit/Source/core/xml/xml_cc.pdb\"\nFAILED: obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj\nninja -t msvc -e environment.x64 -- \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64/cl.exe\" /nologo /showIncludes /FC @obj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj.rsp /c ../../third_party/WebKit/Source/core/xml/XPathParser.cpp /Foobj/third_party/WebKit/Source/core/xml/xml/XPathParser.obj /Fd\"obj/third_party/WebKit/Source/core/xml/xml_cc.pdb\"\ng:\\chromium\\ungoogled-chromium\\build\\sandbox\\third_party\\webkit\\source\\core\\xml\\xpathparser.cpp(31): fatal error C1083: Cannot open include file: 'core/XPathGrammar.h': No such file or directory\n. Interesting stuff:\nBUILD.gn calls rule_bison.py here using bison_exe :\n```\naction_foreach(\"make_core_generated_bison\") {\n  script = \"../build/scripts/rule_bison.py\"\n  sources = [\n    \"xml/XPathGrammar.y\",\n  ]\n  outputs = [\n    \"$blink_core_output_dir/{{source_name_part}}.cpp\",\n    \"$blink_core_output_dir/{{source_name_part}}.h\",\n  ]\n  args = [\n    \"{{source}}\",\n    rel_blink_core_gen_dir,\n    bison_exe,\n  ]\n  if (!use_system_xcode) {\n    args += [ hermetic_xcode_path ]\n  }\ndeps = make_core_generated_deps\n}\n```\nin here we see that it just runs bison\nthird_party/WebKit/Source/build/script/rule_bison.py\nEDIT: I will additionally print out that subprocess call and see what it tries to run and add some other debug prints.. to see whether the code even ever gets there..\n```\n...\nreturnCode = subprocess.call([bisonExe, '-d', '-p', prefix, inputFile, '-o', outputCpp])\n...\nprefix = {'XPathGrammar.y': 'xpathyy'}[inputName]\n(inputRoot, inputExt) = os.path.splitext(inputName)\nThe generated .h will be in a different location depending on the bison \"bisonExe = sys.argv[3]\"\nversion.\noutputHTries = [\n    os.path.join(outputDir, inputRoot + '.cpp.h'),\n    os.path.join(outputDir, inputRoot + '.hpp'),\n]\n```\nNow the problem here is, where is bisonExe defined... as in the root of it, I can't see any other usage of bisonExe in the GN file. EDIT: Is there a way to echo out things in gn files?\nEDIT2: I also just compared both BUILD.gn (official LKGR and ungoogled)\nSome interesting differences are:\nlkgr:\nvisibility = [\n  \"//third_party/WebKit/Source/*\",\n  \"//third_party/WebKit/public/*\",\n]\nungoogled:\nvisibility = [ \"//third_party/WebKit/Source/*\" ]\nand\nthe lkgr having:\ngroup(\"all_generators\") {\n  public_deps = targets_generating_sources\nwhich leads to:\n```\nTargets from above that generate outputs that need to be compiled.\nAll sources declared as outputs from these targets will be compiled into one\ntarget.\ntargets_generating_sources = [\n  \":make_core_generated_bison\",\n```\nand ungoogled does not have that.\nBefore EDIT2:\ne.g print \"got here\" (my usual debug steps include that, to see whether the code actually ever reaches a certain point)\nI just checked the folders, rule_bison.py is never called (hence the lack of a pyc file and others having a pyc file, for example \"make_style_builder.py\" is being called by:\ncss_properties(\"make_core_generated_style_builder\") {\n  script = \"../build/scripts/make_style_builder.py\"\nin the very same BUILD.gn file\nDo you have any clue what makes it call that but not\naction_foreach(\"make_core_generated_bison\") {\n  script = \"../build/scripts/rule_bison.py\"\n  sources = [\n    \"xml/XPathGrammar.y\",\nalso.. make_core_generated_bison\nappears in:\n```\ntarget(core_link_small_target_type, \"core_generated\") {\n  sources = bindings_core_v8_files\n# Targets from above that generate outputs that need to be compiled.\n  # All sources declared as outputs from these targets will be compiled into this\n  # target.\n  targets_generating_sources = [\n    \":make_core_generated_bison\",\nand core_generated\nappears in:\nsource_set(\"generated\") {\n  deps = [\n    \":core_generated\",\n```\nAnd thats as far as my guessing goes any other ideas?\n. # EDIT (be sure to read this first):\nTime for some laughing, then some crying, then some face palming and then some.. I don't even know anymore, add this(see below) and the import of CPUArch to the building.md guide\nSo after finally finding out how bison/rule_bison is actually being called, I attempted to run it manually and see what happens.. well... prepare for some face palming:\nG:\\chromium\\ungoogled-chromium\\build\\sandbox>C:\\Python27\\python.exe third_party/WebKit/Source/build/scripts/rule_bison.py third_party/WebKit/Source/core/xml/XPathGrammar.y gen/blink/core bison.exe\nm4: cannot open `Files': No such file or directory\nm4: cannot open `(x86)\\GnuWin32/share/bison': No such file or directory\nm4: cannot open `C:\\Program': No such file or directory\nm4: cannot open `Files': No such file or directory\nm4: cannot open `(x86)\\GnuWin32/share/bison/m4sugar/m4sugar.m4': No such file or directory\n just wonder why it doesn't show this in the build output at all.....\n(And also wonder how to fix this, a work-around for now is using a less... spacy .. location, but that seems stupid.. should be fixed with quotation...)\nBut for now, probably add \"Make sure to install Bison into a path without spaces. (e.g D:\\bison\\(share,bin,etc)\"\nEither way ...\n\n397 517 0   gen/blink/core/XPathGrammar.cpp 86f0fe2a26595c38\n397 517 0   gen/blink/core/XPathGrammar.h   86f0fe2a26595c38\nThis sure was/is annoying....\nFun fact, this is the first time I've ever opened ungoogled chrome, since I've never got it to compile before.. be it due to this issue or the non-existent 64bit support before.\nAnd.. Merry Christmas I guess.\nOriginal reply:\nyep, toolchain.ninja has::\n```\nrule __third_party_WebKit_Source_core_make_core_generated_bisonbuildtoolchain_win_x64rule\n  command = C$:/Python27/python.exe ../../third_party/WebKit/Source/build/scripts/rule_bison.py ${in} gen/blink/core bison.exe\n  description = ACTION //third_party/WebKit/Source/core:make_core_generated_bison(//build/toolchain/win:x64)\n  restat = 1\nbuild obj/third_party/WebKit/Source/core/make_core_generated_bison.inputdeps.stamp: stamp ../../third_party/WebKit/Source/build/scripts/rule_bison.py obj/third_party/WebKit/Source/core/core_event_interfaces.stamp obj/third_party/WebKit/Source/core/generated_settings_macros.stamp obj/third_party/WebKit/Source/core/generated_testing_idls.stamp obj/third_party/WebKit/Source/core/generated_testing_idls_internal_runtime_flags.stamp obj/third_party/WebKit/Source/core/generated_testing_idls_settings.stamp\nbuild gen/blink/core/XPathGrammar.cpp gen/blink/core/XPathGrammar.h: __third_party_WebKit_Source_core_make_core_generated_bisonbuildtoolchain_win_x64rule ../../third_party/WebKit/Source/core/xml/XPathGrammar.y | obj/third_party/WebKit/Source/core/make_core_generated_bison.inputdeps.stamp\nbuild obj/third_party/WebKit/Source/core/make_core_generated_bison.stamp: stamp gen/blink/core/XPathGrammar.cpp gen/blink/core/XPathGrammar.h\n```\nalso:\n.ninja.log\n221313  221531  0   gen/blink/core/testing/InternalSettingsGenerated.idl    513b877cc043a3cd\n221313  221531  0   gen/blink/core/testing/InternalSettingsGenerated.cpp    513b877cc043a3cd\n221313  221531  0   gen/blink/core/testing/InternalSettingsGenerated.h  513b877cc043a3cd\nAfter this, it should do xpathgrammar, but, no output. Have you read my big edit?. Nope, big fat bold header\nEDIT (be sure to read this first)\nhttps://github.com/Eloston/ungoogled-chromium/issues/156#issuecomment-269113502. That's a short reply .. heh.. hoped you'd say a little more.\nBut you got any idea why it does not show up in any logs AT ALL?\nI mean surely it should be... > I'm wondering how Google deals with this space issue. Maybe they patched their versions of the utilities? Or somehow used relative paths? Or they don't?\nPatches I guess? official source comes with its own bison-source that gets compiled, they maybe added actual error handling and spaced path support.\nEDIT:\n\nCould've ran the 32-bit version but I guess you like more bits and some more security.\n\nI boycott 32bit on a 64bit OS. (I totally just like more bits.) \nStrike the below, possibly was google fighting back and corrupting some files.\n(Or me killing the chrome process which probably corrupted a file, for whatever reason that might be, as copying the packaged files over again fixed it)\nEither way, now I'm very tired, ill reply tomorrow if you add anything else.\n~~Btw..offtopic issue I now face:~~\n~~Every single page is grayed out and shows the error icon, even internal ones, any idea? (I can post this in a new issue if you want)~~\n~~~~\n. wow that sounds very sad (it was in C:/Pr..Files/Chromium-ungoogled/ actually)... \n(now i just need ungoogled chromium for android...). chrome extensions on android are my dream\nGood night and see you at the next issue i guess?. > The grey page can also be caused by moving the ungoogled-chromium directory to a different path which is really dumb and needs to be fixed, but i'll open another issue when I get time (it's a holiday weekend for me).\nMeaning its fixable from your side and not chromium?\n(By patching chromium itself rather than making the chromium team fix it?)\n. > If you extra that zip again then move it before running it works just fine. I think it's saving the sandbox binary location somewhere. I can upstream it later after its fixed. I'm a hobbyist c++ programmer so I should be able to fix it.\nWell, so am I, altho all other languages more than c++, but does it really have to do where it saves the zip, does the entire build process remember \"i saved my zip to G:\\test\"\"lets fail everywhere else except G:\"\nBut ye I need more information to fully understand this, since if it saves the sandbox binary somewhere, shouldn't all we have to do be, moving said binary as well?. No problem, was just curious (ye even on my 6700k it takes a long while, def needs more than 8 threads, more like 24 :p)\nBe sure to quote me or reply here or so when you get more Information.. By the way, it does still work just fine, no matter which drive I put it on, after you mentioned it, I just took it for granted (that it won't work/causes issues) but it does work just fine.. @9Morello We had that discussion before, afaik its not possible yet, unfortunately.. You can just change the binary name yourself.\nAbout the changing of the chromium branding itself, take a look at:\nhttps://groups.google.com/a/chromium.org/forum/#!searchin/chromium-dev/change$20logo/chromium-dev/hVv04bSV7sM/J2m23-kkYYwJ\nI haven't tested that yet.. It might be that they use the very same file for linux as well, I'm not sure.\nAs I couldn't find any other information.\nEDIT: Try .\\chrome\\app\\chromium_strings.grd\nSee: \n<message name=\"IDS_PRODUCT_NAME\" desc=\"The Chrome application name\">\n        Chromium\n      </message>\n      <message name=\"IDS_SHORT_PRODUCT_NAME\" desc=\"The Chrome application short name.\">\n        Chromium\n      </message>\nAnd many others.. You def. need Clang 3.9, I tried the \"LVM Debian/Ubuntu nightly packages\" http://apt.llvm.org/\ncompiled fine for me on ubuntu using that.\nNot sure how to get that on Fedora.. ",
    "sbeh": "I can confirm this fix just worked for me on Windows 10 and Chromium 72.0.3626.109. @wokawoka I installed Chrome into a VM and then copied C:\\Users\\...\\AppData\\Local\\Google\\Chrome\\Application\\72.0.3626.109\\WidevineCdm into my ungoogled-chromium directory (that one with the chrome.exe-File). Result was a previously not and now working Netflix ;). ",
    "wokawoka": "@sbeh , thank you for contributing but I can't follow you, your links brings to a reply with a mac os fix, not a windows one. I'm trying to install widevine on 72.0.3626.109 under windows 10 and I would be very grateful if you can expand more. Many thanks. @sbeh, thanks, that's what I also previosly did but I forgot to close all the active windows in background (chromium needed a restart). Thank you very much again\nP.S.: In order to get the widevine addon I just installed chrome parallely to chromium on the same machine.. Great, many thanks for the information and (please) keep up with the great work!. ",
    "agucova": "Dragging from finder seems to work, but according to the inox-patchset documentation:\n\nDownload the crx file with the browser, open chrome://extensions and drop the file from the download bar into the extensions tab.\n. Should I close the issue?\n. \n",
    "c-sanchez": "I understand, really thank you very much for your reply.\n. ",
    "dangom": "I'm no expert, but this does the trick under Python 3.5 on MacOS Sierra:\n@static_method\ndef get_homebrew_gcc_bin():\n    brew_list_gcc = subprocess.Popen(['brew', 'list', 'gcc'],\n                                     stdout=subprocess.PIPE)\n    grep_gcc_path = subprocess.Popen(['grep', 'bin/x86_64'],\n                                stdin=brew_list_gcc.stdout,\n                                stdout=subprocess.PIPE,\n                                stderr=subprocess.PIPE)\n    out, err = grep_gcc_path.communicate()\n    result = out.split(b'\\n')[0]\n    if not result:\n        raise OSError(\"Is gcc properly installed? Please check the output of \\\"brew list gcc\\\"\")\n    return result\nIn [34]: get_homebrew_gcc_bin()\nOut[34]: \nb'/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-c++-6'\n. @Eloston \n Is gcc-4.9 or something similar already in your PATH?\nNo, it isn't. \nIf not, is there one in $(brew --prefix)/bin?\nNo, I only have 6.2 on brew, and it isn't symlinked to /usr/local/bin/. My PATH still points to /usr/bin/gcc.\nI haven't built Chromium myself yet.\nThe dummy function above will always return the oldest available brew install - since the folders are listed in alphabetical order. Should the oldest be 4.9.0, then that's what we get.\nWe can force search for gcc-4.9:\ngrep_gcc_path = subprocess.Popen(['grep', 'bin/x86_64.*c++-4.9'],\nMassaging the output of the function gives us the directory name we need:\n```\nimport functools as ftools\ntmp = get_homebrew_gcc_bin()\ngcc_path = b'/' + ftools.reduce(lambda a,b: a + b'/' + b, tmp.split(b'/')[1:-1])\n```\nIn [128]: gcc_path\nOut[128]: \nb'/usr/local/Cellar/gcc/6.2.0/bin'\nPrepending this to the PATH, as you suggested in #69, should do the trick without having to symlink all gcc binaries or overwrite user defaults. \nAgain, I'm not an expert. Would a fix for the include and lib directories also be necessary for the build?\n. Are you saying that there's a gcc-6.2 in /usr/local/Cellar/gcc/6.2.0/bin?\nYes. These are the files in said directory:\n/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-c++-6\n/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-g++-6\n/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-gcc-6\n/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-gcc-6.2.0\n/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-gcc-ar-6\n/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-gcc-nm-6\n/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-gcc-ranlib-6\n/usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-gfortran-6\n$ /usr/local/Cellar/gcc/6.2.0/bin/x86_64-apple-darwin15.6.0-gcc-6 --version\nx86_64-apple-darwin15.6.0-gcc-6 (Homebrew gcc 6.2.0) 6.2.0\nCopyright (C) 2016 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nI guess I must have misunderstood #69 then. My bad.\n\nCreate a directory build/path_overrides that contains files to override PATH commands. ...\nFor Python, /usr/bin/python will have to be changed to point to the Python command in path_overrides. \n\nYour idea is to have a directory with symlinks to the correct binaries? And prepend this build/path_overrides to the PATH?\nI don't know how to get a list of installed GCC versions apart from brew list | grep gcc. Or looping through the $PATH and seeing what's in there.\nWhat information about GCC versions are you interested in?\n. Not quite gcc-6.2, but brew link gcc adds gcc-6 to my path.\n$ which gcc-6\n/usr/local/bin/gcc-6\n$ gcc-6 --version\ngcc-6 (Homebrew gcc 6.2.0) 6.2.0\nCopyright (C) 2016 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n. It is. Takes an awful long time to build though.\nbrew install homebrew/versions/gcc49\n\ud83c\udf7a  /usr/local/Cellar/gcc49/4.9.3: 1,181 files, 196.4M, built in 62 minutes 48 seconds\n$ which gcc-4.9 && gcc-4.9 --version\n/usr/local/bin/gcc-4.9\ngcc-4.9 (Homebrew gcc49 4.9.3) 4.9.3\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n. ",
    "takinbo": "Hey, I had this problem the first time I was building the project for MacOS. I had to modify the patch file in order to get it to build. I made a pull request based on the conversation here to properly detect the existence of gcc-4.9 and then use the c++-4.9 binary that gcc-4.9 provides when it's installed.\n. ",
    "qazip": "I think he means the current name of this project is a bit dangerous. Google can shut it down easily I suppose?\nSince this has been getting so much attention now, I suggest a name change. \n. What the hell is Chrominium? Googling that doesn't find anything. If your question is in regards with Chromium, then, you should've read the README: https://github.com/Eloston/ungoogled-chromium/blob/master/README.md\nIt has all your answers there. Noone is going to read it for you. \n. How's the new version coming along? I'm eagerly awaiting version 54 for debian/ubuntu. Oh, that's weird. My version is still version 53. The latest release here on github was on the 24th of September. \nHow do I go about getting the version 54? Is there a .deb installer? . Trying to build this on Ubuntu 16.04 and got the following error:\n```\nCurrent dir: /home/my_user/ungoogled-chromium/build/sandbox/out/Default/\nCommand: python -- /home/my_user/ungoogled-chromium/build/sandbox/printing/cups_config_helper.py --api-version \nReturned 1.\nstderr:\nTraceback (most recent call last):\n  File \"/home/my_user/ungoogled-chromium/build/sandbox/printing/cups_config_helper.py\", line 106, in \n    sys.exit(main())\n  File \"/home/my_user/ungoogled-chromium/build/sandbox/printing/cups_config_helper.py\", line 76, in main\n    subprocess.call([cups_config, '--api-version'])\n  File \"/usr/lib/python2.7/subprocess.py\", line 523, in call\n    return Popen(popenargs, *kwargs).wait()\n  File \"/usr/lib/python2.7/subprocess.py\", line 711, in init\n    errread, errwrite)\n  File \"/usr/lib/python2.7/subprocess.py\", line 1343, in _execute_child\n    raise child_exception\nOSError: [Errno 2] No such file or directory\nSee //BUILD.gn:264:7: which caused the file to be included.\n      \"//printing:printing_unittests\",\n      ^------------------------------\n2016-12-10 10:23:44,061 - ERROR: gn gen returned non-zero exit code: 1\n```\nI think I'll just wait for the .debs. . @Eloston, will you tag these binaries? Do you trust 9Morello's binaries?\n@9Morello's, can you tell how you compiled on Ubuntu 16.04? What did you install before doing ./build.py? . ",
    "ajkblue": "I would say keep the name just as it is now, \"ungoogled-chromium\" tells me everything I need to know about the browser, basically \"Chromium without Google\", and that's exactly what I want. I also believe it's the simplest to understand and comes across more trustworthy than a name like \"Iron\" or \"Epic Privacy Browser\". Names like those make me think of the other chromium-based browsers that have pretty bad security reputations (see the Web Browsing section from the OS X Security and Privacy Guide which states \"Many Chromium-derived browsers are not recommended. They are usually closed source, poorly maintained, have bugs, and make dubious claims to protect privacy.\") The majority of people that would even use this understand the difference between Chrome and Chromium, the latter being the open source version and therefore the more trusted of the two.\n. I've found the easiest way to keep ungoogled-chromium updated is with brew cask, which will automatically install the latest version for me as long as I run \"brew update\".. ",
    "adammenges": "just seems a little weird that through the UI, in the about area, you can click on a URL that is blocked.\n. ",
    "jgoldgh": "That explains it. Thank you very much for the response and for all the work you put in doing this! I'm going to use it as my main browser.\n. ",
    "antonin-lebrard": "@MrOCR \nThere is an issue about the CryptoTokenExtension on the inox patchet repository that have some useful informations: https://github.com/gcarq/inox-patchset/issues/25\nIt seems to be related only to the U2F keys like Yubikeys. So it seems to be an important extension to keep, but maybe having the options to disable it could be cool. But I suspect it is more coupled with the chromium code base than others extensions, hence the non-disable status of it. @sem5959 https://ungoogled-software.github.io/ungoogled-chromium-binaries/. I think the FAQ section on Flash player should answer your request :\nhttps://github.com/Eloston/ungoogled-chromium/blob/master/FAQ.md#how-do-i-install-flash-player. There is some supplementary installations instructions on the debian wiki: https://wiki.debian.org/PepperFlashPlayer/Installing\nMaybe by trying to fiddle with the chromium installation and the libpepflashplayer.so file you will find a solution ? \nAnd there is the chrome url : chrome://flash/ that might ease your test scenario. I didn't managed myself to make it work, but I'm in ubuntu so I'm using the build of dubvulture https://ungoogled-software.github.io/ungoogled-chromium-binaries/releases/ubuntu/xenial_amd64/65.0.3325.181-1 \nSo I might not be able to help you . I don't have access to my computer at the moment, but i have been using this parameter on both Chrome (last version) and Iridium browser (last 2017 version). And they both don't suppress history on exit (I still have all my auto-completion when i search something in the address bar).\nIt only affects cookies for my case (maybe session storage, and local storage, but I didn't tested). The chrome help page from google seems not to talks about history when talking of this parameter: https://support.google.com/chrome/answer/95647?co=GENIE.Platform%3DDesktop&oco=1\nAnd from the chrome help page about history itself, it seems only the incognito mode is mentioned as a way to not keep history\nhttps://support.google.com/chrome/answer/95589?hl=en&co=GENIE.Platform%3DDesktop&oco=0\nSo I suppose it's the intended behavior . From the README.md\nFollow the FAQ link in the Table of Contents \nClick on the link downside of its title \nClick the link saying it has moved to the wiki \nAnd first question is Can I install extensions from the Chrome Webstore?\nThis may be not the average numbers of links to go through, but this is a small hurdle that is understable when dealing with one man open source projects. The whole text could be roughly translated in english to :\nChromium want to use your confidentials  informations kept in \"Chromium Safe  Storage\" of your key hold.(don't know for this one).\nThe authenticity of \"Chromium\" can't be verified. Forauthorizing it, enter the password of your key hold \"session\"\nPassword : [ Text Area ]\n| Always Authorize  |  Refuse  |   Authorize  |. I think this is the kind of features that you will not find here.\nThe whole first paragraph of the README.md, do not suggests usability features being part of the modifications made to chromium, and the first line is :\n\nungoogled-chromium is Google Chromium, sans integration with Google. It also features some changes to enhance privacy, control, and transparency.\n\nAnd each usability improvement for some might be a hurdle for others.\nYou might create a patch for yourself and follow the guides compiled here to try to create a chromium for your use case. \nFor example the method in the chromium source that seems to do the job to close a tab seems to be here. In the FAQ, first question, first answer:\nhttps://ungoogled-software.github.io/ungoogled-chromium-wiki/faq#can-i-install-extensions-from-the-chrome-webstore. @hardhub Unfortunatly I didn't find any way to auto update each extensions.\nBut in my experience it is actually a very good thing, as extensions may change of owner without notice or the owner might be malicious, and profit of autoupdate behavior of chrome to update its extensions with crypto-miner, adware, malware, anti-privacy features etc... \nI prefer to search for the code source of each extensions I wish to install/update.\nIt might be cumbersome, but I don't see better way to manage this automaticaly. @intika You may want to check the Session Buddy extensions, it does have a Google Analytics tracker inside it. I removed it because of that \nFor me:\n- Ublock origin and its sibling extension Ublock origin extra\n- Umatrix (to control near everything a webpage loads, from web requests and scripts to images)\n- ScriptSafe (disable or control fingerprinting of Canvas/Audio/Plugins/ClientRect access features of each website)\n- Decentraleyes (avoid re-fetching common javascript libraries, kinda useless as ublock origin begins to do it on its own)\n- WebScrobbler (scrobbles to lastfm from common streaming platfrom, lets you disable its google analytics tracker, and is available on github). @xsmile Didn't know about these ones, and I always thought about doing one myself, so thank you for these additions !\n@intika This is something I would gladly re-download if it were cleaned :) But I don't know if it would be possible as it seems to not be open source, and copyrighted without any trace of legal agreements or privacy policy :/ . @anchev I think there is some good ways to avoid most nefarious or dangerous extensions:\n\nNever install from the chrome web store, install directly from source (github/gitlab etc..), this will avoid auto-updates with unforseen code added (this could happen even with a good willed developper, if his chrome web store account has been accessed by someone else, to push a nefarious update)\nTry to avoid team based developped extensions, this seems to be counter-productive (as in security, the more person is behind a product, the more it might gain legitimity).\nBut extensions are only monkey-patchs on existing webpages, so there is no stability on the working state of the code base.\nThis incitate team based extensions to build metrics on its working state, and indirectly its user-base. \nAnd unfortunaly, the already developpers are more armed to go through the code base to watch for suspect urls, suspect unicode characters, or suspect mimified code .. . @csalvato You mention Brave each time, but this github project has nothing to do with Brave. It uses some patches developped by the brave team, but the relations between them stop here.\n\nAnd this github project has no \"team\" working on it, only effort from people (mostly @Eloston and kudos for him !) on their free time with no money tied to it. So I think its presumptuous to demand ease of use, and covering all usages such an effort. Without even talking about going exactly against the primary goal of this project, removing all google related services from chromium.. For a tempory fix for your case (that is nor a really a beautiful trick to do, neither beautiful to see in practice):\nYou can create a .bat file that start chrome.exe with all the command line flags you want, then:\n\n\nCreate a shortcut to your batch file.\nGet into shortcut property and change target to something like: cmd.exe /C \"path-to-your-batch\".\nSimply drag your new shortcut to the taskbar. It should now be pinnable.\n\n\n(from: https://superuser.com/questions/100249/how-to-pin-either-a-shortcut-or-a-batch-file-to-the-new-windows-7-8-and-10-task)\nAnd I think you can find a way to change the icon of the shortcut to the icon of chromium in its properties. \nBut in practice, I think that when you're gonna click on this shorctut, Windows will open chromium but will append the chromium icon to your taskbar, like it is not pinned to it.\n(And of course if you pin it thereafter, and click on it to launch chromium, it will not do it with the flags you have put in the shorcut) . ",
    "maciozo": "Well, that fixed the d3d problem. But now I've run in to another one. Seems that Bison is unhappy with something.\n[4120/20445] RULE make_core_generated: bison_fe4dcbb12ad96ef4dade61a9dbd3691f xml\\XPathGrammar.y\nFAILED: gen/blink/core/XPathGrammar.cpp gen/blink/core/XPathGrammar.h\nC:\\Python27\\python.exe gyp-win-tool action-wrapper environment.x86 make_core_generated_target_bison_fe4dcbb12ad96ef4dade61a9dbd3691f.29be8c7a8e7e566255f37ac5795d1bd2.rsp ..\\..\\third_party\\WebKit\\Source\\core\nxml\\xpathgrammar.y:58: unrecognized: %parse_param\nxml\\xpathgrammar.y:58:    Skipping to next %\nTraceback (most recent call last):\n  File \"../build/scripts/rule_bison.py\", line 83, in <module>\n    assert returnCode == 0\nAssertionError\n[4128/20445] LINK_EMBED(DLL) libEGL.dll\n. I think I did. I extracted the three archives and merged them all in to one folder (bison-2.4.1)\nThen I added C:\\Chromium\\bison-2.4.1\\bin;C:\\Chromium\\bison-2.4.1\\lib;C:\\Chromium\\bison-2.4.1\\include to PATH.\n. chromium-53.0.2785.143 and x86. I haven't messed with any of the build scripts.\n. Deleted the build directory, changed the version in version.ini to 53.0.2785.116\n[4102/20445] RULE make_core_generated: bison_fe4dcbb12ad96ef4dade61a9dbd3691f xml\\XPathGrammar.y\nFAILED: gen/blink/core/XPathGrammar.cpp gen/blink/core/XPathGrammar.h\nC:\\Python27\\python.exe gyp-win-tool action-wrapper environment.x86 make_core_generated_target_bison_fe4dcbb12ad96ef4dade61a9dbd3691f.29be8c7a8e7e566255f37ac5795d1bd2.rsp ..\\..\\third_party\\WebKit\\Source\\core\nxml\\xpathgrammar.y:58: unrecognized: %parse_param\nxml\\xpathgrammar.y:58:    Skipping to next %\nTraceback (most recent call last):\n  File \"../build/scripts/rule_bison.py\", line 83, in <module>\n    assert returnCode == 0\nAssertionError\n[4110/20445] LINK_EMBED(DLL) libGLESv2.dll\n. Alright, downloaded the sources, merged them all in to the same bison-2.4.1 directory, recloned this repo, and now I'm getting patching errors.\npatching file `components/domain_reliability/uploader.cc'\npatching file `components/domain_reliability/bake_in_configs.py'\nHunk #1 FAILED at 21.\nHunk #2 FAILED at 32.\n2 out of 2 hunks FAILED -- saving rejects to components/domain_reliability/bake_in_configs.py.rej\n2016-10-09 16:08:43,619 - ERROR: 'patch -p1' returned non-zero exit code 1\nI'm not familiar with how patching works, but to me it looks like it's trying to remove a line that doesn't exist in /components/domain_reliability/BUILD.gn?\n. Still fails\n```\n[3743/20445] LIB obj\\v8\\src\\v8_base_3.lib\nLINK : MSIL .netmodule or module compiled with /GL found; restarting link with /LTCG; add /LTCG to the link command line to improve linker performance\n[4109/20445] RULE make_core_generated: bison_fe4dcbb12ad96ef4dade61a9dbd3691fxml\\XPathGrammar.y\nFAILED: gen/blink/core/XPathGrammar.cpp gen/blink/core/XPathGrammar.h\nC:\\Python27\\python.exe gyp-win-tool action-wrapper environment.x86 make_core_generated_target_bison_fe4dcbb12ad96ef4dade61a9dbd3691f.29be8c7a8e7e56625\n5f37ac5795d1bd2.rsp ....\\third_party\\WebKit\\Source\\core\nxml\\xpathgrammar.y:58: unrecognized: %parse_param\nxml\\xpathgrammar.y:58:    Skipping to next %\nTraceback (most recent call last):\n  File \"../build/scripts/rule_bison.py\", line 83, in \n    assert returnCode == 0\nAssertionError\n[4116/20445] LINK_EMBED(DLL) libGLESv2.dll\nLibDef: Total time = 0.047s\nLINK : /LTCG specified but no code generation required; remove /LTCG from the link command line to improve linker performance\n  OptRef: Total time = 0.000s\n  OptIcf: Total time = 0.078s\nPass 1: Interval #1, time = 1.391s\n  Wait PDB close: Total time = 0.297s\n  Wait type merge: Total time = 0.016s\nPass 2: Interval #2, time = 0.500s\nFinal: Total time = 1.891s\n[4118/20445] LINK_EMBED mksnapshot.exe\nninja: build stopped: subcommand failed.\n2016-10-10 14:21:05,844 - ERROR: ninja returned non-zero exit code: 1\n```\n. Alright, turns out the problem was that my system was using GNU Patch 2.5 from WinAVR, rather than 2.7.5 from MSYS. x86 builds successfully now.\n. How does this happen to just Symantec certs?\n. > Widevine support in Chromium doesn't work without the actual module.\nGood. Proprietary DRM has no place on the open web.. ",
    "wbedard": "Please specify what OS you are looking for and/or what portable apps framework (i.e. portableapps.com) you are requesting.  In the case of Windows, the only release so far has been a ZIP file, which is generally regarded as very \"portable.\" \n. ",
    "AlxMxlA": "I'm looking for Windows.\nBy \"portable\"  I mean a program, which during operations does not extend beyond the directory where it was installed.\n. No.\nungoogled-chromium_53.0.2785.116-1_win32.zip \u0441reates a folder in the user profile.\n. ",
    "the4anoni": "Win32 version is portable :P\n. why you closed ?\n. Ok ,got it thanks. Just thinked that chrominium is without google ,but now i'm on good way ;)\n. Updates via browser ,not github\n. If you have a very good reason for implementing this, let me know.\nBecause i don't want every day check for updates...\n. ",
    "sergeevabc": "Issue is not resolved, just a quick workaround was mentioned, which is not convenient and not sufficient.\nWe want a true portability right out the box w/o additional switches like other forks offer (e.g. Cent, Iron).\n3: https://superuser.com/questions/1140195/why-portable-chrome-creates-crashpad-directory-under-appdata. @Eloston, since you commit patches, I thought this behaviour could be modified internally as well.. Steps to reproduce:\n1. Download and extract Ungoogled Chromium binary package for Windows (e.g. 55.0.2883.87-1).\n2. Launch chrome.exe --user-data-dir=profile --no-default-browser-check --disable-breakpad.\nResult: profile is stored nearby, yet Chromium/User Data/Crashpad is created in %localappdata%. \nExpected: all Chromium related data is stored nearby.\nThe same question was asked once on Stackoverflow \u2014 with no solution, alas.\nTherefore it seems there is no flag to use, so patch is the way to go.\nEdit: link is fixed.\n. Err\u2026 Anyone?. @Unkn0wn-MDCLXIV, compiled Windows binary would be appreciated indeed.. > If there is some demand for that, I would be glad to upload the code and the compiled release\nNotably, @Unkn0wn-MDCLXIV offered a way for Windows twice (here and there), but never uploaded it.\nA man is only as good as his word, right?\n3: https://www.quora.com/A-man-is-only-as-good-as-his-word-How-true-is-this. The story of updating Chromium Ungoogled reminds me of Duke Nukem Forever development.\n1: https://en.wikipedia.org/wiki/Development_of_Duke_Nukem_Forever. Regular rescheduling and lack of support across more popular platforms led me to think @Eloston came in with a bang, but went out with a whimper, i.e. he is out of his depth. Hence, I unsubscribe and move on.",
    "tonowoe": "It's working! I love this.\nThe building itself took over 1 hour even though I have pretty decent PC. It's going to be a pain in the ass in the future when building for the updated versions. By the way, is there some reason why there aren't pre-built packages available for the new releases to download (e.g. for Debian/Ubuntu)?\n. Yeah no hurry man, better safe than sorry, it's all good. Keep up the good work.\n. I had the same error. You need the dev-packages to get packaging work in Debian.\nJust run this:\nsudo apt-get install packaging-dev\n. I think what he is asking is that that should he install the pre-built Debian Stretch or Ubuntu Xenial package for his Ubuntu system.\nIf you have Ubuntu, then I would assume that you want the Ubuntu Xenial pre-built package. Current available pre-built version for Ubuntu is 53.0.2785.116-1.1. So go ahead and download the xenial_chromium_53.0.2785.116-1_amd64.deb.\n. Does the notification come to the tab (under the URL bar) where the connection was made? For example, does it mean that if I have two tabs, YouTube and Wikipedia, and the Wikipedia tab is active/opened and then I get a notification in my Wikipedia tab that there was attempted request to https://accounts.9oo91e.qj9zk, that there was something in the Wikipedia page itself which triggered the connection attempt to Google? Or does the notification come by default for the active tab, despite what tab triggered it?\nI tried to replicate it, but I couldn't. I was logged in my Google Accounts and I had two tabs; YouTube and Wikipedia, and Wikipedia opened. Maybe my YouTube page was trying to connect to Google Accounts in the background, don't know. I can't get the notification even if I try to \"trigger\" it by loggin in and out from Google Accounts, and browsing videos in YouTube and doing Google searches and stuff.\nHere is a screenshot from the notification what I've had couple of times now.\n. Yea, purely through web, clicking sign-in button in google.com (https://accounts.google.com/ServiceLogin). I have installed these extensions: HTTPS Everywhere, uBlock Origin and uMatrix.\n. > Are you seeing any connections right when you open your browser?\nConnections, you mean notifications? No, I don't. Only notification I get when I open up my browser is:\n\nYou are using an unsupported command-line flag: --no-sandbox. Stability and security will suffer.\n\nIf you don't mean notifications; should I monitor my traffic when I open up my browser to spot some weird/Google connections?\n\nWhat platform are you using?\n\nAmd64 Debian Jessie & Chromium_53.0.2785.143-1_amd64\n. No I don't. I can't replicate it in the incognito mode either.\n. Yea, didn't edit those.\n. Now I got a new notification:\nBlocked attempted request to: http://www.95tat1c.qjz9zk/generate_204\nImmediately after opening https://translate.google.com. I was logged in in Google (through web).\nWhat I'm wondering is that, is this normal behavior? Do you guys too get these notifications regularly?\n. I really don't use Google account or their services that much, I use YouTube and Google Translate. Although I'm logged in when I do other surfing, but I don't use any other Google services other than those, or use Google accounts for anything else.\nI can't replicate it either. It just comes randomly without any repeatability. I logged in normally through web by clicking Sign-In in google.com, then I did some random surfing and after a while I went to translate.google.com and I got the notification. I tried to refresh the page, close the page and open it again, logging in and out and trying to replicate it, and trying replicating it in incognito mode etc, but without success. \n. Okay, so now I can replicate one notification:\n1. Go to https://mcdonalds.fi/\n2. Get notification Blocked attempted request to: http://www.95tat1c.qjz9zk/generate_204\nThis notification comes only with HTTPS connection. I'm not logged into Google, so it can be replicated in incognito mode too. This is what I see when I go to that page (due to the invalid certificate):\nYour connection is not private\nAttackers might be trying to steal your information from www.mcdonalds.fi (for example, passwords, messages, or credit cards). NET::ERR_CERT_COMMON_NAME_INVALID\nBack to safetyHIDE ADVANCED\nThis server could not prove that it is www.mcdonalds.fi; its security certificate is from a248.e.akamai.net. This may be caused by a misconfiguration or an attacker intercepting your connection.\nProceed to www.mcdonalds.fi (unsafe)\n. That's weird. I'm not managing my cookies, I get it in the incognito mode too (fresh mode, no cookies/visits to other sites). \n. Oh guys, I'm sorry. The correct URL which triggers it is without www. So the correct URL is https://mcdonalds.fi\nDo you now get the notification too?\n. Hmm, that's strange. For me the notification comes up every time I refresh that (Privacy error) page, even in fresh incognito mode.\n. How about this one, can you replicate it?\n1. Open a new tab (e.g. google.com)\n2. Open Task Manager (Shift + Esc)\n3. Highlight the tab which you just opened in step 1.\n4. Click the \"End process\" button\n5. Aw, Snap! page will be shown: \"Aw, Snap! Something went wrong while displaying this webpage. Learn more    Send feedback\"\n6. Click the \"Learn more\" link\n7. Get notification Blocked attempted request to: https://support.9oo91e.qjz9zk/chrome/?p=e_awsnap_rl\n. Oh I see. \n. Kind of offtopic from triceratops1's issue (I think), but do you all have all sandboxes enabled? chrome://sandbox/ Gives me this:\n```\nSandbox Status\nSUID Sandbox    Yes\nNamespace Sandbox   No\nPID namespaces  Yes\nNetwork namespaces  Yes\nSeccomp-BPF sandbox Yes\nSeccomp-BPF sandbox supports TSYNC  Yes\nYama LSM enforcing  Yes\nYou are adequately sandboxed.\n```\nSo it seems like I don't have the Namespace Sandbox. What should I do? Is it dangerous to have this in \"No\"?. > Are you also running on Arch? I know Debian also disables this by default, but it's configurable at runtime.\nI'm running Debian. How can I configure it? Tried to Google but no luck.. I'm not sure if this kind of script have already been shared here. I made this JavaScript code which I can run on my browser's console to download the crx file automatically. This can't be run via bookmark, unfortunately (for security reasons I think).\nScript can be found here (minified here).\nSo when you are at the extension page in Google Webstore, just press F12 and open up the console and paste the code there. It should download the .crx file for you. No need to add browser version and extension ID to the URL manually.. Me and my friends are using \"ungoogled-chromium\". I think it's good.\nThere are also news about this browser and in those articles they are calling it \"ungoogled chromium\".\nhttps://lifehacker.com/ungoogled-chromium-strips-away-the-privacy-invading-fea-1787139870\nhttps://betanews.com/2016/10/05/ungoogled-chromium-is-a-completely-google-free-browser/\nand in Finnish\nhttps://www.tivi.fi/Kaikki_uutiset/nain-saat-chrome-selaimen-ilman-googlen-vakoilutoimintoja-6586115\nhttps://www.mikrobitti.fi/2016/09/tassa-on-todellisen-foliohatun-chrome-selain/\n(tivi and mikrobitti are the largest tech newsmagazine in Finland). I'm using those pre-built binaries as well with Debian 9 amd64, and I've noticed the same. If I don't reboot my browser or computer for couple of days, I see that the browser is being heavy on RAM usage. It haven't bothered be that much because it's really fast to just restart the browser so the RAM usage will go back to normal again. I have had this problem for many versions now, and it's about the same in the latest 67 version. But it seems that RAM usage will not grow as fast as in earlier versions.\nIf I remember correct, this happened in the normal chromium too, not just in ungoogled, not sure though.. This is not the issue anymore for me after upgrading to 71.x. RAM usage is normal after keeping the browser on several days.. I think this might have something to do with swap. I just realized that this issue haven't been problem for me since I disabled swap on my Linux pc (debian stretch).. Same! Especially the pre-built packages are SUPER helpful. I love how they get updated fast for debian.. Here's how you can use Tor for specific domains in Chromium.\n1) make sure you have Tor proxy for SOCKS5 (in Linux, \"apt-get install tor\" should be enough)\n2) install Proxy SwitchyOmega extension\n3) make a new PAC profile\n4) create a PAC script, like this for example which uses the proxy for reddit (not for 3rd party domains!), for all .se domains, and for one .onion url\nThis is laborious, and this can potentially leak your real IP (if you for example don't write all the needed 3rd party domains for the website you want to browse through Tor), but that's how you can do it if you really want it.. ",
    "lenormf": "Here's the first half of the gpu page:\n```\nGraphics Feature Status\nCanvas:                         Hardware accelerated\nFlash:                          Hardware accelerated\nFlash Stage3D:                  Hardware accelerated\nFlash Stage3D Baseline profile: Hardware accelerated\nCompositing:                    Hardware accelerated\nMultiple Raster Threads:        Enabled\nNative GpuMemoryBuffers:        Software only. Hardware acceleration disabled\nRasterization:                  Software only. Hardware acceleration disabled\nVideo Decode:                   Hardware accelerated\nWebGL:                          Hardware accelerated\nDriver Bug Workarounds\nclear_uniforms_before_first_program_use\ncount_all_in_varyings_packing\ndisable_framebuffer_cmaa\ndisable_post_sub_buffers_for_onscreen_surfaces\nmsaa_is_slow\nscalarize_vec_and_mat_constructor_args\nProblems Detected\nEXT_occlusion_query appears to be buggy with Intel GPUs on Linux\nClear uniforms before first program use on all platforms:               124764, 349137\nApplied Workarounds:                                                    clear_uniforms_before_first_program_use\nMesa drivers in Linux handle varyings without static use incorrectly:   333885\nApplied Workarounds:                                                    count_all_in_varyings_packing\nDisable partial swaps on linux drivers:                                 339493\nApplied Workarounds:                                                    disable_post_sub_buffers_for_onscreen_surfaces\nAlways rewrite vec/mat constructors to be consistent:                   398694\nApplied Workarounds:                                                    scalarize_vec_and_mat_constructor_args\nOn Intel GPUs MSAA performance is not acceptable for GPU rasterization: 527565\nApplied Workarounds:                                                    msaa_is_slow\nTimer queries crash on Intel GPUs on Linux:                             540543, 576991\nLimited enabling of Chromium GL_INTEL_framebuffer_CMAA:                 535198\nApplied Workarounds:                                                    disable_framebuffer_cmaa\nAccelerated rasterization has been disabled, either via blacklist, about:flags or the command line.\nDisabled Features:                                                      rasterization\nNative GpuMemoryBuffers have been disabled, either via about:flags or command line.\nDisabled Features:                                                      native_gpu_memory_buffers\n``\n. I usually sandbox my browser infirejail`, but since I couldn't get the project to compile on archlinux I just deployed the pre-compiled ubuntu packages in a container. So I haven't experimented with video playback with anything else, unfortunately.\nI can compile the project in a debian container though, so if you want me to try a specific patch, send it my way and I'll try the new build.\nBy the way here is my Dockerfile, if you want to try it yourself:\n```\n\nDockerfile by lenormf\nThe docker image has to run in privileged mode to allow chromium to\nhave access to the sound card (ALSA supported only), and to be able to\nrun the sandbox (namespaces)\n\ndocker build --rm \\\n--build-arg DISPLAY=${DISPLAY} \\\n--build-arg UID=$(id -u) \\\n--build-arg GID=$(id -g) \\\n-t ${USER}/chromium .\ndocker run --rm --privileged --name=chromium \\\n-v /tmp/.X11-unix:/tmp/.X11-unix \\\n-v ~/Downloads:/home/chromium/Downloads \\\n-v ~/.config/chromium:/home/chromium/.config/chromium \\\n-v /etc/localtime:/etc/localtime \\\n-v /dev/snd:/dev/snd \\\n${USER}/chromium chromium \"$@\"\n\nFROM ubuntu:xenial\nMAINTAINER \"Frank LENORMAND lenormf@gmail.com\"\nLABEL version=\"1.0\" \\\n      description=\"Run ungoogled-chromium in a docker container\" \\\n      source=\"https://github.com/Eloston/ungoogled-chromium\"\nDisplay chromium will connect to\nARG DISPLAY=:0\nIdentifier of the ungoogled-chromium release\nARG RELEASE=53.0.2785.116-1.1\nChromium version\nARG VERSION=53.0.2785.116-1\nIDs of the user/group that will own the Downloads directory\nARG UID=1000\nARG GID=100\nENV DISPLAY ${DISPLAY}\nVOLUME /tmp/.X11-unix/:/tmp/.X11-unix/\nVOLUME /dev/snd:/dev/snd\nVOLUME /etc/localtime:/etc/localtime\nVOLUME /home/chromium/Downloads/\nVOLUME /home/chromium/.config/chromium/\nWORKDIR /root\nRUN \\\n    apt-get update \\\n    && apt-get install -y wget lsb-release \\\n    && wget https://github.com/Eloston/ungoogled-chromium/releases/download/${RELEASE}/xenial_chromedriver_${VERSION}amd64.deb \\\n            https://github.com/Eloston/ungoogled-chromium/releases/download/${RELEASE}/xenial_chrome-sandbox${VERSION}amd64.deb \\\n            https://github.com/Eloston/ungoogled-chromium/releases/download/${RELEASE}/xenial_chromium${VERSION}amd64.deb \\\n            https://github.com/Eloston/ungoogled-chromium/releases/download/${RELEASE}/xenial_chromium-l10n${VERSION}_all.deb\nRUN dpkg -i --force-overwrite \\\n        xenial_chromedriver_${VERSION}amd64.deb \\\n        xenial_chrome-sandbox${VERSION}amd64.deb \\\n        xenial_chromium${VERSION}amd64.deb \\\n        xenial_chromium-l10n${VERSION}all.deb \\\n    ; apt-get -f install -y \\\n    && rm xenial_chromedriver${VERSION}amd64.deb \\\n          xenial_chrome-sandbox${VERSION}amd64.deb \\\n          xenial_chromium${VERSION}amd64.deb \\\n          xenial_chromium-l10n${VERSION}_all.deb\nRUN \\\n    useradd -m -u ${UID} -g ${GID} chromium \\\n    && chown -R ${UID}:${GID} /home/chromium\nUSER chromium\nWORKDIR /home/chromium\n```\n. I tried the Debian binaries in a stretch container, and the browser doesn't crash miserably. Instead the error tab gets displayed (the one that says \"something went wrong\"), which is better I guess, but more importantly ~~the ffmpeg errors have gone and only the bus error stacktrace remains~~ (the warnings re-appeared after I scrolled down with the mouse wheel on an imgur album preview displayed by the Hover Zoom chrome addon). I've allowed dbus into the container hoping that it would magically fix everything, unfortunately it didn't.\nEDIT: for the sake of completeness, here's the Dockerfile used\n```\n\nDockerfile by lenormf\nThe docker image has to run in privileged mode to allow chromium to\nhave access to the sound card (ALSA supported only), and to be able to\nrun the sandbox (namespaces)\n\ndocker build --rm \\\n--build-arg DISPLAY=${DISPLAY} \\\n--build-arg UID=$(id -u) \\\n--build-arg GID=$(id -g) \\\n-t ${USER}/chromium .\ndocker run --rm --privileged --name=chromium \\\n-v /tmp/.X11-unix:/tmp/.X11-unix \\\n-v ~/Downloads:/home/chromium/Downloads \\\n-v ~/.config/chromium:/home/chromium/.config/chromium \\\n-v /etc/localtime:/etc/localtime \\\n-v /dev/snd:/dev/snd \\\n-v /var/run/dbus:/var/run/dbus \\\n${USER}/chromium chromium \"$@\"\n\nFROM debian:stretch\nMAINTAINER \"Frank LENORMAND lenormf@gmail.com\"\nLABEL version=\"1.0\" \\\n      description=\"Run ungoogled-chromium in a docker container\" \\\n      source=\"https://github.com/Eloston/ungoogled-chromium\"\nDisplay chromium will connect to\nARG DISPLAY=:0\nIdentifier of the ungoogled-chromium release\nARG RELEASE=53.0.2785.116-1\nChromium version\nARG VERSION=53.0.2785.116-1\nIDs of the user/group that will own the Downloads directory\nARG UID=1000\nARG GID=100\nENV DISPLAY ${DISPLAY}\nVOLUME /tmp/.X11-unix/:/tmp/.X11-unix/\nVOLUME /dev/snd:/dev/snd\nVOLUME /var/run/dbus:/var/run/dbus\nVOLUME /etc/localtime:/etc/localtime\nVOLUME /home/chromium/Downloads/\nVOLUME /home/chromium/.config/chromium/\nWORKDIR /root\nRUN \\\n    apt-get update \\\n    && apt-get install -y wget lsb-release \\\n    && wget https://github.com/Eloston/ungoogled-chromium/releases/download/${RELEASE}/chromedriver_${VERSION}amd64.deb \\\n            https://github.com/Eloston/ungoogled-chromium/releases/download/${RELEASE}/chrome-sandbox${VERSION}amd64.deb \\\n            https://github.com/Eloston/ungoogled-chromium/releases/download/${RELEASE}/chromium${VERSION}amd64.deb \\\n            https://github.com/Eloston/ungoogled-chromium/releases/download/${RELEASE}/chromium-l10n${VERSION}_all.deb\nRUN \\\n    apt-get install -f -y \\\n        ./chromedriver_${VERSION}amd64.deb \\\n        ./chrome-sandbox${VERSION}amd64.deb \\\n        ./chromium${VERSION}amd64.deb \\\n        ./chromium-l10n${VERSION}_all.deb\nRUN \\\n    rm chromedriver_${VERSION}amd64.deb \\\n       chrome-sandbox${VERSION}amd64.deb \\\n       chromium${VERSION}amd64.deb \\\n       chromium-l10n${VERSION}_all.deb\nRUN \\\n    useradd -m -u ${UID} -g ${GID} chromium \\\n    && chown -R ${UID}:${GID} /home/chromium\nUSER chromium\nWORKDIR /home/chromium\n``\n. That was it! I added/dev/shm` as a volume to my container, and everything works fine now, no more errors.\nThanks for the help.\n. >That way collaborators can upload binaries to a GitHub release associated with that tag and link them from gh-pages.\nI don't know the details of this part of the plan, but I don't think third-party builds are going to have much success if anybody can submit their binaries. Are you going to appoint the people allowed to submit builds personally, and take responsability for them? Or declare that anybody can upload their builds and the users are responsible for anything that might happen to them? Please give more details of what you have in mind.. @Eloston do you take responsibility for the binaries uploaded by contributors? Does being a contributor automatically grant you the right to upload builds or do you select them (making the contributor concept moot)?. Thanks, it's all clear now.. >Faster\n\nBrowser Fingerprinting would be harder since no special \"domain\" is used\nLess complicated\n\nI think @Eloston's answer shows that all those points are incorrect.. https://sslmate.com/blog/post/ct_redaction_in_chrome_53\n. How are we doing on the update?\n. Maybe bitbake? It would take a massive amount of amount to migrate though.. Can we hope for a release?. Nice, I've been on the lookout for new official packages to download in my scripts that update docker containers.\nTried building on debian:stretch, got an error:\n```\n2016-12-05 08:56:05,233 - INFO: Running gn command...\n2016-12-05 08:56:05,233 - DEBUG: Appending resources/common/gn_flags\n2016-12-05 08:56:05,234 - DEBUG: Appending resources/linux_static/gn_flags\n2016-12-05 08:56:05,234 - DEBUG: GN command: out/bootstrap_gn gen out/Release --args=is_debug=false is_clang=true enable_hangout_services_extension=false treat_warnings_as_errors=false ffmpeg_branding=\"ChromeOS\" enable_remoting=false use_gconf=false remove_webcore_debug_symbols=true clang_base_path=\"/usr/lib/llvm-3.9\" enable_iterator_debugging=false fatal_linker_warnings=false enable_nacl_nonsfi=false google_api_key=\"\" enable_hevc_demuxing=true google_default_client_secret=\"\" enable_widevine=true enable_mse_mpeg2ts_stream_parser=true enable_hotwording=false gold_path=\"\" icu_use_data_file=false use_gold=true enable_nacl=false use_official_google_api_keys=false clang_use_chrome_plugins=false enable_webrtc=false is_official_build=true use_sysroot=false fieldtrial_testing_like_official_build=true google_default_client_id=\"\" enable_rlz_support=false safe_browsing_mode=0 enable_google_now=false proprietary_codecs=true symbol_level=0 use_gnome_keyring=false enable_one_click_signin=false use_ozone=false\nERROR at //printing/BUILD.gn:135:22: Script returned non-zero exit code.\n      cups_version = exec_script(\"cups_config_helper.py\",\n                     ^----------\nCurrent dir: /root/ungoogled-chromium/build/sandbox/out/Release/\nCommand: python -- /root/ungoogled-chromium/build/sandbox/printing/cups_config_helper.py --api-version \nReturned 1.\nstderr:\nTraceback (most recent call last):\n  File \"/root/ungoogled-chromium/build/sandbox/printing/cups_config_helper.py\", line 106, in \n    sys.exit(main())\n  File \"/root/ungoogled-chromium/build/sandbox/printing/cups_config_helper.py\", line 76, in main\n    subprocess.call([cups_config, '--api-version'])\n  File \"/usr/lib/python2.7/subprocess.py\", line 523, in call\n    return Popen(popenargs, *kwargs).wait()\n  File \"/usr/lib/python2.7/subprocess.py\", line 711, in init\n    errread, errwrite)\n  File \"/usr/lib/python2.7/subprocess.py\", line 1343, in _execute_child\n    raise child_exception\nOSError: [Errno 2] No such file or directory\nSee //BUILD.gn:264:7: which caused the file to be included.\n      \"//printing:printing_unittests\",\n      ^------------------------------\n2016-12-05 08:56:05,552 - ERROR: gn gen returned non-zero exit code: 1\n```\nApparently the cups_config isn't reachable in my docker container, and I couldn't find the package that provides it (it's not part of depot_tools either), so I just wrote a cups_config script that forwards everything to cups-config  and it seems to have done it. Maybe this needs to be changed.\nI had other errors due to some packages not being installed, it seems that the dependency install script has some blindspots (a lot). I'm not done installing all of them, I'll let you know if I run into more issues.. I hadn't realized I had hit a bug, I was just making a comment about the workaround I had to do.\nThe build finished, it produced a ungoogled-chromium_55.0.2883.75-1_linuxstatic.tar.xz archive.\nAs for the build container, it's a buildpack-deps official image, plus the dependencies I installed manually.\nI'm building the project with the modifications you recommend -a patch would have been nice ;)- I'll let you know how that goes.\nEDIT: /etc/os-release\nshell\nPRETTY_NAME=\"Debian GNU/Linux stretch/sid\"\nNAME=\"Debian GNU/Linux\"\nID=debian\nHOME_URL=\"https://www.debian.org/\"\nSUPPORT_URL=\"https://www.debian.org/support\"\nBUG_REPORT_URL=\"https://bugs.debian.org/\"\n```python\n\n\n\ndistro._distroi.linux_distribution()\n('Debian GNU/Linux', '', '')\ndistro._distroi.info()\n{'like': '', 'codename': '', 'id': 'debian', 'version': '', 'version_parts': {'build_number': '', 'major': '', 'minor': ''}}\n``. The build has ended, all the packages seem to have been successfully generated (haven't tested them yet). I've also kept the full build log if needed.. I fixed it by installing thelsb-release` package, even though there wasn't apparently any need for it. I reported the bug upstream.\n\n\n\nEDIT: I'm restarting a build to see if everything is working as expected now.. The build finished, the proper dynamic builder has been selected and the packages were built. Log here.. My 2c:\n```shell\n! /usr/bin/env bash\nset -e\nreadonly URL_EXT_DL='https://clients2.google.com/service/update2/crx?response=redirect&prodversion=48.0&x=id%3D{id_ext}%26installsource%3Dondemand%26uc'\nreadonly PATH_EXTENSIONS=\"${XDG_CONFIG_HOME:-${HOME}/.config}/chromium/Extensions\"\nreadonly PATH_TMP_DIR=$(mktemp -d)\ntrap \"rm -rf '${PATH_TMP_DIR}'\" ERR\nfatal() {\n    echo \"$@\" >&2\n    exit 1\n}\nget_json_value() {\n    grep \"\\\"$2\\\":\" \"$1\" \\\n       | sed 's/^[[:space:]][^[:space:]][[:space:]]\"(.)\".*$/\\1/'\n}\nmain() {\n    if [ $# -lt 1 ]; then\n        fatal \"Usage: $0 \"\n    fi\nreadonly ID_EXT=\"$1\"\n\nmkdir -p \"${PATH_EXTENSIONS}\"\nurl=$(printf %s \"${URL_EXT_DL}\" | sed \"s/{id_ext}/${ID_EXT}/g\")\n\nwget -O \"${PATH_TMP_DIR}/extension.crx\" \"${url}\"\n7z x -o\"${PATH_TMP_DIR}\" \"${PATH_TMP_DIR}/extension.crx\"\nrm -r \"${PATH_TMP_DIR}/_metadata\" \"${PATH_TMP_DIR}/extension.crx\"\n\nname_ext=$(get_json_value \"${PATH_TMP_DIR}/manifest.json\" \"name\" \\\n            | sed 's/[^[:alnum:]]/-/g')\nversion_ext=$(get_json_value \"${PATH_TMP_DIR}/manifest.json\" \"version\")\npath_ext=\"${PATH_EXTENSIONS}/${name_ext}_${version_ext}\"\n\nmv -f \"${PATH_TMP_DIR}\" \"${path_ext}\"\n\nprintf %s\\\\n \"Extension installed at ${path_ext}\"\n\n}\nmain \"$@\"\n``. Nothing in particular, this browser has gotten some exposure recently, I wanted to make sure we're not missing anything. If that's the case, then I'm closing this.. Will you experiment with community builds for this release? I have adocker` container dedicated to building the project, so I can help on that front if needs be.. You could try setting up an environment with udocker, and compile from there.. >Meanwhile I've been building with no problems thus far after forcing clang-3.9 and clang++-3.9 on Debian Jessie. It's an ugly workaround though.\nHow is that a workaround? This version was released years ago and is no longer relevant, so you have to install one that's in line with modern C++/flags. The issue is that Debian's Jessie is years behind and Stretch is nowhere near ready of being promoted as new stable.. I was talking about the clang version.. I'll be waiting for a PR!. I've compiled v58 packages for Debian Stretch, available here:\n\nchromium-driver_58.0.3029.110-1_amd64.deb 1.98 MiB\nchromium-l10n_58.0.3029.110-1_all.deb 3.11 MiB\nchromium-shell_58.0.3029.110-1_amd64.deb 18.84 MiB\nchromium-widevine_58.0.3029.110-1_amd64.deb 104.47 KiB\nchromium_58.0.3029.110-1_amd64.deb 39.53 MiB\n\nI've installed and tested them, it's working.. ",
    "hook321": "Makes it more difficult for network managers to see what you are searching, if it is implemented it should be able to be turned on and off.\n. Wait, it appears to be an issue with the network that I'm on.\n. I'm having the same issue. When I try to go to https://www.greatagain.gov/ it comes up with the \"Your connection is not private\" page.\n. ",
    "edintomato": "i am using ubuntu gnome edition, but i have also tried this on manjaro and linux mint.\n. @Eloston yes, i am using the prebuilt binary in the releases section. i tried opening an swf file in vivaldi and it worked just fine. am i doing something wrong?\n. @Eloston vivaldi is a chromium-based browser.\nusing the flag \"--ppapi-flash-path\" doesn't seem to work. is it because the package \"adobe-flashplayer\" is not supported by chromium?\n. @Eloston yes, that one and also this one\nedit: i just realized the adobe-flashplugin is outdated. thanks canonical.\n. @Eloston both flags --ppapi-flash-path and --ppapi-flash-version do not work. i will try this with iridium just to make sure.\n. @Eloston yep. i also used an equal sign with the --ppapi-flash-version flag.\n. @usernamenotexist it's hard to kill something that is used for many websites. if browsers like chrome and firefox remove the ability to use flash, most of the history of the internet is inaccessible.\n. ",
    "my-password-is-password": "I don't use ungoogled-chromium but I do use  Chromium dev build 56.0.2915.0 by nik and my flash was missing too.  Once something stops working on dev builds I usually check chrome://flags/ to see if I can re-enable stuff they take out and I found this, \n\nGo to chrome://flags/#prefer-html-over-flash and change it to Disabled and relaunch chromium.\n\nSee if flash starts working for you.  It did for me.  I'm on Windows though, don't know if it works on Linux.\n. ",
    "Deltadragoon": "I can confirm that the issue exists on version 55.0.2883.87 built on Ubuntu xenial/16.04, running on LinuxMint serena/18.1 (64-bit). I've installed PPAPI correctly and the plugin is not detected by ungoogled-chromium. And I should add the flash plugin I do have installed is detected by vanilla Chromium and Google Chrome and I am running version 56.0.2924.76 of Chromium. . It's an issue for myself, at least. . ",
    "ryneeverett": "You might set up CI to do the build matrix for you when a commit is tagged. For example, you could add encrypted github credentials to a .travis.yml and authorize only that build account to push to the separate gh-pages repo. Not only would that mean your whole build process is automated and isolated, but you wouldn't have to give co-maintainers the authority to upload binaries\n. > I don't like having to give my credentials.\nI could have been more explicit -- my idea was to create a separate github user for this purpose. But good point, probably no free CI runner is going to be able to build chromium within the timeout period.\n. ",
    "Technologov": "Today Chromium lacks Windows installer completely.\nOnly Google Chrome has it. So basically I decided to fill the void by creating my own installer from scratch.\nI don't mind if you use someone else's installer, but we need one.\n. ",
    "Velocet": "I would also suggest to use0.0.0.0:\n- Faster\n- Browser Fingerprinting would be harder since no special \"domain\" is used\n- Less complicated. ",
    "seb-m": "+1\nI hit this nagging issue with version 53 https://sslmate.com/blog/post/ct_redaction_in_chrome_53\n. ",
    "japostoles": "+1, same here @seb-m \n. Ugh, sorry for not searching well enough to uncover that duplicate!\nthanks for the link to 54!. ",
    "VittGam": "Regarding the certificates breakage, you can find a workaround command-line flag on https://github.com/Eloston/ungoogled-chromium/issues/119#issuecomment-262473485.\nThis will also work with Inox, by the way.. You can workaround this bug by disabling the same FieldTrial flag that was disabled on-the-fly by Google on Google Chrome 53 using their Finch remote hijacking ehm, Field Trial Testing server. You can use this command-line switch to do this:\n--force-fieldtrials=*EnforceCTForProblematicRoots/Disabled/\nEnjoy! :). @Eloston No, unfortunately they're scattered all around the code, and there is no place where they're defined... It's just a key-value store that's checked when needed.\nThis particular one is checked here: https://chromium.googlesource.com/chromium/src/+/53.0.2785.116/net/http/transport_security_state.cc#753\nWhile the --force-fieldtrials option is described here:\nhttps://chromium.googlesource.com/chromium/src/+/53.0.2785.116/base/base_switches.cc#36. ",
    "nopjmp": "swapimport.exe is a 32bit process only. It has 32bit assembly for injecting the DOS header in the PE file. x64 builds will have to have an additional step that just compiles swapimport.exe first and then allows it to be called within the normal build process.\nUnless you have another idea on how to get this to work.\nEdit: technically the 32bit assemble is just 16bit instructions, but it is required for PE. @Eloston I'm just getting familiar with GN. We could just disable it and do some testing. I'm currently just using Google's provided binary while I straighten out the swapimport repo since the GN build files do not work.. The browser works fine without swapimport. If you are okay, we can remove it as a requirement. I don't see any purpose for this except for prevent dependency hell and other things. I'll try a 64bit build tomorrow after work.. CMake is akin to systems like GYP and GN.\nI think the current system is fine, it just needs to be refined into something simple and easy to use. The main issue is supporting 3 different platforms with their own quirks. All other build systems are code oriented. I've dealt with custom python build systems before on another project. This is fairly simple compared to that monster and I'm able to easily understand what is going on.\nI think some sort of configuration file would make it easier with the defaults being what works on \"generic\" Linux. Windows can then override binary names and such and would get rid of different constants in the build system. Python takes care of some things like paths for you which makes this easier to abstract.\nIt would be best to avoid deviating away from what Google is using for Chromium otherwise we risk of falling behind on updates which means leaving users vulnerable to exploits and bugs.\nI do understand your point on simplifying the build system, but Windows makes it a pain.. It looks like it's a bug upstream that they fixed recently. I'm able to replicate it on my system. I'll see if I can figure something out.. I got it fixed. The bootstrap.py file needed to be updated. I'm fixing up the other parts of the Windows build now as well and will submit a pull request with my changes once I'm done.. Not much progress except it's at least building to linking. There was a wierd patch problem because git converted the LFs to CRLFs on the line endings. I got a linker error yesterday probably because I kept stopping the build.\nIt takes several hours on my machine to compile and can be quite annoying to deal with. I'd check back next week or this weekend instead of what you are doing.. @Eloston I forgot about the subscribe button. I'm using GNU patch from MSYS2 the problem is the patches were never applied due to how Python was working. Switching to -i and providing the full path resolved the issue. I'm going to try to build again tonight and see if I can fix my problems.\nSent from my android device.\n-----Original Message-----\nFrom: Eloston notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Wed, 14 Dec 2016 4:18 PM\nSubject: Re: [Eloston/ungoogled-chromium] Problem building on Windows: GN bootstrapping problem (#137)\n@waqas In the future, you can just click the \"subscribe\" button on the side to listen to notifications.\n@nopjmp GNU patch from MSYS2 (which I tell users to use) seems to be fine with different line endings. What are you using to apply patches?\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/137#issuecomment-267174719. @Eloston I should have known about it when telling wasqas. There was no error that was the problem, it just didn't actually patch anything until I switch to the other method.\nBuilding now. Everything built. creating a branch and pushing individual commits for review this might take a bit.. It might also be a good idea to create an IRC channel or a channel on another messaging system. It might be able to help keep issues done and help point people to older issues that were resolved.. I haven't used gitter before Ive mainly used slack and discord. I'll check it out.\nSent from my android device.\n-----Original Message-----\nFrom: Eloston notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Author author@noreply.github.com\nSent: Sun, 25 Dec 2016 1:56 PM\nSubject: Re: [Eloston/ungoogled-chromium] Create Organization (#145)\nHow about Gitter?\n-- \nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/145#issuecomment-269135362. I do apologize for the terribly formatted git message. I was in a rush to get this pull request created before I went to bed to avoid another 24 hour wait.\nI'll check 64bit build tomorrow.. The patch function outputs patching but it doesn't patch anything. I can look further into it.\nI'll disable the download when I test 64bit\nSent from my android device.. I think it might be due to how python is interacting with the shell, but stdin might have been acting strangely in my setup. I'm not using ActivePython, but the official release. It might work if I updated python 3 I just noticed I'm on a REALLY old version.\n```\nC:\\Users\\nopjmp>C:\\Python34\\python.exe\nPython 3.4.3 (v3.4.3:9b73f1c3e601, Feb 24 2015, 22:44:40) [MSC v.1600 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\n``. @Eloston 64bit builds, but I need to fix GN bootstrap.py to compile for 64bit. Otherwise, it works just fine. I'll try to clean it up today if I have time; otherwise, it will be done tomorrow. I'll test Python3.5 also.. Windows 64bit is fixed and I reverted the hacked up patch function.. I'm curious whatchrome://sandbox` says for you @triceratops1 \n\n\n\nEdit: Never mind I'm half asleep. I'll check Arch Linux tomorrow when I wake up. @tonowoe that means you don't have user namespaces enabled I'm pretty sure. Arch doesn't have that enabled since they introduced a security hole and the other sandboxing techniques work well enough. https://bugs.archlinux.org/task/36969. @Eloston It may have problems. User namespaces allows users and not just root to make namespaces. This means a user could create a situation that they are \"root\" in the user namespace which may make it easier to exploit kernel bugs. Chromium says \"You are adequately sandboxed.\" so you shouldn't have to worry about it. It's only needed if you are missing more recent features like seccomp-bpf.. @9Morello what system did you build the semi-static version on? It feels like an ABI compatibility problem.. @Eloston chrome's sandboxing works I'm using it right now (not using ungoogled). It looks like the issue is something is blocking SBX_CHROME_API_RQ from getting set to 1 or parsing SBX_CHROME_API_RQ is not getting parsed to 1. I copied chrome's official sandbox binary to ungoogled and it's still broken.. Our build system is naming the binary as chrome_sandbox instead of chrome-sandbox. That's why it's not finding the binary and throwing the more appropriate error of \"please fix the permissions\".\nEDIT: Offending code\nbase::FilePath SetuidSandboxHost::GetSandboxBinaryPath() {\n  base::FilePath sandbox_binary;\n  base::FilePath exe_dir;\n  if (PathService::Get(base::DIR_EXE, &exe_dir)) {\n    base::FilePath sandbox_candidate = exe_dir.AppendASCII(\"chrome-sandbox\");\n    if (base::PathExists(sandbox_candidate))\n      sandbox_binary = sandbox_candidate;\n  }\n[...]. @tonowoe you can use the debian specific sysctl kernel.unprivileged_userns_clone flag to enable user namespaces as well to prevent having to use setuid binaries.. Oh I didn't see it. User namespaces is what Google prefers. They still use the setuid sandbox on ChromeOS, but we will probably never target that.\nThey both have trade offs, but it depends on what the distro maintainers want. If Google killed setuid, distros like Arch would have to enable user namespaces and/or patch it like Debian did.\nI trust the Debian and Arch security team for the most part, but I can't remember a recent user namespace exploit since June 2015.\nEdit: Script would be fine. We could also just edit chrome-wrapper to check the sandbox binary and/or detect user namespaces not being enabled and warn the user and prompt to allow us to fix it for them.. That's probably the best option until we have packages for their system.. I'm just going to chime in some closing thoughts just in case someone else stumbles across this issue.\nSpaces cause problems in a lot of ported tools on Windows. I always suggest used the VS2015 x86 Native Tools Command Prompt and VS2015 x64 Native Tools Command Prompt and then changing directories just because it prevents less knowledgeable users from making a mistake.\nThe grey page can also be caused by moving the ungoogled-chromium directory to a different path which is really dumb and needs to be fixed, but i'll open another issue when I get time (it's a holiday weekend for me).\nI was actually going to work on getting Ungoogled Chromium on Android. It's going to take a lot more fiddling, but it's completely possible. CopperheadOS builds Chromium as part of their build process.. If you extra that zip again then move it before running it works just fine. I think it's saving the sandbox binary location somewhere. I can upstream it later after its fixed. I'm a hobbyist c++ programmer so I should be able to fix it.\nSent from my android device.\n-----Original Message-----\nFrom: DeadSix27 notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Sun, 25 Dec 2016 1:11 PM\nSubject: Re: [Eloston/ungoogled-chromium] Issue including XpathGrammar.h (#156)\n\nThe grey page can also be caused by moving the ungoogled-chromium directory to a different path which is really dumb and needs to be fixed, but i'll open another issue when I get time (it's a holiday weekend for me).\n\nMeaning its fixable from your side and not chromium?\n(By patching chromium itself rather than making the chromium team fix it?)\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/156#issuecomment-269134068. I'm just mentioning the behavior I noticed I haven't looked into it too much since made the pull request. I will look into it later. It takes way too long for me to build chromium on my machine. I'm waiting for my new machine to come in.\nSent from my android device.\n-----Original Message-----\nFrom: DeadSix27 notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Sun, 25 Dec 2016 1:48 PM\nSubject: Re: [Eloston/ungoogled-chromium] Issue including XpathGrammar.h (#156)\nWell, so am I, altho all other languages more than c++, but does it really have to do where it saves the zip, does the entire build process remember \"i saved my zip to G:\\test\"\"lets fail everywhere else except G:\"\nBut ye I need more information to fully understand this, since if it saves the sandbox binary somewhere, shouldn't all we have to do be, moving said binary as well?\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/156#issuecomment-269135157. I think it's the sandbox process but it could be something else. I'm going to make a new issue or just submit a pull request to fix it. Most likely it only is a problem on Windows since macOS and Linux use different methods. macOS stores everything in the app and Linux uses a wrapper script.\nSent from my android device.\n-----Original Message-----\nFrom: Eloston notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Sun, 25 Dec 2016 2:00 PM\nSubject: Re: [Eloston/ungoogled-chromium] Issue including XpathGrammar.h (#156)\nWhat \"sandbox binary\" are we talking about here? And zip file? I thought Chromium just made system API calls to get sandboxing to work\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/156#issuecomment-269135500. They probably fixed it upstream. Windows filesystem can be crazy. UTF16 file names if I remember correctly.\nSent from my android device.\n-----Original Message-----\nFrom: Eloston notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Sun, 25 Dec 2016 2:10 PM\nSubject: Re: [Eloston/ungoogled-chromium] Issue including XpathGrammar.h (#156)\nHuh, I remember that it wouldn't run on my secondary HDD attached to the VM, but it would run just fine on the C: drive. Maybe they changed it now?\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/156#issuecomment-269135781. I'll discuss it you on gitter once I'm done with family activities for the holiday.\nSent from my android device.\n-----Original Message-----\nFrom: Eloston notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Author author@noreply.github.com\nSent: Sun, 25 Dec 2016 2:31 PM\nSubject: Re: [Eloston/ungoogled-chromium] Ungoogled on Android (#157)\nHmm this is a nice issue report, but now I don't know what to do with #56. I guess I can close that one?\n\nExtend current build system to support Android\n\nShould probably wait for #125.\n-- \nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/157#issuecomment-269136378. Extension support would require quite a bit of custom ui code and integration since nothing is supported in there. You can make a simple app that injects javascript onto a page using WebView. WebView uses Chromium under the hood for a while.. Work has been busy so I haven't been able to setup a working development system. My home lab I'm building will help me get a build vm up so I can iterate fast. I'll update the main issue just in case someone else comes in later and doesn't read the entire thread.. most likely it's a similar issue to the other platforms like in the issue #73. I replaced the widevincdm with the one from my Chrome install and big buck bunny streaming worked.. Chromecasts are just browsers hooked up to your TV. It runs a stripped down version of Android with WebView. It loads a page that the website choices to load and runs content. If you are wanting this seamless integration, you may want to stick with a less paranoid chromium patchset.. afaik they don't need google's servers to work, but I haven't looking into them in great detail.. What version of clang do you have installed? ~~You may want to try adding clang_base_path=\"/usr\" to gn_flags.~~ The first issue should be resolved after a discussion on what to do about the icu data files.\nEdit: You might want to try removing the clang_base_path instead of what I said.. I'll install fedora in a VM tonight and see about fixing the clang flags. I was going to tidy them up anyways, but this gives me a good reason.\nSent from my android device.\n-----Original Message-----\nFrom: xa0 notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Thu, 29 Dec 2016 12:04 PM\nSubject: Re: [Eloston/ungoogled-chromium] Cannot compile on Fedora 25 (#161)\n@nopjmp if I remove clang_base_path, I get:\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory\nI'm using clang 3.8.0\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/161#issuecomment-269668775. I got the same thing. I have the patch updated in my local tree and I'll submit a pull request when I get home this evening.\nI'm currently discussing with @Eloston what to do about the icu data. It's just a lookup table as far as I can tell. While it is a binary blob, it can be regenerated which files under the acceptable binary blobs in my book.. @9Morello build instructions are in the third_party/icu/README.chromium macOS and Linux will probably not have problems, but Windows it would be a nightmare since it's a bash script.\nEdit: Also buildlib is going away. @Eloston not sure, but this can probably be closed now since the build fix commit got merged. we can discuss icu in another issue if needed. WebVR is strictly a display platform. It's mainly for android and VR headsets (57 adds improvements) user's position is not based on geolocation and rather movement in a \"VR\" space (ex: HTC Vive).\nWebGL was recommended to be disabled since it leaks information through GPU \"bugs\" or \"anomalies\". This is well documented in research papers. The better approach for all of these things is to disable JavaScript since third party JavaScript cannot be trusted.\nRemote Playback will most likely be disabled anyways since we don't support Chromecasts technically. For now it's a Android only feature since the Desktop backend hasn't been made yet.\nTor adds click to play through built in Firefox features since Mozilla has been helping the Tor Project with improving the security and privacy of Firefox.. @triceratops1 I suggest reading this paper (one of the many) https://cseweb.ucsd.edu/~hovav/dist/canvas.pdf. Targeting anything before 10.8 is bad. Chrome doesn't support it anymore and there are no security updates for those operating systems.\nI highly suggest those users get a new PC, if they want to use a computer for multiple years without worrying, they should stick with non-Apple devices. I don't feel like we should be bending over backwards for users of \"EOL\" operating systems.. Google is upstream. They are now using APIs that are not in 10.8 (at least sanely). I don\u2019t know what they are off the top of my head, but I build cef for another project which is where my experience comes from.\nOn February 26, 2017 at 2:18:04 PM, 1-61803 (notifications@github.com) wrote:\nThat Google doesn't support \u226410.8 (is this still ungoogled-chromium, right?) and that Apple also dropped it, doesn't mean you also have to jump in the same bandwagon.\nYou are already building it for 10.9. If you target 10.8 I'll be happy to test it.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. They mainly changed the compiler flags and used clang instead of GCC in 10.9.\nSent from my android device.\n-----Original Message-----\nFrom: 1-61803 notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Sun, 26 Feb 2017 2:35 PM\nSubject: Re: [Eloston/ungoogled-chromium] Target OS X 10.8 and lower (#189)\n@nopjmp, in my experience problems arose between 10.8 and 10.9 with new UI assets in such generic applications, no special APIs \u2014 after all, it's just a browser.\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/189#issuecomment-282585161. There is a flag to switch the target. I forget where it is.\nSent from my android device.\n-----Original Message-----\nFrom: Eloston notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Sun, 26 Feb 2017 2:48 PM\nSubject: Re: [Eloston/ungoogled-chromium] Target OS X 10.8 and lower (#189)\n\nafter all, it's just a browser.\n\nThat's what I thought at first too. But, the modern web browser isn't some simple file-rendering application like the old days. It's essentially an application runner. Just consider the new technologies like WebRTC, WebAssembly, WebGL, WebUSB, Web Bluetooth, WebVR, HTML5, CSS3, APIs to access speakers, play video, use the microphone, use your webcam, and all of the new ECMAScript features coming out. And those are just the developing web standards that all modern web browsers are supposed to support; I haven't considered non-standard technologies like Native Client or Widevine.\nAlso, I believe Chromium takes as long (or longer) to compile than the Linux kernel.\n\ncould you ask @9Morello to target 10.8? The switch is a couple of clicks away, build and wait.\n\nI will let @9Morello or anyone else make that choice on their own. Plus, I'm not sure how this would be done; could you elaborate?\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/189#issuecomment-282586189. The flags I'm speaking of are just the default Apple compiler flags.\nSent from my android device.\n-----Original Message-----\nFrom: Eloston notifications@github.com\nTo: Eloston/ungoogled-chromium ungoogled-chromium@noreply.github.com\nCc: nopjmp jmp@const.ninja, Mention mention@noreply.github.com\nSent: Sun, 26 Feb 2017 2:57 PM\nSubject: Re: [Eloston/ungoogled-chromium] Target OS X 10.8 and lower (#189)\n\nThey mainly changed the compiler flags and used clang instead of GCC in 10.9.\n\nAre the flags backwards-compatible? Does clang work in pre-10.9 systems?\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Eloston/ungoogled-chromium/issues/189#issuecomment-282586829. Because this would have to change the target over to clang instead of GCC manually. You can already modify the plist file to make it run on an older macOS version. The chromium build system is the one that changes the target and will override any environment flag you set.\nYou can find the appropriate GN config flag, install xcode and dependencies and build ungoogled-chromium yourself. No one is stopping someone else from making this work.. ",
    "ipetepete": "@hook54321a LOL, oh the irony\n. ",
    "biergaizi": "@ipetepete @hook54321a \nhttps://www.nsa.gov is affected by the same issue.\n. ",
    "think3t": "@VittGam Thanks for the tip! It works!. ",
    "xaviervalarino": "@VittGam Sorry to resurrect this year old topic, but how would I go about enabling --force-fieldtrials option from the command-line in OSX?\nRunning chromium --force-fieldtrials=*EnforceCTForProblematicRoots/Disabled/ from term returns unrecognized option and then the usage text.. ",
    "bcallaars": "If I'm not mistaken this is due to the unique way how Google Chrome access the security key. I'll see if I can investigate further, but it might be one of the patches breaking it. In my mind it was something to do with a request Google Chrome does in the background, but I'm not sure.\nThere is no info bar.. Thanks for the tip, I'm going to see if I can find something out.. When I check out the Google JavaScript it's trying to execute, references are made to this FIDO U2F extension. Strangely enough when I install it, it works.\nI can't find references of this in the vanilla Google Chrome, but I'm a 100% sure that this is what makes it tick. Do we need to change the instructions/wiki/documentation here somewhere to make the user aware of this?. Ok as far as I can gather these are installed as plugins when needed, it seems odd, but at least legit. I've created a PR to add a section in the FAQ.. ",
    "pmico": "I found other sites with the same problems. It's always a problem with image links broken: amazon.es, images of phones like in http://www.htcmania.com/forumdisplay.php?f=1907, https://www.powerplanetonline.com/ ... \nIn amazon and powerplanetonline, html divs are not shown, css fails too ...\nIt's very strange.\nRight now in amazon there is an image about black friday that i can't see accessing directly to the web page, but if i copy the link to the image and try to open it in another tab, i can see this image.\nCapture of web page:\n\nCapture of image in new tab:\n\n. Upss sorry ... I didn't read this entry ... I didn't think it is related to.\nThanks for the answer.\nEloston, you know you're doing a great job and we all really appreciate your efforts.. ",
    "waqas": "It's because of #119 . IMDb gets some images from https://images-na.ssl-images-amazon.com. I think it is already being worked on by releasing 54.. Any progress on Windows build? I am checking this every few hours since last couple of weeks :). Seems fixed to me on second build from @squalus.\nhttps://github.com/squalus/ungoogled-chromium-winbuild/releases. Been using 67 on Windows last few days. No issues so far. Thanks @Eloston, @Wyse- . That worked. Thanks.. Can you please share Windows binaries if build succeeds? Thanks.. Yes, related to Safebrowsing. Minus those patches and someone has released the build...\nhttps://chromium.woolyss.com/#comment-4085. ",
    "se4u": "Thanks for the suggestion of looking into developer tools. It turns out that the problem was not a problem with ungoogled-chromium but rather the content_security_policy in the manifest.json. Somehow the following syntax for specifying the CSP is invalid (or incorrect)\n\"content_security_policy\": \"script-src 'self' https://*.googleapis.com https://*.bootstrapcdn.com; object-src 'self'\"\n\nand because of this  jquery was not being loaded from googleapis. I was able to fix the error by just downloading jquery to the extension folder and loading the unpacked extension. . I was able to get past this error by adding the -f flag to the quilt pop command that is executed in the QuiltPatchComponent in buildlib/common.py \n-            result = self._run_subprocess([self.quilt_command, \"pop\", \"-a\"],\n+            result = self._run_subprocess([self.quilt_command, \"pop\", \"-af\"],\nIMO adding a verbose flag in the pop and push command would also be useful. \nAlternatively a .quiltrc file can be used as follows:\nQUILT_POP_ARGS=\"--color=auto -f\"\nQUILT_PUSH_ARGS=\"--color=auto -f\". Hi Eloston, I was finally able to get time to report my experience with building ungoogled-chromium. I also give a patch for a small TODO. Hopefully this feedback will be useful in designing the build system, or for future issues about installation on osx. Thanks again for this great project, I had first wanted to build chromium 6 months ago to remove google specific components when I first found out that chrome and chromium run involuntary marketing research on all computers and send the result back to google.\n\n\nWhile running quilt the environment variables QUILT_SERIES and QUILT_PATCHES are passed to the quilt program in calls like these:\npython\nresult = self._run_subprocess([self.quilt_command, \"push\", \"-a\"],\n                                      append_environ=self.quilt_env_vars,\n                                      cwd=str(self._sandbox_dir))\nit will be great if these two variables are printed out because they change the default behavior of quilt of looking for a series file, which is what most documentation online says that quilt is looking for. I wasted some time at this step when quilt was throwing up at this step and I was trying to debug quitl and I could not find the series file.\n\n\nThe rebuilding of chromium fails currently, for example if there is an error at the quilt push stage, and I rebuild the code, then the build crashes at the quilt pop stage, which is frustrating because that means I have to delete the build folder and start again.\n\n\nCurrently the OSX build guides people to use the g++-4.9 compiler. This is bad/wrong advice. The chromium developers have moved to clang for linux and osx and I can attest that clang is much faster than g++. Furthermore I was unable to finish building using g++ but that might just be because of error on my part. \n\n\nWe can switch from g++ to clang by changing the files buildlib/macos.py and resources/macos/patches/ungoogled-macos/fix-libcxx-archive-build-script.patch\npatch\n-        gxx_compiler = shutil.which(\"g++-4.9\")\n+        gxx_compiler = shutil.which(\"clang-3.9\")\npatch\n-+CXX=g++-4.9\n++CXX=clang-3.9\nAlso I found that I was unable to compile chromium using the macport's version of clang, instead, I directly downloaded Clang for Mac OS X from LLVM's website.\n\nChecking the macOS SDK version is definitely important. I did not know about the SDK requirement in the beginning and I can confirm that chromium can not be built with SDK 10.12, because I wasted a lot of time with errors like unexpected token: !tapi-tbd-v2 etc.\nPlease add the following code to buildlib/macos.py in place of the TODO to check for SDK version \n\npatch \n- # TODO: Maybe add check for macOS SDK version\n+ assert subprocess.run(\"xcrun --show-sdk-version\", shell=True, stdout=subprocess.PIPE, universal_newlines=True).stdout.strip() in [\"10.10\",] \n\nFinally, it would be pretty sweet if there was a way to bypass the step where 7,000 files are untarred from the chromium source code and put into a source hierarchy. This step takes 4 minutes only but it occurs fairly early in the build process and it's hard to skip this step, so even this step doesn't take a long time in the grand scheme, some people might have to rerun this step a number of times during debugging and that can be frustrating.\n\n2016-11-27 02:36:35,626 - INFO: Extracting source archive into building sandbox...\n2016-11-27 02:36:35,626 - DEBUG: Appending resources/common/cleaning_list\n2016-11-27 02:40:40,895 - ERROR\n. ",
    "luckydonald": "Is there a .zip file already ready to use?\nChrome 53 isn't able to access amazon.com any more.\nWarning ERR_CERTIFICATE_TRANSPARENCY_REQUIRED.\nIt seems because of https://sslmate.com/blog/post/ct_redaction_in_chrome_53 (https://bugs.chromium.org/p/chromium/issues/detail?id=664177)\nEdit: Amazon.com, Ebay.com, .... @Eloston https://github.com/Eloston/ungoogled-chromium/issues/129#issuecomment-264738968, also @pjv\nThanks for that!\nEdit: Is working, am using it ATM.\n. yay! You guys are awesome!. Please make that opt-out, I use that regularly.. ",
    "Eitot": "@9Morello: which SDK have you built against?. @9Morello: Just FYI, 10.12 SDK seems to be working fine as well.. Can this issue remain open, so that someone may still figure out why Widevine cannot be built?. Does the Widevine build also fail with the regular Chromium source code? The FreeSMUG build also does not seem to have it.. The Caskroom maintainers decided against that name when the cask was added, per https://github.com/caskroom/homebrew-cask/pull/24969#issuecomment-250848695.. ",
    "bradx954": "This is more likely an issue with cups or the chromium source code but would like to hear about possible fixes or workarounds. . Thanks for getting back to me. This will work great thanks. I look forward to 55 being available in the future.. ",
    "Admicos": "After reading your reply, i think it's better to do everything clientside than send a request to my server. It's just a couple of string replaces, should be easy to port over. I'll still leave the PHP script up for convenience though.\nAlso, the PHP script's source available here if anyone wants to look at how i did it.\nEDIT: The userscript has been updated to do everything clientside.. I don't think there is, unless i try to extract it from the user agent, but most people will probably change it so that won't be effective. . @perfect7gentleman Are you using Tampermonkey to install it? If not then you should. If you are using Tampermonkey, try this:\nIf you are opening the extension details from the store and not from a external link, try refreshing since  Tampermonkey doesn't play well with the soft-reload thing Google is doing.\nThe button should appear where the original \"Install Extension\" button would be.. @perfect7gentleman I don't think uMatrix blocks it. But i only tested it using Tampermonkey so yeah.\nCan you tell me how you installed the script?. @perfect7gentleman You'll want to use Tampermonkey to install the script as currently it requires it to do its thing. I'll look into making it work with Chrome's own userscript loader.. I just checked with \"normal\" Chromium and it doesn't work here too. This is getting weird. \nEDIT: It looks like either Chrome (or Tampermonkey) disables extensions at the Chrome Web Store or i screwed up my URL matches. What's funny is that it actually works without any issues on my Windows partition (that i developed the userscript in).. ",
    "mikerockett": "With the latest realease, I'm unable to drag anything into the extensions page. As such, I can't even install Tampermonkey, nor can I install this natively (that is possible, right?).. @Eloston I'm Win10 64-bit. I'd installed all my current extensions with the v54 through chrome-extension-downloader.com, and now it appears I can't.\nUpdate: Interesting -- just tried it again, and it worked... Not sure what could possibly have blocked it. Yesterday, after several attempts, dragging the crx into the extensions tab didn't show the drop-to-install box and, upon release, Chrome would simply re-download the crx file... But it is working now.... @Eloston I didn't try from file explorer, dragged it directly from the download-bar... Something must've been interfering - perhaps a browser restart was the solution, for some weird reason.. The seems like it's going to take some time. I guess I'm okay sticking with 55 for the time being, but if this nobody is able to provide a newer build for WIndows any time soon, is Iridium safe enough to switch to (temporarily)?. Out of curiosity, does the decision to move to Clang help this issue in any way?\nhttps://mspoweruser.com/googles-chrome-ditches-microsofts-compiler-clang-windows/. I see. I\u2019m quite unversed when it comes to much of this, but a bit of insight is always good, so thanks for that. \ud83d\udc4d . ",
    "szepeviktor": "Could this user script be included in ungoogled-chromium?. You may wrap the whole thing in a function to avoid collision with globals.\n. OK-OK, I use JSLint.\n. And I think ungoogled-chromium uses Chromium's data dir as\n[1226/184120:ERROR:process_info.cc(608)] range at 0x5d791cee00000000, size 0x2b2 fully unreadable\n[1226/184120:ERROR:process_info.cc(608)] range at 0x5d791d0e00000000, size 0x2b2 fully unreadable\n[1226/184120:ERROR:process_info.cc(608)] range at 0x0, size 0x2b2 fully unreadable\n[1226/184120:WARNING:in_range_cast.h(38)] value 2965096411020 out of range\n[1226/184120:WARNING:in_range_cast.h(38)] value 2965096411264 out of range\n[1226/184120:WARNING:in_range_cast.h(38)] value 2965096412640 out of range\n[1226/184120:WARNING:in_range_cast.h(38)] value 2965096410250 out of range\n[1226/184120:WARNING:in_range_cast.h(38)] value 2965096418928 out of range\n[1226/184120:WARNING:in_range_cast.h(38)] value 108084205055182070 out of range\n[1226/184120:WARNING:in_range_cast.h(38)] value 2965096581216 out of range\n. *Edits Excuse me I was mixing Google Chrome and Chromium as I am experimenting with 5 browsers.. Then I've realized it is not not easy to distinguish ungoogled-chromium from Chromium.Even the About page is exactly the same chrome://help/ and also its application icon.\nDo you plan to add something different from Chromium?. Thank you for your answer.\nI am not able to build Windows apps, only Linux ones.. Thank you.. chrome://version says\nChromium   55.0.2883.87 (Official Build) (64-bit)\nMaybe you could change it to (ungoogled-chromium build). ",
    "vonagam": "The problem with this userscript is that it uses @require to add jquery while built-in userscript executor in Chromium does not support this directive:\nhttp://www.chromium.org/developers/design-documents/user-scripts\nSo you need Greasemonkey to use it and can't install by simply dragging the file into extenstions.\nHere is the simple modified version without @require, jquery and need for Greasemonkey:\n```js\n// ==UserScript==\n// @name         Get CRX\n// @description  Get crx of extension for Chrome\n// @match        https://chrome.google.com/webstore/detail/*\n// @grant        none\n// ==/UserScript==\nwindow.setTimeout( function () {\nvar href = 'https://clients2.google.com/service/update2/crx?response=redirect&prodversion=48.0&x=id%3D[EXTENSION_ID]%26installsource%3Dondemand%26uc';\nvar id = window.location.href;\nid = id.replace( 'https://chrome.google.com/webstore/detail/', '' );\nid = id.split( '/' )[ 1 ];\nid = id.split( '?' )[ 0 ];\nhref = href.replace( '[EXTENSION_ID]', id );\nvar link = document.createElement( 'a' );\nlink.href = href;\nlink.innerHTML = 'Get CRX';\ndocument.querySelector( 'div.h-e-f-Ra-c.e-f-oh-Md-zb-k' ).appendChild( link );\n}, 4000 );\n```. Yes, it works. I installed fresh setup with brew cask, couldn't install extensions, so went looking into issues, find this script, installed by dragging into extensions, saw errors about jquery, fixed it, and it worked.\nYou click the link, a crx file gets downloaded, which you can drop into extensions. As simple as it intended to be.\nURL manipulation code is from original userscript, i just removed dependency on jquery. Also increased timeout to 4 seconds. Yeah, the script can be impoved a little bit ( to wait until .h-e-f-Ra-c.e-f-oh-Md-zb-k appears instead of timeout, for example ), but it gets job done.. My attempt to improve the script even further beyond:\n1) Uses interval waiting for potential button container to appear.\n2) Uses web store classes for button, so that it appears as official one.\n3) Simplified id retrieval from location.\n```js\n// ==UserScript==\n// @name         Get CRX\n// @description  Download CRX of extension from Chrome Web Store\n// @match        https://chrome.google.com/webstore/detail/*\n// @grant        none\n// ==/UserScript==\nvar HREF_TEMPLATE = 'https://clients2.google.com/service/update2/crx?response=redirect&prodversion=48.0&x=id%3D[EXTENSION_ID]%26installsource%3Dondemand%26uc';\nvar BUTTON_TEMPLATE = 'Download CTX';\nvar CONTAINER_SELECTOR = '.h-e-f-Ra-c.e-f-oh-Md-zb-k';\nvar pathnameParts = window.location.pathname.split( '/' );\nif ( pathnameParts.length !== 5 ) return;\nvar id = pathnameParts[ 4 ];\nvar href = HREF_TEMPLATE.replace( '[EXTENSION_ID]', id );\nvar intervalId = setInterval( function () {\nvar container = document.querySelector( CONTAINER_SELECTOR );\nif ( ! container ) return;\ncontainer.innerHTML = BUTTON_TEMPLATE.replace( '[HREF]', href );\nclearInterval( intervalId );\n}, 500 );\n```. Added handling of links in the search list. \nAlso, now the script never clears an interval, keeps looking for changes.\nPublished on gist:\nhttps://gist.github.com/vonagam/51664e8a43b9f44a7e14be07a7c4d697. @mapx how did you install the user script (by drag-and-dropping file into chrome://extensions/ or through some extension)? do you see any errors in javascript console on webstore page?. @mapx Can you try to install it by downloading user script as a file and drag-dropping it into chrome://extensions/?. Thanks, updated gist of the script with same changes. \n(You have typo in gist in url template: instead of [EXTENSION_ID] there is [EXTENSIONID]). ",
    "mapx": "\nhow does that script work? i don't see any button on store's extension page.\n\nSame issue as @perfect7gentleman mentioned with ungoogled-chromium_55.0.2883.87-1_windows_x64 and the two versions of user scripts.. @WIZARDISHUNGRY Thank you, but as I mentioned above, these two versions of user scripts, including what @vonagam linked, do not work with ungoogled-chromium_55.0.2883.87-1_windows_x64 at present.\nI took your advice and tried again to say so.. @vonagam Thanks!\nIt's installed through Tampermonkey when I clicked the Raw button at your gist page.\nJavascript console on the webstore page (https://chrome.google.com/webstore/category/extensions) only shows the following irrelevant error:\nGET https://ssl.google-analytics.com/ga.js net::ERR_BLOCKED_BY_CLIENT\nOn the extensions page, all extensions are marked as \"Not from Chrome Web Store.\". I disabled Tampermonkey, did what you told me, and saw the same things on webstore and extensions pages.. ",
    "WIZARDISHUNGRY": "@perfect7gentleman @mapx Use the gist @vonagam linked.. @Eloston the \"Downloads for the latest release\" link in README.md points to https://github.com/Eloston/ungoogled-chromium/releases/tag/55.0.2883.87-1 . ",
    "Tank-Missile": "Looks like the link is dead. ):. This is where altnerative services come in. For bookmarks, you can use Floccus with a nextcloud instance or provider, or xBrowserSync. For passwords, you can sync a KeePassXC database using the nextcloud client along with the browser extension. As for syncing extensions, history, and settings... Yeah I got nothing there at the moment.. The problem is this is a \"hobbyist\" project according to @Eloston, and people who do these types of projects tend to have other things going on in their lives. It all comes down to reporting issues, and awaiting responses. If it takes a month, so be it. If I had more knowledge on chromium's source code I would definitely pitch in, but the most I can do right now is just report issues and wait. If you ask me, the browser is safer outdated with google integration removed than updated with it.. I've been using it for the last several months with no issues. It seems there is an official build for Arch Linux, but the the AUR package doesn't appear to be using it yet. Right now it's downloading the binary from https://cloud.woelkli.com/. According to the user hosting it there, he says you just have to trust him. The best move at this point would be for the packager to change the source URL, since fishy looking links like that may deter people from using it. It's up to you if you want to use it.. ",
    "pwindle": "The current chrome version from the user agent string:\n/Chrome\\/([0-9.]+)/.exec(navigator.userAgent)[1]\nHopefully with that we can make get something working that doesn't need updating so often. Here's some stuff:\nBookmarklet\nSave the following line of code as a bookmark and click it from any extension details page on chrome web store to download its crx. I prefer this solution to adding a search engine as suggested in the FAQ.\n(SOURCE without the url formatting) \njavascript:(function()%7Bwindow.location.href%3D%22https%3A%2F%2Fclients2.google.com%2Fservice%2Fupdate2%2Fcrx%3Fresponse%3Dredirect%26acceptformat%3Dcrx2%2Ccrx3%26prodversion%3D%22%2B%2FChrome%5C%2F(%5B0-9.%5D%2B)%2F.exec(navigator.userAgent)%5B1%5D%2B%22%26x%3Did%253D%22%2B%2F%5Ehttps%3A%5C%2F%5C%2Fchrome.google.com%5C%2Fwebstore%5C%2Fdetail%5C%2F.%2B%5C%2F(%5Ba-z%5D%2B)%2F.exec(window.location.href)%5B1%5D%2B%22%2526installsource%253Dondemand%2526uc%22%7D)()\nScript\nHERE is an update of the script by @vonagam. It wasn't working for search results page. Also added the newer url, updated button style, and it gets chrome version from user agent string (and I just had to remove the line spacing to read it, sorry!).\nThe issue seemed to be google adjusted the layout of the html slightly. This script may be quite sensitive to that. \n. @miklide You're right. I had an extra bracket at the end. Oops! Remove the last bracket or copy this:\njavascript:(function()%7Bwindow.location.href%3D%22https%3A%2F%2Fclients2.google.com%2Fservice%2Fupdate2%2Fcrx%3Fresponse%3Dredirect%26acceptformat%3Dcrx2%2Ccrx3%26prodversion%3D%22%2B%2FChrome%5C%2F(%5B0-9.%5D%2B)%2F.exec(navigator.userAgent)%5B1%5D%2B%22%26x%3Did%253D%22%2B%2F%5Ehttps%3A%5C%2F%5C%2Fchrome.google.com%5C%2Fwebstore%5C%2Fdetail%5C%2F.%2B%5C%2F(%5Ba-z%5D%2B)%2F.exec(window.location.href)%5B1%5D%2B%22%2526installsource%253Dondemand%2526uc%22%7D)(). ",
    "miklide": "\nThe current chrome version from the user agent string:\n(function()%7Bwindow.location.href%3D%22https%3A%2F%2Fclients2.google.com%2Fservice%2Fupdate2%2Fcrx%3Fresponse%3Dredirect%26acceptformat%3Dcrx2%2Ccrx3%26prodversion%3D%22%2B%2FChrome%5C%2F(%5B0-9.%5D%2B)%2F.exec(navigator.userAgent)%5B1%5D%2B%22%26x%3Did%253D%22%2B%2F%5Ehttps%3A%5C%2F%5C%2Fchrome.google.com%5C%2Fwebstore%5C%2Fdetail%5C%2F.%2B%5C%2F(%5Ba-z%5D%2B)%2F.exec(window.location.href)%5B1%5D%2B%22%2526installsource%253Dondemand%2526uc%22%7D)())\n\nBookmarklet does not seem to work for me. When I press it, nothing happens:\n\nungoogled chromium windows x64  v67.0.3396.87\n. ",
    "JamesBedwell": "I too would like to know the security implications of this.. ",
    "strangefreeworld": "I am trying to install this on Linux Mint 18 (based on Ubuntu 16.04).  When I try to install it (via gdebi), I get the following message:\nThis package is uninstallable\nDependency is not satisfiable: libavcodec57 (>= 7:3.2.1)|libavcodec-extra57 (>= 7:3.2.1)\nWhen I try to install chromedriver, I get the following message:\nThis package is uninstallable\nDependency is not satisfiable: libicu57 (>= 57.1-1~). Yes I did that.  My bad.. ",
    "pr0ggy": "Looks like the .deb file links for Ubuntu 16.04 in the comment above are broken. No problem at all, appreciate the work you all are putting into this project!. Awesome, thanks again!. 7:2.8.11-0ubuntu0.16.04.1. After running the above commands, the package installs correctly, but any attempt to navigate results in this error. Negative, native install. No problem at all...let me know if there's anything I can do to help, will do what I can. Yes, GTX1060. Using NVidia driver 367.57. Awesome, I can just wait for the new binaries...thanks again!. ",
    "stefson": "I'm interested to hear if you managed to write a step by step guide as proposed? :) . if you can please provide this draft, I'll have a look into it. . Well, I certainly don't agree to your style of bypassing the package manager, so I'd rather build a deb package for every single dependency which needs an upgrade to compile with recent chromium. The way the here hosted build scripts work seems to be different from what I learned to be \"the debian way\", going via the fakeroot debian/rules method. \nWhere can I find these sort of presets, usually found in $package-name.debian.tar.xz, for your project? All information I could find in your git tree are about the build dependencies and their respective names on ubuntu? \nI would like to build dynamically linked binaries for ubuntu-14.04 for my chromebook, which is an arm device, and has not more than 512mb of ram. So I will end up compiling via a qemu-static chroot where I set up and upgraded all the build dependencies beforehand - if I make it to overcome all the obstacles I'll try to provide patches etc. pp. back here. . - in order to work with utilikit, you'll need a working python3.5? \n- utilikit will generate the build scripts for the user, depending upon which value of ressources/config gets activated via export UTILIKIT_CONFIG_TYPE, correct? If so, it would be the best idea to create a prefix for trusty. \n\nis anyone able to download the sources of chromium-57.0.2987.133.tar.xz via the prepare_sources.py script? . for the UTILKIT* variables UTILIKIT_CONFIG_TYPE , UTILIKIT_RESOURCES , UTILIKIT_DOWNLOAD_DIR , UTIL_SANDBOX_DIR it seems to be mandantory to export their absolute paths (?), even though they are in the place they intended to be. \n\ndoes the download work for other users? I know that I can copy over the tar.xz archive into the right place where it gets recognized, but I can't download via the scripts. Is this a bug? \nis ninja or ninja-build a dependency for building chromium? \ndpkg-checkbuilddeps says ninja-build, the Building.md file says ninja . There is a PPA with python3.5 for trusty, to make utilikit working! It doesn't really with python3.4. No port for arm unfortunately, maybe I can ask for it. \nhttps://launchpad.net/~fkrull/+archive/ubuntu/deadsnakes \nI also found informations about how to setup a PPA fairly easy, I may try to config one to satisfy the build dependencies. Regarding libminizip-dev, it obviously can be taken from xenial without breaking the system.\nhttps://opensourcehacker.com/2013/03/20/how-to-backport-packages-on-ubuntu-linux/ \nThe libvpx dependency might be tricky, gentoo for instance doesn't allow a build against system-libvpx for >57 at the moment, and my guess is there will be a reason for it. ffmpeg-3.2 seems to be mandatory.\nBut tell me, what is the benefit of this project compared to the upstream chromium provided by ubuntu-security channel? I thought it was that ubuntu-security links statical, and this project links dynamical - but pointing on /usr/lib/chromium/chromium of the ubuntu-security build via file or ldd command shows that it is dynamically linked without a doubt. \nIs it the patchset and some of the build options which you seem to alter? . Can you please provide me with the output of ldd and file of the chromium binary, so that I can compare it to my gentoo build which is, in my believe, 100% dynamically linked?. nevermind, I'll download the binaries from here to check them on my own. I can't continue with my efforts at the moment because there is no arm backport of python-3.5 for trusty available. If this ever will be available I'll try to go on with working this out. Keep the thread on subscribed, so please ping me if there is something of interest. . I asked the guy from the ppa for an arm backport via email, to no response. \nDon't think it is a reasonable idea to copy over the prepared build sandbox from my main amd64 machine into an arm environement, 100% dynamic building is not possible anyway, see - https://bugs.chromium.org/p/chromium/issues/detail?id=697843. I can't imagine it would work. Maybe it does, but don't care at the moment due to #697843 and other issues ahead. . ",
    "fredd727": "good, so that might be a easy fix then! I only use firefox for browsing and chromium (UGC) for streaming and webapps so i dont have a chrome install, but let me know if i can be of any help. ",
    "leso-kn": "I'll drop this comment to give back some attention to this topic.\nWhat exactly is the issue with the chromecast functionality? Does it require proprietary libraries from google?\n@nopjmp @Eloston Chromecast v1 works via ssdp and CC v2 via mdns and websockets using the ipc and 'casts'-protocol. It doesn't require connecting to google servers.\nThe receiver part is quite complicated and not really documented, as google want's to give their technology only to certified device manufacturers. Whereas the sender part is quite well documented and widely implemented (see e.g. Node Cast v2)\n@Eloston Would you mind referencing the concerning sections of the code here? I'm very busy at the moment but i'd like to take a look. @Eloston I don't think there's any real privacy issue :) Service discovery could only be a privacy issue if information about discovered devices is sent somewhere, which it of cause wouldn't be in case of ungoogled-chromium.\nEnabling the features would i guess bring back chromecast functionality, as, as far as i can see, all other components required for it to work are present. Yes, but that goes for the receiver only. The sender only sends an mDNS request and connects to found devices via websockets to provide the cast functionality. I don't concider this a privacy issue. That's a good idea! Do you think there's a way to sort of switch the no-mDNS patch on and off via a command line arg or config flag? . Arround Christmas i might actually find time to have a look at the code. I'll try to figure out a useful place for the switch to put at.\nUnfortunately i didn't manage to compile chromium myself, i tried it serval times a while ago. \nMaybe you could release a test build with mDNS enabled to see if enabling it is already sufficient for chromecast?\nI'd be up for testing it, my television supports chromecast . Short answer: Linux\nLong answer: My main machine is currently still on Ubuntu 16.04. But any debian compatible package is fine, i guess for testing i'd prefer the linux portable build. And sure! I'll submit a PR with a patch file if i get this far :) . Alright, merry chistmas afterwards!\nToday i had a look at the concerning code. I went for a very basic approach now, wrapping all relevant mDNS and service discovery related code into if conditions, that i control via a flag.\nPlease note, that as i mentioned earlier i didn't have the opportunity to test the changes myself. Thus i will not commit a PR yet, but attached to this post you'll find a patch file containing the changes.\npatch.zip\nPlease note, that this patch replaces the prevous patch 'fix-building-without-mdns-and-service-discovery.patch' inside /patches/ungoogled-chromium, so you'll need to delete that one.\nI'd be glad if you could test it @Eloston :) If it works i'll submit a PR containing the patch file and removal of the old patch. Hey! Forgive me if i didn't get everything right, i'm extremely tired today.\nI'll start off question by question:\n\nDoes the flag toggle broadcasts in #436?\n\nI'd say yes. As i didn't test it i'm not completely sure of cause, but i think the every two minute broadcast are most likely mdns requests and therefor affected by the patch.\n\nHow will Chromium's behavior change with the flag toggled on and off?\n\nAs far as i know chromium only uses discovery on the local network for chromecast and cloud print functionality. The patch will probably bring back the mentioned every two minute broadcasts, though i don't think it's used for anything more than printer and chromecast discovery.\nBtw, did anyone @ #436 have a look at those packets? It's very unlikely that packages used for udp based discovery are encrypted in any way and i'm sure it would turn out to be just mdns requests addressing printers or something\nTip: mdns traffic can be efficiently tracked and displayed as json by writing a small nodejs program using multicast-dns\n\nWhat code is affected by the GN flags for mDNS and Service Discovery?\n\nI don't know if i got the question right; the patch doesn't add a GN flag, it adds a chrome://flags flag and a command line argument for chromium.\n\nHow will the current patch address any privacy/security concerns related to code that will be enabled?\n\nAs i just said, i don't think there are any privacy issues with browsing the local network, as (as far as i can see) ungoogled-chromium blocks any internal requests to the google servers.\nThus i assume this data couldn't possibly be published anywhere and the data will probably even turn out to only be what chromecast devices you have in your house and what printers you have arround.\n\nIn line 42 of the patch file, you define a function inside another function\n\nYou're absolutely right! Perhaps i have rushed threw this a bit, here's a new version of the patch:\npatch (patched).zip\nI also made ShouldEnableDiscovery() a private member function.\n\nAlso, will the command line flag be guarenteed to be read (in ::Discover()) before any other function is invoked in DnsSdDeviceLister?\n\nYes, pretty sure!\nThe only other methods related code is invoked in are callbacks resulting from the discovery and a reset method related to discovery. Everything happens inside a single, nicely assessable file and the patch only enables code that had been disabled by a single patch before.\n\n[\u2026] you could define a new instance variable in the constructor of DnsSdDeviceLister\n\nYes! The new version of the patch contains the changes.\n\nPlease tell me if anything's missing, tomorrow I'll probably also provide a concerning nodejs script for #436. > Will it only bring it back if the flag is enabled?\nYes, as discovery can only be done if the flag is enabled\n\nYes, but the patch should address any other code changes that result from changing the GN flags for mDNS and Service Discovery back to their default values (i.e. enabled)\n\nOh! I think there was a missunderstanding from my side. I didn't know there's also GN flags, sorry about that! Of cause we'll have to include those in the patch and check whether it enables any unwanted behaviour.\n\nit is the act of broadcasting itself that is the issue\n\nokay. Then we'll have to make sure there's really no broadcasting if the flag's disabled. I think the easiest solution may be to prepare a prototype patch, compile it and check if any broadcasting is happening.\n\nAre [users of DnsSdDeviceLister] guarenteed to call ::Discover() first?\n\nAs i said, i'm sure that it is. If you want we can also adjust the patch to call ShouldEnableDiscovery every time. I was going to put the cache variable in order to keep the performance at best level, but in that case there's practically not really a situation where that plays a major role.\nAbout the new patch:\n\nthe scenario you described in the code comment is not possible.\n\nokay, that's right. Even better then! Then technically we may even put the function call in the constructor of DnsSdDeviceLister.\n\nOn line 57 [\u2026] This is still not valid C++\n\nYep, sorry about that, i forgot the brackets. As i said, i didn't compile it\n\nOn line 24, you do not need to add ShouldEnableDiscovery to the header file.\n\nIf you prefer so, sure! I think it's a preference thing but yep, definitely possible.. Facing the future of this issue: Do you want me to write a propper patch, or would you prefer writing the final version yourself?\nAs i said, it's only been a little time arround christmas and work will start again soon, so it may take me some time till i can continue (in a more propper way than before, sorry about all those small mistakes).\nI'd still be up for sitting down at some point, checking out the whole chromium sourcecode (till now i only checked out the files i needed) and having a propper overview about what's going on and what needs to be done for writing a clean patch.. Thanks a lot! :+1: . ",
    "ian-moone": "Chromecast is made specifically to be an open device that can be easily be used by anyone on the network. Hence ... No privacy\n\ud83d\udc49 https://www.reddit.com/r/Chromecast/comments/79bk34/i_know_pretty_much_nothing_about_chromecasts/dp0nsot/. > It is a good idea to disable expliclitly chrome://flags/#enable-quic because QUIC is UDP and Tor socks proxy works only on TCP.\nNo, it is not. Enabling QUIC does not conflict with TCP/SOCKS5, so it continues to work as usual.. > The point is: When one uses Tor one doesn't want to \"work as usual\" (i.e. having non-torified connections).\nSo you are saying that if I happen to visit a QUIC-enabled server, it will bypass SOCKS5 and use QUIC as preferred protocol? If so, do you have a source?. I'm making one for my overlay. You can follow the issue tracker here. I hope to have a working ebuild in a few days.. I'm happy to announce that we have an ebuild that strictly follows ungoogled-chromium's GN flags. However, I haven't tested all USE flags, the issue tracker (link above) has a detailed list of which ones need to be tested. Enjoy!. www-client/ungoogled-chromium-bin is available now, which uses the binaries published by @intika.. > Do not agree.\nI hope it's just you. Based on the commit history in your repo, all your ebuilds should be renamed to *-9999.. We have a proper 70.0.3538.67_pre* ebuild available now. Have fun!. > Nice job on the patches and new USE flags!\nThank you.\n\nWhy not change installation directories and binary name so you can keep Chromium installed at the same time? Since this is a fork, it also makes more sense to rename the binary to the name of the fork.\n\nYeah, I really thought about that, and almost followed that path, but then after I read the README, it states, \"Unlike other Chromium forks that have their own visions of a web browser, ungoogled-chromium is essentially a drop-in replacement for Chromium\", and seeing how ungoogled-chromium is distributed for other distros, I decided to not divert from them.\nHowever, I don't mind to maintain an USE flag (chromium-compat ?!), that would let the user install it with vanilla chromium, but I'm not willing to test it myself. If anyone is interested in this, I will ask that person to help me.\n\nAlso, is \"!<\" any different from the established \">=\" in RDEPEND?\n\nYes, using >= makes it dependent on >=x11-drivers/nvidia-drivers-331.20. !< just block it, not necessarily depend on it.. Regarding the install compatibility with vanilla www-client/chromium, I decided that I will be adding the USE flag chromium-compat (disabled by default, of course) in near future. There's an issue tracker for those who want to contribute.. > 1. Considering the above - what should I actually do?\nAs your system supports namespaces, then there's nothing to do about it.\n\n\nWhy is all this namespace business important and why not simply run chrome? (please ELI5)\n\n\nIt's not an ELI5, but I'm sure you'll understand the summary: https://chromium.googlesource.com/chromium/src/+/lkgr/docs/linux_sandboxing.md. > Does that mean I should simply run chrome and not worry about any other executables?\nYes.\nFrom the link above:\n\nYou can see which sandboxes are currently engaged by looking at chrome://sandbox (renderer processes) and chrome://gpu (gpu process).. > chrome://sandbox/ is telling me 'No' for SUID Sandbox and 'Yama LSM Enforcing'.\n\nThose are just alternative modes that should be used when namespaces aren't available.\n\nchrome://gpu/ shows Sandboxed: false and in its Log Messages I read:\n\nI need to investigate this further. I'm also getting that first line in your log.. > I've also been getting that error for many versions now (at least with the Debian builds).\nYeah, I've seen that error way back, like ~62.x, but tbh, I never gave the proper attention to it.\nAlso, that error seems more common than I thought, it has been a bit hard get any useful information. There are many bug reports, but they always seems to be just co-related to it.\n. > i personally use http://crxextractor.com/ to install extensions\nIt doesn't work if you try to download the aforementioned extension. It gives a blank page, at least for me.. Did you try to download the aforementioned extension?!. I looked at the link you provided, and I ended up installing Chrome extension source viewer, but it suffer from the same issues.\nThere's also an online version: https://robwu.nl/crxviewer/. @Rob--W was kind enough to quick fix the ref. issue above, and update his documentation at https://stackoverflow.com/a/14099762\n\n(New in 2018) acceptformat=crx2,crx3 instructs the server to also respond with extensions in the CRX3 format (instead of 204 No Content when the extension is not available as CRX2).. You should emerge x11-libs/libva. But the proper way is to enable the USE flag vaapi globally. See https://wiki.gentoo.org/wiki/VAAPI. On my gentoo box ldd chrome says:\n\nlinux-vdso.so.1 (0x00007fff5ff4b000)\n        libdl.so.2 => /lib64/libdl.so.2 (0x00007f69b1f88000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f69b1d68000)\n        librt.so.1 => /lib64/librt.so.1 (0x00007f69b1b60000)\n        libX11.so.6 => /usr/lib64/libX11.so.6 (0x00007f69b1800000)\n        libX11-xcb.so.1 => /usr/lib64/libX11-xcb.so.1 (0x00007f69b15f8000)\n        libxcb.so.1 => /usr/lib64/libxcb.so.1 (0x00007f69b13c8000)\n        libXcomposite.so.1 => /usr/lib64/libXcomposite.so.1 (0x00007f69b11c0000)\n        libXcursor.so.1 => /usr/lib64/libXcursor.so.1 (0x00007f69b0fb0000)\n        libXdamage.so.1 => /usr/lib64/libXdamage.so.1 (0x00007f69b0da8000)\n        libXext.so.6 => /usr/lib64/libXext.so.6 (0x00007f69b0b90000)\n        libXfixes.so.3 => /usr/lib64/libXfixes.so.3 (0x00007f69b0988000)\n        libXi.so.6 => /usr/lib64/libXi.so.6 (0x00007f69b0778000)\n        libXrender.so.1 => /usr/lib64/libXrender.so.1 (0x00007f69b0568000)\n        libXtst.so.6 => /usr/lib64/libXtst.so.6 (0x00007f69b0360000)\n        libgmodule-2.0.so.0 => /usr/lib64/libgmodule-2.0.so.0 (0x00007f69b0158000)\n        libgobject-2.0.so.0 => /usr/lib64/libgobject-2.0.so.0 (0x00007f69afef8000)\n        libgthread-2.0.so.0 => /usr/lib64/libgthread-2.0.so.0 (0x00007f69afcf0000)\n        libglib-2.0.so.0 => /usr/lib64/libglib-2.0.so.0 (0x00007f69af9a0000)\n        libsmime3.so => /usr/lib64/libsmime3.so (0x00007f69af778000)\n        libnss3.so => /usr/lib64/libnss3.so (0x00007f69af448000)\n        libnssutil3.so => /usr/lib64/libnssutil3.so (0x00007f69af218000)\n        libplds4.so => /usr/lib64/libplds4.so (0x00007f69af010000)\n        libplc4.so => /usr/lib64/libplc4.so (0x00007f69aee08000)\n        libnspr4.so => /usr/lib64/libnspr4.so (0x00007f69aebc8000)\n        libva.so.2 => /usr/lib64/libva.so.2 (0x00007f69ae9a0000)\n        libcups.so.2 => /usr/lib64/libcups.so.2 (0x00007f69ae700000)\n        libexpat.so.1 => /usr/lib64/libexpat.so.1 (0x00007f69ae4c8000)\n        libdbus-1.so.3 => /usr/lib64/libdbus-1.so.3 (0x00007f69ae270000)\n        libatomic.so.1 => /usr/lib/gcc/x86_64-pc-linux-gnu/8.2.0/libatomic.so.1 (0x00007f69ae068000)\n        libresolv.so.2 => /lib64/libresolv.so.2 (0x00007f69ade50000)\n        libgio-2.0.so.0 => /usr/lib64/libgio-2.0.so.0 (0x00007f69ada58000)\n        libuuid.so.1 => /lib64/libuuid.so.1 (0x00007f69ad850000)\n        libXrandr.so.2 => /usr/lib64/libXrandr.so.2 (0x00007f69ad640000)\n        libpci.so.3 => /usr/lib64/libpci.so.3 (0x00007f69ad430000)\n        libXss.so.1 => /usr/lib64/libXss.so.1 (0x00007f69ad228000)\n        libasound.so.2 => /usr/lib64/libasound.so.2 (0x00007f69acf48000)\n        libm.so.6 => /lib64/libm.so.6 (0x00007f69acc68000)\n        libz.so.1 => /lib64/libz.so.1 (0x00007f69aca40000)\n        libpangocairo-1.0.so.0 => /usr/lib64/libpangocairo-1.0.so.0 (0x00007f69ac830000)\n        libpango-1.0.so.0 => /usr/lib64/libpango-1.0.so.0 (0x00007f69ac5d8000)\n        libcairo.so.2 => /usr/lib64/libcairo.so.2 (0x00007f69ac250000)\n        libatk-1.0.so.0 => /usr/lib64/libatk-1.0.so.0 (0x00007f69ac020000)\n        libatk-bridge-2.0.so.0 => /usr/lib64/libatk-bridge-2.0.so.0 (0x00007f69abde8000)\n        libgtk-3.so.0 => /usr/lib64/libgtk-3.so.0 (0x00007f69ab3c0000)\n        libgdk-3.so.0 => /usr/lib64/libgdk-3.so.0 (0x00007f69ab0e8000)\n        libcairo-gobject.so.2 => /usr/lib64/libcairo-gobject.so.2 (0x00007f69aaed8000)\n        libgdk_pixbuf-2.0.so.0 => /usr/lib64/libgdk_pixbuf-2.0.so.0 (0x00007f69aaca8000)\n        libgcc_s.so.1 => /usr/lib/gcc/x86_64-pc-linux-gnu/8.2.0/libgcc_s.so.1 (0x00007f69aaa90000)\n        libc.so.6 => /lib64/libc.so.6 (0x00007f69aa700000)\n        /lib64/ld-linux-x86-64.so.2 (0x00007f69ba460000)\n        libXau.so.6 => /usr/lib64/libXau.so.6 (0x00007f69aa4f8000)\n        libXdmcp.so.6 => /usr/lib64/libXdmcp.so.6 (0x00007f69aa2f0000)\n        libffi.so.6 => /usr/lib64/libffi.so.6 (0x00007f69aa0e8000)\n        libpcre.so.1 => /lib64/libpcre.so.1 (0x00007f69a9e70000)\n        libgnutls.so.30 => /usr/lib64/libgnutls.so.30 (0x00007f69a9b30000)\n        libmount.so.1 => /lib64/libmount.so.1 (0x00007f69a98c8000)\n        libudev.so.1 => /lib64/libudev.so.1 (0x00007f69a9698000)\n        libpangoft2-1.0.so.0 => /usr/lib64/libpangoft2-1.0.so.0 (0x00007f69a9480000)\n        libfribidi.so.0 => /usr/lib64/libfribidi.so.0 (0x00007f69a9260000)\n        libharfbuzz.so.0 => /usr/lib64/libharfbuzz.so.0 (0x00007f69a8f98000)\n        libfontconfig.so.1 => /usr/lib64/libfontconfig.so.1 (0x00007f69a8d38000)\n        libfreetype.so.6 => /usr/lib64/libfreetype.so.6 (0x00007f69a8a78000)\n        libpixman-1.so.0 => /usr/lib64/libpixman-1.so.0 (0x00007f69a87c8000)\n        libEGL.so.1 => /usr/lib64/libEGL.so.1 (0x00007f69a8588000)\n        libpng16.so.16 => /usr/lib64/libpng16.so.16 (0x00007f69a8348000)\n        libxcb-shm.so.0 => /usr/lib64/libxcb-shm.so.0 (0x00007f69a8140000)\n        libxcb-render.so.0 => /usr/lib64/libxcb-render.so.0 (0x00007f69a7f30000)\n        libGL.so.1 => /usr/lib64/libGL.so.1 (0x00007f69a7cb0000)\n        libatspi.so.0 => /usr/lib64/libatspi.so.0 (0x00007f69a7a70000)\n        libepoxy.so.0 => /usr/lib64/libepoxy.so.0 (0x00007f69a7788000)\n        libbsd.so.0 => /usr/lib64/libbsd.so.0 (0x00007f69a7568000)\n        libidn2.so.0 => /usr/lib64/libidn2.so.0 (0x00007f69a7348000)\n        libunistring.so.2 => /usr/lib64/libunistring.so.2 (0x00007f69a6fc8000)\n        libtasn1.so.6 => /usr/lib64/libtasn1.so.6 (0x00007f69a6db0000)\n        libnettle.so.6 => /usr/lib64/libnettle.so.6 (0x00007f69a6b70000)\n        libhogweed.so.4 => /usr/lib64/libhogweed.so.4 (0x00007f69a6938000)\n        libgmp.so.10 => /usr/lib64/libgmp.so.10 (0x00007f69a66b8000)\n        libblkid.so.1 => /lib64/libblkid.so.1 (0x00007f69a6460000)\n        libgraphite2.so.3 => /usr/lib64/libgraphite2.so.3 (0x00007f69a6230000)\n        libbz2.so.1 => /lib64/libbz2.so.1 (0x00007f69a6018000)\n        libgbm.so.1 => /usr/lib64/libgbm.so.1 (0x00007f69a5e08000)\n        libglapi.so.0 => /usr/lib64/libglapi.so.0 (0x00007f69a5bd0000)\n        libxcb-dri2.so.0 => /usr/lib64/libxcb-dri2.so.0 (0x00007f69a59c8000)\n        libxcb-xfixes.so.0 => /usr/lib64/libxcb-xfixes.so.0 (0x00007f69a57c0000)\n        libdrm.so.2 => /usr/lib64/libdrm.so.2 (0x00007f69a55a8000)\n        libwayland-client.so.0 => /usr/lib64/libwayland-client.so.0 (0x00007f69a5390000)\n        libwayland-server.so.0 => /usr/lib64/libwayland-server.so.0 (0x00007f69a5178000)\n        libxcb-dri3.so.0 => /usr/lib64/libxcb-dri3.so.0 (0x00007f69a4f70000)\n        libxcb-present.so.0 => /usr/lib64/libxcb-present.so.0 (0x00007f69a4d68000)\n        libxcb-sync.so.1 => /usr/lib64/libxcb-sync.so.1 (0x00007f69a4b60000)\n        libxshmfence.so.1 => /usr/lib64/libxshmfence.so.1 (0x00007f69a4958000)\n        libxcb-glx.so.0 => /usr/lib64/libxcb-glx.so.0 (0x00007f69a4738000). > I noticed then that x11-libs/libva was already installed\nThen upgrade to >= 2.1.0\n\n(along with libva-intel-driver and another libva package, but note that my system has AMD graphics)\n\nI think libva-intel-driver was pulled by VIDEO_CARDS=\"i965 intel\" try to disable those flags.. Duplicate of https://github.com/Eloston/ungoogled-chromium/issues/525. Duplicate of https://github.com/Eloston/ungoogled-chromium/issues/525. Alternatively you can sed-fix the gn_flags.map file located in config_bundles/common/.\nAdd this into prepare(), close to the other sed there.\nshell\nsed -i -E 's/(is_debug=)[a-z]+/\\1true/' ${_config_bundle/archlinux/common}/gn_flags.map. > I found is_official_build = false on line 131, but the failed assertion suggests that is_official_build = true.\nHm... Ok, then try this one:\nshell\nsed -i -E \\\n    -e 's/(is_debug=)[a-z]+/\\1true/' \\\n    -e 's/(is_official_build=)[a-z]+/\\1false/' \\\n     ${_config_bundle/archlinux/common}/gn_flags.map\n. > _I found a pretty strange url on extension page.\n\n...\nI cannot install extensions from Chrome extension store._\n\nPlease see https://ungoogled-software.github.io/ungoogled-chromium-wiki/faq \n. ~~Not really. There's no . after !.~~ \ud83d\ude2a . @jlj2 You'll better off with one of those ungoogled-chromium* ebuilds.\nThe non-bin version is ccache friendly, so I recommend to enable it.. > As users are advised to become more cautious about whether to trust sources, binaries, etc., users should be able to understand and check what is downloaded before running it.\n\ud83d\udc4d \n\nHow ${PN} is defined is not clear to me.\n\nIt's a standard variable in portage build system.\n\nAlso, please explain your strapline, 'The cancer is coming!'\n\nWell that's a bit off-topic. Anyways, it's just a sarcastic expression to reference Microsoft's GitHub acquisition.. > If those variations could be explained, it would help, but this is not a forum to dwell into them.\nIt's easy to explain. The ebuild uses the tagged/released tarball. In this case, the commit 009c8e19255a8a0255ec0be40eb4872471318463 is 69.0.3497.100-2. The master zip archive contains the latest changes, so naturally won't be the same.\nSince the last tagged version (69.0.3497.100-2), the master branch has the  following changes https://github.com/Eloston/ungoogled-chromium/compare/009c8e19255a8a0255ec0be40eb4872471318463...2ce08944aebdb704c1cd66e2515f6d2cf32c2d88, which certainly will match your diff above.\nEdit: I just noticed that you tagged the wrong person. Sorry about that, Mr. Ian Moore.. I've found the relevant commit: https://chromium.googlesource.com/chromium/src/+/515acc1a65c80e373be42fa49a51683b5374043e. use_gtk3 too: https://chromium.googlesource.com/chromium/src/+/287339e07364162daa8fd6f90ef1d2338f32bed5. More or less duplicate of https://github.com/ungoogled-software/ungoogled-chromium-binaries/issues/30. > Could you explain what your choice of use_gold=false with use_lld=true does?\nOh, sorry for my poor explanation. Because it's not possible to use both linker at the same time. lld is the preferred linker to use with is_clang. The logic is defined in build/config/compiler/compiler.gni. \n```\ndeclare_args() {\n  # Set to true to use lld, the LLVM linker. This flag may be used on Windows,\n  # Linux or Fuchsia.\n  # TODO(pcc): Enable lld on more architectures on Linux. E.g. we probably need\n  # to fix some of crbug.com/742655 to enable it on ARM.\n  use_lld =\n      is_clang &&\n      (is_win || is_fuchsia || (use_thin_lto && target_os != \"chromeos\") ||\n       (is_linux && current_cpu == \"x64\" && target_os != \"chromeos\") ||\n       (is_android && (current_cpu != \"arm\" || arm_version >= 7) &&\n        current_cpu != \"mipsel\" && current_cpu != \"mips64el\"))\n}\ndeclare_args() {\n  # Whether to use the gold linker from binutils instead of lld or bfd.\n  use_gold = !use_lld && !(is_chromecast && is_linux &&\n                           (current_cpu == \"arm\" || current_cpu == \"mipsel\")) &&\n             ((is_linux && (current_cpu == \"x64\" || current_cpu == \"x86\" ||\n                            current_cpu == \"arm\" || current_cpu == \"mipsel\" ||\n                            current_cpu == \"mips64el\")) ||\n              (is_android && (current_cpu == \"x86\" || current_cpu == \"x64\" ||\n                              current_cpu == \"arm\" || current_cpu == \"arm64\")))\n}\n```\nWe could even remove both lines, as long as is_clang is true.. > with suggestion to update the latest linux kernel to use sandbox.\nRegarding that issue, your kernel seems to be lacking support for namespaces or Yama. If you don't want to dive into that, you need to setup a SUID sandbox.. I got a similar report a few weeks ago. The solution seems to either create a symlink or pass the environment variable EXTRA_GN=\"clang_use_default_sample_profile=false is_cfi=false\". Personally, I don't recommend the latter.. I'm not sure, but if I have to guess, this isn't Chromium's fault (or something that should be defined by it), but it's the Clang/LLVM that is not properly configured.\n\nAssuming that this is CFI, if you're using a custom build of Clang it's possible that your LLVM build tree does not have a copy of the cfi_blacklist.txt file (its absence would cause a number of binaries to fail like that). To copy it into place you can try building the cfi_blackilst target in LLVM, cleaning your Chromium build tree and rebuilding. - source\n\nHere is a blog post that also mention the GN flags I commented earlier.\nA side note, the user that reported similar issue, uses same distro as mine and likewise, used the same ebuild, that's why I think he borked his Clang/LLVM somewhere, because so far I haven't experienced that issue. . > with what flags have you llvm/clang compiled ?\n```\nsys-devel/llvm-7.0.0-r1::gentoo was built with the following:\nUSE=\"gold libffi ncurses xml -debug -doc -exegesis -libedit -test -xar\" LLVM_TARGETS=\"AMDGPU BPF (X86) -AArch64 -ARM -Hexagon -Lanai -MSP430 -Mips -NVPTX -PowerPC -Sparc -SystemZ -XCore\"\nCFLAGS=\"-O3 -march=native -pipe\"\nCXXFLAGS=\"-O3 -march=native -pipe -stdlib=libc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -Wl,--icf=all -fuse-ld=lld -rtlib=compiler-rt -lc++abi\"\nsys-devel/clang-7.0.0::gentoo was built with the following:\nUSE=\"static-analyzer xml -debug -default-compiler-rt -default-libcxx -doc -test (-z3)\" LLVM_TARGETS=\"AMDGPU BPF (X86) -AArch64 -ARM -Hexagon -Lanai -MSP430 -Mips -NVPTX -PowerPC -Sparc -SystemZ -XCore\" PYTHON_TARGETS=\"python2_7\"\nCFLAGS=\"-O3 -march=native -pipe\"\nCXXFLAGS=\"-O3 -march=native -pipe -stdlib=libc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -Wl,--icf=all -fuse-ld=lld -rtlib=compiler-rt -lc++abi\"\n```. > I think that USE=static-analyzer makes use of cfi possible.\nHmm. I'm not so sure. Anyways, this page gives more insight about it: https://clang.llvm.org/docs/ControlFlowIntegrity.html\nEdit: Do you have sys-libs/compiler-rt-sanitizers installed? It is pulled by sys-devel/clang-runtime[sanitize], which has the following description \"Enable compiler-rt sanitizer (-fsanitize*) support\".. Please try it and report back. Perhaps that's the culprit.\n\nwhat do you have there?\n\nUSE=\"compiler-rt libcxx openmp sanitize -crt\"\n. Then do a symlink, as a temporary workaround, like the OP did. Could be a bug in the packaging. IMO, it's much better than disabling cfi altogether, giving the fact that -lto will be used anyway.. > There is no such file in the system.\nI have it, in the exact path you pointed out. But the strange thing is that, the file do not belong (equery b) to any package. So it was generated outside portage's sandbox. \ud83d\ude15 \nPerhaps you should file a bug report to Clang/LLVM maintainers in Gentoo's main tree.. > But the strange thing is that, the file do not belong (equery b) to any package. So it was generated outside portage's sandbox.\n\nI don't think it's LLVM/Clang bug as if there is no sanitizer (cfi) support, imo cfi_blacklist.txt should not be generated.\n\nMy mistake. I had to install Clang in another machine, I can confirm that cfi_blacklist.txt indeed belongs to sys-libs/compiler-rt-sanitizers:\nequery b /usr/lib/clang/7.0.0/share/cfi_blacklist.txt\n * Searching for /usr/lib/clang/7.0.0/share/cfi_blacklist.txt ... \nsys-libs/compiler-rt-sanitizers-7.0.0 (/usr/lib/clang/7.0.0/share/cfi_blacklist.txt). > clang: error: invalid linker name in argument '-fuse-ld=lld'\nYour system does not seems to have lld installed.\n\nI'll try with default llvm-6.\n\nVersion 6 is known to cause more issues. Stick to 7 for now.\n. > with llvm-7:\nSame as https://github.com/Eloston/ungoogled-chromium/issues/569#issuecomment-433523779\nMore elucidation: https://codereview.chromium.org/1558333002. ```\n...\nThe next patch would create the file third_party/ungoogled/BUILD.gn,\nwhich already exists!  Skipping patch.\n...\n```\nTry a fresh build; with a clean build tree.. Please don't. I'll quote @hasufell here:\n\n\"Don't make such choices for users. Instead, fixing/simplifying (if that's possible) the plugin installation/update process would make more sense.\" - https://github.com/gcarq/inox-patchset/issues/53#issuecomment-278578819\n. > Can people get extensions to install in ungoog chrome?\n\nThis is off-topic. Please file a new issue. There you should put which URL you're trying to use.. Ops! I just saw that you already fixed in 4a94286d9d42c3d796a345b58c71e1d46b3ba1cc.. If it depends on hangouts, then I guess that's the expected behavior. enable_hangout_services_extension is disabled here.. > ...fails with an error thrown by sandbox_linux.cc, followed by a segmentation fault.\nThat error is unrelated to the segfault. If you search around, you will see that's a common error, with no clear solution. See https://github.com/Eloston/ungoogled-chromium/issues/519#issuecomment-425247527. Your kernel is missing namespaces and/or Yama support.. Thank you. It builds fine for me.. @perfect7gentleman Those warnings comes from the theme engine, I think, and shouldn't cause an abort. On another issue tracker, I saw that you are using Clang as the default toolchain, yes? If so, you should double-check if you properly built chromium's dependencies, specially C++ ones.\nI had similar issue when tried to build against libcxx/libcxxabi.. Have you successfully built chromium against libcxx/libxxabi in the past? Because I don't. I had to build dev-libs/re2, dev-libs/jsoncpp and of course, chromium itself with:\nCXXFLAGS=\"${CFLAGS} -stdlib=libstdc++\"\nLDFLAGS=\"-Wl,-O2 -Wl,--as-needed -fuse-ld=lld -Wl,-lgcc_s\". I'm not sure if chromium truly supports system libcxx on linux yet. At least looking at the build/config/compiler/BUILD.gn, libc++ are only related to Mac, like this one:\nif (is_mac) {\n    # The system libc++ on Mac doesn't have aligned allocation in C++17.\n    defines += [ \"_LIBCPP_HAS_NO_ALIGNED_ALLOCATION\" ]\n    cflags_cc += [ \"-stdlib=libc++\" ]\n    ldflags += [ \"-stdlib=libc++\" ]\n  }\nThe other references are when use_custom_libcxx == true, which uses the bundled toolchain. So I suggest that you should stick to libstdc++ for now. Or at least try it, and see if that works for you.. Yeah, but chromium's internals could've changed a lot between them.. I've just found that the latest chromium build log for openSUSE Leap 42.3 (which still depends on libva 1.7.3) has failed because of this patch. Similar to an issue reported by another user here.\nBTW, I took the patch from their repo.\n. Thanks for the suggestion. I'll downgrade libva to try out your patch.. > I haven't tried it yet, so I don't know if it works.\nI can confirm it works. \ud83c\udf89 . Instead of config_bundles/archlinux/patch_order.list, I would like to request to be added to config_bundles/linux_rooted/patch_order.list. So downstream gentooers can be benefited too. For the time being I'm sed-fixing it.. > Is there fuzz in debian_buster/fixes/as-needed.patch now?\nI'll refresh the patches.. All systems go!. It's related to the gn flag is_official_build:\n```gn\nSet to enable the official build level of optimization. This has nothing\nto do with branding, but enables an additional level of optimization above\nrelease (!is_debug). This might be better expressed as a tri-state\n(debug, release, official) but for historical reasons there are two\nseparate flags.\nis_official_build = false\n```\n\ud83d\udc49 https://chromium.googlesource.com/chromium/src/+/72.0.3626.96/build/config/BUILDCONFIG.gn#125. It's a known issue. See https://bugs.freedesktop.org/show_bug.cgi?id=106490\nTL;DR: Start with allow_rgb10_configs=false or add it to /etc/environment (or similar), then reboot.. ",
    "xa0": "@nopjmp if I remove clang_base_path, I get:\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory\nI'm using clang 3.8.0. Thanks for the replies. I upgraded to Clang 3.9 from Fedora Rawhide repo, and now it successfully compiles.\nI can see the other problem is fixed now, so I will close this issue.. ",
    "jackturnbull": "Should really have rubber ducked this one, sorry...\nResolved by changing the 8pp2p8t.qjz9zk to appspot.com in the resulting warning.. ",
    "rolodato": "Sorry, I'm blind and need to RTFM better. Thanks!. ",
    "leeoniya": "Ok, i tried to carefully reproduce the exact thing in all versions using this bench [1]. Turns out this difference is due to x32 (mean settles @1.00ms) vs x64 (mean settles at 1.50ms).\nQuite the perf hit for x64. Sorry for the noise.\n[1] https://rawgit.com/leeoniya/domvm/2.x-dev/demos/bench/dbmonster/index.html. i re-tested on my Thinkpad T440S Win10 x64. the x64 overhead is ~8% in all builds. think it depends on what V8's JIT can cobble together for any given CPU's features. i've seen exactly the same code perform differently on different CPUs and platforms using the same V8 version.. will there be windows binaries for v57? i'd like to use it in combination with https://github.com/henrypp/chrlauncher and https://chromium.woolyss.com/. it may be the case that it \"sends\" it to 0.0.0.0.\nit's much more work to tweak the UI than to just shunt all the google domains & comm internally.. https://github.com/Eloston/ungoogled-chromium/issues/235. ",
    "robotme": "How do I install extentions in ungoogled chromium (mac os 12.2.2)?. ",
    "JUserLittleEnglish": "I installed \"Change Font Family Style\"!\nI changed the font and it became very easy to see.\n\nThank you very much!. ",
    "raininja": "am I sure that I am finished building? lolwat\nOK recompiled and again, it's core dumping \n[raijin@ishtar][~/build/aur/ungoogled-chromium]%ungoogled-chromium\n[1:1:0100/000000:ERROR:broker_posix.cc(41)] Invalid node channel message\nzsh: segmentation fault (core dumped)  ungoogled-chromium\n[raijin@ishtar][~/build/aur/ungoogled-chromium]%[3:3:0100/000000:FATAL:zygote_linux.cc(511)] Check failed: len > 0 (0 vs. 0)\n0 0x5584363da39e \n1 0x5584363ee3e0 \n2 0x5584351cb220 \n3 0x5584351cc5b3 \n4 0x5584351ca625 \n5 0x5584351ca2b4 \n6 0x5584351c9f68 \n7 0x5584351ce7be \n8 0x55843624c666 \n9 0x55843624d792 \n10 0x55843624c370 \n11 0x55843505a46e \n12 0x7fc6362ff291 __libc_start_main\n13 0x55843505a30a \nReceived signal 6\n0 0x5584363d9f37 \n1 0x7fc641240080 \n2 0x7fc63631204f __GI_raise\n3 0x7fc63631347a __GI_abort\n4 0x5584363d8db2 \n5 0x5584363ee677 \n6 0x5584351cb220 \n7 0x5584351cc5b3 \n8 0x5584351ca625 \n9 0x5584351ca2b4 \nopen(\"/usr/share/icons/oxygen/16x16/actions/go-next.png\", O_RDONLY) = -1 ENOENT (No such file or directory)\n10 0x5584351c9f68 \n11 0x5584351ce7be \n12 0x55843624c666 \n13 0x55843624d792 \n14 0x55843624c370 \n15 0x55843505a46e \n16 0x7fc6362ff291 __libc_start_main\n17 0x55843505a30a \nr8: 0000000000000000  r9: 00007ffcf4fdfd20 r10: 0000000000000008 r11: 0000000000000246\n r12: 00007ffcf4fe0c68 r13: 00000000000000ad r14: 00007ffcf4fe0c78 r15: 00007fc636c1a060\n  di: 0000000000000002  si: 00007ffcf4fdfd20  bp: 0000000000000000  bx: 0000000000000006\n  dx: 0000000000000000  ax: 0000000000000000  cx: 00007fc63631204f  sp: 00007ffcf4fdfd98\n  ip: 00007fc63631204f efl: 0000000000000246 cgf: 002b000000000033 erf: 0000000000000000\n trp: 0000000000000000 msk: 0000000000010000 cr2: 0000000000000000\n[end of stack trace]\n[1:1:0100/000000:ERROR:broker_posix.cc(41)] Invalid node channel message\n[1:1:0100/000000:FATAL:zygote_linux.cc(481)] Failed to synchronise with parent zygote process\n0 0x5584363da39e \n1 0x5584363ee3e0 \n2 0x5584351cb508 \n3 0x5584351cc5b3 \n4 0x5584351ca625 \n5 0x5584351ca2b4 \n6 0x5584351c9f68 \n7 0x5584351ce7be \n8 0x55843624c666 \n9 0x55843624d792 \n10 0x55843624c370 \n11 0x55843505a46e \n12 0x7fc6362ff291 __libc_start_main\n13 0x55843505a30a \nReceived signal 6\n0 0x5584363d9f37 \n1 0x7fc641240080 \n2 0x7fc63631204f __GI_raise\n3 0x7fc63631347a __GI_abort\n4 0x5584363d8db2 \n5 0x5584363ee677 \n6 0x5584351cb508 \n7 0x5584351cc5b3 \n8 0x5584351ca625 \n9 0x5584351ca2b4 \n10 0x5584351c9f68 \n11 0x5584351ce7be \n12 0x55843624c666 \n13 0x55843624d792 \n14 0x55843624c370 \n15 0x55843505a46e \n16 0x7fc6362ff291 __libc_start_main\n17 0x55843505a30a \nr8: 0000000000000000  r9: 00007ffcf4fdfd20 r10: 0000000000000008 r11: 0000000000000246\n r12: 00007ffcf4fe2f98 r13: 00000000000000ad r14: 00007ffcf4fe2fa8 r15: 00007fc636c1a060\n  di: 0000000000000002  si: 00007ffcf4fdfd20  bp: 0000000000000000  bx: 0000000000000006\n  dx: 0000000000000000  ax: 0000000000000000  cx: 00007fc63631204f  sp: 00007ffcf4fdfd98\n  ip: 00007fc63631204f efl: 0000000000000246 cgf: 002b000000000033 erf: 0000000000000000\n trp: 0000000000000000 msk: 0000000000010000 cr2: 0000000000000000\n[end of stack trace]\n. What I've posted was from the output to console upon the coredump.\n  The issue is seemingly that here on my arch oxygen-icons installs that file to /usr/share/icons/oxygen/base/16x16/actions/go-next.png rather than /usr/share/icons/oxygen/16x16/actions/go-next.png.    I suppose I could kludge it by creating symlinks. . .\nand it still coredumps.. OK so following the symlink replacement method I got the two icon dumps to go away, because of oxygen-icons.  now it's looking for a libdbusmenu.mo which isn't on arch anywhere. in fact that seems to be an exclusively ubuntu package. \nhttp://packages.ubuntu.com/xenial-updates/all/language-pack-touch-en/filelist <--only place I can find libdbusmenu.mo. ok I debtap'ed that package and now I'm stuck because the arch atk doesn't supply an atk10.mo for en_US.  tried copying that file and the libdbusmenu.mo into the needed directories and it still segfaults.  I give. ",
    "sp-1234": "https://blog.chromium.org/2009/07/smaller-is-faster-and-safer-too.html\nhttps://dev.chromium.org/developers/design-documents/software-updates-courgette\ntl;dr original chromium uses updates in form of binary diffs and they are very size-efficient\nProbably if these diffs are generated and uploaded to \"Github releases\" too, they might work too.. ",
    "koichirose": "Any news on this? Is there a way to at least have notifications about new updates?. ",
    "Unkn0wn-MDCLXIV": "I've written a small script to update and install extensions easily.\nIt's windows only tho, but if there is demand I can upload and release it on github.\nSee my other reply at #226 . I've also created a small script for that issue.\nIt reads a textfile containing all extension ids you want to use and downloads them if they don't exist or updates them if there is a newer version.\nThe CRX files then get stored in a subfolder called and extensions and can be dragged in chromium to install them.\nIf there is some demand for that, I would be glad to upload the code and the compiled release to github.\nIt's windows only unfortunately.. @sergeevabc \nHaha, got me.\nHere you are\nFill the extensions.txt with the ids of the extensions you want to download and the run the exectuable.\nIf there is anything wrong, just contact me.. ",
    "XXLCXX": "Eloston - Give please the link to download your browser. DEBIAN. \u0421\u043f\u0430\u0441\u0438\u0431\u043e.. ",
    "unicorntaco": "I favor the idea of an extension to perform these various checks.  It would be great if that extension would accept SOCKS5 proxy (with auth) for googley chittering.\n. ",
    "ownchoice": "This is the only downside of using Ungoogled Chromium for me.\nI don't want to have the browser and extensions outdated, and updating manually is a little bit painful.. ",
    "nhantrn": "I don't want to make a new issue, so I'll report it here. For current release v 55.x\nThere seem to be some kind weird bug when loading www.ign.com that only happen in ungoogled-chromium but not in other chrome variants. If you go to IGN.com, it'll connect to www.example.com and got redirected to http://www.ign.com/g00/?i10c.referrer= according to the network log. This does not happen in Chrome official. Nor in Firefox, IE, etc.\nAlso ublock does not block correctly and letting some ads slip through on IGN. However, if you open up the devtool, then the page will automatically reload and ublock will block all ads correctly. This only happens when you first launch ungoogled chromium. After opening the devtool, ublock will work fine for the rest of the session.\n. Yes, I can see it in the url bar. I've included a video showing it briefly appear in the urlbar. But you can also see it in the network log in the video.\nThe first video show you the devtool issue. When I open it, you can the see IGN getting refreshed. uBlock also shows it blocking more addresses once the devtool is invoked.\nThe second video shows you ads playing before opening the devtool and did not after.\nscreen records: https://1drv.ms/f/s!AkqT8bVKK245pBZ-6flqd8KIahJH\n. I haven't seen any mention of why would opening the devtool fixes the problem though.\nAlso for my case, this only happen in ungoogled-chromium right now. Vivaldi and CentBrowser does not have this issue. They are both chromium v56.x right now.. Yes, I only have uBO installed.. Actually I rechecked Vivaldi and it has the same problem. Openning the F12 devtool fixes the problem too. Weird. There's no user option to disable webrtc on Vivaldi so can't test that without webrtc.\nIGN does not do the g00 redirect on Cent Browser with or without webrtc enabled.\nVivaldi is chromium 56.0.2924.88\nCentbrowser is chromium 56.0.2924.87. ",
    "andrewoesten": "You need someone to make a Windows build and/or are there code changes needed to get it running? I might help out here.. @Eloston I got Chromium built on Windows now (working, with VS2017 tools). Will try to apply your patches now.. @Eloston Somehow the patches differ from what is in the source. For example the url/gurl.cc in both chromiums GIT repo and the downloaded source don't contain code about the trk scheme. What is the reason? E.g.\n```\n--- a/url/gurl.cc\n+++ b/url/gurl.cc\n@@ -504,15 +504,7 @@ size_t GURL::EstimateMemoryUsage() const\nstd::string &gurl_strip_trk(std::string &s)\n {\n-   auto slen = strlen(url::kTraceScheme);\n-   if (!isdigit(s[slen+1]))\n-       / trk:https://... /\n-       return s.erase(0, slen);\n-   / trk:123:https://... (or so we hope) /\n-   auto pos = s.find(':', slen + 1);\n-   if (pos == std::string::npos)\n-       return s.erase(0, slen);\n-   return s.erase(0, pos + 1);\n+   s.clear(); s.append(\"about:blank\"); return s;\n }\nbool gurl_is_trq(const std::string &s)\n```\nThe code you're referring to here isn't in chromiums source. Am I missing something?. @Eloston I use your tag 58.0.3029.110 - also I use chromium GIT Tag for that version. And I also tried with the source you downloaded with the utilikit py script.... @Eloston But on which chromium version do these patches base? It seems the 58 source doesn't have any trk: scheme etc. So the patches must be for a newer version? \nAt the moment I'm fixing the patches by hand. Already got the build script generator to make a \"build.bat\" for me where I apply the patches. \nYeah I got it compiled with VS 2017 tools and the specific SDK version:\nset DEPOT_TOOLS_WIN_TOOLCHAIN=0\nset GYP_MSVS_VERSION=2017\nThat was working for me.. @Eloston \nTake a look here: https://chromium.googlesource.com/chromium/src.git/+/58.0.3029.110/build/vs_toolchain.py\nHere he reads the GYP_MSVS_VERSION and also seems to support 2017.\nOK, I will try again with a corrected patch order :-). @Eloston OK, when applying the correct patch order he seems to run through. Now have to fix the windows patches.. @Eloston Fortunately yes \ud83d\udc4d. ",
    "darkenvy": "Looking forward to being able to build for Mac OSX (v57 ofc). Is there a way to export on v57? The notes say only for linux and the build process doesn't work like it did on v55.. On my third machine, I tried NOT adding any bookmarks before importing my bookmark file... well that was it.\n. ",
    "grandfroid": "Do you plan to realese the update to 57.xxx in .exe form ?. But those who don't have the level to patch or re-package the Windows version can't get a secured updated version :'( ... That's quite a bad thing don't you think ?. ",
    "lulcat": "+1 on the macandchief.. there is ample oppurtunity to have a side browser with full functionalkuty and little privacy, even chromium/chrome normal.. changing your stance due to 'compaints' is the wrong way to go. The entire pointof privacy breaches is the reliance on the lazy masses.. you are now adding to that. \nI just found this project as I have along time intended it myself but have so many other patching projects.. and the first thing I will have to do is fork this again to uncommit this? Wow, easier to just drawpatches again then and this becomes pointless.. Eloston.. having now built the (inox) , after patching it to my distro... I see where you are coming from. Although I stand by the unecessary unique machine id hash sharing and what not with this.. (\"in the old days, one would manually grant stuff\").. there is just so much metadata.. so ye.. the lan ip being blockable is a good thing.. that people who work on patching chromium to be non-google for safety, is great work.. and if it makes sense to keep webrtc enabled, and rather patch in the surrounding framework, then ok... but it is just generally how things are going which is so bad. I think maybe a solution to this, is integrating the chrome extension into the code.. It seemed Serge (from Canonical) linked the source code at some point and it seems to have been removed again.. not sure why, but as I will build (or try to build) this from an old version of yours, I can try to put that in.. Mind you, I have entirely different projects I am working on, so this might be a on and off thing to look into from my side. . Well, exposing your public ip any browser does and has to... this was about internal local ip. This is a huge network discovery exploit.. and despite using stuff like tor, you will have e.g. 10.1.XX ranges identifying networks/users and so on. data collection is a very bad thing in this day and age, and no responsibilities upon 'corps', one needs to do it oneself unfortunately.. anyway. when it comes to the block ting from the internet, the source is by canonical 0.21, and is simply setting the media.peerconnection flag thing to disable. This should just be done in during building, so it is not enabled. with a button/option to enable it if needed. Like the extension just prebuilt imo. Apart form that ye.. as long as one can set it to not be active and not be circumvented, there is no issue with allowing it to be toggled on by a user should he or she wish to use it at some point. but local network info should absolutely be disabled by default. If it's an issue to integrate the extension, then sure, keep it as a manual extra install bit then. . Ye.. well, like you said.. you were chaning stance.. I guess it's your call... I haven't tested enough to know how swell only disabling the media.peerconnection is.. but I know when websockets webrtc first came out a long time ago and it oculd read my lan ip I totally lost it ,p As you said yourself, you are thinking of not disabling it entirely.. either it's ripped out.. or I thin for now, perhaps integrating the default connection value ot be false is the way to go? If over time it turns out it there are poc's showing vulernabilities , then patch then?. lol.. ",
    "g4b1nagy": "Quoting Julian Pastarmov on this: \"In a nutshell you can still control the state of the two plugins that are part of Chrome's bundle but do not represent essential Chrome components - PDF and Flash - both of those can be controlled through the content settings dialog that you can reach from the settings page.\"\nSee this page => https://groups.google.com/a/chromium.org/forum/#!topic/chromium-discuss/PmF9gGe9Auc for details.. ",
    "wimh": "I have also noticed that tag does not build. As a workaround you can remove resources/linux_static/cleaning_list before building. (remove build\\sandbox if it still exists).\nNote that you will also need python 3.5 or 3.6. Jessie includes python 3.4, will will cause an error at the end of the build (AttributeError: 'PosixPath' object has no attribute 'write_bytes').\n(I am working on a docker image which is currently able to build the master branch and some tags: https://github.com/wimh/build-ungoogled-chromium/blob/master/debian-8/Dockerfile)\n. Looks like the windows build has to be fixed first (#215).\nIn #235 I read it is easy to add the binary download to the release when it's available:\n\nYeah. It takes little effort to publish binaries once support is there.. \n",
    "Hillside502": "@Eloston duplicate of what?\n. ",
    "gplessis": "AFAIK, it's already available as eloston-chromium. ",
    "sg-s": "\nBut you can't find the package by typing in ungoogled which sort of bugs me.\n\nyes, my problem precisely. . ",
    "hovancik": "I guess small PR can change it (rename it). I can do it, or anyone, really. . ",
    "dieideeistgut": "Sorry for replying on a closed issue but i found this is where it suits best. I somehow wonder why there's no way to build the 57 version on the mac. Maybe cask is the way to go here but many users don't have homebrew in favour of a different pkg-manager. I'd be really keen to know why currently there's no mac 57-option willing to spend some time on building this if possible without a strict requirement for homebrew (so free to chose brew, macports or nixpkg). . @Eloston is this why i can't generate matching buildfiles targetting macos as the process changed since the 55? Maybe i can help @9Morello out if he needs some helping hands doing the dirty-work? . @9Morello i'll give it a shot during next week, let's see how far i'll come. ",
    "jhuss": "this is old an related to another chromium-based project, but it's about spell checking https://bitbucket.org/chromiumembedded/cef/issues/137. ",
    "TCB13": "\n@Eloston how to do that?\n\n+1 here, I would like have a working spell check!. My issue with 71.0.3578.98-2 is not about extracting the file, that works fine however, like what happens to @yikjin it fails to patch a bunch of files down the line:\n`\npatching file chrome/browser/chrome_browser_main_win.cc\nHunk #2 FAILED at 394.\nHunk #3 succeeded at 548 with fuzz 1 (offset -4 lines).\n1 out of 3 hunks FAILED -- saving rejects to file chrome/browser/chrome_browser_main_win.cc.rej\npatching file chrome/browser/extensions/BUILD.gn\nHunk #1 succeeded at 776 (offset -32 lines).\npatching file chrome/browser/prefs/browser_prefs.cc\nHunk #1 succeeded at 111 (offset 2 lines).\nHunk #2 FAILED at 300.\nHunk #3 FAILED at 503.\nHunk #4 succeeded at 586 (offset 16 lines).\nHunk #5 FAILED at 710.\n3 out of 5 hunks FAILED -- saving rejects to file chrome/browser/prefs/browser_prefs.cc.rej\npatching file chrome/browser/profiles/off_the_record_profile_io_data.cc\nHunk #1 FAILED at 177.\n1 out of 1 hunk FAILED -- saving rejects to file chrome/browser/profiles/off_the_record_profile_io_data.cc.rej\npatching file chrome/browser/profiles/profile_impl_io_data.cc\nHunk #1 FAILED at 378.\n1 out of 1 hunk FAILED -- saving rejects to file chrome/browser/profiles/profile_impl_io_data.cc.rej\npatching file chrome/browser/ui/BUILD.gn\nHunk #1 succeeded at 381 (offset -460 lines).\nHunk #2 succeeded at 2145 (offset -421 lines).\npatching file chrome/browser/ui/browser_dialogs.h\nHunk #2 succeeded at 292 (offset 1 line).\npatching file chrome/browser/ui/webui/settings/chrome_cleanup_handler.cc\nHunk #1 succeeded at 281 (offset 6 lines).\npatching file chrome/browser/ui/webui/settings/md_settings_ui.cc\nHunk #2 succeeded at 256 (offset 2 lines).\npatching file chrome/common/safe_browsing/BUILD.gn\nHunk #1 FAILED at 95.\n1 out of 1 hunk FAILED -- saving rejects to file chrome/common/safe_browsing/BUILD.gn.rej\npatching file chrome/renderer/url_loader_throttle_provider_impl.cc\nHunk #1 succeeded at 112 (offset 2 lines).\nHunk #2 succeeded at 166 with fuzz 2 (offset 9 lines).\nTraceback (most recent call last):\n  File \"ungoogled_packaging\\build.py\", line 187, in <module>\n    main()\n  File \"ungoogled_packaging\\build.py\", line 164, in main\n    buildkit.patches.patch_paths_by_bundle(bundle), source_tree, patch_bin_path=None)\n  File \"C:\\Users\\TCB13\\Desktop\\ungoogled-chromium-71.0.3578.98-2\\build\\src\\ungoogled_packaging\\buildkit\\patches.py\", line 95, in apply_patches\n    subprocess.run(cmd, check=True)\n  File \"C:\\Program Files\\Python36\\lib\\subprocess.py\", line 418, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['C:\\\\Users\\\\TCB13\\\\Desktop\\\\ungoogled-chromium-71.0.3578.98-2\\\\build\\\\src\\\\third_party\\\\git\\\\usr\\\\bin\\\\patch.exe', '-p1', '--ignore-whitespace', '-i', 'C:\\\\Users\\\\TCB13\\\\Desktop\\\\ungoogled-chromium-71.0.3578.98-2\\\\build\\\\src\\\\ungoogled_packaging\\\\patches\\\\ungoogled-chromium\\\\windows\\\\windows-fix-building-without-safebrowsing.patch', '-d', 'C:\\\\Users\\\\TCB13\\\\Desktop\\\\ungoogled-chromium-71.0.3578.98-2\\\\build\\\\src', '--no-backup-if-mismatch', '--forward']' returned non-zero exit status 1.. @arutr Disabling that patches seem to work...\n~~Update: Also installed depot_tools from https://storage.googleapis.com/chrome-infra/depot_tools.zip (as explained here https://chromium.googlesource.com/chromium/src/+/64.0.3282.168/docs/windows_build_instructions.md#install).~~ -- useless tried with it and without it, same result bellow.\nHere is my current build process, you might want to take a look @yikjin :\n(All commands bellow run as Admin)\n\nFor faster build you can preemptively disable:\nWindows Defender: Run gpedit.msc > Local Group Policy Editor; Browse the following path Computer Configuration > Administrative Templates > Windows Components > Windows Defender Antivirus; Double-click theTurn off Windows Defender Antivirus policy; SelectEnabled` and apply your changes\nWindows Update: Control Panel > Administrative Tools > Services; Scroll down to Windows Update, right-click on the process, click on Properties and select Disabled\nInstall:\n7z1806-x64.msi\npython-2.7.15.amd64.msi (add it to path)\npython-3.6.5-amd64.exe (don't add to path; enable py launcher)\nRun pip install pypiwin32\nInstall VSCode (vs_community__735157147.1549731593.exe) with the following components:\n```\nMicrosoft.VisualStudio.Workload.NativeDesktop\nmicrosoft.visualstudio.component.debugger.justintime\nmicrosoft.visualstudio.component.vc.diagnostictools\nmicrosoft.visualstudio.component.vc.cmake.project\nmicrosoft.visualstudio.component.vc.testadapterforboosttest\nmicrosoft.visualstudio.component.vc.testadapterforgoogletest\nmicrosoft.component.vc.runtime.ucrtsdk\nmicrosoft.visualstudio.component.vc.atlmfc\nmicrosoft.visualstudio.component.vc.cli.support\nmicrosoft.visualstudio.component.vc.140\ncomponent.linux.cmake\n```\nOpen Settings > Apps & features > Windows SDK 10.0.17763.132 > Modify and enable Debugging Tools For Windows\nDownload https://github.com/Eloston/ungoogled-chromium/archive/71.0.3578.98-2.zip and extract it to c:\\ungoogled-chromium-71.0.3578.98-2\nAdd a new system variable DEPOT_TOOLS_WIN_TOOLCHAIN with value 0\nDisable safe-browsing patches by:\nRemove lines related to it from C:\\ungoogled-chromium-71.0.3578.98-2\\config_bundles\\windows\\patch_order.list\nRemove lines related to it from C:\\ungoogled-chromium-71.0.3578.98-2\\config_bundles\\common\\patch_order.list\nSearch in the folder C:\\ungoogled-chromium-71.0.3578.98-2\\patches for safe and delete all files related to safe search\nRun:\nmkdir build\\src\npy get_package.py windows build\\src\\ungoogled_packaging\ncd build\\src\nSearch once again for safe inside build\\src and also remove any files there\nFinally build by running py ungoogled_packaging\\build.py\n\nIt goes almost until the end (15581/19963) and then:\n```\nIn file included from ../..\\third_party/skia/include/core/../private/SkOnce.h:13:\n../..\\third_party/skia/include/core/SkTypes.h(13,10):  fatal error: 'SkUserConfig.h' file not found\ninclude \"SkUserConfig.h\"\n     ^~~~~~~~~~~~~~~~\n\n1 warning and 1 error generated.\n[15581/19963] CXX obj/services/resource_coordinator/public/mojom/mojom_blink/mojom_blink_jumbo_1.obj\nninja: build stopped: subcommand failed.\nC:\\ungoogled-chromium-71.0.3578.98-2\\build\\src>exit\nTraceback (most recent call last):\n  File \"ungoogled_packaging\\build.py\", line 187, in \n    main()\n  File \"ungoogled_packaging\\build.py\", line 183, in main\n    'chromedriver')\n  File \"ungoogled_packaging\\build.py\", line 65, in _run_build_process\n    **kwargs)\n  File \"C:\\Users\\TCB13\\AppData\\Local\\Programs\\Python\\Python36\\lib\\subprocess.py\", line 418, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '('cmd.exe', '/k')' returned non-zero exit status 1.\n```\nThis setup was done on a fresh install of Windows 10:\nC:\\Users\\TCB13>systeminfo | findstr /B /C:\"OS Name\" /C:\"OS Version\"\nOS Name:                   Microsoft Windows 10 Enterprise LTSC\nOS Version:                10.0.17763 N/A Build 17763\nC:\\Users\\TCB13>python --version\nPython 2.7.15\nC:\\Users\\TCB13>py --version\nPython 3.6.5\nIs there anything broken with skia? Is this a known issue or am I failing at some point.. Looks like I'm not properly disabling the safe browser, how am I supposed to do that?. @TN0X should I worry about this error?\n[546/20133] ACTION //chrome/test/chromedriver:embed_version_in_cpp(//build/toolchain/win:win_clang_x64)\nERROR:root:Git error: rc=0, output='. @TN0X I finally managed to get a working build!! Only possible with your precious help!\nI did a few things differently this time:\n\nUsed PowerShell instead of cmd.exe to compile it\nApplied your patches using Notepad instead of Subime Text (maybe it was messing line endings?)\nI was downloading the tag as a zip from github, this time I did:\ngit clone https://github.com/Eloston/ungoogled-chromium.git\ngit checkout tags/71.0.3578.98-2\nYesterday I was getting a bunch of nonsense erros as you probably saw here https://github.com/Eloston/ungoogled-chromium/issues/675#issuecomment-466378877.\nNot sure if there was some issue with that zip download or the path in my computer was way too big, because it used to be C:\\ungoogled-chromium\\71.0.3578.98-2 and this time, it was just C:\\ungoogled-chromium. \n\nThank you very much for all your help!. @k2l8m11n2 you can always edit build/src/chrome/browser/resources/settings/about_page/about_page.html to add something after the current message:\n<div class=\"secondary\">$i18n{aboutBrowserVersion} [happy ungoogled-chromium build!]</div>. @twolf35 you might want to take a look at my step by step guide on how to install the dependencies here: https://github.com/Eloston/ungoogled-chromium/issues/675#issuecomment-464741452. ~~Maybe related to the safe browsing mess? https://github.com/Eloston/ungoogled-chromium/issues/639\nI was stuck on this for a long time, manage to get around it on macOS but under windows looks like its harder...~~\n@hardhub how come you had this issue 6 days ago? I was trying to compile 71.0.3578.98-2 at that time and hitting a wall on the safe browsing patches (that are applied way after BUILD.gn) and I did not have this error.\n@Eloston ?. @hardhub can you cofirm that your build process was like this?\n\nInstall:\n7z1806-x64.msi\npython-2.7.15.amd64.msi (add it to path)\npython-3.6.5-amd64.exe (don't add to path; enable py launcher)\nRun pip install pypiwin32\nInstall VSCode (vs_community__735157147.1549731593.exe) with the following components:\n```\nMicrosoft.VisualStudio.Workload.NativeDesktop\nmicrosoft.visualstudio.component.debugger.justintime\nmicrosoft.visualstudio.component.vc.diagnostictools\nmicrosoft.visualstudio.component.vc.cmake.project\nmicrosoft.visualstudio.component.vc.testadapterforboosttest\nmicrosoft.visualstudio.component.vc.testadapterforgoogletest\nmicrosoft.component.vc.runtime.ucrtsdk\nmicrosoft.visualstudio.component.vc.atlmfc\nmicrosoft.visualstudio.component.vc.cli.support\nmicrosoft.visualstudio.component.vc.140\ncomponent.linux.cmake\n```\nOpen Settings > Apps & features > Windows SDK 10.0.17763.132 > Modify and enable Debugging Tools For Windows\nDownload https://github.com/Eloston/ungoogled-chromium/archive/71.0.3578.98-2.zip and extract it to c:\\ungoogled-chromium-71.0.3578.98-2\nAdd a new system variable DEPOT_TOOLS_WIN_TOOLCHAIN with value 0\n\nRun:\nmkdir build\\src\npy get_package.py windows build\\src\\ungoogled_packaging\ncd build\\src\npy ungoogled_packaging\\build.py. @hardhub my 5th step is to just get the code from this repo, so I can have get_package.py... I guess we're doing it in the exact same way. Thanks for the clarification.. @TN0X thank you for the answer, can you tell us the exact steps to disable safe browsing in 71.0.3578.98-x and to add the build-flag? I tried to do this and failed (not very well versed in chromium).. @TN0X I tried to compile both 70.0.3538.110-3 and 71.0.3578.98-2 with your changes and it seems to work but it later fails on other issues.\n\n\n70.0.3538.110-3: https://pastebin.com/raw/j9dUJkWD\n\n71.0.3578.98-2: https://pastebin.com/raw/ZJEFTCGL\n\nWasn't 71.0.3578.98-3 supposed to build?\nI'm not sure those errors aren't somehow related to Windows Updates. Two weeks ago I was trying to disable safe browsing, I also removed any references to the patches but I forgot the flag at gn_flags.map. At that time I wasn't getting this kinds of errors, it was failing later on as you can see here:  https://github.com/Eloston/ungoogled-chromium/issues/639#issuecomment-461983120\n. > Duplicate of #675 ?\nYes... the changes proposed by @TN0X fix this issues.. @intika #619 doesn't provide solutions, this issue and https://github.com/Eloston/ungoogled-chromium/issues/639 do.. That feature was removed so.... > @hardhub hardhub can you try again with latest version?\n@lipici what do you mean by \"latest version\", a specific tag or master? Either way, is it even possible to build above 71.0.3578.98-2 under Windows? Seems like there is a lot of broken stuff...\n. Tried 72.0.3626.122-1:\n2019-03-14 22:54:14,811 - INFO: * Applying windows-disable-reorder-fix-linking.patch (115/124)\n2019-03-14 22:54:14,811 - DEBUG: C:\\ungoogled-chromium\\build\\src\\third_party\\git\\usr\\bin\\patch.exe -p1 --ignore-whitespace -i C:\\ungoogled-chromium\\build\\src\\ungoogled_packaging\\patches\\ungoogled-chromium\\windows\\windows-disable-reorder-fix-linking.patch -d C:\\ungoogled-chromium\\build\\src --no-backup-if-mismatch --forward\n(Stripping trailing CRs from patch; use --binary to disable.)\npatching file chrome/BUILD.gn\nHunk #2 FAILED at 83.\nHunk #3 succeeded at 309 (offset -3 lines).\n1 out of 3 hunks FAILED -- saving rejects to file chrome/BUILD.gn.rej\n(Stripping trailing CRs from patch; use --binary to disable.)\npatching file tools/perf/chrome_telemetry_build/BUILD.gn\nHunk #1 succeeded at 36 (offset 4 lines).\n(Stripping trailing CRs from patch; use --binary to disable.)\npatching file chrome/test/chromedriver/BUILD.gn\nHunk #1 succeeded at 364 (offset 7 lines).. So, I just tried to compile master after the patches by @r4sas and I got this:\n```````\nC:\\ungoogled-chromium\\build\\src>\"third_party\\ninja\\ninja.exe\" \"-C\" \"out\\Default\" \"chrome\" \"chromedriver\"\nninja: Entering directoryout\\Default'\n[479/20080] ACTION //chrome/test/chromedriver:embed_version_in_cpp(//build/toolchain/win:win_clang_x64)\nERROR:root:Git error: rc=0, output=''\n[11021/20080] RC obj/chrome/elevation_service/elevation_service/elevation_service.res\nFAILED: obj/chrome/elevation_service/elevation_service/elevation_service.res\nC:/Python27/python.exe ../../build/toolchain/win/tool_wrapper.py rc-wrapper environment.x64 rc.exe /nologo -DV8_DEPRECATION_WARNINGS -DUSE_AURA=1 -DNO_TCMALLOC -DOFFICIAL_BUILD -DCHROMIUM_BUILD \"-DCR_CLANG_REVISION=\\\"346388-5\\\"\" -D_HAS_NODISCARD -D_HAS_EXCEPTIONS=0 -D__STD_C -D_CRT_RAND_S -D_CRT_SECURE_NO_DEPRECATE -D_SCL_SECURE_NO_DEPRECATE -D_ATL_NO_OPENGL -D_WINDOWS -DCERT_CHAIN_PARA_HAS_EXTRA_FIELDS -DPSAPI_VERSION=1 -DWIN32 -D_SECURE_ATL -D_USING_V110_SDK71_ -DWINAPI_FAMILY=WINAPI_FAMILY_DESKTOP_APP -DWIN32_LEAN_AND_MEAN -DNOMINMAX -D_UNICODE -DUNICODE -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DNTDDI_VERSION=NTDDI_WIN7 -D_WIN32_WINNT=_WIN32_WINNT_WIN7 -DWINVER=_WIN32_WINNT_WIN7 -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -I../.. -Igen -I../../third_party/protobuf/src -Igen/protoc_out -I../../third_party/protobuf/src /foobj/chrome/elevation_service/elevation_service/elevation_service.res ../../chrome/elevation_service/elevation_service.rc\n../../chrome/elevation_service/elevation_service.rc(38) : error RC2135 : file not found: chrome/elevation_service/elevation_service_idl.tlb\n[11034/20080] ACTION //chrome/app:generated_resources_grit(//build/toolchain/win:win_clang_x64)\nninja: build stopped: subcommand failed.\n````````\nThank you for the continuous effort.. @patchouli69ou ~~I removed all the references to safe browsing and this is what I get:\n../../third_party/skia/include/core/../private/SkOnce.h:13:10: fatal error: 'SkTypes.h' file not found\ninclude \"SkTypes.h\"\n     ^~~~~~~~~~~\n\n1 warning and 1 error generated.\nninja: build stopped: subcommand failed.\nI don't get it.~~\nUpdate: it worked just fine. You rock. I wasn't disabling the patch properly.. @Eloston I've updated the file as discussed.. @xhiddle You won't be able to set Ungoogled as your default browser because it isn't registered in the system.\nFaced with the same issue I've made a .reg that takes care of installing the necessary keys to make it work. After running it you should be able to set Ungoogled as the default preferences in the Settings.\nungoogled-chromium.zip\n. @fujitsuDev I'm running the extension on 71.0.3578.98-2 without issues. It was downloaded from here: https://chrome.google.com/webstore/detail/keepassxc-browser/oboonakemofpalcgghocfoadofidjkkk. @fujitsuDev you can't download directly from the store, you need to follow this procedure: https://ungoogled-software.github.io/ungoogled-chromium-wiki/faq#can-i-install-extensions-or-themes-from-the-chrome-webstore. I did that and I was able to use the extension.. If you change the flag, chrome://flags/#extension-mime-request-handling to Always prompt for install., you don\u2019t even need to drag and drop - opening the link of the file would ask you to install it right away.. > Obviously KeePassXC-Browser don't allow unpacked installation\nHave you experienced this with other extensions? If not, I guess this can be closed. @Eloston. @mymortal did you take a look at https://github.com/Eloston/ungoogled-chromium/issues/675 ?. @mymortal it only works up to 71.0.3578.98-2. You can't build anything newer than that.. @Eloston yeah we can do it with pyenv, but I initially did it via bash aliases and it complied just fine, multiple times. I'll check this later today again.. ",
    "1-61803": "55.0.2883-75-1 doesn't launch, even with Info.plist set to 10.8\n53.0.2785.116-1.2 launches with Info.plist set to 10.8, UI quirky\n51.0.2704.106-3 launches with Info.plist set to 10.8, UI somewhat quirky\nI've seen this with other applications, mostly due to new UI assets since 10.9. It should compile if targeted to 10.8 or lower.. That Google doesn't support \u226410.8 (is this still ungoogled-chromium, right?) and that Apple also dropped it, doesn't mean you also have to jump in the same bandwagon.\nYou are already building it for 10.9. If you target 10.8 I'll be happy to test it.. @nopjmp, in my experience problems arose between 10.8 and 10.9 with new UI assets in such generic applications, no special APIs \u2014 after all, it's just a browser.. @Eloston, could you ask @9Morello to target 10.8? The switch is a couple of clicks away, build and wait.. @Eloston, change MACOSX_DEPLOYMENT_TARGET to 10.8, build and wait. I would ask @9Morello myself, had I a means to contact him. If no new APIs or other new shiny standards were in the way, why not target lower systems? And in any case, why not give it a shot, even as unsupported build?. > I believe 9Morello has notifications enabled, so this should not be a problem.\nI don't know what you mean by that.. @9Morello, thanks for that. I guess you mean this post. Let me know if you build it for 10.8 and I'll be more than happy to test it.. @9Morello, did you have a chance to compile it for 10.8 or lower?\nOf all the Chromium variants I checked this is the only one, at least in the couple of hours I informally tested, that doesn't unilaterally start to chatter with Almighty Google or, for that matter, any other third party. Iridium, Iron, Epic \u2014 all of them leak.\nThis one (v51) is the best.. @9Morello, could you provide instructions for your current build? The documentation hasn't been updated yet.. ",
    "GauthierPLM": "Check the develop branch which is updated more often. The master branch represent the last released version.\nAlso, note that each release comes with a lot of changes, so it's not easy to update all the code base each time a version is released and it takes time.. ",
    "ffa": "there are other paths you can take until an update is available, particularly security tools. And, in general, using security tools goes a long way to preventing currently unknown exploits.\n1. use firejail or a sandbox\n2. use the umatrix extension. ",
    "lehitoskin": "The default profile is shared between the two. Before I figured out how to install extensions in ungoogled-chromium what I would do is start regular chromium, install the extension, and then start ungoogled-chromium so that I could then use the extensions like how I want.. I'm just following the \"General building instructions\". I'm using utilikit with the UTILIKIT_CONFIG_TYPE=linux_conservative environment variable set. I don't know anything about the GN flags, so your guess is as better than mine.. Okay, I'll try it with linux_simple.. After running bootstrap.py this time, it complains that it's missing sysroot and I should run build/linux/sysroot_scripts/install-sysroot.py --arch=amd64. Doing that allows bootstrap.py to get further than before, but after a while it fails again:\n[337/337] LINK gn\nBuilding gn using itself to out/Release...\nDone. Made 5947 targets from 1244 files in 2375ms\nninja: Entering directory `/home/lehi/Downloads/ungoogled-chromium-57.0.2987.110-1/build/sandbox/out/Release'\n[1/494] CXX obj/base/base_paths/base_paths.o\nFAILED: obj/base/base_paths/base_paths.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/base/base_paths/base_paths.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DFIELDTRIAL_TESTING_ENABLED -DCR_CLANG_REVISION=289944-2 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DBASE_IMPLEMENTATION -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/lehi/Downloads/ungoogled-chromium-57.0.2987.110-1/build/sandbox=. -m64 -march=x86-64 -pthread -Wall -Werror -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -O2 -fno-ident -fdata-sections -ffunction-sections -g0 --sysroot=../../build/linux/debian_wheezy_amd64-sysroot -fvisibility=hidden -Xclang -load -Xclang ../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-ipc -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wexit-time-destructors -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../base/base_paths.cc -o obj/base/base_paths/base_paths.o\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory\n[2/494] CXX obj/base/base_static/switches.o\nFAILED: obj/base/base_static/switches.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/base/base_static/switches.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DFIELDTRIAL_TESTING_ENABLED -DCR_CLANG_REVISION=289944-2 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/lehi/Downloads/ungoogled-chromium-57.0.2987.110-1/build/sandbox=. -m64 -march=x86-64 -pthread -Wall -Werror -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -g0 --sysroot=../../build/linux/debian_wheezy_amd64-sysroot -fvisibility=hidden -Xclang -load -Xclang ../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-ipc -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -O2 -fno-ident -fdata-sections -ffunction-sections -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../base/task_scheduler/switches.cc -o obj/base/base_static/switches.o\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory\n[3/494] CXX obj/base/base_static/base_switches.o\nFAILED: obj/base/base_static/base_switches.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/base/base_static/base_switches.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DFIELDTRIAL_TESTING_ENABLED -DCR_CLANG_REVISION=289944-2 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/lehi/Downloads/ungoogled-chromium-57.0.2987.110-1/build/sandbox=. -m64 -march=x86-64 -pthread -Wall -Werror -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -g0 --sysroot=../../build/linux/debian_wheezy_amd64-sysroot -fvisibility=hidden -Xclang -load -Xclang ../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-ipc -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -O2 -fno-ident -fdata-sections -ffunction-sections -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../base/base_switches.cc -o obj/base/base_static/base_switches.o\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory\n[4/494] CXX obj/base/base_paths/base_paths_posix.o\nFAILED: obj/base/base_paths/base_paths_posix.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/base/base_paths/base_paths_posix.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DFIELDTRIAL_TESTING_ENABLED -DCR_CLANG_REVISION=289944-2 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DBASE_IMPLEMENTATION -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/lehi/Downloads/ungoogled-chromium-57.0.2987.110-1/build/sandbox=. -m64 -march=x86-64 -pthread -Wall -Werror -Wextra -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -O2 -fno-ident -fdata-sections -ffunction-sections -g0 --sysroot=../../build/linux/debian_wheezy_amd64-sysroot -fvisibility=hidden -Xclang -load -Xclang ../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-ipc -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wexit-time-destructors -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -c ../../base/base_paths_posix.cc -o obj/base/base_paths/base_paths_posix.o\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory\n[5/494] CXX obj/base/allocator/tcmalloc/free_list.o\nFAILED: obj/base/allocator/tcmalloc/free_list.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/base/allocator/tcmalloc/free_list.o.d -DNO_HEAP_CHECK -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DFIELDTRIAL_TESTING_ENABLED -DCR_CLANG_REVISION=289944-2 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DTCMALLOC_DONT_REPLACE_SYSTEM_ALLOC -I../../base/allocator -I../../third_party/tcmalloc/chromium/src/base -I../../third_party/tcmalloc/chromium/src -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/lehi/Downloads/ungoogled-chromium-57.0.2987.110-1/build/sandbox=. -m64 -march=x86-64 -pthread -g0 --sysroot=../../build/linux/debian_wheezy_amd64-sysroot -fvisibility=hidden -Xclang -load -Xclang ../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-ipc -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Werror -Wall -Wno-unused-variable -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-reorder -Wno-unused-function -Wno-unused-local-typedefs -Wno-unused-private-field -Wno-sign-compare -Wno-unused-result -O2 -fno-ident -fdata-sections -ffunction-sections -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -Wno-deprecated -c ../../third_party/tcmalloc/chromium/src/free_list.cc -o obj/base/allocator/tcmalloc/free_list.o\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory\n[6/494] CXX obj/base/allocator/tcmalloc/heap-profile-table.o\nFAILED: obj/base/allocator/tcmalloc/heap-profile-table.o \n../../third_party/llvm-build/Release+Asserts/bin/clang++ -MMD -MF obj/base/allocator/tcmalloc/heap-profile-table.o.d -DNO_HEAP_CHECK -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUI_COMPOSITOR_IMAGE_TRANSPORT -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DFULL_SAFE_BROWSING -DSAFE_BROWSING_CSD -DSAFE_BROWSING_DB_LOCAL -DCHROMIUM_BUILD -DENABLE_MEDIA_ROUTER=1 -DFIELDTRIAL_TESTING_ENABLED -DCR_CLANG_REVISION=289944-2 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DTCMALLOC_DONT_REPLACE_SYSTEM_ALLOC -I../../base/allocator -I../../third_party/tcmalloc/chromium/src/base -I../../third_party/tcmalloc/chromium/src -I../.. -Igen -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -funwind-tables -fPIC -pipe -B../../third_party/binutils/Linux_x64/Release/bin -fcolor-diagnostics -fdebug-prefix-map=/home/lehi/Downloads/ungoogled-chromium-57.0.2987.110-1/build/sandbox=. -m64 -march=x86-64 -pthread -g0 --sysroot=../../build/linux/debian_wheezy_amd64-sysroot -fvisibility=hidden -Xclang -load -Xclang ../../third_party/llvm-build/Release+Asserts/lib/libFindBadConstructs.so -Xclang -add-plugin -Xclang find-bad-constructs -Xclang -plugin-arg-find-bad-constructs -Xclang check-ipc -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Werror -Wall -Wno-unused-variable -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-deprecated-register -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-shift-negative-value -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-reorder -Wno-unused-function -Wno-unused-local-typedefs -Wno-unused-private-field -Wno-sign-compare -Wno-unused-result -O2 -fno-ident -fdata-sections -ffunction-sections -fno-threadsafe-statics -fvisibility-inlines-hidden -std=gnu++11 -fno-rtti -fno-exceptions -Wno-deprecated -c ../../third_party/tcmalloc/chromium/src/heap-profile-table.cc -o obj/base/allocator/tcmalloc/heap-profile-table.o\n/bin/sh: ../../third_party/llvm-build/Release+Asserts/bin/clang++: No such file or directory\nninja: build stopped: subcommand failed.\nCommand '['ninja', '-C', '/home/lehi/Downloads/ungoogled-chromium-57.0.2987.110-1/build/sandbox/out/Release', 'gn']' returned non-zero exit status 1. Ah, hm, the ungoogled_linux_simple directory doesn't appear to exist.. Probably not. I'm running the command utilikit/generate_build_files.py debian --flavor standard --apply-domain-substitution, but since that was taken from the Debian build section, maybe I don't want to run it?. Ah-ha! There we go. ungoogled_linux_simple has now been generated.. ",
    "a-thoma": "I'm running clang 3.5.0-10.. May I ask what the alternative to gcc is that you're using? Thank you for such quick feedback.. There's a version of clang 3.9 available for Debian Jessie, so I'm gonna install it and see what I can do.\nPerhaps changing the CC environment variable from gcc to clang-3.9 and then building will work... I'm trying it now.. Meanwhile I've been building with no problems thus far after forcing clang-3.9 and clang++-3.9 on Debian Jessie. It's an ugly workaround though.\nSounds like a good plan.. >How is that a workaround?\nIt's not so much a workaround, it's just that the way that I myself got clang-3.9 and what not to work is very ugly.. So fun news, I've successfully built on Debian Jessie using clang-3.9 and clang++-3.9. The ugly part was removing the versions (3.4 or 3.5 I believe) I got from Debian's repository, installing 3.9 from LLVM's repository, and symlinking clang-3.9 to clang.\nI'll try your GCC build idea now.. GCC version builds, but when it creates the build output archive tarball I get this:\nTraceback (most recent call last):                                                                                                   \n  File \"./build.py\", line 58, in  \n    exit(main())                                                                                                                         \n  File \"./build.py\", line 44, in main                                                                                                    \n    builder.generate_package()                                                                                                           \n  File \"/home/known/Downloads/develop/ungoogled-chromium/buildlib/linux.py\", line 75, in generate_package                                \n    for arcname, real_path in file_list_generator():                                                                                     \n  File \"/home/known/Downloads/develop/ungoogled-chromium/buildlib/linux.py\", line 73, in file_list_generator                             \n    target_path.write_bytes(input_path.read_bytes())                                                                                     \nAttributeError: 'PosixPath' object has no attribute 'write_bytes'\nThis is a problem?. ",
    "nzytkkunit": "I'm trying to install 55.0.2883.87-1 Binaries for Ubuntu - 16.04 (xenial) amd64. @Eloston the install worked after I added the PPA you recommended, but its impossible to browse, I get this error everytime I try to browse\n\n. @9Morello sudo add-apt-repository -y ppa:jonathonf/ffmpeg-3 and https://ungoogled-software.github.io/ungoogled-chromium-binaries/releases/ubuntu/xenial_amd64/. @9Morello it works now thanks, just too many things to install :/\nbut thanks anyway!. ",
    "egorpe": "What's the status of it at the moment?. I might pick it up if no one else will. I will give it a try over the coming weekend, will report here.. I am sorry, I dropped the ball on this one but I picked it back up.\nI have a toolchain installed and am able to build official Chromium version.\nI'll try to apply patches and re-build in the next few days.. I stuck at the point when, even though stock Chromium (before patches) builds, the resulting executable is unusable (simply crashes). I lack hands-on Chromium development experience to debug the issue. Hopefully someone more experienced with the project will pick it up.. I just follow Google's direction on how to build Chromium. No patches whatsoever. Just a clean check out.\nFollowed this https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md to the letter.\nBuild successful, executable runs but crashes with a dead dinosaur in the middle immediately after start.. ",
    "Woodzrul": "Happy to do some UAT if you require any assistance. Just opened up a bug which I hope it resolved in your version.\nhttps://github.com/Eloston/ungoogled-chromium/issues/224. @Eloston Thank you so much for the detailed response. Unfortunately I do not know how to submit a pull request and then find the piece of code that needs removing. Oh well... Thought I would mention anyway. :-). ",
    "leedoyle": "@egorpe any luck so far?. So do points 3 and 4.... Are there going to be 32-bit binaries for Linux?. ",
    "Daisenki": "Please, someone give use a up to date Windows version :(. ",
    "FaceHiddenInsideTheDark": "I can confirm that 58 runs flawlessly on the Windows Subsystem for Linux (https://github.com/Cynede/gentoo-wsl), but I guess that doesn't really mean Windows support. Xming is kind of slow in comparison to the real deal. It's also kind of a nightmare getting modules right.. ",
    "ribatamu": "I can confirm the mobile version is working fine with issue 215.\nHopefully, Eloston can fine a way to bring back Windows support, because there are a lot peoples, which are waiting for updaded ungoogled version.. I can also confirm the following:\nIf I have downloaded  crx file directly from the store and drag and drop in the extensions or I go in chrome store and installed from there, then the extension is \"not from the store\" in the chromium extensions section.. https://github.com/Eloston/ungoogled-chromium/issues/215 is working for me.. Eloston, please could you point me the correct patch name?. @PonyPC can you upload your version somewhere?\nI would like to test some recent version of ungoogled chromium. The last one is very old.. When I am at chrome://extensions/ and refresh the the page all extension are hiding in the chromium menu.. This is not happening with the regular Chromium.\nIt's happening only with the Ungoogled Chromium and with the Iridium browser. So this bug it's something to do with the patches from Iridium.. Onabi, thank you for sharing it. Why, this build is connecting to clients2.google.com ?. Ublock Origin is crashing at start up. Something to do with the WebRTC?. Squalus, could you share your build?. Squalus, I have the same issue with your build. The build is connecting to clients2.google.com and Ublock Origin is crashing at start up. Do you have this issues on your end?. I am not sure if anybody is using, but there is extension called privacy manager by saroyanm... After installation if I mouse click on this extension icon, Ungoogled Chromium is closing.. The connections to clients2.google.com are not caused by Ungoogled Chromium. I used additional software on my system, which is installing crx file and reg key in the registry, which is causing this connections.. Squalus, Ungoogled Chromium is closing, when you open new incognito window. That's without any extensions.. Actually, when I click on \"Manage People\", Chromium is closing again and at start up is not complaining about shutdown error.\nBut If I click on \"Guest\" or \"Close all your Windows\", Chromium is closing and complaining like is not shutdown correctly at start up.. Yeap, when I removed the calls to safebrowsing in the extension options in https://github.com/Manvel/Privacy-Manager  I able to install this extension and used without problems.. Yeap v66 is working, except the bug which is already reported for the crash when extensions access safebrowsing prefs.. :). @jlj2 tried to disabled the flag at chrome://flags/#enable-md-extensions\nI think that will solved your problem.. ",
    "MathiasRenner": "The dpkg -i command did not fail. The install finishes with exit code 0 (=all fine).\nI tested it again and ran apt clean in advance to avoid issues through caching. Unfortunately, same thing...\nAlso, the sandbox-package is removed if I run apt autoremove afterwards. Probably, because chromium-package does not have the sandbox-package as dependency.. Ah, I see :-) This is the terminal of sudo dpkg -i chromium_57.0.2987.110-1_amd64.deb. It looks just fine to me.\nSelecting previously unselected package chromium.\n(Reading database ... 419282 files and directories currently installed.)\nPreparing to unpack chromium_57.0.2987.110-1_amd64.deb ...\nUnpacking chromium (57.0.2987.110-1) ...\nSetting up chromium (57.0.2987.110-1) ...\nProcessing triggers for bamfdaemon (0.5.3-2) ...\nRebuilding /usr/share/applications/bamf-2.index...\nProcessing triggers for desktop-file-utils (0.23-1) ...\nProcessing triggers for mime-support (3.60) ...\nProcessing triggers for hicolor-icon-theme (0.15-1) ...\nProcessing triggers for man-db (2.7.6.1-2) .... @Eloston \n\nWait, I overlooked something in your message. When you say \"not replaced properly\", do you mean that after you install it you just have that sandbox issue, or the package you specified in the dpkg command isn't even being used at all?\n\nI tried it again: The package you provide does replace an existing chromium package, so that's fine. Thus, regarding this issue only the sandbox issue exists. \n(I don't know why the behavior is now different, sorry. I just updated the issue title and my first post.). @Somedude98 This issue might be of your interest as well https://github.com/Eloston/ungoogled-chromium/issues/216. Do you encounter similar problems?. ",
    "Somedude98": "Here is the process I go through\n|sudo apt purge -y chromium To ensure no previous version of chromium\nremains before installing ungoogled version\nDownload|||chromium_57.0.2987.110-1_amd64.deb\nsudo |||dpkg -i chromium_57.0.2987.110-1_amd64.deb\nsudo apt-get -f install to fetch dependencies\nGet:1 http://ftp.uk.debian.org/debian unstable/main amd64 chromium amd64\n57.0.2987.133-1 [49.9 MB]\nFetched 49.9 MB in 17s (2,919\nkB/s)                                         \nReading changelogs... Done\n(Reading database ... 195301 files and directories currently installed.)\nPreparing to unpack .../chromium_57.0.2987.133-1_amd64.deb ...\nUnpacking chromium (57.0.2987.133-1) over (57.0.2987.110-1) ...\nProcessing triggers for mime-support (3.60) ...\nProcessing triggers for desktop-file-utils (0.23-1) ...\nSetting up chromium (57.0.2987.133-1) ...\nProcessing triggers for man-db (2.7.6.1-2) ...\nProcessing triggers for gnome-menus (3.13.3-9) ...\nProcessing triggers for hicolor-icon-theme (0.15-1) ...\nGet:1 http://ftp.uk.debian.org/debian unstable/main amd64 chromium amd64\n57.0.2987.133-1 [49.9 MB]\nFetched 49.9 MB in 17s (2,919\nkB/s)                                         \nReading changelogs... Done\n(Reading database ... 195301 files and directories currently installed.)\nPreparing to unpack .../chromium_57.0.2987.133-1_amd64.deb ...\nUnpacking chromium (57.0.2987.133-1) over (57.0.2987.110-1) ...\nProcessing triggers for mime-support (3.60) ...\nProcessing triggers for desktop-file-utils (0.23-1) ...\nSetting up chromium (57.0.2987.133-1) ...\nProcessing triggers for man-db (2.7.6.1-2) ...\nProcessing triggers for gnome-menus (3.13.3-9) ...\nProcessing triggers for hicolor-icon-theme (0.15-1) ...\nThe chromium installed seems to be the default chromium from the debian\nunstable repository. When I run it, the configuration (booksmarks,\nsettings ect) seem to be saved from after I purged it. I'm not sure what\nto do.\n|\nOn 18/04/17 03:24, Eloston wrote:\n\nDid you already have Chromium packages installed from the repo? How\nare you installing the packages?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/217#issuecomment-294654489,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AaXlHW7N5BtXbr7OFfhTSXoFaga8YxZBks5rxB7cgaJpZM4M-waX.\n\n\n. ",
    "funghetto": "Try to manually delete .config/chromium\n. I believe that they just lack manpower, anyways debian sid & ubuntu Zesty Zapus have new kernels.. sid is unstable like fedora, not meant for a server that requires years of uptime.\nYou can find this kernel on the experimental branch.. Point 5 seems to be the hardest for a non-developer.... ",
    "kkliebersbach": "@Eloston What's the process for setting it up on the build server then?. @Eloston How does one get the build added here?. ",
    "brokoli-mate": "I made binaries for ubuntu 17.04 and created pull request . Have i done everything rihght?\n. [14/25062] CXX obj/breakpad/client/ucontext_reader.o\nFAILED: obj/breakpad/client/ucontext_reader.o \n../../../../../../../../usr/lib/llvm-3.9/bin/clang++ -MMD -MF obj/breakpad/client/ucontext_reader.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUSE_AURA=1 -DUSE_PANGO=1 -DUSE_CAIRO=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DDISABLE_NACL -DCHROMIUM_BUILD -DCR_CLANG_REVISION=\\\"310694-2\\\" -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNO_UNWIND_TABLES -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../../breakpad -I../../breakpad/src -I../../breakpad/src/client -I../../breakpad/src/third_party/linux/include -I../.. -Igen -I../../breakpad/src -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -Wno-builtin-macro-redefined -D__DATE__= -D__TIME__= -D__TIMESTAMP__= -fno-unwind-tables -fno-asynchronous-unwind-tables -fPIC -pipe -pthread -fcolor-diagnostics -m64 -march=x86-64 -Oz -fno-ident -fdata-sections -ffunction-sections -fomit-frame-pointer -g0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wall -Wno-unused-variable -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-unused-lambda-capture -Wno-user-defined-warnings -Wno-enum-compare-switch -std=gnu++14 -fno-rtti -fno-exceptions -fvisibility-inlines-hidden -c ../../breakpad/src/client/linux/dump_writer_common/ucontext_reader.cc -o obj/breakpad/client/ucontext_reader.o\nwarning: unknown warning option '-Wno-address-of-packed-member' [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-unused-lambda-capture'; did you mean '-Wno-unused-parameter'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-user-defined-warnings'; did you mean '-Wno-user-defined-literals'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-enum-compare-switch'; did you mean '-Wno-enum-compare'? [-Wunknown-warning-option]\n../../breakpad/src/client/linux/dump_writer_common/ucontext_reader.cc:92:12: error: member access into incomplete type 'const struct ucontext'\n  return uc->uc_mcontext.gregs[REG_RSP];\n           ^\n../../breakpad/src/client/linux/dump_writer_common/ucontext_reader.h:44:49: note: forward declaration of 'google_breakpad::ucontext'\n  static uintptr_t GetStackPointer(const struct ucontext uc);\n                                                ^\n../../breakpad/src/client/linux/dump_writer_common/ucontext_reader.cc:96:12: error: member access into incomplete type 'const struct ucontext'\n  return uc->uc_mcontext.gregs[REG_RIP];\n           ^\n../../breakpad/src/client/linux/dump_writer_common/ucontext_reader.h:44:49: note: forward declaration of 'google_breakpad::ucontext'\n  static uintptr_t GetStackPointer(const struct ucontext uc);\n                                                ^\n../../breakpad/src/client/linux/dump_writer_common/ucontext_reader.cc:101:26: error: member access into incomplete type 'const google_breakpad::ucontext'\n  const greg_t regs = uc->uc_mcontext.gregs;\n                         ^\n../../breakpad/src/client/linux/dump_writer_common/ucontext_reader.h:44:49: note: forward declaration of 'google_breakpad::ucontext'\n  static uintptr_t GetStackPointer(const struct ucontext uc);\n                                                ^\n4 warnings and 3 errors generated.\n[15/25062] CC obj/base/third_party/dyn...amic_annotations/dynamic_annotations.o\nwarning: unknown warning option '-Wno-address-of-packed-member' [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-unused-lambda-capture'; did you mean '-Wno-unused-parameter'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-user-defined-warnings'; did you mean '-Wno-user-defined-literals'? [-Wunknown-warning-option]\nwarning: unknown warning option '-Wno-enum-compare-switch'; did you mean '-Wno-enum-compare'? [-Wunknown-warning-option]\n4 warnings generated.\nninja: build stopped: subcommand failed.\ndebian/rules:126: recipe for target 'override_dh_auto_build-arch' failed\nmake[1]:  [override_dh_auto_build-arch] Error 1*\nmake[1]: Leaving directory '/home/brokoli/Programs/ungoogled-chromium-62.0.3202.94-1/build/sandbox'\ndebian/rules:108: recipe for target 'binary' failed\nmake:  [binary] Error 2\ndpkg-buildpackage: error: fakeroot debian/rules binary gave error exit status 2*\n. just following the instructions for debian 9. What should i do to use the patch?\nupd: this pathc is already present in folder \"patches\" from this release https://github.com/Eloston/ungoogled-chromium/archive/62.0.3202.94-1.tar.gz\ndoes it means i'm already using it when building?\nby the way it was the same with version 58 as i remember, i just decided to wait until version 62 before creating an issue.. I run in terminal: ./platform_ini_generator.py [tag_name [64.0.3282.186]]\nand get this:\n```\n['[tag_name', '[64.0.3282.186]]']\n[_metadata]\npublication_time = 2018-03-10T20:18:04.694945\ngithub_author = [64.0.3282.186]]\nAdd a note field here for additional information. Markdown is supported\n```\n. [24411:24411:0928/101035.176250:ERROR:vaapi_wrapper.cc(323)] vaInitialize failed: unknown libva error\n[1:13:0928/101038.021975:ERROR:adm_helpers.cc(73)] Failed to query stereo recording.\nThis is a *.deb version from Eloston\n. I'll test portable later today.\nlibva 2.1.0-3 version\nIt's the same with portable version.. Disabling chrome://flags/#enable-accelerated-video does not work.\nI have installed vdpau-va-driver, but now i get this\n[15120:15120:0929/100543.483332:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.483546:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 0 and entrypoint 1\n[15120:15120:0929/100543.483825:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.483918:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 1 and entrypoint 1\n[15120:15120:0929/100543.484011:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.484102:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 2 and entrypoint 1\n[15120:15120:0929/100543.484196:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.484287:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 3 and entrypoint 1\n[15120:15120:0929/100543.484379:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.484471:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 6 and entrypoint 1\n[15120:15120:0929/100543.484563:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.484654:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 7 and entrypoint 1\n[15120:15120:0929/100543.484746:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.484838:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 8 and entrypoint 1\n[15120:15120:0929/100543.484930:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.485020:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 9 and entrypoint 1\n[15120:15120:0929/100543.485111:ERROR:vaapi_wrapper.cc(632)] vaQuerySurfaceAttributes failed VA error: invalid parameter\n[15120:15120:0929/100543.485202:ERROR:vaapi_wrapper.cc(532)] GetMaxResolution failed for va_profile 10 and entrypoint 1\nvdpau_video: vaTerminate(): config ID 0x01000000 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000001 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000002 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000003 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000004 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000005 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000006 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000007 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000008 is still allocated, destroying\n[1:1:0929/100544.364673:ERROR:webthread_impl_for_utility_thread.cc(19)] Not implemented reached in virtual blink::ThreadScheduler *blink::scheduler::WebThreadImplForUtilityThread::Scheduler() const. I replaced vdpau-va-driver with patched version for chromium from this ppa https://launchpad.net/~saiarcot895/+archive/ubuntu/chromium-dev\nThe scroling looks smoother now, but i still expirience some tearing/artefacts and get this errors:\nvdpau_video: vaTerminate(): config ID 0x01000000 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000001 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000002 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000003 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000004 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000005 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000006 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000007 is still allocated, destroying\nvdpau_video: vaTerminate(): config ID 0x01000008 is still allocated, destroying. > What version of LLVM are you using?\nI have 3.9 and 6.0 versions installed.. ",
    "guzelmarmara": "I would like to offer support but unfortunately I don't know anything about coding or the stuff relevant to computing. I think there should be a solution through a normal firewall since all these extensions have processes that can be monitored at the Task Manager.. I try to stick to the extensions I trust and also my IT expert friends trust. My problem is I cannot read the source codes or even cannot compile anything (regardless from the extensions, in general). Installing extensions from their websites or from GitHub makes more sense since Chrome Web Store has the ability to update them without my consent (is not a subject to discuss under Ungoogled-Chromium forum, I know).\nI'll check uMatrix now, thanks :). ",
    "Shalachaska": "It seems like Google Cloud Print functionality (including the settings UI related to it) can be disabled by setting the enable_service_discovery build flag to false, but I can't test it myself as I don't have the requirements to build Chromium.. Another way would be to just delete lines 782 to 810 in /src/chrome/browser/resources/options/browser_options.html\nand maybe lines 735 to 740 in /src/chrome/browser/resources/options/browser_options.js. ",
    "shak3800": "@iCeC0M Thanks for this great workaround. However i can't seem to install extensions. I keep getting this message : \napps extensions and userscripts cannot be added from this website.\nOf course dragging and dropping the extension works ok. Is this disabled by default?. Ok so there is a patch that can do it. The reason why i m asking is because ungoogled doesnt use syncing. If you mean that users create locally person accounts and switch between them then yes. However there maybe a way to keep the sign in to chromium but the space consumed by the avatar to be removed. @Artur96  Thanks for the information!. Are there any updates of UG new version ? Or we have to wait when Iridum updates their browser to get the patches?. ",
    "a-teammate": "Conan for itself is not a CI, they just provide some add-on tools to directly upload packages built on various CIs to their packet store.\nOne would probably need to use a Jenkins or maybe one could ask Travis and Appveyor to allow us an exception to the build time restriction.\nOr just anyone wanting to provide packages for different compilers/settings could build them locally on their machine and upload them to conan.io. \nThe main work would actually be to transform all Chromium dependencies to be built from sources as well (and do so in a repeatable way, meaning creating a conan package for each)\n\nLicense:\nI see your point. So ungoogled-chromium got infected itself.. :/\nWell thanks for the hint, I open an issue in Inox.\n(The bad thing is that CEF is a library, so its not a separate module and hence we would be GPL infected as well. We wont do that, since we're trying to stay free.. :/). Hurray! Yeah the BSD license is fine :) anything without copyleft is okay :)\nThanks a ton!\nNow we'll only have to solve the big build mess chromium and CEF are atm.. . I will give some more detailed explanation:\nWhat is conan?\nConan is a tool comparable i.e. to CMake. (but on a different layer; you can use CMake with Conan, but you don't have to)\nIt gives you a way, to deterministically define how to build a project.\nI.e. on windows? cmake .. afterwards cmake --build .\n           Linux? ./configure afterwards make afterwards make install.\nSeems simple so far, no tool needed isn't it?\nprobably wrong as soon as you are stepping away from the very basics.\nSoon some people need ./configure shared-build=false on some linux derivades just because something is missing.\nStill. Devs using conan will just execute conan build and in the conan-recipe, everything is done.\nSure, you could use another tool for that, i.e. a batch script on windows and a bash script on linux. but read on before: this is not even the interesting part\nProblem:\nImagine you have a depdency which depends on zlib, i.e. libreSSL. And you also need zlib yourself in the project.\nNow the problem is: if you build libreSSL with zlib 1.4, you are absolutely forced to use zlib 1.4 in your project as well. Otherwise it wont link.\nOther problem:\nRemember the people on that unix derivade which needed to build everything with shared=false? Well, better make sure you add the right zlib-files for them in your build system!\nThis can become quite messy pretty quickly if you operate on more than just a single OS.\nHow does conan help?\nYou can add as dependency the libreSSL- and zlib-projects to your project. It will build them prior to building your project (and with the defined build procedure for each OS). You can also override the zlib version libreSSL depends on, if you want a newer one in your project. Afterwards you can add to your CMake-buildfiles to use \"the conan libs\". You want to build with make? Well, then add \"the conan libs\" to your makefile, also works.\nThe user on the unix derivade without shared libs? Hey you didn't even notice that the zlib package is building differently for those people, someone else made that package. And in your project? Everything just works.\nAnother problem: Rebuilding everything sucks\nHey you do not want everyone to rebuild all dependencies everytime they want to build your shit do you?\nSo what to do?\nJust one compiler in a specific version and always in debug? then you won't need conan. just upload the binaries somewhere in a big package.\nVisual Studio 2015 Debug and Release? Already 2 prebuilts for each dependency.\nVisual Studio 2017 as well? -> 4 prebuilts. And remember: when you update them: make sure to compile them with the very same settings. If something didn't work for building them: better remember what you needed to change for the next time!!!!\nConan way\nBefore prebuilding the dependencies for the user, it checks, whether the package already has prebuilt packages uploaded for it, which are compatible. It downloads just them and does not try to build them on the devs pc.\nNeed dependencies for your project? \u2192Use a package manager.\nWell, srsly. I didn't even get started yet, with this textwall.. There is a lot more you can do with it. It is helping a LOT. If you need to deal with dependencies on more than one system with more than one compiler? You actually better use conan (or a similar package manager, there just isn't any :P)\nchrome has tons of dependencies and I would assume that you will have a lot of effort for bringing this cool project to different platforms.\nI do think Conan would solve a shitlot of problems for you.\nIve been through all of these problems I mentioned above and we had way less dependencies required for building than you have.\nHow to do that?\n- [ ] Find out for which dependencies there is a conan package\n- [ ] Use conan to get those dependencies into your project\n- [ ] Step by step create conan packages for all remaining dependencies (if there are some missing ones)\n- [ ] Profit.\nEDIT: Going through your issue tracker makes me think that at least half of them are related to this issue.. ",
    "Croydon": "\nI see that the user grants a license to this barbarian.\n\nIf you want that a service is hosting and distributing your stuff you need to give the service the permission to do so. That's all.. @Eloston Conan is a package manager, not a CI platform.\nGitLab CI can't replace a package manager.. ",
    "mercerius": "I have so far made it to setting up the buildspace tree for the latest windows build, however there has been a few issues with a little python comprehension that didn't stop me. Another hiccup was that buildkit-launcher seems to break when half-way through tarball extraction, which I instead used 7zip and it worked. Now I am running into an issue with domain substitution and it spits back:\n```\nD:\\src>py buildkit-launcher.py subdom\n2018-03-06 16:55:47,885 - DEBUG: Initialized logger 'buildkit'\n2018-03-06 16:55:47,895 - ERROR: Buildspace tree does not exist: [Errno 2] No such file or directory\n: 'D:\\src\\buildspace\\tree\\third_party\\devtools-node-modules\\third_party\\node_modules\\gulp\\n\node_modules\\gulp-util\\node_modules\\dateformat\\node_modules\\meow\\node_modules\\normalize-packag\ne-data\\node_modules\\is-builtin-module\\node_modules\\builtin-modules\\package.json'\nD:\\src>\n```\nThis is due to the directory being too long, but I am unsure how I could fix that given the structure of the tree. I have tried subst to no avail. I am using Win 7 Ultimate SP1.\nUsing \\\\?\\ notation or retrieving the short path through win32api might work however I'm not sure where I should force that behavior in the python scripts.. ",
    "matbonucci": "\nDid you install the Ubuntu 16.04 version 58 packages?\n\nYes. >After publishing that build I made another one while testing some flags so you might try that out -> https://www.dropbox.com/s/lku4ed8hnebzl9t/build.tar.xz\nTry them and the same error\nI solved the problem by deleting the config folder from an old chromium installed from apt, the folder was\n/home/$USER/.config/chromium/\nThanks @Eloston @dubvulture  for your answers. ",
    "nixballs": "I have updated the macos build instructions.\nRe code, few warnings upon build, but it completes fine.\nMaybe allow Chrome plugins.\n. Eloston,\nOriginally, following tectiv3's build instructions resulted in some directories not found, however I just re-run the same commands and it worked OK - weird.\nRe source cleaning, I believe it is not necessary if using prepare_sources.py\nDependencies, no, don't think so, it should work with Xcode 7 as well - I have 8.3.3 - simply added the info more as fyi.\nOh Chrome plugins 'for' Clang - I thought it is to enable installation of chrome extensions from the store. Currently I use Chrome-Extension-Downloader and install via drag and drop. Being able to install extensions from the store would be beneficial.\ntectiv3 is right, current instructions worked fine on the second run, so all good.\nThe warning is as per tectiv3's post above - however it does not seem to affect the build / unless I'm missing something.. @pjv  - that's strange, all those websites work perfectly fine on my MBPr.\nI would suggest downloading EasyFind, search for \"Chromium\" as per screenshot below (All Volumes), Delete everything, install the latest available version and try again.\n\n\n. @kfur  - from what I can see, the above applies to the 59 branch - Native Notifications macOS. Ungoogled-Chromium is still at 58 branch.\nMaybe @Eloston can further clarify.. That's strange, builds fine for me - https://github.com/nixballs/ungoogled-chromium/releases/tag/64.0.3282.168-1. @tectiv3 , @Eloston \nmacOS 10.13.5 - latest build  - 67.0.3396.62-1 causes high CPU usage, details below.\n\n\n. @tectiv3 // @Eloston \nLatest release seems to be working fine. I put the macOS binaries here 67.0.3396.87-1. @tectiv3 nope, none so far. @bjrnio also mentioned .79 was supposed to fix the high CPU. Using around 4~5 tabs and CPU is hovering around 5-10%. . ",
    "kfur": "It seems that all working again in Chromium 60.\nSo i guess issue may be closed.. @Eloston i don't know a lot about it flag. But at least it block all mixed content in pages. When by default chromium block only active mixed contend.. @tectiv3 I can. Just let me get your build image.. ",
    "Moscarda": "Sure, code-signing with an Apple Developer ID would be preferable, but one can compile on/for macOS with other certificates.  Personally I find the official Apple developer program to be a scam, targeted toward those who want to see their apps in the official App Store, which is the antithesis of open-source.   Perhaps @Eloston could provide another kind of certificate that isn't strictly for Darwin builds but compatible?  @lukf, I would ask that your code-signature be permitted in a merge, but could that prove problematic in the future should your membership lapse?  I am new to Git, and \nhazy on the workings and repercussions of forks/branches merging again downstream.. > In my opinion, the Eloston fork could just as well use some other means of integrity check, since the process of installing and updating the app and its extensions makes it a bad choice for everyone but the most savvy person.  Thus, I've come to see that you probably do have a different threat model and usability requirement than I do.\nThanks for the input. You are probably speaking to the developer but I mostly agree.  Looking forward, I'd hope our collective 'threat models' for anonymity and privacy concerns as both developers and consumers of data and technology should strive to be both strict and standardised.  The usability of current browser offerings is, to a large degree, determined by extensibility.  So for now I find myself switching between the TOR browser bundle for some applications and chromium builds for ease-of-use, but as someone who probably isn't 'the most savvy' the latter choice is a least-worst option scenario.. The Iridium browser you list in the readme and credits, offers a few suggestions here.  The GitHub page for the macOS package includes build instructions with multiple options for code-signing identities. I'm fairly sure they would work in Ungoogled with a little savvy scripting edits.. ",
    "lukf": "For better or worse, Apple Developer ID signing is the only established way macOS and other apps can assure integrity of Chromium. Without it, 1Password, Little Snitch, XFENCE, and Apple's firewall all have to fall back to their unsafe mode, thus opening up the device to exploitation of Chromium's privileges by malware.\nIn any case, I've since switched to Brave, which is a better fit for my needs and probably most average people. In my opinion, the Eloston fork could just as well use some other means of integrity check, since the process of installing and updating the app and its extensions makes it a bad choice for everyone but the most savvy person. Thus, I've come to see that you probably do have a different threat model and usability requirement than I do.. ",
    "nsuchy": "My opinion here is that if your system is already compromised a signature check isn't going to do much to protect you.. Currently we're building our own binaries. After building, sign with your own Apple ID, problem solved :). Regarding DuckDuckGo:\n \"DDG promotes CloudFlare sites, which compromises both privacy and anonymity:\" Could you cite a source of this, I'd like to read more about this if this is indeed the case.\n \"Anonymity: CloudFlare DoS attacks Tor users, causing substantial damage to the Tor network. (Torproject is not vocal about this because DDG paid $25k to the Tor project)\" Cloudflare sending attacks to Tor users? Those are very serious accusations. I'd like to read more on this.\n \"Privacy: All CloudFlare sites are MitM'd by design.\" It's up to the site owner whether to use Cloudflare or not, Cloudflare functions as a reverse proxy filtering out bad traffic, by its design it can see traffic flowing through its network, the only different is they also hold TLS Keys.\n As for the corporate sponsorships I cannot say as much as I'm not very informed on those types of issues.. CloudFlare sites appeared in the 6th, 8th, 11th, & 14th rankings, which are obviously unacceptably high.\nSo if multiple relevant results have the same frontend hosting provider, in this case Cloudflare, they're not allowed to be ranked highly together? Perhaps they're ranked highly because they load faster than non-cloudflare websites.\nYou've apparently answered your own question, if you had one. Whether you rationalize or accept the MitM (by design) or not is your choice. Certainly any well-informed self-respecting privacy advocate does not accept CF holding the keys and having visibility on all that sensitive data that the general public (including some web admins) is deceived into believing they've secured. BTW, when you say \"CF functions as.. filtering out bad traffic\", that's inaccurate. CF filters out both malicious and non-malicious traffic. You can say \"bad traffic\" is a subset of that, but it's misleading because it neglects collateral damage.\nAny solution that blocks traffic will have false-positives, that's not a cloudflare specific issue.\nCloudFlare's DoS attack is easily verified if you have Tor installed. Simply run torsocks lynx 'https://www.simplyrecipes.com/recipes/buffalo_wings/' and you'll be denied service; thus blocked from retrieving the target document. CF also DoS attacks in per the degradation of service meaning. That is, if you use a GUI browser, you'll be forced to solve a CAPTCHA. If the CAPTCHA is solvable, then it's degraded service as you've have to do a bit of manual labor. If it's not solvable, you'll be denied just as lynx users are. If you don't have Tor installed, a good read is this thread: https://trac.torproject.org/projects/tor/ticket/18361.\nThat's not a DoS attack, a DoS attack attempts to deny users access to a service by sending it a flood of malicious traffic. Cloudflare isn't doing that, they are simply blocking you from accessing a website.. \n\nFirst of all, when we speak of \"DoS\" (note the omission of \"attack\"), it covers all situations where service to users is denied or degraded. That means someone accidentally tripping over a power cord and knocking a server offline is a DoS (one that security admins are also responsible to mitigate by not having power cords run across a walkway). That's how broad it is. Adding the word \"attack\" merely takes the subset of intentional and malicious DoS. This means you can cleverly write a trojan that knocks a server offline (for example). It's still a DoS attack, even without the traffic flood.\n\nSo next time I am banned or kicked from a chatroom or forum can I accuse them of DoSing me?\n\nOnly socially irresponsible solutions accept false-positives to the reckless extent that CF does. CFs competitors (e.g. perimeterX) don't have this problem of mass collateral damage. Also, you need not have false-positives. A well-designed socially responsible solution would likely accept false-negatives in pursuit of ensuring that positives are true.\n\nSo pretty much any system that makes decisions for the site owner.\n\nSince this is about Ungoogled-Chromium, ungoogled chromium users are also largely a pro-privacy demographic. This is why DDG is a particularly poor choice as a default search engine. It keeps the lie going.\n\nWell the only alternative I can think of is Startpage and they just proxy results from Google so you are still subject to the same bias as a not privacy friendly search engine. Do you have a better idea? The search engines I looked at in your list had bad results.. Bangs are for using other search engines not DuckDuckGo. Type your search query. Click images. Problem solved.. @Eloston I have a working macOS Build, is there a way I can share with you for a public release binary?. @Eloston Thanks for the quick response, it's late in my timezone, in the morning I will read the instructions and upload my personal build and submit a PR.. @Eloston My knowledge of C++ is minimal. Is there any way I could help with the macOS patches.. @Eloston And on ParrotOS you can enable anonsurf and force all traffic including DNS/WebRTC traffic (enforced with iptables/netfilter) to route thru Tor that said integrating a Tor binary into ungoogled chromium would make the privacy benefits of Tor more accessible to people.. @tonowoe We're well aware extensions exist for this task. We are looking into an integration where it's a native feature of the browser.. ",
    "carlorosati": "Can you use ad-hoc signing? . If the problem is solved, why is this issue still open?. ",
    "38576010295": "I'm still learning Linux but I'll do what I can.\nUsing a few different methods:\napt-cache rdepends:\nuser@browser:~$ apt-cache rdepends libnettle4\nlibnettle4\nReverse Depends:\n  libgnutls-deb0-28\n  libhogweed2\n  chromium\nuser@browser:~$\naptitude -v why\n```\nuser@browser:~$ aptitude -v why libnettle4\ni   libgnutls-deb0-28 Depends libnettle4 (>= 2.7)\ni   libhogweed2 Depends libnettle4 (= 2.7.1-5+deb8u1)\nuser@browser:~$ \n**apt-cache showpkg**\nuser@browser:~$ apt-cache showpkg libnettle4\nPackage: libnettle4\nVersions: \n2.7.1-5+deb8u1 (/var/lib/dpkg/status)\n Description Language: \n                 File: /var/lib/dpkg/status\n                  MD5: 9dcb77a61a93b06eb5b005f9c8c509a4\nReverse Depends: \n  libgnutls-deb0-28,libnettle4 2.7\n  libhogweed2,libnettle4 2.7.1-5+deb8u1\n  chromium,libnettle4\nDependencies: \n2.7.1-5+deb8u1 - multiarch-support (0 (null)) libc6 (2 2.14) \nProvides: \n2.7.1-5+deb8u1 - \nReverse Provides: \nuser@browser:~$ \n```\nHope that's helpful, lemme know if there's a better method.. Strange that this would happen since I fully updated Debian 9 and did the cleanup process too.\nI'll try aptitude purge ~o and see if that fixes it.. Looks like it will...\nuser@browser:~$ su\nroot@browser:/home/user# aptitude purge ~o\nThe following packages will be REMOVED:  \n  gcc-4.8-base{p} gcc-4.9-base{p} libapt-inst1.5{p} libapt-pkg4.12{p} \n  libboost-iostreams1.55.0{p} libdns-export100{p} libgnutls-deb0-28{p} \n  libhogweed2{p} libicu52{p} libirs-export91{p} libisc-export95{p} \n  libisccfg-export90{p} libjson-c2{p} liblognorm1{p} libnettle4{p} \n  libprocps3{p} libpsl0{p} libreadline6{p} libssl1.0.0{p} \n  libtxc-dxtn-s2tc0{p} libxtables10{p} python-debian{u} python-debianbts{u} \n  python-httplib2{u} python-pysimplesoap{u} python-reportbug{p} \n  python-support{p} \n0 packages upgraded, 0 newly installed, 27 to remove and 0 not upgraded.\nNeed to get 0 B of archives. After unpacking 42.0 MB will be freed.\nDunno why they were on the system to begin with, weird. Wonder if they have something to do with Qubes, I dunno. Ya see the update and cleanup I did in the TemplateVM, this the AppVM made from the Template. Not sure if these maybe have something to do with how Qubes handles virtual machines.. Looks like I'll have to do a bit more...\n```\nuser@browser:~$ cd /home/user/Downloads\nuser@browser:~/Downloads$ sudo dpkg -i chromium_58.0.3029.110-1_amd64.deb\nSelecting previously unselected package chromium.\n(Reading database ... 98145 files and directories currently installed.)\nPreparing to unpack chromium_58.0.3029.110-1_amd64.deb ...\nUnpacking chromium (58.0.3029.110-1) ...\ndpkg: dependency problems prevent configuration of chromium:\n chromium depends on libatomic1 (>= 4.8); however:\n  Package libatomic1 is not installed.\n chromium depends on libavformat57 (>= 7:3.2.4); however:\n  Package libavformat57 is not installed.\n chromium depends on libminizip1 (>= 1.1); however:\n  Package libminizip1 is not installed.\n chromium depends on libre2-3 (>= 20160901); however:\n  Package libre2-3 is not installed.\n chromium depends on libwebpdemux2 (>= 0.5.1); however:\n  Package libwebpdemux2 is not installed.\ndpkg: error processing package chromium (--install):\n dependency problems - leaving unconfigured\nProcessing triggers for qubes-core-agent (3.2.18-1+deb9u1) ...\nProcessing triggers for desktop-file-utils (0.23-1) ...\nProcessing triggers for mime-support (3.60) ...\nProcessing triggers for hicolor-icon-theme (0.15-1) ...\nProcessing triggers for man-db (2.7.6.1-2) ...\n```\nWell, guess I'll just install these and stuff. I need to get out for a walk or something first though, been staring at a screen all day. I'll report with news in a little while probably.. ",
    "temoto": "Sorry I don't know what is GN, but that word occurs in build output as target name.\nI followed macos build instructions from BUILDING.md\nOSX version was likely 10.10 or 10.11, I've just upgraded to 10.12 and will try again.\nXCode 6.3\nungoogled_macos/build.sh was deleted.\nIt works now, so I guess you could state OSX 10.10 is not supported as build machine.. ",
    "zcyzcy88": "You should obey the system's style guide.\nUse Windows's default style, instead of implement your own.\nSpecification: https://msdn.microsoft.com/en-us/library/windows/desktop/dn742392.aspx\nGoogle won't change this: https://superuser.com/a/630510. @Artur96 You are true, but Chrome is even not consistency inside self.\n\n\n\n@Eloston Bad argument.\n\nChrome uses its own rendering engine for its UI.\n\nGecko (Firefox engine) also, but Gecko did it.\n\nIt also has a consistent UI across all of its desktop platforms.\n\nFalse. Chrome obey the standard on Mac.. ",
    "arutr": "@zcyzcy88 If you're looking for UI consistency, then Windows is not the operating system to go for, considering that Windows 10 UI alone has several different context menus.. Can confirm macOS build 60 works.. It is possible to write a patch to disable the avatar button, but I'm not sure whether that would be desirable for people who use multiple profiles. I don't see any Google-specific sign in option on the latest build.. By default, cookies are not saved after closing the browser.. Why are you using such an old version? Binaries for 58 are available.. Okay, I've updated the macos-fix-gn-bootstrap patch. Now I get this error after building base:\nERROR at //chrome/BUILD.gn:591:7: Unknown substitution pattern\n      \"{{bundle_contents_dir}}/XPCServices/{{source_file_part}}\",\n      ^---------------------------------------------------------\nFound a {{ at offset 0 and did not find a known substitution following it.\nSee //BUILD.gn:102:7: which caused the file to be included.\n      \"//chrome\",\n      ^---------. @Eloston It does break indeed, but a bit further ;)\n[365/365] c++  -o gn tools/gn/gn_main.o -framework AppKit -framework CoreFoundation -framework Foundation -framework Security libevent.a base.a gn_lib.a dynamic_annotations.a\nFAILED: gn \nc++  -o gn tools/gn/gn_main.o -framework AppKit -framework CoreFoundation -framework Foundation -framework Security libevent.a base.a gn_lib.a dynamic_annotations.a\nUndefined symbols for architecture x86_64:\n  \"tracked_objects::ThreadData::InitializeThreadContext(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)\", referenced from:\n      base::PlatformThread::SetName(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in base.a(platform_thread_mac.o)\n  \"tracked_objects::ThreadData::TallyRunOnNamedThreadIfTracking(base::TrackingInfo const&, tracked_objects::TaskStopwatch const&)\", referenced from:\n      base::SequencedWorkerPool::Inner::ThreadLoop(base::SequencedWorkerPool::Worker*) in base.a(sequenced_worker_pool.o)\n      base::debug::TaskAnnotator::RunTask(char const*, base::PendingTask*) in base.a(task_annotator.o)\n  \"tracked_objects::TaskStopwatch::Stop()\", referenced from:\n      base::SequencedWorkerPool::Inner::ThreadLoop(base::SequencedWorkerPool::Worker*) in base.a(sequenced_worker_pool.o)\n      base::RunLoop::Run() in base.a(run_loop.o)\n      base::debug::TaskAnnotator::RunTask(char const*, base::PendingTask*) in base.a(task_annotator.o)\n  \"tracked_objects::TaskStopwatch::Start()\", referenced from:\n      base::SequencedWorkerPool::Inner::ThreadLoop(base::SequencedWorkerPool::Worker*) in base.a(sequenced_worker_pool.o)\n      base::RunLoop::Run() in base.a(run_loop.o)\n      base::debug::TaskAnnotator::RunTask(char const*, base::PendingTask*) in base.a(task_annotator.o)\n  \"tracked_objects::TaskStopwatch::TaskStopwatch()\", referenced from:\n      base::SequencedWorkerPool::Inner::ThreadLoop(base::SequencedWorkerPool::Worker*) in base.a(sequenced_worker_pool.o)\n      base::RunLoop::Run() in base.a(run_loop.o)\n      base::debug::TaskAnnotator::RunTask(char const*, base::PendingTask*) in base.a(task_annotator.o)\n  \"tracked_objects::TaskStopwatch::~TaskStopwatch()\", referenced from:\n      base::SequencedWorkerPool::Inner::ThreadLoop(base::SequencedWorkerPool::Worker*) in base.a(sequenced_worker_pool.o)\n      base::RunLoop::Run() in base.a(run_loop.o)\n      base::debug::TaskAnnotator::RunTask(char const*, base::PendingTask*) in base.a(task_annotator.o)\n  \"base::TrackingInfo::TrackingInfo(tracked_objects::Location const&, base::TimeTicks)\", referenced from:\n      base::SequencedWorkerPool::Inner::PostTask(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const*, base::SequencedWorkerPool::SequenceToken, base::SequencedWorkerPool::WorkerShutdown, tracked_objects::Location const&, base::OnceCallback<void ()>, base::TimeDelta) in base.a(sequenced_worker_pool.o)\n      base::PendingTask::PendingTask(tracked_objects::Location const&, base::OnceCallback<void ()>) in base.a(pending_task.o)\n      base::PendingTask::PendingTask(tracked_objects::Location const&, base::OnceCallback<void ()>, base::TimeTicks, bool) in base.a(pending_task.o)\n      base::PendingTask::PendingTask(tracked_objects::Location const&, base::OnceCallback<void ()>) in base.a(pending_task.o)\n  \"base::TrackingInfo::TrackingInfo()\", referenced from:\n      base::SequencedWorkerPool::Inner::ThreadLoop(base::SequencedWorkerPool::Worker*) in base.a(sequenced_worker_pool.o)\n  \"base::TrackingInfo::~TrackingInfo()\", referenced from:\n      base::SequencedWorkerPool::Inner::ThreadLoop(base::SequencedWorkerPool::Worker*) in base.a(sequenced_worker_pool.o)\n      base::SequencedWorkerPool::Inner::PostTask(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const*, base::SequencedWorkerPool::SequenceToken, base::SequencedWorkerPool::WorkerShutdown, tracked_objects::Location const&, base::OnceCallback<void ()>, base::TimeDelta) in base.a(sequenced_worker_pool.o)\n      std::__1::__tree<base::(anonymous namespace)::SequencedTask, base::(anonymous namespace)::SequencedTaskLessThan, std::__1::allocator<base::(anonymous namespace)::SequencedTask> >::destroy(std::__1::__tree_node<base::(anonymous namespace)::SequencedTask, void*>*) in base.a(sequenced_worker_pool.o)\n      base::PendingTask::~PendingTask() in base.a(pending_task.o)\n      base::PendingTask::~PendingTask() in base.a(pending_task.o)\n  \"base::subtle::ReadWriteLock::ReadAcquire()\", referenced from:\n      base::internal::IncomingTaskQueue::PostPendingTask(base::PendingTask*) in base.a(incoming_task_queue.o)\n  \"base::subtle::ReadWriteLock::ReadRelease()\", referenced from:\n      base::internal::IncomingTaskQueue::PostPendingTask(base::PendingTask*) in base.a(incoming_task_queue.o)\n  \"base::subtle::ReadWriteLock::WriteAcquire()\", referenced from:\n      base::internal::IncomingTaskQueue::WillDestroyCurrentMessageLoop() in base.a(incoming_task_queue.o)\n  \"base::subtle::ReadWriteLock::WriteRelease()\", referenced from:\n      base::internal::IncomingTaskQueue::WillDestroyCurrentMessageLoop() in base.a(incoming_task_queue.o)\n  \"base::subtle::ReadWriteLock::ReadWriteLock()\", referenced from:\n      base::internal::IncomingTaskQueue::IncomingTaskQueue(base::MessageLoop*) in base.a(incoming_task_queue.o)\n      base::internal::IncomingTaskQueue::IncomingTaskQueue(base::MessageLoop*) in base.a(incoming_task_queue.o)\n  \"base::subtle::ReadWriteLock::~ReadWriteLock()\", referenced from:\n      base::internal::IncomingTaskQueue::~IncomingTaskQueue() in base.a(incoming_task_queue.o)\n  \"tracked_objects::TaskStopwatch::StartTime() const\", referenced from:\n      base::debug::TaskAnnotator::RunTask(char const*, base::PendingTask*) in base.a(task_annotator.o). Xcode 9.2 and macOS 10.13.2\nEDIT:\nIt seems that CBError.h underwent some changes from 10.12 to 10.13\nThe issue has been addressed by this commit though.. @sebvargo That process shouldn't be active. Maybe the patch is no longer valid. I've pulled from develop, and generating build files fails on parsing:\nTraceback (most recent call last):\n  File \"./utilikit/generate_build_files.py\", line 118, in <module>\n    _main()\n  File \"./utilikit/generate_build_files.py\", line 115, in _main\n    args.callback(resources, output_dir, args)\n  File \"./utilikit/generate_build_files.py\", line 49, in _macos_callback\n    args.apply_domain_substitution)\n  File \"/Users/Artur/ungoogled-chromium/utilikit/_build_files_generators/macos.py\", line 55, in generate_build_files\n    apply_domain_substitution)\n  File \"/Users/Artur/ungoogled-chromium/utilikit/export_resources.py\", line 52, in export_patches_dir\n    log_warnings=False)\n  File \"/Users/Artur/ungoogled-chromium/utilikit/substitute_domains.py\", line 76, in substitute_domains_in_patches\n    patchset = unidiff.PatchSet(file_obj.read())\n  File \"/Users/Artur/ungoogled-chromium/utilikit/_lib/unidiff/patch.py\", line 353, in __init__\n    self._parse(data, encoding=encoding)\n  File \"/Users/Artur/ungoogled-chromium/utilikit/_lib/unidiff/patch.py\", line 399, in _parse\n    current_file._parse_hunk(line, diff, encoding)\n  File \"/Users/Artur/ungoogled-chromium/utilikit/_lib/unidiff/patch.py\", line 237, in _parse_hunk\n    raise UnidiffParseError('Hunk diff line expected: %s' % line)\nunidiff.errors.UnidiffParseError: Hunk diff line expected: @@ -724,6 +732,7 @@. @tectiv3 This PR builds and doesn't crash, but #315 still persists. @tectiv3 I've only started using UGC 64 today with a crashpad handler patch I've written yesterday.\nEDIT: The browser seems to crash due to freeing an unallocated pointer in TemplateURLRef.. @tectiv3 It did actually crash, I have a crash report.\n@Eloston Unfortunately, not really. I was using the omnibox to perform a search.. @Eloston So far the most probable way of inducing the crash is by typing webrtc test into the omnibar and clicking on the first result in DuckDuckGo. I'll try building without the mentioned patch and see if the crash still occurs.. @Eloston https://test.webrtc.org/, it doesn't always cause a crash.. @tectiv3 I've submitted a PR to your fork. @tectiv3 removing ungoogled-chromium/add-flag-for-search-engine-collection.patch does fix the crash.. GitHub Pages has page templates, might be worth checking them out. Didn't know about that, will do.. @tectiv3 Could you provide steps to reproduce the artifacts?. @tectiv3 I don't get any artifacts. What macOS version do you have?. @Eloston I've built on my own machine (10.13.3).. @tectiv3 No issues with your build either. Void Linux is a distro with its own packaging system.. Just place it in Program Files. There is no installer :). It is ungoogled. The official build flag has been set to strip down on the binary size.\nTry using any Google API service if you're skeptical :). It's storage for remembered passwords, I think.. Yeah, but if you choose the basic option, you'll be storing your passwords plaintext. In macOS, you can select 'Always allow' (like in OP) to make it automatically unlock.\nWhereas for GNU/Linux, you can make the keyring unlock automatically on startup.\nBoth methods make the prompt go away.. @Eloston I've just checked, it doesn't.. @Eloston nope. Arch Linux, the most modular It Just Werks\u2122 distribution that doesn't require compiling from source. You can check out Distrochooser to see which distro is right for you. > Just tested it, ungoogled-chromium is still noticeably slower than Debian's chromium package. By the way, which .deb packages should I be installing after manually building? The following packages are in my ungoogled-chromium/build folder:\n\nungoogled-chromium_70.0.3538.110-3~buster_amd64.deb\nungoogled-chromium-common_70.0.3538.110-3~buster_amd64.deb\nungoogled-chromium-driver_70.0.3538.110-3~buster_amd64.deb\nungoogled-chromium-l10n_70.0.3538.110-3~buster_all.deb\nungoogled-chromium-sandbox_70.0.3538.110-3~buster_amd64.deb\nungoogled-chromium-shell_70.0.3538.110-3~buster_amd64.deb\n\nAll of them. > @arturkomoter Are you able to build from source on that machine?\nYes, but the same problem occurs.. @Eloston like which one? I have built in my user home directory.. I've fallen back to 18.04, and the latest v71 works fine.. After running this script, UGC still can't tell that it is the default browser. What to do?. @hydrogenpi It's failing. Apparently disabling the Safe Browsing patch seems to make the build work, according to this.. If you look at browser version statistics, most popular version of Chrome is 71, so UGC is up-to-date with the mainstream version.. ",
    "Streetwalrus": "I just want to pitch in to say that this might be out of scope for this project, whose goal is to remove Google's spyware from Chromium. If you want to mess with the UI design, you should maintain a separate patchset for that.\nJust my two cents.. ",
    "fitzha": "This issue should be closed.. ",
    "bennyprofane": "I didn't even think about the 3.4 vs 3.5 python differences. So here's where I'm at now:\nI installed python 3.5 and gentoo lets you switch between python versions with the eselect command so I switch to python 3.5 and the following commands all appear to work. No more \"exist_ok\" errors:\nexport UTILIKIT_CONFIG_TYPE=linux_simple\nmkdir build/\nmkdir build/sandbox\nmkdir build/downloads\n./utilikit/prepare_sources.py\n./utilikit/substitute_domains.py\n./utilikit/generate_build_files.py linux_simple --apply-domain-substitution\n\nNext I run the following:\ncd build/sandbox\n./ungoogled_linux_simple/build.sh\n\nBut it complains about print statements so that makes me think that the bootstrap.py script needs to be run as python 2.7 so I switch to python 2.7 with eselect and I run this command again:\n./ungoogled_linux_simple_build.sh\n\nAnd it appears to do a bunch of c++ commands and it gets to [347/347] and then it says \"FAILED: gn\"\nHere's the output from there:\n[347/347] c++ -pthread -o gn -Wl,--start-group tools/gn/gn_main.o libevent.a base.a xdg_user_dirs.a gn_lib.a dynamic_annotations.a -Wl,--end-group -lrt -latomic\nFAILED: gn \nc++ -pthread -o gn -Wl,--start-group tools/gn/gn_main.o libevent.a base.a xdg_user_dirs.a gn_lib.a dynamic_annotations.a -Wl,--end-group -lrt -latomic\nbase/threading/thread_task_runner_handle.o: In function `base::ThreadTaskRunnerHandle::OverrideForTesting(scoped_refptr<base::SingleThreadTaskRunner>)':\nthread_task_runner_handle.cc:(.text+0x832): undefined reference to `base::ScopedClosureRunner::ScopedClosureRunner(base::Callback<void (), (base::internal::CopyMode)1, (base::internal::RepeatMode)1> const&)'\ncollect2: error: ld returned 1 exit status\nninja: build stopped: subcommand failed.\nCommand '['ninja', '-C', '/tmp/tmpZT6cfl', '-v', 'gn']' returned non-zero exit status 1\n./ungoogled_linux_simple/build.sh: line 10: ./out/Default/gn: No such file or directory\nninja: Entering directory `out/Default'\nninja: error: loading 'build.ninja': No such file or directory\n\nAre there some other important preparation steps that I'm missing? \nI also just ran it again and redirected stderr to a separate file and this is what is says:\nNo patches in series\nDEBUG:root:Running: /home/bennyprofane/ungoo/ungoogled-chromium-58.0.3029.110-1/build/sandbox/build/write_buildflag_header.py --output base/allocator/features.h --gen-dir /tmp/tmpztWtHE/gen --definitions /tmp/tmpztWtHE/gen/base/allocator/features.h.tmp\nDEBUG:root:Running: /home/bennyprofane/ungoo/ungoogled-chromium-58.0.3029.110-1/build/sandbox/build/write_buildflag_header.py --output base/debug/debugging_flags.h --gen-dir /tmp/tmpztWtHE/gen --definitions /tmp/tmpztWtHE/gen/base/debug/debugging_flags.h.tmp\nDEBUG:root:Running: /home/bennyprofane/ungoo/ungoogled-chromium-58.0.3029.110-1/build/sandbox/build/write_build_date_header.py /tmp/tmpztWtHE/gen/base/generated_build_date.h default\nDEBUG:root:Running: ninja -C /tmp/tmpztWtHE -v gn\nCommand '['ninja', '-C', '/tmp/tmpztWtHE', '-v', 'gn']' returned non-zero exit status 1\n./ungoogled_linux_simple/build.sh: line 10: ./out/Default/gn: No such file or directory\nninja: error: loading 'build.ninja': No such file or directory\n\nWhat does \"No patches in series\" mean? Am I supposed to manually load patches into that directory or file? . Yes the series file is there but when I opened it in vim it's blank. . ",
    "Recolate": "Very grateful for all the working and looking forward to the Windows version.. ",
    "drkhsh": "@92847586 the cert is ok again. i think they just renewed let's encrypt lol. ",
    "LeFroid": "@Eloston  I was able to update ungoogled chromium to 61.0.3163.79. I did not follow the steps as outlined in DEVELOPING.md, but you can review the changes if you'd like at https://pastebin.com/P3gS2Cj1 - These patches worked on OpenSUSE leap 42.3 with GCC 6.2.1, however I have not had the time to test these being applied to a clean build.. No problem! I appreciate all the work you've been doing to maintain the project. I used to maintain the FreeBSD port of chromium so I'm familiar with some of the challenges that come with each stable release.. definitely not an easy job to tackle!\nIt seems the stable branch was updated to 61.0.3163.91, so I'll see if I can get that to build cleanly and send any additional patches if needed. On 61.0.3163.79 everything has been running normally, no apparent regressions and certainly no crashes, although it took more manual intervention with ninja's build process than I'd like - such as manually directing ninja to build a protobuf target because it attempted to build the targets relying on that code first.. @Eloston I had to search a little but it was the target to generate the cc / header files from chrome/browser/safe_browsing/chunk.proto\nThe ninja file that failed was obj/chrome/browser/safe_browsing/chunk_proto.ninja, and (found in toolchain.ninja) the rule __chrome_browser_safe_browsing_chunk_proto_genbuildtoolchain_linux_x64rule had to be executed manually to get the build to proceed. @Eloston I'm building version 61.0.3163.91 now from a clean source tree, and just hit that error about 2/3rds of the way through. Besides that, I noticed that the patch debian/gn/scheduler.patch is no longer needed, the code addition from that patch already seemed to be in the source tree. I'll see if I can come up with a fix for the ninja build, although I'm not too familiar with the build system since the transition was made from GYP to GN. @Eloston I updated the patches myself. Just made an adjustment to the safe browsing GN file, updated another file related to safe browsing, and that part of the build seems to be working now.\n@xmile Thanks for letting me know! and thanks for your hard work as well. Going through your repo it seems you already resolved many of the issues from I was working on for version 61, including the ones I made just moments ago haha. I'll go ahead and update my copy of the ungoogled chromium repo with your version of the inox patchset.. @Eloston I worked on an update for chromium 62.0.3202.62 today and it seems to be running without any regressions so far on my machine. I've posted the patches at the following URL: https://pastebin.com/SYfuyUCb. Updated my patch for 62.0.3202.75 : https://pastebin.com/wdtyDVnd. @Eloston Updated my patchset for 62.0.3202.89 : https://pastebin.com/CnB8ux0c. Should be good after the last two commits, let me know if I missed anything though!. @Eloston I'm not sure if this is related to the recent build configuration changes, but when I attempted to build version 66.0.3359.170 I ran into the following compilation error with the OpenSUSE config and LLVM/clang version 6.0.0: https://pastebin.com/PC74QWmq\nCommenting out the troublesome call to base::Bind(..) allowed the build to complete, and I'm seeing if there is a more appropriate way to fix the issue.. LLVM 6 was being used to compile the last version. I looked through the linux unbundle toolchain files and couldn't find anything apparent. I hadn't thought of it before, but maybe it's caused by the compiler flags that are set in the RPM spec file, as I'm seeing both '-std=gnu++14' and '-std=c++17' in the build output. For the next release I'll remove the compiler flag settings from the spec file to see if that was the cause.. The OpenSUSE build is also having the issue where media cannot be played.. You can use my fork of ungoogled chromium at https://github.com/LeFroid/ungoogled-chromium until I submit a PR. The latest release is working, I just haven't adapted the OpenSUSE config to conform with the new buildkit system yet.. That's correct\nThe file crc32c.h essentially upstreamed the changes from debian/fixes/crc32.patch in v63.\nAs for inox-patchset/9001-disable-profiler.patch, I removed that because it was removed in the v63 branch of the inox-patchset repo.\nMost of the other inox-patchset changes in this PR come from my merging of the branch https://github.com/gcarq/inox-patchset/tree/feature/63 into the ungoogled chromium version as well. They do seem to have much in common. I'll try chaning the base config to linux_rooted on the next minor version update and see how it goes.. No problem. I don't recall making any changes to this patch, it's probably that the upstream version added or modified the item and I did not notice it. Yeah, I fixed this patch manually in the last update and forgot to consider the domain substitution! Just uploaded a fix. ",
    "chew-z": "Any chance to get binaries for Mac ?. @pjv Thank you very much Sir.. This release is great progress. Is it possible to obtaing macOS binaries?. Releases for most platforms are stuck on version 55 or 58. It might have been important privacy project pity it is Debian-only.. ",
    "chantisnake": "just adding downloads to GitHub release.. Just this current repo would work. Thanks.. The thing is I need the binary file in the release page for my script to find it.\nIs it possible that you can add them to the release instead of in the git repo?\nI am terribly sorry about the trouble I have caused.\nBest,\nCheng\n. I totally understand. Thank you.. ",
    "matthewbauer": "Hi,\nHave you tried to upstream this to Chromium? It is still needed for me.. ",
    "lecler-i": "Linux. ",
    "englishextra": "@arturkomoter\nYou have to uncheck in advanced options in settings - keep cookies until browser closes. \n\n\nit wont tell you anything please read the issue in the first post. @Eloston Wait for a half year and in the meantime delete BrowserMetrics content manually - is that what you are saying?\nIn two weeks of usage the folder grew from 300 mb to 4 GB\nIsn't that crirtical?. @Eloston. Thanks . To set up an env to compile is rather expensive thing in terms of time.. ",
    "lenomirei": "Thanks a lot!. ",
    "dimqua": "Why do you use patches from Debian project, what their main purpose? Are they enhance privacy even further?. >They're mostly patches to integrate with Debian better\nWhy not to drop their support in this case?. Is there any way to update extensions automaticly?. ",
    "Calinou": "\nThere are also a few very minor tweaks, a couple of which are privacy related.\n\nJust a note, one of the included Debian patches implements mouse wheel scrolling in the tab list (scrolling the mouse wheel while having the mouse cursor on the tab list will cycle between tabs). This is a useful feature for some people, but it's hardcoded and cannot be disabled once it's compiled in.\nHowever, this feature cannot be implemented with an extension, it has to be done in the Chromium core.. ",
    "khalibadelni": "Iridium 61.0.0 is released.\nwhen we will expect the new version of ungoogled chromium?\nbtw  last stable chrome version now is  62.0.3202.62\n. ",
    "phaoost": "Hello,\nis there any chance to get pre-built binaries?\nOn 26 November 2017 at 03:10, Eloston notifications@github.com wrote:\n\nI'm writing this message from 91a9671\nhttps://github.com/Eloston/ungoogled-chromium/commit/91a96717f6e5a2b1ee191c0c94dd8eb6aef8fe92,\nand the tip of develop is being built right now. I don't think anything\nI've committed since my last build will break anything, so everyone is\nwelcome to try it out.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Eloston/ungoogled-chromium/issues/262#issuecomment-346959903,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AA5xJ2LBLLasAEzowVNJrtcuRwQxrNhhks5s6GYJgaJpZM4PZ3PJ\n.\n\n\n-- \nRegards,\nYevgeny\n. Yes it is. I am running sid. Hi,\nI have plugin installed:\n~# update-pepperflashplugin-nonfree --status\nFlash Player version installed on this system  : 29.0.0.113\nFlash Player version available on upstream site: 29.0.0.113\nHowever it doesn't appear listed in chromium extensions.. I had no any troubles with chromium installation.\nHere is what chrome://flash showing (GL_EXTENSIONS omitted)\nAbout Flash\nChromium    65.0.3325.181 (built on Debian stretch/9.4, running on Devuan ceres/unstable)\nOS  Linux\nFlash plugin    29.0.0.113 /usr/lib/pepperflashplugin-nonfree/libpepflashplayer.so\n--- Crash data ---\nCrash Reporting Enable crash reporting to see crash IDs\nFor more details    https://support.9oo91e.qjz9zk/chrome/?p=ui_usagestat\n--- GPU information ---\n--- GPU driver, more information ---\nVendor Id   0x8086\nDevice Id   0x1916\nDriver vendor   Mesa\nDriver version  17.3.3\nDriver date \nPixel shader version    1.30\nVertex shader version   1.30\nGL_VENDOR   Intel Open Source Technology Center\nGL_RENDERER Mesa DRI Intel(R) HD Graphics 520 (Skylake GT2)\nGL_VERSION  3.0 Mesa 17.3.3. ",
    "Alex2242": "I tried to follow BUILDING.md   : \nexport UTILIKIT_CONFIG_TYPE=linux_simple\n./utilikit/prepare_sources.py\n./utilikit/substitute_domains.py\n./utilikit/generate_build_files.py linux_simple --apply-domain-substitution\n./ungoogled_linux_simple/build.sh. The reason I put linux_simple is this : \n$ ./utilikit/generate_build_files.py archlinux --apply-domain-substitution\ngenerate_build_files.py: error: argument files_type: invalid choice: 'archlinux' (choose from 'debian', 'macos', 'linux_simple'). @Eloston  Thanks, my bad.\n@avently No, it still fails. I think I've the same error you had :\nninja: error: '../../components/domain_reliability/baked_in_configs/c_bigcache_googleapis_com.json', needed by 'obj/components/domain_reliability/bake_in_configs.inputdeps.stamp', missing and no known rule to make it\n but I haven't found a way to fix it. How did you do ?\n. ",
    "solinium": "Thanks for the reply, I'll try that. I'll also make a quick pull request to update the FAQ. #273. ",
    "wallofbytes": "It would be great! I don't know about separate patches, sorry, I am not a programmer, but I think, it's possible to extract font fixing functionality from this patch. I am wrong? In this case you can contact to the creator of this patch to ask a patch that specifically adds font-fixing functionality.. ",
    "libBletchley": "The Yahoo partner Duckduckgo is a poor choice for the reasons I mentioned.  Bad results, bad politics.  And worse, it's falsely positioned (it masquerades as privacy-respecting when it's proven to be privacy-hostile).  The only good thing about DDG is the bang queries, but that's not good enough reason to make it a default choice in a browser that is meant to cater to a pro-privacy community.  It's a bad idea to continue to mislead privacy-respecting users into thinking DDG is aligned with their principles.\nStartpage would be a reasonable choice because it's privacy-focused, but with results similar to google's.  It's centralized by a Dutch company with no connection to PRISM.\nSearx comes out ahead though because it's decentralized.  If you don't like the results one particular instance gives, you can change nodes.  Roughly 90% of the nodes I've tried give results that are better than DDG results.. > \"DDG promotes CloudFlare sites, which compromises both privacy and anonymity:\" Could you cite a source of this, I'd like to read more about this if this is indeed the case.\nIt's unclear if you need a citation for DDGs promotion of those sites, or if you're questioning CloudFlare's destruction of privacy and anonymity. If you're looking for a scientific study for the former, such a study would be a waste of money when it's trivially verified (faster than one could even read a study).  I just went to DDG and searched for \"buffalo wings recipe\".  CloudFlare sites appeared in the 6th, 8th, 11th, & 14th rankings, which are obviously unacceptably high.  (To confirm if you don't have Tor, run curl --head <URL> | grep CF-RAY. If there is a match, it's a CF site)\n\nCloudflare sending attacks to Tor users? Those are very serious accusations. I'd like to read more on this.\n\nCloudFlare's DoS attack is easily verified if you have Tor installed.  Simply run torsocks lynx 'https://www.simplyrecipes.com/recipes/buffalo_wings/' and you'll be denied service; thus blocked from retrieving the target document.  CF also DoS attacks in per the degradation of service meaning.  That is, if you use a GUI browser, you'll be forced to solve a CAPTCHA.  If the CAPTCHA is solvable, then it's degraded service as you've have to do a bit of manual labor.  If it's not solvable, you'll be denied just as lynx users are.  If you don't have Tor installed, a good read is this thread: https://trac.torproject.org/projects/tor/ticket/18361.\n\nIt's up to the site owner whether to use Cloudflare or not, Cloudflare functions as a reverse proxy filtering out bad traffic, by its design it can see traffic flowing through its network, the only different is they also hold TLS Keys.\n\nYou've apparently answered your own question, if you had one. Whether you rationalize or accept the MitM (by design) or not is your choice.  Certainly any well-informed self-respecting privacy advocate does not accept CF holding the keys and having visibility on all that sensitive data that the general public (including some web admins) is deceived into believing they've secured.  BTW, when you say \"CF functions as.. filtering out bad traffic\", that's inaccurate.  CF filters out both malicious and non-malicious traffic.  You can say \"bad traffic\" is a subset of that, but it's misleading because it neglects collateral damage.\n\nAs for the corporate sponsorships I cannot say as much as I'm not very informed on those types of issues.\n\nI'm not sure why you would say something about them.  What's your objective?\nDDG is apparently embarrassed about their partnerships.  Their main page used to proudly say \"partnered with Yahoo\", but now they've removed that.  Not only have they removed it from their front page, they seem to have scrubbed it from deeper parts of their site (as far as I can tell).. > So if multiple relevant results have the same frontend hosting provider, in this case Cloudflare, they're not allowed to be ranked highly together? Perhaps they're ranked highly because they load faster than non-cloudflare websites.\nSearch engines base rankings on lots of trivia, such as whether a website has a white background.  So \"relevance\" is generally perversely distorted and overloaded to start with.  DDG is (falsely) positioned as a pro-privacy search engine, and is thus targeted toward privacy enthusiasts.  With that user demographic, privacy-abusing search results are of little relevance.  And yet such results get high rankings on DDG.  The privacy-embracing demographic that DDG claims to serve is less interested in load speed than they are about privacy.  CF results would be relevant enough for 1st page hits to users who aren't concerned with privacy (e.g. Google and Yahoo users).\nIt's also extra damaging that DDG subjects users to privacy compromise, b/c most DDG users value privacy, and that value for privacy was exploited by false ads to bring them to DDG.  So users proactively seeking privacy are being conned, which is more harmful than say a Google user who unlikely has concern for privacy in the first place.  Not to mention the privacy-abuse resulting from feeding Verizon and Yahoo with financial support by way of the partnership.\nSince this is about Ungoogled-Chromium, ungoogled chromium users are also largely a pro-privacy demographic.  This is why DDG is a particularly poor choice as a default search engine.  It keeps the lie going.\n\nAny solution that blocks traffic will have false-positives, that's not a cloudflare specific issue.\n\nOnly socially irresponsible solutions accept false-positives to the reckless extent that CF does.  CFs competitors (e.g. perimeterX) don't have this problem of mass collateral damage.  Also, you need not have false-positives.  A well-designed socially responsible solution would likely accept false-negatives in pursuit of ensuring that positives are true.\nIt's also a bit perverse to even say the variety of collateral damage CF does is a \"false positive\", when it's actually doing a crude pre-emptive strike for the purpose of avoiding a proper traffic analysis that could sensibly try to determine malice from non-malice.\n\nThat's not a DoS attack, a DoS attack attempts to deny users access to a service by sending it a flood of malicious traffic. Cloudflare isn't doing that, they are simply blocking you from accessing a website.\n\nOf course it's a DoS attack.  You're only describing one specific variety of DoS attack.\nFirst of all, when we speak of \"DoS\" (note the omission of \"attack\"), it covers all situations where service to users is denied or degraded.  That means someone accidentally tripping over a power cord and knocking a server offline is a DoS (one that security admins are also responsible to mitigate by not having power cords run across a walkway).  That's how broad it is.  Adding the word \"attack\" merely takes the subset of intentional and malicious DoS.  This means you can cleverly write a trojan that knocks a server offline (for example).  It's still a DoS attack, even without the traffic flood.\nWhat you describe is better known as a DDoS (distributed denial of service) attack.. > So next time I am banned or kicked from a chatroom or forum can I accuse them of DoSing me?\nThat would depend on a couple factors.  Did the moderator kick you out to enforce a policy, or did the moderator kick you out as a power abuse despite your adherence to the policy?  Was the owner in control of and fully informed of the policy that the moderator was working to?  If the moderator is breaking the contract or not enforcing the policy and will (intent) of the ownership, then I would call it a DoS (just as a disgruntled employee might DoS attack by disconnecting the ethernet cable of a company asset).\nIf you get kicked out of a forum despite following the rules of the ownership, it's a good idea to notify the owners because it may indeed be a DoS.\n\nSo pretty much any system that makes decisions for the site owner.\n\nThe site owner should make the decisions, of course. Whenever there is a disconnect between a site owner making decisions there is obviously risk of the site owners intent undermined, and the owner's assets therefore being misused.\n\nDo you have a better idea? The search engines I looked at in your list had bad results.\n\nI'm barely satisfied with the alternate sites because they also have the CF ranking problem, although to a lesser extent.  DDG seems to have more CF pollution than the searx instances I've used.  Searx is giving better results and more importantly it's better for privacy and also has the benefit of decentralization and the transparency of open source s/w.  When you use DDG, you're feeding the ad revenue machinery of a privacy abuser (Yahoo) and it's parent Verizon, and you're feeding DDG, a profit-driven corporation who spends a lot of money to create a false public perception of being privacy-centric in order to con privacy enthusiasts into its centralized private space that runs CSS.  DDG has been buying influence the same way corporations use PACs to buy politicians, and lately hiding their partnerships that work against the values of their userbase.\nSearx can also give worse results than DDG.  This is the nature of being decentralized.  I tried about half a dozen different instances before I found one that gives better results than DDG.. I think I neglected to mention another point about DDG as a U.C. default engine:\nThe primary mission of Ungoogled Chromium is to avoid Google.  Yet DDG directs all image searches (!images) to Google.. I've submitted the bugtracker manpage bug here:\nhttps://bugs.debian.org/cgi-bin/bugreport.cgi?bug=880965\nThis bug report is to cover the --temp-profile option:\nhttps://bugs.debian.org/cgi-bin/bugreport.cgi?bug=881040\n\nThe develop branch has all package names prefixed with ungoogled-. This change will be merged to master in the next release of ungoogled-chromium.\n\nWhen that happens, should Debian users run dpkg --remove chromium and install the package that uses the new name?\n. I was waiting for the next release, and ignoring the apt nags to \"upgrade\", then on Nov.14 Ungoogled-Chromium was silently replaced with the google version.  According to the logs, unattended-upgrade did that, which I think suggests the version of that day was security-critical.\nAnyone following this thread will want to pin the version of their ungoogled-chromium.  These are the steps:\n$ aptitude remove chromium\n  $ dpkg -i chromium_58.0.3029.110-1_amd64.deb\n  $ aptitude -f install\n  $ aptitude hold chromium. Ungoogled-chromium now sends a nag upon every launch that the profile is for a more recent version.  It also lost access to the password store, so no passwords are prefilled, nor can it store new passwords.\nAnyone know how to fix these issues, apart from obliterating the profile?. Ah, sorry about that.  The D in \"%3D\" is a character code, but indeed I needed the browser's version.. Sloppy reading on my part.. ",
    "vaguiners": "Not on windows. https://github.com/henrypp/chromium/blob/master/hevc_support.md\nhttps://github.com/henrypp/chromium/blob/master/hevc_support_new.md. close this please\n284. Using lastest x64 build for windows. i did not\nim just using the lastest x64  unchromium . k i got this by simply downloading the widevide folder from chrome/chromium\nlooks like the chrome/chormium come without widevine, but it download from google servers when you frist starty your browser.. ",
    "garoto": "See #235 and #215 (215 is not loading for me, github hiccup perhaps).. ",
    "chaoskagami": "Hey, I'm fine with that. I agree effort is better spent removing tracking. :P\nBefore the removal, there was an option in chrome://flags that allowed to toggle it as well as a console argument - upstream removed both, so kTabStripStackedLayout is right now used internally to keep track of the state from what I can tell. It's not exposed to the user.\nDon't quote me on this: I think adjust_layout is used on tablets/touchscreens. From reading the issue tracker for chromium, it seems tablets are normally in equal-width mode until one hovers/touches the tabs bar, which causes it to switch to stacked. I'm assuming adjust_layout triggers this, but I'm not sure.. ",
    "Jallot": "I've already solved it. I just needed to make /usr/lib/chromium/chrome-sandbox owned by root and set its mode to 4755. ",
    "rednithin": "\u279c cat /usr/share/applications/firefox-developer.desktop\n[Desktop Entry]\nName=Firefox Developer\nGenericName=Web Browser\nIcon=firefox-developer-icon\nType=Application\nCategories=Application;Network;\nMimeType=text/html;text/xml;application/xhtml+xml;application/xml;application/vnd.mozilla.xul+xml;application/rss+xml;application/rdf+xml;image/gif;image/jpeg;image/png;x-scheme-handler/http;x-scheme-handler/https;x-scheme-handler/ftp;x-scheme-handler/chrome;\nEncoding=UTF-8\nExec=env GTK_THEME=Breeze firefox-developer --class=firefox-developer %u\nTerminal=false\nMultipleArgs=false\nStartupNotify=true\nLook for the corresponding .desktop file for the application and in the Exec line remove the flag causing the problem.. ",
    "d-packs": "there is no such flag set. it must be something hardcoded...\n\n. ",
    "PonyPC": "so how to fix it for 62. I has fixed it for windows. This is my patch:\n~~0000-fix-safebrowsing.txt~~\n. Well, you're right. I did missing add GN config to git and I'll upload the patch again include these, sorry for that.\n0000-fix-safebrowsing.txt\nHow do I know?\nThere isn't a safe_browsing.lib in \"obj\\chrome\\browser\\safe_browsing\", I checked \"chrome\\browser\\safe_browsing\\BUILD.gn\" and found that there is no source file so that the compiler can not generate library. I tried add some sources which build without errors, and found that corrupt references, fix it. Then try to remove the static_library(\"safe_browsing\"), the compiler figure out which contains safe_browsing.\nHow do I do?\n1. Firstly, remove \"static_library(\"safe_browsing\")\" in \"chrome\\browser\\safe_browsing\\BUILD.gn\"\n2. Build as normal you will get error about which GN config include these library.\n3. Remove those you got above.\n4. Build as normal you will get error about the references in header and source.\n5. Remove by context to not break whole function.\n6. Build passed.\n. @ribatamu sorry, my binary version contains custom modifies.. Actually, I patched my version without domain substitution. But if patch them all, you can still use depot tools. You can fetch build params from ungoogle script and parsing them to ninja. Only the windows version I have environment to build, those platform I can't fix it.. ",
    "stolendata": "Can confirm same problem when running on 10.11.6. Also noticed that the mds/mdworker metadata daemons for Spotlight were running haywire during this - probably indicating high disk output by the crashpad_handler processes - though I couldn't locate exactly what or where.. I have nothing to add as dbf4c0e unfortunately refuses to build on my El Capital setup. I'm too swamped with work right now to get enough time to dig into it. @tectiv3, have perhaps you gotten around to building it?. ",
    "kelvinq": "This happens on my machine too.. ",
    "sebvargo": "I experienced this problem as well. I left my computer overnight to upload videos to a cloud using Google Chrome and my fans started to sound very loud to the point that they woke me up.\nAfter checking Activity Monitor,  crashpad_handler was taking 199% CPU. Please see image below.\n\nHow can this be troubleshooted?\nThank you. ",
    "pbajno": "Please update it to 64 and also with windows version which is outdated.. ",
    "szatan667": "It's a wait then, thanks!. ",
    "onabi": "Will you publish binaries?. Pretty unfortunate, I was looking forward to it, I guess it can't be helped.. It's not a virus, it's the package I got after building it by following the instructions and as for why it is connecting to clients2.google.com I have no idea.. @ribatamu https://github.com/gorhill/uBlock/issues/533 That fixed it for me.\nI don't recommend using my build though as it may be broken.... After trying on another windows 10 installation, cookies seem to be saved properly, my bad, I should have done it before opening an issue.. @ribatamu My build closes too when using incognito mode.. ",
    "proteo": "Sorry to interrupt you guys, just wanted to let you know how much we, Mac users, appreciate your efforts. Ungoogled Chromium has been my main browser for a while now.\nThanks a a lot for your hard work!. ",
    "0vermind": "May I suggest \"UnG\" Chrome/Browser as a name?\nTo spread the awareness of the project and get the advantage of the Word of mouth you need a site and a community around the project.\nmy two cents. ",
    "murqach": "I click \"clear data\" button (no matter \"advanced\" or \"basic\" tab), browser window closing. When I start browser again I see \"chromium didn't shut down correctly\" popup and data isn't cleared. yep. every time. on fresh profile too.\nalso I mentioned that there is a crash only if I choose time range: \"all time\"\nI run chromium from terminal and get this output on crash:\n```\nlibva error: va_getDriverName() failed with unknown libva error,driver_name=(null)\n[16240:16240:0225/145659.531633:ERROR:vaapi_wrapper.cc(252)] vaInitialize failed: unknown libva error\nATTENTION: default value of option force_s3tc_enable overridden by environment.\n[16171:16171:0225/145712.636543:FATAL:memory_linux.cc(35)] Out of memory.\n0 0x55811edaa753 \nReceived signal 6\n0 0x55811edabb63 \nr8: 0000000000000000  r9: 00007ffcb01067d0 r10: 0000000000000008 r11: 0000000000000246\n r12: 00007fe822ace080 r13: 00007ffcb0106ee0 r14: 0000000000000049 r15: 00007ffcb0106ed8\n  di: 0000000000000002  si: 00007ffcb01067d0  bp: 00007ffcb0106a20  bx: 00007ffcb0106a70\n  dx: 0000000000000000  ax: 0000000000000000  cx: 00007fe8221890bb  sp: 00007ffcb01067d0\n  ip: 00007fe8221890bb efl: 0000000000000246 cgf: 002b000000000033 erf: 0000000000000000\n trp: 0000000000000000 msk: 0000000000000000 cr2: 0000000000000000\n[end of stack trace]\nCalling _exit(1). Core file will not be generated.\n```\nis it helpful?. fixed, thanks!. ",
    "squalus": "With your version I get these errors:\n2018-02-27 22:17:57,313 - ERROR: Parent directories do not exist for path: [Errno 2] No such file or directory: 'buildspace/tree/ungoogled_packaging/archive_include/README'\nLooks like archive_include directory is not created. Adding (output_dir / 'archive_include').mkdir() before the README copy fixes it for me\nThen running the package.sh script, adding the README file to the archive fails. This was the reason I did the compression in an extra step - I couldn't find a way to add a file to the compressed archive in-place.\n+ tar --transform 's,^,ungoogled-chromium_64.0.3282.186-1_linux,' -r -J -v -f /src/ungoogled-chromium/buildspace/ungoogled-chromium_64.0.3282.186-1_linux.tar.xz --null -T -\ntar: Cannot update compressed archives\nTry 'tar --help' or 'tar --usage' for more information.\n. Also, the archive created results in files that look like this: ungoogled-chromium_64.0.3282.186-1_linuxchrome-wrapper. I'm assuming the first part of this should be a directory instead, like ungoogled-chromium_64.0.3282.186-1_linux/chrome-wrapper. Updated with a new proposed patch that's working for me. @Eloston Which problem - the path limit thing? No, I never hit that one. I saw your build doc and took your suggestion of using official Python3.6 binaries and I had a fully updated Win10 system. > LLVM needs to be copied into tree (I have a patch coming to do this in getsrc)\n\n\nAre you doing this through the extra dependencies mechanism? I would rather extend that than use some hack in buildkit.\n\n\nI used a hack in buildkit. I have a PR in #360. You probably won't like it but we can discuss :)\n\nNo packaging or installer at the end. I tried using ninja mini-installer but the installer did not start up. Haven't looked into it yet.\n\nI was thinking about using resources/packaging/shared/list_build_outputs.py to determine what files would be added to a zip file. If it's easier, we can write a small Python script to do this rather than use a batch script.\n\n\nYes I think the linux_simple approach would be great here. I prefer Python (or really anything that's not Windows batch files). Maybe in this case the same script could be shared between the platforms.. > Also, would you be able to test if %VS140COMNTOOLS% is available in regular command-prompt (or similar variable)? It'll save some path hardcoding (info from https://stackoverflow.com/questions/18711595/how-run-clang-from-command-line-on-windows).\nI just checked and it's not available, nor is anything else that looks similar. A search indicates that as of VS2017 they no longer provide such a variable. It seems the newer way to do it is to use this tool: https://github.com/Microsoft/vswhere. Yeah, it works.\n\"%ProgramFiles(x86)%\\Microsoft Visual Studio\\Installer\\vswhere.exe\" -latest -property installationPath\nproduces:\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community. macOS is now tested and working for me. Windows binaries available here: https://github.com/squalus/ungoogled-chromium-winbuild/releases/tag/65.0.3325.181-1\nThis was done on the build system available in the same repo. @Eloston This sounds plausible. Another culprit might be the windows-fix-building-without-safebrowsing.patch where some of the prefs no longer get registered. There was one crasher related to that. Regardless I will try to get more information from a debug build. How much value does the Iridium trk: feature really add? It seems that the subdom step destroys all the bad urls. For the trk: feature, urls must be manually patched to add the prefix, and this is only covering a subset of the bad urls. \nIt does result in the infobar showing up sometimes but that's hardly useful for a normal user. They really don't need to know about this; the request to Google didn't go through. It's more like a warning to tell developers to try to remove the code that made the request.. > If is_multi_dll_chrome=false is the cause, I'll look into rewriting the trk: scheme code to work with multiple DLLs.\n@Eloston A build with is_multi_dll_chrome=true works fine, so this does appear to be the cause of #380. I removed all the trk-related patches and produced a build with a chrome_child.dll.. @Eloston A linux_simple build worked for me, but I got an error on the Windows build. I used da4ccbd + some changes to switch back to multi-dll and remove a remaining reference to iridium:trknotify in windows-disable-reorder-fix-linking.patch.\ndefault: [9196/24174] LINK transport_security_state_generator.exe\n    default: FAILED: transport_security_state_generator.exe \n    default: cmd /c C:/Python27/python.exe ../../build/toolchain/win/tool_wrapper.py delete-file ./transport_security_state_generator.exe.pdb && C:/Python27/python.exe ../../build/toolchain/win/tool_wrapper.py link-wrapper environment.x64 False ../../third_party/llvm-build/Release+Asserts/bin/lld-link.exe /nologo /OUT:./transport_security_state_generator.exe /PDB:./transport_security_state_generator.exe.pdb @./transport_security_state_generator.exe.rsp\n    default: ..\\..\\third_party\\llvm-build\\Release+Asserts\\bin\\lld-link.exe: error: obj/third_party/ungoogled/util/util.obj: undefined symbol: ?kTraceScheme@url@@3QBDB\n    default: ..\\..\\third_party\\llvm-build\\Release+Asserts\\bin\\lld-link.exe: error: obj/third_party/ungoogled/util/util.obj: undefined symbol: ?SchemeIs@GURL@@QEBA_NV?$BasicStringPiece@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@base@@@Z\n    default: ..\\..\\third_party\\llvm-build\\Release+Asserts\\bin\\lld-link.exe: error: obj/third_party/ungoogled/util/util.obj: undefined symbol: ?spec@GURL@@QEBAAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@XZ. @Eloston Great, I'll re-test. My Windows branch was working and ready for testing at the time I wrote it. I haven't rebased it yet though on the new patches.. What's the rationale for including this patch anyway? I've never been bothered by seeing the extra EV trust indicators.. I used this config to get a successful build that withstood a few minutes of testing. I used LLVM 6.0.0. There were a few other random script hacks I had to do as well to get this to work but I dont have those ready yet.. I'd rather not post binaries as the security of my Windows system is in doubt. If I can put together a better Windows environment then I may be able to do this in the future though. Here are the outstanding issues I encountered. Thanks for the Windows building notes, those were helpful and some of these items are noted there.\n\nbuild.bat script did not copy the args.gn file. Don't know why yet. Windows batch files are awful!\nquilt needed the series file to be in unix rather than windows (CRLF) format. Though this may have been because I was using WSL instead of MSYS2. I'll need to check this\nbuild.bat needs to have gperf/bison env vars set\nI needed to run the \"x64 Native Tools\" command prompt rather than use the entries in build.bat. Not sure why\nLLVM needs to be copied into tree (I have a patch coming to do this in getsrc)\nNo packaging or installer at the end. I tried using ninja mini-installer but the installer did not start up. Haven't looked into it yet.. Also, I used the 64 bit LLVM 6.0.0 official binaries from llvm.org. I tried to make this as automatic as possible.\n\nThe first thought is to use the same method as macOS to download and extract official LLVM binaries. But the Windows LLVM binaries only come in the form of an installer (as far as I can tell). And I couldn't find any way to extract their self-extracting installer on the command-line. 7-Zip GUI does it, but the standalone command-line 7za.exe does not. And anyway, that would be another new binary to have to bootstrap. Nor does Python3.6 lzma, unzip, xz, etc. work to do this.\nSo instead I provided two options:\n1) User installs system-wide LLVM and buildkit automatically locates it from the Windows Registry\n2) User manually extracts LLVM and provides the --windows-llvm-path option to getsrc\nThese only work if the platform is detected as Windows, so a Windows buildspace tree does need to be generated on a Windows system.\n. A simpler implementation, but a little more work for the user, would be to allow the user to provide a path (instead of tar.xz file) in extra deps, then the user points to the already extracted LLVM path. To do that they would either edit an existing dummy extra_deps.ini in the windows bundle or create a new bundle with the extra_deps listed.. This still \"installs\" the software though right? Uninstall info would get recorded in the registry. It's weird to have this tool automatically perform a system-wide installation into a temporary path. I agree extracting is better. Thanks, I didn't realize the 7z vs 7za issue. I do like the idea of bootstrapping as many dependencies as we can for Windows since it reduces work for the user, increases repeatability (we know we all have the same version of tools), and increases security since we can validate the hashes on each tool.\nYour proposal is better than what I have in this PR. How about this slightly modified proposal that includes 7-zip downloading?\n\nCreate extractor field in extra_deps.ini. Supported values:\n7zip: Extracts a 7-zip file\nmsi: Extracts MSI file using msiexec\ntar/gnu_tar/internal_tar: Extracts tar file using logic you described\nAdd provides field in extra_deps.ini\nThe 7zip dependency will be listed with provides = 7zip\nThe 7zip extractor will use this map to look up the output path of 7zip, e.g. provided_deps['7zip'].output_path or something\nThis allows one extractor to depend on a previously downloaded artifact as long as the order is correct\nDownload 7-zip with msi extractor in the first extra_deps entry\nDownload LLVM with 7zip extractor in the second extra_deps entry. Never mind about my comment above. If we want to do this we can do it as a second pass. I have a PR incoming implementing your suggestions. This implements the suggestions from #360.\n\nThe only supported extractors are 7z and tar. Untar strategies are chosen automatically, there's no support yet for explicit internal_tar, gnu_tar, etc as extractor fields.\nThe tar extractor is compatible with gnutar and bsdtar (for macos)\n7z.exe is used to extract tars on Windows, with a fallback to Python. Auto-location is not yet implemented for Windows, so the --7z-path argument to getsrc is now required for a Windows build.. Looks good!\nI added the 7-zip registry lookup support and a small fix for the extra_deps schema.\nI will also note that 7z doesn't need to be artifically limited to Windows-only. In its current state, it will work on linux/macos but only if you pass --7z-path. Added a small fix for the following error on Windows:\nTraceback (most recent call last):\n  File \"D:\\src\\ungoogled-chromium\\buildkit\\cli.py\", line 441, in main\n    args.callback(args=args)\n  File \"D:\\src\\ungoogled-chromium\\buildkit\\cli.py\", line 146, in _callback\n    show_progress=args.show_progress, extractors=extractors)\n  File \"D:\\src\\ungoogled-chromium\\buildkit\\source_retrieval.py\", line 213, in retrieve_and_extract\n    pruning_set=remaining_files, extractors=extractors)\n  File \"D:\\src\\ungoogled-chromium\\buildkit\\source_retrieval.py\", line 131, in _setup_chromium_source\n    extractors=extractors)\n  File \"D:\\src\\ungoogled-chromium\\buildkit\\extractors.py\", line 209, in extract_tar_file\n    sevenzip_cmd = str(_find_7z_by_registry())\n  File \"D:\\src\\ungoogled-chromium\\buildkit\\extractors.py\", line 40, in _find_7z_by_registry\n    sevenzip_path = Path(sevenzipfm_dir / '7z.exe')\nTypeError: unsupported operand type(s) for /: 'str' and 'str'\nOtherwise it looks good. I confirmed that it works on Windows with and without --7z-path argument.. Further automation for the Windows build.\n\ngperf, bison, and ninja no longer require ahead-of-time user setup\nbuild.bat script now works fine for me in testing\n\nThe bison zip files all extract to the same target directory, but extra_deps.ini section names still need to be distinct. To do this I introduced : as a delimiter to allow for an optional string distinguishing the otherwise identical entries.\nAlso I had SSL cert validation errors downloading from Sourceforge using official Python3.6 Windows binaries. I need to investigate this further, as it may be some local configuration problem. Linux/macOS works fine, and they don't need to download from Sourceforge anyway. Is it ok to disable SSL cert validation in the downloader, since we are checking hashes anyway?. On further thought, a better way to do the extra_deps.ini change might be to make the section heading an arbitrary string, e.g. \"bison-bin\", and introduce an \"output_path\" field. Forget the SSL certificate thing for now. I think it's just some kind of local misconfiguration on my machine. The downloads work fine on an Appveyor CI instance so I think it's just me. Besides, there's not a good way to disable certificate verification on Python3 urlretrieve. I'm ok for this to be merged.. What about using git apply? That works fine for me in testing on Windows. And we can download updated official binaries from https://git-scm.com in the extra deps.\nWould the new buildkit command run between subdom and genpkg? And I guess we no longer need genpkg to copy patches or patching scripts to the tree.. Also it appears python-quilt just invokes patch :)\nhttps://github.com/bjoernricks/python-quilt/blob/3dd50bc77/quilt/patch.py#L26. A few more things\n- The Windows git binaries actually include patch.exe so it's possible we could use this\n- If patsrc is run after getsrc it's no longer necessary to perform subdomain replacement on the patches, so that code could be deleted in the subdom step. Is this what you have in mind?. Yes, my goal here is to make the Windows build simpler for non-developers. The build will be more reliable and repeatable if there are fewer manual setup steps.\n\nOn the other hand, my GNU patch approach only requires two small downloads; of which only a single exe and dll are required from it.\n\nUsing the Gnuwin32 binary is my first choice too since it's so small. Let's do this if the version isn't too old to work.\n\ngit apply requires Git to be downloaded. If you're not a developer, this is a large and non-portable dependency\n\nI was thinking about getting the PortableGit-2.16.2-64-bit.7z.exe binary from git-scm.org which doesn't require an install and can be extracted by 7z. So it can go through the automatic extra_deps.ini system. I haven't tested it yet though. The download is 35mb which doesn't bother me. We should do this if Gnuwin32 doesn't work.\n\nThe only reason I considered including python-quilt is for its usefulness in development,\n\npython-quilt would be fine because it can be bundled. I just want to get rid of the unnecessary manual dependencies in the non-developer build workflow. But like you mentioned, it's easier to just invoke patch directly\n\nInstead, I think it's better to go with the alternative to patsrc I had in mind, which is to add a shared packaging Python script to apply a patch series using GNU patch or git apply (i.e. a script like apply_patch_series.py in resources/packaging/shared/). This is because the windows base bundle and packaging types are already semantically linked to one another, so it's valid for build.bat to use apply_patch_series.py and the predetermined location of GNU patch. buildkit and packaging types don't have this sort of relationship.\n\nTo me it makes more sense as a buildkit source processing step, because it can be done before subdom and the patch substitution code can be eliminated. The patch substitution  just seems like unnecessary complexity. But of course it works fine either way, it's just a judgement call. I don't know enough about Debian packaging to speak about that issue.\n\nAlso, domain substitution over the source tree and user bundle allows users to build Chromium in an environment without Python 3\n\nlist_build_outputs.py is a build-time dependency on Python3, and we'll be adding another one using the new apply_patch_series.py script. I have no problem with this.\nThanks for the thoughts, I will work on adding apply_patch_series.py script using patch. I like the idea of generating a domain substitution patch. It will be interesting to look at the patch and see just how big it is and what kind of urls are in there. I agree there may be  challenges with the size of the patch. Windows, macos, and linux_simple are tested with the new script. Note that other platforms are free to continue using quilt if they want since the format of the files has not changed. Fixes #366 \n. I tested the Gnuwin32 patch binary and found that it didn't work. First, there's a bizarre problem with UAC that had to be worked around (http://irq5.io/2011/06/26/gnu-patch-and-windows-uac/). Next, I found that it crashed when applying some of the patches. I didn't investigate why.\nSo instead I got the portable git binaries and used the patch.exe from there. That worked fine for me locally and on Appveyor CI.. No problem! I'm glad to see this done either way. I tested your change on Windows and got this error running package.bat:\n```\nTraceback (most recent call last):\n  File \"C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ungoogled_packaging\\scripts\\process_build_outputs.py\", line 155, in \n    main()\n  File \"C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ungoogled_packaging\\scripts\\process_build_outputs.py\", line 152, in main\n    args.callback(args)\n  File \"C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ungoogled_packaging\\scripts\\process_build_outputs.py\", line 101, in _handle_archive\n    for include_path in _include_paths(args, recursive=False):\n  File \"C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ungoogled_packaging\\scripts\\process_build_outputs.py\", line 70, in _include_paths\n    for include_path in args.include_file:\nAttributeError: 'Namespace' object has no attribute 'include_file'\n``. Same error with fd7bf84. Changingdest='append'toaction='append'in the--include-dirand--include-file` arguments fixes it. That works! :+1: . You compiled without webrtc? I got build errors when I tried to do that.. With my Windows build I don't see problems persisting cookies, nor is it connecting to google.. @ribatamu https://github.com/squalus/ungoogled-chromium-winbuild/releases/tag/65.0.3325.181-1\nI have a PR open to put it up on the main site. I just tested in a clean Windows Server 2016 install. I don't see a connection to google or anywhere else on startup. I do see the same problem with uBlock Origin crashing though. A few other extensions I tested seem to work fine.. It is something related to the webrtc check. You can get it working if you comment out code in js/is-webrtc-supported.js.. new self.RTCPeerConnection(null) causes a crash on Windows but not Linux. Same here. So it seems there's two major bugs in the Windows build:\n- new self.RTCPeerConnection(null) crashes \n- Incognito mode crashes. @Eloston I am able to reproduce this on Windows 65.0.3325.181-1 and in my testing this is fixed by #384. Stack trace:\nchrome.dll!PrefService::Preference::IsUserModifiable() Line 617\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\components\\prefs\\pref_service.cc(617)\nchrome.dll!subtle::PrefMemberBase::UpdateValueFromPref(const base::RepeatingCallback<void ()> & callback) Line 74\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\components\\prefs\\pref_member.cc(74)\nchrome.dll!subtle::PrefMemberBase::MoveToThread(scoped_refptr<base::SingleThreadTaskRunner> task_runner) Line 57\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\components\\prefs\\pref_member.cc(57)\nchrome.dll!PrefMember<bool>::MoveToThread(scoped_refptr<base::SingleThreadTaskRunner> task_runner) Line 204\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\components\\prefs\\pref_member.h(204)\nchrome.dll!OffTheRecordProfileIOData::Handle::LazyInitialize() Line 161\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\profiles\\off_the_record_profile_io_data.cc(161)\nchrome.dll!OffTheRecordProfileIOData::Handle::GetResourceContext() Line 66\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\profiles\\off_the_record_profile_io_data.cc(66)\nchrome.dll!content::StoragePartitionImplMap::Get(const std::basic_string<char,std::char_traits<char>,std::allocator<char> > & partition_domain, const std::basic_string<char,std::char_traits<char>,std::allocator<char> > & partition_name, bool in_memory, bool can_create) Line 413\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\content\\browser\\storage_partition_impl_map.cc(413)\nchrome.dll!content::BrowserContext::GetStoragePartition(content::BrowserContext * browser_context, content::SiteInstance * site_instance, bool can_create) Line 276\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\content\\browser\\browser_context.cc(276)\nchrome.dll!content::HostZoomMap::GetDefaultForBrowserContext(content::BrowserContext * context) Line 71\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\content\\browser\\host_zoom_map_impl.cc(71)\nchrome.dll!OffTheRecordProfileImpl::TrackZoomLevelsFromParent() Line 235\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\profiles\\off_the_record_profile_impl.cc(235)\nchrome.dll!OffTheRecordProfileImpl::Init() Line 176\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\profiles\\off_the_record_profile_impl.cc(176)\nchrome.dll!Profile::CreateOffTheRecordProfile() Line 559\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\profiles\\off_the_record_profile_impl.cc(559)\nchrome.dll!ProfileImpl::GetOffTheRecordProfile() Line 751\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\profiles\\profile_impl.cc(751)\nchrome.dll!chrome::NewIncognitoWindow(Browser * browser) Line 559\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\ui\\browser_commands.cc(559)\nchrome.dll!chrome::BrowserCommandController::ExecuteCommandWithDisposition(int id, WindowOpenDisposition disposition) Line 343\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\ui\\browser_command_controller.cc(343)\nchrome.dll!views::internal::MenuRunnerImpl::OnMenuClosed(views::internal::MenuControllerDelegate::NotifyType type, views::MenuItemView * menu, int mouse_event_flags) Line 181\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\views\\controls\\menu\\menu_runner_impl.cc(181)\nchrome.dll!views::MenuController::ExitMenu() Line 2562\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\views\\controls\\menu\\menu_controller.cc(2562)\nchrome.dll!views::MenuController::OnMouseReleased(views::SubmenuView * source, const ui::MouseEvent & event) Line 725\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\views\\controls\\menu\\menu_controller.cc(725)\nchrome.dll!views::Widget::OnMouseEvent(ui::MouseEvent * event) Line 1219\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\views\\widget\\widget.cc(1219)\nchrome.dll!ui::EventDispatcher::DispatchEvent(ui::EventHandler * handler, ui::Event * event) Line 192\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\events\\event_dispatcher.cc(192)\nchrome.dll!ui::EventDispatcher::ProcessEvent(ui::EventTarget * target, ui::Event * event) Line 140\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\events\\event_dispatcher.cc(140)\nchrome.dll!ui::EventDispatcherDelegate::DispatchEventToTarget(ui::EventTarget * target, ui::Event * event) Line 87\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\events\\event_dispatcher.cc(87)\nchrome.dll!ui::EventDispatcherDelegate::DispatchEvent(ui::EventTarget * target, ui::Event * event) Line 58\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\events\\event_dispatcher.cc(58)\nchrome.dll!ui::EventProcessor::OnEventFromSource(ui::Event * event) Line 57\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\events\\event_processor.cc(57)\nchrome.dll!ui::EventSource::SendEventToSink(ui::Event * event) Line 52\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\events\\event_source.cc(52)\nchrome.dll!views::DesktopWindowTreeHostWin::HandleMouseEvent(const ui::MouseEvent & event) Line 846\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\views\\widget\\desktop_aura\\desktop_window_tree_host_win.cc(846)\nchrome.dll!views::HWNDMessageHandler::HandleMouseEventInternal(unsigned int message, unsigned __int64 w_param, __int64 l_param, bool track_mouse) Line 2675\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\views\\win\\hwnd_message_handler.cc(2675)\nchrome.dll!views::HWNDMessageHandler::_ProcessWindowMessage(HWND__ * hWnd, unsigned int uMsg, unsigned __int64 wParam, __int64 lParam, __int64 & lResult, unsigned long dwMsgMapID) Line 357\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\views\\win\\hwnd_message_handler.h(357)\nchrome.dll!views::HWNDMessageHandler::OnWndProc(unsigned int message, unsigned __int64 w_param, __int64 l_param) Line 941\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\ui\\views\\win\\hwnd_message_handler.cc(941)\nchrome.dll!base::win::WrappedWindowProc<&gfx::WindowImpl::WndProc>(HWND__ * hwnd, unsigned int message, unsigned __int64 wparam, __int64 lparam) Line 79\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\base\\win\\wrapped_window_proc.h(79)\n[External Code]\nchrome.dll!base::MessagePumpForUI::ProcessMessageHelper(const tagMSG & msg) Line 363\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\base\\message_loop\\message_pump_win.cc(363)\nchrome.dll!base::MessagePumpForUI::DoRunLoop() Line 169\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\base\\message_loop\\message_pump_win.cc(169)\nchrome.dll!base::MessagePumpWin::Run(base::MessagePump::Delegate * delegate) Line 58\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\base\\message_loop\\message_pump_win.cc(58)\nchrome.dll!base::RunLoop::Run() Line 136\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\base\\run_loop.cc(136)\nchrome.dll!ChromeBrowserMainParts::MainMessageLoopRun(int * result_code) Line 1999\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\browser\\chrome_browser_main.cc(1999)\nchrome.dll!content::BrowserMainLoop::RunMainMessageLoopParts() Line 1238\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\content\\browser\\browser_main_loop.cc(1238)\nchrome.dll!content::BrowserMainRunnerImpl::Run() Line 146\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\content\\browser\\browser_main_runner.cc(146)\nchrome.dll!content::BrowserMain(const content::MainFunctionParams & parameters) Line 46\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\content\\browser\\browser_main.cc(46)\nchrome.dll!content::ContentMainRunnerImpl::Run() Line 717\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\content\\app\\content_main_runner.cc(717)\nchrome.dll!service_manager::Main(const service_manager::MainParams & params) Line 456\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\services\\service_manager\\embedder\\main.cc(456)\nchrome.dll!content::ContentMain(const content::ContentMainParams & params) Line 19\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\content\\app\\content_main.cc(19)\nchrome.dll!ChromeMain(HINSTANCE__ * instance, sandbox::SandboxInterfaceInfo * sandbox_info, __int64 exe_entry_point_ticks) Line 132\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\app\\chrome_main.cc(132)\nchrome.exe!MainDllLoader::Launch(HINSTANCE__ * instance, base::TimeTicks) Line 199\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\app\\main_dll_loader_win.cc(199)\nchrome.exe!wWinMain(HINSTANCE__ * instance, HINSTANCE__ * prev, wchar_t *, int) Line 230\n    at C:\\Users\\vagrant\\Desktop\\ungoogled-chromium\\buildspace\\tree\\chrome\\app\\chrome_exe_main_win.cc(230)\n[External Code]. I have a working set of Windows patches on https://github.com/squalus/ungoogled-chromium/tree/66-win branch. I'll submit Windows patches in a PR after this is merged. I've been using portable Linux for a while and I've had no problems. No changes were needed to get it to build. Windows looks fine to me: https://github.com/ungoogled-software/ungoogled-chromium-binaries/pull/16. @tectiv3 That was for 66, but 65 on master is currently broken. @tectiv3 65 on master worked until da4ccbd26. I just tested a master@e492ff672 macos build today and ran into a build error running the gn step. Here's the error message:\n+ ./out/Default/gn gen out/Default '--args=enable_ac3_eac3_audio_demuxing=true enable_google_now=false enable_hangout_services_extension=false enable_hevc_demuxing=true enable_iterator_debugging=false enable_mdns=false enable_mse_mpeg2ts_stream_parser=true enable_nacl=false enable_nacl_nonsfi=false enable_one_click_signin=false enable_reading_list=false enable_remoting=false enable_reporting=false enable_service_discovery=false enable_swiftshader=false enable_widevine=false exclude_unwind_tables=true fatal_linker_warnings=false ffmpeg_branding=\"Chrome\" fieldtrial_testing_like_official_build=true google_api_key=\"\" google_default_client_id=\"\" google_default_client_secret=\"\" is_debug=false optimize_webui=false proprietary_codecs=true remove_webcore_debug_symbols=true safe_browsing_mode=0 symbol_level=0 treat_warnings_as_errors=false use_gnome_keyring=false use_official_google_api_keys=false use_ozone=false use_sysroot=false use_unofficial_version_number=false clang_use_chrome_plugins=false is_clang=true use_jumbo_build=true' --fail-on-unused-args\nERROR at //chrome/BUILD.gn:1169:7: Can't load input file.\n      \"//iridium:trknotify\",\n      ^--------------------\nUnable to load:\n  /Users/ug/src/ungoogled-chromium/buildspace/tree/iridium/BUILD.gn\nI also checked in the secondary tree for:\n  /Users/ug/src/ungoogled-chromium/buildspace/tree/build/secondary/iridium/BUILD.gn. Credit for finding this and fixing first to @Tacolizard. Yeah. It seems they fixed the gtk2 build error upstream. Not really. MEI = media engagement index, which is about collecting analytics in order to determine whether to allow videos to auto-play\nIt does break the build if not included. It's only 14 bytes and doesn't contain anything interesting if printed with protoc --decode_raw. \n```\nmedia/base/media_switches.cc\n// Allows Media Engagement to use preloaded data to decide whether an origin has\n// a high media engagement.\n// - PreloadMediaEngagementData: enables a list of origins to be considered as\n//   having a high MEI until there is enough local data to determine the user's\n//   preferred behaviour.\n```\nMaybe in an official branded build they preload a larger file with real data in it?. The proto is at chrome/browser/media/media_engagement_preload.proto\nmessage PreloadedData {\n  // The data in DAFSA format.\n  optional bytes dafsa = 1;\n}\nSome more references:\nchrome/browser/media/media_engagement_preloaded_list.cc\nchrome/browser/media/media_engagement_session.cc\nnet/tools/dafsa . You're right, I'll remove them. I prefer excluding these files too. There's no good reason for the change. I restored the build_output substitution in the build script.. I think you're right here. I just wanted to make it clear it was Python 3, but your explanation makes more sense. ",
    "socketbox": "Sorry, I took the note in the instructions to (\"There is no official maintainer for this platform. If there is a problem, please submit a pull request or issue\") at face value.. Okay, thank you for the guidance. And also, of course, for your combined efforts on this project.. ",
    "stubkan": "I see now, that it is WebRTC that is disabled, causing this.. I'm using version 55.\nWebRTC enabled from 62 on, apparently.  Going to try to find a version 62+ \nDownloadable prebuilt binary from here for Windows is = version 55.\nWill an updated version for windows ever be made?. ",
    "ThatNerdyPikachu": "@Eloston If I'm correct, this is the right binary? https://ungoogled-software.github.io/ungoogled-chromium-binaries/releases/linux_static/64bit/55.0.2883.75-1. @Eloston Alright, thanks! I'll test and report back to you when I get the chance!. @Eloston Erm, sorry for the very very late response... Nope, that didn't work.. ",
    "faulesocke": "Some precompiled binary would not be accepted as an official void package. You guys have to figure, how to compile your own binary on the various platforms. I would recommend having a look at the chromium package's template and modify that to package this browser. That's what I did when I packaged Iridium for Void. However, first ask in IRC if they even want new browser packages, otherwise you're wasting your time.\nSince I'm not using chromium-derivatives anymore since Firefox 57, I'm not too motivated to put too much time into this (I was asked if I could help a little bit here). ",
    "dylanaraps": "Chromium requires a large number of patches to build on Alpine Linux (which solely uses musl). Most of these are likely required to get an ungoogled-chromium build working on a musl system.\nList of patches as well as build setup (inside APKBUILD): https://git.alpinelinux.org/aports/tree/community/chromium\nI'd love to see some movement here as Alpine doesn't ship with any privacy conscious browser full stop. Firefox is built with all telemetry enabled and not to mention it's stuck on an outdated non-LTS release.\nhttps://git.alpinelinux.org/aports/tree/testing/firefox\n(Firefox also hard-depends on dbus on Alpine so I can't use it. Though this is an entirely different issue). ",
    "CardealRusso": "thanks for the virus. https://github.com/squalus/ungoogled-chromium-winbuild/releases/tag/65.0.3325.181-1\nthis one. https://pt.aliexpress.com/. ",
    "ryanmusante": "Place that into /usr/lib/chromium? It seems to still not detect widevine component. I'm using AUR, I tried the binary as well as compiled version.. @Eloston I will need to recompile and test. Is it important to use thi specific version of widevine?. I think it is when I reboot the machine without closing the window. That and killing  externally, I wish there was a way to force disable it.. ",
    "Tacolizard": "ubuntu 18.04 build has been working fine for me for around a week.. ",
    "Obsessive": "Moved from Firefox quantum to Chrome thanks to this project ;). ",
    "UnnoTed": "I wrote a extension to make it easier to install extensions from the webstore by following the url method stated in the faq, All that it does is get chrome's version and extension's id and insert it into the crx url, The #extension-mime-request-handling flag is still required.\nhttps://github.com/UnnoTed/Ungoogled-Chromium-Extension-Installer. Same thing with master\n```sh\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium $ git clone https://github.com/Eloston/ungoogled-chromium\nCloning into 'ungoogled-chromium'...\nremote: Counting objects: 7575, done.\nremote: Compressing objects: 100% (58/58), done.\nremote: Total 7575 (delta 32), reused 64 (delta 28), pack-reused 7487\nReceiving objects: 100% (7575/7575), 3.76 MiB | 2.21 MiB/s, done.\nResolving deltas: 100% (4659/4659), done.\nChecking connectivity... done.\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium $ cd ungoogled-chromium\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ ls\nBUILDING.md  buildkit  buildkit-launcher.py  DESIGN.md  developer_utilities  DEVELOPING.md  FAQ.md  LICENSE  README.md  resources\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ mkdir -p buildspace/downloads\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ \nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ ./buildkit-launcher.py genbun linux_portable\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ ./buildkit-launcher.py getsrc\n2018-05-15 11:32:38,686 - DEBUG: Initialized logger 'buildkit'\n2018-05-15 11:32:38,686 - INFO: Downloading Chromium source code...\n2018-05-15 11:32:38,687 - INFO: Downloading buildspace/downloads/chromium-66.0.3359.139.tar.xz ...\nProgress: 100.0% of 583,978,636 B\n2018-05-15 11:36:07,499 - INFO: Downloading buildspace/downloads/chromium-66.0.3359.139.tar.xz.hashes ...\n2018-05-15 11:36:08,103 - INFO: Verifying hashes...\n2018-05-15 11:36:13,897 - DEBUG: Verifying md5 hash...\n2018-05-15 11:36:14,822 - DEBUG: Verifying sha1 hash...\n2018-05-15 11:36:15,478 - DEBUG: Verifying sha224 hash...\n2018-05-15 11:36:16,919 - DEBUG: Verifying sha256 hash...\n2018-05-15 11:36:18,344 - DEBUG: Verifying sha384 hash...\n2018-05-15 11:36:19,321 - DEBUG: Verifying sha512 hash...\n2018-05-15 11:36:20,301 - INFO: Extracting archive...\n2018-05-15 11:36:22,829 - DEBUG: Using BSD or GNU tar extractor\n2018-05-15 11:36:22,829 - DEBUG: tar command line: /bin/tar -xf buildspace/downloads/chromium-66.0.3359.139.tar.xz -C /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium/buildspace/tree\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ \nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ ./buildkit-launcher.py subdom\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ \nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ ./buildkit-launcher.py genpkg debian --flavor minimal\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium $ cd buildspace/tree\nvasp375@vasp375 /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium/buildspace/tree $ dpkg-buildpackage -b -uc\ndpkg-buildpackage: source package ungoogled-chromium-browser\ndpkg-buildpackage: source version 66.0.3359.139-1\ndpkg-buildpackage: source distribution stable\ndpkg-buildpackage: source changed by Maintainer maintainer@null\ndpkg-buildpackage: host architecture amd64\n dpkg-source --before-build tree\ndpkg-source: info: applying inox-patchset/fix-crash-in-is_cfi-true-builds-with-unbundled-ICU.patch\ndpkg-source: info: applying inox-patchset/fix-frame-buttons-rendering-too-large-when-using-OSX.patch\ndpkg-source: info: applying inox-patchset/chromium-exclude_unwind_tables.patch\ndpkg-source: info: applying inox-patchset/chromium-ffmpeg-r1.patch\ndpkg-source: info: applying inox-patchset/chromium-skia-harmony.patch\ndpkg-source: info: applying inox-patchset/0001-fix-building-without-safebrowsing.patch\ndpkg-source: info: applying inox-patchset/0002-fix-building-without-reporting.patch\ndpkg-source: info: applying inox-patchset/0003-disable-autofill-download-manager.patch\ndpkg-source: info: applying inox-patchset/0004-disable-google-url-tracker.patch\ndpkg-source: info: applying inox-patchset/0005-disable-default-extensions.patch\ndpkg-source: info: applying inox-patchset/0006-modify-default-prefs.patch\ndpkg-source: info: applying inox-patchset/0007-disable-web-resource-service.patch\ndpkg-source: info: applying inox-patchset/0008-restore-classic-ntp.patch\ndpkg-source: info: applying inox-patchset/0009-disable-google-ipv6-probes.patch\ndpkg-source: info: applying inox-patchset/0010-disable-gcm-status-check.patch\ndpkg-source: info: applying inox-patchset/0011-add-duckduckgo-search-engine.patch\ndpkg-source: info: applying inox-patchset/0013-disable-missing-key-warning.patch\ndpkg-source: info: applying inox-patchset/0014-disable-translation-lang-fetch.patch\ndpkg-source: info: applying inox-patchset/0015-disable-update-pings.patch\ndpkg-source: info: applying inox-patchset/0016-chromium-sandbox-pie.patch\ndpkg-source: info: applying inox-patchset/0017-disable-new-avatar-menu.patch\ndpkg-source: info: applying inox-patchset/0018-disable-first-run-behaviour.patch\ndpkg-source: info: applying inox-patchset/0019-disable-battery-status-service.patch\ndpkg-source: info: applying inox-patchset/0021-disable-rlz.patch\ndpkg-source: info: applying inox-patchset/9000-disable-metrics.patch\ndpkg-source: info: applying debian/gn/libcxx.patch\ndpkg-source: info: applying debian/gn/parallel.patch\ndpkg-source: info: applying debian/gn/narrowing.patch\ndpkg-source: info: applying debian/disable/fonts.patch\ndpkg-source: info: applying debian/disable/fuzzers.patch\ndpkg-source: info: applying debian/disable/welcome-page.patch\ndpkg-source: info: applying debian/disable/google-api-warning.patch\ndpkg-source: info: applying debian/disable/device-notifications.patch\ndpkg-source: info: applying debian/fixes/mojo.patch\ndpkg-source: info: applying debian/fixes/optional.patch\ndpkg-source: info: applying debian/fixes/optimize.patch\ndpkg-source: info: applying debian/fixes/ps-print.patch\ndpkg-source: info: applying debian/fixes/inspector.patch\ndpkg-source: info: applying debian/fixes/gpu-timeout.patch\ndpkg-source: info: applying debian/fixes/duplicate-name.patch\ndpkg-source: info: applying debian/fixes/overloaded-call.patch\ndpkg-source: info: applying debian/fixes/incomplete-types.patch\ndpkg-source: info: applying debian/fixes/ambiguous-aliases.patch\ndpkg-source: info: applying debian/fixes/widevine-revision.patch\ndpkg-source: info: applying debian/fixes/connection-message.patch\ndpkg-source: info: applying debian/fixes/chromedriver-revision.patch\ndpkg-source: info: applying debian/fixes/skia_buildfix.patch\ndpkg-source: info: applying debian/warnings/sequence-point.patch\ndpkg-source: info: applying debian/warnings/initialization.patch\ndpkg-source: info: applying iridium-browser/net-cert-increase-default-key-length-for-newly-gener.patch\ndpkg-source: info: applying iridium-browser/mime_util-force-text-x-suse-ymp-to-be-downloaded.patch\ndpkg-source: info: applying iridium-browser/prefs-only-keep-cookies-until-exit.patch\ndpkg-source: info: applying iridium-browser/prefs-always-prompt-for-download-directory-by-defaul.patch\ndpkg-source: info: applying iridium-browser/updater-disable-auto-update.patch\ndpkg-source: info: applying iridium-browser/Remove-EV-certificates.patch\ndpkg-source: info: applying iridium-browser/safe_browsing-disable-incident-reporting.patch\ndpkg-source: info: applying iridium-browser/safe_browsing-disable-reporting-of-safebrowsing-over.patch\ndpkg-source: info: applying iridium-browser/safe_browsing-support-trk-prefix.patch\ndpkg-source: info: applying iridium-browser/all-add-trk-prefixes-to-possibly-evil-connections.patch\ndpkg-source: info: applying iridium-browser/promo-disable-Google-promotion-fetching.patch\ndpkg-source: info: applying iridium-browser/browser-disable-profile-auto-import-on-first-run.patch\ndpkg-source: info: applying ungoogled-chromium/clear-http-auth-cache-menu-item.patch\ndpkg-source: info: applying ungoogled-chromium/disable-crash-reporter.patch\ndpkg-source: info: applying ungoogled-chromium/disable-formatting-in-omnibox.patch\ndpkg-source: info: applying ungoogled-chromium/disable-google-host-detection.patch\ndpkg-source: info: applying ungoogled-chromium/replace-google-search-engine-with-nosearch.patch\ndpkg-source: info: applying ungoogled-chromium/disable-signin.patch\ndpkg-source: info: applying ungoogled-chromium/disable-translate.patch\ndpkg-source: info: applying ungoogled-chromium/popups-to-tabs.patch\ndpkg-source: info: applying ungoogled-chromium/disable-untraceable-urls.patch\ndpkg-source: info: applying ungoogled-chromium/add-ipv6-probing-option.patch\ndpkg-source: info: applying ungoogled-chromium/disable-profile-avatar-downloading.patch\ndpkg-source: info: applying ungoogled-chromium/remove-disable-setuid-sandbox-as-bad-flag.patch\ndpkg-source: info: applying ungoogled-chromium/disable-gcm.patch\ndpkg-source: info: applying ungoogled-chromium/disable-domain-reliability.patch\ndpkg-source: info: applying ungoogled-chromium/block-trk-and-subdomains.patch\ndpkg-source: info: applying ungoogled-chromium/disable-intranet-redirect-detector.patch\ndpkg-source: info: applying ungoogled-chromium/fix-building-without-one-click-signin.patch\ndpkg-source: info: applying ungoogled-chromium/enable-page-saving-on-more-pages.patch\ndpkg-source: info: applying ungoogled-chromium/disable-download-quarantine.patch\ndpkg-source: info: applying ungoogled-chromium/disable-gaia.patch\ndpkg-source: info: applying ungoogled-chromium/disable-fonts-googleapis-references.patch\ndpkg-source: info: applying ungoogled-chromium/disable-webstore-urls.patch\ndpkg-source: info: applying ungoogled-chromium/fix-learn-doubleclick-hsts.patch\ndpkg-source: info: applying ungoogled-chromium/disable-webrtc-log-uploader.patch\ndpkg-source: info: applying ungoogled-chromium/fix-building-without-mdns-and-service-discovery.patch\ndpkg-source: info: applying ungoogled-chromium/use-local-devtools-files.patch\ndpkg-source: info: applying ungoogled-chromium/add-flag-to-stack-tabs.patch\ndpkg-source: info: applying ungoogled-chromium/add-flag-to-configure-extension-downloading.patch\ndpkg-source: info: applying ungoogled-chromium/disable-network-time-tracker.patch\ndpkg-source: info: applying ungoogled-chromium/add-flag-for-search-engine-collection.patch\ndpkg-source: info: applying ungoogled-chromium/add-flag-to-disable-beforeunload.patch\ndpkg-source: info: applying ungoogled-chromium/add-flag-to-enable-potentially-annoying-security-features.patch\ndpkg-source: info: applying ungoogled-chromium/disable-mei-preload.patch\ndpkg-source: info: applying ungoogled-chromium/add-flag-to-force-punycode-hostnames.patch\ndpkg-source: info: applying ungoogled-chromium/fix-screen-sharing-in-google-meet.patch\ndpkg-source: info: applying ubuntu/no-new-ninja-flag.patch\ndpkg-source: info: applying ubuntu/relax-ninja-version-requirement.patch\ndpkg-source: info: applying ungoogled-chromium/linux/manpage.patch\n fakeroot debian/rules clean\ndh clean\n   dh_testdir\n   debian/rules override_dh_auto_clean\nmake[1]: Entering directory '/media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium/buildspace/tree'\nrm -rf out\nfind . -name *.pyc -execdir rm -f {} \\;\ndh_auto_clean\nmake[1]: Leaving directory '/media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium/buildspace/tree'\n   dh_clean\n    rm -f debian/debhelper-build-stamp\n    rm -f debian/ungoogled-chromium.substvars\n    rm -f debian/ungoogled-chromium..debhelper\n    rm -rf debian/ungoogled-chromium/\n    rm -f debian/ungoogled-chromium-l10n.substvars\n    rm -f debian/ungoogled-chromium-l10n..debhelper\n    rm -rf debian/ungoogled-chromium-l10n/\n    rm -f debian/ungoogled-chromium-shell.substvars\n    rm -f debian/ungoogled-chromium-shell..debhelper\n    rm -rf debian/ungoogled-chromium-shell/\n    rm -f debian/ungoogled-chromium-widevine.substvars\n    rm -f debian/ungoogled-chromium-widevine..debhelper\n    rm -rf debian/ungoogled-chromium-widevine/\n    rm -f debian/ungoogled-chromium-driver.substvars\n    rm -f debian/ungoogled-chromium-driver..debhelper\n    rm -rf debian/ungoogled-chromium-driver/\n    rm -f debian/ungoogled-chromium-common.substvars\n    rm -f debian/ungoogled-chromium-common..debhelper\n    rm -rf debian/ungoogled-chromium-common/\n    rm -rf debian/.debhelper/\n    rm -f debian/.debhelper.log\n/media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium/buildspace/tree/debian/clean: 1: /media/vasp375/125EE02A0436C528/chromium/ungoogled-chromium/buildspace/tree/debian/clean: debian/files: not found\ndh_clean: debian/clean (executable config) returned exit code 127\ndebian/rules:103: recipe for target 'clean' failed\nmake: ** [clean] Error 127\ndpkg-buildpackage: error: fakeroot debian/rules clean gave error exit status 2\n. I was able to get it compiled through a docker container with Debian 9, I had to add `deb http://deb.debian.org/debian stretch main` to `/etc/apt/sources.list` just to install some deps that i couldn't find...sh\n libavformat57 : Depends: libchromaprint1 (>= 1.3.2) but it is not going to be installed\n                 Depends: libopenmpt0 (>= 0.2.7025~beta20.1) but it is not going to be installed\n ungoogled-chromium : Depends: libicu57 (>= 57.1-1~) but it is not going to be installed\n                      Depends: libjpeg62-turbo (>= 1:1.5.1-2) but it is not going to be installed\n                      Depends: libre2-3 (>= 20160901) but it is not going to be installed\n                      Depends: libvpx4 (>= 1.6.0) but it is not going to be installed\n                      Depends: libwebpdemux2 (>= 0.5.1) but it is not going to be installed\n                      Depends: libwebpmux2 (>= 0.5.1) but it is not going to be installed\n```\nBut it's working fine now, thanks.. ",
    "Kherby": "I love it as well!! <3\nI'm using ungoogled chromium for all my GUI based network devices and never had any problem with it...\nFor normal browsing i still use a customized Firefox ESR 52, with noscript, uBlock Origin and a few more addons.\nFirefox only sucks with youtube 4k content... On my i5 7200u Notebook youtube 4k content is causing ~65% CPU load where Chrome only needs ~12% CPU and ~15% iGPU load for the same 4k content!. Thanks for the link!\nYes, a installer would be nice but as long as i don't lose my bookmarks i'm fine with the portable solution.\nI'm using ungoogled chromium only for my GUI based network devices and for normal browsing i'm using Waterfox with some addons.. ",
    "ericdmoore": "+1 for this product. Gave you a shout out here too: https://news.ycombinator.com/item?id=18047418. ",
    "niftylettuce": "@Eloston you should set up a donation link with PayPal, Patreon, or Open Collective so you can work on this more \ud83d\udc4d . ",
    "jmauss": "Much appreciated!. ",
    "TRSx80": "Wow! Thanks for quick reply!\nYes under chrome://settings/content/microphone it looks like this:\nMicrophone\nG533 Wireless Headset Dongle\nAsk before accessing (recommended)       [toggle ON]\nBlock\nNo Sites Added\nAllow\nhttps://voicenotebook.com:443\nhttps://voicenote.in:443\nhttps://test.webrtc.org:443. Just tried that. It took me a few minutes to remove old version, install (extract, really) the portable version, and then figure out the \"allow user namespaces\" thing.\nBut the answer is yes, still appear to be having same problem.\nI launched it from Konsole, and I did get a few error messages, not sure if these will mean anything to you or not:\n[19948:20002:0518/164632.483345:ERROR:nss_util.cc(724)] After loading Root Certs, loaded==false: NSS error code: -8018\n[19948:20009:0518/164632.512517:ERROR:in_progress_cache_impl.cc(93)] Could not read download entries from file because there was a read failure.\nATTENTION: default value of option force_s3tc_enable overridden by environment.\n[20023:20023:0518/164632.684548:ERROR:sandbox_linux.cc(379)] InitializeSandbox() called with multiple threads in process gpu-process.\n[1:18:0518/164719.149559:ERROR:adm_helpers.cc(73)] Failed to query stereo recording.\n[1:18:0518/164725.256161:ERROR:sctptransport.cc(818)] SctpTransport->SendQueuedStreamResets(): Failed to send a stream reset for 1 streams: [0x00000009] Bad file descriptor\n[1:18:0518/164741.022261:ERROR:sctptransport.cc(818)] SctpTransport->SendQueuedStreamResets(): Failed to send a stream reset for 1 streams: [0x00000009] Bad file descriptor\n[1:18:0518/164754.243918:ERROR:sctptransport.cc(818)] SctpTransport->SendQueuedStreamResets(): Failed to send a stream reset for 1 streams: [0x00000009] Bad file descriptor\nI also just realized that I had old version of Chromium still open when I executed sudo apt remove ungoogled-chromium ungoogled-chromium-common ungoogled-chromium-driver ungoogled-chromium-shell ungoogled-chromium-widevine. I closed it and started the portable version but all settings (and plug-ins, etc.) from old version were still there. I am now thinking I should have done purge? I will wait for your instructions before proceeding further.. Just for informational purposes, I got busy with other projects and never got back to working on this. But I expect to at some point, if/when I do, I will try and remember to report back, one way or the other.\nThank you very much for your time and keep up the great work! Cheers!. ",
    "ricardbejarano": "Just FYI, 67.0.3396.79 patches a high severity bug in CSP header handling that could lead to clickjacking and XSS, it'd be great to use it as the reference revision here.\nEdit: also, someone in the comments of that blog post says .79 fixes tabs hogging the CPU on Mac, but the blog post does not mention such fix.. ",
    "Wyse-": "Building version 67.0.3396.87-1 on Windows seems to fail. Actually the build process doesn't even start.\nThis is the output I get when running build.bat:\nhttps://paste.debian.net/plain/1030109\nAlso note that on same setup the build process starts normally for version 66.0.3359.181-1, so I'm guessing this is something inherent to the latest update.. No issues so far on the Windows build mentioned above.. Build of the master branch on Windows is indeed failing. I pretty much got the same error as @Ti-R, here it is:\nhttps://paste.debian.net/plain/1031758\n. @Eloston, @Ti-R build successful on Windows (commit e9ce6ca67ed84d68a2716e7cca8ba55d3feca963 of develop branch). Compiled binaries available here.. @Eloston I believe they are, however I thought waiting for a stable release on the master branch would be best. I just noticed you added a spot for builds of the develop branch though, I'll submit them later.. The culprit seems to be line 22 of build.bat:\ncall python tools\\gn\\bootstrap\\bootstrap.py -o out\\Default\\gn.exe -s\nHere's the output (I redacted my full PATH, I don't think it's necessary):\nhttps://paste.debian.net/plain/1030249\n. Okay, I believe I might've found out what is causing this. \nHere's the full content of the bootstrap.py and setup_toolchain.py files for reference:\nbootstrap.py\nsetup_toolchain.py\nFirst of all it doesn't seem like the above command is correct batch syntax. It's being built by bootstrap.py (lines 125-137) and probably executed some other way. \nFrom what I understand it executes setup_toolchain.py with python 2.7 and passes the rest of its contents as an array of arguments to the setup_toolchain.py script, which performs a check on its arguments (lines 185-190). In our case there's 6 (I'm guessing setup_toolchain.py itself is considered an argument) strings being passed as arguments and since they should be 8 the script returns exit code 2.\nAlso, the order in which the argument strings are being passed appears to be different from the one specified in lines 186-189 of setup_toolchain.py:\n'Usage setup_toolchain.py '\n          '<visual studio path> <win sdk path> '\n          '<runtime dirs> <target_os> <target_cpu> '\n          '<environment block name|none> <goma_disabled>'\nIt seems like setup_toolchain.py is being fed the following:\nwin_sdk_path = sys.argv[2] (C:\\\\Program Files (x86)\\\\Windows Kits\\x08)\n  runtime_dirs = sys.argv[3] (C:\\\\Windows\\\\Sysnative;C:\\\\Windows/SysWOW64)\n  target_os = sys.argv[4] (x64)\n  target_cpu = sys.argv[5] (true)\n  environment_block_name = sys.argv[6] (null)\n  goma_disabled = sys.argv[7] (null)\nI believe we're missing target_os and environment_block_name when calling setup_toolchain.py.\nI tried modifying setup_toolchain.py with these values\nwin_sdk_path = r'C:\\Program Files (x86)\\Windows Kits\\10'\n  runtime_dirs = r'C:\\Windows\\Sysnative;C:\\Windows\\SysWOW64'\n  target_os = 'win32'\n  target_cpu = 'x64'\n  environment_block_name = 'none'\n  goma_disabled = 'true'\nAnd while this makes build.bat go further than before I get the following output:\nhttps://paste.debian.net/plain/1030470. Awesome, 67.0.3396.87 Windows binaries built successfully on commit https://github.com/Eloston/ungoogled-chromium/commit/6453c2d13a03ee151211a82c06d281209876f688 of develop branch.\nHere they are if anyone needs them:\nhttps://github.com/Wyse-/ungoogled-chromium/releases/tag/67.0.3396.87-2. Yes, overwriting everything in the install directory is perfectly fine, on Windows ungoogled-chromium stores user data in the AppData folder (like Chromium does). See this documentation for more info.. Sorry for the delay.\nI just tested the new scripts and this is what I get when running py ungoogled_packaging\\build.py:\nhttps://paste.debian.net/plainh/a61acaac\nIt also doesn't seem clear which python version is supposed to run which script: they all have #!/usr/bin/env python3 above the license header, however build.py does some version checks against python 2.7.\nSpecifying the python version as an argument to py (e.g. py -2) in the instructions might be a good idea.. Ah, I see, I thought py was included in both python versions. As to why I ran build.py with python instead of py: running the script with py gave me build.py: error: Unable to find pypiwin32 in Python 2 installation., so I assumed it was supposed to be ran with python 2.7 (the instructions also specify pip install pypiwin32 for python2.7.\nAssuming all ungoogled-chromium scripts should be ran with python 3.7, does this mean that pypiwin32 is needed for python 3.7 as well? I tried running pip install pypiwin32 with the python 3.7 pip executable but I still get the same error as above (build.py: error: Unable to find pypiwin32 in Python 2 installation.).. Tested the the scripts on the latest commit and build.py still seems to check for pypiwin32 in lines 85-87. After commenting these out I get the following:\nhttps://paste.debian.net/plainh/cc66f445. My bad, I assumed the script was looking for pypiwin32 in the python3 installation, I should've taken a look at the code.\nApparently the check is not working even though I did install pypiwin32 through pip (pip install pypiwin32). If I run import pypiwin32 in a Python 2 shell I get ImportError: No module named pypiwin32.\nFrom what I can see it seems like pypiwin32 is not supposed to be imported with its name, but with import win32api.\nMaybe line 85 should be changed to\nresult = subprocess.run((python2_exe, '-c', 'import win32api'))\nAfter this change the script works, until, while applying patches, I get this:\nhttps://paste.debian.net/plainh/155d21b4. > I'm guessing the build instructions were confusing to you, because the exact steps to take are all there. Could you tell me what confused you, or submit a PR with fixes?\nActually the instructions are just fine, the only thing that confused me was that the build.py script was checking for a Python 2 module while being ran with Python 3: I assumed that it was looking for the module in the Python 3 installation, which in turn made me assume that either the check was not needed or that pypiwin32 was needed in Python 3 as well.\nThat was all caused by the check not passing even though pypiwin32 was installed correctly (and by me not actually checking the code!), but now that it's fixed with https://github.com/Eloston/ungoogled-chromium/pull/488 I doubt that it'll be a problem for anyone else.\n\nThat's expected. The patches haven't been updated yet. I might have an opportunity to update them this and/or next week, but I can't guarantee anything.\n\nI see, no worries. I'll proceed to building and submitting the binaries when the patches are ready.. Just started testing, there's a problem with this line, the $ character should be a %, like in the other URLs.\nAfter this change I get this error:\nhttps://paste.debian.net/plainh/442baf75. @shiromichi\n\n@Wyse- I tried to build d307bb0, but failed to download LLVM(HTTP Error 404: Not Found)\n\nYes, that's what I meant with\n\nthere's a problem with this line, the $ character should be a %, like in the other URLs.\n\nThe version number is not getting properly replaced in the URL and the script is calling\nhttps://prereleases.llvm.org/win-snapshots/LLVM-$(version)s-win64.exe\nwhich delivers a 404, instead of\nhttps://prereleases.llvm.org/win-snapshots/LLVM-8.0.0-r339319-win64.exe\nwhich properly downloads LLVM\nThe corrected line would be\nurl = https://prereleases.llvm.org/win-snapshots/LLVM-%(version)s-win64.exe\n@Eloston \n\nI noticed your current working directory is changing between vcvars64.bat and bootstrap.py\n\nYou're correct, I believe the script is switching directory after executing vcvars64.bat, C:\\Users\\Wyse\\source is a Visual Studio related directory. vcvars64.bat behaves the same way when called manually:\nhttps://paste.debian.net/plainh/ccad1c34\nThe fixes I'm testing on Wyse-/ungoogled-chromium seem to be working for me, however I now get the same issue as @shiromichi:\nhttps://paste.debian.net/plainh/ad3e9a70. The latest fix (https://github.com/Eloston/ungoogled-chromium/commit/dc456c6943bb9fcf025705c6b25dfd40a3b45afb) worked for me, however I now get this:\nhttps://paste.debian.net/plainh/a30ba8c5. ",
    "Ti-R": "Hello,\nI'm trying to compile this revision (The master)\nhttps://github.com/Eloston/ungoogled-chromium/commit/7c9d189ff0c4ba33d923bc67f47998d4fb6460a2\nThis version possess one more \"commit\" to enhance the tag version\nhttps://github.com/Eloston/ungoogled-chromium/tree/67.0.3396.87-2\nAll is going well until it do not find \"kDisableWebRtcHWDecoding\"\nThis var is only available if ENABLE_WEBRTC and OS_CHROMEOS are enable inside \"content\\public\\common\\content_switches.cc\"\nENABLE_WEBRTC flag seems to be part of media_buildflags inside \"media\\BUILD.gn\" file.\nSo the build seems to miss a flag, maybe ENABLE_WEBRTC  or OS_CHROMEOS, how can I solve the compilation part ?\nOr did I not install the good SDK\nMy softwares are: \nVisual studio Community 2017 - 15.5.27130.2010\nWindows Software Development Kit - Windows 10.0.15063.468 is install among others.\nThx to looking at my problem and point me in the good direction.\nProject is great !\nThe error:\n```\n[17510/21319] CXX obj/content/browser/browser/browser_jumbo_11.obj\nFAILED: obj/content/browser/browser/browser_jumbo_11.obj\n../../third_party/llvm-build/Release+Asserts/bin/clang-cl.exe /nologo /showIncludes  \"-imsvcC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.12.25827\\ATLMFC\\include\" \"-imsvcC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.12.25827\\include\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\ucrt\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\shared\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\um\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\winrt\" \"-imsvcC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.12.25827\\ATLMFC\\include\" \"-imsvcC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.12.25827\\include\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\ucrt\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\shared\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\um\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\winrt\" -DENABLE_SCREEN_CAPTURE=1 -D__ATLHOST_H__ -DV8_DEPRECATION_WARNINGS -DUSE_AURA=1 -DNO_TCMALLOC -DOFFICIAL_BUILD -DCHROMIUM_BUILD -D\"CR_CLANG_REVISION=\\\"328716-2\\\"\" -D_HAS_EXCEPTIONS=0 -D__STD_C -D_CRT_RAND_S -D_CRT_SECURE_NO_DEPRECATE -D_SCL_SECURE_NO_DEPRECATE -DDEPRECATEDENUMERATOR(x)=[[deprecated(x)]] -D_ATL_NO_OPENGL -D_WINDOWS -DCERT_CHAIN_PARA_HAS_EXTRA_FIELDS -DPSAPI_VERSION=1 -DWIN32 -D_SECURE_ATL -D_USING_V110_SDK71_ -DWINAPI_FAMILY=WINAPI_FAMILY_DESKTOP_APP -DWIN32_LEAN_AND_MEAN -DNOMINMAX -D_UNICODE -DUNICODE -DNTDDI_VERSION=0x0A000002 -D_WIN32_WINNT=0x0A00 -DWINVER=0x0A00 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DCONTENT_IMPLEMENTATION -DV8_USE_EXTERNAL_STARTUP_DATA -DWEBP_EXTERN=extern -DUSE_EGL -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_STATIC_IMPLEMENTATION -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_FILE -DUCHAR_TYPE=wchar_t -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_HAS_PNG_LIBRARY -DSK_HAS_WEBP_LIBRARY -DSK_HAS_JPEG_LIBRARY -DSK_SUPPORT_GPU=1 -DGR_GL_FUNCTION_TYPE=__stdcall -DLEVELDB_PLATFORM_CHROMIUM=1 -DDeleteFile=DeleteFileW -DOS_WIN -DWEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=0 -DGTEST_RELATIVE_PATH -DWEBRTC_CHROMIUM_BUILD -DWEBRTC_WIN -D_CRT_SECURE_NO_WARNINGS -DMESA_EGL_NO_X11_HEADERS -DXML_STATIC -DNO_MAIN_THREAD_WRAPPING -DFLAC__NO_DLL -I. -I../.. -Igen -I../../third_party/libwebp/src -I../../third_party/khronos -I../../gpu -I../../third_party/wtl/include -I../../third_party/libyuv/include -I../../third_party/protobuf/src -I../../third_party/ced/src -I../../third_party/icu/source/common -I../../third_party/icu/source/i18n -I../../skia/config -I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/encode -I../../third_party/skia/include/gpu -I../../third_party/skia/include/images -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pdf -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/src/gpu -I../../third_party/skia/src/sksl -I../../third_party/libwebm/source -I../../third_party/protobuf/src -Igen/protoc_out -I../../third_party/leveldatabase -I../../third_party/leveldatabase/src -I../../third_party/leveldatabase/src/include -I../../third_party/webrtc_overrides -I../../testing/gtest/include -I../../third_party/webrtc -I../../third_party/webrtc_overrides -I../../third_party/webrtc -Igen/third_party/metrics_proto -I../../third_party/boringssl/src/include -I../../third_party/blink -Igen/third_party/blink -I../../v8/include -Igen/v8/include -I../../third_party/angle/src/common/third_party/base -Igen/angle -I../../third_party/brotli/include -I../../third_party/re2/src -I../../third_party/zlib -I../../third_party/mesa/src/include -I../../third_party/expat/files/lib /utf-8 /X -fcolor-diagnostics -Xclang -mllvm -Xclang -instcombine-lower-dbg-declare=0 /Gy /FS /bigobj /d2FastFail /Zc:sizedDealloc- -fmsc-version=1911 -m64 /W4 -Wimplicit-fallthrough -Wthread-safety /wd4091 /wd4127 /wd4251 /wd4275 /wd4312 /wd4324 /wd4351 /wd4355 /wd4503 /wd4589 /wd4611 /wd4100 /wd4121 /wd4244 /wd4505 /wd4510 /wd4512 /wd4610 /wd4838 /wd4995 /wd4996 /wd4456 /wd4457 /wd4458 /wd4459 /wd4702 -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-unused-lambda-capture -Wno-user-defined-warnings -Wno-enum-compare-switch -Wno-null-pointer-arithmetic /O1 /Ob2 /Oy- /Zc:inline /Gw /Oi /MT -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wshadow /wd4267 /TP /wd4577 /GR- /c gen/content/browser/browser_jumbo_11.cc /Foobj/content/browser/browser/browser_jumbo_11.obj /Fd\"obj/content/browser/browser_cc.pdb\"\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\nIn file included from gen/content/browser/browser_jumbo_11.cc:51:\n.../../content/browser/renderer_host/render_process_host_impl.cc(2850,15):  error: no member named 'kDisableWebRtcHWDecoding' in namespace 'switches'\n    switches::kDisableWebRtcHWDecoding,\n    ~~~~~~~~~~^\n.../../content/browser/renderer_host/render_process_host_impl.cc(2851,15):  error: no member named 'kDisableWebRtcHWEncoding' in namespace 'switches'; did you mean 'kDisableWebRtcEncryption'?\n    switches::kDisableWebRtcHWEncoding,\n    ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n              kDisableWebRtcEncryption\n../..\\content/public/common/content_switches.h(251,34):  note: 'kDisableWebRtcEncryption' declared here\nCONTENT_EXPORT extern const char kDisableWebRtcEncryption[];\n                                 ^\nIn file included from gen/content/browser/browser_jumbo_11.cc:51:\n.../../content/browser/renderer_host/render_process_host_impl.cc(2886,34):  error: no matching function for call to 'ArraySizeHelper'\n                                 arraysize(kSwitchNames));\n                                 ^~~~~~~~~~~~~~~~~~~~~~~\n../..\\base/macros.h(54,34):  note: expanded from macro 'arraysize'\ndefine arraysize(array) (sizeof(ArraySizeHelper(array)))\n                             ^~~~~~~~~~~~~~~\n\n../..\\base/macros.h(53,40):  note: candidate template ignored: could not match 'T [N]' against 'const char *const []'\ntemplate  char (&ArraySizeHelper(T (&array)[N]))[N];\n                                       ^\n3 errors generated.\n[17511/21319] CXX obj/content/browser/browser/browser_jumbo_10.obj\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\n[17512/21319] CXX obj/content/browser/browser/browser_jumbo_9.obj\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\n[17513/21319] CXX obj/content/browser/browser/browser_jumbo_6.obj\nFAILED: obj/content/browser/browser/browser_jumbo_6.obj\n../../third_party/llvm-build/Release+Asserts/bin/clang-cl.exe /nologo /showIncludes  \"-imsvcC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.12.25827\\ATLMFC\\include\" \"-imsvcC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.12.25827\\include\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\ucrt\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\shared\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\um\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\winrt\" \"-imsvcC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.12.25827\\ATLMFC\\include\" \"-imsvcC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.12.25827\\include\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\ucrt\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\shared\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\um\" \"-imsvcC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\winrt\" -DENABLE_SCREEN_CAPTURE=1 -D__ATLHOST_H__ -DV8_DEPRECATION_WARNINGS -DUSE_AURA=1 -DNO_TCMALLOC -DOFFICIAL_BUILD -DCHROMIUM_BUILD -D\"CR_CLANG_REVISION=\\\"328716-2\\\"\" -D_HAS_EXCEPTIONS=0 -D__STD_C -D_CRT_RAND_S -D_CRT_SECURE_NO_DEPRECATE -D_SCL_SECURE_NO_DEPRECATE -DDEPRECATEDENUMERATOR(x)=[[deprecated(x)]] -D_ATL_NO_OPENGL -D_WINDOWS -DCERT_CHAIN_PARA_HAS_EXTRA_FIELDS -DPSAPI_VERSION=1 -DWIN32 -D_SECURE_ATL -D_USING_V110_SDK71_ -DWINAPI_FAMILY=WINAPI_FAMILY_DESKTOP_APP -DWIN32_LEAN_AND_MEAN -DNOMINMAX -D_UNICODE -DUNICODE -DNTDDI_VERSION=0x0A000002 -D_WIN32_WINNT=0x0A00 -DWINVER=0x0A00 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DCONTENT_IMPLEMENTATION -DV8_USE_EXTERNAL_STARTUP_DATA -DWEBP_EXTERN=extern -DUSE_EGL -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DU_USING_ICU_NAMESPACE=0 -DU_ENABLE_DYLOAD=0 -DU_STATIC_IMPLEMENTATION -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_FILE -DUCHAR_TYPE=wchar_t -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_HAS_PNG_LIBRARY -DSK_HAS_WEBP_LIBRARY -DSK_HAS_JPEG_LIBRARY -DSK_SUPPORT_GPU=1 -DGR_GL_FUNCTION_TYPE=__stdcall -DLEVELDB_PLATFORM_CHROMIUM=1 -DDeleteFile=DeleteFileW -DOS_WIN -DWEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=0 -DGTEST_RELATIVE_PATH -DWEBRTC_CHROMIUM_BUILD -DWEBRTC_WIN -D_CRT_SECURE_NO_WARNINGS -DMESA_EGL_NO_X11_HEADERS -DXML_STATIC -DNO_MAIN_THREAD_WRAPPING -DFLAC__NO_DLL -I. -I../.. -Igen -I../../third_party/libwebp/src -I../../third_party/khronos -I../../gpu -I../../third_party/wtl/include -I../../third_party/libyuv/include -I../../third_party/protobuf/src -I../../third_party/ced/src -I../../third_party/icu/source/common -I../../third_party/icu/source/i18n -I../../skia/config -I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/encode -I../../third_party/skia/include/gpu -I../../third_party/skia/include/images -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pdf -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/skia/src/gpu -I../../third_party/skia/src/sksl -I../../third_party/libwebm/source -I../../third_party/protobuf/src -Igen/protoc_out -I../../third_party/leveldatabase -I../../third_party/leveldatabase/src -I../../third_party/leveldatabase/src/include -I../../third_party/webrtc_overrides -I../../testing/gtest/include -I../../third_party/webrtc -I../../third_party/webrtc_overrides -I../../third_party/webrtc -Igen/third_party/metrics_proto -I../../third_party/boringssl/src/include -I../../third_party/blink -Igen/third_party/blink -I../../v8/include -Igen/v8/include -I../../third_party/angle/src/common/third_party/base -Igen/angle -I../../third_party/brotli/include -I../../third_party/re2/src -I../../third_party/zlib -I../../third_party/mesa/src/include -I../../third_party/expat/files/lib /utf-8 /X -fcolor-diagnostics -Xclang -mllvm -Xclang -instcombine-lower-dbg-declare=0 /Gy /FS /bigobj /d2FastFail /Zc:sizedDealloc- -fmsc-version=1911 -m64 /W4 -Wimplicit-fallthrough -Wthread-safety /wd4091 /wd4127 /wd4251 /wd4275 /wd4312 /wd4324 /wd4351 /wd4355 /wd4503 /wd4589 /wd4611 /wd4100 /wd4121 /wd4244 /wd4505 /wd4510 /wd4512 /wd4610 /wd4838 /wd4995 /wd4996 /wd4456 /wd4457 /wd4458 /wd4459 /wd4702 -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-inconsistent-missing-override -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-address-of-packed-member -Wno-unused-lambda-capture -Wno-user-defined-warnings -Wno-enum-compare-switch -Wno-null-pointer-arithmetic /O1 /Ob2 /Oy- /Zc:inline /Gw /Oi /MT -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wshadow /wd4267 /TP /wd4577 /GR- /c gen/content/browser/browser_jumbo_6.cc /Foobj/content/browser/browser/browser_jumbo_6.obj /Fd\"obj/content/browser/browser_cc.pdb\"\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\nIn file included from gen/content/browser/browser_jumbo_6.cc:43:\n.../../content/browser/gpu/gpu_process_host.cc(138,15):  error: no member named 'kDisableWebRtcHWEncoding' in namespace 'switches'; did you mean 'kDisableWebRtcEncryption'?\n    switches::kDisableWebRtcHWEncoding,\n    ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n              kDisableWebRtcEncryption\n../..\\content/public/common/content_switches.h(251,34):  note: 'kDisableWebRtcEncryption' declared here\nCONTENT_EXPORT extern const char kDisableWebRtcEncryption[];\n                                 ^\n1 error generated.\n[17514/21319] CXX obj/content/browser/browser/browser_jumbo_15.obj\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\n[17515/21319] CXX obj/content/browser/browser/browser_jumbo_8.obj\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\n[17516/21319] CXX obj/content/browser/browser/browser_jumbo_7.obj\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\n[17517/21319] CXX obj/content/browser/browser/browser_jumbo_5.obj\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\n[17518/21319] CXX obj/content/browser/browser/browser_jumbo_4.obj\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\n[17519/21319] CXX obj/content/browser/browser/browser_jumbo_12.obj\nclang-cl.exe: warning: argument unused during compilation: '/X' [-Wunused-command-line-argument]\nninja: build stopped: subcommand failed.\n```\n\nI try it again from start with Visual studio Community 2017 15.7.4.\nIt does the same.. @Eloston, @Wyse- build successful on Windows also for me.\nTook me a while to come back.\nI got some problems some days ago, with \n\nThe procedure entry point _o_memset could not be located in the dynamic link library api-mswin-crt-private-l1-1-0.dll\n\nDue to some of my Windows Software Development Kit missing \"Debugging Tools for Windows\" option\nAll is ok now.\nI compile this version\n* Move VA-API patch back into Linux bundles\ne9ce6ca67ed84d68a2716e7cca8ba55d3feca963\n. Hello @Eloston , I submit a pull request to fix the issue.\nhttps://github.com/Eloston/ungoogled-chromium/pull/445\n. ",
    "vivienney": "Will there be an update for the Windows binaries to 66.0.3359.181-1?. ",
    "BrianD91": "This seems to be true on Kubuntu as well. ",
    "jlj2": "The steps described in your entry are correct. \nEmploying those steps in this installation, dragging and dropping the Disable HTML5 Autoplay extension using the Extension ID from this URL also generates the error described above.\nA 'Learn more' link is now noted across from the error message;  it opens a tab announcing:\n\"support.9oo91e.qjz9zk is blocked\nRequests to the server have been blocked by an extension.\nTry disabling your extensions.\nERR_BLOCKED_BY_CLIENT\"\nThe only enabled extensions are Chromium PDF Viewer and CryptoTokenExtension, as supplied by default in ungoogled-chromium, and their 'enable' switch is greyed out.  The Dark Night Mode extension was installed but disabled.\nFor reference, ungoogled-chromium is launched from jwm window manager tray launcher using the following path:\n/opt/bin/ungoogled-chromium/chrome-wrapper\nThe chrome://sandbox/ tab reports as follows:-\nSandbox Status\nSUID Sandbox    No\nNamespace Sandbox   Yes\nPID namespaces  Yes\nNetwork namespaces  Yes\nSeccomp-BPF sandbox Yes\nSeccomp-BPF sandbox supports TSYNC  Yes\nYama LSM Enforcing  No\nYou are adequately sandboxed.\nWhen launched from a shell and with Dark Night Mode -- the only working added extension -- disabled beforehand, errors appear:\n$ sh /opt/bin/ungoogled-chromium/chrome-wrapper\n[12760:12760:0616/235536.824264:ERROR:sandbox_linux.cc(378)] InitializeSandbox() called with multiple threads in process gpu-process.\n[12688:12738:0616/235540.216479:ERROR:url_request.cc(590)] Block URL in URLRequest: https://support.9oo91e.qjz9zk/chrome_webstore/?p=crx_warning\n[12688:12738:0616/235540.216699:ERROR:trk_protocol_handler.cc(17)] Blocked URL in TrkProtocolHandler: trk:https://support.9oo91e.qjz9zk/chrome_webstore/?p=crx_warning\n[12688:12738:0616/235540.670398:ERROR:url_request.cc(590)] Block URL in URLRequest: https://support.9oo91e.qjz9zk/chrome_webstore/?p=crx_warning\n[12688:12738:0616/235540.670909:ERROR:trk_protocol_handler.cc(17)] Blocked URL in TrkProtocolHandler: trk:https://support.9oo91e.qjz9zk/chrome_webstore/?p=crx_warning\n[12688:12738:0616/235540.800051:ERROR:url_request.cc(590)] Block URL in URLRequest: https://support.9oo91e.qjz9zk/chrome_webstore/?p=crx_warning\n[12688:12738:0616/235540.800279:ERROR:trk_protocol_handler.cc(17)] Blocked URL in TrkProtocolHandler: trk:https://support.9oo91e.qjz9zk/chrome_webstore/?p=crx_warning. Update 1:  The newer Linux Portable build of 67.0.3396.87-1 has now been installed (NB:  earlier version was left installed at /opt/bin/ungoogled-chromium).\nUpdate 2:  The 'Block URL in URLRequest' error messages reported lately seem to have been due to the duplicate tabs (https://support.9oo91e.qjz9zk/chrome_webstore/?p=crx_warning) that were left opened after clicking on the 'Learn more' link mentioned above upon attempting to install various extensions.  After closing those tabs in the new build, there is just the following error at launch:\n$ sh /opt/bin/ungoogled-chromium_67.0.3396.87-1_linux/chrome-wrapper \n[6356:6356:0617/025101.558665:ERROR:sandbox_linux.cc(378)] InitializeSandbox() called with multiple threads in process gpu-process.\nHowever, the  Disable HTML5 Autoplay extension still generates the same error and 'Learn more' report.\nReply to question:  With a clean profile (renaming ~/.config/chromium to ~/.config/chromiumoriginal) in the new build it launches as follows:\n$ sh /opt/bin/ungoogled-chromium_67.0.3396.87-1_linux/chrome-wrapper \n[7511:7511:0617/025544.604522:ERROR:sandbox_linux.cc(378)] InitializeSandbox() called with multiple threads in process gpu-process.\nThe same error and 'Learn more' report that happened earlier when trying to install the Disable HTML5 Autoplay extension occur in the new build with a new profile.\nReply to other question:  Attempting to launch (deleting new profile again) using chrome instead of chrome-wrapper: \n$ sh /opt/bin/ungoogled-chromium_67.0.3396.87-1_linux/chrome\n/opt/bin/ungoogled-chromium_67.0.3396.87-1_linux/chrome: /opt/bin/ungoogled-chromium_67.0.3396.87-1_linux/chrome: cannot execute binary file\n. ANSWER No. 1 -  Thank you for the pointers re no need to use sh here and about the 'Learn more' link, etc.  Thank you also for your suggestion to examine the chrome://gpu report in order to determine what possibly may be an incompatibility with the kernel.  I don't know how to interpret it however and don't know if it is advisable to paste it publicly e.g. in pastebin, but the following sections or lines with entries that mostly appear in red:\nGraphics Feature Status\n[...]\nCheckerImaging: Disabled\n[...]\nVideo Decode: Unavailable\nViz Service Display Compositor: Disabled\n[...]\nProblems Detected\n- Accelerated video decode is unavailable on Linux: 137247\n- Disabled Features: accelerated_video_decode\n[NB:  Other entries appear here including, for example, the following two first lines, but no entries have any red, and 'Applied Workarounds' are mentioned in all those cases:]\n* Clear uniforms before first program use on all platforms: 124764, 349137\n   Applied Workarounds: clear_uniforms_before_first_program_use\n[...]\n Don't expose disjoint_timer_query extensions to WebGL: 808744_\n_ Native GpuMemoryBuffers have been disabled, either via about:flags or command line.\nDisabled Features: native_gpu_memory_buffers\n Viz service display compositor is not enabled by default.\n   _Disabled Features: viz_display_compositor\n_ Checker-imaging has been disabled via finch trial or the command line.\nDisabled Features: checker_imaging\nANSWER No. 2 - There is no 'dark puzzle piece icon' nor the text 'Drop to install' when drag-and-dropping the .crx extension.  When drag-and-dropping the extension from within the Thunar file manager, the pointer becomes an icon resembling a hand grabbing a white 'file' with a 'plus' sign .  The system had XFCE  installed as the default desktop environment.  I then installed jwm window manager, and that is the chosen window manager at login, so technically, I don't know what the desktop environment is.\nNotes: \n The suspicion that Chromium considers .crx to be an URL to download when dragged-and-dropped, and not a file, could be spot on!   When drag-and-dropping it, a 'Downloads status bar' appears (peculiarly?) at the bottom, including a 'Show all' button on the right, typical of when Chromium downloads items from URLs, and the .crx extension appears to be 'downloading' with a spinning circle and flashing when finished 'downloading' from a local folder.\n When drag-and-dropping from SpaceFM file manager within jwm:  often, the drag-and-dropping fails as the SpaceFM mysteriously vanishes from screen and Chromium doesn't even report any .crx file 'downloading' (an issue for SpaceFM?).  However, even when the drag-and-drop engages correctly, the same error message, 'Downloads' status bar and the same 'hand, file and plus sign' icon appear.\n When drag-and-dropping from Thunar file manager during an XFCE window manager session (instead of choosing JWM window manager at the display manager login):  the same error message, 'Downloads' status bar and rather an icon resembling a file with a plus sign and two 'image-cropping' edges appear.\n When drag-and-dropping from SpaceFM file manager during an XFCE window manager session (not JWM):   sometimes the drag-and-dropping fails because, as in JWM sometimes, the SpaceFM vanishes from screen and Chromium doesn't even report any .crx file 'downloading', as has happened in JWM.  When the drag-and-dropping engages correctly, the same error message, 'Downloads' status bar and an icon resembling a file with a plus sign and two 'image-cropping' edges appear.\nIf Chromium should be set not to 'download' .crx from an URL, maybe a MIME setting was changed or could be changed?. @xsmile, I have been drag-and-dropping onto the page, not to the address bar.  \nFurther to your proposal, \"Chromium Version 67.0.3396.62 (Developer Build) (64-bit)\" was installed from the repositories on my system.  The Extensions page does not 'grey out' when drag-and-dropping an extension there.  Unlike all Portable build versions of ungoogled-chromium (v66 and v67) on this installation, a bar appears at the bottom announcing instead, \"Extensions, apps and themes can damage your computer.  Are you sure you want to continue?\"  If \"Continue\" is clicked, the bar doubles as the 'Downloads' bar mentioned earlier, and the extension seems to 'download', but does not install, which is odd because I have succeeded in previous Calculate Linux installations, and with ungoogle-chromium v55 from its repositories.\nHere is a screenshot in Chromium v67 having dragged-and-dropped an extension earlier (to display the bar that appeared), and while repeating the action (to show no greyed-out area):\n\nHere is a screenshot in ungoogled-chromium_67.0.3396.87-1_linux Portable Build (disregard the .crx55 file in the file manager, it is an old .crx file for v55):\n\nHere is a screenshot in ungoogled-chromium_66.0.3359.139-1_linux Portable Build;  it greys out ok and extensions would load fine:\n\n@xsmile, have you installed Linux Portable build of ungoogled-chromium v67 in your XFCE environment?  If so, does drag-and-dropping extensions work ok in that Portable build?   Would you kindly indicate why you have a fork of ungoogled-chromium in your repositories?  Thank you, all.\n. @ribatamu, setting \"Enable Material Design extensions\" flag to 'Disabled' works indeed, thank you very much!\n@xsmile, setting Extensions tab to 'Developer mode' also works when drag-and-dropping, thank you!\nThanks for all the other information!. Thanks a lot, @ian-moone!  However, recent ungoogled-chromium portable linux versions have been working here without needing to set such a flag.\nAlso,  my machine would crash out of the display manager twice in a row after having tried to set the USE=\"vaapi\" flag today and having rebooted.   I'm not clear whether that link you kindly shared states that as root I should first run \"vainfo to check VAAPI support\", but I did so first anyway:\n```\nvainfo\nlibva info: VA-API version 0.39.4\nlibva info: va_getDriverName() returns 0\nlibva info: Trying to open /usr/lib64/va/drivers/r600_drv_video.so\nlibva info: Found init function __vaDriverInit_0_39\nlibva info: va_openDriver() returns 0\nvainfo: VA-API version: 0.39 (libva 1.7.3)\nvainfo: Driver version: Mesa Gallium driver 18.1.6 for AMD ARUBA (DRM 2.50.0 / 4.18.9-calculate, LLVM 6.0.1)\nvainfo: Supported profile and entrypoints\n      VAProfileMPEG2Simple            : VAEntrypointVLD\n      VAProfileMPEG2Main              : VAEntrypointVLD\n      VAProfileVC1Simple              : VAEntrypointVLD\n      VAProfileVC1Main                : VAEntrypointVLD\n      VAProfileVC1Advanced            : VAEntrypointVLD\n      VAProfileH264ConstrainedBaseline: VAEntrypointVLD\n      VAProfileH264ConstrainedBaseline: VAEntrypointEncSlice\n      VAProfileH264Main               : VAEntrypointVLD\n      VAProfileH264Main               : VAEntrypointEncSlice\n      VAProfileH264High               : VAEntrypointVLD\n      VAProfileH264High               : VAEntrypointEncSlice\n      VAProfileNone                   : VAEntrypointVideoProc\n```\nAs there is already a custom file under  /etc/portage/make.conf, I added the flag there:\n```\nrnano  /etc/portage/make.conf/custom   # to insert following line\nUSE=\"vaapi\"\n```\nThen, trying to follow instructions at that link:\n```\n # emerge --ask --changed-use --deep @world\nLocal copy of remote index is up-to-date and will be used.\n\nIMPORTANT: 10 news items need reading for repository 'gentoo'.\nUse eselect news read to view new items.\n\nThese are the packages that would be merged, in order:\nCalculating dependencies... done!\nNothing to merge; quitting.\n```\nI noticed then that x11-libs/libva was already installed (along with libva-intel-driver and another libva package, but note that my system has AMD graphics):\n```\n$ eix -S x11-libs/libva\n[I] x11-libs/libva\n     Available versions:  1.7.3 ~1.8.3 ~2.1.0(0/2) ~2.2.0(0/2) **9999(0/9999) {X +drm egl opengl utils vdpau wayland ABI_MIPS=\"n32 n64 o32\" ABI_PPC=\"32 64\" ABI_S390=\"32 64\" ABI_X86=\"32 64 x32\" VIDEO_CARDS=\"dummy i965 intel nouveau nvidia\"}\n     Installed versions:  1.7.3(09:32:52 PM 05/13/2018)(X drm opengl vdpau -egl -wayland ABI_MIPS=\"-n32 -n64 -o32\" ABI_PPC=\"-32 -64\" ABI_S390=\"-32 -64\" ABI_X86=\"32 64 -x32\" VIDEO_CARDS=\"i965 intel nouveau nvidia -dummy\")\n     Homepage:            https://01.org/linuxmedia/vaapi\n     Description:         Video Acceleration (VA) API for Linux\n[I] x11-libs/libva-intel-driver\n     Available versions:  1.7.3 ~1.8.3 ~2.1.0 ~2.2.0 **9999 {X +drm wayland ABI_MIPS=\"n32 n64 o32\" ABI_PPC=\"32 64\" ABI_S390=\"32 64\" ABI_X86=\"32 64 x32\"}\n     Installed versions:  1.7.3(09:43:39 PM 05/13/2018)(X drm -wayland ABI_MIPS=\"-n32 -n64 -o32\" ABI_PPC=\"-32 -64\" ABI_S390=\"-32 -64\" ABI_X86=\"32 64 -x32\")\n     Homepage:            https://github.com/intel/intel-vaapi-driver\n     Description:         HW video decode support for Intel integrated graphics\n[I] x11-libs/libva-vdpau-driver\n     Available versions:  0.7.4-r4 {debug opengl ABI_MIPS=\"n32 n64 o32\" ABI_PPC=\"32 64\" ABI_S390=\"32 64\" ABI_X86=\"32 64 x32\"}\n     Installed versions:  0.7.4-r4(09:43:05 PM 05/13/2018)(opengl -debug ABI_MIPS=\"-n32 -n64 -o32\" ABI_PPC=\"-32 -64\" ABI_S390=\"-32 -64\" ABI_X86=\"32 64 -x32\")\n     Homepage:            https://www.freedesktop.org/wiki/Software/vaapi\n     Description:         VDPAU Backend for Video Acceleration (VA) API\nFound 3 matches\n```\nRecapping, the system crashed out of the display manager on reboot the way I proceeded, and there wasn't a need to set a vaapi flag with recent portable linux ungoogled-chromium versions.  Thanks anyway @ian-moone, and thanks a lot for this very useful package and for looking into this, @Eloston!. As users are advised to become more cautious about whether to trust sources, binaries, etc., users should be able to understand and check what is downloaded before running it.\nSo, @ian-moone, to help trust that ebuild, please spell out what would be substituted in for this system for the {PN} parameter in your ebuild at line 23:\n    https://github.com/Eloston/${PN}/archive/${UGC_PV}.tar.gz -> ${UGC_P}.tar.gz\nHow ${PN} is defined is not clear to me.\nAlso, please explain your strapline, 'The cancer is coming!'  Thank you, @ian-moone.  \nMy original question remains, however.\n. @ian-moone, thank you kindly. Now, https://github.com/Eloston/ungoogled-chromium/archive/69.0.3497.100-2.tar.gz is interpreted to be downloaded by your ebuild.\nRunning a comparison between extracted versions of that download and a .zip download of the currently displayed ungoogled-chromium-master, differences appear:-\n$ diff -qr ../ungoogled-chromium-69.0.3497.100-2/ungoogled-chromium-69.0.3497.100-2/ ungoogled-chromium-master/ |sort\nFiles ../ungoogled-chromium-69.0.3497.100-2/ungoogled-chromium-69.0.3497.100-2/docs/building.md and ungoogled-chromium-master/docs/building.md differ\nFiles ../ungoogled-chromium-69.0.3497.100-2/ungoogled-chromium-69.0.3497.100-2/docs/design.md and ungoogled-chromium-master/docs/design.md differ\nFiles ../ungoogled-chromium-69.0.3497.100-2/ungoogled-chromium-69.0.3497.100-2/docs/developing.md and ungoogled-chromium-master/docs/developing.md differ\nFiles ../ungoogled-chromium-69.0.3497.100-2/ungoogled-chromium-69.0.3497.100-2/README.md and ungoogled-chromium-master/README.md differ\nOnly in ../ungoogled-chromium-69.0.3497.100-2/ungoogled-chromium-69.0.3497.100-2/.github: issue_template.md\nOnly in ungoogled-chromium-master/docs: contributing.md\nOnly in ungoogled-chromium-master/.github: ISSUE_TEMPLATE\nOnly in ungoogled-chromium-master/.github: PULL_REQUEST_TEMPLATE.md\nOnly in ungoogled-chromium-master/packaging/linux_simple: package.appimage.sh.ungoogin\nOnly in ungoogled-chromium-master/packaging/linux_simple: ungoogled-chromium.yml\nOnly in ungoogled-chromium-master/: SUPPORT.md\nIf those variations could be explained, it would help, but this is not a forum to dwell into them.  \nThank you for kindly explaining your strapline, @ian-moore.  \nThanks to all for your efforts to hopefully resolve the original issue re ungoogled-chromium source code.. Thank you @ian-moone and @intika.\nApologies to @ian-moore.\n@intika, You are correct:\n$ python --version\nPython 3.6.5\nCould a stated software requirement for Any Linux Distribution, 'Python 3 (tested on 3.5)', need to be updated regarding the current Linux Simple release, unless the absence of LLVM 7.0 on this system is relevant?\nAs 3.6.6 and above are currently marked as unstable for this OS, I am withholding installing ungoogled-chromium for now.. Thank you very much for all your considerations, @intika!\nFurther to your first request:\n$ python2 --version\nPython 2.7.15\nBuilding ungoogled-chromium again with the same steps but running alias python=/usr/bin/python2.7 first, unfortunately, produces the same conclusion:  the output starting from the line + python3 -m buildkit gnargs print -b config_bundles/linux_portable is the same as originally reported:\n$ ./ungoogled_packaging/build.sh    \n[...]\n2018-10-16 19:37:08,362 - INFO: Path has no substitutions: third_party/crashpad/crashpad/doc/support/crashpad_doxygen.css\n2018-10-16 19:37:17,871 - INFO: Path has no substitutions: tools/md_browser/base.css\n2018-10-16 19:37:29,318 - INFO: Path has no substitutions: build/config/compiler/BUILD.gn\n+ python3 -m buildkit gnargs print -b config_bundles/linux_portable\n+ popd\n/tmp/ungoogled-chromium/build/src\n+ export AR=llvm-ar\n+ AR=llvm-ar\n+ export NM=llvm-nm\n+ NM=llvm-nm\n+ export CC=clang\n+ CC=clang\n+ export CXX=clang++\n+ CXX=clang++\n+ ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn\n  File \"/tmp/ungoogled-chromium/build/src/tools/gn/build/gen.py\", line 171\n    print 'Installing Debian root image from %s' % url\n                                               ^\nSyntaxError: Missing parentheses in call to 'print'. Did you mean print('Installing Debian root image from %s' % url)?\nTraceback (most recent call last):\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 92, in <module>\n    sys.exit(main(sys.argv[1:]))\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 78, in main\n    subprocess.check_call(cmd)\n  File \"/usr/lib64/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['/usr/lib/python-exec/python3.6/python', '/tmp/ungoogled-chromium/build/src/tools/gn/build/gen.py', '--no-last-commit-position', '--out-path=/tmp/ungoogled-chromium/build/src/out/Release/gn_build', '--no-sysroot']' returned non-zero exit status 1.\nWouldn't a solution be to work out which 'X' file generates the troubled file ungoogled-chromium/build/src/tools/gn/build/gen.py and then amend the X file to produce the gen.py file with line 171 amended, as suggested by the debug?  That is, adding parentheses:\nprint('Installing Debian root image from %s' % url)\nNote:  Line 177 may need to be amended similarly, as it currently reads:\nprint 'Downloading %s' % url\nWould that perhaps create a problem with other (?GN) syntax? \nYour considerations are very appreciated anyway, @intika!  Thanks again.. Thanks @Intika.\nFollowing your proposal, the build was begun again, commenting out the last three commands in./ungoogled_packaging/build.sh as described before running that script.\nNext, $ python2 ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn was run successfully.\nThere was an error when manually executing the second last command in the original build.sh file:\n$ ./out/Default/gn gen out/Default --fail-on-unused-args\nbash: ./out/Default/gn: No such file or directory\nFor what it's worth, in case it can give insight into any unforeseen required modifications, the last command in the script was attempted next, disregarding the failure of the previous command, and it failed in the following way:\n$ ninja -C out/Default chrome chrome_sandbox chromedriver\nninja: Entering directory `out/Default'\nninja: error: loading 'build.ninja': No such file or directory\nThe alternative you proposed - linking python to python2 - was attempted next, building from scratch without modifying build.sh.  First:\n$ sudo mv /usr/bin/python /usr/bin/pythonbakup\n$ sudo ln -s /usr/bin/python2 /usr/bin/python\nAfter building c45mins, building stopped.  Clang & ninja ran (as demonstrated by $ top).  Responses were often being overwritten towards the last line of output.  When halted:\n$ ./ungoogled_packaging/build.sh    \n[...]\n2018-10-17 10:01:01,188 - INFO: Path has no substitutions: rlz/lib/lib_values.cc\n2018-10-17 10:01:13,887 - INFO: Path has no substitutions: third_party/catapult/third_party/polymer/components/font-roboto/roboto.html\n2018-10-17 10:01:14,215 - INFO: Path has no substitutions: third_party/catapult/tracing/third_party/gl-matrix/jsdoc-template/static/default.css\n2018-10-17 10:01:16,781 - INFO: Path has no substitutions: third_party/crashpad/crashpad/doc/support/crashpad_doxygen.css\n2018-10-17 10:01:34,024 - INFO: Path has no substitutions: tools/md_browser/base.css\n2018-10-17 10:01:43,915 - INFO: Path has no substitutions: build/config/compiler/BUILD.gn\n+ python3 -m buildkit gnargs print -b config_bundles/linux_portable\n+ popd\n/tmp/ungoogled-chromium/build/src\n+ export AR=llvm-ar\n+ AR=llvm-ar\n+ export NM=llvm-nm\n+ NM=llvm-nm\n+ export CC=clang\n+ CC=clang\n+ export CXX=clang++\n+ CXX=clang++\n+ ./tools/gn/bootstrap/bootstrap.py -o out/Default/gn\nninja: Entering directory `/tmp/ungoogled-chromium/build/src/out/Release/gn_build'\n[171/171] LINK gn\n+ ./out/Default/gn gen out/Default --fail-on-unused-args\nDone. Made 9349 targets from 1631 files in 47440ms\n+ ninja -C out/Default chrome chrome_sandbox chromedriver\nninja: Entering directory `out/Default'\n[485/20953] ACTION //chrome/test/chromedriver:e...n_cpp(//build/toolchain/linux/unbundle:default)\nERROR:root:Git error: rc=0, output=''\n[488/20953] ACTION //third_party/blink/renderer..._data(//build/toolchain/linux/unbundle:default)\nFAILED: gen/third_party/blink/renderer/platform/color_data.cc \npython ../../third_party/blink/renderer/build/scripts/gperf.py gperf --key-positions=\\* -D -s 2 ../../third_party/blink/renderer/platform/color_data.gperf --output-file=gen/third_party/blink/renderer/platform/color_data.cc\nTraceback (most recent call last):\n  File \"../../third_party/blink/renderer/build/scripts/gperf.py\", line 91, in <module>\n    main()\n  File \"../../third_party/blink/renderer/build/scripts/gperf.py\", line 88, in main\n    generate_gperf(gperf_path, open(infile).read(), gperf_args))\n  File \"../../third_party/blink/renderer/build/scripts/gperf.py\", line 45, in generate_gperf\n    127, gperf_args, output='Command not found.')\nsubprocess.CalledProcessError: Command '['--key-positions=*', '-D', '-s', '2']' returned non-zero exit status 127\n[493/20953] CXX obj/ppapi/cpp/objects/graphics_3d.o\nninja: build stopped: subcommand failed.\nYour considerate guidance to immediately reset python was then executed.  Thanks again.\n. Thanks for showing me along the way, @intika, but questions (Q4)-(Q6) below could be the most relevant at this point.  \nThank you also for the interesting and practical solutions to use python 2 instead of python 3.  Maybe virtualenvwrapper could be the most appealing choice, if need be.\n\nso to accelerate a little bit the whole thing you can install all needed dependency to build chromium/uc with some commands... there is an aur package https://aur.archlinux.org/packages/ungoogled-chromium for UC\n\nLinux Simple UC was being built with chromium 69.0.3497.100 already installed with a view to uninstalling it before untaring the target build, so presumably all dependencies were already installed?  Linux Portable UC 69 didn't install any dependencies that I know of (without chromium installed at the time!), so I thought that Linux Simple UC wouldn't require any either.\nA list of chromium dependencies is indeed given at that link, but (Q1) if you mean that makepkg -s PKGBUILD could be a quick way to determine which are 'missing' dependencies (despite chromium 69 operating ok!), how could I run makepkg, seeing that it isn't in the Gentoo repository? (Q2)  Wouldn't makepkg -s PKGBUILD also need ungoogled-chromium or chromium as an argument?  (Q3) If so, what is the syntax?\nA backup could be done to proceed, but the link you suggested to build LLVM 7 lists python 2.7 as a prerequisite, which is missing on my system and is not planned to be installed.  Maybe once my python 2 is upgraded I will.\n\nNote II : Also as you are using llvm 6 you can directly try to build v68 just use 'git checkout 68...' after cloning the project... \n\nV68 could be a fallback.  (Q4) Could you please spell out that command, as I am not familiar with 'after cloning the project', and the last tagged v68 source code tagged is 68.0.3440.106-2, e.g.:\n$ git clone https://github.com/Eloston/ungoogled-chromium.git\n$ git checkout 68.0.3440.106-2\n$ cd ungoogled-chromium\netc\n(Q5) Another alternative:  what do you think about using ebuilds offered for gentoo, as suggested earlier, which may address environments like mine with python 2.6.5 and llvm 6.0.1?\nWell, this was thought to be a bug report, but it isn't identified as that.  (Q6) Is it because my system is missing python 2.7 and LLVM 7?  Is it kept open to try to solve situations with systems that 'default' to python 3 (as signalled earlier re Arch systems)?  Despite your continued help, my interest to keep stable python 2.6.5 seems to mean that there is no way forward for Linux Simple UC v69 here.  Even some temporary install of python 2.7 in order to build LLVM 7 is not appealing.\nThank you very much anyway for all your help, @antika, and have a great Friday and weekend!. > Thoughts?\nPortable Linux builds by @intika are very valuable to me.  They are the ones being used by at least myself a considerable amount of time.\nGentoo overlays are not attractive as an alternative. \n. Hi @ribatamu!\nUsing Calculate Linux, based on Gentoo.  Unlike Gentoo itself, the desktop environment is set up for you from the start, but still it might pose some challenges to newcomers to GNU/Linux.  For example, some might not realize that the /etc/sudoers file doesn't have the # %wheel     ALL=(ALL)      ALL line uncommented, and that visudo at a root prompt would be a way to change that, which would be an added challenge to newcomers.  Nevertheless, the base of Calculate Linux, Gentoo, gets considerable attention in some aspects.\nLinux Lite takes you 'by the hand' in some respects and in my experience may be a good introductory system for newcomers to GNU/Linux.  It uses systemd, which is ubiquitous with many Linux installations but has its detractors.  \nMoving to Linux is a good idea.  \nHopefully that helps.. Hopefully some of the following might help:-\n\nHTTPS Everywhere  - By eff.org, leading internet privacy body, but @intika made very interesting points and he offered an excellent alternative.  Thanks @intika!  (Anyway, some valued webpage (directory.shoutcast.com :persevere:!) didn't work for me, unfortunately, if I remember correctly, with \"#enable-potentially-annoying-security-features\" flag enabled.)\nPrivacy Badger - By eff.org.\nuBlock Origin\nTranslation Comparison - select text;  then click on toolbar icon for 3 translations (including google translate... or customize number) or right-click.\nSelection Context Search - small.\nDark Night Mode - small, doesn't seem to 'phone home' and may not invert colours on videos.\nDisable HTML5 Autoplay - by @Eloston.. Hi @memeticks!\nIn case it can help you, a quick way IMHO to install extensions with ungoogled-chromium v70.0 (and v69 too, if I remember correctly, in my experience) is to let the browser install it for you by setting up a custom search engine for extension installation.  Looking through the link you posted, to \"set up the custom search engine\", you should modify the 'template CRX URL', as described in the FAQ, with the browser (basic) version number;  and replace [EXTENSION ID] with %s (the term you use to create engines in typical chromium browsers).  Therefore...\n\nhttps://clients2.google.com/service/update2/crx?response=redirect&acceptformat=crx2,crx3&prodversion=[VERSION]&x=id%3D[EXTENSION_ID]%26installsource%3Dondemand%26uc\n...should look as follows for ungoogled-chromium v70.0:\nhttps://clients2.google.com/service/update2/crx?response=redirect&acceptformat=crx2,crx3&prodversion=70.0&x=id%3D%s%26installsource%3Dondemand%26uc\nNext, you could set the flag to download the extension as suggested in the next sentence (\"Then, set chrome://flags/#extension-mime-request-handling to Download as regular file\"), and then install it as described there.  \nThe next paragraph in the FAQ, entitled \"Installing the CRX file\", offers a very helpful and quicker solution in my experience:  \"Change the flag chrome://flags/#extension-mime-request-handling  to Always prompt for install\".  Relaunch the browser.  Add the search engine under chrome://settings/.  For example, call it 'Installextension', and set a search key - 'i', say.  Then, in the location bar, type an 'i' and press tab.  Installextension should then appear as the 'search mode'.  Paste the extension ID for the extension that you found earlier in the Chrome Store (as described in the FAQ);  and press 'enter'.  It should prompt you to accept the extension.  \nIt is good practice the turn the flag back to Default for security.. Excellent, thanks @intika.  I notice that the github page referred to above has also been updated to describe the latest version, v70.0.3538.110-1.  The hash sums match the ones for the tar.xz downloaded earlier for that version, so all matches up fine.  Thanks for all that, and for your willingness and dedication to compile and package these!  :). @Eloston, thank you too for your attention, persistence and commits!. To be able to meet points 2 & 3 (\"I want ungoogled-chromium to be software that I'd like to use\" and \"I want ungoogled-chromium to grow. Clearly, the people that use my browser are not all like me. So to attract more users, I have to keep evolving ungoogled-chromium and myself\"), maybe there could be two browsers:-\n1.  A base browser ('ungoogled-chromium'?), which just provides source and, say, a portable Linux version.   Developers could adapt/patch for requirements of their target OS (and links for their source files and any unofficial binaries could be placed on your readme file?)   I am unfamiliar with the concepts though e.g. \"fingerprinting deception mechanisms\", \"domain substitution\", binary pruning\".  Could command-line flags be used for this version, ideally, for those who have requested this?\n2.  Your ideal browser (stripped, FOSS, etc.) under a different (related?) name, patched from the aforementioned 'base browser' and offered as a fork of yours on another repository.  Again, binaries could be built for the platforms that you and others consider attractive.\nThose two flavours may keep even more people happier and therefore enjoy greater input and growth.  \nFurther point:  In a link offered above, someone writing as a contributor to Chromium development appears to indicate that Chromium is already privacy-minded, as far as you agree to the terms if you sign in, etc e.g. even if and when you sync data, it's encrypted, etc.  Perhaps any representation of ungoogled-chromium as a 'privacy-minded' browser going forward could be reviewed - perhaps in favour of 'unblobbed' 'unbloated', etc.  Keeping the name 'ungoogled-chromium' would still be relevant and might be preferable (even for either of the browser versions suggested above) after all these years due to valuable product recognition.. ",
    "HotelBellaMuerte": "@lefroid @tectiv3\n. at canvas effect you need add an extra patch stupid clang rules\nhttps://p.teknik.io/Jdcaf\nim just importing it AS IS ... ",
    "zaza42": "Ok, it's compiled and working. Only some warning messages:\n```\n[5076/19999] CXX obj/third_party/flatbuffers/compiler_files/flatc.o\n../../third_party/flatbuffers/src/src/flatc.cpp:227:38: warning: expansion of date or time macro is not reproducible [-Wdate-time]\n        printf(\"flatc version %s\\n\", FLATC_VERSION);\n                                     ^\n../../third_party/flatbuffers/src/src/flatc.cpp:21:33: note: expanded from macro 'FLATC_VERSION'\ndefine FLATC_VERSION \"1.6.0 (\" DATE \")\"\n                            ^\n\n1 warning generated.\n[12817/19999] CXX obj/components/compo.../component_updater/configurator_impl.o\nIn file included from ../../components/component_updater/configurator_impl.cc:5:\n../../components/component_updater/configurator_impl.h:92:8: warning: private field 'require_encryption_' is not used [-Wunused-private-field]\n  bool require_encryption_;\n       ^\n1 warning generated.\n[14496/19999] CXX obj/chrome/browser/m...overy/discovery/dns_sd_device_lister.o\nIn file included from ../../chrome/browser/media/router/discovery/mdns/dns_sd_device_lister.cc:5:\n../../chrome/browser/media/router/discovery/mdns/dns_sd_device_lister.h:45:24: warning: private field 'delegate_' is not used [-Wunused-private-field]\n  DnsSdDelegate const delegate_;\n                       ^\n../../chrome/browser/media/router/discovery/mdns/dns_sd_device_lister.h:47:8: warning: private field 'started_' is not used [-Wunused-private-field]\n  bool started_;\n       ^\n2 warnings generated.\n[14985/19999] CXX obj/chrome/browser/u...one_click_signin_links_delegate_impl.o\nIn file included from ../../chrome/browser/ui/sync/one_click_signin_links_delegate_impl.cc:5:\n../../chrome/browser/ui/sync/one_click_signin_links_delegate_impl.h:26:18: warning: private field 'browser_' is not used [-Wunused-private-field]\n  Browser const browser_;\n                 ^\n1 warning generated.\n```\nOne more tip: when use_kerberos=false then checking for libkrb5-dev in debian/control is useless.\nI've noticed that ffmpeg is internal now and not depending on system's libavcodec library, opposite to previous versions.. I'm using ffmpeg 4.0.1 system wide already. How can I revert this change? Which patch is it?. The key was in file: resources/packaging/debian/buster/scripts/unbundle\nI've removed ffmpeg from this line:\n+keepers = ('openh264', 'libjpeg', 'ffmpeg')\nThen chromium building automatically switched to external ffmpeg library.\nI've found the debian patch exactly here: https://salsa.debian.org/chromium-team/chromium/commit/402b98bb1079079a788696650e0a922b1e16bed8\nThx!\nps. Yes, i've backported ffmpeg4 for buster, because of the newest mpv 0.28 also depends on it and I wanted to switch from v0.27.. Not the -dev for compiling; the plain gsettings-desktop-schemas for Package: ungoogled-chromium for running the compiled binary.. There are binary .deb packages: https://ungoogled-software.github.io/ungoogled-chromium-binaries/. The link is in the official documentation: https://github.com/Eloston/ungoogled-chromium#download-pre-built-packages . Read more carefully!. With llvm-7:\n```\n[2064/19011] LINK ./character_data_generator\nFAILED: character_data_generator\npython \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./character_data_generator\" -- clang++-7 -flto=thin -Wl,--build-id=sha1 -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -fuse-ld=lld -Wl,--icf=all -Wl,--color-diagnostics -flto=thin -Wl,--thinlto-jobs=8 -Wl,--thinlto-cache-dir=thinlto-cache -Wl,--thinlto-cache-policy,cache_size=10\\%:cache_size_bytes=10g:cache_size_files=100000 -Wl,--lto-O0 -fwhole-program-vtables -m64 -Wl,-O2 -Wl,--gc-sections -rdynamic -Wl,-rpath-link=. -Wl,--disable-new-dtags -Wl,--stats -flto=thin -Wl,--stats -flto=thin -o \"./character_data_generator\" -Wl,--start-group @\"./character_data_generator.rsp\"  -Wl,--end-group   -latomic -ldl -lpthread -lrt -licui18n -licuuc -licudata\nclang: error: invalid linker name in argument '-fuse-ld=lld'\n[2072/19011] CXX obj/third_party/hunspell/hunspell/suggestmgr.o\nninja: build stopped: subcommand failed.\nmake[1]:  [debian/rules:89: override_dh_auto_build-arch] Error 1\nmake[1]: Leaving directory '/usr/src/sources/2018/browser/ung70/ungoogled-chromium-70.0.3538.77-1-my/build/src'\nmake:  [debian/rules:68: binary] Error 2\ndpkg-buildpackage: error: debian/rules binary subprocess returned exit status 2\nI'll try with default llvm-6.. with llvm-7:\n[18067/19011] CXX obj/content/test/test_support/test_support_jumbo_2.o                                   \nFAILED: obj/content/test/test_support/test_support_jumbo_2.o                                             \nclang++-7 -MMD -MF obj/content/test/test_support/test_support_jumbo_2.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUSE_AURA=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DOFFICIAL_BUILD -DCHROMIUM_BUILD -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGE\nFILE64_SOURCE -DNO_UNWIND_TABLES -D_GNU_SOURCE -DCR_CLANG_REVISION=\\\"340925-1\\\" -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_V8_CONTEXT_SNAPSHOT -DGLIB_V\nERSION_MAX_ALLOWED=GLIB_VERSION_2_32 -DGLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_26 -DGL_GLEXT_PROTOTYPES -DUSE_GLX -DUSE_EGL -DVK_NO_PROTOTYPES -DGTEST_API_= -DGTEST_HAS_POSIX_RE=0 -DGTEST_LANG_CXX11=1 -DGTEST_HAS_TR1_TUPLE=0 -DTOOLKIT_VIEWS=1 -DGOOGLE_PROTOBUF_NO_R\nTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DHAVE_PTHREAD -DUSING_SYSTEM_ICU=1 -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC -DUCHAR_TYPE=uint16_t -DU_IMPORT=U_EXPORT -DWEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=0 -DWEBRTC_CHROMIUM_BUILD -DWEBRTC_POSIX -DWEBRTC_LINUX -DABS\nL_ALLOCATOR_NOTHROW=1 -DNO_MAIN_THREAD_WRAPPING -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_HAS_PNG_LIBRARY -DSK_HAS_WEBP_LIBRARY -DSK_HAS_JPEG_LIBRARY -DSK_VULKAN_HEADER=\\\"../../skia/config/SkVulkanConfig.h\\\" -DSK_VULKAN=1 -DSK_SUPPORT_GPU=1 -DSK_GPU_WORKAROUNDS_\nHEADER=\\\"gpu/config/gpu_driver_bug_workaround_autogen.h\\\" -DVK_NO_PROTOTYPES -DLEVELDB_PLATFORM_CHROMIUM=1 -DV8_DEPRECATION_WARNINGS -DWTF_USE_WEBAUDIO_FFMPEG=1 -DSUPPORT_WEBGL2_COMPUTE_CONTEXT=1 -DWTF_USE_DEFAULT_RENDER_THEME=1 -DUSE_SYSTEM_LIBJPEG -DV8_DEPRECATION\nWARNINGS -DUNIT_TEST -I. -I../.. -Igen -Igen/shim_headers/libevent_shim -Igen/shim_headers/zlib_shim -Igen/shim_headers/re2_shim -Igen/shim_headers/snappy_shim -Igen/shim_headers/icui18n_shim -Igen/shim_headers/icuuc_shim -I../../third_party/libyuv/include -Igen/sh\nim_headers/ffmpeg_shim -Igen/shim_headers/openh264_shim -Igen/shim_headers/libvpx_shim -Igen/shim_headers/opus_shim -Igen/shim_headers/libpng_shim -Igen/shim_headers/libwebp_shim -Igen/shim_headers/libdrm_shim -I../../third_party/khronos -I../../gpu -I../../third_pa\nrty/vulkan/include -I../../third_party/googletest/custom -I../../third_party/googletest/src/googletest/include -Igen/shim_headers/minizip_shim -Igen/shim_headers/flac_shim -I../../third_party/protobuf/src -Igen/protoc_out -I../../third_party/protobuf/src -I../../thi\nrd_party/boringssl/src/include -I../../third_party/googletest/custom -I../../third_party/googletest/src/googlemock/include -I../../third_party/ced/src -I../../third_party/webrtc_overrides -I../../third_party/webrtc -I../../third_party/abseil-cpp -I../../skia/config \n-I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/encode -I../../third_party/skia/include/gpu -I../../third_part\ny/skia/include/images -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pdf -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../thir\nd_party/vulkan/include -I../../third_party/skia/third_party/vulkanmemoryallocator -I../../third_party/skia/src/gpu -I../../third_party/skia/src/sksl -I../../third_party/skia/modules/skottie/include -I../../third_party/vulkan/include -I../../third_party/leveldatabase -I../../third_party/leveldatabase/src -I../../third_party/leveldatabase/src/include -I../../third_party/libwebm/source -I../../v8/include -Igen/v8/include -I../../third_party/iccjpeg -I../../third_party/ots/include -I../../v8/include -Igen/v8/include -I../../third_party/webrtc_overrides -I../../testing/gtest/include -I../../third_party/webrtc -I../../third_party/mesa_headers -fprofile-sample-use=../../chrome/android/profiles/afdo.prof -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -fno-unwind-tables -fno-asynchronous-unwind-tables -fPIC -pthread -fcolor-diagnostics -fmerge-all-constants -Xclang -mllvm -Xclang -instcombine-lower-dbg-declare=0 -no-canonical-prefixes -m64 -march=x86-64 -Wall -Wextra -Wimplicit-fallthrough -Wthread-safety -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-user-defined-warnings -Wno-unused-lambda-capture -Wno-null-pointer-arithmetic -Wno-enum-compare-switch -Wno-ignored-pragma-optimize -O2 -fno-ident -fdata-sections -ffunction-sections -fno-omit-frame-pointer -g0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -Wno-header-guard -I/usr/include/nss -I/usr/include/nspr -Wno-inconsistent-missing-override -I/usr/include/libpng16 -std=c++14 -fno-exceptions -fno-rtti -fvisibility-inlines-hidden -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-pedantic -Wno-unused-function -Wno-unused-variable -Wno-deprecated-declarations  -Wno-return-type  -Wno-pedantic -Wno-unused-function -Wno-unused-variable -Wno-deprecated-declarations  -Wno-return-type  -c gen/content/test/test_support_jumbo_2.cc -o obj/content/test/test_support/test_support_jumbo_2.o\nIn file included from gen/content/test/test_support_jumbo_2.cc:5:\nIn file included from ./../../content/public/test/test_frame_navigation_observer.cc:5:\nIn file included from ../../content/public/test/test_frame_navigation_observer.h:11:\n../../content/public/test/browser_test_utils.h:608:24: error: unknown type name 'nullptr_t'; did you mean 'std::nullptr_t'?\ninline bool operator==(nullptr_t a, const EvalJsResult& b) {\n                       ^~~~~~~~~\n                       std::nullptr_t\n/usr/bin/../lib/gcc/x86_64-linux-gnu/8/../../../../include/x86_64-linux-gnu/c++/8/bits/c++config.h:242:29: note: 'std::nullptr_t' declared here\n  typedef decltype(nullptr)     nullptr_t;\n                                ^\n1 error generated.         \n[18074/19011] CXX obj/content/test/test_support/test_support_jumbo_1.o\nFAILED: obj/content/test/test_support/test_support_jumbo_1.o\nclang++-7 -MMD -MF obj/content/test/test_support/test_support_jumbo_1.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUSE_AURA=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DOFFICIAL_BUILD -DCHROMIUM_BUILD -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNO_UNWIND_TABLES -D_GNU_SOURCE -DCR_CLANG_REVISION=\\\"340925-1\\\" -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DV8_USE_EXTERNAL_STARTUP_DATA -DUSE_V8_CONTEXT_SNAPSHOT -DGLIB_VERSION_MAX_ALLOWED=GLIB_VERSION_2_32 -DGLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_26 -DGL_GLEXT_PROTOTYPES -DUSE_GLX -DUSE_EGL -DVK_NO_PROTOTYPES -DGTEST_API= -DGTEST_HAS_POSIX_RE=0 -DGTEST_LANG_CXX11=1 -DGTEST_HAS_TR1_TUPLE=0 -DTOOLKIT_VIEWS=1 -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DHAVE_PTHREAD -DUSING_SYSTEM_ICU=1 -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC -DUCHAR_TYPE=uint16_t -DU_IMPORT=U_EXPORT -DWEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=0 -DWEBRTC_CHROMIUM_BUILD -DWEBRTC_POSIX -DWEBRTC_LINUX -DABSL_ALLOCATOR_NOTHROW=1 -DNO_MAIN_THREAD_WRAPPING -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_HAS_PNG_LIBRARY -DSK_HAS_WEBP_LIBRARY -DSK_HAS_JPEG_LIBRARY -DSK_VULKAN_HEADER=\\\"../../skia/config/SkVulkanConfig.h\\\" -DSK_VULKAN=1 -DSK_SUPPORT_GPU=1 -DSK_GPU_WORKAROUNDS_HEADER=\\\"gpu/config/gpu_driver_bug_workaround_autogen.h\\\" -DVK_NO_PROTOTYPES -DLEVELDB_PLATFORM_CHROMIUM=1 -DV8_DEPRECATION_WARNINGS -DWTF_USE_WEBAUDIO_FFMPEG=1 -DSUPPORT_WEBGL2_COMPUTE_CONTEXT=1 -DWTF_USE_DEFAULT_RENDER_THEME=1 -DUSE_SYSTEM_LIBJPEG -DV8_DEPRECATION_WARNINGS -DUNIT_TEST -I. -I../.. -Igen -Igen/shim_headers/libevent_shim -Igen/shim_headers/zlib_shim -Igen/shim_headers/re2_shim -Igen/shim_headers/snappy_shim -Igen/shim_headers/icui18n_shim -Igen/shim_headers/icuuc_shim -I../../third_party/libyuv/include -Igen/shim_headers/ffmpeg_shim -Igen/shim_headers/openh264_shim -Igen/shim_headers/libvpx_shim -Igen/shim_headers/opus_shim -Igen/shim_headers/libpng_shim -Igen/shim_headers/libwebp_shim -Igen/shim_headers/libdrm_shim -I../../third_party/khronos -I../../gpu -I../../third_party/vulkan/include -I../../third_party/googletest/custom -I../../third_party/googletest/src/googletest/include -Igen/shim_headers/minizip_shim -Igen/shim_headers/flac_shim -I../../third_party/protobuf/src -Igen/protoc_out -I../../third_party/protobuf/src -I../../third_party/boringssl/src/include -I../../third_party/googletest/custom -I../../third_party/googletest/src/googlemock/include -I../../third_party/ced/src -I../../third_party/webrtc_overrides -I../../third_party/webrtc -I../../third_party/abseil-cpp -I../../skia/config -I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/effects -I../../third_party/skia/include/encode -I../../third_party/skia/include/gpu -I../../third_party/skia/include/images -I../../third_party/skia/include/lazy -I../../third_party/skia/include/pathops -I../../third_party/skia/include/pdf -I../../third_party/skia/include/pipe -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/vulkan/include -I../../third_party/skia/third_party/vulkanmemoryallocator -I../../third_party/skia/src/gpu -I../../third_party/skia/src/sksl -I../../third_party/skia/modules/skottie/include -I../../third_party/vulkan/include -I../../third_party/leveldatabase -I../../third_party/leveldatabase/src -I../../third_party/leveldatabase/src/include -I../../third_party/libwebm/source -I../../v8/include -Igen/v8/include -I../../third_party/iccjpeg -I../../third_party/ots/include -I../../v8/include -Igen/v8/include -I../../third_party/webrtc_overrides -I../../testing/gtest/include -I../../third_party/webrtc -I../../third_party/mesa_headers -fprofile-sample-use=../../chrome/android/profiles/afdo.prof -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -fno-unwind-tables -fno-asynchronous-unwind-tables -fPIC -pthread -fcolor-diagnostics -fmerge-all-constants -Xclang -mllvm -Xclang -instcombine-lower-dbg-declare=0 -no-canonical-prefixes -m64 -march=x86-64 -Wall -Wextra -Wimplicit-fallthrough -Wthread-safety -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-user-defined-warnings -Wno-unused-lambda-capture -Wno-null-pointer-arithmetic -Wno-enum-compare-switch -Wno-ignored-pragma-optimize -O2 -fno-ident -fdata-sections -ffunction-sections -fno-omit-frame-pointer -g0 -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -Wno-header-guard -I/usr/include/nss -I/usr/include/nspr -Wno-inconsistent-missing-override -I/usr/include/libpng16 -std=c++14 -fno-exceptions -fno-rtti -fvisibility-inlines-hidden -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-pedantic -Wno-unused-function -Wno-unused-variable -Wno-deprecated-declarations  -Wno-return-type  -Wno-pedantic -Wno-unused-function -Wno-unused-variable -Wno-deprecated-declarations  -Wno-return-type  -c gen/content/test/test_support_jumbo_1.cc -o obj/content/test/test_support/test_support_jumbo_1.o\nIn file included from gen/content/test/test_support_jumbo_1.cc:19:\nIn file included from ./../../content/public/test/browser_test_base.cc:37:\n../../content/public/test/browser_test_utils.h:608:24: error: unknown type name 'nullptr_t'; did you mean 'std::nullptr_t'?\ninline bool operator==(nullptr_t a, const EvalJsResult& b) {\n                       ^~~~~~~~~\n                       std::nullptr_t\n/usr/bin/../lib/gcc/x86_64-linux-gnu/8/../../../../include/x86_64-linux-gnu/c++/8/bits/c++config.h:242:29: note: 'std::nullptr_t' declared here\n  typedef decltype(nullptr)     nullptr_t;\n                                ^\n1 error generated.         \n[18075/19011] CXX obj/extensions/renderer/renderer/renderer_jumbo_3.o\nninja: build stopped: subcommand failed.\nmake[1]:  [debian/rules:89: override_dh_auto_build-arch] Error 1\nmake[1]: Leaving directory '/usr/src/sources/2018/browser/ung70/ungoogled-chromium-70.0.3538.77-1-my/build/src'\nmake:  [debian/rules:68: binary] Error 2\n```. ",
    "laamalif": "\nBy the way, is there any reason why DNS over HTTPS is available on Android only? Can it be enabled for all platforms?\n\nYou mean that more specific changes help in troubleshooting?\n\nSorry, I wasn't clear enough. Doing more extensive and \"cleaner\" stubbing can reduce the risk of breaking assumptions made in involved components. Memory leaking can be a symptom of assumptions being broken.\nAn example of this is the disable-metrics patch that xsmile wrote a little while back, but it ended up causing the Chromium profile to experience unbounded disk growth. (It was decided that fixing the patch wasn't worth the effort, so it was removed.)\n\nIs possible to add custom servers? apart from Google and Cloudflare anyone can run there own DoH server.\nhttps://github.com/jedisct1/rust-doh\n. ",
    "forkoz": "Thanks I grabbed portable because it was the newest build. I assumed they would all have the same feature set.. ",
    "anchev": "Something got messed up with my previous account, so I had to create a new one.\nDuring registration at GitHub I noticed another issue: a cookie (tz) which in which I saw the local timezone (with city). TBB doesn't leak this info, UC obviously does (even through Tor).. > Chromium allows you to spoof the timezone with an environment variable.\nHow do you do that?\n\nDoes TBB spoof the timezone by default?\n\nAccording to about:config the setting is privacy.use_utc_timezone=true (which is the same I saw in the cookie when testing).\n\nSo far, I am fine with the general idea of adding better Tor integration to achieve feature parity with TBB.\n\nPerhaps the best way to approach this is to open a discussion with the Tor developers themselves as there are surely additional factors we didn't look into here. Also bear in mind that TBB itself is not perfect at all. In fact I think UC has potential to be much better (as unlinke Firefox it doesn't connect to Mozilla's telemetry, Amazon, Akamai and all the rest of Mozilla's \"privacy respecting\" stuff).. > I see. I just set TZ='Etc/UTC' whenever I need to spoof timezone to UTC.\nThanks. But which other programs may be affected by this?\nAlso is this documented somewhere? - If not - it would be good to be.\nOr maybe it would be best to have a flag for it?\n\nUnless Firefox's design makes this significantly more difficult, I believe the potential in this area is equal to Chromium.\n\nI am not so sure. Chromium connects only to Google hosts. It is probably easier to find and block these connections in which you have done an excellent job.\nAs Firefox piles up more and more \"features\" they can add new connections at any time with new Mozilla's partners and the about:config flags for controlling all that are poorly documented (if at all). There are people who spend a lot of time to find info about that and reflect it in the multiple user.js projects but so far I haven't found a project focused on eliminating completely the unrequested connections (TBB also doesn't seem to do it). My own attempts in that were successful to a point but I stopped keeping up to date the user.js I created because following all that is a real nightmare - very time consuming and IMO unreliable. That's why I think UC is a much cleaner thing to start with.\n. Thanks @Eloston. env worked just fine.\n@intika: pyllyukko's user.js is a nice project but the very existence of it and many similar is a proof that there is something is very crooked in Mozilla. In an old issue some of that was discussed.\n. A little off-topic but perhaps worth mentioning:\nA post in Tor's blog from 2018-11-23 says:\n\nThe Tor Project has received $8,840 so far from AmazonSmile. If you buy from Amazon, please consider using smile.amazon.com and making the Tor Project your designated charity.\n\nSo now Amazon is financing Tor and Tor is advertising Amazon. And this article ends with \"Join the fight for privacy, security, and freedom online.\" Hm.... Just another note in the context of Tor:\nIt is a good idea to disable expliclitly chrome://flags/#enable-quic because QUIC is UDP and Tor socks proxy works only on TCP.. > Enabling QUIC does not conflict with TCP/SOCKS5, so it continues to work as usual.\nThe point is: When one uses Tor one doesn't want to \"work as usual\" (i.e. having non-torified connections).. My understanding is that it will simply won't use it - just like some of the UDP connections used in torrents (and the recommendation not to use Tor for torrents).\nI haven't researched deeply into QUIC but I have read it is based on UDP, so logically the same should apply as long as Tor supports only TCP. In a quick search I found this (I still have not read it but you may be interested to).. As I said I haven't read it.\nJust what searx returned.\n. Finally I got some help on LLVM's lists. The key component is to add -m32 to the command line in which case CFLAGS=-O3 -pipe -m32 -march=pentium-m -mtune=pentium-m. This works!\nHowever I am getting some new errors (perhaps missing dependencies):\nhttps://susepaste.org/a3d7b5bc\n(On openSUSE Leap 15) I have installed all 32-bit versions of the prerequisite packages but for some of them zypper simply doesn't have a 32bit version. Even that didn't remove the errors though.\nCan you help?. I don't understand.\nI am using the same linux_portable process as in #447 which has always worked so far for 64-bit architecures (including native and cross-compiling). The only difference as per the current issue is the target architecture/cpu (pentium-m). Re. libcxx, here is what zypper finds:\n```\nzypper se libcxx\nLoading repository data...\nReading installed packages...\nS | Name                               | Summary                                                              | Type\n--+------------------------------------+----------------------------------------------------------------------+--------\n  | libcxx-gtk-utils-3-2_2-0           | Lightweight library for GTK+ programs using C++                      | package\n  | libcxx-gtk-utils-3-2_2-0-debuginfo | Debug information for package libcxx-gtk-utils-3-2_2-0               | package\n  | libcxx-gtk-utils-3-devel           | Lightweight library for GTK+ programs using C++ -- Development Files | package\n  | libcxxtools-bin9                   | A C++ toolbox - binary RPC package                                   | package\n  | libcxxtools-bin9-debuginfo         | Debug information for package libcxxtools-bin9                       | package\n  | libcxxtools-http9                  | A C++ toolbox - HTTP protocol implementation                         | package\n  | libcxxtools-http9-debuginfo        | Debug information for package libcxxtools-http9                      | package\n  | libcxxtools-json9                  | A C++ toolbox - JSON package                                         | package\n  | libcxxtools-json9-debuginfo        | Debug information for package libcxxtools-json9                      | package\n  | libcxxtools-unit9                  | A C++ toolbox - testing library                                      | package\n  | libcxxtools-unit9-debuginfo        | Debug information for package libcxxtools-unit9                      | package\n  | libcxxtools-xmlrpc9                | A C++ toolbox - XMLRPC package                                       | package\n  | libcxxtools-xmlrpc9-debuginfo      | Debug information for package libcxxtools-xmlrpc9                    | package\n  | libcxxtools9                       | Collection of General-purpose C++ Classes                            | package\n  | libcxxtools9-debuginfo             | Debug information for package libcxxtools9                           | package\nzypper se libstd\nLoading repository data...\nReading installed packages...\nS  | Name                        | Summary                                               | Type\n---+-----------------------------+-------------------------------------------------------+--------\ni+ | libstdc++-devel             | The system GNU C++ development files                  | package\ni+ | libstdc++-devel-32bit       | The system GNU C++ 32bit development files            | package\ni+ | libstdc++6                  | The standard C++ shared library                       | package\ni+ | libstdc++6-32bit            | The standard C++ shared library                       | package\n   | libstdc++6-32bit-debuginfo  | Debug information for package libstdc++6-32bit        | package\n   | libstdc++6-debuginfo        | Debug information for package libstdc++6              | package\ni+ | libstdc++6-devel-gcc7       | Include Files and Libraries mandatory for Development | package\ni  | libstdc++6-devel-gcc7-32bit | Include Files and Libraries mandatory for Development | package\n   | libstdc++6-gcc6-doc         | Documentation for the GNU C++ standard library        | package\n   | libstdc++6-locale           | Standard C++ Library Locales                          | package\n```\nWhat package(s) do I have to install?. > Perhaps the GN bootstrap script doesn't support cross-compiling.\nHow come? I cross-compile successfully for other 64-bit architecture as mentioned in an earlier comment.\nAlso the error is by clang++ itself. Trying to run one of the problematic commands separately produces the same output. Adding a -v to it shows where it looks for includes:\nhttps://susepaste.org/4830cd4f\nDoes that give a hint about anything?\n\nYou can try setting native compilation flags for GN bootstrap, then change them to your desired pentium-m setting before you run gn gen and ninja.\n\nCan you elaborate on this please?\nFWIW: Currently my build script inserts the CFLAGS before the line with the ninja command (just think that in the context of this discussion architecture and cpu are set to penitum-m).. > As I understand it, you are now compiling on a 64-bit host for a 32-bit target.\nCorrect.\n\nWere you compiling on a 64-bit host for a 64-bit target before (because existing 64-bit shared libraries could be used)?\n\nYes.\n\nWere you compiling the same version of Chromium (because GN bootstrap script has changed)?\n\nYes.\n\nEDIT: I just re-read and you mentioned you could do both cross and native compilation (i.e. 64-bit host to 64-bit target, and 64-bit host to 32-bit target).\n\nSo far I have cross-compiled successfully only 64-bit host to 64-bit target. I am still struggling with 64 host to 32 target.\nRe. the suggestion to reorder flags here is what I did:\nFirst I moved the CFLAGS lines after the call of bootstrap.py and before the call of ninja. The resulting build.sh:\nhttps://susepaste.org/80d52e41\nThe output shows some new error:\nhttps://susepaste.org/7875fafd\nThen I tried explicitly setting native flags before calling bootsrap.py:\nhttps://susepaste.org/13c10e79\nand that again gave the error:\nhttps://susepaste.org/fd8c60a2\n. The doucmentation says that clang is a cross-compiler. From what you say it sounds to me that the program should be written in a way which supports cross compilation. I wonder what that means.\nI suppose the discrepancy which you point out (sizeof) may be due to the assumption that the CFLAGS must be after the call of bootstrap.py because there are no such discrepancies if CFLAGS are set before bootstrap.py. IOW: isn't it more correct to look for a way to fix the failures with includes?\n\nI belive you will need to set some GN flags in order to tell the build process to cross-compile a 32-bit binary. Unfortunately, I don't have any experience with this.\n\nHow do you set thouse GN flags (in which file(s)?) and where can I read some documentation about what flags exists or may be needed?. So here is what I found:\nDiscussion from 2015 suggesting some modifications for a 32-build. I don't know if those are applicable as of today of how to use them. In any all sources I found clearly say that it is impossible to build 32 bit chrome on 32 bit machine because the build process requires more memory than any 32 bit system can handle. So it must be done on a 64 bit machine.\nA similar discussion from 2016.\nOfficial documentation about Linux-specific build instructions where in system requirements it is written:\n\nx86 builds are not supported on Linux\n\nStill in the Mandriva section it says:\n\nThese packages are for 64 bit, to download the 32 bit packages, substitute lib64 with lib\n\nwhich seems to contradict the above statement. I don't know if that implies that with certain modifications a 32-bit build would be possible (as per older discussions).\nGN build configuration documentation which says:\n\nChrome OS supports \"x86\" and \"x64\", but to build a 32-bit binary you will need to use a sysroot on a 64-bit machine.\n\nI have no idea if that applies to chromium browser as well. It also suggests:\n\nFor 32-bit official builds, append this arg to the above set: target_cpu = \"x86\"\n\nConsidering all that: can you recommend any particular steps to try (as I am honestly lost in what is discussed on Google groups) or is it a mission impossible (considering the info in system requirements).\nETA: On a second read, I think the system requirements mean that the build host should be x64, i.e. the requirement is for the building system, not for the target.. > Architecture is just one parameter that defines a target configuration, see the Target Triple for other parameters.\nI have linked to the same reading earlier. The big question which still remains is: how does one specify the target tripple when building UC? Currently I do it by exporting CFLAGS inside build.sh. Are you suggesting any other approach?\n\nI believe Debian manages to build i386 packages on i386 systems. You can have a look at the chromium-browser source package to see how they did it.\n\nI don't know how this can be possible, considering that chromim developers explain that linking needs more than 4GB of memory. Anyway re. Debian I searched and found this but I have no idea where to look further (as it doesn't actually show how it was built).\nCan you please \"decypher\" for me what this means and how to use it in the context of UC? (considering that I am building linux_portable and not debian-specific). Thanks for the info. I will have to look into all that more carefully.\n\nGoogle normally uses sysroots in Linux builds, but ungoogled-chromium and all other Linux distros that package Chromium don't use them.\n\nDoes that mean there is a risk of ending up with a binary which is not ungoogled?. Sorry for the slow reply.\n\nPotentially yes, only if you use Google's pre-built sysroot while building.\n\nHm. But didn't the above explanations mean that there was no other way?\nIOW: What would be the right (ungoogled) way to approach all this?\nSorry for so many questions, this is just quite confusing matter for a non-dev. Hopefully this issue may help to document a 32-bit build process.. Thanks for clarifying.\nAre these the scripts you are you are talking about?\n. *re-subscribing with new account. > Illegal instruction may arise because LLVM is compiling with an assembly instruction that your CPU doesn't support.\nI don't see why. I am building everything with -march=native and -mtune=native -- the way I have always done and which has always worked so far.\n\nWe should stick either to stable versions or LLVM revisions that Google uses to compile\n\nBut the current stable version of LLVM is 7.0 (released on 2018-09-19) and UC requires 8.0 to compile which as of this moment LLVM 8 is an \"upcoming release\" as per their official page. I also remember your words about it:\n\nIn addition, it seems likely that linux_portable actually requires at least LLVM 8;\n. > It's hard to say unless we get down to the specific changes that happened in trunk.\n\nTrue. I already wrote in the LLVM user maling list but nobody has replied. I wish I knew how to properly report it as a bug but given the scarce info I wonder what to do.\n\nMaybe we could document the LLVM revision that works and/or Google uses?\n\nSounds good to me.. - uBlock origin\n- uMatrix\n- HTTPS Everywhere\n\nDisable HTML5 Autoplay\n\nDoesn't chrome://flags/#autoplay-policy control this?. Considering that so many extensions request significant access rights a relevant question when talking about \"best\" seems to be: How do you decide whether you can grant those rights to an extension or not?\nDo you check the source code?\n\nIf yes: How exactly? Are you doing it line by line for all files or are you looking for a particular pattern in specific files?\nIf no: Do you simply follow recommendations?\n\nDo you trust an extension based on what many people trust?\nAnd the dangers of that. (considering so many people use all kind of spyware without even knowing)\n. @pegasusearl - when the answer is before the question it looks weird :)\n\nNever install from the chrome web store, install directly from source (github/gitlab etc..), this will avoid auto-updates with unforseen code added\n\nBut UC is \"immune\" to that, so it is not a real issue.. My recent findings:\nThe command line option:\n--enable-strict-mixed-content-checking\ndisables mixed content.\nThe following flag does the same + it enforces a non-HTTPS warning in address bar:\nchrome://flags/#enable-potentially-annoying-security-features\nAs you may know uMatrix can also block mixed requests.\nSo these practically make HTTPS Everywhere not necessary. The only thing which these 2 options don't do is to enforce secure requests but that may break loading (just like with HTTP-E) and is generally a thing which the website itself should fix, not the client.. Tried. The issue remains.. > Firefox does not need to be rebuilt to be cleaned from privacy/security issues; as all settings can be changed in the about:config\nI question that and you should question it too (unless you have inspected personally all the millions of lines of code).\n\nThis project aim to fix all security/privacy issues related to firefox and also tune it to gain some speed performances.\n\nThis is an impossible task, so no serious project should ever claim even an attempt for full security and privacy, especially in conjunction with speed performance. Not only because security and speed are contradictory (in today's computer world) but also because of all the issues in the hardware itself which cannot be fixed - neither at kernel level, even less at browser settings level.\n. > i don't have the time to maintain a more elaborated version\nThis is quite different from the claim about aiming to fix all security/privacy. Also please bear in mind:\nI am not alone != everyone who is with me is right\nAiming to secure != secure\nMitigation != fix\nNot in my vocabulary != not a fact (and vice versa)\nUsability <-> security (in today's computers)\nIn any case this is much more off-topic than the issue about implementing Tor functionality in UC, so we should probably stop here :). You may be right but considering how serious this sounds it deserves a more in-depth look.. @azdps the link you shared seems to be about QUIC flags. How is that related?\nBTW speaking of QUIC: I see it as the next anti-privacy thing by G because Tor works with TCP only. Of course that's a whole other big topic to discuss separately.. I haven't taken the trouble to measure it but the very\nfact that I had enough time to notice it means it can\nbe optimized. Considering that the whole build takes\nabout 2h everything counts.\nBTW man page of xz shows a --threads= option.\n. I don't know how to fix this with Python.\nI just noticed it and decided to share it.\n. Can you point me to the actual code which runs the xz?\n. Thanks. Unfortunately I don't know how this has to be fixed in Python.\nI reported it because noticed that it takes more than a minute to create that tar.xz which seems way too much considering that the whole build is being done on a ramdrive (tmpfs) using i7 3770.\nJust for comparison, using system tar it takes less than 10 seconds to compress the same data:\n```\n[/tmp/download]: time tar czf test.tgz ungoogled-chromium_70.0.3538.110-1_linux\nreal    0m9.860s\nuser    0m9.794s\nsys     0m0.367s\n``. I noticed that the above generates94605755` bytes file which is probably not a fair comparison.\nTesting with something closer to what you use and with streaming output to xz I see that lzma doesn't seem to use multiple threads at all (resulting file is 67179312 bytes):\n```\n[/tmp/download]: time tar -c ungoogled-chromium_70.0.3538.110-1_linux | xz --format=lzma --threads=1 > test.tar.xz\nreal    1m30.870s\nuser    1m30.529s\nsys     0m0.473s\n[/tmp/download]: time tar -c ungoogled-chromium_70.0.3538.110-1_linux | xz --format=lzma --threads=4 > test.tar.xz \nreal    1m30.516s\nuser    1m30.250s\nsys     0m0.533s\nFor comparison `7z` creates is faster and the output file is smaller:\n[/tmp/download]: time tar cf - ungoogled-chromium_70.0.3538.110-1_linux | 7za a -si -t7z -m0=lzma2 -mx=9 -mfb=64 -md=32m -ms=on test.tar.7z\n7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\np7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz (306A9),ASM,AES-NI)\nCreating archive: test.tar.7z\nItems to compress: 1\nFiles read from disk: 1\nArchive size: 63887463 bytes (61 MiB)\nEverything is Ok\nreal    0m41.607s\nuser    1m54.822s\nsys     0m0.538s\n``\nSo if anything can be optimized: perhaps7z` is the way.. > How about completely removing all broken links from Chromium including its online help pages?\nI have thought about that too but it may also be confusing for someone who may have just started using UC. Perhaps it will be better to have them display a UI element saying \"In UC all links pointing to Google have been removed deliberately\". Then it will not create the impression of something broken. Ideally the info from each link should be available inside the browser itself, not on some external host, but that may be too much work. Also some of that info may not apply to UC itself, so it would need additional maintenance.. > \"Link is deliberately not working\" messages...\nBut I have never suggested that. Deliberaterly removed != deliberately not working.\nAlso a layman doesn't know what a \"client\" is. So any message should be clear enough for everyone, not just for experts. Currently it is not, hence the issue.. Be careful when downloading Google owned content. It may be copyrighted (and risky for this precious project).\nPerhaps the safest (and maybe easier for you) would be to display a special page explaining (for all links) that this is ungoogled chromium and that's why it has no links to Google whatsoever, underlining that it is not an error (broken) but that it is so by design and concept.\nIf the user should be given the option to find more info: That info page may contain a link to a search URL, e.g. https://searx.me/?q=chrome+incognito (using whichever search engine the user has specified in settings) giving the user a possibility to search for himself - the way he wants.. Re. Any type of error message creates the impression of something broken - it seems we agree doesn't sound good.\n\nand what to do to view the actual page (maybe even provide the real link to view the page?)\n\nA link to Google in an ungoogled project - hm, please don't do it :) That's why I suggested a search link instead.\nThe very fact that you would have to handle separately actual \"real links\" and other links too Google (which you replace currently) is prone to errors which can lead to leaks in other parts of the project. Not worth the long term risk for something cosmetic like the current issue. That's worse than showing an error message (or having things as they are right now).. ",
    "leewdch": "From what I read online about the content deletion on exit it was supposed to delete ALL local content, history as well. Got it, guess I should not trust every single tech blog I find online. Thanks for the info. ",
    "2x9Mon": "That's correct, they are tested on 66.0.3359.139-1 for Windows.\nAs for the UDP broadcasts, they persist even after disabling \"Load Media Router Component Extension\" and \"Media Remoting during Cast Tab Mirroring\" in chrome:flags and setting EnableMediaRouter to false via group policy. A comment on issue 665572 at bugs.chromium.org suggests just disabling Media Router should be enough to stop them, but it's from two years ago and I haven't checked this on an unmodified Chromium build.. Under Windows I tried both this...\n[HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Chromium]\n\"EnableMediaRouter\"=dword:00000000\n...and setting EnableMediaRouter to 0 by enabling the \"Enable policy management page\" experiment and going to chrome:policy-tool.\nIn both cases the change is acknowledged by about:policy, but the broadcasts continue anyway.. @xsmile ,\nI did restart, and chrome:policy indeed says it's mandatory. My OS is Windows 7 x64 in case that helps.\nSpeaking of which, I'm guessing you compiled 67.0.3396.87 from source to run it under Windows 10? I'm running 66.0.3359.139-1 as that's the latest one I can find precompiled binaries for. Maybe this is fixed in version 67, making my bug report on this matter moot :). @xsmile \nThanks for the link! I upgraded to that version and the broadcasts are now gone under the same profile and setup, without having to patch anything.\nI took a little time to find out which of the countermeasures I'd tried actually does the trick. It seems the UDP traffic is gone if and only if EnableMediaRouter is set to 0 via group policy. The \"official\" solution of disabling \"Load Media Router Component Extension\" and \"Media Remoting during Cast Tab Mirroring\" via chrome:flags does nothing, and neither does using their corresponding command-line switches instead.\nI guess this issue is only about the crash reporter processes now :). ",
    "azdps": "I located 2 chromium files that seem to be related to broadcasting 239.255.255.250.\ndial_service.cc\npermissions_data_unittest.cc\nNot really sure what could be done with these but thought this information could be helpful.. Wow nice find anchev. Looks like they are actively working on it right now in chromium.\nInteresting flags. After some tinkering and learning a little bit about python I was able to fix the issue. \n```\nWorks great\n(source_tree / 'out/Default/args.gn').write_text(str(bundle.gn_flags))\nWorks great too. Although it works without encoding is it needed?\n(source_tree / 'out/Default/args.gn').write_text(str(bundle.gn_flags), encoding=ENCODING)\nDoes not work as intended\n(source_tree / 'out/Default/args.gn').write_text('\\n'.join(str(bundle.gn_flags)), encoding=ENCODING)\n```\nResult of the changed code creates the expected args.gn file. args.txt\n. I have yet to have a successful Windows build. I'm working my way much closer though. When I do I will be sure to share it here.. With some changes that have recently been fixed with the Windows building process I have been able to get fairly far through the build process. Unfortunately, the build process fails when building the safebrowsing portion of ungoogled-chromium. Looking through some of the patches and the files that are being patched it looks like the Windows safebrowsing patches need to be updated. Not only are there specific patches for Windows there's also other safebrowsing patches as well that are applied in a certain sequence during the patch process. Not sure if those patches are having a negative impact as well.. I briefly looked at  the chromium code and it seems that device_id_helper.cc will generate signin_scoped_device_id if one does not exist.. I would prefer ungoogled-chromium to remain as is and not a separate distribution. Branching too far from chromium would be a huge nightmare for updating security issues etc. Patching and pruning chromium code would probably be best. I think the difficult part is to make sure the build process works properly for each operating system. Also determine which operating systems will be supported. I would prefer that the patches for each operating system become completely separate from one another and not rely on a patch sequence as it currently is. It currently seems that for example changing a patch for debian can possibly affect other operating system builds. Maybe there can be maintainer(s) for each OS. If modifications are made to patches for a specific OS it should not affect the build process of another. Although if patches are modified and can benefit other OS'es that ungoogled supports I think the maintainers for those OS'es should inspect the patches to see if they could be applied to the maintainers OS build.\nI too like a lean mean browser without unnecessary bloat.. > @azdps and @qvint are leaning more towards breaking up the project and clarifying what \"ungoogling\" entails, leaving more control to builders and packagers in what they want \"ungoogled-chromium\" to be. \nI'm not leaning towards separate projects. Just separate patches for each OS distribution. I prefer not to see patches from one distro affecting another distro build process.\nI like the direction you are going with with the project. I do think the project lacks OS patch maintainers. Unfortunately, I don't have the coding knowledge to fix the Windows safe browsing patches.\n. Brave - Suppose to be working towards pay to browse. No way.\nVivaldi - Closed source. Not fond of the GUI.\nIridium - I currently use this. Seems to have the same goals as ungoogled-chromium.\nIf you are actually considering a name change I like:\npure-chromium\nchromium-pure\nBut ungoogled-chromium is fine as well.. ",
    "caada": "I downloaded the Brave browser yesterday. I made it portable. I changed the settings and modified the extensions. I copied to 3 computers. And settings and extensions are preserved. So, yes Brave is portable as far as I tested. \nBased on my research, people are saying related file is pref_hash_store_impl.cc and functions are GenerateDeviceId \nGetDeterministicMachineSpecificId \nLookupAccountNameW. \"chrlauncher\"\nis not portable accross systems. chrome is checking for system change lately. \nThanks for the suggestion. . If someone can build chrome windows version with --disable-machine-id and --disable-encryption switches, I can test portability.\nThanks keeping an eye on this issue. . you have 2 options:\nungoogled-chrome, garble the places chrome phones home. this was the original intention of ungoogled-chrome.  I personally prefer ungoogled-chrome stays like this. this is a simple approach; modifications will be fast, won't break the code, so everyone can compile. we can have fast updates. we are aware that when we use google services, we are subject to tracking. \nlite-chrome, in this, you are talking about chrome browser with just the blink engine. everything about google is removed. of course, everyone would love to have something like this; however, this is not practical. since google always adds more tracking, code will eventually break and that sounds to be the case right now with the project. you need to put lots of effort in this. that's probably why you are talking about \"popularity\". if you want to go this way, I suggest to start a new project. \n. ",
    "octopuserectus": "I think you can achieve portability by using this launcher, it keeps everything in one folder: https://github.com/henrypp/chrlauncher\nI am not sure though, but I think it worked fine when I transfered the folder to another system some time ago.. ",
    "mehrdadn": "I just realized my issue (#538) is essentially a duplicate of this one. I believe the patch I suggested there should solve this problem.. I believe it's performed only on Windows (but I don't know for sure) and the rationale is to prevent external programs from messing with preferences. I think that wasn't common in other platforms, hence why it occurs only on Windows.. I think it's just the preferences file that's checked for tampering (there's a file called \"Secure Preferences\"). But even if other things are checked for migrating profiles between machines, note that migrating profiles between machines is not the real issue here\u2014the problem here is that even on the exact same account and machine, you can't migrate a Chrome profile to ungoogled-chromium. I think it'd directly benefit this project to make that migration easy; the ability to migrate to other machines, if affected, would only be a side benefit.\nAnd yes, it's true that not all errors are caught, but errors are not introduced in the first place unless an external entity is messing with the profile. Given that normal Chrome doesn't allow tampering on Windows, programs don't do that anymore either, so the only time this would occur for a user is if he tried to modify his preferences by hand himself in ungoogled-chromium... in which case I think the user would know what he's doing and the potential for the resulting damage. Though even then, Google's solution of just wiping their settings/extensions/etc. isn't exactly helpful... it inflicts a ton more damage than the user himself did.\nBut in any case, I think a flag would suffice anyway if you think it needs to be behind one, though it probably wouldn't help make it too easy to migrate to ungoogled-chromium.. Oh, the alternative interpretation was migrating from Chrome to ungoogled-chromium.\nAnd again, yes, it does \"catch\" corruption caused by software/hardware glitches, and it \"fixes\" it by just obliterating almost everything. You can judge whether that's a cure better or worse than the disease; personally I think it's the latter, since I've literally not found this helpful even once.... Hi @pellaeon, yup I got it working. I just changed the last line of PrefHashCalculator::Validate() (in services/preferences/tracked/pref_hash_calculator.cc) from return INVALID to return /*IN*/VALID.\nBTW, another helpful thing I did (completely unrelated to this issue, but maybe something else you'd also like to consider) is to avoid blocking extensions that aren't on the web store. You can do that by changing return false to return true in ExtensionManagement::IsInstallationExplicitlyAllowed() (chrome/browser/extensions/extension_management.cc).. Yup!. Related to #538.. ",
    "crazy-max": "@Eloston I can implement the changes I made on brave-core here if you like ?. @Eloston I also tried to build a release on my side by fixing patches and also in a Python script but I'm encountering a strange error now : #598. @Eloston\n\nWIP to handle certificates but I think we cannot do something about it so feel free to remove the WIP :)\nFor me encryption is not tied to machine-id. Machine ID seems to be linked to extensions and only used on Windows.. @Eloston Passwords are stored in the user data directory in a sqlite database called Login Data with the following schema :\n\nsql\nBEGIN TRANSACTION;\nCREATE TABLE stats (origin_domain VARCHAR NOT NULL, username_value VARCHAR, dismissal_count INTEGER, update_time INTEGER NOT NULL, UNIQUE(origin_domain, username_value));\nCREATE TABLE meta(key LONGVARCHAR NOT NULL UNIQUE PRIMARY KEY, value LONGVARCHAR);\nCREATE TABLE logins (origin_url VARCHAR NOT NULL, action_url VARCHAR, username_element VARCHAR, username_value VARCHAR, password_element VARCHAR, password_value BLOB, submit_element VARCHAR, signon_realm VARCHAR NOT NULL, preferred INTEGER NOT NULL, date_created INTEGER NOT NULL, blacklisted_by_user INTEGER NOT NULL, scheme INTEGER NOT NULL, password_type INTEGER, times_used INTEGER, form_data BLOB, date_synced INTEGER, display_name VARCHAR, icon_url VARCHAR, federation_url VARCHAR, skip_zero_click INTEGER, generation_upload_status INTEGER, possible_username_pairs BLOB, UNIQUE (origin_url, username_element, username_value, password_element, signon_realm));\nCREATE INDEX stats_origin ON stats(origin_domain);\nCREATE INDEX logins_signon ON logins (signon_realm);\nCOMMIT;. And Chromium uses CryptProtectData to encrypt passwords in the password_value BLOB.. @Eloston Ok understand about the cleanup issue in the script ;)\nAbout the suggestions, I am making changes to use the official Chromium depot_tools bundle. I was wondering why you weren't using it anyway?. @Eloston It was for a better integration in order to limit itself to a single construction process, but I completely understand. Thank you for your explanations. And yes I will make other changes, especially in the build documentation and consolidate the build script.. @Eloston For now you can merge this PR. I will create a new one for build/packaging on Windows later. I've copied the stub from machine_id_provider_stub.cc which is also handled on mac/linux :\n// static\nstd::string MachineIdProvider::GetMachineId() {\n  NOTREACHED();\n  return std::string();\n}\nIt seems to work for Windows too :). You're right, I should have asked about this behavior. But indeed this stub allows to test the code without dealing with this dependency directly.. I get an error if the extraction failed. So I think it's better to clean this folder before extraction ?. On Windows rename does not work if the file already exists. @intika I was talking about this line.. The build script is not working as expected doh\nI will check this out. ",
    "TN0X": "@Eloston: you have updated the script \"update_lists.py\" in devtools with the exclude pattern for visual_studio_writer.cc, but it has no effect yet because of the following reasons: \n1.) the pattern is in the wrong section in PRUNING_EXCLUDE_PATTERNS. It should be instead in the DOMAIN_EXCLUDE_PREFIXES, because the substitution is executed in the domain_substition task and this task uses domain_substitution.list and not pruning.list.\n2.) but these changes have no effects until any developer executes the update_lists.py script and pushs the changed domain_substitution.list to the repository, so the problem is not solved yet in the current release. > 4. Disable safe-browsing patches by:\n\n\nSearch in the folder C:\\ungoogled-chromium-71.0.3578.98-2\\patches for safe and delete all files related to safe search\n\n\nyou dont have to delete any files. Only edit the patch.list and gn_flags.map files\n\n\nRun:\n\nmkdir build\\src\npy get_package.py windows build\\src\\ungoogled_packaging\ncd build\\src\n9. Search once again for safe inside build\\src and also remove any files there\n10. Finally build by running py ungoogled_packaging\\build.py\n\nStep 9. is not neccessary, because step 8. copies your changes in step 7. into build\\src\\ungoogled_packaging. \nHere the steps for the build process of ungoogled-chromium 71.0.3578.98-2:\n\n\ncheckout tagged version 71.0.3578.98-2 of ungoogled-chromium\n\n\ndelete build/src folder completely (after prior build process)\n\n\nedit like described for deleting all \"safe-browsing\" references:\nconfig_bundles\\windows\\patch_order.list\nconfig_bundles\\common\\patch_order.list\nconfig_bundles\\common\\gn_flags.map\n\n\nRun\nmkdir build\\src\npy get_package.py windows build\\src\\ungoogled_packaging\ncd build\\src\npy ungoogled_packaging\\build.py\npy ungoogled_packaging\\package.py\n\n\nthats all. > @TN0X should I worry about this error?\n\n`\n[546/20133] ACTION //chrome/test/chromedriver:embed_version_in_cpp(//build/toolchain/win:win_clang_x64)\nERROR:root:Git error: rc=0, output='\nNo, I got the same error message at this point. . > ### Description\nError during patching:\npatching file chrome/BUILD.gn\nHunk #2 FAILED at 83.\n\nThe problem arises due to problems in some patches for windows since chromium 72.0.72.0.3626.xx.\nSo there is not only the known issue with all safe-browsing patches since 71.0.3578.98-x, which could be solved by disabling these patches and setting the approriate build-flag. Since ungoogled-chromium 72.0.3626.96-1 there are new issues with other patches for windows. These patches in ungoogled-chromium does not fit to the source code of chromium 72.0.xxx:\nwindows-disable-reorder-fix-linking.patch:\npatching file chrome/BUILD.gn\nHunk #2 FAILED at 83.\nwindows-disable-rcpy.patch:\npatching file build/toolchain/win/tool_wrapper.py\nHunk #1 FAILED at 195.\nHunk #2 FAILED at 227.\nlast working build with disabled safe-browsing patches is 71.0.3578.98-3. > @TN0X thank you for the answer, can you tell us the exact steps to disable safe browsing in 71.0.3578.98-x and to add the build-flag? I tried to do this and failed (not very well versed in chromium).\nsee: https://github.com/TN0X/ungoogled-chromium/compare/master...TN0X:test1\nyou have to change these files: \nconfig_bundles/windows/patch_order.list\nconfig_bundles/common/patch_order.list\nconfig_bundles/common/gn_flags.map\n. ",
    "JokerQyou": "It seems like some extensions cannot be downloaded this way, like this one: https://chrome.google.com/webstore/detail/privacy-badger/pkehgijcmpdhfbdbbnkijodmdjhbjlgp. Using the URL template provided in the wiki page would result in a 204 No content response.. ",
    "rburcham": "@basilthegreat have you had success?  I'm happy to help too.. Yeah bleeding edge really should be a 9999 ebuild.  At least that's what I'm renaming it to in my overlay.. ",
    "stefantalpalaru": "www-client/ungoogled-chromium-69.0.3497.100.1 is available in my overlay: https://github.com/stefantalpalaru/gentoo-overlay\nPlease test it.. > a ebuild that strictly follows ungoogled-chromium's GN flags\nIf you really wanted that, you should have used the provided script to generate them, like Arch Linux does: https://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=ungoogled-chromium&id=5952aa489b6954319455bf08adfb7783c3e237c7#n119. Of course. I've been running ungoogled-chromium since I got the ebuild working, but don't expect me to test every possible combination of USE flags. My build has these enabled: \"cups proprietary-codecs suid system-icu system-libvpx tcmalloc\".. How can you release a version 70 when the most recent tag is for 69.0.3497.100-2?\nhttps://github.com/Eloston/ungoogled-chromium/tags\nIf you're forking the project to apply the patchset to unsupported Chromium versions, you need to rename the package.. We have live ebuilds for that. Make it ungoogled-chromium-9999.ebuild and there will be no ambiguity about its stability or upstream support.. Nice job on the patches and new USE flags!\nWhy not change installation directories and binary name so you can keep Chromium installed at the same time? Since this is a fork, it also makes more sense to rename the binary to the name of the fork.\nAlso, is \"!<\" any different from the established \">=\" in RDEPEND?. \"firefox-bin\" is a drop-in replacement for \"firefox\", but they have different binary names so they can be installed side by side. This gives more freedom to the user and clearly differentiates the packages.\n. I had a real use for it, a few days ago. \"The Great Suspender\" extension was not working on ungoogled-chromium, so I tried to remove it and install it again. Unfortunately, the removal process led to all suspended tabs being lost. I had to copy back the relevant db file from backup, start Chromium, unsuspend all tabs and only then upgrade the extension. It still doesn't work on ungoogled, for some reason.\nI also noticed that ungoogled-chromium has no access to the app store, so if you want to install an extension from there, you have to use Chromium.. ",
    "unicornlover89": "@rburcham I work on this intermittently, so far i'm still figuring out how to build normally on my gentoo m achine :P. ",
    "powerman": "\ndon't expect me to test every possible combination of USE flags\n\nThere is dev-python/ebuildtester to make such testing automated and easier. Of course, no one expects you to manually test how it works with each USE flags combination, but at least you should be sure it's able to build.. ",
    "blackknifes": "Thanks for you answer. I have found function to build dll. I is similar to build libchromium of electron.. ",
    "Zig-03": "they're usually on this page  no? In any case thanks for the link.. No, just add a check box saying \"Never ask me again\". This functionality may be important for someone.. ",
    "lalascott7": "No. It is a telephony website where you dial calls like a cloud-based dialer similar to Five9. Not sure if you are familiar with that. I have to end up using Firefox for now. But I am wondering if I can make Chromium work for ytel. It It works with regular Chrome :( I don't want to have to go back to that. I really need it to work for my job. When I log in I get the sound prompt. But when I hit active status to dial my calls in it, I don't get the sound that I a ready to take calls. Same with mycallcloud which is another web phone. :( . Do you have access to IRC? I am tired of waiting to get requests. This is so tiring.. Can I just get immediate help, please? I have to use this for work, otherwise, I will have to say forget it and use the original chrome and just don't sign into it. Just remove the tracking stuff. I wish someone can create an article on how to get sound to work on web phones in telephony.. hmm ok well my Project Manager told me to use Chrome in incognito mode so I had to set the settings exactly how Chromium is and just use that. I still have Chromium on my PC. I did not sign into Chrome as I am anonymous on that. I deleted my bookmarks and everything with them. If you guys can see if it can work in Chromium that would be awesome! I understand this is a hobby to you. I did my research on both ytel.com and mycallcloud.com webphones and yes they are both WebRTC-based.  So it would be possible it can work?. Yes it was Chromium the ungoogled one.. Ok. Well if you guys come across anything, let me know. I am in the mean\ntime configurated regular chrome like chromium's settings are. The web\nphones do work. Thanks.\n--\n  LaToya Scott\n  lalascott@postinbox.com\nOn Mon, Aug 13, 2018, at 7:00 PM, Eloston wrote:\n\n\nIf you guys can see if it can work in Chromium that would be awesome!> I'm confused. So you confirmed that Chromium doesn't work? Or by\n\"Chromium\", do you mean ungoogled-chromium?>> So it would be possible it can work?\n\nWebRTC testing sites say WebRTC is functional, but it seems that\ncertain web applications don't work anyway. I don't know why, and I'm\nnot sure how to diagnose (I know little about WebRTC). Seeing whether\nChromium and Chromium-based browsers (like Brave) work or not may give\nus a clue of the root cause.> \u2014 You are receiving this because you authored the thread. Reply to\nthis email directly, view it on GitHub[1], or mute the thread[2].\nLinks:\n\n\nhttps://github.com/Eloston/ungoogled-chromium/issues/452#issuecomment-412694007\nhttps://github.com/notifications/unsubscribe-auth/AoYzOSJuLfbUFwc-Y1PHz7T7fmCbXDlxks5uQgUegaJpZM4V6poO\n. \n",
    "BobMacpherson": "\nI'm guessing you mean the GN flag use_vaapi and the patch inox-patchset/chromium-vaapi-r18.patch, respectively.\n\nYes, the gn flag, and commenting out the  chromium-vaapi-r18.patch in ungoogled/patch_order.list\n\nSo do you get the same result disabling chrome://flags/#enable-accelerated-video?\n\nI cannot launch chromium and even using --no-experiments switch, chromium faults\n\nWhat conditions causes this crash?\n\nCompiling and then running chromium.\n\nThis is an interesting error. I'm not sure if it's related to the VA-API errors above, but it does have a higher severity level... \nMaybe this is causing the crash?\n\nI dont have the slightest clue, this is a new issue for me, i've been using ungoogled-chromium since around v 58\nI can run vanilla chromium fine, its just the patched version that im not able to run.\nThis is the error when i disable the gn flag for vaapi or simply comment out the vaapi line \nERROR Unresolved dependencies.\n//content/gpu:gpu_sources(//build/toolchain/linux/unbundle:default)\n  needs //media/gpu:libva_config(//build/toolchain/linux/unbundle:default)\n. ",
    "taahamahdi": "Thanks for the info!. After doing a bit of research, this issue seems somewhat related. Is the issue out of the scope of this project?. My bad, I was pointing out that there is actually an error message presented. The issue is still there, and ungoogled-chromium still opens, albeit with a delay.. Sorry for taking so long to respond. I tried commenting out the flags and there was no change in startup time. It might just be an issue with Buster itself.. Yup! I have it enabled in both regular Chromium and ungoogled-chromium. I tried running ./chromium --show-component-extension-options --disk-cache-dir=/tmp/ungoogled-chromium-disk-cache --disable-component-update --ignore-gpu-blacklist --no-default-browser-check --media-router=0 --enable-remote-extensions --load-extension=`ls -dm /usr/share/chromium/extensions/* 2>/dev/null | tr -d '\\n'` in the folder /usr/lib/chromium, and ungoogled-chromium launches as fast as regular Chromium now, but I'm not sure why. I guess I can alias the command in the meantime, but if I'm using the same launch options, I wonder why it's faster than just entering chromium.\nOne thing to note is I no longer get the libva warning I was getting earlier, even after opening multiple windows at the same time with ./chromium [same as before]. Are there any other flags I might be missing?. Just tested it, ungoogled-chromium is still noticeably slower than Debian's chromium package. By the way, which .deb packages should I be installing after manually building? The following packages are in my ungoogled-chromium/build folder:\nungoogled-chromium_70.0.3538.110-3~buster_amd64.deb\nungoogled-chromium-common_70.0.3538.110-3~buster_amd64.deb\nungoogled-chromium-driver_70.0.3538.110-3~buster_amd64.deb\nungoogled-chromium-l10n_70.0.3538.110-3~buster_all.deb\nungoogled-chromium-sandbox_70.0.3538.110-3~buster_amd64.deb\nungoogled-chromium-shell_70.0.3538.110-3~buster_amd64.deb. Cool, just checking. I have the issue either way unfortunately. . ",
    "glomeg132": "Unfortunately, I do not know how to program ungoogled chromium. But is\u2019s correct that version 67 is the current Version for Ubuntu right?. ",
    "shiromichi": "I tried build at 8815e41\n 2018-09-15 00:19:11,129 - INFO: * Applying windows-fix-enum-conflict.patch (119/119)\n 2018-09-15 00:19:11,129 - DEBUG: E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src\\third_party\\git\\usr\\bin\\patch.exe -p1 --ignore-whitespace -i E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src\\ungoogled_packaging\\patches\\ungoogled-chromium\\windows\\windows-fix-enum-conflict.patch -d E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src --no-backup-if-mismatch --forward\n (Stripping trailing CRs from patch; use --binary to disable.)\n patching file extensions/browser/api/feedback_private/feedback_private_api.cc\n (Stripping trailing CRs from patch; use --binary to disable.)\n patching file extensions/common/api/feedback_private.idl\n 2018-09-15 00:19:18,003 - INFO: Path has no substitutions: chrome/browser/plugins/plugins_resource_service.cc\n 2018-09-15 00:19:19,229 - INFO: Path has no substitutions: chrome/browser/safe_browsing/client_side_model_loader.cc\n 2018-09-15 00:19:22,079 - INFO: Path has no substitutions: chrome/common/page_load_metrics/page_load_metrics_util.cc\n 2018-09-15 00:19:24,438 - INFO: Path has no substitutions: components/dom_distiller/content/browser/dom_distiller_viewer_source.cc\n 2018-09-15 00:19:24,441 - INFO: Path has no substitutions: components/dom_distiller/core/html/preview.html\n 2018-09-15 00:19:24,452 - INFO: Path has no substitutions: components/domain_reliability/google_configs.cc\n 2018-09-15 00:19:24,742 - INFO: Path has no substitutions: components/google/core/browser/google_url_tracker.cc\n 2018-09-15 00:19:28,218 - INFO: Path has no substitutions: components/variations/net/variations_http_headers.cc\n 2018-09-15 00:19:55,330 - INFO: Path has no substitutions: net/dns/dns_transaction.cc\n 2018-09-15 00:19:56,141 - INFO: Path has no substitutions: net/tools/transport_security_state_generator/transport_security_state_generator.cc\n 2018-09-15 00:19:57,408 - INFO: Path has no substitutions: rlz/lib/lib_values.cc\n 2018-09-15 00:20:20,196 - INFO: Path has no substitutions: third_party/catapult/third_party/polymer/components/font-roboto/roboto.html\n 2018-09-15 00:20:21,196 - INFO: Path has no substitutions: third_party/catapult/tracing/third_party/gl-matrix/jsdoc-template/static/default.css\n 2018-09-15 00:20:27,430 - INFO: Path has no substitutions: third_party/crashpad/crashpad/doc/support/crashpad_doxygen.css\n 2018-09-15 00:21:04,376 - INFO: Path has no substitutions: tools/md_browser/base.css\n E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src>call \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\" >nul\n\n E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src>\"C:\\Python27\\python.EXE\" \"tools\\gn\\bootstrap\\bootstrap.py\" \"-oout\\Default\\gn.exe\"\n ninja: Entering directory `E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src\\out\\Release\\gn_build'\n ninja: error: unknown target 'gn'\n Traceback (most recent call last):\n   File \"tools\\gn\\bootstrap\\bootstrap.py\", line 92, in <module>\n     sys.exit(main(sys.argv[1:]))\n   File \"tools\\gn\\bootstrap\\bootstrap.py\", line 87, in main\n     ['ninja', '-C', gn_build_dir, 'gn', '-w', 'dupbuild=err'])\n   File \"C:\\Python27\\lib\\subprocess.py\", line 190, in check_call\n     raise CalledProcessError(retcode, cmd)\n subprocess.CalledProcessError: Command '['ninja', '-C', 'E:\\\\work\\\\github\\\\Eloston\\\\ungoogled-chromium\\\\build\\\\src\\\\out\\\\Release\\\\gn_build', 'gn', '-w', 'dupbuild=err']' returned non-zero exit status 1\n\n E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src>exit\n Traceback (most recent call last):\n   File \"ungoogled_packaging\\build.py\", line 187, in <module>\n     main()\n   File \"ungoogled_packaging\\build.py\", line 175, in main\n     shutil.which('python'), 'tools\\\\gn\\\\bootstrap\\\\bootstrap.py', '-o'\n   File \"ungoogled_packaging\\build.py\", line 65, in _run_build_process\n     **kwargs)\n   File \"C:\\Users\\TEST\\AppData\\Local\\Programs\\Python\\Python37\\lib\\subprocess.py\", line 468, in run\n     output=stdout, stderr=stderr)\n subprocess.CalledProcessError: Command '('cmd.exe', '/k')' returned non-zero exit status 1.\n\n E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src>\n\n\n['ninja', '-C', gn_build_dir, 'gn', '-w', 'dupbuild=err']\n\nThe fourth parameter 'gn' probably needs to be 'gn.exe'. I tried building the GN manually\nHowever, in the Japanese version of the compiler has failed\nFAILED: tools/gn/command_gen.obj \nninja -t msvc -- cl.exe /nologo /showIncludes /FC @tools/gn/command_gen.obj.rsp /c E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src\\tools\\gn\\tools/gn/command_gen.cc /Fotools/gn/command_gen.obj\ne:\\work\\github\\eloston\\ungoogled-chromium\\build\\src\\tools\\gn\\tools\\gn\\command_gen.cc: error C2220: \u8b66\u544a\u3092\u30a8\u30e9\u30fc\u3068\u3057\u3066\u6271\u3044\u307e\u3057\u305f\u3002'object' \u30d5\u30a1\u30a4\u30eb\u306f\u751f\u6210\u3055\u308c\u307e\u305b\u3093\u3002\ne:\\work\\github\\eloston\\ungoogled-chromium\\build\\src\\tools\\gn\\tools\\gn\\command_gen.cc: warning C4819: \u30d5\u30a1\u30a4\u30eb\u306f\u3001\u73fe\u5728\u306e\u30b3\u30fc\u30c9 \u30da\u30fc\u30b8 (932) \u3067\u8868\u793a\u3067\u304d\u306a\u3044\u6587\u5b57\u3092\u542b\u3093\u3067\u3044\u307e\u3059\u3002\u30c7\u30fc\u30bf\u306e\u640d\u5931\u3092\u9632\u3050\u305f\u3081\u306b\u3001\u30d5\u30a1\u30a4\u30eb\u3092 Unicode \u5f62\u5f0f\u3067\u4fdd\u5b58\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\nerror C2220: \u8b66\u544a\u3092\u30a8\u30e9\u30fc\u3068\u3057\u3066\u6271\u3044\u307e\u3057\u305f\u3002'object' \u30d5\u30a1\u30a4\u30eb\u306f\u751f\u6210\u3055\u308c\u307e\u305b\u3093\u3002\n\nerror C2220: warning treated as error - no 'object' file generated\n\nwarning C4819: \u30d5\u30a1\u30a4\u30eb\u306f\u3001\u73fe\u5728\u306e\u30b3\u30fc\u30c9 \u30da\u30fc\u30b8 (932) \u3067\u8868\u793a\u3067\u304d\u306a\u3044\u6587\u5b57\u3092\u542b\u3093\u3067\u3044\u307e\u3059\u3002\u30c7\u30fc\u30bf\u306e\u640d\u5931\u3092\u9632\u3050\u305f\u3081\u306b\u3001\u30d5\u30a1\u30a4\u30eb\u3092 Unicode \u5f62\u5f0f\u3067\u4fdd\u5b58\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\nwarning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss \nAdding the /utf-8 parameter to cl.exe solves it\n--- a/tools/gn/build/build_win.ninja.template\n+++ b/tools/gn/build/build_win.ninja.template\n@@ -1,12 +1,12 @@\n rule cc\n-  command = ninja -t msvc -- $cc /nologo /showIncludes /FC @${out}.rsp /c ${in} /Fo${out}\n+  command = ninja -t msvc -- $cc /utf-8 /nologo /showIncludes /FC @${out}.rsp /c ${in} /Fo${out}\n   description = CC ${out}\n   rspfile = ${out}.rsp\n   rspfile_content = ${defines} ${includes} ${cflags} ${cflags_c}\n   deps = msvc\n\n rule cxx\n-  command = ninja -t msvc -- $cxx /nologo /showIncludes /FC @${out}.rsp /c ${in} /Fo${out}\n+  command = ninja -t msvc -- $cxx /utf-8 /nologo /showIncludes /FC @${out}.rsp /c ${in} /Fo${out}\n   description = CXX ${out}\n   rspfile = ${out}.rsp\n   rspfile_content = ${defines} ${includes} ${cflags} ${cflags_cc}. @Wyse- I tried to build d307bb0, but failed to download LLVM(HTTP Error 404: Not Found)\n\nSo, I'm downloading \"LLVM\" manually and building d307bb0\nHowever, on my side, \"can not open file\" error did not occur...\nPlease make sure chromium-69.0.3497.92.tar.xz is extracted correctly\nE:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src>call \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\" >nul\n\nE:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src>\"C:\\Python27\\python.EXE\" \"tools\\gn\\bootstrap\\bootstrap.py\" \"-o\" \"out\\Default\\gn.exe\"\nninja: Entering directory `E:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src\\out\\Release\\gn_build'\nninja: error: unknown target 'gn'\nTraceback (most recent call last):\n  File \"tools\\gn\\bootstrap\\bootstrap.py\", line 92, in <module>\n    sys.exit(main(sys.argv[1:]))\n  File \"tools\\gn\\bootstrap\\bootstrap.py\", line 87, in main\n    ['ninja', '-C', gn_build_dir, 'gn', '-w', 'dupbuild=err'])\n  File \"C:\\Python27\\lib\\subprocess.py\", line 190, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['ninja', '-C', 'E:\\\\work\\\\github\\\\Eloston\\\\ungoogled-chromium\\\\build\\\\src\\\\out\\\\Release\\\\gn_build', 'gn', '-w', 'dupbuild=err']' returned non-zero exit status 1\n\nE:\\work\\github\\Eloston\\ungoogled-chromium\\build\\src>exit\nTraceback (most recent call last):\n  File \"ungoogled_packaging\\build.py\", line 186, in <module>\n    main()\n  File \"ungoogled_packaging\\build.py\", line 175, in main\n    shutil.which('python'), 'tools\\\\gn\\\\bootstrap\\\\bootstrap.py', '-o', 'out\\\\Default\\\\gn.exe')\n  File \"ungoogled_packaging\\build.py\", line 65, in _run_build_process\n    **kwargs)\n  File \"C:\\Users\\TEST\\AppData\\Local\\Programs\\Python\\Python37\\lib\\subprocess.py\", line 468, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '('cmd.exe', '/k')' returned non-zero exit status 1.\n\nFull(Expiration 90days):\n https://paste.debian.net/plain/1042283. ",
    "shiioo": "It fails on my end too, using the \"master\" repo to get the latest fixes for Windows:\nhttps://paste.ee/p/0QlCw. ",
    "lukaszswitaj": "Sorry, my mistake.\nLooks everything is fine.. ",
    "steven-omaha": "Sorry, I don't have my test machine available right now. I'll be reporting back in about a week.\nAm 2. September 2018 01:56:13 MESZ schrieb Eloston notifications@github.com:\n\nIs there a\u00a0cache_index.list\u00a0in\u00a0debian/scripts/ungoogled-chromium/domsubcache.tar.gz?\n. According to tar -tvf debian/scripts/ungoogled-chromium/domsubcache.tar.gz | grep -i 'cache_index', no.. No, I don't. I'm currently building again from a fresh clone.. By the way: Did you ever think about automating your builds in your CI system?. Rebuilt using the initially mentioned commit. Could not reproduce the bug.. Thanks for actually taking the time to keep this project running! Maybe my build tree wasn't completely clean. I had some issues with the proper value of njobs. chromium requires ridiculous amounts of RAM for parallel building. That saturated my VM.. @DrDonkey There is also a precompiled package available for Arch / Manjaro. It lacks behinds the git repository most of the time. Try ungoogled-chromium-bin.\n\nhttps://aur.archlinux.org/packages/ungoogled-chromium-bin. You could also make a pull request yourself. I'm not a maintainer neither of this project, nor of the Arch packages. . If this is really the case, this issue can be closed. Is there a way to check this?. I think I will give this a try tomorrow. Thanks.. Trying the method from @xsmile, I can confirm that deleting cookies actually deletes all cookies on ungoogled-chromium-69. \n. ",
    "dakka2": "I don't know why this fails validation with your CI setup. It seems to apply cleanly for me.. ",
    "ipeacocks": "It's was because of this option https://i.imgur.com/KZp0lqb.png. I am also using 18.04 with proprietary nvidia drivers. This problem is happening in Chromium only or system-wide? Try next:\nnvidia-settings -a CurrentMetaMode=\"DPY-1: nvidia-auto-select @1920x1080 +0+0 {ViewPortIn=1920x1080, ViewPortOut=1920x1080+0+0, ForceCompositionPipeline = On}\" -a '[gpu:0]/GPUPowerMizerMode=1'\nChange resolution if needed.. ",
    "webbertakken": "besides the version string from chromium --version it is also displayed under about, saying (Official build).\n\n. ",
    "mintunitish": "I would like to tackle this one. Any tips about how to proceed?. ",
    "DrDonkey": "Ok then. As I already said I got some old ass amd processor(dual core tho), and 2GB ram.\nI guess I don't deserve ungoogled.. ",
    "kovetskiy": "@steven-omaha  can you please mention that package in README too? it would be really helpful.. @steven-omaha oh, ok, I thought you are a maintainer.. ",
    "pastmaster007": "when i build first time, remote archives(chromium, llvm, google toolbox) downloaded into download_cache folder. I got few errors, becauses of patches are not up-to-date. Then i modified a patch and try to build again. I got error saying download_cache directory already exists can not be created and build process exited. So i made command to ignore if the folder already exists by adding -p flag. Now, build process does not fail, if folder exists. So, no need to re-download archives again.. > > Are we using domainsubcache.tar.gz file anywhere after zipping?\n\nIf by \"zipping\", you mean the production of an archive of the build outputs, then no. domainsubcache.tar.gz exists to allow people to revert domain substitution. The main use case is to allow developers to update patches and resume building, since patches can include code with Google domains in them.\nI mean archive file for \"zipping\"..\n\nCan we create this zip file inside \"build/src/out\" folder?\nCurrently, dmg file creates in \"build/src/ungoogled_packaging\" folder, can we move it to \"build/src/out\" folder?\n\nCould you explain why?\nJust checking as this is an output file, so can we keep in out folder or is it okay to keep in ungoogled_packaging folder?\n\nCan we comment \"-Wno-ignored-pragma-optimize\" flag in \"build/config/compiler/BUILD.gn:1519\" for macOS?\nlooks like this flag mainly for Microsoft optimzation which means for WindowsOS..\n\nHere's the relevant comment for the associated bug report (in the GN file you linked): https://bugs.chromium.org/p/chromium/issues/detail?id=505314#c7\nThe report says that pragma optimize breaks Windows compilation. So, they ignore it by default and add exceptions for configurations like macOS so that the warning doesn't appear.\nI don't see any benefit of removing the flag.\n\nI see below warning 11462 times..\n\nwarning: unknown warning option '-Wno-ignored-pragma-optimize'; did you mean '-Wno-ignored-pragma-intrinsic'? [-Wunknown-warning-option]\n1 warning generated.\n. \nI don't understand what you are referring to. Do you mean the creation of domainsubcache.tar.gz, or the .dmg (which can be understood as an archive)?\nI was asking about \"domainsubcache.tar.gz\" file, i got answer in your previous comment.. \nthe reason for asking, when i recompile with 70 chrome, previous build's (chrome 69) \"domainsubcache.tar.gz\" files exists and new build exited with error. I deleted \"domainsubcache.tar.gz\" file from \"ungoogled_packaging\" folder and tried, then build works fine. \nIn general, how do you start rebuild? by deleting entire \"ungoogled_packaging\" folder and run python script?\nIt doesn't matter too much for this specific file, but I'd rather keep files introduced by ungoogled-chromium in one place. The compressed archive isn't part of the normal Chromium build process, but something generated by ungoogled-chromium tools.\nWe may need to update build readme file for macOS, it says DMG file might generate in build folder.. So, i was thinking DMG file should be in \"out\" folder instead of build folder, that's why i asked question :)\nThis might be because we're using the old LLVM 6.0.0 on macOS. What happens if LLVM 7.0.0 is used? FYI, LLVM is normally downloaded via downloads.ini in the macos config bundle.\nCurrently, i am using 6.0.0, i will try update to latest and verify..\nDo i need to update google toolbox version too? we are using from jul 24th 2017 version... libui.a static framework refers below two functions from safe browsing class..\nsafe_browsing::ChromePasswordProtectionService::OnUserAction\nsafe_browsing::ChromePasswordProtectionService::ShouldShowChangePasswordSettingUI\n\nAs we remove safe browsing reference using fix-gn-safe_browsing.patch file, which causes linking error..\nSo i removed corresponding safe browse reference from change password handler UI class..\ni guess we could replace \"ShouldShowChangePasswordSettingUI\" with \"true\" boolean value..\nbelow is the error:\n\n[19859/20025] LINK ./v8_context_snapshot_generator\nwarning: no debug symbols in executable (-arch x86_64)\n[19871/20025] SOLINK 'obj/chrome/chrom...ts/Resources/DWARF/Chromium Framework'\nFAILED: obj/chrome/chrome_framework_shared_library/Chromium Framework obj/chrome/chrome_framework_shared_library/Chromium Framework.TOC Chromium Framework.dSYM Chromium Framework.dSYM/Contents/Info.plist Chromium Framework.dSYM/Contents/Resources/DWARF/Chromium Framework \nif [ ! -e \"obj/chrome/chrome_framework_shared_library/Chromium Framework\" -o ! -e \"obj/chrome/chrome_framework_shared_library/Chromium Framework.TOC\" ] || otool -l \"obj/chrome/chrome_framework_shared_library/Chromium Framework\" | grep -q LC_REEXPORT_DYLIB ; then TOOL_VERSION=1539717229 ../../build/toolchain/mac/linker_driver.py ../../third_party/llvm-build/Release+Asserts/bin/clang++ -shared  -Wcrl,dsym,. -Wl,-install_name,@executable_path/../Versions/70.0.3538.67/Chromium\\ Framework.framework/Chromium\\ Framework -compatibility_version 3538.0.67 -current_version 3538.0.67 -Wl,-order_file,../../chrome/app/framework.order -stdlib=libc++ -arch x86_64 -segprot PROTECTED_MEMORY rw r -isysroot ../../../../../../../../../Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk -mmacosx-version-min=10.9.0 -Wl,-ObjC -Wcrl,strip,-x,-S -L/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/lib -o \"obj/chrome/chrome_framework_shared_library/Chromium Framework\" -Wl,-filelist,\"obj/chrome/chrome_framework_shared_library/Chromium Framework.rsp\" -framework Cocoa -framework Foundation -framework IOKit -framework Security -framework SystemConfiguration -framework Accelerate -framework AudioUnit -framework DiskArbitration -framework ImageCaptureCore -framework OpenGL -framework QuartzCore -framework SecurityInterface -lcups -framework ApplicationServices -framework AppKit -lbsm -framework CoreFoundation -framework CFNetwork -framework CoreServices -lresolv -framework IOBluetooth -framework Carbon -framework CoreVideo -framework CoreGraphics -framework CoreText -framework IOSurface -framework AudioToolbox -framework CoreAudio -framework Quartz -framework AVFoundation -framework CoreMedia -framework VideoToolbox -lsandbox -framework CoreMIDI -framework OpenDirectory -framework AddressBook -framework LocalAuthentication -framework ForceFeedback -framework GameController -framework CoreWLAN  && { otool -l \"obj/chrome/chrome_framework_shared_library/Chromium Framework\" | grep LC_ID_DYLIB -A 5; nm -gP \"obj/chrome/chrome_framework_shared_library/Chromium Framework\" | cut -f1-2 -d' ' | grep -v U$$; true; } > \"obj/chrome/chrome_framework_shared_library/Chromium Framework.TOC\"; else TOOL_VERSION=1539717229 ../../build/toolchain/mac/linker_driver.py ../../third_party/llvm-build/Release+Asserts/bin/clang++ -shared  -Wcrl,dsym,. -Wl,-install_name,@executable_path/../Versions/70.0.3538.67/Chromium\\ Framework.framework/Chromium\\ Framework -compatibility_version 3538.0.67 -current_version 3538.0.67 -Wl,-order_file,../../chrome/app/framework.order -stdlib=libc++ -arch x86_64 -segprot PROTECTED_MEMORY rw r -isysroot ../../../../../../../../../Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk -mmacosx-version-min=10.9.0 -Wl,-ObjC -Wcrl,strip,-x,-S -L/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/lib -o \"obj/chrome/chrome_framework_shared_library/Chromium Framework\" -Wl,-filelist,\"obj/chrome/chrome_framework_shared_library/Chromium Framework.rsp\" -framework Cocoa -framework Foundation -framework IOKit -framework Security -framework SystemConfiguration -framework Accelerate -framework AudioUnit -framework DiskArbitration -framework ImageCaptureCore -framework OpenGL -framework QuartzCore -framework SecurityInterface -lcups -framework ApplicationServices -framework AppKit -lbsm -framework CoreFoundation -framework CFNetwork -framework CoreServices -lresolv -framework IOBluetooth -framework Carbon -framework CoreVideo -framework CoreGraphics -framework CoreText -framework IOSurface -framework AudioToolbox -framework CoreAudio -framework Quartz -framework AVFoundation -framework CoreMedia -framework VideoToolbox -lsandbox -framework CoreMIDI -framework OpenDirectory -framework AddressBook -framework LocalAuthentication -framework ForceFeedback -framework GameController -framework CoreWLAN  && { otool -l \"obj/chrome/chrome_framework_shared_library/Chromium Framework\" | grep LC_ID_DYLIB -A 5; nm -gP \"obj/chrome/chrome_framework_shared_library/Chromium Framework\" | cut -f1-2 -d' ' | grep -v U$$; true; } > \"obj/chrome/chrome_framework_shared_library/Chromium Framework.tmp\" && if ! cmp -s \"obj/chrome/chrome_framework_shared_library/Chromium Framework.tmp\" \"obj/chrome/chrome_framework_shared_library/Chromium Framework.TOC\"; then mv \"obj/chrome/chrome_framework_shared_library/Chromium Framework.tmp\" \"obj/chrome/chrome_framework_shared_library/Chromium Framework.TOC\" ; fi; fi\nUndefined symbols for architecture x86_64:\n  \"safe_browsing::ChromePasswordProtectionService::OnUserAction(content::WebContents, safe_browsing::LoginReputationClientRequest_PasswordReuseEvent_ReusedPasswordType, safe_browsing::WarningUIType, safe_browsing::WarningAction)\", referenced from:\n      settings::ChangePasswordHandler::HandleChangePassword(base::ListValue const) in libui.a(ui_jumbo_7.o)\n  \"safe_browsing::ChromePasswordProtectionService::ShouldShowChangePasswordSettingUI(Profile*)\", referenced from:\n      settings::ChangePasswordHandler::UpdateChangePasswordCardVisibility() in libui.a(ui_jumbo_7.o)\nld: symbol(s) not found for architecture x86_64\nclang-6.0: error: linker command failed with exit code 1 (use -v to see invocation)\nTraceback (most recent call last):\n  File \"../../build/toolchain/mac/linker_driver.py\", line 229, in \n    Main(sys.argv)\n  File \"../../build/toolchain/mac/linker_driver.py\", line 79, in Main\n    subprocess.check_call(compiler_driver_args)\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py\", line 190, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['../../third_party/llvm-build/Release+Asserts/bin/clang++', '-shared', '-Wl,-install_name,@executable_path/../Versions/70.0.3538.67/Chromium Framework.framework/Chromium Framework', '-compatibility_version', '3538.0.67', '-current_version', '3538.0.67', '-Wl,-order_file,../../chrome/app/framework.order', '-stdlib=libc++', '-arch', 'x86_64', '-segprot', 'PROTECTED_MEMORY', 'rw', 'r', '-isysroot', '../../../../../../../../../Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk', '-mmacosx-version-min=10.9.0', '-Wl,-ObjC', '-L/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/lib', '-o', 'obj/chrome/chrome_framework_shared_library/Chromium Framework', '-Wl,-filelist,obj/chrome/chrome_framework_shared_library/Chromium Framework.rsp', '-framework', 'Cocoa', '-framework', 'Foundation', '-framework', 'IOKit', '-framework', 'Security', '-framework', 'SystemConfiguration', '-framework', 'Accelerate', '-framework', 'AudioUnit', '-framework', 'DiskArbitration', '-framework', 'ImageCaptureCore', '-framework', 'OpenGL', '-framework', 'QuartzCore', '-framework', 'SecurityInterface', '-lcups', '-framework', 'ApplicationServices', '-framework', 'AppKit', '-lbsm', '-framework', 'CoreFoundation', '-framework', 'CFNetwork', '-framework', 'CoreServices', '-lresolv', '-framework', 'IOBluetooth', '-framework', 'Carbon', '-framework', 'CoreVideo', '-framework', 'CoreGraphics', '-framework', 'CoreText', '-framework', 'IOSurface', '-framework', 'AudioToolbox', '-framework', 'CoreAudio', '-framework', 'Quartz', '-framework', 'AVFoundation', '-framework', 'CoreMedia', '-framework', 'VideoToolbox', '-lsandbox', '-framework', 'CoreMIDI', '-framework', 'OpenDirectory', '-framework', 'AddressBook', '-framework', 'LocalAuthentication', '-framework', 'ForceFeedback', '-framework', 'GameController', '-framework', 'CoreWLAN']' returned non-zero exit status 1\nninja: build stopped: subcommand failed.\n\n. here chromium looking at account sync password and deciding whether to prompt for password change or not based on safe browsing settings.. \nIf we replace with true, when safe browsing warning enabled, chromium always asks for password change.. may be we need to keep \"false\" by default.. so it will not prompt for password change..\nrelated files:\nchrome/browser/safe_browsing/chrome_password_protection_service_browsertest.cc:327\nchrome/browser/ui/webui/settings/change_password_handler.cc:63\nchrome/browser/resources/settings/basic_page/basic_page.js:127\nchrome/browser/resources/settings/change_password_page/change_password_page.html\nchrome/browser/resources/settings/basic_page/basic_page.html:134\n. one more thing is as we commented onUserAction function contents using patch file, handling password change is no more available. so, it does not matter what value returns from \"ShouldShowChangePasswordSetting\"... ",
    "FabioNevesRezende": "debian_minimal and \"Building locally\". I'll try now \"Building via source package\" maybe it works. Also \"building via source package\" didn't work:\n\ndpkg-source: info: building ungoogled-chromium-browser in ungoogled-chromium-browser_69.0.3497.100-1~portable.dsc\ndpkg-genbuildinfo --build=source\ndpkg-genchanges -sa --build=source >../ungoogled-chromium->browser_69.0.3497.100-1~portable_source.changes\ndpkg-genchanges: info: including full source code in upload\n dpkg-source --after-build src\ndpkg-buildpackage: info: full upload (original source is included)\nNow running lintian...\nCould not find a profile matching \"{VENDOR}/main\" for vendor devuan at /usr/share/lintian/commands/lintian line 1561.\nFinished running lintian.\nNow signing changes and any dsc files...\nsignfile dsc ungoogled-chromium-browser_69.0.3497.100-1~portable.dsc ungoogled-chromium Authors maintainer@null\ngpg: skipped \"ungoogled-chromium Authors maintainer@null\": No secret key\ngpg: /tmp/debsign.X3HmiE6M/ungoogled-chromium-browser_69.0.3497.100-1~portable.dsc: clear-sign failed: No secret key\ndebsign: gpg error occurred!  Aborting....\ndebuild: fatal error at line 1045:\nrunning debsign failed\n. solved. you mean, this https://github.com/Eloston/ungoogled-chromium/blob/master/patches/ungoogled-chromium/linux/fix-libva1-compatibility.patch?\n\nhow to apply these patches?. So, I've changed to debian_stretch and applied the patch\n\n./get_package.py debian_stretch build/src/debian/\ncd build/src\ngit apply ../../patches/ungoogled-chromium/linux/fix-libva1-compatibility.patch\n\nI also had to install a new dependency\n\nsudo apt-get install gsettings-desktop-schemas-dev\n\nBut now fails with\n\nERROR at //BUILD.gn:668:7: Can't load input file.\n     \"//third_party/libjpeg_turbo:simd\",\n     ^---------------------------------\nUnable to load:\n/home/fabio/src/ungoogled-chromium/build/src/third_party/libjpeg_turbo/BUILD.gn\nI also checked in the secondary tree for:\n /home/fabio/src/ungoogled-chromium/build/src/build/secondary/third_party/libjpeg_turbo/BUILD.gn\ndebian/rules:88: recipe for target 'override_dh_auto_build-arch' failed\nmake[1]:  [override_dh_auto_build-arch] Error 1\nmake[1]: Leaving directory '/home/fabio/src/ungoogled-chromium/build/src'\ndebian/rules:68: recipe for target 'binary' failed\nmake:  [binary] Error 2\ndpkg-buildpackage: error: fakeroot debian/rules binary gave error exit status 2\n\n. So I've just deleted everything and restarted, this time using debian_stretch and it worked successfully. ",
    "oktvn": "\nFor Google it was removed\n\nToo bad. I'd say Google's autocomplete is unrivaled, and it could've gone well with 3rd party search engines (like DuckDuckGo). Any chance for having a config switch flag for that?. ",
    "grepwood": "\nBut I do this to reduce wear on my storage devices, not for performance. I don't believe there is much of a performance improvement with RAM disks compared to non-volatile storage devices, but I have no data to back this up.\n\nI beg to differ. Using LibreOffice as an example I testify that putting /var/tmp (default $TMPDIR for Portage) into a 23GB RAM disk allows me to emerge it in just 40 minutes compared to standard 440 minutes. This amount of space I found is optimal for that package - it fits the source code, the objects, it satisfied the ebuild's storage requirements, and on a machine with 32GB RAM it's enough to let 16 compilation threads go. All at once. But this is using very light libraries, contrast to Chromium where 1 compilation thread can take a lot more memory.\n\nI don't know the Chromium code nearly well enough to tell you the breakdown of memory usage. You'd need people with the equivalent knowledge of core Chromium developers (for at least Blink and V8) to get a satisfactory answer. On a tangential note, DevTools has some profiling tools that might give you some insights on the HTML/CSS/JavaScript side.\nAll of your concerns fall under secondary objectives of this project. I am open to anyone contributing features to resolve these problems.\n\nIf time allows, I'll try. Thank you.\n. >I forgot to mention that I have a SATA III SSD, so I'm not sure if RAM disks yield a significant improvement. If you're using a HDD, then your numbers make more sense.\nI'm using mdadm RAID10, far2, consisting of 4 HDDs, rough performance is somewhere at 200-320MB/s.. Random. It may be cached though, I'm using LVM cache on an encrypted M2 SSD.. ",
    "auvipy": "I believe so. even AGPL v3. ",
    "rudolfolah": "Thanks @Eloston for responding with a pointer to the discussion and a nice explanation as to why the license is BSD rather than GPL. It's nice to help free/open source software developer neighbours but at the same time...GPL sends a stronger message, at least to me, that the project is motivated by free software ideals and practical ideals such as breaking vendor lock-in.\nFor my own project I would lean toward GPLv3. In this case, it's very cool to see a good dialogue on which license to use and the choice of BSD does make sense.. ",
    "hardhub": "@antonin-lebrard Thank you! But it is still not clear how to update automatically.. @TCB13 \nI simply made all as specified in instructions.\nMaybe you used different version of chromium source.\nTo be honest I do not know exactly.\n. @TCB13 \nNot exactly so...\n\n\n7z was already installed. Just checked version - 16.04 (but nor sure it is so important).\n\n* python-3.6.5-amd64.exe (don't add to path; enable py launcher)\n\nboth are in PATH but 27 before 37 (not 3.6.5) and py launcher is also in PATH\n\n\n\nYes, I did\n\n\nI have Visual Studio 2017 Enterprise latest update (I am working on some .Net projects).\nSo I just installed all C++ features including MFC library.\nI have list of all installed packages, but it is 36 KB (I cannot simply paste it here).\n\n\nI have installed lastest Windows 10 SDK 1809:\n17763.132.181022-1834.rs5_release_svc_prod1_WindowsSDK\n\n\nDebugging Tools was also installed with this SDK.\n\nNo.. I did this:\nmkdir build\\src\npy get_package.py windows build\\src\\ungoogled_packaging\ncd build\\src\npy ungoogled_packaging\\build.py\npy ungoogled_packaging\\package.py\n\nI think get_package.py does that.\n\n\nYes\nC:\\>set | findstr DEPOT\nDEPOT_TOOLS_WIN_TOOLCHAIN=0\n\n\nYes as described above.\n. > \n\n@hardhub hardhub can you try again with latest version?\n\n\n\nmaster:\nsubprocess.CalledProcessError: Command '['C:\\\\ungoogled-chromium\\\\build\\\\src\\\\third_party\\\\git\\\\usr\\\\bin\\\\patch.exe', '-p1', '--ignore-whitespace', '-i', 'C:\\\\ungoogled-chromium\\\\build\\\\src\\\\ungoogled_packaging\\\\patches\\\n\\ungoogled-chromium\\\\windows\\\\windows-disable-reorder-fix-linking.patch', '-d', 'C:\\\\ungoogled-chromium\\\\build\\\\src', '--no-backup-if-mismatch', '--forward']' returned non-zero exit status 1.\n72.0.3626.122-1\n(Stripping trailing CRs from patch; use --binary to disable.)\npatching file chrome/BUILD.gn\nHunk #2 FAILED at 83.\nHunk #3 succeeded at 309 (offset -3 lines).\n. Tried on master:\n```\n(Stripping trailing CRs from patch; use --binary to disable.)\npatching file chrome/BUILD.gn\nHunk #2 FAILED at 83.\nHunk #3 succeeded at 309 (offset -3 lines).\n1 out of 3 hunks FAILED -- saving rejects to file chrome/BUILD.gn.rej\n(Stripping trailing CRs from patch; use --binary to disable.)\npatching file tools/perf/chrome_telemetry_build/BUILD.gn\nHunk #1 succeeded at 36 (offset 4 lines).\n(Stripping trailing CRs from patch; use --binary to disable.)\npatching file chrome/test/chromedriver/BUILD.gn\nHunk #1 succeeded at 364 (offset 7 lines).\nTraceback (most recent call last):\n  File \"ungoogled_packaging\\build.py\", line 187, in \n    main()\n  File \"ungoogled_packaging\\build.py\", line 164, in main\n    buildkit.patches.patch_paths_by_bundle(bundle), source_tree, patch_bin_path=None)\n```. ",
    "kabo": "I did install the base requirements, and I can't see anything about installing deps in the build instructions.\nBuilding via source package\n```sh\nRun from inside the clone of the repository\nmkdir -p build/src\n./get_package.py PACKAGE_TYPE_HERE build/src/debian\ncd build/src\nIf necessary, change the dependencies in debian/control to accomodate your environment.\nIf necessary, modify AR, NM, CC, and CXX variables in debian/rules\ndebian/rules get-orig-source\ndebuild -S -sa\n```\nWould be nice to have something like dpkg-checkbuilddeps | xargs sudo apt -y install in the instructions. That command probably doesn't work, but something to that effect.. Ah, I see now there's a note about it under Building locally.\nBut I downloaded the tarball, I didn't clone the repo, so I was following the Building via source package instructions.. Open source is important to me, so I use Debian Buster, and don't enable contrib or non-free, I just stick to main.. Got a different error at least.\nninja -j4 -C out/Default chrome chrome_sandbox content_shell chromedriver\nninja: Entering directory `out/Default'\n[3/19007] CC obj/base/third_party/dynamic_annotations/dynamic_annotations/dynamic_annotations.o\nFAILED: obj/base/third_party/dynamic_annotations/dynamic_annotations/dynamic_annotations.o\nclang-7 -MMD -MF obj/base/third_party/dynamic_annotations/dynamic_annotations/dynamic_annotations.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUSE_AURA=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DOFFICIAL_BUILD -DCHROMIUM_BUILD -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNO_UNWIND_TABLES -D_GNU_SOURCE -DCR_CLANG_REVISION=\\\"340925-1\\\" -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../.. -Igen -fprofile-sample-use=../../chrome/android/profiles/afdo.prof -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -fno-unwind-tables -fno-asynchronous-unwind-tables -fPIC -pthread -fcolor-diagnostics -fmerge-all-constants -Xclang -mllvm -Xclang -instcombine-lower-dbg-declare=0 -no-canonical-prefixes -flto=thin -fwhole-program-vtables -m64 -march=x86-64 -Wall -Wextra -Wimplicit-fallthrough -Wthread-safety -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-user-defined-warnings -Wno-unused-lambda-capture -Wno-null-pointer-arithmetic -Wno-enum-compare-switch -Wno-ignored-pragma-optimize -O2 -fno-ident -fdata-sections -ffunction-sections -fno-omit-frame-pointer -g0 -fsanitize=cfi-vcall -fsanitize-blacklist=../../tools/cfi/blacklist.txt -fsanitize=cfi-icall -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -std=c11 -Wdate-time -D_FORTIFY_SOURCE=2 -g -O2 -fdebug-prefix-map=/home/kabo/Downloads/ungoogled-chromium-70.0.3538.77-1/build/src=. -fstack-protector-strong -Wformat -Werror=format-security -c ../../base/third_party/dynamic_annotations/dynamic_annotations.c -o obj/base/third_party/dynamic_annotations/dynamic_annotations/dynamic_annotations.o\nclang-7: error: no such file or directory: '/usr/lib/clang/7.0.0/share/cfi_blacklist.txt'\n[5/19007] CXX obj/base/base_static/base_switches.o\nFAILED: obj/base/base_static/base_switches.o\nclang++-7 -MMD -MF obj/base/base_static/base_switches.o.d -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUSE_AURA=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DOFFICIAL_BUILD -DCHROMIUM_BUILD -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNO_UNWIND_TABLES -D_GNU_SOURCE -DCR_CLANG_REVISION=\\\"340925-1\\\" -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -I../.. -Igen -fprofile-sample-use=../../chrome/android/profiles/afdo.prof -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -fno-unwind-tables -fno-asynchronous-unwind-tables -fPIC -pthread -fcolor-diagnostics -fmerge-all-constants -Xclang -mllvm -Xclang -instcombine-lower-dbg-declare=0 -no-canonical-prefixes -flto=thin -fwhole-program-vtables -m64 -march=x86-64 -Wall -Wextra -Wimplicit-fallthrough -Wthread-safety -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-user-defined-warnings -Wno-unused-lambda-capture -Wno-null-pointer-arithmetic -Wno-enum-compare-switch -Wno-ignored-pragma-optimize -fno-omit-frame-pointer -g0 -fsanitize=cfi-vcall -fsanitize-blacklist=../../tools/cfi/blacklist.txt -fsanitize=cfi-icall -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -O2 -fno-ident -fdata-sections -ffunction-sections -std=c++14 -fno-exceptions -fno-rtti -fvisibility-inlines-hidden -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-pedantic -Wno-unused-function -Wno-unused-variable -Wno-deprecated-declarations  -Wno-return-type  -Wno-pedantic -Wno-unused-function -Wno-unused-variable -Wno-deprecated-declarations  -Wno-return-type  -c ../../base/base_switches.cc -o obj/base/base_static/base_switches.o\nclang++-7: error: no such file or directory: '/usr/lib/clang/7.0.0/share/cfi_blacklist.txt'\n[6/19007] ACTION //base:base__jumbo_merge(//build/toolchain/linux/unbundle:default)\nninja: build stopped: subcommand failed.\nmake[1]: *** [debian/rules:89: override_dh_auto_build-arch] Error 1\nmake[1]: Leaving directory '/home/kabo/Downloads/ungoogled-chromium-70.0.3538.77-1/build/src'\nmake: *** [debian/rules:68: binary] Error 2\ndpkg-buildpackage: error: debian/rules binary subprocess returned exit status 2. That file seems to be located here for me\n/usr/lib/llvm-7/lib/clang/7.0.0/share/cfi_blacklist.txt. yup, setting up symlink and editing debian/rules to use llvm and clang 7 seems to work better.\nletting it compile over night, fingers crossed :). Next error\nIn file included from gen/content/test/test_support_jumbo_1.cc:19:\nIn file included from ./../../content/public/test/browser_test_base.cc:37:\n../../content/public/test/browser_test_utils.h:608:24: error: unknown type name 'nullptr_t'; did you mean 'std::nullptr_t'?\ninline bool operator==(nullptr_t a, const EvalJsResult& b) {\n                       ^~~~~~~~~\n                       std::nullptr_t\n/usr/bin/../lib/gcc/x86_64-linux-gnu/8/../../../../include/x86_64-linux-gnu/c++/8/bits/c++config.h:242:29: note: 'std::nullptr_t' declared here\n  typedef decltype(nullptr)     nullptr_t;\n                                ^\n1 error generated.\nninja: build stopped: subcommand failed.\nmake[1]: *** [debian/rules:89: override_dh_auto_build-arch] Error 1\nmake[1]: Leaving directory '/home/kabo/Downloads/ungoogled-chromium-70.0.3538.77-1/build/src'\nmake: *** [debian/rules:68: binary] Error 2\ndpkg-buildpackage: error: debian/rules binary subprocess returned exit status 2. build/src/build_overrides/build.gni, line 30 has cfi_blacklist_path commented out, presumably one can set a custom path there?. Also, when I try building again I get this error.\n$ dpkg-buildpackage -b -uc\ndpkg-buildpackage: info: source package ungoogled-chromium-browser\ndpkg-buildpackage: info: source version 70.0.3538.77-1~buster\ndpkg-buildpackage: info: source distribution buster\ndpkg-buildpackage: info: source changed by ungoogled-chromium Authors <maintainer@null>\ndpkg-buildpackage: info: host architecture amd64\n dpkg-source --before-build .\n debian/rules clean\ndh clean\n   debian/rules override_dh_auto_clean\nmake[1]: Entering directory '/home/kabo/Downloads/ungoogled-chromium-70.0.3538.77-1/build/src'\nrm -rf out\nfind . -name \\*.pyc -execdir rm -f {} \\;\ndh_auto_clean\nmake[1]: Leaving directory '/home/kabo/Downloads/ungoogled-chromium-70.0.3538.77-1/build/src'\n   dh_clean\n        rm -f debian/debhelper-build-stamp\n        cp -an --reflink=auto debian/.debhelper/bucket/files/2e278c39be4815452f1c227f7b1e818267e3c3f25dc95e87868dae2bbba6dae2 debian/.debhelper/bucket/files/2e278c39be4815452f1c227f7b1e818267e3c3f25dc95e87868dae2bbba6dae2.tmp\n        mv debian/.debhelper/bucket/files/2e278c39be4815452f1c227f7b1e818267e3c3f25dc95e87868dae2bbba6dae2.tmp third_party/sqlite/src/config.guess\n        cp -an --reflink=auto debian/.debhelper/bucket/files/2e278c39be4815452f1c227f7b1e818267e3c3f25dc95e87868dae2bbba6dae2 debian/.debhelper/bucket/files/2e278c39be4815452f1c227f7b1e818267e3c3f25dc95e87868dae2bbba6dae2.tmp\n        mv debian/.debhelper/bucket/files/2e278c39be4815452f1c227f7b1e818267e3c3f25dc95e87868dae2bbba6dae2.tmp third_party/sqlite/sqlite-src-3240000/config.guess\n        cp -an --reflink=auto debian/.debhelper/bucket/files/9be3de218833c076786b919dc34aab691611f4cd73316e7705f2673e2c41921b debian/.debhelper/bucket/files/9be3de218833c076786b919dc34aab691611f4cd73316e7705f2673e2c41921b.tmp\n        mv debian/.debhelper/bucket/files/9be3de218833c076786b919dc34aab691611f4cd73316e7705f2673e2c41921b.tmp third_party/yasm/source/patched-yasm/config/config.guess\ndh_clean: mv debian/.debhelper/bucket/files/9be3de218833c076786b919dc34aab691611f4cd73316e7705f2673e2c41921b.tmp third_party/yasm/source/patched-yasm/config/config.guess: No such file or directory\nmake: *** [debian/rules:68: clean] Error 2\ndpkg-buildpackage: error: debian/rules clean subprocess returned exit status 2. Changing nullptr_t to std::nullptr_t worked. Compiled, installs, and runs fine. @Eloston I symlinked cfi_blacklist.txt instead of changing the builb_overrides, so can't confirm that.\nWith llvm7, cfi_blacklist.txt symlinked and the std::nullptr_t patch I got it to build.. ",
    "nadavhury": "It's a property which is exposed when using chrome-driver\\selenium for testing\\scraping.\nadded by google since version 68 I think.\n. ",
    "pellaeon": "Hi @mehrdadn , I'm trying to get this working, have you figured out a way to get this working? My patch according to your hints doesn't work. (I copied the entire content of profile folder from Chrome and the patched chromium deleted the copied extensions upon startup). Cool! Just built it and it works! Thanks!. ",
    "maxbla": "\nThis version doesn't exist. Do you mean 69.0.3497.100-2?\n\nThe version number listed on the AUR here is 69.0.3497.100-3\nI'll run chromium --version when I am back at my home computer to see what the real version number is.\n\nI believe setting is_debug=true GN flag should be sufficient (it's false by default in the PKGBUILD)\n\nWhere do I put is_dubug=true in the PKGBUILD? It appears as if gn is a google-specific build tool, and I don't know how to use it.\n. Sorry for the confusion.\nI initially installed ungoogled-chromium 69.0.3497.100-2, encountered the runtime error, then installed ungoogled-chromium-bin 69.0.3497.100-3 in the hopes that my toolchain was the issue. I had the same error message with the *-bin distribution as the source ungoogled-chromium package on the AUR.\nI am now looking through ungoogled-chromium's PKGBUILD from a computer where ungoogled-chromium is not installed and I don't know where to add is_dubug=true. Hm... can you give me a line number? My pkgbuild looks like this.\n```\nMaintainer: Seppia \nContributors: Eloston\nDerived from official Chromium and Inox PKGBUILDS and ungoogled-chromium buildkit\npkgname=ungoogled-chromium\npkgver=69.0.3497.100\npkgrel=2\n_launcher_ver=6\npkgdesc=\"Modifications to Google Chromium for removing Google integration and enhancing privacy, control, and transparency\"\narch=('x86_64')\nurl=\"https://github.com/Eloston/ungoogled-chromium\"\nlicense=('BSD')\ndepends=('gtk3' 'nss' 'alsa-lib' 'xdg-utils' 'libxss' 'libcups' 'libgcrypt'\n         'ttf-font' 'systemd' 'dbus' 'libpulse' 'pciutils' 'json-glib'\n         'desktop-file-utils' 'hicolor-icon-theme')\nmakedepends=('python' 'python2' 'gperf' 'yasm' 'mesa' 'ninja' 'git'\n             'clang' 'lld' 'gn' 'llvm' 'libva' 'quilt')\noptdepends=('pepper-flash: support for Flash content'\n            'kdialog: needed for file dialogs in KDE'\n            'gnome-keyring: for storing passwords in GNOME keyring'\n            'kwallet: for storing passwords in KWallet'\n            'libva-intel-driver: for hardware video acceleration with Intel GPUs'\n            'libva-mesa-driver: for hardware video acceleration with AMD/ATI GPUs'\n            'libva-vdpau-driver: for hardware video acceleration with NVIDIA GPUs')\nprovides=('chromium')\nconflicts=('chromium')\nsource=(https://commondatastorage.googleapis.com/chromium-browser-official/chromium-$pkgver.tar.xz\n        chromium-launcher-$_launcher_ver.tar.gz::https://github.com/foutrelis/chromium-launcher/archive/v$_launcher_ver.tar.gz\n        'https://github.com/Eloston/ungoogled-chromium/archive/69.0.3497.100-2.tar.gz')\nsha256sums=('e3391560e73e25fb4afc3f2dd5616607e2dbfc58aa88251a2c5d6b7096fe9e35'\n            '04917e3cd4307d8e31bfb0027a5dce6d086edb10ff8a716024fbb8bb0c7dccf1'\n            '5aae8b05b8d366afb929627831e4d156a6cad917238c94a2a725b04c6ff59821')\nPossible replacements are listed in build/linux/unbundle/replace_gn_files.py\nKeys are the names in the above script; values are the dependencies in Arch\ndeclare -gA _system_libs=(\n  [ffmpeg]=ffmpeg\n  [flac]=flac\n  [fontconfig]=fontconfig\n  [freetype]=freetype2\n  [harfbuzz-ng]=harfbuzz\n  [icu]=icu\n  [libdrm]=\n  [libevent]=libevent\n  [libjpeg]=libjpeg\n  #[libpng]=libpng            # https://crbug.com/752403#c10\n  [libvpx]=libvpx\n  [libwebp]=libwebp\n  [libxml]=libxml2\n  [libxslt]=libxslt\n  [opus]=opus\n  [re2]=re2\n  [snappy]=snappy\n  [yasm]=\n  [zlib]=minizip\n)\n_unwanted_bundled_libs=(\n  ${!_system_libs[@]}\n  ${_system_libs[libjpeg]+libjpeg_turbo}\n)\ndepends+=(${_system_libs[@]})\nprepare() {\n  local _buildkit_cli=\"$srcdir/$pkgname-$pkgver-$pkgrel/run_buildkit_cli.py\"\n  local _config_bundle=\"$srcdir/$pkgname-$pkgver-$pkgrel/config_bundles/archlinux\"\ncd \"$srcdir/chromium-$pkgver\"\nmsg2 'Pruning binaries'\n  python \"$_buildkit_cli\" prune -b \"$_config_bundle\" ./\n  msg2 'Applying patches'\n  python \"$_buildkit_cli\" patches apply -b \"$_config_bundle\" ./\n  msg2 'Applying domain substitution'\n  python \"$_buildkit_cli\" domains apply -b \"$_config_bundle\" -c domainsubcache.tar.gz ./\n# Force script incompatible with Python 3 to use /usr/bin/python2\n  sed -i '1s|python$|&2|' third_party/dom_distiller_js/protoc_plugins/*.py\n# Remove bundled libraries for which we will use the system copies; this\n  # should do what the remove_bundled_libraries.py script does, with the\n  # added benefit of not having to list all the remaining libraries\n  local _lib\n  for _lib in ${_unwanted_bundled_libs[@]}; do\n    find -type f -path \"third_party/$_lib/\" \\\n      ! -path \"third_party/$_lib/chromium/\" \\\n      ! -path \"third_party/$_lib/google/\" \\\n      ! -path './base/third_party/icu/' \\\n      ! -path './third_party/crashpad/crashpad/third_party/zlib/zlib_crashpad.h' \\\n      ! -path './third_party/pdfium/third_party/freetype/include/pstables.h' \\\n      ! -path './third_party/yasm/run_yasm.py' \\\n      ! -regex '..(gn\\|gni\\|isolate)' \\\n      -delete\n  done\npython2 build/linux/unbundle/replace_gn_files.py \\\n    --system-libraries \"${!_system_libs[@]}\"\n}\nbuild() {\n  make -C chromium-launcher-$_launcher_ver\ncd \"$srcdir/chromium-$pkgver\"\nif check_buildoption ccache y; then\n    # Avoid falling back to preprocessor mode when sources contain time macros\n    export CCACHE_SLOPPINESS=time_macros\n  fi\nexport CC=clang\n  export CXX=clang++\n  export AR=llvm-ar\n  export NM=llvm-nm\nmkdir -p out/Default\nlocal _buildkit_cli=\"$srcdir/$pkgname-$pkgver-$pkgrel/run_buildkit_cli.py\"\n  local _config_bundle=\"$srcdir/$pkgname-$pkgver-$pkgrel/config_bundles/archlinux\"\npython \"$_buildkit_cli\" gnargs print -b \"$_config_bundle\" \\\n    > \"$srcdir/chromium-$pkgver/out/Default/args.gn\"\n# Facilitate deterministic builds (taken from build/config/compiler/BUILD.gn)\n  CFLAGS+='   -Wno-builtin-macro-redefined'\n  CXXFLAGS+=' -Wno-builtin-macro-redefined'\n  CPPFLAGS+=' -D__DATE__=  -D__TIME__=  -D__TIMESTAMP__='\nmsg2 'Configuring Chromium'\n  gn gen out/Default --script-executable=/usr/bin/python2 --fail-on-unused-args\n  msg2 'Building Chromium'\n  ninja -C out/Default chrome chrome_sandbox chromedriver\n}\npackage() {\n  cd chromium-launcher-$_launcher_ver\n  make PREFIX=/usr DESTDIR=\"$pkgdir\" install\n  install -Dm644 LICENSE \\\n    \"$pkgdir/usr/share/licenses/chromium/LICENSE.launcher\"\ncd \"$srcdir/chromium-$pkgver\"\ninstall -D out/Default/chrome \"$pkgdir/usr/lib/chromium/chromium\"\n  install -Dm4755 out/Default/chrome_sandbox \"$pkgdir/usr/lib/chromium/chrome-sandbox\"\n  ln -s /usr/lib/$pkgname/chromedriver \"$pkgdir/usr/bin/chromedriver\"\ninstall -Dm644 chrome/installer/linux/common/desktop.template \\\n    \"$pkgdir/usr/share/applications/chromium.desktop\"\n  install -Dm644 chrome/app/resources/manpage.1.in \\\n    \"$pkgdir/usr/share/man/man1/chromium.1\"\n  sed -i \\\n    -e \"s/@@MENUNAME@@/Chromium/g\" \\\n    -e \"s/@@PACKAGE@@/chromium/g\" \\\n    -e \"s/@@USR_BIN_SYMLINK_NAME@@/chromium/g\" \\\n    \"$pkgdir/usr/share/applications/chromium.desktop\" \\\n    \"$pkgdir/usr/share/man/man1/chromium.1\"\ncp \\\n    out/Default/{chrome_{100,200}_percent,resources}.pak \\\n    out/Default/{.bin,chromedriver} \\\n    \"$pkgdir/usr/lib/chromium/\"\n  install -Dm644 -t \"$pkgdir/usr/lib/chromium/locales\" out/Default/locales/.pak\nif [[ -z ${_system_libs[icu]+set} ]]; then\n    cp out/Default/icudtl.dat \"$pkgdir/usr/lib/chromium/\"\n  fi\nfor size in 22 24 48 64 128 256; do\n    install -Dm644 \"chrome/app/theme/chromium/product_logo_$size.png\" \\\n      \"$pkgdir/usr/share/icons/hicolor/${size}x${size}/apps/chromium.png\"\n  done\nfor size in 16 32; do\n    install -Dm644 \"chrome/app/theme/default_100_percent/chromium/product_logo_$size.png\" \\\n      \"$pkgdir/usr/share/icons/hicolor/${size}x${size}/apps/chromium.png\"\n  done\ninstall -Dm644 LICENSE \"$pkgdir/usr/share/licenses/chromium/LICENSE\"\n}\nvim:set ts=2 sw=2 et:\n. Just to confirm,\n$ chromium --version\nChromium 69.0.3497.100 Arch Linux\n```\nThat's for your AUR package.\nI installed chromium-vaapi (built from source) and got the same error messages, but no segfault and the browser worked\n$ chromium\nmesa: for the -simplifycfg-sink-common option: may only occur zero or one times!\nmesa: for the -global-isel-abort option: may only occur zero or one times!\n[5083:5083:1003/031023.072107:ERROR:sandbox_linux.cc(379)] InitializeSandbox() called with multiple threads in process gpu-process.\n[72:72:1003/031119.435021:ERROR:webthread_impl_for_utility_thread.cc(19)] Not implemented reached in virtual blink::ThreadScheduler *blink::scheduler::WebThreadImplForUtilityThread::Scheduler() const\nSo it seems the segfault is unrelated to the displayed error messages.\n. > You'll need to edit $srcdir/chromium-$pkgver/out/Default/args.gn then with sed or similar.\nThis is a pain because that .gn file doesn't yet exist after the pkgbuild's prepare phase. I guess it is generated by this line in the PKGBUILD's build gn gen out/Default --script-executable=/usr/bin/python2 --fail-on-unused-args.\nAlso I can't run makepkg multiple times, as the second (and further times) it gives an error.\nThe next patch would create the file third_party/ungoogled/ungoogled_switches.h,\nwhich already exists!  Skipping patch.\n1 out of 1 hunk ignored\n2018-10-03 04:35:11,890 - ERROR: Unexpected exception caught.\nTraceback (most recent call last):\n  File \"/home/max/Downloads/AUR/ungoogled-chromium/src/ungoogled-chromium-69.0.3497.100-1/buildkit/cli.py\", line 384, in main\n    args.callback(args=args)\n  File \"/home/max/Downloads/AUR/ungoogled-chromium/src/ungoogled-chromium-69.0.3497.100-1/buildkit/cli.py\", line 232, in _apply_callback\n    patch_bin_path=args.patch_bin)\n  File \"/home/max/Downloads/AUR/ungoogled-chromium/src/ungoogled-chromium-69.0.3497.100-1/buildkit/patches.py\", line 95, in apply_patches\n    subprocess.run(cmd, check=True)\n  File \"/usr/lib/python3.7/subprocess.py\", line 468, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['/usr/bin/patch', '-p1', '--ignore-whitespace', '-i', '/home/max/Downloads/AUR/ungoogled-chromium/src/ungoogled-chromium-69.0.3497.100-1/patches/ungoogled-chromium/add-third-party-ungoogled.patch', '-d', '.', '--no-backup-if-mismatch', '--forward']' returned non-zero exit status 1.\n==> ERROR: A failure occurred in prepare().\n    Aborting...\nDo you want me to file an issue about this makepkg error? How should I proceed with the debug build/Can you give me step-by-step instructions on how to make a debug build on arch?. I tried @ian-moone's suggestion (thanks), but can you please hold my hand a little bit more? I got this error\n-> Configuring Chromium\nERROR at //build/config/BUILDCONFIG.gn:168:1: Assertion failed.\nassert(!(is_debug && is_official_build), \"Can't do official debug builds\")\n^-----\nCan't do official debug builds\n==> ERROR: A failure occurred in build().\n    Aborting...\nI don't know what I'm doing with this build system, but it's not very intuitive. In BUILDCONFIG.gn (./src/chromium-69.0.3497.100/build/config/BUILDCONFIG.gn), I found is_official_build = false on line 131, but the failed assertion suggests that is_official_build = true.\n. I got much of the way through compiling this time, then...\n```\n/usr/bin/ld.lld: error: duplicate symbol: download::QuarantineFile(base::FilePath const&, GURL const&, GURL const&, std::__cxx11::basic_string, std::allocator > const&)\n\n\n\ndefined at quarantine.cc\n           quarantine/quarantine.o:(download::QuarantineFile(base::FilePath const&, GURL const&, GURL const&, std::__cxx11::basic_string, std::allocator > const&)) in archive obj/components/download/quarantine/libquarantine.a\ndefined at quarantine_linux.cc\n           quarantine/quarantine_linux.o:(.text+0x0) in archive obj/components/download/quarantine/libquarantine.a\n\n\n\n/usr/bin/ld.lld: error: duplicate symbol: download::IsFileQuarantined(base::FilePath const&, GURL const&, GURL const&)\n\n\n\ndefined at quarantine.cc\n           quarantine/quarantine.o:(download::IsFileQuarantined(base::FilePath const&, GURL const&, GURL const&)) in archive obj/components/download/quarantine/libquarantine.a\ndefined at quarantine_linux.cc\n           quarantine/quarantine_linux.o:(.text+0x2A0) in archive obj/components/download/quarantine/libquarantine.a\nclang-6.0: error: linker command failed with exit code 1 (use -v to see invocation)\n[15596/19271] CXX obj/v8/torque/TorqueParser.o\nninja: build stopped: subcommand failed.\n==> ERROR: A failure occurred in build().\n    Aborting...\n```\nI'm done trying things on my own. I'll try simple suggestions, but I don't have time to try to understand the build system (and I don't really want to learn it). If someone tells me a way that they successfully made a debug build of this on Arch, I'm all ears.. \n\n\n",
    "lefedor": "Judging by third_party/blink/renderer/core/fullscreen/fullscreen.cc there's no build-in key for that feature.. Have made estimated patch file but don't have disk space currently to compile this beast and don't know if it's the right way to implement feature.\nallowanyfsr.patch.zip\n. ",
    "Kavatch": "No, I got no zip file.. > Let me rephrase: Did build.py complete successfully? What did it say near the end of its output?\nOh sorry ^^ I think it gave me two errors at first, but I fixed those and than it completed successfully.. > Interesting, I didn't know Windows support was fixed. Are you able to run the browser from the build outputs? (e.g. located in build/src/out/Default/chrome.exe)\nIt is not fixed, like I said it gave me an error but I just bypassed with some comments in one file to disable a feature which should not have been needed. (At least I hope it was not needed. I think it was \"Safe Browsing Basic\" ).\nAnd there is sadly no chrome.exe file in my folder. \nBut as I said, because I have bypassed the whole thing in such a way can of course also have led to the error. But what really surprised me was that it didn't even execute a single line from 'package.py'. I debugged it and it exited immediately after starting and didn't even execute the import.. ",
    "Aquarian-Age": "@Eloston @intika  \nThanks Reply\nI modified the compile option of the spec file to\nNinja -v -j2 -C out/Default chrome chrome_sandbox chromedriver\nappear\nError: --thinlto-cache-policy: invalid cache policy: Unknown key: cache_size_files'\nReference: https://clang.llvm.org/docs/ThinLTO.html\nThen modified BUILD/ungoogled-chromium-9.0.3497.100/build/config/compiler/BUILD.gn\nCache_policy =\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"cache_size=75%: cache_size_bytes=70g\"\nThe problem is solved. Continue to compile.\nFAILED: chrome_sandbox\nError: Invalid summary version 4, 1, 2 or 3 expected\nI located the source of the error message in third_party/llvm/lib/Bitcode/Reader/BitcodeReader.cpp\n5178 const uint64_t Version = Record[0];\n5179 const bool IsOldProfileFormat = Version == 1;\n5180 if (Version < 1 || Version > 4)\n5181 return error(\"Invalid summary version \" + Twine(Version) +\n5182 \", 1, 2, 3 or 4 expected\");\n5183 Record.clear();\nThe following is the error message\nDone. Made 9329 targets from 1628 files in 8550ms\nninja -v -j2 -C out/Default chrome chrome_sandbox chromedriver\nNinja: Entering directory out/Default\n[1/16703] python \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./chrome_sandbox\" -- clang++ -pie -Wl,--build-id=sha1 -fPIC -Wl, -z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -fuse-ld=lld -Wl,--icf=all - Wl,--color-diagnostics -flto=thin -Wl,--thinlto-jobs=2 -Wl,--thinlto-cache-dir=thinlto-cache -Wl,--thinlto-cache-policy,cache_size=75\\ %:cache_size_bytes=75g -Wl,--lto-O0 -fwhole-program-vtables -m64 -Wl,-O2 -Wl,--gc-sections -rdynamic -Wl,-rpath-link=. -Wl,-- Disable-new-dtags -o \"./chrome_sandbox\" -Wl,--start-group @\"./chrome_sandbox.rsp\" -Wl,--end-group -latomic -ldl -lpthread -lrt\nFAILED: chrome_sandbox\nPython \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./chrome_sandbox\" -- clang++ -pie -Wl,--build-id=sha1 -fPIC -Wl,-z,noexecstack - Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -fuse-ld=lld -Wl,--icf=all -Wl,--color -diagnostics -flto=thin -Wl,--thinlto-jobs=2 -Wl,--thinlto-cache-dir=thinlto-cache -Wl,--thinlto-cache-policy,cache_size=75\\%:cache_size_bytes=75g -Wl,--lto-O0 -fwhole-program-vtables -m64 -Wl,-O2 -Wl,--gc-sections -rdynamic -Wl,-rpath-link=. -Wl,--disable-new-dtags -o \"./chrome_sandbox\" -Wl,--start-group @\"./chrome_sandbox.rsp\" -Wl,--end-group -latomic -ldl -lpthread -lrt\n/usr/bin/ld.lld: error: Invalid summary version 4, 1, 2 or 3 expected\n/usr/bin/ld.lld: error: Invalid summary version 4, 1, 2 or 3 expected\nClang-6.0.1: error: linker command failed with exit code 1 (use -v to see invocation)\n[2/16703] python ../../tools/licenses.py --target-os=linux --depfile gen/components/resources/about_credits.d credits gen/components/resources/about_credits.html\nNinja: build stopped: subcommand failed.\nThe gongle search did not see the corresponding instructions. I don\u2019t know what the value is. I can\u2019t succeed after trying it.\nMy build environment is:\n`openSUSE 15.0\nClang --version\nClang version 6.0.1 (tags/RELEASE_601/final 335528)\nTarget: x86_64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /usr/bin\nGcc --version\nGcc (SUSE Linux) 7.3.1 20180323 [gcc-7-branch revision 258812]\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions. There is NO\nWarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nLlvm-config --version\n6.0.1`. ",
    "Eddi2015": "same here. I bet there's something faulty at the PKGBUILD. I think 'hostname' has to be replaced with 127.0.0.1 or localhost. Maybe I'm wrong and the whole thing needs to be replaced by a valid url.. I also like this ideas @probonopd . As already said by others there might be some issues. ~99.5 % of the websites work with uBlock Origin, but none technical users might wonder at the 0.5 % of the sites why it doesn't work. So I still would leave it up to the user to install the extension. Maybe we can add some sort of startpage on the first launch that prposes to install those extensions and is able to insatll (and update) with one click. Maybe a related project: https://github.com/UnnoTed/Ungoogled-Chromium-Extension-Installer. Personally I'm using UC on Manjaro Linux as a daily driver. I really like it how it is at the moment, so there are just some things I'd like to see in the future: \n\nmerging useful privacy / security patches (especially fingerprint deception and stopping google connections) from other Browsers (e.g. Brave)\nmaking packaging as dynamic as possible, so that you can easily choose wheter you just want an ungoogled browser (no fingerprint deception etc) or 'more features' like additional features that are useful, but not directly related to ungoogling.\nI'm not sure if we really need an Android variant as there already exists Bromite which includes some of UC's patches. IMO it does a pretty good job.\nautomatic building system for all platforms including Arch AUR (maybe using a free service or running a build server by donations).\nplease don't remove binary pruning or domain substitution, as they are useful. Maybe add some sort of whitelist for domain substitution.\n\nThank you for your effort. I really appreciate this project.. ",
    "tavlima": "@Eloston, I tried to follow the build instructions in master, but they seem to be outdated. Tried the instructions in the specific tag used by the latest (stable) Linux Portable binary artifact, but also to no avail.\nAnd I really mean statically linked binaries, which is not the case of the Portable Linux published in the Contributor Binaries:\n```\nLooking into ungoogled-chromium_67.0.3396.87-1_linux.tar.gz ...\n$ ldd chrome | grep \"not found\"\nlibatk-bridge-2.0.so.0 => not found\nlibgtk-3.so.0 => not found\nlibgdk-3.so.0 => not found\n```. ",
    "raizam": "Travis is free for open source projects.\nSupports all major platforms, it's the usual way to go.\n(never used it though). ",
    "ODB88": "I tried 68 and 69 from the latest builds, maybe should i remove the cache or anything like that?. Working!. ",
    "hamishknight": "I found I had to enable the flag #upcoming-ui-features in order to get the new UI (69.0.3497.100 on macOS).. And in 70.0.3538.77 you now get the new UI by default.. @stfnhh You can change the flag #show-avatar-button for that.. ",
    "s1nceri7y": "i enabled users namespaces, but no luck\n`> sudo sysctl kernel.unprivileged_userns_clone=1\nkernel.unprivileged_userns_clone = 1\n\n./chrome-wrapper \nfish: \u201c./chrome-wrapper\u201d terminated by signal SIGSEGV (Address boundary error)\nbash\n[s1nceri7y@s1nceri7y ungoogled-chromium_69.0.3497.100-2_linux]$ ./chrome-wrapper \nSegmentation fault (core dumped)\n. after trying to launch from root w/ --no-sandbox option( which was failed too) and reassigment the unprivileged userns clone variable, i have another error (w/ delaying on ~0.5 sec before printing \"Segmentation fault\":[s1nceri7y@s1nceri7y ungoogled-chromium_69.0.3497.100-2_linux]$ ./chrome-wrapper \n[5145:5205:1025/184834.633308:ERROR:data_store_impl.cc(131)] Failed to open Data Reduction Proxy DB: 3\nSegmentation fault (core dumped)\n[s1nceri7y@s1nceri7y ungoogled-chromium_69.0.3497.100-2_linux]$ \n. at the beggining i was looking for easy ways, but then i downloaded the portable build.\nhere's what i have for now  when trying to launch an appimage builds1nceri7y@s1nceri7y ~/Downloads> \n./ungoogled-chromium_69.0.3497.100-2_linux(1).AppImage \n[7203:7219:1025/190231.321316:ERROR:data_store_impl.cc(131)] Failed to open Data Reduction Proxy DB: 3\n/tmp/.mount_ungoog2VYYdS/AppRun: line 4:  7203 Segmentation fault      (core dumped) \"${HERE}\"/opt/google/chrome/chrome --password-store=basic $@\ns1nceri7y@s1nceri7y ~/Downloads> \n. 1. Only one of them, but i still able to run it.\n2. I'm a little bit busy. i'll try later\n3. They are disabled on Arch Linux by default.\n4. I'm using original kernel (i mentioned my kernel in Enviroment info)Linux s1nceri7y 4.18.16-arch1-1-ARCH #1 SMP PREEMPT Sat Oct 20 22:06:45 UTC 2018 x86_64 GNU/Linux\ns1nceri7y@s1nceri7y ~> \n5. I'll try later, but i just noticed i haven't removed my profile from Chromium before uninstalling (i was logged in google account). i'll remove it and try.\nThanks for helping me!\n. yes, that was a deal: i wasn't able to launch ungoogled-chromium cause of remaining google acount i hadn't log out and disabled namespaces by default.\nthanks.\ni think it's a good idea to add removing existing cookies and etc before installing ungoogled-chromium. i should mention that i logged in in chromium 70.\nafter cleaning cache, cookies and everything but boomarks, everything become right . \n",
    "misaka00251": "It works!. ",
    "hasufell": "If you want preinstalled protection and whatnot, you are better off using brave browser, because that's exactly what they do. This is just a patched chromium. I think it's good to keep the scope small. . ",
    "brianegan": "Wait! I found it. For those who are curious: You need to open the Settings and uncheck \"Keep local data only until you quit your browser.\"\nPerhaps not as secure of course, but certainly more convenient!. ",
    "FriendlyAI": "Previews work in both regular Chrome and in Vivaldi. Tried v70, but the issue persists. Previews for other file types work, however, including mp4's.. With some more testing, it looks like the previews are only broken when you are signed into an account and works when not signed in. \nComparing the DevTools log from Chromium and a working Chrome, there is a failed media download from https://doc-0k-2k-docs.googleusercontent.com/docs/securesc/... initiated by nonceSigner with error (failed) net::ERR_TOO_MANY_REDIRECTS in Chromium but not in Chrome. \nThere are a lot of requests to https://docs.google.com/nonceSigner?nonce=..., then to the doc-0k-2k-docs.googleusercontent.com url, then back and forth, creating a redirect loop and eventually failing.. Nope. Same problem when on Firefox and Safari user agents.. Worked, thank you.. ",
    "saltama": "Instead of adding this back for everyone, adding an entry in the wiki on how to enable it back before compilation would be a better idea (albeit requiring some maintenance in future releases), in my opinion.\nWas this working before #7? It was committed 2 years ago, hard to tell.. That option was removed with this commit.. I've added a patch for this in this branch, but I'm not opening a PR since this should be fixed once we have a new source tarball from chromium (the most recent I can download is 70.0.3538.102, newer ones are not available yet it seems).. I've noticed that they store those files in a S3v1 API-compatible server, and a query shows they've just generated chromium-70.0.3538.110.\nThose builds look like the result of manual triggering since I can't see any clear pattern.\n71.x should become the new stable in 3 weeks or so, so I suppose there will not be many additional 70.x releases.\nI'm building 110 now to verify if the patch is still needed and if the other patches still apply correctly.. Ok, the no-sysroot patch is still needed in 110, opening a PR.\nBy the way, as expected a few patches will need to be updated for 110.. Added here: https://chromium.googlesource.com/chromium/src/+/6e0836efbb227cba1336d7750899d4d242d1224d%5E%21/#F0\nThe content of that commit has not been altered by any patch from here as far as I can tell.. See #627. Build in progress (at least it gets past the error), I'll let you know.. Ok, it worked, thanks tie!. As  long time user of https everywhere, great patch, thanks.. I can confirm that the directory is still Chromium.app/Contents/Versions/71.0.3578.98/Chromium Framework.framework/Libraries, the WidevineCdm directory from Chrome should be copied there.\nIf you are using 70.0.3538.77 just change that part of the path (the release number).\n(I've noticed a new Widevine Resources.bundle file under 71.0.3578.98/, don't think it's required, instructions can stay as they are). The first part of the patch @patchouli69ou is referring to commented out the flag, but that has been completely removed from chromium in October, see: https://bugs.chromium.org/p/chromium/issues/detail?id=753973\nI'm opening a quick PR for this.\n. requests.exceptions.HTTPError: 502 Server Error: Bad Gateway for url: https://chromium.googlesource.com/chromium/src.git/+/72.0.3626.109/chrome/common/extensions/chrome_extensions_client.cc?format=TEXT\n(I didn't run validate_patches on the other patches, btw). ",
    "tvd9": "All I know is that it was working with \"stock\" chromium. Also, I agree,  that this shouldn't be added for everyone.. ",
    "memeticks": "Can people get extensions to install in ungoog chrome? I cant get the url on this page to work at all, https://ungoogled-software.github.io/ungoogled-chromium-wiki/faq#can-i-install-extensions-from-the-chrome-webstore.\nI keep getting invalid appID, i tried including the [ ] and not including them, tried including the \"id=\" bit and not including it, tried multiple extensions and even tried pasting the modified url into chrome but always invalid appID. . Apologies for the off topic, and thanks a mill jlj2 for your help. Not sure what I was doing wrong yesterday but I got it to work today thanks to your examples and I now have my ublock and common hangouts installed and working perfectly.\nThanks all!. ",
    "pegasusearl": "hmm, after I read this discussion, I think I should reconsider my extension. But my must have extension is The Great Suspender.\nThe extension I used before is:\n- The Great Suspender - saves memory when opening stupid amount of tabs\n- Adguard Adblocker *)*\n- Poper Blocker (probably should change, but not sure what to change to) )\n- No Script\n- xdman helper for my download manager\nEDIT: @anchev \nDo you check the source code?\nNo I didn't even understand the source even though we can see it.\nif no: Do you simply follow recommendations?\nSometimes, most of the times I just search random extension by the function I want.\nDo you trust an extension based on what many people trust?\nNo I don't trust somethings because many people do. But I still install it because I think I need those extensions **) and I can't find more legit choice.. ",
    "rockingaryan": "Hi,\nI have already tried with Guest and new people profile in ungoogled chromium. I got the notification pop-up but it not activate from the facebook settings.. ",
    "tvaleev": "Right! Push Notifications used GCM service for client notification.For example user get unique ID for future notifications.  In chrome/browser/push_messaging is located Push notifications implementation. Impossible to have client Push API notification without cloud services by Google (or Mozilla in case of Firefox browser).\nBy the way, currently they migrate to FCM.\n . ",
    "caspertone2003": "@crazy-max \n@Eloston \nThanks!\nGood job, much desired behaviour.. @leo-liar \nThanks very much, precious resource that link you gave!\n@Eloston \nPerhaps would be good to add compilation to https://ungoogled-software.github.io/ungoogled-chromium-binaries/releases/windows/64bit/ \nThanks again\nCT\n. @Eloston \nThanks for the explanation. Difficult topics to understand for a layman...\nSo I will wait.\nCT. ",
    "yl3dy": "AFAIK, xz utility does not support multithreaded compression/decompression now, so apparently nothing can be done. Does this step really consume a lot of time for you?. Yes, it does: https://pastebin.com/ympcgrcC. At last I think I figured out the root of the problem: leftover hidden files in build/src. Looks like these somehow prevented patches from applying. Now the version from master builds successfully.\nProbably it should be added to the docs that build/src directory should be cleared before every building attempt.. ",
    "clapbr": "If you use makepkg, I have those modified lines in /etc/makepkg.conf for multithreaded compression:\nCOMPRESSGZ=(pigz -c -f -n)\nCOMPRESSBZ2=(bzip2 -c -f)\nCOMPRESSXZ=(xz -c -z - --threads=0)\nCOMPRESSLRZ=(lrzip -q)\nCOMPRESSLZO=(lzop -q)\nCOMPRESSZ=(compress -c -f)\nalso remember to install pigz. ",
    "renatolond": "Thanks for the response!\nI was not sure if there was any google component involved, but it does make sense that they would be using their own stuff.\nI will check what would be needed and if I find it I will document it on the wiki :)\n@Atavic having to use google meet for work does not make me want to give google control over every other website I access, hence the issue.. ",
    "csalvato": "Why can't we, as users, decide whether or not to enable this extension? Why is this marked as wontfix?. @Eloston I am not super intimate with the goals of the project, but I would image that one of the goals is to actually have the browser get adopted.  If that's the case, then this extension being excluded creates a massive barrier for many people who rely on screen sharing with Google Meet.\nGoogle Meet is one of the most popular and pervasive video meeting and screen sharing tools for remote teams. Every team I've been on since 2010 has used Google Hangouts or Google Meet daily.\nIf I need to load up Chrome to run my work meetings, then switch to Brave for everything else, that's a level of complexity that is too much for me, personally. And if the goal is mass adoption, not supporting Google Meet screensharing will be in the way for many more people who don't want to deal with a wonky, persnickety browser.\nI can use Google Meet screen sharing on Chrome and Firefox.  But I can't use it on Brave. If one of the goals of the project is to not support an integral remote-working use case because of an arbitrary ungoogled-chromium setup file, I guess Brave isn't for me. \ud83d\ude22. Re: rebuilding the browser: I wouldn't even know how to rebuild the browser from source just to get Google Meet working.  If that's the solution to the problem, I think you'll find a barrier to getting more people to use Brave.. @antonin-lebrard Oh wow! My mistake. I was linked here from another issue on the Brave project.  How embarrassing :). In that context, that makes total sense.. ",
    "riyad": "I'll have a look. \ud83d\ude00. Me neither, but the warning at the top of the ungoogled-chromium downloads page sparked my interest. Once I had the build process somewhat automated I just tried to poke around diffing two of my builds out of curiosity. I was surprised by the outcome to be honest. I was even more surprised when comparing my build against yours. :slightly_smiling_face: \nI had watched a few talks about the reproducible builds effort and was aware that there are a myriad of possibilities for differences especially in a project the size of chromium. And a little research shows that chromium itself isn't reproducible yet ... it seems because of build ids and some debug info. Whatever the source, it seems it's patched out of ungoogled-chromium. :smile: \nI'm still not sure what the consequence should be. We should be aware that builds on other platforms might not be reproducible ... although I'm fairly confident they are since AFAIK Windows and macOS builds also use the LLVM toolchain (instead of \"platform specific\" ones).\nOne idea would be to ask previous/new contributors of binaries to try to verify on their platform/distro.\nAnother would be to invert the assumption on the download page to e.g. \"(preliminary) tests have shown builds should be/can be expected to be reproducible\" and ask users for ideas and feedback.\nMaybe gathering some more data and/or making this info public will spark some idea. :man_shrugging:\nI was just the lucky finder ... I don't know what to do with it. :joy:. FYI: this is still an issue in the recent 72.0.3626.109-1 release.. I've hacked together a working set of changes to build chromium with the bundled version of icu. You can find the changes in https://github.com/riyad/ungoogled-chromium/commit/296d6f423523c9669ce971d2ce027824b2dd38f3 ... I'm trying to clean them up for submission.\n@Eloston maybe you can point me in the right direction. I had to remove entries from linux_rooted's pruning.list and patche_order.list. The documentation mentions that .list files are concatenated down the dependency chain ... so how do I skip or undo a patch from a dependency?\n:warning: : just as a test I went through Wikipedias with different scripts. Everything looked good except Arabic and similar scripts (Farsi, Urdu, etc.) crashed the tab ... but only on Wikipedia, other websites with Arabic script (e.g. Al-Jazeera, BBC Arabic) rendered without problems. :man_shrugging: \n. ",
    "zchlm": "I'm running into the same error on Ubuntu Cosmic. Using the Contributor Binary 71.0.3578.98-2. Same issue building from source.. ",
    "chrisbarber": "I did see this happen with 2.7.12. It might work in 2.7.13 for all I know, but you might want to just recommend \">=2.7.15\" since we know it works in that version. 2.7.15 is the latest but it was released in May of this year so it is not that stringent of a recommendation.. ",
    "jjpe": "Tried to build a second time. This time the output differs somewhat:\n```\n+++ greadlink -f ./ungoogled_packaging/build.sh\n++ dirname /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/build.sh\n+ packaging_dir=/Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging\n++ ls -A /var/empty\n+ '[' -n '' ']'\n+ rm -rf out\n+ mkdir out\n+ mkdir out/Default\n+ DOWNLOAD_CACHE=/Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache\n+ pushd ungoogled_packaging\n~/Development/ungoogled-chromium/build/src/ungoogled_packaging ~/Development/ungoogled-chromium/build/src\n+ mkdir -p /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache\n+ python3 -m buildkit downloads retrieve -b config_bundles/macos -c /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache\n2018-12-02 23:52:27,864 - DEBUG: Initialized logger 'buildkit'\n2018-12-02 23:52:27,864 - INFO: Downloading \"chromium\" to \"chromium-70.0.3538.110.tar.xz\" ...\n2018-12-02 23:52:27,865 - INFO: /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache/chromium-70.0.3538.110.tar.xz already exists. Skipping download.\n2018-12-02 23:52:27,865 - INFO: Downloading hashes for \"chromium\"\n2018-12-02 23:52:27,866 - INFO: /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache/chromium-70.0.3538.110.tar.xz.hashes already exists. Skipping download.\n2018-12-02 23:52:27,866 - INFO: Downloading \"google-toolbox-for-mac\" to \"google-toolbox-for-mac-3c3111d3aefe907c8c0f0e933029608d96ceefeb.tar.gz\" ...\n2018-12-02 23:52:27,867 - INFO: /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache/google-toolbox-for-mac-3c3111d3aefe907c8c0f0e933029608d96ceefeb.tar.gz already exists. Skipping download.\n2018-12-02 23:52:27,867 - INFO: Downloading \"llvm\" to \"clang+llvm-6.0.0-x86_64-apple-darwin.tar.xz\" ...\n2018-12-02 23:52:27,867 - INFO: /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache/clang+llvm-6.0.0-x86_64-apple-darwin.tar.xz already exists. Skipping download.\n2018-12-02 23:52:27,867 - INFO: Verifying hashes for \"chromium\" ...\n2018-12-02 23:52:30,330 - DEBUG: Verifying md5 hash...\n2018-12-02 23:52:32,300 - DEBUG: Verifying sha1 hash...\n2018-12-02 23:52:34,079 - DEBUG: Verifying sha224 hash...\n2018-12-02 23:52:37,917 - DEBUG: Verifying sha256 hash...\n2018-12-02 23:52:41,806 - DEBUG: Verifying sha384 hash...\n2018-12-02 23:52:44,920 - DEBUG: Verifying sha512 hash...\n2018-12-02 23:52:47,840 - INFO: Verifying hashes for \"google-toolbox-for-mac\" ...\n2018-12-02 23:52:47,906 - DEBUG: Verifying sha512 hash...\n2018-12-02 23:52:47,908 - INFO: Verifying hashes for \"llvm\" ...\n2018-12-02 23:52:48,969 - DEBUG: Verifying sha512 hash...\n+ python3 -m buildkit downloads unpack -b config_bundles/macos -c /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache ../\n2018-12-02 23:52:50,675 - DEBUG: Initialized logger 'buildkit'\n2018-12-02 23:52:50,676 - INFO: Unpacking \"chromium\" to ./ ...\n2018-12-02 23:52:50,688 - DEBUG: Using BSD or GNU tar extractor\n2018-12-02 23:52:50,688 - DEBUG: tar command line: /usr/bin/tar -xf /Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/../../download_cache/chromium-70.0.3538.110.tar.xz -C ..\n2018-12-02 23:56:50,457 - ERROR: Unexpected exception caught.\nTraceback (most recent call last):\n  File \"/Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/buildkit/cli.py\", line 384, in main\n    args.callback(args=args)\n  File \"/Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/buildkit/cli.py\", line 95, in _unpack_callback\n    downloads.unpack_downloads(args.bundle, args.cache, args.output, extractors)\n  File \"/Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/buildkit/downloads.py\", line 195, in unpack_downloads\n    extractors=extractors)\n  File \"/Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/buildkit/extraction.py\", line 210, in extract_tar_file\n    _extract_tar_with_tar(tar_bin, archive_path, output_dir, relative_to)\n  File \"/Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/buildkit/extraction.py\", line 126, in _extract_tar_with_tar\n    _process_relative_to(output_dir, relative_to)\n  File \"/Users/j/Development/ungoogled-chromium/build/src/ungoogled_packaging/buildkit/extraction.py\", line 70, in _process_relative_to\n    src_path.rename(dest_path)\n  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/pathlib.py\", line 1302, in rename\n    self._accessor.rename(self, target)\nOSError: [Errno 66] Directory not empty: '../chromium-70.0.3538.110/skia' -> '../skia'\n```. That's the problem with old MacOS versions: Apple won't allow upgrading. \nAt the same time, Apple won't allow me to upgrade to the newest MacOS version either (pre-2012 MBP here).\nSo basically what I infer it comes down to is that support is needed for older MacOS versions and accompanying XCode versions, because it's ridiculous that an otherwise perfectly good laptop (it's perfect shape considering its age) become unusable because the company that made it doesn't want the job of maintenance anymore.. ",
    "ibeanubis": "I have the same problem. > @jjpe Did you follow the instructions in your original error?:\n\n__main__.SdkError: 'Install Xcode, launch it, accept the license agreement, and run `sudo xcode-select -s /path/to/Xcode.app` to continue.'\nAlso, when you re-ran the build, did you remove build/src first?\n\nHey, I got it to work. I had already accepted the agreements but I also had to leave the xcode application open throughout the process for it to work!  Thanks for your amazing work!. ",
    "wiredrunner": "At the same time apparently chromium plans to deprecate them they are showing up from websites (on Chrome) I never even visit. pippio.com, superfastcdn.com breitbart.com and endless google properties all it says under cookies is Channel ID and the name of the website.  I could block all cookies and they still show up.  \nhttps://groups.google.com/a/chromium.org/forum/#!topic/net-dev/AjFQjBmaEQE\nhttps://github.com/EFForg/privacybadger/issues/1135\nhttps://bugs.chromium.org/p/chromium/issues/detail?id=467312#c23\nhttps://bugs.chromium.org/p/chromium/issues/detail?id=875046. If you look at the Channel ID they all say -\nDomain \n.\nCertificate Type\necdsa_sign\nMaybe they aren't really cookies?. Chrome no longer processes these.  It must have taken some time for them to reach this point after deprecating token binding.  Either that or their being hidden but it makes sense that they got rid of them.\nSorry to waste your time on this.. ",
    "xhiddle": "So there's this lovely freeware tool\nhttps://kolbi.cz/blog/2017/11/10/setdefaultbrowser-set-the-default-browser-per-user-on-windows-10-and-server-2016-build-1607/\nBut because UNgoogled chromium prebuilt binary was a zip file it's not hooked into all the right places so more magic required\nThere is this other tool that references the first tool which explains that a hash must be generated to bind new associations prossibly explaining why OP does not result in satisfaction\nhttps://kolbi.cz/blog/2017/10/25/setuserfta-userchoice-hash-defeated-set-file-type-associations-per-user/\nwhich itself cryptically references GPO  (not for  win 10 home users).  Good thing I have pro?\n. > we would need to do to implement it in the Chromium\nexport whatever to a fixed filesystem location outside of chromium profile directorie trees. Use third party tool to sync given location to whichever cloudy services. User provides own sync tool, and cloud credentials via that tool.\nway less huge undertaking?  Option to auto export user selections on startup as shutdown seems sketchy.\n\nconsider an external syncing system that can synchronize the entire profile directory?\n\nAnd that's what I get for not completely reading prior to replying.\n\nnextcloud\n\nThis reminds me to ask vultr why the listed $2.50/mo USD price is unobtainable.\nMaybe this tool has the desired promise:\nhttps://github.com/ncw/rclone\nespecially with\n\nOptional encryption (Crypt)\nCopy mode to just copy new/changed files\nSync (one way) mode to make a directory identical\nCheck mode to check for file hash equality\n\nand/or\nhttps://restic.readthedocs.io/en/latest/010_introduction.html\n: via https://help.nextcloud.com/t/rsync-to-cloud-storage-for-backups/43574. ",
    "black-ish": "Forgot to add that I currently use these command line switches:\n\"\\Chrome.exe --user-data-dir=\".\\Profile\" --disable-breakpad --disable-logging --disable-sync --disable-speech-api --disable-voice-input --disable-domain-reliability\"\nAlso forgot to say thank you for this nice edition of Chromium, thank you very much.\nI don't seem to be able to edit my other post for some reason, so sorry for double posting.. So first I'm no dev, so my point of view will come from a pure windows \"user/consumer\" perspektive here.\nImo unggogle-chromium is how that piece of software should have been from the start, any and all dependecies from web services (google etc.) should not exists it should be a \"pure\" browser and mostly get security updates and some \"nice\" new features that don't exist but are useful for a practical reasons or simply privacy reasons.\nFor ex. my request ( #625 ) comes from the simple fact that there are already so many flags to set that you \"should\" use because those \"features\" should be enabled by youself if you have something to use them with (certain webpages, need for debuging etc.).\nChromium contains things I simply will never use but there is no real option to disable or change them without certain flags set. (Many things can be added later with extensions for each ones needs.)\nTo add to that, that those flags won't be set if you open a link from another program because in the registry those extra flags aren't there, it simply calls for chrome.exe.\nAnd I also do not want a piece of software to \"think for me\", it needs to be clear how the sofware accomplishes a task and what it will do, in as detailed as possible.\nIn regards to the thing that CHEF-KOCH mentiones, I find it a little concerning that Cent Browser is mentioned, because it's closed source and even if you disable everything it still connects to 3 IPs and two DNS requests are send at startup, one to google and another to centbrowsers website, and I would like to know why it still does that, for many people that is a concern and not a desired \"thing\" that should happen at all.\nWith the general state of browsers now (bloated, lack of transprancey without scouring the source code, Chromium/Chrome being now almost a monopol) I think a \"minimal\" browser even if a little \"crippled\" but working on all sites and even if based on Chromium is needed.\nI would say that the general direction I would like to see ungoogled-chromium to head is: minimal, no-dependency, user options, portable (preferably by default, also means nothing written to registry).\nThat way it should already be a very good base for everyone that would like to fork it imo.\nEdit:\nCent Browser does have many features that Chromium/Chrome should actually have since the beginning (imo) like the ability to switch Tab behaviour, download viewer button like Firefox, ability to toggle HTML5 canvas fingerprinting etc.\nSo that can also be a way look to in terms of features. Just my two cents.. ",
    "tie": "Seems to be a bug in Chromium's build scripts.\nDid the patch from PR work for you?. > Added here: https://chromium.googlesource.com/chromium/src/+/6e0836efbb227cba1336d7750899d4d242d1224d%5E%21/#F0\n\nThe content of that commit has not been altered by any patch from here as far as I can tell.\n\nActually it was fixed in upstream a week ago.\n. TL;DR: out/Default/gn executable is built in out/Release/gn_build directory.  With this PR bootstrap script will use out/Default/gn_build.\n\nIf --build-path is not passed, either out/Release/gn_build or out/Debug/gn_build are used for gn_build_dir variable value ($build_path/gn_build otherwise).\nThe script then runs build commands in directory specified by gn_build_dir and copies $gn_build_dir/gn to output in the end.  If output is not defined, it uses $build_path/gn as the default.\nThat said, I've just noticed that -o out/Default/gn option is dummy\u2026\nAnyway, I can remove this change from PR if it's the desired behavior.. I've fixed suggestions in the last commit.  Scheme is trimmed in suggestion dropdown for URLs without explicit scheme.. @Eloston, should be ready for merging.  What's your opinion?. >However, will this patch affect other ways of loading web pages?\nThanks for noticing that.\nI've looked through the users of FixupURL on GitHub chromium mirror and, except omnibox (which is already covered by this patch), only searchbox.cc depends on old FixupURL implementation.\nAlso, url_formatter::FixupURL is used in most of the user URL input parsing, so this should affect command-line usage too.\nI'll describe the behavior when I come home because I don't have the build right now.. With the last commit URLs without explicit scheme entered in chrome://bookmarks will be prefixed with https://.\nCommand line usage works as expected \u2014 chromium example.com opens a new tab for https://example.com URL.. Well, it might be a limitation if you enter (unvisited) URL and don't know in advance that the content is not served over HTTPS.  Though the same issue persists for HTTPS-only websites when http:// is default.\nAnd both cases are pretty rare these days:\n- Let's Encrypt Stats\n- Firefox Telemetry for HTTP_PAGELOAD_IS_SSL\n- HTTPS encryption on the web \u2014 Google Transparency Report\nIf you have to type URL more than once regularly (e.g. visiting the website of some local shop or whatever still does not serve HTTPS) then I'd recommend adding http:// URL to the bookmarks.  Even if you don't want to clutter bookmarks list, as long as the browsing history contains HTTP URL, autocompletion does the trick.\nAs for Captive Portals (which are MiTM attack by design, so connection must fail), visiting something like http://neverssl.com from the bookmarks for initial identification on the network solves the issue.\nI don't think that opt-out flag is worth the effort, but let me know your use case if I am missing something.\n\n[\u2026]\nIf your program is overall very easy to use but security adds complexity, people will work to defeat the security even if it's still reasonably easy to use with the security in place.\n[\u2026]\nThe ideal approach is to make security have a negative cost: make it harder to do things the insecure way than the secure one (which would include making insecure impossible).\n\u2014 Design for security, comment by rgmoore\n\n\nI'd also like to note that there are mechanisms such as HSTS that enforce similar policy, but they rely on preloaded lists, require user action or server-side setup and assume that the initial request is made over secure protocol (see Limitations).  That said, HSTS only benefits from default HTTPS scheme in ungoogled-chromium.\n. ",
    "marksolaris": "There's a docs/building.md file which could be extended, or a docs/building_debian.md file created. It needs to explain where in the created tree to find the created debs and the sequnce on how to install the software. That HOWTO for Debian variants would also help people compiling for other OS's in what to do next.. Mostly I'm trying to make the experience less obtuse, so getting from wanting the software functionality to being able to install and run it is less of a google-fu test and more of a HOWTO recipe. I've recently switched from Redhat systems to Debian systems so have a new build eco-system to learn. Before that I've compiled 1000's of packages in other OS's and am quite fond of the old faithful make install. If that's not available in ungoogled-chromium, then at least having the end to end process documented will greatly help the softwares uptake.. Generating a new timestamp upon compiling and creation of the packages would be much more useful to anyone trying to do forensics on what's in the filesystem. Currently installing new files with the 29th July date makes you think the new code didn't work and something broke. I'm assuming the date gets sent to the deb creation logic. If it's possible to turn off setting hard coded dates entirely that'd be useful - keeping the actual ctime/mtime of the files as they are added to the deb.. Ubuntu 18.04.1:\nIn the original chromium src:\nungoogle-chrominum/ungoogled-chromium-72.0.3626.122-1/build/download_cache/unpack root# find . -print | xargs grep -s UCHAR_EXTENDED_PICTOGRAPHIC\n./chromium-72.0.3626.122/v8/src/regexp/regexp-parser.cc:    case UCHAR_EXTENDED_PICTOGRAPHIC:\n./chromium-72.0.3626.122/third_party/icu/source/common/unicode/uchar.h:    UCHAR_EXTENDED_PICTOGRAPHIC=64,\nIn the src after the build failed (didn't find yet why icu went missing):\nungoogle-chrominum/ungoogled-chromium-72.0.3626.122-1/build/src root# find . -print | xargs grep -s UCHAR_EXTENDED_PICTOGRAPHIC\n./v8/src/regexp/regexp-parser.cc:    case UCHAR_EXTENDED_PICTOGRAPHIC:. Installing your own ICU\nFetch:\nhttp://apps.icu-project.org/icu-jsp/downloadSection.jsp?ver=63.1&base=cs&svn=release-63-1\nhttp://download.icu-project.org/files/icu4c/63.1/icu4c-63_1-src.zip\nCompile and install to /usr/local:\ngunzip -c icu4c-63_1-src.tgz | tar -xvf -\ncd icu/source/\nchmod +x runConfigureICU configure install-sh\n./runConfigureICU Linux\nmake \nmake install\n. To compile and link the binary I use the recipe below. The final debian packager complains the /usr/local/lib ICU libraries don't have packaging information and ends, but the new chromium is already built in the build/src/debian directory tree and can be manually copied to /usr. I need to get up to speed what the dh_*tools do to complete the task, but don't have the bandwidth to spend on this linux variant.\nrm -rf ungoogled-chromium-7*\nuntgz ungoogled-chromium-master_2019_03_08.tgz\necho \"Doesn't work\"\nsetenv DEB_DH_SHLIBDEPS_ARGS_ALL --dpkg-shlibdeps-params=--ignore-missing-info\necho \"Find and use new includes\"\nsetenv CFLAGS \"-I/usr/local/include -DUSING_SYSTEM_ICU=1\"\nsetenv CPPFLAGS \"-I/usr/local/include -DUSING_SYSTEM_ICU=1\"\nsetenv CXXFLAGS \"-I/usr/local/include -DUSING_SYSTEM_ICU=1\"\necho \"These two make the linker happy once third_party/icu is nuked\"\nsetenv LDFLAGS \"-L/usr/local/lib\"\nsetenv LD_LIBRARY_PATH /lib:/usr/lib:/usr/local/lib\ncd ungoogled-chromium-7*\nmkdir -p build/src\n./get_package.py ubuntu_bionic build/src/debian\ncd build/src/\necho \"Did you just assume my clang?\"\nperl -pe 's/clang-7/clang/g' -i debian/rules\nperl -pe 's/clang\\+\\+-7/clang++/g' -i debian/rules\nperl -pe 's/llvm-nm-7/llvm-nm/g' -i debian/rules\nperl -pe 's/llvm-ar-7/llvm-ar/g' -i debian/rules\n./debian/rules setup-local-src\necho \"Another presumption, use benign default\"\nperl -pe 's/clang-7\\,/wdiff,/' -i debian/control\nperl -pe 's/lld-7\\,/wdiff,/' -i debian/control\nperl -pe 's/llvm-7\\,/wdiff,/' -i debian/control\nperl -pe 's/llvm-7-dev\\,/wdiff,/' -i debian/control\nsetenv PATH \"/root/bin:/usr/local/bin:/bin:/usr/ccs/bin:/etc:/usr/etc:/usr/bin:/usr/local/X11/bin:/usr/bin/X11:/usr/proc/bin:/usr/local/sbin:/sbin:/usr/local/go/bin:/root/go/bin:/usr/local/etc:/usr/sbin\"\nrm -rf third_party/icu\ndpkg-buildpackage -b -uc. ",
    "AlexIsNice": "\nAre the instructions not working?\n\nWell,the folders mentioned no longer exist.\n. Alright i apologize.Closing this issue.. https://chromium.woolyss.com/\nThe ungoogled one  72.0.3626.121\nLink to download: https://chromium.woolyss.com/f/chrlauncher-win64-stable-ungoogled.zip. ",
    "zeptoSteve": "I'm not 100% sure which file to be looking for, so I attempted to list them all in that directory.\nsh\n[christopher /Volumes/Google Chrome ]% exa -Tbgl Google\\ Chrome.app/Contents/Versions/71.0.3578.98/Google\\ Chrome\\ Framework.framework/Libraries/WidevineCdm\ndrwxr-xr-x@     - christopher staff 11 Dec 22:43 Google Chrome.app/Contents/Versions/71.0.3578.98/Google Chrome Framework.framework/Libraries/WidevineCdm\ndrwxr-xr-x@     - christopher staff 11 Dec 22:43 \u251c\u2500\u2500 _platform_specific\ndrwxr-xr-x@     - christopher staff 11 Dec 22:43 \u2502  \u2514\u2500\u2500 mac_x64\n.rw-r--r--@ 7.0Mi christopher staff 11 Dec 19:19 \u2502     \u251c\u2500\u2500 libwidevinecdm.dylib\n.rw-r--r--@ 1.4Ki christopher staff 11 Dec 19:19 \u2502     \u2514\u2500\u2500 libwidevinecdm.dylib.sig\n.rw-r--r--@   918 christopher staff 11 Dec 19:19 \u2514\u2500\u2500 manifest.json. sh\nexa -Tbgl Chromium.app/Contents/Versions/70.0.3538.110/Chromium\\ Framework.framework/Libraries/   \ndrwxr-xr-x@     - christopher staff  1 Dec 20:18 Chromium.app/Contents/Versions/70.0.3538.110/Chromium Framework.framework/Libraries\n.rwxr-xr-x@  20Ki christopher staff  1 Dec 18:02 \u251c\u2500\u2500 libEGL.dylib\n.rwxr-xr-x@ 2.3Mi christopher staff  1 Dec 18:02 \u251c\u2500\u2500 libGLESv2.dylib\n.rwxr-xr-x@  68Ki christopher staff  1 Dec 18:23 \u251c\u2500\u2500 libswiftshader_libEGL.dylib\n.rwxr-xr-x@ 2.7Mi christopher staff  1 Dec 18:24 \u2514\u2500\u2500 libswiftshader_libGLESv2.dylib. ",
    "hydrogenpi": "can someone create an OVA for the windows 64bit build of latest version 71.x and upload it?. ",
    "ahmedflix25": "same error, i think the problem with the extraction of the chromium-71.0.3578.98.tar.xz or the file itself even manual extraction for it with winrar stops with errors and freeze every thing it touches the file explorer the winrar\nthe process from the script messed up my ssd now i have 2 src folder in the same location properties says it's about 900mb folder the delete process which takes half an hour says it's about 12gb and chkdsk command doesn't help\n\n\n . ",
    "Peacock365": "I think Ungoogled-Chromium is fine as it is. All I (and I suppose many others) want is a Chrome / Chromium variant with as much Google stripped out as possible. If I wanted more features or a different UI I'd choose Vivaldi or Brave.\nAs Microsoft has announced to switch to the Blink rendering engine in Edge, the dominance of Blink has grown stronger. I also use Firefox (and derivatives), as I like its customization options in about:config or userChrome.css. However, more and more settings need to be changed in Firefox in order to keep it as private as possible, ever since Mozilla decided to introduce BS like Pocket / Mr Robot / Cliqz etc. There is also the issue of the Gecko rendering engine: Firefox has around 10% market share left, and Chrome (other browsers using Blink not included) has something like 70%. With Microsoft's recent move, Blink will have 80% market share soon, I suppose. Fewer and fewer web admins will optimize for other engines than Blink (and Safari, I guess), so I am not sure how viable Gecko is at this point and how long Mozilla can keep it up. Eventually, they'll have to throw in the towel and use Blink as it will be the only rendering engine website admins test against.\nWith Blink dominating the market, I've searched a browser that uses this rendering engine but respects privacy at the same time. Chrome and Opera were out. Knowing Windows 10's behavior, I am not too optimistic when it comes to the Edge of the future, as far as privacy is concerned. \nAgain, I like the Chrome / Chromium interface and ease of use, and Ungoogled-Chromium is therefore my best bet at the moment. If this project did not exist, I'd probably use Brave for privacy reasons.\nI feel like continuing to \"ungoogle\" the more and more spyware-infested Chrome / Chromium is an uphill battle in itself, and I somewhat doubt that you'd have time to introduce much if any additional features. Throwing the spyware code out is a full-time job. Keep it clean, keep it unbloated, keep all of Chromium except for the privacy-evading stuff. As Firefox is going downhill and as Blink becomes a de facto monopoly, a \"Chrome without Google\" is a much needed asset now and in the future. I wouldn't change much if anything, the project is doing fine and will be of higher relevance going forward.\n. ",
    "siric1": "\nShould I change the scope of ungoogled-chromium to more align with my preferences (and perhaps change the name as well)?\n\nWith the entire market favoring chromium based browsers, I wouldn't mind seeing a \"new\" browser based on ungoogled-chromium. A purified chromium. Chromium Pure? \nThis project in it's current state is ideal for developers who know how to use build tools. However, it isn't gaining as much traction as we'd all like to see because there are no pre-built binaries and no auto-updates, so it makes it hard for the general public to consider using this, even though there might be many people who stand behind the same philosophy (no bloat, privacy respecting, secure, etc). For this to happen I believe this project will need more contributors, people who stand by the same philosophy and can keep up with the fast paced development of chromium and release binaries in time, to avoid running behind on security fixes. It would position itself well next to Brave because even though Brave does use ungoogled-chromium's patches, is open source and respects privacy just as well, it also adds bloat (Brave Rewards, baked in adblocker and https everywhere, bloated new tab page, upcoming sync functionality, etc). Vivaldi isn't even worth the mention as it's not open source. So I would say there is definitely room for a purified chromium browser, if done right.. ",
    "mowanotm": "I'm not an active user of ungoogled-chromium, please take my opinion with a grain of salt.\nungoogled-chromium means two things to me, Lightweight and Up-to-date (in terms of security and compatibility).\nI use ungoogled-chromium as a supplement for my main Firefox, as a compatibility reference, a quarantined WebGUI, a host for fishy chrome extensions and a backup browser when system under load.\nAdvanced feature is never my reason to use ungoogled-chromium. If ungoogled-chromium were heading into competition with Brave and Iridium, getting more unique for standing out from the crown, I would probably not pick ungoogled-chromium in the first place.\nI just need a bland browser, with chromium compatibility and up-to-date security patch, nothing more. Chromium is not Firefox after all.\nI'm in no position to request the project stay in its niche and unpopular path.. ",
    "MalevolentGrin": "https://github.com/Eloston/ungoogled-chromium/issues/640\n\ntreating ungoogled-chromium as a browser for dealing with privacy issues... However, ungoogled-chromium does not have much in terms of privacy; I leave a lot of that to the user.\n\nTake the project in a Pro Privacy direction?  From Human Dignity is derived one's (negative) rights to privacy.  Everyone has something to keep secret: one's private thoughts [individualism], and one's intimate self (which cannot be taken, but only given freely).\nhttps://github.com/privacytoolsIO/privacytools.io/issues/274#issuecomment-391922550\n\nFirefox and Chrome and every other Browser does connect straight from the start with default settings to several domains, to update the disconnect filter list or for the safebrowsing mechanism etc.\n\nThe problem with these defaults is FAILure to collect INFORMED Consent from the user.  This poses a business model threat to google: explaining how not charging user money allows google to profit from user.  [Privacy Raping]. \nhttps://github.com/Eloston/ungoogled-chromium/issues/640\n\n[2] I have a bias for control over convenience. \n\nI have this not-blind-trust bias also.  Google has done nothing to earn my trust and everything to have me embrace the nomenclature Privacy Raping as profit.  It is crass but apt.\n\nI don't like bloat. I want to remove stuff that I don't need or want.\n\nThis is why I adblock.  I not only minimize data harvesting but I feed the system lies.\n\nI don't like runtime dependence on online code\n\nThis is another example of non-trust with which I agree.\n\n[3] I want ungoogled-chromium to grow. Clearly, the people that use my browser are not all like me\n\nI find myself in parity with your values in this scope thus far.\n\nWhat do you think ungoogled-chromium should be? \n\n\nMinimalism\nHonor the user's dignity:  Privacy Rights are sacrosanct.  Collect Informed Consent before exposing them to harm.\n2b. blocking\n2c. disinformation\n\n\nshould fingerprinting deception mechanisms should be removed\n\nno.\n[disinformation] the entire userbase should appear to have the same fingerprint. E pluribus unum with a twist\n\nPerhaps domain substitution and binary pruning can be optional for packagers of ungoogled-chromium\n\nAny easy built kit for others sure, but would that more than double your effort?\n\nshould ungoogled-chromium become a Chromium derivative that emphasizes more on privacy and FOSS (which aligns more with my preferences), in addition to removing Google-specific behavior (e.g. Google host detection, connecting to Google servers)?\n\nYES\n\nother developers determine how they want to package ungoogled-chromium\n\nWhat are the numbers for people doing this now?\n\nshould it more strictly control the entire process of the browser creation \n\nYou have a firm grasp on the important of privacy, and as a single issue we can all stand together on it ultimately doesn't matter how or why you have reached this valuation to this end.  \nPrivacyMatters\nYes, this is an exacting discipline few will adopt as vigorously but by example we can save more people from inadvertently self harming.\n. ",
    "fosslinux": "\nI want ungoogled-chromium to be as unobtrusive and lightweight as possible. \n\n+1\n\nI am heavily influenced by Debian's philosophy of FOSS. This is why things like binary pruning (to remove any binaries) or domain substitution (to remove any background connections to proprietary services) exist.\n\nI am a huge fan of FOSS and on all my computers require a FOSS-only system. I think these two features (binary pruning and domain substitution) are vital to ungoogled chromium.\n\nI don't like activities to \"think for me\". I want to know what a certain activity will do and its implications. In other words, I have a bias for control over convenience. This is why flags exist for things like IPv6 probing, the removal of captive portal detection, and the removal of mDNS and Service Discovery in #160.\n\nSame. I think all of these should be enabled by default (I can't remember if they are).\n\nI don't like runtime dependence on online code. This goes back to having control of what my software does (e.g. take the NPM module disaster not too long ago). Also, I don't like the assumption that an Internet connection is always available (maybe in the near future, but not yet). This is why I patched the browser UI to use bundled Google fonts instead of Google's font server, and why I changed DevTools to only use a local copy of its JavaScript code (it usually uses JS code hosted on Google).\n\nI never want this to be the case. With this dependence, air gapped systems are basically rendered useless.\n\nPerhaps domain substitution and binary pruning can be optional for packagers of ungoogled-chromium\n\nNo. As I said, these two are vital to ensuring a fully-FOSS browser. Even if you do make them optional, please make sure that they are enabled by default.\nSome further thoughts are below, just things I had thought of, especially in relation to goals.\nThe name states the main goal:\nTo remove Google from the picture of Chromium.\nChromium/Chrome is a great browser, but what primarily prevents me from using it is Google. Google is a for-profit, and has had many occurrences of data/privacy leaks.\nhttps://www.independent.co.uk/life-style/gadgets-and-tech/news/google-chrome-incognito-mode-personal-data-private-browser-a8502386.html\nhttps://hackernoon.com/data-privacy-concerns-with-google-b946f2b7afea\nhttps://www.cnbc.com/2018/09/26/google-changes-chrome-browser-in-response-to-privacy-advocate-critics.html\nhttps://www.makeuseof.com/tag/browser-leaking-online-secrets/\nThis brings me to one of the other goals that I think should be an integral part of ungoogled chromium - privacy. In this day and age, internet privacy is dying. We need more applications that a) can be verified that are private (FOSS, I'll talk about this shortly) and b) care about the users privacy. Ungoogled Chromium can be one of these.\nI believe security should also be a goal of ungoogled chromium. AFAIK, Chromium has never had an independent security audit done and is not written with the goal of security in mind.\nAt some point, as a person who would like to work in infosec, I would love to do a security audit of Chromium. Security patches should be put into ungoogled chromium, however should also be submitted to upstream. If the patch is rejected, it should stay in ungoogled chromium, however be removed if accepted in upstream.\nThis can be summed up as Chromium is a great browser, but has been too much Google-fied. It needs a better focus on security and privacy.. @dackelblut self-built kernel? no. I'll try again, maybe this got fixed?. I don't have a self-build kernel; I'm running 4.19.0-2-amd64 from Debian Testing.\nI'm trying on a Dell Latitude 7480, with a Intel i5-7200U.\nI'm planning to try compiling it again tonight, in about 4-5 hours.. ",
    "swedebugia": "ccache was used and this was not the first attempt to build (deleted src/ in between). Thanks a bunch! I will add bison to the PKGBUILD and try again :)\nThe AUR-packages are all broken/old (tried all Inox- and ungoogled-packages).. It helped installing bison and it compiled all night until this:\nAny ideas?\n``\n[15366/17722] CXX obj/content/browser/browser/browser_jumbo_7.o\nFAILED: obj/content/browser/browser/browser_jumbo_7.o \nclang++ -MMD -MF obj/content/browser/browser/browser_jumbo_7.o.d -DENABLE_SCREEN_CAPTURE=1 -DV8_DEPRECATION_WARNINGS -DUSE_UDEV -DUSE_AURA=1 -DUSE_GLIB=1 -DUSE_NSS_CERTS=1 -DUSE_X11=1 -DNO_TCMALLOC -DOFFICIAL_BUILD -DCHROMIUM_BUILD -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE -DNO_UNWIND_TABLES -D_GNU_SOURCE -DCR_CLANG_REVISION=\\\"344066-1\\\" -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_FORTIFY_SOURCE=2 -DNDEBUG -DNVALGRIND -DDYNAMIC_ANNOTATIONS_ENABLED=0 -DCONTENT_IMPLEMENTATION -DV8_USE_EXTERNAL_STARTUP_DATA -DATK_LIB_DIR=\\\"/usr/lib\\\" -DUSE_ATK_BRIDGE -DATSPI_MAJOR_VERSION=2 -DATSPI_MINOR_VERSION=30 -DATSPI_MICRO_VERSION=0 -DGLIB_VERSION_MAX_ALLOWED=GLIB_VERSION_2_32 -DGLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_26 -DGL_GLEXT_PROTOTYPES -DUSE_GLX -DUSE_EGL -DVK_NO_PROTOTYPES -DTOOLKIT_VIEWS=1 -DUSING_SYSTEM_ICU=1 -DICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC -DUCHAR_TYPE=uint16_t -DU_IMPORT=U_EXPORT -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER -DHAVE_PTHREAD -DSK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS -DSK_HAS_PNG_LIBRARY -DSK_HAS_WEBP_LIBRARY -DSK_HAS_JPEG_LIBRARY -DSK_VULKAN_HEADER=\\\"../../skia/config/SkVulkanConfig.h\\\" -DSK_VULKAN=1 -DSK_SUPPORT_GPU=1 -DSK_GPU_WORKAROUNDS_HEADER=\\\"gpu/config/gpu_driver_bug_workaround_autogen.h\\\" -DVK_NO_PROTOTYPES -DLEVELDB_PLATFORM_CHROMIUM=1 -DLEVELDB_PLATFORM_CHROMIUM=1 -DWEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=0 -DWEBRTC_CHROMIUM_BUILD -DWEBRTC_POSIX -DWEBRTC_LINUX -DABSL_ALLOCATOR_NOTHROW=1 -DNO_MAIN_THREAD_WRAPPING -DV8_DEPRECATION_WARNINGS -DAUDIO_PROCESSING_IN_AUDIO_SERVICE -DSQLITE_ENABLE_FTS3 -DSQLITE_DISABLE_FTS3_UNICODE -DSQLITE_DISABLE_FTS4_DEFERRED -DSQLITE_ENABLE_ICU -DSQLITE_SECURE_DELETE -DSQLITE_THREADSAFE=1 -DSQLITE_MAX_WORKER_THREADS=0 -DSQLITE_MAX_MMAP_SIZE=268435456 -DSQLITE_DEFAULT_FILE_PERMISSIONS=0600 -DSQLITE_DEFAULT_LOOKASIDE=0,0 -DSQLITE_DEFAULT_MEMSTATUS=1 -DSQLITE_DEFAULT_PAGE_SIZE=4096 -DSQLITE_DEFAULT_PCACHE_INITSZ=0 -DSQLITE_LIKE_DOESNT_MATCH_BLOBS -DSQLITE_OMIT_DEPRECATED -DSQLITE_OMIT_PROGRESS_CALLBACK -DSQLITE_OMIT_SHARED_CACHE -DSQLITE_USE_ALLOCA -DSQLITE_OMIT_AUTOINIT -DSQLITE_OMIT_AUTORESET -DSQLITE_OMIT_COMPILEOPTION_DIAGS -DSQLITE_OMIT_COMPLETE -DSQLITE_OMIT_DECLTYPE -DSQLITE_OMIT_GET_TABLE -DSQLITE_OMIT_LOAD_EXTENSION -DSQLITE_OMIT_TCL_VARIABLE -DSQLITE_OMIT_TRACE -DSQLITE_OMIT_UPSERT -DSQLITE_OMIT_WINDOWFUNC -DSQLITE_HAVE_ISNAN -DSQLITE_ENABLE_LOCKING_STYLE=0 -DUSE_SYSTEM_ZLIB=1 -I. -I../.. -Igen -Igen/shim_headers/libevent_shim -Igen/shim_headers/icui18n_shim -Igen/shim_headers/icuuc_shim -Igen/shim_headers/zlib_shim -Igen/shim_headers/libwebp_shim -Igen/shim_headers/libdrm_shim -Igen/shim_headers/re2_shim -I../../third_party/khronos -I../../gpu -I../../third_party/libyuv/include -I../../third_party/vulkan/include -Igen/shim_headers/ffmpeg_shim -Igen/shim_headers/libvpx_shim -Igen/shim_headers/snappy_shim -Igen/shim_headers/opus_shim -Igen/shim_headers/minizip_shim -Igen/shim_headers/flac_shim -I../../third_party/ced/src -I../../third_party/protobuf/src -I../../skia/config -I../../skia/ext -I../../third_party/skia/include/c -I../../third_party/skia/include/config -I../../third_party/skia/include/core -I../../third_party/skia/include/docs -I../../third_party/skia/include/effects -I../../third_party/skia/include/encode -I../../third_party/skia/include/gpu -I../../third_party/skia/include/pathops -I../../third_party/skia/include/ports -I../../third_party/skia/include/utils -I../../third_party/vulkan/include -I../../third_party/skia/third_party/vulkanmemoryallocator -I../../third_party/skia/include/codec -I../../third_party/skia/src/gpu -I../../third_party/skia/src/sksl -I../../third_party/skia/modules/skottie/include -I../../third_party/vulkan/include -I../../third_party/libwebm/source -I../../third_party/protobuf/src -Igen/protoc_out -I../../third_party/leveldatabase -I../../third_party/leveldatabase/src -I../../third_party/leveldatabase/src/include -I../../third_party/webrtc_overrides -I../../testing/gtest/include -I../../third_party/webrtc -I../../third_party/webrtc_overrides -I../../third_party/webrtc -Igen/third_party/metrics_proto -I../../third_party/boringssl/src/include -I../../third_party/mesa_headers -I../../third_party/abseil-cpp -I../../v8/include -Igen/v8/include -I../../third_party/angle/src/common/third_party/base -Igen/angle -I../../third_party/brotli/include -fprofile-sample-use=../../chrome/android/profiles/afdo.prof -fno-strict-aliasing --param=ssp-buffer-size=4 -fstack-protector -fno-unwind-tables -fno-asynchronous-unwind-tables -fPIC -pthread -fcolor-diagnostics -fmerge-all-constants -Xclang -mllvm -Xclang -instcombine-lower-dbg-declare=0 -no-canonical-prefixes -flto=thin -fwhole-program-vtables -m64 -march=x86-64 -Wall -Wextra -Wimplicit-fallthrough -Wthread-safety -Wno-missing-field-initializers -Wno-unused-parameter -Wno-c++11-narrowing -Wno-covered-switch-default -Wno-unneeded-internal-declaration -Wno-undefined-var-template -Wno-nonportable-include-path -Wno-user-defined-warnings -Wno-unused-lambda-capture -Wno-null-pointer-arithmetic -Wno-enum-compare-switch -Wno-ignored-pragma-optimize -O2 -fno-ident -fdata-sections -ffunction-sections -fno-omit-frame-pointer -g0 -fsanitize=cfi-vcall -fsanitize-blacklist=../../tools/cfi/blacklist.txt -fsanitize=cfi-icall -fvisibility=hidden -Wheader-hygiene -Wstring-conversion -Wtautological-overlap-compare -Wshadow -Wexit-time-destructors -Wno-unused-function -Wno-unused-local-typedefs -I/usr/include/atk-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/lib/libffi-3.2.1/include -I/usr/include/at-spi2-atk/2.0 -I/usr/include/at-spi-2.0 -I/usr/include/dbus-1.0 -I/usr/lib/dbus-1.0/include -I/usr/include/at-spi-2.0 -I/usr/include/dbus-1.0 -I/usr/lib/dbus-1.0/include -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/lib/libffi-3.2.1/include -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/lib/libffi-3.2.1/include -I/usr/include/fribidi -I/usr/include/cairo -I/usr/include/pixman-1 -I/usr/include/libpng16 -I/usr/include/harfbuzz -I/usr/include/uuid -Wno-shorten-64-to-32 -Wno-header-guard -I/usr/include/nss -I/usr/include/nspr -I/usr/include/dbus-1.0 -I/usr/lib/dbus-1.0/include -std=c++14 -fno-exceptions -fno-rtti -fvisibility-inlines-hidden -D_FORTIFY_SOURCE=2 -D__DATE__=  -D__TIME__=  -D__TIMESTAMP__= -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector-strong -Wno-builtin-macro-redefined -c gen/content/browser/browser_jumbo_7.cc -o obj/content/browser/browser/browser_jumbo_7.o\nclang++: error: unable to execute command: Killed\nclang++: error: clang frontend command failed due to signal (use -v to see invocation)\nclang version 7.0.1 (tags/RELEASE_701/final)\nTarget: x86_64-pc-linux-gnu\nThread model: posix\nInstalledDir: /usr/bin\nclang++: note: diagnostic msg: PLEASE submit a bug report to  and include the crash backtrace, preprocessed source, and associated run script.\nclang++: note: diagnostic msg: \n\nPLEASE ATTACH THE FOLLOWING FILES TO THE BUG REPORT:\nPreprocessed source(s) and associated run script(s) are located at:\nclang++: note: diagnostic msg: /tmp/browser_jumbo_7-6a0b3b.cpp\nclang++: note: diagnostic msg: /tmp/browser_jumbo_7-6a0b3b.sh\nclang++: note: diagnostic msg: \n\n[15368/17722] CXX obj/content/browser/browser/browser_jumbo_5.o\nninja: build stopped: subcommand failed.\n==> FEL:  Ett fel uppstod i build().\n    Avbryter...\n\n$ cat /tmp/browser_jumbo_7-6a0b3b.sh\n #Crash reproducer for clang version 7.0.1 (tags/RELEASE_701/final)\n #Driver args: \"--driver-mode=g++\" \"-fprofile-sample-use=../../chrome/android/profiles/afdo.prof\" \"-fno-strict-aliasing\" \"--param\" \"ssp-buffer-size=4\" \"-fstack-protector\" \"-fno-unwind-tables\" \"-fno-asynchronous-unwind-tables\" \"-fPIC\" \"-pthread\" \"-fcolor-diagnostics\" \"-fmerge-all-constants\" \"-Xclang\" \"-mllvm\" \"-Xclang\" \"-instcombine-lower-dbg-declare=0\" \"-no-canonical-prefixes\" \"-flto=thin\" \"-fwhole-program-vtables\" \"-m64\" \"-march=x86-64\" \"-Wall\" \"-Wextra\" \"-Wimplicit-fallthrough\" \"-Wthread-safety\" \"-Wno-missing-field-initializers\" \"-Wno-unused-parameter\" \"-Wno-c++11-narrowing\" \"-Wno-covered-switch-default\" \"-Wno-unneeded-internal-declaration\" \"-Wno-undefined-var-template\" \"-Wno-nonportable-include-path\" \"-Wno-user-defined-warnings\" \"-Wno-unused-lambda-capture\" \"-Wno-null-pointer-arithmetic\" \"-Wno-enum-compare-switch\" \"-Wno-ignored-pragma-optimize\" \"-O2\" \"-Qn\" \"-fdata-sections\" \"-ffunction-sections\" \"-fno-omit-frame-pointer\" \"-g0\" \"-fsanitize=cfi-vcall\" \"-fsanitize-blacklist=../../tools/cfi/blacklist.txt\" \"-fsanitize=cfi-icall\" \"-fvisibility=hidden\" \"-Wheader-hygiene\" \"-Wstring-conversion\" \"-Wtautological-overlap-compare\" \"-Wshadow\" \"-Wexit-time-destructors\" \"-Wno-unused-function\" \"-Wno-unused-local-typedefs\" \"-Wno-shorten-64-to-32\" \"-Wno-header-guard\" \"-std=c++14\" \"-fno-exceptions\" \"-fno-rtti\" \"-fvisibility-inlines-hidden\" \"-march=x86-64\" \"-mtune=generic\" \"-O2\" \"-pipe\" \"-fstack-protector-strong\" \"-Wno-builtin-macro-redefined\" \"-D\" \"ENABLE_SCREEN_CAPTURE=1\" \"-D\" \"V8_DEPRECATION_WARNINGS\" \"-D\" \"USE_UDEV\" \"-D\" \"USE_AURA=1\" \"-D\" \"USE_GLIB=1\" \"-D\" \"USE_NSS_CERTS=1\" \"-D\" \"USE_X11=1\" \"-D\" \"NO_TCMALLOC\" \"-D\" \"OFFICIAL_BUILD\" \"-D\" \"CHROMIUM_BUILD\" \"-D\" \"_FILE_OFFSET_BITS=64\" \"-D\" \"_LARGEFILE_SOURCE\" \"-D\" \"_LARGEFILE64_SOURCE\" \"-D\" \"NO_UNWIND_TABLES\" \"-D\" \"_GNU_SOURCE\" \"-D\" \"CR_CLANG_REVISION=\\\"344066-1\\\"\" \"-D\" \"STDC_CONSTANT_MACROS\" \"-D\" \"__STDC_FORMAT_MACROS\" \"-D\" \"_FORTIFY_SOURCE=2\" \"-D\" \"NDEBUG\" \"-D\" \"NVALGRIND\" \"-D\" \"DYNAMIC_ANNOTATIONS_ENABLED=0\" \"-D\" \"CONTENT_IMPLEMENTATION\" \"-D\" \"V8_USE_EXTERNAL_STARTUP_DATA\" \"-D\" \"ATK_LIB_DIR=\\\"/usr/lib\\\"\" \"-D\" \"USE_ATK_BRIDGE\" \"-D\" \"ATSPI_MAJOR_VERSION=2\" \"-D\" \"ATSPI_MINOR_VERSION=30\" \"-D\" \"ATSPI_MICRO_VERSION=0\" \"-D\" \"GLIB_VERSION_MAX_ALLOWED=GLIB_VERSION_2_32\" \"-D\" \"GLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_26\" \"-D\" \"GL_GLEXT_PROTOTYPES\" \"-D\" \"USE_GLX\" \"-D\" \"USE_EGL\" \"-D\" \"VK_NO_PROTOTYPES\" \"-D\" \"TOOLKIT_VIEWS=1\" \"-D\" \"USING_SYSTEM_ICU=1\" \"-D\" \"ICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC\" \"-D\" \"UCHAR_TYPE=uint16_t\" \"-D\" \"U_IMPORT=U_EXPORT\" \"-D\" \"GOOGLE_PROTOBUF_NO_RTTI\" \"-D\" \"GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER\" \"-D\" \"HAVE_PTHREAD\" \"-D\" \"SK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS\" \"-D\" \"SK_HAS_PNG_LIBRARY\" \"-D\" \"SK_HAS_WEBP_LIBRARY\" \"-D\" \"SK_HAS_JPEG_LIBRARY\" \"-D\" \"SK_VULKAN_HEADER=\\\"../../skia/config/SkVulkanConfig.h\\\"\" \"-D\" \"SK_VULKAN=1\" \"-D\" \"SK_SUPPORT_GPU=1\" \"-D\" \"SK_GPU_WORKAROUNDS_HEADER=\\\"gpu/config/gpu_driver_bug_workaround_autogen.h\\\"\" \"-D\" \"VK_NO_PROTOTYPES\" \"-D\" \"LEVELDB_PLATFORM_CHROMIUM=1\" \"-D\" \"LEVELDB_PLATFORM_CHROMIUM=1\" \"-D\" \"WEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=0\" \"-D\" \"WEBRTC_CHROMIUM_BUILD\" \"-D\" \"WEBRTC_POSIX\" \"-D\" \"WEBRTC_LINUX\" \"-D\" \"ABSL_ALLOCATOR_NOTHROW=1\" \"-D\" \"NO_MAIN_THREAD_WRAPPING\" \"-D\" \"V8_DEPRECATION_WARNINGS\" \"-D\" \"AUDIO_PROCESSING_IN_AUDIO_SERVICE\" \"-D\" \"SQLITE_ENABLE_FTS3\" \"-D\" \"SQLITE_DISABLE_FTS3_UNICODE\" \"-D\" \"SQLITE_DISABLE_FTS4_DEFERRED\" \"-D\" \"SQLITE_ENABLE_ICU\" \"-D\" \"SQLITE_SECURE_DELETE\" \"-D\" \"SQLITE_THREADSAFE=1\" \"-D\" \"SQLITE_MAX_WORKER_THREADS=0\" \"-D\" \"SQLITE_MAX_MMAP_SIZE=268435456\" \"-D\" \"SQLITE_DEFAULT_FILE_PERMISSIONS=0600\" \"-D\" \"SQLITE_DEFAULT_LOOKASIDE=0,0\" \"-D\" \"SQLITE_DEFAULT_MEMSTATUS=1\" \"-D\" \"SQLITE_DEFAULT_PAGE_SIZE=4096\" \"-D\" \"SQLITE_DEFAULT_PCACHE_INITSZ=0\" \"-D\" \"SQLITE_LIKE_DOESNT_MATCH_BLOBS\" \"-D\" \"SQLITE_OMIT_DEPRECATED\" \"-D\" \"SQLITE_OMIT_PROGRESS_CALLBACK\" \"-D\" \"SQLITE_OMIT_SHARED_CACHE\" \"-D\" \"SQLITE_USE_ALLOCA\" \"-D\" \"SQLITE_OMIT_AUTOINIT\" \"-D\" \"SQLITE_OMIT_AUTORESET\" \"-D\" \"SQLITE_OMIT_COMPILEOPTION_DIAGS\" \"-D\" \"SQLITE_OMIT_COMPLETE\" \"-D\" \"SQLITE_OMIT_DECLTYPE\" \"-D\" \"SQLITE_OMIT_GET_TABLE\" \"-D\" \"SQLITE_OMIT_LOAD_EXTENSION\" \"-D\" \"SQLITE_OMIT_TCL_VARIABLE\" \"-D\" \"SQLITE_OMIT_TRACE\" \"-D\" \"SQLITE_OMIT_UPSERT\" \"-D\" \"SQLITE_OMIT_WINDOWFUNC\" \"-D\" \"SQLITE_HAVE_ISNAN\" \"-D\" \"SQLITE_ENABLE_LOCKING_STYLE=0\" \"-D\" \"USE_SYSTEM_ZLIB=1\" \"-I\" \".\" \"-I\" \"../..\" \"-I\" \"gen\" \"-I\" \"gen/shim_headers/libevent_shim\" \"-I\" \"gen/shim_headers/icui18n_shim\" \"-I\" \"gen/shim_headers/icuuc_shim\" \"-I\" \"gen/shim_headers/zlib_shim\" \"-I\" \"gen/shim_headers/libwebp_shim\" \"-I\" \"gen/shim_headers/libdrm_shim\" \"-I\" \"gen/shim_headers/re2_shim\" \"-I\" \"../../third_party/khronos\" \"-I\" \"../../gpu\" \"-I\" \"../../third_party/libyuv/include\" \"-I\" \"../../third_party/vulkan/include\" \"-I\" \"gen/shim_headers/ffmpeg_shim\" \"-I\" \"gen/shim_headers/libvpx_shim\" \"-I\" \"gen/shim_headers/snappy_shim\" \"-I\" \"gen/shim_headers/opus_shim\" \"-I\" \"gen/shim_headers/minizip_shim\" \"-I\" \"gen/shim_headers/flac_shim\" \"-I\" \"../../third_party/ced/src\" \"-I\" \"../../third_party/protobuf/src\" \"-I\" \"../../skia/config\" \"-I\" \"../../skia/ext\" \"-I\" \"../../third_party/skia/include/c\" \"-I\" \"../../third_party/skia/include/config\" \"-I\" \"../../third_party/skia/include/core\" \"-I\" \"../../third_party/skia/include/docs\" \"-I\" \"../../third_party/skia/include/effects\" \"-I\" \"../../third_party/skia/include/encode\" \"-I\" \"../../third_party/skia/include/gpu\" \"-I\" \"../../third_party/skia/include/pathops\" \"-I\" \"../../third_party/skia/include/ports\" \"-I\" \"../../third_party/skia/include/utils\" \"-I\" \"../../third_party/vulkan/include\" \"-I\" \"../../third_party/skia/third_party/vulkanmemoryallocator\" \"-I\" \"../../third_party/skia/include/codec\" \"-I\" \"../../third_party/skia/src/gpu\" \"-I\" \"../../third_party/skia/src/sksl\" \"-I\" \"../../third_party/skia/modules/skottie/include\" \"-I\" \"../../third_party/vulkan/include\" \"-I\" \"../../third_party/libwebm/source\" \"-I\" \"../../third_party/protobuf/src\" \"-I\" \"gen/protoc_out\" \"-I\" \"../../third_party/leveldatabase\" \"-I\" \"../../third_party/leveldatabase/src\" \"-I\" \"../../third_party/leveldatabase/src/include\" \"-I\" \"../../third_party/webrtc_overrides\" \"-I\" \"../../testing/gtest/include\" \"-I\" \"../../third_party/webrtc\" \"-I\" \"../../third_party/webrtc_overrides\" \"-I\" \"../../third_party/webrtc\" \"-I\" \"gen/third_party/metrics_proto\" \"-I\" \"../../third_party/boringssl/src/include\" \"-I\" \"../../third_party/mesa_headers\" \"-I\" \"../../third_party/abseil-cpp\" \"-I\" \"../../v8/include\" \"-I\" \"gen/v8/include\" \"-I\" \"../../third_party/angle/src/common/third_party/base\" \"-I\" \"gen/angle\" \"-I\" \"../../third_party/brotli/include\" \"-I\" \"/usr/include/atk-1.0\" \"-I\" \"/usr/include/glib-2.0\" \"-I\" \"/usr/lib/glib-2.0/include\" \"-I\" \"/usr/lib/libffi-3.2.1/include\" \"-I\" \"/usr/include/at-spi2-atk/2.0\" \"-I\" \"/usr/include/at-spi-2.0\" \"-I\" \"/usr/include/dbus-1.0\" \"-I\" \"/usr/lib/dbus-1.0/include\" \"-I\" \"/usr/include/at-spi-2.0\" \"-I\" \"/usr/include/dbus-1.0\" \"-I\" \"/usr/lib/dbus-1.0/include\" \"-I\" \"/usr/include/glib-2.0\" \"-I\" \"/usr/lib/glib-2.0/include\" \"-I\" \"/usr/include/glib-2.0\" \"-I\" \"/usr/lib/glib-2.0/include\" \"-I\" \"/usr/lib/libffi-3.2.1/include\" \"-I\" \"/usr/include/pango-1.0\" \"-I\" \"/usr/include/glib-2.0\" \"-I\" \"/usr/lib/glib-2.0/include\" \"-I\" \"/usr/lib/libffi-3.2.1/include\" \"-I\" \"/usr/include/fribidi\" \"-I\" \"/usr/include/cairo\" \"-I\" \"/usr/include/pixman-1\" \"-I\" \"/usr/include/libpng16\" \"-I\" \"/usr/include/harfbuzz\" \"-I\" \"/usr/include/uuid\" \"-I\" \"/usr/include/nss\" \"-I\" \"/usr/include/nspr\" \"-I\" \"/usr/include/dbus-1.0\" \"-I\" \"/usr/lib/dbus-1.0/include\" \"-D\" \"_FORTIFY_SOURCE=2\" \"-D\" \"__DATE=\" \"-D\" \"TIME=\" \"-D\" \"TIMESTAMP=\" \"-c\" \"-o\" \"obj/content/browser/browser/browser_jumbo_7.o\" \"gen/content/browser/browser_jumbo_7.cc\"\nOriginal command:  \"/usr/bin/clang++\" \"-cc1\" \"-triple\" \"x86_64-pc-linux-gnu\" \"-emit-llvm-bc\" \"-flto=thin\" \"-flto-unit\" \"-disable-free\" \"-disable-llvm-verifier\" \"-discard-value-names\" \"-main-file-name\" \"browser_jumbo_7.cc\" \"-mrelocation-model\" \"pic\" \"-pic-level\" \"2\" \"-mthread-model\" \"posix\" \"-fmerge-all-constants\" \"-mdisable-fp-elim\" \"-relaxed-aliasing\" \"-fmath-errno\" \"-masm-verbose\" \"-mconstructor-aliases\" \"-fuse-init-array\" \"-target-cpu\" \"x86-64\" \"-dwarf-column-info\" \"-debugger-tuning=gdb\" \"-momit-leaf-frame-pointer\" \"-ffunction-sections\" \"-fdata-sections\" \"-coverage-notes-file\" \"/home/sdb/src/ungoogled-chromium/src/chromium-71.0.3578.98/out/Default/obj/content/browser/browser/browser_jumbo_7.gcno\" \"-resource-dir\" \"/usr/lib/clang/7.0.1\" \"-D\" \"ENABLE_SCREEN_CAPTURE=1\" \"-D\" \"V8_DEPRECATION_WARNINGS\" \"-D\" \"USE_UDEV\" \"-D\" \"USE_AURA=1\" \"-D\" \"USE_GLIB=1\" \"-D\" \"USE_NSS_CERTS=1\" \"-D\" \"USE_X11=1\" \"-D\" \"NO_TCMALLOC\" \"-D\" \"OFFICIAL_BUILD\" \"-D\" \"CHROMIUM_BUILD\" \"-D\" \"_FILE_OFFSET_BITS=64\" \"-D\" \"_LARGEFILE_SOURCE\" \"-D\" \"_LARGEFILE64_SOURCE\" \"-D\" \"NO_UNWIND_TABLES\" \"-D\" \"_GNU_SOURCE\" \"-D\" \"CR_CLANG_REVISION=\\\"344066-1\\\"\" \"-D\" \"STDC_CONSTANT_MACROS\" \"-D\" \"__STDC_FORMAT_MACROS\" \"-D\" \"_FORTIFY_SOURCE=2\" \"-D\" \"NDEBUG\" \"-D\" \"NVALGRIND\" \"-D\" \"DYNAMIC_ANNOTATIONS_ENABLED=0\" \"-D\" \"CONTENT_IMPLEMENTATION\" \"-D\" \"V8_USE_EXTERNAL_STARTUP_DATA\" \"-D\" \"ATK_LIB_DIR=\\\"/usr/lib\\\"\" \"-D\" \"USE_ATK_BRIDGE\" \"-D\" \"ATSPI_MAJOR_VERSION=2\" \"-D\" \"ATSPI_MINOR_VERSION=30\" \"-D\" \"ATSPI_MICRO_VERSION=0\" \"-D\" \"GLIB_VERSION_MAX_ALLOWED=GLIB_VERSION_2_32\" \"-D\" \"GLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_26\" \"-D\" \"GL_GLEXT_PROTOTYPES\" \"-D\" \"USE_GLX\" \"-D\" \"USE_EGL\" \"-D\" \"VK_NO_PROTOTYPES\" \"-D\" \"TOOLKIT_VIEWS=1\" \"-D\" \"USING_SYSTEM_ICU=1\" \"-D\" \"ICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC\" \"-D\" \"UCHAR_TYPE=uint16_t\" \"-D\" \"U_IMPORT=U_EXPORT\" \"-D\" \"GOOGLE_PROTOBUF_NO_RTTI\" \"-D\" \"GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER\" \"-D\" \"HAVE_PTHREAD\" \"-D\" \"SK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS\" \"-D\" \"SK_HAS_PNG_LIBRARY\" \"-D\" \"SK_HAS_WEBP_LIBRARY\" \"-D\" \"SK_HAS_JPEG_LIBRARY\" \"-D\" \"SK_VULKAN_HEADER=\\\"../../skia/config/SkVulkanConfig.h\\\"\" \"-D\" \"SK_VULKAN=1\" \"-D\" \"SK_SUPPORT_GPU=1\" \"-D\" \"SK_GPU_WORKAROUNDS_HEADER=\\\"gpu/config/gpu_driver_bug_workaround_autogen.h\\\"\" \"-D\" \"VK_NO_PROTOTYPES\" \"-D\" \"LEVELDB_PLATFORM_CHROMIUM=1\" \"-D\" \"LEVELDB_PLATFORM_CHROMIUM=1\" \"-D\" \"WEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=0\" \"-D\" \"WEBRTC_CHROMIUM_BUILD\" \"-D\" \"WEBRTC_POSIX\" \"-D\" \"WEBRTC_LINUX\" \"-D\" \"ABSL_ALLOCATOR_NOTHROW=1\" \"-D\" \"NO_MAIN_THREAD_WRAPPING\" \"-D\" \"V8_DEPRECATION_WARNINGS\" \"-D\" \"AUDIO_PROCESSING_IN_AUDIO_SERVICE\" \"-D\" \"SQLITE_ENABLE_FTS3\" \"-D\" \"SQLITE_DISABLE_FTS3_UNICODE\" \"-D\" \"SQLITE_DISABLE_FTS4_DEFERRED\" \"-D\" \"SQLITE_ENABLE_ICU\" \"-D\" \"SQLITE_SECURE_DELETE\" \"-D\" \"SQLITE_THREADSAFE=1\" \"-D\" \"SQLITE_MAX_WORKER_THREADS=0\" \"-D\" \"SQLITE_MAX_MMAP_SIZE=268435456\" \"-D\" \"SQLITE_DEFAULT_FILE_PERMISSIONS=0600\" \"-D\" \"SQLITE_DEFAULT_LOOKASIDE=0,0\" \"-D\" \"SQLITE_DEFAULT_MEMSTATUS=1\" \"-D\" \"SQLITE_DEFAULT_PAGE_SIZE=4096\" \"-D\" \"SQLITE_DEFAULT_PCACHE_INITSZ=0\" \"-D\" \"SQLITE_LIKE_DOESNT_MATCH_BLOBS\" \"-D\" \"SQLITE_OMIT_DEPRECATED\" \"-D\" \"SQLITE_OMIT_PROGRESS_CALLBACK\" \"-D\" \"SQLITE_OMIT_SHARED_CACHE\" \"-D\" \"SQLITE_USE_ALLOCA\" \"-D\" \"SQLITE_OMIT_AUTOINIT\" \"-D\" \"SQLITE_OMIT_AUTORESET\" \"-D\" \"SQLITE_OMIT_COMPILEOPTION_DIAGS\" \"-D\" \"SQLITE_OMIT_COMPLETE\" \"-D\" \"SQLITE_OMIT_DECLTYPE\" \"-D\" \"SQLITE_OMIT_GET_TABLE\" \"-D\" \"SQLITE_OMIT_LOAD_EXTENSION\" \"-D\" \"SQLITE_OMIT_TCL_VARIABLE\" \"-D\" \"SQLITE_OMIT_TRACE\" \"-D\" \"SQLITE_OMIT_UPSERT\" \"-D\" \"SQLITE_OMIT_WINDOWFUNC\" \"-D\" \"SQLITE_HAVE_ISNAN\" \"-D\" \"SQLITE_ENABLE_LOCKING_STYLE=0\" \"-D\" \"USE_SYSTEM_ZLIB=1\" \"-I\" \".\" \"-I\" \"../..\" \"-I\" \"gen\" \"-I\" \"gen/shim_headers/libevent_shim\" \"-I\" \"gen/shim_headers/icui18n_shim\" \"-I\" \"gen/shim_headers/icuuc_shim\" \"-I\" \"gen/shim_headers/zlib_shim\" \"-I\" \"gen/shim_headers/libwebp_shim\" \"-I\" \"gen/shim_headers/libdrm_shim\" \"-I\" \"gen/shim_headers/re2_shim\" \"-I\" \"../../third_party/khronos\" \"-I\" \"../../gpu\" \"-I\" \"../../third_party/libyuv/include\" \"-I\" \"../../third_party/vulkan/include\" \"-I\" \"gen/shim_headers/ffmpeg_shim\" \"-I\" \"gen/shim_headers/libvpx_shim\" \"-I\" \"gen/shim_headers/snappy_shim\" \"-I\" \"gen/shim_headers/opus_shim\" \"-I\" \"gen/shim_headers/minizip_shim\" \"-I\" \"gen/shim_headers/flac_shim\" \"-I\" \"../../third_party/ced/src\" \"-I\" \"../../third_party/protobuf/src\" \"-I\" \"../../skia/config\" \"-I\" \"../../skia/ext\" \"-I\" \"../../third_party/skia/include/c\" \"-I\" \"../../third_party/skia/include/config\" \"-I\" \"../../third_party/skia/include/core\" \"-I\" \"../../third_party/skia/include/docs\" \"-I\" \"../../third_party/skia/include/effects\" \"-I\" \"../../third_party/skia/include/encode\" \"-I\" \"../../third_party/skia/include/gpu\" \"-I\" \"../../third_party/skia/include/pathops\" \"-I\" \"../../third_party/skia/include/ports\" \"-I\" \"../../third_party/skia/include/utils\" \"-I\" \"../../third_party/vulkan/include\" \"-I\" \"../../third_party/skia/third_party/vulkanmemoryallocator\" \"-I\" \"../../third_party/skia/include/codec\" \"-I\" \"../../third_party/skia/src/gpu\" \"-I\" \"../../third_party/skia/src/sksl\" \"-I\" \"../../third_party/skia/modules/skottie/include\" \"-I\" \"../../third_party/vulkan/include\" \"-I\" \"../../third_party/libwebm/source\" \"-I\" \"../../third_party/protobuf/src\" \"-I\" \"gen/protoc_out\" \"-I\" \"../../third_party/leveldatabase\" \"-I\" \"../../third_party/leveldatabase/src\" \"-I\" \"../../third_party/leveldatabase/src/include\" \"-I\" \"../../third_party/webrtc_overrides\" \"-I\" \"../../testing/gtest/include\" \"-I\" \"../../third_party/webrtc\" \"-I\" \"../../third_party/webrtc_overrides\" \"-I\" \"../../third_party/webrtc\" \"-I\" \"gen/third_party/metrics_proto\" \"-I\" \"../../third_party/boringssl/src/include\" \"-I\" \"../../third_party/mesa_headers\" \"-I\" \"../../third_party/abseil-cpp\" \"-I\" \"../../v8/include\" \"-I\" \"gen/v8/include\" \"-I\" \"../../third_party/angle/src/common/third_party/base\" \"-I\" \"gen/angle\" \"-I\" \"../../third_party/brotli/include\" \"-I\" \"/usr/include/atk-1.0\" \"-I\" \"/usr/include/glib-2.0\" \"-I\" \"/usr/lib/glib-2.0/include\" \"-I\" \"/usr/lib/libffi-3.2.1/include\" \"-I\" \"/usr/include/at-spi2-atk/2.0\" \"-I\" \"/usr/include/at-spi-2.0\" \"-I\" \"/usr/include/dbus-1.0\" \"-I\" \"/usr/lib/dbus-1.0/include\" \"-I\" \"/usr/include/at-spi-2.0\" \"-I\" \"/usr/include/dbus-1.0\" \"-I\" \"/usr/lib/dbus-1.0/include\" \"-I\" \"/usr/include/glib-2.0\" \"-I\" \"/usr/lib/glib-2.0/include\" \"-I\" \"/usr/include/glib-2.0\" \"-I\" \"/usr/lib/glib-2.0/include\" \"-I\" \"/usr/lib/libffi-3.2.1/include\" \"-I\" \"/usr/include/pango-1.0\" \"-I\" \"/usr/include/glib-2.0\" \"-I\" \"/usr/lib/glib-2.0/include\" \"-I\" \"/usr/lib/libffi-3.2.1/include\" \"-I\" \"/usr/include/fribidi\" \"-I\" \"/usr/include/cairo\" \"-I\" \"/usr/include/pixman-1\" \"-I\" \"/usr/include/libpng16\" \"-I\" \"/usr/include/harfbuzz\" \"-I\" \"/usr/include/uuid\" \"-I\" \"/usr/include/nss\" \"-I\" \"/usr/include/nspr\" \"-I\" \"/usr/include/dbus-1.0\" \"-I\" \"/usr/lib/dbus-1.0/include\" \"-D\" \"_FORTIFY_SOURCE=2\" \"-D\" \"__DATE=\" \"-D\" \"TIME=\" \"-D\" \"TIMESTAMP=\" \"-internal-isystem\" \"/usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/8.2.1/../../../../include/c++/8.2.1\" \"-internal-isystem\" \"/usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/8.2.1/../../../../include/c++/8.2.1/x86_64-pc-linux-gnu\" \"-internal-isystem\" \"/usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/8.2.1/../../../../include/c++/8.2.1/backward\" \"-internal-isystem\" \"/usr/local/include\" \"-internal-isystem\" \"/usr/lib/clang/7.0.1/include\" \"-internal-externc-isystem\" \"/include\" \"-internal-externc-isystem\" \"/usr/include\" \"-O2\" \"-Wall\" \"-Wextra\" \"-Wimplicit-fallthrough\" \"-Wthread-safety\" \"-Wno-missing-field-initializers\" \"-Wno-unused-parameter\" \"-Wno-c++11-narrowing\" \"-Wno-covered-switch-default\" \"-Wno-unneeded-internal-declaration\" \"-Wno-undefined-var-template\" \"-Wno-nonportable-include-path\" \"-Wno-user-defined-warnings\" \"-Wno-unused-lambda-capture\" \"-Wno-null-pointer-arithmetic\" \"-Wno-enum-compare-switch\" \"-Wno-ignored-pragma-optimize\" \"-Wheader-hygiene\" \"-Wstring-conversion\" \"-Wtautological-overlap-compare\" \"-Wshadow\" \"-Wexit-time-destructors\" \"-Wno-unused-function\" \"-Wno-unused-local-typedefs\" \"-Wno-shorten-64-to-32\" \"-Wno-header-guard\" \"-Wno-builtin-macro-redefined\" \"-std=c++14\" \"-fdeprecated-macro\" \"-fdebug-compilation-dir\" \"/home/sdb/src/ungoogled-chromium/src/chromium-71.0.3578.98/out/Default\" \"-ferror-limit\" \"19\" \"-fmessage-length\" \"0\" \"-fvisibility\" \"hidden\" \"-fvisibility-inlines-hidden\" \"-fsanitize=cfi-icall,cfi-vcall\" \"-fsanitize-trap=cfi-icall,cfi-vcall\" \"-fsanitize-blacklist=/usr/lib/clang/7.0.1/share/cfi_blacklist.txt\" \"-fsanitize-blacklist=../../tools/cfi/blacklist.txt\" \"-fdepfile-entry=../../tools/cfi/blacklist.txt\" \"-pthread\" \"-stack-protector\" \"2\" \"-stack-protector-buffer-size\" \"4\" \"-fprofile-sample-use=../../chrome/android/profiles/afdo.prof\" \"-fno-rtti\" \"-fobjc-runtime=gcc\" \"-Qn\" \"-fdiagnostics-show-option\" \"-fcolor-diagnostics\" \"-vectorize-loops\" \"-vectorize-slp\" \"-mllvm\" \"-instcombine-lower-dbg-declare=0\" \"-o\" \"obj/content/browser/browser/browser_jumbo_7.o\" \"-x\" \"c++\" \"gen/content/browser/browser_jumbo_7.cc\" \"-fwhole-program-vtables\" \"-faddrsig\"\n\"/usr/bin/clang++\" \"-cc1\" \"-triple\" \"x86_64-pc-linux-gnu\" \"-emit-llvm-bc\" \"-flto=thin\" \"-flto-unit\" \"-disable-free\" \"-disable-llvm-verifier\" \"-discard-value-names\" \"-main-file-name\" \"browser_jumbo_7.cc\" \"-mrelocation-model\" \"pic\" \"-pic-level\" \"2\" \"-mthread-model\" \"posix\" \"-fmerge-all-constants\" \"-mdisable-fp-elim\" \"-relaxed-aliasing\" \"-fmath-errno\" \"-masm-verbose\" \"-mconstructor-aliases\" \"-fuse-init-array\" \"-target-cpu\" \"x86-64\" \"-dwarf-column-info\" \"-debugger-tuning=gdb\" \"-momit-leaf-frame-pointer\" \"-ffunction-sections\" \"-fdata-sections\" \"-coverage-notes-file\" \"/home/sdb/src/ungoogled-chromium/src/chromium-71.0.3578.98/out/Default/obj/content/browser/browser/browser_jumbo_7.gcno\" \"-D\" \"ENABLE_SCREEN_CAPTURE=1\" \"-D\" \"V8_DEPRECATION_WARNINGS\" \"-D\" \"USE_UDEV\" \"-D\" \"USE_AURA=1\" \"-D\" \"USE_GLIB=1\" \"-D\" \"USE_NSS_CERTS=1\" \"-D\" \"USE_X11=1\" \"-D\" \"NO_TCMALLOC\" \"-D\" \"OFFICIAL_BUILD\" \"-D\" \"CHROMIUM_BUILD\" \"-D\" \"_FILE_OFFSET_BITS=64\" \"-D\" \"_LARGEFILE_SOURCE\" \"-D\" \"_LARGEFILE64_SOURCE\" \"-D\" \"NO_UNWIND_TABLES\" \"-D\" \"_GNU_SOURCE\" \"-D\" \"CR_CLANG_REVISION=\\\"344066-1\\\"\" \"-D\" \"STDC_CONSTANT_MACROS\" \"-D\" \"__STDC_FORMAT_MACROS\" \"-D\" \"_FORTIFY_SOURCE=2\" \"-D\" \"NDEBUG\" \"-D\" \"NVALGRIND\" \"-D\" \"DYNAMIC_ANNOTATIONS_ENABLED=0\" \"-D\" \"CONTENT_IMPLEMENTATION\" \"-D\" \"V8_USE_EXTERNAL_STARTUP_DATA\" \"-D\" \"ATK_LIB_DIR=\\\"/usr/lib\\\"\" \"-D\" \"USE_ATK_BRIDGE\" \"-D\" \"ATSPI_MAJOR_VERSION=2\" \"-D\" \"ATSPI_MINOR_VERSION=30\" \"-D\" \"ATSPI_MICRO_VERSION=0\" \"-D\" \"GLIB_VERSION_MAX_ALLOWED=GLIB_VERSION_2_32\" \"-D\" \"GLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_26\" \"-D\" \"GL_GLEXT_PROTOTYPES\" \"-D\" \"USE_GLX\" \"-D\" \"USE_EGL\" \"-D\" \"VK_NO_PROTOTYPES\" \"-D\" \"TOOLKIT_VIEWS=1\" \"-D\" \"USING_SYSTEM_ICU=1\" \"-D\" \"ICU_UTIL_DATA_IMPL=ICU_UTIL_DATA_STATIC\" \"-D\" \"UCHAR_TYPE=uint16_t\" \"-D\" \"U_IMPORT=U_EXPORT\" \"-D\" \"GOOGLE_PROTOBUF_NO_RTTI\" \"-D\" \"GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER\" \"-D\" \"HAVE_PTHREAD\" \"-D\" \"SK_IGNORE_LINEONLY_AA_CONVEX_PATH_OPTS\" \"-D\" \"SK_HAS_PNG_LIBRARY\" \"-D\" \"SK_HAS_WEBP_LIBRARY\" \"-D\" \"SK_HAS_JPEG_LIBRARY\" \"-D\" \"SK_VULKAN_HEADER=\\\"../../skia/config/SkVulkanConfig.h\\\"\" \"-D\" \"SK_VULKAN=1\" \"-D\" \"SK_SUPPORT_GPU=1\" \"-D\" \"SK_GPU_WORKAROUNDS_HEADER=\\\"gpu/config/gpu_driver_bug_workaround_autogen.h\\\"\" \"-D\" \"VK_NO_PROTOTYPES\" \"-D\" \"LEVELDB_PLATFORM_CHROMIUM=1\" \"-D\" \"LEVELDB_PLATFORM_CHROMIUM=1\" \"-D\" \"WEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=0\" \"-D\" \"WEBRTC_CHROMIUM_BUILD\" \"-D\" \"WEBRTC_POSIX\" \"-D\" \"WEBRTC_LINUX\" \"-D\" \"ABSL_ALLOCATOR_NOTHROW=1\" \"-D\" \"NO_MAIN_THREAD_WRAPPING\" \"-D\" \"V8_DEPRECATION_WARNINGS\" \"-D\" \"AUDIO_PROCESSING_IN_AUDIO_SERVICE\" \"-D\" \"SQLITE_ENABLE_FTS3\" \"-D\" \"SQLITE_DISABLE_FTS3_UNICODE\" \"-D\" \"SQLITE_DISABLE_FTS4_DEFERRED\" \"-D\" \"SQLITE_ENABLE_ICU\" \"-D\" \"SQLITE_SECURE_DELETE\" \"-D\" \"SQLITE_THREADSAFE=1\" \"-D\" \"SQLITE_MAX_WORKER_THREADS=0\" \"-D\" \"SQLITE_MAX_MMAP_SIZE=268435456\" \"-D\" \"SQLITE_DEFAULT_FILE_PERMISSIONS=0600\" \"-D\" \"SQLITE_DEFAULT_LOOKASIDE=0,0\" \"-D\" \"SQLITE_DEFAULT_MEMSTATUS=1\" \"-D\" \"SQLITE_DEFAULT_PAGE_SIZE=4096\" \"-D\" \"SQLITE_DEFAULT_PCACHE_INITSZ=0\" \"-D\" \"SQLITE_LIKE_DOESNT_MATCH_BLOBS\" \"-D\" \"SQLITE_OMIT_DEPRECATED\" \"-D\" \"SQLITE_OMIT_PROGRESS_CALLBACK\" \"-D\" \"SQLITE_OMIT_SHARED_CACHE\" \"-D\" \"SQLITE_USE_ALLOCA\" \"-D\" \"SQLITE_OMIT_AUTOINIT\" \"-D\" \"SQLITE_OMIT_AUTORESET\" \"-D\" \"SQLITE_OMIT_COMPILEOPTION_DIAGS\" \"-D\" \"SQLITE_OMIT_COMPLETE\" \"-D\" \"SQLITE_OMIT_DECLTYPE\" \"-D\" \"SQLITE_OMIT_GET_TABLE\" \"-D\" \"SQLITE_OMIT_LOAD_EXTENSION\" \"-D\" \"SQLITE_OMIT_TCL_VARIABLE\" \"-D\" \"SQLITE_OMIT_TRACE\" \"-D\" \"SQLITE_OMIT_UPSERT\" \"-D\" \"SQLITE_OMIT_WINDOWFUNC\" \"-D\" \"SQLITE_HAVE_ISNAN\" \"-D\" \"SQLITE_ENABLE_LOCKING_STYLE=0\" \"-D\" \"USE_SYSTEM_ZLIB=1\" \"-D\" \"_FORTIFY_SOURCE=2\" \"-D\" \"__DATE=\" \"-D\" \"TIME=\" \"-D\" \"TIMESTAMP=\" \"-O2\" \"-Wall\" \"-Wextra\" \"-Wimplicit-fallthrough\" \"-Wthread-safety\" \"-Wno-missing-field-initializers\" \"-Wno-unused-parameter\" \"-Wno-c++11-narrowing\" \"-Wno-covered-switch-default\" \"-Wno-unneeded-internal-declaration\" \"-Wno-undefined-var-template\" \"-Wno-nonportable-include-path\" \"-Wno-user-defined-warnings\" \"-Wno-unused-lambda-capture\" \"-Wno-null-pointer-arithmetic\" \"-Wno-enum-compare-switch\" \"-Wno-ignored-pragma-optimize\" \"-Wheader-hygiene\" \"-Wstring-conversion\" \"-Wtautological-overlap-compare\" \"-Wshadow\" \"-Wexit-time-destructors\" \"-Wno-unused-function\" \"-Wno-unused-local-typedefs\" \"-Wno-shorten-64-to-32\" \"-Wno-header-guard\" \"-Wno-builtin-macro-redefined\" \"-std=c++14\" \"-fdeprecated-macro\" \"-ferror-limit\" \"19\" \"-fmessage-length\" \"0\" \"-fvisibility\" \"hidden\" \"-fvisibility-inlines-hidden\" \"-fsanitize=cfi-icall,cfi-vcall\" \"-fsanitize-trap=cfi-icall,cfi-vcall\" \"-fsanitize-blacklist=/usr/lib/clang/7.0.1/share/cfi_blacklist.txt\" \"-fsanitize-blacklist=../../tools/cfi/blacklist.txt\" \"-fdepfile-entry=../../tools/cfi/blacklist.txt\" \"-pthread\" \"-stack-protector\" \"2\" \"-stack-protector-buffer-size\" \"4\" \"-fprofile-sample-use=../../chrome/android/profiles/afdo.prof\" \"-fno-rtti\" \"-fobjc-runtime=gcc\" \"-Qn\" \"-fdiagnostics-show-option\" \"-fcolor-diagnostics\" \"-vectorize-loops\" \"-vectorize-slp\" \"-mllvm\" \"-instcombine-lower-dbg-declare=0\" \"-x\" \"c++\" \"browser_jumbo_7-6a0b3b.cpp\" \"-fwhole-program-vtables\" \"-faddrsig\"\n$ file /tmp/browser_jumbo_7-6a0b3b.cpp\n/tmp/browser_jumbo_7-6a0b3b.cpp: C++ source, ASCII text\n$ du -sh /tmp/browser_jumbo_7-6a0b3b.cpp\n47M     /tmp/browser_jumbo_7-6a0b3b.cpp\n/tmp/browser_jumbo_7-6a0b3b.cpp contains this:\n$ head -50 /tmp/browser_jumbo_7-6a0b3b.cpp \n1 \"\"\n1 \"gen/content/browser/browser_jumbo_7.cc\"\n/ This is a Jumbo file. Don't edit. /\n/ Generated with merge_for_jumbo.py. /\nif 0 / expanded by -frewrite-includes /\ninclude \"../../content/browser/frame_host/navigation_controller_impl.cc\"\nendif / expanded by -frewrite-includes /\n5 \"gen/content/browser/browser_jumbo_7.cc\"\n1 \"./../../content/browser/frame_host/navigation_controller_impl.cc\" 1\n// Copyright 2013 The Chromium Authors. All rights reserved.\n// Use of this source code is governed by a BSD-style license that can be\n// found in the LICENSE file.\n/\n * Copyright (C) 2006, 2007, 2008, 2009 Apple Inc. All rights reserved.\n * Copyright (C) 2008 Nokia Corporation and/or its subsidiary(-ies)\n * Copyright (C) 2008, 2009 Torch Mobile Inc. All rights reserved.\n *     (http://www.torchmobile.com/)\n \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n \n * 1.  Redistributions of source code must retain the above copyright\n *     notice, this list of conditions and the following disclaimer.\n * 2.  Redistributions in binary form must reproduce the above copyright\n *     notice, this list of conditions and the following disclaimer in the\n *     documentation and/or other materials provided with the distribution.\n * 3.  Neither the name of Apple Computer, Inc. (\"Apple\") nor the names of\n *     its contributors may be used to endorse or promote products derived\n *     from this software without specific prior written permission.\n \n * THIS SOFTWARE IS PROVIDED BY APPLE AND ITS CONTRIBUTORS \"AS IS\" AND ANY\n * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL APPLE OR ITS CONTRIBUTORS BE LIABLE FOR ANY\n * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nif 0 / expanded by -frewrite-includes /\ninclude \"content/browser/frame_host/navigation_controller_impl.h\"\nendif / expanded by -frewrite-includes /\n36 \"./../../content/browser/frame_host/navigation_controller_impl.cc\"\n``\n. I had 4 gb mem and 4 gb swap. Will try increase to 12 in total... ",
    "Ranguvar": "Have you tried the AUR PKGBUILD?\nThat works for me, though I need to use the old libfdk-aac 0.1.6 not 2.0.0.. ",
    "dackelblut": "Have you tried starting it using gdb? And: self-build kernel?\nFYI: yesterday I successfully built 71.0.3578.98-2 using the buster target on a sid machine. It starts and runs smoothly. . No, I was thinking that your (possible) self-built kernel lacks a symbol (USER_NS) needed for sandbox. But the sandbox error can't be the problem anyway, I get that with vivaldi (based on chromium) too without the browser crashing.\nWhat cpu do you have? Many search results point at older cpus, without newer SSE-Versions.. I don't fully understand the build system details yet, but it seems that chromium can be build using his own copy of ffmpeg or a system-provided one. AV_CODEC_ID_AV1 can be found in avcodec.h, which is part of the package libavcodec-dev (atleast on unstable). If you have that package but it's too old or in the wrong header file, the build fails with the missing include.\nYou could try to force the build system to use chromium's own copy regardless of the system one. But you may end up with dpkg/apt complaining during install because of duplicate files (provided by different packages). Or, you could check wether there's a newer version of libavformat and libavcodec for your system.. ",
    "arichiardi": "Well yes I should be using. Will double check but I thought for a moment the cert was expired for real, would that be possible?. It looks like I have just discovered that I need this for wget in my ubuntu:\n wget --ca-directory /etc/ssl/certs ...\n\nCan it be a difference in openssl configuration for Ubuntu?. @Eloston you have been very hasty in closing this - my Ubuntu is vanilla.\nI am trying now in a VirtualBox VM. In the meantime please have a look at this: https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error/31915123#31915123\nIt seems similar to my error and has to do with urllib.\n. It seems like the VM downloads correctly the package. Definitely something is odd on my end. Thanks for now.. For posterity, when you compile openssl yourself, make sure you set --openssldirs=/etc/ssl in case of Ubuntu so that you reuse your distro certificates. This now works for me.\nThanks @Eloston for you patience and guidance. . ",
    "lipici": "sorry to ask in here this but there is a place where i can see the evolution of ungoogled windows version?\ni know a while ago was a thread where eloston updated the progress with V and X for version 69 but cant find it .\nAnd second question because i dont understand:\nLatest version is 67.0.3396.87-2 and browser is still in development ?\n.  Thanks for the answer bro. Good luck with your project. I see and feel your passion that you put in because i know how it is to hate /dont like something that invade your privacy. I use windows 8.1 and removed everything from it with\u00a0 nlite and i downloaded whatsapp from site and didnt logged in google play store.I mean they can have every site that i log into it and every app that i use but to pay me for that. I think is fair.\u00a0\nOn Thursday, February 21, 2019, 9:25:54 AM GMT+2, Eloston <notifications@github.com> wrote:\n\n@lipici Right now, I don't think there's is anyone working on Windows support., so no issue has been created for it.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n   . @hardhub hardhub can you try again with latest version?.  Sorry if 71 is still the latest one. I believed chromium has the same version like chrome, in this case, 72.\n    On Saturday, March 9, 2019, 12:07:18 PM GMT+2, TCB13 notifications@github.com wrote:  \n@hardhub hardhub can you try again with latest version?\n@lipici what do you mean by \"latest version\", a specific tag or master? Either way, is it even possible to build above 71.0.3578.98-2 under Windows? Seems like there is a lot of broken stuff...\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n   .  Thanks bro. Sad day for fans.\n    On Saturday, March 9, 2019, 1:37:07 PM GMT+2, warmaster345 notifications@github.com wrote:  \n@hardhub hardhub can you try again with latest version?\nI have tried with the latest version, the same error occurred. Windows 10 x64, VS 2017\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n   .  Ahhh, no luck yet. Thanks, bro.\n    On Sunday, March 10, 2019, 2:56:42 AM GMT+2, Maxim notifications@github.com wrote:  \n@hardhub hardhub can you try again with latest version?\nmaster:\nsubprocess.CalledProcessError: Command '['C:\\ungoogled-chromium\\build\\src\\third_party\\git\\usr\\bin\\patch.exe', '-p1', '--ignore-whitespace', '-i', 'C:\\ungoogled-chromium\\build\\src\\ungoogled_packaging\\patches\\\n\\ungoogled-chromium\\windows\\windows-disable-reorder-fix-linking.patch', '-d', 'C:\\ungoogled-chromium\\build\\src', '--no-backup-if-mismatch', '--forward']' returned non-zero exit status 1.\n72.0.3626.122-1\n(Stripping trailing CRs from patch; use --binary to disable.)\npatching file chrome/BUILD.gn\nHunk #2 FAILED at 83.\nHunk #3 succeeded at 309 (offset -3 lines).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n   . ",
    "leo-liar": "You can grab an up-to-date one frome here:\n- [ungoogled-chromium-71.0.3578.98-1_windows.7z][2]\n[2]: https://github.com/macchrome/winchrome/releases/download/v71.0.3578.98-r599034-Win64/ungoogled-chromium-71.0.3578.98-1_windows.7z \"v71.0.3578.98-r599034-Win64\". You can grab an up-to-date one frome here, but please take a look at #657 beforehand!\n- [ungoogled-chromium-71.0.3578.98-1_windows.7z][2]\n[2]: https://github.com/macchrome/winchrome/releases/download/v71.0.3578.98-r599034-Win64/ungoogled-chromium-71.0.3578.98-1_windows.7z \"v71.0.3578.98-r599034-Win64\". ",
    "k2l8m11n2": "\nThis is what it looks in a version I found for Fedora. (What's the difference between an Official Build and a Developer Build BTW?). ",
    "naymapl": "Hey.\nI sorted this issue myself. It was strange but after reinstall ungoogled-chromium and reboot my mac its start runing well. Hope so forever ;) Thanks a lot.. ",
    "joey04": "I advise planning for this sooner rather than later. I have little hope that Google will make any serious concessions on this matter. (Folks can read the thread I linked to, the threads on Reddit, etc. to understand why.)\nI have several points to cover in this post, but first a little about me since I'm new here.\nI'm a Firefox guy who has never built a browser from source. I've been using Chrome on Windows and Chromium on Linux for a few years as a supplement, but I'm much more familiar with the Mozilla way of doing things. As for content filtering, I've twice forked uBlock Origin (uBO), first for XUL (aka Firefox legacy) and now for WebExtensions. It's been a while since I've used regular uBO :)\nI obviously know a lot more about filtering than modifying Chromium. But I've now spent several hours looking into code possibilities. From the readme here I found Bromite with its integrated blocker inherited from the defunct NoChromo code. Csagan5 has done some nice refactoring work, including moving the code from the net component to the chrome component. However, he still has the very simplistic hard-coded header file of 50K+ rules, apparently translated via script from EasyList. (Upon seeing this, I couldn't help but laugh at the irony of Google going this direction with extensions being limited to a single json file of rules.)\nOn the other hand, Brave has a full-fledged filtering engine (though not robust enough for me) but with a heavyweight integration into Chromium. (Understandably, given their grand ambitions of an entirely new online advertising model, along with other features they've added.)\nFor me, assuming my big learning curve and setup of a build environment goes well, I'll probably go with a more Bromite way of doing things to start. Eventually I'd incorporate more robust capabilities, possibly borrowing from the Brave code. Lots of details TBD, of course, but I mention it as food for thought here.\n\nFor those reading this and fretting about their browsing future, I too have some anxiety about the end of robust extensions. (Not just in Chrome; I would expect Mozilla to follow suit eventually, which is another reason I'm here.) It'll be at least a year before the current extension API is phased out of Chromium, so there's plenty of time to prepare. While there won't be any options as desirable as the robust extensions we're accustomed to, we won't be restricted to just a Google or Mozilla browser with crappy filter extensions.\nI advise not putting all your eggs in one basket. A custom Chromium appears to be the best choice to transition to for my primary browser, given its best-possible web compatibility. But another possibility is Firefox forks. I used Pale Moon for several years and can attest to the quality work of Mark Straver and his helpers. He has a clear vision of what he wants his browser to be and has done a good job making it happen. There are inherent drawbacks, unfortunately, like web compatibility, but it's still worth considering, especially since it will always maintain robust XUL extension support. (It'll be easy for me to revive my original uBO fork.)\nI expect I'll continue to have a multi-browser setup. It's TBD what will be primary (for the lion share of browsing), but that's what I intend to figure out in the coming months. Worst-case, I can use regular Chromium with a very limited v3 extension as a supplemental browser starting next year. Like I said before, there are a number of options worth considering.. > Where I could follow your progress on a new Chromium Fork ?\nNowhere. This is a preliminary exploratory time. I can't guarantee I will do anything on Chromium. (The way I wrote it yesterday didn't properly convey that. Sorry about that.)\nAs I wrote yesterday, I've never built a browser. Chromium is a massive codebase with millions of lines of code. And one very important item I didn't mention before is that I would be purchasing a new machine to do this work.\nMy current PC is a Windows 8.1 with hyper-threaded dual-core and 8 GB of RAM. So it's capable of building Chromium, but doing so would abuse the hell out of my hardware. I really like my highly-customized Windows setup, in large part because 8.1 is the last version I can control. In fact, I've been intending for several years to transition to a Linux distro for my next PC because I hate Windows 10. But I'm in no hurry to do this and would prefer to continue using my current PC indefinitely. Running it hot for several hours (at least) for an initial build of a Chromium pull is the last thing I'll be doing to it.\nAt this point, undertaking a very time-consuming Chromium modification project is literally a thousand times more involved for me compared to simply installing and configuring one of Straver's browsers (Pale Moon or Basilisk) as a backup option to my current primary browser of Firefox ESR. (I probably won't do that just yet, because I'm content with my ESR setup, but it wouldn't take me more than a few hours to have a Basilisk with Classic Theme Restorer configured to my liking.)\nI mention all of this for context. I'm still interested in modifying Chromium because it will have the best web compatibility in the long run. But, practically-speaking, so long as Firefox or Straver's forks are a viable primary browser for me, I would prefer to stick with them. There are a number of things I prefer about the Firefox way, including privacy settings and the quality of Gecko rendering, compared to Chromium.\nFinally, I'll add that while I suspect Mozilla will eventually conform to Google's V3 API at some point, that wouldn't be for at least another year. So there's no urgency for me here.\n. There's one more point I'd like to make. Please don't think I'm a Mozilla advocate here. That's not my intention.\nIn fact, I don't like the Mozilla organization. Nor do I trust them to make good or even ethical decisions. But, as I've stated, its ESR browser is my best choice as primary right now.\nI must state that my ESR setup is highly customized to the point that the browser does not emit a single packet unless I expressly want it to. (I've verified it with Wireshark.) This took a number of hours to do, using the thorough documentation of the ghacks-user project to disable a bunch of settings. I honestly consider it an \"UnMozillad Firefox\" :)\nIt helps a lot that all of my extensions are either my own creation or modified by me. So they're all unsigned, of course, and I had to fully disable add-on updates to not have the browser ping Mozilla's add-on servers.\nOne advantage of Straver's forks is that I got this same level of control much easier. He doesn't do any shady crap like Mozilla. Seriously, default Firefox settings result in almost Chrome level of phoning home.\n(No way I can completely UnGoogle my Chrome install on Windows, of course, but I have done so to the extents possible in settings. As a supplemental browser, I only use Chrome for a few websites, so I'm okay with it.). It just occurred to me, perhaps there's a way to do Chromium development without need of my own build machine.\nIdeally, I could just pull the code here on GitHub and run a Travis build. But I don't know much about the particulars.\nQuestion: Does anyone know if this is feasible? Or is there another online service I could use?\n. @Eloston thanks for your thoughtful reply. I appreciate your advice. In fact, I suggest adding it to your developing doc.\nI read several of the Chromium docs last week when I first looked into this. I was pleasantly surprised how helpful they are. It was a good first impression.\nBut, all things considered, I probably won't be interested in using a modified Chromium until uBO becomes unviable in Chrome. I'm guessing that will be in the next 18 months, depending on Google's TBA timeframe for phasing out webRequest.\nThis doesn't mean I'm not interested in exploring the integration of a custom filter engine. I'm actually going to continue looking into that in the near future. I already have very clear notions of what a custom filter engine should be; for me, that's the easy part because I've tailored my current uBO fork to be just that. Of course there are other essential considerations, which is what I'll be focusing on as I look at relevant portions of the code. But without a build machine of my own or a pressing need to make these changes, it'll just be a learning exercise for now.. ",
    "mikhoul": "\nI'll probably go with a more Bromite way of doing things to start. Eventually I'd incorporate more robust capabilities, possibly borrowing from the Brave code. Lots of details TBD, of course, but I mention it as food for thought here.\n\nWhere I could follow your progress on a new Chromium Fork ?  \nLike you know from the other Nano thread I'm really interested by a new Chromium fork that would stay retro-compatible with V2 Manifest  but that would also be compatible with the future V3 manifest.\nRegards :octocat: . ",
    "gmt": "FYI the chromium build requirements are just crazy.  If you want to hack on the chromium source, you really need a beefy machine with a lot of ram, the more cores the better.  On my old 8-core-8-thread-32G system it takes about 12 hours to build, and I have to turn off debug symbols or else I run out of ram.  On my new 16-core-32-thread-64G system, it takes two or three hours without symbols and three or four with debug symbols.\nOn the relatively rare occasions I do chromium-related development I usually am worried about packaging for Gentoo, not chromium itself, per-se.  Which means, my workflow is quite different from the standard one.  But the standard workflow, which I do also have limited experience with, is considerably more, not less, resource intensive.\nMy point is, you are going to need some horse-power, probably more than you'd like to pay Amazon for, unless you're made of money.  You might look into if the gcc compute cluster, a free resource hosted by FSF France for open-source projects needing access to a bunch of heterogeneous computer systems, could help you.\nThere are some bureaucratic hurdles to getting access (human review is involved) but they deliver a fair amount of compute for free.  If you go this route, please mind your resource consumption; those are shared compute resources like in the bad old days, and there is an assumption that folks will not gobble up all the resources on those machines, so you need to play nice.\nFor the record, I landed here because I share your concerns about this manifest v3 business, and have come to the same (or worse) conclusions as you about the likely outcomes.  In my (hopefully paranoid) imagination, their incentive is to create as much \"counter-fud,\" to coin a phrase, as possible, essentially stringing everyone along with vague hopes that the inconceivable will not happen until it's too late, and \ncoordinated code-drops and a simultaneous web-store revamp drop this on the unsuspecting public like a bomb.\nHopefully I'm wrong.  I definitely have no insider knowledge and only a very cursory understanding of the technical stuff involved.  But I'm not optimistic at all, personally -- it seems to me they have decided that, with the public increasingly concerned about privacy, now is the time to monetize their investment in web-client software, leveraging it as a means to limit the threat of the privacy arms race to their future revenue.\n. My old workstation is pretty darn slow (bulldozer) and largely built with -Og -ggdb3 which leads to high build-time memory demands.  Also maybe I'm exxagerating the numbers a little bit... definitely in that ballpark but I never measured scientifically.\nBtw I've noticed for my chromium builds ccache always got huge \"hit\" percentages compared to other projects I've tried it with, when I activate it.  This can be a lifesaver under the right circumstances (or lead to segfaults in the wrong ones).. ",
    "pipboy96": "There's way too much off-topic conversation here. @Eloston can you hide all these comments (mostly about hardware \"needed\" to build Chromium) using GitHub's new feature (like this one) and if possible make an official comment, even if it's just:\n\nRight now, there are no concrete plans related to this issue.. Related: EFForg/https-everywhere#17268, EFForg/privacybadger#2273.. @Eloston Excuse me, I only skimmed over the first page of issues looking for words like \"Manifest v3\" and \"declarativeNetRequest\" before asking.. @Eloston No problem.. \n",
    "davidhuff2014": "My current build system works so I'll upgrade and see what happens, I'd prefer that exercise over dropping flags. . Unfortunately clang-8 gave the same initial response. But now, looking at it again it appears it is ld that is having the problem not clang?\ncp base/numerics/safe_conversions_arm_impl.h base/numerics/safe_math_arm_impl.h tools/gn/base/numerics\n./tools/gn/bootstrap/bootstrap.py --skip-generate-buildfiles -j4 -o out/Release/gn\nninja: Entering directory/tmp/src/ungoogled-chromium-master/build/src/out/Release/gn_build'\n[175/175] LINK gn\nFAILED: gn \nclang++-8 -Wl,--stats -Wl,--stats -O3 -fdata-sections -ffunction-sections -Wl,--gc-sections -Wl,-strip-all -Wl,--icf=all -Wl,--as-needed -o gn -Wl,--start-group tools/gn/gn_main.o base.a gn_lib.a -Wl,--end-group -ldl -lpthread -lnspr4 -levent\n/usr/bin/ld: unrecognized option '--icf=all'\n/usr/bin/ld: use the --help option for usage information\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 101, in \n    sys.exit(main(sys.argv[1:]))\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 84, in main\n    ['ninja', '-C', gn_build_dir, 'gn', '-w', 'dupbuild=err', '-j'+str(options.jobs)])\n  File \"/usr/lib/python2.7/subprocess.py\", line 190, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['ninja', '-C', '/tmp/src/ungoogled-chromium-master/build/src/out/Release/gn_build', 'gn', '-w', 'dupbuild=err', '-j4']' returned non-zero exit status 1\ndebian/rules:78: recipe for target 'out/Release/gn' failed\n. Setting use_lld=true in the gn_flags.map for ubuntu_bionic did not work for me.\nMoving ld out of the way and copying ld64.lld-7 as ld,  did work.. I too added lldb-7 but it didn't change the outcome. I tried setting the gn_flags.map with use_lld=true and it too had the same outcome. There may be somewhere else where the flags can be set that I am not aware of. I agree it  is calling the wrong linker, copying ld64.lld-7 as ld did allow it to build. I was also able to build by patching out the --icf=all appends everywhere I could find them, was just hoping to make a completely clean build.. Set both flags as you suggested and it got all the way into ninja but:[451/18196] ACTION //chrome/test/chromedriver:embed_version_in_cpp(//build/toolchain/linux/unbundle:default)\nERROR:root:Git error: rc=128, output=''\n[2832/18196] LINK ./chrome_sandbox\nFAILED: chrome_sandbox \npython \"../../build/toolchain/gcc_link_wrapper.py\" --output=\"./chrome_sandbox\" -- clang++-7 -pie -Wl,--build-id=sha1 -fPIC -Wl,-z,noexecstack -Wl,-z,now -Wl,-z,relro -Wl,-z,defs -Wl,--no-as-needed -fuse-ld=lld -Wl,--icf=all -Wl,--color-diagnostics -flto=thin -Wl,--thinlto-jobs=8 -Wl,--thinlto-cache-dir=thinlto-cache -Wl,--thinlto-cache-policy,cache_size=10\\%:cache_size_bytes=10g:cache_size_files=100000 -Wl,--lto-O0 -fwhole-program-vtables -m64 -Wl,-O2 -Wl,--gc-sections -rdynamic -fsanitize=cfi-vcall -fsanitize=cfi-icall -pie -Wl,-rpath-link=. -Wl,--disable-new-dtags -Wl,--stats,-fuse-ld=lld -Wl,--stats,-fuse-ld=lld -o \"./chrome_sandbox\" -Wl,--start-group @\"./chrome_sandbox.rsp\"  -Wl,--end-group   -latomic -ldl -lpthread -lrt \nld.lld: error: unknown argument: -fuse-ld=lld\nld.lld: error: unknown argument: -fuse-ld=lld\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n[2835/18196] CXX obj/sandbox/linux/sandbox_services/syscall_wrappers.o\nninja: build stopped: subcommand failed.\ndebian/rules:100: recipe for target 'override_dh_auto_build-arch' failed\nmake[1]:  [override_dh_auto_build-arch] Error 1\nmake[1]: Leaving directory '/tmp/src/ungoogled-chromium-master/build/src'\ndebian/rules:75: recipe for target 'binary' failed\nmake:  [binary] Error 2\ndpkg-buildpackage: error: debian/rules binary subprocess returned exit status 2\n`. Something may have changed in the setup, this did build with only gn flag set this time. Won't have time until tonight to verify the video.. Adding only use_lld=true to gn_flags.map for ubuntu_bionic worked. . Adding only use_lld=true to gn_flags.map for ubuntu_bionic worked. I tested several clickbait videos on youtube and one that previously failed all the time with the previous built and all were very good quality. . As an additional note, some days after the build I had some video issues of the same nature I'd experienced previously. Turning off hardware acceleration reduced those rare remaining occurrences to zero.. ",
    "psilocibin": "[175/175] LINK gn\nFAILED: gn \nclang++-7 -Wl,--stats -Wl,--stats -O3 -fdata-sections -ffunction-sections -Wl,--gc-sections -Wl,-strip-all -Wl,--icf=all -Wl,--as-needed -o gn -Wl,--start-group tools/gn/gn_main.o base.a gn_lib.a -Wl,--end-group -ldl -lpthread -lnspr4 -levent\n/usr/bin/ld: unrecognized option '--icf=all'\n/usr/bin/ld: use the --help option for usage information\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nninja: build stopped: subcommand failed.\nTraceback (most recent call last):\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 101, in <module>\n    sys.exit(main(sys.argv[1:]))\n  File \"./tools/gn/bootstrap/bootstrap.py\", line 84, in main\n    ['ninja', '-C', gn_build_dir, 'gn', '-w', 'dupbuild=err', '-j'+str(options.jobs)])\n  File \"/usr/lib/python2.7/subprocess.py\", line 190, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['ninja', '-C', '/home/user/ungoogled-chromium/build/src/out/Release/gn_build', 'gn', '-w', 'dupbuild=err', '-j8']' returned non-zero exit status 1\nmake[1]: *** [debian/rules:80: out/Release/gn] Error 1\nmake[1]: Leaving directory '/home/user/ungoogled-chromium/build/src'\nmake: *** [debian/rules:75: binary] Error 2\ndpkg-buildpackage: error: debian/rules binary subprocess returned exit status 2\nubuntu_cosmic\nclang-7 --version\nclang version 7.0.0-3 (tags/RELEASE_700/final)\n. installed lldb-7 and it works now\n. ",
    "spotlightishere": "Cannot reproduce, but instead of your Python 2.7.13, Python 3 should work. The script seems to want such as well.\nhttps://github.com/Eloston/ungoogled-chromium/blob/c68b9f4916d6a34dc6c843a565bfd1ca08b9fe4c/get_package.py#L1. ",
    "restfuladi": "I don't mind using Resilio or Syncthing to sync the entire profile. Which file/folder should I sync? Using Mac and Windows 10.. ",
    "dryshirt": "I tried out Resilio Sync for a couple days, and although it works most of the times, there are a couple key points which are definitely worsening the issue instead of fixing it:\n\nUpdate intervals: Whenever there is an update to the directory, Resilio Sync attempts to send the changes to all other peers. Paired with an unstable or slow network (like my school's, for example) - this quickly becomes tiresome. There is no way to manually adjust sync intervals in order to reduce bandwidth usage (not that I would anyways - with the frequency of changes that are made, syncing on any reasonable interval of time (>1min) isn't very useful due to the large amount of changes made)\nFile sync failure/corruption: If Chromium is opened and incoming changes are made, then after restarting the app and visiting the settings page you will be told settings have been corrupted, and that they have been reset to default. This is by far the largest issue: there is no built-in method to prevent the corruption from happening, and it can happen very easily. After it happens, the user is forced to reconfigure their settings - there is no failsafe to easily revert changes.\nFile versioning: Another problem occurs after some usage: if the sync service doesn't start itself reliably, then point 2 happens repeatedly. This doesn't really have anything to do with Chromium, but it's worth thinking about when recommending third-party services in order to synchronize files across two or more systems.\n\nApart from that, I suppose the solution works as a temporary bandaid. However, after navigating the initial setup (and following mess), and the problem-filled days after that, I won't be likely to try it again.. ",
    "warmaster345": "I'm having the same issue. It seems that disabling safe browsing doesn't fix all problems, windows-disable-rcpy and windows-disable-reorder-fix-linking patches are still broken with the last chromium version on windows\n. > @hardhub can you try again with latest version?\nI have tried with the latest version, the same error occurred. Windows 10 x64, VS 2017. Thanks to @r4sas patches the goal is close, but I'm still getting errors.\n[15871/20080] CXX obj/chrome/common/media_router/mojo/media_router/media_router_jumbo_1.obj\nninja: build stopped: subcommand failed.\n. ",
    "r4sas": "I also stopped here, thats why I said about need for additional patching.. Looks like something wrong with gn output...\nrule __chrome_elevation_service_elevation_service_idl_idl_action___build_toolchain_win_win_clang_x64__rule\n  command = D$:/devel/Python27/python.exe ../../build/toolchain/win/midl.py environment.x64 gen/chrome/elevation_service none ${source_name_part}.tlb ${source_name_part}.h ${source_name_part}.dlldata.c ${source_name_part}_i.c ${source_name_part}_p.c ${in} /char signed /env x64 /Oicf\n  description = ACTION //chrome/elevation_service:elevation_service_idl_idl_action(//build/toolchain/win:win_clang_x64)\n  restat = 1\n  pool = build_toolchain_action_pool\nI'm about ${source_name_part}, ${in} in command line.\nadd:\nIf someone understand GN's scripts, please help with build\\toolchain\\win\\midl.gni and build\\win\\message_compiler.gni.\nadd2:\nIn gni scripts all correct.\nProblem in build/toolchain/win/midl.py which store all processed files in temp directory.\nWill add in this post patch later.\npatch for testing\n```diff\n--- a/build/toolchain/win/midl.py\n+++ b/build/toolchain/win/midl.py\n@@ -171,12 +171,6 @@\n   if sys.platform != 'win32':\n     return 0\n\n\nOn Windows, run midl.exe on the input and check that its outputs are\n\n\nidentical to the checked-in outputs (after possibly replacing their main\n\n\nclass guid).\n\ntmp_dir = tempfile.mkdtemp()\n\ndelete_tmp_dir = True\n   # Read the environment block from the file. This is stored in the format used\n   # by CreateProcess. Drop last 2 NULs, one for list terminator, one for\n   # trailing vs. separator.\n@@ -184,13 +178,14 @@\n   env_dict = dict([item.split('=', 1) for item in env_pairs])\n\nargs = ['midl', '/nologo'] + list(flags) + [\n-      '/out', tmp_dir,\n+      '/out', outdir,\n       '/tlb', tlb,\n       '/h', h,\n       '/dlldata', dlldata,\n       '/iid', iid,\n       '/proxy', proxy,\n       idl]\n+\n   try:\n     popen = subprocess.Popen(args, shell=True, env=env_dict,\n                              stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n@@ -209,29 +204,11 @@\n     if popen.returncode != 0:\n       return popen.returncode\n\nfor f in os.listdir(tmp_dir):\n\nZapTimestamp(os.path.join(tmp_dir, f))\n\n\nNow compare the output in tmp_dir to the copied-over outputs.\n\ndiff = filecmp.dircmp(tmp_dir, outdir)\nif diff.diff_files:\nprint 'midl.exe output different from files in %s, see %s' \\\n% (outdir, tmp_dir)\nfor f in diff.diff_files:\nif f.endswith('.tlb'): continue\nfromfile = os.path.join(outdir, f)\ntofile = os.path.join(tmp_dir, f)\nprint ''.join(difflib.unified_diff(open(fromfile, 'U').readlines(),\nopen(tofile, 'U').readlines(),\nfromfile, tofile))\ndelete_tmp_dir = False\nprint 'To rebaseline:'\nprint '  copy /y %s* %s' % (tmp_dir, source)\nsys.exit(1)\nfor f in os.listdir(outdir):\nZapTimestamp(os.path.join(outdir, f))\n     return 0\n   finally:\nif os.path.exists(tmp_dir) and delete_tmp_dir:\nshutil.rmtree(tmp_dir)\nreturn 0\n\nif name == 'main':\n``. >windows-disable-reorder-fix-linking.patch` still doesn't apply cleanly according to the CI check, but I'll merge anyway to let you guys make progress on Windows.\nI can create PR with fix of this fuzz'es if needed.. ",
    "sgqy": "ubuntu server 18.04.2.\nbuilding 72.0.3626.122-1, same error.\n\nI compile & installed icu 63 directly. Then ignore dependancy, it works.\nBut it may destroy the default icu on system. And it is dangerous to use.\nMaybe I should wait for icu-63.deb first.. ",
    "pouledodue": "same as #672\nproblem is like me you did \ngit clone https://github.com/Eloston/ungoogled-chromium.git\nbut you have to do: \ngit clone --branch 71.0.3578.98-2 https://github.com/Eloston/ungoogled-chromium.git\nbefore following those instructions: \n```\nRun from inside the clone of the repository\nmkdir -p build/src/ungoogled_packaging\npython3 get_package.py macos build/src/ungoogled_packaging\ncd build/src\n./ungoogled_packaging/build.sh\n```. ",
    "patchouli69ou": "/build/config/compiler/BUILD.gn section in fix-gn-safe_browsing.patch seems to be the cause of the problem. You can compile if you delete this section from the patch file, though I don't know how safe that is.. ",
    "flagg19": "I've the latest version available on apt for debian 9:\nlibavformat-dev is already the newest version (7:3.2.12-1~deb9u1).\nlibavcodec-dev is already the newest version (7:3.2.12-1~deb9u1).\nIn the header /usr/include/x86_64-linux-gnu/libavcodec/avcodec.h there is no AV_CODEC_ID_AV1\nThis may have something to do with it: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=905595\nSo i guess it's not a problem of ungoogled-chromium, but something wrong with the official version of libavformat-dev & libavcodec-dev for debian 9.. ",
    "23rd": "Please ensure you have read FAQ.. ",
    "laokong911": "I am so sorry! do not lookout it ! thank you.... ",
    "congma": "The version is 71.0.3578.98.\nI don't think this is the same as #688 though. This request is about the behaviour triggered when typing an URL by hand without the scheme part.. Admittedly, my usage pattern isn't very typical. For daily browsing I use Firefox. I use the ungoogled-chromium only temporarily when accessing the sites that I have to use (insurance, some airline companies, for example) but somehow break under Firefox. Those sites are mostly not very well tested in the first place (as you might infer from their non-compatibility with more than one browser), and they don't usually fail or fall back gracefully.\nI agree with @tie that for the daily usage cases the default to https:// schema is more beneficial than inconvenient or problematic. What I was requesting wouldn't change this for the default usage, as https:// would still be the default of the default scheme ;) The difference is whether this can be modified or not. Does this fit into the goal of ungoogled-chromium? Will this take too much effort if it's to be implemented?. ",
    "steemandlinux": ". Proxy controller blocks proxy extensions every 7 days and may cause data leakage through a direct connection. There is no possibility to disable it through the settings.. ",
    "fujitsuDev": "Same error with:\n\nOne other PC under Windows 10\nLatest ungoogled-chromium 64-bits version 72.0.3626.122-1 with chrlauncher default parameters\nChromiumCommandLine=--user-data-dir=..\\profile --no-default-browser-check --allow-outdated-plugins --disable-logging --disable-breakpad\n3 latest versions of KeePassXC-Browser: 1.3.2, 1.3.1 and 1.3.0\n\n\n\nCan't install CRX file packaged with Chromium from downloaded extension folder\n\n\n\nCan't install any extension from the Chrome Web Store\n\n. @TCB13 I downloaded CRX file from Web Store by following the procedure, but impossible to install CRX within developer mod anyway under Windows 7 or 10: can't drag and drop file (see 2nd screenshot above).. Ok, thats works now! Thanks!\nObviously KeePassXC-Browser don't allow unpacked installation, but only CRX from Web Store.\nI don't understand why, but the most important thing, is that works.. > > Obviously KeePassXC-Browser don't allow unpacked installation\n\nHave you experienced this with other extensions? If not, I guess this can be closed. @Eloston\n\nOnly KeePassXC at this time. Works with others extensions tested.. ",
    "NickKartha": "What's your question? Perhaps, it's best starting a repository with further description of the project you're proposing. I understand that Safari is the main standard in Apple's closed garden ecosystem environment. There might not be a requirement for jaibreaking the device for this. iOS is still an evolving standard. \n\"it would not be worthwile to make a Ungoogled Chromium for iOS since iOS does not allow [this]\" is a really depressing statement from a developer standpoint. Multi-platform availability is a goal in almost every project. It's too strange for a platform, that too a popular platform, to have limited support like this. A little more clarity is definitely needed here.. ",
    "boozedog": "Sorry this was meant as a feature request, not so much as a question. ",
    "vovkasm": "Followup. When I open console for devtools itself (thanks https://stackoverflow.com/a/27661701)\nI see this:\n\nSeems Tracing API removed?. I think it is because of this patch: https://github.com/Eloston/ungoogled-chromium/blob/master/patches/debian_buster/disable/tracing.patch. Refer to same bug report for debian folks https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=922431\n. ",
    "mymortal": "\n@mymortal\u4f60\u770b\u4e86\uff03675\u5417\uff1f\n\nYes, I have seen it, and reference\nhttps://github.com/Eloston/ungoogled-chromium/issues/639#issuecomment-466478108\nMethods. > @mymortal it only works up to 71.0.3578.98-2. You can't build anything newer than that.\nthank you . "
}